<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005240">
<title confidence="0.954621">
Dependency and relational structure in treebank annotation
</title>
<author confidence="0.943632">
Cristina BOSCO, Vincenzo LOMBARDO
</author>
<affiliation confidence="0.893913">
Dipartimento di Informatica, Universit`a di Torino
</affiliation>
<address confidence="0.864300666666667">
Corso Svizzera 185
10149 Torino,
Italia,
</address>
<email confidence="0.996081">
bosco,vincenzo@di.unito.it
</email>
<sectionHeader confidence="0.9938" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999011952380953">
Among the variety of proposals currently mak-
ing the dependency perspective on grammar
more concrete, there are several treebanks
whose annotation exploits some form of Rela-
tional Structure that we can consider a general-
ization of the fundamental idea of dependency
at various degrees and with reference to differ-
ent types of linguistic knowledge.
The paper describes the Relational Structure as
the common underlying representation of tree-
banks which is motivated by both theoretical
and task-dependent considerations. Then it
presents a system for the annotation of the Rela-
tional Structure in treebanks, called Augmented
Relational Structure, which allows for a system-
atic annotation of various components of lin-
guistic knowledge crucial in several tasks. Fi-
nally, it shows a dependency-based annotation
for an Italian treebank, i.e. the Turin Univer-
sity Treebank, that implements the Augmented
Relational Structure.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992006419642857">
Different treebanks use different annotation
schemes which make explicit two distinct but
interrelated aspects of the structure of the sen-
tence, i.e. the function of the syntactic units
and their organization according to a part-whole
paradigm. The first aspect refers to a form of
Relational Structure (RS), the second refers to
its constituent or Phrase Structure (PS). The
major difference between the two structures is
that the RS allows for several types of rela-
tions to link the syntactic units, whilst the PS
involves a single relation ”part-of”. The RS
can be seen as a generalization of the depen-
dency syntax with the syntactic units instanti-
ated to individual words in the dependency tree
(Mel’ˇcuk, 1988). As described in many theo-
retical linguistic frameworks, the RS provides a
useful interface between syntax and a seman-
tic or conceptual representation of predicate-
argument structure. For example, Lexical Func-
tional Grammar (LFG) (Bresnan, 1982) collo-
cates relations at the interface between lexicon
and syntax, Relational Grammar (RG) (Perl-
mutter, 1983) provides a description of the sen-
tence structure exclusively based on relations
and syntactic units not structured beyond the
string level.
This paper investigates how the notion of RS
has been applied in the annotation of tree-
banks, in terms of syntactic units and types
of relations, and presents a system for the
definition of the RS that encompasses several
uses in treebank schemata and can be viewed
as a common underlying representation. The
system, called Augmented Relational Struc-
ture (ARS) allows for an explicit representa-
tion of the three major components of linguistic
structures, i.e. morpho-syntactic, functional-
syntactic and semantic. Then the paper shows
how a dependency-based annotation can de-
scend on ARS, and describes the ARS-based an-
notation of a dependency treebank for Italian,
the Turin University Treebank (TUT), which is
the first available treebank for Italian, with a
few quantitative results.
The paper is organized as follows. The next
section investigates both the annotation of RS
in treebanks and the major motivations for the
use of RS from language-specific issues and NLP
tasks implementation; then we present the ARS
system; finally, we show the dependency anno-
tation of the TUT corpus.
2 Annotation of the Relational
Structure
In practice, all the existing treebank schemata
implement some form of relational structure.
Annotation schemata range from pure (depen-
dency) RS-based approaches to RS-PS combi-
nations (Abeill´e, 2003).
Some treebanks consider the relational infor-
mation as the exclusive basis of the annotation.
The Prague Dependency Treebank ((Hajiˇcov´a
and Ceplov´a, 2000), (B¨ohmov´a et al., 2003))
implements a three level annotation scheme
where both the analytical (surface syntactic)
and tectogrammatical level (deep syntactic and
topic-focus articulation) are dependency-based;
the English Dependency Treebank (Rambow
et al., 2002) implements a dependency-based
mono-stratal analysis which encompasses sur-
face and deep syntax and directly represents the
predicate-argument structure. Other projects
adopt mixed formalisms where the sentence is
split in syntactic subunits (phrases), but linked
by functional or semantic relations, e.g. the Ne-
gra Treebank for German ((Brants et al., 2003),
(Skut et al., 1998)), the Alpino Treebank for
Dutch (van der Beek et al., 2002), and the Lingo
Redwood Treebank for English (Oepen et al.,
2002). Also in the Penn Treebank ((Marcus
et al., 1993), (Marcus et al., 1994)) a limited
set of relations is placed over the constituency-
based annotation in order to make explicit the
(morpho-syntactic or semantic) roles that the
constituents play.
The choice of a RS-based annotation schema
can depend on theoretical linguistic motivations
(a RS-based schema allows for an explicit, fine-
grained representation of several linguistic phe-
nomena), task-dependent motivations (the RS-
based schema represents the linguistic informa-
tion involved in the task(s) at hand), language-
dependent motivations (the relational structure
is traditionally considered as the most adequate
representation of the object language).
Theoretical motivations for exploiting repre-
sentations based on forms of RS was developed
in the several RS-based theoretical linguistic
frameworks (e.g. Lexical Functional Grammar,
Relaional Grammar and dependency grammar),
which allow for capturing information involved
at various level (e.g. syntactic and semantic)
in linguistic structures, and grammatical for-
malisms have been proposed with the aim to
capture the linguistic knowledge represented in
these frameworks. Since the most immediate
way to build wide-coverage grammars is to
extract them directly from linguistic data (i.e.
from treebanks), the type of annotation used in
the data is a factor of primary importance, i.e.
a RS-based annotation allows for the extraction
of a more descriptive grammar1.
</bodyText>
<footnote confidence="0.976699">
1See (Mazzei and Lombardo, 2004a) and (Mazzei and
Lombardo, 2004b) for experiments of LTAG extraction
from TUT.
</footnote>
<bodyText confidence="0.9999006">
Task-dependent motivations rely on how the
annotation of the RS can facilitate some
processing aspects of NLP applications. The
explicit representation of predicative structures
allowed by the RS can be a powerful source
of disambiguation. In fact, a large amount of
ambiguity (such as coordination, Noun-Noun
compounds and relative clause attachment) can
be resolved using such a kind of information,
and relations can provide a useful interface
between syntax and semantics. (Hindle and
Rooth, 1991) had shown the use of dependency
in Prepositional Phrase disambiguation, and
the experimental results reported in (Hock-
enmaier, 2003) demonstrate that a language
model which encodes a rich notion of predicate
argument structure (e.g. including long-range
relations arising through coordination) can
significantly improve the parsing performances.
Moreover, the notion of predicate argument
structure has been advocated as useful in
a number of different large-scale language-
processing tasks, and the RS is a convenient
intermediate representation in several applica-
tions (see (Bosco, 2004) for a survey on this
topic). For instance, in Information Extraction
relations allows for recognizing different guises
in which an event can appear regardless of the
several different syntactic patterns that can be
used to specify it (Palmer et al., 2001)2. In
Question Answering, systems usually use forms
of relation-based structured representations of
the input texts (i.e. questions and answers)
and try to match those representations (see
e.g. (Litkowski, 1999), (Buchholz, 2002)).
Also the in-depth understanding of the text,
necessary in Machine Translation task, requires
the use of relation-based representations where
an accurate predicate argument structure is a
critical factor (Han et al., 2000)3.
Language-dependent motivations rely on the
fact that the dependency-based formalisms has
been traditionally considered as the most ade-
quate for the representation of free word order
languages. With respect to constituency-based
</bodyText>
<footnote confidence="0.997179">
2Various approaches to IE (Collins and Miller, 1997)
address this issue by using relational representations,
that is forms of ”concept nodes” which specifies a trig-
ger word (usually a Verb) and also forms of mapping
between the syntactic and the semantic relations of the
trigger.
3The system presented in (Han et al., 2000) gener-
ates the dependency trees of the source language (Ko-
rean) sentences, then directly maps them to the trans-
lated (English) sentences.
</footnote>
<bodyText confidence="0.999976533333333">
formalisms, free word order languages involves a
large amount of discontinuous constituents (i.e.
constituents whose parts are not contiguous in
the linear order of the sentence). In practice, a
constituency-based representation was adopted
for languages with rather fixed word order
patterns, like English (Penn Treebank), while
a dependency representation for languages
which allow variable degrees of word order
freedom, such as Czech (see Prague Depen-
dency Treebank) or Italian (as we will see later,
TUT). Nevertheless, in principle, since the
representation of a discontinuous constituent X
can be addressed in various ways (e.g. by in-
troducing lexically empty elements co-indexed
with the moved parts of X), the presence to
a certain extent of word order freedom does
not necessarily mean that a language has to be
necessarily annotated according to a relation-
based format rather than a constituency-based
one. Moreover, free word order languages can
present difficulties for dependency-based as
well as for constituency-based frameworks (e.g.
non-projective structures). The development
of dependency-based treebanks for English (see
English Dependency Treebank) together with
the inclusion of relations in constituency-based
treebanks (see Penn Treebank) too, confirms
the strongly prevailing relevance of motivations
beyond the language-dependent ones.
</bodyText>
<sectionHeader confidence="0.7383395" genericHeader="method">
3 The Augmented Relational
Structure
</sectionHeader>
<bodyText confidence="0.999841666666667">
A RS consists of syntactic units linked by re-
lations. An Augmented Relational Structure
(ARS) organizes and systematizes the informa-
tion usually associated in existing annotations
to the RS, and includes not only syntactic ,
but also linguistic information that can be rep-
resented according to a dependency paradigm
and that is proximate to semantics and un-
derlies syntax and morphology. Therefore the
</bodyText>
<figure confidence="0.833898333333333">
eats
rel2
John the apple
</figure>
<figureCaption confidence="0.999961">
Figure 1: A simple RS.
</figureCaption>
<bodyText confidence="0.9999778">
ARS expresses the relations and syntactic units
in terms of multiple components. We describe
the ARS as a dag where each relation is a
feature structure including three components.
Each component of the ARS-relations is use-
</bodyText>
<equation confidence="0.97284325">
morph v1
rel1
fsynt v2
sem v3
</equation>
<bodyText confidence="0.999989714285714">
The types of knowledge that many applica-
tions actually need are RS-based representa-
tions where predicate argument structure and
the associated morphological and syntactic in-
formation can operate as an interface to a
semantic-conceptual representation. All these
types of knowledge have in common the fact
that they can be described according to the de-
pendency paradigm, rather than according to
the constituency paradigm. The many applica-
tions (in particular those referring to the Penn
Treebank) which use heuristics-based transla-
tion schemes from the phrase structure to lexical
dependency (”head percolation tables”) (Ram-
bow et al., 2002) show that the access to com-
prehensive and accurate extended dependency-
based representations has to be currently con-
sidered as a critical issue for the development of
robust and accurate NLP technologies.
Now we define our proposal for the representa-
tion of the RS in treebank annotation.
</bodyText>
<figureCaption confidence="0.988923">
Figure 2: An ARS relation.
</figureCaption>
<bodyText confidence="0.999916014492753">
ful in marking both similarities and differences
among the behavior of units linked by the de-
pendency relations.
The morpho-syntactic component of the ARS
describes morpho-syntactic features of the
words involved in relations, such as their gram-
matical category. This component is useful for
making explicit the morpho-syntactic variants
of predicative structures. Instances of this kind
of variants often occur in intransitive, tran-
sitive and di-transitive predicative structures,
e.g. esplosione-esplodere (explosion - to ex-
plode) are respectively nominal and verbal vari-
ants of the intransitive structure ”something ex-
plodes”. By referring to the TUT, we can evalu-
ate the frequency of this phenomenon: in 1,500
sentences 944 Verbs occur (for a total of 4169
occurrences) and around the 30% of them are
present in the nominal variant too¢.
The functional-syntactic component identifies
the subcategorized elements, that is it keeps
apart arguments and modifiers in the pred-
icative structures. Moreover, this component
makes explicit the similarity of a same predica-
tive structure when it occurs in the sentence in
different morpho-syntactic variants. In fact, the
functional-syntactic components involved, e.g.,
in the transitive predicative structure ”some-
one declares something”, are the same in both
the nominal (dichiarazione [di innocenza]OBJ
[di John]SUBJ - John’s declaration of innocence)
and verbal realization ([John]SUBJ dichiara [la
sua innocenza]OBJ - John declares his inno-
cence) of such a predication, i.e. SUBJ and
OBJ. The distinction between arguments and
modifiers has been considered as quite problem-
atic in the practice of the annotation, even if rel-
evant from the applicative and theoretical point
of views, and is not systematically annotated in
the Penn Treebank (only in clear cases, the use
of semantic roles allows for the annotation of
argument and modifier) and in the Negra Tree-
bank. This distinction is instead usually marked
in dependency representations, e.g. in the En-
glish Dependency Treebank and in the Prague
Dependency Treebank.
The semantic component of the ARS-relations
specifies the role of words in the syntax-
semantics interface and discriminates among
different kinds of modifiers and oblique com-
plements. We can identify at least three levels
of generality: verb-specific roles (e.g. Runner,
Killer, Bearer); thematic roles (e.g. Agent, In-
strument, Experiencer, Theme, Patient); gener-
alized roles (e.g. Actor and Undergoer). The
use of specific roles can cause the loss of useful
generalizations, whilst too generic roles do not
describe with accuracy the data. An example of
annotation of semantic roles is the tectogram-
matical layer of the Prague Dependency Tree-
bank.
ARS features a mono-stratal approach. By fol-
lowing this strategy, the annotation process can
be easier, and the result is a direct represen-
tation of a complete predicate argument struc-
ture, that is a RS where all the information
(morpho-syntactic, functional-syntactic and se-
mantic) are immediately available. An alterna-
tive approach has been followed by the Prague
</bodyText>
<footnote confidence="0.965973333333333">
4This statistics does not take into consideration the
possible polysemic nature of words involved.
5See, for instance, in LFG and RG.
</footnote>
<bodyText confidence="0.999724894736842">
Dependency Treebank, which is featured by
a three levels annotation. This case shows
that the major difference between the syntactic
(analytic) and the semantic (tectogrammatical)
layer consists in the inclusion of empty nodes
for recovering forms of deletion ((B¨ohmova et
al., 1999), (Hajiˇcov´a and Ceplov´a, 2000)). But
this kind of information does not necessarily re-
quires a separated semantic layer and can be
annotated as well in a mono-stratal represen-
tation, like the English Dependency Treebank
(Rambow et al., 2002) does.
The tripartite structure of the relations in ARS
guarantees that different components can be ac-
cessed separately and analyzed independently
(like in (Montemagni et al., 2003) or in (Ram-
bow et al., 2002)). Furthermore, the ARS al-
lows for forms of annotation of relations where
not all the features are specified too. In fact, the
ARS-relations which specify only a part of com-
ponents allow for the description of syntactic
grammatical relations which do not correspond
with any semantic relation, either because they
have a void semantic content or because they
have a different structure from any possible cor-
responding semantic relation (i.e. there is no
semantic relation linking the same ARS-units
linked by the syntactic one). Typical relations
void of semantic content can link the parts of ex-
pressions not compositionally interpretable (id-
ioms), for instance together with with in to-
gether with. While a classic example of a non-
isomorphic syntactic and semantic structure is
one which involves the meaning of quantifiers:
a determiner within a NP extends its scope be-
yond the semantic concept that results from the
interpretation of the NP. Another example is
the coordination where the semantic and syn-
tactic structure are often considered as non iso-
morphic in several forms of representation.
The ARS-relations including values for both
functional-syntactic and semantic components
may be used in the representation of grammat-
ical relations which participate into argument
structures and the so-called oblique cases (see
Fillmore and (Hudson, 1990)), i.e. where the
semantic structures are completely isomorphic
to the syntactic structures. For example, a
locative adjunct like in the garden in John was
eating fish in the garden is represented at the
syntactic level as a Prepositional Phrase play-
ing the syntactic function locative in the Verb
Phrase (in the Penn Treebank it could be an-
notated as a PP-LOC); the semantic concept
corresponding to the garden plays the semantic
role LOCATION in the ”eating” event stated
by the sentence.
</bodyText>
<sectionHeader confidence="0.5606905" genericHeader="method">
4 TUT: a dependency-based
treebank for Italian
</sectionHeader>
<bodyText confidence="0.9999135">
The TUT is the first available tree-
bank of Italian (freely downloadable at
http://www.di.unito.it/˜tutreeb/). The cur-
rent release of TUT includes 1,500 sentences
corresponding to 38,653 tokens (33,868 words
and 4,785 punctuation marks). The average
sentence length is of 22,57 words and 3,2
punctuation marks.
In this section, we concentrate on the major
features of TUT annotation schema, i.e. how
the ARS system can describe a dependency
structure.
</bodyText>
<subsectionHeader confidence="0.997516">
4.1 A dependency-based schema
</subsectionHeader>
<bodyText confidence="0.999957">
In Italian the order of words is fixed in non
verbal phrases, but verbal arguments and mod-
ifiers can be freely distributed without affect-
ing the semantic interpretation of the sentence.
A study on a set of sentences of TUT shows
that the basic word order for Italian is Subject-
Verb-Complement (SVC), as known in litera-
ture (Renzi, 1988), (Stock, 1989), but in more
than a quarter of declarative sentences it is vi-
olated (see the following table6). Although the
</bodyText>
<table confidence="0.997394">
Permutations Occurrences
S V C 74,26%
V C S 11,38%
S C V 7,98%
C S V 3,23%
V S C 2,29%
C V S 0,77%
</table>
<tableCaption confidence="0.999938">
Table 1: Italian word order
</tableCaption>
<bodyText confidence="0.9998106">
SVC order is well over the others, the fact that
all the other orders are represented quantita-
tively confirms the assumption of partial con-
figurationality intuitively set in the literature.
The partial configurationality of Italian can be
considered as a language-dependent motivation
for the choice of a dependency-based annota-
tion for an Italian treebank. The schema is
similar to that of the Prague Dependency Tree-
bank analytical-syntactic level with which TUT
</bodyText>
<footnote confidence="0.729123">
6The data reported in the table refer to 1,200 anno-
tated sentences where 1,092 verbal predicate argument
structures involving Subject and at least one other Com-
plement occur.
</footnote>
<bodyText confidence="0.9820035">
shares the following basic design principles typ-
ical of the dependency paradigm:
</bodyText>
<listItem confidence="0.9880823125">
• the sentence is represented by a tree where
each node represents a word and each
edge represents a dependency labelled by a
grammatical relation which involves a head
and a dependent,
• each single word and punctuation mark
is represented by a single node, the so-
called amalgamated words, which are words
composed by lexical units that can occur
both in compounds and alone, e.g. Verbs
with clitic suffixes (amarti (to love-you) or
Prepositions with Article (dal (from-the)),
are split in more lexical units7,
• since the constituent structure of the sen-
tence is implicit in dependency trees, no
phrases are annotated8.
</listItem>
<bodyText confidence="0.999784344827586">
If the partial configurationality makes the
dependency-based annotation more adequate
for Italian, other features of this language
should be well represented by exploiting a
Negra-like format where the syntactic units are
phrases rather than single words. For instance,
in Italian, Nouns are in most cases introduced
by the Article: the relation between Noun and
Determiner is not very relevant in a dependency
perspective, while it contributes to the defini-
tion of a clearer notion of NP in Italian than
in languages poorer of Determiners like, e.g.,
Czech. The major motivation of a dependency-
based schema is therefore theoretical and, in
particular, to make explicit in the treebank an-
notation a variety of structures typical of the
object language.
Moreover, in order to make explicit in cases
of deletion and ellipsis the predicate argument
structure, we annotate in the TUT null ele-
ments. These elements allow for the annota-
tion of a variety of phenomena: from the ”equi”
deletion which affects the subject of infinitive
Verb depending on a tensed Verb (e.g. John(1)
vuole T(1) andare a casa - John(1) want to
T(1) go home), to the various forms of gap-
ping that can affect parts of the structure of
the sentence (e.g. John va(1) a casa e Mario
T(1) al cinema - John goes(1) home and Mario
</bodyText>
<footnote confidence="0.99056">
7Referring to the current TUT corpus, we see that
around 7,7% words are amalgamated.
8If phrase structure is needed for a particular appli-
cation, it is possible to automatically derive it from the
dependency structure along with the surface word order.
</footnote>
<figure confidence="0.79869775">
dichiarava
VERB,DET+DEF
OBJ
THEME
DET+DEF,NOUN
ARG
#
giorni zingara
</figure>
<figureCaption confidence="0.99922">
Figure 3: The TUT representation of In quei
</figureCaption>
<bodyText confidence="0.95230575">
giorni Sudja la zingara dichiarava il fallimento
(In those days Sudja the gipsy declared the
bankruptcy).
T(1) to the cinema), to the pro-dropped sub-
jects typical of Italian (as well as of Portuguese
and Spanish), i.e. the subject of tensed Verbs
which are not lexically realized in the sentence
(e.g. T Va a casa - T goes home). For phenom-
ena such as equi and gapping TUT implements
co-indexed traces, while it implements non co-
indexed traces for phenomena such as the pro-
drop subject.
</bodyText>
<subsectionHeader confidence="0.999778">
4.2 An ARS-based schema
</subsectionHeader>
<bodyText confidence="0.997267684210526">
In TUT the dependency relations form the
skeleton of the trees and the ARS tripartite fea-
ture structures which are associated to these re-
lations resolve the interface between the mor-
phology, syntax and semantics. The ARS al-
lows for some form of annotation also of rela-
tions where only parts of the features are spec-
ified. In TUT this has been useful for under-
specifying relations both in automatic analysis
of the treebank (i.e. we can automatically ex-
clude the analysis of a specific component of
the relations) and in the annotation process (i.e.
when the annotator is not confident of a specific
component of a relation, he/she can leave such
a component void).
In the figure 3 we see a TUT tree.
All the relations annotated in the tree in-
clude the morpho-syntactic component, formed
by the morphological categories of the words in-
volved in the relation separated by a comma,
e.g. VERB,PREP for the relation linking the
root of the sentence with its leftmost child
(In). Some relation involves a morpho-syntactic
component where morphological categories are
composed by more elements, e.g. DET+DEF
(in DET+DEF,NOUN) for the relation linking
quei with giorni. The elements of the morpho-
syntactic component of TUT includes, in fact,
10 ”primary” tags that represent morphologi-
cal categories of words (e.g. DET for Deter-
miner, NOUN for Noun, and VERB for Verb),
and that can be augmented with 20 ”secondary”
tags (specific of the primary tags) which further
describe them by showing specific features, e.g.
DEF which specifies the definiteness of the De-
terminer or INF which specifies infiniteness of
Verb. Valid values of the elements involved in
TUT morpho-syntactic tags are 40.
By using the values of the functional-syntactic
component, TUT distinguishes among a variety
of dependency relations. In figure 3 we see the
distinction between argument, e.g. the relation
SUBJ linking the argument Sudja with the ver-
bal root of the sentence dichiarava, and the rela-
tion RMOD which represents a restrictive mod-
ifier and links the verbal root dichiarava with
in quei giorni. The dependents of Prepositions
and determiners are annotated as argument too,
according to arguments presented in (Hudson,
1990). Another distinction which is exploited
in the annotation of the sentence is that be-
tween restrictive modifier (i.e. RMOD which
links dichiarava with in quei giorni) and AP-
POSITION (i.e. non restrictive modifier linking
Sudja with la zingara), which are modifiers that
restrict the meaning of the head. Beyond these
basic distinctions, TUT schema draws other dis-
tinctions among the functional-syntactic rela-
tions and includes a large set of tags for a total
of 55 items, which are compounds of 27 pri-
mary and 23 secondary tags. These tags are
organized in a hierarchy (Bosco, 2004) accord-
ing to their different degree of specification. In
the hierarchy of relations, Arguments (ARG) in-
clude Subject (SUBJ), Object (OBJ), Indirect
Object (INDOBJ), Indirect Complement (IN-
DCOMPL), Predicative Complements (of the
Subject (PREDCOMPL+SUBJ) and of the Ob-
ject (PREDCOMPL+OBJ)). The direct conse-
quence of its hierarchical organization is the
availability of another mechanisms of under-
specification in the annotation or in the anal-
ysis of annotated data. In fact, by referring to
the hierarchy we can both annotate and analyze
relations at various degrees of specificity.
The semantic component discriminates among
</bodyText>
<figure confidence="0.996349375">
VERB,PREP VERB,NOUN
RMOD SUBJ
TIME AGENT
In Sudja
PREP,DET+DEF NOUN,DET+DEF
ARG APPOSITION
# DENOM
quei la
il
DET+DEF,NOUN
ARG
#
fallimento
DET+DEF,NOUN
ARG
#
</figure>
<bodyText confidence="0.999820355555556">
different kinds of modifiers and oblique com-
plements. The approach pursued in TUT has
been to annotate very specific semantic roles
only when they are immediately and neatly
distinguishable. For instance, by referring to
the prepositional dependents introduced by da9
(from/by), we find the following six different
values for the semantic component:
- REASONCAUSE, e.g., in gli investitori sono
impazziti dalle prospettive di guadagno (the in-
vestors are crazy because of the perspectives of
gain)
- SOURCE, e.g., in traggono benefici dalla
bonifica ([they] gain benefit from the drainage)
- AGENT, e.g., l’iniziativa e` appoggiata dagli
USA (the venture is supported by USA)
- TIME, e.g., dal ’91 sono stati stanziati 450
miliardi (since ’91 has been allocated 450 bil-
lions)
- THEME, e.g., ci`o distingue l’Albania dallo
Zaire (that distinguishes the Albany from
Zaire)
- LOC, which can be further specialized in
LOC+FROM, e.g., in da qui e` partito l’assalto
(from here started the attack), LOC+IN, e.g., in
quello che succedeva dall’altra parte del mondo
(what happened in the other side of the world),
LOC+METAPH, e.g., in l’Albania e` passata dal
lancio dei sassi alle mitragliatrici (the Albany
has passed from the stone-throwing to the ma-
chineguns).
In figure 3 the semantic component has been
annotated only in four relations, which respec-
tively represent the temporal modifier In quei
giorni of the main Verb dichiarava, the appo-
sition la zingara of the Noun Sudja, and the
arguments of the Verb, i.e. the subject Sudja la
zingara which plays the semantic role AGENT
and the object il fallimento which plays the se-
mantic role THEME. In the other relations in-
volved in this sentence a value for the semantic
component cannot be identified10, e.g. the ar-
gument of a Preposition or Determiner cannot
be semantically specified as in the case of the
verbal arguments.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999907333333333">
The paper analyzes the annotation of the RS in
the existing treebanks by referring to a notion
of RS which is a generalization of dependency.
</bodyText>
<footnote confidence="0.99345225">
9In 1,500 TUT sentences we find 591 occurrences of
this Preposition.
10In figure 3, we marked the semantic component of
these cases with q.
</footnote>
<bodyText confidence="0.999454571428572">
According to this notion, the RS includes types
of linguistic knowledge which are different, but
which have in common that they can be repre-
sented by a dependency paradigm rather than
to a constituency-based one.
The paper identifies two major motivations
for exploiting RS in treebank annotation:
language-dependent motivations that have de-
termined the use of dependency for the repre-
sentation of treebanks of free word order lan-
guages, and task-dependent motivations that
have determined a wider use of relations in tree-
banks.
In the second part of the paper, we show a sys-
tem for the annotation of RS, i.e. the ARS,
and how the ARS can be used for the an-
notation of a dependency-based treebank, the
TUT whose schema augments classical depen-
dency (functional-syntactic) relations with mor-
phological and semantic knowledge according to
the above mentioned notion of RS.
</bodyText>
<sectionHeader confidence="0.991738" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981792564356436">
A. Abeill´e, editor. 2003. Building and using
syntactically annotated corpora. Kluwer, Dor-
drecht.
A. B¨ohmova, J. Panevov´a, and P. Sgall. 1999.
Syntactic tagging: procedure for the transi-
tion from analytic to the tectogrammatical
treestructures. In Proc. of 2nd Workshop on
Text, speech and dialog, pages 34–38.
A. B¨ohmov´a, J. Hajiˇc, E. Hajiˇcov´a, and
B. Hladk´a. 2003. The Prague Dependency
Treebank: A three level annotation scenario.
In Abeill´e (Abeill´e, 2003), pages 103–127.
C. Bosco. 2004. A grammatical rela-
tion system for treebank annotation.
Ph.D. thesis, University of Torino.
http://www.di.unito.it/˜bosco/.
T. Brants, W. Skut, and H. Uszkoreit. 2003.
Syntactic annotation of a German newspaper
corpus. In Abeill´e (Abeill´e, 2003), pages 73–
87.
J. Bresnan, editor. 1982. The mental represen-
tation of grammatical relations. MIT Press,
Cambridge.
S. Buchholz. 2002. Using grammatical rela-
tions, answer frequencies and the World Wide
Web for TREC Question Answering. In Proc.
of TREC 2001, pages 502–509.
M. Collins and S. Miller. 1997. Semantic tag-
ging using a probabilistic context free gram-
mar. In Proc. of 6th Workshop on Very Large
Corpora.
E. Hajiˇcov´a and M. Ceplov´a. 2000. Deletions
and their reconstruction in tectogrammatical
syntactic tagging of very large corpora. In
Porc. of COLING 2000, pages 278–284.
C. Han, B. Lavoie, M. Palmer, O. Rambow,
R. Kittredge, T. Korelsky, N. Kim, and
M. Kim. 2000. Handling structural diver-
gences and recovering dropped arguments in a
Korean/English machine translation system.
In Proc. of AMTA 2000, pages 40–54.
D. Hindle and M. Rooth. 1991. Structural am-
biguity and lexical relations. In Proc. of ACL
91, pages 229–236.
J. Hockenmaier. 2003. Parsing with generative
models of predicate-argument structure. In
Proc. of ACL 2003.
R. Hudson. 1990. English Word Grammar.
Basil Blackwell, Oxford and Cambridge.
K.C. Litkowski. 1999. Question-answering us-
ing semantic relation triples. In Proc. of
TREC-8, pages 349–356.
M. Marcus, B. Santorini, and M.A.
Marcinkiewicz. 1993. Building a large
annotated corpus of English: The Penn
Treebank. Computational Linguistics,
19:313–330.
M. Marcus, G. Kim, M.A. Marcinkiewicz,
R. MacIntyre, A. Bies, M. Ferguson, K. Katz,
and B. Schasberger. 1994. The Penn Tree-
bank: Annotating predicate argument struc-
ture. In Proc. of HLT-94.
A. Mazzei and V. Lombardo. 2004a. Building a
large grammar for Italian. In Proc. of LREC
2004, pages 51–54.
A. Mazzei and V. Lombardo. 2004b. A com-
parative analysis of extracted grammars. In
Proc. of ECAI 2004.
I.A. Mel’ˇcuk. 1988. Dependency Syntax: theory
and practice. SUNY, Albany.
S. Montemagni, F. Barsotti, M. Battista,
and N. Calzolari. 2003. Building the Ital-
ian syntactic-semantic treebank. In Abeill´e
(Abeill´e, 2003), pages 189–210.
S. Oepen, K. Toutanova, S. Shieber, C.D. Man-
ning, D. Flickinger, and T. Brants. 2002. The
LinGO Redwoods treebank: motivation and
prliminary applications. In Proc. of COLING
2002, pages 1253–1257.
M. Palmer, J. Rosenzweig, and S. Cotton. 2001.
Automatic predicate argument analysis of the
Penn Treebank. In Proc. of HLT 2001.
D.M. Perlmutter. 1983. Studies in Relational
Grammar 1. University of Chicago Press.
O. Rambow, C. Creswell, R. Szekely, H. Taber,
and M. Walker. 2002. A dependency tree-
bank for English. In Proc. of LREC 2002,
pages 857–863.
L. Renzi, editor. 1988. Grande grammatica
italiana di consultazione, vol. I. Il Mulino,
Bologna.
W. Skut, T. Brants, B. Krenn, and H. Uszkor-
eit. 1998. A linguistically interpreted corpus
of German in newspaper texts. In Proc. of
LREC 98, pages 705–713.
O. Stock. 1989. Parsing with flexibility, dy-
namic strategies, and idioms in mind. Com-
putational Linguistics, 15(1):1–17.
L. van der Beek, G. Bouma, R. Malouf, and
G. van der Noord. 2002. The Alpino depen-
dency treebank. In Proc. of CLIN 2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.298665">
<title confidence="0.999394">Dependency and relational structure in treebank annotation</title>
<author confidence="0.999774">Cristina BOSCO</author>
<author confidence="0.999774">Vincenzo</author>
<affiliation confidence="0.8355055">Dipartimento di Informatica, Universit`a di Corso Svizzera</affiliation>
<address confidence="0.922164">10149</address>
<email confidence="0.995737">bosco,vincenzo@di.unito.it</email>
<abstract confidence="0.979197761904762">Among the variety of proposals currently making the dependency perspective on grammar more concrete, there are several treebanks whose annotation exploits some form of Relational Structure that we can consider a generalization of the fundamental idea of dependency at various degrees and with reference to different types of linguistic knowledge. The paper describes the Relational Structure as the common underlying representation of treebanks which is motivated by both theoretical and task-dependent considerations. Then it presents a system for the annotation of the Relational Structure in treebanks, called Augmented Relational Structure, which allows for a systematic annotation of various components of linguistic knowledge crucial in several tasks. Finally, it shows a dependency-based annotation for an Italian treebank, i.e. the Turin University Treebank, that implements the Augmented</abstract>
<intro confidence="0.50946">Relational Structure.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Building and using syntactically annotated corpora.</title>
<date>2003</date>
<editor>A. Abeill´e, editor.</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>2003</marker>
<rawString>A. Abeill´e, editor. 2003. Building and using syntactically annotated corpora. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A B¨ohmova</author>
<author>J Panevov´a</author>
<author>P Sgall</author>
</authors>
<title>Syntactic tagging: procedure for the transition from analytic to the tectogrammatical treestructures.</title>
<date>1999</date>
<booktitle>In Proc. of 2nd Workshop on Text, speech and dialog,</booktitle>
<pages>34--38</pages>
<marker>B¨ohmova, Panevov´a, Sgall, 1999</marker>
<rawString>A. B¨ohmova, J. Panevov´a, and P. Sgall. 1999. Syntactic tagging: procedure for the transition from analytic to the tectogrammatical treestructures. In Proc. of 2nd Workshop on Text, speech and dialog, pages 34–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A B¨ohmov´a</author>
<author>J Hajiˇc</author>
<author>E Hajiˇcov´a</author>
<author>B Hladk´a</author>
</authors>
<title>The Prague Dependency Treebank: A three level annotation scenario. In Abeill´e (Abeill´e,</title>
<date>2003</date>
<pages>103--127</pages>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2003</marker>
<rawString>A. B¨ohmov´a, J. Hajiˇc, E. Hajiˇcov´a, and B. Hladk´a. 2003. The Prague Dependency Treebank: A three level annotation scenario. In Abeill´e (Abeill´e, 2003), pages 103–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bosco</author>
</authors>
<title>A grammatical relation system for treebank annotation.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Torino.</institution>
<note>http://www.di.unito.it/˜bosco/.</note>
<contexts>
<context position="7292" citStr="Bosco, 2004" startWordPosition="1077" endWordPosition="1078">Hindle and Rooth, 1991) had shown the use of dependency in Prepositional Phrase disambiguation, and the experimental results reported in (Hockenmaier, 2003) demonstrate that a language model which encodes a rich notion of predicate argument structure (e.g. including long-range relations arising through coordination) can significantly improve the parsing performances. Moreover, the notion of predicate argument structure has been advocated as useful in a number of different large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a survey on this topic). For instance, in Information Extraction relations allows for recognizing different guises in which an event can appear regardless of the several different syntactic patterns that can be used to specify it (Palmer et al., 2001)2. In Question Answering, systems usually use forms of relation-based structured representations of the input texts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation</context>
<context position="24963" citStr="Bosco, 2004" startWordPosition="3867" endWordPosition="3868">ts presented in (Hudson, 1990). Another distinction which is exploited in the annotation of the sentence is that between restrictive modifier (i.e. RMOD which links dichiarava with in quei giorni) and APPOSITION (i.e. non restrictive modifier linking Sudja with la zingara), which are modifiers that restrict the meaning of the head. Beyond these basic distinctions, TUT schema draws other distinctions among the functional-syntactic relations and includes a large set of tags for a total of 55 items, which are compounds of 27 primary and 23 secondary tags. These tags are organized in a hierarchy (Bosco, 2004) according to their different degree of specification. In the hierarchy of relations, Arguments (ARG) include Subject (SUBJ), Object (OBJ), Indirect Object (INDOBJ), Indirect Complement (INDCOMPL), Predicative Complements (of the Subject (PREDCOMPL+SUBJ) and of the Object (PREDCOMPL+OBJ)). The direct consequence of its hierarchical organization is the availability of another mechanisms of underspecification in the annotation or in the analysis of annotated data. In fact, by referring to the hierarchy we can both annotate and analyze relations at various degrees of specificity. The semantic com</context>
</contexts>
<marker>Bosco, 2004</marker>
<rawString>C. Bosco. 2004. A grammatical relation system for treebank annotation. Ph.D. thesis, University of Torino. http://www.di.unito.it/˜bosco/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>W Skut</author>
<author>H Uszkoreit</author>
</authors>
<title>Syntactic annotation of a German newspaper corpus. In Abeill´e (Abeill´e,</title>
<date>2003</date>
<pages>73--87</pages>
<contexts>
<context position="4473" citStr="Brants et al., 2003" startWordPosition="662" endWordPosition="665">(B¨ohmov´a et al., 2003)) implements a three level annotation scheme where both the analytical (surface syntactic) and tectogrammatical level (deep syntactic and topic-focus articulation) are dependency-based; the English Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play. The choice of a RS-based annotation schema can depend on theoretical linguistic motivations (a RS-based schema allows for an explicit, finegrained representation of several linguistic phenomena), task-dependen</context>
</contexts>
<marker>Brants, Skut, Uszkoreit, 2003</marker>
<rawString>T. Brants, W. Skut, and H. Uszkoreit. 2003. Syntactic annotation of a German newspaper corpus. In Abeill´e (Abeill´e, 2003), pages 73– 87.</rawString>
</citation>
<citation valid="true">
<title>The mental representation of grammatical relations.</title>
<date>1982</date>
<editor>J. Bresnan, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>1982</marker>
<rawString>J. Bresnan, editor. 1982. The mental representation of grammatical relations. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
</authors>
<title>Using grammatical relations, answer frequencies and the World Wide Web for TREC Question Answering.</title>
<date>2002</date>
<booktitle>In Proc. of TREC</booktitle>
<pages>502--509</pages>
<contexts>
<context position="7777" citStr="Buchholz, 2002" startWordPosition="1149" endWordPosition="1150">-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a survey on this topic). For instance, in Information Extraction relations allows for recognizing different guises in which an event can appear regardless of the several different syntactic patterns that can be used to specify it (Palmer et al., 2001)2. In Question Answering, systems usually use forms of relation-based structured representations of the input texts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation-based representations where an accurate predicate argument structure is a critical factor (Han et al., 2000)3. Language-dependent motivations rely on the fact that the dependency-based formalisms has been traditionally considered as the most adequate for the representation of free word order languages. With respect to constituency-based 2Various approaches to IE (Collins and Miller, 1997) address this issue by using relational representations, that is forms of ”concept nodes” whi</context>
</contexts>
<marker>Buchholz, 2002</marker>
<rawString>S. Buchholz. 2002. Using grammatical relations, answer frequencies and the World Wide Web for TREC Question Answering. In Proc. of TREC 2001, pages 502–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>S Miller</author>
</authors>
<title>Semantic tagging using a probabilistic context free grammar.</title>
<date>1997</date>
<booktitle>In Proc. of 6th Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="8284" citStr="Collins and Miller, 1997" startWordPosition="1218" endWordPosition="1221">exts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation-based representations where an accurate predicate argument structure is a critical factor (Han et al., 2000)3. Language-dependent motivations rely on the fact that the dependency-based formalisms has been traditionally considered as the most adequate for the representation of free word order languages. With respect to constituency-based 2Various approaches to IE (Collins and Miller, 1997) address this issue by using relational representations, that is forms of ”concept nodes” which specifies a trigger word (usually a Verb) and also forms of mapping between the syntactic and the semantic relations of the trigger. 3The system presented in (Han et al., 2000) generates the dependency trees of the source language (Korean) sentences, then directly maps them to the translated (English) sentences. formalisms, free word order languages involves a large amount of discontinuous constituents (i.e. constituents whose parts are not contiguous in the linear order of the sentence). In practic</context>
</contexts>
<marker>Collins, Miller, 1997</marker>
<rawString>M. Collins and S. Miller. 1997. Semantic tagging using a probabilistic context free grammar. In Proc. of 6th Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajiˇcov´a</author>
<author>M Ceplov´a</author>
</authors>
<title>Deletions and their reconstruction in tectogrammatical syntactic tagging of very large corpora.</title>
<date>2000</date>
<booktitle>In Porc. of COLING</booktitle>
<pages>278--284</pages>
<marker>Hajiˇcov´a, Ceplov´a, 2000</marker>
<rawString>E. Hajiˇcov´a and M. Ceplov´a. 2000. Deletions and their reconstruction in tectogrammatical syntactic tagging of very large corpora. In Porc. of COLING 2000, pages 278–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Han</author>
<author>B Lavoie</author>
<author>M Palmer</author>
<author>O Rambow</author>
<author>R Kittredge</author>
<author>T Korelsky</author>
<author>N Kim</author>
<author>M Kim</author>
</authors>
<title>Handling structural divergences and recovering dropped arguments in a Korean/English machine translation system.</title>
<date>2000</date>
<booktitle>In Proc. of AMTA</booktitle>
<pages>40--54</pages>
<contexts>
<context position="8001" citStr="Han et al., 2000" startWordPosition="1179" endWordPosition="1182">ecognizing different guises in which an event can appear regardless of the several different syntactic patterns that can be used to specify it (Palmer et al., 2001)2. In Question Answering, systems usually use forms of relation-based structured representations of the input texts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation-based representations where an accurate predicate argument structure is a critical factor (Han et al., 2000)3. Language-dependent motivations rely on the fact that the dependency-based formalisms has been traditionally considered as the most adequate for the representation of free word order languages. With respect to constituency-based 2Various approaches to IE (Collins and Miller, 1997) address this issue by using relational representations, that is forms of ”concept nodes” which specifies a trigger word (usually a Verb) and also forms of mapping between the syntactic and the semantic relations of the trigger. 3The system presented in (Han et al., 2000) generates the dependency trees of the source</context>
</contexts>
<marker>Han, Lavoie, Palmer, Rambow, Kittredge, Korelsky, Kim, Kim, 2000</marker>
<rawString>C. Han, B. Lavoie, M. Palmer, O. Rambow, R. Kittredge, T. Korelsky, N. Kim, and M. Kim. 2000. Handling structural divergences and recovering dropped arguments in a Korean/English machine translation system. In Proc. of AMTA 2000, pages 40–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1991</date>
<booktitle>In Proc. of ACL 91,</booktitle>
<pages>229--236</pages>
<contexts>
<context position="6703" citStr="Hindle and Rooth, 1991" startWordPosition="993" endWordPosition="996">grammar1. 1See (Mazzei and Lombardo, 2004a) and (Mazzei and Lombardo, 2004b) for experiments of LTAG extraction from TUT. Task-dependent motivations rely on how the annotation of the RS can facilitate some processing aspects of NLP applications. The explicit representation of predicative structures allowed by the RS can be a powerful source of disambiguation. In fact, a large amount of ambiguity (such as coordination, Noun-Noun compounds and relative clause attachment) can be resolved using such a kind of information, and relations can provide a useful interface between syntax and semantics. (Hindle and Rooth, 1991) had shown the use of dependency in Prepositional Phrase disambiguation, and the experimental results reported in (Hockenmaier, 2003) demonstrate that a language model which encodes a rich notion of predicate argument structure (e.g. including long-range relations arising through coordination) can significantly improve the parsing performances. Moreover, the notion of predicate argument structure has been advocated as useful in a number of different large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a surv</context>
</contexts>
<marker>Hindle, Rooth, 1991</marker>
<rawString>D. Hindle and M. Rooth. 1991. Structural ambiguity and lexical relations. In Proc. of ACL 91, pages 229–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hockenmaier</author>
</authors>
<title>Parsing with generative models of predicate-argument structure.</title>
<date>2003</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="6836" citStr="Hockenmaier, 2003" startWordPosition="1013" endWordPosition="1015">otivations rely on how the annotation of the RS can facilitate some processing aspects of NLP applications. The explicit representation of predicative structures allowed by the RS can be a powerful source of disambiguation. In fact, a large amount of ambiguity (such as coordination, Noun-Noun compounds and relative clause attachment) can be resolved using such a kind of information, and relations can provide a useful interface between syntax and semantics. (Hindle and Rooth, 1991) had shown the use of dependency in Prepositional Phrase disambiguation, and the experimental results reported in (Hockenmaier, 2003) demonstrate that a language model which encodes a rich notion of predicate argument structure (e.g. including long-range relations arising through coordination) can significantly improve the parsing performances. Moreover, the notion of predicate argument structure has been advocated as useful in a number of different large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a survey on this topic). For instance, in Information Extraction relations allows for recognizing different guises in which an event can ap</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>J. Hockenmaier. 2003. Parsing with generative models of predicate-argument structure. In Proc. of ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hudson</author>
</authors>
<title>English Word Grammar. Basil Blackwell, Oxford and Cambridge.</title>
<date>1990</date>
<contexts>
<context position="17061" citStr="Hudson, 1990" startWordPosition="2562" endWordPosition="2563">c syntactic and semantic structure is one which involves the meaning of quantifiers: a determiner within a NP extends its scope beyond the semantic concept that results from the interpretation of the NP. Another example is the coordination where the semantic and syntactic structure are often considered as non isomorphic in several forms of representation. The ARS-relations including values for both functional-syntactic and semantic components may be used in the representation of grammatical relations which participate into argument structures and the so-called oblique cases (see Fillmore and (Hudson, 1990)), i.e. where the semantic structures are completely isomorphic to the syntactic structures. For example, a locative adjunct like in the garden in John was eating fish in the garden is represented at the syntactic level as a Prepositional Phrase playing the syntactic function locative in the Verb Phrase (in the Penn Treebank it could be annotated as a PP-LOC); the semantic concept corresponding to the garden plays the semantic role LOCATION in the ”eating” event stated by the sentence. 4 TUT: a dependency-based treebank for Italian The TUT is the first available treebank of Italian (freely dow</context>
<context position="24381" citStr="Hudson, 1990" startWordPosition="3771" endWordPosition="3772">finiteness of Verb. Valid values of the elements involved in TUT morpho-syntactic tags are 40. By using the values of the functional-syntactic component, TUT distinguishes among a variety of dependency relations. In figure 3 we see the distinction between argument, e.g. the relation SUBJ linking the argument Sudja with the verbal root of the sentence dichiarava, and the relation RMOD which represents a restrictive modifier and links the verbal root dichiarava with in quei giorni. The dependents of Prepositions and determiners are annotated as argument too, according to arguments presented in (Hudson, 1990). Another distinction which is exploited in the annotation of the sentence is that between restrictive modifier (i.e. RMOD which links dichiarava with in quei giorni) and APPOSITION (i.e. non restrictive modifier linking Sudja with la zingara), which are modifiers that restrict the meaning of the head. Beyond these basic distinctions, TUT schema draws other distinctions among the functional-syntactic relations and includes a large set of tags for a total of 55 items, which are compounds of 27 primary and 23 secondary tags. These tags are organized in a hierarchy (Bosco, 2004) according to thei</context>
</contexts>
<marker>Hudson, 1990</marker>
<rawString>R. Hudson. 1990. English Word Grammar. Basil Blackwell, Oxford and Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>Question-answering using semantic relation triples.</title>
<date>1999</date>
<booktitle>In Proc. of TREC-8,</booktitle>
<pages>349--356</pages>
<contexts>
<context position="7759" citStr="Litkowski, 1999" startWordPosition="1147" endWordPosition="1148"> of different large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a survey on this topic). For instance, in Information Extraction relations allows for recognizing different guises in which an event can appear regardless of the several different syntactic patterns that can be used to specify it (Palmer et al., 2001)2. In Question Answering, systems usually use forms of relation-based structured representations of the input texts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation-based representations where an accurate predicate argument structure is a critical factor (Han et al., 2000)3. Language-dependent motivations rely on the fact that the dependency-based formalisms has been traditionally considered as the most adequate for the representation of free word order languages. With respect to constituency-based 2Various approaches to IE (Collins and Miller, 1997) address this issue by using relational representations, that is forms of ”</context>
</contexts>
<marker>Litkowski, 1999</marker>
<rawString>K.C. Litkowski. 1999. Question-answering using semantic relation triples. In Proc. of TREC-8, pages 349–356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="4669" citStr="Marcus et al., 1993" startWordPosition="697" endWordPosition="700">ndency-based; the English Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play. The choice of a RS-based annotation schema can depend on theoretical linguistic motivations (a RS-based schema allows for an explicit, finegrained representation of several linguistic phenomena), task-dependent motivations (the RSbased schema represents the linguistic information involved in the task(s) at hand), languagedependent motivations (the relational structure is traditionally considered as the</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>G Kim</author>
<author>M A Marcinkiewicz</author>
<author>R MacIntyre</author>
<author>A Bies</author>
<author>M Ferguson</author>
<author>K Katz</author>
<author>B Schasberger</author>
</authors>
<title>The Penn Treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In Proc. of HLT-94.</booktitle>
<contexts>
<context position="4692" citStr="Marcus et al., 1994" startWordPosition="701" endWordPosition="704">sh Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play. The choice of a RS-based annotation schema can depend on theoretical linguistic motivations (a RS-based schema allows for an explicit, finegrained representation of several linguistic phenomena), task-dependent motivations (the RSbased schema represents the linguistic information involved in the task(s) at hand), languagedependent motivations (the relational structure is traditionally considered as the most adequate represen</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>M. Marcus, G. Kim, M.A. Marcinkiewicz, R. MacIntyre, A. Bies, M. Ferguson, K. Katz, and B. Schasberger. 1994. The Penn Treebank: Annotating predicate argument structure. In Proc. of HLT-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mazzei</author>
<author>V Lombardo</author>
</authors>
<title>Building a large grammar for Italian.</title>
<date>2004</date>
<booktitle>In Proc. of LREC</booktitle>
<pages>51--54</pages>
<contexts>
<context position="6121" citStr="Mazzei and Lombardo, 2004" startWordPosition="906" endWordPosition="909"> Grammar, Relaional Grammar and dependency grammar), which allow for capturing information involved at various level (e.g. syntactic and semantic) in linguistic structures, and grammatical formalisms have been proposed with the aim to capture the linguistic knowledge represented in these frameworks. Since the most immediate way to build wide-coverage grammars is to extract them directly from linguistic data (i.e. from treebanks), the type of annotation used in the data is a factor of primary importance, i.e. a RS-based annotation allows for the extraction of a more descriptive grammar1. 1See (Mazzei and Lombardo, 2004a) and (Mazzei and Lombardo, 2004b) for experiments of LTAG extraction from TUT. Task-dependent motivations rely on how the annotation of the RS can facilitate some processing aspects of NLP applications. The explicit representation of predicative structures allowed by the RS can be a powerful source of disambiguation. In fact, a large amount of ambiguity (such as coordination, Noun-Noun compounds and relative clause attachment) can be resolved using such a kind of information, and relations can provide a useful interface between syntax and semantics. (Hindle and Rooth, 1991) had shown the use</context>
</contexts>
<marker>Mazzei, Lombardo, 2004</marker>
<rawString>A. Mazzei and V. Lombardo. 2004a. Building a large grammar for Italian. In Proc. of LREC 2004, pages 51–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mazzei</author>
<author>V Lombardo</author>
</authors>
<title>A comparative analysis of extracted grammars.</title>
<date>2004</date>
<booktitle>In Proc. of ECAI</booktitle>
<contexts>
<context position="6121" citStr="Mazzei and Lombardo, 2004" startWordPosition="906" endWordPosition="909"> Grammar, Relaional Grammar and dependency grammar), which allow for capturing information involved at various level (e.g. syntactic and semantic) in linguistic structures, and grammatical formalisms have been proposed with the aim to capture the linguistic knowledge represented in these frameworks. Since the most immediate way to build wide-coverage grammars is to extract them directly from linguistic data (i.e. from treebanks), the type of annotation used in the data is a factor of primary importance, i.e. a RS-based annotation allows for the extraction of a more descriptive grammar1. 1See (Mazzei and Lombardo, 2004a) and (Mazzei and Lombardo, 2004b) for experiments of LTAG extraction from TUT. Task-dependent motivations rely on how the annotation of the RS can facilitate some processing aspects of NLP applications. The explicit representation of predicative structures allowed by the RS can be a powerful source of disambiguation. In fact, a large amount of ambiguity (such as coordination, Noun-Noun compounds and relative clause attachment) can be resolved using such a kind of information, and relations can provide a useful interface between syntax and semantics. (Hindle and Rooth, 1991) had shown the use</context>
</contexts>
<marker>Mazzei, Lombardo, 2004</marker>
<rawString>A. Mazzei and V. Lombardo. 2004b. A comparative analysis of extracted grammars. In Proc. of ECAI 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: theory and practice.</title>
<date>1988</date>
<publisher>SUNY,</publisher>
<location>Albany.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>I.A. Mel’ˇcuk. 1988. Dependency Syntax: theory and practice. SUNY, Albany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Montemagni</author>
<author>F Barsotti</author>
<author>M Battista</author>
<author>N Calzolari</author>
</authors>
<title>Building the Italian syntactic-semantic treebank. In Abeill´e (Abeill´e,</title>
<date>2003</date>
<pages>189--210</pages>
<contexts>
<context position="15679" citStr="Montemagni et al., 2003" startWordPosition="2342" endWordPosition="2345"> that the major difference between the syntactic (analytic) and the semantic (tectogrammatical) layer consists in the inclusion of empty nodes for recovering forms of deletion ((B¨ohmova et al., 1999), (Hajiˇcov´a and Ceplov´a, 2000)). But this kind of information does not necessarily requires a separated semantic layer and can be annotated as well in a mono-stratal representation, like the English Dependency Treebank (Rambow et al., 2002) does. The tripartite structure of the relations in ARS guarantees that different components can be accessed separately and analyzed independently (like in (Montemagni et al., 2003) or in (Rambow et al., 2002)). Furthermore, the ARS allows for forms of annotation of relations where not all the features are specified too. In fact, the ARS-relations which specify only a part of components allow for the description of syntactic grammatical relations which do not correspond with any semantic relation, either because they have a void semantic content or because they have a different structure from any possible corresponding semantic relation (i.e. there is no semantic relation linking the same ARS-units linked by the syntactic one). Typical relations void of semantic content </context>
</contexts>
<marker>Montemagni, Barsotti, Battista, Calzolari, 2003</marker>
<rawString>S. Montemagni, F. Barsotti, M. Battista, and N. Calzolari. 2003. Building the Italian syntactic-semantic treebank. In Abeill´e (Abeill´e, 2003), pages 189–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>K Toutanova</author>
<author>S Shieber</author>
<author>C D Manning</author>
<author>D Flickinger</author>
<author>T Brants</author>
</authors>
<title>The LinGO Redwoods treebank: motivation and prliminary applications.</title>
<date>2002</date>
<booktitle>In Proc. of COLING</booktitle>
<pages>1253--1257</pages>
<contexts>
<context position="4619" citStr="Oepen et al., 2002" startWordPosition="688" endWordPosition="691"> syntactic and topic-focus articulation) are dependency-based; the English Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play. The choice of a RS-based annotation schema can depend on theoretical linguistic motivations (a RS-based schema allows for an explicit, finegrained representation of several linguistic phenomena), task-dependent motivations (the RSbased schema represents the linguistic information involved in the task(s) at hand), languagedependent motivations (the relat</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>S. Oepen, K. Toutanova, S. Shieber, C.D. Manning, D. Flickinger, and T. Brants. 2002. The LinGO Redwoods treebank: motivation and prliminary applications. In Proc. of COLING 2002, pages 1253–1257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>J Rosenzweig</author>
<author>S Cotton</author>
</authors>
<title>Automatic predicate argument analysis of the Penn Treebank.</title>
<date>2001</date>
<booktitle>In Proc. of HLT</booktitle>
<contexts>
<context position="7548" citStr="Palmer et al., 2001" startWordPosition="1116" endWordPosition="1119">re (e.g. including long-range relations arising through coordination) can significantly improve the parsing performances. Moreover, the notion of predicate argument structure has been advocated as useful in a number of different large-scale languageprocessing tasks, and the RS is a convenient intermediate representation in several applications (see (Bosco, 2004) for a survey on this topic). For instance, in Information Extraction relations allows for recognizing different guises in which an event can appear regardless of the several different syntactic patterns that can be used to specify it (Palmer et al., 2001)2. In Question Answering, systems usually use forms of relation-based structured representations of the input texts (i.e. questions and answers) and try to match those representations (see e.g. (Litkowski, 1999), (Buchholz, 2002)). Also the in-depth understanding of the text, necessary in Machine Translation task, requires the use of relation-based representations where an accurate predicate argument structure is a critical factor (Han et al., 2000)3. Language-dependent motivations rely on the fact that the dependency-based formalisms has been traditionally considered as the most adequate for </context>
</contexts>
<marker>Palmer, Rosenzweig, Cotton, 2001</marker>
<rawString>M. Palmer, J. Rosenzweig, and S. Cotton. 2001. Automatic predicate argument analysis of the Penn Treebank. In Proc. of HLT 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Perlmutter</author>
</authors>
<date>1983</date>
<booktitle>Studies in Relational Grammar</booktitle>
<volume>1</volume>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2224" citStr="Perlmutter, 1983" startWordPosition="329" endWordPosition="331">l types of relations to link the syntactic units, whilst the PS involves a single relation ”part-of”. The RS can be seen as a generalization of the dependency syntax with the syntactic units instantiated to individual words in the dependency tree (Mel’ˇcuk, 1988). As described in many theoretical linguistic frameworks, the RS provides a useful interface between syntax and a semantic or conceptual representation of predicateargument structure. For example, Lexical Functional Grammar (LFG) (Bresnan, 1982) collocates relations at the interface between lexicon and syntax, Relational Grammar (RG) (Perlmutter, 1983) provides a description of the sentence structure exclusively based on relations and syntactic units not structured beyond the string level. This paper investigates how the notion of RS has been applied in the annotation of treebanks, in terms of syntactic units and types of relations, and presents a system for the definition of the RS that encompasses several uses in treebank schemata and can be viewed as a common underlying representation. The system, called Augmented Relational Structure (ARS) allows for an explicit representation of the three major components of linguistic structures, i.e.</context>
</contexts>
<marker>Perlmutter, 1983</marker>
<rawString>D.M. Perlmutter. 1983. Studies in Relational Grammar 1. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Rambow</author>
<author>C Creswell</author>
<author>R Szekely</author>
<author>H Taber</author>
<author>M Walker</author>
</authors>
<title>A dependency treebank for English.</title>
<date>2002</date>
<booktitle>In Proc. of LREC</booktitle>
<pages>857--863</pages>
<contexts>
<context position="4116" citStr="Rambow et al., 2002" startWordPosition="612" endWordPosition="615">practice, all the existing treebank schemata implement some form of relational structure. Annotation schemata range from pure (dependency) RS-based approaches to RS-PS combinations (Abeill´e, 2003). Some treebanks consider the relational information as the exclusive basis of the annotation. The Prague Dependency Treebank ((Hajiˇcov´a and Ceplov´a, 2000), (B¨ohmov´a et al., 2003)) implements a three level annotation scheme where both the analytical (surface syntactic) and tectogrammatical level (deep syntactic and topic-focus articulation) are dependency-based; the English Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relat</context>
<context position="11438" citStr="Rambow et al., 2002" startWordPosition="1694" endWordPosition="1698">e that many applications actually need are RS-based representations where predicate argument structure and the associated morphological and syntactic information can operate as an interface to a semantic-conceptual representation. All these types of knowledge have in common the fact that they can be described according to the dependency paradigm, rather than according to the constituency paradigm. The many applications (in particular those referring to the Penn Treebank) which use heuristics-based translation schemes from the phrase structure to lexical dependency (”head percolation tables”) (Rambow et al., 2002) show that the access to comprehensive and accurate extended dependencybased representations has to be currently considered as a critical issue for the development of robust and accurate NLP technologies. Now we define our proposal for the representation of the RS in treebank annotation. Figure 2: An ARS relation. ful in marking both similarities and differences among the behavior of units linked by the dependency relations. The morpho-syntactic component of the ARS describes morpho-syntactic features of the words involved in relations, such as their grammatical category. This component is use</context>
<context position="15498" citStr="Rambow et al., 2002" startWordPosition="2315" endWordPosition="2318">deration the possible polysemic nature of words involved. 5See, for instance, in LFG and RG. Dependency Treebank, which is featured by a three levels annotation. This case shows that the major difference between the syntactic (analytic) and the semantic (tectogrammatical) layer consists in the inclusion of empty nodes for recovering forms of deletion ((B¨ohmova et al., 1999), (Hajiˇcov´a and Ceplov´a, 2000)). But this kind of information does not necessarily requires a separated semantic layer and can be annotated as well in a mono-stratal representation, like the English Dependency Treebank (Rambow et al., 2002) does. The tripartite structure of the relations in ARS guarantees that different components can be accessed separately and analyzed independently (like in (Montemagni et al., 2003) or in (Rambow et al., 2002)). Furthermore, the ARS allows for forms of annotation of relations where not all the features are specified too. In fact, the ARS-relations which specify only a part of components allow for the description of syntactic grammatical relations which do not correspond with any semantic relation, either because they have a void semantic content or because they have a different structure from </context>
</contexts>
<marker>Rambow, Creswell, Szekely, Taber, Walker, 2002</marker>
<rawString>O. Rambow, C. Creswell, R. Szekely, H. Taber, and M. Walker. 2002. A dependency treebank for English. In Proc. of LREC 2002, pages 857–863.</rawString>
</citation>
<citation valid="false">
<date>1988</date>
<editor>L. Renzi, editor.</editor>
<location>Mulino, Bologna.</location>
<marker>1988</marker>
<rawString>L. Renzi, editor. 1988. Grande grammatica italiana di consultazione, vol. I. Il Mulino, Bologna.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Skut</author>
<author>T Brants</author>
<author>B Krenn</author>
<author>H Uszkoreit</author>
</authors>
<title>A linguistically interpreted corpus of German in newspaper texts.</title>
<date>1998</date>
<booktitle>In Proc. of LREC 98,</booktitle>
<pages>705--713</pages>
<contexts>
<context position="4494" citStr="Skut et al., 1998" startWordPosition="666" endWordPosition="669">)) implements a three level annotation scheme where both the analytical (surface syntactic) and tectogrammatical level (deep syntactic and topic-focus articulation) are dependency-based; the English Dependency Treebank (Rambow et al., 2002) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure. Other projects adopt mixed formalisms where the sentence is split in syntactic subunits (phrases), but linked by functional or semantic relations, e.g. the Negra Treebank for German ((Brants et al., 2003), (Skut et al., 1998)), the Alpino Treebank for Dutch (van der Beek et al., 2002), and the Lingo Redwood Treebank for English (Oepen et al., 2002). Also in the Penn Treebank ((Marcus et al., 1993), (Marcus et al., 1994)) a limited set of relations is placed over the constituencybased annotation in order to make explicit the (morpho-syntactic or semantic) roles that the constituents play. The choice of a RS-based annotation schema can depend on theoretical linguistic motivations (a RS-based schema allows for an explicit, finegrained representation of several linguistic phenomena), task-dependent motivations (the RS</context>
</contexts>
<marker>Skut, Brants, Krenn, Uszkoreit, 1998</marker>
<rawString>W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998. A linguistically interpreted corpus of German in newspaper texts. In Proc. of LREC 98, pages 705–713.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Stock</author>
</authors>
<title>Parsing with flexibility, dynamic strategies, and idioms in mind.</title>
<date>1989</date>
<journal>Computational Linguistics,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="18431" citStr="Stock, 1989" startWordPosition="2783" endWordPosition="2784">ctuation marks). The average sentence length is of 22,57 words and 3,2 punctuation marks. In this section, we concentrate on the major features of TUT annotation schema, i.e. how the ARS system can describe a dependency structure. 4.1 A dependency-based schema In Italian the order of words is fixed in non verbal phrases, but verbal arguments and modifiers can be freely distributed without affecting the semantic interpretation of the sentence. A study on a set of sentences of TUT shows that the basic word order for Italian is SubjectVerb-Complement (SVC), as known in literature (Renzi, 1988), (Stock, 1989), but in more than a quarter of declarative sentences it is violated (see the following table6). Although the Permutations Occurrences S V C 74,26% V C S 11,38% S C V 7,98% C S V 3,23% V S C 2,29% C V S 0,77% Table 1: Italian word order SVC order is well over the others, the fact that all the other orders are represented quantitatively confirms the assumption of partial configurationality intuitively set in the literature. The partial configurationality of Italian can be considered as a language-dependent motivation for the choice of a dependency-based annotation for an Italian treebank. The s</context>
</contexts>
<marker>Stock, 1989</marker>
<rawString>O. Stock. 1989. Parsing with flexibility, dynamic strategies, and idioms in mind. Computational Linguistics, 15(1):1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L van der Beek</author>
<author>G Bouma</author>
<author>R Malouf</author>
<author>G van der Noord</author>
</authors>
<title>The Alpino dependency treebank.</title>
<date>2002</date>
<booktitle>In Proc. of CLIN</booktitle>
<marker>van der Beek, Bouma, Malouf, van der Noord, 2002</marker>
<rawString>L. van der Beek, G. Bouma, R. Malouf, and G. van der Noord. 2002. The Alpino dependency treebank. In Proc. of CLIN 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>