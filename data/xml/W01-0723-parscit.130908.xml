<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000256">
<title confidence="0.948205">
Using ALLiS for Clausing
</title>
<author confidence="0.821364">
Herye Dejean
</author>
<affiliation confidence="0.534794">
Seminar fiir Sprachwissenschaft
</affiliation>
<address confidence="0.243097">
Universitat Tubingen
</address>
<email confidence="0.302388">
dejeanOsfs.nphil.uni-tuebingen.de
</email>
<sectionHeader confidence="0.934506" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999717">
We present the result of a symbolic machine
learning system, ALLiS 2.0 for the CoNLL-2001
shared task. ALLiS 2.0 is a theory refinement
system using hierarchical data. Results are
F=89.04 for subtask 1, F=68.02 for subtask 2
and F=67.70 for subtask 3 (development test).
Adding manual rules improves considerably re-
sults specially for task 2 (F=79.44). For the
test data, results are slightly worst (F=62.27
for subtask 3).
</bodyText>
<sectionHeader confidence="0.995353" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999125">
ALLiS (Architecture for Learning Linguistic
Structure) (Dejean, 2000a), (Dejean, 2000b) is a
symbolic machine learning system. The learn-
ing system is based on theory refinement. It
tries to refine (to improve) an existing imper-
fect grammar using operators such as contex-
tualization and lexicalization. ALLiS separates
the task of the generation of rules and the task
of the use of these rules (task of parsing). First
symbolic rules are learned and saved using an
own formalism, and in a second time, these rules
are converted into a proper formalism used by a
specific rule-based parser. ALLiS uses XML for-
malism for learning as well as for parsing. The
following XML Components are:
</bodyText>
<listItem confidence="0.999242375">
• LT TTT, a text tokenization system and
toolset which enables users to produce a
swift and individually-tailored tokenization
of text.
• LT XML , an integrated set of XML tools
and a developers tool-kit, including a C-
based API.
• XMLQUERY, (Mckelvie, 2000), an exten-
</listItem>
<bodyText confidence="0.959097333333333">
sion of the LTXML query language to allow
more complex queries including operators
for finding sequences of XML elements.
</bodyText>
<sectionHeader confidence="0.915088" genericHeader="method">
2 Theory Refinement
</sectionHeader>
<bodyText confidence="0.99978365">
We present here a brief introduction to the-
ory refinement. For a more detailed presen-
tation, we refer the reader to (Abecker and
Schmid, 1996), (Brunk, 1996) or (Mooney,
1993). (Mooney, 1993) defines it as:
Theory refinement systems developed
in Machine Learning automatically
modify a Knowledge Base to render it
consistent with a set of classified train-
ing examples.
This technique thus consists of improving a
given Knowledge Base (here a grammar) on the
basis of examples (here a treebank). Some im-
pose to modify the initial knowledge base as lit-
tle as possible. Applied in conjunction with ex-
isting learning techniques (Explanation-Based
Learning, Inductive Logic Programming), TR
seems to achieve better results than these tech-
niques used alone (Mooney, 1997). It consists
of two main steps:
</bodyText>
<listItem confidence="0.9997185">
1. Build a more or less correct grammar on
the basis of background knowledge.
2. Refine this grammar using training exam-
ples:
(a) Identify the revision points
(b) Correct them
</listItem>
<bodyText confidence="0.9999224">
The first step consists in acquiring an initial
grammar (or more generally a knowledge base).
In this work, the initial grammar is automati-
cally induced from a tagged and bracketed cor-
pus. The second step (the refinement) compares
the prediction of the initial grammar with the
training corpus in order to firstly identify the re-
vision points, i.e. points that are not correctly
described by the grammar, and secondly, to cor-
rect these revision points.
</bodyText>
<sectionHeader confidence="0.983327" genericHeader="method">
3 Hierarchical Data
</sectionHeader>
<bodyText confidence="0.999973875">
The difference between ALLiS 1.0 and ALLiS
2.0 relies on the use of hierarchical structure.
The alternate usual solution is to replace a seg-
ment (chunk for example) by a unique element
(a word, namely the head of the structure). The
advantage of this solution is to reduce the search
space, the drawback to delete some potential
useful information.
</bodyText>
<subsectionHeader confidence="0.998235">
3.1 Data representation
</subsectionHeader>
<bodyText confidence="0.999591">
Data provided by (Tjong Kim Sang and Dejean,
2001) are first converted into ALLiS&apos; input for-
malism. The three hierarchical levels are S (sen-
tence), PHR (phrase), and W (word). Here is
the DTD used for training data:
</bodyText>
<figure confidence="0.527624057142857">
&lt;!ELEMENT WSJ (S)*&gt;
&lt;!ATTLIST WSJ S CDATA &amp;quot;0&amp;quot;›
&lt;!ELEMENT S (SIPHRIW)*&gt;
&lt;!ATTLIST S C CDATA
NUM CDATA &amp;quot;&gt;
&lt;!ELEMENT PHR (W)* &gt;
&lt;!ATTLIST PHR CAT CDATA &amp;quot;0&amp;quot;
B CDATA &amp;quot;&gt;
&lt;!ELEMENT W EMPTY&gt;
&lt;!ATTLIST W W CDATA
BP CDATA
B CDATA
C CDATA &amp;quot;&gt;
An example of data:
&lt;S NUM=&apos;38 &apos;&gt;
&lt;PHR CAT= &apos;A&apos;&gt;&lt;W CAT=&apos;A&apos;/&gt;&lt;/PHR&gt;
&lt;PHR CAT= &apos;NP&apos; B=&apos;Y&apos;&gt;
&lt;W BP=&apos;B &apos; C=&apos;VBN&apos; W=&apos;Estimated&apos;/&gt;
&lt;W BP=&apos;I &apos; C=&apos;NN&apos; W=&apos;volume&apos;/&gt;
&lt;/PHR&gt;
&lt;PHR CAT= &apos;VP&apos; B=&apos;N&apos;&gt;
&lt;W BP=&apos;B &apos; C=&apos;VBD&apos; W=&apos;was&apos;/&gt;
&lt;/PHR&gt;
&lt;PHR CAT= &apos;NP&apos; B=&apos;N&apos;&gt;
&lt;W BP=&apos;B &apos; C=&apos;DT&apos; W=&apos;a&apos;/&gt;
&lt;W BP=&apos;I &apos; C=&apos;NN&apos; W=&apos;light&apos;/&gt;
&lt;W BP=&apos;I ; C=&apos;CD&apos; W=&apos;2.4&apos;/&gt;
&lt;W BP=&apos;I ; C=&apos;CD&apos; W=&apos;million&apos;/&gt;
&lt;W BP=&apos;I ; C=&apos;NNS&apos; W=&apos;ounces&apos;/&gt;
&lt;/PHR&gt;
&lt;PHR CAT= &apos;WORD&apos; B=&apos;N&apos;&gt;
&lt;W C=&apos;.
&lt;/PHR&gt;
&lt;PHR CAT=&apos;E&apos;&gt; &lt;W S=&apos;E&apos;/&gt;&lt;/PHR&gt;
&lt;/S&gt;
</figure>
<bodyText confidence="0.9931255">
Two PHR elements are added, marking up be-
ginning and end of sentence. Information pro-
vided by the original corpus (word, POS-tag,
chunk-tag) are integrated in the XML corpus by
the way of attributes. The attribute B carried
on by PHR element corresponds to the bound-
ary clause we are looking for. Values are Y or
N.
</bodyText>
<sectionHeader confidence="0.994778" genericHeader="method">
4 Learning
</sectionHeader>
<bodyText confidence="0.9995815">
The learning method consists in finding con-
texts in which an element can be associated to
a specific category with a high confidence. The
following query returns the list of the elements
PHR with the category NP which are clause be-
ginning (B&apos;Y&apos;).
</bodyText>
<equation confidence="0.512785">
WSJ/S/PHR [CAT= &apos;NP &apos; , B=&apos; Y &apos; ]
</equation>
<bodyText confidence="0.948259454545455">
We now try to find negative examples, and eval-
uate the ratio between positive and negative ex-
amples. Extending a query consists in extend-
ing a tree using a breath-first path. First neigh-
bors are added (left and right), and then at-
tributes are added to each new element.
WSJ/S/ (PHR [CAT= &apos; PP &apos; ] ,PHR [CAT= &apos; NP &apos; ] )
The extension lasts until the accuracy of the
rule is high enough or until the frequency of
the sequence is high enough. Here is one of the
possible final rules:
</bodyText>
<figure confidence="0.957707692307692">
&lt;query FREQ=&apos;11&apos; ACC=&apos;0.92&apos;&gt;
&lt;save&gt;
&lt;PHR CAT=&apos;PP&apos;&gt;
&lt;W W=&apos;for&apos; C=&apos;IN&apos;/&gt;
&lt;/PHR&gt;
&lt;PHR B=&apos;Y&apos; CAT=&apos;NP&apos;&gt;
&lt;W C=&apos;NNP&apos; CUR=&apos;N&apos;/&gt;
&lt;/PHR&gt;
&lt;PHR CAT=&apos;VP&apos;&gt;
&lt;W BP=&apos;B&apos; W=&apos;to&apos; C=&apos;T0&apos;/&gt;
&lt;/PHR&gt;
&lt;/save&gt;
&lt;/query&gt;
</figure>
<bodyText confidence="0.987815857142857">
In a more readable formalism:
if left elt = PP/IN/for
right elt = VP/TO/to
[np NNP] -&gt; S
If a NP with an NNP occurs between a PP con-
taining IN/for and a VP containg TO/to, it is
a start of clause.
</bodyText>
<sectionHeader confidence="0.974563" genericHeader="evaluation">
5 Rules
</sectionHeader>
<bodyText confidence="0.99988875">
For data testi, ALLiS has learned 149 rules, the
coverage of the learning test being 82% (82% of
the positive cases are explained). As usually,
few very frequent rules insure the main part of
the coverage.
Concerning the second data, rules are more
difficult to learn. ALLiS only generates 25 rules
and the recall is very low.
</bodyText>
<subsectionHeader confidence="0.990904">
5.1 Which precision?
</subsectionHeader>
<bodyText confidence="0.99994747368421">
Another important parameter is the threshold
0 which determines when the accuracy of a rule
is high enough. We tried two values: 0.8 and
0.9. For the chunking task (last year shared-
task), the best value was 0.9. In this task, the
best one is 0.8. We think that the explanation
is partially due to a more important quatity of
noise in data. For the chunking task, the noise
was due to POS tagging. In this data, it is due
to errors of tagging and also errors of chunking.
The F-score being around 92% for chunking, it
is obvious that the error rate for some tags is
higher than 10%. We can note that, even if the
threshold is set up at 0.8, the overall precision
stays high enough (94.08% against 95.76% for
0=0.9). Furthermore, setting 0 at 0.8 allows a
better recall (84.59% against 78.58%). It then
seems that 0 &apos;s value should be correlated with
the estimation of the noise in data.
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="conclusions">
6 Result
</sectionHeader>
<bodyText confidence="0.99983775">
For CoNLL&apos;01 shared-task 1, ALLiS offers a
good precision but a lower recall. Using a win-
dow of one element before and after seems to
be sufficient. Concerning subtask 2, the result
is unfortunately very close to the baseline. It
is clear that this task does not need local in-
formation, but information about the existence
of opened clauses. In order to validate this af-
firmation, we add a new rule which consists
in adding a tag B&apos;E&apos; at the last word of the
sentence when two clauses are open. This im-
proves greatly recall (72.76) and precision keeps
high enough (87.48) to improve the overall re-
sult (F=79.44).
Results of the task 3 are provided by combin-
ing taskl and 2 and using a Perl script provided
</bodyText>
<table confidence="0.839274375">
developement precision recall F0-1
part 1 94.08% 84.59% 89.08
part 2 99.28% 51.73% 68.02
part 3 73.93% 62.44% 67.70
test precision recall F0-1
part 1 93.76% 81.90% 87.43
part 2 99.04% 48.90% 65.47
part 3 72.56% 54.55% 62.27
</table>
<tableCaption confidence="0.998415">
Table 1: ALLiS results
</tableCaption>
<bodyText confidence="0.316831">
by Erik Tjong Kim Sang.
</bodyText>
<sectionHeader confidence="0.923566" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999173592592593">
Andreas Abecker and Klaus Schmid. 1996. From
theory refinement to kb maintenance: a position
statement. In ECAI&apos;96, Budapest, Hungary.
Clifford Alan Brunk. 1996. An investigation
of Knowledge Intensive Approaches to Concept
Learning and Theory Refinement. Ph.D. thesis,
University of California, Irvine.
Herve Dejean. 2000a. Theory refinement and
natural language learning. In COLING&apos;2000,
Saarbriicken.
Herve Dejean. 2000b. A use of xml for ma-
chine learning. In Proceeding of the workshop
on Computational Natural Language Learning,
CONLL&apos;2000.
David Mckelvie, 2000. XML QUERY 2.0. Edin-
burgh. http://www.ltg.ed.ac.uk/software/ttt/.
Raymond J. Mooney. 1993. Induction over the un-
explained: Using overly-general domain theories
to aid concept learning. Machine Learning, 10:79.
Raymond J. Mooney. 1997. Inductive logic pro-
gramming for natural language processing. In
Sixth International Inductive Logic Programming
Workshop, pages 205-224, Stockholm,Sweden.
Erik F. Tjong Kim Sang and Herve Dejean. 2001.
Introduction to the con11-2001 shared task: Clause
identification. In Proceedings of CoNLL, shared
task.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.172631">
<title confidence="0.9769725">Using ALLiS for Clausing Herye</title>
<author confidence="0.703385">Seminar fiir</author>
<affiliation confidence="0.676341">Universitat</affiliation>
<abstract confidence="0.851711454545455">We present the result of a symbolic machine learning system, ALLiS 2.0 for the CoNLL-2001 shared task. ALLiS 2.0 is a theory refinement system using hierarchical data. Results are F=89.04 for subtask 1, F=68.02 for subtask 2 and F=67.70 for subtask 3 (development test). Adding manual rules improves considerably results specially for task 2 (F=79.44). For the test data, results are slightly worst (F=62.27 for subtask 3).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andreas Abecker</author>
<author>Klaus Schmid</author>
</authors>
<title>From theory refinement to kb maintenance: a position statement.</title>
<date>1996</date>
<booktitle>In ECAI&apos;96,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1809" citStr="Abecker and Schmid, 1996" startWordPosition="284" endWordPosition="287">sm for learning as well as for parsing. The following XML Components are: • LT TTT, a text tokenization system and toolset which enables users to produce a swift and individually-tailored tokenization of text. • LT XML , an integrated set of XML tools and a developers tool-kit, including a Cbased API. • XMLQUERY, (Mckelvie, 2000), an extension of the LTXML query language to allow more complex queries including operators for finding sequences of XML elements. 2 Theory Refinement We present here a brief introduction to theory refinement. For a more detailed presentation, we refer the reader to (Abecker and Schmid, 1996), (Brunk, 1996) or (Mooney, 1993). (Mooney, 1993) defines it as: Theory refinement systems developed in Machine Learning automatically modify a Knowledge Base to render it consistent with a set of classified training examples. This technique thus consists of improving a given Knowledge Base (here a grammar) on the basis of examples (here a treebank). Some impose to modify the initial knowledge base as little as possible. Applied in conjunction with existing learning techniques (Explanation-Based Learning, Inductive Logic Programming), TR seems to achieve better results than these techniques us</context>
</contexts>
<marker>Abecker, Schmid, 1996</marker>
<rawString>Andreas Abecker and Klaus Schmid. 1996. From theory refinement to kb maintenance: a position statement. In ECAI&apos;96, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifford Alan Brunk</author>
</authors>
<title>An investigation of Knowledge Intensive Approaches to Concept Learning and Theory Refinement.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Irvine.</institution>
<contexts>
<context position="1824" citStr="Brunk, 1996" startWordPosition="288" endWordPosition="289">or parsing. The following XML Components are: • LT TTT, a text tokenization system and toolset which enables users to produce a swift and individually-tailored tokenization of text. • LT XML , an integrated set of XML tools and a developers tool-kit, including a Cbased API. • XMLQUERY, (Mckelvie, 2000), an extension of the LTXML query language to allow more complex queries including operators for finding sequences of XML elements. 2 Theory Refinement We present here a brief introduction to theory refinement. For a more detailed presentation, we refer the reader to (Abecker and Schmid, 1996), (Brunk, 1996) or (Mooney, 1993). (Mooney, 1993) defines it as: Theory refinement systems developed in Machine Learning automatically modify a Knowledge Base to render it consistent with a set of classified training examples. This technique thus consists of improving a given Knowledge Base (here a grammar) on the basis of examples (here a treebank). Some impose to modify the initial knowledge base as little as possible. Applied in conjunction with existing learning techniques (Explanation-Based Learning, Inductive Logic Programming), TR seems to achieve better results than these techniques used alone (Moone</context>
</contexts>
<marker>Brunk, 1996</marker>
<rawString>Clifford Alan Brunk. 1996. An investigation of Knowledge Intensive Approaches to Concept Learning and Theory Refinement. Ph.D. thesis, University of California, Irvine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herve Dejean</author>
</authors>
<title>Theory refinement and natural language learning.</title>
<date>2000</date>
<booktitle>In COLING&apos;2000, Saarbriicken.</booktitle>
<contexts>
<context position="641" citStr="Dejean, 2000" startWordPosition="89" endWordPosition="90">e Dejean Seminar fiir Sprachwissenschaft Universitat Tubingen dejeanOsfs.nphil.uni-tuebingen.de Abstract We present the result of a symbolic machine learning system, ALLiS 2.0 for the CoNLL-2001 shared task. ALLiS 2.0 is a theory refinement system using hierarchical data. Results are F=89.04 for subtask 1, F=68.02 for subtask 2 and F=67.70 for subtask 3 (development test). Adding manual rules improves considerably results specially for task 2 (F=79.44). For the test data, results are slightly worst (F=62.27 for subtask 3). 1 Introduction ALLiS (Architecture for Learning Linguistic Structure) (Dejean, 2000a), (Dejean, 2000b) is a symbolic machine learning system. The learning system is based on theory refinement. It tries to refine (to improve) an existing imperfect grammar using operators such as contextualization and lexicalization. ALLiS separates the task of the generation of rules and the task of the use of these rules (task of parsing). First symbolic rules are learned and saved using an own formalism, and in a second time, these rules are converted into a proper formalism used by a specific rule-based parser. ALLiS uses XML formalism for learning as well as for parsing. The following XML</context>
</contexts>
<marker>Dejean, 2000</marker>
<rawString>Herve Dejean. 2000a. Theory refinement and natural language learning. In COLING&apos;2000, Saarbriicken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herve Dejean</author>
</authors>
<title>A use of xml for machine learning.</title>
<date>2000</date>
<booktitle>In Proceeding of the workshop on Computational Natural Language Learning, CONLL&apos;2000.</booktitle>
<contexts>
<context position="641" citStr="Dejean, 2000" startWordPosition="89" endWordPosition="90">e Dejean Seminar fiir Sprachwissenschaft Universitat Tubingen dejeanOsfs.nphil.uni-tuebingen.de Abstract We present the result of a symbolic machine learning system, ALLiS 2.0 for the CoNLL-2001 shared task. ALLiS 2.0 is a theory refinement system using hierarchical data. Results are F=89.04 for subtask 1, F=68.02 for subtask 2 and F=67.70 for subtask 3 (development test). Adding manual rules improves considerably results specially for task 2 (F=79.44). For the test data, results are slightly worst (F=62.27 for subtask 3). 1 Introduction ALLiS (Architecture for Learning Linguistic Structure) (Dejean, 2000a), (Dejean, 2000b) is a symbolic machine learning system. The learning system is based on theory refinement. It tries to refine (to improve) an existing imperfect grammar using operators such as contextualization and lexicalization. ALLiS separates the task of the generation of rules and the task of the use of these rules (task of parsing). First symbolic rules are learned and saved using an own formalism, and in a second time, these rules are converted into a proper formalism used by a specific rule-based parser. ALLiS uses XML formalism for learning as well as for parsing. The following XML</context>
</contexts>
<marker>Dejean, 2000</marker>
<rawString>Herve Dejean. 2000b. A use of xml for machine learning. In Proceeding of the workshop on Computational Natural Language Learning, CONLL&apos;2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mckelvie</author>
</authors>
<date>2000</date>
<contexts>
<context position="1515" citStr="Mckelvie, 2000" startWordPosition="237" endWordPosition="238">of the generation of rules and the task of the use of these rules (task of parsing). First symbolic rules are learned and saved using an own formalism, and in a second time, these rules are converted into a proper formalism used by a specific rule-based parser. ALLiS uses XML formalism for learning as well as for parsing. The following XML Components are: • LT TTT, a text tokenization system and toolset which enables users to produce a swift and individually-tailored tokenization of text. • LT XML , an integrated set of XML tools and a developers tool-kit, including a Cbased API. • XMLQUERY, (Mckelvie, 2000), an extension of the LTXML query language to allow more complex queries including operators for finding sequences of XML elements. 2 Theory Refinement We present here a brief introduction to theory refinement. For a more detailed presentation, we refer the reader to (Abecker and Schmid, 1996), (Brunk, 1996) or (Mooney, 1993). (Mooney, 1993) defines it as: Theory refinement systems developed in Machine Learning automatically modify a Knowledge Base to render it consistent with a set of classified training examples. This technique thus consists of improving a given Knowledge Base (here a gramma</context>
</contexts>
<marker>Mckelvie, 2000</marker>
<rawString>David Mckelvie, 2000. XML QUERY 2.0. Edinburgh. http://www.ltg.ed.ac.uk/software/ttt/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Induction over the unexplained: Using overly-general domain theories to aid concept learning.</title>
<date>1993</date>
<booktitle>Machine Learning,</booktitle>
<pages>10--79</pages>
<contexts>
<context position="1842" citStr="Mooney, 1993" startWordPosition="291" endWordPosition="292">ollowing XML Components are: • LT TTT, a text tokenization system and toolset which enables users to produce a swift and individually-tailored tokenization of text. • LT XML , an integrated set of XML tools and a developers tool-kit, including a Cbased API. • XMLQUERY, (Mckelvie, 2000), an extension of the LTXML query language to allow more complex queries including operators for finding sequences of XML elements. 2 Theory Refinement We present here a brief introduction to theory refinement. For a more detailed presentation, we refer the reader to (Abecker and Schmid, 1996), (Brunk, 1996) or (Mooney, 1993). (Mooney, 1993) defines it as: Theory refinement systems developed in Machine Learning automatically modify a Knowledge Base to render it consistent with a set of classified training examples. This technique thus consists of improving a given Knowledge Base (here a grammar) on the basis of examples (here a treebank). Some impose to modify the initial knowledge base as little as possible. Applied in conjunction with existing learning techniques (Explanation-Based Learning, Inductive Logic Programming), TR seems to achieve better results than these techniques used alone (Mooney, 1997). It consi</context>
</contexts>
<marker>Mooney, 1993</marker>
<rawString>Raymond J. Mooney. 1993. Induction over the unexplained: Using overly-general domain theories to aid concept learning. Machine Learning, 10:79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Inductive logic programming for natural language processing.</title>
<date>1997</date>
<booktitle>In Sixth International Inductive Logic Programming Workshop,</booktitle>
<pages>205--224</pages>
<location>Stockholm,Sweden.</location>
<contexts>
<context position="2432" citStr="Mooney, 1997" startWordPosition="382" endWordPosition="383">1996) or (Mooney, 1993). (Mooney, 1993) defines it as: Theory refinement systems developed in Machine Learning automatically modify a Knowledge Base to render it consistent with a set of classified training examples. This technique thus consists of improving a given Knowledge Base (here a grammar) on the basis of examples (here a treebank). Some impose to modify the initial knowledge base as little as possible. Applied in conjunction with existing learning techniques (Explanation-Based Learning, Inductive Logic Programming), TR seems to achieve better results than these techniques used alone (Mooney, 1997). It consists of two main steps: 1. Build a more or less correct grammar on the basis of background knowledge. 2. Refine this grammar using training examples: (a) Identify the revision points (b) Correct them The first step consists in acquiring an initial grammar (or more generally a knowledge base). In this work, the initial grammar is automatically induced from a tagged and bracketed corpus. The second step (the refinement) compares the prediction of the initial grammar with the training corpus in order to firstly identify the revision points, i.e. points that are not correctly described by</context>
</contexts>
<marker>Mooney, 1997</marker>
<rawString>Raymond J. Mooney. 1997. Inductive logic programming for natural language processing. In Sixth International Inductive Logic Programming Workshop, pages 205-224, Stockholm,Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Herve Dejean</author>
</authors>
<title>Introduction to the con11-2001 shared task: Clause identification.</title>
<date>2001</date>
<booktitle>In Proceedings of CoNLL, shared task.</booktitle>
<contexts>
<context position="3537" citStr="Sang and Dejean, 2001" startWordPosition="565" endWordPosition="568">the training corpus in order to firstly identify the revision points, i.e. points that are not correctly described by the grammar, and secondly, to correct these revision points. 3 Hierarchical Data The difference between ALLiS 1.0 and ALLiS 2.0 relies on the use of hierarchical structure. The alternate usual solution is to replace a segment (chunk for example) by a unique element (a word, namely the head of the structure). The advantage of this solution is to reduce the search space, the drawback to delete some potential useful information. 3.1 Data representation Data provided by (Tjong Kim Sang and Dejean, 2001) are first converted into ALLiS&apos; input formalism. The three hierarchical levels are S (sentence), PHR (phrase), and W (word). Here is the DTD used for training data: &lt;!ELEMENT WSJ (S)*&gt; &lt;!ATTLIST WSJ S CDATA &amp;quot;0&amp;quot;› &lt;!ELEMENT S (SIPHRIW)*&gt; &lt;!ATTLIST S C CDATA NUM CDATA &amp;quot;&gt; &lt;!ELEMENT PHR (W)* &gt; &lt;!ATTLIST PHR CAT CDATA &amp;quot;0&amp;quot; B CDATA &amp;quot;&gt; &lt;!ELEMENT W EMPTY&gt; &lt;!ATTLIST W W CDATA BP CDATA B CDATA C CDATA &amp;quot;&gt; An example of data: &lt;S NUM=&apos;38 &apos;&gt; &lt;PHR CAT= &apos;A&apos;&gt;&lt;W CAT=&apos;A&apos;/&gt;&lt;/PHR&gt; &lt;PHR CAT= &apos;NP&apos; B=&apos;Y&apos;&gt; &lt;W BP=&apos;B &apos; C=&apos;VBN&apos; W=&apos;Estimated&apos;/&gt; &lt;W BP=&apos;I &apos; C=&apos;NN&apos; W=&apos;volume&apos;/&gt; &lt;/PHR&gt; &lt;PHR CAT= &apos;VP&apos; B=&apos;N&apos;&gt; &lt;W BP=&apos;B &apos; C=&apos;VBD&apos; </context>
</contexts>
<marker>Sang, Dejean, 2001</marker>
<rawString>Erik F. Tjong Kim Sang and Herve Dejean. 2001. Introduction to the con11-2001 shared task: Clause identification. In Proceedings of CoNLL, shared task.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>