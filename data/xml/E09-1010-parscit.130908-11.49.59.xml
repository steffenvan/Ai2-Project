<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000097">
<title confidence="0.9941165">
Data-driven semantic ana/ysis for mu/ti/ingua/ WSD
and /exica/ se/ection in trans/ation
</title>
<author confidence="0.983938">
Marianna Apidianaki
</author>
<affiliation confidence="0.99652">
National Centre for Language Technology
School of Computing, Dublin City University
</affiliation>
<address confidence="0.810556">
Dublin 9, Ireland
</address>
<email confidence="0.916895">
mapidianaki@c*mputing.dcu.ie
</email>
<sectionHeader confidence="0.998036" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999566">
A common way of describing the senses of
ambiguous words in multilingual Word Sense
Disambiguation (WSD) is by reference to their
translation equivalents in another language.
The theoretical soundness of the senses
induced in this way can, however, be doubted.
This type of cross-lingual sense identification
has implications for multilingual WSD and MT
evaluation as well. In this article, we first
present some arguments in favour of a more
thorough analysis of the semantic information
that may be induced by the equivalents of
ambiguous words found in parallel corpora.
Then, we present an unsupervised WSD
method and a lexical selection method that
exploit the results of a data-driven sense
induction method. Finally, we show how this
automatically acquired information can be
exploited for a multilingual WSD and MT
evaluation more sensitive to lexical semantics.
</bodyText>
<sectionHeader confidence="0.995256" genericHeader="keywords">
1 Word senses in a bi-(mu/ti-)/ingua/
context
</sectionHeader>
<subsectionHeader confidence="0.8179105">
1.1 Cross-/ingua/ sense determination for
WSD
</subsectionHeader>
<bodyText confidence="0.9998962">
Determining the senses of ambiguous words by
reference to their translational equivalents
constitutes a common practice in multilingual
WSD: the candidate senses of an ambiguous
word, from which one has to be selected during
WSD, correspond to its equivalents in another
language. This empirical approach to sense
identification circumvents the need for
predefined sense inventories and their
disadvantages for automatic WSD.1 The first to
</bodyText>
<footnote confidence="0.924057">
1 Such as the high granularity, the great number and the
striking similarity of the described senses, and their
</footnote>
<bodyText confidence="0.99972384">
adopt it were Brown et al. (1991), who
represented the two main senses of a SL word by
its two most frequent translations in the target
language (TL). Further promoted by Resnik and
Yarowsky (2000) and endorsed in the
multilingual tasks of the Senseval (Chklovski et
al., 2004) and Semeval (Jin et al., 2007)
exercises, this conception of senses is still found
in recent works on the integration of WSD in
MT.
From these works, only that of Carpuat and
Wu (2005) exploits an external hand-crafted
sense inventory. The use of an external resource,
not related to the training corpus of their
Statistical Machine Translation (SMT) system,
turned out to be one of the causes of the observed
deterioration of translation quality. In later works
on the subject, which show a more or less
important improvement in translation quality, SL
word senses are considered as directly reflected
in their equivalents found in a parallel training
corpus (Cabezas and Resnik, 2005; Carpuat and
Wu, 2007; Chan et al., 2007). Nevertheless, the
theoretical soundness of these senses is not really
addressed.
</bodyText>
<subsectionHeader confidence="0.8401795">
1.2 Advantages of cross-/ingua/ sense
determination
</subsectionHeader>
<bodyText confidence="0.998971111111111">
Cross-lingual sense induction offers a standard
criterion for sense delimitation: the translation
equivalents of ambiguous words are supposed to
reveal their hidden meanings (Resnik, 2004).
Additional advantages become evident in MT:
when the candidate senses of an ambiguous word
consist of its possible translations, identifying the
sense carried by a new instance of the word
coincides with its translation. Conceiving WSD
</bodyText>
<footnote confidence="0.7068745">
irrelevance to the domains of the processed texts (Edmonds
and Kilgarriff, 2002).
</footnote>
<note confidence="0.958171">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998631">
77
</page>
<bodyText confidence="0.9996">
as lexical selection thus seems natural (Vickrey
et al., 2005): it appears that there is no reason to
pass through senses in order to arrive to
translations. A correct translation may be attained
even without WSD, as in the case of parallel
ambiguities where the SL and TL words are
similarly ambiguous (Resnik and Yarowsky,
2000).2
</bodyText>
<subsectionHeader confidence="0.722923">
1.3 Disadvantages of cross-/ingua/ sense
determination
</subsectionHeader>
<bodyText confidence="0.99997406060606">
However, this conception of senses is not
theoretically sound, as translation equivalents do
not always constitute valid sense indicators. This
is often neglected in an attempt to render the
sense inventory as close as possible to the
training corpus of the SMT system. So,
translation equivalents are considered as
straightforward indicators of SL senses.
This approach assumes and results in some
type of uniformity regarding the nature of the
induced senses: clear-cut (e.g. homonymic) and
finer sense distinctions are all handled in the
same way. Moreover, senses are enumerated
without any description of their possible
relations. For instance, a SL word w having three
equivalents (a, b and c) is considered to have
three distinct senses (described as `w-a&apos;, `w-b&apos; et
`w-c)&apos;.
The assumption of biunivocal (one-to-one)
correspondences between senses and equivalents
disregards the fact that semantically similar
equivalents may be used to translate the same
sense of a SL word in context. However, this
constitutes a common practice in translation and
an advised technique for translators, in order to
avoid repetitions in the translated texts. The
phenomenon of translation ambiguity may pose
some problems as well: it may not need to be
resolved during translation but should be
considered in multilingual WSD. Resolving this
kind of ambiguity could also improve the quality
of the results of applications such as multilingual
information retrieval.
</bodyText>
<subsectionHeader confidence="0.9738615">
1.4 Impact of cross-/ingua//y defined senses
on eva/uation
</subsectionHeader>
<bodyText confidence="0.9797016">
Ignoring the relations between word senses may
raise further problems during WSD evaluation,
as errors concerning close or distant senses are
considered as equally important. Thus, if a WSD
algorithm selects a sense which is slightly
2 A typical example is that of the ambiguous English noun
interestwhose &amp;quot;personal&amp;quot; and &amp;quot;financial&amp;quot; senses are
translated by the same word in French (interet).
different from the one effectively carried by an
instance of an ambiguous word, but not totally
wrong, this is directly considered as a false
choice. A differing weighting of WSD errors
would be preferable in these cases, if sense
distance information was available (Resnik and
Yarowsky, 2000).
When WSD coincides with lexical selection
in MT, the equivalents of a SL word (w) are
perceived to be its candidate senses. The sense
assigned to a new instance of w is considered to
be correct if it corresponds to the reference
translation (i.e. the translation of that instance in
the test corpus). This strict requirement of exact
correspondence constitutes one of the main
critics addressed to MT evaluation metrics
(Cabezas and Resnik, 2005; Callison-Burch,
2006; Chan et al., 2007) and is one of the main
reasons that methods have been developed which
go beyond pure string matching (Owczarzak et
al., 2007).
A central issue in MT evaluation is the high
correlation of the metrics with human
judgements of translation quality, which puts the
accent on the identification of sense
correspondences. Here too, it is essential to
penalize errors relatively to their importance and
so information relative to the semantics of the
equivalents should be available. In the next
section we will show how this information can
be acquired using a data-driven sense induction
method.
</bodyText>
<sectionHeader confidence="0.993609" genericHeader="method">
2 Data-driven semantic ana/ysis in a
bi/ingua/ context
</sectionHeader>
<bodyText confidence="0.999864578947368">
We propose to explore the semantic relations of
the equivalents of ambiguous words using a
parallel corpus and to exploit these relations for
SL sense induction. A data-driven sense
acquisition method based on this type of
relations is presented in Apidianaki (2008). The
theoretical assumptions underlying this approach
are the distributional hypotheses of meaning
(Harris, 1954) and of semantic similarity (Miller
and Charles, 1989), and that of sense
correspondence between words in translation
relation in real texts.
Our training corpus is the English (EN)—
Greek (GR) part of the lemmatized and
POS-tagged INTERA corpus (Gavrilidou et al.,
2004) which contains approximately four million
words. The corpus has been sentence- and word-
aligned at the level of tokens and types (Simard
and Langlais, 2003). Two bilingual lexicons (one
</bodyText>
<page confidence="0.9967">
78
</page>
<bodyText confidence="0.9991906">
for each translation direction: EN—GRiGR—EN
are built from the alignment of word types. In
these lexicons, each SL word (&amp;) is associated
with the set of the equivalents to which it is
aligned, as shown hereafter:
</bodyText>
<construct confidence="0.49438775">
imp/ication: {/0123456 (consequence), 437389/:
(impact), 4353;&lt;=&gt; (complication)}
variation: {?56=@A61/: (fluctuation),A486B&lt;;&gt;
(alteration), 8C&lt;3&lt;3&lt;7:/: (modification)}
</construct>
<bodyText confidence="0.994586977272727">
The words in parentheses describe the senses
of the Greek equivalents. In order to eliminate
the noise present in the lexicons, two filters are
used: a POS-filter, that keeps only the
correspondences between words of the same
category&apos; and an intersection filter, which
discards the translation correspondences not
found in both translation lexicons. A lexical
sample of 150 ambiguous English nouns having
more than two equivalents is then created from
the EN—GR lexicon°. At this stage, the semantic
relations possibly existing between the
equivalents are not yet evident, and so no
conclusions can be extracted concerning the
distinctiveness of the senses they can induce on
the SL words.
The core component of the sense induction
method used is a semantic similarity calculation
which aims at discovering the relations between
the equivalents of a SL ambiguous word (&amp;).
First, the translation units (TUs)� in which &amp;
appears in the SL sentence(s) are extracted from
the training corpus and are then grouped by
reference to &amp;&apos;s equivalents. For instance, if &amp; is
translated by $, &apos; and (, three sets of TUs are
formed (where &amp; is translated by $ (&apos;&amp;D$&apos; TUs),
by &apos; (&apos;&amp;D&apos;&apos; TUs), etc.).
The SL context features corresponding to
each equivalent (i.e. the set of lemmatized
content words surrounding &amp; in the SL side of
the TUs corresponding to the equivalent) are
extracted and treated as a &apos;bag of words&apos;. This
distributional information serves to calculate the
equivalents&apos; similarity using a variation of the
Weighted Jaccard coefficient (Grefenstette,
199°). The similarity calculation is described in
detail in Apidianaki (2008).
Each retained context feature is assigned a
weight relatively to each equivalent, which
&apos; The noun equivalents of nouns, the verb equivalents of
verbs, etc.
° Here we focus on nouns but the method is applicable to
words of other POS categories.
s A translation unit contains up to 2 sentences of each
language linked by an alignment.
serves to define its relevance for the estimation
of the equivalents&apos; similarity. The equivalents are
compared in a pairwise manner and a similarity
score is assigned to each pair. Two equivalents
are considered as semantically related if the
instances of &amp; they translate in the training
corpus occur in &amp;quot;similar enough&amp;quot; contexts. The
pertinence of their relation is judged by
comparing its score to a threshold, equal to the
mean of the scores assigned to all the pairs of
equivalents of &amp;.
The results of this calculation are exploited
by a clustering algorithm which takes as input
the set of equivalents of &amp; and outputs clusters of
similar equivalents illustrating its senses
(Apidianaki, 2008). Clustered equivalents are
semantically related&apos; and considered as
translating the same SL sense, while isolated
ones translate distinct senses.
The same calculation is performed by
reference to the TL contexts of the equivalents,
i.e. using the lemmatized content words
surrounding the equivalents in the TL side of the
corresponding TUs sets. Contrary to the SL
results, the TL ones are not used for clustering.
The TL distributional information relative to the
clustered equivalents and acquired at this stage
will be used for lexical selection, as we will
show later in this paper.
The sense clusters created for a word serve to
identify its senses. We describe the senses
acquired for the nouns )EF%)($&amp;quot;)G* and H$+)$&amp;quot;)G*:
imp/ication:
{/0123456, 437389/:}: the &amp;quot;impact&amp;quot; sense
{4353;&lt;=&gt;}: the &amp;quot;complication&amp;quot; sense
variation:
{?56=@A61/:}: the &amp;quot;fluctuation&amp;quot; sense
{A486B&lt;;&gt;I 8C&lt;3&lt;3&lt;7:/:}: the &amp;quot;alteration&amp;quot; sense
The sense induction method presented above
thus permits the automatic creation of a sense
inventory from a parallel corpus. In what
follows, we will show how this can be exploited
for WSD.
</bodyText>
<sectionHeader confidence="0.893321" genericHeader="method">
3 Unsupervised WSD based on the
semantic c/ustering
</sectionHeader>
<bodyText confidence="0.909596428571429">
The method described in section 2 provides, as a
by-product, information that can be exploited by
an unsupervised WSD classifier. In the case of a
one-equivalent cluster, this information
corresponds to the set of the equivalent&apos;s
&apos; Most often near-synonyms but they may be linked by other
relations (hyperonymy, hyponymy, etc.).
</bodyText>
<page confidence="0.943297">
79
</page>
<figure confidence="0.555808666666667">
e
f
L
i=1
L
j =1
</figure>
<bodyText confidence="0.943247142857143">
features, retained from the corresponding SL
contexts of w. In the case of bigger clusters, it
consists of the SL context features that reveal the
equivalents&apos; similarities: for a cluster of two
equivalents, it consists of their assimilative
contexts (i.e. the features they share)7; for a
cluster of more than 2 equivalents, it consists of
the intersection of the common features of the
pairs of equivalents found in the cluster.
As we have already said, each retained
context feature is assigned a weight relatively to
each equivalent. Here are the weighted features
characterizing the clusters of variation :
{8tax6ttavuqj: significant (2.04), range (0.76),
pharmacokinetics(1.89), individual (1.89), affect
(1.89), insulin (1.89), woman (1.89), year (1.49),
man (1.19), considerable (1.19), member (1.12),
old (0.76), Ireland (0.76), case (0.72), increase
(0.76), group (0.76), states (0.71), external (0.76),
good (0.76), expectancy (0.76), Spain (0.76),
pressure (0.76), Europe (0.76)
</bodyText>
<equation confidence="0.979048">
{ipoaoaoiquq, ttmapok4j : minor (2.25i1.83),
8
human (2.01i1.13), number (0.73i1.16)
</equation>
<bodyText confidence="0.9990172">
In order to disambiguate a new instance of a
word w, cooccurrence information coming from
its context is compared to the sets of features
characterizing the clusters. The new context must
thus be lemmatized and POS-tagged as well.
Here is an example of a new instance of
variation:
a. &amp;quot;Although certain regions have been faced
with an exodus of their endogenous population,
most of the coastal zones are experiencing an
increase in overall demographic pressure, as
well as significant seasonal variations in
employment, essentially linked to tourism.&amp;quot;
The features retained from this context are
the lemmas of the content words (nouns, verbs
and adjectives) surrounding w. If common
features (CFs) are found between this context
and just one cluster of w, this is selected as
describing the sense of the new instance. On the
contrary, if CFs with more than one cluster are
found, a score is given to each context-cluster
association. This score corresponds to the mean
of the weights of the CFs relatively to each
equivalent of the cluster and is given by the
following formula.
</bodyText>
<footnote confidence="0.74074525">
7 Term used in the study of paraphrase (Fuchs, 1994).
8 The two scores in parentheses correspond, respectively, to
the score of the feature by reference to the first and the
second equivalent of the cluster.
</footnote>
<equation confidence="0.5643915">
w (equivalenti , feature j)
e* f
</equation>
<bodyText confidence="0.999926956521739">
In this formula, e is the number of the
equivalents of a cluster and f is the number of its
CFs with the new context. The cluster with the
highest score is retained; it describes the sense
carried by the new instance of w and could be
used as its sense tag. The only cluster having CFs
with the context of variation in (a) and is thus
selected is J&amp;axauavorl} ( C F s : increase,
pressure, significant).
If any instances remain ambiguous at the end
of the WSD process (i.e. no associations are
established with the sense clusters), a small
modification could increase the method&apos;s
coverage. If w has clusters of more than two
equivalents, it is possible to use the assimilative
contexts of the pairs of equivalents instead of
their intersection. The coverage of the WSD
method would be increased in this way, as the
sets of assimilative contexts would contain more
features than their intersection, and so it would
become more probable to find CFs with the new
contexts and to establish &apos;context-cluster&apos;
associations.
</bodyText>
<sectionHeader confidence="0.997668" genericHeader="method">
4 Semantics-sensitive WSD eva/uation
</sectionHeader>
<subsectionHeader confidence="0.984616">
4.1 The notion of enriched precision
</subsectionHeader>
<bodyText confidence="0.99975495">
In this section, we will present the evaluation of
the proposed WSD method and we will show
how the clustering information can be exploited
at this stage.9 The new instances of the nouns of
our lexical sample, used for evaluation, come
from our test corpus, the sentence aligned EN—
GR part of EUROPARL (Koehn, 2005). The
TUs containing the ambiguous nouns are
extracted from the corpus. Lacking a gold-
standard for evaluation, we exploit information
relative to translations.
In the multilingual tasks of Senseval and
Semeval (Ckhlovski et al., 2004; Jin et al.,
2007), the translations of the words in the
parallel test corpus are considered as their sense
tags. Here, we consider that the equivalent
translating an ambiguous SL word in context
(called reference translation) points to a sense
described by a cluster. Consequently, what is
being evaluated is the capacity of the WSD
</bodyText>
<footnote confidence="0.9870865">
9 Some of the equivalents of w found in the training corpus
and contained in the clusters may not be used in the test
corpus. The evaluation concerns only those that are found in
the test corpus.
</footnote>
<page confidence="0.99641">
80
</page>
<bodyText confidence="0.999978703703704">
method to predict this sense. The sense
proposed for an instance of an ambiguous word
is considered as correct if a) a 1-equivalent
cluster is selected and the equivalent
corresponds to the reference, or b) if a bigger
cluster containing the reference is selected.
Otherwise, the proposed sense is fa/se.
In the multilingual tasks where translations
are regarded as sense tags, the proposed senses
are considered as correct only if they correspond
exactly to the reference translation. This is the
principle ofprecision, underlying most of the
existing MT evaluation metrics. From a
quantitative point of view, this strict criterion
has a negative impact on the WSD evaluation
results. From a qualitative point of view, it
ignores the fact that different equivalents may
correspond to the same source sense and that an
ambiguous word in context can have more than
one good translation.
The use of the sense clusters during WSD
evaluation offers the possibility of capturing the
semantic relations between the equivalents of
ambiguous words, acquired during learning. In
this case, the evaluation could be considered as
based on a principle of enriched precision that
exploits the paradigmatic relations of TL words.
</bodyText>
<subsectionHeader confidence="0.463001">
4.2. Eva/uation metrics
</subsectionHeader>
<bodyText confidence="0.937656">
The metrics used for WSD evaluation are the
following:
number of correct predictions
</bodyText>
<equation confidence="0.746100666666667">
recall =
number of new instances
precision =
</equation>
<bodyText confidence="0.998731741935484">
number of correct predictions
number of predictions
The obtained results are compared to those
of a baseline method. The baseline most often
used in Senseval is that of the most frequent
sense (i.e. the first sense given for a word in a
predefined sense inventory). This is a very
powerful heuristic because of the asymmetric
distribution of word senses in real texts. Our
baseline consists of choosing the most frequent
equivalent (i.e. the one that translates w most
frequently in the training corpus) as illustrating
the sense of all its new instances. The
asymmetric distribution of senses is, however,
reflected at the level of the equivalents used to
translate them: the most frequent equivalent in
the training corpus is often the one that
translates most of the instances of w in the test
corpus.
The baseline score corresponds to both
recall and precision, as a prediction is made for
all the new instances. This score is calculated,
for each w, on the basis of the number of its
instances for which the proposed sense is
correct. This number coincides with the
frequency of the most frequent equivalent of w
in the test corpus. In order to facilitate the
comparison between our results and the
baseline, we use thef-measure (f-score) that
combines precision and recall in a unique
measure:
</bodyText>
<equation confidence="0.816632666666667">
2*( precision*recall)
f —score =
precision + recall
</equation>
<bodyText confidence="0.999025151515152">
We evaluate here the performance of our
WSD method on the 150 ambiguous nouns of
our sample. We observe that the f-score of our
method easily overcomes the results of the
baseline.
base/ine 51.42%
enriched f-score 76.99%
The difference between these scores
indicates the positive impact of the clustering
information on the WSD results. As the senses
are situated at a higher level of abstraction, the
correspondences with the reference are
established at a more abstract level than that of
exact unigram correspondences.
Our results can be compared to those
obtained in the multilingual lexical sample tasks
of Senseval and SemEval. This comparison
seems interesting although these tasks concern
words of different parts of speech (nouns, verbs
and adjectives). The systems participating at the
multilingual English—Hindi lexical sample task
of Senseval-3 are all supervised and they all
perform better than the baseline (Chklovski et
al., 2004). This is interpreted by the authors as
an indication of the clarity of the sense
distinctions performed using translations, which
provide sufficient information for the training of
supervised classifiers. The systems performed
better on the sense-tagged part of the data,
showing that sense information may be helpful
for the task of targeted word translation. In the
English—Chinese lexical sample task of
SemEval the unsupervised systems perform
</bodyText>
<page confidence="0.996934">
81
</page>
<bodyText confidence="0.995678">
worse than the baseline, contrary to the
supervised ones (Jin !&amp;quot; $%., 2007).
</bodyText>
<sectionHeader confidence="0.9697145" genericHeader="method">
5 Capturing semantic simi/arity during
trans/ation
</sectionHeader>
<subsectionHeader confidence="0.990861">
5.1 Lexica/ se/ection based on WSD
</subsectionHeader>
<bodyText confidence="0.999744363636364">
In the experiments reported here, %!R)($%
,!%!(&amp;quot;)G* refers to the translation of ambiguous
SL nouns in context and not to that of whole
sentences. Lexical selection is thus considered
as a &apos;%$*MDK)%%)*J task (Vickrey !&amp;quot; $%., 2005): the
equivalents translating the SL nouns in the TL
sentences of the test TUs are automatically
replaced by a blank which has to be filled by the
WSD or the lexical selection method. We give
an example of a test TU containing the noun
)EF%)($&amp;quot;)G*.
</bodyText>
<equation confidence="0.900921857142857">
b) &amp;quot;U*P (L$*J! &amp;quot;G &amp;quot;L! (O++!*&amp;quot; ,)&amp;quot;O$&amp;quot;)G* EO,&amp;quot; &apos;!
F+!(!N!N &apos;P $ +)JG+GO, ,&amp;quot;ONP GK )&amp;quot;, H$+)GO,
implicationsI &amp;)&amp;quot;L &amp;quot;L! G&apos;X!(&amp;quot;)H! $%&amp;$P, &apos;!)*J
&amp;quot;G JO$+$*&amp;quot;!! $ L)JLDYO$%)&amp;quot;P FO&apos;%)( ,!+H)(! $*N
&amp;quot;G +!&amp;quot;$)* &amp;quot;L! (O++!*&amp;quot; FO&apos;%)( GF!+$&amp;quot;G+, $*N
!R),&amp;quot;)*J XG&apos;,W&amp;quot; l &amp;quot;Z37/:[I /4 &lt;3&lt;56?&gt;3&lt;84
A486B&lt;;&gt; 8:[ /:A4C51&gt;[ =68\/86/:[ ]6 3C2345
3\186 16 3C&lt;:^47865 A76 4A34C5/8689A21:
A4;28: 891 ?56_&lt;C485=`1 [...] 2a&lt;186[ ?56C=`[
=68\ 1&lt;0 8&lt; /8ba&lt; 8:[ ?56/_\;5/:[ A76[
3&lt;5&lt;85=&gt;[ ?:Ab/56[ 03:C4/76[I 8:[ ?568&gt;C:/:[
891 /:A4C51`1 ?:A&lt;/791 _&lt;C291 36C&lt;a&gt;[
03:C4/5`1 =65 8:[ =68&lt;a@C9/:[ 891 /:A4C51`1
]2/491 4C^6/76[W&amp;quot;
</equation>
<bodyText confidence="0.999986">
If a one-equivalent cluster is selected by the
WSD method, this equivalent is retained as the
translation of the SL word (cf. ($), section 3).
On the contrary, when a bigger sense cluster is
proposed, the most adequate equivalent for the
TL context has to be selected. This is done by
the lexical selection method, which filters the
cluster and fills the blank in the TL sentence
with the best translation according to the TL
context.
The cluster retained during WSD as
describing the sense of )EF%)($&amp;quot;)G* in (b) is
J/0123456I 437389/:}. Most often the clustered
equivalents are near-synonyms translating the
same source sense, but almost never absolute
synonyms interchangeable in all TL contexts.
Consequently, the cluster can be filtered by
considering their differences.
In order to judge the equivalents&apos; adequacy
in the new TL context, the lexical selection
method compares information coming from this
context to information learned during training.
Given that the training was performed on a
lemmatized and POS-tagged corpus, the new TL
context must be lemmatized and POS-tagged as
well, in order to retain only the lemmas of the
content words10.
The information acquired during training
and exploited here concerns the context features
that differentiate the equivalents in the TL, as
shown by the semantic similarity calculation in
the TL side of the training corpus (cf. section 2).
The differentiating contexts of the equivalents
characterize the sense clusters as well, as was
the case with their assimilative contexts.11
The equivalent retained by the lexical
selection method for )EF%)($&amp;quot;)G* in the example
(b) is /0123456. This differs from the reference
translation (437389/:) but is closely related to it.
Thus, it is a semantically plausible translation
that can be used in this TL context.
In a real Statistical Machine Translation
(SMT) system, the clusters could be filtered by
the language model, on the basis of word
sequence probabilities in translations. In this
way, the most probable translation in the TL
context, among the semantically pertinent
alternatives included in the cluster suggested
during WSD, would be selected.
</bodyText>
<subsectionHeader confidence="0.999544">
5.2 Eva/uation of the /exica/ se/ection
</subsectionHeader>
<bodyText confidence="0.999971130434783">
The lexical selection method has been applied to
the WSD results on our lexical sample. The
reference translations, found in the test corpus,
serve for evaluation here as well. We calculate
the results of this method first using the
principle of ,&amp;quot;+)(&amp;quot; F+!(),)G* (i.e. looking for
exact correspondences with the reference) and
then on the basis of !*+)(L!N F+!(),)G* (i.e.
exploiting the clustering information).
The sense clusters serve here to estimate the
semantic proximity of the proposed translation
to the reference, in cases of no exact
correspondence. Thus, a translation which is
semantically similar to the reference is
considered to be correct if they are both found in
the cluster proposed during WSD. This renders
the evaluation more flexible and significantly
increases the quantity of semantically pertinent
translations compared to the baseline.
The strict and enrichedKDscores are
estimated by considering as correct (score = 1)
every translation that is pertinent according to
the corresponding evaluation principles. The
</bodyText>
<footnote confidence="0.891177">
10 Our test corpus has been tagged and lemmatized using the
TreeTagger (Schmid, 1994).
</footnote>
<page confidence="0.9256885">
11 The SL contextual information exploited for WSD.
82
</page>
<bodyText confidence="0.993883415584416">
results indicate the increase in pertinent
translations.
base/ine 52.14%
strict -f-score 48.37%
enriched f-score 77.79%
We observe that the strict f-score is lower
than the baseline. This happens because our
method proposes equivalents semantically
similar to the reference for some instances for
which the baseline predictions are correct.
However, these pertinent predictions are not
taken into account by the principle of strict
precision. This is the case in example (b): the
baseline prediction (e7chacouq) for this instance
o f implication corresponds to the reference
while the suggestion of our method (uvve7ceaa),
even though semantically pertinent, is not
considered as correct according to the principle
of strict precision and is not rewarded.
Nevertheless, it would be preferable to
weigh differently the predictions related to the
reference, by taking into account the strength of
their relation. These predictions could be
considered as almost correct and they could be,
at the same time, penalized less than translations
having a different sense and less rewarded than
exact correspondences to the reference.
For this to be done, a measure capable of
capturing the semantic distance would be
needed. Using a weighted coefficient is essential
in tasks implicating semantics, not only in WSD
(Resnik and Yarowsky, 2000) but also in tasks
such as the estimation of inter-annotator
agreement in semantic annotation (Artstein and
Poesio, 2008). The common element between
these tasks is that the distances between the
categories (word senses) should be weighted, so
that the WSD errors or the divergences between
annotators be treated differently.
We envisaged the possibility of weighting
differently the proposed translations on the basis
of their relation to the reference, by using as
distance measure their similarity score in the
TL. A semantically pertinent translation
different from the reference was assigned a
score equal to the similarity score of the two
equivalents in the TL. A problem that we
encountered, and that made us fall back to the
solution of a uniform weighting of semantically
pertinent translations, is that the comparison of
these results to the baseline was not
representative of the effective improvement (the
great increase in the number of pertinent
translation predictions) brought about by
exploiting the clustering information. This
happens because all the correct suggestions of
the baseline are weighted by a score equal to 1,
while the score of translations semantically
related to the reference is always lower than 1,
given that absolute synonyms are very rare in
natural language.
We envisage the elaboration of a more
sophisticated coefficient for weighting
semantically pertinent translations, that will
permit a more conclusive comparison with the
baseline. This coefficient could take into
account not only the similarity score between a
proposed translation and the reference but also
the number of the SL word&apos;s candidate
translations, the number of its senses and their
distinctiveness, as well as the number of the
equivalents similar to the reference and their
scores.
Before concluding, we would like to take a
look at the way the concern for lexical
semantics is manifested and taken into account
in existing MT evaluation metrics.
</bodyText>
<subsectionHeader confidence="0.92914">
5.3 Semantic simi/arity in existing MT
eva/uation metrics
</subsectionHeader>
<bodyText confidence="0.999930518518519">
Lexical semantic relations are supposed to be
captured in BLEU by the use of multiple
reference translations (Papineni et al., 2002).
Finding many references for evaluation is,
however, rather problematic (Callison-Burch,
2006).
In METEOR (Banerjee and Lavie, 2005),
such relations are detected by exploiting
WordNet (Miller et al., 1990). More precisely,
the number of pertinent translations is increased
using synset information: a translation is correct
not only if it corresponds to the reference, but
also if it is semantically similar to it, i.e. found in
the same synset.
One of the limitations of this metric is that
the words being tested for synonymy are not
disambiguated; that is what Banerjee and Lavie
call &amp;quot;a poor-man&apos;s synonymy detection
algorithm&amp;quot;. Consequently, the WN-Synonymy
module used maps two unigrams together simply
if at least one sense of each word belongs to the
same WordNet synset.
Another problem is that the metric is
strongly dependent on a predefined sense
inventory. Given that such resources are publicly
available for very few languages, the synonymy
module often is not operational and is omitted.
</bodyText>
<page confidence="0.996045">
83
</page>
<bodyText confidence="0.9998804">
Lavie and Agarwal (2007) envisage the
possibility of developing new synonymy
modules for languages other than English, which
would be based on alternative methods and could
replace WordNet.
In the previous sections, we showed how the
information acquired by an unsupervised sense
induction method can help to account for the
words&apos; semantic similarity. The created sense
clusters, grouping semantically similar
equivalents, can be compared to WordNet
synsets. This kind of semantic information,
extracted directly from text data, can constitute
an alternative to the use of predefined sense
inventories. A clear advantage of a metric based
on the results of unsupervised semantic analysis,
in comparison to one dependent on a predefined
resource, is that it is language-independent and
may be used for evaluation in languages where
semantic resources are not available.
</bodyText>
<sectionHeader confidence="0.990703" genericHeader="conclusions">
6 Conc/usion and perspectives
</sectionHeader>
<bodyText confidence="0.999980862068965">
In this paper, we have presented the advantages
and weaknesses of cross-lingual sense
determination, often used in multilingual WSD
and MT. We have put forward some arguments
towards a more thorough semantic analysis of
the translation equivalents of ambiguous words
that serve as sense indicators, and we have
shown how it could be of use in multilingual
WSD and MT.
The data-driven sense induction method used
identifies the senses of ambiguous English nouns
by clustering their translation equivalents
according to their semantic similarity. Exploiting
the sense inventory built in this way proves of
benefit in multilingual WSD and lexical selection
in MT. Their evaluation becomes more flexible
as well, as it becomes possible to capture the
semantic relations between the translations of
ambiguous words.
The problem of strictness of the MT
evaluation metrics can thus be overcome without
the need for a predefined inventory. This would
allow for a more conclusive estimation of the
effect of WSD in SMT. The integration of the
cluster-based WSD method into a real SMT
system and the evaluation of its impact on
translation quality constitute the main
perspectives of the work presented in this article
and the object of future work.
</bodyText>
<sectionHeader confidence="0.702148" genericHeader="acknowledgments">
Acknow/edgments
</sectionHeader>
<bodyText confidence="0.999909">
I would like to thank Philippe Langlais for the
word alignment and Andy Way for useful
comments. This research is funded by SFI grant
05iINi1732.
</bodyText>
<sectionHeader confidence="0.99585" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999219744680851">
Marianna Apidianaki. 2008. Translation-oriented
Sense Induction Based on Parallel Corpora, In
Proceedings of the 6th Conference on Language
Resources and Evaluation (LREC), Marrakech,
Morocco.
Ron Artstein and Massimo Poesio. 2008. Inter-coder
Agreement for Computational Linguistics,
Computational Linguistics 34(4): 555-596.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with
Improved Correlation with Human Judgments. In
Proceedings of the Workshop on Intrinsic and
Extrinsic Evaluation Measures for MT andior
Summarization, 43rd Annual Meeting of the
Association for Computational Linguistics (ACL),
Ann Arbor, Michigan, 65-72.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra and Robert L. Mercer. 1991. Word-
sense disambiguation using statistical methods. In
29th Annual Meeting of the Association for
Computational Linguistics (ACL), Berkeley,
California, 264-270.
Clara Cabezas and Philip Resnik. 2005. Using WSD
Techniques for Lexical Selection in Statistical
Machine Translation. Technical Report CS-TR-
4736iLAMP-TR-124iUMIACS-TR-2005-42.
Chris Callison-Burch, Miles Osborne and Philipp
Koehn. 2006. Re-evaluating the Role of BLEU in
Machine Translation Research. In Proceedings of
the 11th Conference of the European Chapter of the
Association for Computational Linguistics
(EACL), Trento, Italy, 249-256.
Marine Carpuat and Dekai Wu. 2005. Word Sense
Disambiguation vs. Statistical Machine
Translation. In 43rd Annual Meeting of the
Association for Computational Linguistics (ACL).
Ann Arbor, Michigan, 387-394.
Marine Carpuat and Dekai Wu. 2007. Improving
Statistical Machine Translation using Word Sense
Disambiguation. In Proceedings of the Joint
Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), Prague,
Czech Republic, 61-72.
Yee Seng Chan, Hwee Tou Ng and David Chiang.
2 0 0 7. Word Sense Disambiguation Improves
Statistical Machine Translation. In 45th Annual
</reference>
<page confidence="0.983627">
84
</page>
<reference confidence="0.999660905882353">
Meeting of the Association for Computational
Linguistics, Prague, Czech Republic, 33-40.
Timothy Chklovski, Rada Mihalcea, Ted Pedersen and
Amruta Purandare. 2004. The senseval-3
multilingual English-Hindi lexical sample task.
Senseval-3, Third International Workshop on
Evaluating Word Sense Disambiguation Systems,
Barcelona, Spain, 5-8.
Philip Edmonds and Adam Kilgarriff. 2002.
Introduction to the special issue on evaluating
word sense disambiguation systems. Natural
Language Engineering 8(4): 279-291.
Catherine, Fuchs. 1994. Paraphrase et 6nonciation.
Editions Ophrys, Paris.
Maria Gavrilidou, Peny Labropoulou, Elina Desipri,
Voula Giouli, Vasilis Antonopoulos and Stelios
Piperidis. 2004. Building parallel corpora for
eContent professionals. In Proceedings of the
Workshop on Multilingual Linguistic Resources,
20th International Conference on Computational
Linguistics (COLING), Geneva, Switzerland,
90-93.
Gregory Grefenstette. 1994. Explorations in
Automatic Thesaurus Discovery. Kluwer Academic
Publishers, BostoniDordrechtiLondon.
Zellig Harris. 1954. Distributional Structure. Word,
10: 146-162.
Peng Jin, Yunfang Wu and Shiwen Yu. 2007.
SemEval-2007 Task S: Multilingual Chinese-
English Lexical Sample, In Proceedings of the 4th
International Workshop on Semantic Evaluations
(SemEval 2007), Prague, Czech Republic, 19-23.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of
MT Summit X, Phuket, Thailand, 79-86.
Alon Lavie and Abhaya Agarwal. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
Proceedings of the 2nd Workshop on Statistical
Machine Translation, 45th Meeting of the
Association for Computational Linguistics (ACL),
Prague, Czech Republic, 228-231.
George A. Miller, Richard Beckwith, Christiane
Fellbaum, Derek Groos and Katherine Miller. 1990.
Introduction to WordNet: An On-line Lexical
Database. International Journal of Lexicography
3(4): 235-312.
George A. Miller and Walter G. Charles. 1991.
Contextual correlates of semantic similarity.
Language and Cognitive Processes 6(1): 1-28.
Karolina Owczarzak, Josef van Genabith and Andy
Way. 2007. Labelled Dependencies in Machine
Translation Evaluation. In Proceedings of the 2nd
Workshop on Statistical Machine Translation, 45th
Meeting of the Association for Computational
Linguistics (ACL), Prague, Czech Republic,
104-111.
Kishore Papineni, Salim Roukos, Todd Ward and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In 40th Annual
Meeting of the Association for Computational
Linguistics, Philadelphia, PA., 311-318.
Philip Resnik. 2004. Exploiting Hidden Meanings:
Using Bilingual Text for Monolingual Annotation.
In Gelbukh, A. (ed.), Lecture Notes in Computer
Science 2945: Computational Linguistics and
Intelligent Text Processing: Proceedings of the 5th
International Conference CICLing, Seoul, Korea,
283-299.
Philip Resnik and David Yarowsk. 2000.
Distinguishing Systems and Distinguishing Senses:
New Evaluation Methods for Word Sense
Disambiguation, Natural Language Engineering
5(3): 113-133.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In Proceedings of
the International Conference on New Methods in
Language Processing, Manchester, 44-49.
David Vickrey, Luke Biewald, Marc Teyssier and
Daphne Koller. 2005. Word-Sense Disambiguation
for Machine Translation. In Proceedings of the
Joint Conference on Human Language
Technology i Empirical Methods in Natural
Language Processing (HLT-EMNLP), Vancouver,
Canada, 771-778.
</reference>
<page confidence="0.999699">
85
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001159">
<title confidence="0.9945365">Data-driven semantic ana/ysis for mu/ti/ingua/ WSD and /exica/ se/ection in trans/ation</title>
<author confidence="0.999841">Marianna Apidianaki</author>
<affiliation confidence="0.997215">National Centre for Language Technology School of Computing, Dublin City University</affiliation>
<address confidence="0.995001">Dublin 9, Ireland</address>
<email confidence="0.985592">mapidianaki@c*mputing.dcu.ie</email>
<abstract confidence="0.988871324763197">A common way of describing the senses of ambiguous words in multilingual Word Sense Disambiguation (WSD) is by reference to their translation equivalents in another language. The theoretical soundness of the senses induced in this way can, however, be doubted. This type of cross-lingual sense identification has implications for multilingual WSD and MT evaluation as well. In this article, we first present some arguments in favour of a more thorough analysis of the semantic information that may be induced by the equivalents of ambiguous words found in parallel corpora. Then, we present an unsupervised WSD method and a lexical selection method that exploit the results of a data-driven sense induction method. Finally, we show how this automatically acquired information can be exploited for a multilingual WSD and MT evaluation more sensitive to lexical semantics. 1 Word senses in a bi-(mu/ti-)/ingua/ context 1.1 Cross-/ingua/ sense determination for WSD Determining the senses of ambiguous words by reference to their translational equivalents constitutes a common practice in multilingual WSD: the candidate senses of an ambiguous word, from which one has to be selected during WSD, correspond to its equivalents in another language. This empirical approach to sense identification circumvents the need for predefined sense inventories and their for automatic The first to as the high granularity, the great number and the striking similarity of the described senses, and their it were Brown (1991), who represented the two main senses of a SL word by its two most frequent translations in the target language (TL). Further promoted by Resnik and Yarowsky (2000) and endorsed in the tasks of the Senseval (Chklovski 2004) and Semeval (Jin 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus (Cabezas and Resnik, 2005; Carpuat and 2007; Chan 2007). Nevertheless, the theoretical soundness of these senses is not really addressed. 1.2 Advantages of cross-/ingua/ sense determination Cross-lingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving WSD irrelevance to the domains of the processed texts (Edmonds and Kilgarriff, 2002). of the 12th Conference of the European Chapter of the pages 77–85, Greece, 30 March – 3 April 2009. Association for Computational Linguistics 77 as lexical selection thus seems natural (Vickrey 2005): it appears that there is no reason to pass through senses in order to arrive to translations. A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous (Resnik and Yarowsky, 1.3 Disadvantages of cross-/ingua/ sense determination However, this conception of senses is not theoretically sound, as translation equivalents do not always constitute valid sense indicators. This is often neglected in an attempt to render the sense inventory as close as possible to the training corpus of the SMT system. So, translation equivalents are considered as straightforward indicators of SL senses. This approach assumes and results in some type of uniformity regarding the nature of the induced senses: clear-cut (e.g. homonymic) and finer sense distinctions are all handled in the same way. Moreover, senses are enumerated without any description of their possible For instance, a SL word three is considered to have distinct senses (described as et The assumption of biunivocal (one-to-one) correspondences between senses and equivalents disregards the fact that semantically similar equivalents may be used to translate the same sense of a SL word in context. However, this constitutes a common practice in translation and an advised technique for translators, in order to avoid repetitions in the translated texts. The phenomenon of translation ambiguity may pose some problems as well: it may not need to be resolved during translation but should be considered in multilingual WSD. Resolving this kind of ambiguity could also improve the quality of the results of applications such as multilingual information retrieval. 1.4 Impact of cross-/ingua//y defined senses on eva/uation Ignoring the relations between word senses may raise further problems during WSD evaluation, as errors concerning close or distant senses are considered as equally important. Thus, if a WSD algorithm selects a sense which is slightly 2A typical example is that of the ambiguous English noun &amp;quot;personal&amp;quot; and &amp;quot;financial&amp;quot; senses are by the same word in French different from the one effectively carried by an instance of an ambiguous word, but not totally wrong, this is directly considered as a false choice. A differing weighting of WSD errors would be preferable in these cases, if sense distance information was available (Resnik and Yarowsky, 2000). When WSD coincides with lexical selection MT, the equivalents of a SL word are perceived to be its candidate senses. The sense to a new instance of considered to be correct if it corresponds to the reference translation (i.e. the translation of that instance in the test corpus). This strict requirement of exact correspondence constitutes one of the main critics addressed to MT evaluation metrics (Cabezas and Resnik, 2005; Callison-Burch, Chan 2007) and is one of the main reasons that methods have been developed which beyond pure string matching (Owczarzak 2007). A central issue in MT evaluation is the high correlation of the metrics with human judgements of translation quality, which puts the accent on the identification of sense correspondences. Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available. In the next section we will show how this information can be acquired using a data-driven sense induction method. 2 Data-driven semantic ana/ysis in a bi/ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction. A data-driven sense acquisition method based on this type of relations is presented in Apidianaki (2008). The theoretical assumptions underlying this approach are the distributional hypotheses of meaning (Harris, 1954) and of semantic similarity (Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts. Our training corpus is the English (EN)— Greek (GR) part of the lemmatized and INTERA corpus (Gavrilidou 2004) which contains approximately four million words. The corpus has been sentenceand wordaligned at the level of tokens and types (Simard and Langlais, 2003). Two bilingual lexicons (one 78 for each translation direction: EN—GRiGR—EN are built from the alignment of word types. In lexicons, each SL word is associated with the set of the equivalents to which it is aligned, as shown hereafter: The words in parentheses describe the senses of the Greek equivalents. In order to eliminate the noise present in the lexicons, two filters are used: a POS-filter, that keeps only the correspondences between words of the same an intersection filter, which discards the translation correspondences not found in both translation lexicons. A lexical sample of 150 ambiguous English nouns having more than two equivalents is then created from EN—GR At this stage, the semantic relations possibly existing between the equivalents are not yet evident, and so no conclusions can be extracted concerning the distinctiveness of the senses they can induce on the SL words. The core component of the sense induction method used is a semantic similarity calculation which aims at discovering the relations between equivalents of a SL ambiguous word the translation units which appears in the SL sentence(s) are extracted from the training corpus and are then grouped by to equivalents. For instance, if by three sets of TUs are (where translated by TUs), TUs), etc.). The SL context features corresponding to each equivalent (i.e. the set of lemmatized words surrounding the SL side of the TUs corresponding to the equivalent) are extracted and treated as a &apos;bag of words&apos;. This distributional information serves to calculate the equivalents&apos; similarity using a variation of the Weighted Jaccard coefficient (Grefenstette, 199°). The similarity calculation is described in detail in Apidianaki (2008). Each retained context feature is assigned a weight relatively to each equivalent, which noun equivalents of nouns, the verb equivalents of verbs, etc. we focus on nouns but the method is applicable to words of other POS categories. sA translation unit contains up to 2 sentences of each language linked by an alignment. serves to define its relevance for the estimation of the equivalents&apos; similarity. The equivalents are compared in a pairwise manner and a similarity score is assigned to each pair. Two equivalents are considered as semantically related if the of translate in the training corpus occur in &amp;quot;similar enough&amp;quot; contexts. The pertinence of their relation is judged by comparing its score to a threshold, equal to the mean of the scores assigned to all the pairs of of The results of this calculation are exploited by a clustering algorithm which takes as input set of equivalents of outputs clusters of similar equivalents illustrating its senses (Apidianaki, 2008). Clustered equivalents are considered as translating the same SL sense, while isolated ones translate distinct senses. The same calculation is performed by reference to the TL contexts of the equivalents, i.e. using the lemmatized content words surrounding the equivalents in the TL side of the corresponding TUs sets. Contrary to the SL results, the TL ones are not used for clustering. The TL distributional information relative to the clustered equivalents and acquired at this stage will be used for lexical selection, as we will show later in this paper. The sense clusters created for a word serve to identify its senses. We describe the senses for the nouns the &amp;quot;impact&amp;quot; sense the &amp;quot;complication&amp;quot; sense the &amp;quot;fluctuation&amp;quot; sense the &amp;quot;alteration&amp;quot; sense The sense induction method presented above thus permits the automatic creation of a sense inventory from a parallel corpus. In what follows, we will show how this can be exploited for WSD. 3 Unsupervised WSD based on the semantic c/ustering The method described in section 2 provides, as a by-product, information that can be exploited by an unsupervised WSD classifier. In the case of a one-equivalent cluster, this information corresponds to the set of the equivalent&apos;s often near-synonyms but they may be linked by other relations (hyperonymy, hyponymy, etc.). 79 e f L L features, retained from the corresponding SL of In the case of bigger clusters, it consists of the SL context features that reveal the equivalents&apos; similarities: for a cluster of two equivalents, it consists of their assimilative (i.e. the features they for a cluster of more than 2 equivalents, it consists of the intersection of the common features of the pairs of equivalents found in the cluster. As we have already said, each retained context feature is assigned a weight relatively to each equivalent. Here are the weighted features the clusters of ttmapok4j 8 In order to disambiguate a new instance of a cooccurrence information coming from its context is compared to the sets of features characterizing the clusters. The new context must thus be lemmatized and POS-tagged as well. Here is an example of a new instance of certain regions have been faced with an exodus of their endogenous population, most of the coastal zones are experiencing an increase in overall demographic pressure, as as significant seasonal essentially linked to The features retained from this context are the lemmas of the content words (nouns, verbs adjectives) surrounding If common features (CFs) are found between this context just one cluster of this is selected as describing the sense of the new instance. On the contrary, if CFs with more than one cluster are a score is given to each association. This score corresponds to the mean of the weights of the CFs relatively to each equivalent of the cluster and is given by the following formula. 7Term used in the study of paraphrase (Fuchs, 1994). 8The two scores in parentheses correspond, respectively, to the score of the feature by reference to the first and the second equivalent of the cluster. , feature this formula, the number of the of a cluster and the number of its CFs with the new context. The cluster with the highest score is retained; it describes the sense by the new instance w could be used as its sense tag. The only cluster having CFs the context of (a) and is thus is ( C F s : If any instances remain ambiguous at the end of the WSD process (i.e. no associations are established with the sense clusters), a small modification could increase the method&apos;s If clusters of more than two equivalents, it is possible to use the assimilative contexts of the pairs of equivalents instead of their intersection. The coverage of the WSD method would be increased in this way, as the sets of assimilative contexts would contain more features than their intersection, and so it would become more probable to find CFs with the new and to establish associations. 4 Semantics-sensitive WSD eva/uation The notion of precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited this The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL (Koehn, 2005). The TUs containing the ambiguous nouns are extracted from the corpus. Lacking a goldstandard for evaluation, we exploit information relative to translations. In the multilingual tasks of Senseval and (Ckhlovski 2004; Jin 2007), the translations of the words in the parallel test corpus are considered as their sense tags. Here, we consider that the equivalent translating an ambiguous SL word in context points to a sense described by a cluster. Consequently, what is being evaluated is the capacity of the WSD 9Some of the equivalents of in the training corpus and contained in the clusters may not be used in the test corpus. The evaluation concerns only those that are found in the test corpus. 80 method to predict this sense. The sense proposed for an instance of an ambiguous word considered as a) a 1-equivalent cluster is selected and the equivalent corresponds to the reference, or b) if a bigger cluster containing the reference is selected. the proposed sense is In the multilingual tasks where translations are regarded as sense tags, the proposed senses are considered as correct only if they correspond exactly to the reference translation. This is the underlying most of the existing MT evaluation metrics. From a quantitative point of view, this strict criterion has a negative impact on the WSD evaluation results. From a qualitative point of view, it ignores the fact that different equivalents may correspond to the same source sense and that an ambiguous word in context can have more than one good translation. The use of the sense clusters during WSD evaluation offers the possibility of capturing the semantic relations between the equivalents of ambiguous words, acquired during learning. In this case, the evaluation could be considered as on a principle of precision exploits the paradigmatic relations of TL words. 4.2. Eva/uation metrics The metrics used for WSD evaluation are the following: number of correct predictions number of new instances number of correct predictions number of predictions The obtained results are compared to those of a baseline method. The baseline most often used in Senseval is that of the most frequent sense (i.e. the first sense given for a word in a predefined sense inventory). This is a very powerful heuristic because of the asymmetric distribution of word senses in real texts. Our baseline consists of choosing the most frequent (i.e. the one that translates frequently in the training corpus) as illustrating the sense of all its new instances. The asymmetric distribution of senses is, however, reflected at the level of the equivalents used to translate them: the most frequent equivalent in the training corpus is often the one that most of the instances of the test corpus. The baseline score corresponds to both recall and precision, as a prediction is made for all the new instances. This score is calculated, each on the basis of the number of its instances for which the proposed sense is correct. This number coincides with the of the most frequent equivalent of in the test corpus. In order to facilitate the comparison between our results and the we use that combines precision and recall in a unique measure: We evaluate here the performance of our WSD method on the 150 ambiguous nouns of sample. We observe that the our method easily overcomes the results of the baseline. base/ine 51.42% 76.99% The difference between these scores indicates the positive impact of the clustering information on the WSD results. As the senses are situated at a higher level of abstraction, the correspondences with the reference are established at a more abstract level than that of exact unigram correspondences. Our results can be compared to those obtained in the multilingual lexical sample tasks of Senseval and SemEval. This comparison seems interesting although these tasks concern words of different parts of speech (nouns, verbs and adjectives). The systems participating at the multilingual English—Hindi lexical sample task of Senseval-3 are all supervised and they all better than the baseline (Chklovski 2004). This is interpreted by the authors as an indication of the clarity of the sense distinctions performed using translations, which provide sufficient information for the training of supervised classifiers. The systems performed better on the sense-tagged part of the data, showing that sense information may be helpful for the task of targeted word translation. In the English—Chinese lexical sample task of SemEval the unsupervised systems perform 81 worse than the baseline, contrary to the ones (Jin 5 Capturing semantic simi/arity during trans/ation 5.1 Lexica/ se/ection based on WSD the experiments reported here, to the translation of ambiguous SL nouns in context and not to that of whole sentences. Lexical selection is thus considered a (Vickrey 2005): the equivalents translating the SL nouns in the TL sentences of the test TUs are automatically replaced by a blank which has to be filled by the WSD or the lexical selection method. We give an example of a test TU containing the noun (L$*J! &amp;quot;G &amp;quot;L! (O++!*&amp;quot; ,)&amp;quot;O$&amp;quot;)G* EO,&amp;quot; &apos;! F+!(!N!N &apos;P $ +)JG+GO, ,&amp;quot;ONP GK )&amp;quot;, H$+)GO, &amp;)&amp;quot;L &amp;quot;L! G&apos;X!(&amp;quot;)H! $%&amp;$P, &apos;!)*J &amp;quot;G JO$+$*&amp;quot;!! $ L)JLDYO$%)&amp;quot;P FO&apos;%)( ,!+H)(! $*N &amp;quot;G +!&amp;quot;$)* &amp;quot;L! (O++!*&amp;quot; FO&apos;%)( GF!+$&amp;quot;G+, $*N l /4 &lt;3&lt;56?&gt;3&lt;84 A486B&lt;;&gt; 8:[ /:A4C51&gt;[ =68\/86/:[ ]6 3C2345 3\186 16 3C&lt;:^47865 A76 4A34C5/8689A21: A4;28: 891 2a&lt;186[ ?56C=`[ =68\ 1&lt;0 8&lt; /8ba&lt; 8:[ ?56/_\;5/:[ A76[ ?:Ab/56[ 8:[ ?568&gt;C:/:[ 891 /:A4C51`1 ?:A&lt;/791 _&lt;C291 36C&lt;a&gt;[ 03:C4/5`1 =65 8:[ =68&lt;a@C9/:[ 891 /:A4C51`1 If a one-equivalent cluster is selected by the WSD method, this equivalent is retained as the of the SL word (cf. section 3). On the contrary, when a bigger sense cluster is proposed, the most adequate equivalent for the TL context has to be selected. This is done by the lexical selection method, which filters the cluster and fills the blank in the TL sentence with the best translation according to the TL context. The cluster retained during WSD as the sense of (b) is Most often the clustered equivalents are near-synonyms translating the same source sense, but almost never absolute synonyms interchangeable in all TL contexts. Consequently, the cluster can be filtered by considering their differences. In order to judge the equivalents&apos; adequacy in the new TL context, the lexical selection method compares information coming from this context to information learned during training. Given that the training was performed on a lemmatized and POS-tagged corpus, the new TL context must be lemmatized and POS-tagged as well, in order to retain only the lemmas of the The information acquired during training and exploited here concerns the context features that differentiate the equivalents in the TL, as shown by the semantic similarity calculation in the TL side of the training corpus (cf. section 2). The differentiating contexts of the equivalents characterize the sense clusters as well, as was case with their assimilative The equivalent retained by the lexical method for the example is This differs from the reference but is closely related to it. Thus, it is a semantically plausible translation that can be used in this TL context. In a real Statistical Machine Translation (SMT) system, the clusters could be filtered by the language model, on the basis of word sequence probabilities in translations. In this way, the most probable translation in the TL context, among the semantically pertinent alternatives included in the cluster suggested during WSD, would be selected. 5.2 Eva/uation of the /exica/ se/ection The lexical selection method has been applied to the WSD results on our lexical sample. The reference translations, found in the test corpus, serve for evaluation here as well. We calculate the results of this method first using the of F+!(),)G* looking for exact correspondences with the reference) and on the basis of F+!(),)G* exploiting the clustering information). The sense clusters serve here to estimate the semantic proximity of the proposed translation to the reference, in cases of no exact correspondence. Thus, a translation which is semantically similar to the reference is considered to be correct if they are both found in the cluster proposed during WSD. This renders the evaluation more flexible and significantly increases the quantity of semantically pertinent translations compared to the baseline. strict and are estimated by considering as correct (score = 1) every translation that is pertinent according to the corresponding evaluation principles. The 10Our test corpus has been tagged and lemmatized using the TreeTagger (Schmid, 1994). 11The SL contextual information exploited for WSD. 82 results indicate the increase in pertinent translations. base/ine 52.14% 48.37% 77.79% observe that the strict lower than the baseline. This happens because our method proposes equivalents semantically similar to the reference for some instances for which the baseline predictions are correct. However, these pertinent predictions are not taken into account by the principle of strict precision. This is the case in example (b): the prediction for this instance f to the reference the suggestion of our method even though semantically pertinent, is not considered as correct according to the principle of strict precision and is not rewarded. Nevertheless, it would be preferable to weigh differently the predictions related to the reference, by taking into account the strength of their relation. These predictions could be as correct they could be, at the same time, penalized less than translations having a different sense and less rewarded than exact correspondences to the reference. For this to be done, a measure capable of capturing the semantic distance would be needed. Using a weighted coefficient is essential in tasks implicating semantics, not only in WSD (Resnik and Yarowsky, 2000) but also in tasks such as the estimation of inter-annotator agreement in semantic annotation (Artstein and Poesio, 2008). The common element between these tasks is that the distances between the categories (word senses) should be weighted, so that the WSD errors or the divergences between annotators be treated differently. We envisaged the possibility of weighting differently the proposed translations on the basis of their relation to the reference, by using as distance measure their similarity score in the TL. A semantically pertinent translation different from the reference was assigned a score equal to the similarity score of the two equivalents in the TL. A problem that we encountered, and that made us fall back to the solution of a uniform weighting of semantically pertinent translations, is that the comparison of these results to the baseline was not representative of the effective improvement (the great increase in the number of pertinent translation predictions) brought about by exploiting the clustering information. This happens because all the correct suggestions of the baseline are weighted by a score equal to 1, while the score of translations semantically related to the reference is always lower than 1, given that absolute synonyms are very rare in natural language. We envisage the elaboration of a more sophisticated coefficient for weighting semantically pertinent translations, that will permit a more conclusive comparison with the baseline. This coefficient could take into account not only the similarity score between a proposed translation and the reference but also the number of the SL word&apos;s candidate translations, the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores. Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics. 5.3 Semantic simi/arity in existing MT eva/uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple translations (Papineni al., Finding many references for evaluation is, however, rather problematic (Callison-Burch, 2006). In METEOR (Banerjee and Lavie, 2005), such relations are detected by exploiting (Miller 1990). More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset. One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call &amp;quot;a poor-man&apos;s synonymy detection algorithm&amp;quot;. Consequently, the WN-Synonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset. Another problem is that the metric is strongly dependent on a predefined sense inventory. Given that such resources are publicly available for very few languages, the synonymy module often is not operational and is omitted. 83 Lavie and Agarwal (2007) envisage the possibility of developing new synonymy modules for languages other than English, which would be based on alternative methods and could replace WordNet. In the previous sections, we showed how the information acquired by an unsupervised sense induction method can help to account for the words&apos; semantic similarity. The created sense clusters, grouping semantically similar equivalents, can be compared to WordNet synsets. This kind of semantic information, extracted directly from text data, can constitute an alternative to the use of predefined sense inventories. A clear advantage of a metric based on the results of unsupervised semantic analysis, in comparison to one dependent on a predefined resource, is that it is language-independent and may be used for evaluation in languages where semantic resources are not available. 6 Conc/usion and perspectives In this paper, we have presented the advantages and weaknesses of cross-lingual sense determination, often used in multilingual WSD and MT. We have put forward some arguments towards a more thorough semantic analysis of the translation equivalents of ambiguous words that serve as sense indicators, and we have shown how it could be of use in multilingual WSD and MT. The data-driven sense induction method used identifies the senses of ambiguous English nouns by clustering their translation equivalents according to their semantic similarity. Exploiting the sense inventory built in this way proves of benefit in multilingual WSD and lexical selection in MT. Their evaluation becomes more flexible as well, as it becomes possible to capture the semantic relations between the translations of ambiguous words. The problem of strictness of the MT evaluation metrics can thus be overcome without the need for a predefined inventory. This would allow for a more conclusive estimation of the effect of WSD in SMT. The integration of the cluster-based WSD method into a real SMT system and the evaluation of its impact on translation quality constitute the main perspectives of the work presented in this article and the object of future work.</abstract>
<note confidence="0.774398">Acknow/edgments I would like to thank Philippe Langlais for the word alignment and Andy Way for useful comments. This research is funded by SFI grant 05iINi1732. References Apidianaki. 2008. Induction Based on Parallel In of the Conference on Language Resources and Evaluation (LREC), Marrakech, Morocco. Artstein and Massimo Poesio. 2008. for Computational Computational Linguistics 34(4): 555-596. Banerjee and Alon Lavie. 2005. An Automatic Metric for MT Evaluation with Correlation with Human In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Annual Meeting of the Association for Computational Linguistics (ACL), Ann Arbor, Michigan, 65-72. Peter F. Brown, Stephen A. Della Pietra, Vincent J. Pietra and Robert L. Mercer. 1991. Word-</note>
<title confidence="0.69942">disambiguation using statistical In</title>
<author confidence="0.780327">Annual Meeting of the Association for</author>
<affiliation confidence="0.993685">Computational Linguistics (ACL), Berkeley,</affiliation>
<address confidence="0.844639">California, 264-270. Cabezas and Philip Resnik. 2005. WSD</address>
<title confidence="0.858492">Techniques for Lexical Selection in Statistical</title>
<pubnum confidence="0.984304">Technical Report CS-TR-</pubnum>
<note confidence="0.91651259375">4736iLAMP-TR-124iUMIACS-TR-2005-42. Chris Callison-Burch, Miles Osborne and Philipp 2006. the Role of BLEU in Translation In Proceedings of Conference of the European Chapter of the Association for Computational Linguistics (EACL), Trento, Italy, 249-256. Carpuat and Dekai Wu. 2005. Sense Disambiguation vs. Statistical Machine In Annual Meeting of the Association for Computational Linguistics (ACL). Ann Arbor, Michigan, 387-394. Carpuat and Dekai Wu. 2007. Statistical Machine Translation using Word Sense In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Prague, Czech Republic, 61-72. Yee Seng Chan, Hwee Tou Ng and David Chiang. 0 0 7. Sense Disambiguation Improves Machine In Annual 84 Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 33-40. Timothy Chklovski, Rada Mihalcea, Ted Pedersen and Purandare. 2004. senseval-3 English-Hindi lexical sample Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain, 5-8. Philip Edmonds and Adam Kilgarriff. 2002.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
</authors>
<title>Translation-oriented Sense Induction Based on Parallel Corpora,</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="7579" citStr="Apidianaki (2008)" startWordPosition="1169" endWordPosition="1170">nse correspondences. Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available. In the next section we will show how this information can be acquired using a data-driven sense induction method. 2 Data-driven semantic ana/ysis in a bi/ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction. A data-driven sense acquisition method based on this type of relations is presented in Apidianaki (2008). The theoretical assumptions underlying this approach are the distributional hypotheses of meaning (Harris, 1954) and of semantic similarity (Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts. Our training corpus is the English (EN)— Greek (GR) part of the lemmatized and POS-tagged INTERA corpus (Gavrilidou et al., 2004) which contains approximately four million words. The corpus has been sentence- and wordaligned at the level of tokens and types (Simard and Langlais, 2003). Two bilingual lexicons (one 78 for each translation direc</context>
<context position="10169" citStr="Apidianaki (2008)" startWordPosition="1565" endWordPosition="1566">eference to &amp;&apos;s equivalents. For instance, if &amp; is translated by $, &apos; and (, three sets of TUs are formed (where &amp; is translated by $ (&apos;&amp;D$&apos; TUs), by &apos; (&apos;&amp;D&apos;&apos; TUs), etc.). The SL context features corresponding to each equivalent (i.e. the set of lemmatized content words surrounding &amp; in the SL side of the TUs corresponding to the equivalent) are extracted and treated as a &apos;bag of words&apos;. This distributional information serves to calculate the equivalents&apos; similarity using a variation of the Weighted Jaccard coefficient (Grefenstette, 199°). The similarity calculation is described in detail in Apidianaki (2008). Each retained context feature is assigned a weight relatively to each equivalent, which &apos; The noun equivalents of nouns, the verb equivalents of verbs, etc. ° Here we focus on nouns but the method is applicable to words of other POS categories. s A translation unit contains up to 2 sentences of each language linked by an alignment. serves to define its relevance for the estimation of the equivalents&apos; similarity. The equivalents are compared in a pairwise manner and a similarity score is assigned to each pair. Two equivalents are considered as semantically related if the instances of &amp; they t</context>
</contexts>
<marker>Apidianaki, 2008</marker>
<rawString>Marianna Apidianaki. 2008. Translation-oriented Sense Induction Based on Parallel Corpora, In Proceedings of the 6th Conference on Language Resources and Evaluation (LREC), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<date>2008</date>
<journal>Inter-coder Agreement for Computational Linguistics, Computational Linguistics</journal>
<volume>34</volume>
<issue>4</issue>
<pages>555--596</pages>
<contexts>
<context position="27461" citStr="Artstein and Poesio, 2008" startWordPosition="4304" endWordPosition="4307">s related to the reference, by taking into account the strength of their relation. These predictions could be considered as almost correct and they could be, at the same time, penalized less than translations having a different sense and less rewarded than exact correspondences to the reference. For this to be done, a measure capable of capturing the semantic distance would be needed. Using a weighted coefficient is essential in tasks implicating semantics, not only in WSD (Resnik and Yarowsky, 2000) but also in tasks such as the estimation of inter-annotator agreement in semantic annotation (Artstein and Poesio, 2008). The common element between these tasks is that the distances between the categories (word senses) should be weighted, so that the WSD errors or the divergences between annotators be treated differently. We envisaged the possibility of weighting differently the proposed translations on the basis of their relation to the reference, by using as distance measure their similarity score in the TL. A semantically pertinent translation different from the reference was assigned a score equal to the similarity score of the two equivalents in the TL. A problem that we encountered, and that made us fall</context>
</contexts>
<marker>Artstein, Poesio, 2008</marker>
<rawString>Ron Artstein and Massimo Poesio. 2008. Inter-coder Agreement for Computational Linguistics, Computational Linguistics 34(4): 555-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Summarization, 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="29626" citStr="Banerjee and Lavie, 2005" startWordPosition="4637" endWordPosition="4640"> the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores. Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics. 5.3 Semantic simi/arity in existing MT eva/uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations (Papineni et al., 2002). Finding many references for evaluation is, however, rather problematic (Callison-Burch, 2006). In METEOR (Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet (Miller et al., 1990). More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset. One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call &amp;quot;a poor-man&apos;s synonymy detection algorithm&amp;quot;. Consequently, the WN-Synonymy module used maps two unigrams together simply if at least one sense o</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Summarization, 43rd Annual Meeting of the Association for Computational Linguistics (ACL), Ann Arbor, Michigan, 65-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Wordsense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>264--270</pages>
<location>Berkeley, California,</location>
<contexts>
<context position="1796" citStr="Brown et al. (1991)" startWordPosition="262" endWordPosition="265">ngua/ sense determination for WSD Determining the senses of ambiguous words by reference to their translational equivalents constitutes a common practice in multilingual WSD: the candidate senses of an ambiguous word, from which one has to be selected during WSD, correspond to its equivalents in another language. This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al. (1991), who represented the two main senses of a SL word by its two most frequent translations in the target language (TL). Further promoted by Resnik and Yarowsky (2000) and endorsed in the multilingual tasks of the Senseval (Chklovski et al., 2004) and Semeval (Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) syst</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1991</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra and Robert L. Mercer. 1991. Wordsense disambiguation using statistical methods. In 29th Annual Meeting of the Association for Computational Linguistics (ACL), Berkeley, California, 264-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clara Cabezas</author>
<author>Philip Resnik</author>
</authors>
<title>Using WSD Techniques for Lexical Selection in Statistical Machine Translation.</title>
<date>2005</date>
<tech>Technical Report CS-TR4736iLAMP-TR-124iUMIACS-TR-2005-42.</tech>
<contexts>
<context position="2726" citStr="Cabezas and Resnik, 2005" startWordPosition="415" endWordPosition="418">senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus (Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007). Nevertheless, the theoretical soundness of these senses is not really addressed. 1.2 Advantages of cross-/ingua/ sense determination Cross-lingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving W</context>
<context position="6625" citStr="Cabezas and Resnik, 2005" startWordPosition="1016" endWordPosition="1019">tly considered as a false choice. A differing weighting of WSD errors would be preferable in these cases, if sense distance information was available (Resnik and Yarowsky, 2000). When WSD coincides with lexical selection in MT, the equivalents of a SL word (w) are perceived to be its candidate senses. The sense assigned to a new instance of w is considered to be correct if it corresponds to the reference translation (i.e. the translation of that instance in the test corpus). This strict requirement of exact correspondence constitutes one of the main critics addressed to MT evaluation metrics (Cabezas and Resnik, 2005; Callison-Burch, 2006; Chan et al., 2007) and is one of the main reasons that methods have been developed which go beyond pure string matching (Owczarzak et al., 2007). A central issue in MT evaluation is the high correlation of the metrics with human judgements of translation quality, which puts the accent on the identification of sense correspondences. Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available. In the next section we will show how this information can be acquired using a dat</context>
</contexts>
<marker>Cabezas, Resnik, 2005</marker>
<rawString>Clara Cabezas and Philip Resnik. 2005. Using WSD Techniques for Lexical Selection in Statistical Machine Translation. Technical Report CS-TR4736iLAMP-TR-124iUMIACS-TR-2005-42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>Philipp Koehn</author>
</authors>
<title>Re-evaluating the Role of BLEU in Machine Translation Research.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>249--256</pages>
<location>Trento, Italy,</location>
<marker>Callison-Burch, Osborne, Koehn, 2006</marker>
<rawString>Chris Callison-Burch, Miles Osborne and Philipp Koehn. 2006. Re-evaluating the Role of BLEU in Machine Translation Research. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), Trento, Italy, 249-256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Word Sense Disambiguation vs. Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<pages>387--394</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2225" citStr="Carpuat and Wu (2005)" startWordPosition="337" endWordPosition="340">disadvantages for automatic WSD.1 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al. (1991), who represented the two main senses of a SL word by its two most frequent translations in the target language (TL). Further promoted by Resnik and Yarowsky (2000) and endorsed in the multilingual tasks of the Senseval (Chklovski et al., 2004) and Semeval (Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus (Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007). Nevertheless, the theoretical soundness of these senses</context>
</contexts>
<marker>Carpuat, Wu, 2005</marker>
<rawString>Marine Carpuat and Dekai Wu. 2005. Word Sense Disambiguation vs. Statistical Machine Translation. In 43rd Annual Meeting of the Association for Computational Linguistics (ACL). Ann Arbor, Michigan, 387-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving Statistical Machine Translation using Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>61--72</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2748" citStr="Carpuat and Wu, 2007" startWordPosition="419" endWordPosition="422">ecent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus (Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007). Nevertheless, the theoretical soundness of these senses is not really addressed. 1.2 Advantages of cross-/ingua/ sense determination Cross-lingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving WSD irrelevance to the </context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving Statistical Machine Translation using Word Sense Disambiguation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Prague, Czech Republic, 61-72.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>7. Word Sense Disambiguation Improves Statistical Machine Translation.</title>
<booktitle>In 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>33--40</pages>
<location>Prague, Czech Republic,</location>
<marker>Chan, Ng, Chiang, </marker>
<rawString>Yee Seng Chan, Hwee Tou Ng and David Chiang. 2 0 0 7. Word Sense Disambiguation Improves Statistical Machine Translation. In 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 33-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Rada Mihalcea</author>
<author>Ted Pedersen</author>
<author>Amruta Purandare</author>
</authors>
<date>2004</date>
<booktitle>The senseval-3 multilingual English-Hindi lexical sample task. Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>5--8</pages>
<location>Barcelona,</location>
<contexts>
<context position="2040" citStr="Chklovski et al., 2004" startWordPosition="303" endWordPosition="306">be selected during WSD, correspond to its equivalents in another language. This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al. (1991), who represented the two main senses of a SL word by its two most frequent translations in the target language (TL). Further promoted by Resnik and Yarowsky (2000) and endorsed in the multilingual tasks of the Senseval (Chklovski et al., 2004) and Semeval (Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflec</context>
<context position="20952" citStr="Chklovski et al., 2004" startWordPosition="3302" endWordPosition="3305"> WSD results. As the senses are situated at a higher level of abstraction, the correspondences with the reference are established at a more abstract level than that of exact unigram correspondences. Our results can be compared to those obtained in the multilingual lexical sample tasks of Senseval and SemEval. This comparison seems interesting although these tasks concern words of different parts of speech (nouns, verbs and adjectives). The systems participating at the multilingual English—Hindi lexical sample task of Senseval-3 are all supervised and they all perform better than the baseline (Chklovski et al., 2004). This is interpreted by the authors as an indication of the clarity of the sense distinctions performed using translations, which provide sufficient information for the training of supervised classifiers. The systems performed better on the sense-tagged part of the data, showing that sense information may be helpful for the task of targeted word translation. In the English—Chinese lexical sample task of SemEval the unsupervised systems perform 81 worse than the baseline, contrary to the supervised ones (Jin !&amp;quot; $%., 2007). 5 Capturing semantic simi/arity during trans/ation 5.1 Lexica/ se/ectio</context>
</contexts>
<marker>Chklovski, Mihalcea, Pedersen, Purandare, 2004</marker>
<rawString>Timothy Chklovski, Rada Mihalcea, Ted Pedersen and Amruta Purandare. 2004. The senseval-3 multilingual English-Hindi lexical sample task. Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain, 5-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Edmonds</author>
<author>Adam Kilgarriff</author>
</authors>
<title>Introduction to the special issue on evaluating word sense disambiguation systems.</title>
<date>2002</date>
<journal>Natural Language Engineering</journal>
<volume>8</volume>
<issue>4</issue>
<pages>279--291</pages>
<contexts>
<context position="3409" citStr="Edmonds and Kilgarriff, 2002" startWordPosition="513" endWordPosition="516">ss, the theoretical soundness of these senses is not really addressed. 1.2 Advantages of cross-/ingua/ sense determination Cross-lingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving WSD irrelevance to the domains of the processed texts (Edmonds and Kilgarriff, 2002). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 77 as lexical selection thus seems natural (Vickrey et al., 2005): it appears that there is no reason to pass through senses in order to arrive to translations. A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous (Resnik and Yarowsky, 2000).2 1.3 Disadvantages of cross-/ingua/ sense determination However, this conception of sense</context>
</contexts>
<marker>Edmonds, Kilgarriff, 2002</marker>
<rawString>Philip Edmonds and Adam Kilgarriff. 2002. Introduction to the special issue on evaluating word sense disambiguation systems. Natural Language Engineering 8(4): 279-291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchs Catherine</author>
</authors>
<date>1994</date>
<booktitle>Paraphrase et 6nonciation. Editions Ophrys,</booktitle>
<location>Paris.</location>
<marker>Catherine, 1994</marker>
<rawString>Catherine, Fuchs. 1994. Paraphrase et 6nonciation. Editions Ophrys, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Gavrilidou</author>
</authors>
<title>Peny Labropoulou, Elina Desipri, Voula Giouli, Vasilis Antonopoulos and Stelios Piperidis.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Multilingual Linguistic Resources, 20th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>90--93</pages>
<location>Geneva,</location>
<marker>Gavrilidou, 2004</marker>
<rawString>Maria Gavrilidou, Peny Labropoulou, Elina Desipri, Voula Giouli, Vasilis Antonopoulos and Stelios Piperidis. 2004. Building parallel corpora for eContent professionals. In Proceedings of the Workshop on Multilingual Linguistic Resources, 20th International Conference on Computational Linguistics (COLING), Geneva, Switzerland, 90-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Explorations in Automatic Thesaurus Discovery.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers, BostoniDordrechtiLondon.</publisher>
<marker>Grefenstette, 1994</marker>
<rawString>Gregory Grefenstette. 1994. Explorations in Automatic Thesaurus Discovery. Kluwer Academic Publishers, BostoniDordrechtiLondon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<journal>Distributional Structure. Word,</journal>
<volume>10</volume>
<pages>146--162</pages>
<contexts>
<context position="7693" citStr="Harris, 1954" startWordPosition="1183" endWordPosition="1184">lative to the semantics of the equivalents should be available. In the next section we will show how this information can be acquired using a data-driven sense induction method. 2 Data-driven semantic ana/ysis in a bi/ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction. A data-driven sense acquisition method based on this type of relations is presented in Apidianaki (2008). The theoretical assumptions underlying this approach are the distributional hypotheses of meaning (Harris, 1954) and of semantic similarity (Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts. Our training corpus is the English (EN)— Greek (GR) part of the lemmatized and POS-tagged INTERA corpus (Gavrilidou et al., 2004) which contains approximately four million words. The corpus has been sentence- and wordaligned at the level of tokens and types (Simard and Langlais, 2003). Two bilingual lexicons (one 78 for each translation direction: EN—GRiGR—EN are built from the alignment of word types. In these lexicons, each SL word (&amp;) is associated wi</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional Structure. Word, 10: 146-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Jin</author>
<author>Yunfang Wu</author>
<author>Shiwen Yu</author>
</authors>
<title>SemEval-2007 Task S: Multilingual ChineseEnglish Lexical Sample,</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2071" citStr="Jin et al., 2007" startWordPosition="309" endWordPosition="312"> its equivalents in another language. This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al. (1991), who represented the two main senses of a SL word by its two most frequent translations in the target language (TL). Further promoted by Resnik and Yarowsky (2000) and endorsed in the multilingual tasks of the Senseval (Chklovski et al., 2004) and Semeval (Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT. From these works, only that of Carpuat and Wu (2005) exploits an external hand-crafted sense inventory. The use of an external resource, not related to the training corpus of their Statistical Machine Translation (SMT) system, turned out to be one of the causes of the observed deterioration of translation quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found </context>
<context position="16769" citStr="Jin et al., 2007" startWordPosition="2625" endWordPosition="2628"> eva/uation 4.1 The notion of enriched precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited at this stage.9 The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL (Koehn, 2005). The TUs containing the ambiguous nouns are extracted from the corpus. Lacking a goldstandard for evaluation, we exploit information relative to translations. In the multilingual tasks of Senseval and Semeval (Ckhlovski et al., 2004; Jin et al., 2007), the translations of the words in the parallel test corpus are considered as their sense tags. Here, we consider that the equivalent translating an ambiguous SL word in context (called reference translation) points to a sense described by a cluster. Consequently, what is being evaluated is the capacity of the WSD 9 Some of the equivalents of w found in the training corpus and contained in the clusters may not be used in the test corpus. The evaluation concerns only those that are found in the test corpus. 80 method to predict this sense. The sense proposed for an instance of an ambiguous word</context>
</contexts>
<marker>Jin, Wu, Yu, 2007</marker>
<rawString>Peng Jin, Yunfang Wu and Shiwen Yu. 2007. SemEval-2007 Task S: Multilingual ChineseEnglish Lexical Sample, In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval 2007), Prague, Czech Republic, 19-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand,</location>
<contexts>
<context position="16517" citStr="Koehn, 2005" startWordPosition="2588" endWordPosition="2589">n this way, as the sets of assimilative contexts would contain more features than their intersection, and so it would become more probable to find CFs with the new contexts and to establish &apos;context-cluster&apos; associations. 4 Semantics-sensitive WSD eva/uation 4.1 The notion of enriched precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited at this stage.9 The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL (Koehn, 2005). The TUs containing the ambiguous nouns are extracted from the corpus. Lacking a goldstandard for evaluation, we exploit information relative to translations. In the multilingual tasks of Senseval and Semeval (Ckhlovski et al., 2004; Jin et al., 2007), the translations of the words in the parallel test corpus are considered as their sense tags. Here, we consider that the equivalent translating an ambiguous SL word in context (called reference translation) points to a sense described by a cluster. Consequently, what is being evaluated is the capacity of the WSD 9 Some of the equivalents of w f</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of MT Summit X, Phuket, Thailand, 79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>228--231</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="30525" citStr="Lavie and Agarwal (2007)" startWordPosition="4781" endWordPosition="4784"> to it, i.e. found in the same synset. One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call &amp;quot;a poor-man&apos;s synonymy detection algorithm&amp;quot;. Consequently, the WN-Synonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset. Another problem is that the metric is strongly dependent on a predefined sense inventory. Given that such resources are publicly available for very few languages, the synonymy module often is not operational and is omitted. 83 Lavie and Agarwal (2007) envisage the possibility of developing new synonymy modules for languages other than English, which would be based on alternative methods and could replace WordNet. In the previous sections, we showed how the information acquired by an unsupervised sense induction method can help to account for the words&apos; semantic similarity. The created sense clusters, grouping semantically similar equivalents, can be compared to WordNet synsets. This kind of semantic information, extracted directly from text data, can constitute an alternative to the use of predefined sense inventories. A clear advantage of</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments. In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics (ACL), Prague, Czech Republic, 228-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Groos</author>
<author>Katherine Miller</author>
</authors>
<title>Introduction to WordNet: An On-line Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography</journal>
<volume>3</volume>
<issue>4</issue>
<pages>235--312</pages>
<contexts>
<context position="29699" citStr="Miller et al., 1990" startWordPosition="4648" endWordPosition="4651">the equivalents similar to the reference and their scores. Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics. 5.3 Semantic simi/arity in existing MT eva/uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations (Papineni et al., 2002). Finding many references for evaluation is, however, rather problematic (Callison-Burch, 2006). In METEOR (Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet (Miller et al., 1990). More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset. One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call &amp;quot;a poor-man&apos;s synonymy detection algorithm&amp;quot;. Consequently, the WN-Synonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset. Another problem is that t</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Groos, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Groos and Katherine Miller. 1990. Introduction to WordNet: An On-line Lexical Database. International Journal of Lexicography 3(4): 235-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Walter G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<journal>Language and Cognitive Processes</journal>
<volume>6</volume>
<issue>1</issue>
<pages>1--28</pages>
<marker>Miller, Charles, 1991</marker>
<rawString>George A. Miller and Walter G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes 6(1): 1-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karolina Owczarzak</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Labelled Dependencies in Machine Translation Evaluation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>104--111</pages>
<location>Prague, Czech Republic,</location>
<marker>Owczarzak, van Genabith, Way, 2007</marker>
<rawString>Karolina Owczarzak, Josef van Genabith and Andy Way. 2007. Labelled Dependencies in Machine Translation Evaluation. In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics (ACL), Prague, Czech Republic, 104-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.,</location>
<contexts>
<context position="29493" citStr="Papineni et al., 2002" startWordPosition="4620" endWordPosition="4623">the similarity score between a proposed translation and the reference but also the number of the SL word&apos;s candidate translations, the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores. Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics. 5.3 Semantic simi/arity in existing MT eva/uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations (Papineni et al., 2002). Finding many references for evaluation is, however, rather problematic (Callison-Burch, 2006). In METEOR (Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet (Miller et al., 1990). More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset. One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call &amp;quot;a poor-man</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA., 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Exploiting Hidden Meanings: Using Bilingual Text for Monolingual Annotation.</title>
<date>2004</date>
<booktitle>Lecture Notes in Computer Science 2945: Computational Linguistics and Intelligent Text Processing: Proceedings of the 5th International Conference CICLing, Seoul, Korea,</booktitle>
<pages>283--299</pages>
<editor>In Gelbukh, A. (ed.),</editor>
<contexts>
<context position="3091" citStr="Resnik, 2004" startWordPosition="467" endWordPosition="468">n quality. In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus (Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007). Nevertheless, the theoretical soundness of these senses is not really addressed. 1.2 Advantages of cross-/ingua/ sense determination Cross-lingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving WSD irrelevance to the domains of the processed texts (Edmonds and Kilgarriff, 2002). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 77 as lexical selection thus seems natural (Vickrey et al., 2005): it appears that there is no reason to p</context>
</contexts>
<marker>Resnik, 2004</marker>
<rawString>Philip Resnik. 2004. Exploiting Hidden Meanings: Using Bilingual Text for Monolingual Annotation. In Gelbukh, A. (ed.), Lecture Notes in Computer Science 2945: Computational Linguistics and Intelligent Text Processing: Proceedings of the 5th International Conference CICLing, Seoul, Korea, 283-299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsk</author>
</authors>
<title>Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation,</title>
<date>2000</date>
<journal>Natural Language Engineering</journal>
<volume>5</volume>
<issue>3</issue>
<pages>113--133</pages>
<marker>Resnik, Yarowsk, 2000</marker>
<rawString>Philip Resnik and David Yarowsk. 2000. Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation, Natural Language Engineering 5(3): 113-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester,</location>
<contexts>
<context position="25950" citStr="Schmid, 1994" startWordPosition="4078" endWordPosition="4079">reference, in cases of no exact correspondence. Thus, a translation which is semantically similar to the reference is considered to be correct if they are both found in the cluster proposed during WSD. This renders the evaluation more flexible and significantly increases the quantity of semantically pertinent translations compared to the baseline. The strict and enrichedKDscores are estimated by considering as correct (score = 1) every translation that is pertinent according to the corresponding evaluation principles. The 10 Our test corpus has been tagged and lemmatized using the TreeTagger (Schmid, 1994). 11 The SL contextual information exploited for WSD. 82 results indicate the increase in pertinent translations. base/ine 52.14% strict -f-score 48.37% enriched f-score 77.79% We observe that the strict f-score is lower than the baseline. This happens because our method proposes equivalents semantically similar to the reference for some instances for which the baseline predictions are correct. However, these pertinent predictions are not taken into account by the principle of strict precision. This is the case in example (b): the baseline prediction (e7chacouq) for this instance o f implicati</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proceedings of the International Conference on New Methods in Language Processing, Manchester, 44-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vickrey</author>
<author>Luke Biewald</author>
<author>Marc Teyssier</author>
<author>Daphne Koller</author>
</authors>
<title>Word-Sense Disambiguation for Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Joint Conference on Human Language Technology i Empirical Methods in Natural Language Processing (HLT-EMNLP),</booktitle>
<pages>771--778</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="3650" citStr="Vickrey et al., 2005" startWordPosition="551" endWordPosition="554">ds are supposed to reveal their hidden meanings (Resnik, 2004). Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation. Conceiving WSD irrelevance to the domains of the processed texts (Edmonds and Kilgarriff, 2002). Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 77 as lexical selection thus seems natural (Vickrey et al., 2005): it appears that there is no reason to pass through senses in order to arrive to translations. A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous (Resnik and Yarowsky, 2000).2 1.3 Disadvantages of cross-/ingua/ sense determination However, this conception of senses is not theoretically sound, as translation equivalents do not always constitute valid sense indicators. This is often neglected in an attempt to render the sense inventory as close as possible to the training corpus of the SMT system. So, </context>
</contexts>
<marker>Vickrey, Biewald, Teyssier, Koller, 2005</marker>
<rawString>David Vickrey, Luke Biewald, Marc Teyssier and Daphne Koller. 2005. Word-Sense Disambiguation for Machine Translation. In Proceedings of the Joint Conference on Human Language Technology i Empirical Methods in Natural Language Processing (HLT-EMNLP), Vancouver, Canada, 771-778.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>