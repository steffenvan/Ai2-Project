<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001598">
<title confidence="0.979391">
Toward Plot Units: Automatic Affect State Analysis
</title>
<author confidence="0.987009">
Amit Goyal and Ellen Riloff and Hal Daume III and Nathan Gilbert
</author>
<affiliation confidence="0.864852666666667">
School of Computing
University of Utah
Salt Lake City, UT 84112
</affiliation>
<email confidence="0.999515">
{amitg,riloff,hal,ngilbert}@cs.utah.edu
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845933333333">
We present a system called AESOP that au-
tomatically produces affect states associated
with characters in a story. This research repre-
sents a first step toward the automatic genera-
tion of plot unit structures from text. AESOP
incorporates several existing sentiment analy-
sis tools and lexicons to evaluate the effective-
ness of current sentiment technology on this
task. AESOP also includes two novel compo-
nents: a method for acquiring patient polar-
ity verbs, which impart negative affect on their
patients, and affect projection rules to propa-
gate affect tags from surrounding words onto
the characters in the story. We evaluate AE-
SOP on a small collection of fables.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991351229166667">
In the 1980s, plot units (Lehnert, 1981) were pro-
posed as a knowledge structure for representing nar-
rative stories and generating summaries. Plot units
are fundamentally different from the story represen-
tations that preceded them because they focus on the
emotional states and tensions between characters as
the driving force behind interesting plots and cohe-
sive stories. Plot units were used in narrative sum-
marization studies, both in computer science and
psychology (Lehnert et al., 1981), but the compu-
tational models of plot units relied on tremendous
amounts of manual knowledge engineering.
Given the recent swell of activity in automated
methods for sentiment analysis, we embarked on a
project to see whether current techniques could auto-
matically detect the affect states needed for plot unit
17
analysis. Plot units are complex structures that in-
clude affect states, causal links, and cross-character
links, and generating complete plot unit structures is
beyond the scope of this work. As an initial step to-
ward the long-term goal of automatically generating
plot units, we began by creating a system to automat-
ically identify the affect states associated with char-
acters. An affect state represents the emotional state
of a character, based on their perspective of events
in the story. Plots units include three types of af-
fect states: positive (+) states, negative (-) states, and
mental (M) states that have neutral emotion (these
are often associated with plans and goals).
Our system, called AESOP, pulls together a va-
riety of existing technologies in sentiment analy-
sis to automatically identify words and phrases that
have positive/negative polarity or that correspond
to speech acts (for mental states). However, we
needed to develop a method to automatically map
these affect tags onto characters in the story.1 To
address this issue, we created affect projection rules
that propagate affect tags from words and phrases to
characters in the story via syntactic relations.
During the course of our research, we came to ap-
preciate that affect states, of the type required for
plot units, can represent much more than just di-
rect expressions of emotion. A common phenom-
ena are affect states that result from a character be-
ing acted upon in a positive or negative way. For
example, “the cat ate the mouse” produces a pos-
itive affect state for the cat and a negative affect
</bodyText>
<footnote confidence="0.872421333333333">
1This is somewhat analogous to, but not exactly the same as,
associating opinion words with their targets or topics (Kim and
Hovy, 2006; Stoyanov and Cardie, 2008).
</footnote>
<note confidence="0.979656666666667">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 17–25,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
The Father and His Sons
</note>
<bodyText confidence="0.945138705882353">
(s1) A father had a family of sons who were perpetually
quarreling among themselves. (s2) When he failed to
heal their disputes by his exhortations, he determined to
give them a practical illustration of the evils of disunion;
and for this purpose he one day told them to bring him a
bundle of sticks. (s3) When they had done so, he placed
the faggot into the hands of each of them in succession,
and ordered them to break it in pieces. (s4) They tried
with all their strength, and were not able to do it. (s5) He
next opened the faggot, took the sticks separately, one by
one, and again put them into his sons’ hands, upon which
they broke them easily. (s6) He then addressed them in
these words: “My sons, if you are of one mind, and unite
to assist each other, you will be as this faggot, uninjured
by all the attempts of your enemies; but ifyou are divided
among yourselves, you will be broken as easily as these
sticks.”
</bodyText>
<figure confidence="0.9964484375">
(a) “Father and Sons” Fable
Father Sons
s1
(quarreling)a1
s2
s2
(stop quarreling)a3
(lesson succeeds).15
s5
(b) Plot Unit Analysis for “Father and Sons” Fable
M
(exhortations)a4
s2
(exhortations fail)a5
s2
s2
s2
(teach lesson)as
(get sticks &amp; break)a7
request
M
a
a
a
s4
shared
(cannot break sticks)a10
a
s5 (break sticks).14
s5
(bundle &amp; break)a11 request
shared
a
s
s5
(bundle &amp; break)a12
5
(break sticks)a13
M
M
a
M
(get sticks &amp; break)a�
s2
(cannot break sticks)a9
s4
(annoyed)a2
shared
</figure>
<bodyText confidence="0.99997485">
state for the mouse because obtaining food is good
but being eaten is bad. This type of world knowl-
edge is difficult to obtain, yet essential for plot unit
analysis. In AESOP, we use corpus statistics to au-
tomatically learn a set of negative patient polarity
verbs which impart a negative polarity on their pa-
tient (e.g., eaten, killed, injured, fired). To acquire
these verbs, we queried a large corpus with patterns
to identify verbs that frequently occur with agents
who stereotypically have evil intent.
We evaulate our complete system on a set of AE-
SOP’s fables. In this paper, we also explain and cat-
egorize different types of situations that can produce
affect states, several of which cannot be automati-
cally recognized by existing sentiment analysis tech-
nology. We hope that one contribution of our work
will be to create a better awareness of, and apprecia-
tion for, the different types of language understand-
ing mechanisms that will ultimately be necessary for
comprehensive affect state analysis.
</bodyText>
<sectionHeader confidence="0.780843" genericHeader="method">
2 Overview of Plot Units
</sectionHeader>
<bodyText confidence="0.999391380952381">
Narratives can often be understood in terms of the
emotional reactions and affect states of the char-
acters therein. The plot unit formalism (Lehnert,
1981) provides a representational mechanism for af-
fect states and the relationships between them. Plot
unit structures can be used for tasks such as narrative
summarization and question answering.
Plot unit structures consist of affect states for each
character in a narrative, and links explaining the re-
lationships between these affect states. The affect
states themselves each have a type: (+) for positive
states, (-) for negative states, and (M) for mental
states (with neutral affect). Although affect states
are not events per se, events often trigger affect
states. If an event affects multiple characters, it can
trigger multiple affect states, one for each character.
Affect states are further connected by causal links,
which explain how the narrative hangs together.
These include motivations (m), actualizations (a),
terminations (t) and equivalences (e). Causal links
exist between affect states for the same character.
Cross-character links explain how single events af-
fect two characters. For instance, if one character
requests something of the other, this is an M-to-M
link, since it spans a shared mental affect for both
characters. Other speech acts can be represented as
M to + (promise) or M to - (threat).
To get a better feeling of the plot unit represen-
tation, a short fable, “The Father and His Sons,” is
shown in Figure 1(a) and our annotation of its plot
unit structure is shown in Figure 1(b). In this fa-
ble, there are two characters (the “Father” and the
“Sons”) who go through a series of affect states, de-
picted chronologically in the two columns.
In this example, the first affect state is a negative
state for the sons, who are quarreling (a1). This state
is shared by the father (via a cross-character link)
who has a negative annoyance state (a2). The fa-
ther then decides that he wants to stop the sons from
quarreling, which is a mental event (a3). The causal
link from a2 to a3 with an m label indicates a “mo-
tivation.” His first attempt is by exhortations (a4).
</bodyText>
<page confidence="0.954927">
18
</page>
<bodyText confidence="0.999210880434783">
This produces an M (a3) linked to an M (a4) with tions that can produce an affect state, based on our
a m (motivation) link, which represents subgoaling. observations in working with fables. Most likely, an
The father’s overall goal is to stop the quarreling even wider variety of situations could produce affect
(a3) and in order to do so, he creates a subgoal of states in other text genres.
exhorting the sons to stop (a4). The exhortations 3.1 Direct Expressions of Emotion
fail, which produces a negative state (a5) for the fa- Plot units can include affect states that correspond to
ther. The a causal link indicates an “actualization”, explicit expressions of positive/negative emotional
representing the failure of the plan (a4). states, as has been studied in the realm of sentiment
The failure of the father’s exhortations leads to a analysis. For example, “Max was disappointed”
new subgoal: to teach the sons a lesson (a�). The m produces a negative affect state for Max, and “Max
link from a5 to a� is an example of “enablement.” was pleased” produces a positive affect state for
At a high level, this subgoal has two parts, indicated Max. However, the affect must relate to an event that
by the two gray regions (a7 − a10 and a11 − a14). occurs in the story’s plot. For example, a hypotheti-
The first gray region begins with a cross-character cal expression of emotion would not yield an affect
link (M to M), which indicates a request (in this case, state (e.g., “if the rain stops, she will be pleased”).
to break a bundle of sticks). The sons fail at this, 3.2 Situational Affect States
which upsets them (a9) but pleases the father (a10). Positive and negative affect states also frequently
The second gray region depicts the second part of represent good and bad situational states that char-
the father’s subgoal; he makes a second request (a11 acters find themselves in. These states do not rep-
to a12) to separate the bundle and break the sticks, resent emotion, but indicate whether a situation is
which the sons successfully do, making them happy good or bad for a character based on world knowl-
(a13) and the father happy (a14). This latter struc- edge. For example, “Wolf, who had a bone stuck
ture (the second gray region) is an HONORED RE- in his throat, ...” produces a negative affect state
QUEST plot unit. At the end, the father’s plan suc- for the wolf. Similarly, “The Old Woman recovered
ceeds (a15) which is an actualization (a link) of his her sight...” produces a positive affect state. Senti-
goal to teach the sons a lesson (a�). ment analysis is not sufficient to generate these af-
In this example, as well as the others that we an- fect states. Sometimes, however, a direct expression
notated in our gold standard, (see Section 5.1), we of emotion will also be present (e.g., “Wolf was un-
annotated conservatively. In particular, in reading happy because he had a bone stuck...”), providing
the story, we may assume that the father’s origi- redundancy and multiple opportunities to recognize
nal plan of stopping the son’s quarrelling also suc- the correct affect state for a character.
ceeded. However, this is not mentioned in the story Situational affect states are common and often
and therefore we chose not to represent it. It is also motivate plans and goals that are central to the plot.
important to note that plot unit representations can 3.3 Plans and Goals
have t (termination) and e (equivalence) links that Plans and goals are another common reason for
point backwards in time, but they do not occur in affect states. The existence of a plan or goal is
the Father and Sons fable. usually represented as a mental state (M). Plans and
3 Where Do Affect States Come From? goals can be difficult to detect automatically. A
We began this research with the hope that recent re- story may reveal that a character has a plan or goal
search in sentiment analysis would supply us with in a variety of ways, such as:
effective tools to recognize affect states. However, Direct expressions of plans/goals: a plan or goal
we soon realized that affect states, as required for may be explicitly stated (e.g., “the lion wanted to
plot unit analysis, go well beyond the notions of pos- find food”). In this case, a mental state (M) should
itive/negative polarity and private states that have
been studied in recent sentiment analysis work. In
this section, we explain the wide variety of situa-
19
be generated.
Speech acts: a plan or goal may be revealed
through a speech act between characters. For
example, “the wolf asked an eagle to extract the
bone” is a directive speech act that indicates the
wolf’s plan to resolve its negative state (having a
bone stuck). This example illustrates how a negative
state (bone stuck) can motivate a mental state (plan).
When a speech act involves multiple characters, it
produces multiple mental states. For example, a
mental state should also be produced for the eagle,
because it now has a plan to help the wolf (by virtue
of being asked).
Inferred plans/goals: plans and goals sometimes
must be inferred from actions. For example, “the
lion hunted deer” reveals the lion’s plan to obtain
food. Similarly, the serpent spat poison into the
man’s water” implies that the serpent had a plan to
kill the man.
Plans and goals also produce positive/negative af-
fect states when they succeed/fail. For example, if
the eagle successfully extracts the bone from the
wolf’s throat, then both the wolf and the eagle will
have positive affect states, because both were suc-
cessful in their respective goals. A directive speech
act between two characters coupled with positive af-
fect states for both characters is a common plot unit
structure called an HONORED REQUEST, depicted
by the second gray block shown in Fig.1(b).
The affect state for a character is always with
respect to its view of the situation. For example,
consider: “The owl besought a grasshopper to
stop chirping. The grasshopper refused to desist,
and chirped louder and louder.” Both the owl and
the grasshopper have M affect states representing
the request from the owl to the grasshopper (i.e.,
the owl’s plan to stop the chirping is to ask the
grasshopper to knock it off). The grasshopper
refuses the request, so a negative affect state is
produced for the owl, indicating that its plan failed.
However, a positive affect state is produced for
the grasshopper, because its goal was to continue
chirping which was accomplished by refusing the
request. This scenario is also a common plot unit
structure called a DENIED REQUEST.
</bodyText>
<subsectionHeader confidence="0.992231">
3.4 Patient Role Affect States
</subsectionHeader>
<bodyText confidence="0.997934285714286">
Many affect states come directly from events. In
particular, when a character is acted upon (the theme
or patient of an event), a positive or negative affect
state often results for the character. These affect
states reflect world knowledge about what situations
are good and bad. For example:
Negative patient roles: killed X, ate X, chased X,
captured X, fired X, tortured X
Positive patient roles: rescued X, fed X, adopted X,
housed X, protected X, rewarded X
For example, “a man captured a bear” indicates a
negative state for the bear. Overall, this sentence
would generate a SUCCESS plot unit consisting of
an M state and a + state for the man (with an actual-
ization a causal link between them representing the
plan’s success) and a - state for the bear (as a cross-
character link indicating that what was good for the
man was bad for the bear). A tremendous amount of
world knowledge is needed to generate these states
from such a seemingly simple sentence. Similarly,
if a character is rescued, fed, or adopted, then a + af-
fect state should be produced for the character based
on knowledge that these events are desirable. We
are not aware of existing resources that can automat-
ically identify affect polarity with respect to event
roles. In Section 4.1.2, we explain how we automat-
ically acquire Patient Polarity Verbs from a corpus
to identify some of these affect states.
</bodyText>
<sectionHeader confidence="0.994266" genericHeader="method">
4 AESOP: Automatic Affect State Analysis
</sectionHeader>
<bodyText confidence="0.999721692307692">
We created a system, called AESOP, to try to auto-
matically identify the types of affect states that are
required for plot unit analysis. AESOP incorporates
existing resources for sentiment analysis and speech
act recognition, and includes two novel components:
patient polarity verbs, which we automatically gen-
erate using corpus statistics, and affect projection
rules, which automatically project and infer affect
labels via syntactic relations.
AESOP produces affect states in a 3-step process.
First, AESOP labels individual words and phrases
with an M, +, or - affect tag. Second, it identi-
fies all references to the two main characters of the
</bodyText>
<page confidence="0.772828">
20
</page>
<footnote confidence="0.999869">
2http://www.cs.pitt.edu/mpqa/opinionfinderrelease/
3http://www.cs.pitt.edu/mpqa/lexiconrelease/collectinfo1.html
4http://www.lr.pi.titech.ac.jp/—takamura/pndic en.html
5http://openlibrary.org/b/OL2413134M/English speech act verbs
</footnote>
<bodyText confidence="0.987028666666667">
story. Third, AESOP applies affect projection rules
to propagate affect states onto the characters, and in
some cases, to infer new affect states.
</bodyText>
<subsectionHeader confidence="0.990914">
4.1 Step 1: Assigning Affect Tags to Words
4.1.1 Sentiment Analysis Resources
</subsectionHeader>
<bodyText confidence="0.997849666666667">
AESOP incorporates several existing sentiment
analysis resources to recognize affect states associ-
ated with emotions and speech acts.
</bodyText>
<listItem confidence="0.996486470588235">
• OpinionFinder2 (Wilson et al., 2005) (Version
1.4) is used to identify all three types of states. We
use the +/- labels assigned by its contextual polar-
ity classifier (Wilson, 2005) to create +/- affect tags.
The MPQASD tags produced by its Direct Subjective
and Speech Event Identifier (Choi et al., 2006) are
used as M affect tags.
• Subjectivity Lexicon3 (Wilson, 2005): The pos-
itive/negative words in this list are assigned +/- af-
fect tags, when they occur with the designated part-
of-speech (POS).
• Semantic Orientation Lexicon4 (Takamura et
al., 2005): The positive/negative words in this list
are assigned +/- affect tags, when they occur with
the designated part-of-speech.
• A list of 228 speech act verbs compiled from
(Wierzbicka, 1987)5, which are used for M states.
</listItem>
<subsubsectionHeader confidence="0.710346">
4.1.2 Patient Polarity Verbs
</subsubsectionHeader>
<bodyText confidence="0.99981178125">
As we discussed in Section 3.4, existing resources
are not sufficient to identify affect states that arise
from a character being acted upon. Sentiment lexi-
cons, for example, assign polarity to verbs irrespec-
tive of their agents or patients. To fill this gap,
we tried to automatically acquire verbs that have a
strong patient polarity (i.e., the patient will be in a
good or bad state by virtue of being acted upon).
We used corpus statistics to identify verbs that
frequently occur with agents who typically have
evil (negative) or charitable (positive) intent. First,
we identified 40 words that are stereotypically evil
agents, such as monster, villain, terrorist, and mur-
derer, and 40 words that are stereotypically charita-
ble agents, such as hero, angel, benefactor, and res-
cuer. Next, we searched the google Web 1T 5-gram
corpus6 using patterns designed to identify verbs
that co-occur with these words as agents. For each
agent term, we applied the pattern “*ed by [a,an,the]
AGENT” and extracted the list of matching verbs.7
Next, we rank the extracted verbs by computing
the ratio between the frequency of the verb with a
negative agent versus a positive agent. If this ratio
is &gt; 1, then we save the verb as a negative patient
polarity verb (i.e., it imparts negative polarity to its
patient). This process produced 408 negative patient
polarity verbs, most of which seemed clearly neg-
ative for the patient. Table 1 shows the top 20 ex-
tracted verbs. We also tried to identify positive pa-
tient polarity verbs using a positive-to-negative ra-
tio, but the extracted verbs were often neutral for the
patient, so we did not use them.
</bodyText>
<table confidence="0.6686214">
scammed damaged disrupted ripped
raided corrupted hindered crippled
slammed chased undermined possesed
dogged tainted grounded levied
patched victimized posessed bothered
</table>
<tableCaption confidence="0.999563">
Table 1: Top 20 negative patient polarity verbs
</tableCaption>
<subsectionHeader confidence="0.966537">
4.2 Step 2: Identifying the Characters
</subsectionHeader>
<bodyText confidence="0.999939947368421">
The problem of coreference resolution in fables
is somewhat different than for other genres, pri-
marily because characters are often animals (e.g.,
“he”=“owl”). So we hand-crafted a simple rule-
based coreference system. For the sake of this task,
we made two assumptions: (1) There are only two
characters per fable, and (2) Both characters are
mentioned in the fable’s title.
We then apply heuristics to determine number and
gender for the characters based on word lists, Word-
Net (Miller, 1990) and POS tags. If no determina-
tion of a character’s gender or number can be made
from these resources, a process of elimination is em-
ployed. Given the two character assumption, if one
character is known to be male, but there are female
pronouns in the fable, then the other character is as-
sumed to be female. The same is done for number
agreement. Finally, if there is only one character be-
tween a pronoun and the beginning of a document,
</bodyText>
<footnote confidence="0.999217333333333">
6http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2006T13
7The corpus is not POS tagged so there is no guarantee these
will be verbs, but they usually are in this construction.
</footnote>
<page confidence="0.998931">
21
</page>
<bodyText confidence="0.999964666666667">
the pronoun is assumed to corefer with that char-
acter. The character then assumes the gender and
number of that pronoun. Lastly, WordNet is used
to obtain a small set of non-pronominal, non-string-
match resolutions by exploiting hypernym relations,
for instance, linking Peasant with the man.
</bodyText>
<subsectionHeader confidence="0.997114">
4.3 Step 3: Affect Projection
</subsectionHeader>
<bodyText confidence="0.999608083333333">
Our goal is to produce affect states for each char-
acter in the story. Therefore every affect tag needs
to be attributed to a character, or discarded. Since
plots typically revolve around actions, we used the
verbs as the basis for projecting affect tags onto the
characters. In some cases, we also spawn new affect
tags associated with mental states to indicate that an
action is likely the manifestation of a plan.
We developed 6 types of affect projection rules
that orchestrate how affect tags are assigned to the
characters based on verb argument structure. We
use the Sundance shallow parsing toolkit (Riloff and
Phillips, 2004) to generate a syntactic analysis of
each sentence, including syntactic chunking, clause
segmentation, and active/passive voice recognition.
We normalize the verb phrases (VPs) with respect to
voice (i.e., we transform the passive voice construc-
tions into an active voice equivalent) to simplify our
rules. We then make the assumption that the Subject
of the VP is its AGENT and the Direct Object of the
VP is its PATIENT.8 The affect projection rules only
project affect states onto AGENTS and PATIENTS
that correspond to a character in the story. The five
types of rules are described below.
</bodyText>
<listItem confidence="0.992576888888889">
1. AGENT VP : This case applies when the VP
has no PATIENT, or a PATIENT that is not a char-
acter in the story, or the PATIENT corefers with
the AGENT. All affect tags associated with the VP
are projected onto the AGENT. For example, “Mary
laughed (+)” projects a positive affect state onto
Mary.
2. VP PATIENT9: All affect tags associated with
the VP are projected onto the PATIENT, unless both
</listItem>
<bodyText confidence="0.805480666666667">
M and +/- tags exist, in which case only the +/- tags
are projected. For example, “loved (+) the cat”,
projects a positive affect state onto the cat.
</bodyText>
<footnote confidence="0.998987333333333">
8We are not actually doing thematic role recognition, so this
will not always be correct, but it is a reasonable approximation.
9Agent is missing or not a character.
</footnote>
<listItem confidence="0.767745">
3. AGENT VP PATIENT: This case applies when
the AGENT and PATIENT refer to different char-
acters. All affect tags associated with the VP are
projected onto the PATIENT, unless both M and +/-
tags exist, in which case only the +/- tags are pro-
jected (as in Rule #2). If the VP has an M tag, then
we also project an M tag onto the AGENT (repre-
senting a shared, cross-character mental state). If
the VP has a +/- tag, then we project a + tag onto
the agent (as an inference that the AGENT accom-
plished some action).
4. AGENT VERB1 to VERB2 PATIENT. We di-
vide this into two cases: (a) If the agent and patient
refer to the same character, then Rule #1 is applied
(e.g., “Bo decided to teach himself...”). (b) If the
agent and patient are different, we apply Rule #1 to
VERB1 to agent and Rule #2 to VERB2. If no af-
fect tags are assigned to either verb, then we create
an M affect state for the agent (assuming that the VP
represents some sort of plan).
5. If a noun phrase refers to a character and in-
cludes a modifying adjective with an affect tag, then
the affect is mapped onto the character. For exam-
ple, “the happy (+) fox”.
</listItem>
<bodyText confidence="0.999520125">
Finally, if an adverb or adjectival phrase (e.g.,
predicate adjective) has an affect tag, then that affect
tag is mapped onto the preceding VP and the projec-
tion rules above are applied. For all of the rules, if
a clause contains a negation word, then we flip the
polarity of all words in that clause. Our negation list
contains: no, not, never, fail, failed, fails, don’t, and
didn’t.
</bodyText>
<sectionHeader confidence="0.993872" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997119">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.99955925">
Plot unit analysis of ordinary text is enormously
complex – even the idea of manually creating gold
standard annotations seemed like a monumental
task. So we began our exploration with simpler and
more constrained texts that seemed particularly ap-
propriate for plot unit analysis: fables. Fables have
two desirable attributes: (1) they have a small cast
of characters, and (2) they typically revolve around
a moral, which is exemplified by a short and concise
plot. Even so, fables are challenging for NLP due to
anthropomorphic characters, flowery language, and
sometimes archaic vocabulary.
</bodyText>
<page confidence="0.994627">
22
</page>
<table confidence="0.999339727272727">
State M (66) + (52) - (39) All (157)
System R P F R P F R P F R P F
Bsent baseline .65 .10 .17 .52 .08 .14 .74 .06 .11 .63 .08 .14
Bclause baseline .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31
All 4 resources (w/proj. rules) .48 .43 .45 .23 .39 .29 .23 .41 .29 .34 .41 .37
OpinionFinder .36 .42 .39 .00 .00 .00 .00 .00 .00 .15 .35 .21
Subjectivity Lexicon .45 .43 .44 .23 .35 .28 .21 .44 .28 .32 .41 .36
Semantic Dictionary .42 .45 .43 .00 .00 .00 .00 .00 .00 .18 .45 .26
Semantic Orientation Lexicon .41 .43 .42 .17 .53 .26 .08 .43 .13 .25 .45 .32
PPV Lexicon .41 .42 .41 .02 .17 .04 .21 .73 .33 .23 .44 .30
AESOP (All 4 + PPV) .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38
</table>
<tableCaption confidence="0.9853235">
Table 2: Evaluation results for 2 baselines, 4 sentiment analysis resources with projection rules, and our PPV lexicon
with projection rules. (The # in parentheses is the number of occurrences of that state in the gold standard).
</tableCaption>
<bodyText confidence="0.999982181818182">
We collected 34 fables from an Aesop’s Fables
web site10, choosing fables that have a true plot
(some only contain quotes) and exactly two charac-
ters. We divided them into a development set of 11
stories, a tuning set of 8 stories, and a test set of 15
stories. The Father and Sons story from Figure 1(a)
is an example from our set.
Creating a gold standard was itself a substantial
undertaking. Plot units are complex structures, and
training non-experts to produce them did not seem
feasible in the short term. So three of the authors
discussed and iteratively refined manual annotations
for the development and tuning set stories until we
became comfortable that we had a common under-
standing for the annotation task. Then to create our
gold standard test set, two authors independently
created annotations for the test set, and a third au-
thor adjudicated the differences. The gold standard
contains complete plot unit annotations, including
affect states, causal links, and cross-character links.
For the experiments in this paper, however, only the
affect state annotations were used.
</bodyText>
<subsectionHeader confidence="0.997835">
5.2 Baselines
</subsectionHeader>
<bodyText confidence="0.99996375">
We created two baselines to measure what would
happen if we use all 4 sentiment analysis resources
without any projection rules. The first one (Bsent)
operates at the sentence level. It naively projects ev-
ery affect tag that occurs in a sentence onto every
character in the same sentence. The second base-
line (Bclause) operates identically, but at the clause
level.
</bodyText>
<footnote confidence="0.687662">
10http://www.pacificnet.net/-johnr/aesop/
</footnote>
<subsectionHeader confidence="0.939131">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999929615384615">
As our evaluation metrics we used recall (R), preci-
sion (P), and F-measure (F). We evaluate each sys-
tem on individual affect states (+, - and M) as well
as across all affect states. The evaluation is done at
the sentence level. Meaning, if a system produces
the same affect state as present in the gold standard
for a sentence, we count it as a correct affect state.
Our main evaluation also requires each affect state
to be associated with the correct character.
Table 2 shows the coverage of our two baseline
systems as well as the four Sentiment Analysis
Resources used with our projection rules. We can
make several observations:
</bodyText>
<listItem confidence="0.889330333333333">
• As expected, the baselines achieve relatively high
recall, but low precision.
• Each of the sentiment analysis resources alone
is useful, and using them with the projection rules
leads to improved performance over the baselines
(10 points in F score for M and 6 points overall).
</listItem>
<bodyText confidence="0.955615692307692">
This shows that the projection rules are helpful
in identifying the characters associated with each
affect state.
• The PPV Lexicon, alone, is quite good at cap-
turing negative affect states. Together with the
projection rules, this leads to good performance on
identifying mental states as well.
To better assess our projection rules, we evaluated
the systems both with respect to characters and with-
out respect to characters. In this evaluation, system-
produced states are correct even if they are assigned
to the wrong character. Table 3 reveals several re-
sults: (1) For the baseline: there is a large drop when
</bodyText>
<page confidence="0.995928">
23
</page>
<table confidence="0.998629666666667">
State M (66) + (52) - (39) All (157)
System R P F R P F R P F R P F
Bclause w/o char .65 .37 .47 .50 .25 .33 .77 .19 .30 .63 .26 .37
AESOP w/o char .55 .44 .49 .33 .47 .39 .36 .50 .42 .43 .46 .44
Bclause w/ char .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31
AESOP w/ char .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38
</table>
<tableCaption confidence="0.997707">
Table 3: Evaluating affect states with and without respect to character.
</tableCaption>
<table confidence="0.999588833333333">
State M (66) + (52) - (39) All (157)
System R P F R P F R P F R P F
Bclause PCoref .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31
AESOP PCoref .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38
Bclause ACoref .42 .45 .43 .25 .34 .29 .54 .24 .33 .39 .33 .36
AESOP ACoref .41 .54 .47 .12 .40 .18 .26 .45 .33 .27 .49 .35
</table>
<tableCaption confidence="0.999284">
Table 4: Final results of Bclause and AESOP systems with perfect and automated coreference
</tableCaption>
<bodyText confidence="0.999909725">
evaluated with respect to the correct character. (2)
For AESOP: there is a smaller drop in both preci-
sion and recall for M and -, suggesting that our pro-
jection rules are doing well for these affect states.
(3) For AESOP: there is a large drop in both preci-
sion and recall for +, suggesting that there is room
for improvement of our projection rules for positive
affect.
Finally, we wish to understand the role that coref-
erence plays. Table 4 summarizes the results with
perfect coreference and with automated coreference.
AESOP is better than both baselines when we use
perfect coreference (PCoref), which indicates that
the affect projection rules are useful. However,
when we use automated coreference (ACoref), re-
call goes down and precision goes up. Recall goes
down because our automated coreference system is
precision oriented: it only says “coreferent” if it is
sure.
The increase in precision when moving to auto-
mated coreference is bizarre. We suspect it is pri-
marily due to the handling of quotations. Our perfect
coreference system resolves first and second person
pronouns in quotations, but the automated system
does not. Thus, with automated coreference, we al-
most never produce affect states from quotations.
This is a double-edged sword: sometimes quotes
contain important affect states, sometimes they do
not. For example, from the Father and Sons fable,
“if you are divided among yourselves, you will be
broken as easily as these sticks.” Automated coref-
erence does not produce any character resolutions
and therefore AESOP produces no affect states. In
this case this is the right thing to do. However, in
another well-known fable, a tortoise says to a hare:
“although you be as swift as the wind, I have beaten
you in the race.” Here, perfect coreference produces
multiple affect states, which are related to the plot:
the hare recieves a negative affect state for having
been beaten in the race.
</bodyText>
<sectionHeader confidence="0.999823" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999628363636364">
AESOP demonstrates that sentiment analysis tools
can successfully recognize many affect states when
coupled with syntax-based projection rules to map
the affect states onto characters. We also showed
that negative patient polarity verbs can be harvested
from a corpus to identify characters that are in a neg-
ative state due to an action. However, performance is
still modest, revealing that much work remains to be
done. In future work, new methods will be needed
to represent affect states associated with plans/goals,
events, and inferences.
</bodyText>
<sectionHeader confidence="0.999615" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999616166666667">
The authors thank the anonymous reviewers for
many helpful comments. This work was sup-
ported in part by the Department of Homeland Se-
curity Grant N0014-07-1-0152, the DARPA Ma-
chine Reading program under contract FA8750-09-
C-0172, and the NSF grant IIS-0712764.
</bodyText>
<page confidence="0.998178">
24
</page>
<sectionHeader confidence="0.998331" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997131230769231">
Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recogni-
tion. In EMNLP ’06: Proceedings of the 2006 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 431–439, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
S. Kim and E. Hovy. 2006. Extracting Opinions, Opin-
ion Holders, and Topics Expressed in Online News
Media Text. In Proceedings of ACL/COLING Work-
shop on Sentiment and Subjectivity in Text.
W. Lehnert, J. Black, and B. Reiser. 1981. Summariz-
ing Narratives. In Proceedings of the Seventh Interna-
tional Joint Conference on Artificial Intelligence.
W. G. Lehnert. 1981. Plot Units and Narrative Summa-
rization. Cognitive Science, 5(4):293–331.
G. Miller. 1990. Wordnet: An On-line Lexical Database.
International Journal of Lexicography, 3(4).
E. Riloff and W. Phillips. 2004. An Introduction to the
Sundance and AutoSlog Systems. Technical Report
UUCS-04-015, School of Computing, University of
Utah.
V. Stoyanov and C. Cardie. 2008. Topic Identification
for Fine-Grained Opinion Analysis. In Conference on
Computational Linguistics (COLING 2008).
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words using
spin model. In ACL ’05: Proceedings of the 43rd An-
nual Meeting on Association for Computational Lin-
guistics.
A. Wierzbicka. 1987. English speech act verbs: a se-
mantic dictionary. Academic Press, Sydney, Orlando.
T. Wilson, P. Hoffmann, S. Somasundaran, J. Kessler,
J. Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Pat-
wardhan. 2005. OpinionFinder: A system for subjec-
tivity analysis. In Proceedings of HLT/EMNLP 2005
Interactive Demonstrations.
Theresa Wilson. 2005. Recognizing contextual polarity
in phrase-level sentiment analysis. In In Proceedings
of HLT-EMNLP.
</reference>
<page confidence="0.998701">
25
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.722106">
<title confidence="0.998827">Toward Plot Units: Automatic Affect State Analysis</title>
<author confidence="0.931825">Goyal Riloff Daume</author>
<affiliation confidence="0.997304">School of University of</affiliation>
<address confidence="0.806436">Salt Lake City, UT</address>
<abstract confidence="0.9973886875">We present a system called AESOP that automatically produces affect states associated with characters in a story. This research represents a first step toward the automatic generation of plot unit structures from text. AESOP incorporates several existing sentiment analysis tools and lexicons to evaluate the effectiveness of current sentiment technology on this task. AESOP also includes two novel compoa method for acquiring polarwhich impart negative affect on their and projection rules propagate affect tags from surrounding words onto the characters in the story. We evaluate AE- SOP on a small collection of fables.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Eric Breck</author>
<author>Claire Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In EMNLP ’06: Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>431--439</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="17872" citStr="Choi et al., 2006" startWordPosition="2963" endWordPosition="2966">es to propagate affect states onto the characters, and in some cases, to infer new affect states. 4.1 Step 1: Assigning Affect Tags to Words 4.1.1 Sentiment Analysis Resources AESOP incorporates several existing sentiment analysis resources to recognize affect states associated with emotions and speech acts. • OpinionFinder2 (Wilson et al., 2005) (Version 1.4) is used to identify all three types of states. We use the +/- labels assigned by its contextual polarity classifier (Wilson, 2005) to create +/- affect tags. The MPQASD tags produced by its Direct Subjective and Speech Event Identifier (Choi et al., 2006) are used as M affect tags. • Subjectivity Lexicon3 (Wilson, 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated partof-speech (POS). • Semantic Orientation Lexicon4 (Takamura et al., 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated part-of-speech. • A list of 228 speech act verbs compiled from (Wierzbicka, 1987)5, which are used for M states. 4.1.2 Patient Polarity Verbs As we discussed in Section 3.4, existing resources are not sufficient to identify affect states th</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In EMNLP ’06: Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 431–439, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>E Hovy</author>
</authors>
<title>Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL/COLING Workshop on Sentiment and Subjectivity in Text.</booktitle>
<contexts>
<context position="3437" citStr="Kim and Hovy, 2006" startWordPosition="549" endWordPosition="552">ffect tags from words and phrases to characters in the story via syntactic relations. During the course of our research, we came to appreciate that affect states, of the type required for plot units, can represent much more than just direct expressions of emotion. A common phenomena are affect states that result from a character being acted upon in a positive or negative way. For example, “the cat ate the mouse” produces a positive affect state for the cat and a negative affect 1This is somewhat analogous to, but not exactly the same as, associating opinion words with their targets or topics (Kim and Hovy, 2006; Stoyanov and Cardie, 2008). Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 17–25, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The Father and His Sons (s1) A father had a family of sons who were perpetually quarreling among themselves. (s2) When he failed to heal their disputes by his exhortations, he determined to give them a practical illustration of the evils of disunion; and for this purpose he one day told them to bring him a bundle of sticks. (s3) When they had done so, </context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>S. Kim and E. Hovy. 2006. Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text. In Proceedings of ACL/COLING Workshop on Sentiment and Subjectivity in Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lehnert</author>
<author>J Black</author>
<author>B Reiser</author>
</authors>
<title>Summarizing Narratives.</title>
<date>1981</date>
<booktitle>In Proceedings of the Seventh International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1403" citStr="Lehnert et al., 1981" startWordPosition="214" endWordPosition="217"> tags from surrounding words onto the characters in the story. We evaluate AESOP on a small collection of fables. 1 Introduction In the 1980s, plot units (Lehnert, 1981) were proposed as a knowledge structure for representing narrative stories and generating summaries. Plot units are fundamentally different from the story representations that preceded them because they focus on the emotional states and tensions between characters as the driving force behind interesting plots and cohesive stories. Plot units were used in narrative summarization studies, both in computer science and psychology (Lehnert et al., 1981), but the computational models of plot units relied on tremendous amounts of manual knowledge engineering. Given the recent swell of activity in automated methods for sentiment analysis, we embarked on a project to see whether current techniques could automatically detect the affect states needed for plot unit 17 analysis. Plot units are complex structures that include affect states, causal links, and cross-character links, and generating complete plot unit structures is beyond the scope of this work. As an initial step toward the long-term goal of automatically generating plot units, we began</context>
</contexts>
<marker>Lehnert, Black, Reiser, 1981</marker>
<rawString>W. Lehnert, J. Black, and B. Reiser. 1981. Summarizing Narratives. In Proceedings of the Seventh International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Lehnert</author>
</authors>
<title>Plot Units and Narrative Summarization.</title>
<date>1981</date>
<journal>Cognitive Science,</journal>
<volume>5</volume>
<issue>4</issue>
<contexts>
<context position="951" citStr="Lehnert, 1981" startWordPosition="147" endWordPosition="148">tory. This research represents a first step toward the automatic generation of plot unit structures from text. AESOP incorporates several existing sentiment analysis tools and lexicons to evaluate the effectiveness of current sentiment technology on this task. AESOP also includes two novel components: a method for acquiring patient polarity verbs, which impart negative affect on their patients, and affect projection rules to propagate affect tags from surrounding words onto the characters in the story. We evaluate AESOP on a small collection of fables. 1 Introduction In the 1980s, plot units (Lehnert, 1981) were proposed as a knowledge structure for representing narrative stories and generating summaries. Plot units are fundamentally different from the story representations that preceded them because they focus on the emotional states and tensions between characters as the driving force behind interesting plots and cohesive stories. Plot units were used in narrative summarization studies, both in computer science and psychology (Lehnert et al., 1981), but the computational models of plot units relied on tremendous amounts of manual knowledge engineering. Given the recent swell of activity in aut</context>
<context position="6312" citStr="Lehnert, 1981" startWordPosition="1043" endWordPosition="1044">s paper, we also explain and categorize different types of situations that can produce affect states, several of which cannot be automatically recognized by existing sentiment analysis technology. We hope that one contribution of our work will be to create a better awareness of, and appreciation for, the different types of language understanding mechanisms that will ultimately be necessary for comprehensive affect state analysis. 2 Overview of Plot Units Narratives can often be understood in terms of the emotional reactions and affect states of the characters therein. The plot unit formalism (Lehnert, 1981) provides a representational mechanism for affect states and the relationships between them. Plot unit structures can be used for tasks such as narrative summarization and question answering. Plot unit structures consist of affect states for each character in a narrative, and links explaining the relationships between these affect states. The affect states themselves each have a type: (+) for positive states, (-) for negative states, and (M) for mental states (with neutral affect). Although affect states are not events per se, events often trigger affect states. If an event affects multiple ch</context>
</contexts>
<marker>Lehnert, 1981</marker>
<rawString>W. G. Lehnert. 1981. Plot Units and Narrative Summarization. Cognitive Science, 5(4):293–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>Wordnet: An On-line Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="20764" citStr="Miller, 1990" startWordPosition="3436" endWordPosition="3437">hed victimized posessed bothered Table 1: Top 20 negative patient polarity verbs 4.2 Step 2: Identifying the Characters The problem of coreference resolution in fables is somewhat different than for other genres, primarily because characters are often animals (e.g., “he”=“owl”). So we hand-crafted a simple rulebased coreference system. For the sake of this task, we made two assumptions: (1) There are only two characters per fable, and (2) Both characters are mentioned in the fable’s title. We then apply heuristics to determine number and gender for the characters based on word lists, WordNet (Miller, 1990) and POS tags. If no determination of a character’s gender or number can be made from these resources, a process of elimination is employed. Given the two character assumption, if one character is known to be male, but there are female pronouns in the fable, then the other character is assumed to be female. The same is done for number agreement. Finally, if there is only one character between a pronoun and the beginning of a document, 6http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2006T13 7The corpus is not POS tagged so there is no guarantee these will be verbs, but they usua</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Wordnet: An On-line Lexical Database. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>W Phillips</author>
</authors>
<title>An Introduction to the Sundance and AutoSlog Systems.</title>
<date>2004</date>
<tech>Technical Report UUCS-04-015,</tech>
<institution>School of Computing, University of Utah.</institution>
<contexts>
<context position="22352" citStr="Riloff and Phillips, 2004" startWordPosition="3696" endWordPosition="3699">l is to produce affect states for each character in the story. Therefore every affect tag needs to be attributed to a character, or discarded. Since plots typically revolve around actions, we used the verbs as the basis for projecting affect tags onto the characters. In some cases, we also spawn new affect tags associated with mental states to indicate that an action is likely the manifestation of a plan. We developed 6 types of affect projection rules that orchestrate how affect tags are assigned to the characters based on verb argument structure. We use the Sundance shallow parsing toolkit (Riloff and Phillips, 2004) to generate a syntactic analysis of each sentence, including syntactic chunking, clause segmentation, and active/passive voice recognition. We normalize the verb phrases (VPs) with respect to voice (i.e., we transform the passive voice constructions into an active voice equivalent) to simplify our rules. We then make the assumption that the Subject of the VP is its AGENT and the Direct Object of the VP is its PATIENT.8 The affect projection rules only project affect states onto AGENTS and PATIENTS that correspond to a character in the story. The five types of rules are described below. 1. AGE</context>
</contexts>
<marker>Riloff, Phillips, 2004</marker>
<rawString>E. Riloff and W. Phillips. 2004. An Introduction to the Sundance and AutoSlog Systems. Technical Report UUCS-04-015, School of Computing, University of Utah.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>C Cardie</author>
</authors>
<title>Topic Identification for Fine-Grained Opinion Analysis.</title>
<date>2008</date>
<booktitle>In Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="3465" citStr="Stoyanov and Cardie, 2008" startWordPosition="553" endWordPosition="556">s and phrases to characters in the story via syntactic relations. During the course of our research, we came to appreciate that affect states, of the type required for plot units, can represent much more than just direct expressions of emotion. A common phenomena are affect states that result from a character being acted upon in a positive or negative way. For example, “the cat ate the mouse” produces a positive affect state for the cat and a negative affect 1This is somewhat analogous to, but not exactly the same as, associating opinion words with their targets or topics (Kim and Hovy, 2006; Stoyanov and Cardie, 2008). Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 17–25, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The Father and His Sons (s1) A father had a family of sons who were perpetually quarreling among themselves. (s2) When he failed to heal their disputes by his exhortations, he determined to give them a practical illustration of the evils of disunion; and for this purpose he one day told them to bring him a bundle of sticks. (s3) When they had done so, he placed the faggot into th</context>
</contexts>
<marker>Stoyanov, Cardie, 2008</marker>
<rawString>V. Stoyanov and C. Cardie. 2008. Topic Identification for Fine-Grained Opinion Analysis. In Conference on Computational Linguistics (COLING 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18123" citStr="Takamura et al., 2005" startWordPosition="3004" endWordPosition="3007">ognize affect states associated with emotions and speech acts. • OpinionFinder2 (Wilson et al., 2005) (Version 1.4) is used to identify all three types of states. We use the +/- labels assigned by its contextual polarity classifier (Wilson, 2005) to create +/- affect tags. The MPQASD tags produced by its Direct Subjective and Speech Event Identifier (Choi et al., 2006) are used as M affect tags. • Subjectivity Lexicon3 (Wilson, 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated partof-speech (POS). • Semantic Orientation Lexicon4 (Takamura et al., 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated part-of-speech. • A list of 228 speech act verbs compiled from (Wierzbicka, 1987)5, which are used for M states. 4.1.2 Patient Polarity Verbs As we discussed in Section 3.4, existing resources are not sufficient to identify affect states that arise from a character being acted upon. Sentiment lexicons, for example, assign polarity to verbs irrespective of their agents or patients. To fill this gap, we tried to automatically acquire verbs that have a strong patient polarity (i.e., the pa</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Wierzbicka</author>
</authors>
<title>English speech act verbs: a semantic dictionary.</title>
<date>1987</date>
<publisher>Academic Press,</publisher>
<location>Sydney, Orlando.</location>
<contexts>
<context position="18313" citStr="Wierzbicka, 1987" startWordPosition="3036" endWordPosition="3037">y its contextual polarity classifier (Wilson, 2005) to create +/- affect tags. The MPQASD tags produced by its Direct Subjective and Speech Event Identifier (Choi et al., 2006) are used as M affect tags. • Subjectivity Lexicon3 (Wilson, 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated partof-speech (POS). • Semantic Orientation Lexicon4 (Takamura et al., 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated part-of-speech. • A list of 228 speech act verbs compiled from (Wierzbicka, 1987)5, which are used for M states. 4.1.2 Patient Polarity Verbs As we discussed in Section 3.4, existing resources are not sufficient to identify affect states that arise from a character being acted upon. Sentiment lexicons, for example, assign polarity to verbs irrespective of their agents or patients. To fill this gap, we tried to automatically acquire verbs that have a strong patient polarity (i.e., the patient will be in a good or bad state by virtue of being acted upon). We used corpus statistics to identify verbs that frequently occur with agents who typically have evil (negative) or chari</context>
</contexts>
<marker>Wierzbicka, 1987</marker>
<rawString>A. Wierzbicka. 1987. English speech act verbs: a semantic dictionary. Academic Press, Sydney, Orlando.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>P Hoffmann</author>
<author>S Somasundaran</author>
<author>J Kessler</author>
<author>J Wiebe</author>
<author>Y Choi</author>
<author>C Cardie</author>
<author>E Riloff</author>
<author>S Patwardhan</author>
</authors>
<title>OpinionFinder: A system for subjectivity analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP</booktitle>
<contexts>
<context position="17602" citStr="Wilson et al., 2005" startWordPosition="2917" endWordPosition="2920">/www.cs.pitt.edu/mpqa/opinionfinderrelease/ 3http://www.cs.pitt.edu/mpqa/lexiconrelease/collectinfo1.html 4http://www.lr.pi.titech.ac.jp/—takamura/pndic en.html 5http://openlibrary.org/b/OL2413134M/English speech act verbs story. Third, AESOP applies affect projection rules to propagate affect states onto the characters, and in some cases, to infer new affect states. 4.1 Step 1: Assigning Affect Tags to Words 4.1.1 Sentiment Analysis Resources AESOP incorporates several existing sentiment analysis resources to recognize affect states associated with emotions and speech acts. • OpinionFinder2 (Wilson et al., 2005) (Version 1.4) is used to identify all three types of states. We use the +/- labels assigned by its contextual polarity classifier (Wilson, 2005) to create +/- affect tags. The MPQASD tags produced by its Direct Subjective and Speech Event Identifier (Choi et al., 2006) are used as M affect tags. • Subjectivity Lexicon3 (Wilson, 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated partof-speech (POS). • Semantic Orientation Lexicon4 (Takamura et al., 2005): The positive/negative words in this list are assigned +/- affect tags, when t</context>
</contexts>
<marker>Wilson, Hoffmann, Somasundaran, Kessler, Wiebe, Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>T. Wilson, P. Hoffmann, S. Somasundaran, J. Kessler, J. Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005. OpinionFinder: A system for subjectivity analysis. In Proceedings of HLT/EMNLP 2005 Interactive Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis. In</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP.</booktitle>
<contexts>
<context position="17747" citStr="Wilson, 2005" startWordPosition="2944" endWordPosition="2945"> en.html 5http://openlibrary.org/b/OL2413134M/English speech act verbs story. Third, AESOP applies affect projection rules to propagate affect states onto the characters, and in some cases, to infer new affect states. 4.1 Step 1: Assigning Affect Tags to Words 4.1.1 Sentiment Analysis Resources AESOP incorporates several existing sentiment analysis resources to recognize affect states associated with emotions and speech acts. • OpinionFinder2 (Wilson et al., 2005) (Version 1.4) is used to identify all three types of states. We use the +/- labels assigned by its contextual polarity classifier (Wilson, 2005) to create +/- affect tags. The MPQASD tags produced by its Direct Subjective and Speech Event Identifier (Choi et al., 2006) are used as M affect tags. • Subjectivity Lexicon3 (Wilson, 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated partof-speech (POS). • Semantic Orientation Lexicon4 (Takamura et al., 2005): The positive/negative words in this list are assigned +/- affect tags, when they occur with the designated part-of-speech. • A list of 228 speech act verbs compiled from (Wierzbicka, 1987)5, which are used for M states. 4.</context>
</contexts>
<marker>Wilson, 2005</marker>
<rawString>Theresa Wilson. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In In Proceedings of HLT-EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>