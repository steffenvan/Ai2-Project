<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.063511">
<title confidence="0.996128">
Anaphora Resolution in Multi-Person Dialogues
</title>
<author confidence="0.980395">
Prateek Jain and Manav Ratan Mital and Sumit Kumar and Amitabha Mukerjee and Achla M. Raina
</author>
<affiliation confidence="0.990088">
Indian Institute of Technology Kanpur,
</affiliation>
<address confidence="0.675618">
Kanpur 208016 INDIA
</address>
<email confidence="0.996883">
{pjain,sumit,manavrm,amit,achla}@iitk.ac.in
</email>
<sectionHeader confidence="0.995599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999898222222222">
Anaphora resolution for dialogues is a difficult
problem because of the several kinds of com-
plex anaphoric references generally present in
dialogic discourses. It is nevertheless a criti-
cal first step in the processing of any such dis-
course. In this paper, we describe a system for
anaphora resolution in multi-person dialogues.
This system aims to bring together a wide array
syntactic, semantic and world knowledge based
techniques used for anaphora resolution. In
this system, the performance of the heuristics is
optimized for specific dialogues using genetic
algorithms, which relieves the programmer of
hand-crafting the weights of these heuristics. In
our system, we propose a new technique based
on the use of anaphora chains to enable reso-
lution of a large variety of anaphors, including
plural anaphora and cataphora.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927019607843">
Anaphoric references abound in natural language dis-
courses and their resolution has often been identified as
the first step towards any serious discourse processing re-
lated tasks. However, any comprehensive anaphora reso-
lution scheme is expected to entail the use of rich seman-
tic and pragmatic knowledge representation and process-
ing, and is, therefore, a complex problem. As a result of
such problems, several heuristics-based approaches have
been developed and adopted over the years to achieve par-
tial solutions to the problem.
The pioneering work in the area of anaphora resolu-
tion was done by Hobbs (Jerry R. Hobbs, 1978) who
designed several early syntactic and semantic heuristics
for the same. (Hirst, 1981) discusses several early ap-
proaches to anaphora resolution in discourses. (Denber,
1998) and (Lappin and Leass, 1994) describe several syn-
tactic heuristics for reflexive, reciprocal and pleonastic
anaphora, among others. Often domain-specific heuris-
tics are used for anaphora resolution and fine tuned to
perform well on a limited corpus, such as in (Mitkov,
1998). (Ng and Cardie, 2002) proposes a machine learn-
ing approach to Anaphora Resolution but generally sta-
tistical learning approaches suffer from the problems of
small corpuses and corpus dependent learning. A more
general and comprehensive overview of state-of-the-art
in anaphora resolution is given in (Mitkov, 1999) and also
in (Mitkov et al., 2001).
Few systems have been developed that are specifically
aimed at the task of anaphora resolution in discourses.
ROSANA, an algorithm for anaphora resolution that fo-
cuses on robustness against information deficiency in the
parsed output, is described in (Stuckardt, 2001). MARS,
the Mitkov Anaphora Resolution System, is another au-
tomatic, knowledge-poor anaphora resolution system that
has been implemented for several languages including
English, Bulgarian and Japanese.
In this paper, we describe the design and implementa-
tion of Jepthah1, a rule-based system for resolving a wide
variety of anaphora occurring in multi-person dialogues
in English. In this system, we integrate several different
knowledge-poor constraints and heuristics, and operate
them over a naive character model of the entire dialogue
to perform effective anaphora resolution. In addition to
using standard heuristics, we have developed our own se-
mantic and pragmatic heuristics, specific to dialogue sit-
uations, that operate on this character model. There is
a weight assigned to each of these heuristics and these
weights are fine-tuned using a learning mechanism im-
plemented by genetic algorithms. We use the linguistic
feature of anaphoric chains, present in dialogues, to re-
solve a relatively large class of anaphora.
</bodyText>
<footnote confidence="0.800752">
1name of a wise Isreali judge in the Bible
</footnote>
<sectionHeader confidence="0.935369" genericHeader="introduction">
2 Jepthah
</sectionHeader>
<bodyText confidence="0.999946">
In Jepthah, we adopt an integrated approach towards re-
solving various different kinds of anaphors occurring in
dialogue situations. In this approach we fuse together
several heuristics with a new kind of computational lin-
guistic insight – that of the deployment of anaphora
chains and we develop a graph-based technique for han-
dling the resolution of various anaphors. An anaphora
chain may be described as a referential chain compris-
ing series of mutually co-referential anaphoric elements,
generally of more than one type, headed by a referential
element.
The class of anaphors that we aim to resolve is
fairly large and includes pronouns, reflexives and deic-
tic anaphors. In terms of distribution, we are dealing with
anaphors in subject, object and modifier positions, pos-
sessive reflexive, and cataphora. It is may be mentioned
here that we deal only with unambiguous cases of plural
pronouns, such as both of us, two ofyou, etc. These are
the cases in which the domain of the pronouns is clearly
quantified, unlike the case of such instances as all of us
or they, etc.
</bodyText>
<subsectionHeader confidence="0.972943">
2.1 Graph-theoretic Approach
</subsectionHeader>
<bodyText confidence="0.999973471698113">
The entire operation is centered around a graph formu-
lation of the resolution problem in the perspective of the
dialogue. We extract all the nouns and pronouns present
in the dialogue. Assume there are n nouns and p pro-
nouns in the dialogue. Let the ith noun be represented as
Ni, with i &lt; n and that Pi represents the ith pronoun,
with i &lt; p. Now, we construct a graph representation for
the problem as follows. Let G be the graph that we are
interested in formulating, comprising of a node for every
Ni and Pj.Let NGi be the node corresponding to the noun
Ni and PjG be the node corresponding to the pronoun Pj.
Thus, we can split the set of vertices of this graph VG into
two parts, the set consisting of NGi , di &lt; n and the set
consisting of PjG, dj &lt; p. The set of edges EG for this
graph G comprises of two types of directed edges and is
constructed as follows. Construct a set of edges E1 which
includes a directed edge Ei→j from PiG to NGj, for all
pairs PiG and NGj. The other set E2 includes a directed
edge Ei→j from PiG to PjG for all pair of nodes PiG and
PjG such that i =� j. Clearly, we have EG = E1 U E2. Let
us define a property L on the paths in this graph as fol-
lows – a path p satisfies the property L iff it consists of a
sequence of edges Ei E EG (i &lt; length(p)) with exactly
one edge Ef from the set E1 and the condition that this is
the last edge in the sequence, i.e., Elength(p) = Ef.
Intuitively, this graph represents the set of possible
anaphor-antecedent relationships. The set of possible ref-
erents of an anaphor represented by the node PiG in the
graph G consists of all possible distinct nodes NGk that
can be reached from PiG using paths that satisfy the prop-
erty L. Let this set be represented as Si. Note here
that paths as above of length &gt; 2 represent anaphoric
chains present in the dialogue. One or more edges in
these paths are from one anaphor to another and represent
co-reference amongst these anaphors. The antecedent
space of an anaphor Pi consists of all nouns and pronouns
whose corresponding nodes in the graph G are reachable
from PiG by traversing a single edge belonging to EG.
Now, the idea here is to process this antecedent space and
rank all the nodes in Si to determine the most likely an-
tecedent for the anaphor Pi. This ranking is done by at-
taching weights to the edges present in the graph.
Every edge is awarded a particular weight (less than
1.0), that is evaluated for every edge using a set of heuris-
tics described in section 2.4. The rank of each node NGk
in the set Si is determined by the total weight Wik for that
node. Wik is computed as follows – let the weight Wp of
each path p be defined as the product of the weights of
all the edges lying on that path. Then, Wik is the sum of
the weights of all the paths from PiG to NGk, i.e., Ep Wp.
Hence, for anaphora resolution, we need to basically de-
sign an algorithm or a function to compute the weight for
each edge in the graph.
</bodyText>
<subsectionHeader confidence="0.992093">
2.2 System Design
</subsectionHeader>
<bodyText confidence="0.9999829375">
The input dialogue is passed to the front end which com-
prises of the Stanford Serialized Parser and PoS tagger.
The parser gives the best parse for every input sentence,
each of which are then subsequently processed. In the
first step we extract all the proper nouns present in the
dialogue and initialize our character model base and the
graph G that was explained in section 2.1. We then
take the sequence of parses corresponding to each sub-
sequent dialogue by a speaker and process them sequen-
tially. Techniques for anaphora resolution are then ap-
plied in two phases. In the first phase, a set of constraints
is applied to this graph, to prune out edges that represent
any unfeasible co-references. In the second phase, a set
of heuristics are applied to award weights to edges repre-
senting these relationships. After the processing is over
and all weights have been obtained, the permissible an-
tecedents for each anaphor are ranked and the most likely
antecedent for each is outputted. In case there is a plu-
ral anaphor, with quantification over x nouns, the top x
likely antecedents are outputted.
While processing the dialogue, a naive character build-
ing is implemented. This is done mainly by focusing on
the verbs in the sentences. The subject and object nouns
associated with these verbs are selected and their relation-
ship is put in the character model base associated with the
speaker of the corresponding dialogue. The system main-
tains an apriori knowledge base with it containing infor-
mation like ontology and functionalities of several nouns.
This combination of apriori and assimilated knowledge
is then used to apply certain semantic and pragmatic con-
straints/heuristics on the graph, as shown in the following
sections.
</bodyText>
<subsectionHeader confidence="0.991595">
2.3 Constraints
</subsectionHeader>
<bodyText confidence="0.998528">
We apply the set of restrictions prior to the set of prefer-
ences, thereby narrowing down the candidate set as early
as possible. The list of constraints that implement these
restrictions in Jepthah are listed as follows –
</bodyText>
<listItem confidence="0.99673428">
1. Deictic Constraint: This is a set of simple con-
straints that are specific to dialogue settings because
in such settings we can have the concept of frames
of reference with regard to the various speakers in-
volved in the dialogue action.
2. Non-coreference (Mitkov, 1999): Syntactic fea-
tures present in a sentence often lend themselves
to be expressed as constraints on anaphora refer-
ence. These features are captured by our non-
coreference constraints which stipulate that certain
pairs of anaphor and noun phrases within the same
sentence cannot refer to the same antecedent.
3. Gender, Number and Person Agreement: This is
a low level constraint which requires that anaphors
and their antecedents must agree in gender, number
and person respectively.
4. Constraint on Reflexive Pronoun: A reflexive pro-
noun such as himself, herself, etc must refer to the
subject or the object of the verb in whose clause it
lies. In case of ellipsis, however, it may refer to the
subject or object of the next higher verb to which the
clause is attached.
5. Semantic Consistency (Mitkov, 1999): This con-
straint enforces same semantics of the antecedent as
the anaphor under consideration.
</listItem>
<subsectionHeader confidence="0.985533">
2.4 Heuristics
</subsectionHeader>
<bodyText confidence="0.999747875">
Each preference or heuristic, has a certain weight and
awards certain points to every anaphor-antecedent rela-
tionship. These points are a measure of the likelihood of
that anaphor-antecedent relationship. The weight of an
edge is the sum total of the weights awarded by each in-
dividual heuristic to the anaphor-antecedent relationship.
The heuristics used in our system are enumerated as fol-
lows –
</bodyText>
<listItem confidence="0.844585184210527">
1. Definiteness (Lappin and Leass, 1994): Accord-
ing to this heuristic, nouns that are preceded by a
demonstrative pronoun or a definite article are more
likely to be antecedents and are awarded higher
credibilities.
2. Non-prepositional NP (Lappin and Leass, 1994):
This heuristic states that a noun phrase which occurs
within a prepositional phrase is less probable to be
an antecedent to an anaphor and consequently, it is
awarded less credibility.
3. Pleonastic (Lappin and Leass, 1994): This heuris-
tic is based on the observation that there exist some
syntactic patterns such that every it anaphor occur-
ring in any of those patterns must be pleonastic.
4. Syntactic Parallelism (Lappin and Leass, 1994):
As per this heuristic, preference is given to noun
phrases with the same syntactic function as the
anaphor.
5. Recency (Mitkov, 1999): This is a very simple
heuristic according to which, everything else being
comparable, a higher credibility is awarded to the
antecedent nearer to the anaphor.
6. Semantic Parallelism (Lappin and Leass, 1994):
This heuristic gives preference to those noun phrases
which have the same semantic role as the anaphor
in question. This is a useful heuristic and can be
implemented by a system that can identify semantic
roles.
7. Pragmatic Heuristics: We use certain pragmatic
heuristics that we have identified to be very spe-
cific to dialogue settings. These are of the following
kinds
• If one speaker asks a question, then the next
speaker is likely to be the antecedent of the you
that may occur in the former’s sentence.
• If a speaker makes an exclamation then he is
likely to be the antecedent of the you in the
speech of the speaker just before him.
</listItem>
<bodyText confidence="0.980458866666667">
8. Naive Character Building: This refers to a naive
character model that we have used to implement a
restricted knowledge-based representation of the di-
alogue, woven around all the noun entities that are
present in the dialogue. To this end, we use a certain
amount of world knowledge that is present apriori
with the system, in the form of ontology and func-
tionality of possible noun entities. For instance, we
associate actions with each character based on their
subject object relationship with the verbs that occur
in the dialogues. Now for an anaphor we see if a
possible antecedent has functionality of the action
associated with the anaphor, implied by the verb of
the sentence. if it is so, we then give higher credibil-
ity to this particular antecedent.
</bodyText>
<tableCaption confidence="0.999203">
Table 1: Results
</tableCaption>
<table confidence="0.9989288">
Corpus % Accuracy
Shaw’s play - Pygmalion 62
Shaw’s play - Man and Superman 67
Hand-Crafted Dialogue I 83
Hand-Crafted Dialogue II 81
</table>
<subsectionHeader confidence="0.99783">
2.5 Learning approach
</subsectionHeader>
<bodyText confidence="0.999903363636364">
In most systems ((Mitkov, 1998),(Lappin and Leass,
1994)) the weights that are assigned for different
anaphor-antecedent relationships are programmer depen-
dent. Fixing these values in a adhoc fashion can clearly
give rise to unstable behaviour. In our work, we use
manually tagged corpora to evaluate the effectiveness
of a given weight assignment; these can then be tuned
using Genetic Algorithms(Goldberg, 1989). We use 2-
point crossover and mutation which are used in Standard
Genetic Algorithm for Real Variables(Deb and Kumar,
1995).
</bodyText>
<sectionHeader confidence="0.999975" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.9998475">
We used our system for anaphora resolution in the fol-
lowing types of dialogue corpora:
</bodyText>
<listItem confidence="0.987841666666667">
• Dialogues written manually, woven broadly in a stu-
dent environment
• Fragments from the plays by the writer G. B. Shaw
</listItem>
<bodyText confidence="0.999701375">
Our System gave nearly 65% accuracy on Shaw’s plays
and almost 80% accuracy on our own “hand crafted” dia-
logues [Table:1]. In the table, the name “hand-crafted di-
alogues” refers to sample dialogues that the authors wrote
themselves to test the performance of the system.
The genetic algorithms that we use help in fine-tuning
weights according to the particular corpus, and show ap-
preciable increase in accuracy.
</bodyText>
<sectionHeader confidence="0.999587" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999996294117647">
We have implemented an automatic, knowledge-based
anaphora resolution system that works for dialogic dis-
courses. The lack of availability of any standard corpora
(Mitkov, 1999) is a major drawback in case of anaphora
resolution systems in general and those for dialogues in
particular. The original contribution of this system is
mainly two-fold. First, the anaphora resolution system
that we have implemented uses an innovative graph tech-
nique, based on the idea of anaphora chaining, that makes
it possible to resolve such references as cataphora and
plural anaphora. Secondly, we give an algorithm which
uses naive character building to apply various semantic
and world-knowledge based heuristics to the process of
anaphora resolution. The results obtained from the sys-
tem indicate a fairly high accuracy, though an extensive
evaluation of the various resolution algorithms as well as
the system as a whole remains to be done.
</bodyText>
<sectionHeader confidence="0.996231" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998675648648649">
K. Deb and A. Kumar. 1995. Real-coded genetic al-
gorithms with simulated binary crossover: Studies on
multimodal and multiobjective problems. Complex
Systems, 9(6):431–454.
M. Denber. 1998. Automatic resolution of anaphora in
english. Technical report, Eastman Kodak Co., Imag-
ing Science Division.
D. E. Goldberg. 1989. Genetic Algorithms in Search,
Optimization, and Machine Learning. Addison-
Wesley Publishing Company, Reading, MA.
Graeme Hirst. 1981. Discourse-oriented anaphora
resolution in natural language understanding: A re-
view”. American Journal of Computational Linguis-
tics, 7(2):85–98, April-June.
Jerry R. Hobbs. 1978. Resolving pronoun references.
Lingua, 44:311–338.
Shalom Lappin and Herbert J. Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Computa-
tional Linguistics, 20(4):535–561.
Ruslan Mitkov, Branimir Boguraev, and Shalom Lappin.
2001. An Introduction to the Special Issue on Com-
putational Anaphora Resolution. Computational Lin-
guistics, 27(4).
Ruslan Mitkov. 1998. Robust pronoun resolution with
limited knowledge. In COLING-ACL, pages 869–875.
R. Mitkov. 1999. Anaphora Resolution: The State
of the Art. Working paper (Based on the COL-
ING’98/ACL’98 tutorial on anaphora resolution).
Vincent Ng and Claire Cardie. 2002. Combining sample
selection and error-driven pruning for machine learn-
ing of coreference rules. In Proceedings of the 2002
Conference on Empirical Methods in Natural Lan-
guage Processing, Association for Computational Lin-
guistics.
Roland Stuckardt. 2001. Design and Enhanced Evalua-
tion of a Robust Anaphor Resolution Algorithm. Com-
putational Linguistics, 27(4):479–506, December.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.764603">
<title confidence="0.998592">Anaphora Resolution in Multi-Person Dialogues</title>
<author confidence="0.798625">Jain Ratan Mital Kumar Mukerjee M</author>
<affiliation confidence="0.995987">Indian Institute of Technology</affiliation>
<address confidence="0.989215">Kanpur 208016</address>
<abstract confidence="0.998244842105263">Anaphora resolution for dialogues is a difficult problem because of the several kinds of complex anaphoric references generally present in dialogic discourses. It is nevertheless a critical first step in the processing of any such discourse. In this paper, we describe a system for anaphora resolution in multi-person dialogues. This system aims to bring together a wide array syntactic, semantic and world knowledge based techniques used for anaphora resolution. In this system, the performance of the heuristics is optimized for specific dialogues using genetic algorithms, which relieves the programmer of hand-crafting the weights of these heuristics. In our system, we propose a new technique based on the use of anaphora chains to enable resolution of a large variety of anaphors, including plural anaphora and cataphora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Deb</author>
<author>A Kumar</author>
</authors>
<title>Real-coded genetic algorithms with simulated binary crossover: Studies on multimodal and multiobjective problems.</title>
<date>1995</date>
<journal>Complex Systems,</journal>
<volume>9</volume>
<issue>6</issue>
<contexts>
<context position="14677" citStr="Deb and Kumar, 1995" startWordPosition="2451" endWordPosition="2454">n 67 Hand-Crafted Dialogue I 83 Hand-Crafted Dialogue II 81 2.5 Learning approach In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent. Fixing these values in a adhoc fashion can clearly give rise to unstable behaviour. In our work, we use manually tagged corpora to evaluate the effectiveness of a given weight assignment; these can then be tuned using Genetic Algorithms(Goldberg, 1989). We use 2- point crossover and mutation which are used in Standard Genetic Algorithm for Real Variables(Deb and Kumar, 1995). 3 Results We used our system for anaphora resolution in the following types of dialogue corpora: • Dialogues written manually, woven broadly in a student environment • Fragments from the plays by the writer G. B. Shaw Our System gave nearly 65% accuracy on Shaw’s plays and almost 80% accuracy on our own “hand crafted” dialogues [Table:1]. In the table, the name “hand-crafted dialogues” refers to sample dialogues that the authors wrote themselves to test the performance of the system. The genetic algorithms that we use help in fine-tuning weights according to the particular corpus, and show a</context>
</contexts>
<marker>Deb, Kumar, 1995</marker>
<rawString>K. Deb and A. Kumar. 1995. Real-coded genetic algorithms with simulated binary crossover: Studies on multimodal and multiobjective problems. Complex Systems, 9(6):431–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denber</author>
</authors>
<title>Automatic resolution of anaphora in english.</title>
<date>1998</date>
<tech>Technical report,</tech>
<institution>Eastman Kodak Co., Imaging Science Division.</institution>
<contexts>
<context position="1897" citStr="Denber, 1998" startWordPosition="285" endWordPosition="286">y comprehensive anaphora resolution scheme is expected to entail the use of rich semantic and pragmatic knowledge representation and processing, and is, therefore, a complex problem. As a result of such problems, several heuristics-based approaches have been developed and adopted over the years to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also</context>
</contexts>
<marker>Denber, 1998</marker>
<rawString>M. Denber. 1998. Automatic resolution of anaphora in english. Technical report, Eastman Kodak Co., Imaging Science Division.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Goldberg</author>
</authors>
<date>1989</date>
<booktitle>Genetic Algorithms in Search, Optimization, and Machine Learning.</booktitle>
<publisher>AddisonWesley Publishing Company,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="14552" citStr="Goldberg, 1989" startWordPosition="2433" endWordPosition="2434"> this particular antecedent. Table 1: Results Corpus % Accuracy Shaw’s play - Pygmalion 62 Shaw’s play - Man and Superman 67 Hand-Crafted Dialogue I 83 Hand-Crafted Dialogue II 81 2.5 Learning approach In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent. Fixing these values in a adhoc fashion can clearly give rise to unstable behaviour. In our work, we use manually tagged corpora to evaluate the effectiveness of a given weight assignment; these can then be tuned using Genetic Algorithms(Goldberg, 1989). We use 2- point crossover and mutation which are used in Standard Genetic Algorithm for Real Variables(Deb and Kumar, 1995). 3 Results We used our system for anaphora resolution in the following types of dialogue corpora: • Dialogues written manually, woven broadly in a student environment • Fragments from the plays by the writer G. B. Shaw Our System gave nearly 65% accuracy on Shaw’s plays and almost 80% accuracy on our own “hand crafted” dialogues [Table:1]. In the table, the name “hand-crafted dialogues” refers to sample dialogues that the authors wrote themselves to test the performance</context>
</contexts>
<marker>Goldberg, 1989</marker>
<rawString>D. E. Goldberg. 1989. Genetic Algorithms in Search, Optimization, and Machine Learning. AddisonWesley Publishing Company, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Discourse-oriented anaphora resolution in natural language understanding: A review”.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>7</volume>
<issue>2</issue>
<pages>April-June.</pages>
<contexts>
<context position="1809" citStr="Hirst, 1981" startWordPosition="273" endWordPosition="274">d as the first step towards any serious discourse processing related tasks. However, any comprehensive anaphora resolution scheme is expected to entail the use of rich semantic and pragmatic knowledge representation and processing, and is, therefore, a complex problem. As a result of such problems, several heuristics-based approaches have been developed and adopted over the years to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive</context>
</contexts>
<marker>Hirst, 1981</marker>
<rawString>Graeme Hirst. 1981. Discourse-oriented anaphora resolution in natural language understanding: A review”. American Journal of Computational Linguistics, 7(2):85–98, April-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<pages>44--311</pages>
<contexts>
<context position="1720" citStr="Hobbs, 1978" startWordPosition="260" endWordPosition="261">ences abound in natural language discourses and their resolution has often been identified as the first step towards any serious discourse processing related tasks. However, any comprehensive anaphora resolution scheme is expected to entail the use of rich semantic and pragmatic knowledge representation and processing, and is, therefore, a complex problem. As a result of such problems, several heuristics-based approaches have been developed and adopted over the years to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the p</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>Jerry R. Hobbs. 1978. Resolving pronoun references. Lingua, 44:311–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="1926" citStr="Lappin and Leass, 1994" startWordPosition="288" endWordPosition="291">phora resolution scheme is expected to entail the use of rich semantic and pragmatic knowledge representation and processing, and is, therefore, a complex problem. As a result of such problems, several heuristics-based approaches have been developed and adopted over the years to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Fe</context>
<context position="11549" citStr="Lappin and Leass, 1994" startWordPosition="1935" endWordPosition="1938">rb to which the clause is attached. 5. Semantic Consistency (Mitkov, 1999): This constraint enforces same semantics of the antecedent as the anaphor under consideration. 2.4 Heuristics Each preference or heuristic, has a certain weight and awards certain points to every anaphor-antecedent relationship. These points are a measure of the likelihood of that anaphor-antecedent relationship. The weight of an edge is the sum total of the weights awarded by each individual heuristic to the anaphor-antecedent relationship. The heuristics used in our system are enumerated as follows – 1. Definiteness (Lappin and Leass, 1994): According to this heuristic, nouns that are preceded by a demonstrative pronoun or a definite article are more likely to be antecedents and are awarded higher credibilities. 2. Non-prepositional NP (Lappin and Leass, 1994): This heuristic states that a noun phrase which occurs within a prepositional phrase is less probable to be an antecedent to an anaphor and consequently, it is awarded less credibility. 3. Pleonastic (Lappin and Leass, 1994): This heuristic is based on the observation that there exist some syntactic patterns such that every it anaphor occurring in any of those patterns mus</context>
<context position="14195" citStr="Lappin and Leass, 1994" startWordPosition="2378" endWordPosition="2381">of possible noun entities. For instance, we associate actions with each character based on their subject object relationship with the verbs that occur in the dialogues. Now for an anaphor we see if a possible antecedent has functionality of the action associated with the anaphor, implied by the verb of the sentence. if it is so, we then give higher credibility to this particular antecedent. Table 1: Results Corpus % Accuracy Shaw’s play - Pygmalion 62 Shaw’s play - Man and Superman 67 Hand-Crafted Dialogue I 83 Hand-Crafted Dialogue II 81 2.5 Learning approach In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent. Fixing these values in a adhoc fashion can clearly give rise to unstable behaviour. In our work, we use manually tagged corpora to evaluate the effectiveness of a given weight assignment; these can then be tuned using Genetic Algorithms(Goldberg, 1989). We use 2- point crossover and mutation which are used in Standard Genetic Algorithm for Real Variables(Deb and Kumar, 1995). 3 Results We used our system for anaphora resolution in the following types of dialogue corpora: • Dialogues written</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert J. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
<author>Branimir Boguraev</author>
<author>Shalom Lappin</author>
</authors>
<title>An Introduction to the Special Issue on Computational Anaphora Resolution.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="2522" citStr="Mitkov et al., 2001" startWordPosition="378" endWordPosition="381">(Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Few systems have been developed that are specifically aimed at the task of anaphora resolution in discourses. ROSANA, an algorithm for anaphora resolution that focuses on robustness against information deficiency in the parsed output, is described in (Stuckardt, 2001). MARS, the Mitkov Anaphora Resolution System, is another automatic, knowledge-poor anaphora resolution system that has been implemented for several languages including English, Bulgarian and Japanese. In this paper, we describe the design and implementation of Jepthah1, a rule-based system for resolving a wide variety of anapho</context>
</contexts>
<marker>Mitkov, Boguraev, Lappin, 2001</marker>
<rawString>Ruslan Mitkov, Branimir Boguraev, and Shalom Lappin. 2001. An Introduction to the Special Issue on Computational Anaphora Resolution. Computational Linguistics, 27(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In COLING-ACL,</booktitle>
<pages>869--875</pages>
<contexts>
<context position="2173" citStr="Mitkov, 1998" startWordPosition="327" endWordPosition="328">pted over the years to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Few systems have been developed that are specifically aimed at the task of anaphora resolution in discourses. ROSANA, an algorithm for anaphora resolution that focuses on robustness against information deficiency in the parsed output, is described i</context>
<context position="14170" citStr="Mitkov, 1998" startWordPosition="2377" endWordPosition="2378"> functionality of possible noun entities. For instance, we associate actions with each character based on their subject object relationship with the verbs that occur in the dialogues. Now for an anaphor we see if a possible antecedent has functionality of the action associated with the anaphor, implied by the verb of the sentence. if it is so, we then give higher credibility to this particular antecedent. Table 1: Results Corpus % Accuracy Shaw’s play - Pygmalion 62 Shaw’s play - Man and Superman 67 Hand-Crafted Dialogue I 83 Hand-Crafted Dialogue II 81 2.5 Learning approach In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent. Fixing these values in a adhoc fashion can clearly give rise to unstable behaviour. In our work, we use manually tagged corpora to evaluate the effectiveness of a given weight assignment; these can then be tuned using Genetic Algorithms(Goldberg, 1989). We use 2- point crossover and mutation which are used in Standard Genetic Algorithm for Real Variables(Deb and Kumar, 1995). 3 Results We used our system for anaphora resolution in the following types of dialogue cor</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In COLING-ACL, pages 869–875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Anaphora Resolution: The State of the Art. Working paper (Based on the COLING’98/ACL’98 tutorial on anaphora resolution).</title>
<date>1999</date>
<contexts>
<context position="2488" citStr="Mitkov, 1999" startWordPosition="373" endWordPosition="374">ourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Few systems have been developed that are specifically aimed at the task of anaphora resolution in discourses. ROSANA, an algorithm for anaphora resolution that focuses on robustness against information deficiency in the parsed output, is described in (Stuckardt, 2001). MARS, the Mitkov Anaphora Resolution System, is another automatic, knowledge-poor anaphora resolution system that has been implemented for several languages including English, Bulgarian and Japanese. In this paper, we describe the design and implementation of Jepthah1, a rule-based system for </context>
<context position="10192" citStr="Mitkov, 1999" startWordPosition="1718" endWordPosition="1719">ertain semantic and pragmatic constraints/heuristics on the graph, as shown in the following sections. 2.3 Constraints We apply the set of restrictions prior to the set of preferences, thereby narrowing down the candidate set as early as possible. The list of constraints that implement these restrictions in Jepthah are listed as follows – 1. Deictic Constraint: This is a set of simple constraints that are specific to dialogue settings because in such settings we can have the concept of frames of reference with regard to the various speakers involved in the dialogue action. 2. Non-coreference (Mitkov, 1999): Syntactic features present in a sentence often lend themselves to be expressed as constraints on anaphora reference. These features are captured by our noncoreference constraints which stipulate that certain pairs of anaphor and noun phrases within the same sentence cannot refer to the same antecedent. 3. Gender, Number and Person Agreement: This is a low level constraint which requires that anaphors and their antecedents must agree in gender, number and person respectively. 4. Constraint on Reflexive Pronoun: A reflexive pronoun such as himself, herself, etc must refer to the subject or the</context>
<context position="12350" citStr="Mitkov, 1999" startWordPosition="2066" endWordPosition="2067">sitional NP (Lappin and Leass, 1994): This heuristic states that a noun phrase which occurs within a prepositional phrase is less probable to be an antecedent to an anaphor and consequently, it is awarded less credibility. 3. Pleonastic (Lappin and Leass, 1994): This heuristic is based on the observation that there exist some syntactic patterns such that every it anaphor occurring in any of those patterns must be pleonastic. 4. Syntactic Parallelism (Lappin and Leass, 1994): As per this heuristic, preference is given to noun phrases with the same syntactic function as the anaphor. 5. Recency (Mitkov, 1999): This is a very simple heuristic according to which, everything else being comparable, a higher credibility is awarded to the antecedent nearer to the anaphor. 6. Semantic Parallelism (Lappin and Leass, 1994): This heuristic gives preference to those noun phrases which have the same semantic role as the anaphor in question. This is a useful heuristic and can be implemented by a system that can identify semantic roles. 7. Pragmatic Heuristics: We use certain pragmatic heuristics that we have identified to be very specific to dialogue settings. These are of the following kinds • If one speaker </context>
<context position="15500" citStr="Mitkov, 1999" startWordPosition="2586" endWordPosition="2587">. B. Shaw Our System gave nearly 65% accuracy on Shaw’s plays and almost 80% accuracy on our own “hand crafted” dialogues [Table:1]. In the table, the name “hand-crafted dialogues” refers to sample dialogues that the authors wrote themselves to test the performance of the system. The genetic algorithms that we use help in fine-tuning weights according to the particular corpus, and show appreciable increase in accuracy. 4 Conclusions We have implemented an automatic, knowledge-based anaphora resolution system that works for dialogic discourses. The lack of availability of any standard corpora (Mitkov, 1999) is a major drawback in case of anaphora resolution systems in general and those for dialogues in particular. The original contribution of this system is mainly two-fold. First, the anaphora resolution system that we have implemented uses an innovative graph technique, based on the idea of anaphora chaining, that makes it possible to resolve such references as cataphora and plural anaphora. Secondly, we give an algorithm which uses naive character building to apply various semantic and world-knowledge based heuristics to the process of anaphora resolution. The results obtained from the system </context>
</contexts>
<marker>Mitkov, 1999</marker>
<rawString>R. Mitkov. 1999. Anaphora Resolution: The State of the Art. Working paper (Based on the COLING’98/ACL’98 tutorial on anaphora resolution).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Combining sample selection and error-driven pruning for machine learning of coreference rules.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2196" citStr="Ng and Cardie, 2002" startWordPosition="329" endWordPosition="332">ars to achieve partial solutions to the problem. The pioneering work in the area of anaphora resolution was done by Hobbs (Jerry R. Hobbs, 1978) who designed several early syntactic and semantic heuristics for the same. (Hirst, 1981) discusses several early approaches to anaphora resolution in discourses. (Denber, 1998) and (Lappin and Leass, 1994) describe several syntactic heuristics for reflexive, reciprocal and pleonastic anaphora, among others. Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998). (Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Few systems have been developed that are specifically aimed at the task of anaphora resolution in discourses. ROSANA, an algorithm for anaphora resolution that focuses on robustness against information deficiency in the parsed output, is described in (Stuckardt, 2001). MA</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Combining sample selection and error-driven pruning for machine learning of coreference rules. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Stuckardt</author>
</authors>
<title>Design and Enhanced Evaluation of a Robust Anaphor Resolution Algorithm.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="2792" citStr="Stuckardt, 2001" startWordPosition="420" endWordPosition="421">Ng and Cardie, 2002) proposes a machine learning approach to Anaphora Resolution but generally statistical learning approaches suffer from the problems of small corpuses and corpus dependent learning. A more general and comprehensive overview of state-of-the-art in anaphora resolution is given in (Mitkov, 1999) and also in (Mitkov et al., 2001). Few systems have been developed that are specifically aimed at the task of anaphora resolution in discourses. ROSANA, an algorithm for anaphora resolution that focuses on robustness against information deficiency in the parsed output, is described in (Stuckardt, 2001). MARS, the Mitkov Anaphora Resolution System, is another automatic, knowledge-poor anaphora resolution system that has been implemented for several languages including English, Bulgarian and Japanese. In this paper, we describe the design and implementation of Jepthah1, a rule-based system for resolving a wide variety of anaphora occurring in multi-person dialogues in English. In this system, we integrate several different knowledge-poor constraints and heuristics, and operate them over a naive character model of the entire dialogue to perform effective anaphora resolution. In addition to usi</context>
</contexts>
<marker>Stuckardt, 2001</marker>
<rawString>Roland Stuckardt. 2001. Design and Enhanced Evaluation of a Robust Anaphor Resolution Algorithm. Computational Linguistics, 27(4):479–506, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>