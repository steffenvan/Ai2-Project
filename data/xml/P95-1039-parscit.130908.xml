<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006560">
<title confidence="0.984636">
Tagset Reduction Without Information Loss
</title>
<author confidence="0.972409">
Thorsten Brants
</author>
<affiliation confidence="0.7406655">
Universitat des Saarlandes
Computerlinguistik
</affiliation>
<address confidence="0.5025">
D-66041 Saarbriicken, Germany
</address>
<email confidence="0.766222">
thorstenOcoli.uni—sb.de
</email>
<sectionHeader confidence="0.983262" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999974">
A technique for reducing a tagset used
for n-gram part-of-speech disambiguation
is introduced and evaluated in an experi-
ment. The technique ensures that all in-
formation that is provided by the original
tagset can be restored from the reduced
one. This is crucial, since we are intere-
sted in the linguistically motivated tags for
part-of-speech disambiguation. The redu-
ced tagset needs fewer parameters for its
statistical model and allows more accurate
parameter estimation. Additionally, there
is a slight but not significant improvement
of tagging accuracy.
</bodyText>
<sectionHeader confidence="0.990022" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999965136363636">
Statistical part-of-speech disambiguation can be ef-
ficiently done with n-gram models (Church, 1988;
Cutting et al., 1992). These models are equivalent
to Hidden Markov Models (HMMs) (Rabiner, 1989)
of order n — 1. The states represent parts of speech
(categories, tags), there is exactly one state for each
category, and each state outputs words of a particu-
lar category. The transition and output probabilities
of the HMM are derived from smoothed frequency
counts in a text corpus.
Generally, the categories for part-of-speech tag-
ging are linguistically motivated and do not reflect
the probability distributions or co-occurrence pro-
babilities of words belonging to that category. It is
an implicit assumption for statistical part-of-speech
tagging that words belonging to the same category
have similar probability distributions. But this as-
sumption does not hold in many of the cases.
Take for example the word cliff which could be a
proper (NP)&apos; or a common noun (NN) (ignoring ca-
pitalization of proper nouns for the moment). The
two previous words are a determiner (AT) and an
</bodyText>
<footnote confidence="0.5438655">
&apos;All tag names used in this paper are inspired by
those used for the LOB Corpus (Garside et al., 1987).
</footnote>
<bodyText confidence="0.99993875862069">
adjective (11). The probability of cliff being a com-
mon noun is the product of the respective contextual
and lexical probabilities p(NNIAT, JJ) • p(cliff INN),
regardless of other information provided by the ac-
tual words (a sheer cliff vs. Me wise Cliff). Obvi-
ously, information useful for probability estimation
is not encoded in the tagset.
On the other hand, in some cases information not
needed for probability estimation is encoded in the
tagset. The distributions for comparative and su-
perlative forms of adjectives in the Susanne Corpus
(Sampson, 1995) are very similar. The number of
correct tag assignments is not affected when we com-
bine the two categories. However, it does not suffice
to assign the combined tag, if we are interested in
the distinction between comparative and superlative
form for further processing. We have to ensure that
the original (interesting) tag can be restored.
There are two contradicting requirements. On the
one hand, more tags mean that there is more infor-
mation about a word at hand, on the other hand,
the more tags, the severer the sparse-data problem
is and the larger the corpora that are needed for
training.
This paper presents a way to modify a given tag-
set, such that categories with similar distributions
in a corpus are combined without losing information
provided by the original tagset and without losing
accuracy.
</bodyText>
<subsectionHeader confidence="0.556789">
2 Clustering of Tags
</subsectionHeader>
<bodyText confidence="0.999986583333333">
The aim of the presented method is to reduce a tag-
set as much as possible by combining (clustering)
two or more tags without losing information and wi-
thout losing accuracy. The fewer tags we have, the
less parameters have to be estimated and stored, and
the less severe is the sparse data problem. Incoming
text will be disambiguated with the new reduced
tagset, but we ensure that the original tag is still
uniquely ide,itified by the new tag.
The basic idea is to exploit the fact that some of
the categories have a very similar frequency distri-
bution in a corpus. If we combine categories with
</bodyText>
<page confidence="0.976758">
287
</page>
<bodyText confidence="0.9999924">
similar distribution characteristics, there should be
only a small change in the tagging result. The main
change is that single tags are replaced by a cluster
of tags, from which the original has to be identified.
First experiments with tag clustering showed that,
even for fully automatic identification of the original
tag, tagging accuracy slightly increased when the re-
duced tagset was used. This might be a result of ha-
ving more occurrences per tag for a smaller tagset,
and probability estimates are preciser.
</bodyText>
<subsectionHeader confidence="0.94007">
2.1 Unique Identification of Original Tags
</subsectionHeader>
<bodyText confidence="0.999967222222222">
A crucial property of the reduced tagset is that the
original tag information can be restored from the
new tag, since this is the information we are intere-
sted in. The property can be ensured if we place a
constraint on the clustering of tags.
Let W be the set of words, C the set of clusters
(i.e. the reduced tagset), and T the original tagset.
To restore the original tag from a combined tag (clu-
ster), we need a unique function
</bodyText>
<equation confidence="0.365687">
forig : W X C 1—+ T (1)
</equation>
<bodyText confidence="0.999814">
To ensure that there is such a unique function,
we prohibit some of the possible combinations. A
cluster is allowed if and only if there is no word in the
lexicon which can have two or more of the original
tags combined in one cluster. Formally, seeing tags
as sets of words and clusters as sets of tags:
</bodyText>
<equation confidence="0.848458">
VcEC,ti,t2 Ec,tiOt2,wEW: wEti
(2)
</equation>
<bodyText confidence="0.9057005">
If this condition holds, then for all words w tagged
with a cluster c, exactly one tag 4,, fulfills
w E twc Atu„ E c,
yielding
forig(w, = twc.
So, the original tag can be restored any time and no
information from the original tagset is lost.
Example: Assume that no word in the lexicon can
be both comparative (JJ R) and superlative adjective
(JJT). The categories are combined to {JJR,JJ-1}.
When processing a text, the word easier is tagged
as {.1.1R,JJT}. Since the lexicon states that easier
can be of category JJR but not of category JJT, the
original tag must be JJ R.
</bodyText>
<subsectionHeader confidence="0.81674">
2.2 Criteria For Combining Tags
</subsectionHeader>
<bodyText confidence="0.9902535">
The are several criteria that can determine the qua-
lity of a particular clustering.
</bodyText>
<listItem confidence="0.998078111111111">
1. Compare the trigram probabilities p(BIXi, A),
p(BIA, Xi), and p(XilA, B), i = 1,2. Combine
two tags X1 and X2, if these probabilities coin-
cide to a certain extent.
2. Maximize the probability that the training cor-
pus is generated by the HMM which is described
by the trigram probabilities.
3. Maximize the tagging accuracy for a training
corpus.
</listItem>
<bodyText confidence="0.9995205">
Criterion (1) establishes the theoretical basis,
while criteria (2) and (3) immediately show the be-
nefit of a particular combination. A measure of si-
milarity for (1) is currently under investigation. We
chose (3) for our first experiments, since it was the
easiest one to implement. The only additional ef-
fort is a separate, previously unused part of the trai-
ning corpus for this purpose, the clustering part. We
combine those tags into clusters which give the best
results for tagging of the clustering part.
</bodyText>
<subsectionHeader confidence="0.989723">
2.3 The Algorithm
</subsectionHeader>
<bodyText confidence="0.999574882352941">
The total number of potential clusterings grows ex-
ponential with the size of the tagset. Since we are
interested in the reduction of large tagsets, a full
search regarding all potential clusterings is not fea-
sible. We compute the local maximum which can be
found in polynomial time with a best-first search.
We use a slight modification of the algorithm
used by (Stolcke and Omohundro, 1994) for merging
HMMs. Our task is very similar to theirs. Stolcke
and Omohundro start with a first order HMM where
every state represents a single occurrence of a word
in a corpus, and the goal is to maximize the a po-
steriori probability of the model. We start with a
second order HMM (since we use trigrams) where
each state represents a part of speech, and our goal
is to maximize the tagging accuracy for a corpus.
The clustering algorithm works as follows:
</bodyText>
<listItem confidence="0.9907469375">
1. Compute tagging accuracy for the clustering
part with the original tagset.
2. Loop:
(a) Compute a set of candidate clusters (obey-
ing constraint (2) mentioned in section
2.1), each consisting of two tags from the
pre 4ous step.
(b) For each candidate cluster build the resul-
ting tagset and compute tagging accuracy
for that tagset.
(c) If tagging accuracy decreases for all combi-
nations of tags, break from the loop.
(d) Add the cluster which maximized the tag-
ging accuracy to the tagset and remove the
two tags previously used.
3. Output the resulting tagset.
</listItem>
<subsectionHeader confidence="0.983775">
2.4 Application of Tag Clustering
</subsectionHeader>
<bodyText confidence="0.999904625">
Two standard trigram tagging procedures were
performed as the baseline. Then clustering was per-
formed on the same data and tagging was done with
the reduced tagset. The reduced tagset was only in-
ternally used, the output of the tagger consisted of
the original tagset for all experiments.
The Susanne Corpus has about 157,000 words and
uses 424 tags (counting tags with indices denoting
</bodyText>
<page confidence="0.998819">
288
</page>
<tableCaption confidence="0.942489">
Table 1: Tagging results for the test parts in the clustering experiments. Exp. 1 and 2 are used as the
baseline.
</tableCaption>
<bodyText confidence="0.986627475">
Training Clustering Testing Result (known words)
parts A and B — part C 93.7% correct
parts A and C — part B 94.6% correct
part A part B part C 93.9% correct
part A part C part B 94.7% correct
multi-word lexemes as separate tags). The tags are
based on the LOB tagset (Garside et al., 1987).
Three parts are taken from the corpus. Part A
consists of about 127,000 words, part B of about
10,000 words, and part C of about 10,000 words.
The rest of the corpus, about 10,000 words, is not
used for this experiment. All parts are mutually
disjunct.
First, part A and B were used for training, and
part C for testing. Then, part A and C were used
for training, and part B for testing. About 6% of the
words in the test parts did not occur in the training
parts, i.e. they are unknown. For the moment we
only care about the known words and not about the
unknown words (this is treated as a separate pro-
blem). Table 1 shows the tagging results for known
words.
Clustering was applied in the next steps. In the
third experiment, part A was used for trigram trai-
ning, part B for clustering and part C for testing. In
the fourth experiment, part A was used for trigram
training, part C for clustering and part B for testing.
The baseline experiments used the clustering part
for the normal training procedure to ensure that bet-
ter performance in the clustering experiments is not
due to information provided by the additional part.
Clustering reduced the tagset by 33 (third exp.),
and 31 (fourth exp.) tags. The tagging results for
the known words are shown in table 1.
The improvement in the tagging result is too small
to be significant. However, the tagset is reduced,
thus also reducing the number of parameters without
losing accuracy. Experiments with larger texts and
more permutations will be performed to get precise
results for the improvement.
</bodyText>
<sectionHeader confidence="0.999572" genericHeader="conclusions">
3 Conclusions
</sectionHeader>
<bodyText confidence="0.999995">
We have shown a method for reducing a tagset used
for part-of-speech tagging without losing informa-
tion given by the original tagset. In a first expe-
riment, we were able to reduce a large tagset and
needed fewer parameters for the n-gram model. Ad-
ditionally, tagging accuracy slightly increased, but
the improvement was not significant. Further inve-
stigation will focus on criteria for cluster selection.
Can we use a similarity measure of probability dis-
tributions to identify optimal clusters? How far can
we reduce the tagset without losing accuracy?
</bodyText>
<sectionHeader confidence="0.999414" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998541208333333">
Kenneth Ward Church. 1988. A stochastic parts
program and noun phrase parser for unrestricted
text. In Proc. Second Conference on Applied Na-
tural Language Processing, pages 136-143, Austin,
Texas, USA.
Doug Cutting, Julian Kupiec, Jan Pedersen, and Pe-
nelope Sibun. 1992. A practical part-of-speech
tagger. In Proceedings of the 3rd Conference on
Applied Natural Language Processing (ACL), pa-
ges 133-140.
R. G. Garside, G. N. Leech, and G. It. Sampson
(eds.). 1987. The Computational Analysis of Eng-
lish. Longman.
L. R. Rabiner. 1989. A tutorial on hidden markov
models and selected applications in speech reco-
gnition. In Proceedings of the IEEE, volume 77(2),
pages 257-285.
Geoffrey Sampson. 1995. English for the Computer.
Oxford University Press, Oxford.
Andreas Stolcke and Stephen M. Omohundro. 1994.
Best-first model merging for hidden markov mo-
del induction. Technical Report TR-94-003, In-
ternational Computer Science Institute, Berkeley,
California, USA.
</reference>
<page confidence="0.998634">
289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.021749">
<title confidence="0.99985">Tagset Reduction Without Information Loss</title>
<author confidence="0.996987">Thorsten Brants</author>
<affiliation confidence="0.9319525">Universitat des Saarlandes Computerlinguistik</affiliation>
<address confidence="0.984662">D-66041 Saarbriicken, Germany</address>
<email confidence="0.999063">thorstenOcoli.uni—sb.de</email>
<abstract confidence="0.997964565040651">A technique for reducing a tagset used for n-gram part-of-speech disambiguation is introduced and evaluated in an experiment. The technique ensures that all information that is provided by the original tagset can be restored from the reduced one. This is crucial, since we are interested in the linguistically motivated tags for part-of-speech disambiguation. The reduced tagset needs fewer parameters for its statistical model and allows more accurate parameter estimation. Additionally, there is a slight but not significant improvement of tagging accuracy. 1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al., 1992). These models are equivalent Hidden Markov Models 1989) of order n — 1. The states represent parts of speech tags), is exactly one state for each category, and each state outputs words of a particular category. The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus. Generally, the categories for part-of-speech tagging are linguistically motivated and do not reflect the probability distributions or co-occurrence probabilities of words belonging to that category. It is an implicit assumption for statistical part-of-speech tagging that words belonging to the same category have similar probability distributions. But this assumption does not hold in many of the cases. for example the word could be a proper (NP)&apos; or a common noun (NN) (ignoring capitalization of proper nouns for the moment). The two previous words are a determiner (AT) and an tag used in this paper are inspired by those used for the LOB Corpus (Garside et al., 1987). (11). The probability of a common noun is the product of the respective contextual lexical probabilities p(NNIAT, JJ) • regardless of other information provided by the acwords (a cliff vs. Me wise Cliff). Obviously, information useful for probability estimation is not encoded in the tagset. the other hand, in some cases information needed for probability estimation is encoded in the tagset. The distributions for comparative and superlative forms of adjectives in the Susanne Corpus (Sampson, 1995) are very similar. The number of tag assignments is when we combine the two categories. However, it does not suffice to assign the combined tag, if we are interested in the distinction between comparative and superlative form for further processing. We have to ensure that the original (interesting) tag can be restored. There are two contradicting requirements. On the one hand, more tags mean that there is more information about a word at hand, on the other hand, the more tags, the severer the sparse-data problem is and the larger the corpora that are needed for training. This paper presents a way to modify a given tagset, such that categories with similar distributions in a corpus are combined without losing information provided by the original tagset and without losing accuracy. 2 Clustering of Tags The aim of the presented method is to reduce a tagas much as possible by combining two or more tags without losing information and without losing accuracy. The fewer tags we have, the less parameters have to be estimated and stored, and the less severe is the sparse data problem. Incoming text will be disambiguated with the new reduced tagset, but we ensure that the original tag is still by the new tag. The basic idea is to exploit the fact that some of the categories have a very similar frequency distribution in a corpus. If we combine categories with 287 similar distribution characteristics, there should be only a small change in the tagging result. The main change is that single tags are replaced by a cluster of tags, from which the original has to be identified. First experiments with tag clustering showed that, even for fully automatic identification of the original tag, tagging accuracy slightly increased when the reduced tagset was used. This might be a result of having more occurrences per tag for a smaller tagset, and probability estimates are preciser. 2.1 Unique Identification of Original Tags A crucial property of the reduced tagset is that the original tag information can be restored from the new tag, since this is the information we are interested in. The property can be ensured if we place a constraint on the clustering of tags. W be the set of words, set of clusters the reduced tagset), and original tagset. restore the original tag from a combined tag (cluneed a unique function : W X C 1—+ T (1) To ensure that there is such a unique function, we prohibit some of the possible combinations. A cluster is allowed if and only if there is no word in the lexicon which can have two or more of the original tags combined in one cluster. Formally, seeing tags as sets of words and clusters as sets of tags: Ec,tiOt2,wEW: wEti (2) If this condition holds, then for all words w tagged a cluster one tag E twc E yielding = So, the original tag can be restored any time and no information from the original tagset is lost. Example: Assume that no word in the lexicon can be both comparative (JJ R) and superlative adjective The categories are combined to processing a text, the word tagged {.1.1R,JJT}. Since the lexicon states that of category JJR but not of category JJT, the original tag must be JJ R. 2.2 Criteria For Combining Tags The are several criteria that can determine the quality of a particular clustering. Compare the trigram probabilities A), Xi), B), i = Combine tags and these probabilities coincide to a certain extent. 2. Maximize the probability that the training corpus is generated by the HMM which is described by the trigram probabilities. 3. Maximize the tagging accuracy for a training corpus. Criterion (1) establishes the theoretical basis, while criteria (2) and (3) immediately show the benefit of a particular combination. A measure of similarity for (1) is currently under investigation. We chose (3) for our first experiments, since it was the easiest one to implement. The only additional effort is a separate, previously unused part of the traicorpus for this purpose, the We combine those tags into clusters which give the best results for tagging of the clustering part. 2.3 The Algorithm The total number of potential clusterings grows exponential with the size of the tagset. Since we are interested in the reduction of large tagsets, a full search regarding all potential clusterings is not feasible. We compute the local maximum which can be found in polynomial time with a best-first search. We use a slight modification of the algorithm used by (Stolcke and Omohundro, 1994) for merging HMMs. Our task is very similar to theirs. Stolcke and Omohundro start with a first order HMM where every state represents a single occurrence of a word in a corpus, and the goal is to maximize the a posteriori probability of the model. We start with a second order HMM (since we use trigrams) where each state represents a part of speech, and our goal is to maximize the tagging accuracy for a corpus. The clustering algorithm works as follows: 1. Compute tagging accuracy for the clustering part with the original tagset. 2. Loop: (a) Compute a set of candidate clusters (obeying constraint (2) mentioned in section 2.1), each consisting of two tags from the pre 4ous step. (b) For each candidate cluster build the resulting tagset and compute tagging accuracy for that tagset. If tagging accuracy decreases for combinations of tags, break from the loop. (d) Add the cluster which maximized the tagging accuracy to the tagset and remove the two tags previously used. 3. Output the resulting tagset. 2.4 Application of Tag Clustering Two standard trigram tagging procedures were performed as the baseline. Then clustering was performed on the same data and tagging was done with the reduced tagset. The reduced tagset was only internally used, the output of the tagger consisted of the original tagset for all experiments. The Susanne Corpus has about 157,000 words and uses 424 tags (counting tags with indices denoting 288 1: Tagging results for the test parts in the clustering experiments. Exp. and are used as the baseline. Training Clustering Testing Result (known words) parts A and B — part C 93.7% correct parts A and C — part B 94.6% correct part A part B part C 93.9% correct part A part C part B 94.7% correct multi-word lexemes as separate tags). The tags are based on the LOB tagset (Garside et al., 1987). Three parts are taken from the corpus. Part A consists of about 127,000 words, part B of about 10,000 words, and part C of about 10,000 words. The rest of the corpus, about 10,000 words, is not used for this experiment. All parts are mutually disjunct. First, part A and B were used for training, and part C for testing. Then, part A and C were used for training, and part B for testing. About 6% of the words in the test parts did not occur in the training parts, i.e. they are unknown. For the moment we only care about the known words and not about the unknown words (this is treated as a separate problem). Table 1 shows the tagging results for known words. Clustering was applied in the next steps. In the third experiment, part A was used for trigram training, part B for clustering and part C for testing. In the fourth experiment, part A was used for trigram training, part C for clustering and part B for testing. The baseline experiments used the clustering part for the normal training procedure to ensure that better performance in the clustering experiments is not due to information provided by the additional part. Clustering reduced the tagset by 33 (third exp.), and 31 (fourth exp.) tags. The tagging results for the known words are shown in table 1. The improvement in the tagging result is too small to be significant. However, the tagset is reduced, also reducing the number of parameters losing accuracy. Experiments with larger texts and more permutations will be performed to get precise results for the improvement. 3 Conclusions We have shown a method for reducing a tagset used for part-of-speech tagging without losing information given by the original tagset. In a first experiment, we were able to reduce a large tagset and needed fewer parameters for the n-gram model. Additionally, tagging accuracy slightly increased, but improvement significant. Further investigation will focus on criteria for cluster selection. Can we use a similarity measure of probability distributions to identify optimal clusters? How far can we reduce the tagset without losing accuracy?</abstract>
<note confidence="0.3603298">References Ward Church. 1988. parts program and noun phrase parser for unrestricted In Second Conference on Applied Na- Language Processing, 136-143, Austin,</note>
<address confidence="0.990486">Texas, USA.</address>
<author confidence="0.65464">Doug Cutting</author>
<author confidence="0.65464">Julian Kupiec</author>
<author confidence="0.65464">Jan Pedersen</author>
<author confidence="0.65464">Pe-</author>
<abstract confidence="0.918393875">nelope Sibun. 1992. A practical part-of-speech In of the 3rd Conference on Natural Language Processing (ACL), pages 133-140. R. G. Garside, G. N. Leech, and G. It. Sampson 1987. Computational Analysis of Eng- L. R. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech reco-</abstract>
<note confidence="0.944736714285714">In of the IEEE, 77(2), pages 257-285. Sampson. 1995. for the Computer. Oxford University Press, Oxford. Andreas Stolcke and Stephen M. Omohundro. 1994. Best-first model merging for hidden markov moinduction. Report TR-94-003, In-</note>
<affiliation confidence="0.986696">ternational Computer Science Institute, Berkeley,</affiliation>
<address confidence="0.7144055">California, USA. 289</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In Proc. Second Conference on Applied Natural Language Processing,</booktitle>
<pages>136--143</pages>
<location>Austin, Texas, USA.</location>
<contexts>
<context position="838" citStr="Church, 1988" startWordPosition="114" endWordPosition="115">peech disambiguation is introduced and evaluated in an experiment. The technique ensures that all information that is provided by the original tagset can be restored from the reduced one. This is crucial, since we are interested in the linguistically motivated tags for part-of-speech disambiguation. The reduced tagset needs fewer parameters for its statistical model and allows more accurate parameter estimation. Additionally, there is a slight but not significant improvement of tagging accuracy. 1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al., 1992). These models are equivalent to Hidden Markov Models (HMMs) (Rabiner, 1989) of order n — 1. The states represent parts of speech (categories, tags), there is exactly one state for each category, and each state outputs words of a particular category. The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus. Generally, the categories for part-of-speech tagging are linguistically motivated and do not reflect the probability distributions or co-occurrence probabilities of words belonging to that category. It is an implic</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Kenneth Ward Church. 1988. A stochastic parts program and noun phrase parser for unrestricted text. In Proc. Second Conference on Applied Natural Language Processing, pages 136-143, Austin, Texas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Cutting</author>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Penelope Sibun</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd Conference on Applied Natural Language Processing (ACL),</booktitle>
<pages>133--140</pages>
<contexts>
<context position="861" citStr="Cutting et al., 1992" startWordPosition="116" endWordPosition="119">uation is introduced and evaluated in an experiment. The technique ensures that all information that is provided by the original tagset can be restored from the reduced one. This is crucial, since we are interested in the linguistically motivated tags for part-of-speech disambiguation. The reduced tagset needs fewer parameters for its statistical model and allows more accurate parameter estimation. Additionally, there is a slight but not significant improvement of tagging accuracy. 1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al., 1992). These models are equivalent to Hidden Markov Models (HMMs) (Rabiner, 1989) of order n — 1. The states represent parts of speech (categories, tags), there is exactly one state for each category, and each state outputs words of a particular category. The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus. Generally, the categories for part-of-speech tagging are linguistically motivated and do not reflect the probability distributions or co-occurrence probabilities of words belonging to that category. It is an implicit assumption for stati</context>
</contexts>
<marker>Cutting, Kupiec, Pedersen, Sibun, 1992</marker>
<rawString>Doug Cutting, Julian Kupiec, Jan Pedersen, and Penelope Sibun. 1992. A practical part-of-speech tagger. In Proceedings of the 3rd Conference on Applied Natural Language Processing (ACL), pages 133-140.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R G Garside</author>
<author>G N Leech</author>
<author>G It</author>
</authors>
<booktitle>The Computational Analysis of English.</booktitle>
<publisher>Longman.</publisher>
<marker>Garside, Leech, It, </marker>
<rawString>R. G. Garside, G. N. Leech, and G. It. Sampson (eds.). 1987. The Computational Analysis of English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>In Proceedings of the IEEE,</booktitle>
<volume>77</volume>
<issue>2</issue>
<pages>257--285</pages>
<contexts>
<context position="937" citStr="Rabiner, 1989" startWordPosition="129" endWordPosition="130"> information that is provided by the original tagset can be restored from the reduced one. This is crucial, since we are interested in the linguistically motivated tags for part-of-speech disambiguation. The reduced tagset needs fewer parameters for its statistical model and allows more accurate parameter estimation. Additionally, there is a slight but not significant improvement of tagging accuracy. 1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al., 1992). These models are equivalent to Hidden Markov Models (HMMs) (Rabiner, 1989) of order n — 1. The states represent parts of speech (categories, tags), there is exactly one state for each category, and each state outputs words of a particular category. The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus. Generally, the categories for part-of-speech tagging are linguistically motivated and do not reflect the probability distributions or co-occurrence probabilities of words belonging to that category. It is an implicit assumption for statistical part-of-speech tagging that words belonging to the same category have</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L. R. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings of the IEEE, volume 77(2), pages 257-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
</authors>
<title>English for the Computer.</title>
<date>1995</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="2486" citStr="Sampson, 1995" startWordPosition="383" endWordPosition="384"> those used for the LOB Corpus (Garside et al., 1987). adjective (11). The probability of cliff being a common noun is the product of the respective contextual and lexical probabilities p(NNIAT, JJ) • p(cliff INN), regardless of other information provided by the actual words (a sheer cliff vs. Me wise Cliff). Obviously, information useful for probability estimation is not encoded in the tagset. On the other hand, in some cases information not needed for probability estimation is encoded in the tagset. The distributions for comparative and superlative forms of adjectives in the Susanne Corpus (Sampson, 1995) are very similar. The number of correct tag assignments is not affected when we combine the two categories. However, it does not suffice to assign the combined tag, if we are interested in the distinction between comparative and superlative form for further processing. We have to ensure that the original (interesting) tag can be restored. There are two contradicting requirements. On the one hand, more tags mean that there is more information about a word at hand, on the other hand, the more tags, the severer the sparse-data problem is and the larger the corpora that are needed for training. T</context>
</contexts>
<marker>Sampson, 1995</marker>
<rawString>Geoffrey Sampson. 1995. English for the Computer. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Stephen M Omohundro</author>
</authors>
<title>Best-first model merging for hidden markov model induction.</title>
<date>1994</date>
<tech>Technical Report TR-94-003,</tech>
<institution>International Computer Science Institute,</institution>
<location>Berkeley, California, USA.</location>
<contexts>
<context position="7233" citStr="Stolcke and Omohundro, 1994" startWordPosition="1209" endWordPosition="1212"> additional effort is a separate, previously unused part of the training corpus for this purpose, the clustering part. We combine those tags into clusters which give the best results for tagging of the clustering part. 2.3 The Algorithm The total number of potential clusterings grows exponential with the size of the tagset. Since we are interested in the reduction of large tagsets, a full search regarding all potential clusterings is not feasible. We compute the local maximum which can be found in polynomial time with a best-first search. We use a slight modification of the algorithm used by (Stolcke and Omohundro, 1994) for merging HMMs. Our task is very similar to theirs. Stolcke and Omohundro start with a first order HMM where every state represents a single occurrence of a word in a corpus, and the goal is to maximize the a posteriori probability of the model. We start with a second order HMM (since we use trigrams) where each state represents a part of speech, and our goal is to maximize the tagging accuracy for a corpus. The clustering algorithm works as follows: 1. Compute tagging accuracy for the clustering part with the original tagset. 2. Loop: (a) Compute a set of candidate clusters (obeying constr</context>
</contexts>
<marker>Stolcke, Omohundro, 1994</marker>
<rawString>Andreas Stolcke and Stephen M. Omohundro. 1994. Best-first model merging for hidden markov model induction. Technical Report TR-94-003, International Computer Science Institute, Berkeley, California, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>