<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059017">
<title confidence="0.975696">
UvT: The UvT Term Extraction System in the Keyphrase Extraction task
</title>
<author confidence="0.814104">
Kalliopi Zervanou
</author>
<affiliation confidence="0.8543845">
ILK / TiCC - Tilburg centre for Cognition and Communication
University of Tilburg, P.O. Box 90153, 5000 LE Tilburg, The Netherlands
</affiliation>
<email confidence="0.986054">
K.Zervanou@uvt.nl
</email>
<sectionHeader confidence="0.993644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999479">
The UvT system is based on a hybrid, lin-
guistic and statistical approach, originally
proposed for the recognition of multi-
word terminological phrases, the C-value
method (Frantzi et al., 2000). In the UvT
implementation, we use an extended noun
phrase rule set and take into consideration
orthographic and morphological variation,
term abbreviations and acronyms, and ba-
sic document structure information.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980642857142">
The increasing amount of documents in elec-
tronic form makes imperative the need for docu-
ment content classification and semantic labelling.
Keyphrase extraction contributes to this goal by
the identification of important and discriminative
concepts expressed as keyphrases. Keyphrases
as reduced document content representations may
find applications in document retrieval, classifica-
tion and summarisation (D’Avanzo and Magnini,
2005). The literature distinguishes between two
principal processes: keyphrase extraction and
keyphrase assignment. In the case of keyphrase
assignment, suitable keyphrases from an exist-
ing knowledge resource, such as a controlled vo-
cabulary, or a thesaurus are assigned to docu-
ments based on classification of their content. In
keyphrase extraction, the phrases are mined from
the document itself. Supervised approaches to
the problem of keyphrase extraction include the
Naive Bayes-based KEA algorithms (Gordon et
al., 1999) (Medelyan and Witten, 2006), deci-
sion tree-based and the genetic algorithm-based
GenEx (Turney, 1999), and the probabilistic KL
divergence-based language model (Tomokiyo and
Hurst, 2003). Research in keyphrase extrac-
tion proposes the detection of keyphrases based
on various statistics-based, or pattern-based fea-
tures. Statistical measures investigated focus pri-
marily on keyphrase frequency measures, whereas
pattern-features include noun phrase pattern filter-
ing, identification of keyphrase head and respec-
tive frequencies (Barker and Cornacchia, 2000),
document section position of the keyphrase (e.g.,
(Medelyan and Witten, 2006)) and keyphrase
coherence (Turney, 2003). In this paper, we
present an unsupervised approach which combines
pattern-based morphosyntactic rules with a statis-
tical measure, the C-value measure (Frantzi et al.,
2000) which originates from research in the field
of automatic term recognition and was initially de-
signed for specialised domain terminology acqui-
sition.
</bodyText>
<sectionHeader confidence="0.917286" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999960125">
The input documents in the Keyphrase Extrac-
tion task were scientific articles converted from
their originally published form to plain text.
Due to this process, some compound hyphen-
ated words are erroneously converted into a single
word (e.g., “resourcemanagement” vs. “resource-
management”). Moreover, document sections
such as tables, figures, footnotes, headers and foot-
ers, often intercept sentence and paragraph text.
Finally, due to the particularity of the scientific ar-
ticles domain, input documents often contain ir-
regular text, such as URLs, inline bibliographic
references, mathematical formulas and symbols.
In our approach, we attempted to address some
of these issues by document structuring, treatment
of orthographic variation and filtering of irregular
text.
The approach adopted first applies part-of-
speech tagging and basic document structuring
(sec. 2.1 and 2.2). Subsequently, keyphrase can-
didates conforming to pre-defined morphosyntac-
tic rule patterns are identified (sec. 2.3). In
the next stage, orthographic, morphological and
abbreviation variation phenomena are addressed
</bodyText>
<page confidence="0.98337">
194
</page>
<bodyText confidence="0.8286966">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 194–197,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
(sec. 2.4) and, finally, candidate keyphrases are
selected based on C-value statistical measure (sec.
2.5).
</bodyText>
<subsectionHeader confidence="0.994044">
2.1 Linguistic pre-processing
</subsectionHeader>
<bodyText confidence="0.999970428571428">
For morphosyntactic analysis, we used the Maxent
(Ratnaparkhi, 1996) POS tagger implementation
of the openNLP toolsuite1. In order to improve
tagging accuracy, irregular text, such as URLs,
inline references, and recurrent patterns indicat-
ing footers and mathematical formulas are filtered
prior to tagging.
</bodyText>
<subsectionHeader confidence="0.999155">
2.2 Basic document structuring
</subsectionHeader>
<bodyText confidence="0.9999388">
Document structuring is based on identified re-
current patterns, such as common section titles
and legend indicators (e.g., “Abstract”, “Table...”),
section headers numbering and preserved format-
ting, such as newline characters. Thus, the doc-
ument sections that the system may recognise
are: Title, Abstract, Introduction, Conclusion,
Acknowledgements, References, Header (for any
other section headers and legends) and Main (for
any other document section text).
</bodyText>
<subsectionHeader confidence="0.999707">
2.3 Rule pattern filtering
</subsectionHeader>
<bodyText confidence="0.999609">
The UvT system considers as candidate
keyphrases, those multi-word noun phrases
conforming to pre-defined morphosyntactic rule
patterns. In particular, the patterns considered are:
</bodyText>
<construct confidence="0.55022875">
M+ N
MCMN
M+NCN
NPM*N
NPM*NCN
NCNPM* N
MCMN
M+NCN
</construct>
<bodyText confidence="0.999718666666667">
where M is a modifier, such as an adjective, a
noun, a present or past participle, or a proper noun
including a possessive ending, N is a noun, P a
preposition and C a conjunction. For every sen-
tence input, the matching process is exhaustive:
after the longest valid match is identified, the rules
</bodyText>
<footnote confidence="0.918596">
1http://opennlp.sourceforge.net/
</footnote>
<bodyText confidence="0.9996948">
are re-applied, so as to identify all possible shorter
valid matches for nested noun phrases. At this
stage, the rules also allow for inclusion of poten-
tial abbreviations and acronyms in the identified
noun phrase of the form:
</bodyText>
<equation confidence="0.6979515">
M+ (A) N
M+ N (A)
</equation>
<bodyText confidence="0.998651">
where (A) is a potential acronym appearing as a
single token in uppercase, enclosed by parentheses
and tagged as a proper noun.
</bodyText>
<subsectionHeader confidence="0.995764">
2.4 Text normalisation
</subsectionHeader>
<bodyText confidence="0.999983962962963">
In this processing stage, the objective is the
recognition and reduction of variation phenom-
ena which, if left untreated, will affect the C-
value statistical measures at the keyphrase selec-
tion stage. Variation is a pervasive phenomenon
in terminology and is generally defined as the al-
teration of the surface form of a terminological
concept (Jacquemin, 2001). In our approach, we
attempt to address morphological variation, i.e.,
variation due to morphological affixes and ortho-
graphic variation, such as hyphenated vs. non-
hyphenated compound phrases and abbreviated
phrase forms vs. full noun phrase forms.
In order to reduce morphological variation, UvT
system uses the J.Renie interface2 to WordNet lex-
icon3 to acquire lemmas for the respective can-
didate phrases. Orthographic variation phenom-
ena are treated by rule matching techniques. In
this process, for every candidate keyphrase match-
ing a rule, the respective string alternations are
generated and added as variant phrases. For ex-
ample, for patterns including acronyms and the
respective full form, alternative variant phrases
generated may contain either the full form only,
or the acronym replacing its respective full form.
Similarly, for hyphenated words, non-hyphenated
forms are generated.
</bodyText>
<subsectionHeader confidence="0.935592">
2.5 C-value measure
</subsectionHeader>
<bodyText confidence="0.9998542">
The statistical measure used for keyphrase ranking
and selection is the C-value measure (Frantzi et al.,
2000). C-value was originally proposed for defin-
ing potential terminological phrases and is based
on normalising frequency of occurrence measures
</bodyText>
<footnote confidence="0.9999655">
2http://www.ai.mit.edu/ jrennie/WordNet/
3http://wordnet.princeton.edu/
</footnote>
<page confidence="0.985749">
195
</page>
<table confidence="0.9999842">
Performance over Reader-Assigned Keywords
System top 5 candidates top 10 candidates top 15 candidates
P R F P R F P R F
TF·IDF 17.80% 7.39% 10.44% 13.90% 11.54% 12.61% 11.60% 14.45% 12.87%
NB &amp; ME 16.80% 6.98% 9.86% 13.30% 11.05% 12.07% 11.40% 14.20% 12.65%
UvT 20.40% 8.47% 11.97% 15.60% 12.96% 14.16% 11.93% 14.87% 13.24%
UvT - A 23.60% 9.80% 13.85% 16.10% 13.37% 14.61% 12.00% 14.95% 13.31%
UvT - I 21.20% 8.80% 12.44% 14.50% 12.04% 13.16% 12.00% 14.95% 13.31%
UvT - M 20.40% 8.47% 11.97% 15.10% 12.54% 13.70% 11.40% 14.20% 12.65%
UvT - IC 23.20% 9.63% 13.61% 16.00% 13.29% 14.52% 13.07% 16.28% 14.50%
Performance over Combined Keywords
System top 5 candidates top 10 candidates top 15 candidates
P R F P R F P R F
TF·IDF 22.00% 7.50% 11.19% 17.70% 12.07% 14.35% 14.93% 15.28% 15.10%
NB &amp; ME 21.40% 7.30% 10.89% 17.30% 11.80% 14.03% 14.53% 14.87% 14.70%
UvT 24.80% 8.46% 12.62% 18.60% 12.69% 15.09% 14.60% 14.94% 14.77%
UvT - A 28.80% 9.82% 14.65% 19.60% 13.37% 15.90% 14.67% 15.01% 14.84%
UvT - I 26.40% 9.00% 13.42% 17.80% 12.14% 14.44% 14.73% 15.08% 14.90%
UvT - M 24.80% 8.46% 12.62% 17.90% 12.21% 14.52% 14.07% 14.39% 14.23%
UvT - IC 28.60% 9.75% 14.54% 19.70% 13.44% 15.98% 16.13% 16.51% 16.32%
</table>
<tableCaption confidence="0.999835">
Table 1: UvT, UvT variants and baseline systems performance on the Keyphrase Extraction Task
</tableCaption>
<bodyText confidence="0.999659">
by taking into consideration the candidate multi-
word phrase constituent length and terms appear-
ing as nested within longer terms. In particu-
lar, depending on whether a candidate multi-word
phrase is nested or not, C-value is defined as:
</bodyText>
<equation confidence="0.986482666666667">
lo92 |a|f(a)
lo92 |a |(f (a) − P(Ta) E f (b))
b
</equation>
<bodyText confidence="0.99997335">
In the above, the first C-value measurement is
for non-nested terms and the second for nested
terms, where a denotes the word sequence that is
proposed as a term, |a |is the length of this term
in words, f(a) is the frequency of occurrence of
this term in the corpus, both as an independent
term and as a nested term within larger terms, and
P(Ta) denotes the probability of a term string oc-
curring as nested term.
In this processing stage of keyphrase selection,
we start by measuring frequency of occurrence for
all our candidate phrases, taking into considera-
tion phrase variants, as identified in the Text nor-
malisation stage. Then, we proceed by calculating
nested phrases frequences and, finally, we estimate
C-value.
The result of this process is a list of proposed
keyphrases, ranked by decreasing C-value mea-
sure, wherefrom the top 15 were selected for the
evaluation of the system results.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.998838333333333">
The overall official results of the UvT system are
shown in Table 1, where P, R and F correspond
to micro-averaged precision, recall and F-score
for the respective sets of candidate keyphrases,
based on reader-assigned and combined author-
and reader-assigned gold standards. Table 1 also
illustrates the reported performance of the task
baseline systems (i.e., TF·IDF, Naive Bayes (NB)
and maximum entropy (ME)4 ) and the UvT sys-
tem performance variance based on document sec-
tion candidates (-A: Abstract, -I: Introduction, -M:
Main, -IC: Introduction and Conclusion combina-
tion). In these system variants, rather than select-
ing the top 15 C-value candidates from the sys-
tem output, we also apply restrictions based on
the candidate keyphrase document section infor-
mation, thus skipping candidates which do not ap-
pear in the respective document section.
Overall, the UvT system performance is close
to the baseline systems results. We observe that
the system exhibits higher performance for its top
</bodyText>
<footnote confidence="0.991583666666667">
4The reported performance of both NB and ME for the re-
spective gold-standard sets in the Keyphrase Extraction Task
is identical.
</footnote>
<figure confidence="0.8590535">
⎧
⎨
⎩
C-value =
</figure>
<page confidence="0.996546">
196
</page>
<bodyText confidence="0.999890285714286">
5 candidate set and this performance drops rapidly
as we include more terms in the answer set. One
possible reason for its average performance could
be attributed to increased “noise” in the results set.
In particular, our text filtering method failed to ac-
curately remove a large amount of irregular text
in form of mathematical formulas and symbols
which were erroneously tagged as proper nouns.
As indicated in Table 1, the improved results of
system variants based on document sections, such
as Abstract, Introduction and Conclusion, where
these symbols and formulas are rather uncommon,
could be partly attributed to “noise” reduction.
Interestingly, the best system performance
in these document section results is demon-
strated by the Introduction-Conclusion com-
bination (UvT-IC). Other tested combinations
(not illustrated in Table 1), such as abstract-
intro, abstract-intro-conclusions, abstract-intro-
conclusions-references, display similar results on
the reader-assigned set and a performance rang-
ing between 15,6-16% for the 15 candidates on
the combined set, while the inclusion of the Main
section candidates reduces the performance to the
overall system output (i.e., UvT results). Further
experiments are required for refining the criteria
for document section information, when the text
filtering process for “noise” is improved.
Finally, another reason that contributes to the
system’s average performance lies in its inherent
limitation for the detection of multi-word phrases,
rather than both single and multi-word. In partic-
ular, single word keyphrases account for approx.
20% of the correct keyphrases in the gold standard
sets.
</bodyText>
<sectionHeader confidence="0.99933" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999949111111111">
We have presented an approach to keyphrase ex-
traction mainly based on adaptation and imple-
mentation of the C-value method. This method
was originally proposed for the detection of ter-
minological phrases and although domain terms
may express the principal informational content of
a scientific article document, a method designed
for their exhaustive identification (including both
nested and longer multi-word terms) has not been
proven more effective than baseline methods in
the keyphrase detection task. Potential improve-
ments in performance could be investigated by
(1) improving document structure detection, so as
to reduce irregular text, (2) refinement of docu-
ment section information in keyphrase selection,
(3) adaptation of the C-value measure, so as to
possibly combine keyphrase frequency with a dis-
criminative measure, such as idf.
</bodyText>
<sectionHeader confidence="0.989527" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9990700625">
Ken Barker and Nadia Cornacchia. 2000. Using noun
phrase heads to extract document keyphrases. In
Proceedings of the 13th Biennial Conference of the
Canadian Society on Computational Studies of In-
telligence: Advances in Artificial Intelligence, pages
40–52, Montreal, Canada, May.
Ernesto D’Avanzo and Bernado Magnini. 2005. A
keyphrase-based approach to summarization: the
LAKE system. In Proceedings of Document Under-
standing Conferences, pages 6–8, Vancouver, BC,
Canada, October 9-10.
Katerina Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic recognition of multi-
word terms: The C-Value/NC-value Method. Intern.
Journal of Digital Libraries, 3(2):117–132.
Ian Witten Gordon, Gordon W. Paynter, Eibe Frank,
Carl Gutwin, and Craig G. Nevill-manning. 1999.
Kea: Practical automatic keyphrase extraction. In
Proceedings of the Fourth ACM conference on Dig-
ital Libraries, pages 254–256, Berkeley, CA, USA,
August 11-14. ACM Press.
Christian Jacquemin. 2001. Spotting and Discovering
Terms through Natural Language Processing. MIT
Press, Cambridge, MA, USA.
Olena Medelyan and Ian H. Witten. 2006. Thesaurus
based automatic keyphrase indexing. In JCDL ’06:
Proceedings of the 6th ACM/IEEE-CS joint confer-
ence on Digital libraries, pages 296–297, New York,
NY, USA. ACM.
Adwait Ratnaparkhi. 1996. A maximum entropy
model for part-of-speech tagging. In Eric Brill and
Kenneth Church, editors, Proceedings of the Empiri-
cal Methods in Natural Language Processing, pages
133–142.
Takashi Tomokiyo and Matthew Hurst. 2003. A lan-
guage model approach to keyphrase extraction. In
Proceedings of the ACL 2003 workshop on Mul-
tiword expressions, pages 33–40, Morristown, NJ,
USA. Association for Computational Linguistics.
Peter Turney. 1999. Learning to extract keyphrases
from text. Technical Report ERB-1057, National
Research Council, Institute for Information Technol-
ogy, February 17.
Peter Turney. 2003. Coherent keyphrase extraction via
web mining. In IJCAI’03: Proceedings of the 18th
international joint conference on Artificial intelli-
gence, pages 434–439, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
</reference>
<page confidence="0.998195">
197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.681765">
<title confidence="0.9988">UvT: The UvT Term Extraction System in the Keyphrase Extraction task</title>
<author confidence="0.993383">Kalliopi Zervanou</author>
<affiliation confidence="0.978328">ILK / TiCC - Tilburg centre for Cognition and Communication</affiliation>
<address confidence="0.702751">University of Tilburg, P.O. Box 90153, 5000 LE Tilburg, The Netherlands</address>
<email confidence="0.996494">K.Zervanou@uvt.nl</email>
<abstract confidence="0.998497">The UvT system is based on a hybrid, linguistic and statistical approach, originally proposed for the recognition of multiword terminological phrases, the C-value method (Frantzi et al., 2000). In the UvT implementation, we use an extended noun phrase rule set and take into consideration orthographic and morphological variation, term abbreviations and acronyms, and basic document structure information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ken Barker</author>
<author>Nadia Cornacchia</author>
</authors>
<title>Using noun phrase heads to extract document keyphrases.</title>
<date>2000</date>
<booktitle>In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in Artificial Intelligence,</booktitle>
<pages>40--52</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="2180" citStr="Barker and Cornacchia, 2000" startWordPosition="300" endWordPosition="303">tion include the Naive Bayes-based KEA algorithms (Gordon et al., 1999) (Medelyan and Witten, 2006), decision tree-based and the genetic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witten, 2006)) and keyphrase coherence (Turney, 2003). In this paper, we present an unsupervised approach which combines pattern-based morphosyntactic rules with a statistical measure, the C-value measure (Frantzi et al., 2000) which originates from research in the field of automatic term recognition and was initially designed for specialised domain terminology acquisition. 2 System description The input documents in the Keyphrase Extraction task were scientific articles converted from their originally published form to plain te</context>
</contexts>
<marker>Barker, Cornacchia, 2000</marker>
<rawString>Ken Barker and Nadia Cornacchia. 2000. Using noun phrase heads to extract document keyphrases. In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in Artificial Intelligence, pages 40–52, Montreal, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ernesto D’Avanzo</author>
<author>Bernado Magnini</author>
</authors>
<title>A keyphrase-based approach to summarization: the LAKE system.</title>
<date>2005</date>
<booktitle>In Proceedings of Document Understanding Conferences,</booktitle>
<pages>6--8</pages>
<location>Vancouver, BC, Canada,</location>
<marker>D’Avanzo, Magnini, 2005</marker>
<rawString>Ernesto D’Avanzo and Bernado Magnini. 2005. A keyphrase-based approach to summarization: the LAKE system. In Proceedings of Document Understanding Conferences, pages 6–8, Vancouver, BC, Canada, October 9-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina Frantzi</author>
<author>Sophia Ananiadou</author>
<author>Hideki Mima</author>
</authors>
<title>Automatic recognition of multiword terms: The C-Value/NC-value Method.</title>
<date>2000</date>
<journal>Intern. Journal of Digital Libraries,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="2473" citStr="Frantzi et al., 2000" startWordPosition="341" endWordPosition="344">s the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witten, 2006)) and keyphrase coherence (Turney, 2003). In this paper, we present an unsupervised approach which combines pattern-based morphosyntactic rules with a statistical measure, the C-value measure (Frantzi et al., 2000) which originates from research in the field of automatic term recognition and was initially designed for specialised domain terminology acquisition. 2 System description The input documents in the Keyphrase Extraction task were scientific articles converted from their originally published form to plain text. Due to this process, some compound hyphenated words are erroneously converted into a single word (e.g., “resourcemanagement” vs. “resourcemanagement”). Moreover, document sections such as tables, figures, footnotes, headers and footers, often intercept sentence and paragraph text. Finally</context>
<context position="7237" citStr="Frantzi et al., 2000" startWordPosition="1043" endWordPosition="1046">. Orthographic variation phenomena are treated by rule matching techniques. In this process, for every candidate keyphrase matching a rule, the respective string alternations are generated and added as variant phrases. For example, for patterns including acronyms and the respective full form, alternative variant phrases generated may contain either the full form only, or the acronym replacing its respective full form. Similarly, for hyphenated words, non-hyphenated forms are generated. 2.5 C-value measure The statistical measure used for keyphrase ranking and selection is the C-value measure (Frantzi et al., 2000). C-value was originally proposed for defining potential terminological phrases and is based on normalising frequency of occurrence measures 2http://www.ai.mit.edu/ jrennie/WordNet/ 3http://wordnet.princeton.edu/ 195 Performance over Reader-Assigned Keywords System top 5 candidates top 10 candidates top 15 candidates P R F P R F P R F TF·IDF 17.80% 7.39% 10.44% 13.90% 11.54% 12.61% 11.60% 14.45% 12.87% NB &amp; ME 16.80% 6.98% 9.86% 13.30% 11.05% 12.07% 11.40% 14.20% 12.65% UvT 20.40% 8.47% 11.97% 15.60% 12.96% 14.16% 11.93% 14.87% 13.24% UvT - A 23.60% 9.80% 13.85% 16.10% 13.37% 14.61% 12.00% 14.</context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Katerina Frantzi, Sophia Ananiadou, and Hideki Mima. 2000. Automatic recognition of multiword terms: The C-Value/NC-value Method. Intern. Journal of Digital Libraries, 3(2):117–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Witten Gordon</author>
<author>Gordon W Paynter</author>
<author>Eibe Frank</author>
<author>Carl Gutwin</author>
<author>Craig G Nevill-manning</author>
</authors>
<title>Kea: Practical automatic keyphrase extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the Fourth ACM conference on Digital Libraries,</booktitle>
<pages>254--256</pages>
<publisher>ACM Press.</publisher>
<location>Berkeley, CA, USA,</location>
<contexts>
<context position="1623" citStr="Gordon et al., 1999" startWordPosition="227" endWordPosition="230">d applications in document retrieval, classification and summarisation (D’Avanzo and Magnini, 2005). The literature distinguishes between two principal processes: keyphrase extraction and keyphrase assignment. In the case of keyphrase assignment, suitable keyphrases from an existing knowledge resource, such as a controlled vocabulary, or a thesaurus are assigned to documents based on classification of their content. In keyphrase extraction, the phrases are mined from the document itself. Supervised approaches to the problem of keyphrase extraction include the Naive Bayes-based KEA algorithms (Gordon et al., 1999) (Medelyan and Witten, 2006), decision tree-based and the genetic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphras</context>
</contexts>
<marker>Gordon, Paynter, Frank, Gutwin, Nevill-manning, 1999</marker>
<rawString>Ian Witten Gordon, Gordon W. Paynter, Eibe Frank, Carl Gutwin, and Craig G. Nevill-manning. 1999. Kea: Practical automatic keyphrase extraction. In Proceedings of the Fourth ACM conference on Digital Libraries, pages 254–256, Berkeley, CA, USA, August 11-14. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing.</title>
<date>2001</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="6209" citStr="Jacquemin, 2001" startWordPosition="893" endWordPosition="894">sion of potential abbreviations and acronyms in the identified noun phrase of the form: M+ (A) N M+ N (A) where (A) is a potential acronym appearing as a single token in uppercase, enclosed by parentheses and tagged as a proper noun. 2.4 Text normalisation In this processing stage, the objective is the recognition and reduction of variation phenomena which, if left untreated, will affect the Cvalue statistical measures at the keyphrase selection stage. Variation is a pervasive phenomenon in terminology and is generally defined as the alteration of the surface form of a terminological concept (Jacquemin, 2001). In our approach, we attempt to address morphological variation, i.e., variation due to morphological affixes and orthographic variation, such as hyphenated vs. nonhyphenated compound phrases and abbreviated phrase forms vs. full noun phrase forms. In order to reduce morphological variation, UvT system uses the J.Renie interface2 to WordNet lexicon3 to acquire lemmas for the respective candidate phrases. Orthographic variation phenomena are treated by rule matching techniques. In this process, for every candidate keyphrase matching a rule, the respective string alternations are generated and </context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Christian Jacquemin. 2001. Spotting and Discovering Terms through Natural Language Processing. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>Ian H Witten</author>
</authors>
<title>Thesaurus based automatic keyphrase indexing.</title>
<date>2006</date>
<booktitle>In JCDL ’06: Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries,</booktitle>
<pages>296--297</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1651" citStr="Medelyan and Witten, 2006" startWordPosition="231" endWordPosition="234">ment retrieval, classification and summarisation (D’Avanzo and Magnini, 2005). The literature distinguishes between two principal processes: keyphrase extraction and keyphrase assignment. In the case of keyphrase assignment, suitable keyphrases from an existing knowledge resource, such as a controlled vocabulary, or a thesaurus are assigned to documents based on classification of their content. In keyphrase extraction, the phrases are mined from the document itself. Supervised approaches to the problem of keyphrase extraction include the Naive Bayes-based KEA algorithms (Gordon et al., 1999) (Medelyan and Witten, 2006), decision tree-based and the genetic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witte</context>
</contexts>
<marker>Medelyan, Witten, 2006</marker>
<rawString>Olena Medelyan and Ian H. Witten. 2006. Thesaurus based automatic keyphrase indexing. In JCDL ’06: Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries, pages 296–297, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>Proceedings of the Empirical Methods in Natural Language Processing,</booktitle>
<pages>133--142</pages>
<editor>In Eric Brill and Kenneth Church, editors,</editor>
<contexts>
<context position="4131" citStr="Ratnaparkhi, 1996" startWordPosition="573" endWordPosition="574">2.1 and 2.2). Subsequently, keyphrase candidates conforming to pre-defined morphosyntactic rule patterns are identified (sec. 2.3). In the next stage, orthographic, morphological and abbreviation variation phenomena are addressed 194 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 194–197, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics (sec. 2.4) and, finally, candidate keyphrases are selected based on C-value statistical measure (sec. 2.5). 2.1 Linguistic pre-processing For morphosyntactic analysis, we used the Maxent (Ratnaparkhi, 1996) POS tagger implementation of the openNLP toolsuite1. In order to improve tagging accuracy, irregular text, such as URLs, inline references, and recurrent patterns indicating footers and mathematical formulas are filtered prior to tagging. 2.2 Basic document structuring Document structuring is based on identified recurrent patterns, such as common section titles and legend indicators (e.g., “Abstract”, “Table...”), section headers numbering and preserved formatting, such as newline characters. Thus, the document sections that the system may recognise are: Title, Abstract, Introduction, Conclus</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Eric Brill and Kenneth Church, editors, Proceedings of the Empirical Methods in Natural Language Processing, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Tomokiyo</author>
<author>Matthew Hurst</author>
</authors>
<title>A language model approach to keyphrase extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1810" citStr="Tomokiyo and Hurst, 2003" startWordPosition="252" endWordPosition="255">n and keyphrase assignment. In the case of keyphrase assignment, suitable keyphrases from an existing knowledge resource, such as a controlled vocabulary, or a thesaurus are assigned to documents based on classification of their content. In keyphrase extraction, the phrases are mined from the document itself. Supervised approaches to the problem of keyphrase extraction include the Naive Bayes-based KEA algorithms (Gordon et al., 1999) (Medelyan and Witten, 2006), decision tree-based and the genetic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witten, 2006)) and keyphrase coherence (Turney, 2003). In this paper, we present an unsupervised approach which combines pattern-based morphosyntactic rules with a </context>
</contexts>
<marker>Tomokiyo, Hurst, 2003</marker>
<rawString>Takashi Tomokiyo and Matthew Hurst. 2003. A language model approach to keyphrase extraction. In Proceedings of the ACL 2003 workshop on Multiword expressions, pages 33–40, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Learning to extract keyphrases from text.</title>
<date>1999</date>
<tech>Technical Report ERB-1057,</tech>
<institution>National Research Council, Institute for Information Technology,</institution>
<contexts>
<context position="1725" citStr="Turney, 1999" startWordPosition="243" endWordPosition="244">rature distinguishes between two principal processes: keyphrase extraction and keyphrase assignment. In the case of keyphrase assignment, suitable keyphrases from an existing knowledge resource, such as a controlled vocabulary, or a thesaurus are assigned to documents based on classification of their content. In keyphrase extraction, the phrases are mined from the document itself. Supervised approaches to the problem of keyphrase extraction include the Naive Bayes-based KEA algorithms (Gordon et al., 1999) (Medelyan and Witten, 2006), decision tree-based and the genetic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witten, 2006)) and keyphrase coherence (Turney, 2003). In this paper, we presen</context>
</contexts>
<marker>Turney, 1999</marker>
<rawString>Peter Turney. 1999. Learning to extract keyphrases from text. Technical Report ERB-1057, National Research Council, Institute for Information Technology, February 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Coherent keyphrase extraction via web mining.</title>
<date>2003</date>
<booktitle>In IJCAI’03: Proceedings of the 18th international joint conference on Artificial intelligence,</booktitle>
<pages>434--439</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="2299" citStr="Turney, 2003" startWordPosition="318" endWordPosition="319">ic algorithm-based GenEx (Turney, 1999), and the probabilistic KL divergence-based language model (Tomokiyo and Hurst, 2003). Research in keyphrase extraction proposes the detection of keyphrases based on various statistics-based, or pattern-based features. Statistical measures investigated focus primarily on keyphrase frequency measures, whereas pattern-features include noun phrase pattern filtering, identification of keyphrase head and respective frequencies (Barker and Cornacchia, 2000), document section position of the keyphrase (e.g., (Medelyan and Witten, 2006)) and keyphrase coherence (Turney, 2003). In this paper, we present an unsupervised approach which combines pattern-based morphosyntactic rules with a statistical measure, the C-value measure (Frantzi et al., 2000) which originates from research in the field of automatic term recognition and was initially designed for specialised domain terminology acquisition. 2 System description The input documents in the Keyphrase Extraction task were scientific articles converted from their originally published form to plain text. Due to this process, some compound hyphenated words are erroneously converted into a single word (e.g., “resourcema</context>
</contexts>
<marker>Turney, 2003</marker>
<rawString>Peter Turney. 2003. Coherent keyphrase extraction via web mining. In IJCAI’03: Proceedings of the 18th international joint conference on Artificial intelligence, pages 434–439, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>