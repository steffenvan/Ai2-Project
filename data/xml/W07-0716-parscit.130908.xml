<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003200">
<title confidence="0.981791">
Using Paraphrases for Parameter Tuning in Statistical Machine Translation
</title>
<author confidence="0.996288">
Nitin Madnani, Necip Fazil Ayan, Philip Resnik &amp; Bonnie J. Dorr
</author>
<affiliation confidence="0.997382">
Institute for Advanced Computer Studies
University of Maryland
</affiliation>
<address confidence="0.965332">
College Park, MD, 20742
</address>
<email confidence="0.999705">
{nmadnani,nfa,resnik,bonnie}@umiacs.umd.edu
</email>
<sectionHeader confidence="0.994821" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979529411765">
Most state-of-the-art statistical machine
translation systems use log-linear models,
which are defined in terms of hypothesis fea-
tures and weights for those features. It is
standard to tune the feature weights in or-
der to maximize a translation quality met-
ric, using held-out test sentences and their
corresponding reference translations. How-
ever, obtaining reference translations is ex-
pensive. In this paper, we introduce a new
full-sentence paraphrase technique, based
on English-to-English decoding with an MT
system, and we demonstrate that the result-
ing paraphrases can be used to drastically re-
duce the number of human reference transla-
tions needed for parameter tuning, without a
significant decrease in translation quality.
</bodyText>
<sectionHeader confidence="0.998777" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998215">
Viewed at a very high level, statistical machine
translation involves four phases: language and trans-
lation model training, parameter tuning, decoding,
and evaluation (Lopez, 2007; Koehn et al., 2003).
Since their introduction in statistical MT by Och and
Ney (2002), log-linear models have been a standard
way to combine sub-models in MT systems. Typi-
cally such a model takes the form
</bodyText>
<equation confidence="0.9364655">
� AiOi(f,e) (1)
i
</equation>
<bodyText confidence="0.999976681818182">
where Oi are features of the hypothesis e and Ai are
weights associated with those features.
Selecting appropriate weights Ai is essential
in order to obtain good translation performance.
Och (2003) introduced minimum error rate train-
ing (MERT), a technique for optimizing log-linear
model parameters relative to a measure of translation
quality. This has become much more standard than
optimizing the conditional probability of the train-
ing data given the model (i.e., a maximum likelihood
criterion), as was common previously. Och showed
that system performance is best when parameters are
optimized using the same objective function that will
be used for evaluation; BLEU (Papineni et al., 2002)
remains common for both purposes and is often re-
tained for parameter optimization even when alter-
native evaluation measures are used, e.g., (Banerjee
and Lavie, 2005; Snover et al., 2006).
Minimum error rate training—and more gener-
ally, optimization of parameters relative to a trans-
lation quality measure—relies on data sets in which
source language sentences are paired with (sets of)
reference translations. It is widely agreed that, at
least for the widely used BLEU criterion, which is
based on n-gram overlap between hypotheses and
reference translations, the criterion is most accu-
rate when computed with as many distinct reference
translations as possible. Intuitively this makes sense:
if there are alternative ways to phrase the meaning
of the source sentence in the target language, then
the translation quality criterion should take as many
of those variations into account as possible. To do
otherwise is to risk the possibility that the criterion
might judge good translations to be poor when they
fail to match the exact wording within the reference
translations that have been provided.
This reliance on multiple reference translations
creates a problem, because reference translations are
labor intensive and expensive to obtain. A com-
mon source of translated data for MT research is the
Linguistic Data Consortium (LDC), where an elab-
orate process is undertaken that involves translation
agencies, detailed translation guidelines, and qual-
ity control processes (Strassel et al., 2006). Some
</bodyText>
<page confidence="0.94667">
120
</page>
<note confidence="0.891054">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999934655172414">
efforts have been made to develop alternative pro-
cesses for eliciting translations, e.g., from users on
the Web (Oard, 2003) or from informants in low-
density languages (Probst et al., 2002). However,
reference translations for parameter tuning and eval-
uation remain a severe data bottleneck for such ap-
proaches.
Note, however, one crucial property of reference
translations: they are paraphrases, i.e., multiple ex-
pressions of the same meaning. Automatic tech-
niques exist for generating paraphrases. Although
one would clearly like to retain human transla-
tions as the benchmark for evaluation of translation,
might it be possible to usefully increase the number
of reference translations for tuning by using auto-
matic paraphrase techniques?
In this paper, we demonstrate that it is, in fact,
possible to do so. Section 2 briefly describes our
translation framework. Section 3 lays out a novel
technique for paraphrasing, designed with the ap-
plication to parameter tuning in mind. Section 4
presents evaluation results using a state of the art sta-
tistical MT system, demonstrating that half the hu-
man reference translations in a standard 4-reference
tuning set can be replaced with automatically gener-
ated paraphrases, with no significant decrease in MT
system performance. In Section 5 we discuss related
work, and in Section 6 we summarize the results and
discuss plans for future research.
</bodyText>
<sectionHeader confidence="0.984151" genericHeader="method">
2 Translation Framework
</sectionHeader>
<bodyText confidence="0.999977">
The work described in this paper makes use
of the Hiero statistical MT framework (Chiang,
2007). Hiero is formally based on a weighted syn-
chronous context-free grammar (CFG), containing
synchronous rules of the form
</bodyText>
<equation confidence="0.999809">
X — (�e,�f,�i(�f, e,X)) (2)
</equation>
<bodyText confidence="0.989955210526316">
where X is a symbol from the nonterminal alpha-
bet, and e� and f can contain both words (terminals)
and variables (nonterminals) that serve as placehold-
ers for other phrases. In the context of statistical
MT, where phrase-based models are frequently used,
these synchronous rules can be interpreted as pairs
of hierarchical phrases. The underlying strength
of a hierarchical phrase is that it allows for effec-
tive learning of not only the lexical re-orderings, but
phrasal re-orderings, as well. Each 0(e, f, X) de-
notes a feature function defined on the pair of hierar-
chical phrases.&apos; Feature functions represent condi-
tional and joint co-occurrence probabilities over the
hierarchical paraphrase pair.
The Hiero framework includes methods to learn
grammars and feature values from unannotated par-
allel corpora, without requiring syntactic annotation
of the data. Briefly, training a Hiero model proceeds
as follows:
</bodyText>
<listItem confidence="0.996409714285714">
• GIZA++ (Och and Ney, 2000) is run on the
parallel corpus in both directions, followed by
an alignment refinement heuristic that yields a
many-to-many alignment for each parallel sen-
tence.
• Initial phrase pairs are identified following the
procedure typically employed in phrase based
systems (Koehn et al., 2003; Och and Ney,
2004).
• Grammar rules in the form of equation (2)
are induced by “subtracting” out hierarchical
phrase pairs from these initial phrase pairs.
• Fractional counts are assigned to each pro-
duced rule:
</listItem>
<equation confidence="0.74816">
c(X —* (e,
</equation>
<bodyText confidence="0.946438882352941">
where m is the number of initial phrase pairs
that give rise to this grammar rule and njr is
the number of grammar rules produced by the
jth initial phrase pair.
• Feature functions O1(�f, e, X) are calculated
for each rule using the accumulated counts.
Once training has taken place, minimum error rate
training (Och, 2003) is used to tune the parameters
Ai.
Finally, decoding in Hiero takes place using a
CKY synchronous parser with beam search, aug-
mented to permit efficient incorporation of language
model scores (Chiang, 2007). Given a source lan-
guage sentence f, the decoder parses the source lan-
guage sentence using the grammar it has learned
&apos;Currently only one nonterminal symbol is used in Hiero
productions.
</bodyText>
<equation confidence="0.491243666666667">
f)) � M 1 (3)
E njr
j=1
</equation>
<page confidence="0.988197">
121
</page>
<bodyText confidence="0.9996186">
during training, with parser search guided by the
model; a target-language hypothesis is generated
simultaneously via the synchronous rules, and the
yield of that hypothesized analysis represents the hy-
pothesized string e in the target language.
</bodyText>
<sectionHeader confidence="0.982141" genericHeader="method">
3 Generating Paraphrases
</sectionHeader>
<bodyText confidence="0.991772052631579">
As discussed in Section 1, our goal is to make it pos-
sible to accomplish the parameter-tuning phase us-
ing fewer human reference translations. We accom-
plish this by beginning with a small set of human
reference translations for each sentence in the devel-
opment set, and expanding that set by automatically
paraphrasing each member of the set rather than by
acquiring more human translations.
Most previous work on paraphrase has focused
on high quality rather than coverage (Barzilay and
Lee, 2003; Quirk et al., 2004), but generating ar-
tificial references for MT parameter tuning in our
setting has two unique properties compared to other
paraphrase applications. First, we would like to ob-
tain 100% coverage, in order to avoid modifications
to our minimum error rate training infrastructure.2
Second, we prefer that paraphrases be as distinct as
possible from the original sentences, while retaining
as much of the original meaning as possible.
In order to satisfy these two properties, we ap-
proach sentence-level paraphrase for English as
a problem of English-to-English translation, con-
structing the model using English-F translation, for
a second language F, as a pivot. Following Ban-
nard and Callison-Burch (2005), we first identify
English-to-F correspondences, then map from En-
glish to English by following translation units from
English to F and back. Then, generalizing their ap-
proach, we use those mappings to create a well de-
fined English-to-English translation model. The pa-
rameters of this model are tuned using MERT, and
then the model is used in an the (unmodified) sta-
tistical MT system, yielding sentence-level English
paraphrases by means of decoding input English
sentences. The remainder of this section presents
this process in detail.
2Strictly speaking, this was not a requirement of the ap-
proach, but rather a concession to practical considerations.
</bodyText>
<subsectionHeader confidence="0.999678">
3.1 Mapping and Backmapping
</subsectionHeader>
<bodyText confidence="0.9996559">
We employ the following strategy for the induction
of the required monolingual grammar. First, we train
the Hiero system in standard fashion on a bilingual
English-F training corpus. Then, for each exist-
ing production in the resulting Hiero grammar, we
create multiple new English-to-English productions
by pivoting on the foreign hierarchical phrase in the
rule. For example, assume that we have the follow-
ing toy grammar for English-F, as produced by Hi-
ero:
</bodyText>
<equation confidence="0.9999954">
X —* (�e1, f1)
X —* (e3, f1)
X —* (�e1, f2)
X —* (e2, f2)
X —* (e4, f2)
</equation>
<bodyText confidence="0.999458666666666">
If we use the foreign phrase f1 as a pivot and
backmap, we can extract the two English-to-English
rules: X —* (�e1,
ping using both f1 and f2 produces the following
new rules (ignoring duplicates and rules that map
any English phrase to itself):
</bodyText>
<equation confidence="0.9999726">
X —* (�e1, e2)
X —* (�e1, e3)
X —* (�e1, e4)
X —* (e2, �e1)
X —* (e2, e4)
</equation>
<subsectionHeader confidence="0.99729">
3.2 Feature values
</subsectionHeader>
<bodyText confidence="0.999905071428572">
Each rule production in a Hiero grammar is
weighted by several feature values defined on the
rule themselves. In order to perform accurate
backmapping, we must recompute these feature
functions for the newly created English-to-English
grammar. Rather than computing approximations
based on feature values already existing in the bilin-
gual Hiero grammar, we calculate these features
in a more principled manner, by computing max-
imum likelihood estimates directly from the frac-
tional counts that Hiero accumulates in the penul-
timate training step.
We use the following features in our induced
English-to-English grammar:3
</bodyText>
<footnote confidence="0.829196">
3Hiero also uses lexical weights (Koehn et al., 2003) in both
</footnote>
<equation confidence="0.931004666666667">
e3) and X —* (
�e1). Backmap-
e3,
</equation>
<page confidence="0.979743">
122
</page>
<bodyText confidence="0.962993333333333">
• The joint probability of the two English hierar-
chical paraphrases, conditioned on the nonter-
minal symbol, as defined by this formula:
</bodyText>
<equation confidence="0.997787">
c(X → h ¯e1, ¯e2i)
= (4)
c(X)
</equation>
<bodyText confidence="0.999922">
where the numerator is the fractional count of
the rule under consideration and the denomina-
tor represents the marginal count over all the
English hierarchical phrase pairs.
</bodyText>
<listItem confidence="0.8913475">
• The conditionals p( ¯e1, x |¯e2) and p( ¯e2, x |¯e1)
defined as follows:
</listItem>
<equation confidence="0.99923125">
¯ ¯ c(X → h ¯e1, ¯e2i)
p(e1, x|e2) = E¯e1, c(X → h ¯e1&apos;, ¯e2i) (5)
c(X → h ¯e1, ¯e2i)
p( ¯e2, x |¯e1) = E¯e2, c(X → h ¯e1, ¯e2&apos;i) (6)
</equation>
<bodyText confidence="0.9998300625">
Finally, for all induced rules, we calculate a word
penalty exp(−T( ¯e2)), where T( ¯e2) just counts the
number of terminal symbols in ¯e2. This feature al-
lows the model to learn whether it should produce
shorter or longer paraphrases.
In addition to the features above that are estimated
from the training data, we also use a trigram lan-
guage model. Since we are decoding to produce
English sentences, we can use the same language
model employed in a standard statistical MT setting.
Calculating the proposed features is complicated
by the fact that we don’t actually have the counts
for English-to-English rules because there is no
English-to-English parallel corpus. This is where
the counts provided by Hiero come into the picture.
We estimate the counts that we need as follows:
</bodyText>
<equation confidence="0.980819333333333">
c(X → h ¯e1, ¯e2i) =
� c(X → h ¯e1, fi)c(X → h¯e2, fi) (7)
f¯
</equation>
<bodyText confidence="0.995009">
An intuitive way to think about the formula above
is by using an example at the corpus level. As-
sume that, in the given bilingual parallel corpus,
there are m sentences in which the English phrase
directions as features but we don’t use them for our grammar.
¯e1 co-occurs with the foreign phrase f and n sen-
tences in which the same foreign phrase f¯ co-occurs
with the English phrase ¯e2. The problem can then
be thought of as defining a function g(m, n) which
computes the number of sentences in a hypotheti-
cal English-to-English parallel corpus wherein the
phrases ¯e1 and ¯e1 co-occur. For this paper, we de-
fine g(m, n) to be the upper bound mn.
Tables 1 and 2 show some examples of para-
phrases generated by our system across a range of
paraphrase quality for two different pivot languages.
</bodyText>
<subsectionHeader confidence="0.994546">
3.3 Tuning Model Parameters
</subsectionHeader>
<bodyText confidence="0.9999958">
Although the goal of the paraphrasing approach
is to make it less data-intensive to tune log-linear
model parameters for translation, our paraphrasing
approach, since it is based on an English-to-English
log-linear model, also requires its own parameter
tuning. This, however, is straightforward: regard-
less of how the paraphrasing model will be used
in statistical MT, e.g., irrespective of source lan-
guage, it is possible to use any existing set of English
paraphrases as the tuning set for English-to-English
translation. We used the 2002 NIST MT evaluation
test set reference translations. For every item in the
set, we randomly chose one sentence as the source
sentence, and the remainder as the “reference trans-
lations” for purposes of minimum error rate training.
</bodyText>
<sectionHeader confidence="0.999092" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999982714285714">
Having developed a paraphrasing approach based on
English-to-English translation, we evaluated its use
in improving minimum error rate training for trans-
lation from a second language into English.
Generating paraphrases via English-to-English
translation makes use of a parallel corpus, from
which a weighted synchronous grammar is automat-
ically acquired. Although nothing about our ap-
proach requires that the paraphrase system’s training
bitext be the same one used in the translation exper-
iments (see Section 6), doing so is not precluded, ei-
ther, and it is a particularly convenient choice when
the paraphrasing is being done in support of MT.4
The training bitext comprised of Chinese-English
</bodyText>
<footnote confidence="0.969921666666667">
4The choice of the foreign language used as the pivot should
not really matter but it is worth exploring this using other lan-
guage pairs as our bitext.
</footnote>
<equation confidence="0.998285333333333">
c(X → h ¯e1, ¯e2i)
p( ¯e1, ¯e2|x) =
E¯e1,,¯e2, c(X → h ¯e1&apos;, ¯e2&apos;i)
</equation>
<page confidence="0.987423">
123
</page>
<bodyText confidence="0.997023">
we must bear in mind the community as a whole.
we must remember the wider community.
thirdly , the implications of enlargement for the union ’s regional policy cannot be overlooked .
finally, the impact of enlargement for eu regional policy cannot be ignored.
how this works in practice will become clear when the authority has to act.
how this operate in practice will emerge when the government has to play .
this is an ill-advised policy.
this is an unwelcome in europe .
</bodyText>
<tableCaption confidence="0.996878">
Table 1: Example paraphrases with French as the pivot language. O = Original Sentence, P = Paraphrase.
</tableCaption>
<bodyText confidence="0.99985325">
alcatel added that the company’s whole year earnings would be announced on february 4 .
alcatel said that the company’s total annual revenues would be released on february 4 .
he was now preparing a speech concerning the us policy for the upcoming world economic forum.
he was now ready to talk with regard to the us policies for the forthcoming international economic forum.
tibet has entered an excellent phase of political stability, ethnic unity and people living in peace.
tibetans have come to cordial political stability, national unity and lived in harmony .
its ocean and blue-sky scenery and the mediterranean climate make it world’s famous scenic spot.
its harbour and blue-sky appearance and the border situation decided it world’s renowned tourist attraction.
</bodyText>
<tableCaption confidence="0.995292">
Table 2: Example paraphrases with Chinese as the pivot language. O = Original Sentence, P = Paraphrase.
</tableCaption>
<table confidence="0.999776142857143">
Corpus # Sentences # Words
HK News 542540 11171933
FBIS 240996 9121210
Xinhua 54022 1497562
News1 9916 314121
Treebank 3963 125848
Total 851437 22230674
</table>
<tableCaption confidence="0.9794755">
Table 3: Chinese-English corpora used as training
bitext both for paraphrasing and for evaluation.
</tableCaption>
<bodyText confidence="0.987166576923077">
parallel corpora containing 850, 000 sentence pairs –
approx. 22 million words (details shown in Table 3).
As the source of development data for minimum
error rate training, we used the 919 source sen-
tences and human reference translations from the
2003 NIST Chinese-English MT evaluation exer-
cise. As raw material for experimentation, we gen-
erated a paraphrase for each reference sentence via
1-best decoding using the English-to-English trans-
lation approach of Section 3.
As our test data, we used the 1082 source sen-
tences and human reference translations from the
2005 NIST Chinese-English MT evaluation.
Our core experiment involved three conditions
where the only difference was the set of references
for the development set used for tuning feature
weights. For each condition, once the weights were
tuned, they were used to decode the test set. Note
that for all the conditions, the decoded test set was
always scored against the same four high-quality hu-
man reference translations included with the set.
The three experimental conditions were designed
around the constraint that our development set con-
tains a total of four human reference translations per
sentence, and therefore a maximum of four human
references with which to compute an upper bound:
</bodyText>
<listItem confidence="0.707034090909091">
• Baseline (214): For each item in the devel-
opment set, we randomly chose two of the
four human-constructed reference translations
as references for minimum error rate training.
• Expanded (214 + 2P): For each of the two hu-
man references in the baseline tuning set, we
automatically generated a corresponding para-
phrase using (1-best) English-to-English trans-
lation, decoding using the model developed in
Section 3. This condition represents the critical
case in which you have a limited number of hu-
</listItem>
<page confidence="0.997418">
124
</page>
<bodyText confidence="0.999445428571428">
man references (two, in this case) and augment
them with artificially generated reference trans-
lations. This yields a set of four references for
minimum error rate training (two human, two
paraphrased), which permits a direct compar-
ison against the upper bound of four human-
generated reference translations.
</bodyText>
<listItem confidence="0.566866333333333">
• Upper bound: 4H: We performed minimum
error rate training using the four human refer-
ences from the development set.
</listItem>
<bodyText confidence="0.992802">
In addition to these core experimental conditions,
we added a fourth condition to assess the effect on
performance when all four human reference trans-
lations are used in expanding the reference set via
paraphrase:
</bodyText>
<listItem confidence="0.6751305">
• Expanded (4H + 4P): This is the same as Con-
dition 2, but using all four human references.
</listItem>
<bodyText confidence="0.999259538461539">
Note that since we have only four human references
per item, this fourth condition does not permit com-
parison with an upper bound of eight human refer-
ences.
Table 4 shows BLEU and TER scores on the test
set for all four conditions.5 If only two human ref-
erences were available (simulated by using only two
of the available four), expanding to four using para-
phrases would yield a clear improvement. Using
bootstrap resampling to compute confidence inter-
vals (Koehn, 2004), we find that the improvement in
BLEU score is statistically significant at p &lt; .01.
Equally interesting, expanding the number of ref-
erence translations from two to four using para-
phrases yields performance that approaches the up-
per bound obtained by doing MERT using all four
human reference translations. The difference in
BLEU between conditions 2 and 3 is not significant.
Finally, our fourth condition asks whether it is
possible to improve MT performance given the
typical four human reference translations used for
MERT in most statistical MT systems, by adding a
paraphrase to each one for a total eight references
per translation. There is indeed further improve-
ment, although the difference in BLEU score does
not reach significance.
</bodyText>
<footnote confidence="0.848143">
5We plan to include METEOR scores in future experiments.
</footnote>
<table confidence="0.9992846">
Condition References used BLEU TER
1 2 H 30.43 59.82
2 2 H + 2 P 31.10 58.79
3 4 H 31.26 58.66
4 4 H + 4 P 31.68 58.24
</table>
<tableCaption confidence="0.941444666666667">
Table 4: BLEU and TER scores showing utility of
paraphrased reference translations. H = human ref-
erences, P = paraphrased references.
</tableCaption>
<bodyText confidence="0.999850857142857">
We also evaluated our test set using TER (Snover
et al., 2006) and observed that the TER scores follow
the same trend as the BLEU scores. Specifically, the
TER scores demonstrate that using paraphrases to
artificially expand the reference set is better than us-
ing only 2 human reference translations and as good
as using 4 human reference translations.6
</bodyText>
<sectionHeader confidence="0.999848" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.995698423076923">
The approach we have taken here arises from a typ-
ical situation in NLP systems: the lack of sufficient
data to accurately estimate a model based on super-
vised training data. In a structured prediction prob-
lem such as MT, we have an example input and a
single labeled, correct output. However, this output
is chosen from a space in which the number of pos-
sible outputs is exponential in the input size, and in
which there are many good outputs in this space (al-
though they are vastly outnumbered by the bad out-
puts). Various discriminative learning methods have
attempted to deal with the first of these issues, often
by restricting the space of examples. For instance,
some max-margin methods restrict their computa-
tions to a set of examples from a “feasible set,”
where they are expected to be maximally discrim-
inative (Tillmann and Zhang, 2006). The present
approach deals with the second issue: in a learning
problem where the use of a single positive example
is likely to be highly biased, how can we produce a
set of positive examples that is more representative
of the space of correct outcomes? Our method ex-
ploits alternative sources of information to produce
new positive examples that are, we hope, reasonably
likely to represent a consensus of good examples.
Quite a bit of work has been done on paraphrase,
</bodyText>
<footnote confidence="0.9968985">
6We anticipate doing significance tests for differences in
TER in future work.
</footnote>
<page confidence="0.997536">
125
</page>
<bodyText confidence="0.999920666666667">
some clearly related to our technique, although in
general previous work has been focused on human
readability rather than high coverage, noisy para-
phrases for use downstream in an automatic process.
At the sentence level, (Barzilay and Lee, 2003)
employed an unsupervised learning approach to
cluster sentences and extract lattice pairs from
comparable monolingual corpora. Their technique
produces a paraphrase only if the input sentence
matches any of the extracted lattice pairs, leading to
a bias strongly favoring quality over coverage. They
were able to generate paraphrases for 59 sentences
(12%) out of a 484-sentence test set, generating no
paraphrases at all for the remainder.
Quirk et al. (2004) also generate sentential para-
phrases using a monolingual corpus. They use
IBM Model-1 scores as the only feature, and em-
ploy a monotone decoder (i.e., one that cannot pro-
duce phrase-level reordering). This approach em-
phasizes very simple “substitutions of words and
short phrases,” and, in fact, almost a third of their
best sentential “paraphrases” are identical to the in-
put sentence.
A number of other approaches rely on parallel
monolingual data and, additionally, require pars-
ing of the training sentences (Ibrahim et al., 2003;
Pang et al., 2003). Lin and Pantel (2001) use a
non-parallel corpus and employ a dependency parser
and computation of distributional similarity to learn
paraphrases.
There has also been recent work on using para-
phrases to improve statistical machine translation.
Callison-Burch et al. (2006) extract phrase-level
paraphrases by mapping input phrases into a phrase
table and then mapping back to the source language.
However, they do not generate paraphrases of entire
sentences, but instead employ paraphrases to add en-
tries to an existing phrase table solely for the pur-
pose of increasing source-language coverage.
Other work has incorporated paraphrases into MT
evaluation: Russo-Lassner et al. (2005) use a com-
bination of paraphrase-based features to evaluate
translation output; Zhou et al. (2006) propose a new
metric that extends n-gram matching to include syn-
onyms and paraphrases; and Lavie’s METEOR met-
ric (Banerjee and Lavie, 2005) can be used with ad-
ditional knowledge such as WordNet in order to sup-
port inexact lexical matches.
</bodyText>
<sectionHeader confidence="0.994277" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999978652173913">
We introduced an automatic paraphrasing technique
based on English-to-English translation of full sen-
tences using a statistical MT system, and demon-
strated that, using this technique, it is possible to
cut in half the usual number of reference transla-
tions used for minimum error rate training with no
significant loss in translation quality. Our method
enables the generation of paraphrases for thousands
of sentences in a very short amount of time (much
shorter than creating other low-cost human refer-
ences). This might prove beneficial for various dis-
criminative training methods (Tillmann and Zhang,
2006).
This has important implications for data acquisi-
tion strategies For example, it suggests that rather
than obtaining four reference translations per sen-
tence for development sets, it may be more worth-
while to obtain fewer translations for a wider range
of sentences, e.g., expanding into new topics and
genres. In addition, this approach can significantly
increase the utility of datasets which include only a
single reference translation.
A number of future research directions are pos-
sible. First, since we have already demonstrated
that noisy paraphrases can nonetheless add value,
it would be straightforward to explore the quan-
tity/quality tradeoff by expanding the MERT refer-
ence translations with n-best paraphrases for n &gt; 1.
We also plan to conduct an intrinsic evaluation of
the quality of paraphrases that our technique gener-
ates. It is important to note that a different tradeoff
ratio may lead to even better results, e.g, using only
the paraphrased references when they pass some
goodness threshold, as used in Ueffing’s (2006) self-
training MT approach.
We have also observed that named entities are
usually paraphrased incorrectly if there is a genre
mismatch between the training and the test data. The
Hiero decoder allows spans of source text to be an-
notated with inline translations using XML. We plan
to identify and annotate named entities in the En-
glish source so that they are left unchanged.
Also, since the language F for English-F pivoting
is arbitrary, we plan to investigate using English-to-
English grammars created using multiple English-F
grammars based on different languages, both indi-
</bodyText>
<page confidence="0.995583">
126
</page>
<bodyText confidence="0.999735">
vidually and in combination, in order to improve
paraphrase quality.
We also plan to explore a wider range of
paraphrase-creation techniques, ranging from sim-
ple word substitutions (e.g., based on WordNet) to
using the pivot technique with other translations sys-
tems.
</bodyText>
<sectionHeader confidence="0.998254" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999987125">
We are indebted to David Chiang, Adam Lopez
and Smaranda Muresan for insights and comments.
This work has been supported under the GALE pro-
gram of the Defense Advaned Research Projects
Agency, Contract No. HR0011-06-2-001. Any opin-
ions, findings, conclusions or recommendations ex-
pressed in this paper are those of the authors and do
not necessarily reflect the view of DARPA.
</bodyText>
<sectionHeader confidence="0.999203" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998745625">
S. Banerjee and A. Lavie. 2005. Meteor: An auto-
matic metric for mt evaluation with improved correla-
tion with human judgments. In Proceedings of Work-
shop on Intrinsic and Extrinsic Evaluation Measures
for MT and/or Summarization at ACL.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL.
Regina Barzilay and Lillian Lee. 2003. Learning to
paraphrase: An unsupervised approach using multiple-
sequence alignment. In Proceedings of HLT-NAACL.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine translation
using paraphrases. In Proceedings of HLT-NAACL.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2).
A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting struc-
tural paraphrases from aligned monolingual corpora.
In Proceedings the Second International Workshop on
Paraphrasing (ACL 2003).
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT-NAACL.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining.
A. Lopez. 2007. A survey of statistical machine transla-
tion. Technical Report 2006-47, University of Mary-
land, College Park.
D. W. Oard. 2003. The surprise langauge exercises.
ACM Transactions on Asian Language Information
Processing, 2(3).
Franz J. Och and Hermann Ney. 2000. Improved statisti-
cal alignment models. In Proceedings of ACL.
Franz J. Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statistical
machine translation. In Proceedings of ACL.
Franz Och and Hermann Ney. 2004. The alignment tem-
plate approach to statistical machine translation. Com-
putational Linguistics, 30(4).
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings ofACL.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations: Ex-
tracting paraphrases and generating new sentences. In
Proceedings of HLT/NAACL.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of ACL.
K. Probst, L. Levin, E. Peterson, A. Lavie, and J. Car-
bonell. 2002. Mt for minority languages using
elicitation-based learning of syntactic transfer rules.
Machine Translation, 17(4).
Chris Quirk, Chris Brockett, and William Dolan. 2004.
Monolingual machine translation for paraphrase gen-
eration. In Proceedings of EMNLP 2004.
Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik.
2005. A paraphrase-based approach to machine trans-
lation evaluation. Technical Report UMIACS-TR-
2005-57, University of Maryland, College Park.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and
J. Makhoul. 2006. A study of translation edit rate with
targeted human annotation. In Proceedings of AMTA.
S. Strassel, C. Cieri, A. Cole, D. DiPersio, M. Liberman,
X. Ma, M. Maamouri, and K. Maeda. 2006. Inte-
grated linguistic resources for language exploitation
technologies. In Proceedings of LREC.
Christoph Tillmann and Tong Zhang. 2006. A discrimi-
native global training algorithm for statistical MT. In
Proceedings of ACL.
Nicola Ueffing. 2006. Using monolingual source-
language data to improve MT performance. In Pro-
ceedings of IWSLT.
L. Zhou, C.-Y. Lin, D. Muntenau, and E. Hovy. 2006.
ParaEval: Using paraphrases to evaluate summaries
automatically. In Proceedings of HLT-NAACL.
</reference>
<page confidence="0.997335">
127
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909294">
<title confidence="0.999943">Using Paraphrases for Parameter Tuning in Statistical Machine Translation</title>
<author confidence="0.968524">Nitin Madnani</author>
<author confidence="0.968524">Necip Fazil Ayan</author>
<author confidence="0.968524">Philip Resnik</author>
<author confidence="0.968524">J Bonnie</author>
<affiliation confidence="0.998847">Institute for Advanced Computer University of</affiliation>
<address confidence="0.942399">College Park, MD,</address>
<abstract confidence="0.999785611111111">Most state-of-the-art statistical machine translation systems use log-linear models, which are defined in terms of hypothesis features and weights for those features. It is standard to tune the feature weights in order to maximize a translation quality metric, using held-out test sentences and their corresponding reference translations. However, obtaining reference translations is expensive. In this paper, we introduce a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and we demonstrate that the resulting paraphrases can be used to drastically reduce the number of human reference translations needed for parameter tuning, without a significant decrease in translation quality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>A Lavie</author>
</authors>
<title>Meteor: An automatic metric for mt evaluation with improved correlation with human judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at ACL.</booktitle>
<contexts>
<context position="2293" citStr="Banerjee and Lavie, 2005" startWordPosition="339" endWordPosition="342">ERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizing the conditional probability of the training data given the model (i.e., a maximum likelihood criterion), as was common previously. Och showed that system performance is best when parameters are optimized using the same objective function that will be used for evaluation; BLEU (Papineni et al., 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al., 2006). Minimum error rate training—and more generally, optimization of parameters relative to a translation quality measure—relies on data sets in which source language sentences are paired with (sets of) reference translations. It is widely agreed that, at least for the widely used BLEU criterion, which is based on n-gram overlap between hypotheses and reference translations, the criterion is most accurate when computed with as many distinct reference translations as possible. Intuitively this makes sense: if there are alternative ways to phrase the meaning of the source sent</context>
<context position="25027" citStr="Banerjee and Lavie, 2005" startWordPosition="4052" endWordPosition="4055">aphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Other work has incorporated paraphrases into MT evaluation: Russo-Lassner et al. (2005) use a combination of paraphrase-based features to evaluate translation output; Zhou et al. (2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie’s METEOR metric (Banerjee and Lavie, 2005) can be used with additional knowledge such as WordNet in order to support inexact lexical matches. 6 Conclusions and Future Work We introduced an automatic paraphrasing technique based on English-to-English translation of full sentences using a statistical MT system, and demonstrated that, using this technique, it is possible to cut in half the usual number of reference translations used for minimum error rate training with no significant loss in translation quality. Our method enables the generation of paraphrases for thousands of sentences in a very short amount of time (much shorter than c</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>S. Banerjee and A. Lavie. 2005. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="9145" citStr="Bannard and Callison-Burch (2005)" startWordPosition="1416" endWordPosition="1420">r setting has two unique properties compared to other paraphrase applications. First, we would like to obtain 100% coverage, in order to avoid modifications to our minimum error rate training infrastructure.2 Second, we prefer that paraphrases be as distinct as possible from the original sentences, while retaining as much of the original meaning as possible. In order to satisfy these two properties, we approach sentence-level paraphrase for English as a problem of English-to-English translation, constructing the model using English-F translation, for a second language F, as a pivot. Following Bannard and Callison-Burch (2005), we first identify English-to-F correspondences, then map from English to English by following translation units from English to F and back. Then, generalizing their approach, we use those mappings to create a well defined English-to-English translation model. The parameters of this model are tuned using MERT, and then the model is used in an the (unmodified) statistical MT system, yielding sentence-level English paraphrases by means of decoding input English sentences. The remainder of this section presents this process in detail. 2Strictly speaking, this was not a requirement of the approac</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiplesequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="8423" citStr="Barzilay and Lee, 2003" startWordPosition="1306" endWordPosition="1309">the yield of that hypothesized analysis represents the hypothesized string e in the target language. 3 Generating Paraphrases As discussed in Section 1, our goal is to make it possible to accomplish the parameter-tuning phase using fewer human reference translations. We accomplish this by beginning with a small set of human reference translations for each sentence in the development set, and expanding that set by automatically paraphrasing each member of the set rather than by acquiring more human translations. Most previous work on paraphrase has focused on high quality rather than coverage (Barzilay and Lee, 2003; Quirk et al., 2004), but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications. First, we would like to obtain 100% coverage, in order to avoid modifications to our minimum error rate training infrastructure.2 Second, we prefer that paraphrases be as distinct as possible from the original sentences, while retaining as much of the original meaning as possible. In order to satisfy these two properties, we approach sentence-level paraphrase for English as a problem of English-to-English translation, constructi</context>
<context position="23090" citStr="Barzilay and Lee, 2003" startWordPosition="3753" endWordPosition="3756">tive examples that is more representative of the space of correct outcomes? Our method exploits alternative sources of information to produce new positive examples that are, we hope, reasonably likely to represent a consensus of good examples. Quite a bit of work has been done on paraphrase, 6We anticipate doing significance tests for differences in TER in future work. 125 some clearly related to our technique, although in general previous work has been focused on human readability rather than high coverage, noisy paraphrases for use downstream in an automatic process. At the sentence level, (Barzilay and Lee, 2003) employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora. Their technique produces a paraphrase only if the input sentence matches any of the extracted lattice pairs, leading to a bias strongly favoring quality over coverage. They were able to generate paraphrases for 59 sentences (12%) out of a 484-sentence test set, generating no paraphrases at all for the remainder. Quirk et al. (2004) also generate sentential paraphrases using a monolingual corpus. They use IBM Model-1 scores as the only feature, and employ a monotone de</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiplesequence alignment. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="24377" citStr="Callison-Burch et al. (2006)" startWordPosition="3952" endWordPosition="3955">g). This approach emphasizes very simple “substitutions of words and short phrases,” and, in fact, almost a third of their best sentential “paraphrases” are identical to the input sentence. A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al., 2003; Pang et al., 2003). Lin and Pantel (2001) use a non-parallel corpus and employ a dependency parser and computation of distributional similarity to learn paraphrases. There has also been recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Other work has incorporated paraphrases into MT evaluation: Russo-Lassner et al. (2005) use a combination of paraphrase-based features to evaluate translation output; Zhou et al. (2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; an</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="5306" citStr="Chiang, 2007" startWordPosition="804" endWordPosition="805">ique for paraphrasing, designed with the application to parameter tuning in mind. Section 4 presents evaluation results using a state of the art statistical MT system, demonstrating that half the human reference translations in a standard 4-reference tuning set can be replaced with automatically generated paraphrases, with no significant decrease in MT system performance. In Section 5 we discuss related work, and in Section 6 we summarize the results and discuss plans for future research. 2 Translation Framework The work described in this paper makes use of the Hiero statistical MT framework (Chiang, 2007). Hiero is formally based on a weighted synchronous context-free grammar (CFG), containing synchronous rules of the form X — (�e,�f,�i(�f, e,X)) (2) where X is a symbol from the nonterminal alphabet, and e� and f can contain both words (terminals) and variables (nonterminals) that serve as placeholders for other phrases. In the context of statistical MT, where phrase-based models are frequently used, these synchronous rules can be interpreted as pairs of hierarchical phrases. The underlying strength of a hierarchical phrase is that it allows for effective learning of not only the lexical re-or</context>
<context position="7440" citStr="Chiang, 2007" startWordPosition="1147" endWordPosition="1148"> phrase pairs. • Fractional counts are assigned to each produced rule: c(X —* (e, where m is the number of initial phrase pairs that give rise to this grammar rule and njr is the number of grammar rules produced by the jth initial phrase pair. • Feature functions O1(�f, e, X) are calculated for each rule using the accumulated counts. Once training has taken place, minimum error rate training (Och, 2003) is used to tune the parameters Ai. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores (Chiang, 2007). Given a source language sentence f, the decoder parses the source language sentence using the grammar it has learned &apos;Currently only one nonterminal symbol is used in Hiero productions. f)) � M 1 (3) E njr j=1 121 during training, with parser search guided by the model; a target-language hypothesis is generated simultaneously via the synchronous rules, and the yield of that hypothesized analysis represents the hypothesized string e in the target language. 3 Generating Paraphrases As discussed in Section 1, our goal is to make it possible to accomplish the parameter-tuning phase using fewer h</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ibrahim</author>
<author>B Katz</author>
<author>J Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora.</title>
<date>2003</date>
<booktitle>In Proceedings the Second International Workshop on Paraphrasing (ACL</booktitle>
<contexts>
<context position="24084" citStr="Ibrahim et al., 2003" startWordPosition="3908" endWordPosition="3911">tence test set, generating no paraphrases at all for the remainder. Quirk et al. (2004) also generate sentential paraphrases using a monolingual corpus. They use IBM Model-1 scores as the only feature, and employ a monotone decoder (i.e., one that cannot produce phrase-level reordering). This approach emphasizes very simple “substitutions of words and short phrases,” and, in fact, almost a third of their best sentential “paraphrases” are identical to the input sentence. A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al., 2003; Pang et al., 2003). Lin and Pantel (2001) use a non-parallel corpus and employ a dependency parser and computation of distributional similarity to learn paraphrases. There has also been recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-l</context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Proceedings the Second International Workshop on Paraphrasing (ACL 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="1225" citStr="Koehn et al., 2003" startWordPosition="170" endWordPosition="173">nslations. However, obtaining reference translations is expensive. In this paper, we introduce a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and we demonstrate that the resulting paraphrases can be used to drastically reduce the number of human reference translations needed for parameter tuning, without a significant decrease in translation quality. 1 Introduction Viewed at a very high level, statistical machine translation involves four phases: language and translation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al., 2003). Since their introduction in statistical MT by Och and Ney (2002), log-linear models have been a standard way to combine sub-models in MT systems. Typically such a model takes the form � AiOi(f,e) (1) i where Oi are features of the hypothesis e and Ai are weights associated with those features. Selecting appropriate weights Ai is essential in order to obtain good translation performance. Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizin</context>
<context position="6684" citStr="Koehn et al., 2003" startWordPosition="1016" endWordPosition="1019"> conditional and joint co-occurrence probabilities over the hierarchical paraphrase pair. The Hiero framework includes methods to learn grammars and feature values from unannotated parallel corpora, without requiring syntactic annotation of the data. Briefly, training a Hiero model proceeds as follows: • GIZA++ (Och and Ney, 2000) is run on the parallel corpus in both directions, followed by an alignment refinement heuristic that yields a many-to-many alignment for each parallel sentence. • Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al., 2003; Och and Ney, 2004). • Grammar rules in the form of equation (2) are induced by “subtracting” out hierarchical phrase pairs from these initial phrase pairs. • Fractional counts are assigned to each produced rule: c(X —* (e, where m is the number of initial phrase pairs that give rise to this grammar rule and njr is the number of grammar rules produced by the jth initial phrase pair. • Feature functions O1(�f, e, X) are calculated for each rule using the accumulated counts. Once training has taken place, minimum error rate training (Och, 2003) is used to tune the parameters Ai. Finally, decodi</context>
<context position="11373" citStr="Koehn et al., 2003" startWordPosition="1785" endWordPosition="1788"> several feature values defined on the rule themselves. In order to perform accurate backmapping, we must recompute these feature functions for the newly created English-to-English grammar. Rather than computing approximations based on feature values already existing in the bilingual Hiero grammar, we calculate these features in a more principled manner, by computing maximum likelihood estimates directly from the fractional counts that Hiero accumulates in the penultimate training step. We use the following features in our induced English-to-English grammar:3 3Hiero also uses lexical weights (Koehn et al., 2003) in both e3) and X —* ( �e1). Backmape3, 122 • The joint probability of the two English hierarchical paraphrases, conditioned on the nonterminal symbol, as defined by this formula: c(X → h ¯e1, ¯e2i) = (4) c(X) where the numerator is the fractional count of the rule under consideration and the denominator represents the marginal count over all the English hierarchical phrase pairs. • The conditionals p( ¯e1, x |¯e2) and p( ¯e2, x |¯e1) defined as follows: ¯ ¯ c(X → h ¯e1, ¯e2i) p(e1, x|e2) = E¯e1, c(X → h ¯e1&apos;, ¯e2i) (5) c(X → h ¯e1, ¯e2i) p( ¯e2, x |¯e1) = E¯e2, c(X → h ¯e1, ¯e2&apos;i) (6) Finall</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="20017" citStr="Koehn, 2004" startWordPosition="3233" endWordPosition="3234">d in expanding the reference set via paraphrase: • Expanded (4H + 4P): This is the same as Condition 2, but using all four human references. Note that since we have only four human references per item, this fourth condition does not permit comparison with an upper bound of eight human references. Table 4 shows BLEU and TER scores on the test set for all four conditions.5 If only two human references were available (simulated by using only two of the available four), expanding to four using paraphrases would yield a clear improvement. Using bootstrap resampling to compute confidence intervals (Koehn, 2004), we find that the improvement in BLEU score is statistically significant at p &lt; .01. Equally interesting, expanding the number of reference translations from two to four using paraphrases yields performance that approaches the upper bound obtained by doing MERT using all four human reference translations. The difference in BLEU between conditions 2 and 3 is not significant. Finally, our fourth condition asks whether it is possible to improve MT performance given the typical four human reference translations used for MERT in most statistical MT systems, by adding a paraphrase to each one for a</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="24127" citStr="Lin and Pantel (2001)" startWordPosition="3916" endWordPosition="3919">at all for the remainder. Quirk et al. (2004) also generate sentential paraphrases using a monolingual corpus. They use IBM Model-1 scores as the only feature, and employ a monotone decoder (i.e., one that cannot produce phrase-level reordering). This approach emphasizes very simple “substitutions of words and short phrases,” and, in fact, almost a third of their best sentential “paraphrases” are identical to the input sentence. A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al., 2003; Pang et al., 2003). Lin and Pantel (2001) use a non-parallel corpus and employ a dependency parser and computation of distributional similarity to learn paraphrases. There has also been recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Other work has incorporat</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>A survey of statistical machine translation.</title>
<date>2007</date>
<tech>Technical Report 2006-47,</tech>
<institution>University of Maryland, College Park.</institution>
<contexts>
<context position="1204" citStr="Lopez, 2007" startWordPosition="168" endWordPosition="169">reference translations. However, obtaining reference translations is expensive. In this paper, we introduce a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and we demonstrate that the resulting paraphrases can be used to drastically reduce the number of human reference translations needed for parameter tuning, without a significant decrease in translation quality. 1 Introduction Viewed at a very high level, statistical machine translation involves four phases: language and translation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al., 2003). Since their introduction in statistical MT by Och and Ney (2002), log-linear models have been a standard way to combine sub-models in MT systems. Typically such a model takes the form � AiOi(f,e) (1) i where Oi are features of the hypothesis e and Ai are weights associated with those features. Selecting appropriate weights Ai is essential in order to obtain good translation performance. Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more st</context>
</contexts>
<marker>Lopez, 2007</marker>
<rawString>A. Lopez. 2007. A survey of statistical machine translation. Technical Report 2006-47, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
</authors>
<title>The surprise langauge exercises.</title>
<date>2003</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="3919" citStr="Oard, 2003" startWordPosition="587" endWordPosition="588">eference translations are labor intensive and expensive to obtain. A common source of translated data for MT research is the Linguistic Data Consortium (LDC), where an elaborate process is undertaken that involves translation agencies, detailed translation guidelines, and quality control processes (Strassel et al., 2006). Some 120 Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127, Prague, June 2007. c�2007 Association for Computational Linguistics efforts have been made to develop alternative processes for eliciting translations, e.g., from users on the Web (Oard, 2003) or from informants in lowdensity languages (Probst et al., 2002). However, reference translations for parameter tuning and evaluation remain a severe data bottleneck for such approaches. Note, however, one crucial property of reference translations: they are paraphrases, i.e., multiple expressions of the same meaning. Automatic techniques exist for generating paraphrases. Although one would clearly like to retain human translations as the benchmark for evaluation of translation, might it be possible to usefully increase the number of reference translations for tuning by using automatic paraph</context>
</contexts>
<marker>Oard, 2003</marker>
<rawString>D. W. Oard. 2003. The surprise langauge exercises. ACM Transactions on Asian Language Information Processing, 2(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6398" citStr="Och and Ney, 2000" startWordPosition="972" endWordPosition="975">rases. The underlying strength of a hierarchical phrase is that it allows for effective learning of not only the lexical re-orderings, but phrasal re-orderings, as well. Each 0(e, f, X) denotes a feature function defined on the pair of hierarchical phrases.&apos; Feature functions represent conditional and joint co-occurrence probabilities over the hierarchical paraphrase pair. The Hiero framework includes methods to learn grammars and feature values from unannotated parallel corpora, without requiring syntactic annotation of the data. Briefly, training a Hiero model proceeds as follows: • GIZA++ (Och and Ney, 2000) is run on the parallel corpus in both directions, followed by an alignment refinement heuristic that yields a many-to-many alignment for each parallel sentence. • Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al., 2003; Och and Ney, 2004). • Grammar rules in the form of equation (2) are induced by “subtracting” out hierarchical phrase pairs from these initial phrase pairs. • Fractional counts are assigned to each produced rule: c(X —* (e, where m is the number of initial phrase pairs that give rise to this grammar rule and njr</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz J. Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1291" citStr="Och and Ney (2002)" startWordPosition="181" endWordPosition="184">In this paper, we introduce a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and we demonstrate that the resulting paraphrases can be used to drastically reduce the number of human reference translations needed for parameter tuning, without a significant decrease in translation quality. 1 Introduction Viewed at a very high level, statistical machine translation involves four phases: language and translation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al., 2003). Since their introduction in statistical MT by Och and Ney (2002), log-linear models have been a standard way to combine sub-models in MT systems. Typically such a model takes the form � AiOi(f,e) (1) i where Oi are features of the hypothesis e and Ai are weights associated with those features. Selecting appropriate weights Ai is essential in order to obtain good translation performance. Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizing the conditional probability of the training data given the model</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz J. Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="6704" citStr="Och and Ney, 2004" startWordPosition="1020" endWordPosition="1023">nt co-occurrence probabilities over the hierarchical paraphrase pair. The Hiero framework includes methods to learn grammars and feature values from unannotated parallel corpora, without requiring syntactic annotation of the data. Briefly, training a Hiero model proceeds as follows: • GIZA++ (Och and Ney, 2000) is run on the parallel corpus in both directions, followed by an alignment refinement heuristic that yields a many-to-many alignment for each parallel sentence. • Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al., 2003; Och and Ney, 2004). • Grammar rules in the form of equation (2) are induced by “subtracting” out hierarchical phrase pairs from these initial phrase pairs. • Fractional counts are assigned to each produced rule: c(X —* (e, where m is the number of initial phrase pairs that give rise to this grammar rule and njr is the number of grammar rules produced by the jth initial phrase pair. • Feature functions O1(�f, e, X) are calculated for each rule using the accumulated counts. Once training has taken place, minimum error rate training (Och, 2003) is used to tune the parameters Ai. Finally, decoding in Hiero takes pl</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="1627" citStr="Och (2003)" startWordPosition="239" endWordPosition="240">duction Viewed at a very high level, statistical machine translation involves four phases: language and translation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al., 2003). Since their introduction in statistical MT by Och and Ney (2002), log-linear models have been a standard way to combine sub-models in MT systems. Typically such a model takes the form � AiOi(f,e) (1) i where Oi are features of the hypothesis e and Ai are weights associated with those features. Selecting appropriate weights Ai is essential in order to obtain good translation performance. Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizing the conditional probability of the training data given the model (i.e., a maximum likelihood criterion), as was common previously. Och showed that system performance is best when parameters are optimized using the same objective function that will be used for evaluation; BLEU (Papineni et al., 2002) remains common for both purposes and is often retained for parameter optimization even when alterna</context>
<context position="7233" citStr="Och, 2003" startWordPosition="1114" endWordPosition="1115">ypically employed in phrase based systems (Koehn et al., 2003; Och and Ney, 2004). • Grammar rules in the form of equation (2) are induced by “subtracting” out hierarchical phrase pairs from these initial phrase pairs. • Fractional counts are assigned to each produced rule: c(X —* (e, where m is the number of initial phrase pairs that give rise to this grammar rule and njr is the number of grammar rules produced by the jth initial phrase pair. • Feature functions O1(�f, e, X) are calculated for each rule using the accumulated counts. Once training has taken place, minimum error rate training (Och, 2003) is used to tune the parameters Ai. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores (Chiang, 2007). Given a source language sentence f, the decoder parses the source language sentence using the grammar it has learned &apos;Currently only one nonterminal symbol is used in Hiero productions. f)) � M 1 (3) E njr j=1 121 during training, with parser search guided by the model; a target-language hypothesis is generated simultaneously via the synchronous rules, and the yield of that hypothesized a</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="24104" citStr="Pang et al., 2003" startWordPosition="3912" endWordPosition="3915">ting no paraphrases at all for the remainder. Quirk et al. (2004) also generate sentential paraphrases using a monolingual corpus. They use IBM Model-1 scores as the only feature, and employ a monotone decoder (i.e., one that cannot produce phrase-level reordering). This approach emphasizes very simple “substitutions of words and short phrases,” and, in fact, almost a third of their best sentential “paraphrases” are identical to the input sentence. A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al., 2003; Pang et al., 2003). Lin and Pantel (2001) use a non-parallel corpus and employ a dependency parser and computation of distributional similarity to learn paraphrases. There has also been recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Ot</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2127" citStr="Papineni et al., 2002" startWordPosition="313" endWordPosition="316"> those features. Selecting appropriate weights Ai is essential in order to obtain good translation performance. Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizing the conditional probability of the training data given the model (i.e., a maximum likelihood criterion), as was common previously. Och showed that system performance is best when parameters are optimized using the same objective function that will be used for evaluation; BLEU (Papineni et al., 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al., 2006). Minimum error rate training—and more generally, optimization of parameters relative to a translation quality measure—relies on data sets in which source language sentences are paired with (sets of) reference translations. It is widely agreed that, at least for the widely used BLEU criterion, which is based on n-gram overlap between hypotheses and reference translations, the criterion is most accurate when c</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Probst</author>
<author>L Levin</author>
<author>E Peterson</author>
<author>A Lavie</author>
<author>J Carbonell</author>
</authors>
<title>Mt for minority languages using elicitation-based learning of syntactic transfer rules.</title>
<date>2002</date>
<journal>Machine Translation,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="3984" citStr="Probst et al., 2002" startWordPosition="596" endWordPosition="599">to obtain. A common source of translated data for MT research is the Linguistic Data Consortium (LDC), where an elaborate process is undertaken that involves translation agencies, detailed translation guidelines, and quality control processes (Strassel et al., 2006). Some 120 Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127, Prague, June 2007. c�2007 Association for Computational Linguistics efforts have been made to develop alternative processes for eliciting translations, e.g., from users on the Web (Oard, 2003) or from informants in lowdensity languages (Probst et al., 2002). However, reference translations for parameter tuning and evaluation remain a severe data bottleneck for such approaches. Note, however, one crucial property of reference translations: they are paraphrases, i.e., multiple expressions of the same meaning. Automatic techniques exist for generating paraphrases. Although one would clearly like to retain human translations as the benchmark for evaluation of translation, might it be possible to usefully increase the number of reference translations for tuning by using automatic paraphrase techniques? In this paper, we demonstrate that it is, in fac</context>
</contexts>
<marker>Probst, Levin, Peterson, Lavie, Carbonell, 2002</marker>
<rawString>K. Probst, L. Levin, E. Peterson, A. Lavie, and J. Carbonell. 2002. Mt for minority languages using elicitation-based learning of syntactic transfer rules. Machine Translation, 17(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
<author>William Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="8444" citStr="Quirk et al., 2004" startWordPosition="1310" endWordPosition="1313">esized analysis represents the hypothesized string e in the target language. 3 Generating Paraphrases As discussed in Section 1, our goal is to make it possible to accomplish the parameter-tuning phase using fewer human reference translations. We accomplish this by beginning with a small set of human reference translations for each sentence in the development set, and expanding that set by automatically paraphrasing each member of the set rather than by acquiring more human translations. Most previous work on paraphrase has focused on high quality rather than coverage (Barzilay and Lee, 2003; Quirk et al., 2004), but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications. First, we would like to obtain 100% coverage, in order to avoid modifications to our minimum error rate training infrastructure.2 Second, we prefer that paraphrases be as distinct as possible from the original sentences, while retaining as much of the original meaning as possible. In order to satisfy these two properties, we approach sentence-level paraphrase for English as a problem of English-to-English translation, constructing the model using En</context>
<context position="23551" citStr="Quirk et al. (2004)" startWordPosition="3823" endWordPosition="3826"> on human readability rather than high coverage, noisy paraphrases for use downstream in an automatic process. At the sentence level, (Barzilay and Lee, 2003) employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora. Their technique produces a paraphrase only if the input sentence matches any of the extracted lattice pairs, leading to a bias strongly favoring quality over coverage. They were able to generate paraphrases for 59 sentences (12%) out of a 484-sentence test set, generating no paraphrases at all for the remainder. Quirk et al. (2004) also generate sentential paraphrases using a monolingual corpus. They use IBM Model-1 scores as the only feature, and employ a monotone decoder (i.e., one that cannot produce phrase-level reordering). This approach emphasizes very simple “substitutions of words and short phrases,” and, in fact, almost a third of their best sentential “paraphrases” are identical to the input sentence. A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al., 2003; Pang et al., 2003). Lin and Pantel (2001) use a non-parallel corp</context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>Chris Quirk, Chris Brockett, and William Dolan. 2004. Monolingual machine translation for paraphrase generation. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grazia Russo-Lassner</author>
<author>Jimmy Lin</author>
<author>Philip Resnik</author>
</authors>
<title>A paraphrase-based approach to machine translation evaluation.</title>
<date>2005</date>
<tech>Technical Report UMIACS-TR2005-57,</tech>
<institution>University of Maryland, College Park.</institution>
<contexts>
<context position="24789" citStr="Russo-Lassner et al. (2005)" startWordPosition="4014" endWordPosition="4017">oy a dependency parser and computation of distributional similarity to learn paraphrases. There has also been recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Other work has incorporated paraphrases into MT evaluation: Russo-Lassner et al. (2005) use a combination of paraphrase-based features to evaluate translation output; Zhou et al. (2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie’s METEOR metric (Banerjee and Lavie, 2005) can be used with additional knowledge such as WordNet in order to support inexact lexical matches. 6 Conclusions and Future Work We introduced an automatic paraphrasing technique based on English-to-English translation of full sentences using a statistical MT system, and demonstrated that, using this technique, it is possible to cut in half the usual number o</context>
</contexts>
<marker>Russo-Lassner, Lin, Resnik, 2005</marker>
<rawString>Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik. 2005. A paraphrase-based approach to machine translation evaluation. Technical Report UMIACS-TR2005-57, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciulla</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of AMTA.</booktitle>
<contexts>
<context position="2315" citStr="Snover et al., 2006" startWordPosition="343" endWordPosition="346">mizing log-linear model parameters relative to a measure of translation quality. This has become much more standard than optimizing the conditional probability of the training data given the model (i.e., a maximum likelihood criterion), as was common previously. Och showed that system performance is best when parameters are optimized using the same objective function that will be used for evaluation; BLEU (Papineni et al., 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al., 2006). Minimum error rate training—and more generally, optimization of parameters relative to a translation quality measure—relies on data sets in which source language sentences are paired with (sets of) reference translations. It is widely agreed that, at least for the widely used BLEU criterion, which is based on n-gram overlap between hypotheses and reference translations, the criterion is most accurate when computed with as many distinct reference translations as possible. Intuitively this makes sense: if there are alternative ways to phrase the meaning of the source sentence in the target lan</context>
<context position="21134" citStr="Snover et al., 2006" startWordPosition="3423" endWordPosition="3426">nce translations used for MERT in most statistical MT systems, by adding a paraphrase to each one for a total eight references per translation. There is indeed further improvement, although the difference in BLEU score does not reach significance. 5We plan to include METEOR scores in future experiments. Condition References used BLEU TER 1 2 H 30.43 59.82 2 2 H + 2 P 31.10 58.79 3 4 H 31.26 58.66 4 4 H + 4 P 31.68 58.24 Table 4: BLEU and TER scores showing utility of paraphrased reference translations. H = human references, P = paraphrased references. We also evaluated our test set using TER (Snover et al., 2006) and observed that the TER scores follow the same trend as the BLEU scores. Specifically, the TER scores demonstrate that using paraphrases to artificially expand the reference set is better than using only 2 human reference translations and as good as using 4 human reference translations.6 5 Related Work The approach we have taken here arises from a typical situation in NLP systems: the lack of sufficient data to accurately estimate a model based on supervised training data. In a structured prediction problem such as MT, we have an example input and a single labeled, correct output. However, </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J. Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Strassel</author>
<author>C Cieri</author>
<author>A Cole</author>
<author>D DiPersio</author>
<author>M Liberman</author>
<author>X Ma</author>
<author>M Maamouri</author>
<author>K Maeda</author>
</authors>
<title>Integrated linguistic resources for language exploitation technologies.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="3630" citStr="Strassel et al., 2006" startWordPosition="544" endWordPosition="547">count as possible. To do otherwise is to risk the possibility that the criterion might judge good translations to be poor when they fail to match the exact wording within the reference translations that have been provided. This reliance on multiple reference translations creates a problem, because reference translations are labor intensive and expensive to obtain. A common source of translated data for MT research is the Linguistic Data Consortium (LDC), where an elaborate process is undertaken that involves translation agencies, detailed translation guidelines, and quality control processes (Strassel et al., 2006). Some 120 Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127, Prague, June 2007. c�2007 Association for Computational Linguistics efforts have been made to develop alternative processes for eliciting translations, e.g., from users on the Web (Oard, 2003) or from informants in lowdensity languages (Probst et al., 2002). However, reference translations for parameter tuning and evaluation remain a severe data bottleneck for such approaches. Note, however, one crucial property of reference translations: they are paraphrases, i.e., multiple expressions of the same</context>
</contexts>
<marker>Strassel, Cieri, Cole, DiPersio, Liberman, Ma, Maamouri, Maeda, 2006</marker>
<rawString>S. Strassel, C. Cieri, A. Cole, D. DiPersio, M. Liberman, X. Ma, M. Maamouri, and K. Maeda. 2006. Integrated linguistic resources for language exploitation technologies. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
<author>Tong Zhang</author>
</authors>
<title>A discriminative global training algorithm for statistical MT.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="22287" citStr="Tillmann and Zhang, 2006" startWordPosition="3620" endWordPosition="3623">we have an example input and a single labeled, correct output. However, this output is chosen from a space in which the number of possible outputs is exponential in the input size, and in which there are many good outputs in this space (although they are vastly outnumbered by the bad outputs). Various discriminative learning methods have attempted to deal with the first of these issues, often by restricting the space of examples. For instance, some max-margin methods restrict their computations to a set of examples from a “feasible set,” where they are expected to be maximally discriminative (Tillmann and Zhang, 2006). The present approach deals with the second issue: in a learning problem where the use of a single positive example is likely to be highly biased, how can we produce a set of positive examples that is more representative of the space of correct outcomes? Our method exploits alternative sources of information to produce new positive examples that are, we hope, reasonably likely to represent a consensus of good examples. Quite a bit of work has been done on paraphrase, 6We anticipate doing significance tests for differences in TER in future work. 125 some clearly related to our technique, altho</context>
<context position="25767" citStr="Tillmann and Zhang, 2006" startWordPosition="4169" endWordPosition="4172">nd Future Work We introduced an automatic paraphrasing technique based on English-to-English translation of full sentences using a statistical MT system, and demonstrated that, using this technique, it is possible to cut in half the usual number of reference translations used for minimum error rate training with no significant loss in translation quality. Our method enables the generation of paraphrases for thousands of sentences in a very short amount of time (much shorter than creating other low-cost human references). This might prove beneficial for various discriminative training methods (Tillmann and Zhang, 2006). This has important implications for data acquisition strategies For example, it suggests that rather than obtaining four reference translations per sentence for development sets, it may be more worthwhile to obtain fewer translations for a wider range of sentences, e.g., expanding into new topics and genres. In addition, this approach can significantly increase the utility of datasets which include only a single reference translation. A number of future research directions are possible. First, since we have already demonstrated that noisy paraphrases can nonetheless add value, it would be st</context>
</contexts>
<marker>Tillmann, Zhang, 2006</marker>
<rawString>Christoph Tillmann and Tong Zhang. 2006. A discriminative global training algorithm for statistical MT. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
</authors>
<title>Using monolingual sourcelanguage data to improve MT performance.</title>
<date>2006</date>
<booktitle>In Proceedings of IWSLT.</booktitle>
<marker>Ueffing, 2006</marker>
<rawString>Nicola Ueffing. 2006. Using monolingual sourcelanguage data to improve MT performance. In Proceedings of IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zhou</author>
<author>C-Y Lin</author>
<author>D Muntenau</author>
<author>E Hovy</author>
</authors>
<title>ParaEval: Using paraphrases to evaluate summaries automatically.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="24887" citStr="Zhou et al. (2006)" startWordPosition="4029" endWordPosition="4032">en recent work on using paraphrases to improve statistical machine translation. Callison-Burch et al. (2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language. However, they do not generate paraphrases of entire sentences, but instead employ paraphrases to add entries to an existing phrase table solely for the purpose of increasing source-language coverage. Other work has incorporated paraphrases into MT evaluation: Russo-Lassner et al. (2005) use a combination of paraphrase-based features to evaluate translation output; Zhou et al. (2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie’s METEOR metric (Banerjee and Lavie, 2005) can be used with additional knowledge such as WordNet in order to support inexact lexical matches. 6 Conclusions and Future Work We introduced an automatic paraphrasing technique based on English-to-English translation of full sentences using a statistical MT system, and demonstrated that, using this technique, it is possible to cut in half the usual number of reference translations used for minimum error rate training with no significant loss in translat</context>
</contexts>
<marker>Zhou, Lin, Muntenau, Hovy, 2006</marker>
<rawString>L. Zhou, C.-Y. Lin, D. Muntenau, and E. Hovy. 2006. ParaEval: Using paraphrases to evaluate summaries automatically. In Proceedings of HLT-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>