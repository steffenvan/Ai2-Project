<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.555799">
A Computational Semantics for Natural Language
Lewis G. Creary and Carl J. Pollard
Hewlett-Packard Laboratories
1501 Page Mill Road
</title>
<author confidence="0.299547">
Palo Alto, CA 94304, USA
</author>
<sectionHeader confidence="0.94454" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947">
In the new Head-driven Phrase Structure Grammar
(HPSG) language processing system that is currently under
development at Hewlett-Packard Laboratories, the
Montagovian semantics of the earlier GPSG system (see
IGawron et al. 1982I) is replaced by a radically different
approach with a number of distinct advantages. In place
of the lambda calculus and standard first-order logic, our
medium of conceptual representation is a new logical for-
malism called NFLT (Neo-Fregean Language of Thought);
compositional semantics is effected, not by schematic
lambda expressions, but by LISP procedures that operate
on NFLT expressions to produce new expressions. NFLT
has a number of features that make it well-suited for nat-
ural language translations, including predicates of variable
arity in which explicitly marked situational roles supercede
order-coded argument positions, sortally restricted quan-
tification, a compositional (but nonextensional) semantics
that handles causal contexts, and a principled conceptual
raising mechanism that we expect to lead to a computation-
ally tractable account of propositional attitudes. The use
of semantically compositional LISP procedures in place of
lambda-schemas allows us to produce fully reduced trans-
!ations on the fly, with no need for post-processing. This
approach should simplify the task of using semantic infor-
mation (such as sortal incompatibilities) to eliminate bad
parse paths.
</bodyText>
<sectionHeader confidence="0.99836" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.997207767441861">
Someone who knows a natural language is able to use
utterances of certain types to give and receive information
about the world. How can we explain this? We take as
our point of departure the assumption that members of a
language community share a certain mental system — a
grammar — that mediates the correspondence between ut-
terance types and other things in the world, such as individ-
uals, relations, and states of affairs; to a large degree, this
system is the language. According to the relation theory
of meaning (Barwise &amp; Perry 119831), linguistic meaning is
a relation between types of utterance events and other as-
pects of objective reality. We accept this view of linguistic
meaning, but unlike Barwise and Perry we focus on how the
meaning relation is mediated by the intersubjective psycho-
logical system of grammar.
In our view, a computational semantics for a natural
language has three essential components:
a. a system of conceptual representation for internal use
as a computational medium in processes of information
retrieval, inference, planning, etc.
b. a system of linkages between expressions of the natural
language and those of the conceptual representation,
and
c. a system of linkages between expressions in the concep-
tual representation and objects, relations, and states of
affairs in the external world.
In this paper, we shall concentrate almost exclusively on
the first two components. We shall sketch our ontologi-
cal commitments, describe our internal representation lan-
guage, explain how our grammar (and our computer im-
plementation) makes the connection between English and
the internal representations, and finally indicate the present
status and future directions of our research.
Our internal representation language, NFLT. is due to
Creary 119831. The grammatical theory in which the present
research is couched is the theory of head grammar (HG) set
forth in [Pollard 19841 and [Pollard forthcoming; and imple-
mented as the front end of the HPSG (Head-driven Phrase
Structure Grammar) system, an English language database
query system under development at Hewlett-Packard Lab-
oratories. The non-semantic aspects of the implementation
are described in !Flickinger, Pollard, &amp; Wasow 19851 and
[Proudian Se Pollard 1984
</bodyText>
<sectionHeader confidence="0.995221" genericHeader="introduction">
2. Ontological Assumptions
</sectionHeader>
<bodyText confidence="0.936333647058823">
To get started, we make the following assumptions
about what categories of things are in the world.
a. There are individuals. These include objects of the
usual kind (such as Ron and Nancy) as well as situations.
Situations comprise states (such as Ron&apos;s being tall) and
events (such as Ron giving his inaugural address on January
21, 1985).
b. There are relations (subsuming properties). Exam-
ples are COOKIE (= the property of being a cookie) and El.TY
(= the relation which Nancy has to the cookies she buys).
Associated with each relation is a characteristic set of roles
appropriate to that relation (such as AGENT, PATIENT, LO-
CATION, etc.) which can be filled by individuals. Simple
situations consist of individuals playing roles in relations.
Unlike properties and relations in situation semantics
[Barwise &amp; Perry 19831, our relations do not have fixed ar-
ity (number of arguments). This is made possible by taking
</bodyText>
<page confidence="0.995513">
172
</page>
<bodyText confidence="0.953717391304348">
explicit account of roles, and has important linguistic con-
sequences. Also there is no distinguished ontological cate-
gory of locations; instead, the location of an event is just
the individual that fills the LOCATION role.
c. Some relations are sortal relations, or sorts. Associ-
ated with each sort (but not with any non-sortal relation)
is a criterion of identity for individuals of that sort ECoc-
chiarella 1977, Gupta 19801. Predicates denoting sorts oc-
cur in the restrictor-clauses of quantifiers (see section 4.2
below), and the associated criteria of identity are essential
to determining the truth values of quantified assertions.
Two important sorts of situations are states and events.
One can characterize a wide range of subsorts of these
(which we shall call situation types) by specifying a par-
ticular configuration of relation, individuals, and roles. For
example, one might consider the sort of event in which Ron
kisses Nancy in the Oval Office, i.e. in which the relation is
KISS, Ron plays the AGENT role, Nancy plays the PATIENT
role, and the Oval Office plays the LOCATION role. One
might also consider the sort of state in which Ron is a per-
son, i.e. in which the relation is PERSON, and Ron plays
the INSTANCE role. We assume that the INSTANCE role is
appropriate only for sortal relations.
</bodyText>
<listItem confidence="0.866169212121212">
d. There are concepts, both subjective and objective.
Some individuals are information-processing organisms that
use complex symbolic objects (subjective concepts) as com-
putational media for information storage and retrieval, in-
ference, planning, etc. An example is Ron&apos;s internal rep-
resentation of the property COOKIE. This representation
in turn is a token of a certain abstract type TCOOKIE,
an objective concept which is shared by the vast majority
of speakers of English.&apos; Note that the objective concept
TCOOKIE, the property. COOKIE, and the extension of that
property (i.e. the set of all cookies) are three distinct things
that play three different roles in the semantics of the Eng-
lish noun cookie.
e. There are computational processes in organisms for
manipulating concepts e.g. methods for constructing com-
plex concepts from simpler ones, inferencing mechanisms,
etc. Concepts of situations are called propositions; organ-
isms use inferencing mechanisms to derive new propositions
from old. To the extent that concepts are accurate repre-
sentations of existing things and the relations in which they
stand, organisms can contain information. We call the sys-
tem of objective concepts and concept-manipulating mech-
anisms instantiated in an organism its conceptual system.
Communities of organisms can share the same conceptual
system.
f. Communities of organisms whose common concep-
tual system contains a subsystem of a certain kind called
a grammar can communicate with each other. Roughly,
grammars are conceptual subsystems that mediate between
events of a specific type (called utterances) and other as-
pects of reality. Grammars enable organisms to use utter-
ances to give and receive information about the world. This
is the subject of sections 4-6.
</listItem>
<sectionHeader confidence="0.888858" genericHeader="method">
3. The Internal
</sectionHeader>
<subsectionHeader confidence="0.690916">
Representation Language: NFLT
</subsectionHeader>
<bodyText confidence="0.996518235294118">
The translation of input sentences into a logical for-
malism of some kind is a. fairly standard feature of com-
puter systems for natural-language understanding, and one
• which is shared by the HPSG system. A distinctive feature
of this system, however, is the particular logical formalism
involved, which is called NFLT (Neo-Fregean Language of
Thought).2 This. is a new logical language that is being
developed to serve as the internal representation medium
in computer agents with natural language capabilities. The
language is the result of augmenting and partially reinter-
preting the standard predicate calculus formalism in sev-
eral ways, some of which will be described very briefly in
this section. Historically, the predicate calculus was de-
veloped by mathematical logicians as an explication of the
logic of mathematical proofs, in order to throw light on
the nature of purely mathematical concepts and knowledge.
Since many basic concepts that are commonplace in natu-
ral language (including concepts of belief, desire, intention,
temporal change, causality, subjunctive conditionality, etc.)
play no role in pure mathematics, we should not be espe-
cially surprised to find that the predicate calculus requires
supplementation in order to represent adequately and natu-
rally information involving these concepts. The belief that
such supplementation is needed has led to the design of
NF LT.
While NFLT is much closer semantically to natural lan-
guage than is the standard predicate calculus, and is to
some extent inspired by psychologistic considerations, it
is nevertheless a formal logic admitting of a mathemati-
cally precise semantics. The intended semantics incorpo-
rates a Fregean distinction between sense and denotation,
associated principles of compositionality, and a somewhat
non-Fregean theory of situations or situation-types as the
denotations of sentential formulas.
</bodyText>
<subsectionHeader confidence="0.999268">
3.1. Predicates of Variable Arity
</subsectionHeader>
<bodyText confidence="0.999923578947368">
Atomic formulas in NFLT have an explicit role-marker
for each argument; in this respect NFLT resembles seman-
tic network formalisms and differs from standard predicate
We regard this notion of objective concept as the appro-
priate basis on which to reconstruct, ill terms of informa-
tion processing, Saussure&apos;s notions of signsfiant (signifier)
and sign:fie (signified) 119161, as well as Frege&apos;s notion of
Sinn (sense, connotation) [18921.
2 The formalism is called &amp;quot;neo-Fregean&amp;quot; because it in-
corporates many of the semantic ideas of Gottlob Frege,
though it also departs from Frege&apos;s ideas in several signif-
icant ways. It is called a language of thought&amp;quot; because
unlike English, which is first and foremost a medium of
communication, NFLT is designed to serve as a medium
of reasoning in computer problem-solving systems, which
we regard for theoretical purposes as thinking organisms.
(Frege referred to his own logical formalism, Begrifiessehrift,
as a &amp;quot;formula language for pure thought&amp;quot; [Frege 1879, title
and p. 6 (translation)[).
</bodyText>
<page confidence="0.994365">
173
</page>
<bodyText confidence="0.997433">
calculus, in which the roles are order-coded. This explicit
representation of roles permits each predicate-symbol in
NFLT to take a variable number of arguments, which in
turn makes it possible to represent occurrences of the same
verb with the same predicate-symbol, despite differences
in valence (i.e. number and identity of attached comple-
ments and adjuncts). This clears up a host of problems
that arise in theoretical frameworks (such as Montague se-
mantics and situation semantics) that depend on fixed-arity
relations (see [Carlson forthcoming] and Powty 19821 for
discussion). In particular, new roles (corresponding to ad-
juncts or optional complements in natural language) can be
added as required, and there is no need for explicit existen-
tial quantification over &amp;quot;missing arguments&amp;quot;.
Atomic formulas in NFLT are compounded of a base-
predicate and a set of rolemark-argument pairs, as in the
following example:
</bodyText>
<listItem confidence="0.688391">
(1a) English:
</listItem>
<figure confidence="0.851203571428571">
Ron kissed Nancy in the Oval Office on April
1, 1985.
(1b) NFLT Internal Syntax:
(kiss (agent . ron)
(patient . nancy)
(location . oval—office)
(time . 4-1-85) )
</figure>
<listItem confidence="0.8028134">
(1c) NFLT Display Syntax:
(KISS aqt:RON
ptnt :NANCY
loc:OVAL—OFFICE
att: 4-1-8 5 )
</listItem>
<bodyText confidence="0.99947025">
The base-predicate &apos;KISS&apos; takes a variable number of argu-
ments, depending on the needs of a particular context. In
t.le display syntax, the arguments are explicitly introduced
by abbreviated lowercase role markers.
</bodyText>
<subsectionHeader confidence="0.994856">
3.2. Sortal Quantification
</subsectionHeader>
<bodyText confidence="0.9922845">
Quantificational expressions in NFLT differ from those
in predicate calculus by always containing a restrictor-clause
consisting of a sortal predication, in addition to the usual
scope-clause, as in the following example:
</bodyText>
<listItem confidence="0.918701">
(2a) English:
</listItem>
<bodyText confidence="0.462306">
Ron ate a cookie in the Oval Office.
</bodyText>
<equation confidence="0.5202544">
(2b) NF LT Display Syntax:
(SOME X5
(COOKIE inst:X5)
(EAT agt:RON ptnt:X5
loc:OVAL—OFFICE))
</equation>
<bodyText confidence="0.9995249">
Note that we always quantify over instances of a sort, i.e.
the quantified variable fills the instance role in the restrictor-
c lause.
This style of quantifier is superior in several ways to
that of the predicate calculus for the purposes of represent-
ing commonsense knowledge. It is intuitively more natu-
ral, since it follows the quantificational pattern of English.
More importantly, it is more general, being sufficient to
handle a number of natural language determiners such as
many, most, few, etc., that cannot be represented using only
the unrestricted quantification of standard predicate calcu-
lus (see [Wallace 19651, 113arwise Sz Cooper 19811). Finally,
information carried by the sortal predicates in quantifiers
(namely, criteria of identity for things of the various sorts
in question) provides a sound semantic basis for counting
the members of extensions of such predicates (see section
2, assumption c above).
Any internal structure which a variable may have is
irrelevant to its function as a uniquely identifiable place-
holder in a formula. In particular, a quantified formula can
itself serve as its own &amp;quot;bound variable&amp;quot;. This is how quanti-
fiers are actually implemented in the HPSG system; in the
internal (i.e. implementation) syntax for quantified NFLT-
formulas, bound variables of the usual sort are dispensed
with in favor of pointers to the relevant quantified formu-
las. Thus, of the three occurrences of X5 in the display-
formula (2b), the first has no counterpart in the internal
syntax, while the last two correspond internally to LISP
pointers back to the data structure that implements (2b).
This method of implementing quantification has some im-
portant advantages. First, it eliminates the technical prob-
lems of variable clash that arise in conventional treatments.
There are no &amp;quot;alphabetic variants&amp;quot;, just structurally equiv-
alent concept tokens. Secondly, each occurrence of a quanti-
fied &amp;quot;bound variable&amp;quot; provides direct computational access
to the determiner, restrictor-clause, and scope-clause with
which it is associated.
A special class of quantificational expressions, called
quantifier expressions, have no scope-clause. An example
is:
</bodyText>
<listItem confidence="0.72496">
(3) NFLT Display Syntax:
</listItem>
<sectionHeader confidence="0.215227" genericHeader="method">
(SOME X1 (COOKIE inst: x1))
</sectionHeader>
<bodyText confidence="0.7636685">
Such expressions translate quantified noun phrases in En-
glish, e.g. a cookie.
</bodyText>
<subsectionHeader confidence="0.995756">
3.3. Causal Relations and
Non-Extensionality
</subsectionHeader>
<bodyText confidence="0.970974466666667">
According to the standard semantics for the predicate
calculus, predicate symbols denote the extensions of rela-
tions (i.e. sets of ordered n-tuples) and sentential formu-
las denote truth values. By contrast, we propose a non-
extensional semantics for NFLT: we take predicate symbols
to denote relations themselves (rather than their exten-
sions), and sentential formulas to denote situations or situ-
ation types (rather than the corresponding truth values).3
The motivation for this is to provide for the expression of
propositions involving causal relations among situations, as
in the following example:
3 The distinction between situations and situation types
corresponds roughly to the finite/infinitive distinction in
natural language. For discussion of this within the frame-
work of situation semantics, see [Cooper 19841.
</bodyText>
<page confidence="0.983968">
174
</page>
<figure confidence="0.884780714285714">
(4a) English:
John has brown eyes because he is of genotype
XYZW.
(4b) NFLT Display Syntax:
(CAUSE
conditn:(GENOTYPE-XYZW inst:JOHN)
result:(HROWN-EYED bearer:JOHN) )
</figure>
<bodyText confidence="0.999832317073171">
Now, the predicate calculus is an extensional language
in the sense that the replacement of categorical subparts
within an expression by new subparts having the same
extension must preserve the extension of the original ex-
pression. Such replacements within a sentential expression
must preserve the truth-value of the expression, since the
extension of a sentence is a truth-value. NFLT is not ex-
tensional in this sense. In particular, some of its predicate-
symbols may denote causal relations among situations, and
extension-preserving substitutions within causal contexts
do not generally preserve the causal relations. Suppose,
For example, that the formula (4b) is true. While the ex-
tension of the NFLT-predicate `GENOTYPE-XYZW&apos; is the
set of animals of genotype XYZW, its denotation is not this
set, but rather what Putnam 119691 would call a &amp;quot;physical
property&amp;quot;, the property of having the genotype XYZW. As
noted above (section 2, assumption d) a property is to be
distinguished both from the set of objects of which it holds
and from any concept of it. Now even if this property were
to happen by coincidence to have the same extension as
the property of being a citizen of Palo Alto born precisely
at noon on 1 April 1956, the substitution of a predicate-
symbol denoting this latter property for `GENOTYPE-XYZW&apos;
in the formula (4b) would produce a falsehood.
However, NFLT&apos;s lack of extensionality does not involve
any departure from compositional semantics. The deno-
tation of an NFLT-predicate-symbol is a property; thus,
although the substitution discussed earlier preserves the
extension of `GENOTYPE-XYZW&apos;, it does not preserve the
denotation of that predicate-symbol. Similarly, the deno-
tation of an NFLT-sentence is a situation or situation-type,
as distinguished both from a mere truth-value and from d.
proposition.4 Then, although NFLT is not an extensional
language in the standard sense, a Fregean analogue of the
principle of extensionality does hold for it: The replace-
ment of subparts within an expression by new subparts
having the same denotation must preserve the denotation
of the original expression (see 1Frege 1892)). Moreover, such
replacements within an NFLT-sentence must preserve the
truth-value of that sentence. since the truth-value is deter-
mined by the denotation.
</bodyText>
<subsectionHeader confidence="0.9445455">
3.4. Intentionality and
Conceptual Raising
</subsectionHeader>
<bodyText confidence="0.999346153846154">
The NFLT notation for representing information about
propositional attitudes is an improved version of the neo-
Fregean scheme described in [Creary 19791, section 2, which
is itself an extension and improvement of that found in
[McCarthy 19791. The basic idea underlying this scheme
is that propositional attitudes are relations between peo-
plc (or other intelligent organisms) and propositions; both
terms of such relations are taken as members of the do-
main of discourse. Objective propositions and their com-
ponent objective concepts are regarded as abstract enti-
ties, roughly on a par with numbers, sets, etc. They are
person-independent components of situations involving be-
lief, knowledge, desire, and the like. More specifically, ob-
jective concepts are abstract types which may have as to-
kens the subjective concepts of individual organisms, which
in turn are configurations of information and associated
procedures in various individual memories (cf. section 2,
assumption d above).
Unlike Montague semantics [Montague 19731, the se-
mantic theory underlying NFLT does not imply that an
organism necessarily believes all the logical equivalents of
a proposition it believes. This is because distinct propo-
sitions have as tokens distinct subjective concepts, even if
they necessarily have the same truth-value.
Here is an example of the use of NFLT to represent
information concerning propositional attitudes:
</bodyText>
<listItem confidence="0.478701">
(5a) English:
Nancy wants to tickle Ron.
(5b) NFLT Display Syntax:
</listItem>
<sectionHeader confidence="0.6959135" genericHeader="method">
(WANT appr:NANCY
prop:t(TICKLE agt:I ptnt:RON))
</sectionHeader>
<bodyText confidence="0.975312161290323">
In a Fregean spirit, we assign to each categorematic
expression of NFLT both a sense and a denotation. For ex-
ample, the denotation of the predicate-constant `COOKIE&apos;
is the property COOKIE, while the sense of that constant is
a certain objective concept - the &amp;quot;standard public&amp;quot; concept
of a cookie. We say that `COOKIE&apos; expresses its sense and
denotes its denotation. The result of appending the -con-
ceptual raising&amp;quot; symbol to the constant &apos;COOKIE&apos; is
a new constant, fC001ar, that denotes the concept that
&apos;COOKIE&apos; expresses (i.e. applies to a constant and forms
a standard name of the sense of that constant). By ap-
pending multiple occurrences of T&apos; to constants, we obtain
new constants that denote concepts of concepts, concepts
of concepts of concepts, etc.5
In expression (5b), is not explicitly appended to
a constant, but instead is prefixed to a compound expres-
sion. When used in this way, &apos; functions as a syncat-
egorematic operator that &amp;quot;conceptually raises&amp;quot; each cate-
goretnatic constant within its scope and forms a term incor-
porating the raised constants and denoting a proposition.
Thus, something similar to what Barwise and Perry call
&amp;quot;situation semantics&amp;quot; 119831 is to be provided for NFLT-
expressions, insofar as those expressions involve no ascrip-
tion of propositional attitudes (the Barwise-Perry semantics
for ascriptions of propositional attitudes takes a quite dif-
ferent approach from that to be described for NFLT in the
next section):
5 For further details concerning this Fregean conceptual
hierarchy, see [Creary 19791, sections 2.2 and 2.3.1. Cap-
italization, l&apos;-postaxing, and braces are used there to do
the work done here by the symbol
</bodyText>
<page confidence="0.997457">
175
</page>
<bodyText confidence="0.996973235294118">
Thus, the subformula (TICKLE aqt:I RUM:RON) is
the name of a proposition whose component concepts are
the relation-concept ITICRLE and the individual concepts
II and IRON. This proposition is the sense of the unraised
subformula (TICKLE aqt:I ptnt: RON)
The individual concept II, the minimal concept of self,
is an especially interesting objective concept. We assume
that for each sufficiently self-conscious and active organism
X, X&apos;s minimal internal representation of itself is a token of
II. This concept is the sense of the indexical pronoun I, and
is itself indexical in the sense that what it is a concept of is
determined not by its content (which is the same for each
token), but rather by the context of its use. The content
of this concept is partly descriptive but mostly procedural,
consisting mainly of the unique and important role that it
plays in the information-processing of the organisms that
have it.
</bodyText>
<sectionHeader confidence="0.993063" genericHeader="method">
4. Lexicon
</sectionHeader>
<bodyText confidence="0.999959363636364">
HPSG&apos;s head grammar takes as its point of departure
Saussure&apos;s (19161 notion of a sign. A sign is a conceptual ob-
ject, shared by a group of organisms, which consists of two
associated concepts that we call (by a conventional abuse of
language) a phonological representation and a semantic rep-
resentation. For example, members of the English-speaking
community share a sign which consists of an internal rep-
resentation of the utterance-type /kUki/ together with an
internal representation of the property of being a cookie.
In a computer implementation, we model such a concep-
tual object with a data object of this form:
</bodyText>
<listItem confidence="0.531261">
(6) {cookie ; comazI
</listItem>
<bodyText confidence="0.999980904761905">
Here the symbol &apos;cookie&apos; is a surrogate for a phonological
representation (in fact we ignore phonology altogether and
deal only with typewritten English input). The symbol
`COOKIE&apos; (a basic constant of NFLT denoting the prop-
erty COOKIE) models the corresponding semantic represen-
tation. We call a data object such as (6) a lexical entry.
Of course there must be more to a language than simple
signs like (6). Words and phrases of certain kinds can char-
acteristically combine with certain other kinds of phrases to
form longer expressions that can convey information about
the world. Correspondingly, we assume that a grammar
contains in addition to a lexicon a set of grammatical rules
(see next section) for combining simple signs to produce
new signs which pair longer English expressions with more
complex NFLT translations. For rules to work, each sign
must contain information about how it figures in the rules.
We call this information the (syntactic) category of the
sign. Following established practice, we encode categories
as specifications of values for a finite set of features. Aug-
mented with such information, lexical signs assume forms
such as these:
</bodyText>
<listItem confidence="0.8452575">
(7a) (cookie; COOKIE; [MAJOR: N; AGR: 3RDSGI}
(7b) {kisses; KISS; (MAJOR: V; VFORM: FIN(}
</listItem>
<bodyText confidence="0.991711411764706">
Such features as MAJOR (major category), AGR (agree-
ment), and VFORM (verb form) encode inherent syntactic
properties of signs.
Still more information is required, however. Certain
expressions (heads) characteristically combine with other
expressions of specified categories (complements) to form
larger expressions. (For the time being we ignore optional
elements, called adjuncts.) This is the linguistic notion of
subcategorization. For example, the English verb touches
subcategorizes for two NP&apos;s, of which one must be third-
person-singular. We encode subcategorization information
as the value of a feature called SUBCAT. Thus the value
of the SUBCAT feature is a sequence of categories. (Such
features, called stack-valued features, play a central role
in the HG account of binding. See (Pollard forthcoming!.)
Augmented with its SUBCAT feature, the lexical sign (2b)
takes the form:
</bodyText>
<listItem confidence="0.688444">
(8) {kisses; KISS; [MAJOR: V; VFORM: FIN!
SUBCAT: NP, NP-3RDSG}
</listItem>
<bodyText confidence="0.998101473684211">
(Symbols like `NP&apos; and `NP-3RDSG&apos; are shorthand for cer-
tain sets of feature specifications). For ease of reference,
we use traditional grammatical relation names for comple-
ments. Modifying the usage of Dowty 119821, we designate
them (in reverse of the order that they appear in SUBCAT)
as subject, direct object, indirect object, and oblique objects.
(Under this definition, determiners count as subjects of the
nouns they combine with.) Complements that themselves
subcategorize for a complement fall outside this hierarchy
and are called controlled complements. The complement
next in sequence after a controlled complement is called its
controller.
For the sign (8) to play a communicative role, one ad-
ditional kind of information is needed. Typically, heads
give information about relations, while complements give
information about the roles that individuals play in those
relations. Thus lexical signs must assign roles to their com-
plements. Augmented with role-assignment information,
the lexical sign (8) takes the form:
</bodyText>
<listItem confidence="0.838023">
(9) {kisses; KISS; (MAJOR: V: VFORM: FIN!
SUBCAT: ,NP, patient),
(NP-3RDSG, agent)}
</listItem>
<bodyText confidence="0.99929975">
Thus (9) assigns the roles AGENT and PATIENT to the sub-
ject and direct object respectively. (Note: we assume that
nouns subcategorize for a determiner complement and as-
sign it the instance role. See section 6 below.)
</bodyText>
<sectionHeader confidence="0.951614" genericHeader="method">
5. Grammatical Rules
</sectionHeader>
<bodyText confidence="0.971905636363636">
In addition to the lexicon, the grammar must contain
mechanisms for constructing more complex signs that me-
diate between longer English expressions and more complex
NFLT translations. Such mechanisms are called grammat-
ical rules. From a purely syntactic point of view, rules can
be regarded as ordering principles. For example, English
grammar has a rule something like this:
(10) If X is a sign whose SUBCAT value contains just
one category Y, and Z is a sign whose category is
consistent with Y, then X and Z can be combined
to form a new sign W whose expression is got by
</bodyText>
<page confidence="0.997179">
176
</page>
<bodyText confidence="0.987182">
concatenating the expressions of X and Z.
That is, put the final complement (subject) to the left of
the head. We write this rule in the abbreviated form:
</bodyText>
<listItem confidence="0.47362">
(11) -&gt; C H [Condition: length of SUBCAT of H = 11
</listItem>
<bodyText confidence="0.993843375">
The form of (11) is analogous to conventional phrase struc-
ture rules such as NP — &gt; DET N or S — &gt; NP VP;
in fact (11) subsumes both of these. However, (11) has
no left-hand side. This is because the category of the
constructed sign (mother) can be computed from the con-
stituent signs (daughters) by general principles, as we shall
presently show.
Two more rules of English are:
</bodyText>
<listItem confidence="0.874461">
(12) -&gt; H C [Condition: length of SUBCAT of H = 21
(13) -&gt; H C2 CI
[Condition: length of SUBCAT of H = 31
(12) says: put a direct object or subject-controlled comple-
</listItem>
<bodyText confidence="0.991219230769231">
ment after the head. And (13) says: put an indirect object
or object-controlled complement after the direct object. As
in (11), the complement signs have to be consistent with
the subcategorization specifications on the head. In (13),
the indices on the complement symbols correspond to the
order of the complement categories in the SUBCAT of the
head.
The category and translation of a mother need not be
specified by the rule used to construct it. Instead, they are
computed from information on the daughters by universal
principles that govern rule application. Two such princi-
ples are the Head Feature Principle (HFP) (14) and the
Subcategorization Principle (15):
</bodyText>
<listItem confidence="0.885914">
(14) Head Feature Principle:
</listItem>
<bodyText confidence="0.9978896">
Unless otherwise specified, the head features on a
mother coincide with the head features on the head
daughter.
(For present purposes, assume the head features are all fea-
tures except SUBCAT.)
</bodyText>
<listItem confidence="0.829605">
(15) Subcategorization Principle:
</listItem>
<bodyText confidence="0.9998827">
The SUBCAT value on the mother is got by deleting
from the SUBCAT value on the head daughter those
categories corresponding to complement daughters.
(Additional principles not discussed here govern control and
binding.) The basic idea is that we start with the head
daughter and then process the complement daughters in the
order given by the indices on the complement symbols in the
rule. So far, we have said nothing about the determination
of the mother&apos;s translation. We turn to this question in the
next section.
</bodyText>
<sectionHeader confidence="0.904587" genericHeader="method">
6. The Semantic Interpretation Principle
</sectionHeader>
<bodyText confidence="0.999926363636364">
Now we can explain how the NFLT-translation of a
phrase is computed from the translations of its constituents.
The basic idea is that every time we apply a grammar rule,
we process the head first and then the complements in
the order indicated by the rule (see [Proudian &amp; Pollard
19851). As each complement is processed, the correspond-
ing category-role pair is popped off the SUBCAT stack of
the head; the category information is merged (unified) with
the category of the complement, and the role information is
used to combine the complement translation with the head
translation. We state this formally as:
</bodyText>
<listItem confidence="0.836547">
(16) Semantic Interpretation Principle (SIP):
</listItem>
<bodyText confidence="0.87627275">
The translation of the mother is computed by the
following program:
a. Initialize the mother&apos;s translation to be the
head daughter&apos;s translation.
b. Cycle through the complement daughters, set-
ting the mother&apos;s translation to the result of
combining the complement&apos;s translation with
the mother&apos;s translation.
c. Return the mother&apos;s translation.
The program given in (16) calls a function whose ar-
guments are a sign (the complement), a rolemark (gotten
from the top of the head&apos;s SUBCAT stack), and an NFLT
expression (the value of the mother translation computed
thus far). This function is given in (17). There are two
cases to consider, according as the translation of the com-
plement is a determiner or not.
</bodyText>
<sectionHeader confidence="0.539947" genericHeader="method">
(17) Function for Combining Complements:
</sectionHeader>
<bodyText confidence="0.978290793103448">
a. If the MAJOR feature value of the comple-
ment is DET, form the quantifier-expression
whose determiner is the complement transla-
tion and whose restriction is the mother trans-
lation. Then add to the restriction a role link
with the indicated rolemark (viz. instance)
whose argument is a pointer back to that quan-
tifier-expression, and return the resulting quan-
tifier-expression.
b. Otherwise, add to the mother translation a role
link with the indicated rolemark whose argu-
ment is a pointer to the complement transla-
tion (a quantifier-expression or individual con-
stant). If the complement translation is a quan-
tifier-expression, return the quantificational ex-
pression formed from that quantifier-expression
by letting its scope-clause be the mother trans-
lation; if not, return the mother translation.
The first case arises when the head daughter is a noun
and the complement is a determiner. Then (17) simply re-
turns a complement like (3). In the second case, there are
two subcases according as the complement translation is
a quantifier-expression or something else (individual con-
stant, sentential expression, propositional term, etc.) For
example, suppose the head is this:
(18) (jogs ; JOG; IMAJOR: V; VFORM: FIN!
SUBCAT: (NP-3RDSG, agent) }
If the (subject) complement translation is &apos;RON&apos; (not a quan-
tifier-expression), the mother translation is just:
</bodyText>
<sectionHeader confidence="0.347869" genericHeader="method">
(19) (JOG agt: RON) ;
</sectionHeader>
<bodyText confidence="0.669658666666667">
but if the complement translation is
(ALL P3 (PERSON inst: P3 ) )
(a quantifier-expression), the mother translation is:
</bodyText>
<page confidence="0.992838">
177
</page>
<bodyText confidence="0.926194">
concatenating the expressions of X and Z.
That is, put the final complement (subject) to the left of
the head. We write this rule in the abbreviated form:
</bodyText>
<equation confidence="0.346864">
(11) -&gt; C H [Condition: length of SUBCAT of H = 11
</equation>
<bodyText confidence="0.967835">
The form of (11) is analogous to conventional phrase struc-
ture rules such as NP — &gt; DET N or S — &gt; NP VP;
in fact (11) subsumes both of these. However, (11) has
no left-hand side. This is because the category of the
constructed sign (mother) can be computed from the con-
stituent signs (daughters) by general principles, as we shall
presently show.
</bodyText>
<figure confidence="0.535385">
Two more rules of English are:
(12) -&gt; H C [Condition: length of SUBCAT of H = 21
(13) -&gt; H C2 Cl
</figure>
<bodyText confidence="0.950805">
[Condition: length of SUBCAT of H = 31
(12) says: put a direct object or subject-controlled comple-
ment after the head. And (13) says: put an indirect object
or object-controlled complement after the direct object. As
in (11), the complement signs have to be consistent with
the subcategorization specifications on the head. In (13),
the indices on the complement symbols correspond to the
order of the complement categories in the SUBCAT of the
head.
The category and translation of a mother need not be
specified by the rule used to construct it. Instead, they are
computed from information on the daughters by universal
principles that govern rule application. Two such princi-
ples are the Head Feature Principle (HF?) (14) and the
Subcategorization Principle (15):
</bodyText>
<subsectionHeader confidence="0.49171">
(14) Head Feature Principle:
</subsectionHeader>
<bodyText confidence="0.9645524">
Unless otherwise specified, the head features on a
mother coincide with the head features on the head
daughter.
(For present purposes, assume the head features are all fea-
tures except SUBCAT.)
</bodyText>
<subsectionHeader confidence="0.641253">
(15) Subcategorization Principle:
</subsectionHeader>
<bodyText confidence="0.997827">
The SUBCAT value on the mother is got by deleting
from the SUBCAT value on the head daughter those
categories corresponding to complement daughters.
(Additional principles not discussed here govern control and
binding.) The basic idea is that we start with the head
daughter and then process the complement daughters in the
order given by the indices on the complement symbols in the
rule. So far, we have said nothing about the determination
of the mother&apos;s translation. We turn to this question in the
next section.
</bodyText>
<sectionHeader confidence="0.991975" genericHeader="method">
6. The Semantic Interpretation Principle
</sectionHeader>
<bodyText confidence="0.996429727272727">
Now we can explain how the NFLT-translation of a
phrase is computed from the translations of its constituents.
The basic idea is that every time we apply a grammar rule,
we process the head first and then the complements in
the order indicated by the rule (see [Proudian &amp; Pollard
19851). As each complement is processed, the correspond-
ing category-role pair is popped off the SUBCAT stack of
the head; the category information is merged (unified) with
the category of the complement, and the role information is
used to combine the complement translation with the head
translation. We state this formally as:
</bodyText>
<reference confidence="0.9555616">
(16) Semantic Interpretation Principle (SIP):
The translation of the mother is computed by the
following program:
a. Initialize the mother&apos;s translation to be the
head daughter&apos;s translation.
b. Cycle through the complement daughters, set-
ting the mother&apos;s translation to the result of
combining the complement&apos;s translation with
the mother&apos;s translation.
c. Return the mother&apos;s translation.
</reference>
<bodyText confidence="0.983705">
The program given in (16) calls a function whose ar-
guments are a sign (the complement), a rolemark (gotten
from the top of the head&apos;s SUBCAT stack), and an NFLT
expression (the value of the mother translation computed
thus far). This function is given in (17). There are two
cases to consider, according as the translation of the com-
plement is a determiner or not.
</bodyText>
<sectionHeader confidence="0.841529" genericHeader="method">
(17) Function for Combining Complements:
</sectionHeader>
<bodyText confidence="0.99990536">
a. If the MAJOR feature value of the comple-
ment is DET, form the quantifier-expression
whose determiner is the complement transla-
tion and whose restriction is the mother trans-
lation. Then add to the restriction a role link
with the indicated rolemark (viz. instance)
whose argument is a pointer back to that quan-
tifier-expression, and return the resulting quan-
tifier-expression.
b. Otherwise, add to the mother translation a role
link with the indicated rolernark whose argu-
ment is a pointer to the complement transla-
tion (a quantifier-expression or individual con-
stant). If the complement translation is a quan-
tifier-expression, return the quantificational ex-
pression formed from that quantifier-expression
by letting its scope-clause be the mother trans-
lation; if not, return the mother translation.
The first case arises when the head daughter is a noun
and the complement is a determiner. Then (17) simply re-
turns a complement like (3). In the second case. there are
two subcases according as the complement translation is
a quantifier-expression or something else (individual con-
stant, sentential expression, propositional term. etc.) For
example, suppose the head is this:
</bodyText>
<reference confidence="0.890849125">
(18) (jogs ; JOG; (MAJOR: V; VFORNI: FIN)
SUBCAT: KNP-3RDSC, agent)}
If the (subject) complement translation is &apos;RON&apos; ( not a quan-
tifier-expression), the mother translation is just:
(19) (JOG agt: RON) ;
but if the complement translation is
&apos;(ALL P3 (PERSON inst: P3 )
(a quantifier-expression), the mother translation is:
</reference>
<page confidence="0.978505">
177
</page>
<reference confidence="0.998337791666667">
son, Yale University Press, New Haven and London,
1974.
Pollard, Carl [19841. Generalized Phrase Structure Gram-
mars, Head Grammars, and Natural Language. Doc-
toral dissertation, Stanford University.
Pollard, Carl iforthcomingl. &amp;quot;A Semantic Approach to
Binding in a Monostratal Theory.&apos; To appear in
Linguistics and Philosophy.
Proudian, Derek, and Carl Pollard [1985]. &amp;quot;Parsing Head-
driven Phrase Structure Grammar.&amp;quot; Proceedings
of the 23rd Annual Meeting of the Association for
Computational Linguistics.
Putnam, Hilary [1969]. On Properties.&amp;quot; In Essays in
Honor of Carl G. Hempel, N. Rescher, ed., D. Rei-
del, Dordrecht. Reprinted in Mind, Language, and
Reality: Philosophical Papers (Vol. I, Ch. 19), Cam-
bridge University Press, Cambridge, 1975.
Saussure, Ferdinand de [1916]. Cours de Linguistique Gen-
erale. Paris: Payot. Translated into English by
Wade Baskin as Course in General Linguistics, The
Philosophical Library, New York, 1959 (paperback
edition, McGraw-Hill, New York, 1966).
Wallace, John [1965]. &amp;quot;Sortal Predicates and Quantifica-
tion.&amp;quot; The Journal of Philosophy 62, 8-13.
</reference>
<page confidence="0.998796">
179
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000342">
<title confidence="0.999889">A Computational Semantics for Natural Language</title>
<author confidence="0.99965">Lewis G Creary</author>
<author confidence="0.99965">Carl J Pollard</author>
<affiliation confidence="0.998797">Hewlett-Packard Laboratories</affiliation>
<address confidence="0.998226">1501 Page Mill Road Palo Alto, CA 94304, USA</address>
<abstract confidence="0.994625254166667">In the new Head-driven Phrase Structure Grammar (HPSG) language processing system that is currently under development at Hewlett-Packard Laboratories, the Montagovian semantics of the earlier GPSG system (see IGawron et al. 1982I) is replaced by a radically different approach with a number of distinct advantages. In place of the lambda calculus and standard first-order logic, our medium of conceptual representation is a new logical formalism called NFLT (Neo-Fregean Language of Thought); compositional semantics is effected, not by schematic lambda expressions, but by LISP procedures that operate on NFLT expressions to produce new expressions. NFLT has a number of features that make it well-suited for natural language translations, including predicates of variable arity in which explicitly marked situational roles supercede order-coded argument positions, sortally restricted quantification, a compositional (but nonextensional) semantics handles causal contexts, and a principled raising mechanism that we expect to lead to a computationally tractable account of propositional attitudes. The use compositional LISP procedures in place lambda-schemas allows us to produce fully reduced trans- !ations on the fly, with no need for post-processing. This approach should simplify the task of using semantic information (such as sortal incompatibilities) to eliminate bad parse paths. Someone who knows a natural language is able to use utterances of certain types to give and receive information about the world. How can we explain this? We take as our point of departure the assumption that members of a language community share a certain mental system — a grammar — that mediates the correspondence between utterance types and other things in the world, such as individuals, relations, and states of affairs; to a large degree, this language. According to the relation theory of meaning (Barwise &amp; Perry 119831), linguistic meaning is a relation between types of utterance events and other aspects of objective reality. We accept this view of linguistic meaning, but unlike Barwise and Perry we focus on how the meaning relation is mediated by the intersubjective psychological system of grammar. In our view, a computational semantics for a natural language has three essential components: a. a system of conceptual representation for internal use as a computational medium in processes of information retrieval, inference, planning, etc. b. a system of linkages between expressions of the natural language and those of the conceptual representation, and c. a system of linkages between expressions in the conceprepresentation and objects, relations, states of in the external this paper, we shall concentrate exclusively on first two components. We shall sketch ontological commitments, describe our internal representation lanhow our grammar (and our computer implementation) makes the connection between English and internal representations, and indicate the present status and future directions of our research. Our internal representation language, NFLT. is due to Creary 119831. The grammatical theory in which the present research is couched is the theory of head grammar (HG) set forth in [Pollard 19841 and [Pollard forthcoming; and implemented as the front end of the HPSG (Head-driven Phrase Structure Grammar) system, an English language database system under development at Laboratories. The non-semantic aspects of the implementation are described in !Flickinger, Pollard, &amp; Wasow 19851 and Se 1984 2. Ontological Assumptions To get started, we make the following assumptions about what categories of things are in the world. a. There are individuals. These include objects of the kind (such as Ron and Nancy) as well as Situations comprise states (such as Ron&apos;s being tall) and events (such as Ron giving his inaugural address on January 21, 1985). There are Examples are COOKIE (= the property of being a cookie) and El.TY the relation which Nancy has to the cookies buys). with each relation is a characteristic set of to that relation (such as PATIENT, LOwhich can be filled by individuals. Simple situations consist of individuals playing roles in relations. Unlike properties and relations in situation semantics [Barwise &amp; Perry 19831, our relations do not have fixed ar- (number of This is made by taking 172 explicit account of roles, and has important linguistic consequences. Also there is no distinguished ontological category of locations; instead, the location of an event is just the individual that fills the LOCATION role. Some relations are sortal relations, or Associated with each sort (but not with any non-sortal relation) is a criterion of identity for individuals of that sort ECocchiarella 1977, Gupta 19801. Predicates denoting sorts occur in the restrictor-clauses of quantifiers (see section 4.2 below), and the associated criteria of identity are essential to determining the truth values of quantified assertions. important sorts of situations are One can characterize a wide range of subsorts of these we shall call situation specifying a particular configuration of relation, individuals, and roles. For example, one might consider the sort of event in which Ron kisses Nancy in the Oval Office, i.e. in which the relation is plays the Nancy plays the and the Oval Office plays the One might also consider the sort of state in which Ron is a peri.e. in which the relation is Ron plays We assume that the role is appropriate only for sortal relations. There are subjective and objective. individuals are information-processing use complex symbolic objects (subjective concepts) as computational media for information storage and retrieval, inference, planning, etc. An example is Ron&apos;s internal repthe property COOKIE. representation in turn is a token of a certain abstract type TCOOKIE, which is shared by the vast majority speakers of English.&apos; Note that the objective the COOKIE, and extension of that (i.e. the all cookies) are three three different the semantics of the Engnoun e. There are computational processes in organisms for manipulating concepts e.g. methods for constructing complex concepts from simpler ones, inferencing mechanisms, of situations are called organisms use inferencing mechanisms to derive new propositions from old. To the extent that concepts are accurate representations of existing things and the relations in which they stand, organisms can contain information. We call the system of objective concepts and concept-manipulating mechinstantiated in an organism its system. organisms can share the same conceptual system. f. Communities of organisms whose common concepsystem subsystem of a kind called can communicate with each other. Roughly, are conceptual mediate between of specific type (called utterances) and other asreality. Grammars enable organisms to use utterances to give and receive information about the world. This the subject of 3. The Internal Representation Language: NFLT The translation of input sentences into a logical forof some kind is standard feature of computer systems for natural-language understanding, and one which is shared by the HPSG system. A of this system, however, is the particular logical formalism involved, which is called NFLT (Neo-Fregean Language of This. is a new logical language that is being developed to serve as the internal representation medium in computer agents with natural language capabilities. The language is the result of augmenting and partially reinterthe standard predicate calculus in sevways, of which will be described very briefly in this section. Historically, the predicate calculus was developed by mathematical logicians as an explication of the logic of mathematical proofs, in order to throw light on the nature of purely mathematical concepts and knowledge. Since many basic concepts that are commonplace in natural language (including concepts of belief, desire, intention, change, causality, subjunctive conditionality, no role in mathematics, we should not be especially surprised to find that the predicate calculus requires supplementation in order to represent adequately and naturally information involving these concepts. The belief that such supplementation is needed has led to the design of NF LT. NFLT is much closer semantically to natural lanthan is the standard predicate calculus, inspired by psychologistic is nevertheless a formal logic admitting of a mathematiprecise semantics. The intended incorpoa Fregean distinction between sense principles of compositionality, and somewhat theory of situations or the denotations of sentential formulas. Predicates of Variable Atomic formulas in NFLT have an explicit role-marker each argument; in this respect NFLT semanformalisms differs from standard predicate regard this notion of concept the appropriate basis on which to reconstruct, ill terms of informa- Saussure&apos;s notions 119161, as well as Frege&apos;s notion of Sinn (sense, connotation) [18921. 2The formalism called incorporates many of the semantic ideas of Gottlob Frege, though it also departs from Frege&apos;s ideas in several significant ways. It is called a language of thought&amp;quot; because unlike English, which is first and foremost a medium of is designed to serve as a medium of reasoning in computer problem-solving systems, which we regard for theoretical purposes as thinking organisms. referred to his own logical formalism, as a &amp;quot;formula language for pure thought&amp;quot; [Frege 1879, title p. (translation)[). 173 calculus, in which the roles are order-coded. This explicit representation of roles permits each predicate-symbol in NFLT to take a variable number of arguments, which in turn makes it possible to represent occurrences of the same verb with the same predicate-symbol, despite differences in valence (i.e. number and identity of attached complements and adjuncts). This clears up a host of problems that arise in theoretical frameworks (such as Montague semantics and situation semantics) that depend on fixed-arity relations (see [Carlson forthcoming] and Powty 19821 for discussion). In particular, new roles (corresponding to adjuncts or optional complements in natural language) can be added as required, and there is no need for explicit existential quantification over &amp;quot;missing arguments&amp;quot;. Atomic formulas in NFLT are compounded of a basepredicate and a set of rolemark-argument pairs, as in the following example: (1a) English: Ron kissed Nancy in the Oval Office on April 1, 1985. (1b) NFLT Internal Syntax: (kiss (agent . ron) (patient . nancy) (location . oval—office) (time . 4-1-85) ) (1c) NFLT Display Syntax: ptnt :NANCY loc:OVAL—OFFICE att: 4-1-8 5 ) The base-predicate &apos;KISS&apos; takes a variable number of arguments, depending on the needs of a particular context. In t.le display syntax, the arguments are explicitly introduced by abbreviated lowercase role markers. 3.2. Sortal Quantification Quantificational expressions in NFLT differ from those in predicate calculus by always containing a restrictor-clause consisting of a sortal predication, in addition to the usual scope-clause, as in the following example:</abstract>
<note confidence="0.9700405">(2a) English: Ron ate a cookie in the Oval Office. (2b) NF LT Display Syntax: (SOME X5 (COOKIE inst:X5) (EAT agt:RON ptnt:X5</note>
<email confidence="0.536728">loc:OVAL—OFFICE))</email>
<abstract confidence="0.97609368115942">Note that we always quantify over instances of a sort, i.e. quantified variable fills the in the restrictorc lause. This style of quantifier is superior in several ways to that of the predicate calculus for the purposes of representcommonsense knowledge. It is intuitively more natural, since it follows the quantificational pattern of English. More importantly, it is more general, being sufficient to handle a number of natural language determiners such as few, etc., cannot be represented using only the unrestricted quantification of standard predicate calculus (see [Wallace 19651, 113arwise Sz Cooper 19811). Finally, information carried by the sortal predicates in quantifiers (namely, criteria of identity for things of the various sorts in question) provides a sound semantic basis for counting the members of extensions of such predicates (see section 2, assumption c above). Any internal structure which a variable may have is irrelevant to its function as a uniquely identifiable placeholder in a formula. In particular, a quantified formula can itself serve as its own &amp;quot;bound variable&amp;quot;. This is how quantifiers are actually implemented in the HPSG system; in the internal (i.e. implementation) syntax for quantified NFLTformulas, bound variables of the usual sort are dispensed with in favor of pointers to the relevant quantified formu- Thus, of the three occurrences of the displayformula (2b), the first has no counterpart in the internal syntax, while the last two correspond internally to LISP back to the data structure that (2b). method of implementing quantification im- First, it eliminates the technical problems of variable clash that arise in conventional treatments. There are no &amp;quot;alphabetic variants&amp;quot;, just structurally equivalent concept tokens. Secondly, each occurrence of a quanti- &amp;quot;bound variable&amp;quot; provides direct computational the determiner, restrictor-clause, and scope-clause which it is associated. special class of quantificational expressions, have no scope-clause. An is: Syntax: (SOME X1 (COOKIE inst: x1)) Such expressions translate quantified noun phrases in Ene.g. a 3.3. Causal Relations and Non-Extensionality According to the standard semantics for the predicate calculus, predicate symbols denote the extensions of relations (i.e. sets of ordered n-tuples) and sentential formulas denote truth values. By contrast, we propose a nonfor NFLT: we take predicate symbols to denote relations themselves (rather than their extensions), and sentential formulas to denote situations or situtypes (rather than the corresponding truth The motivation for this is to provide for the expression of propositions involving causal relations among situations, as in the following example: 3The distinction between situations and types to the finite/infinitive distinction For discussion of this within the frameof situation semantics, see [Cooper 174 (4a) English: John has brown eyes because he is of genotype XYZW. (4b) NFLT Display Syntax: (CAUSE conditn:(GENOTYPE-XYZW inst:JOHN) result:(HROWN-EYED bearer:JOHN) ) Now, the predicate calculus is an extensional language in the sense that the replacement of categorical subparts within an expression by new subparts having the same extension must preserve the extension of the original expression. Such replacements within a sentential expression preserve the the expression, since the extension of a sentence is a truth-value. NFLT is not extensional in this sense. In particular, some of its predicatesymbols may denote causal relations among situations, and extension-preserving substitutions within causal contexts do not generally preserve the causal relations. Suppose, For example, that the formula (4b) is true. While the exof the NFLT-predicate the animals of genotype its not this set, but rather what Putnam 119691 would call a &amp;quot;physical the property of having the genotype noted above (section 2, assumption d) a property is to be distinguished both from the set of objects of which it holds from any it. Now even if this property were to happen by coincidence to have the same extension as property of being a citizen of Palo Alto born at noon on 1 April 1956, the substitution of a predicatedenoting this latter property for the would produce falsehood. However, NFLT&apos;s lack of extensionality does not involve departure from compositional semantics. denoan NFLT-predicate-symbol a property; the substitution earlier preserves the does the that predicate-symbol. the denoof an NFLT-sentence is a situation or distinguished both from a truth-value and from Then, although NFLT is not an extensional the standard sense, a Fregean analogue of the principle of extensionality does hold for it: The replacement of subparts within an expression by new subparts having the same denotation must preserve the denotation of the original expression (see 1Frege 1892)). Moreover, such replacements within an NFLT-sentence must preserve the truth-value of that sentence. since the truth-value is determined by the denotation. and Conceptual Raising The NFLT notation for representing information about attitudes is an improved of the neo- Fregean scheme described in [Creary 19791, section 2, which is itself an extension and improvement of that found in [McCarthy 19791. The basic idea underlying this scheme that propositional attitudes between peo- (or other intelligent organisms) and both of such relations are as of the doof discourse. Objective their comobjective concepts are as entities, roughly on a par with numbers, sets, etc. They are person-independent components of situations involving belief, knowledge, desire, and the like. More specifically, obconcepts are abstract may have as tosubjective concepts of individual organisms, turn are configurations information and associated procedures in various individual memories (cf. section 2, assumption d above). Unlike Montague semantics [Montague 19731, the setheory underlying NFLT does that an organism necessarily believes all the logical equivalents of a proposition it believes. This is because distinct propositions have as tokens distinct subjective concepts, even if they necessarily have the same truth-value. Here is an example of the use of NFLT to represent concerning attitudes:</abstract>
<note confidence="0.942545">(5a) English: Nancy wants to tickle Ron. (5b) NFLT Display Syntax: (WANT appr:NANCY</note>
<abstract confidence="0.996281988888889">prop:t(TICKLE agt:I ptnt:RON)) a Fregean spirit, we assign to categorematic of NFLT both a a exdenotation of the predicate-constant the property while the sense of that constant is a certain objective concept the &amp;quot;standard public&amp;quot; concept a cookie. We say that its and its The result of appending the raising&amp;quot; symbol to the constant is new constant, fC001ar, concept that applies to a constant and forms name of the that constant). By appending multiple occurrences of T&apos; to constants, we obtain new constants that denote concepts of concepts, concepts of concepts, In expression (5b), is not explicitly appended to constant, but instead is prefixed to a compound expres- When used in this way, &apos; functions as a egorematic operator that &amp;quot;conceptually raises&amp;quot; each categoretnatic constant within its scope and forms a term incorporating the raised constants and denoting a proposition. Thus, something similar to what Barwise and Perry call &amp;quot;situation semantics&amp;quot; 119831 is to be provided for NFLTas those expressions involve no ascripof propositional attitudes Barwise-Perry semantics for ascriptions of propositional attitudes takes a quite different approach from that to be described for NFLT in the next section): 5For further details concerning this Fregean hierarchy, see [Creary 19791, sections 2.2 and 2.3.1. Capand braces are used there to do the work done here by the symbol 175 the subformula RUM:RON) the name of a proposition whose component concepts are the relation-concept ITICRLE and the individual concepts and proposition is the sense of the unraised ptnt: The individual concept II, the minimal concept of self, is an especially interesting objective concept. We assume that for each sufficiently self-conscious and active organism X, X&apos;s minimal internal representation of itself is a token of concept is the sense of the indexical pronoun itself indexical in the sense that what it is a concept determined not by its content (which is the same for each token), but rather by the context of its use. The content of this concept is partly descriptive but mostly procedural, consisting mainly of the unique and important role that it plays in the information-processing of the organisms that have it. 4. Lexicon HPSG&apos;s head grammar takes as its point of departure (19161 notion of a sign is a conceptual object, shared by a group of organisms, which consists of two associated concepts that we call (by a conventional abuse of a representation a repexample, members of the English-speaking community share a sign which consists of an internal representation of the utterance-type /kUki/ together with an internal representation of the property of being a cookie. In a computer implementation, we model such a conceptual object with a data object of this form: ; the symbol is surrogate for a phonological representation (in fact we ignore phonology altogether and deal only with typewritten English input). The symbol basic constant of NFLT denoting the property COOKIE) models the corresponding semantic represen- We call a data object such as (6) a entry. Of course there must be more to a language than simple signs like (6). Words and phrases of certain kinds can characteristically combine with certain other kinds of phrases to form longer expressions that can convey information about the world. Correspondingly, we assume that a grammar in addition to a lexicon a set of rules (see next section) for combining simple signs to produce new signs which pair longer English expressions with more complex NFLT translations. For rules to work, each sign must contain information about how it figures in the rules. call this information the category the sign. Following established practice, we encode categories specifications of a finite set of Augmented with such information, lexical signs assume forms such as these: (cookie; N; AGR: 3RDSGI} {kisses; V; VFORM: FIN(} Such features as MAJOR (major category), AGR (agreement), and VFORM (verb form) encode inherent syntactic properties of signs. Still more information is required, however. Certain combine with other of specified categories form larger expressions. (For the time being we ignore optional called is the linguistic notion of example, the English verb subcategorizes for two NP&apos;s, of which one must be thirdperson-singular. We encode subcategorization information as the value of a feature called SUBCAT. Thus the value of the SUBCAT feature is a sequence of categories. (Such called play a central role the HG account of (Pollard forthcoming!.) Augmented with its SUBCAT feature, the lexical sign (2b) takes the form: {kisses; V; VFORM: FIN! SUBCAT: NP, NP-3RDSG} (Symbols like `NP&apos; and `NP-3RDSG&apos; are shorthand for certain sets of feature specifications). For ease of reference, we use traditional grammatical relation names for complements. Modifying the usage of Dowty 119821, we designate (in the order that they appear in SUBCAT) direct object, indirect object, objects. (Under this definition, determiners count as subjects of the nouns they combine with.) Complements that themselves subcategorize for a complement fall outside this hierarchy are called The complement next in sequence after a controlled complement is called its controller. For the sign (8) to play a communicative role, one additional kind of information is needed. Typically, heads give information about relations, while complements give information about the roles that individuals play in those relations. Thus lexical signs must assign roles to their complements. Augmented with role-assignment information, the lexical sign (8) takes the form: {kisses; V: VFORM: FIN! ,NP, (9) assigns the roles PATIENT to the subject and direct object respectively. (Note: we assume that nouns subcategorize for a determiner complement and assign it the instance role. See section 6 below.) 5. Grammatical Rules In addition to the lexicon, the grammar must contain mechanisms for constructing more complex signs that mediate between longer English expressions and more complex NFLT translations. Such mechanisms are called grammata purely syntactic point of view, rules can be regarded as ordering principles. For example, English grammar has a rule something like this: (10) If X is a sign whose SUBCAT value contains just one category Y, and Z is a sign whose category is consistent with Y, then X and Z can be combined to form a new sign W whose expression is got by 176 concatenating the expressions of X and Z. That is, put the final complement (subject) to the left of the head. We write this rule in the abbreviated form: (11) -&gt; C H [Condition: length of SUBCAT of H = 11 The form of (11) is analogous to conventional phrase structure rules such as NP — &gt; DET N or S — &gt; NP VP; in fact (11) subsumes both of these. However, (11) has no left-hand side. This is because the category of the constructed sign (mother) can be computed from the consigns general principles, as we shall presently show. Two more rules of English are: (12) -&gt; H C [Condition: length of SUBCAT of H = 21 (13) -&gt; H C2 CI length of SUBCAT of H (12) says: put a direct object or subject-controlled compleafter the head. And says: put an indirect object or object-controlled complement after the direct object. As in (11), the complement signs have to be consistent with the subcategorization specifications on the head. In (13), the indices on the complement symbols correspond to the order of the complement categories in the SUBCAT of the head. The category and translation of a mother need not be specified by the rule used to construct it. Instead, they are computed from information on the daughters by universal principles that govern rule application. Two such principles are the Head Feature Principle (HFP) (14) and the Subcategorization Principle (15): (14) Head Feature Principle: Unless otherwise specified, the head features on a mother coincide with the head features on the head daughter. (For present purposes, assume the head features are all features except SUBCAT.) (15) Subcategorization Principle: The SUBCAT value on the mother is got by deleting from the SUBCAT value on the head daughter those categories corresponding to complement daughters. (Additional principles not discussed here govern control and binding.) The basic idea is that we start with the head daughter and then process the complement daughters in the order given by the indices on the complement symbols in the rule. So far, we have said nothing about the determination of the mother&apos;s translation. We turn to this question in the next section. 6. The Semantic Interpretation Principle Now we can explain how the NFLT-translation of a phrase is computed from the translations of its constituents. The basic idea is that every time we apply a grammar rule, we process the head first and then the complements in the order indicated by the rule (see [Proudian &amp; Pollard 19851). As each complement is processed, the corresponding category-role pair is popped off the SUBCAT stack of head; the category information is merged with the category of the complement, and the role information is used to combine the complement translation with the head translation. We state this formally as: (16) Semantic Interpretation Principle (SIP): of the mother is by the following program: a. Initialize the mother&apos;s translation to be the head daughter&apos;s translation. b. Cycle through the complement daughters, setting the mother&apos;s translation to the result of combining the complement&apos;s translation with the mother&apos;s translation. c. Return the mother&apos;s translation. program in (16) calls a function whose arguments are a sign (the complement), a rolemark (gotten from the top of the head&apos;s SUBCAT stack), and an NFLT expression (the value of the mother translation computed thus far). This function is given in (17). There are two cases to consider, according as the translation of the complement is a determiner or not. (17) Function for Combining Complements: a. If the MAJOR feature value of the complement is DET, form the quantifier-expression whose determiner is the complement translation and whose restriction is the mother translation. Then add to the restriction a role link the indicated rolemark (viz. whose argument is a pointer back to that quantifier-expression, and return the resulting quantifier-expression. b. Otherwise, add to the mother translation a role link with the indicated rolemark whose argument is a pointer to the complement translation (a quantifier-expression or individual constant). If the complement translation is a quantifier-expression, return the quantificational expression formed from that quantifier-expression by letting its scope-clause be the mother translation; if not, return the mother translation. first case arises the head daughter is a noun the complement is a determiner. Then returns a complement like (3). In the second case, there are two subcases according as the complement translation is a quantifier-expression or something else (individual constant, sentential expression, propositional term, etc.) For example, suppose the head is this: ; V; VFORM: FIN! (NP-3RDSG, } the (subject) complement translation is quanmother translation is just: agt: RON) ; but if the complement translation is (ALL P3 (PERSON inst: P3 ) ) (a quantifier-expression), the mother translation is: 177 concatenating the expressions of X and Z. That is, put the final complement (subject) to the left of the head. We write this rule in the abbreviated form: (11) -&gt; C H [Condition: length of SUBCAT of H = 11 The form of (11) is analogous to conventional phrase structure rules such as NP — &gt; DET N or S — &gt; NP VP; in fact (11) subsumes both of these. However, (11) has no left-hand side. This is because the category of the sign be computed from the consigns general principles, as we shall presently show. Two more rules of English are: (12) -&gt; H C [Condition: length of SUBCAT of H = 21 (13) -&gt; H C2 Cl [Condition: length of SUBCAT of H = 31 (12) says: put a direct object or subject-controlled complement after the head. And (13) says: put an indirect object or object-controlled complement after the direct object. As in (11), the complement signs have to be consistent with the subcategorization specifications on the head. In (13), the indices on the complement symbols correspond to the order of the complement categories in the SUBCAT of the head. The category and translation of a mother need not be specified by the rule used to construct it. Instead, they are computed from information on the daughters by universal principles that govern rule application. Two such principles are the Head Feature Principle (HF?) (14) and the Subcategorization Principle (15): (14) Head Feature Principle: Unless otherwise specified, the head features on a mother coincide with the head features on the head daughter. (For present purposes, assume the head features are all features except SUBCAT.) (15) Subcategorization Principle: The SUBCAT value on the mother is got by deleting from the SUBCAT value on the head daughter those categories corresponding to complement daughters. (Additional principles not discussed here govern control and binding.) The basic idea is that we start with the head daughter and then process the complement daughters in the given by the indices on symbols in the rule. So far, we have said nothing about the determination the mother&apos;s turn to this question in the next section. 6. The Semantic Interpretation Principle Now we can explain how the NFLT-translation of a phrase is computed from the translations of its constituents. The basic idea is that every time we apply a grammar rule, we process the head first and then the complements in the order indicated by the rule (see [Proudian &amp; Pollard 19851). As each complement is processed, the corresponding category-role pair is popped off the SUBCAT stack of the head; the category information is merged (unified) with the category of the complement, and the role information is used to combine the complement translation with the head translation. We state this formally as: Semantic Interpretation Principle The translation of the mother is computed by the following program: a. Initialize the mother&apos;s translation to be the head daughter&apos;s translation. b. Cycle through the complement daughters, setting the mother&apos;s translation to the result of combining the complement&apos;s translation with the mother&apos;s translation. c. Return the mother&apos;s translation. The program given in (16) calls a function whose arguments are a sign (the complement), a rolemark (gotten from the top of the head&apos;s SUBCAT stack), and an NFLT expression (the value of the mother translation computed far). This function There are two cases to consider, according as the translation of the complement is a determiner or not. (17) Function for Combining Complements: If the MAJOR value of the complement is DET, form the quantifier-expression whose determiner is the complement translation and whose restriction is the mother translation. Then add to the restriction a role link the indicated rolemark (viz. argument is pointer back to that quantifier-expression, and return the resulting quantifier-expression. b. Otherwise, add to the mother translation a role link with the indicated rolernark whose argua pointer the complement translaor individual concomplement translation is a quantifier-expression, return the quantificational expression formed from that quantifier-expression by letting its scope-clause be the mother transnot, return mother translation. first case arises when head daughter is a noun the complement is a determiner. (17) simply rea complement like (3). second case. there are subcases according as complement translation is quantifier-expression or something else (individual consentential expression, term. etc.) For suppose the head is ; V; VFORNI: FIN) KNP-3RDSC, the (subject) complement translation is &apos;RON&apos; ( quanmother translation is just: (JOG ; but if the complement translation is</abstract>
<note confidence="0.572064714285714">P3 (PERSON ) (a quantifier-expression), the mother translation is: 177 son, Yale University Press, New Haven and London, 1974. Carl [19841. Phrase Structure Gram- Head Grammars, Language. Doctoral dissertation, Stanford University. Pollard, Carl iforthcomingl. &amp;quot;A Semantic Approach to Binding in a Monostratal Theory.&apos; To appear in Linguistics and Philosophy. Proudian, Derek, and Carl Pollard [1985]. &amp;quot;Parsing Head- Phrase Structure Grammar.&amp;quot; of the 23rd Annual Meeting of the Association for Computational Linguistics. Hilary [1969]. On Properties.&amp;quot; In in of Carl G. Hempel, Rescher, ed., D. Rei- Dordrecht. Reprinted in Language, and Philosophical Papers I, Ch. 19), Cambridge University Press, Cambridge, 1975. Ferdinand de [1916]. de Linguistique Gen- Payot. Translated into English by Baskin as in General Linguistics, Philosophical Library, New York, 1959 (paperback edition, McGraw-Hill, New York, 1966). Wallace, John [1965]. &amp;quot;Sortal Predicates and Quantifica- Journal of Philosophy 8-13. 179</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Semantic Interpretation Principle (SIP): The translation of the mother is computed by the following program: a. Initialize the mother&apos;s translation to be the head daughter&apos;s translation.</title>
<date></date>
<marker></marker>
<rawString>(16) Semantic Interpretation Principle (SIP): The translation of the mother is computed by the following program: a. Initialize the mother&apos;s translation to be the head daughter&apos;s translation.</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>Cycle through the complement daughters, setting the mother&apos;s translation to the result of combining the complement&apos;s translation with the mother&apos;s translation. c. Return the mother&apos;s translation.</title>
<marker>b, </marker>
<rawString>b. Cycle through the complement daughters, setting the mother&apos;s translation to the result of combining the complement&apos;s translation with the mother&apos;s translation. c. Return the mother&apos;s translation.</rawString>
</citation>
<citation valid="true">
<title>SUBCAT: KNP-3RDSC, agent)} If the (subject) complement translation is &apos;RON&apos; ( not a quantifier-expression), the mother translation is just: (19) (JOG agt: RON) ; but if the complement translation is &apos;(ALL</title>
<date>1974</date>
<booktitle>P3 (PERSON inst: P3 ) (a</booktitle>
<publisher>Yale University Press,</publisher>
<location>New Haven and London,</location>
<marker>1974</marker>
<rawString>(18) (jogs ; JOG; (MAJOR: V; VFORNI: FIN) SUBCAT: KNP-3RDSC, agent)} If the (subject) complement translation is &apos;RON&apos; ( not a quantifier-expression), the mother translation is just: (19) (JOG agt: RON) ; but if the complement translation is &apos;(ALL P3 (PERSON inst: P3 ) (a quantifier-expression), the mother translation is: son, Yale University Press, New Haven and London, 1974.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Carl Pollard</author>
</authors>
<title>19841. Generalized Phrase Structure Grammars, Head Grammars, and Natural Language. Doctoral dissertation,</title>
<institution>Stanford University.</institution>
<marker>Pollard, </marker>
<rawString>Pollard, Carl [19841. Generalized Phrase Structure Grammars, Head Grammars, and Natural Language. Doctoral dissertation, Stanford University.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Carl iforthcomingl Pollard</author>
</authors>
<title>A Semantic Approach to Binding in a Monostratal Theory.&apos;</title>
<note>To appear in Linguistics and Philosophy.</note>
<marker>Pollard, </marker>
<rawString>Pollard, Carl iforthcomingl. &amp;quot;A Semantic Approach to Binding in a Monostratal Theory.&apos; To appear in Linguistics and Philosophy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derek Proudian</author>
<author>Carl Pollard</author>
</authors>
<title>Parsing Headdriven Phrase Structure Grammar.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29794" citStr="Proudian &amp; Pollard 1985" startWordPosition="4656" endWordPosition="4659">he basic idea is that we start with the head daughter and then process the complement daughters in the order given by the indices on the complement symbols in the rule. So far, we have said nothing about the determination of the mother&apos;s translation. We turn to this question in the next section. 6. The Semantic Interpretation Principle Now we can explain how the NFLT-translation of a phrase is computed from the translations of its constituents. The basic idea is that every time we apply a grammar rule, we process the head first and then the complements in the order indicated by the rule (see [Proudian &amp; Pollard 19851). As each complement is processed, the corresponding category-role pair is popped off the SUBCAT stack of the head; the category information is merged (unified) with the category of the complement, and the role information is used to combine the complement translation with the head translation. We state this formally as: (16) Semantic Interpretation Principle (SIP): The translation of the mother is computed by the following program: a. Initialize the mother&apos;s translation to be the head daughter&apos;s translation. b. Cycle through the complement daughters, setting the mother&apos;s translation to the </context>
</contexts>
<marker>Proudian, Pollard, 1985</marker>
<rawString>Proudian, Derek, and Carl Pollard [1985]. &amp;quot;Parsing Headdriven Phrase Structure Grammar.&amp;quot; Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hilary Putnam</author>
</authors>
<title>On Properties.&amp;quot;</title>
<date>1975</date>
<booktitle>In Essays in Honor of</booktitle>
<volume>19</volume>
<editor>Carl G. Hempel, N. Rescher, ed., D. Reidel, Dordrecht. Reprinted in Mind, Language, and Reality: Philosophical Papers (Vol. I, Ch.</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge,</location>
<marker>Putnam, 1975</marker>
<rawString>Putnam, Hilary [1969]. On Properties.&amp;quot; In Essays in Honor of Carl G. Hempel, N. Rescher, ed., D. Reidel, Dordrecht. Reprinted in Mind, Language, and Reality: Philosophical Papers (Vol. I, Ch. 19), Cambridge University Press, Cambridge, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferdinand de  Saussure</author>
</authors>
<title>Cours de Linguistique Generale. Paris: Payot. Translated into English by Wade Baskin as</title>
<date>1959</date>
<booktitle>Course in General Linguistics, The Philosophical Library,</booktitle>
<location>New York,</location>
<marker>Saussure, 1959</marker>
<rawString>Saussure, Ferdinand de [1916]. Cours de Linguistique Generale. Paris: Payot. Translated into English by Wade Baskin as Course in General Linguistics, The Philosophical Library, New York, 1959 (paperback edition, McGraw-Hill, New York, 1966).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Wallace</author>
</authors>
<title>Sortal Predicates and Quantification.&amp;quot;</title>
<date>1965</date>
<journal>The Journal of Philosophy</journal>
<volume>62</volume>
<pages>8--13</pages>
<contexts>
<context position="13303" citStr="Wallace 1965" startWordPosition="2053" endWordPosition="2054">e always quantify over instances of a sort, i.e. the quantified variable fills the instance role in the restrictorc lause. This style of quantifier is superior in several ways to that of the predicate calculus for the purposes of representing commonsense knowledge. It is intuitively more natural, since it follows the quantificational pattern of English. More importantly, it is more general, being sufficient to handle a number of natural language determiners such as many, most, few, etc., that cannot be represented using only the unrestricted quantification of standard predicate calculus (see [Wallace 19651, 113arwise Sz Cooper 19811). Finally, information carried by the sortal predicates in quantifiers (namely, criteria of identity for things of the various sorts in question) provides a sound semantic basis for counting the members of extensions of such predicates (see section 2, assumption c above). Any internal structure which a variable may have is irrelevant to its function as a uniquely identifiable placeholder in a formula. In particular, a quantified formula can itself serve as its own &amp;quot;bound variable&amp;quot;. This is how quantifiers are actually implemented in the HPSG system; in the internal</context>
</contexts>
<marker>Wallace, 1965</marker>
<rawString>Wallace, John [1965]. &amp;quot;Sortal Predicates and Quantification.&amp;quot; The Journal of Philosophy 62, 8-13.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>