<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.064387">
<title confidence="0.984307">
DKPro TC: A Java-based Framework for Supervised Learning
Experiments on Textual Data
</title>
<author confidence="0.99137">
Johannes Daxenbergert, Oliver Ferschkett, Iryna Gurevychtt and Torsten Zesch5t
</author>
<affiliation confidence="0.930592666666667">
† UKP Lab, Technische Universität Darmstadt
‡ Information Center for Education, DIPF, Frankfurt
§ Language Technology Lab, University of Duisburg-Essen
</affiliation>
<email confidence="0.832659">
http://www.ukp.tu-darmstadt.de
</email>
<sectionHeader confidence="0.99554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999975647058824">
We present DKPro TC, a framework for
supervised learning experiments on tex-
tual data. The main goal of DKPro TC is
to enable researchers to focus on the actual
research task behind the learning problem
and let the framework handle the rest. It
enables rapid prototyping of experiments
by relying on an easy-to-use workflow en-
gine and standardized document prepro-
cessing based on the Apache Unstruc-
tured Information Management Architec-
ture (Ferrucci and Lally, 2004). It ships
with standard feature extraction modules,
while at the same time allowing the user
to add customized extractors. The exten-
sive reporting and logging facilities make
DKPro TC experiments fully replicable.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999212734693878">
Supervised learning on textual data is a ubiquitous
challenge in Natural Language Processing (NLP).
Applying a machine learning classifier has be-
come the standard procedure, as soon as there is
annotated data available. Before a classifier can
be applied, relevant information (referred to as
features) needs to be extracted from the data. A
wide range of tasks have been tackled in this way
including language identification, part-of-speech
(POS) tagging, word sense disambiguation, sen-
timent detection, and semantic similarity.
In order to solve a supervised learning task,
each researcher needs to perform the same set of
steps in a predefined order: reading input data,
preprocessing, feature extraction, machine learn-
ing, and evaluation. Standardizing this process
is quite challenging, as each of these steps might
vary a lot depending on the task at hand. To com-
plicate matters further, the experimental process
is usually embedded in a series of configuration
changes. For example, introducing a new fea-
ture often requires additional preprocessing. Re-
searchers should not need to think too much about
such details, but focus on the actual research task.
DKPro TC is our take on the standardization of
an inherently complex problem, namely the imple-
mentation of supervised learning experiments for
new datasets or new learning tasks.
We will make some simplifying assumptions
wherever they do not harm our goal that the frame-
work should be applicable to the widest possible
range of supervised learning tasks. For example,
DKPro TC only supports a limited set of machine
learning frameworks, as we argue that differences
between frameworks will mainly influence run-
time, but will have little influence on the final con-
clusions to be drawn from the experiment. The
main goal of DKPro TC is to enable the researcher
to quickly find an optimal experimental configura-
tion. One of the major contributions of DKPro TC
is the modular architecture for preprocessing and
feature extraction, as we believe that the focus of
research should be on a meaningful and expressive
feature set. DKPro TC has already been applied to
a wide range of different supervised learning tasks,
which makes us confident that it will be of use to
the research community.
DKPro TC is mostly written in Java and freely
available under an open source license.1
</bodyText>
<sectionHeader confidence="0.997543" genericHeader="introduction">
2 Requirements
</sectionHeader>
<bodyText confidence="0.9999136">
In the following, we give a more detailed overview
of the requirements and goals we have identified
for a general-purpose text classification system.
These requirements have guided the development
of the DKPro TC system architecture.
</bodyText>
<footnote confidence="0.998027">
1http://dkpro-tc.googlecode.com
</footnote>
<page confidence="0.991043">
61
</page>
<table confidence="0.917648">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 61–66,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
Single-label Multi-label Regression
Document Mode · Spam Detection · Text Categorization · Text Readability
· Sentiment Detection · Keyphrase Assignment
Unit/Sequence Mode · Named Entity Recognition · Dialogue Act Tagging · Word Difficulty
· Part-of-Speech Tagging
Pair Mode · Paraphrase Identification · Relation Extraction · Text Similarity
· Textual Entailment
</table>
<tableCaption confidence="0.950463">
Table 1: Supervised learning scenarios and feature modes supported in DKPro TC, with example NLP
applications.
</tableCaption>
<bodyText confidence="0.998176076923077">
Flexibility Users of a system for supervised
learning on textual data should be able to choose
between different machine learning approaches
depending on the task at hand. In supervised ma-
chine learning, we have to distinguish between ap-
proaches based on classification and approaches
based on regression. In classification, given a
document d E D and a set of labels C =
{c1, c2, ..., cn}, we want to label each document
d with L C C, where L is the set of relevant
or true labels. In single-label classification, each
document d is labeled with exactly one label, i.e.
|L |= 1, whereas in multi-label classification, a
set of labels is assigned, i.e. |L |&gt; 1. Single-
label classification can further be divided into bi-
nary classification (|C |= 2) and multi-class clas-
sification (|C |&gt; 2). In regression, real numbers
instead of labels are assigned.
Feature extraction should follow a modular de-
sign in order to facilitate reuse and to allow seam-
less integration of new features. However, the way
in which features need to be extracted from the in-
put documents depends on the the task at hand.
We have identified several typical scenarios in su-
pervised learning on textual data and propose the
following feature modes:
</bodyText>
<listItem confidence="0.974615294117647">
• In document mode, each input document will
be used as its own entity to be classified, e.g.
an email classified as wanted or unwanted
(spam).
• In unit/sequence mode, each input document
contains several units to be classified. The
units in the input document cannot be divided
into separate documents, either because the
context of each unit needs to be preserved
(e.g. to disambiguate named entities) or be-
cause they form a sequence which needs to
be kept (in sequence tagging).
• The pair mode is intended for problems
which require a pair of texts as input, e.g.
a pair of sentences to be classified as para-
phrase or non-paraphrase. It represents a
special case of multi-instance learning (Sur-
</listItem>
<bodyText confidence="0.97501771875">
deanu et al., 2012), in which a document con-
tains exactly two instances.
Considering the outlined learning approaches and
feature modes, we have summarized typical sce-
narios in supervised learning on textual data in Ta-
ble 1 and added example applications in NLP.
Replicability and Reusability As it has been
recently noted by Fokkens et al. (2013), NLP ex-
periments are not replicable in most cases. The
problem already starts with undocumented pre-
processing steps such as tokenization or sentence
boundary detection that might have heavy impact
on experimental results. In a supervised learning
setting, this situation is even worse, as e.g. fea-
ture extraction is usually only partially described
in the limited space of a research paper. For ex-
ample, a paper might state that “n-gram features”
were used, which encompasses a very broad range
of possible implementations.
In order to make NLP experiments replicable, a
text classification framework should (i) encourage
the user to reuse existing components which they
can refer to in research papers rather than writ-
ing their own components, (ii) document all per-
formed steps, and (iii) make it possible to re-run
experiments with minimal effort.
Apart from helping the replicability of experi-
ments, reusing components allows the user to con-
centrate on the new functionality that is specific
to the planned experiment instead of having to
reinvent the wheel. The parts of a text classifi-
cation system which can typically be reused are
</bodyText>
<page confidence="0.995705">
62
</page>
<bodyText confidence="0.996836">
preprocessing components, generic feature extrac-
tors, machine learning algorithms, and evaluation.
</bodyText>
<sectionHeader confidence="0.984353" genericHeader="method">
3 Architecture
</sectionHeader>
<bodyText confidence="0.99996125">
We now give an overview of the DKPro TC archi-
tecture that was designed to take into account the
requirements outlined above. A core design deci-
sion is to model each of the typical steps in text
classification (reading input data and preprocess-
ing, feature extraction, machine learning and eval-
uation) as separate tasks. This modular architec-
ture helps the user to focus on the main problem,
i.e. developing and selecting good features.
In the following, we describe each module in
more detail, starting with the workflow engine that
is used to assemble the tasks into an experiment.
</bodyText>
<subsectionHeader confidence="0.997251">
3.1 Configuration and Workflow Engine
</subsectionHeader>
<bodyText confidence="0.999962695652174">
We rely on the DKPro Lab (Eckart de Castilho
and Gurevych, 2011) workflow engine, which al-
lows fine-grained control over the dependencies
between single tasks, e.g. the pre-processing of a
document obviously needs to happen before the
feature extraction. In order to shield the user
from the complex “wiring” of tasks, DKPro TC
currently provides three pre-defined workflows:
Train/Test, Cross-Validation, and Prediction (on
unseen data). Each workflow supports the feature
modes described above: document, unit/sequence,
and pair.
The user is still able to control the behavior of
the workflow by setting parameters, most impor-
tantly the sources of input data, the set of feature
extractors, and the classifier to be used. Internally,
each parameter is treated as a single dimension
in the global parameter space. Users may pro-
vide more than one value for a certain parame-
ter, e.g. specific feature sets or several classifiers.
The workflow engine will automatically run all
possible parameter value combinations (a process
called parameter sweeping).
</bodyText>
<subsectionHeader confidence="0.999278">
3.2 Reading Input Data
</subsectionHeader>
<bodyText confidence="0.999908">
Input data for supervised learning tasks comes in
myriad different formats which implies that read-
ing data cannot be standardized, but needs to be
handled individually for each data set. However,
the internal processing should not be dependent on
the input format. We therefore use the Common
Analysis Structure (CAS), provided by the Apache
Unstructured Information Management Architec-
ture (UIMA), to represent input documents and
annotations in a standardized way.
Under the UIMA model, reading input data
means to transform arbitrary input data into a
CAS representation. DKPro TC already provides
a wide range of readers from UIMA component
repositories such as DKPro Core.2 The reader
also needs to assign to each classification unit an
outcome attribute that represents the relevant label
(single-label), labels (multi-label), or a real value
(regression). In unit/sequence mode, the reader
additionally needs to mark the units in the CAS.
In pair mode, a pair of texts (instead of a single
document) is stored within one CAS.
</bodyText>
<subsectionHeader confidence="0.993857">
3.3 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999825384615385">
In this step, additional information about the docu-
ment is added to the CAS, which efficiently stores
large numbers of stand-off annotations. In pair
mode, the preprocessing is automatically applied
to both documents.
DKPro TC allows the user to run arbitrary
UIMA-based preprocessing components as long
as they are compatible with the DKPro type sys-
tem that is currently used by DKPro Core and
EOP.3 Thus, a large set of ready-to-use prepro-
cessing components for more than ten languages
is available, containing e.g. sentence boundary de-
tection, lemmatization, POS-tagging, or parsing.
</bodyText>
<subsectionHeader confidence="0.958583">
3.4 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999571473684211">
DKPro TC ships a constantly growing number of
feature extractors. Feature extractors have access
to the document text as well as all the additional
information that has been added in the form of
UIMA stand-off annotations during the prepro-
cessing step. Users of DKPro TC can add cus-
tomized feature extractors for particular use cases
on demand.
Among the ready-to-use feature extractors con-
tained in DKPro TC, there are several ones ex-
tracting grammatical information, e.g. the plural-
singular ratio or the ratio of modal to all verbs.
Other features collect information about stylistic
cues of a document, e.g. the number of exclama-
tions or the type-token-ratio. DKPro TC is able to
extract n-grams or skip n-grams of tokens, charac-
ters, and POS tags.
Some feature extractors need access to informa-
tion about the entire document collection, e.g. in
</bodyText>
<footnote confidence="0.9999595">
2http://dkpro-core-asl.googlecode.com
3http://hltfbk.github.io/Excitement-Open-Platform/
</footnote>
<page confidence="0.999001">
63
</page>
<bodyText confidence="0.99996595">
order to weigh lexical features with tf.idf scores.
Such extractors have to declare that they depend
on collection level information and DKPro TC
will automatically include a special task that is
executed before the actual features are extracted.
Depending on the feature mode which has been
configured, DKPro TC will extract information
on document level, unit- and/or sequence-level, or
document pair level.
DKPro TC stores extracted features in its inter-
nal feature store. When the extraction process is
finished, a configurable data writer converts the
content from the feature store into a format which
can be handled by the utilized machine learning
tool. DKPro TC currently ships data writers for
the Weka (Hall et al., 2009), Meka4, and Mallet
(McCallum, 2002) frameworks. Users can also
add dedicated data writers that output features in
the format used by the machine learning frame-
work of their choice.
</bodyText>
<subsectionHeader confidence="0.964145">
3.5 Supervised Learning
</subsectionHeader>
<bodyText confidence="0.99995052631579">
For the actual machine learning, DKPro TC cur-
rently relies on Weka (single-label and regres-
sion), Meka (multi-label), and Mallet (sequence
labeling). It contains a task which trains a freely
configurable classifier on the training data and
evaluates the learned model on the test data.
Before training and evaluation, the user may ap-
ply dimensionality reduction to the feature set, i.e.
select a limited number of (expectedly meaning-
ful) features to be included for training and eval-
uating the classifier. DKPro TC uses the feature
selection capabilities of Weka (single-label and re-
gression) and Mulan (multi-label) (Tsoumakas et
al., 2010).
DKPro TC can also predict labels on unseen
(i.e. unlabeled) data, using a trained classifier. In
that case, no evaluation will be carried out, but the
classifier’s prediction for each document will be
written to a file.
</bodyText>
<subsectionHeader confidence="0.977488">
3.6 Evaluation and Reporting
</subsectionHeader>
<bodyText confidence="0.999808">
DKPro TC calculates common evaluation scores
including accuracy, precision, recall, and F1-
score. Whenever sensible, scores are reported for
each individual label as well as aggregated over
all labels. To support users in further analyz-
ing the performance of a classification workflow,
DKPro TC outputs the confusion matrix, the ac-
</bodyText>
<footnote confidence="0.714911">
4http://meka.sourceforge.net
</footnote>
<bodyText confidence="0.999919222222222">
tual predictions assigned to each document, and a
ranking of the most useful features based on the
configured feature selection algorithm. Additional
task-specific reporting can be added by the user.
As mentioned before, a major goal of
DKPro TC is to increase the replicability of NLP
experiments. Thus, for each experiment, all con-
figuration parameters are stored and will be re-
ported together with the classification results.
</bodyText>
<sectionHeader confidence="0.995399" genericHeader="method">
4 Tweet Classification: A Use Case
</sectionHeader>
<bodyText confidence="0.9999771">
We now give a brief summary of what a supervised
learning task might look like in DKPro TC using
a simple Twitter sentiment classification example.
Assuming that we want to classify a set of tweets
either as “emotional” or “neutral”, we can use the
setup shown in Listing 1. The example uses the
Groovy programming language which yields bet-
ter readable code, but pure Java is also supported.
Likewise, a DKPro TC experiment can also be set
up with the help of a configuration file, e.g. in
JSON or via Groovy scripts.
First, we create a workflow as a BatchTask-
CrossValidation which can be used to run
a cross-validation experiment on the data (using
10 folds as configured by the corresponding pa-
rameter). The workflow uses LabeledTweet-
Reader in order to import the experiment data
from source text files into the internal document
representation (one document per tweet). This
reader adds a UIMA annotation that specifies the
gold standard classification outcome, i.e. the rel-
evant label for the tweet. In this use case, pre-
processing consists of a single step: running the
ArkTweetTagger (Gimpel et al., 2011), a spe-
cialized Twitter tokenizer and POS-tagger that is
integrated in DKPro Core. The feature mode is set
to document (one tweet per CAS), and the learning
mode to single-label (each tweet is labeled with
exactly one label), cf. Table 1.
Two feature extractors are configured: One for
returning the number of hashtags and another one
returning the ratio of emoticons to tokens in the
tweet. Listing 2 shows the Java code for the sec-
ond extractor. Two things are noteworthy: (i) doc-
ument text and UIMA annotations are readily
available through the JCas object, and (ii) this is
really all that the user needs to write in order to
add a new feature extractor.
The next item to be configured is the Weka-
DataWriter which converts the internal fea-
</bodyText>
<page confidence="0.998711">
64
</page>
<table confidence="0.983782888888889">
BatchTaskCrossValidation batchTask = [
experimentName: &amp;quot;Twitter-Sentiment&amp;quot;,
preprocessingPipeline: createEngineDescription(ArkTweetTagger), // Preprocessing
parameterSpace: [ // multi-valued parameters in the parameter space will be swept
Dimension.createBundle(&amp;quot;reader&amp;quot;, [
readerTrain: LabeledTweetReader,
readerTrainParams: [LabeledTweetReader.PARAM_CORPUS_PATH, &amp;quot;src/main/resources/tweets.txt&amp;quot;]]),
Dimension.create(&amp;quot;featureMode&amp;quot;, &amp;quot;document&amp;quot;),
Dimension.create(&amp;quot;learningMode&amp;quot;, &amp;quot;singleLabel&amp;quot;),
Dimension.create(&amp;quot;featureSet&amp;quot;, [EmoticonRatioExtractor.name, NumberOfHashTagsExtractor.name]),
Dimension.create(&amp;quot;dataWriter&amp;quot;, WekaDataWriter.name),
Dimension.create(&amp;quot;classificationArguments&amp;quot;, [NaiveBayes.name, RandomForest.name])],
reports: [BatchCrossValidationReport], // collects results from folds
numFolds: 10];
Listing 1: Groovy code to configure a DKPro TC cross-validation BatchTask on Twitter data.
public class EmoticonRatioFeatureExtractor
extends FeatureExtractorResource_ImplBase implements DocumentFeatureExtractor
{
@Override
public List&lt;Feature&gt; extract(JCas annoDb) throws TextClassificationException {
int nrOfEmoticons = JCasUtil.select(annoDb, EMO.class).size();
int nrOfTokens = JCasUtil.select(annoDb, Token.class).size();
double ratio = (double) nrOfEmoticons / nrOfTokens;
return new Feature(&amp;quot;EmoticonRatio&amp;quot;, ratio).asList();
}
}
Listing 2: A DKPro TC document mode feature extractor measuring the ratio of emoticons to tokens.
</table>
<bodyText confidence="0.999958307692308">
ture representation into the Weka ARFF format.
For the classification, two machine learning algo-
rithms will be iteratively tested: a Naive Bayes
classifier and a Random Forest classifier. Pass-
ing a list of parameters into the parameter space
will automatically make DKPro TC test all pos-
sible parameter combinations. The classification
task automatically trains a model on the training
data and stores the results of the evaluation on
the test data for each fold on the disk. Finally,
the evaluation scores for each fold are collected
by the BatchCrossValidationReport and
written to a single file using a tabulated format.
</bodyText>
<sectionHeader confidence="0.999925" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999627">
This section will give a brief overview about tools
with a scope similar to DKPro TC. We only list
freely available software, most of which is open-
source. Unless otherwise indicated, all of the tools
are written in Java.
ClearTK (Ogren et al., 2008) is conceptually
closest to DKPro TC and shares many of its dis-
tinguishing features like the modular feature ex-
tractors. It provides interfaces to machine learn-
ing libraries such as Mallet or libsvm, offers wrap-
pers for basic NLP components, and comes with
a feature extraction library that facilitates the de-
velopment of custom feature extractors within the
UIMA framework. In contrast to DKPro TC, it is
rather designed as a programming library than a
customizable research environment for quick ex-
periments and does not provide predefined text
classification setups. Furthermore, it does not sup-
port parameter sweeping and has no explicit sup-
port for creating experiment reports.
Argo (Rak et al., 2013) is a web-based work-
bench with support for manual annotation and au-
tomatic analysis of mainly bio-medical data. Like
DKPro TC, Argo is based on UIMA, but focuses
on sequence tagging, and it lacks DKPro TC’s pa-
rameter sweeping capabilities.
NLTK (Bird et al., 2009) is a general-purpose
NLP toolkit written in Python. It offers com-
ponents for a wide range of preprocessing tasks
and also supports feature extraction and machine
learning for supervised text classification. Like
DKPro TC, it can be used to quickly setup baseline
experiments. As opposed to DKPro TC, NLTK
lacks a modular structure with respect to prepro-
cessing and feature extraction and does not sup-
port parameter sweeping.
Weka (Hall et al., 2009) is a machine learning
framework that covers only the last two steps of
DKPro TC’s experimental process, i.e. machine
learning and evaluation. However, it offers no ded-
icated support for preprocessing and feature gener-
ation. Weka is one of the machine learning frame-
works that can be used within DKPro TC for ac-
tual machine learning.
Mallet (McCallum, 2002) is another machine
</bodyText>
<page confidence="0.998736">
65
</page>
<bodyText confidence="0.9999205">
learning framework implementing several super-
vised and unsupervised learning algorithms. As
opposed to Weka, is also supports sequence tag-
ging, including Conditional Random Fields, as
well as topic modeling. Mallet can be used as ma-
chine learning framework within DKPro TC.
Scikit-learn (Pedregosa et al., 2011) is a ma-
chine learning framework written in Python. It
offers basic functionality for preprocessing, fea-
ture selection, and parameter tuning. It provides
some methods for preprocessing such as convert-
ing documents to tf.idf vectors, but does not offer
sophisticated and customizable feature extractors
for textual data like DKPro TC.
</bodyText>
<sectionHeader confidence="0.998339" genericHeader="conclusions">
6 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.999985285714286">
We have presented DKPro TC, a comprehensive
and flexible framework for supervised learning on
textual data. DKPro TC makes setting up exper-
iments and creating new features fast and simple,
and can therefore be applied for rapid prototyp-
ing. Its extensive logging capabilities emphasize
the replicability of results. In our own research
lab, DKPro TC has successfully been applied to a
wide range of tasks including author identification,
text quality assessment, and sentiment detection.
There are some limitations to DKPro TC which
we plan to address in future work. To reduce the
runtime of experiments with very large document
collections, we want to add support for parallel
processing of documents. While the current main
goal of DKPro TC is to bootstrap experiments on
new data sets or new applications, we also plan to
make DKPro TC workflows available as resources
to other applications, so that a model trained with
DKPro TC can be used to automatically label tex-
tual data in different environments.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999810833333333">
This work has been supported by the Volks-
wagen Foundation as part of the Lichtenberg-
Professorship Program under grant No. I/82806,
and by the Hessian research excellence pro-
gram “Landes-Offensive zur Entwicklung
Wissenschaftlich-ökonomischer Exzellenz”
(LOEWE) as part of the research center “Digital
Humanities”. The authors would like give special
thanks to Richard Eckhart de Castilho, Nicolai
Erbs, Lucie Flekova, Emily Jamison, Krish
Perumal, and Artem Vovk for their contributions
to the DKPro TC framework.
</bodyText>
<sectionHeader confidence="0.998426" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999945723404255">
S. Bird, E. Loper, and E. Klein. 2009. Natural Lan-
guage Processing with Python. O’Reilly Media Inc.
R. Eckart de Castilho and I. Gurevych. 2011. A
Lightweight Framework for Reproducible Parame-
ter Sweeping in Information Retrieval. In Proc. of
the Workshop on Data Infrastructures for Support-
ing Information Retrieval Evaluation, pages 7–10.
D. Ferrucci and A. Lally. 2004. UIMA: An Ar-
chitectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327–348.
A. Fokkens, M. van Erp, M. Postma, T. Pedersen,
P. Vossen, and N. Freire. 2013. Offspring from
Reproduction Problems: What Replication Failure
Teaches Us. In Proc. ACL, pages 1691–1701.
K. Gimpel, N. Schneider, B. O’Connor, D. Das,
D. Mills, J. Eisenstein, M. Heilman, D. Yogatama,
J. Flanigan, and N. Smith. 2011. Part-of-speech
tagging for Twitter: annotation, features, and exper-
iments. In Proc. ACL, pages 42–47.
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-
mann, and I. Witten. 2009. The WEKA Data Min-
ing Software: An Update. SIGKDD Explorations,
11(1):10–18.
A. McCallum. 2002. MALLET: A Machine Learning
for Language Toolkit.
P. Ogren, P. Wetzler, and S. Bethard. 2008. ClearTK:
A UIMA toolkit for statistical natural language pro-
cessing. In Towards Enhanced Interoperability for
Large HLT Systems: UIMA for NLP workshop at
LREC, pages 32–38.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine Learn-
ing in Python. Journal of Machine Learning Re-
search, 12:2825–2830.
R. Rak, A. Rowley, J. Carter, and S. Ananiadou.
2013. Development and Analysis of NLP Pipelines
in Argo. In Proc. ACL, pages 115–120.
M. Surdeanu, J. Tibshirani, R. Nallapati, and C. Man-
ning. 2012. Multi-instance multi-label learning for
relation extraction. In Proc. EMNLP-CoNLL, pages
455–465.
G. Tsoumakas, I. Katakis, and I. Vlahavas. 2010. Min-
ing Multi-label Data. Transformation, 135(2):1–20.
</reference>
<page confidence="0.988966">
66
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.476599">
<title confidence="0.9942185">DKPro TC: A Java-based Framework for Supervised Experiments on Textual Data</title>
<author confidence="0.909593">Oliver Iryna Torsten</author>
<affiliation confidence="0.818935">Lab, Technische Universität Center for Education, DIPF, Technology Lab, University of</affiliation>
<web confidence="0.985741">http://www.ukp.tu-darmstadt.de</web>
<abstract confidence="0.992810444444444">We present DKPro TC, a framework for supervised learning experiments on textual data. The main goal of DKPro TC is to enable researchers to focus on the actual research task behind the learning problem and let the framework handle the rest. It enables rapid prototyping of experiments by relying on an easy-to-use workflow engine and standardized document preprocessing based on the Apache Unstructured Information Management Architecture (Ferrucci and Lally, 2004). It ships with standard feature extraction modules, while at the same time allowing the user to add customized extractors. The extensive reporting and logging facilities make DKPro TC experiments fully replicable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Loper</author>
<author>E Klein</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media Inc.</booktitle>
<contexts>
<context position="19997" citStr="Bird et al., 2009" startWordPosition="3057" endWordPosition="3060">in the UIMA framework. In contrast to DKPro TC, it is rather designed as a programming library than a customizable research environment for quick experiments and does not provide predefined text classification setups. Furthermore, it does not support parameter sweeping and has no explicit support for creating experiment reports. Argo (Rak et al., 2013) is a web-based workbench with support for manual annotation and automatic analysis of mainly bio-medical data. Like DKPro TC, Argo is based on UIMA, but focuses on sequence tagging, and it lacks DKPro TC’s parameter sweeping capabilities. NLTK (Bird et al., 2009) is a general-purpose NLP toolkit written in Python. It offers components for a wide range of preprocessing tasks and also supports feature extraction and machine learning for supervised text classification. Like DKPro TC, it can be used to quickly setup baseline experiments. As opposed to DKPro TC, NLTK lacks a modular structure with respect to preprocessing and feature extraction and does not support parameter sweeping. Weka (Hall et al., 2009) is a machine learning framework that covers only the last two steps of DKPro TC’s experimental process, i.e. machine learning and evaluation. However</context>
</contexts>
<marker>Bird, Loper, Klein, 2009</marker>
<rawString>S. Bird, E. Loper, and E. Klein. 2009. Natural Language Processing with Python. O’Reilly Media Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Eckart de Castilho</author>
<author>I Gurevych</author>
</authors>
<title>A Lightweight Framework for Reproducible Parameter Sweeping in Information Retrieval.</title>
<date>2011</date>
<booktitle>In Proc. of the Workshop on Data Infrastructures for Supporting Information Retrieval Evaluation,</booktitle>
<pages>7--10</pages>
<marker>de Castilho, Gurevych, 2011</marker>
<rawString>R. Eckart de Castilho and I. Gurevych. 2011. A Lightweight Framework for Reproducible Parameter Sweeping in Information Retrieval. In Proc. of the Workshop on Data Infrastructures for Supporting Information Retrieval Evaluation, pages 7–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ferrucci</author>
<author>A Lally</author>
</authors>
<title>UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--3</pages>
<contexts>
<context position="821" citStr="Ferrucci and Lally, 2004" startWordPosition="114" endWordPosition="117">t Darmstadt ‡ Information Center for Education, DIPF, Frankfurt § Language Technology Lab, University of Duisburg-Essen http://www.ukp.tu-darmstadt.de Abstract We present DKPro TC, a framework for supervised learning experiments on textual data. The main goal of DKPro TC is to enable researchers to focus on the actual research task behind the learning problem and let the framework handle the rest. It enables rapid prototyping of experiments by relying on an easy-to-use workflow engine and standardized document preprocessing based on the Apache Unstructured Information Management Architecture (Ferrucci and Lally, 2004). It ships with standard feature extraction modules, while at the same time allowing the user to add customized extractors. The extensive reporting and logging facilities make DKPro TC experiments fully replicable. 1 Introduction Supervised learning on textual data is a ubiquitous challenge in Natural Language Processing (NLP). Applying a machine learning classifier has become the standard procedure, as soon as there is annotated data available. Before a classifier can be applied, relevant information (referred to as features) needs to be extracted from the data. A wide range of tasks have bee</context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>D. Ferrucci and A. Lally. 2004. UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment. Natural Language Engineering, 10(3-4):327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fokkens</author>
<author>M van Erp</author>
<author>M Postma</author>
<author>T Pedersen</author>
<author>P Vossen</author>
<author>N Freire</author>
</authors>
<title>Offspring from Reproduction Problems: What Replication Failure Teaches Us. In</title>
<date>2013</date>
<booktitle>Proc. ACL,</booktitle>
<pages>1691--1701</pages>
<marker>Fokkens, van Erp, Postma, Pedersen, Vossen, Freire, 2013</marker>
<rawString>A. Fokkens, M. van Erp, M. Postma, T. Pedersen, P. Vossen, and N. Freire. 2013. Offspring from Reproduction Problems: What Replication Failure Teaches Us. In Proc. ACL, pages 1691–1701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpel</author>
<author>N Schneider</author>
<author>B O’Connor</author>
<author>D Das</author>
<author>D Mills</author>
<author>J Eisenstein</author>
<author>M Heilman</author>
<author>D Yogatama</author>
<author>J Flanigan</author>
<author>N Smith</author>
</authors>
<title>Part-of-speech tagging for Twitter: annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan, and N. Smith. 2011. Part-of-speech tagging for Twitter: annotation, features, and experiments. In Proc. ACL, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hall</author>
<author>E Frank</author>
<author>G Holmes</author>
<author>B Pfahringer</author>
<author>P Reutemann</author>
<author>I Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="12912" citStr="Hall et al., 2009" startWordPosition="2019" endWordPosition="2022"> level information and DKPro TC will automatically include a special task that is executed before the actual features are extracted. Depending on the feature mode which has been configured, DKPro TC will extract information on document level, unit- and/or sequence-level, or document pair level. DKPro TC stores extracted features in its internal feature store. When the extraction process is finished, a configurable data writer converts the content from the feature store into a format which can be handled by the utilized machine learning tool. DKPro TC currently ships data writers for the Weka (Hall et al., 2009), Meka4, and Mallet (McCallum, 2002) frameworks. Users can also add dedicated data writers that output features in the format used by the machine learning framework of their choice. 3.5 Supervised Learning For the actual machine learning, DKPro TC currently relies on Weka (single-label and regression), Meka (multi-label), and Mallet (sequence labeling). It contains a task which trains a freely configurable classifier on the training data and evaluates the learned model on the test data. Before training and evaluation, the user may apply dimensionality reduction to the feature set, i.e. select </context>
<context position="20447" citStr="Hall et al., 2009" startWordPosition="3130" endWordPosition="3133">o-medical data. Like DKPro TC, Argo is based on UIMA, but focuses on sequence tagging, and it lacks DKPro TC’s parameter sweeping capabilities. NLTK (Bird et al., 2009) is a general-purpose NLP toolkit written in Python. It offers components for a wide range of preprocessing tasks and also supports feature extraction and machine learning for supervised text classification. Like DKPro TC, it can be used to quickly setup baseline experiments. As opposed to DKPro TC, NLTK lacks a modular structure with respect to preprocessing and feature extraction and does not support parameter sweeping. Weka (Hall et al., 2009) is a machine learning framework that covers only the last two steps of DKPro TC’s experimental process, i.e. machine learning and evaluation. However, it offers no dedicated support for preprocessing and feature generation. Weka is one of the machine learning frameworks that can be used within DKPro TC for actual machine learning. Mallet (McCallum, 2002) is another machine 65 learning framework implementing several supervised and unsupervised learning algorithms. As opposed to Weka, is also supports sequence tagging, including Conditional Random Fields, as well as topic modeling. Mallet can b</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. Witten. 2009. The WEKA Data Mining Software: An Update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<contexts>
<context position="12948" citStr="McCallum, 2002" startWordPosition="2026" endWordPosition="2027">tomatically include a special task that is executed before the actual features are extracted. Depending on the feature mode which has been configured, DKPro TC will extract information on document level, unit- and/or sequence-level, or document pair level. DKPro TC stores extracted features in its internal feature store. When the extraction process is finished, a configurable data writer converts the content from the feature store into a format which can be handled by the utilized machine learning tool. DKPro TC currently ships data writers for the Weka (Hall et al., 2009), Meka4, and Mallet (McCallum, 2002) frameworks. Users can also add dedicated data writers that output features in the format used by the machine learning framework of their choice. 3.5 Supervised Learning For the actual machine learning, DKPro TC currently relies on Weka (single-label and regression), Meka (multi-label), and Mallet (sequence labeling). It contains a task which trains a freely configurable classifier on the training data and evaluates the learned model on the test data. Before training and evaluation, the user may apply dimensionality reduction to the feature set, i.e. select a limited number of (expectedly mean</context>
<context position="20804" citStr="McCallum, 2002" startWordPosition="3191" endWordPosition="3192">classification. Like DKPro TC, it can be used to quickly setup baseline experiments. As opposed to DKPro TC, NLTK lacks a modular structure with respect to preprocessing and feature extraction and does not support parameter sweeping. Weka (Hall et al., 2009) is a machine learning framework that covers only the last two steps of DKPro TC’s experimental process, i.e. machine learning and evaluation. However, it offers no dedicated support for preprocessing and feature generation. Weka is one of the machine learning frameworks that can be used within DKPro TC for actual machine learning. Mallet (McCallum, 2002) is another machine 65 learning framework implementing several supervised and unsupervised learning algorithms. As opposed to Weka, is also supports sequence tagging, including Conditional Random Fields, as well as topic modeling. Mallet can be used as machine learning framework within DKPro TC. Scikit-learn (Pedregosa et al., 2011) is a machine learning framework written in Python. It offers basic functionality for preprocessing, feature selection, and parameter tuning. It provides some methods for preprocessing such as converting documents to tf.idf vectors, but does not offer sophisticated </context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>A. McCallum. 2002. MALLET: A Machine Learning for Language Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ogren</author>
<author>P Wetzler</author>
<author>S Bethard</author>
</authors>
<title>ClearTK: A UIMA toolkit for statistical natural language processing.</title>
<date>2008</date>
<booktitle>In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at LREC,</booktitle>
<pages>32--38</pages>
<contexts>
<context position="19027" citStr="Ogren et al., 2008" startWordPosition="2899" endWordPosition="2902">ro TC test all possible parameter combinations. The classification task automatically trains a model on the training data and stores the results of the evaluation on the test data for each fold on the disk. Finally, the evaluation scores for each fold are collected by the BatchCrossValidationReport and written to a single file using a tabulated format. 5 Related Work This section will give a brief overview about tools with a scope similar to DKPro TC. We only list freely available software, most of which is opensource. Unless otherwise indicated, all of the tools are written in Java. ClearTK (Ogren et al., 2008) is conceptually closest to DKPro TC and shares many of its distinguishing features like the modular feature extractors. It provides interfaces to machine learning libraries such as Mallet or libsvm, offers wrappers for basic NLP components, and comes with a feature extraction library that facilitates the development of custom feature extractors within the UIMA framework. In contrast to DKPro TC, it is rather designed as a programming library than a customizable research environment for quick experiments and does not provide predefined text classification setups. Furthermore, it does not suppo</context>
</contexts>
<marker>Ogren, Wetzler, Bethard, 2008</marker>
<rawString>P. Ogren, P. Wetzler, and S. Bethard. 2008. ClearTK: A UIMA toolkit for statistical natural language processing. In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at LREC, pages 32–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pedregosa</author>
<author>G Varoquaux</author>
<author>A Gramfort</author>
<author>V Michel</author>
<author>B Thirion</author>
<author>O Grisel</author>
<author>M Blondel</author>
<author>P Prettenhofer</author>
<author>R Weiss</author>
<author>V Dubourg</author>
<author>J Vanderplas</author>
<author>A Passos</author>
<author>D Cournapeau</author>
<author>M Brucher</author>
<author>M Perrot</author>
<author>E Duchesnay</author>
</authors>
<title>Scikit-learn: Machine Learning in Python.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<contexts>
<context position="21138" citStr="Pedregosa et al., 2011" startWordPosition="3239" endWordPosition="3242"> of DKPro TC’s experimental process, i.e. machine learning and evaluation. However, it offers no dedicated support for preprocessing and feature generation. Weka is one of the machine learning frameworks that can be used within DKPro TC for actual machine learning. Mallet (McCallum, 2002) is another machine 65 learning framework implementing several supervised and unsupervised learning algorithms. As opposed to Weka, is also supports sequence tagging, including Conditional Random Fields, as well as topic modeling. Mallet can be used as machine learning framework within DKPro TC. Scikit-learn (Pedregosa et al., 2011) is a machine learning framework written in Python. It offers basic functionality for preprocessing, feature selection, and parameter tuning. It provides some methods for preprocessing such as converting documents to tf.idf vectors, but does not offer sophisticated and customizable feature extractors for textual data like DKPro TC. 6 Summary and Future Work We have presented DKPro TC, a comprehensive and flexible framework for supervised learning on textual data. DKPro TC makes setting up experiments and creating new features fast and simple, and can therefore be applied for rapid prototyping.</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, Duchesnay, 2011</marker>
<rawString>F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rak</author>
<author>A Rowley</author>
<author>J Carter</author>
<author>S Ananiadou</author>
</authors>
<date>2013</date>
<booktitle>Development and Analysis of NLP Pipelines in Argo. In Proc. ACL,</booktitle>
<pages>115--120</pages>
<contexts>
<context position="19733" citStr="Rak et al., 2013" startWordPosition="3012" endWordPosition="3015">the modular feature extractors. It provides interfaces to machine learning libraries such as Mallet or libsvm, offers wrappers for basic NLP components, and comes with a feature extraction library that facilitates the development of custom feature extractors within the UIMA framework. In contrast to DKPro TC, it is rather designed as a programming library than a customizable research environment for quick experiments and does not provide predefined text classification setups. Furthermore, it does not support parameter sweeping and has no explicit support for creating experiment reports. Argo (Rak et al., 2013) is a web-based workbench with support for manual annotation and automatic analysis of mainly bio-medical data. Like DKPro TC, Argo is based on UIMA, but focuses on sequence tagging, and it lacks DKPro TC’s parameter sweeping capabilities. NLTK (Bird et al., 2009) is a general-purpose NLP toolkit written in Python. It offers components for a wide range of preprocessing tasks and also supports feature extraction and machine learning for supervised text classification. Like DKPro TC, it can be used to quickly setup baseline experiments. As opposed to DKPro TC, NLTK lacks a modular structure with</context>
</contexts>
<marker>Rak, Rowley, Carter, Ananiadou, 2013</marker>
<rawString>R. Rak, A. Rowley, J. Carter, and S. Ananiadou. 2013. Development and Analysis of NLP Pipelines in Argo. In Proc. ACL, pages 115–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>J Tibshirani</author>
<author>R Nallapati</author>
<author>C Manning</author>
</authors>
<title>Multi-instance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP-CoNLL,</booktitle>
<pages>455--465</pages>
<contexts>
<context position="6297" citStr="Surdeanu et al., 2012" startWordPosition="986" endWordPosition="990"> email classified as wanted or unwanted (spam). • In unit/sequence mode, each input document contains several units to be classified. The units in the input document cannot be divided into separate documents, either because the context of each unit needs to be preserved (e.g. to disambiguate named entities) or because they form a sequence which needs to be kept (in sequence tagging). • The pair mode is intended for problems which require a pair of texts as input, e.g. a pair of sentences to be classified as paraphrase or non-paraphrase. It represents a special case of multi-instance learning (Surdeanu et al., 2012), in which a document contains exactly two instances. Considering the outlined learning approaches and feature modes, we have summarized typical scenarios in supervised learning on textual data in Table 1 and added example applications in NLP. Replicability and Reusability As it has been recently noted by Fokkens et al. (2013), NLP experiments are not replicable in most cases. The problem already starts with undocumented preprocessing steps such as tokenization or sentence boundary detection that might have heavy impact on experimental results. In a supervised learning setting, this situation </context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>M. Surdeanu, J. Tibshirani, R. Nallapati, and C. Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proc. EMNLP-CoNLL, pages 455–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Tsoumakas</author>
<author>I Katakis</author>
<author>I Vlahavas</author>
</authors>
<date>2010</date>
<journal>Mining Multi-label Data. Transformation,</journal>
<volume>135</volume>
<issue>2</issue>
<contexts>
<context position="13759" citStr="Tsoumakas et al., 2010" startWordPosition="2151" endWordPosition="2154">hine learning, DKPro TC currently relies on Weka (single-label and regression), Meka (multi-label), and Mallet (sequence labeling). It contains a task which trains a freely configurable classifier on the training data and evaluates the learned model on the test data. Before training and evaluation, the user may apply dimensionality reduction to the feature set, i.e. select a limited number of (expectedly meaningful) features to be included for training and evaluating the classifier. DKPro TC uses the feature selection capabilities of Weka (single-label and regression) and Mulan (multi-label) (Tsoumakas et al., 2010). DKPro TC can also predict labels on unseen (i.e. unlabeled) data, using a trained classifier. In that case, no evaluation will be carried out, but the classifier’s prediction for each document will be written to a file. 3.6 Evaluation and Reporting DKPro TC calculates common evaluation scores including accuracy, precision, recall, and F1- score. Whenever sensible, scores are reported for each individual label as well as aggregated over all labels. To support users in further analyzing the performance of a classification workflow, DKPro TC outputs the confusion matrix, the ac4http://meka.sour</context>
</contexts>
<marker>Tsoumakas, Katakis, Vlahavas, 2010</marker>
<rawString>G. Tsoumakas, I. Katakis, and I. Vlahavas. 2010. Mining Multi-label Data. Transformation, 135(2):1–20.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>