<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997026">
Automatic Extraction of Named Entity Translingual Equivalence
Based on Multi-Feature Cost Minimization
</title>
<author confidence="0.962807">
Fei Huang, Stephan Vogel and Alex Waibel
</author>
<affiliation confidence="0.932404">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.449255">
Pittsburgh, PA 15213
</address>
<email confidence="0.989356">
(fhuang, vogel, ahw)@cs.cmu.edu
</email>
<sectionHeader confidence="0.998554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99936616">
Translingual equivalence refers to the relationship
between expressions of the same meaning from different
languages. Identifying translingual equivalence of
named entities (NE) can significantly contribute to
multilingual natural language processing, such as
crosslingual information retrieval, crosslingual
information extraction and statistical machine
translation. In this paper we present an integrated
approach to extract NE translingual equivalence from a
parallel Chinese-English corpus.
Starting from a bilingual corpus where NEs are
automatically tagged for each language, NE pairs are
aligned in order to minimize the overall multi-feature
alignment cost. An NE transliteration model is
presented and iteratively trained using named entity
pairs extracted from a bilingual dictionary. The
transliteration cost, combined with the named entity
tagging cost and word-based translation cost, constitute
the multi-feature alignment cost. These features are
derived from several information sources using
unsupervised and partly supervised methods. A greedy
search algorithm is applied to minimize the alignment
cost. Experiments show that the proposed approach
extracts NE translingual equivalence with 81% F-score
and improves the translation score from 7.68 to 7.74.
</bodyText>
<sectionHeader confidence="0.998705" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999870096774193">
Translingual equivalence refers to the relationship
between expressions of the same meaning from different
languages. Identifying translingual equivalence of
named entities (NE), including proper names, temporal
and numerical expressions, is very important to
multilingual language processing. This is because named
entities, especially names of persons, locations and
organizations, convey essential meaning in human
languages [1][2]. Some approaches for named entity
translation, like bilingual dictionary lookup, word/sub-
word translation or transliteration, have been explored in
the past few years [3][4][5][6][7]. However, dictionary
lookup is particularly difficult for translating uncommon
NEs because of its limited coverage, and simply
applying word-based or character-based transformation
without considering their context information, in most
cases, cannot achieve satisfactory performance either.
For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location
name, cannot be found in an LDC dictionary with 50k
entries, and it is also inappropriate to adopt the
character-by-character translation, &amp;quot;wind tomb cross&amp;quot;.
Rule-based translation is suitable for temporal and
numerical NEs, because of their limited vocabulary and
regular usage, but does not generalize well for proper
name translation, especially the translation of foreign
location or person names.
One possible solution is to automatically extract
named entity translingual equivalence from a parallel
corpus, where named entities have been manually or
automatically annotated. For example, in the following
sentence pair where NEs are automatically tagged,
</bodyText>
<construct confidence="0.372291333333333">
PER( ) LOC( ) LOC( ).
PER(Li Peng) back in LOC(Beijing) after LOC(Attending
Asian) LOC(Europe) Meeting.
</construct>
<bodyText confidence="0.96149065625">
correct NE alignment requires models for both phonetic
transliteration (&amp;quot; &amp;quot; vs. &amp;quot;Li Peng&amp;quot;) and semantic
translation (&amp;quot; &amp;quot; vs. &apos;Asian Europe Meeting&amp;quot;).
Additionally, tagging errors should also be handled.
Therefore more sophisticated models that are able to
incorporate multiple informative features are necessary.
In this paper we propose an integrated approach to
the automatic extraction of named entity translation
equivalence from a parallel Chinese/English corpus.
Initially, named entities are automatically tagged for
each language, after that NE pairs are aligned based on a
multi-feature alignment cost minimization strategy. We
present a named entity transliteration model and
iteratively extract named entities from a bilingual
dictionary to train the model. The NE transliteration
cost, combined with the NE tagging cost and word-based
translation cost, constitute the multi-feature alignment
cost. These features are derived from several
information sources using unsupervised and partly
supervised methods. A greedy search algorithm is
applied to minimize the total alignment cost for each
sentence pair. Experiments show that the proposed
approach can extract NE translingual equivalence with
81% F-score and improved the translation score from
7.68 to 7.74, which is statistically significant.
The structure of this paper is as follows: in section 2
we introduce the NE transliteration model, in section 3
we propose the multi-feature named entity alignment
framework, which incorporates transliteration cost,
word-based translation cost and tagging cost. In section
4 we present the experiments and analysis of the results.
Conclusions will be given in the last section.
</bodyText>
<sectionHeader confidence="0.98976" genericHeader="method">
2. Named Entity Transliteration Model
</sectionHeader>
<bodyText confidence="0.999784085714286">
Transliteration is the process of translating certain
words (e.g., person&apos;s name, location&apos;s name) from the
source language into their phonetic approximations in
the target language. It is an essential component for NE
translation. NEs are usually translated by combining the
phonetic transliteration of some units and semantic
translations of other units, where units can be characters,
sub-words or words. Previous work on transliteration
([3],[6]) explicitly resorts to phoneme similarities, where
a pronunciation lexicon is often needed. Here we try to
take the transliteration on the surface level using DP-
based string matching.
Directly transliterating Chinese characters into
English letters needs a large amount of bilingual NE
pairs for training, considering the parameter estimation
for over 6,000 frequent Chinese characters. However,
intermediate transliteration through pinyin syllables
(pinyin is the romanized representation of Chinese
characters) is more accurate and easier, because the
much smaller alphabet size of pinyin alleviates the data
sparseness. Furthermore, pinyin and English letters share
a quite similar alphabet that enables the Dynamic
Programming (DP)-based string matching.
Mapping Chinese characters to their pinyin syllables
(e.g., &amp;quot; &amp;quot; to &amp;quot;sa la re wo&amp;quot;) can be greatly
facilitated by a character-pinyin mapping table, which is
easy to obtain. However, mapping pinyin syllables to
English string (e.g., &amp;quot;sa la re wo&amp;quot; to &amp;quot;Sarajevo&amp;quot;) needs
more sophisticated models, which usually require a
bilingual NE list for training. To acquire an NE list, we
propose an unsupervised learning approach in which NE
pairs are automatically extracted from a large bilingual
dictionary. DP-based string matching is iteratively
applied in order to estimate the transliteration
probability from pinyin to English letter sequences.
</bodyText>
<subsectionHeader confidence="0.909112">
2.1 Transliteration Model Definition
</subsectionHeader>
<bodyText confidence="0.94471">
To extract NE pairs from a given bilingual
dictionary D , we want to find Chinese-English NE pair
(f *, e *) with highest joint probability,
</bodyText>
<equation confidence="0.896794">
(1)
</equation>
<bodyText confidence="0.996446470588235">
where f is the Chinese character sequence and e is the
English word string, P (f) is the probability of
generating the character sequence of the Chinese NE,
and P (e I f) is the probability of transliterating the
Chinese NE into an English NE.
Suppose f has m characters. For i 1,2, ..m ,
character f is transliterated into an English letter string
e through the pinyin syllable y . These strings are non-
overlapping. The generation process can be depicted as
f  f y e  e. Here the subscript i indicates
that the sub-string is transliterated from f , and it is not
necessarily the i th word/letter in e .
Let&apos;s assume each Chinese character is
independently transliterated into an English letter string
through its pinyin syllable. Considering that mappings
from Chinese characters to their pinyin syllables are
mostly deterministic, i.e., p(y I f )  1, then
</bodyText>
<equation confidence="0.997373">
P (e I f) �(e I f) �(e I y )�(y If)
    . (2)
</equation>
<bodyText confidence="0.9942925">
Suppose y is composed of m letters, for
j 1,2,...m , letter y is aligned to letter e , where
the alignment is represented as k  a . With the
independence assumption,
</bodyText>
<equation confidence="0.993101">
P(e I y ) �(e I y )
  (3)
Thus P (e I f) can be computed as
P e f
( I )  [ ( I ) ( I )]
 � y f � e y (4)
</equation>
<bodyText confidence="0.8908436">
This formula represents two levels of transliteration,
Chinese character to pinyin syllable and pinyin syllable
to English letter string.
P (f) can be computed directly from character
language model for Chinese NEs,
</bodyText>
<equation confidence="0.9760165">
P (f) � (f )� (f I f ) � (f If , f )
  (5)
</equation>
<figure confidence="0.96898062962963">
arg
max
f
),


P
,
max
*,
e
e
(
arg
*)
f
f
(
)
P
P
e
f
(
)
I
(
</figure>
<subsectionHeader confidence="0.998868">
2.2 DP-based Alignment and Iterative Training
</subsectionHeader>
<bodyText confidence="0.992009652173913">
Following the derivation of the transliteration model,
the next steps are how to identify letter-to-letter
alignment and how to train the transliteration model and
language model.
Dynamic programming (DP) has been successfully
applied in searching for the &amp;quot;optimal&amp;quot; alignment path
between two strings, where &amp;quot;optimal&amp;quot; means the
minimum accumulated editing cost between aligned
word/letter pairs (the cost is usually defined as 0 if they
are the same or 1 if there exists insertion, deletion or
substitution errors).
Since pinyin and English share a similar alphabet, the
DP-based string alignment is also applicable. However,
the original binary cost function is not appropriate for
pronunciation-based transliteration. Now the phonetic
similarity is more important than the orthographic
similarity [3], therefore alignment cost between letters
with similar pronunciations (e.g., &amp;quot;c&amp;quot; and &amp;quot;k&amp;quot; or &amp;quot;p&amp;quot; and
&amp;quot;b&amp;quot;) should be smaller.
One alternative is to take the minus logarithm of the
letter transliteration probability as the matching cost,
i.e., the cost of aligning letter e from English and letter
Y from pinyin is defined as,
</bodyText>
<equation confidence="0.626637">
C(e ,Y ) _ —logp(e l Y ) . (6)
</equation>
<bodyText confidence="0.999877586206897">
This cost function is defined directly from
transliteration probabilities. It allows both self-
transliteration and the transliteration from letters with
similar pronunciations. Thus it is more general and
accurate. Further more, the final accumulative alignment
cost between pinyin syllables and English words also
corresponds to the word/character-level transliteration
cost.
To calculate the alignment the transliteration model
parameters have to be known, which in turn are
computed based on the relevant alignment frequency,
i.e.,
where C(e , Y ) is the frequency that e and Y is
aligned. To resolve this inter-dependence between
models, the original binary cost function is first applied
to the DP-based string alignment. A list of bilingual NE
pairs is extracted from the dictionary according to their
alignment cost. Based on this initial imperfect name list,
the letter transliteration model and character language
model are trained, and employed for the NE joint
probability estimation (see formula (1), (4) and (5)). In
the following iterations, the alignment cost function as
well as the transliteration probability is updated, NE
pairs are selected according to their joint probabilities,
and translation and language models are re-trained using
the cleaner NE list. Experiment results in section 4 show
that an unsupervised learning approach improves the
accuracy of extracted NE list by refining both translation
and language models iteratively.
</bodyText>
<sectionHeader confidence="0.9042835" genericHeader="method">
3. Multi-Feature Named Entity Alignment
Model
</sectionHeader>
<bodyText confidence="0.999963571428572">
To align the NE translingual equivalence within a
sentence pair, we adopt the NE alignment model which
incorporates several features for cost estimation and
minimizes the total cost for the given pair. These
features include NE transliteration cost, word-based NE
translation cost and NE tagging cost, and will be
discussed in more details in the following sections.
</bodyText>
<subsectionHeader confidence="0.979513">
3.1. Named Entity Transliteration Cost
</subsectionHeader>
<bodyText confidence="0.9694426">
&amp;quot; to &amp;quot;Sarajevo&amp;quot;) and
semantic translation of the general facility (&amp;quot; &amp;quot; to
&amp;quot;airport&amp;quot;).
To deal with this problem, we adopted a translation-
based transliteration approach, similar to the candidate
generation approach proposed by [4],. For each word in
the Chinese NE candidate, its transliteration could be
either pinyin or its semantic translation(s) from the
bilingual dictionary, and can be aligned to any word in
the English NE candidate. By way of a greedy search
algorithm (detailed discussion in section 3.4), each
English word is aligned to a unique Chinese word such
that their transliteration cost is the minimum among the
unaligned word pairs. The total NE transliteration cost is
the sum of the word-to-word transliteration costs along
the alignment path.
Let A *denotes the &amp;quot;optimal&amp;quot; alignment path, and let
f ,e be the i th word in Chinese NE f and the j th
word in English NE e ,respectively. Then
(g)
</bodyText>
<equation confidence="0.988478777777778">
C(e
�C e Y
( � ,)
, (�)
p e Y
( � )_
,
Y
)
</equation>
<bodyText confidence="0.992499555555556">
The translation of different NE equivalences is highly
type-dependent. While most PERSON and LOCATION
NE equivalences can be transformed primarily through
transliteration, some LOCATION and most
ORGANIZATION NE equivalences are transformed by
combining both semantic translation and phonetic
transliteration. For example, translating a location name
&amp;quot; &amp;quot;needs both phonetic transliteration of
the specific city name (&amp;quot;
</bodyText>
<equation confidence="0.975561421052631">
�
,
)
e
min —log
P e Y
( � )]
�
[arg
,
C (f
e C f
) = (
,
,
�
e
A*)
C (f
</equation>
<bodyText confidence="0.99820625">
where  is one element in  &apos;s transliteration candidate
set  .
This approach allows the alignment between any
word pairs, so it is not sensitive to the word orders in NE
pairs, and therefore can handle flexible combination of
translation and transliteration. It is also robust to
inflectional forms (e.g., the plural form of nouns) in
English NEs.
</bodyText>
<subsectionHeader confidence="0.784413">
3.2. Named Entity Translation Cost
</subsectionHeader>
<tableCaption confidence="0.895087285714286">
Word translation probabilities can be estimated from
a parallel corpus using various well-known alignment
models, such as the IBM-model and HIMM-model [8][9].
They can be further used to calculate the probability that
a Chinese NE is the translation of an English NE on the
word level.
Assume the English NE  has  English words,
</tableCaption>
<bodyText confidence="0.37352425">
  ,... , and the Chinese NE  has  Chinese
words,   ,...  . The translation probability of the
named entities pair is computed using the IBM model-1,
as:
</bodyText>
<equation confidence="0.491582333333333">
1
  
( I )    ( I ) (9)
</equation>
<bodyText confidence="0.7278665">
This alignment model is asymmetric, as one source
word can only be aligned to one target word, while one
target word can be aligned to multiple source words. To
make it symmetric, we estimate both ( I  ) and
</bodyText>
<subsectionHeader confidence="0.591399">
That is, the translation cost of a given NE pair
</subsectionHeader>
<bodyText confidence="0.796835625">
,
)
is composed of the sum of the bi-direction translation
cost, and weighted by position match weight A .
A models the &amp;quot;distance&amp;quot; between the relative
positions of al
(

igned NEs in each sentence. It is
characterized by a normal distribution,
where
,the relative position of a Chinese NE
covering words from
to
, is defined as
The relative position of an English NE,
</bodyText>
<page confidence="0.468455">
is
</page>
<figureCaption confidence="0.55932">
defined similarly. The varian
</figureCaption>
<figure confidence="0.47386">



  (    ) � 2  . (12)
,
</figure>
<footnote confidence="0.325351">
ce 6 is empirically chosen
</footnote>
<bodyText confidence="0.852737333333333">
according to the homogeneity of word orders between
guages.
two lan
</bodyText>
<subsectionHeader confidence="0.916797">
3.3. Named Entity Tagging Cost
</subsectionHeader>
<bodyText confidence="0.99868">
An NE tagging software, IdentiFinderTM,
automatically tags NEs for both English and Chinese.
When evaluated on the bilingual corpus, the tagging
accuracy for ENAMEX type (including PERSON,
LOCATION and ORGANIZATION) NEs is about 80%.
Those tagging errors, including missing, spurious (false
positive) and partial tagging, inevitably introduce errors
into NE alignment. It would be helpful to know the
confidence or the probability that a tagged word
sequence is a real NE. Unfortunately, the outsourced
tagger doesn&apos;t output such information. To get this
information, an
</bodyText>
<equation confidence="0.5726562">
HIMM-based
NE tagger is trained from
the

training corpus, i.e., the automatically
</equation>
<bodyText confidence="0.741652857142857">
tagged bilingual corpus containing incorrect NEs.
Automatic named entity tagging based on
HIMM
has
achieved satisfactory performance [2]. In this
framework, each type of NEs as well as the remaining
type,
</bodyText>
<figure confidence="0.793020824074074">
NOT�A�NAME,
is represented by a unique
internal state in the
HIMM.
An NE-tagged sentence is
generated according to the following assumption:
1. The current NE type is selected according to the
previous word and its NE type, with type
transitional probability
(
I

,

) ;
2. The first word in a NE is generated according to
the current and previous NE types, with first word
generation probability
(
I
,
) ;
3. Each subsequent word in this NE is generated from
a type-dependent bigram model, with probability
(I,).
In the above notation,

and

represent the
current and previous NE type respectively,

represents the first word in the current NE type,

represents the current word, and

represents the
previous word.
Given a sequence of words
(
,

,...,
)
and
its corresponding NE type sequence
(
,

,...,

), the probability of generating the
words from the NE type sequence is defined as
(
I
)( , I  , )
  (13)
where
,
I
,
)denotes the transitional
probability from
to
given that the
corresponding NE types are
and
.When the
tran
(




,


sition is within the same NE, i.e.,    ,this is
( I  ), and define the NE translation cost as:
,

(

)
)

    
( I )  ( I



A
[log
  
( I
)

log

( I )],
 
1
(  )

exp{
A
}
26
</figure>
<page confidence="0.386622">
2706
</page>
<bodyText confidence="0.716972">
just the type-dependent bigram model P (w I w , N ) .
When the transition is between different NEs, this
becomes the product of type transition probability
</bodyText>
<equation confidence="0.86229">
P (N I w , N ) and first word generation probability
P (w IN ,N ).
</equation>
<bodyText confidence="0.967865">
For an aligned NE pair (e , f ) , their NE types
should be the same. So the NE tagging cost is defined as
</bodyText>
<equation confidence="0.463105">
(14)
</equation>
<bodyText confidence="0.9997045">
This criteria chooses the best NE type N from
PERSON, LOCATION and ORGANIZATION that
generates the Chinese and English NE word sequences
with the highest probabilities. During parameter
estimation, to reduce negative effect from erroneous
initial tagging, the corpus is split into 2 parts, and the
model is trained from one half when applied on the other
half.
</bodyText>
<subsectionHeader confidence="0.9932">
3.4 Multi-Feature Cost Minimization
</subsectionHeader>
<bodyText confidence="0.983048">
Provided with different alignment features, including
the transliteration cost C , the translation cost
C and the tagging cost C , the overall alignment
cost for the NE pair (e , f ) is their linear
combination:
</bodyText>
<subsectionHeader confidence="0.302332">
C(
</subsectionHeader>
<bodyText confidence="0.9726815">
) (
where the three A, &apos;s are either empirically chosen to
discriminate correct and incorrect NE alignments with
best accuracy, or selected according to the
quality/confidence of each feature model. In the current
implementation, these parameters are selected to map
the three weighted costs into the same numerical range
while putting a little less confidence on C (since it is
trained from imperfect training data).
For any bilingual sentence pair containing multiple
NEs, the desirable alignment scheme should minimize
the sum of the overall alignment cost. To find this
optimal alignment, an algorithm similar to the
competitive linking algorithm [10] is adopted:
</bodyText>
<listItem confidence="0.8133783">
1. Initialize NE-Aligned to be an empty set and NE-
Pairs as the list of all possible combinations of a
source language NE and a target language NE in the
given sentence pair;
2. Sort NE-Pairs in ascending order according to their
overall alignment cost defined in Formula (15);
3. Move the topmost pair (e , f ) , i.e. the pair with
the smallest alignment cost from NE-Pairs to NE-
Aligned;
4. Remove all entries containing either e or f from
</listItem>
<bodyText confidence="0.969467866666667">
NE-Pairs, with the assumption that once a Chinese
NE is aligned with an English NE, it can&apos;t be aligned
with any other English NE. The same is true for
English NEs;
5. Repeat from Step 3 until NE-Pairs is empty or the
top alignment cost is above a certain threshold. The
resultant NE-Aligned leads to the &amp;quot;optimal&amp;quot;
alignment.
Note that this algorithm is based on a greedy search
approximation, i.e., it only chooses the local optimal
alignment—the currently minimum cost alignment pair
among unaligned pairs—at each step, it cannot
guarantee the global optimality. But empirically it often
finds the alignment with minimum or close to minimum
sentence alignment cost.
</bodyText>
<subsectionHeader confidence="0.942348">
3.5 Open-End NE Alignment
</subsectionHeader>
<bodyText confidence="0.999699875">
When applying extracted NE equivalences to the
statistical machine translation task (see section 4.3), the
translation score is improved. Detailed analysis shows
that initial tagging errors still cause many problems for
NE translation. Some NEs in the test data are not
translated correctly because they are untagged, partially
tagged or tagged with other words as one NE in the
training corpus. For example,
</bodyText>
<figure confidence="0.878914285714286">
}
} } 12
}
should be tagged as
} }
} 12
}
</figure>
<bodyText confidence="0.991119714285714">
To recover from those partial tagging errors, an open-
end NE alignment window is utilized. The window is
initially set to fit the originally tagged NEs, afterwards
both ends of the window are allowed to expand and
shrink within a given range. As a result, optimal aligned
NEs are searched from all word sequences within the
resultant variable-length sliding window.
</bodyText>
<listItem confidence="0.3410375">
4. Experiment Result and Discussion
4.1 Named Entity Transliteration
</listItem>
<bodyText confidence="0.99718">
Three sets of experiments are conducted. The first
one is to evaluate the proposed iterative training for the
NE transliteration model by examining the accuracy of
the extracted NE lists. The second is to measure the
precision/recall of NE pair extracted from a small data
set, and the third is to assess the increased translation
quality by adding the NE bilingual dictionary. The
</bodyText>
<figure confidence="0.997099307692308">
[


( , )
e
( � )
e N
min
log
C
P

P
(f I N)]
log
e ,f
)AC ( , )
e f  � C
( , )
e f

AC
(
e ,f
)
1 5
</figure>
<bodyText confidence="0.999466209302326">
bilingual dictionary used to train the transliteration
model is the Chinese-English dictionary version 3.1
released by the Linguistic Data Consortium (LDC). This
dictionary contains 81,945 entries for 54,131 unique
Chinese words.
Initially we extracted 3,000 NE pairs with minimum
string matching cost under a 0/1 cost function. From this
small name list, the letter transliteration model and
Chinese character language model are trained and
integrated into the statistical transliteration framework.
In the following extraction iteration, additional 500
named entity pairs with higher NE joint probabilities are
added and used to update the transliteration model and
the language model. This process continues until adding
more NE pairs doesn&apos;t improve the extraction accuracy
any more, which usually happens at the 6 iteration
where a total of 5,500�6,000 NE entries are included.
Because NE pairs are sorted descendingly according to
their joint probabilities, entries at the top of the sorted
list are more likely to be NE pairs than those at the
bottom. To estimate the overall accuracy for all
extracted NEs, we evaluate the &amp;quot;local&amp;quot; accuracy of
evenly distributed segments in the sorted NE pair list. In
other word we count the number of correct NE pairs for
each segment located at the 0-100 , 900 -1000 ,
1900 —2000 NE pair, etc.. The precision evaluated on
these sub-samples is used to estimate the overall
accuracy.
Figure 1 shows the precision curve after selected
iterations at different evaluation segments. &amp;quot;0/1
baseline&amp;quot; represents the result when using only DP string
matching with the 0/1 cost function. &amp;quot;Itex&amp;quot; means the
result after the xth iteration. One can see that for well-
trained models (after the 4 iteration) the accuracy of the
evaluation segment at 5000 just slightly degrades
compared with those top segments. The precisions of all
the segments are consistently increased after each
iteration. One can see that the most significant accuracy
degradation happens at the 6000 segment. This
indicates that most NE pairs in the dictionary have
already been included, and adding more non-NE entries
will &amp;quot;pollute&amp;quot; the transliteration model, thus the
performance can become even worse.
</bodyText>
<subsectionHeader confidence="0.760885">
4.2 Extracting Named Entity Translingual
Equivalence
</subsectionHeader>
<bodyText confidence="0.999037872340426">
The bilingual corpus contains sentence-aligned
newswire data from the Xinhua News Agency and the
Foreign Broadcast Information Service (FBIS). Some
bilingual sentence pairs are automatically extracted and
aligned, therefore there exist errors in both alignment
and translation. The Chinese sentences are pre-
segmented using a maximum-matching segmenter with a
44K wordlist. Totally there are 152,391 sentence pairs,
about 6 million English words and 5.5 million Chinese
words. Named entities in the bilingual corpus are first
annotated using BBN&apos;s IdentiFinderTM, then aligned
according to the multi-feature cost minimization
framework.
For the purpose of evaluation, a small set of test data
is randomly selected, which contains 100 sentence pairs,
4950 Chinese words and 5646 English words. The
number of named entity pairs which can be aligned is
357. These named entities are manually annotated and
aligned, and used as the gold standard to evaluate the
automatically extracted and aligned NE pairs.
Table 1 shows the precision/recall/F-score using
different feature sets for cost minimization. &amp;quot; C &amp;quot;
means using word-level translation cost only, &amp;quot;+ C &amp;quot;
means adding NE tagging cost, &amp;quot;+ C &amp;quot; means
adding NE transliteration cost into the previous feature
set. It can be seen that by adding more information, both
precision and recall are improved. Tagging cost and
transliteration cost individually lead to about 3%
increase in F-score and the overall improvement is about
6.8%. The last row shows the NE alignment accuracy on
manually annotated test data, where all tagging errors
have been corrected. The significant improvement in F-
score (81.3% to 93.7%) indicates that initial tagging
errors remain the major cause of alignment errors.
Figure 2 demonstrates some examples of extracted
NE translation equivalences from the given sentence
pairs, when applying various models. In each example
NE pairs with the same number label (e.g., C1 and E1)
are considered correct alignment. One can see from
example 1 that the proposed alignment strategy can
correctly align most NE pairs, even with NE translation
cost only. Those incorrect alignments, marked by (*),
are caused either by missed NE tagging or non-exact
translations. When adding tagging cost, some missed
NEs could be recovered and correctly aligned (See
example 2). Example 3 shows that the transliteration
model works best for NEs containing people&apos;s name.
</bodyText>
<subsectionHeader confidence="0.987114">
4.3 Improving Translation Quality with Named
Entity Dictionary
</subsectionHeader>
<bodyText confidence="0.999935461538462">
A NE translation dictionary can be constructed from
extracted NE equivalences. In the dictionary one
Chinese NE may have multiple English translations with
different probabilities. These probabilities are
proportional to the frequencies of the NE alignments.
This dictionary is integrated into a statistical machine
translation (SMT) engine and evaluated on Chinese-
English newswire translation.
The SMT system is based on weighted finite state
transducers [11], where each transducer is a collection of
bilingual equivalence for words, phrases or NEs. In our
experiment, three transducers are integrated into the
translation engine,
</bodyText>
<listItem confidence="0.665477">
• A word level transducer, which is essentially from
the LDC Chinese-English dictionaries (see Section
4.1). Since many entries in this dictionary are
manually compiled, this dictionary has very high
accuracy. It is called &amp;quot;LDC&amp;quot; in table 2.
• A phrase-to-phrase transducers where the phrase
pairs are extracted from the HMM Viterbi
alignment [9] for each sentence pair in the bilingual
corpus. It is called &amp;quot;HMM&amp;quot; in table 2.
• A NE transducer from the NE translation dictionary,
the &amp;quot;NE&amp;quot; in table 2.
</listItem>
<bodyText confidence="0.999924692307692">
The evaluation data is the same newswire data used in
TIDES 2001 dry-run evaluation. It contains 993
sentences, 24,821 words. From this data set the
IdentiFinderTM extracted 2,379 NEs with totally 3,597
words. Evaluation metrics are fully automatic, including
Bleu and NIST8 scores. Table 2 shows the improvement
on translation score after adding the NE transducer to
various transducer settings. From the table we can see
that the NE transducer gives statistically significant
improvement in all the settings, although the amount of
improvement varies from 0.06 to 0.45. This is because
there are some overlaps between the NE transducer and
the HMM phrase transducer.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="evaluation">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999956133333333">
We proposed an approach to the automatic extraction
of named entity translation equivalence from a parallel
Chinese/English corpus based on multi-feature cost
minimization. We presented a named entity
transliteration model and iteratively extracted named
entities from a bilingual dictionary to train the model.
The NE transliteration cost, the NE tagging cost and
word-based translation cost constitute the multi-feature
alignment cost. These features are derived from several
information sources using unsupervised and partly
supervised methods. Experiments showed that the
proposed approach can extract NE translingual
equivalence with 81% in terms of F-score and
significantly improved the translation score from 7.68 to
7.74.
</bodyText>
<sectionHeader confidence="0.998435" genericHeader="conclusions">
6. Acknowledgement
</sectionHeader>
<bodyText confidence="0.9976656">
We cordially thank the anonymous reviewers for their
valuable comments and suggestions in order to prepare
the final version of this paper. We also thank BBN for
providing us with their named entity tagging software
IdentiFinderTM.
</bodyText>
<tableCaption confidence="0.894978">
Table 1. Precision/Recall of Extracted NE
Translingual Equivalence
</tableCaption>
<table confidence="0.999869">
Precision Recall F-score
66.1% 85.5% 74.5%
69.7% 87.7% 77.7%
73.8% 90.5% 81.3%
91.3% 96.1% 93.7%
</table>
<tableCaption confidence="0.995274">
Table 2. Translation Quality Improvement by
</tableCaption>
<table confidence="0.920857857142857">
Adding NE Dictionaries
Bleu NIST8 t-test
Score Score statistics
LDC 0.131 6.193 t=8.516
LDC+NE 0.151 6.644 p=0.000
LDC+HMM 0.210 7.677 t=1.963
LDC+HMM+NE 0.213 7.744 p=0.026
</table>
<sectionHeader confidence="0.946621" genericHeader="references">
7. References
</sectionHeader>
<reference confidence="0.999660037037037">
[1] D. Appelt, J. Hobbs, D. Israel, and M. Tyson. Fastus:
A finite-state processor for information extraction from
real world texts. In Proceedings of I�CAI--93, pp.1172-
1178, Chambery, France, 1993.
[2] D. Bikel, S. Miller, R. Schwarz and R. Weischedel.
Nymble: A high-performance learning name-finder. In
Proceedings of Applied Natural Language Processing,
pp.194-201, Washington DC, 1997.
[3] K. Knight and J. Graehl. Machine Transliteration. In
Proceedings of the ACL &apos;97. pp.128-135, Somerset,
New Jersey, 1997.
[4] Y. Al-Onaizan and K. Knight. Translating Named
Entity Using Bilingual and Monolingual Resources, in
Proceedings of Association of Computational
Linguistics 2002, Philadelphia, PA, July, 2002.
[5] B. Stalls and K. Knight. Translating Names and
Technical Terms in Arabic Text. In Proceedings of the
COLING/ACL Workshop on Computational Approaches
to Semitic Languages, 1998.
[6] H. Meng, W. K. Lo, B. Chen and K. Tang.
Generating Phonetic Cognates to Handle Named Entities
in English-Chinese Cross-Language Spoken Document
Retrieval. In Proceedings of the Automatic Speech
Recognition and Understanding Workshop, Trento, Italy,
December 2001.
[7] F. Huang and S. Vogel. Improved Named Entity
Translation and Bilingual Named Entity Extraction, In
</reference>
<figure confidence="0.9825808">
C
+ C
+ C
Manual
Annotation
</figure>
<reference confidence="0.993573823529412">
Proceedings of the 4 IEEE International Conference
on Multimodal Interface, pp. 253-258, Pittsburgh, PA,
October 2002.
[8] P. F. Brown, S. A. Della Pietra, V. J. Della Pietra
and R.L. Mercer. The mathematics of Machine
Translation: Parameter Estimation. In Computational
Linguistics, vol 19, number 2. pp.263-311, June, 1993.
[9] S. Vogel, H. Ney and C. Tillmann. HMM-Based
Word Alignment in Statistical Translation. In
Proceedings of the ACL&apos;96, pp. 836-841, Copenhagen,
Denmark, August 1996.
[10] I. Dan Melamed. Models of Translational
Equivalence among Words, In Computational
Linguistics 26(2), pp. 221-249, June 2000.
[11] S. Vogel and H. Ney. Translation with Cascaded
Finite State Transducers. In Proceedings of the ACL&apos;00,
pp. 23-30, Hong Kong, China, October, 2000.
</reference>
<figureCaption confidence="0.999996">
Figure 1. Precision Curve of Evaluation Segments
Figure 2. Selected Parallel Sentences and extracted NE equivalences from Different Feature Combination
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479224">
<title confidence="0.9997095">Automatic Extraction of Named Entity Translingual Based on Multi-Feature Cost Minimization</title>
<author confidence="0.894022">Fei Huang</author>
<author confidence="0.894022">Stephan Vogel</author>
<author confidence="0.894022">Alex</author>
<affiliation confidence="0.7975695">Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.972889">Pittsburgh, PA</address>
<email confidence="0.996051">(fhuang,vogel,ahw)@cs.cmu.edu</email>
<abstract confidence="0.991799">Translingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE) can significantly contribute to multilingual natural language processing, such as crosslingual information retrieval, crosslingual information extraction and statistical machine translation. In this paper we present an integrated approach to extract NE translingual equivalence from a parallel Chinese-English corpus. Starting from a bilingual corpus where NEs are automatically tagged for each language, NE pairs are aligned in order to minimize the overall multi-feature alignment cost. An NE transliteration model is presented and iteratively trained using named entity pairs extracted from a bilingual dictionary. The transliteration cost, combined with the named entity tagging cost and word-based translation cost, constitute the multi-feature alignment cost. These features are derived from several information sources using unsupervised and partly supervised methods. A greedy search algorithm is applied to minimize the alignment cost. Experiments show that the proposed approach extracts NE translingual equivalence with 81% F-score and improves the translation score from 7.68 to 7.74.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Appelt</author>
<author>J Hobbs</author>
<author>D Israel</author>
<author>M Tyson</author>
</authors>
<title>Fastus: A finite-state processor for information extraction from real world texts.</title>
<date>1993</date>
<booktitle>In Proceedings of I�CAI--93,</booktitle>
<pages>1172--1178</pages>
<location>Chambery, France,</location>
<contexts>
<context position="1987" citStr="[1]" startWordPosition="258" endWordPosition="258">st. Experiments show that the proposed approach extracts NE translingual equivalence with 81% F-score and improves the translation score from 7.68 to 7.74. 1. Introduction Translingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is al</context>
</contexts>
<marker>[1]</marker>
<rawString>D. Appelt, J. Hobbs, D. Israel, and M. Tyson. Fastus: A finite-state processor for information extraction from real world texts. In Proceedings of I�CAI--93, pp.1172-1178, Chambery, France, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bikel</author>
<author>S Miller</author>
<author>R Schwarz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: A high-performance learning name-finder.</title>
<date>1997</date>
<booktitle>In Proceedings of Applied Natural Language Processing,</booktitle>
<pages>194--201</pages>
<location>Washington DC,</location>
<contexts>
<context position="1990" citStr="[2]" startWordPosition="258" endWordPosition="258"> Experiments show that the proposed approach extracts NE translingual equivalence with 81% F-score and improves the translation score from 7.68 to 7.74. 1. Introduction Translingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also </context>
<context position="15652" citStr="[2]" startWordPosition="2470" endWordPosition="2470">N and ORGANIZATION) NEs is about 80%. Those tagging errors, including missing, spurious (false positive) and partial tagging, inevitably introduce errors into NE alignment. It would be helpful to know the confidence or the probability that a tagged word sequence is a real NE. Unfortunately, the outsourced tagger doesn&apos;t output such information. To get this information, an HIMM-based NE tagger is trained from the  training corpus, i.e., the automatically tagged bilingual corpus containing incorrect NEs. Automatic named entity tagging based on HIMM has achieved satisfactory performance [2]. In this framework, each type of NEs as well as the remaining type, NOT�A�NAME, is represented by a unique internal state in the HIMM. An NE-tagged sentence is generated according to the following assumption: 1. The current NE type is selected according to the previous word and its NE type, with type transitional probability ( I  ,  ) ; 2. The first word in a NE is generated according to the current and previous NE types, with first word generation probability ( I , ) ; 3. Each subsequent word in this NE is generated from a type-dependent bigram model, with probability (I,). In th</context>
</contexts>
<marker>[2]</marker>
<rawString>D. Bikel, S. Miller, R. Schwarz and R. Weischedel. Nymble: A high-performance learning name-finder. In Proceedings of Applied Natural Language Processing, pp.194-201, Washington DC, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine Transliteration.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL &apos;97.</booktitle>
<pages>128--135</pages>
<location>Somerset, New Jersey,</location>
<contexts>
<context position="2161" citStr="[3]" startWordPosition="282" endWordPosition="282">anslingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also inappropriate to adopt the character-by-character translation, &amp;quot;wind tomb cross&amp;quot;. Rule-based translation is suitable for temporal and numerical NEs, because of their limit</context>
<context position="5450" citStr="[3]" startWordPosition="747" endWordPosition="747">st. In section 4 we present the experiments and analysis of the results. Conclusions will be given in the last section. 2. Named Entity Transliteration Model Transliteration is the process of translating certain words (e.g., person&apos;s name, location&apos;s name) from the source language into their phonetic approximations in the target language. It is an essential component for NE translation. NEs are usually translated by combining the phonetic transliteration of some units and semantic translations of other units, where units can be characters, sub-words or words. Previous work on transliteration ([3],[6]) explicitly resorts to phoneme similarities, where a pronunciation lexicon is often needed. Here we try to take the transliteration on the surface level using DPbased string matching. Directly transliterating Chinese characters into English letters needs a large amount of bilingual NE pairs for training, considering the parameter estimation for over 6,000 frequent Chinese characters. However, intermediate transliteration through pinyin syllables (pinyin is the romanized representation of Chinese characters) is more accurate and easier, because the much smaller alphabet size of pinyin alle</context>
<context position="9401" citStr="[3]" startWordPosition="1425" endWordPosition="1425"> (DP) has been successfully applied in searching for the &amp;quot;optimal&amp;quot; alignment path between two strings, where &amp;quot;optimal&amp;quot; means the minimum accumulated editing cost between aligned word/letter pairs (the cost is usually defined as 0 if they are the same or 1 if there exists insertion, deletion or substitution errors). Since pinyin and English share a similar alphabet, the DP-based string alignment is also applicable. However, the original binary cost function is not appropriate for pronunciation-based transliteration. Now the phonetic similarity is more important than the orthographic similarity [3], therefore alignment cost between letters with similar pronunciations (e.g., &amp;quot;c&amp;quot; and &amp;quot;k&amp;quot; or &amp;quot;p&amp;quot; and &amp;quot;b&amp;quot;) should be smaller. One alternative is to take the minus logarithm of the letter transliteration probability as the matching cost, i.e., the cost of aligning letter e from English and letter Y from pinyin is defined as, C(e ,Y ) _ —logp(e l Y ) . (6) This cost function is defined directly from transliteration probabilities. It allows both selftransliteration and the transliteration from letters with similar pronunciations. Thus it is more general and accurate. Further more, the final accumu</context>
</contexts>
<marker>[3]</marker>
<rawString>K. Knight and J. Graehl. Machine Transliteration. In Proceedings of the ACL &apos;97. pp.128-135, Somerset, New Jersey, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>K Knight</author>
</authors>
<title>Translating Named Entity Using Bilingual and Monolingual Resources,</title>
<date>2002</date>
<booktitle>in Proceedings of Association of Computational Linguistics 2002,</booktitle>
<location>Philadelphia, PA,</location>
<contexts>
<context position="2164" citStr="[4]" startWordPosition="282" endWordPosition="282">lingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also inappropriate to adopt the character-by-character translation, &amp;quot;wind tomb cross&amp;quot;. Rule-based translation is suitable for temporal and numerical NEs, because of their limited </context>
<context position="11897" citStr="[4]" startWordPosition="1807" endWordPosition="1807">ivalence within a sentence pair, we adopt the NE alignment model which incorporates several features for cost estimation and minimizes the total cost for the given pair. These features include NE transliteration cost, word-based NE translation cost and NE tagging cost, and will be discussed in more details in the following sections. 3.1. Named Entity Transliteration Cost &amp;quot; to &amp;quot;Sarajevo&amp;quot;) and semantic translation of the general facility (&amp;quot; &amp;quot; to &amp;quot;airport&amp;quot;). To deal with this problem, we adopted a translationbased transliteration approach, similar to the candidate generation approach proposed by [4],. For each word in the Chinese NE candidate, its transliteration could be either pinyin or its semantic translation(s) from the bilingual dictionary, and can be aligned to any word in the English NE candidate. By way of a greedy search algorithm (detailed discussion in section 3.4), each English word is aligned to a unique Chinese word such that their transliteration cost is the minimum among the unaligned word pairs. The total NE transliteration cost is the sum of the word-to-word transliteration costs along the alignment path. Let A *denotes the &amp;quot;optimal&amp;quot; alignment path, and let f ,e be the</context>
</contexts>
<marker>[4]</marker>
<rawString>Y. Al-Onaizan and K. Knight. Translating Named Entity Using Bilingual and Monolingual Resources, in Proceedings of Association of Computational Linguistics 2002, Philadelphia, PA, July, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Stalls</author>
<author>K Knight</author>
</authors>
<title>Translating Names and Technical Terms in Arabic Text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages,</booktitle>
<contexts>
<context position="2167" citStr="[5]" startWordPosition="282" endWordPosition="282">gual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also inappropriate to adopt the character-by-character translation, &amp;quot;wind tomb cross&amp;quot;. Rule-based translation is suitable for temporal and numerical NEs, because of their limited voc</context>
</contexts>
<marker>[5]</marker>
<rawString>B. Stalls and K. Knight. Translating Names and Technical Terms in Arabic Text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>W K Lo</author>
<author>B Chen</author>
<author>K Tang</author>
</authors>
<title>Generating Phonetic Cognates to Handle Named Entities in English-Chinese Cross-Language Spoken Document Retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the Automatic Speech Recognition and Understanding Workshop,</booktitle>
<location>Trento, Italy,</location>
<contexts>
<context position="2170" citStr="[6]" startWordPosition="282" endWordPosition="282">l equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also inappropriate to adopt the character-by-character translation, &amp;quot;wind tomb cross&amp;quot;. Rule-based translation is suitable for temporal and numerical NEs, because of their limited vocabu</context>
<context position="5454" citStr="[6]" startWordPosition="747" endWordPosition="747">In section 4 we present the experiments and analysis of the results. Conclusions will be given in the last section. 2. Named Entity Transliteration Model Transliteration is the process of translating certain words (e.g., person&apos;s name, location&apos;s name) from the source language into their phonetic approximations in the target language. It is an essential component for NE translation. NEs are usually translated by combining the phonetic transliteration of some units and semantic translations of other units, where units can be characters, sub-words or words. Previous work on transliteration ([3],[6]) explicitly resorts to phoneme similarities, where a pronunciation lexicon is often needed. Here we try to take the transliteration on the surface level using DPbased string matching. Directly transliterating Chinese characters into English letters needs a large amount of bilingual NE pairs for training, considering the parameter estimation for over 6,000 frequent Chinese characters. However, intermediate transliteration through pinyin syllables (pinyin is the romanized representation of Chinese characters) is more accurate and easier, because the much smaller alphabet size of pinyin alleviat</context>
</contexts>
<marker>[6]</marker>
<rawString>H. Meng, W. K. Lo, B. Chen and K. Tang. Generating Phonetic Cognates to Handle Named Entities in English-Chinese Cross-Language Spoken Document Retrieval. In Proceedings of the Automatic Speech Recognition and Understanding Workshop, Trento, Italy, December 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>S Vogel</author>
</authors>
<title>Improved Named Entity Translation and Bilingual Named Entity Extraction,</title>
<date>2002</date>
<booktitle>In Proceedings of the 4 IEEE International Conference on Multimodal Interface,</booktitle>
<pages>253--258</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="2173" citStr="[7]" startWordPosition="282" endWordPosition="282">quivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE), including proper names, temporal and numerical expressions, is very important to multilingual language processing. This is because named entities, especially names of persons, locations and organizations, convey essential meaning in human languages [1][2]. Some approaches for named entity translation, like bilingual dictionary lookup, word/subword translation or transliteration, have been explored in the past few years [3][4][5][6][7]. However, dictionary lookup is particularly difficult for translating uncommon NEs because of its limited coverage, and simply applying word-based or character-based transformation without considering their context information, in most cases, cannot achieve satisfactory performance either. For instance, &amp;quot; /Fenglingdu&amp;quot;, a Chinese location name, cannot be found in an LDC dictionary with 50k entries, and it is also inappropriate to adopt the character-by-character translation, &amp;quot;wind tomb cross&amp;quot;. Rule-based translation is suitable for temporal and numerical NEs, because of their limited vocabular</context>
</contexts>
<marker>[7]</marker>
<rawString>F. Huang and S. Vogel. Improved Named Entity Translation and Bilingual Named Entity Extraction, In Proceedings of the 4 IEEE International Conference on Multimodal Interface, pp. 253-258, Pittsburgh, PA, October 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>In Computational Linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<contexts>
<context position="13655" citStr="[8]" startWordPosition="2116" endWordPosition="2116">in —log P e Y ( � )] � [arg , C (f e C f ) = ( , , � e A*) C (f where  is one element in  &apos;s transliteration candidate set  . This approach allows the alignment between any word pairs, so it is not sensitive to the word orders in NE pairs, and therefore can handle flexible combination of translation and transliteration. It is also robust to inflectional forms (e.g., the plural form of nouns) in English NEs. 3.2. Named Entity Translation Cost Word translation probabilities can be estimated from a parallel corpus using various well-known alignment models, such as the IBM-model and HIMM-model [8][9]. They can be further used to calculate the probability that a Chinese NE is the translation of an English NE on the word level. Assume the English NE  has  English words,   ,... , and the Chinese NE  has  Chinese words,   ,...  . The translation probability of the named entities pair is computed using the IBM model-1, as: 1    ( I )    ( I ) (9) This alignment model is asymmetric, as one source word can only be aligned to one target word, while one target word can be aligned to multiple source words. To make it symmetric, we estimate both ( I  ) and That is, the tran</context>
</contexts>
<marker>[8]</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and R.L. Mercer. The mathematics of Machine Translation: Parameter Estimation. In Computational Linguistics, vol 19, number 2. pp.263-311, June, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM-Based Word Alignment in Statistical Translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the ACL&apos;96,</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="13658" citStr="[9]" startWordPosition="2116" endWordPosition="2116">—log P e Y ( � )] � [arg , C (f e C f ) = ( , , � e A*) C (f where  is one element in  &apos;s transliteration candidate set  . This approach allows the alignment between any word pairs, so it is not sensitive to the word orders in NE pairs, and therefore can handle flexible combination of translation and transliteration. It is also robust to inflectional forms (e.g., the plural form of nouns) in English NEs. 3.2. Named Entity Translation Cost Word translation probabilities can be estimated from a parallel corpus using various well-known alignment models, such as the IBM-model and HIMM-model [8][9]. They can be further used to calculate the probability that a Chinese NE is the translation of an English NE on the word level. Assume the English NE  has  English words,   ,... , and the Chinese NE  has  Chinese words,   ,...  . The translation probability of the named entities pair is computed using the IBM model-1, as: 1    ( I )    ( I ) (9) This alignment model is asymmetric, as one source word can only be aligned to one target word, while one target word can be aligned to multiple source words. To make it symmetric, we estimate both ( I  ) and That is, the transla</context>
<context position="26864" citStr="[9]" startWordPosition="4357" endWordPosition="4357">wswire translation. The SMT system is based on weighted finite state transducers [11], where each transducer is a collection of bilingual equivalence for words, phrases or NEs. In our experiment, three transducers are integrated into the translation engine, • A word level transducer, which is essentially from the LDC Chinese-English dictionaries (see Section 4.1). Since many entries in this dictionary are manually compiled, this dictionary has very high accuracy. It is called &amp;quot;LDC&amp;quot; in table 2. • A phrase-to-phrase transducers where the phrase pairs are extracted from the HMM Viterbi alignment [9] for each sentence pair in the bilingual corpus. It is called &amp;quot;HMM&amp;quot; in table 2. • A NE transducer from the NE translation dictionary, the &amp;quot;NE&amp;quot; in table 2. The evaluation data is the same newswire data used in TIDES 2001 dry-run evaluation. It contains 993 sentences, 24,821 words. From this data set the IdentiFinderTM extracted 2,379 NEs with totally 3,597 words. Evaluation metrics are fully automatic, including Bleu and NIST8 scores. Table 2 shows the improvement on translation score after adding the NE transducer to various transducer settings. From the table we can see that the NE transducer</context>
</contexts>
<marker>[9]</marker>
<rawString>S. Vogel, H. Ney and C. Tillmann. HMM-Based Word Alignment in Statistical Translation. In Proceedings of the ACL&apos;96, pp. 836-841, Copenhagen, Denmark, August 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of Translational Equivalence among Words,</title>
<date>2000</date>
<journal>In Computational Linguistics</journal>
<volume>26</volume>
<issue>2</issue>
<pages>221--249</pages>
<contexts>
<context position="18622" citStr="[10]" startWordPosition="3029" endWordPosition="3029">osen to discriminate correct and incorrect NE alignments with best accuracy, or selected according to the quality/confidence of each feature model. In the current implementation, these parameters are selected to map the three weighted costs into the same numerical range while putting a little less confidence on C (since it is trained from imperfect training data). For any bilingual sentence pair containing multiple NEs, the desirable alignment scheme should minimize the sum of the overall alignment cost. To find this optimal alignment, an algorithm similar to the competitive linking algorithm [10] is adopted: 1. Initialize NE-Aligned to be an empty set and NEPairs as the list of all possible combinations of a source language NE and a target language NE in the given sentence pair; 2. Sort NE-Pairs in ascending order according to their overall alignment cost defined in Formula (15); 3. Move the topmost pair (e , f ) , i.e. the pair with the smallest alignment cost from NE-Pairs to NEAligned; 4. Remove all entries containing either e or f from NE-Pairs, with the assumption that once a Chinese NE is aligned with an English NE, it can&apos;t be aligned with any other English NE. The same is true</context>
</contexts>
<marker>[10]</marker>
<rawString>I. Dan Melamed. Models of Translational Equivalence among Words, In Computational Linguistics 26(2), pp. 221-249, June 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
</authors>
<title>Translation with Cascaded Finite State Transducers.</title>
<date>2000</date>
<booktitle>In Proceedings of the ACL&apos;00,</booktitle>
<pages>23--30</pages>
<location>Hong Kong, China,</location>
<contexts>
<context position="26346" citStr="[11]" startWordPosition="4278" endWordPosition="4278">hows that the transliteration model works best for NEs containing people&apos;s name. 4.3 Improving Translation Quality with Named Entity Dictionary A NE translation dictionary can be constructed from extracted NE equivalences. In the dictionary one Chinese NE may have multiple English translations with different probabilities. These probabilities are proportional to the frequencies of the NE alignments. This dictionary is integrated into a statistical machine translation (SMT) engine and evaluated on ChineseEnglish newswire translation. The SMT system is based on weighted finite state transducers [11], where each transducer is a collection of bilingual equivalence for words, phrases or NEs. In our experiment, three transducers are integrated into the translation engine, • A word level transducer, which is essentially from the LDC Chinese-English dictionaries (see Section 4.1). Since many entries in this dictionary are manually compiled, this dictionary has very high accuracy. It is called &amp;quot;LDC&amp;quot; in table 2. • A phrase-to-phrase transducers where the phrase pairs are extracted from the HMM Viterbi alignment [9] for each sentence pair in the bilingual corpus. It is called &amp;quot;HMM&amp;quot; in table 2. • </context>
</contexts>
<marker>[11]</marker>
<rawString>S. Vogel and H. Ney. Translation with Cascaded Finite State Transducers. In Proceedings of the ACL&apos;00, pp. 23-30, Hong Kong, China, October, 2000.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>