<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.121943">
<title confidence="0.999563">
Computational Measures for Language Similarity across Time
in Online Communities
</title>
<author confidence="0.998149">
David Huffaker Joseph Jorgensen Francisco Iacobelli Paul Tepper Justine Cassell
</author>
<affiliation confidence="0.984137">
Northwestern University
</affiliation>
<email confidence="0.840301">
{d-huffaker, josephj, f-iacobelli, ptepper, justine}@northwestern.edu
</email>
<sectionHeader confidence="0.992855" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994195">
This paper examines language similarity
in messages over time in an online com-
munity of adolescents from around the
world using three computational meas-
ures: Spearman’s Correlation Coefficient,
Zipping and Latent Semantic Analysis.
Results suggest that the participants’ lan-
guage diverges over a six-week period,
and that divergence is not mediated by
demographic variables such as leadership
status or gender. This divergence may
represent the introduction of more unique
words over time, and is influenced by a
continual change in subtopics over time,
as well as community-wide historical
events that introduce new vocabulary at
later time periods. Our results highlight
both the possibilities and shortcomings of
using document similarity measures to as-
sess convergence in language use.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999761266666667">
While document similarity has been a concern in
computational linguistics for some time, less atten-
tion has been paid to change in similarity across
time. And yet, while historical linguists have long
addressed the issue of divergence or convergence
among language groups over long periods of time,
there has also been increasing interest in conver-
gence (also referred to as entrainment, speech ac-
commodation, or alignment) in other areas of
Linguistics, with the realization that we have little
understanding of change in very short periods of
time, such as months, in a particular conversational
setting, between two people, or in a large group.
The Internet provides an ideal opportunity to ex-
amine questions of this sort since all texts perse-
</bodyText>
<page confidence="0.96749">
15
</page>
<bodyText confidence="0.999920208333333">
vere for later analysis, and the diversity in kinds of
online communities ensures that the influence of
social behavior on language can be examined. Yet
there has been very little work on language similar-
ity in online communities.
In this paper we compare the use of three sepa-
rate tools to measure document or message similar-
ity in a large data set from an online community of
over 3,000 participants from 140 different coun-
tries. Based on a review of related work on corpus
similarity measures and document comparison
techniques (Section 2.2), we chose Spearman’s
Correlation Coefficient, a comparison algorithm
that utilizes GZIP (which we will refer to as “Zip-
ping”) and Latent Semantic Analysis. These three
tools have all been shown effective for document
comparison or corpus similarity, but never to our
knowledge have any of them been used for docu-
ment similarity over time, nor have they been
compared to one another. Even though each of
these tools is quite different in what it specifically
measures and how it is used, and each has been
used by quite different communities of researchers,
they are all fairly well-understood (Section 4).
</bodyText>
<sectionHeader confidence="0.999833" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9816024">
In the next sections, we review literature on lan-
guage similarity or convergence. We also review
literature on the three computational tools, Spear-
man’s Correlation Coefficient (SCC), Zipping, and
Latent Semantic Analysis (LSA).
</bodyText>
<subsectionHeader confidence="0.982626">
2.1 Language Similarity in Computer-
mediated Communication
</subsectionHeader>
<bodyText confidence="0.9997964">
In dyadic settings, speakers often converge to one
another’s speech styles, not only matching the
choice of referring expressions or other words, but
also structural dimensions such as syntax, sound
characteristics such as accent, prosody, or phonol-
</bodyText>
<note confidence="0.6870365">
Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 15–22,
New York City, New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.998935120689655">
ogy, or even non-verbal behaviors such as gesture
(Brennan &amp; Clark, 1996; Street &amp; Giles, 1982).
Some scholars suggest that this convergence or
entrainment is based on a conscious need to ac-
commodate to one’s conversational partner, or as a
strategy to maximize communication effectiveness
(Street &amp; Giles, 1982). Others suggest that the
alignment is an automatic response, in which
echoic aspects of speech, gesture and facial expres-
sions are unconscious reactions (Garrod &amp; Ander-
son, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand,
2003). In short, conversational partners tend to
accommodate to each other by imitating or match-
ing the semantic, syntactic and phonological char-
acteristics of their partners (Brennan &amp; Clark,
1996; Garrod &amp; Pickering, 2004).
Many studies have concentrated on dyadic inter-
actions, but large-scale communities also demon-
strate language similarity or convergence. In fact,
speech communities have a strong influence in cre-
ating and maintaining language patterns, including
word choice or phonological characteristics
(Labov, 2001). Language use often plays an impor-
tant role in constituting a group or community
identity (Eckert, 2003). For example, language
‘norms’ in a speech community often result in the
conformity of new members in terms of accent or
lexical choice (Milroy, 1980). This effect has been
quite clear among non-native speakers, who
quickly pick up the vernacular and speech patterns
of their new situation (Chambers, 2001), but the
opposite is also true, with native speakers picking
up speech patterns from non-native speakers (Auer
&amp; Hinskens, 2005)
Linguistic innovation is particularly salient on
the Internet, where words and linguistic patterns
have been manipulated or reconstructed by indi-
viduals and quickly adopted by a critical mass of
users (Crystal, 2001). Niederhoffer &amp; Pennebaker
(2002) found that users of instant messenger tend
to match each other’s linguistic styles. A study of
language socialization in a bilingual chat room
suggests that participants developed particular lin-
guistic patterns and both native and non-native
speakers were influenced by the other (Lam,
2004). Similar language socialization has been
found in ethnographic research of large-scale
online communities as well, in which various ex-
pressions are created and shared by group mem-
bers (Baym, 2000; Cherny, 1999).
Other research not only confirms the creation of
new linguistic patterns online, and subsequent
adoption by users, but suggests that the strength of
the social ties between participants influences how
patterns are spread and adopted (Paolillo, 2001).
However, little research has been devoted to how
language changes over longer periods of time in
these online communities.
</bodyText>
<subsectionHeader confidence="0.9930205">
2.2 Computational Measures of Language
Similarity
</subsectionHeader>
<bodyText confidence="0.999707025641026">
The unit of analysis in online communities is the
(e-mail or chat) message. Therefore, measuring
entrainment in online communities relies on as-
sessing whether or not similarity between the mes-
sages of each participant increases over time. Most
techniques for measuring document similarity rely
on the analysis of word frequencies and their co-
occurrence in two or more corpora (Kilgarriff,
2001), so we start with these techniques.
Spearman’s Rank Correlation Coefficient (SCC)
is particularly useful because it is easy to compute
and not dependent on text size. Unlike some other
statistical approaches (e.g. chi-square), SCC has
been shown effective on determining similarity
between corpora of varying sizes, therefore SCC
will serve as a baseline for comparison in this pa-
per (Kilgarriff, 2001).
More recently, researchers have experimented
with data compression algorithms as a measure of
document complexity and similarity. This tech-
nique uses compression ratios as an approximation
of a document’s information entropy (Baronchelli,
Caglioti, &amp; Loreto, 2005; Benedetto, Caglioti, &amp;
Loreto, 2002). Standard Zipping algorithms have
demonstrated effectiveness in a variety of docu-
ment comparison and classification tasks. Behr et
al. (2003) found that a document and its translation
into another language compressed to approxi-
mately the same size. They suggest that this could
be used as an automatic measure for testing ma-
chine translation quality. Kaltchenko (2004) argues
that using compression algorithms to compute rela-
tive entropy is more relevant than using distances
based on Kolmogorov complexity. Lastly, Ben-
detto et al. (2002) present some basic findings us-
ing GZIP for authorship attribution, determining
the language of a document, and building a tree of
language families from a text written in different
languages. Although Zipping may be a conten-
</bodyText>
<page confidence="0.953629">
16
</page>
<bodyText confidence="0.999354107142857">
tious technique, these results present intriguing data – messages written in English during the 6-
reasons to continue exploration of its applications. week topic group period. For complete details,
Latent Semantic Analysis is another technique please refer to Cassell &amp; Tversky (2005).
used for measuring document similarity. LSA em- 3 The Current Study
ploys a vector-based model to capture the seman- In this paper, we examine entrainment among 419
tics of words by applying Singular Value of the 1000 user groups (the ones who wrote in
Decomposition on a term-document matrix English) and among the 15366 messages they
(Landauer, Foltz, &amp; Laham, 1998). LSA has been wrote over a six-week period (with participants
successfully applied to tasks such as measuring divided into 20 topic groups, with an average of
semantic similarity among corpora of texts 20.95 English writers per group). We ask whether
(Coccaro &amp; Jurafsky, 1998), measuring cohesion the young people’s language converges over time
(Foltz, Kintsch, &amp; Landauer, 1998 ), assessing cor- in an online community. Is similarity between the
rectness of answers in tutoring systems (Wiemer- texts that are produced by the young people greater
Hastings &amp; Graesser, 2000) and dialogue act clas- between adjacent weeks than between the less
sification (Serafin &amp; Di Eugenio, 2004). proximally-related weeks? Furthermore, what
To our knowledge, statistical measures like computational tools can effectively measure trends
SCC, Zipping compression algorithms, or LSA in similarity over time?
have never been used to measure similarity of mes- 3.1 Hypotheses
sages over time, nor have they been applied to In order to address these questions, we chose to
online communities. However, it is not obvious examine change in similarity scores along two di-
how we would verify their performance, and given mensions: (1) at the level of the individual; and (2)
the nature of the task – similarity in over 15,000 e- across the group as a whole. More specifically, we
mail messages – it is impossible to compare the examine similarity between all pairs of individuals
computational methods to hand-coding. As a pre- in a given topic group over time. We also com-
liminary approach, we therefore decided to apply pared similarity across the entire group at different
all three methods in turn to the messages in an time periods.
online community to examine change in linguistic As depicted below, we first look at pairwise
similarity over time, and to compare their results. comparisons between the messages of participants
Through the combination of lexical, phrasal and in a particular topic group within a given time pe-
semantic similarity metrics, we hope to gain in- riod, Tk (one week). For every pair of participants
sight into the questions of whether entrainment in a group, we calculated the similarity between
occurs in online communities, and of what compu- two documents, each comprising all messages for a
tational measures can be used to measure it. participant in the pair. Then we averaged the
2.3 The Junior Summit scores computed for all topic groups within a time
The Junior Summit launched in 1998 as a closed period Tk and produced PTk, the average, pairwise
online community for young people to discuss how similarity score for Tk. Our first hypothesis is that
to use technology to make the world better. 3000 the average, pairwise similarity will increase over
children ages 10 to 16 participated in 1000 teams time, such that:
(some as individuals and some with friends). Par- PT1 &lt; PT2 &lt; PT3 &lt; PT4 &lt; PT5 &lt; PT6
ticipants came from 139 different countries, and For our second set of tests, we compared all
could choose to write in any of 5 languages. After messages from a single time period to all messages
2 weeks online, the young people divided into 20 of a previous time period within a single topic
topic groups of their own choosing. Each of these group. Our hypothesis was that temporal proximity
topic groups functioned as a smaller community would correlate with mean similarity, such that the
within the community of the Junior Summit; after messages of two adjacent time periods would ex-
another 6 weeks, each topic group elected 5 dele- hibit more similarity than those of more distant
gates to come to the US for an in-person forum.
The dataset from the Junior Summit comprises
more than 40,000 e-mail messages; however, in the
current paper we look at only a sub-set of these
17
time periods. In order to examine this, we perform
two individual hypothesis tests, where Mk is the
document containing all the messages produced in
time period Tk, and S(X,Y) is the similarity score
for the two documents X and Y.
</bodyText>
<equation confidence="0.9929395">
a) S(Mk, Mk-1) &gt; S(Mk, Mk-2)
b) S(Mk, Mk-1) &gt; S(Mk, M1)
</equation>
<bodyText confidence="0.9992695">
Finally, we posit that SCC, Zipping and LSA
will yield similar results for these tests.
</bodyText>
<sectionHeader confidence="0.980892" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.999922666666667">
To prepare the data, we wrote a script to remove
the parts of messages that could interfere with
computing their similarity, in particular quoted
messages and binary attachments, which are com-
mon in a corpus of email-like messages. We also
removed punctuation and special characters.
</bodyText>
<subsectionHeader confidence="0.997329">
4.1 Spearman’s Correlation Coefficient
</subsectionHeader>
<bodyText confidence="0.999853615384615">
SCC is calculated as in Kilgarriff (2001). First, we
compile a list of the common words between the
two documents. The statistic can be calculated on
the n most common words, or on all common
words (i.e. n = total number of common words).
We applied the latter approach, using all the words
in common for each document pair. For each docu-
ment, the n common words are ranked by fre-
quency, with the lowest frequency word ranked 1
and the highest ranked n. For each common word,
d is the difference in rank orders for the word in
each document. SCC a normalized sum of the
squared differences:
</bodyText>
<equation confidence="0.764876">
n(n2 −1)
</equation>
<bodyText confidence="0.996939142857143">
The sum is taken over the n most frequent common
words. In the case of ties in rank, where more than
one word in a document occurs with the same fre-
quency, the average of the ranks is assigned to the
tying words. (For example, if words w1, w2 and w3
are ranked 5th, 6th and 7th then all three words
would be assigned the same rank of 5+3+7 = 6).
</bodyText>
<subsectionHeader confidence="0.980879">
4.2 Zipping
</subsectionHeader>
<bodyText confidence="0.999799933333333">
When compressing a document, the resulting com-
pression ratio provides an estimate of the docu-
ment&apos;s entropy. Many compression algorithms
generate a dictionary of sequences based on fre-
quency that is used to compress the document.
Likewise, one can leverage this technique to de-
termine the similarity between two documents by
assessing how optimal the dictionary generated
when compressing one document is when applied
to another document. We used GZIP for compres-
sion, which employs a combination of the LZ77
algorithm and Huffman coding. We based our ap-
proach on the algorithm used by (Benedetto,
Caglioti, &amp; Loreto, 2002), where the cross-entropy
per character is defined as:
</bodyText>
<equation confidence="0.986191">
length(zip(A + B)) − length(zip(A))
length(B)
</equation>
<bodyText confidence="0.999923103448276">
Here, A and B are documents; A + B is docu-
ment B appended to document A; zip(A) is the
zipped document; and length(A) is the length of the
document. It is important to note that the test
document (B) needs to be small enough that it
doesn&apos;t cause the dictionary to adapt to the ap-
pended piece. (Benedetto, Caglioti, &amp; Loreto,
2002) refer to this threshold as the crossover
length. The more similar the appended portion is,
the more it will compress, and vice versa. We ex-
tended the basic algorithm to handle the extremely
varied document sizes found in our data. Our algo-
rithm does two one-way comparisons and returns
the mean score. Each one-way comparison be-
tween two documents, A and B, is computed by
splitting B into 300 character chunks. Then for
each chunk, we calculated the cross entropy per
character when appending the chunk onto A. Each
one-way comparison returns the mean calculation
for every chunk.
We fine-tuned the window size with a small,
hand-built corpus of news articles. The differences
are slightly more pronounced with larger window
sizes, but that trend starts to taper off between
window sizes of 300 and 500 characters. In the
end we chose 300 as our window size, because it
provided sufficient contrast and yet still gave a few
samples from even the smallest documents in our
primary corpus.
</bodyText>
<subsectionHeader confidence="0.999602">
4.3 Latent Semantic Analysis (LSA)
</subsectionHeader>
<bodyText confidence="0.999768">
For a third approach, we used LSA to analyze the
semantic similarity between messages across dif-
ferent periods of time. We explored three imple-
</bodyText>
<equation confidence="0.9034685">
2
6∑ d
p = −
1
</equation>
<page confidence="0.975033">
18
</page>
<bodyText confidence="0.999041105263158">
mentations of LSA: (a) the traditional algorithm
described by Foltz et al (1998 ) with one semantic
space per topic group, (b) the same algorithm but
with one semantic space for all topic groups and
(c) an implementation based on Word Space
(Schutze, 1993) called Infomap. All three were
tested with several settings such as variations in the
number of dimensions and levels of control for
stop words, and all three demonstrated similar re-
sults. For this paper, we present the Infomap re-
sults due to its wide acceptance among scholars as
a successful implementation of LSA.
To account for nuances of the lexicon used in
the Junior Summit data, we built a semantic space
from a subset of this data comprised of 7000 small
messages (under one kb) and 100 dimensions with-
out removing stop words. We then built vectors for
each document and compared them using cosine
similarity (Landauer, Foltz, &amp; Laham, 1998).
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999957">
The tools we employ approach document similarity
quite differently; we therefore compare findings as
a way of triangulating on the nature of entrainment
in the Junior Summit online community.
</bodyText>
<subsectionHeader confidence="0.988911">
5.1 Pairwise Comparisons over Time
</subsectionHeader>
<bodyText confidence="0.996486217391304">
First, we hypothesized that messages between in-
dividuals in a given topic group would demonstrate
more similarity over time. Our findings did not
support this claim; in fact, they show the opposite.
All three tests show slight convergence between
time period one and two, some variation, and then
divergence between time periods four, five and six.
Spearman’s Correlation Coefficient demon-
strates a steady decline in similarity. As shown in
Figure 1, the differences between time periods
were all significant, F(5,1375) = 21.475, p&lt;.001,
where N=1381 (N represents user pairs across all
six time periods).
Zipping also shows a significant difference be-
tween each time period, F(5,1190) = 39.027, p&lt;.001,
N=1196, demonstrating a similar decline in simi-
larity, although not as unwavering. See Figure 2.
LSA demonstrates the same divergent trend over
time, F(5,1410) = 27.139, p&lt;.001, N=1416, with a
slight spike at T4 and T5. While the dip at time 3 is
more pronounced than SCC and Zipping, it is still
consistent with the overall findings of the other
measures. See Figure 3.
</bodyText>
<figure confidence="0.997386272727273">
0.575
0.565
0.555
0.545
0.535
0.525
0.515
0.505
0.495
T1 T2 T3 T4T5 T6
Time Period
</figure>
<figureCaption confidence="0.984499">
Figure 1. Spearman&apos;s Correlation Coefficient Simi-
larity Scores for all Pairwise comparisons, T1 – T6
</figureCaption>
<figure confidence="0.999772416666667">
0.58
0.575
0.57
0.565
0.56
0.555
0.55
0.545
0.54
0.535
T1 T2 T3 T4 T5 T6
Time Period
</figure>
<figureCaption confidence="0.9864815">
Figure 2. Zipping Similarity Scores for all Pairwise
comparisons, T1 – T6
</figureCaption>
<figure confidence="0.999545083333333">
0.91
0.9
0.89
0.88
0.87
0.86
0.85
0.84
0.83
0.82
T1 T2 T3 T4T5 T6
Time Period
</figure>
<figureCaption confidence="0.996594">
Figure 3. LSA Similarity Scores for all Pairwise
comparisons, T1 – T6.
</figureCaption>
<bodyText confidence="0.999939363636364">
Because of these surprising findings, we exam-
ined the influence of demographic variables, such
as leadership (those chosen as delegates from each
topic group to the in-person forum), gender, and
the particular topic groups the individuals were a
part of. We divided delegate pairs into (a) pairs
where both individuals are delegates; (b) pairs
where both individuals are non-delegates; and (c)
mixed pairs of delegates and non-delegates. Simi-
larly, gender pairs were divided into same-sex
(e.g., male-male, female-female) and mixed-sex
</bodyText>
<page confidence="0.998257">
19
</page>
<bodyText confidence="0.999945871794872">
pairs. For topic groups, we re-ran our analyses on
each of the 20 topic groups separately.
Overall, both leaders and gender pairs demon-
strate the same divergent trends as the group as a
whole. However, not all tests showed significant
differences when comparing these pairs.
For instance, Spearman’s Correlation Coeffi-
cient found a significant difference in similarity
between three groups, where F(2,273) = 6.804,
p&lt;.001, n=276, such that delegate-delegate pairs
demonstrate higher similarity scores than non-
delegate pairs and mixed pairs. LSA found the
same result, F(2,280) = 11.122, p&lt;.001 n=283. By
contrast, Zipping did not find this to be the case,
where F(2,226) = 2.568, p=.079, n=229.
In terms of the potential effect of gender on
similarity scores, Zipping showed a significant dif-
ference between the three groups, F(2,236) = 3.546,
p&lt;.05, n=239, such that female-female pairs and
mixed-sex pairs demonstrate more similarity than
male-male pairs. LSA found the same relationship,
F(2,280) = 4.79, p&lt;.005 n=283. By contrast, Spear-
man’s Correlation Coefficient does not show a sig-
nificant between-groups difference, F(2,273) = .699,
p=.498, n=276.
In terms of differences among the topic groups,
we did indeed find differences such that some topic
groups demonstrated the fairly linear slope with
decreasingly similarity shown above, while others
demonstrated dips and rises resulting in a level of
similarity at T6 quite similar to T1. There is no
neat way to statistically measure the differences in
these slopes, but it does indicate that future analy-
ses need to take topic group into account.
In sum, we did not find leadership or gender to
mediate language similarity in this community.
Topic group, on the other hand, did play a role,
however no topic groups showed increasing simi-
larity across time.
</bodyText>
<subsectionHeader confidence="0.999508">
5.2 Similarity and Temporal Proximity
</subsectionHeader>
<bodyText confidence="0.998926428571428">
Our second hypothesis concerned the gradual
change of language over time such that temporal
proximity of time periods would correlate with
mean similarity. In other words, we expect that
messages in close time periods (e.g., adjacent
weeks) should be more similar than messages from
more distant time periods. In order to examine
this, we performed two individual tests, in which
our predictions can be described as follows: (a) the
similarity between texts in one time period and
texts in the neighboring time period is greater than
texts in one time period, and texts that came two
periods previously, S(Mk, Mk-1) &gt; S(Mk, Mk-2); and
(b) the similarity between texts in one time period
and texts in the neighboring time period is greater
than the similarity between texts in one time pe-
riod, and texts in the very first time period, S(Mk,
Mk-1) &gt; S(Mk, M1).
As shown in Table 1, SCC and Zipping tests
confirm these hypotheses, while none of the LSA
tests revealed significant differences.
</bodyText>
<tableCaption confidence="0.992504">
Table 1. Temporal Proximity Similarities SCC,
Zipping, and LSA, n=20 topic groups
</tableCaption>
<table confidence="0.984856">
S(Mk,Mk-1) S(Mk,Mk-1) S(Mk,Mk-2)
&gt; S(Mk ,Mk-2) &gt; S(Mk ,M1) &gt; S(Mk ,M1)
SCC .665 &gt; .653† .665 &gt; .639° .653 &gt; .639°
ZIP .628 &gt; .608† .628 &gt; .605† .608 &gt; .605§
LSA 9.74 &gt; .971 9.74 &gt; .971 .97166 &lt; .97168
Note: *p&lt;.05, °p&lt;.01, †p&lt;.001, §p = .0525, one-tailed
</table>
<sectionHeader confidence="0.997674" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999945357142857">
This work presents several novel contributions
to the analysis of text-based messages in online
communities. Using three separate tools, Spear-
man’s Correlation Coefficient, Zipping and Latent
Semantic Analysis measures, we found that across
time, members of an online community diverge in
the language they use. More specifically, a com-
parison of the words contributed by any pair of
users in a particular topic group shows increasing
dissimilarity over the six-week period.
This finding seems counter-intuitive given work
in linguistics and psychology, which shows that
dyads and communities converge, entrain and echo
each other’s lexical choices and communication
styles. Similarly, our own temporal proximity re-
sults appear to indicate convergence, since closer
time periods are more similar than more distant
ones. Finally, previous hand-coding of these data
revealed convergence, for example between boys
and girls on the use of emotion words, between
older and younger children on talk about the future
(Cassell &amp; Tversky, 2005). So we ask, why do our
tools demonstrate this divergent trend?
We believe that one answer comes from the fact
that, while the young people may be discussing a
more restricted range of topics, they are contribut-
ing a wider variety of vocabulary. In order to ex-
amine whether indeed there were more unique
</bodyText>
<page confidence="0.98666">
20
</page>
<bodyText confidence="0.9996995">
words over time, we first simply manually com-
pared the frequency of words over time and found
that, on the contrary, there are consistently fewer
unique words by T6, which suggests convergence.
However, there are also fewer and fewer total
words by the end of the forum. This is due to the
number of participants who left the forum after
they were not elected to go to Boston. If we divide
the unique words by the total words, we find that
the ratio of unique words consistently increases
over time (see Figure 4). It is likely that this ratio
contributes to our results of divergence.
</bodyText>
<figure confidence="0.997526">
0.075
0.07
0.065
0.06
0.055
0.05
0.045
0.04
0.035
0.03
1 2 3 4 5 6
Time Period
</figure>
<figureCaption confidence="0.999847">
Figure 4. Ratio of Unique to Total Words, T1 – T6
</figureCaption>
<bodyText confidence="0.999958840909091">
In order to further examine the role of increasing
vocabulary in the Junior Summit as a whole, we
also created several control groups comprised of
random pairs of users (i.e., users that had never
written to each other), and measured their pairwise
similarity across time. The results were similar to
the experimental groups, demonstrating a slope
with roughly the same shape. This argues for con-
vergence and divergence being affected by some-
thing at a broader, community-level such as an
increase in vocabulary.
This result is interesting for an additional rea-
son. Some users – perhaps particularly non-native
speakers or younger adolescents, may be learning
new vocabulary from other speakers, which they
begin to introduce at later time periods. An in-
creasingly diversified vocabulary could conceiva-
bly result in differences in word frequency among
speakers. This leads us to some key questions: to
what extent does the language of individuals
change over time? Is individual language influ-
enced by the language of the community? This is
heart of entrainment.
In conclusion, we have shown that SCC, Zip-
ping and LSA can be used to assess message simi-
larity over time, although they may be somewhat
blunt instruments for our purposes. In addition,
while Zipping is somewhat contentious and not as
widely-accepted as SCC or LSA is, we found that
the three tools provide very similar results. This is
particularly interesting given that, while all three
methods take into account word or word-sequence
frequencies, LSA is designed to also take into ac-
count aspects of semantics beyond the surface
level of lexical form.
All in all, these tools not only contribute to ways
of measuring similarity across documents, but can
be utilized in measuring smaller texts, such as
online messages or emails. Most importantly,
these tools remind us how complex and dynamic
everyday language really is, and how much this
complexity must be taken into account when build-
ing computational tools for the analysis of text and
conversation.
</bodyText>
<subsectionHeader confidence="0.977302">
6.1 Future Directions
</subsectionHeader>
<bodyText confidence="0.9999931">
In future work, we intend to find ways to compare
the results obtained from different topic groups and
also to examine differences among individual us-
ers, including re-running our analyses after remov-
ing outliers. We also hope to explore the interplay
between individuals and the community and
changes in language similarity. In other words,
can we find those individuals who may be acquir-
ing new vocabulary? Are there “language leaders”
responsible for language change online?
We also plan to analyze words in terms of their
local contexts, to see if this changes over time and
how it impacts our results. Furthermore, we intend
to go beyond word frequency to classify topic
changes over time to get a better understanding of
the dynamics of the groups (Kaufmann, 1999).
Finally, as we have done in the past with our
analyses of this dataset, we would like to perform a
percentage of hand-coded, human content analysis
to check reliability of these statistical methods.
</bodyText>
<sectionHeader confidence="0.994955" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9988854">
Thanks to members of the Articulab, Stefan Kauf-
mann, Stefan Wuchty, Will Thompson, Debbie
Zutty and Lauren Olson for invaluable input. This
research was in part supported by a generous grant
from the Kellogg Foundation.
</bodyText>
<sectionHeader confidence="0.997311" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.902463666666667">
Auer, P., &amp; Hinskens, F. (2005). The role of interper-
sonal accommodation in a theory of language
change. In P. Auer, F. Hinskens &amp; P. Kerswill
</reference>
<page confidence="0.994063">
21
</page>
<reference confidence="0.9989804">
(Eds.), Dialect change: The convergence and
divergence of dialects in European languages
(pp. 335-357). Cambridge, MA: Cambridge
University Press.
Baronchelli, A., Caglioti, E., &amp; Loreto, V. (2005). Arti-
ficial sequences and complexity measures.
Journal of Statistical Mechanics: Theory and
Experiment, P04002, 1-26.
Baym, N. K. (2000). Tune in, log on: Soaps, fandom,
and online community. New York: Sage Publi-
cations.
Benedetto, D., Caglioti, E., &amp; Loreto, V. (2002). Lan-
guage trees and zipping. Physical Review Let-
ters, 88(4), 1-4.
Brennan, S. E., &amp; Clark, H. H. (1996). Conceptual pacts
and lexical choice in conversation. Journal of
Experimental Psychology: Learning, Memory,
and Cognition, 22(6), 1482-1493.
Cassell, J., &amp; Tversky, D. (2005). The language of
online intercultural community formation.
Journal of Computer-Mediated Communica-
tion, 10(2), Article 2.
Chambers, J. K. (2001). Dynamics of dialect conver-
gence. Journal of Sociolinguistics, 6(1), 117-
130.
Cherny, L. (1999). Conversation and Community: Chat
in a Virtual World. Stanford: Center for the
Study of Language and Information.
Coccaro, N., &amp; Jurafsky, D. (1998, November 1998).
Towards better integration of semantic predic-
tors in statistical language modeling. Paper
presented at the International Conference on
Spoken Language Processing (ICSLP-98),
Sidney, Australia.
Crystal, D. (2001). Language and the Internet. New
York: Cambridge University Press.
Eckert, P. (2003). Language and adolescent peer groups.
Journal of Language and Social Psychology,
22(1), 112-118.
Foltz, P. W., Kintsch, W., &amp; Landauer, T. K. (1998 ).
The measurement of textual Coherence with
Latent Semantic Analysis. Discourse Proc-
esses, 25, 285-307.
Garrod, S., &amp; Anderson, A. (1987). Saying what you
mean in dialogue: A study in conceptual and
semantic coordination. Cognition, 27, 181-218.
Garrod, S., &amp; Pickering, M. J. (2004). Why is conversa-
tion so easy? Trends in Cognitive Sciences,
8(1), 8-11.
Kalthchenko, A. (2004, May 2-5, 2004). Algorithms for
estimation of information distance with appli-
cation to bioinformatics and linguistics. Paper
presented at the Canadian Conference on Elec-
trical and Computer Engineering (CCECE
2004), Niagara Falls, Ontario, Canada.
Kaufmann, S. (1999). Cohesion and collocation: Using
context vectors in text segmentation. Paper pre-
sented at the 37th Annual Meeting of the Asso-
ciation for Computational Linguistics, College
Park, MD.
Kilgarriff, A. (2001). Comparing corpora. International
Journal of Corpus Linguistics, 6(1), 97-133.
Labov, W. (2001). Principles of linguistic change (Vol.
2: Social Factors). Oxford: Blackwell Publish-
ers.
Lakin, J. L., Jefferies, V. E., Cheng, C. M., &amp; Char-
trand, T. L. (2003). The chameleon effect as
social glue: Evidence for the evolutionary sig-
nificance of nonconscious mimicry. Journal of
Nonverbal Behavior, 27(3), 145-162.
Lam, W. S. E. (2004). Second language socialization in
a bilingual chat room: Global and local consid-
erations. Language Learning &amp; Technology,
8(3), 44-65.
Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). In-
troduction to latent semantic analysis. Dis-
course Processes, 25, 259-284.
Milroy, L. (1980). Language and social networks. Ox-
ford: Blackwell Publishers.
Niederhoffer, K. G., &amp; Pennebaker, J. W. (2002). Lin-
guistic style matching in social interaction.
Journal of Language and Social Psychology,
21(4), 337-360.
Paolillo, J. (2001). Language variation on internet relay
chat: A social network approach. Journal of
Sociolinguistics, 5(2), 180-213.
Schutze, H. (1993). Word space. In S. J. Hanson, J. D.
Cowan &amp; C. L. Giles (Eds.), Advances in Neu-
ral Information Processing Systems 5. San
Mateo, CA: Morgan Kaufmann Publishers.
Serafin, R., &amp; Di Eugenio, B. (2004, July 21-26, 2004).
FLSA: Extending latent semantic analysis with
features for dialogue act classification. Paper
presented at the 42nd Annual Meeting for the
Association of Computational Linguistics
(ACL04), Barcelona, Spain.
Street, R. L., &amp; Giles, H. (1982). Speech accommoda-
tion theory. In M. E. Roloff &amp; C. R. Berger
(Eds.), Social cognition and communication
(pp. 193-226). London: Sage Publications.
Wiemer-Hastings, P., &amp; Graesser, A. C. (2000). Select-
a-Kibitzer: A computer tool that gives mean-
ingful feedback on student compositions.
Interactive Learning Environments, 8(2), 149–
169.
</reference>
<page confidence="0.99902">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.605593">
<title confidence="0.997313">Computational Measures for Language Similarity across in Online Communities</title>
<author confidence="0.99952">David Huffaker Joseph Jorgensen Francisco Iacobelli Paul Tepper Justine Cassell</author>
<affiliation confidence="0.999962">Northwestern University</affiliation>
<email confidence="0.99848">d-huffaker@northwestern.edu</email>
<email confidence="0.99848">josephj@northwestern.edu</email>
<email confidence="0.99848">f-iacobelli@northwestern.edu</email>
<email confidence="0.99848">ptepper@northwestern.edu</email>
<email confidence="0.99848">justine@northwestern.edu</email>
<abstract confidence="0.966556416666667">This paper examines language similarity in messages over time in an online community of adolescents from around the world using three computational measures: Spearman’s Correlation Coefficient, Zipping and Latent Semantic Analysis. Results suggest that the participants’ lana six-week period, and that divergence is not mediated by demographic variables such as leadership status or gender. This divergence may</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Auer</author>
<author>F Hinskens</author>
</authors>
<title>The role of interpersonal accommodation in a theory of language change. In</title>
<date>2005</date>
<booktitle>in European languages</booktitle>
<pages>335--357</pages>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="5314" citStr="Auer &amp; Hinskens, 2005" startWordPosition="806" endWordPosition="809">age patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnog</context>
</contexts>
<marker>Auer, Hinskens, 2005</marker>
<rawString>Auer, P., &amp; Hinskens, F. (2005). The role of interpersonal accommodation in a theory of language change. In P. Auer, F. Hinskens &amp; P. Kerswill (Eds.), Dialect change: The convergence and divergence of dialects in European languages (pp. 335-357). Cambridge, MA: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Baronchelli</author>
<author>E Caglioti</author>
<author>V Loreto</author>
</authors>
<title>Artificial sequences and complexity measures.</title>
<date>2005</date>
<journal>Journal of Statistical Mechanics: Theory and Experiment,</journal>
<volume>04002</volume>
<pages>1--26</pages>
<contexts>
<context position="7556" citStr="Baronchelli, Caglioti, &amp; Loreto, 2005" startWordPosition="1137" endWordPosition="1141">ques. Spearman’s Rank Correlation Coefficient (SCC) is particularly useful because it is easy to compute and not dependent on text size. Unlike some other statistical approaches (e.g. chi-square), SCC has been shown effective on determining similarity between corpora of varying sizes, therefore SCC will serve as a baseline for comparison in this paper (Kilgarriff, 2001). More recently, researchers have experimented with data compression algorithms as a measure of document complexity and similarity. This technique uses compression ratios as an approximation of a document’s information entropy (Baronchelli, Caglioti, &amp; Loreto, 2005; Benedetto, Caglioti, &amp; Loreto, 2002). Standard Zipping algorithms have demonstrated effectiveness in a variety of document comparison and classification tasks. Behr et al. (2003) found that a document and its translation into another language compressed to approximately the same size. They suggest that this could be used as an automatic measure for testing machine translation quality. Kaltchenko (2004) argues that using compression algorithms to compute relative entropy is more relevant than using distances based on Kolmogorov complexity. Lastly, Bendetto et al. (2002) present some basic fin</context>
</contexts>
<marker>Baronchelli, Caglioti, Loreto, 2005</marker>
<rawString>Baronchelli, A., Caglioti, E., &amp; Loreto, V. (2005). Artificial sequences and complexity measures. Journal of Statistical Mechanics: Theory and Experiment, P04002, 1-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N K Baym</author>
</authors>
<title>Tune in, log on: Soaps, fandom, and online community.</title>
<date>2000</date>
<publisher>Sage Publications.</publisher>
<location>New York:</location>
<contexts>
<context position="6053" citStr="Baym, 2000" startWordPosition="918" endWordPosition="919">nstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguistic patterns online, and subsequent adoption by users, but suggests that the strength of the social ties between participants influences how patterns are spread and adopted (Paolillo, 2001). However, little research has been devoted to how language changes over longer periods of time in these online communities. 2.2 Computational Measures of Language Similarity The unit of analysis in online communities is the (e-mail or chat) message. Therefore, measuring entrainment in online communities relies on assessing whether </context>
</contexts>
<marker>Baym, 2000</marker>
<rawString>Baym, N. K. (2000). Tune in, log on: Soaps, fandom, and online community. New York: Sage Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Benedetto</author>
<author>E Caglioti</author>
<author>V Loreto</author>
</authors>
<title>Language trees and zipping.</title>
<date>2002</date>
<journal>Physical Review Letters,</journal>
<volume>88</volume>
<issue>4</issue>
<pages>1--4</pages>
<contexts>
<context position="7593" citStr="Benedetto, Caglioti, &amp; Loreto, 2002" startWordPosition="1142" endWordPosition="1146">icient (SCC) is particularly useful because it is easy to compute and not dependent on text size. Unlike some other statistical approaches (e.g. chi-square), SCC has been shown effective on determining similarity between corpora of varying sizes, therefore SCC will serve as a baseline for comparison in this paper (Kilgarriff, 2001). More recently, researchers have experimented with data compression algorithms as a measure of document complexity and similarity. This technique uses compression ratios as an approximation of a document’s information entropy (Baronchelli, Caglioti, &amp; Loreto, 2005; Benedetto, Caglioti, &amp; Loreto, 2002). Standard Zipping algorithms have demonstrated effectiveness in a variety of document comparison and classification tasks. Behr et al. (2003) found that a document and its translation into another language compressed to approximately the same size. They suggest that this could be used as an automatic measure for testing machine translation quality. Kaltchenko (2004) argues that using compression algorithms to compute relative entropy is more relevant than using distances based on Kolmogorov complexity. Lastly, Bendetto et al. (2002) present some basic findings using GZIP for authorship attri</context>
<context position="15107" citStr="Benedetto, Caglioti, &amp; Loreto, 2002" startWordPosition="2396" endWordPosition="2400"> 4.2 Zipping When compressing a document, the resulting compression ratio provides an estimate of the document&apos;s entropy. Many compression algorithms generate a dictionary of sequences based on frequency that is used to compress the document. Likewise, one can leverage this technique to determine the similarity between two documents by assessing how optimal the dictionary generated when compressing one document is when applied to another document. We used GZIP for compression, which employs a combination of the LZ77 algorithm and Huffman coding. We based our approach on the algorithm used by (Benedetto, Caglioti, &amp; Loreto, 2002), where the cross-entropy per character is defined as: length(zip(A + B)) − length(zip(A)) length(B) Here, A and B are documents; A + B is document B appended to document A; zip(A) is the zipped document; and length(A) is the length of the document. It is important to note that the test document (B) needs to be small enough that it doesn&apos;t cause the dictionary to adapt to the appended piece. (Benedetto, Caglioti, &amp; Loreto, 2002) refer to this threshold as the crossover length. The more similar the appended portion is, the more it will compress, and vice versa. We extended the basic algorithm </context>
</contexts>
<marker>Benedetto, Caglioti, Loreto, 2002</marker>
<rawString>Benedetto, D., Caglioti, E., &amp; Loreto, V. (2002). Language trees and zipping. Physical Review Letters, 88(4), 1-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>H H Clark</author>
</authors>
<title>Conceptual pacts and lexical choice in conversation.</title>
<date>1996</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<volume>22</volume>
<issue>6</issue>
<pages>1482--1493</pages>
<contexts>
<context position="3787" citStr="Brennan &amp; Clark, 1996" startWordPosition="575" endWordPosition="578">, Zipping, and Latent Semantic Analysis (LSA). 2.1 Language Similarity in Computermediated Communication In dyadic settings, speakers often converge to one another’s speech styles, not only matching the choice of referring expressions or other words, but also structural dimensions such as syntax, sound characteristics such as accent, prosody, or phonolProceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 15–22, New York City, New York, June 2006. c�2006 Association for Computational Linguistics ogy, or even non-verbal behaviors such as gesture (Brennan &amp; Clark, 1996; Street &amp; Giles, 1982). Some scholars suggest that this convergence or entrainment is based on a conscious need to accommodate to one’s conversational partner, or as a strategy to maximize communication effectiveness (Street &amp; Giles, 1982). Others suggest that the alignment is an automatic response, in which echoic aspects of speech, gesture and facial expressions are unconscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological c</context>
</contexts>
<marker>Brennan, Clark, 1996</marker>
<rawString>Brennan, S. E., &amp; Clark, H. H. (1996). Conceptual pacts and lexical choice in conversation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22(6), 1482-1493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>D Tversky</author>
</authors>
<title>The language of online intercultural community formation.</title>
<date>2005</date>
<journal>Journal of Computer-Mediated Communication,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="8646" citStr="Cassell &amp; Tversky (2005)" startWordPosition="1304" endWordPosition="1307">ve entropy is more relevant than using distances based on Kolmogorov complexity. Lastly, Bendetto et al. (2002) present some basic findings using GZIP for authorship attribution, determining the language of a document, and building a tree of language families from a text written in different languages. Although Zipping may be a conten16 tious technique, these results present intriguing data – messages written in English during the 6- reasons to continue exploration of its applications. week topic group period. For complete details, Latent Semantic Analysis is another technique please refer to Cassell &amp; Tversky (2005). used for measuring document similarity. LSA em- 3 The Current Study ploys a vector-based model to capture the seman- In this paper, we examine entrainment among 419 tics of words by applying Singular Value of the 1000 user groups (the ones who wrote in Decomposition on a term-document matrix English) and among the 15366 messages they (Landauer, Foltz, &amp; Laham, 1998). LSA has been wrote over a six-week period (with participants successfully applied to tasks such as measuring divided into 20 topic groups, with an average of semantic similarity among corpora of texts 20.95 English writers per g</context>
<context position="24207" citStr="Cassell &amp; Tversky, 2005" startWordPosition="3888" endWordPosition="3891"> group shows increasing dissimilarity over the six-week period. This finding seems counter-intuitive given work in linguistics and psychology, which shows that dyads and communities converge, entrain and echo each other’s lexical choices and communication styles. Similarly, our own temporal proximity results appear to indicate convergence, since closer time periods are more similar than more distant ones. Finally, previous hand-coding of these data revealed convergence, for example between boys and girls on the use of emotion words, between older and younger children on talk about the future (Cassell &amp; Tversky, 2005). So we ask, why do our tools demonstrate this divergent trend? We believe that one answer comes from the fact that, while the young people may be discussing a more restricted range of topics, they are contributing a wider variety of vocabulary. In order to examine whether indeed there were more unique 20 words over time, we first simply manually compared the frequency of words over time and found that, on the contrary, there are consistently fewer unique words by T6, which suggests convergence. However, there are also fewer and fewer total words by the end of the forum. This is due to the num</context>
</contexts>
<marker>Cassell, Tversky, 2005</marker>
<rawString>Cassell, J., &amp; Tversky, D. (2005). The language of online intercultural community formation. Journal of Computer-Mediated Communication, 10(2), Article 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K Chambers</author>
</authors>
<title>Dynamics of dialect convergence.</title>
<date>2001</date>
<journal>Journal of Sociolinguistics,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>117--130</pages>
<contexts>
<context position="5185" citStr="Chambers, 2001" startWordPosition="788" endWordPosition="789"> language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both</context>
</contexts>
<marker>Chambers, 2001</marker>
<rawString>Chambers, J. K. (2001). Dynamics of dialect convergence. Journal of Sociolinguistics, 6(1), 117-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Cherny</author>
</authors>
<title>Conversation and Community: Chat in a Virtual World. Stanford: Center for the Study of Language and Information.</title>
<date>1999</date>
<contexts>
<context position="6068" citStr="Cherny, 1999" startWordPosition="920" endWordPosition="921"> individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguistic patterns online, and subsequent adoption by users, but suggests that the strength of the social ties between participants influences how patterns are spread and adopted (Paolillo, 2001). However, little research has been devoted to how language changes over longer periods of time in these online communities. 2.2 Computational Measures of Language Similarity The unit of analysis in online communities is the (e-mail or chat) message. Therefore, measuring entrainment in online communities relies on assessing whether or not similari</context>
</contexts>
<marker>Cherny, 1999</marker>
<rawString>Cherny, L. (1999). Conversation and Community: Chat in a Virtual World. Stanford: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Coccaro</author>
<author>D Jurafsky</author>
</authors>
<title>Towards better integration of semantic predictors in statistical language modeling.</title>
<date>1998</date>
<booktitle>Paper presented at the International Conference on Spoken Language Processing (ICSLP-98),</booktitle>
<location>Sidney, Australia.</location>
<contexts>
<context position="9294" citStr="Coccaro &amp; Jurafsky, 1998" startWordPosition="1409" endWordPosition="1412">cument similarity. LSA em- 3 The Current Study ploys a vector-based model to capture the seman- In this paper, we examine entrainment among 419 tics of words by applying Singular Value of the 1000 user groups (the ones who wrote in Decomposition on a term-document matrix English) and among the 15366 messages they (Landauer, Foltz, &amp; Laham, 1998). LSA has been wrote over a six-week period (with participants successfully applied to tasks such as measuring divided into 20 topic groups, with an average of semantic similarity among corpora of texts 20.95 English writers per group). We ask whether (Coccaro &amp; Jurafsky, 1998), measuring cohesion the young people’s language converges over time (Foltz, Kintsch, &amp; Landauer, 1998 ), assessing cor- in an online community. Is similarity between the rectness of answers in tutoring systems (Wiemer- texts that are produced by the young people greater Hastings &amp; Graesser, 2000) and dialogue act clas- between adjacent weeks than between the less sification (Serafin &amp; Di Eugenio, 2004). proximally-related weeks? Furthermore, what To our knowledge, statistical measures like computational tools can effectively measure trends SCC, Zipping compression algorithms, or LSA in simila</context>
</contexts>
<marker>Coccaro, Jurafsky, 1998</marker>
<rawString>Coccaro, N., &amp; Jurafsky, D. (1998, November 1998). Towards better integration of semantic predictors in statistical language modeling. Paper presented at the International Conference on Spoken Language Processing (ICSLP-98), Sidney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Crystal</author>
</authors>
<title>Language and the Internet.</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<location>New York:</location>
<contexts>
<context position="5531" citStr="Crystal, 2001" startWordPosition="840" endWordPosition="841">eech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguist</context>
</contexts>
<marker>Crystal, 2001</marker>
<rawString>Crystal, D. (2001). Language and the Internet. New York: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Eckert</author>
</authors>
<title>Language and adolescent peer groups.</title>
<date>2003</date>
<journal>Journal of Language and Social Psychology,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>112--118</pages>
<contexts>
<context position="4878" citStr="Eckert, 2003" startWordPosition="739" endWordPosition="740">versational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their partners (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickl</context>
</contexts>
<marker>Eckert, 2003</marker>
<rawString>Eckert, P. (2003). Language and adolescent peer groups. Journal of Language and Social Psychology, 22(1), 112-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Foltz</author>
<author>W Kintsch</author>
<author>T K Landauer</author>
</authors>
<title>The measurement of textual Coherence with Latent Semantic Analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>285--307</pages>
<contexts>
<context position="9396" citStr="Foltz, Kintsch, &amp; Landauer, 1998" startWordPosition="1422" endWordPosition="1426"> In this paper, we examine entrainment among 419 tics of words by applying Singular Value of the 1000 user groups (the ones who wrote in Decomposition on a term-document matrix English) and among the 15366 messages they (Landauer, Foltz, &amp; Laham, 1998). LSA has been wrote over a six-week period (with participants successfully applied to tasks such as measuring divided into 20 topic groups, with an average of semantic similarity among corpora of texts 20.95 English writers per group). We ask whether (Coccaro &amp; Jurafsky, 1998), measuring cohesion the young people’s language converges over time (Foltz, Kintsch, &amp; Landauer, 1998 ), assessing cor- in an online community. Is similarity between the rectness of answers in tutoring systems (Wiemer- texts that are produced by the young people greater Hastings &amp; Graesser, 2000) and dialogue act clas- between adjacent weeks than between the less sification (Serafin &amp; Di Eugenio, 2004). proximally-related weeks? Furthermore, what To our knowledge, statistical measures like computational tools can effectively measure trends SCC, Zipping compression algorithms, or LSA in similarity over time? have never been used to measure similarity of mes- 3.1 Hypotheses sages over time, nor</context>
<context position="16805" citStr="Foltz et al (1998" startWordPosition="2691" endWordPosition="2694">news articles. The differences are slightly more pronounced with larger window sizes, but that trend starts to taper off between window sizes of 300 and 500 characters. In the end we chose 300 as our window size, because it provided sufficient contrast and yet still gave a few samples from even the smallest documents in our primary corpus. 4.3 Latent Semantic Analysis (LSA) For a third approach, we used LSA to analyze the semantic similarity between messages across different periods of time. We explored three imple2 6∑ d p = − 1 18 mentations of LSA: (a) the traditional algorithm described by Foltz et al (1998 ) with one semantic space per topic group, (b) the same algorithm but with one semantic space for all topic groups and (c) an implementation based on Word Space (Schutze, 1993) called Infomap. All three were tested with several settings such as variations in the number of dimensions and levels of control for stop words, and all three demonstrated similar results. For this paper, we present the Infomap results due to its wide acceptance among scholars as a successful implementation of LSA. To account for nuances of the lexicon used in the Junior Summit data, we built a semantic space from a su</context>
</contexts>
<marker>Foltz, Kintsch, Landauer, 1998</marker>
<rawString>Foltz, P. W., Kintsch, W., &amp; Landauer, T. K. (1998 ). The measurement of textual Coherence with Latent Semantic Analysis. Discourse Processes, 25, 285-307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>A Anderson</author>
</authors>
<title>Saying what you mean in dialogue: A study in conceptual and semantic coordination.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>27</volume>
<pages>181--218</pages>
<contexts>
<context position="4205" citStr="Garrod &amp; Anderson, 1987" startWordPosition="639" endWordPosition="643">(ACTS) Workshop at HLT-NAACL 2006, pages 15–22, New York City, New York, June 2006. c�2006 Association for Computational Linguistics ogy, or even non-verbal behaviors such as gesture (Brennan &amp; Clark, 1996; Street &amp; Giles, 1982). Some scholars suggest that this convergence or entrainment is based on a conscious need to accommodate to one’s conversational partner, or as a strategy to maximize communication effectiveness (Street &amp; Giles, 1982). Others suggest that the alignment is an automatic response, in which echoic aspects of speech, gesture and facial expressions are unconscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their partners (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an im</context>
</contexts>
<marker>Garrod, Anderson, 1987</marker>
<rawString>Garrod, S., &amp; Anderson, A. (1987). Saying what you mean in dialogue: A study in conceptual and semantic coordination. Cognition, 27, 181-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>M J Pickering</author>
</authors>
<title>Why is conversation so easy?</title>
<date>2004</date>
<journal>Trends in Cognitive Sciences,</journal>
<volume>8</volume>
<issue>1</issue>
<pages>8--11</pages>
<contexts>
<context position="4469" citStr="Garrod &amp; Pickering, 2004" startWordPosition="679" endWordPosition="682">convergence or entrainment is based on a conscious need to accommodate to one’s conversational partner, or as a strategy to maximize communication effectiveness (Street &amp; Giles, 1982). Others suggest that the alignment is an automatic response, in which echoic aspects of speech, gesture and facial expressions are unconscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their partners (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among</context>
</contexts>
<marker>Garrod, Pickering, 2004</marker>
<rawString>Garrod, S., &amp; Pickering, M. J. (2004). Why is conversation so easy? Trends in Cognitive Sciences, 8(1), 8-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kalthchenko</author>
</authors>
<title>Algorithms for estimation of information distance with application to bioinformatics and linguistics.</title>
<date>2004</date>
<booktitle>Paper presented at the Canadian Conference on Electrical and Computer Engineering (CCECE 2004),</booktitle>
<location>Niagara Falls, Ontario, Canada.</location>
<marker>Kalthchenko, 2004</marker>
<rawString>Kalthchenko, A. (2004, May 2-5, 2004). Algorithms for estimation of information distance with application to bioinformatics and linguistics. Paper presented at the Canadian Conference on Electrical and Computer Engineering (CCECE 2004), Niagara Falls, Ontario, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kaufmann</author>
</authors>
<title>Cohesion and collocation: Using context vectors in text segmentation.</title>
<date>1999</date>
<booktitle>Paper presented at the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>College Park, MD.</location>
<marker>Kaufmann, 1999</marker>
<rawString>Kaufmann, S. (1999). Cohesion and collocation: Using context vectors in text segmentation. Paper presented at the 37th Annual Meeting of the Association for Computational Linguistics, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Comparing corpora.</title>
<date>2001</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>97--133</pages>
<contexts>
<context position="6888" citStr="Kilgarriff, 2001" startWordPosition="1043" endWordPosition="1044">patterns are spread and adopted (Paolillo, 2001). However, little research has been devoted to how language changes over longer periods of time in these online communities. 2.2 Computational Measures of Language Similarity The unit of analysis in online communities is the (e-mail or chat) message. Therefore, measuring entrainment in online communities relies on assessing whether or not similarity between the messages of each participant increases over time. Most techniques for measuring document similarity rely on the analysis of word frequencies and their cooccurrence in two or more corpora (Kilgarriff, 2001), so we start with these techniques. Spearman’s Rank Correlation Coefficient (SCC) is particularly useful because it is easy to compute and not dependent on text size. Unlike some other statistical approaches (e.g. chi-square), SCC has been shown effective on determining similarity between corpora of varying sizes, therefore SCC will serve as a baseline for comparison in this paper (Kilgarriff, 2001). More recently, researchers have experimented with data compression algorithms as a measure of document complexity and similarity. This technique uses compression ratios as an approximation of a d</context>
<context position="13568" citStr="Kilgarriff (2001)" startWordPosition="2123" endWordPosition="2124">sages produced in time period Tk, and S(X,Y) is the similarity score for the two documents X and Y. a) S(Mk, Mk-1) &gt; S(Mk, Mk-2) b) S(Mk, Mk-1) &gt; S(Mk, M1) Finally, we posit that SCC, Zipping and LSA will yield similar results for these tests. 4 Method To prepare the data, we wrote a script to remove the parts of messages that could interfere with computing their similarity, in particular quoted messages and binary attachments, which are common in a corpus of email-like messages. We also removed punctuation and special characters. 4.1 Spearman’s Correlation Coefficient SCC is calculated as in Kilgarriff (2001). First, we compile a list of the common words between the two documents. The statistic can be calculated on the n most common words, or on all common words (i.e. n = total number of common words). We applied the latter approach, using all the words in common for each document pair. For each document, the n common words are ranked by frequency, with the lowest frequency word ranked 1 and the highest ranked n. For each common word, d is the difference in rank orders for the word in each document. SCC a normalized sum of the squared differences: n(n2 −1) The sum is taken over the n most frequent</context>
</contexts>
<marker>Kilgarriff, 2001</marker>
<rawString>Kilgarriff, A. (2001). Comparing corpora. International Journal of Corpus Linguistics, 6(1), 97-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Labov</author>
</authors>
<title>Principles of linguistic change (Vol. 2: Social Factors).</title>
<date>2001</date>
<publisher>Blackwell Publishers.</publisher>
<location>Oxford:</location>
<contexts>
<context position="4773" citStr="Labov, 2001" startWordPosition="722" endWordPosition="723">conscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their partners (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Inter</context>
</contexts>
<marker>Labov, 2001</marker>
<rawString>Labov, W. (2001). Principles of linguistic change (Vol. 2: Social Factors). Oxford: Blackwell Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Lakin</author>
<author>V E Jefferies</author>
<author>C M Cheng</author>
<author>T L Chartrand</author>
</authors>
<title>The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry.</title>
<date>2003</date>
<journal>Journal of Nonverbal Behavior,</journal>
<volume>27</volume>
<issue>3</issue>
<pages>145--162</pages>
<contexts>
<context position="4249" citStr="Lakin, Jefferies, Cheng, &amp; Chartrand, 2003" startWordPosition="644" endWordPosition="649">ACL 2006, pages 15–22, New York City, New York, June 2006. c�2006 Association for Computational Linguistics ogy, or even non-verbal behaviors such as gesture (Brennan &amp; Clark, 1996; Street &amp; Giles, 1982). Some scholars suggest that this convergence or entrainment is based on a conscious need to accommodate to one’s conversational partner, or as a strategy to maximize communication effectiveness (Street &amp; Giles, 1982). Others suggest that the alignment is an automatic response, in which echoic aspects of speech, gesture and facial expressions are unconscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their partners (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or comm</context>
</contexts>
<marker>Lakin, Jefferies, Cheng, Chartrand, 2003</marker>
<rawString>Lakin, J. L., Jefferies, V. E., Cheng, C. M., &amp; Chartrand, T. L. (2003). The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry. Journal of Nonverbal Behavior, 27(3), 145-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W S E Lam</author>
</authors>
<title>Second language socialization in a bilingual chat room: Global and local considerations.</title>
<date>2004</date>
<journal>Language Learning &amp; Technology,</journal>
<volume>8</volume>
<issue>3</issue>
<pages>44--65</pages>
<contexts>
<context position="5857" citStr="Lam, 2004" startWordPosition="888" endWordPosition="889">up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguistic patterns online, and subsequent adoption by users, but suggests that the strength of the social ties between participants influences how patterns are spread and adopted (Paolillo, 2001). However, little research has been devoted to how language changes over longer periods of time in these online communities. 2.2 Computati</context>
</contexts>
<marker>Lam, 2004</marker>
<rawString>Lam, W. S. E. (2004). Second language socialization in a bilingual chat room: Global and local considerations. Language Learning &amp; Technology, 8(3), 44-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>P W Foltz</author>
<author>D Laham</author>
</authors>
<title>Introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<contexts>
<context position="9015" citStr="Landauer, Foltz, &amp; Laham, 1998" startWordPosition="1364" endWordPosition="1368">esults present intriguing data – messages written in English during the 6- reasons to continue exploration of its applications. week topic group period. For complete details, Latent Semantic Analysis is another technique please refer to Cassell &amp; Tversky (2005). used for measuring document similarity. LSA em- 3 The Current Study ploys a vector-based model to capture the seman- In this paper, we examine entrainment among 419 tics of words by applying Singular Value of the 1000 user groups (the ones who wrote in Decomposition on a term-document matrix English) and among the 15366 messages they (Landauer, Foltz, &amp; Laham, 1998). LSA has been wrote over a six-week period (with participants successfully applied to tasks such as measuring divided into 20 topic groups, with an average of semantic similarity among corpora of texts 20.95 English writers per group). We ask whether (Coccaro &amp; Jurafsky, 1998), measuring cohesion the young people’s language converges over time (Foltz, Kintsch, &amp; Landauer, 1998 ), assessing cor- in an online community. Is similarity between the rectness of answers in tutoring systems (Wiemer- texts that are produced by the young people greater Hastings &amp; Graesser, 2000) and dialogue act clas-</context>
<context position="17632" citStr="Landauer, Foltz, &amp; Laham, 1998" startWordPosition="2832" endWordPosition="2836"> three were tested with several settings such as variations in the number of dimensions and levels of control for stop words, and all three demonstrated similar results. For this paper, we present the Infomap results due to its wide acceptance among scholars as a successful implementation of LSA. To account for nuances of the lexicon used in the Junior Summit data, we built a semantic space from a subset of this data comprised of 7000 small messages (under one kb) and 100 dimensions without removing stop words. We then built vectors for each document and compared them using cosine similarity (Landauer, Foltz, &amp; Laham, 1998). 5 Results The tools we employ approach document similarity quite differently; we therefore compare findings as a way of triangulating on the nature of entrainment in the Junior Summit online community. 5.1 Pairwise Comparisons over Time First, we hypothesized that messages between individuals in a given topic group would demonstrate more similarity over time. Our findings did not support this claim; in fact, they show the opposite. All three tests show slight convergence between time period one and two, some variation, and then divergence between time periods four, five and six. Spearman’s </context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). Introduction to latent semantic analysis. Discourse Processes, 25, 259-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Milroy</author>
</authors>
<title>Language and social networks.</title>
<date>1980</date>
<publisher>Blackwell Publishers.</publisher>
<location>Oxford:</location>
<contexts>
<context position="5029" citStr="Milroy, 1980" startWordPosition="764" endWordPosition="765">ers (Brennan &amp; Clark, 1996; Garrod &amp; Pickering, 2004). Many studies have concentrated on dyadic interactions, but large-scale communities also demonstrate language similarity or convergence. In fact, speech communities have a strong influence in creating and maintaining language patterns, including word choice or phonological characteristics (Labov, 2001). Language use often plays an important role in constituting a group or community identity (Eckert, 2003). For example, language ‘norms’ in a speech community often result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’</context>
</contexts>
<marker>Milroy, 1980</marker>
<rawString>Milroy, L. (1980). Language and social networks. Oxford: Blackwell Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K G Niederhoffer</author>
<author>J W Pennebaker</author>
</authors>
<title>Linguistic style matching in social interaction.</title>
<date>2002</date>
<journal>Journal of Language and Social Psychology,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>337--360</pages>
<contexts>
<context position="5565" citStr="Niederhoffer &amp; Pennebaker (2002)" startWordPosition="842" endWordPosition="845">ften result in the conformity of new members in terms of accent or lexical choice (Milroy, 1980). This effect has been quite clear among non-native speakers, who quickly pick up the vernacular and speech patterns of their new situation (Chambers, 2001), but the opposite is also true, with native speakers picking up speech patterns from non-native speakers (Auer &amp; Hinskens, 2005) Linguistic innovation is particularly salient on the Internet, where words and linguistic patterns have been manipulated or reconstructed by individuals and quickly adopted by a critical mass of users (Crystal, 2001). Niederhoffer &amp; Pennebaker (2002) found that users of instant messenger tend to match each other’s linguistic styles. A study of language socialization in a bilingual chat room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguistic patterns online, and subsequent</context>
</contexts>
<marker>Niederhoffer, Pennebaker, 2002</marker>
<rawString>Niederhoffer, K. G., &amp; Pennebaker, J. W. (2002). Linguistic style matching in social interaction. Journal of Language and Social Psychology, 21(4), 337-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Paolillo</author>
</authors>
<title>Language variation on internet relay chat: A social network approach.</title>
<date>2001</date>
<journal>Journal of Sociolinguistics,</journal>
<volume>5</volume>
<issue>2</issue>
<pages>180--213</pages>
<contexts>
<context position="6319" citStr="Paolillo, 2001" startWordPosition="957" endWordPosition="958">room suggests that participants developed particular linguistic patterns and both native and non-native speakers were influenced by the other (Lam, 2004). Similar language socialization has been found in ethnographic research of large-scale online communities as well, in which various expressions are created and shared by group members (Baym, 2000; Cherny, 1999). Other research not only confirms the creation of new linguistic patterns online, and subsequent adoption by users, but suggests that the strength of the social ties between participants influences how patterns are spread and adopted (Paolillo, 2001). However, little research has been devoted to how language changes over longer periods of time in these online communities. 2.2 Computational Measures of Language Similarity The unit of analysis in online communities is the (e-mail or chat) message. Therefore, measuring entrainment in online communities relies on assessing whether or not similarity between the messages of each participant increases over time. Most techniques for measuring document similarity rely on the analysis of word frequencies and their cooccurrence in two or more corpora (Kilgarriff, 2001), so we start with these techni</context>
</contexts>
<marker>Paolillo, 2001</marker>
<rawString>Paolillo, J. (2001). Language variation on internet relay chat: A social network approach. Journal of Sociolinguistics, 5(2), 180-213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schutze</author>
</authors>
<title>Word space. In</title>
<date>1993</date>
<booktitle>Advances in Neural Information Processing Systems 5.</booktitle>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Mateo, CA:</location>
<contexts>
<context position="16982" citStr="Schutze, 1993" startWordPosition="2724" endWordPosition="2725">we chose 300 as our window size, because it provided sufficient contrast and yet still gave a few samples from even the smallest documents in our primary corpus. 4.3 Latent Semantic Analysis (LSA) For a third approach, we used LSA to analyze the semantic similarity between messages across different periods of time. We explored three imple2 6∑ d p = − 1 18 mentations of LSA: (a) the traditional algorithm described by Foltz et al (1998 ) with one semantic space per topic group, (b) the same algorithm but with one semantic space for all topic groups and (c) an implementation based on Word Space (Schutze, 1993) called Infomap. All three were tested with several settings such as variations in the number of dimensions and levels of control for stop words, and all three demonstrated similar results. For this paper, we present the Infomap results due to its wide acceptance among scholars as a successful implementation of LSA. To account for nuances of the lexicon used in the Junior Summit data, we built a semantic space from a subset of this data comprised of 7000 small messages (under one kb) and 100 dimensions without removing stop words. We then built vectors for each document and compared them using</context>
</contexts>
<marker>Schutze, 1993</marker>
<rawString>Schutze, H. (1993). Word space. In S. J. Hanson, J. D. Cowan &amp; C. L. Giles (Eds.), Advances in Neural Information Processing Systems 5. San Mateo, CA: Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Serafin</author>
<author>B Di Eugenio</author>
</authors>
<title>FLSA: Extending latent semantic analysis with features for dialogue act classification.</title>
<date>2004</date>
<booktitle>Paper presented at the 42nd Annual Meeting for the Association of Computational Linguistics (ACL04),</booktitle>
<location>Barcelona,</location>
<marker>Serafin, Di Eugenio, 2004</marker>
<rawString>Serafin, R., &amp; Di Eugenio, B. (2004, July 21-26, 2004). FLSA: Extending latent semantic analysis with features for dialogue act classification. Paper presented at the 42nd Annual Meeting for the Association of Computational Linguistics (ACL04), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Street</author>
<author>H Giles</author>
</authors>
<title>Speech accommodation theory. In</title>
<date>1982</date>
<pages>193--226</pages>
<publisher>Sage Publications.</publisher>
<location>London:</location>
<contexts>
<context position="3810" citStr="Street &amp; Giles, 1982" startWordPosition="579" endWordPosition="582">emantic Analysis (LSA). 2.1 Language Similarity in Computermediated Communication In dyadic settings, speakers often converge to one another’s speech styles, not only matching the choice of referring expressions or other words, but also structural dimensions such as syntax, sound characteristics such as accent, prosody, or phonolProceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 15–22, New York City, New York, June 2006. c�2006 Association for Computational Linguistics ogy, or even non-verbal behaviors such as gesture (Brennan &amp; Clark, 1996; Street &amp; Giles, 1982). Some scholars suggest that this convergence or entrainment is based on a conscious need to accommodate to one’s conversational partner, or as a strategy to maximize communication effectiveness (Street &amp; Giles, 1982). Others suggest that the alignment is an automatic response, in which echoic aspects of speech, gesture and facial expressions are unconscious reactions (Garrod &amp; Anderson, 1987; Lakin, Jefferies, Cheng, &amp; Chartrand, 2003). In short, conversational partners tend to accommodate to each other by imitating or matching the semantic, syntactic and phonological characteristics of their</context>
</contexts>
<marker>Street, Giles, 1982</marker>
<rawString>Street, R. L., &amp; Giles, H. (1982). Speech accommodation theory. In M. E. Roloff &amp; C. R. Berger (Eds.), Social cognition and communication (pp. 193-226). London: Sage Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wiemer-Hastings</author>
<author>A C Graesser</author>
</authors>
<title>Selecta-Kibitzer: A computer tool that gives meaningful feedback on student compositions.</title>
<date>2000</date>
<journal>Interactive Learning Environments,</journal>
<volume>8</volume>
<issue>2</issue>
<pages>149--169</pages>
<marker>Wiemer-Hastings, Graesser, 2000</marker>
<rawString>Wiemer-Hastings, P., &amp; Graesser, A. C. (2000). Selecta-Kibitzer: A computer tool that gives meaningful feedback on student compositions. Interactive Learning Environments, 8(2), 149– 169.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>