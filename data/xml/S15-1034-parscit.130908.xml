<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015010">
<title confidence="0.997079">
A State-of-the-Art Mention-Pair Model for Coreference Resolution
</title>
<author confidence="0.999565">
Olga Uryupina1 and Alessandro Moschitti2,1
</author>
<affiliation confidence="0.982711">
1Department of Information Engineering and Computer Science, University of Trento,
2Qatar Computing Research Institute
</affiliation>
<email confidence="0.995875">
uryupina@gmail.com, amoschitti@gmail.com
</email>
<sectionHeader confidence="0.997363" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999815315789474">
Most recent studies on coreference resolu-
tion advocate accurate yet relatively com-
plex models, relying on, for example, entity-
mention or graph-based representations. As
it has been convincingly demonstrated at the
recent CoNLL 2012 shared task, such algo-
rithms considerably outperform popular basic
approaches, in particular mention-pair mod-
els. This study advocates a novel approach
that keeps the simplicity of a mention-pair
framework, while showing state-of-the-art re-
sults. Apart from being very efficient and
straightforward to implement, our model fa-
cilitates experimental work on the pairwise
classifier, in particular on feature engineering.
The proposed model achieves the performance
level of up to 61.82% (MELA F, v4 scorer)
on the CoNLL test data, on par with complex
state-of-the-art systems.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99928154">
The mention-pair model, as proposed by Soon et
al. (2001) has been used for over a decade now.
It combines a simple classifier trained to discrimi-
nate between coreferent and not-coreferent pairs of
mentions (“links”) with fast heuristic procedures for
merging the classifier’s decisions at the decoding
stage. Several decoding heuristics have been advo-
cated in the literature, the most commonly used ones
including first-link (Soon et al., 2001) and best-link
(Ng and Cardie, 2002).
Most state-of-the-art algorithms for coreference
resolution, on the contrary, rely on complex mod-
eling, ranging from entity-ranking to structural per-
ceptron and other graph-based approaches (for an
overview of state-of-the-art coreference resolvers,
see (Ng, 2010; Pradhan et al., 2012)). Such algo-
rithms show a clearly superior performance: thus, at
the CoNLL-2012 shared task, the best-performing
(Soon et al., 2001)-style system loses around 8% to
the winning algorithm.
However, more traditional mention-pair ap-
proaches still have some important advantages.
Thus, a mention-pair model is easy to implement
and allows for fast prototyping. It relies on a sim-
ple binary classifier making it very fast to train com-
pared to state-of-the-art models that are based on
complex structural representations (Fernandes et al.,
2012; Bj¨orkelund and Kuhn, 2014). This efficiency
at the training step allows for straightforward au-
tomatic parameter optimization. Most importantly,
mention-pair models can be useful for understand-
ing low-level system behavior, and, in particular, for
feature engineering. This can in turn help improve
more complex models, since many of them rely on
mention-pairs as their basic building blocks.
In this paper, we advocate a new easy-first
mention-pair algorithm (EFMP): while it is based
solely on pairs of mentions and does not attempt
any global inference, it benefits from the decision
propagation strategy to create a coreference parti-
tion. Augmented with the sieve-style prefiltering,
the system achieves a performance level comparable
to the state of the art.
The contribution of this paper is two-fold. First,
we propose a novel decoding approach that com-
bines predictions of the mention-pair classifier based
on its confidence score, taking into account—in con-
trast to the previous studies, e.g. (Ng and Cardie,
2002; Stoyanov and Eisner, 2012; Bj¨orkelund and
Kuhn, 2014)—both positive and negative links. We
</bodyText>
<page confidence="0.977498">
289
</page>
<note confidence="0.9531775">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 289–298,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.986385354166667">
thus propose a procedure for propagating positive Our work has been motivated by more complex
and negative links to create the final coreference algorithms using the easy-first strategy, most im-
partition: we start from the most confident among portantly, by Stoyanov and Eisner (2012), Nico-
all the classifier’s decisions and iteratively con- lae and Nicolae (2006) and Bj¨orkelund and Farkas
struct coreference partitions by merging coreference (2012). There are two important differences be-
chains (positive links) or blacklisting future merges tween these studies and the Easy-First Mention-Pair
(negative links). This decoding strategy is slower model (EFMP): (i) EFMP does not evaluate links be-
than the commonly used best-link model, but con- tween entities or clusters, always operating on men-
siderably faster than ILP-based decoding (Finkel tion pairs instead; (ii) EFMP integrates both positive
and Manning, 2008; Denis and Baldridge, 2009). and negative assignments in its hierarchy of easy-to-
Second, we show that our approach, being very hard decisions.
fast and easy to implement, can be used for a variety Being conceptually very simple, our algorithm al-
of low-level experiments on coreference resolution, lows for a straightforward integration of other tech-
in particular, for studies on feature engineering or niques proposed in the literature, in particular, sieve-
selection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature in-
feature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted ex-
ing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on
Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009;
the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Dur-
before, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng,
edge, has never been applied to any NLP task. The 2010) for an overview of different features. Kob-
JIM algorithm has been developed within the data dani et al. (2010) create a framework that facilitates
mining community and aims at finding combina- the engineering process for complex features. This
tions that tend to occur in a particular set of un- approach, however, still relies on the human exper-
labeled transactions. In this paper, we introduce a tise for creating meaningful combinations. Versley
post-filtering technique to re-score JIM output w.r.t. et al. (2008) use kernel-based similarity as an im-
the class labels (±coreferent). We show empirically plicit feature induction technique.
that JIM is more suitable for coreference: it provides The only study we are aware of that investigates
smaller and more meaningful feature combinations an explicit feature combination technique has been
leading to a better performance level. conducted by Fernandes et al. (2012). Their al-
The combination of our decoding approach with gorithm for Entropy-based feature induction (EFI),
the JIM feature induction technique allows us to shows substantial improvement on the OntoNotes
achieve a performance level of 61.82% on the dataset. In the present work, we propose an al-
CoNLL-2012 test data, just 1.5% percent below the ternative to EFI, based on the recent advances in
(much more complex) winning system and above all Data Mining. We believe that Fernandes et al.
the other submissions (cf. Table 4). (2012) have opened a very important research di-
2 Related work rection with their feature induction approach. We
An improvement over the original mention-pair want therefore to evaluate EFI in a simpler and more
model (Soon et al., 2001) has been proposed by straightforward mention-pair model—and compare
Ng and Cardie (2002). Their “best-link” algo- it to our approach.
rithm picks the most confident antecedent for each 3 Easy-First Mention-Pair Model
anaphor. Unlike Ng and Cardie (2002), we do not In what follows, we describe our Easy-First
process the input text from left to right incremen- Mention-Pair (EFMP) approach and then propose
tally, instead, we assess the confidence of all the pro- a solution for combining our model with manu-
posed links at the same time (“easy-first”) and keep ally engineered filters, inspired by Stanford “sieves”
track of negative assignments. (Lee et al., 2011). EFMP is a decoding algorithm.
290
Algorithm 1 Easy-first decoding (EFMP)
</bodyText>
<listItem confidence="0.8034338">
Require: L = {&lt; anal, antel, labell, confidencel &gt;}: list
of classified mention pairs
1: sort L according to confidence
2: for all l E L do
3: /* don’t override prev. decisions */
4: if chain(anal) == chain(antel) then
5: continue
6: if unlinked(chain(anal), chain(antel)) then
7: continue
8: /* update chains and unlink info */
</listItem>
<figure confidence="0.888728181818182">
9: if labell==not-coreferent then
10: unlink(chain(anal), chain(antel))
11: if labell==coreferent then
12: UpdateUnlinkInfo({chain(anal), chain(antel))
13: MergeChains({chain(anal), chain(antel))
14: function UPDATEUNLINKINFO(chain1, chain2)
15: for all c such as unlinked(c, chain2) do
16: unlink(c, chain1)
17: function MERGECHAINS(chain1, chain2)
18: for all m E chain2 do
19: chain(m) = chain1
</figure>
<bodyText confidence="0.990493142857143">
At the encoding step, we generate mention-pairs in
a straightforward exhaustive way: each candidate
anaphor is paired with all the preceding candidate
antecedents. Following the state-of-the-art, we fil-
ter out mention pairs using the same sieve-style ap-
proach at both the encoding and the decoding steps
(cf. Section 3.2 below).
</bodyText>
<subsectionHeader confidence="0.998201">
3.1 Plain EFMP
</subsectionHeader>
<bodyText confidence="0.999935">
Our EFMP approach addresses the clustering step of
a coreference resolution process: as its input, it as-
sumes a set of mention pairs for a given document,
labeled as positive (two mentions corefer) or neg-
ative (two mentions do not corefer) by an external
classifier. We also assume the classifier to output the
confidence of its decisions.
The key idea behind EFMP is the processing of
all the decisions, both positive and negative ones,
in a specific order, according to the classifier’s con-
fidence. We start by sorting all the mention pairs
by the confidence of the assigned label. We in-
stantiate our clustering assigning each mention to
its own cluster (“all singletons”), however, we do
not prohibit potential links between any of them.
Our EFMP module processes all the (sorted) men-
tion pairs one-by-one, at each step performing one
of the following operations, whenever possible:
</bodyText>
<listItem confidence="0.99590225">
• link: merge two clusters (includes propagating
unlink information, cf. below)
• unlink: mark two given clusters to prohibit po-
tential merge at any future step
</listItem>
<bodyText confidence="0.9946396">
These operations, however, are only performed if the
system has no information about the possibility of
(un)linking the two mentions at the given step.
Let us illustrate the approach with the following
example:
</bodyText>
<equation confidence="0.9213205">
(1) [Alice]1 is showing [Zoe]2 [her]3 papers on
coreference.
</equation>
<bodyText confidence="0.999367434782609">
In this snippet, we collect three mentions (“Al-
ice” (M1), “Zoe” (M2) and “her” (M3)), form-
ing three mention pairs.1 A state-of-the-art pair-
wise coreference classifier would confidently label
&lt; Alice, Zoe &gt; as negative; and less confidently—
&lt; Alice, her &gt; and &lt; Zoe, her &gt; as positive.
The score for &lt; Alice, her &gt; would be slightly
higher: “Alice” is a subject and a first mention in
the sentence. The EFMP module starts from three
clusters: C1 = {M1}, C2 = {M2}, C3 = {M3}.
At the first step, it registers the information, that
C1 and C2 should never be merged (“unlink”). At
the second step, it links M1 and M3, merging C1
and C3, thus producing a partition with two clus-
ters: C&apos;1 = {M1, M3}, C2 = {M2}. It also prop-
agates the previously collected unlinking informa-
tion, registering the fact that C&apos;1 and C2 should never
be merged. At the next step, it tries to link M2 and
M3. This, however, doesn’t work, since the system
has already collected some more reliable evidence
that the corresponding clusters shouldn’t be merged.
As there are no more mention-pairs left, the system
stops and outputs the last partition (C&apos;1, C2).
</bodyText>
<subsectionHeader confidence="0.999775">
3.2 EFMP with Sieves
</subsectionHeader>
<bodyText confidence="0.999975125">
The plain EFMP approach, as described above, as-
sumes that all the mention pairs are labeled by the
pairwise classifier. This has several potential issues.
First, it requires sorting all the links: when mention-
pairs are generated exhaustively, it amounts to the
running time of O(n2 log(n)), where n is the total
number of mentions. Second, the pairwise classifier
has to be trained on a very biased dataset, containing
</bodyText>
<footnote confidence="0.7145145">
1We omit other mentions (“her papers” and “coreference”)
to simplify the presentation.
</footnote>
<page confidence="0.992947">
291
</page>
<bodyText confidence="0.999952766666667">
too many negative or irrelevant examples; this might
decrease the performance and also requires substan-
tial tuning of learning parameters.
To alleviate the problem, we pre-filter mention
pairs aggressively, heuristically eliminating links
that are either definitely positive (for example, pairs
of same named entities), definitely negative (pairs
with incompatible gender values) or “uninforma-
tive”. The latter are pairs that we cannot realisti-
cally expect to be analyzed by our system, due to the
limits of our feature representation. For example, a
pair of two noun phrases sharing no common tokens
and appearing far apart from each other might be
either positive or negative, with the particular deci-
sion depending on a lot of factors, starting from the
semantic compatibility of the two mentions (“car”
and “relativity” can hardly be coreferent), but also
including discourse-related factors and some suit-
ably represented knowledge of other entities (“car”
and “Ferrari” in different parts of a document talking
about Formula 1 may refer to different entities). We
believe that forcing our pairwise classifier to learn
a labeling for such “uninformative” examples with-
out providing adequate features might lead to infe-
rior performance.
Our pre-filtering approach was inspired by the
Stanford sieves algorithm (Lee et al., 2011), where
several high-precision rules are applied in a spe-
cific order to filter out candidates. This approach
has since then been used in several systems, most
successfully by Fernandes et al. (2012) to filter out
training data for coreference resolution classifiers.
The idea of distinguishing between “informative”
and “uninformative” instances has been implicitly
adopted by many systems, restricting their search to
a specific window. This approach is very common
for pronominal anaphora, but it’s also used by sev-
eral general-purpose coreference resolvers (Fernan-
des et al., 2012; Stoyanov and Eisner, 2012).
All these rule-based decisions can be integrated
into EFMP in a straightforward way. Thus, the un-
informative pairs are simply excluded from the fur-
ther processing. They do not produce training mate-
rial and they are not processed by EFMP at the test
time (consequently, mentions from such a pair may
end up in the same cluster, as well as in two differ-
ent ones, depending on other (un)links established
by the system). This allows for a substantial reduc-
tion of the pairs to be processed at the decoding step
(for example, in our setting described in Section 5.1
below, around 90% of all the pairs are eliminated
as “uninformative”). The pairs, deemed positive or
negative by the rule-based pre-filtering, do not con-
tribute to the training data. At the test step, they are
considered to be very confidently positive/negative
instances, outscoring any test pairs, originating from
the classifier output. Such pairs do not contribute to
speeding up the EFMP part, however, they help im-
prove the quality of our pairwise classifier, decreas-
ing the bias towards negative instances in the data.
</bodyText>
<sectionHeader confidence="0.992848" genericHeader="method">
4 Techniques for generating feature
combinations
</sectionHeader>
<bodyText confidence="0.99998928125">
Most state-of-the-art coreference resolution systems
combine complex modeling with rich feature sets.
While early data-driven approaches were essentially
knowledge-poor (for example, the famous system of
Soon et al. (2001) is based on 12 shallow features),
modern algorithms rely on dozens of carefully engi-
neered features, encoding various clues relevant for
the task: from different measures of surface similar-
ity, to morphological, syntactic, semantic and dis-
course properties, and world knowledge.
This study focuses on the automatic feature engi-
neering task. We start from atomic features that are
already encoded in a state-of-the-art toolkit (BART)
and use a data mining technique, Jaccard item min-
ing, to boost the system performance through auto-
matic induction of complex features.
The features used by most coreference resolu-
tion systems are very heterogeneous. Some of them
(for example, different measures of salience) encode
insights from the linguistic theory, whereas others
are purely data-driven (tokens). Some features are
direct indicators for or against coreference (string
matching vs. contra-indexing constraints), whereas
others are supposed to provide more general infor-
mation (individual properties of mentions). Some
features are very frequent (mention types), whereas
others are relatively rare (apposition). Finally,
some features encode basic properties (“anaphor is
a pronoun”), whereas others are combinations of
such properties (“both anaphor and antecedent are
pronouns and they have the same surface form”).
Therefore, we specifically aim at designing an algo-
</bodyText>
<page confidence="0.981532">
292
</page>
<bodyText confidence="0.999930666666667">
rithm that is able to overcome these idiosyncrasies
and provide meaningful combinations for such a het-
erogeneous set of atomic features.
</bodyText>
<subsectionHeader confidence="0.989394">
4.1 Jaccard Item Mining
</subsectionHeader>
<bodyText confidence="0.9999324375">
In this study, we adapt the Jaccard Item Mining
(JIM) technique (Segond and Borgelt, 2011) to the
coreference resolution task. Below we describe the
JIM algorithm and our adjustment of JIM to the task
of selecting meaningful features.
The Data Mining community has invested sub-
stantial efforts into Frequent Item Mining algo-
rithms: techniques for finding frequent combina-
tions of “items” in a “transaction database”. We as-
sume that a database is a set of item sets with some
items often appearing together. Several approaches
have been proposed to solve the task of enumerat-
ing all such frequently occurring combinations in a
fast and efficient way, the most popular ones being
Eclat and FP-growth. A typical application would
be, for example, the task of finding similarities in
shopping lists for different customers. We refer the
reader to (Borgelt, 2012) for an overview of relevant
approaches.
Frequent Item Mining algorithms output all the
combinations with a frequency (“support”) higher
than a predefined threshold. If the original items are
very heterogeneous, the output might get very noisy:
for example, if there are some very frequent items,
they will pollute most combinations and the interest-
ing item sets will be difficult to find. To overcome
this problem, Segond and Borgelt (2011) propose to
use the Jaccard index as a measure of the item set
quality. For a given set of items I, the Jaccard in-
dex JT (I) is defined as a ratio of the set’s support
over the number of transactions containing at least
one item from the set:
</bodyText>
<equation confidence="0.970322">
JT (I) =  |∩i∈I KT ({i})|
 |∪i∈I KT ({i})|,
</equation>
<bodyText confidence="0.996814142857143">
where KT({i}) is a set of transactions, containing
the item i.
It is straightforward to see that JT (I) is an anti-
monotone function. Therefore, standard frequent
item mining algorithms can be easily adapted to
cover the Jaccard index. In our experiments, we use
a publicly available JIM implementation.2
</bodyText>
<footnote confidence="0.684334">
2http://www.borgelt.net/jim.html
</footnote>
<bodyText confidence="0.999985782608696">
We recast the feature induction problem as a fre-
quent item mining task. We start from atomic fea-
tures (string, nominal and binary) and convert them
into binary features that represent our items. Since
our feature set is very heterogeneous, some items
are very rare or, conversely, very frequent. We fil-
ter out all the items with the support below or above
predefined thresholds. The frequent item mining ap-
proaches assume that all the transactions are equal.
In our case, however, transactions correspond to
training instances—and they come with the class la-
bels. Since we are interested in the feature combi-
nations that help distinguish between positive and
negative examples, we perform two JIM runs, split-
ting the training data into the positive and negative
parts. For each part, we induce all the combinations
with the high Jaccard index (J+T (I) and J−T (I)). Af-
ter this step, we have two lists of items, each cor-
responding to feature combinations showing a good
association strength for positive and negative exam-
ples respectively.
Both lists are then reranked, dividing the positive
index over the negative one and vice versa:
</bodyText>
<equation confidence="0.9992415">
score+(I) = J+T (I) T (I), score−(I) = J− T (I)
J− J+ T (I).
</equation>
<bodyText confidence="0.999753181818182">
This reranking step helps us to filter out fea-
ture combinations that are either redundant or
not indicative of coreference. For example, our
atomic features already contain some combina-
tions (e.g., NEStringMatch is a combination of
MentionType Coarse and StringED). With-
out the reranking step, we are getting numerous
combinations reflecting peculiarities in the feature
design. As the final JIM output, we take all the sets
I with the scores exceeding some predefined thresh-
olds (score+(I) &gt; thr+ or score−(I) &gt; thr−).
Note that our score measures are not monotone and
cannot therefore be used in a fast Eclat-style al-
gorithm (Borgelt, 2012) to directly provide score-
optimal combinations.
To better align our approach with the Entropy
Guided Feature Induction framework presented be-
low, we convert our item sets back to the sets of
atomic features, abstracting away from the partic-
ular values used for binarization.
The JIM-based feature induction algorithm relies
on several parameters: the feature filtering thresh-
</bodyText>
<page confidence="0.992519">
293
</page>
<bodyText confidence="0.9999062">
olds (for removing too rare or too common features),
the minimal Jaccard index for the JIM algorithm and
the thresholds thr+ and thr− for selecting good
item sets after the reranking step. We fit these pa-
rameters on the development set.
</bodyText>
<subsectionHeader confidence="0.960184">
4.2 Entropy Guided Feature Induction
</subsectionHeader>
<bodyText confidence="0.999220071428571">
Fernandes et al. (2012) have proposed using Entropy
Guided Feature Induction (EFI) for coreference res-
olution and have shown that it significantly improves
the performance of their system. Below we provide
a brief overview of the EFI approach, referring the
reader to the original paper for further details.
The system works at two stages, using two differ-
ent machine learning techniques. At the first stage,
the EFI algorithm relies on a decision tree, generated
from the training data, to obtain meaningful feature
combinations. In particular, the algorithm extracts
all the paths leading from the root of the induced
tree to any node. Each node in a tree corresponds to
a specific value assigned to some atomic feature and
therefore each path corresponds to a conjunction of
atomic features with assigned values. Fernandes et
al. (2012) abstract over the values, thus, converting
each path to a conjunction of atomic features. These
conjunctions, or combinations, are then used to gen-
erate numerous binary features to be used by a linear
classifier at the second stage.
Since the induced tree might get very large, the
EFI algorithm might lead to conjunctions of too
many atomic features, generating, in turn, too many
binary features. To address the issue, Fernandes et
al. (2012) prune their tree at the depth 5. In our im-
plementation, we follow the algorithm of Fernandes
et al. (2012) with no adjustments or alterations.
</bodyText>
<sectionHeader confidence="0.999646" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99997225">
Our first group of experiments assesses the quality
of the baseline setting, with no feature combina-
tion techniques. We compare against the CoNLL
submission of the BART group to make sure that
our (Soon et al., 2001)-style mention-pair baseline
shows an acceptable performance. We then evalu-
ate the EFMP approach to confirm that it provides
much higher performance figures and is on par with
the state of the art. In our second experiment, we use
EFMP to assess the impact of the feature combina-
tion techniques on the performance of a coreference
resolution system.
</bodyText>
<subsectionHeader confidence="0.967961">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999947431818182">
We evaluate our approach on the English portion of
the CoNLL-2012 dataset (Pradhan et al., 2012). To
asses the system’s performance, we use the official
scorer, provided by the CoNLL organizers. How-
ever, the version used at the competition time (v4)
was later found to contain errors and replaced with
another implementation (v7). This procedure re-
sulted in a performance drop for all the systems, but
didn’t affect their ranking. To facilitate comparison
against previous and future studies, we report both
v4 and v7 MELA scores. All the experiments are
performed on automatically extracted mentions and
use no gold information.
For our study, we use the publicly available
BART toolkit (Uryupina et al., 2012). We have
made several adjustments, starting from the con-
figuration, suggested in the BART distribution for
the OntoNotes/CoNLL data. Thus, we have mod-
ified the mention detection module, improving the
treatment of coordinations and eliminating numeric
named entities (PERCENT, MONEY etc). We
have replaced the original split architecture with
a single-classifier approach to be able to estimate
the impact of our feature combination techniques
in a more principled way. We have also re-
placed Decision Trees (Weka J48) with the Lib-
Linear SVM package, to get a classifier outputting
reliable confidence values, as needed by EFMP.
We have considerably expanded the feature set,
mainly reimplementing features from the winning
system of CoNLL-2012 (Fernandes et al., 2012).
Altogether, we have around 170 individual fea-
tures (string, nominal or binary values), correspond-
ing to around 20k features after the binarization
step. The full list of our feature templates can be
found at http://bart-coref.eu/papers/
sem15-suppl.pdf.
Finally, we have augmented BART with a rule-
based prefiltering module, motivated by Stanford
Sieves (Lee et al., 2011), the winning approach of
the CoNLL-2011 shared task. Our sieve-style pre-
filtering algorithm splits all the training instances
into confidently positive, confidently negative, irrel-
evant and relevant. To implement the prefiltering
</bodyText>
<page confidence="0.996073">
294
</page>
<table confidence="0.9994213125">
development test
v4 v4 v7
BART CoNLL-2012 submission
- 56.12 50.02
simplified reimplemented BART submission
WEKA (j48) 56.02 55.84 49.83
SVM (Liblinear) 48.31 47.29 39.17
-*-, all features
WEKA (j48) 56.53 55.98 49.84
SVM (Liblinear) 49.83 48.11 40.04
best-link, all features
SVM (Liblinear) 59.71 59.03 55.21
EFMP, features from BART submission
SVM (Liblinear) 57.40 56.16 50.65
EFMP, all features
SVM (Liblinear) 60.02 59.12 55.38
</table>
<tableCaption confidence="0.980893">
Table 2: Baseline performance vs. plain EFMP: MELA
score, different versions of the CoNLL scorer.
</tableCaption>
<bodyText confidence="0.99971125">
module, we have started with the original sieves and
the version used by Fernandes et al. (2012). We have
changed some sieves and introduced several addi-
tional filters (cf. Table 1).
</bodyText>
<subsectionHeader confidence="0.999236">
5.2 Baselines vs. EFMP
</subsectionHeader>
<bodyText confidence="0.999991019230769">
Table 2 shows the performance levels for different
baseline algorithms, learners and features on both
CoNLL-2012 development and test sets. Note that
the development set was used for parameter tuning
and does not therefore provide an accurate estima-
tion of the system’s performance.
The results suggest that our simplified version of
the BART CONLL-2012 system can be considered
an adequate starting point: it only shows a very mi-
nor performance drop, compared to the original sub-
mission (we believe that this drop can be attributed
to the simpler no-split architecture that we are
adopting in this study). The (Soon et al., 2001)-style
mention-pair model, however, suffers from several
problems. First of all, its performance is simply
not good enough: thus, the winners of the CoNLL-
2012 shared task reported a v4 score of 63.37 on
the test data. With a v4 score of 55.84, our sys-
tem would have achieved the 12th place in the com-
petition (out of 15+1). Second, this approach only
works with the decision tree-based classifier: with
SVMs, the performance gets much lower. We be-
lieve that this can be caused by several factors: (a)
decision trees perform some sort of feature combina-
tions, whereas Liblinear only relies on a sum of indi-
vidual features for its classification and (b) the (Soon
et al., 2001)-style model employs different sampling
strategies for training and testing data (in fact, test-
ing instance are sampled dynamically, based on the
decisions made by the classifier so far), leading to a
misfit between the two sets that is more problematic
for Liblinear. Third, even with the decision trees,
the system performance does not improve substan-
tially when we add a lot of manually engineered
high-quality features.
The EFMP model, on the contrary, shows promis-
ing performance figures. With an F-score of 59.12,
the system would have achieved the 8th place in the
CoNLL-2012 competition, within the cluster of very
similarly performing systems on places 2–8(9). It
must be stressed that EFMP is a very simple and fast
algorithm, much less complex than any of the high-
performing CoNLL systems.
We have also evaluated EFMP against a mention-
pair model with the same sieve-style prefiltering and
a best-link decoder (Table 2, row 6). As the results
suggest, the best-link decoder shows a better perfor-
mance level compared to (Soon et al., 2001), since
it relies on the most confident positive links. The
EFMP decoder, however, brings a further improve-
ment, by incorporating and propagating information
on confident negative links as well.
</bodyText>
<subsectionHeader confidence="0.999149">
5.3 Feature combinations
</subsectionHeader>
<bodyText confidence="0.999440533333333">
In our second experiment, we investigate the appli-
cability of JIM to coreference resolution, comparing
it against EFI. The latter has been proven to yield a
performance gain of up to 10%, leading to a system,
significantly outperforming all the other competitors
at the CoNLL-2012 shared task. While the impact of
EFI on the system of Fernandes et al. (2012) cannot
be underestimated, the following points need further
clarifications: (a) the algorithm of Fernandes et al.
(2012) shows only very moderate performance with-
out EFI—it is not yet clear if EFI is equally benefi-
cial for more competitive approaches; and (b) the
system of Fernandes et al. (2012) relies on a rela-
tively complex model—it is not clear how model-
specific the benefits of EFI are.
</bodyText>
<page confidence="0.994928">
295
</page>
<table confidence="0.9998213125">
Confidently negative
Expletive Mi or Mj is an expletive pronoun
Span one mention spans over the other
Agreement Mi and Mj disagree in number, gender or semantic class
Syntax Mi and Mj violate contra indexing constraints (c-command etc)
SpeakerAliasProFalse heuristics for 1/2 person pronouns, based on the speaker value
Pronouns Mi is a pronoun, Mi and Mj disagree in person (respecting the speaker)
Confidently positive
SpeakerAliasPro heuristics for 1/2 person pronouns, based on the speaker value
SpeakerAliasNE heuristics for 1 person pronouns (Mj) and NE (Mi), based on the speaker
SameNE Mi and Mj are exactly matching NEs
Irrelevant
ProNonpro Mj is a pronoun, Mi is not a pronoun
DistantPro Mj is a pronoun, Mi is more than thr1 sentences away (dist(Mj, Mi) &gt; thr1)
DistantNP Mj is a common NP, dist(Mj, Mi) &gt; thr2, head nouns of Mi and Mj differ
DistantNE Mj is an NE, dist(Mj, Mi) &gt; thr2, Mi and Mj do not match
</table>
<tableCaption confidence="0.9301495">
Table 1: Sieves for pre-filtering of mention pairs: each sieve is applied to a pair of mentions {Mi, Mj}, i &lt; j, where
Mi is a candidate antecedent and Mj is a candidate anaphor.
</tableCaption>
<bodyText confidence="0.99847345">
EFI and JIM use very different intuitions for com-
bining atomic features. It is therefore not surprising,
that the outputs of these two algorithms are different.
Figure 1 summarizes the distribution of EFI vs. JIM-
induced combinations of different lengths, normal-
ized by the total number of combinations extracted
by each method. EFI outputs around 20 times more
sets than JIM (2k vs. 90). Most of them, however,
are too long and do not provide good features. By
definition, EFI cannot produce a lot of short combi-
nations, since all the EFI paths must start from the
root. JIM, on the contrary, tends to produce com-
binations of smaller lengths that are more likely to
yield high-quality features.
Table 3 shows the performance of EFMP, aug-
mented with EFI or JIM-induced features. We see
that both techniques bring an improvement over the
plain EFMP (significant, per-document t-test, p &lt;
0.05). Even though JIM produces much fewer com-
binations, it still outperforms EFI (p &lt; 0.05).
</bodyText>
<subsectionHeader confidence="0.982319">
5.4 EFMP and State of the art
</subsectionHeader>
<bodyText confidence="0.999724">
Table 4 compares the performance level of the
EFMP approach, plain and enhanced with the JIM-
based feature induction module, against the top 5
CoNLL-2012 systems on the CoNLL-2012 test set.
As the results show, the EFMP approach achieves
</bodyText>
<figureCaption confidence="0.997374333333333">
Figure 1: Normalized combination length for JIM and
EFI: number of induced sets of size 1..9, 10+ divided by
the total number of induced sets
</figureCaption>
<bodyText confidence="0.999367538461538">
results comparable to the state-of-the-art. At the
same time, it’s much faster than more complex ap-
proaches. The vast majority of high-performance
coreference resolution systems (in particular, the
CoNLL-2012 winning algorithm by Fernandes et al.
(2012)) rely on complex structural representations
and are therefore slow at the training stage. Our sys-
tem only needs a simple binary mention-pair classi-
fier that can be trained very efficiently. Some high-
performance approaches rely on the same classifier,
postponing a heavy global inference step to the de-
coding stage, for example, through Integer Linear
Programming (Denis and Baldridge, 2009; Finkel
</bodyText>
<page confidence="0.993715">
296
</page>
<table confidence="0.9984315">
development test
v4 v4 v7
EFMP, all features, SVM
none 60.02 59.12 55.38
EFI 61.66 60.75 57.56
JIM 62.53 61.82 59.14
</table>
<tableCaption confidence="0.9946725">
Table 3: Feature combinations, JIM vs. EFI: MELA
score, different versions of the CoNLL scorer.
</tableCaption>
<table confidence="0.998466777777778">
test
v4 v7
1 fernandes 63.37 60.65
EFMP+JIM 61.82 59.14
2 martschat 61.31 57.68
3 bjorkelund 61.24 57.42
EFMP 59.12 55.38
4 chang 60.18 56.10
5 chen 59.69 54.52
</table>
<tableCaption confidence="0.99121">
Table 4: EFMP and top-5 CoNLL-2012 systems: MELA
score, systems ranked by the v7 score on the test set.
</tableCaption>
<bodyText confidence="0.999913083333333">
and Manning, 2008). While these systems have the
same training requirements as EFMP, their decod-
ing (ILP with binary variables) is known to be NP-
complete. In practice, ILP-based approaches incor-
porating any forms of global modeling via transitiv-
ity constraints (Denis and Baldridge, 2009; Finkel
and Manning, 2008) are known to be particularly
slow. Our simple decoding algorithm runs in O(p *
log(p)), where p is the total number of mention
pairs: for the plain EFMP, p = n * (n − 1)/2, for
the EFMP with sieves, p = const*n, where n is the
number of mentions in the document.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999975066666667">
In this study, we advocate an easy-first mention-pair
model (EFMP). This approach combines the sim-
plicity of mention-pair models with the high perfor-
mance level of state-of-the-art systems. We believe
that several research lines are open in the field of
coreference resolution, ours being simple and allow-
ing to focus more on low-level linguistic phenom-
ena. Nevertheless, the approach shows a high per-
formance level, despite the lack of any global infer-
ence (augmented with a feature induction module,
our system would have achieved the second place at
the CoNLL-2012 shared task, outperforming more
complex algorithms). This suggests that there is still
a lot of potential improvement that can be achieved
within more complex frameworks, e.g., structural
approaches that attempt at modeling links interde-
pendence explicitly. One of our directions for future
work involves comparing EFMP against other algo-
rithms effectively combining positive and negative
links, in particular, ILP-based approaches.
The proposed EFMP model allows for a straight-
forward investigation of possibilities for automatic
feature induction. We have adapted the Jaccard Item
Mining algorithm (JIM) to our task and compared
its output against the Entropy-based Feature Induc-
tion (EFI) methodology proposed in the literature,
showing that both techniques yield meaningful fea-
ture combinations and improve the system’s perfor-
mance. Yet, the JIM approach outputs smaller com-
binations, leading to a larger performance increase.
In our future work, we plan to focus further on the
feature induction task, following several research di-
rections. First, we want to apply automatic feature
induction in a multilingual setting. Second, we plan
to investigate other feature induction techniques: (i)
comparing various similarity measures alternative to
the Jaccard index in a JIM-style setting, (ii) trying to
run EFI on different samples of the training set to ob-
tain different decision trees and (iii) combining JIM
and EFI-induced features. Finally, we want to ver-
ify our hypothesis that complex features represent
meaningful linguistic combinations and as such can
be used to enhance the performance level of more
complex algorithms. This again would bridge the
work on mention-pair and more advanced models.
</bodyText>
<sectionHeader confidence="0.998159" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.973036">
This research is part of the Interactive sYstems for
Answer Search (Iyas) project, conducted by the
Arabic Language Technologies (ALT) group at the
Qatar Computing Research Institute (QCRI) within
the Qatar Foundation.
</bodyText>
<page confidence="0.994735">
297
</page>
<sectionHeader confidence="0.998321" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999826126213592">
Eric Bengtson and Dan Roth. 2008. Understanding
the value of features for coreference resolution. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’08,
pages 294–303, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Anders Bj¨orkelund and Rich´ard Farkas. 2012. Data-
driven multilingual coreference resolution using re-
solver stacking. In Joint Conference on EMNLP and
CoNLL - Shared Task, pages 49–55, Jeju Island, Ko-
rea, July. Association for Computational Linguistics.
Anders Bj¨orkelund and Jonas Kuhn. 2014. Learning
structured perceptrons for coreference resolution with
latent antecedents and non-local features. In Proceed-
ings of the 52nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 47–57, Baltimore, Maryland, June. Association
for Computational Linguistics.
Christian Borgelt. 2012. Frequent item set mining. Wiley
Interdisciplinary Reviews: Data Mining and Knowl-
edge Discovery, 2(6):437–456.
Pascal Denis and Jason Baldridge. 2009. Global joint
models for coreference resolution and named entity
classification. In Procesamiento del Lenguaje Natural
42, Barcelona: SEPLN.
Greg Durrett and Dan Klein. 2013. Easy victories and
uphill battles in coreference resolution. In Proceed-
ings of the 2013 Conference on Empirical Methods in
Natural Language Processing, pages 1971–1982.
Eraldo Rezende Fernandes, Cicero Nogueira dos Santos,
and Ruy Luiz Milidi´u. 2012. Latent structure per-
ceptron with feature induction for unrestricted coref-
erence resolution. In Joint Conference on EMNLP
and CoNLL - Shared Task, CoNLL ’12, pages 41–48,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Jenny Rose Finkel and Christopher D. Manning. 2008.
Enforcing transitivity in coreference resolution. In
Proceedings of the Annual Meeting of the Association
for Computational Linguistics, pages 45–48.
Hamidreza Kobdani, Hinrich Sch¨utze, Andre Burkovski,
Wiltrud Kessler, and Gunther Heidemann. 2010. Re-
lational feature engineering of natural language pro-
cessing. In Proceedings of the 19th ACM Conference
on Information and Knowledge Management (CIKM),
pages 1705–1708.
Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael
Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011.
Stanford’s multi-pass sieve coreference resolution sys-
tem at the CoNLL-2011 shared task. In Proceedings
of the Fifteenth Conference on Computational Natu-
ral Language Learning: Shared Task, CONLL Shared
Task ’11, pages 28–34, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Vincent Ng and Claire Cardie. 2002. Improving machine
learning approaches to coreference resolution. In Pro-
ceedings of the 40th Annual Meeting of the Association
for Computational Linguistics, pages 104–111.
Vincent Ng. 2010. Supervised noun phrase coreference
research: The first fifteen years. In Proceedings of the
48th Annual Meeting of the Association for Computa-
tional Linguistics, pages 1396–1411.
Cristina Nicolae and Gabriel Nicolae. 2006. Bestcut:
A graph algorithm for coreference resolution. In Pro-
ceedings of the 2006 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’06,
pages 275–283, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-
2012 shared task: Modeling multilingual unrestricted
coreference in OntoNotes. In Proceedings of the
Sixteenth Conference on Computational Natural Lan-
guage Learning (CoNLL’12), Jeju, Korea.
Marta Recasens and Eduard Hovy. 2009. A deeper look
into features for coreference resolution. In Anaphora
Processing and Applications (DAARC 2009).
Marc Segond and Christian Borgelt. 2011. Item set min-
ing based on cover similarity. In Proceedings of the
15th Pacific-Asia Conference on Knowledge Discov-
ery and Data Mining (PAKDD 2011).
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A machine learning approach to corefer-
ence resolution of noun phrases. Computational Lin-
guistic, 27(4):521–544.
Veselin Stoyanov and Jason Eisner. 2012. Easy-first
coreference resolution. In Proceedings of the 24th In-
ternational Conference on Computational Linguistics
(COLING), pages 2519–2534.
Olga Uryupina, Alessandro Moschitti, and Massimo Poe-
sio. 2012. BART goes multilingual: The UniTN / Es-
sex submission to the CoNLL-2012 Shared Task. In
Proceedings of the Sixteenth Conference on Computa-
tional Natural Language Learning (CoNLL’12).
Olga Uryupina. 2006. Coreference resolution with
and without linguistic knowledge. In Proceedings of
the Language Resources and Evaluation Conference
(LREC’06).
Yannick Versley, Alessandro Moschitti, Massimo Poesio,
and Xiaofeng Yang. 2008. Coreference systems based
on kernels methods. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics
(COLING), pages 961–968.
</reference>
<page confidence="0.997116">
298
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.937156">
<title confidence="0.99885">A State-of-the-Art Mention-Pair Model for Coreference Resolution</title>
<affiliation confidence="0.979272">of Information Engineering and Computer Science, University of Computing Research</affiliation>
<email confidence="0.994256">uryupina@gmail.com,amoschitti@gmail.com</email>
<abstract confidence="0.9996373">Most recent studies on coreference resolution advocate accurate yet relatively complex models, relying on, for example, entitymention or graph-based representations. As it has been convincingly demonstrated at the recent CoNLL 2012 shared task, such algorithms considerably outperform popular basic approaches, in particular mention-pair models. This study advocates a novel approach that keeps the simplicity of a mention-pair framework, while showing state-of-the-art results. Apart from being very efficient and straightforward to implement, our model facilitates experimental work on the pairwise classifier, in particular on feature engineering. The proposed model achieves the performance level of up to 61.82% (MELA F, v4 scorer) on the CoNLL test data, on par with complex state-of-the-art systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Bengtson</author>
<author>Dan Roth</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>294--303</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5539" citStr="Bengtson and Roth, 2008" startWordPosition="811" endWordPosition="814">ntegration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted exing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009; the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Durbefore, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng, edge, has never been applied to any NLP task. The 2010) for an overview of different features. KobJIM algorithm has been developed within the data dani et al. (2010) create a framework that facilitates mining community and aims at finding combina- the engineering process for complex features. This tions that tend to occur in a particular set of un- approach, however, still relies on the human experlabeled transactions. In this paper, we introduce a tise for creating meaningful combinations.</context>
</contexts>
<marker>Bengtson, Roth, 2008</marker>
<rawString>Eric Bengtson and Dan Roth. 2008. Understanding the value of features for coreference resolution. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 294–303, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Rich´ard Farkas</author>
</authors>
<title>Datadriven multilingual coreference resolution using resolver stacking.</title>
<date>2012</date>
<booktitle>In Joint Conference on EMNLP and CoNLL - Shared Task,</booktitle>
<pages>49--55</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<marker>Bj¨orkelund, Farkas, 2012</marker>
<rawString>Anders Bj¨orkelund and Rich´ard Farkas. 2012. Datadriven multilingual coreference resolution using resolver stacking. In Joint Conference on EMNLP and CoNLL - Shared Task, pages 49–55, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Jonas Kuhn</author>
</authors>
<title>Learning structured perceptrons for coreference resolution with latent antecedents and non-local features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>47--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<marker>Bj¨orkelund, Kuhn, 2014</marker>
<rawString>Anders Bj¨orkelund and Jonas Kuhn. 2014. Learning structured perceptrons for coreference resolution with latent antecedents and non-local features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 47–57, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Borgelt</author>
</authors>
<title>Frequent item set mining. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery,</title>
<date>2012</date>
<contexts>
<context position="17871" citStr="Borgelt, 2012" startWordPosition="2757" endWordPosition="2758">Mining community has invested substantial efforts into Frequent Item Mining algorithms: techniques for finding frequent combinations of “items” in a “transaction database”. We assume that a database is a set of item sets with some items often appearing together. Several approaches have been proposed to solve the task of enumerating all such frequently occurring combinations in a fast and efficient way, the most popular ones being Eclat and FP-growth. A typical application would be, for example, the task of finding similarities in shopping lists for different customers. We refer the reader to (Borgelt, 2012) for an overview of relevant approaches. Frequent Item Mining algorithms output all the combinations with a frequency (“support”) higher than a predefined threshold. If the original items are very heterogeneous, the output might get very noisy: for example, if there are some very frequent items, they will pollute most combinations and the interesting item sets will be difficult to find. To overcome this problem, Segond and Borgelt (2011) propose to use the Jaccard index as a measure of the item set quality. For a given set of items I, the Jaccard index JT (I) is defined as a ratio of the set’s</context>
<context position="20772" citStr="Borgelt, 2012" startWordPosition="3240" endWordPosition="3241"> to filter out feature combinations that are either redundant or not indicative of coreference. For example, our atomic features already contain some combinations (e.g., NEStringMatch is a combination of MentionType Coarse and StringED). Without the reranking step, we are getting numerous combinations reflecting peculiarities in the feature design. As the final JIM output, we take all the sets I with the scores exceeding some predefined thresholds (score+(I) &gt; thr+ or score−(I) &gt; thr−). Note that our score measures are not monotone and cannot therefore be used in a fast Eclat-style algorithm (Borgelt, 2012) to directly provide scoreoptimal combinations. To better align our approach with the Entropy Guided Feature Induction framework presented below, we convert our item sets back to the sets of atomic features, abstracting away from the particular values used for binarization. The JIM-based feature induction algorithm relies on several parameters: the feature filtering thresh293 olds (for removing too rare or too common features), the minimal Jaccard index for the JIM algorithm and the thresholds thr+ and thr− for selecting good item sets after the reranking step. We fit these parameters on the d</context>
</contexts>
<marker>Borgelt, 2012</marker>
<rawString>Christian Borgelt. 2012. Frequent item set mining. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2(6):437–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Global joint models for coreference resolution and named entity classification.</title>
<date>2009</date>
<booktitle>In Procesamiento del Lenguaje Natural 42,</booktitle>
<publisher>SEPLN.</publisher>
<location>Barcelona:</location>
<contexts>
<context position="4618" citStr="Denis and Baldridge, 2009" startWordPosition="671" endWordPosition="674"> and iteratively con- lae and Nicolae (2006) and Bj¨orkelund and Farkas struct coreference partitions by merging coreference (2012). There are two important differences bechains (positive links) or blacklisting future merges tween these studies and the Easy-First Mention-Pair (negative links). This decoding strategy is slower model (EFMP): (i) EFMP does not evaluate links bethan the commonly used best-link model, but con- tween entities or clusters, always operating on mensiderably faster than ILP-based decoding (Finkel tion pairs instead; (ii) EFMP integrates both positive and Manning, 2008; Denis and Baldridge, 2009). and negative assignments in its hierarchy of easy-toSecond, we show that our approach, being very hard decisions. fast and easy to implement, can be used for a variety Being conceptually very simple, our algorithm alof low-level experiments on coreference resolution, lows for a straightforward integration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several rec</context>
<context position="32742" citStr="Denis and Baldridge, 2009" startWordPosition="5176" endWordPosition="5179"> to the state-of-the-art. At the same time, it’s much faster than more complex approaches. The vast majority of high-performance coreference resolution systems (in particular, the CoNLL-2012 winning algorithm by Fernandes et al. (2012)) rely on complex structural representations and are therefore slow at the training stage. Our system only needs a simple binary mention-pair classifier that can be trained very efficiently. Some highperformance approaches rely on the same classifier, postponing a heavy global inference step to the decoding stage, for example, through Integer Linear Programming (Denis and Baldridge, 2009; Finkel 296 development test v4 v4 v7 EFMP, all features, SVM none 60.02 59.12 55.38 EFI 61.66 60.75 57.56 JIM 62.53 61.82 59.14 Table 3: Feature combinations, JIM vs. EFI: MELA score, different versions of the CoNLL scorer. test v4 v7 1 fernandes 63.37 60.65 EFMP+JIM 61.82 59.14 2 martschat 61.31 57.68 3 bjorkelund 61.24 57.42 EFMP 59.12 55.38 4 chang 60.18 56.10 5 chen 59.69 54.52 Table 4: EFMP and top-5 CoNLL-2012 systems: MELA score, systems ranked by the v7 score on the test set. and Manning, 2008). While these systems have the same training requirements as EFMP, their decoding (ILP with</context>
</contexts>
<marker>Denis, Baldridge, 2009</marker>
<rawString>Pascal Denis and Jason Baldridge. 2009. Global joint models for coreference resolution and named entity classification. In Procesamiento del Lenguaje Natural 42, Barcelona: SEPLN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Easy victories and uphill battles in coreference resolution.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1971--1982</pages>
<marker>Durrett, Klein, 2013</marker>
<rawString>Greg Durrett and Dan Klein. 2013. Easy victories and uphill battles in coreference resolution. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1971–1982.</rawString>
</citation>
<citation valid="true">
<title>Eraldo Rezende Fernandes, Cicero Nogueira dos Santos, and Ruy Luiz Milidi´u.</title>
<date>2012</date>
<booktitle>In Joint Conference on EMNLP and CoNLL - Shared Task, CoNLL ’12,</booktitle>
<pages>41--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3956" citStr="(2012)" startWordPosition="578" endWordPosition="578">king into account—in contrast to the previous studies, e.g. (Ng and Cardie, 2002; Stoyanov and Eisner, 2012; Bj¨orkelund and Kuhn, 2014)—both positive and negative links. We 289 Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 289–298, Denver, Colorado, June 4–5, 2015. thus propose a procedure for propagating positive Our work has been motivated by more complex and negative links to create the final coreference algorithms using the easy-first strategy, most impartition: we start from the most confident among portantly, by Stoyanov and Eisner (2012), Nicoall the classifier’s decisions and iteratively con- lae and Nicolae (2006) and Bj¨orkelund and Farkas struct coreference partitions by merging coreference (2012). There are two important differences bechains (positive links) or blacklisting future merges tween these studies and the Easy-First Mention-Pair (negative links). This decoding strategy is slower model (EFMP): (i) EFMP does not evaluate links bethan the commonly used best-link model, but con- tween entities or clusters, always operating on mensiderably faster than ILP-based decoding (Finkel tion pairs instead; (ii) EFMP integrat</context>
<context position="6620" citStr="(2012)" startWordPosition="985" endWordPosition="985">still relies on the human experlabeled transactions. In this paper, we introduce a tise for creating meaningful combinations. Versley post-filtering technique to re-score JIM output w.r.t. et al. (2008) use kernel-based similarity as an imthe class labels (±coreferent). We show empirically plicit feature induction technique. that JIM is more suitable for coreference: it provides The only study we are aware of that investigates smaller and more meaningful feature combinations an explicit feature combination technique has been leading to a better performance level. conducted by Fernandes et al. (2012). Their alThe combination of our decoding approach with gorithm for Entropy-based feature induction (EFI), the JIM feature induction technique allows us to shows substantial improvement on the OntoNotes achieve a performance level of 61.82% on the dataset. In the present work, we propose an alCoNLL-2012 test data, just 1.5% percent below the ternative to EFI, based on the recent advances in (much more complex) winning system and above all Data Mining. We believe that Fernandes et al. the other submissions (cf. Table 4). (2012) have opened a very important research di2 Related work rection with</context>
<context position="13703" citStr="(2012)" startWordPosition="2118" endWordPosition="2118">ed knowledge of other entities (“car” and “Ferrari” in different parts of a document talking about Formula 1 may refer to different entities). We believe that forcing our pairwise classifier to learn a labeling for such “uninformative” examples without providing adequate features might lead to inferior performance. Our pre-filtering approach was inspired by the Stanford sieves algorithm (Lee et al., 2011), where several high-precision rules are applied in a specific order to filter out candidates. This approach has since then been used in several systems, most successfully by Fernandes et al. (2012) to filter out training data for coreference resolution classifiers. The idea of distinguishing between “informative” and “uninformative” instances has been implicitly adopted by many systems, restricting their search to a specific window. This approach is very common for pronominal anaphora, but it’s also used by several general-purpose coreference resolvers (Fernandes et al., 2012; Stoyanov and Eisner, 2012). All these rule-based decisions can be integrated into EFMP in a straightforward way. Thus, the uninformative pairs are simply excluded from the further processing. They do not produce t</context>
<context position="21448" citStr="(2012)" startWordPosition="3348" endWordPosition="3348">proach with the Entropy Guided Feature Induction framework presented below, we convert our item sets back to the sets of atomic features, abstracting away from the particular values used for binarization. The JIM-based feature induction algorithm relies on several parameters: the feature filtering thresh293 olds (for removing too rare or too common features), the minimal Jaccard index for the JIM algorithm and the thresholds thr+ and thr− for selecting good item sets after the reranking step. We fit these parameters on the development set. 4.2 Entropy Guided Feature Induction Fernandes et al. (2012) have proposed using Entropy Guided Feature Induction (EFI) for coreference resolution and have shown that it significantly improves the performance of their system. Below we provide a brief overview of the EFI approach, referring the reader to the original paper for further details. The system works at two stages, using two different machine learning techniques. At the first stage, the EFI algorithm relies on a decision tree, generated from the training data, to obtain meaningful feature combinations. In particular, the algorithm extracts all the paths leading from the root of the induced tre</context>
<context position="22709" citStr="(2012)" startWordPosition="3552" endWordPosition="3552">cific value assigned to some atomic feature and therefore each path corresponds to a conjunction of atomic features with assigned values. Fernandes et al. (2012) abstract over the values, thus, converting each path to a conjunction of atomic features. These conjunctions, or combinations, are then used to generate numerous binary features to be used by a linear classifier at the second stage. Since the induced tree might get very large, the EFI algorithm might lead to conjunctions of too many atomic features, generating, in turn, too many binary features. To address the issue, Fernandes et al. (2012) prune their tree at the depth 5. In our implementation, we follow the algorithm of Fernandes et al. (2012) with no adjustments or alterations. 5 Experiments Our first group of experiments assesses the quality of the baseline setting, with no feature combination techniques. We compare against the CoNLL submission of the BART group to make sure that our (Soon et al., 2001)-style mention-pair baseline shows an acceptable performance. We then evaluate the EFMP approach to confirm that it provides much higher performance figures and is on par with the state of the art. In our second experiment, we</context>
<context position="26170" citStr="(2012)" startWordPosition="4089" endWordPosition="4089">4 v7 BART CoNLL-2012 submission - 56.12 50.02 simplified reimplemented BART submission WEKA (j48) 56.02 55.84 49.83 SVM (Liblinear) 48.31 47.29 39.17 -*-, all features WEKA (j48) 56.53 55.98 49.84 SVM (Liblinear) 49.83 48.11 40.04 best-link, all features SVM (Liblinear) 59.71 59.03 55.21 EFMP, features from BART submission SVM (Liblinear) 57.40 56.16 50.65 EFMP, all features SVM (Liblinear) 60.02 59.12 55.38 Table 2: Baseline performance vs. plain EFMP: MELA score, different versions of the CoNLL scorer. module, we have started with the original sieves and the version used by Fernandes et al. (2012). We have changed some sieves and introduced several additional filters (cf. Table 1). 5.2 Baselines vs. EFMP Table 2 shows the performance levels for different baseline algorithms, learners and features on both CoNLL-2012 development and test sets. Note that the development set was used for parameter tuning and does not therefore provide an accurate estimation of the system’s performance. The results suggest that our simplified version of the BART CONLL-2012 system can be considered an adequate starting point: it only shows a very minor performance drop, compared to the original submission (w</context>
<context position="29211" citStr="(2012)" startWordPosition="4589" endWordPosition="4589">pared to (Soon et al., 2001), since it relies on the most confident positive links. The EFMP decoder, however, brings a further improvement, by incorporating and propagating information on confident negative links as well. 5.3 Feature combinations In our second experiment, we investigate the applicability of JIM to coreference resolution, comparing it against EFI. The latter has been proven to yield a performance gain of up to 10%, leading to a system, significantly outperforming all the other competitors at the CoNLL-2012 shared task. While the impact of EFI on the system of Fernandes et al. (2012) cannot be underestimated, the following points need further clarifications: (a) the algorithm of Fernandes et al. (2012) shows only very moderate performance without EFI—it is not yet clear if EFI is equally beneficial for more competitive approaches; and (b) the system of Fernandes et al. (2012) relies on a relatively complex model—it is not clear how modelspecific the benefits of EFI are. 295 Confidently negative Expletive Mi or Mj is an expletive pronoun Span one mention spans over the other Agreement Mi and Mj disagree in number, gender or semantic class Syntax Mi and Mj violate contra in</context>
<context position="32352" citStr="(2012)" startWordPosition="5119" endWordPosition="5119">rmance level of the EFMP approach, plain and enhanced with the JIMbased feature induction module, against the top 5 CoNLL-2012 systems on the CoNLL-2012 test set. As the results show, the EFMP approach achieves Figure 1: Normalized combination length for JIM and EFI: number of induced sets of size 1..9, 10+ divided by the total number of induced sets results comparable to the state-of-the-art. At the same time, it’s much faster than more complex approaches. The vast majority of high-performance coreference resolution systems (in particular, the CoNLL-2012 winning algorithm by Fernandes et al. (2012)) rely on complex structural representations and are therefore slow at the training stage. Our system only needs a simple binary mention-pair classifier that can be trained very efficiently. Some highperformance approaches rely on the same classifier, postponing a heavy global inference step to the decoding stage, for example, through Integer Linear Programming (Denis and Baldridge, 2009; Finkel 296 development test v4 v4 v7 EFMP, all features, SVM none 60.02 59.12 55.38 EFI 61.66 60.75 57.56 JIM 62.53 61.82 59.14 Table 3: Feature combinations, JIM vs. EFI: MELA score, different versions of th</context>
</contexts>
<marker>2012</marker>
<rawString>Eraldo Rezende Fernandes, Cicero Nogueira dos Santos, and Ruy Luiz Milidi´u. 2012. Latent structure perceptron with feature induction for unrestricted coreference resolution. In Joint Conference on EMNLP and CoNLL - Shared Task, CoNLL ’12, pages 41–48, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Enforcing transitivity in coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>45--48</pages>
<contexts>
<context position="33547" citStr="Finkel and Manning, 2008" startWordPosition="5311" endWordPosition="5314">core, different versions of the CoNLL scorer. test v4 v7 1 fernandes 63.37 60.65 EFMP+JIM 61.82 59.14 2 martschat 61.31 57.68 3 bjorkelund 61.24 57.42 EFMP 59.12 55.38 4 chang 60.18 56.10 5 chen 59.69 54.52 Table 4: EFMP and top-5 CoNLL-2012 systems: MELA score, systems ranked by the v7 score on the test set. and Manning, 2008). While these systems have the same training requirements as EFMP, their decoding (ILP with binary variables) is known to be NPcomplete. In practice, ILP-based approaches incorporating any forms of global modeling via transitivity constraints (Denis and Baldridge, 2009; Finkel and Manning, 2008) are known to be particularly slow. Our simple decoding algorithm runs in O(p * log(p)), where p is the total number of mention pairs: for the plain EFMP, p = n * (n − 1)/2, for the EFMP with sieves, p = const*n, where n is the number of mentions in the document. 6 Conclusion In this study, we advocate an easy-first mention-pair model (EFMP). This approach combines the simplicity of mention-pair models with the high performance level of state-of-the-art systems. We believe that several research lines are open in the field of coreference resolution, ours being simple and allowing to focus more </context>
</contexts>
<marker>Finkel, Manning, 2008</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 45–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamidreza Kobdani</author>
<author>Hinrich Sch¨utze</author>
<author>Andre Burkovski</author>
<author>Wiltrud Kessler</author>
<author>Gunther Heidemann</author>
</authors>
<title>Relational feature engineering of natural language processing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>1705--1708</pages>
<marker>Kobdani, Sch¨utze, Burkovski, Kessler, Heidemann, 2010</marker>
<rawString>Hamidreza Kobdani, Hinrich Sch¨utze, Andre Burkovski, Wiltrud Kessler, and Gunther Heidemann. 2010. Relational feature engineering of natural language processing. In Proceedings of the 19th ACM Conference on Information and Knowledge Management (CIKM), pages 1705–1708.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, CONLL Shared Task ’11,</booktitle>
<pages>28--34</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5133" citStr="Lee et al., 2011" startWordPosition="751" endWordPosition="754">l tion pairs instead; (ii) EFMP integrates both positive and Manning, 2008; Denis and Baldridge, 2009). and negative assignments in its hierarchy of easy-toSecond, we show that our approach, being very hard decisions. fast and easy to implement, can be used for a variety Being conceptually very simple, our algorithm alof low-level experiments on coreference resolution, lows for a straightforward integration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted exing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009; the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Durbefore, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng, edge, has never been applied to any NLP task. The 2010) for an overview of different feat</context>
<context position="8048" citStr="Lee et al., 2011" startWordPosition="1210" endWordPosition="1213">r model—and compare Ng and Cardie (2002). Their “best-link” algo- it to our approach. rithm picks the most confident antecedent for each 3 Easy-First Mention-Pair Model anaphor. Unlike Ng and Cardie (2002), we do not In what follows, we describe our Easy-First process the input text from left to right incremen- Mention-Pair (EFMP) approach and then propose tally, instead, we assess the confidence of all the pro- a solution for combining our model with manuposed links at the same time (“easy-first”) and keep ally engineered filters, inspired by Stanford “sieves” track of negative assignments. (Lee et al., 2011). EFMP is a decoding algorithm. 290 Algorithm 1 Easy-first decoding (EFMP) Require: L = {&lt; anal, antel, labell, confidencel &gt;}: list of classified mention pairs 1: sort L according to confidence 2: for all l E L do 3: /* don’t override prev. decisions */ 4: if chain(anal) == chain(antel) then 5: continue 6: if unlinked(chain(anal), chain(antel)) then 7: continue 8: /* update chains and unlink info */ 9: if labell==not-coreferent then 10: unlink(chain(anal), chain(antel)) 11: if labell==coreferent then 12: UpdateUnlinkInfo({chain(anal), chain(antel)) 13: MergeChains({chain(anal), chain(antel)) </context>
<context position="13505" citStr="Lee et al., 2011" startWordPosition="2083" endWordPosition="2086">ing on a lot of factors, starting from the semantic compatibility of the two mentions (“car” and “relativity” can hardly be coreferent), but also including discourse-related factors and some suitably represented knowledge of other entities (“car” and “Ferrari” in different parts of a document talking about Formula 1 may refer to different entities). We believe that forcing our pairwise classifier to learn a labeling for such “uninformative” examples without providing adequate features might lead to inferior performance. Our pre-filtering approach was inspired by the Stanford sieves algorithm (Lee et al., 2011), where several high-precision rules are applied in a specific order to filter out candidates. This approach has since then been used in several systems, most successfully by Fernandes et al. (2012) to filter out training data for coreference resolution classifiers. The idea of distinguishing between “informative” and “uninformative” instances has been implicitly adopted by many systems, restricting their search to a specific window. This approach is very common for pronominal anaphora, but it’s also used by several general-purpose coreference resolvers (Fernandes et al., 2012; Stoyanov and Ei</context>
<context position="25308" citStr="Lee et al., 2011" startWordPosition="3958" endWordPosition="3961">he LibLinear SVM package, to get a classifier outputting reliable confidence values, as needed by EFMP. We have considerably expanded the feature set, mainly reimplementing features from the winning system of CoNLL-2012 (Fernandes et al., 2012). Altogether, we have around 170 individual features (string, nominal or binary values), corresponding to around 20k features after the binarization step. The full list of our feature templates can be found at http://bart-coref.eu/papers/ sem15-suppl.pdf. Finally, we have augmented BART with a rulebased prefiltering module, motivated by Stanford Sieves (Lee et al., 2011), the winning approach of the CoNLL-2011 shared task. Our sieve-style prefiltering algorithm splits all the training instances into confidently positive, confidently negative, irrelevant and relevant. To implement the prefiltering 294 development test v4 v4 v7 BART CoNLL-2012 submission - 56.12 50.02 simplified reimplemented BART submission WEKA (j48) 56.02 55.84 49.83 SVM (Liblinear) 48.31 47.29 39.17 -*-, all features WEKA (j48) 56.53 55.98 49.84 SVM (Liblinear) 49.83 48.11 40.04 best-link, all features SVM (Liblinear) 59.71 59.03 55.21 EFMP, features from BART submission SVM (Liblinear) 57.</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, CONLL Shared Task ’11, pages 28–34, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="1580" citStr="Ng and Cardie, 2002" startWordPosition="220" endWordPosition="223">performance level of up to 61.82% (MELA F, v4 scorer) on the CoNLL test data, on par with complex state-of-the-art systems. 1 Introduction The mention-pair model, as proposed by Soon et al. (2001) has been used for over a decade now. It combines a simple classifier trained to discriminate between coreferent and not-coreferent pairs of mentions (“links”) with fast heuristic procedures for merging the classifier’s decisions at the decoding stage. Several decoding heuristics have been advocated in the literature, the most commonly used ones including first-link (Soon et al., 2001) and best-link (Ng and Cardie, 2002). Most state-of-the-art algorithms for coreference resolution, on the contrary, rely on complex modeling, ranging from entity-ranking to structural perceptron and other graph-based approaches (for an overview of state-of-the-art coreference resolvers, see (Ng, 2010; Pradhan et al., 2012)). Such algorithms show a clearly superior performance: thus, at the CoNLL-2012 shared task, the best-performing (Soon et al., 2001)-style system loses around 8% to the winning algorithm. However, more traditional mention-pair approaches still have some important advantages. Thus, a mention-pair model is easy t</context>
<context position="3430" citStr="Ng and Cardie, 2002" startWordPosition="497" endWordPosition="500">per, we advocate a new easy-first mention-pair algorithm (EFMP): while it is based solely on pairs of mentions and does not attempt any global inference, it benefits from the decision propagation strategy to create a coreference partition. Augmented with the sieve-style prefiltering, the system achieves a performance level comparable to the state of the art. The contribution of this paper is two-fold. First, we propose a novel decoding approach that combines predictions of the mention-pair classifier based on its confidence score, taking into account—in contrast to the previous studies, e.g. (Ng and Cardie, 2002; Stoyanov and Eisner, 2012; Bj¨orkelund and Kuhn, 2014)—both positive and negative links. We 289 Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 289–298, Denver, Colorado, June 4–5, 2015. thus propose a procedure for propagating positive Our work has been motivated by more complex and negative links to create the final coreference algorithms using the easy-first strategy, most impartition: we start from the most confident among portantly, by Stoyanov and Eisner (2012), Nicoall the classifier’s decisions and iteratively con- lae and Nicolae </context>
<context position="7471" citStr="Ng and Cardie (2002)" startWordPosition="1118" endWordPosition="1121">of 61.82% on the dataset. In the present work, we propose an alCoNLL-2012 test data, just 1.5% percent below the ternative to EFI, based on the recent advances in (much more complex) winning system and above all Data Mining. We believe that Fernandes et al. the other submissions (cf. Table 4). (2012) have opened a very important research di2 Related work rection with their feature induction approach. We An improvement over the original mention-pair want therefore to evaluate EFI in a simpler and more model (Soon et al., 2001) has been proposed by straightforward mention-pair model—and compare Ng and Cardie (2002). Their “best-link” algo- it to our approach. rithm picks the most confident antecedent for each 3 Easy-First Mention-Pair Model anaphor. Unlike Ng and Cardie (2002), we do not In what follows, we describe our Easy-First process the input text from left to right incremen- Mention-Pair (EFMP) approach and then propose tally, instead, we assess the confidence of all the pro- a solution for combining our model with manuposed links at the same time (“easy-first”) and keep ally engineered filters, inspired by Stanford “sieves” track of negative assignments. (Lee et al., 2011). EFMP is a decoding al</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1396--1411</pages>
<contexts>
<context position="1845" citStr="Ng, 2010" startWordPosition="257" endWordPosition="258">discriminate between coreferent and not-coreferent pairs of mentions (“links”) with fast heuristic procedures for merging the classifier’s decisions at the decoding stage. Several decoding heuristics have been advocated in the literature, the most commonly used ones including first-link (Soon et al., 2001) and best-link (Ng and Cardie, 2002). Most state-of-the-art algorithms for coreference resolution, on the contrary, rely on complex modeling, ranging from entity-ranking to structural perceptron and other graph-based approaches (for an overview of state-of-the-art coreference resolvers, see (Ng, 2010; Pradhan et al., 2012)). Such algorithms show a clearly superior performance: thus, at the CoNLL-2012 shared task, the best-performing (Soon et al., 2001)-style system loses around 8% to the winning algorithm. However, more traditional mention-pair approaches still have some important advantages. Thus, a mention-pair model is easy to implement and allows for fast prototyping. It relies on a simple binary classifier making it very fast to train compared to state-of-the-art models that are based on complex structural representations (Fernandes et al., 2012; Bj¨orkelund and Kuhn, 2014). This eff</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Vincent Ng. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1396–1411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
</authors>
<title>Bestcut: A graph algorithm for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06,</booktitle>
<pages>275--283</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Cristina Nicolae and Gabriel Nicolae. 2006. Bestcut: A graph algorithm for coreference resolution. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 275–283, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>CoNLL2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL’12),</booktitle>
<location>Jeju,</location>
<contexts>
<context position="1868" citStr="Pradhan et al., 2012" startWordPosition="259" endWordPosition="262">te between coreferent and not-coreferent pairs of mentions (“links”) with fast heuristic procedures for merging the classifier’s decisions at the decoding stage. Several decoding heuristics have been advocated in the literature, the most commonly used ones including first-link (Soon et al., 2001) and best-link (Ng and Cardie, 2002). Most state-of-the-art algorithms for coreference resolution, on the contrary, rely on complex modeling, ranging from entity-ranking to structural perceptron and other graph-based approaches (for an overview of state-of-the-art coreference resolvers, see (Ng, 2010; Pradhan et al., 2012)). Such algorithms show a clearly superior performance: thus, at the CoNLL-2012 shared task, the best-performing (Soon et al., 2001)-style system loses around 8% to the winning algorithm. However, more traditional mention-pair approaches still have some important advantages. Thus, a mention-pair model is easy to implement and allows for fast prototyping. It relies on a simple binary classifier making it very fast to train compared to state-of-the-art models that are based on complex structural representations (Fernandes et al., 2012; Bj¨orkelund and Kuhn, 2014). This efficiency at the training</context>
<context position="23552" citStr="Pradhan et al., 2012" startWordPosition="3689" endWordPosition="3692">ine setting, with no feature combination techniques. We compare against the CoNLL submission of the BART group to make sure that our (Soon et al., 2001)-style mention-pair baseline shows an acceptable performance. We then evaluate the EFMP approach to confirm that it provides much higher performance figures and is on par with the state of the art. In our second experiment, we use EFMP to assess the impact of the feature combination techniques on the performance of a coreference resolution system. 5.1 Experimental Setup We evaluate our approach on the English portion of the CoNLL-2012 dataset (Pradhan et al., 2012). To asses the system’s performance, we use the official scorer, provided by the CoNLL organizers. However, the version used at the competition time (v4) was later found to contain errors and replaced with another implementation (v7). This procedure resulted in a performance drop for all the systems, but didn’t affect their ranking. To facilitate comparison against previous and future studies, we report both v4 and v7 MELA scores. All the experiments are performed on automatically extracted mentions and use no gold information. For our study, we use the publicly available BART toolkit (Uryupin</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. CoNLL2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes. In Proceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL’12), Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Eduard Hovy</author>
</authors>
<title>A deeper look into features for coreference resolution.</title>
<date>2009</date>
<booktitle>In Anaphora Processing and Applications (DAARC</booktitle>
<contexts>
<context position="5446" citStr="Recasens and Hovy, 2009" startWordPosition="797" endWordPosition="800"> algorithm alof low-level experiments on coreference resolution, lows for a straightforward integration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted exing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009; the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Durbefore, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng, edge, has never been applied to any NLP task. The 2010) for an overview of different features. KobJIM algorithm has been developed within the data dani et al. (2010) create a framework that facilitates mining community and aims at finding combina- the engineering process for complex features. This tions that tend to occur in a particular set of un- approach, however, still relies on the human experl</context>
</contexts>
<marker>Recasens, Hovy, 2009</marker>
<rawString>Marta Recasens and Eduard Hovy. 2009. A deeper look into features for coreference resolution. In Anaphora Processing and Applications (DAARC 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Segond</author>
<author>Christian Borgelt</author>
</authors>
<title>Item set mining based on cover similarity.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD</booktitle>
<contexts>
<context position="5277" citStr="Segond and Borgelt, 2011" startWordPosition="772" endWordPosition="775">hierarchy of easy-toSecond, we show that our approach, being very hard decisions. fast and easy to implement, can be used for a variety Being conceptually very simple, our algorithm alof low-level experiments on coreference resolution, lows for a straightforward integration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted exing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009; the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Durbefore, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng, edge, has never been applied to any NLP task. The 2010) for an overview of different features. KobJIM algorithm has been developed within the data dani et al. (2010) create a framework that facilitates mining community and aims at fi</context>
<context position="17103" citStr="Segond and Borgelt, 2011" startWordPosition="2631" endWordPosition="2634"> of mentions). Some features are very frequent (mention types), whereas others are relatively rare (apposition). Finally, some features encode basic properties (“anaphor is a pronoun”), whereas others are combinations of such properties (“both anaphor and antecedent are pronouns and they have the same surface form”). Therefore, we specifically aim at designing an algo292 rithm that is able to overcome these idiosyncrasies and provide meaningful combinations for such a heterogeneous set of atomic features. 4.1 Jaccard Item Mining In this study, we adapt the Jaccard Item Mining (JIM) technique (Segond and Borgelt, 2011) to the coreference resolution task. Below we describe the JIM algorithm and our adjustment of JIM to the task of selecting meaningful features. The Data Mining community has invested substantial efforts into Frequent Item Mining algorithms: techniques for finding frequent combinations of “items” in a “transaction database”. We assume that a database is a set of item sets with some items often appearing together. Several approaches have been proposed to solve the task of enumerating all such frequently occurring combinations in a fast and efficient way, the most popular ones being Eclat and FP</context>
</contexts>
<marker>Segond, Borgelt, 2011</marker>
<rawString>Marc Segond and Christian Borgelt. 2011. Item set mining based on cover similarity. In Proceedings of the 15th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistic,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1156" citStr="Soon et al. (2001)" startWordPosition="155" endWordPosition="158">considerably outperform popular basic approaches, in particular mention-pair models. This study advocates a novel approach that keeps the simplicity of a mention-pair framework, while showing state-of-the-art results. Apart from being very efficient and straightforward to implement, our model facilitates experimental work on the pairwise classifier, in particular on feature engineering. The proposed model achieves the performance level of up to 61.82% (MELA F, v4 scorer) on the CoNLL test data, on par with complex state-of-the-art systems. 1 Introduction The mention-pair model, as proposed by Soon et al. (2001) has been used for over a decade now. It combines a simple classifier trained to discriminate between coreferent and not-coreferent pairs of mentions (“links”) with fast heuristic procedures for merging the classifier’s decisions at the decoding stage. Several decoding heuristics have been advocated in the literature, the most commonly used ones including first-link (Soon et al., 2001) and best-link (Ng and Cardie, 2002). Most state-of-the-art algorithms for coreference resolution, on the contrary, rely on complex modeling, ranging from entity-ranking to structural perceptron and other graph-b</context>
<context position="7382" citStr="Soon et al., 2001" startWordPosition="1106" endWordPosition="1109">llows us to shows substantial improvement on the OntoNotes achieve a performance level of 61.82% on the dataset. In the present work, we propose an alCoNLL-2012 test data, just 1.5% percent below the ternative to EFI, based on the recent advances in (much more complex) winning system and above all Data Mining. We believe that Fernandes et al. the other submissions (cf. Table 4). (2012) have opened a very important research di2 Related work rection with their feature induction approach. We An improvement over the original mention-pair want therefore to evaluate EFI in a simpler and more model (Soon et al., 2001) has been proposed by straightforward mention-pair model—and compare Ng and Cardie (2002). Their “best-link” algo- it to our approach. rithm picks the most confident antecedent for each 3 Easy-First Mention-Pair Model anaphor. Unlike Ng and Cardie (2002), we do not In what follows, we describe our Easy-First process the input text from left to right incremen- Mention-Pair (EFMP) approach and then propose tally, instead, we assess the confidence of all the pro- a solution for combining our model with manuposed links at the same time (“easy-first”) and keep ally engineered filters, inspired by S</context>
<context position="15477" citStr="Soon et al. (2001)" startWordPosition="2391" endWordPosition="2394">ta. At the test step, they are considered to be very confidently positive/negative instances, outscoring any test pairs, originating from the classifier output. Such pairs do not contribute to speeding up the EFMP part, however, they help improve the quality of our pairwise classifier, decreasing the bias towards negative instances in the data. 4 Techniques for generating feature combinations Most state-of-the-art coreference resolution systems combine complex modeling with rich feature sets. While early data-driven approaches were essentially knowledge-poor (for example, the famous system of Soon et al. (2001) is based on 12 shallow features), modern algorithms rely on dozens of carefully engineered features, encoding various clues relevant for the task: from different measures of surface similarity, to morphological, syntactic, semantic and discourse properties, and world knowledge. This study focuses on the automatic feature engineering task. We start from atomic features that are already encoded in a state-of-the-art toolkit (BART) and use a data mining technique, Jaccard item mining, to boost the system performance through automatic induction of complex features. The features used by most coref</context>
<context position="23083" citStr="Soon et al., 2001" startWordPosition="3613" endWordPosition="3616"> classifier at the second stage. Since the induced tree might get very large, the EFI algorithm might lead to conjunctions of too many atomic features, generating, in turn, too many binary features. To address the issue, Fernandes et al. (2012) prune their tree at the depth 5. In our implementation, we follow the algorithm of Fernandes et al. (2012) with no adjustments or alterations. 5 Experiments Our first group of experiments assesses the quality of the baseline setting, with no feature combination techniques. We compare against the CoNLL submission of the BART group to make sure that our (Soon et al., 2001)-style mention-pair baseline shows an acceptable performance. We then evaluate the EFMP approach to confirm that it provides much higher performance figures and is on par with the state of the art. In our second experiment, we use EFMP to assess the impact of the feature combination techniques on the performance of a coreference resolution system. 5.1 Experimental Setup We evaluate our approach on the English portion of the CoNLL-2012 dataset (Pradhan et al., 2012). To asses the system’s performance, we use the official scorer, provided by the CoNLL organizers. However, the version used at the</context>
<context position="26910" citStr="Soon et al., 2001" startWordPosition="4206" endWordPosition="4209">s the performance levels for different baseline algorithms, learners and features on both CoNLL-2012 development and test sets. Note that the development set was used for parameter tuning and does not therefore provide an accurate estimation of the system’s performance. The results suggest that our simplified version of the BART CONLL-2012 system can be considered an adequate starting point: it only shows a very minor performance drop, compared to the original submission (we believe that this drop can be attributed to the simpler no-split architecture that we are adopting in this study). The (Soon et al., 2001)-style mention-pair model, however, suffers from several problems. First of all, its performance is simply not good enough: thus, the winners of the CoNLL2012 shared task reported a v4 score of 63.37 on the test data. With a v4 score of 55.84, our system would have achieved the 12th place in the competition (out of 15+1). Second, this approach only works with the decision tree-based classifier: with SVMs, the performance gets much lower. We believe that this can be caused by several factors: (a) decision trees perform some sort of feature combinations, whereas Liblinear only relies on a sum of</context>
<context position="28633" citStr="Soon et al., 2001" startWordPosition="4494" endWordPosition="4497">MP model, on the contrary, shows promising performance figures. With an F-score of 59.12, the system would have achieved the 8th place in the CoNLL-2012 competition, within the cluster of very similarly performing systems on places 2–8(9). It must be stressed that EFMP is a very simple and fast algorithm, much less complex than any of the highperforming CoNLL systems. We have also evaluated EFMP against a mentionpair model with the same sieve-style prefiltering and a best-link decoder (Table 2, row 6). As the results suggest, the best-link decoder shows a better performance level compared to (Soon et al., 2001), since it relies on the most confident positive links. The EFMP decoder, however, brings a further improvement, by incorporating and propagating information on confident negative links as well. 5.3 Feature combinations In our second experiment, we investigate the applicability of JIM to coreference resolution, comparing it against EFI. The latter has been proven to yield a performance gain of up to 10%, leading to a system, significantly outperforming all the other competitors at the CoNLL-2012 shared task. While the impact of EFI on the system of Fernandes et al. (2012) cannot be underestima</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistic, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Jason Eisner</author>
</authors>
<title>Easy-first coreference resolution.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>2519--2534</pages>
<contexts>
<context position="3457" citStr="Stoyanov and Eisner, 2012" startWordPosition="501" endWordPosition="504">w easy-first mention-pair algorithm (EFMP): while it is based solely on pairs of mentions and does not attempt any global inference, it benefits from the decision propagation strategy to create a coreference partition. Augmented with the sieve-style prefiltering, the system achieves a performance level comparable to the state of the art. The contribution of this paper is two-fold. First, we propose a novel decoding approach that combines predictions of the mention-pair classifier based on its confidence score, taking into account—in contrast to the previous studies, e.g. (Ng and Cardie, 2002; Stoyanov and Eisner, 2012; Bj¨orkelund and Kuhn, 2014)—both positive and negative links. We 289 Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 289–298, Denver, Colorado, June 4–5, 2015. thus propose a procedure for propagating positive Our work has been motivated by more complex and negative links to create the final coreference algorithms using the easy-first strategy, most impartition: we start from the most confident among portantly, by Stoyanov and Eisner (2012), Nicoall the classifier’s decisions and iteratively con- lae and Nicolae (2006) and Bj¨orkelund and </context>
<context position="14116" citStr="Stoyanov and Eisner, 2012" startWordPosition="2174" endWordPosition="2177">e et al., 2011), where several high-precision rules are applied in a specific order to filter out candidates. This approach has since then been used in several systems, most successfully by Fernandes et al. (2012) to filter out training data for coreference resolution classifiers. The idea of distinguishing between “informative” and “uninformative” instances has been implicitly adopted by many systems, restricting their search to a specific window. This approach is very common for pronominal anaphora, but it’s also used by several general-purpose coreference resolvers (Fernandes et al., 2012; Stoyanov and Eisner, 2012). All these rule-based decisions can be integrated into EFMP in a straightforward way. Thus, the uninformative pairs are simply excluded from the further processing. They do not produce training material and they are not processed by EFMP at the test time (consequently, mentions from such a pair may end up in the same cluster, as well as in two different ones, depending on other (un)links established by the system). This allows for a substantial reduction of the pairs to be processed at the decoding step (for example, in our setting described in Section 5.1 below, around 90% of all the pairs a</context>
</contexts>
<marker>Stoyanov, Eisner, 2012</marker>
<rawString>Veselin Stoyanov and Jason Eisner. 2012. Easy-first coreference resolution. In Proceedings of the 24th International Conference on Computational Linguistics (COLING), pages 2519–2534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Uryupina</author>
<author>Alessandro Moschitti</author>
<author>Massimo Poesio</author>
</authors>
<title>BART goes multilingual: The UniTN / Essex submission to the CoNLL-2012 Shared Task.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL’12).</booktitle>
<contexts>
<context position="24167" citStr="Uryupina et al., 2012" startWordPosition="3787" endWordPosition="3790">, 2012). To asses the system’s performance, we use the official scorer, provided by the CoNLL organizers. However, the version used at the competition time (v4) was later found to contain errors and replaced with another implementation (v7). This procedure resulted in a performance drop for all the systems, but didn’t affect their ranking. To facilitate comparison against previous and future studies, we report both v4 and v7 MELA scores. All the experiments are performed on automatically extracted mentions and use no gold information. For our study, we use the publicly available BART toolkit (Uryupina et al., 2012). We have made several adjustments, starting from the configuration, suggested in the BART distribution for the OntoNotes/CoNLL data. Thus, we have modified the mention detection module, improving the treatment of coordinations and eliminating numeric named entities (PERCENT, MONEY etc). We have replaced the original split architecture with a single-classifier approach to be able to estimate the impact of our feature combination techniques in a more principled way. We have also replaced Decision Trees (Weka J48) with the LibLinear SVM package, to get a classifier outputting reliable confidence</context>
</contexts>
<marker>Uryupina, Moschitti, Poesio, 2012</marker>
<rawString>Olga Uryupina, Alessandro Moschitti, and Massimo Poesio. 2012. BART goes multilingual: The UniTN / Essex submission to the CoNLL-2012 Shared Task. In Proceedings of the Sixteenth Conference on Computational Natural Language Learning (CoNLL’12).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Uryupina</author>
</authors>
<title>Coreference resolution with and without linguistic knowledge.</title>
<date>2006</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC’06).</booktitle>
<contexts>
<context position="5514" citStr="Uryupina, 2006" startWordPosition="809" endWordPosition="810">traightforward integration of other techin particular, for studies on feature engineering or niques proposed in the literature, in particular, sieveselection. Thus, we augment our system with two style prefiltering (Lee et al., 2011) and feature infeature combination techniques, Jaccard Item Min- duction. Several recent studies have attempted exing (Segond and Borgelt, 2011) and Entropy Guided haustive analysis of features and their impact on Feature Inductions (Fernandes et al., 2012). While the overall performance (Recasens and Hovy, 2009; the latter has been used for coreference resolution Uryupina, 2006; Bengtson and Roth, 2008; Durbefore, Jaccard Item Mining (JIM), to our knowl- rett and Klein, 2013). We refer the reader to (Ng, edge, has never been applied to any NLP task. The 2010) for an overview of different features. KobJIM algorithm has been developed within the data dani et al. (2010) create a framework that facilitates mining community and aims at finding combina- the engineering process for complex features. This tions that tend to occur in a particular set of un- approach, however, still relies on the human experlabeled transactions. In this paper, we introduce a tise for creating</context>
</contexts>
<marker>Uryupina, 2006</marker>
<rawString>Olga Uryupina. 2006. Coreference resolution with and without linguistic knowledge. In Proceedings of the Language Resources and Evaluation Conference (LREC’06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Alessandro Moschitti</author>
<author>Massimo Poesio</author>
<author>Xiaofeng Yang</author>
</authors>
<title>Coreference systems based on kernels methods.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>961--968</pages>
<marker>Versley, Moschitti, Poesio, Yang, 2008</marker>
<rawString>Yannick Versley, Alessandro Moschitti, Massimo Poesio, and Xiaofeng Yang. 2008. Coreference systems based on kernels methods. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 961–968.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>