<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005225">
<note confidence="0.556934">
The hyperonym problem revisited:
Conceptual and lexical hierarchies.in language• generation
</note>
<author confidence="0.956528">
Manfred Stede
</author>
<affiliation confidence="0.809177666666667">
Technical University of Berlin
Dept. of Computer Science
KIT Project Group
</affiliation>
<address confidence="0.79399">
10587 Berlin/Germany
</address>
<email confidence="0.855643">
stedefts.tu-berlin.de
</email>
<sectionHeader confidence="0.976822" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999808857142857">
When a lexical item is selected in the language
production process, it needs to be explained
why none of its superordinates gets selected in-
stead, since their applicability conditions are
fulfilled all the same. This question has received
much attention in cognitive modelling and not
as much in other branches of NLG. This pa-
per describes the various approaches taken, dis-
cusses the reasons why they are so different, and
argues that production models using symbolic
representations should make a distinction be-
tween conceptual and lexical hierarchies, which
can be organized along fixed levels as studied in
(some branches of) lexical semantics.
</bodyText>
<sectionHeader confidence="0.995518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989705581818182">
Representations used in language processing
owe much to the tradition of &apos;semantic net-
works&apos;, which nowadays have been successfully
formalized and organized especially around one
particular kind of link between nodes: the ISA-
link, which connects entities to subordinate en-
tities. This link is, by definition, the root of
the so-called &apos;hyperonymi problem&apos;: When a
speaker utters a. word, she presumably needs
to retrieve a lemma from her mental lexicon,
and the &apos;applicability conditions of the lemma
automatically render the lemma&apos;s hyperonyms
also applicable, thus raising the question how
the choice among a set of more or less specific
words is made.
In this paper, I briefly review approaches
to the hyperonym _problem in psycholinguis-
tics, natural language generation, and lexical
semantics. In doing that, I will refer to differ-
ent branches of NLG according to their roots
&apos;Alternatively called &apos;hypernvin&apos; in many pul31ica-
lions; &apos;hyperonym&apos; seems preferable. as the Greek root
is &apos;hyper&apos; (super) 01101Ild: (name).
and main motivations. Generally acknowl-
edged are the two poles of &apos;cognition-inspired&apos;
and &apos;engineering-inspired&apos; language production:
Cognition-inspired work (CI-NLG, for short)
seeks to build models that replicate perfor-
mance data and explain phenomena of human
language production with the help of psycholog-
ical experiments; engineering-inspired work (El-
NLG) seeks to build programs that provide lin-
guistic output to some particular computer ap-
plication. These goals are extremely different,
and it seems that the gap between the respec-
tive methodologies will persist for quite some
time. In between the two, however, I would
situate a third category, which may be called
&apos;linguistics-inspired&apos;. For this branch, here ab-
breviated as LI-NLG, the primary motivation
is neither in modelling human performance nor
in efficiently performing a technical application;
rather, LI-NLG seeks production models that
replicate &apos;competence data&apos;, i.e. that account for
observed linguistic regularities, without com-
miting to statements about the human produc-
tion process.
Arguing that progress hinges on a better un-
derstanding of the structure of the mental vo-
cabulary, which includes a clear picture of the
nature of the ISA-link, I will sketch a framework
of distinct (but related) conceptual and lexical
hierarchies, which offers possibilities to account
for at least some of the phenomena to be dis-
cussed.
</bodyText>
<sectionHeader confidence="0.963645" genericHeader="method">
2 The hyperonym.problem
</sectionHeader>
<bodyText confidence="0.998935333333333">
Following the psycholinguistics literature, the
hyperonym problem is regarded as an aspect of
lemma retrieval. Roelofs [1996, p. 308] describes
a &apos;lemma&apos; as a representation of the meaning
and the syntactic properties of a word, and the
task of lemma retrieval as a crucial step in the
</bodyText>
<page confidence="0.997967">
93
</page>
<bodyText confidence="0.999795228070175">
process of grammatical encoding, where build-
ing of a phrasal, clausal, or sentential structure
requires the syntactic-information that lemmas
CO ntain.
Thus abstracting from the other steps of lan-
guage production (formulation, articulation) as
well as from possible influences of context, the
task is confined to retrieve a lemma that cor-
responds to the conceptual specification that
is represented in some adequate way. For the
psycholinguist, the general problem is that of
convergence from an under-specified conceptual
representation to one word that the speaker ut-
ters. Levelt [1989, p. 201] characterizes the by-
peronyin problem:
&amp;quot;There is one particularly nasty con-
vergence problem that has not been
solved by any theory of lexical access.
I will call it the hyperonyrn problem
[...]: When lemma A&apos;s meaning entails
lemma B&apos;s meaning, B is a hyperonym
of A. If A&apos;s conceptual conditions are
met, then B&apos;s are necessarily also satis-
fied. Hence, if A is the correct lemma,
13 will (also) be retrieved.&amp;quot;
The relation of hyperonymy is generally re-
garded as transitive: If A is a hyperonym of
B, and B is a hyperonym of C, then A is a by-
peronym of C. Following common practice, we
call A a direct hyperonym of B, while it is only
an indirect hyperonym of C. The same holds for
the inverse relation, hyponymy.
For Cl-NLG, which is concerned with find-
ing models that resolve the convergence prob-
lem with the impressive speed displayed by hu-
man speakers, the hyperonym problem is im-
portant because it serves to put implemented
models of spreading activation to the test. For
El-NLG. on the other hand, it can usually be
ignored. as most of today&apos;s practical applica-
tions either do not require the production of a
more general word (i.e.. there is a one-to-one
mapping from concept to word) or can rely on
fairly simple mechanisins. that avoid lexical rep-
etitions by choosing from a fixed. pre-defined set
of near-synonyms. For Ll-NLG, the challenge
of the Ityperon■,,m problem is to explain how a
sentence can be paraphrased by others that re-
p] ace a word 1.)■,.. a Ityperonym, and why speakers
select from candidate hyperonyins in different
situations of utterance. More concrete, given
a conceptual specification (in a wide sense, in-
cluding .contex.tual parameters,-and. comtriu-nica-
tive goals), the task is to find the best candidate
from a set of valid paraphrases, here especially
on the grounds of replacing content words with
hyperonyrns.
</bodyText>
<listItem confidence="0.886731">
3 Psycholinguistic production
models
• Language-prod ur tion odels-riewloped&apos;in
</listItem>
<bodyText confidence="0.999948675">
cholinguistics are nowadays couched in neural
network theory. Under debate are the computa-
tional properties of the networks, i.e., the modes
of activation spreading, the existence of feed-
back, of inhibitory links, etc. The main method-
ological concern is to construct the models in
such a way that they account for data gathered
in human speech production experiments, of-
ten involving production errors, which can shed
light on the underlying mechanisms.
A central point of content is the ques-
tion whether the meaning of concepts and/or
words is represented in a decomposed fashion
or not. Here, the hyperonym problem is some-
times used as evidence by proponents of non-
decompositional models. Roelofs [1996], for in-
stance, argues that if a number of nodes repre-
senting semantic features are the basis for lex-
ical access, in lemma retrieval it becomes ex-
tremely difficult to control the activation spread
in such a way that only the most specific lexical
unit that combines these features gets selected.
Roelofs concludes that a non-decompositional
model is to be favoured: When lemma retrieval
starts with activation of the &apos;lexical concept&apos;
FATHER, rather than with the features MALE
and PARENT, the output word will be father,
without, the danger of being outranked by a
higher activation of parent (or person. or Croity.
presumably).
This line is continued in a recent compre-
hensive theory of speech production by Lev-
elt. Roelofs, and Meyer [1999]. The focus of
this theory _is .more on the side of articulation,
hut their approach to (non-) decomposition&apos;and
hyperonyms follows the basic assumption just
sketched, The model consists of three layers of
nodes: A layer of concept nodes with labelled
concept links, a layer of lemma nodes, and a
layer of word form nodes that include morplio-
</bodyText>
<page confidence="0.996533">
94
</page>
<bodyText confidence="0.999975307692308">
logical information. When a lexical concept is
activated, the mechanism of activation spread-
ing ensu res that the direct ly..connected- lemma
receives the highest activation, and not a lemma
associated with a hyperonym of the lexical con-
cept (which is connected by an ISA-link).
Working out the mechanics to ensure this
behaviour is important for the implementa-
tion, but from the particular viewpoint of word
choice, approaches of this kind are not very ex-
planatory. Levelt et at, [1999, p-4]. state that
&amp;quot;there is not the slightest evidence that speak-
ers tend to produce hyperonyms of intended
target words.&amp;quot; But when lexical access starts
with an appropriately activated lexical concept,
the problem is effectively moved away, into the
realm of conceptualization. The authors ac-
knowledge the need for a component that es-
tablishes a &apos;perspective&apos; by selecting a specific
set of words, but have not incorporated such a
component into their model. Thus, why and
how the lexical concept receives its activation,
and where the intention of using a word arises
from, is not covered by the theory. For these
questions, we have to turn to work in natural
language generation.
</bodyText>
<sectionHeader confidence="0.800103" genericHeader="method">
4 Hyperonyms in NLG systems
</sectionHeader>
<bodyText confidence="0.99960822972973">
in contrast to psycholinguistics-inspired work,
the vast majority of natural language genera-
tion systems uses computations based on sym-
bol manipulation, often connected with sym-
bolic knowledge representation and reasoning
techniques. In these systems, the hyperonym
problem as one aspect of the general task of
lexical choice arises only in systems that em-
ploy a sufficiently rich model of the lexicon and
the concept-lexicon link, involving some sort. of
hierarchy information. As pointed out above,
from an application-oriented perspective (i.e..
in EI-NLG) it is often sufficient to work with
rather limited mechanisms that largely eschew
the lexical choice task.
The earliest and very influential device for
performing lexical .choice, Qoldman&apos;s I1.9751
discrimination net hard-wires the sequence of
choice points leading to a specific lexical item,
which is in fact the general strategy taken in the
majority of NLG systems: if you have a choice,
then prefer the most specific term.
The most substantial criticism on the prefer-
the-specific heuristic has been voiced in the
work of Reiter [1991]. One of his examples
is a. systern..:a,nsweringAtte_&apos;question-ls- Terry -a
woman? Even if the system has the specific
knowledge that Terry is a bachelor, the response
No, Terry is a bachelor would not be appropri-
ate here; the less specific No, Terry is a man
is better since it does not prompt the hearer to
draw any conclusions as to the particular rele-
vance of Terry&apos;s marital status for the present
cornversation. Reiter!s-. main -point is to distin-
guish the knowledge a generation system has at
its disposal from the communicative goals fol-
lowed in producing an utterance. The latter
are explicitly represented in his system as a list
of attributes to communicate about an entity&apos;,
which is a subset of the overall knowledge the
system has of that entity. In the Terry-example,
the goal is to inform the hearer that Terry
has the attributes {Human, Age-status:adult,
Sex:Male}.
In the KL-ONE [Brachman, Schmolze 1985])
style knowledge representation used by Reiter,
concepts can be marked as &apos;basic-level&apos; in the
sense of [Rosch 1978]. Thus, on the taxonomic
path Tweety (instance-of) Robin - Bird - Ver-
tebrate - Animal - Object, the concept Bird is
a basic-level one, which leads to a preference
for using the corresponding lexical item when
referring to some kind of bird (i.e., some con-
cept or instance subsumed by it). Simultane-
ous to Rosch&apos;s work, Cruse [1977] (who in turn
was building on earlier research by Roger Brown
in the 1960s) had pointed out that the failure
to use items of &amp;quot;inherently neutral specificity&amp;quot;
(a notion that closely corresponds to the basic
level) results in unwanted conversational impli-
catures -- the hearer will surmise the existence
of some reason why the neutral term cottici not
be used in the specific situation of utterance.
But using the basic level is not mandatory.
of course. Given a suitable context where at-
tention is directed to particular attributes of
entitities, a speaker moves to a more specific
or sometimes to a more-general -level. .Reiter&apos;s
mechanism of to-communicate attribute S tries
to capture this: Covering these attributes with
a suitable term can override the preference for
the basic level. Other kinds of preferences are
also accounted for, such as favouring shorter
rather than longer words, which typically (but
</bodyText>
<page confidence="0.994801">
95
</page>
<bodyText confidence="0.999880346938776">
not always) co-incides with the basic-level pref-
erence. Reiter notes that humans also employ
some preferences that can not be &apos;explained with-
the parameters investigated so far. He gives
the example [Reiter 1991, p. 248] of a speaker
pointing the hearer to a cow and a horse with
the utterance Look at the animals / mammals /
vertebrates! None of the terms is basic-level or
signigificantly shorter than the others, yet there
is a clear order of `normality&apos;in the sequence of
the three candidates.
In my own work on lexical choice in the
&apos;Moose&apos; generator [Stede 1999], 1 used language-
neutral conceptual hierarchies and the sub-
sum ption relation, inter alia to account for the
fact that different languages occasionally dis-
play preferences for different levels of specificity.
For example, in bi-lingual instructional text we
find a regular correspondence between the gen-
eral English to remove and numerous more spe-
cific German lexemes (abziehen, abriehmen, her-
ausdrehen, ...); this might very well be a genre-
specific tendency. Furthermore, Moose employs
a model of lexical connotations that can over-
ride the general preference for a more specific
lexical item. For example, when referring to a
POODLE in a derogatory manner, Moose can
choose the appropriately connota,ted word mutt,
which requires moving up the taxonomy to the
DOG concept, where a range of near-synonyms
(differing in their connotations) are attached.
Another reason for considering hyperonyms in
the lexical choice process is to avoid repeated
usage of the same term when referring to some
object multiple times.
In the present Moose implementation, all
more general words are inherited to the concept-
to-be-lexicalized, and the preference mechanism
selects one of them (in case of absence of any de-
cisive factors. it chooses the most specific word).
This mechanism is certainly not cognitively ad-
equate (it was not intended to be) and also not
particularly efficient: The range of candidates
under consideration should be constrained be-
forehand.
In conclusion, NLG -systems, -employ a mix-
ture of constraints and preferences in their ap-
proaches to hyperonymy. The factors used by
various systems in the choice process are:
</bodyText>
<listItem confidence="0.99197775">
• User&apos;s vocabulary and knowledge (e.g..
[McKeown et al. 1993[)
• Successul reference, i.e., discrimination
from other candidate entities (e.g., [Dale,
_Reiter 1995])
a Basic-level and entry-level effects, conver-
sational implicatures
• Length of words
• Stylistic features such as formality, posi-
tive/negative attitude
• Language, genre
• Givenness of item, avoid repetition or &amp;quot;say-
</listItem>
<bodyText confidence="0.9864717">
ing the very obvious&amp;quot;
Not surprisingly, there is no generator yet that
would incorporate all these factors within a
single system. It is not clear which general
lexical items should be inherited down to the
concept-to-be-lexicalized and enter the prefer-
ential choice mechanism; it is also riot clear how
exactly the various preferences would interact
and which would take precedence in a particu-
lar situation of utterance.
</bodyText>
<sectionHeader confidence="0.849816" genericHeader="method">
5 Hyperonymy in lexical semantics
</sectionHeader>
<bodyText confidence="0.99982562962963">
Linguists studying lexical semantics are to a
good extent concerned with sense relations be-
tween words, and hyp(er)onymy is certainly one
of the relations receiving the most attention.
While the intuitive decision whether some en-
tity is subordinate to some other entity is in
most cases not difficult to make, spelling out
the precise definition of hyponymy (and thus
hyperonymy) and its consequences is anything
but trivial. Lyons [1977], for example, proposes
that fish and bird share the direct hyperonym
creature but not animal. That is, when I say
There were plenty of fish in the creek, the al-
ternative sentence There were plenty of animals
in the creek would not be a felicitous utterance.
even though it is &amp;quot;truth-conditionally correct&amp;quot;.
And hence, there is a difference between fiA
ISA creature and fish ISA animal.
An interesting distinction in this respect is
offered by Cruse [1986], who separates hy-
ponymy from the. more constrained relation of
taxonymy. A diagnosis for the latter is the ut-
terance frame X is a kind of/ type of V. Exam-
ples that &amp;quot;work&amp;quot; in this frame are: spaniel-dog,
rose-flower. mango-fruit. Examples that seem
not to work are: kitten-eat, queen-monarch,
sprmstcr-woman. waiter-man. Notice that both
</bodyText>
<page confidence="0.980628">
96
</page>
<bodyText confidence="0.999297574468085">
groups are perfectly compatible with the ISA-
test, though: No one would doubt that a waiter
IS A man, a-queen IS A-monaTch.
Taxonomies, as Cruse proposes, typically
have no more than five levels, and frequently
have fewer. The levels are commonly labelled
as &apos;unique beginner&apos; — &apos;life form&apos; — &apos;generic&apos; —
&apos;specific&apos; — &apos;varietal&apos;. (The origin of these-term
in biology is obvious, but they can be trans—
ferred to other Teahns, as Cruse notes.) Mitigt
important is the generic level, which holds or—
dinary everyday names like cat, apple, church,
cup. These items tend to be morphologically
simple and are not metaphorically transferred
from elsewhere. Most branches of hierarchies
terminate at the generic level, and hence this
is the level with the largest number of items.
Items at specific and varietal levels are particu-
larly likely to be morphologically complex, and
compound words are frequent here.
From the notion of explicitly defined levels,
it follows that hierarchies do not need to have
nodes at each level. Consider the examples in
figure 1. Depending on what items people place
on the generic level, they end up with one of the
two variants; according to Cruse, most people
subscribe to the second, which holds dog, cat,
bird on the same, generic level. Another ex-
ample are musical instruments: Most of them
belong to a kind such as strings, woodwind,
brass, percussion, but there is no obvious kind
for bagpipes or concertina, which are thus di-
rectly linked to musical instrument.
Cruse elaborated the importance of the
generic level in [Cruse 1977], where he states
that for every line of noun taxonomy, there is
one term that is &apos;inherently neutral&apos; (cf. the no-
tion of basic level mentioned above). There is
a general rule that requires speakers to use this
term in order to obtain an unmarked utterance
in a given context- .unless .this-would- result
in an &apos;abnormal communication&apos;, in which case
the speaker should deviate from neutral level,
but only to the minimum degree required to en-
sure normality. Cruse then offers several condi-
tions that would license such over- and under-
specification, which we do not reproduce here.
</bodyText>
<figure confidence="0.686563">
creature
bird
</figure>
<figureCaption confidence="0.995116">
Figure 1: Variants of taxonomy, reproduced
from [Cruse 1986, p. 146]
</figureCaption>
<bodyText confidence="0.997548461538462">
Synthesis: Toward a model of
-,,,conceptuat:ana-lexical-inhetitanee
Due to the very different motivations, different
kinds of NLG have very different approaches to
the hyperonym problem. EI-NLG can basically
ignore or finess it. In CI-NLG, it is reduced
to a merely technical question: getting the me-
chanics of spreading activation right, so that
lexical convergence enables the subsequent pro-
cesses of syntactization and articulation (which
the CI-NLG models place their emphasis on).
A broader view is necessarily based on reason-
ing with speaker&apos;s goals and contextual features,
which for the time being is the realm of LI-
NLG. Thus, before embarking on building more
comprehensive connectionist models, the hyper-
onym problem is best studied in the frameworks
of LI-NLG but with the motivation of mod-
elling human performance taken into account.
Thus adopting the perspective outlined in
section 4, we are interested in choosing words
between more or less specific alternatives as well
as between near-synonyms of the same speci-
ficity. We thereby open the door to both &apos;ver-
tical&apos; and &apos;horizontal&apos; lexical choice within a hi-
erarchy, which raises a number of questions:
</bodyText>
<listItem confidence="0.9406917">
• What is the granularity of conceptual, and
that of lexical knowledge?
• How are the differences between near-
synonyms representeci?2
* Given an activated concept, which more
general lexical items are considered in the
choice process; are there any restrictions on
- .-lexical inheritance?
• How is the eventual choice from the set of
candidate lexical items being made?
</listItem>
<bodyText confidence="0.684181666666667">
2 This question is beyond the scope of this paper; the
kind of approach 1 have in mind here is represented in
[DiNlarco et al. 1993], [Hirst 19951, [Edmonds 1909].
</bodyText>
<figure confidence="0.752134666666667">
animal crea Curt
Z\ •
dog cat
collie spaniel
robin blackbird starling
collie Spaniel robin blackbird starting
</figure>
<page confidence="0.998016">
97
</page>
<bodyText confidence="0.98183665">
collie -- (a silky-coated sheepdog with a long ruff and long narrow head developed in Scotland)
=&gt; shepherd dog, sheepdog, sheep dog -- (any .of various usually long-hairdbreeds.of dog
reared to herd-and guard sheep)
=&gt; working dog -- (any of several breeds of usually large powerful dogs bred to work as
draft animals and guard and guide dogs)
=&gt; dog, domestic dog, Canis familiaris -- (a member of the genus Canis (probably...
=&gt; canine, canid -- (any of various fissiped mammals with nonretractile claws and
typically long muzzles)
=&gt; carnivore -- (terrestrial or aquatic flesh-eating mammal; terrestrial carnivores
have four or five clawed digits on each limb)
=&gt; placental, placental mammal, eutherian, eutherian mammal -- (mammals having a
placenta; all mammals except monotremes and marsupials)
mammal- -1--‘laity-varmrialooded -vertebrate -the- skin.:mare- :or &apos;leas covered...
=&gt; vertebrate, craniate -- (animals having a bony or cartilaginous skeleton...
=&gt; chordate -- (any animal of the phylum Chordata having a notochord or
spinal column)
=&gt; animal, animate being, beast, brute, creature, fauna -- (a living
organism characterized by voluntary movement)
=&gt; life form, organism, being, living thing -- (any living entity)
=&gt; entity, something -- (anything having existence (living or nonliving))
</bodyText>
<figureCaption confidence="0.982903">
Figure 2: Hyperonyms for collie from WordNet
</figureCaption>
<bodyText confidence="0.999737466666667">
As we have seen, present models that admit
hyperonyms into the choice process (in particu-
lar those of Reiter [1991] and Stede [19991) run
into the problem of overgeneration: Too many
candidates have to be compared for their prefer-
ential features, and it is not clear that a decision
can always be made.
To illustrate the question of granularity and
range of hyperonymic alternatives, contrast the
path from collie to creature given by Cruse
[1986] in figure 1 with the hyperonym chain
for collie offered by WordNet [Fellbaum 1998],
shown in figure 2. The WordNet chain includes
many items that clearly do not show up in ev-
eryday language use, and that a lexical choice
process should prefer not to consider when pro-
ducing an utterance about a collie. Chordate,
for example, would in the vast majority of utter-
ance situations not be an option. On the other
hand, all these terms are certainly &apos;correct&apos;, and
a system should be able to respond affirmatively
to the question Is a collie a chordate?
This divergence points to the need for a dis-
tinction between conceptual and lexical-granu-
larity and inheritance: The WordNet chain rep-
resents rather a series of concepts than of words
entering the lexical choice process, which ap-
pears to be better represented by a Cruse-type
chain with few designated levels (but needs to
be augmented with near-synonyms for the &apos;hor-
</bodyText>
<figure confidence="0.977518571428571">
tzing,... Fluty
cr &amp;quot;ature, form
animal, beast, „. atfirnal
cyrdate
ve,brate
,ammal
plyental
Tivore
canine
dog, murt, • • dog
r
yking dog
shepherd dog
collie -- - collie
</figure>
<figureCaption confidence="0.989371">
Figure 3: Active-lexical and conceptual hierar-
chy
</figureCaption>
<bodyText confidence="0.988874333333334">
izontal&apos; aspects of choice).
The resulting situation is sketched in figure 3.
On the right hand side, the nodes of the concep-
tual chain also are linguistic units, but in lan-
guage production they would be accessed only
if the, `to-communicate&apos; -.attributes explicitly call
for it, e.g., when comparing chordates to verte-
brates. Otherwise, only items on the left hand
side (tentatively called &apos;active-lexical&apos;) enter the
lexical choice process, which are characterized
by their particular level in the vocabulary struc-
ture, and further differentiated by stylistic and
</bodyText>
<page confidence="0.989653">
98
</page>
<bodyText confidence="0.999855966666667">
other features. The generic, or basic, level is
marked by a box.
When a hyperonym chain is thus not merely
an ordered list, but the signficance of the levels
is recognized (assuming that Cruse&apos;s proposal of
level structure indeed scales up to other areas of
vocabulary), rules for deviating from the generic
level can be stated that map contextual param-
eters onto &apos;level movement instructions&apos;. These
rules would extend the lexicalisation framework
of Reiter [1991], where the. first condition is ad-
hering to the hard constraints (the word must
convey the essential attributes that are to be
communicated), and the second is a preference
for the basic level. Adding the instructions
for level movement would &amp;quot;contextualize&amp;quot; this
framework.
The rules for moving between levels have to
consider the specific function of the NP (refer,
inform about category membership, etc.) and
other factors as indicated in the previous sec-
tions (and others mentioned by Cruse [1977]).
Since the roles and interactions of these fac-
tors are not well understood yet, at this point
CI-NLG can make important contributions by
designing experiments that shed more light on
the parameters that prompt speakers to deviate
from the basic level; one example here is the
study on speaker&apos;s lexical choices in narrative
by Downing [1980].
</bodyText>
<sectionHeader confidence="0.997138" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999532242424243">
R. Brach man, „I. Schmolze. &amp;quot;An overview of the
KL-ONE knowledge representation system.&amp;quot;
In: Cognitive Science 9 (2), 1985.
D. Cruse. &amp;quot;The pragmatics of lexical speci-
ficity.&amp;quot; In: Journal of Linguistics 13, pp. 153-
164. 1977.
D. Cruse. Lexica/ semantics. Cambridge, LIE:
Cambridge University Press, 1986.
R. Dale, E. Reiter. &amp;quot;Computational Interpreta-
tions of the Gricean Maxims in the Genera-
tion of Referring Expressions.&amp;quot; In: Cognitive
Science 19:233-263, 1995.
C. DiMarco, G. Hirst, M. Stede. &amp;quot;The semantic
and stylistic differentiation of synonyms and
near-synonyms.&amp;quot; In: Working notes of the
AAM Spring Symposium on Building Lexi-
cons for Machine Translation, Stanford Uni-
versity, March 1993.
P. Downing. &amp;quot;Factors influencing lexical choice
in narrative.&amp;quot; In: W. Chafe (ed.): The pear
• stories: ,.cognitire,-: arrItura4 .and ;linguistic &apos;as-
pects of narrative production. Norwood/NJ:
Ablex, 1980
P. Edmonds. &amp;quot;Semantic representations of near-
synonyms for automatic lexical choice.&amp;quot; PhD -
thesis, Department of Computer Science,
University of Toronto, September 1999.
C. Fellbaum. WordNet An Electronic Lexical
,Da.tabase bridge/MA: .MIT.Press, 199$.
N.M. Goldman. &amp;quot;Conceptual generation.&amp;quot; In:
R.C. Schank (ed.): Conceptual informa-
tion processing. Amsterdam: North-Holla.nd,
1975.
G. Hirst. &amp;quot;Near-synonymy and the structure of
lexical knowledge.&amp;quot; In: Working notes of the
AAAI Spring Symposium on Representation
and Acquisition of Lexical Knowledge. Stan-
ford University, 1995.
J. Lyons. Semantics. Volume I. Cambridge/UK:
Cambridge University Press, 1977.
K. McKeown, J. Robin, M. Tanenblatt. &amp;quot;Tai-
loring lexical choice to the user&apos;s vocabulary
in multimedia explanation generation.&amp;quot; In:
Proceedings of the 31st Annual Meeting of
the Association for Computational Linguis-
• tics (A CL). Columbus, OH, 1993.
W. Leveit. Speaking: From Intention to Articu-
lation. Cambridge/MA: MIT Press, 1989.
W. Levelt, A. Roelofs, A. Meyer. &amp;quot;A theory
of lexical access in speech production.&amp;quot; In:
Behavioral and Brain Sciences 22, pp. 1-75,
1999.
E. Reiter. &amp;quot;A new model of lexical choice for
nouns.&amp;quot; In: Computational Intelligence 7,
240-251, 1991.
A. Roelofs. &amp;quot;Computational Models of Lemma
Retrieval.&amp;quot; In: T. Dijkstra, N. de Sniedt
(eds.): Computational Psych °linguist ie.,.
London: Taylor k Francis. 1996.
E. Rosch. &amp;quot;Principles of categorization.&amp;quot; in: E.
Rosch, B. Lloyd (eds.): Cognition and cute-
gorL-ation. Hilldale, NJ: Lawrence Ertbauni.
1978.
M. Stede. Lexical semantics and knowledge rep-
resentation in multilingual text generation.
Dordrecht/Boston: Kluwer, 1999.
</reference>
<page confidence="0.99897">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.947691">
<title confidence="0.9987425">The hyperonym problem Conceptual and lexical hierarchies.in language• generation</title>
<author confidence="0.995186">Manfred</author>
<affiliation confidence="0.99965">Technical University of Dept. of Computer</affiliation>
<address confidence="0.970963">10587</address>
<email confidence="0.991563">stedefts.tu-berlin.de</email>
<abstract confidence="0.999417333333333">When a lexical item is selected in the language production process, it needs to be explained why none of its superordinates gets selected instead, since their applicability conditions are fulfilled all the same. This question has received much attention in cognitive modelling and not as much in other branches of NLG. This paper describes the various approaches taken, discusses the reasons why they are so different, and argues that production models using symbolic representations should make a distinction between conceptual and lexical hierarchies, which can be organized along fixed levels as studied in (some branches of) lexical semantics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Brach man</author>
<author>„I Schmolze</author>
</authors>
<title>An overview of the KL-ONE knowledge representation system.&amp;quot;</title>
<date>1985</date>
<journal>In: Cognitive Science</journal>
<volume>9</volume>
<issue>2</issue>
<marker>man, Schmolze, 1985</marker>
<rawString>R. Brach man, „I. Schmolze. &amp;quot;An overview of the KL-ONE knowledge representation system.&amp;quot; In: Cognitive Science 9 (2), 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>The pragmatics of lexical specificity.&amp;quot; In:</title>
<date>1977</date>
<journal>Journal of Linguistics</journal>
<volume>13</volume>
<pages>153--164</pages>
<contexts>
<context position="18357" citStr="Cruse 1977" startWordPosition="2934" endWordPosition="2935"> follows that hierarchies do not need to have nodes at each level. Consider the examples in figure 1. Depending on what items people place on the generic level, they end up with one of the two variants; according to Cruse, most people subscribe to the second, which holds dog, cat, bird on the same, generic level. Another example are musical instruments: Most of them belong to a kind such as strings, woodwind, brass, percussion, but there is no obvious kind for bagpipes or concertina, which are thus directly linked to musical instrument. Cruse elaborated the importance of the generic level in [Cruse 1977], where he states that for every line of noun taxonomy, there is one term that is &apos;inherently neutral&apos; (cf. the notion of basic level mentioned above). There is a general rule that requires speakers to use this term in order to obtain an unmarked utterance in a given context- .unless .this-would- result in an &apos;abnormal communication&apos;, in which case the speaker should deviate from neutral level, but only to the minimum degree required to ensure normality. Cruse then offers several conditions that would license such over- and underspecification, which we do not reproduce here. creature bird Fig</context>
</contexts>
<marker>Cruse, 1977</marker>
<rawString>D. Cruse. &amp;quot;The pragmatics of lexical specificity.&amp;quot; In: Journal of Linguistics 13, pp. 153-164. 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>Lexica/ semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, LIE:</location>
<contexts>
<context position="19013" citStr="Cruse 1986" startWordPosition="3043" endWordPosition="3044"> taxonomy, there is one term that is &apos;inherently neutral&apos; (cf. the notion of basic level mentioned above). There is a general rule that requires speakers to use this term in order to obtain an unmarked utterance in a given context- .unless .this-would- result in an &apos;abnormal communication&apos;, in which case the speaker should deviate from neutral level, but only to the minimum degree required to ensure normality. Cruse then offers several conditions that would license such over- and underspecification, which we do not reproduce here. creature bird Figure 1: Variants of taxonomy, reproduced from [Cruse 1986, p. 146] Synthesis: Toward a model of -,,,conceptuat:ana-lexical-inhetitanee Due to the very different motivations, different kinds of NLG have very different approaches to the hyperonym problem. EI-NLG can basically ignore or finess it. In CI-NLG, it is reduced to a merely technical question: getting the mechanics of spreading activation right, so that lexical convergence enables the subsequent processes of syntactization and articulation (which the CI-NLG models place their emphasis on). A broader view is necessarily based on reasoning with speaker&apos;s goals and contextual features, which for</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. Cruse. Lexica/ semantics. Cambridge, LIE: Cambridge University Press, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<title>Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions.&amp;quot; In: Cognitive Science</title>
<date>1995</date>
<marker>Dale, Reiter, 1995</marker>
<rawString>R. Dale, E. Reiter. &amp;quot;Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions.&amp;quot; In: Cognitive Science 19:233-263, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C DiMarco</author>
<author>G Hirst</author>
<author>M Stede</author>
</authors>
<title>The semantic and stylistic differentiation of synonyms and near-synonyms.&amp;quot; In: Working notes of the AAM Spring Symposium on Building Lexicons for Machine Translation,</title>
<date>1993</date>
<institution>Stanford University,</institution>
<marker>DiMarco, Hirst, Stede, 1993</marker>
<rawString>C. DiMarco, G. Hirst, M. Stede. &amp;quot;The semantic and stylistic differentiation of synonyms and near-synonyms.&amp;quot; In: Working notes of the AAM Spring Symposium on Building Lexicons for Machine Translation, Stanford University, March 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Downing</author>
</authors>
<title>Factors influencing lexical choice in narrative.&amp;quot; In:</title>
<date>1980</date>
<editor>W. Chafe (ed.):</editor>
<marker>Downing, 1980</marker>
<rawString>P. Downing. &amp;quot;Factors influencing lexical choice in narrative.&amp;quot; In: W. Chafe (ed.): The pear • stories: ,.cognitire,-: arrItura4 .and ;linguistic &apos;aspects of narrative production. Norwood/NJ: Ablex, 1980</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Edmonds</author>
</authors>
<title>Semantic representations of nearsynonyms for automatic lexical choice.&amp;quot;</title>
<date>1999</date>
<tech>PhD -thesis,</tech>
<institution>Department of Computer Science, University of Toronto,</institution>
<marker>Edmonds, 1999</marker>
<rawString>P. Edmonds. &amp;quot;Semantic representations of nearsynonyms for automatic lexical choice.&amp;quot; PhD -thesis, Department of Computer Science, University of Toronto, September 1999. C. Fellbaum. WordNet An Electronic Lexical ,Da.tabase bridge/MA: .MIT.Press, 199$.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N M Goldman</author>
</authors>
<title>Conceptual generation.&amp;quot;</title>
<date>1975</date>
<booktitle>Conceptual information processing.</booktitle>
<editor>In: R.C. Schank (ed.):</editor>
<publisher>North-Holla.nd,</publisher>
<location>Amsterdam:</location>
<marker>Goldman, 1975</marker>
<rawString>N.M. Goldman. &amp;quot;Conceptual generation.&amp;quot; In: R.C. Schank (ed.): Conceptual information processing. Amsterdam: North-Holla.nd, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
</authors>
<title>Near-synonymy and the structure of lexical knowledge.&amp;quot; In: Working notes of the AAAI Spring Symposium on Representation and Acquisition of Lexical Knowledge.</title>
<date>1995</date>
<publisher>Stanford University,</publisher>
<contexts>
<context position="20707" citStr="Hirst 1995" startWordPosition="3315" endWordPosition="3316">ical&apos; and &apos;horizontal&apos; lexical choice within a hierarchy, which raises a number of questions: • What is the granularity of conceptual, and that of lexical knowledge? • How are the differences between nearsynonyms representeci?2 * Given an activated concept, which more general lexical items are considered in the choice process; are there any restrictions on - .-lexical inheritance? • How is the eventual choice from the set of candidate lexical items being made? 2 This question is beyond the scope of this paper; the kind of approach 1 have in mind here is represented in [DiNlarco et al. 1993], [Hirst 19951, [Edmonds 1909]. animal crea Curt Z\ • dog cat collie spaniel robin blackbird starling collie Spaniel robin blackbird starting 97 collie -- (a silky-coated sheepdog with a long ruff and long narrow head developed in Scotland) =&gt; shepherd dog, sheepdog, sheep dog -- (any .of various usually long-hairdbreeds.of dog reared to herd-and guard sheep) =&gt; working dog -- (any of several breeds of usually large powerful dogs bred to work as draft animals and guard and guide dogs) =&gt; dog, domestic dog, Canis familiaris -- (a member of the genus Canis (probably... =&gt; canine, canid -- (any of various fis</context>
</contexts>
<marker>Hirst, 1995</marker>
<rawString>G. Hirst. &amp;quot;Near-synonymy and the structure of lexical knowledge.&amp;quot; In: Working notes of the AAAI Spring Symposium on Representation and Acquisition of Lexical Knowledge. Stanford University, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lyons</author>
</authors>
<title>Semantics. Volume I. Cambridge/UK:</title>
<date>1977</date>
<publisher>Cambridge University Press,</publisher>
<marker>Lyons, 1977</marker>
<rawString>J. Lyons. Semantics. Volume I. Cambridge/UK: Cambridge University Press, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
<author>J Robin</author>
<author>M Tanenblatt</author>
</authors>
<title>Tailoring lexical choice to the user&apos;s vocabulary in multimedia explanation generation.&amp;quot; In:</title>
<date>1993</date>
<booktitle>Proceedings of the 31st Annual Meeting of the Association for Computational Linguis• tics (A CL).</booktitle>
<location>Columbus, OH,</location>
<contexts>
<context position="14782" citStr="McKeown et al. 1993" startWordPosition="2355" endWordPosition="2358">al words are inherited to the conceptto-be-lexicalized, and the preference mechanism selects one of them (in case of absence of any decisive factors. it chooses the most specific word). This mechanism is certainly not cognitively adequate (it was not intended to be) and also not particularly efficient: The range of candidates under consideration should be constrained beforehand. In conclusion, NLG -systems, -employ a mixture of constraints and preferences in their approaches to hyperonymy. The factors used by various systems in the choice process are: • User&apos;s vocabulary and knowledge (e.g.. [McKeown et al. 1993[) • Successul reference, i.e., discrimination from other candidate entities (e.g., [Dale, _Reiter 1995]) a Basic-level and entry-level effects, conversational implicatures • Length of words • Stylistic features such as formality, positive/negative attitude • Language, genre • Givenness of item, avoid repetition or &amp;quot;saying the very obvious&amp;quot; Not surprisingly, there is no generator yet that would incorporate all these factors within a single system. It is not clear which general lexical items should be inherited down to the concept-to-be-lexicalized and enter the preferential choice mechanism; i</context>
</contexts>
<marker>McKeown, Robin, Tanenblatt, 1993</marker>
<rawString>K. McKeown, J. Robin, M. Tanenblatt. &amp;quot;Tailoring lexical choice to the user&apos;s vocabulary in multimedia explanation generation.&amp;quot; In: Proceedings of the 31st Annual Meeting of the Association for Computational Linguis• tics (A CL). Columbus, OH, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Leveit</author>
</authors>
<title>Speaking: From Intention to Articulation. Cambridge/MA:</title>
<date>1989</date>
<booktitle>Behavioral and Brain Sciences 22,</booktitle>
<pages>1--75</pages>
<publisher>MIT Press,</publisher>
<marker>Leveit, 1989</marker>
<rawString>W. Leveit. Speaking: From Intention to Articulation. Cambridge/MA: MIT Press, 1989. W. Levelt, A. Roelofs, A. Meyer. &amp;quot;A theory of lexical access in speech production.&amp;quot; In: Behavioral and Brain Sciences 22, pp. 1-75, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>A new model of lexical choice for nouns.&amp;quot; In:</title>
<date>1991</date>
<journal>Computational Intelligence</journal>
<volume>7</volume>
<pages>240--251</pages>
<contexts>
<context position="12740" citStr="Reiter 1991" startWordPosition="2029" endWordPosition="2030">ular attributes of entitities, a speaker moves to a more specific or sometimes to a more-general -level. .Reiter&apos;s mechanism of to-communicate attribute S tries to capture this: Covering these attributes with a suitable term can override the preference for the basic level. Other kinds of preferences are also accounted for, such as favouring shorter rather than longer words, which typically (but 95 not always) co-incides with the basic-level preference. Reiter notes that humans also employ some preferences that can not be &apos;explained withthe parameters investigated so far. He gives the example [Reiter 1991, p. 248] of a speaker pointing the hearer to a cow and a horse with the utterance Look at the animals / mammals / vertebrates! None of the terms is basic-level or signigificantly shorter than the others, yet there is a clear order of `normality&apos;in the sequence of the three candidates. In my own work on lexical choice in the &apos;Moose&apos; generator [Stede 1999], 1 used languageneutral conceptual hierarchies and the subsum ption relation, inter alia to account for the fact that different languages occasionally display preferences for different levels of specificity. For example, in bi-lingual instruc</context>
</contexts>
<marker>Reiter, 1991</marker>
<rawString>E. Reiter. &amp;quot;A new model of lexical choice for nouns.&amp;quot; In: Computational Intelligence 7, 240-251, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Roelofs</author>
</authors>
<title>Computational Models of Lemma Retrieval.&amp;quot; In:</title>
<date>1996</date>
<editor>T. Dijkstra, N. de Sniedt (eds.):</editor>
<marker>Roelofs, 1996</marker>
<rawString>A. Roelofs. &amp;quot;Computational Models of Lemma Retrieval.&amp;quot; In: T. Dijkstra, N. de Sniedt (eds.): Computational Psych °linguist ie.,. London: Taylor k Francis. 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rosch</author>
</authors>
<title>Principles of categorization.&amp;quot;</title>
<date>1978</date>
<booktitle>Cognition and cutegorL-ation. Hilldale, NJ: Lawrence Ertbauni.</booktitle>
<editor>in: E. Rosch, B. Lloyd (eds.):</editor>
<contexts>
<context position="11282" citStr="Rosch 1978" startWordPosition="1790" endWordPosition="1791"> main -point is to distinguish the knowledge a generation system has at its disposal from the communicative goals followed in producing an utterance. The latter are explicitly represented in his system as a list of attributes to communicate about an entity&apos;, which is a subset of the overall knowledge the system has of that entity. In the Terry-example, the goal is to inform the hearer that Terry has the attributes {Human, Age-status:adult, Sex:Male}. In the KL-ONE [Brachman, Schmolze 1985]) style knowledge representation used by Reiter, concepts can be marked as &apos;basic-level&apos; in the sense of [Rosch 1978]. Thus, on the taxonomic path Tweety (instance-of) Robin - Bird - Vertebrate - Animal - Object, the concept Bird is a basic-level one, which leads to a preference for using the corresponding lexical item when referring to some kind of bird (i.e., some concept or instance subsumed by it). Simultaneous to Rosch&apos;s work, Cruse [1977] (who in turn was building on earlier research by Roger Brown in the 1960s) had pointed out that the failure to use items of &amp;quot;inherently neutral specificity&amp;quot; (a notion that closely corresponds to the basic level) results in unwanted conversational implicatures -- the </context>
</contexts>
<marker>Rosch, 1978</marker>
<rawString>E. Rosch. &amp;quot;Principles of categorization.&amp;quot; in: E. Rosch, B. Lloyd (eds.): Cognition and cutegorL-ation. Hilldale, NJ: Lawrence Ertbauni. 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stede</author>
</authors>
<title>Lexical semantics and knowledge representation in multilingual text generation.</title>
<date>1999</date>
<publisher>Dordrecht/Boston: Kluwer,</publisher>
<contexts>
<context position="13096" citStr="Stede 1999" startWordPosition="2093" endWordPosition="2094"> than longer words, which typically (but 95 not always) co-incides with the basic-level preference. Reiter notes that humans also employ some preferences that can not be &apos;explained withthe parameters investigated so far. He gives the example [Reiter 1991, p. 248] of a speaker pointing the hearer to a cow and a horse with the utterance Look at the animals / mammals / vertebrates! None of the terms is basic-level or signigificantly shorter than the others, yet there is a clear order of `normality&apos;in the sequence of the three candidates. In my own work on lexical choice in the &apos;Moose&apos; generator [Stede 1999], 1 used languageneutral conceptual hierarchies and the subsum ption relation, inter alia to account for the fact that different languages occasionally display preferences for different levels of specificity. For example, in bi-lingual instructional text we find a regular correspondence between the general English to remove and numerous more specific German lexemes (abziehen, abriehmen, herausdrehen, ...); this might very well be a genrespecific tendency. Furthermore, Moose employs a model of lexical connotations that can override the general preference for a more specific lexical item. For e</context>
</contexts>
<marker>Stede, 1999</marker>
<rawString>M. Stede. Lexical semantics and knowledge representation in multilingual text generation. Dordrecht/Boston: Kluwer, 1999.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>