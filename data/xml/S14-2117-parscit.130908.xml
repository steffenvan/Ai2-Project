<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002232">
<title confidence="0.986727">
TJP: Identifying the Polarity of Tweets from Context
</title>
<author confidence="0.996415">
Tawunrat Chalothorn Jeremy Ellman
</author>
<affiliation confidence="0.875573692307692">
Department of Computer Science and
Digital Technologies
University of Northumbria at Newcas-
tle, Pandon Building, Camden Street
Newcastle Upon Tyne, NE2 1XE, UK
tawunrat.chalothorn
@northumbria.ac.uk
Department of Computer Science and
Digital Technologies
University of Northumbria at Newcas-
tle, Pandon Building, Camden Street
Newcastle Upon Tyne, NE2 1XE, UK
jeremy.ellman
</affiliation>
<email confidence="0.90434">
@northumbria.ac.uk
</email>
<sectionHeader confidence="0.990203" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994771">
The TJP system is presented, which partici-
pated in SemEval 2014 Task 9, Part A:
Contextual Polarity Disambiguation. Our
system is ‘constrained’, using only data
provided by the organizers. The goal of this
task is to identify whether marking contexts
are positive, negative or neutral. Our system
uses a support vector machine, with exten-
sive pre-processing and achieved an overall
F-score of 81.96%.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998366133333334">
The aim of sentiment analysis is to identify
whether the subject of a text is intended to be
viewed positively of negatively by a reader. Such
emotions are sometimes hidden in long sentences
and are difficult to identify. Consequently senti-
ment analysis is an active research area in natural
language processing.
Sentiment is currently conceived terms of po-
larity. This has numerous interesting applica-
tions. For example, Grabner et al. (2012) used
sentiment analysis to classify customers’ reviews
of hotels by using a star rating to categorize the
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
reviews as bad, neutral and good. Similarly,
Tumasjan et al. (2010) tried to predict the out-
come of the German federal election through the
analysis more than 100,000 tweets posted in the
lead up. Sentiment analysis has also used to
classify whether dreams are positive or nega-
tive (Nadeau et al. 2006).
This paper presents the TJP system which
was submitted to SemEval 2014 Task 9, Part A:
Contextual Polarity Disambiguation (Rosenthal
et al., 2014). TJP focused on the ‘Constrained’
task.
The ‘Constrained’ task only uses data provid-
ed by the organizers. That is, external resources
such as sentiment inventories (e.g. Sentiwordnet
(Esuli, and Sebastiani 2006) are excluded. The
objective of the TJP system was to use the results
for comparison with our previous experiment
(Chalothorn and Ellman, 2013). More details of
these can be found in section 5.
The TJP system was implemented using a
support vector machine (SVM, e.g. Joachims,
1999) with the addition of extensive pre-
processing such as stopword removal, negation,
slang, contraction, and emoticon expansions.
The remainder of this paper is constructed as
follows: firstly, related work is discussed in sec-
tion 2; the methodology, the experiment and re-
sults are presented in sections 3 and 4,
</bodyText>
<page confidence="0.992652">
657
</page>
<note confidence="0.730985">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 657–662,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.9978">
respectively. Finally a discussion and future
work are given in section 5.
</bodyText>
<sectionHeader confidence="0.999342" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999688616666667">
Twitter is a popular social networking and mi-
croblogging site that allows users to post mes-
sages of up to 140 characters; known as
‘Tweets’. Tweets are extremely attractive to the
marketing sector, since tweets may be searched
in real-time. This means marketing can find cus-
tomer sentiment (both positive and negative) far
more quickly than through the use of web pages
or traditional media. Consequently analyzing the
sentiment of tweets is currently active research
task.
The word &apos;emoticon&apos; is a neologistic contrac-
tion of &apos;emotional icon&apos;. It refers specifically to
the use of combinations of punctuation charac-
ters to indicate sentiment in a text. Well known
emoticons include :) to represent a happy face,
and :( a sad one. Emoticons allow writers to
augment the impact of limited texts (such as in
SMS messages or tweets) using few characters.
Read (2005) used emoticons from a training
set downloaded from Usenet newsgroups as an-
notations (positive and negative). Using the ma-
chine learning techniques of Naïve Bayes and
SVM, Read (2005) achieved up to 61.50 % and
70.10%, accuracy respectively in determining
text polarity from the emoticons used.
Go et al. (2009) used distant supervision to
classify sentiment of Twitter, similar to Read
(2005). Emoticons were used as noisy labels in
training data. This allowed the performance of
supervised learning (positive and negative) at a
distance. Three classifiers were used: Naïve
Bayes, Maximum Entropy and SVM. These
classifiers were able to obtain more than
81.30%, 80.50% and 82.20%, respectively accu-
racy on their unigram testing data .
Aramaki et al. (2011) classified contexts on
Twitter related to influenza using a SVM. The
training data was annotated with the polarity la-
bel by humans, whether they are positive or neg-
ative. The contexts will be labelled as positive if
the contexts mention the user or someone close
to them has the flu, or if they mention a time
when they caught the flu. The results demon-
strated that they obtained a 0.89 correction ratio
for their testing data against a gold standard.
Finally, a well known paper by Bollen and
Mao (2011) identified a correlation between the
movements of the Dow Jones stock market
index, and prevailing sentiment as determined
from twitter&apos;s live feed. This application has
prompted considerable work such as Makrehchi
et al (2013) that has attempted to create success-
ful trading strategies from sentiment analysis of
tweets.
These work both the wide ranging applica-
tions of analysing twitter data, and the
importance of Sentiment Analysis. We now
move on to look at our approach to SemEval
2014 task 9.
</bodyText>
<sectionHeader confidence="0.996775" genericHeader="method">
3 Methodology
</sectionHeader>
<subsectionHeader confidence="0.995403">
3.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999934533333333">
The training and development dataset of
SemEval was built using Tweets from more than
one thousand pieces of context. The contexts
have various features often used in Tweets, such
as emoticons, tags, usernames etc. These features
were extracted from the datasets before training
for the supervised machine learning model.
During initial pre-processing of the datasets,
emoticons were labelled by matching with the
emoticons that have been collect manually from
the dataset. Those labelled were matched against
a well-known collection of emoticons†.
Subsequently, negative contractions‡ were
expanded in place and converted to full form
(e.g. don’t -&gt; do not). Moreover, the features of
</bodyText>
<subsectionHeader confidence="0.508166">
†http://en.wikipedia.org/wiki/List of emoticons
</subsectionHeader>
<bodyText confidence="0.894871">
‡http://en.wikipedia.org/wiki/Engl_ish__auxiliaries_and_contr
actions#Negative_contractions
</bodyText>
<page confidence="0.99453">
658
</page>
<bodyText confidence="0.999960454545455">
twitters were also removed or replaced by words
such as twitter usernames, URLs and hashtags.
A Twitter username is a unique name that
shows in the user&apos;s profile and may be used for
both authentication and identification. This is
shown by prefacing the username with an @
symbol. When a tweet is directed at an individual
or particular entity this can be shown in the tweet
by including @username. For example a tweet
directed at ‘tawunrat’ would include the text
@tawunrat. Before URLs are posted in twitter
they are shortened automatically to use the t.co
domain whose modified URLs are at most 22
characters. However, both features have been
removed from the datasets. For the hashtags,
they are used for represent keyword and topics in
twitter by using # follow by words or phrase
such as #newcastleuk. This feature has been re-
placed with the following word after # symbol.
For example, #newcastleuk was replaced by
newcastleuk.
Frequently repeated letters are used in tweets
for emphasis. These were reduced and replaced
using a simple regular expression by two of the
same character. For example, happpppppy will
be replaced with happy, and coollllll will be re-
placed by cooll. Next, special character such as
[j,{,},?,and ! were also removed. Slang and con-
tracted words were converted to their full form.
E.g. ‘fyi’ was converted to ‘for your infor-
mation’. Finally, NLTK (Bird et al. 2009) stop-
words such as ‘a’, ‘the’, etc., were removed from
the datasets.
</bodyText>
<subsectionHeader confidence="0.987828">
3.2 Classifier
</subsectionHeader>
<bodyText confidence="0.9998348">
Our system uses the SVM classifier model
(Hearst et al., 1998, Cristianini and Shawe-
Taylor, 2000), which is based on SVM-light (Jo-
achims, 1999). SVM is a binary linear classifica-
tion model with the learning algorithm for
classification and regression analyzing the data
and recognizing the pattern.
Training SVMLight requires data to be for-
mulated into vectors of attribute value pairs pre-
ceded by a numeric value. For example,
</bodyText>
<equation confidence="0.599167">
&lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; #
&lt;info&gt;
</equation>
<bodyText confidence="0.997861409090909">
Here, ‘target’ represents the polarity of a sen-
tence or tweet; ‘feature’ refers to a term in the
document, and ‘value’ refers to a feature weight.
This could be used as the relative frequency of a
term in the set of documents, or Tf-Idf. Tf-idf is
the combination of term frequency (tf) and in-
verse document frequency (idf), is a weight value
often used in text mining and information re-
trieval. This weight is a statistical measure used
to evaluate the relative important of word in a
document in the collection (Manning et al.,
2008).
where is the weighting the scheme assigns to
term in document
Term frequency (tf) is used to measure how fre-
quent the term appears in the document.
∑
where is the number of term appears in a document
∑ is the total number of terms in the document .
Inverse document frequency (idf) is used to
measure how important the term is – i.e. whether
the term is common or rare in the collection.
</bodyText>
<equation confidence="0.7763">
(3)
</equation>
<bodyText confidence="0.996712166666667">
where is the total number of documents in the collection
in corpus. is the number of documents which term
appears.
Therefore, we chose to work with both of these
to observe which yielded the best results in the
polarity classification.
</bodyText>
<page confidence="0.998436">
659
</page>
<bodyText confidence="0.999879666666667">
The default settings of SVMLight were used
throughout. This meant that we used a linear
kernel that did not require any parameters.§
</bodyText>
<sectionHeader confidence="0.987338" genericHeader="evaluation">
4 Experiment and Results
</sectionHeader>
<bodyText confidence="0.937124675675675">
In our experiment, we used the datasets and
evaluated the system using the F-score measure-
ment. During pre-processing features were ex-
tracted from both datasets. First, we used a
frequency of word as a featured weight by calcu-
lating the frequency of word in the dataset and,
during pre-processing, we labelled the emotions
in both datasets. The results revealed a lower
than average F-score at 34.80%. As this was
quite low we disregarded further use of term fre-
quency as a feature weight. We moved on to use
Tf-Idf as the feature weight and, again, emoti-
cons in both datasets were labelled. The score of
78.10% was achieved. Then, we kept the pre-
possessing of the training set stable by combin-
ing the features to extract from the testing data.
These results are presented in Table 1**.
The highest score of 81.96% was recorded
when all the features were combined and extract-
ed from both datasets.
The lowest score of 36.48% was recorded
when emoticons were extracted from testing data
and all features were extracted from training da-
tasets. The results of the highest scoring experi-
ment were submitted to the task organizers.
Following solution submissions, the task or-
ganizers announced the scores by separating the
data into the following five groups: LiveJour-
nal2014; SMS2013; Twitter2013; Twitter2014;
and Twitter2014 Sarcasm. This would allow the
identification of any domain dependent effects.
However, the results showed that we achieved
above average in all the datasets, as illustrated in
Figure 1.
§Based on SVMLight
**The results in the table are from the test set 2014 in task
2A.
</bodyText>
<sectionHeader confidence="0.817057" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999932606060606">
The TJP system participated in SemEval 2014
Task 9, Part A: Contextual Polarity Disambigua-
tion. The system exploited considerable pre-
processing, before using the well known,
SVMLight machine learning algorithm (Joa-
chims. 1999). The pre-processing used several
twitter specific features, such as hashtags and
ids, in addition to more traditional Information
Retrieval concepts such as the Tf-Idf heuristic
(Manning et al., 2008). The results showed that
the combination of all features in both datasets
achieved the best results, at 81.96%.
An aspect of this contribution is the compara-
tive analysis of feature effectiveness. That is, we
attempted to identify which factor(s) made the
most significant improvement to system perfor-
mance. It is clear the pre-processing had a con-
siderable effect on system performance. The use
of a different learning algorithm also contributed
to performance since, on this task, SVMLight
performed better than the Naive Bayes algorithm
that was used by our team in 2013.
Sentiment resources was not been used in our
system in SemEval 2014 as same as in SemEval
2013 whilst other user groups have employed a
variety of resources of different sizes, and accu-
racy (Wilson et al., 2013). These points lead to
the following plan for future activities.
Our future work is to rigorously investigate
the success factors for sentiment analysis, espe-
cially in the twitter domain. More specifically,
we have formulated the following research ques-
tions as a result of our participation in SemEval
</bodyText>
<listItem confidence="0.994514333333334">
• Are Sentiment resources essential for the
Sentiment Analysis task?
• Can the accuracy and effectiveness of
sentiment lexicons be measured? If so,
which feature of the resource (accuracy
vs. coverage) is the most effective met-
ric.
• Might it be more effective to use a range
of sentiments (e.g. [-1.0 .. 1.0]), rather
</listItem>
<page confidence="0.98722">
660
</page>
<tableCaption confidence="0.466704833333333">
than binary approach(e.g. positive and ly would an ensemble approach (Rokach,
negative) taken in SemEval 2013, and 2005) significantly improve perfor-
2014? mance?
 Is one machine learning algorithm suffi-
cient, and if so which is it? Or, alternate-
Table 1: The results of each feature analyzed in the approach of TF-IDF
</tableCaption>
<figureCaption confidence="0.996835">
Figure 1: The comparison of TJP and average scores
</figureCaption>
<sectionHeader confidence="0.996949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99860145">
Alec Go, Richa Bhayani and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervi-
sion. CS224N Project Report, Stanford, 1-12.
Andrea Esuli, Fabrizio Sebastiani 2006
&amp;quot;SENTIWORDNET: A Publicly Available Lexi-
cal Resource for Opinion Mining&amp;quot; in Proceedings
of the 5th Conference on Language Resources and
Evaluation, LREC (2006), pp. 417-422
Andranik Tumasjan, Timm O. Sprenger, Philipp G.
Sandner and Isabell M. Welpe. 2010. &amp;quot;Predicting
elections with twitter: What 140 characters reveal
about political sentiment,&amp;quot; in Proceedings of the
Fourth International AAAI Conference on Web-
logs and Social Media, pp. 178-185.
Christopher D. Manning, Prabhakar Raghavan and
Hinrich Schütze, Introduction to Information Re-
trieval, Cambridge University Press. 2008. ISBN:
0521865719.
David Nadeau, Catherine Sabourin, Joseph De Kon-
inck, Stan Matwin and Peter D. Turney. 2006.
</reference>
<page confidence="0.989189">
661
</page>
<reference confidence="0.995477301369863">
&amp;quot;Automatic dream sentiment analysis,&amp;quot; presented
at the In: Proceedings of the Workshop on Compu-
tational Aesthetics at the Twenty-First National
Conference on Artificial Intelligence, Boston,
Massachussetts, USA.
Dietmar Grabner, Markus Zanker, Gunther Fliedl and
Matthias Fuchs. 2012.&amp;quot;Classification of customer
reviews based on sentiment analysis,&amp;quot; presented at
the 19th Conference on Information and Commu-
nication Technologies in Tourism (ENTER), Hel-
singborg, Sweden.
Eiji Aramaki, Sachiko Maskawa and Mizuki Morita.
2011. Twitter catches the flu: detecting influenza
epidemics using Twitter. Proceedings of the Con-
ference on Empirical Methods in Natural Lan-
guage Processing. Edinburgh, United Kingdom:
Association for Computational Linguistics.
Johan. Bollen and Huina. Mao. Twitter mood as a
stock market predictor. IEEE Computer,
44(10):91–94.
Jonathon Read. 2005. Using emoticons to reduce de-
pendency in machine learning techniques for sen-
timent classification. Proceedings of the ACL
Student Research Workshop. Ann Arbor, Michi-
gan: Association for Computational Linguistics.
Lior Rokach. 2005. Chapter 45 Ensemble Methods for
Classifiers. In: Oded Maimon and Lior Rokach
(eds.) Data Mining and Knowledge Discovery
Handbook. Springer US.
Marti A. Hearst, Susan T. Dumais, Edgar Osman,
John Platt and Bernhard Scholkopf . 1998. Sup-
port vector machines. IEEE, Intelligent Systems
and their Applications, 13, 18-28.
Masoud Makrehchi, Sameena Shah and Wenhui Liao.
2013. Stock Prediction Using Event-Based Senti-
ment Analysis. Web Intelligence (WI) and Intelli-
gent Agent Technologies (IAT), 2013
IEEE/WIC/ACM International Joint Conferences
on,. 337-342.
Nello Cristianini and John Shawe-Taylor. 2000. An
introduction to support vector machines and other
kernel-based learning methods, Cambridge uni-
versity press.
Sara Rosenthal, Preslav Nakov, Alan Ritter and
Veselin Stoyanov. 2014. SemEval-2014 Task 9:
Sentiment Analysis in Twitter. International
Workshop on Semantic Evaluation (SemEval-
2014). Dublin, Ireland.
Steven Bird, Ewan Klein and Edward Loper. 2009.
NLTK: Natural language processing with Python,
O&apos;Reilly.
Takeshi Sakaki, Makoto Okazaki and Yutaka Matsuo.
2010. Earthquake shakes Twitter users: real-time
event detection by social sensors. Proceedings of
the 19th international conference on World wide
web. Raleigh, North Carolina, USA: ACM.
Tawunrat Chalothorn and Jeremy Ellman. 2013. TJP:
Using Twitter to Analyze the Polarity of Contexts.
Second Joint Conference on Lexical and Compu-
tational Semantics (*SEM), Volume 2: Proceed-
ings of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013). Atlanta,
Georgia, USA: Association for Computational
Linguistics.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,
Alan Ritter, Sara Rosenthal and Veselin Stoyanov.
2013. SemEval-2013 Task 2: Sentiment Analysis
in Twitter. Proceedings of the 7th International
Workshop on Semantic Evaluation. Association
for Computational Linguistics.
Thorsten Joachims. 1999. Making large-scale support
vector machine learning practical. Advances in
kernel methods. MIT Press.
</reference>
<page confidence="0.997224">
662
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.151572">
<title confidence="0.999266">TJP: Identifying the Polarity of Tweets from Context</title>
<author confidence="0.999841">Tawunrat Chalothorn Jeremy Ellman</author>
<affiliation confidence="0.7719784">Department of Computer Science Digital of Northumbria at tle, Pandon Building, Camden Newcastle Upon Tyne, NE2 1XE,</affiliation>
<email confidence="0.998119">@northumbria.ac.uk</email>
<affiliation confidence="0.7688168">Department of Computer Science Digital of Northumbria at tle, Pandon Building, Camden Newcastle Upon Tyne, NE2 1XE,</affiliation>
<email confidence="0.994892">@northumbria.ac.uk</email>
<abstract confidence="0.985481">The TJP system is presented, which participated in SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation. Our system is ‘constrained’, using only data provided by the organizers. The goal of this task is to identify whether marking contexts are positive, negative or neutral. Our system uses a support vector machine, with extensive pre-processing and achieved an overall F-score of 81.96%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision. CS224N Project Report,</title>
<date>2009</date>
<pages>1--12</pages>
<location>Stanford,</location>
<contexts>
<context position="4324" citStr="Go et al. (2009)" startWordPosition="667" endWordPosition="670">cifically to the use of combinations of punctuation characters to indicate sentiment in a text. Well known emoticons include :) to represent a happy face, and :( a sad one. Emoticons allow writers to augment the impact of limited texts (such as in SMS messages or tweets) using few characters. Read (2005) used emoticons from a training set downloaded from Usenet newsgroups as annotations (positive and negative). Using the machine learning techniques of Naïve Bayes and SVM, Read (2005) achieved up to 61.50 % and 70.10%, accuracy respectively in determining text polarity from the emoticons used. Go et al. (2009) used distant supervision to classify sentiment of Twitter, similar to Read (2005). Emoticons were used as noisy labels in training data. This allowed the performance of supervised learning (positive and negative) at a distance. Three classifiers were used: Naïve Bayes, Maximum Entropy and SVM. These classifiers were able to obtain more than 81.30%, 80.50% and 82.20%, respectively accuracy on their unigram testing data . Aramaki et al. (2011) classified contexts on Twitter related to influenza using a SVM. The training data was annotated with the polarity label by humans, whether they are posi</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani and Lei Huang. 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
</authors>
<title>Fabrizio Sebastiani</title>
<date>2006</date>
<booktitle>in Proceedings of the 5th Conference on Language Resources and Evaluation, LREC</booktitle>
<pages>417--422</pages>
<marker>Esuli, 2006</marker>
<rawString>Andrea Esuli, Fabrizio Sebastiani 2006 &amp;quot;SENTIWORDNET: A Publicly Available Lexical Resource for Opinion Mining&amp;quot; in Proceedings of the 5th Conference on Language Resources and Evaluation, LREC (2006), pp. 417-422</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andranik Tumasjan</author>
<author>Timm O Sprenger</author>
<author>Philipp G Sandner</author>
<author>Isabell M Welpe</author>
</authors>
<title>Predicting elections with twitter: What 140 characters reveal about political sentiment,&amp;quot;</title>
<date>2010</date>
<booktitle>in Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="1733" citStr="Tumasjan et al. (2010)" startWordPosition="250" endWordPosition="253">t to identify. Consequently sentiment analysis is an active research area in natural language processing. Sentiment is currently conceived terms of polarity. This has numerous interesting applications. For example, Grabner et al. (2012) used sentiment analysis to classify customers’ reviews of hotels by using a star rating to categorize the This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ reviews as bad, neutral and good. Similarly, Tumasjan et al. (2010) tried to predict the outcome of the German federal election through the analysis more than 100,000 tweets posted in the lead up. Sentiment analysis has also used to classify whether dreams are positive or negative (Nadeau et al. 2006). This paper presents the TJP system which was submitted to SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation (Rosenthal et al., 2014). TJP focused on the ‘Constrained’ task. The ‘Constrained’ task only uses data provided by the organizers. That is, external resources such as sentiment inventories (e.g. Sentiwordnet (Esuli, and Sebastiani 2006) are </context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Andranik Tumasjan, Timm O. Sprenger, Philipp G. Sandner and Isabell M. Welpe. 2010. &amp;quot;Predicting elections with twitter: What 140 characters reveal about political sentiment,&amp;quot; in Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media, pp. 178-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
</authors>
<title>Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval,</title>
<date>2008</date>
<pages>0521865719</pages>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008. ISBN: 0521865719.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Catherine Sabourin</author>
<author>Joseph De Koninck</author>
<author>Stan Matwin</author>
<author>Peter D Turney</author>
</authors>
<date>2006</date>
<marker>Nadeau, Sabourin, De Koninck, Matwin, Turney, 2006</marker>
<rawString>David Nadeau, Catherine Sabourin, Joseph De Koninck, Stan Matwin and Peter D. Turney. 2006.</rawString>
</citation>
<citation valid="false">
<title>Automatic dream sentiment analysis,&amp;quot; presented at the In:</title>
<booktitle>Proceedings of the Workshop on Computational Aesthetics at the Twenty-First National Conference on Artificial Intelligence,</booktitle>
<location>Boston, Massachussetts, USA.</location>
<marker></marker>
<rawString>&amp;quot;Automatic dream sentiment analysis,&amp;quot; presented at the In: Proceedings of the Workshop on Computational Aesthetics at the Twenty-First National Conference on Artificial Intelligence, Boston, Massachussetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietmar Grabner</author>
<author>Markus Zanker</author>
</authors>
<title>Gunther Fliedl and Matthias Fuchs. 2012.&amp;quot;Classification of customer reviews based on sentiment analysis,&amp;quot;</title>
<date></date>
<booktitle>presented at the 19th Conference on Information and Communication Technologies in Tourism (ENTER),</booktitle>
<location>Helsingborg,</location>
<marker>Grabner, Zanker, </marker>
<rawString>Dietmar Grabner, Markus Zanker, Gunther Fliedl and Matthias Fuchs. 2012.&amp;quot;Classification of customer reviews based on sentiment analysis,&amp;quot; presented at the 19th Conference on Information and Communication Technologies in Tourism (ENTER), Helsingborg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eiji Aramaki</author>
<author>Sachiko Maskawa</author>
<author>Mizuki Morita</author>
</authors>
<title>Twitter catches the flu: detecting influenza epidemics using Twitter.</title>
<date>2011</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<location>Edinburgh, United</location>
<contexts>
<context position="4770" citStr="Aramaki et al. (2011)" startWordPosition="736" endWordPosition="739"> techniques of Naïve Bayes and SVM, Read (2005) achieved up to 61.50 % and 70.10%, accuracy respectively in determining text polarity from the emoticons used. Go et al. (2009) used distant supervision to classify sentiment of Twitter, similar to Read (2005). Emoticons were used as noisy labels in training data. This allowed the performance of supervised learning (positive and negative) at a distance. Three classifiers were used: Naïve Bayes, Maximum Entropy and SVM. These classifiers were able to obtain more than 81.30%, 80.50% and 82.20%, respectively accuracy on their unigram testing data . Aramaki et al. (2011) classified contexts on Twitter related to influenza using a SVM. The training data was annotated with the polarity label by humans, whether they are positive or negative. The contexts will be labelled as positive if the contexts mention the user or someone close to them has the flu, or if they mention a time when they caught the flu. The results demonstrated that they obtained a 0.89 correction ratio for their testing data against a gold standard. Finally, a well known paper by Bollen and Mao (2011) identified a correlation between the movements of the Dow Jones stock market index, and prevai</context>
</contexts>
<marker>Aramaki, Maskawa, Morita, 2011</marker>
<rawString>Eiji Aramaki, Sachiko Maskawa and Mizuki Morita. 2011. Twitter catches the flu: detecting influenza epidemics using Twitter. Proceedings of the Conference on Empirical Methods in Natural Language Processing. Edinburgh, United Kingdom: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bollen</author>
<author>Huina Mao</author>
</authors>
<title>Twitter mood as a stock market predictor.</title>
<journal>IEEE Computer,</journal>
<volume>44</volume>
<issue>10</issue>
<marker>Bollen, Mao, </marker>
<rawString>Johan. Bollen and Huina. Mao. Twitter mood as a stock market predictor. IEEE Computer, 44(10):91–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathon Read</author>
</authors>
<title>Using emoticons to reduce dependency in machine learning techniques for sentiment classification.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL Student Research Workshop.</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan:</location>
<contexts>
<context position="4013" citStr="Read (2005)" startWordPosition="619" endWordPosition="620"> marketing can find customer sentiment (both positive and negative) far more quickly than through the use of web pages or traditional media. Consequently analyzing the sentiment of tweets is currently active research task. The word &apos;emoticon&apos; is a neologistic contraction of &apos;emotional icon&apos;. It refers specifically to the use of combinations of punctuation characters to indicate sentiment in a text. Well known emoticons include :) to represent a happy face, and :( a sad one. Emoticons allow writers to augment the impact of limited texts (such as in SMS messages or tweets) using few characters. Read (2005) used emoticons from a training set downloaded from Usenet newsgroups as annotations (positive and negative). Using the machine learning techniques of Naïve Bayes and SVM, Read (2005) achieved up to 61.50 % and 70.10%, accuracy respectively in determining text polarity from the emoticons used. Go et al. (2009) used distant supervision to classify sentiment of Twitter, similar to Read (2005). Emoticons were used as noisy labels in training data. This allowed the performance of supervised learning (positive and negative) at a distance. Three classifiers were used: Naïve Bayes, Maximum Entropy an</context>
</contexts>
<marker>Read, 2005</marker>
<rawString>Jonathon Read. 2005. Using emoticons to reduce dependency in machine learning techniques for sentiment classification. Proceedings of the ACL Student Research Workshop. Ann Arbor, Michigan: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lior Rokach</author>
</authors>
<title>Chapter 45 Ensemble Methods for Classifiers. In: Oded Maimon and Lior Rokach (eds.) Data Mining and Knowledge Discovery Handbook.</title>
<date>2005</date>
<publisher>Springer US.</publisher>
<marker>Rokach, 2005</marker>
<rawString>Lior Rokach. 2005. Chapter 45 Ensemble Methods for Classifiers. In: Oded Maimon and Lior Rokach (eds.) Data Mining and Knowledge Discovery Handbook. Springer US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
<author>Susan T Dumais</author>
<author>Edgar Osman</author>
<author>John Platt</author>
<author>Bernhard Scholkopf</author>
</authors>
<title>Support vector machines.</title>
<date>1998</date>
<journal>IEEE, Intelligent Systems and their Applications,</journal>
<volume>13</volume>
<pages>18--28</pages>
<contexts>
<context position="8173" citStr="Hearst et al., 1998" startWordPosition="1277" endWordPosition="1280">wcastleuk. Frequently repeated letters are used in tweets for emphasis. These were reduced and replaced using a simple regular expression by two of the same character. For example, happpppppy will be replaced with happy, and coollllll will be replaced by cooll. Next, special character such as [j,{,},?,and ! were also removed. Slang and contracted words were converted to their full form. E.g. ‘fyi’ was converted to ‘for your information’. Finally, NLTK (Bird et al. 2009) stopwords such as ‘a’, ‘the’, etc., were removed from the datasets. 3.2 Classifier Our system uses the SVM classifier model (Hearst et al., 1998, Cristianini and ShaweTaylor, 2000), which is based on SVM-light (Joachims, 1999). SVM is a binary linear classification model with the learning algorithm for classification and regression analyzing the data and recognizing the pattern. Training SVMLight requires data to be formulated into vectors of attribute value pairs preceded by a numeric value. For example, &lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; # &lt;info&gt; Here, ‘target’ represents the polarity of a sentence or tweet; ‘feature’ refers to a term in the document, and ‘value’ refers to a feature weight. This could</context>
</contexts>
<marker>Hearst, Dumais, Osman, Platt, Scholkopf, 1998</marker>
<rawString>Marti A. Hearst, Susan T. Dumais, Edgar Osman, John Platt and Bernhard Scholkopf . 1998. Support vector machines. IEEE, Intelligent Systems and their Applications, 13, 18-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masoud Makrehchi</author>
<author>Sameena Shah</author>
<author>Wenhui Liao</author>
</authors>
<title>Stock Prediction Using Event-Based Sentiment Analysis. Web Intelligence (WI) and Intelligent Agent Technologies (IAT),</title>
<date>2013</date>
<journal>IEEE/WIC/ACM International Joint Conferences</journal>
<volume>on,.</volume>
<pages>337--342</pages>
<contexts>
<context position="5503" citStr="Makrehchi et al (2013)" startWordPosition="860" endWordPosition="863">rity label by humans, whether they are positive or negative. The contexts will be labelled as positive if the contexts mention the user or someone close to them has the flu, or if they mention a time when they caught the flu. The results demonstrated that they obtained a 0.89 correction ratio for their testing data against a gold standard. Finally, a well known paper by Bollen and Mao (2011) identified a correlation between the movements of the Dow Jones stock market index, and prevailing sentiment as determined from twitter&apos;s live feed. This application has prompted considerable work such as Makrehchi et al (2013) that has attempted to create successful trading strategies from sentiment analysis of tweets. These work both the wide ranging applications of analysing twitter data, and the importance of Sentiment Analysis. We now move on to look at our approach to SemEval 2014 task 9. 3 Methodology 3.1 Corpus The training and development dataset of SemEval was built using Tweets from more than one thousand pieces of context. The contexts have various features often used in Tweets, such as emoticons, tags, usernames etc. These features were extracted from the datasets before training for the supervised mach</context>
</contexts>
<marker>Makrehchi, Shah, Liao, 2013</marker>
<rawString>Masoud Makrehchi, Sameena Shah and Wenhui Liao. 2013. Stock Prediction Using Event-Based Sentiment Analysis. Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on,. 337-342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
</authors>
<title>An introduction to support vector machines and other kernel-based learning methods, Cambridge university press.</title>
<date>2000</date>
<marker>Cristianini, Shawe-Taylor, 2000</marker>
<rawString>Nello Cristianini and John Shawe-Taylor. 2000. An introduction to support vector machines and other kernel-based learning methods, Cambridge university press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<date>2014</date>
<booktitle>SemEval-2014 Task 9: Sentiment Analysis in Twitter. International Workshop on Semantic Evaluation (SemEval2014).</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2116" citStr="Rosenthal et al., 2014" startWordPosition="314" endWordPosition="317">Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ reviews as bad, neutral and good. Similarly, Tumasjan et al. (2010) tried to predict the outcome of the German federal election through the analysis more than 100,000 tweets posted in the lead up. Sentiment analysis has also used to classify whether dreams are positive or negative (Nadeau et al. 2006). This paper presents the TJP system which was submitted to SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation (Rosenthal et al., 2014). TJP focused on the ‘Constrained’ task. The ‘Constrained’ task only uses data provided by the organizers. That is, external resources such as sentiment inventories (e.g. Sentiwordnet (Esuli, and Sebastiani 2006) are excluded. The objective of the TJP system was to use the results for comparison with our previous experiment (Chalothorn and Ellman, 2013). More details of these can be found in section 5. The TJP system was implemented using a support vector machine (SVM, e.g. Joachims, 1999) with the addition of extensive preprocessing such as stopword removal, negation, slang, contraction, and </context>
</contexts>
<marker>Rosenthal, Nakov, Ritter, Stoyanov, 2014</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Alan Ritter and Veselin Stoyanov. 2014. SemEval-2014 Task 9: Sentiment Analysis in Twitter. International Workshop on Semantic Evaluation (SemEval2014). Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<title>NLTK: Natural language processing with Python,</title>
<date>2009</date>
<location>O&apos;Reilly.</location>
<contexts>
<context position="8028" citStr="Bird et al. 2009" startWordPosition="1252" endWordPosition="1255">hrase such as #newcastleuk. This feature has been replaced with the following word after # symbol. For example, #newcastleuk was replaced by newcastleuk. Frequently repeated letters are used in tweets for emphasis. These were reduced and replaced using a simple regular expression by two of the same character. For example, happpppppy will be replaced with happy, and coollllll will be replaced by cooll. Next, special character such as [j,{,},?,and ! were also removed. Slang and contracted words were converted to their full form. E.g. ‘fyi’ was converted to ‘for your information’. Finally, NLTK (Bird et al. 2009) stopwords such as ‘a’, ‘the’, etc., were removed from the datasets. 3.2 Classifier Our system uses the SVM classifier model (Hearst et al., 1998, Cristianini and ShaweTaylor, 2000), which is based on SVM-light (Joachims, 1999). SVM is a binary linear classification model with the learning algorithm for classification and regression analyzing the data and recognizing the pattern. Training SVMLight requires data to be formulated into vectors of attribute value pairs preceded by a numeric value. For example, &lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; # &lt;info&gt; Here, ‘targe</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein and Edward Loper. 2009. NLTK: Natural language processing with Python, O&apos;Reilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Sakaki</author>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Earthquake shakes Twitter users: real-time event detection by social sensors.</title>
<date>2010</date>
<booktitle>Proceedings of the 19th international conference on World wide web.</booktitle>
<publisher>ACM.</publisher>
<location>Raleigh, North Carolina, USA:</location>
<marker>Sakaki, Okazaki, Matsuo, 2010</marker>
<rawString>Takeshi Sakaki, Makoto Okazaki and Yutaka Matsuo. 2010. Earthquake shakes Twitter users: real-time event detection by social sensors. Proceedings of the 19th international conference on World wide web. Raleigh, North Carolina, USA: ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tawunrat Chalothorn</author>
<author>Jeremy Ellman</author>
</authors>
<title>TJP: Using Twitter to Analyze the Polarity of Contexts.</title>
<date>2013</date>
<booktitle>Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013).</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA:</location>
<contexts>
<context position="2471" citStr="Chalothorn and Ellman, 2013" startWordPosition="368" endWordPosition="371">ted in the lead up. Sentiment analysis has also used to classify whether dreams are positive or negative (Nadeau et al. 2006). This paper presents the TJP system which was submitted to SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation (Rosenthal et al., 2014). TJP focused on the ‘Constrained’ task. The ‘Constrained’ task only uses data provided by the organizers. That is, external resources such as sentiment inventories (e.g. Sentiwordnet (Esuli, and Sebastiani 2006) are excluded. The objective of the TJP system was to use the results for comparison with our previous experiment (Chalothorn and Ellman, 2013). More details of these can be found in section 5. The TJP system was implemented using a support vector machine (SVM, e.g. Joachims, 1999) with the addition of extensive preprocessing such as stopword removal, negation, slang, contraction, and emoticon expansions. The remainder of this paper is constructed as follows: firstly, related work is discussed in section 2; the methodology, the experiment and results are presented in sections 3 and 4, 657 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 657–662, Dublin, Ireland, August 23-24, 2014. respective</context>
</contexts>
<marker>Chalothorn, Ellman, 2013</marker>
<rawString>Tawunrat Chalothorn and Jeremy Ellman. 2013. TJP: Using Twitter to Analyze the Polarity of Contexts. Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013). Atlanta, Georgia, USA: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Alan Ritter</author>
<author>Sara Rosenthal</author>
<author>Veselin Stoyanov</author>
</authors>
<date>2013</date>
<booktitle>SemEval-2013 Task 2: Sentiment Analysis in Twitter. Proceedings of the 7th International Workshop on Semantic Evaluation. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="12780" citStr="Wilson et al., 2013" startWordPosition="2041" endWordPosition="2044">ysis of feature effectiveness. That is, we attempted to identify which factor(s) made the most significant improvement to system performance. It is clear the pre-processing had a considerable effect on system performance. The use of a different learning algorithm also contributed to performance since, on this task, SVMLight performed better than the Naive Bayes algorithm that was used by our team in 2013. Sentiment resources was not been used in our system in SemEval 2014 as same as in SemEval 2013 whilst other user groups have employed a variety of resources of different sizes, and accuracy (Wilson et al., 2013). These points lead to the following plan for future activities. Our future work is to rigorously investigate the success factors for sentiment analysis, especially in the twitter domain. More specifically, we have formulated the following research questions as a result of our participation in SemEval • Are Sentiment resources essential for the Sentiment Analysis task? • Can the accuracy and effectiveness of sentiment lexicons be measured? If so, which feature of the resource (accuracy vs. coverage) is the most effective metric. • Might it be more effective to use a range of sentiments (e.g. [</context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Ritter, Rosenthal, Stoyanov, 2013</marker>
<rawString>Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Alan Ritter, Sara Rosenthal and Veselin Stoyanov. 2013. SemEval-2013 Task 2: Sentiment Analysis in Twitter. Proceedings of the 7th International Workshop on Semantic Evaluation. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale support vector machine learning practical. Advances in kernel methods.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2610" citStr="Joachims, 1999" startWordPosition="394" endWordPosition="395">JP system which was submitted to SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation (Rosenthal et al., 2014). TJP focused on the ‘Constrained’ task. The ‘Constrained’ task only uses data provided by the organizers. That is, external resources such as sentiment inventories (e.g. Sentiwordnet (Esuli, and Sebastiani 2006) are excluded. The objective of the TJP system was to use the results for comparison with our previous experiment (Chalothorn and Ellman, 2013). More details of these can be found in section 5. The TJP system was implemented using a support vector machine (SVM, e.g. Joachims, 1999) with the addition of extensive preprocessing such as stopword removal, negation, slang, contraction, and emoticon expansions. The remainder of this paper is constructed as follows: firstly, related work is discussed in section 2; the methodology, the experiment and results are presented in sections 3 and 4, 657 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 657–662, Dublin, Ireland, August 23-24, 2014. respectively. Finally a discussion and future work are given in section 5. 2 Related Work Twitter is a popular social networking and microblogging si</context>
<context position="8255" citStr="Joachims, 1999" startWordPosition="1291" endWordPosition="1293">uced and replaced using a simple regular expression by two of the same character. For example, happpppppy will be replaced with happy, and coollllll will be replaced by cooll. Next, special character such as [j,{,},?,and ! were also removed. Slang and contracted words were converted to their full form. E.g. ‘fyi’ was converted to ‘for your information’. Finally, NLTK (Bird et al. 2009) stopwords such as ‘a’, ‘the’, etc., were removed from the datasets. 3.2 Classifier Our system uses the SVM classifier model (Hearst et al., 1998, Cristianini and ShaweTaylor, 2000), which is based on SVM-light (Joachims, 1999). SVM is a binary linear classification model with the learning algorithm for classification and regression analyzing the data and recognizing the pattern. Training SVMLight requires data to be formulated into vectors of attribute value pairs preceded by a numeric value. For example, &lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; # &lt;info&gt; Here, ‘target’ represents the polarity of a sentence or tweet; ‘feature’ refers to a term in the document, and ‘value’ refers to a feature weight. This could be used as the relative frequency of a term in the set of documents, or Tf-Idf. T</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale support vector machine learning practical. Advances in kernel methods. MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>