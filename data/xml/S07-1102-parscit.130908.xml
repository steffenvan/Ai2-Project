<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019938">
<title confidence="0.9940735">
UTD-SRL: A Pipeline Architecture for Extracting Frame
Semantic Structures
</title>
<author confidence="0.461473">
Cosmin Adrian Bejan and Chris Hathaway
</author>
<affiliation confidence="0.662262">
Human Language Technology Research Institute
The University of Texas at Dallas
</affiliation>
<address confidence="0.698069">
Richardson, TX 75083-0688, USA
</address>
<email confidence="0.999442">
{ady,chris}@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961555555556">
This paper describes our system for the task
of extracting frame semantic structures in
SemEval–2007. The system architecture
uses two types of learning models in each
part of the task: Support Vector Machines
(SVM) and Maximum Entropy (ME). De-
signed as a pipeline of classifiers, the seman-
tic parsing system obtained competitive pre-
cision scores on the test data.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999849272727273">
The SemEval–2007 task for extracting frame se-
mantic structures relies on the human annotated
data available in the FrameNet (FN) database. The
Berkeley FrameNet project (Baker et al., 1998) is
an ongoing effort of building a semantic lexicon for
English based on the theory of frame semantics. In
frame semantics, the meaning of words or word ex-
pressions, also called target words (TW), comprises
aspects of conceptual structures, or frames, that de-
scribe specific situations. The semantic roles, or
frame elements (FE), associated with a target word
are locally defined in the frame evoked by the tar-
get word. Currently, the FN lexicon includes more
than 135,000 sentences extracted from the British
National Corpus containing more than 6,100 target
words that evoke more than 825 semantic frames.
For this task, we extended our previous work at
Senseval-3 (Bejan et al., 2004) by (1) experiment-
ing with additional features, (2) adding new classifi-
cation sub-tasks to accomplish all the requirements,
and (3) integrating these sub-tasks into a pipeline ar-
chitecture.
</bodyText>
<sectionHeader confidence="0.995739" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999964916666667">
Given a sentence, the frame semantic structure ex-
traction task consists of recognizing the word ex-
pressions that evoke semantic frames, assigning the
correct frame to them and, for each target word,
detecting and labeling the corresponding frame el-
ements properly. The task also requires the de-
termination of syntactic realizations associated to a
frame element, such as grammatical function (GF)
and phrase type (PT). The following illustrates a
sentence example annotated with frame elements to-
gether with their corresponding grammatical func-
tions and phrase types for the target word “tie”:
</bodyText>
<equation confidence="0.3918135">
Frame = Make_Cognitive_Connection
evokes
</equation>
<bodyText confidence="0.869613">
AEOI’s activities and facilities have been tied to several universities .
</bodyText>
<equation confidence="0.999543666666666">
FE = Content1 FE = Content2
GF = Ext GF = Dep
PT = NP PT = PP
</equation>
<bodyText confidence="0.999770375">
To extract semantic structures similar to those il-
lustrated in the example we divide the SemEval–
2007 task into four sub-tasks: (1) target word frame
disambiguation (TWFD); (2) FE boundary detection
(FEBD); (3) GF label classification (GFLC) and (4)
FE label classification (FELC). The sub-tasks TWFD
and GFLC are natural extensions of the approach de-
scribed in (Bejan et al., 2004) for the task of se-
mantic role labeling at Senseval-03. We design ma-
chine learning classifiers specific for each of the four
sub-tasks and arrange them in a pipeline architecture
such that a classifier can use information predicted
by its previous classifiers. The system architecture
is illustrated in Figure 1. In the data processing step,
we parse each sentence into a syntactic tree using the
Collins parser and extract named entities using an in
</bodyText>
<page confidence="0.991922">
460
</page>
<bodyText confidence="0.5737115">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 460–463,
Prague, June 2007. c�2007 Association for Computational Linguistics
</bodyText>
<figure confidence="0.999872882352942">
Test data
FrameNet
Lexicon
SVM model
556 multi−class classifiers
Frame Disambiguation
SVM train
Feature Extractor
Data Processing
ME model
Target word list
ME train
Named Entity
Recognizer
Syntactic
Parser
Train Data
Test Data
Extractor
Feature
Frame
Predictor
SVM model
SVM train
FE Boundary Detection
one binary classifier
Feature Extractor
Target word
Test Data
Frame
ME model
ME train
Extractor
Feature
FE Boundary
Predictor
Target word
Test Data
FE Boundary
Frame
SVM model
GF Label Classification
SVM train
one multi−class classifier
Feature Extractor
ME model
Extractor
ME train
Feature
GF Label
Predictor
Target word
Test Data
GF
FE Boundary
Frame
Extractor
Feature
SVM model
489 multi−class classifiers
SVM train
FE Label Classification
FE Label
Predictor
Feature Extractor
ME model
ME train
FN Annotation
</figure>
<figureCaption confidence="0.999993">
Figure 1: System architecture.
</figureCaption>
<bodyText confidence="0.999915666666667">
house implementation of a named entity recognizer.
We also extract from the FN lexicon mappings of
target words and the semantic frames they evoke.
Various features corresponding to constituents
were extracted and passed to SVM and ME clas-
sifiers. For example, in Figure 2, the frame dis-
</bodyText>
<figureCaption confidence="0.981238">
Figure 2: Classification examples for each sub-task.
</figureCaption>
<bodyText confidence="0.999923611111111">
ambiguation sub-task extracts features correspond-
ing to the constituent tied in order to predict the
right frame between the semantic frames that can be
evoked by this target word. In this figure, the correct
categories for each sub-task are shown in boldface.
The complete set of features extracted for all the
classification sub-tasks is illustrated in Figure 3.
These represent a subset of features used in previ-
ous works (Gildea and Jurafsky, 2002; Florian et al.,
2002; Surdeanu et al., 2003; Xue and Palmer, 2004;
Bejan et al., 2004; Pradhan et al., 2005) for auto-
matic semantic role labeling and word sense disam-
biguation. Figure 3 also indicates whether or not a
feature is selected for a specific classification task.
In the remaining part of this section we describe
in detail each classification sub-task and the features
that have the most salient effect on improving the
corresponding classifiers.
</bodyText>
<subsectionHeader confidence="0.988921">
2.1 Frame Disambiguation
</subsectionHeader>
<bodyText confidence="0.999980555555556">
In FrameNet, some target words can evoke multiple
semantic frames. In order to extract the semantic
structure of an ambiguous target word, the first step
is to assign the correct frame to the target word in
a given context. This task is similar with the word
sense disambiguation task.
We select from the FN lexicon 556 target words
that evoke at least two semantic frames and have at
least five sentences annotated for each frame, and
assemble a multi-class classifier for each ambiguous
target word. As described in Figure 3, for this task
we extract features used in word sense disambigua-
tion (Florian et al., 2002), lexical features of the tar-
get word, and NAMED ENTITY FLAGS associated
with the root node in a syntactic parse tree. For
the rest of the ambiguous target words that have less
than five sentences annotated we randomly choose a
frame as being the correct frame in a given context.
</bodyText>
<subsectionHeader confidence="0.998879">
2.2 Frame Element Identification
</subsectionHeader>
<bodyText confidence="0.999525571428571">
The idea of splitting the automatic semantic role la-
beling task into FE boundary detection and FE label
classification was first proposed in (Gildea and Ju-
rafsky, 2002) and then adopted by other works in
this task. The problem of detecting the FE bound-
aries is cast as the problem of deciding whether or
not a constituent is a valid candidate for a FE.
</bodyText>
<figure confidence="0.999391241379311">
AEOI
Inhibit_movement
Rope_manipulation
Attaching
Closure
Activity_finish
NNP POS
NP
’s
activities
NP
NNS
Frame Disambiguation
Knot_creation
Finish_competition
Immobilization
Make_cognitive_connection
Forming_relationships
and
CC
facilities
NNS
S
have
VBP
FE Boundary Detection
been
VP
positive negative
VBN
VBN
VP
tied to NP
VP
several
JJ
PP
universities
NNS
Appositive
Dep
Ext
Gen
GF Classification
Time
Place
Concept_1
Concept_2
Evidence
Cognizer
Concepts
Circumstances
Frequency
FE Classif.
Head
NULL
Obj
Quant
</figure>
<page confidence="0.996401">
461
</page>
<table confidence="0.89859003030303">
TWFD FEBD FELC TWFD FEBD CELF Feature Description
GFLC Feature Description GFLC
N
O
01 v TW UNIGRAMS: The words, stem words and part of speech (POS) unigrams 20 v CW: The content word of the constituent computed as described in
that are adjacent to target word expressions; (Surdeanu et al., 2003);
02 v TW BIGRAMS: The words, stem words and POS bigrams that are adjacent to 21 v CW POS: The POS corresponding to the content word;
target word expressions; 22 v CW STEM: Stemmed content word;
03 v TW WORD: The target word expression; 23 v v GOVERNING CATEGORY: Test whether the noun phrase constituents are
04 v v TW STEM: The stem word(s) of the target word expression; dominated by verbal phrases or sentence phrases;
05 v TW POS: The POS of the target word; 24 v SYNTACTIC DISTANCE: The length of the syntactic path;
06 v v TW CLASS: The lexical class of the target word, e.g. verb, noun, adjective; 25 v PP FIRST WORD: If the constituent is a prepositional phrase, return the first
07 v v NAMED ENTITY FLAGS: Set of binary features indicating whether a consti− word in the phrase;
tuent contains, is contained or exactly identifies a named entity; 26 v HUMAN: Test whether the constituent phrase is either a personal pronoun
08 v VERB WSD: If the target word is a verb, extract the head noun of the direct or a hyponym of first sense of PERSON synset in WordNet;
object and the prepositional object included in the verbal phrase; 27 v CONSTITUENTS NUMBER: The number of candidate FEs;
09 v NOUN WSD: If the target word is a noun, extract the head word of the verbal 28 v CONSTITUENTS LIST: Constituents labels list of the candidate FEs;
phrase that is in a verb−subject or verb−object relation with the noun; 29 v SAME CLAUSE: Test whether the constituent is in the same clause with
10 v ADJECTIVE WSD: If the target word is an adjective, extract the head noun the target word;
that is modified by the adjective; 30 v GF: The grammatical function of a candidate frame element;
11 v v PHRASE TYPE: The syntactic category of the constituent; 31 v GF LIST: The list of grammatical functions associated to the candidate FEs;
12 v v v DIRECTED PATH: Path in the syntactic parse tree between the constituent 32 v v v FRAME: The name of the semantic frame that is evoked by the target word;
and the target word preserving the movement direction; 33 v NP SISTER: Determine whether the constituent has a noun phrase sister;
13 v UNDIRECTED PATH: Same syntactic path as DIRECTED PATH without 34 v FIRST/LAST WORD: Return the first/last word of the constituent phrase;
preserving the movement direction; 35 v v FIRST/LAST POS: Return the first/last POS in the constituent;
14 v PARTIAL PATH: Path from the constituent to the earlier common ancestor of 36 v LEFT/RIGHT SISTER LABEL: Return the left/right sibling constituent label;
the target word and the constituent; 37 v LEFT/RIGHT SISTER HEAD: Return the left/right sibling head word;
15 v v v POSITION: Test whether the constituent contains the target word, or appears 38 v LEFT/RIGHT SISTER STEM HEAD: Return the left/right sibling stemmed
before or after the target word; head word;
16 v v VOICE: Test if the verbal target word has active or passive construction; 39 v LEFT/RIGHT SISTER POS HEAD: Return the left/right sibling head POS;
17 v v v HW: The head word of the constituent; 40 v TW STEM &amp; HW STEM: Join of TW STEM and HW STEM;
18 v v HW POS: The syntactic head POS of the constituent; 41 v TW STEM &amp; PHRASE TYPE: Join of TW STEM and PHRASE TYPE;
19 v HW STEM: The stem word of the constituent’s head word; 42 v VOICE &amp; POSITION: Join of VOICE and POSITION.
</table>
<figureCaption confidence="0.987557">
Figure 3: Feature set for extracting frame semantic structures.
</figureCaption>
<bodyText confidence="0.999970666666667">
We consider a binary classifier over the entire FN
data and extract features for each constituent from a
syntactic parse tree. Because this experimental setup
allows training the binary classifier on a large set of
examples, the best feature combination consists of
a restrained number of features. Most of these fea-
tures are from the set proposed by (Gildea and Juraf-
sky, 2002). Another feature that improved the pre-
diction of FE boundaries in every feature selection
experiment is the FRAME feature. Since the frame
disambiguation is executed before the FE boundary
detection in the pipeline architecture, we can use the
FRAME feature at this step. This feature helps the
binary classifier distinguish between frame element
structures from different semantic frames.
</bodyText>
<subsectionHeader confidence="0.99968">
2.3 Grammatical Function Classification
</subsectionHeader>
<bodyText confidence="0.999973">
Once we identify the candidate boundaries for frame
elements, the next step is to assign the grammat-
ical functions to these boundaries. In FrameNet,
the grammatical functions represent the manner in
which the frame elements satisfy grammatical con-
straints with respect to the target word.
For this task we train a multi-class classifier over
the entire lexicon to predict seven categories of GFs
that exist in FN. In addition, we assign the NULL
category for those FEs that double as target words.
The features are extracted only for the constituents
that are identified as FEs in the previous FE bound-
ary identification sub-task. The best feature set in
this phase includes the features proposed by (Gildea
and Jurafsky, 2002) and the FRAME feature.
</bodyText>
<subsectionHeader confidence="0.999234">
2.4 Frame Element Classification
</subsectionHeader>
<bodyText confidence="0.9999752">
The task of FE classification is to assign FE labels to
every constituent identified as FE. In order to predict
the frame elements, which are locally defined for
each semantic frame, we built 489 multi-class clas-
sifiers, where each classifier corresponds to a frame
in FrameNet. This partitioning of the FN lexicon has
the advantage of increasing the overall classification
performance and efficiently learning the frame ele-
ments labels. On the other hand, this approach suf-
fers from the lack of annotated data in some frames
and hence it requires using a large set of features.
The advantage of designing the classifiers in a
pipeline architecture is best illustrated in this sub-
task. Some of the most effective features for FE
classification are extracted using information from
previous sub-tasks: FRAME feature is made avail-
able by the TWFD sub-task, CONSTITUENTS NUM-
BER and CONSTITUENTS LIST are made available
by the FEBD sub-task, and GF and GF LIST are
made available by the GFLC sub-task.
</bodyText>
<page confidence="0.998797">
462
</page>
<sectionHeader confidence="0.999434" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.99572125">
We report experimental results on all four classi-
fication sub-tasks. In our experiments we trained
two types of classification models for each sub-task:
SVM and ME. In order to optimize the performance
measure of each sub-task and to find the best config-
uration of classification models we used 20% of the
sub-tasks training data as validation data. Table 1
lists the best configuration of classification models
as well as the best sub-task results when running
the experiments on the validation data. For frame
disambiguation, we obtained 76.71% accuracy com-
pared to a baseline of 60.72% accuracy that always
predicts the most annotated frame for each of the
556 target words. The results for GFLC and FELC
sub-tasks listed in Table 1 were achieved by using
gold FE boundaries.
</bodyText>
<table confidence="0.999265166666667">
Task Best Model Accuracy
Frame Disambiguation SVM 76.71
GF Label Classification ME 96.00
FE Label Classification ME 88.93
Precision Recall F1−measure
FE Boundary Detection SVM 73.65 87.08 79.80
</table>
<tableCaption confidence="0.999813">
Table 1: Task results on the validation set.
</tableCaption>
<bodyText confidence="0.999411">
The SemEval–2007 organizers provided fully an-
notated training files, a scorer to evaluate these
training files, and testing files containing flat sen-
tences. In the evaluation process, a semantic depen-
dency graph corresponding to a fully system anno-
tated sentence is created and then matched with its
gold dependency graph. The matching process not
only evaluates every semantic structure of a target
word, but also considers frame-to-frame and FE-to-
FE graph relations between the semantic structures.
In addition, various scoring options were consid-
ered: exact or partial frame matching, partial credit
for evaluating the named entities, evaluation of the
flat frame elements labels, and an option for match-
ing only the frames in evaluation. The evaluation for
flat frame elements labels is similar with the evalu-
ation performed at Senseval-3. The only difference
is that for this scorer the FE boundaries must match
exactly.
In Table 2, we present the averaged precision,
recall and F1 measures for evaluating the seman-
tic dependency graphs and detecting the semantic
frames on the testing files. The “Options” col-
umn represents the configuration parameters of the
scorer: (E)xact/(P)artial frame matching, seman-
tic (D)ependency or (L)abels only evaluation, and
(Y)es/(N)o named entity evaluation.
</bodyText>
<table confidence="0.9990971">
Options Semantic Dependency Evaluation Frame Detection Evaluation
Precision Recall F1−measure Precision Recall F1−measure
E L Y 51.10 27.74 35.88 69.16 42.73 52.71
P L Y 55.56 30.19 39.04 77.82 48.09 59.32
E D Y 50.29 27.05 35.11 71.69 44.43 54.74
P D Y 54.78 29.48 38.26 80.35 49.79 61.35
E L N 51.85 27.59 35.94 69.16 42.73 52.71
P L N 56.59 30.14 39.25 77.82 48.09 59.32
E D N 51.38 26.95 35.29 71.69 44.43 54.74
P D N 56.13 29.45 38.57 80.35 49.79 61.35
</table>
<tableCaption confidence="0.998559">
Table 2: System results on the test set.
</tableCaption>
<bodyText confidence="0.999820833333333">
Although the system achieved good precision
scores on the test data, the recall values caused the
system to obtain unsatisfactory F1-measure values.
We expect that the recall will increase by consid-
ering various heuristics for a better mapping of the
frame elements to constituents in parse trees.
</bodyText>
<sectionHeader confidence="0.999905" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999954666666667">
We described a system that participated in SemEval–
2007 for the task of extracting frame semantic struc-
tures. We showed that a pipeline architecture of the
SVM and ME classifiers as well as an adequate se-
lection of the classification models can improve the
performance measures of each sub-task.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999645">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998.
The Berkeley FrameNet project. In Proceedings of the
COLING-ACL, Montreal, Canada.
Cosmin Adrian Bejan, Alessandro Moschitti, Paul Mor˘arescu,
Gabriel Nicolae, and Sanda Harabagiu. 2004. Semantic
Parsing Based on FrameNet. In Senseval-3: Workshop on
the Evaluation of Systems for the Semantic Analysis of Text.
Radu Florian, Silviu Cucerzan, Charles Schafer, and David
Yarowsky. 2002. Combining classifiers for word sense dis-
ambiguation. Natural Language Engineering.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling
of Semantic Roles. Computational Linguistic.
Sameer Pradhan, Kadri Hacioglu, Valeri Krugler, Wayne Ward,
James H. Martin, and Daniel Jurafsky. 2005. Support vec-
tor learning for semantic argument classification. Journal of
Machine Learning Research.
Mihai Surdeanu, Sanda M. Harabagiu, John Williams, and Paul
Aarseth. 2003. Using predicate-argument structures for in-
formation extraction. In Proceedings ofACL.
Nianwen Xue and Marta Palmer. 2004. Calibrating features for
semantic role labeling. In Proceedings ofEMNLP.
</reference>
<page confidence="0.999714">
463
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969276">
<title confidence="0.9996805">UTD-SRL: A Pipeline Architecture for Extracting Frame Semantic Structures</title>
<author confidence="0.999863">Adrian Bejan Hathaway</author>
<affiliation confidence="0.999043">Human Language Technology Research Institute The University of Texas at Dallas</affiliation>
<address confidence="0.99783">Richardson, TX 75083-0688, USA</address>
<abstract confidence="0.9973783">This paper describes our system for the task of extracting frame semantic structures in SemEval–2007. The system architecture uses two types of learning models in each part of the task: Support Vector Machines (SVM) and Maximum Entropy (ME). Designed as a pipeline of classifiers, the semantic parsing system obtained competitive precision scores on the test data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING-ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="830" citStr="Baker et al., 1998" startWordPosition="118" endWordPosition="121">3-0688, USA {ady,chris}@hlt.utdallas.edu Abstract This paper describes our system for the task of extracting frame semantic structures in SemEval–2007. The system architecture uses two types of learning models in each part of the task: Support Vector Machines (SVM) and Maximum Entropy (ME). Designed as a pipeline of classifiers, the semantic parsing system obtained competitive precision scores on the test data. 1 Introduction The SemEval–2007 task for extracting frame semantic structures relies on the human annotated data available in the FrameNet (FN) database. The Berkeley FrameNet project (Baker et al., 1998) is an ongoing effort of building a semantic lexicon for English based on the theory of frame semantics. In frame semantics, the meaning of words or word expressions, also called target words (TW), comprises aspects of conceptual structures, or frames, that describe specific situations. The semantic roles, or frame elements (FE), associated with a target word are locally defined in the frame evoked by the target word. Currently, the FN lexicon includes more than 135,000 sentences extracted from the British National Corpus containing more than 6,100 target words that evoke more than 825 semanti</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of the COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cosmin Adrian Bejan</author>
<author>Alessandro Moschitti</author>
<author>Paul Mor˘arescu</author>
<author>Gabriel Nicolae</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Semantic Parsing Based on FrameNet.</title>
<date>2004</date>
<booktitle>In Senseval-3: Workshop on the Evaluation of Systems for the Semantic Analysis of Text.</booktitle>
<marker>Bejan, Moschitti, Mor˘arescu, Nicolae, Harabagiu, 2004</marker>
<rawString>Cosmin Adrian Bejan, Alessandro Moschitti, Paul Mor˘arescu, Gabriel Nicolae, and Sanda Harabagiu. 2004. Semantic Parsing Based on FrameNet. In Senseval-3: Workshop on the Evaluation of Systems for the Semantic Analysis of Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Silviu Cucerzan</author>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Combining classifiers for word sense disambiguation. Natural Language Engineering.</title>
<date>2002</date>
<contexts>
<context position="5167" citStr="Florian et al., 2002" startWordPosition="798" endWordPosition="801">s were extracted and passed to SVM and ME classifiers. For example, in Figure 2, the frame disFigure 2: Classification examples for each sub-task. ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word. In this figure, the correct categories for each sub-task are shown in boldface. The complete set of features extracted for all the classification sub-tasks is illustrated in Figure 3. These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation. Figure 3 also indicates whether or not a feature is selected for a specific classification task. In the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers. 2.1 Frame Disambiguation In FrameNet, some target words can evoke multiple semantic frames. In order to extract the semantic structure of an ambiguous target word</context>
</contexts>
<marker>Florian, Cucerzan, Schafer, Yarowsky, 2002</marker>
<rawString>Radu Florian, Silviu Cucerzan, Charles Schafer, and David Yarowsky. 2002. Combining classifiers for word sense disambiguation. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistic.</journal>
<contexts>
<context position="5145" citStr="Gildea and Jurafsky, 2002" startWordPosition="794" endWordPosition="797">orresponding to constituents were extracted and passed to SVM and ME classifiers. For example, in Figure 2, the frame disFigure 2: Classification examples for each sub-task. ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word. In this figure, the correct categories for each sub-task are shown in boldface. The complete set of features extracted for all the classification sub-tasks is illustrated in Figure 3. These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation. Figure 3 also indicates whether or not a feature is selected for a specific classification task. In the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers. 2.1 Frame Disambiguation In FrameNet, some target words can evoke multiple semantic frames. In order to extract the semantic structure of an</context>
<context position="6730" citStr="Gildea and Jurafsky, 2002" startWordPosition="1059" endWordPosition="1063">each ambiguous target word. As described in Figure 3, for this task we extract features used in word sense disambiguation (Florian et al., 2002), lexical features of the target word, and NAMED ENTITY FLAGS associated with the root node in a syntactic parse tree. For the rest of the ambiguous target words that have less than five sentences annotated we randomly choose a frame as being the correct frame in a given context. 2.2 Frame Element Identification The idea of splitting the automatic semantic role labeling task into FE boundary detection and FE label classification was first proposed in (Gildea and Jurafsky, 2002) and then adopted by other works in this task. The problem of detecting the FE boundaries is cast as the problem of deciding whether or not a constituent is a valid candidate for a FE. AEOI Inhibit_movement Rope_manipulation Attaching Closure Activity_finish NNP POS NP ’s activities NP NNS Frame Disambiguation Knot_creation Finish_competition Immobilization Make_cognitive_connection Forming_relationships and CC facilities NNS S have VBP FE Boundary Detection been VP positive negative VBN VBN VP tied to NP VP several JJ PP universities NNS Appositive Dep Ext Gen GF Classification Time Place Con</context>
<context position="11492" citStr="Gildea and Jurafsky, 2002" startWordPosition="1887" endWordPosition="1891">onstituent; 41 v TW STEM &amp; PHRASE TYPE: Join of TW STEM and PHRASE TYPE; 19 v HW STEM: The stem word of the constituent’s head word; 42 v VOICE &amp; POSITION: Join of VOICE and POSITION. Figure 3: Feature set for extracting frame semantic structures. We consider a binary classifier over the entire FN data and extract features for each constituent from a syntactic parse tree. Because this experimental setup allows training the binary classifier on a large set of examples, the best feature combination consists of a restrained number of features. Most of these features are from the set proposed by (Gildea and Jurafsky, 2002). Another feature that improved the prediction of FE boundaries in every feature selection experiment is the FRAME feature. Since the frame disambiguation is executed before the FE boundary detection in the pipeline architecture, we can use the FRAME feature at this step. This feature helps the binary classifier distinguish between frame element structures from different semantic frames. 2.3 Grammatical Function Classification Once we identify the candidate boundaries for frame elements, the next step is to assign the grammatical functions to these boundaries. In FrameNet, the grammatical func</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valeri Krugler</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support vector learning for semantic argument classification.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="5255" citStr="Pradhan et al., 2005" startWordPosition="814" endWordPosition="817">ame disFigure 2: Classification examples for each sub-task. ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word. In this figure, the correct categories for each sub-task are shown in boldface. The complete set of features extracted for all the classification sub-tasks is illustrated in Figure 3. These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation. Figure 3 also indicates whether or not a feature is selected for a specific classification task. In the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers. 2.1 Frame Disambiguation In FrameNet, some target words can evoke multiple semantic frames. In order to extract the semantic structure of an ambiguous target word, the first step is to assign the correct frame to the target word in a given context. T</context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Valeri Krugler, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2005. Support vector learning for semantic argument classification. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda M Harabagiu</author>
<author>John Williams</author>
<author>Paul Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="5190" citStr="Surdeanu et al., 2003" startWordPosition="802" endWordPosition="805">assed to SVM and ME classifiers. For example, in Figure 2, the frame disFigure 2: Classification examples for each sub-task. ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word. In this figure, the correct categories for each sub-task are shown in boldface. The complete set of features extracted for all the classification sub-tasks is illustrated in Figure 3. These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation. Figure 3 also indicates whether or not a feature is selected for a specific classification task. In the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers. 2.1 Frame Disambiguation In FrameNet, some target words can evoke multiple semantic frames. In order to extract the semantic structure of an ambiguous target word, the first step is to </context>
<context position="7731" citStr="Surdeanu et al., 2003" startWordPosition="1216" endWordPosition="1219">ection Forming_relationships and CC facilities NNS S have VBP FE Boundary Detection been VP positive negative VBN VBN VP tied to NP VP several JJ PP universities NNS Appositive Dep Ext Gen GF Classification Time Place Concept_1 Concept_2 Evidence Cognizer Concepts Circumstances Frequency FE Classif. Head NULL Obj Quant 461 TWFD FEBD FELC TWFD FEBD CELF Feature Description GFLC Feature Description GFLC N O 01 v TW UNIGRAMS: The words, stem words and part of speech (POS) unigrams 20 v CW: The content word of the constituent computed as described in that are adjacent to target word expressions; (Surdeanu et al., 2003); 02 v TW BIGRAMS: The words, stem words and POS bigrams that are adjacent to 21 v CW POS: The POS corresponding to the content word; target word expressions; 22 v CW STEM: Stemmed content word; 03 v TW WORD: The target word expression; 23 v v GOVERNING CATEGORY: Test whether the noun phrase constituents are 04 v v TW STEM: The stem word(s) of the target word expression; dominated by verbal phrases or sentence phrases; 05 v TW POS: The POS of the target word; 24 v SYNTACTIC DISTANCE: The length of the syntactic path; 06 v v TW CLASS: The lexical class of the target word, e.g. verb, noun, adjec</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Mihai Surdeanu, Sanda M. Harabagiu, John Williams, and Paul Aarseth. 2003. Using predicate-argument structures for information extraction. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Marta Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="5212" citStr="Xue and Palmer, 2004" startWordPosition="806" endWordPosition="809">ssifiers. For example, in Figure 2, the frame disFigure 2: Classification examples for each sub-task. ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word. In this figure, the correct categories for each sub-task are shown in boldface. The complete set of features extracted for all the classification sub-tasks is illustrated in Figure 3. These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation. Figure 3 also indicates whether or not a feature is selected for a specific classification task. In the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers. 2.1 Frame Disambiguation In FrameNet, some target words can evoke multiple semantic frames. In order to extract the semantic structure of an ambiguous target word, the first step is to assign the correct fra</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Marta Palmer. 2004. Calibrating features for semantic role labeling. In Proceedings ofEMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>