<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000033">
<title confidence="0.987636">
Generating and selecting grammatical paraphrases
</title>
<author confidence="0.976946">
Claire Gardent Eric Kow
</author>
<affiliation confidence="0.764089">
CNRS/LORIA INRIA/LORIA
Nancy, France Nancy, France
</affiliation>
<email confidence="0.997828">
claire.gardent@loria.fr eric.kow@loria.fr
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999928">
Natural language has a high paraphrastic power yet
not all paraphrases are appropriate for all contexts.
In this paper, we present a TAG based surface re-
aliser which supports both the generation and the
selection of paraphrases. To deal with the combi-
natorial explosion typical of such an NP-complete
task, we introduce a number of new optimisations
in a tabular, bottom-up surface realisation algo-
rithm. We then show that one of these optimisations
supports paraphrase selection.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978625">
As is well known, natural language has a very high paraphras-
tic power so that the same core meaning can be expressed in
many different ways [Gross, 1975; Mel’ˇcuk, 1988]. Yet not
all paraphrases are appropriate for all contexts. So for in-
stance, a sentence and its converse (1a) express the same core
meaning and so can be considered paraphrases of each other.
Yet as example (1b) illustrates, they are not interchangeable
in the context of a control verb:
</bodyText>
<listItem confidence="0.964833">
(1) a. John borrowed a book from Mary.
≡ Mary lent a book to John
b. Peter persuaded John to borrow a book from Mary.
≡� Peter persuaded Mary to lend a book to John
</listItem>
<bodyText confidence="0.946890333333333">
Similarly, a canonical and a cleft sentence (2a) communi-
cate the same core meaning yet a contrastive context (2b) only
admits the cleft version.
</bodyText>
<listItem confidence="0.596928333333333">
(2) a. John looks at Mary.
≡ It is Mary that John looks at
b. * It is not Sarah, John looks at Mary.
</listItem>
<bodyText confidence="0.992309904761905">
It is not Sarah, it is Mary that John looks at
More generally, the anaphoric potential (that is, the dis-
course status of the entities being talked about) of the pre-
ceding discourse, its structure, the presence of an embedding
verb or of a given subordinating or coordinating conjunction
are all factors which may restrict the use of paraphrases. To
preserve completeness, it is therefore important that a gener-
ator be able to produce paraphrases in a systematic fashion.
On the other hand, it is also well known that surface real-
isation (the task of producing the set of sentences associated
by a grammar with a given semantic representation) is NP-
complete [Brew, 1992].
In this paper, we present a TAG based surface realiser
which supports both the generation and the selection ofgram-
matical paraphrases (section 2 and 3). To deal with the re-
sulting combinatorics, we introduce a number of new opti-
misations (section 4). We then show how one of these op-
timisations can be used to support the selection of contextu-
ally appropriate paraphrases (section 5). Finally, we relate
our approach to similar proposals and show that it compares
favourably in terms of efficiency (section 6 and 7).
</bodyText>
<sectionHeader confidence="0.84639" genericHeader="method">
2 The grammar
</sectionHeader>
<bodyText confidence="0.999960363636364">
The grammar used by the surface realiser is Feature-based
TAG, a unification based version of Tree Adjoining Gram-
mar. Briefly1, a Feature-based TAG consists of a set of (aux-
iliary or initial) elementary trees and of two tree composition
operations: substitution and adjunction. Substitution inserts a
tree onto a leaf node of another tree2 while adjunction inserts
an auxiliary tree into a derived tree (i.e., either an elementary
tree or a tree resulting from the combination of two trees). In
an FTAG, each tree node which is not a substitution node is
associated with two feature structures called top and bottom
and during derivation, the following unifications take place.
</bodyText>
<listItem confidence="0.999355444444444">
• The adjunction at some node X with top features tX
and bottom features bX, of an auxiliary tree with root
top features r and foot bottom features f entails the
unification of tX with r and of bX with f.
• The substitution at some node X with top features tX
of a tree with root top features t entails the unification
of tX with t.
• At the end of a derivation, the top and bottom features
of all nodes in the derived tree are unified.
</listItem>
<footnote confidence="0.999603666666667">
1For more details on FTAG see [Vijay-Shanker and Joshi, 1988].
2Leaf nodes where substitution can take place are graphically
distinguished by a down arrow.
</footnote>
<bodyText confidence="0.999846909090909">
In the FTAG used by the surface realisation algorithm, lin-
guistic expressions are associated with semantic representa-
tions as advocated in [Gardent and Kallmeyer, 2003]. The se-
mantic representations used are flat semantic representations
in the sense of [Copestake et al., 2001] and the semantic pa-
rameters (that is, the semantic indices representing the miss-
ing arguments of the semantic functors) are represented by
unification variables.
Further, each elementary tree is associated with a semantic
representation of the type just described and the appropriate
nodes of the elementary trees are decorated with semantic in-
dices or parameters.
More precisely, the substitution nodes of the tree associated
with a semantic functor will be associated with semantic pa-
rameters whilst root nodes and certain adjunction nodes will
be labelled with semantic indices. As trees are combined,
semantic parameters and semantic indices are unified by the
FTAG unification mechanism thus specifying which semantic
index provides the value for which semantic parameter.
Generally, the idea is that the association between tree
nodes and unification variables encodes the syntax/seman-
tics interface: it specifies which node in the tree provides the
value for which semantic parameter in the semantic represen-
tation of a semantic functor. So for instance, the trees for
John, loves and Mary will be as given in Figure 1. The tree for
loves is associated with a semantic representation including
the two semantic parameters x and y. These parameters also
label the subject and the object substitution nodes of this tree.
Conversely, the root node of the tree for John is labelled with
the semantic index j. If the string parsed is John loves Mary,
this tree will be substituted at the subject substitution node of
the loves tree thus instantiating the semantic parameter x to j.
And similarly, for the Mary tree.
</bodyText>
<equation confidence="0.8451985">
S
NPJ- VP
NPS V NPJy NP,
John loves Mary
name(j,john) love(x,y) name(m,mary)
⇒ love(j,m),name(j,john),name(m,mary)
</equation>
<figureCaption confidence="0.998385">
Figure 1: John loves Mary
</figureCaption>
<bodyText confidence="0.999878909090909">
Coverage. The grammar used describes a core fragment for
French and contains around 4 000 trees. It covers some 35
basic subcategorisation frames and for each of these frames,
the set of argument redistributions (active, passive, middle,
reflexivisation, impersonal, passive impersonal) and of argu-
ment realisations (cliticisation, extraction, omission, permu-
tations, etc.) possible for this frame. As a result, it captures
most grammatical paraphrases that is, paraphrases due to di-
verging argument realisations or to different meaning pre-
serving alternation (e.g., active/passive or clefted/non clefted
sentence).
</bodyText>
<sectionHeader confidence="0.944196" genericHeader="method">
3 The basic algorithm
</sectionHeader>
<bodyText confidence="0.9952402">
The basic surface realisation algorithm used is summarised in
Figure 1 (appendix). It is a bottom up, tabular algorithm [Kay,
1996] optimised for TAGs. Its workings can be illustrated by
the following example. Suppose that the input semantics is
the following:
{camp(s,j),john(j),in(s,l),paris(l)}
Then the algorithm proceeds as follows. In a first step (lex-
ical selection), the elementary trees whose semantics sub-
sumes3 part of the input semantics are retrieved and added
to the agenda. In our simple example, the selected trees are
the trees for Jean, campe, dans and paris.
The second step (the substitution phase) consists in sys-
tematically exploring the possibility of combining two trees
by substitution. It is summarised for our example by the ta-
ble in figure 2 where each line corresponds to a processing
step. The words in each column indicate the trees present at
each step in the chart, the agenda and the agenda for auxiliary
trees (AgendaA). The combination column indicates which
tree combines with which tree by means of which operation
(↓ indicates a substitution, ⋆ an adjunction). The trees result-
ing from such a combination are represented using the con-
catenation of the names of the combined trees (jeanCampe is
the tree resulting from the combination of the tree anchored
by Jean with that anchored by campe). Thus, the first line in-
dicates that the trees anchored by Jean, campe, dans and Paris
are in the agenda and that the chart is empty. The second line
shows that the next state is a state where the tree anchored
by Jean has been retrieved from the agenda and added to the
chart. The third line indicates that when the trees anchored by
campe and Jean are in the chart, they can be combined using
substitution. The result is added to the agenda etc.
More generally, the items are retrieved one by one from
the agenda to be added either to the chart or to the auxiliary
agenda (in the case of an auxiliary tree devoid of substitution
node). For each item added to the chart, all possible substitu-
tions are carried out and the resulting derived trees are added
to the agenda. The loop ends when the agenda is empty.
At this stage, all the items containing an empty substitution
node are erased from the chart (here, the trees anchored by
campe and dans are erased). The agenda is then reinitialised to
the content of the chart and the chart to the content of the aux-
iliary agenda. The third step (the adjunction phase) occurs
then in which all possible adjunctions are performed (figure
3). Finally (retrieval phase), the strings labelling the items in
the chart whose semantics is the input semantics are printed
</bodyText>
<footnote confidence="0.9936799">
3Subsumption is here taken to denote term unification. Hence
lexical selection is done on a very “syntactic” basis: only these lexi-
cal entries whose semantics representation matches part of the input
semantics are selected. This is partly alleviated by taking lexical
synonymy into account while developing the grammar so that two
(intra- or inter-categorical) synonyms are assigned the same seman-
tic representation. A more complete treatment would require the in-
tegration either of a richer lexical semantics or of a lexical selection
module permitting inference so that for instance “adult(x) male(x)
human(x)” can be inferred to be denoted by the word “man”.
</footnote>
<table confidence="0.645419285714286">
Agenda Chart Combination AgendaA
Jean,campe,dans,Paris Jean ↓(campe,Jean) dansParis
campe,dans,Paris campe,Jean ↓(dans,Paris)
dans,Paris campe,Jean,dans
Paris,JeanCampe campe,Jean,dans,Paris
JeanCampe campe,Jean,dans,Paris,JeanCampe
dansParis campe,Jean,dans,Paris,JeanCampe
</table>
<figureCaption confidence="0.993501">
Figure 2: Sample run of the substitution phase
</figureCaption>
<bodyText confidence="0.985326">
out, which in this case yields the sentence Jean campe dans
Paris.
</bodyText>
<sectionHeader confidence="0.998473" genericHeader="method">
4 Optimisations
</sectionHeader>
<bodyText confidence="0.999801714285714">
Surface realisation is NP complete [Brew, 1992]. More-
over the paraphrastic power of natural language is enormous
[Gross, 1975; Mel’ˇcuk, 1988]. Hence optimisation is a key
issue and so is the possibility to select a given paraphrase
on demand. We now present a number of optimisations we
added to the algorithm just described in order to reduce the
combinatorics.
</bodyText>
<subsectionHeader confidence="0.998938">
4.1 Tabulation and ordered combinations
</subsectionHeader>
<bodyText confidence="0.978502066666667">
Tabulation serves to avoid redundant computations. In analy-
sis, the use of the chart to store intermediate constituents and
avoid multiple computation of the same structure renders an
exponential task polynomial. In generation however, tabula-
tion increases efficiency by avoiding duplicate computations
but the complexity remains exponential because in particular
of multiple modifiers [Brew, 1992]. Suppose for instance
that the input semantic representation is the following:
fierce(x),little(x),cat(x),black(x)
For this input, a naive bottom-up realisation algorithm will
generate all intermediate structures that is, n! intermediate
structures with n the number of modifiers. These n! struc-
tures will furthermore be multiplied by the context so that for
instance given the input for the fierce little black cat runs, the
following structures will all be generated.
</bodyText>
<construct confidence="0.991199714285714">
(3) a. fierce cat, fierce black cat, little cat,little black cat, fierce
little cat, black cat
b. the fierce cat, the fierce black cat, the little cat, the little
black cat, the fierce little cat, the black cat
c. the fierce cat runs, the fierce black cat runs, the little cat
runs, the little black cat runs, thefierce little cat runs, the black
cat runs
</construct>
<bodyText confidence="0.9999565">
To minimise the impact of multiple modifiers, the algo-
rithm presented here performs all substitutions before con-
sidering adjunctions. In effect, this means that adjunction
only applies to syntactically complete trees and so that the
many intermediate structures induced by the modifiers do not
multiply out with other incomplete structures. In the above
example for instance, (3c) will be computed but neither (3a)
nor (3b).
</bodyText>
<subsectionHeader confidence="0.99929">
4.2 Avoiding spurious derivations
</subsectionHeader>
<bodyText confidence="0.998744866666667">
Categorical grammars often allow so called spurious deriva-
tions in that one and the same syntactic structure can be
derived in several different ways [Hepple, 1991]. TAGs also
induce spurious derivations due to the fact that substitutions
and adjunctions on different nodes of the same tree can be
carried out in different relative orders all of which result in
one and the same structure. Thus for instance, given the
trees np(Marie), np(Jean), s(np↓, v(aime), np↓)
and the semantic aime(j,m),jean(j), marie(m), two
derivations are possibles, one where np(Jean) is first
substituted in s(np↓, v(aime), np↓) before the tree for
np(Marie) is ; and the other where np(Marie) is first
substituted before np(Jean) is added. More generally, for a
tree containing n substitution nodes, there will be n! possible
derivations. For instance given the sentence
</bodyText>
<listItem confidence="0.90256">
(4) Jean persuade Marie de promettre a` Claire de donner un
livre a` Marie.
</listItem>
<bodyText confidence="0.991740692307692">
Jean persuades Mary to promise Claire to give Mary a
book
there will be 3! × 2! × 2! = 24 possible derivations all
of them produce the same syntactic tree and hence the same
sentence.
Adjunction suffers from the same shortcoming. Given a
TAG tree and n auxiliary trees that can adjoin to different
nodes of that tree, there are n! possible ways of deriving the
tree resulting from these n adjunctions.
To avoid these spurious derivations, we impose a unique
order (from left to right) on the sequences of substitutions
and adjunctions done within a given tree. Because the al-
gorithm systematically examines all pairs of items, this re-
striction does not affect completeness : the unique derivation
supported by the imposed constraints will be taken into con-
sideration by the algorithm and will therefore be produced.
A third source of spurious derivations come from the pos-
sibility of having multiple adjunctions on the same node of a
given tree for instance in the case of the little black cat. The
auxiliary trees anchored by little and black can adjoin in two
different orders on the tree anchored by cat: either little is ad-
joined to cat and black to the foot node of little in the resulting
tree or black is adjoined to cat and little to the root node of
the resulting derived tree. To eliminate this type of spurious
derivations, adjunction on a foot node is ruled out – which is
usual in TAG parsers.
</bodyText>
<table confidence="0.508611375">
Agenda Chart Combination AgendaA
Jean,Paris,JeanCampe dansParis
Paris,JeanCampe dansParis,Jean
JeanCampe dansParis,Jean,Paris
dansParis,Jean,Paris,JeanCampe ⋆(JeanCampe,dansParis)
JeanCampeDansParis dansParis,Jean,Paris,JeanCampe
dansParis,Jean,Paris,JeanCampe,
JeanCampeDansParis
</table>
<figureCaption confidence="0.987898">
Figure 3: Sample run of the adjunction phase
</figureCaption>
<subsectionHeader confidence="0.999939">
4.3 Filtering of valid lexical sequences
</subsectionHeader>
<bodyText confidence="0.999871066666666">
The most efficient optimisation takes place between the lex-
ical selection phase and that of combination by substitution
and adjunction. At this stage, the number of combinations
that are a priori possible is � ai with ai the degree of
lexical ambiguity of the i-th literal and n, the number of lit-
erals in the input semantic. That is, the search space is expo-
nential in the number of literals. To reduce the combinatorics,
we use a technique introduced for parsing by [Perrier, 2003]
called polarity basedfiltering.
Polarity based filtering is based on the observation that
many of the combinations of lexical items which cover the in-
put semantics are in fact syntactically invalid either because
a syntactic requirement is not fulfilled or because a syntac-
tic resource is not used. Accordingly, polarity based filtering
detects and eliminates such combinations by:
</bodyText>
<listItem confidence="0.97671875">
1. assigning each lexical item a polarity signature reflecting
its syntactic requirements and resources
2. computing for each possible combination of lexical
items the net sum of its syntactic requirements and re-
sources and
3. eliminating all combinations of lexical items that do not
have a net sum of zero (because such combinations can-
not possibly lead to a syntactically valid sentence)
</listItem>
<bodyText confidence="0.9587484">
As we shall see below, polarity based filtering is imple-
mented using finite state techniques.
Let us see how this works by running through a simple
example. Suppose that the input semantic representation is:
(5) buy(e,t,j), annoying(e), field(t),john(j)
and that the TAG trees selected for this input are the ones
given in Figure 8 (appendix).
In this figure, the literals following the tree name give the
polarities that are automatically assigned to each of these
trees on the basis of their root and substitution nodes (for in-
stance, the v achete has polarity (+p − 2n) meaning that it
provides a sentence and requires two NPs). Since in a TAG,
substitution nodes indicates syntactic requirements whilst an
initial tree permits fulfilling a syntactic requirement, polarity
signatures can be automatically computed as follows:
</bodyText>
<listItem confidence="0.961547666666667">
• a polarity of the form +C is added to the tree polarity
signature of each initial tree with root node category C.
• a polarity of the form −S is added to the tree polarity
</listItem>
<bodyText confidence="0.7793095">
signature of each initial tree for each substitution node
with category S in that tree.
Now we need to compute the polarity of all possible com-
binations of lexical items. This is done by:
</bodyText>
<listItem confidence="0.9990816">
1. building a polarity automaton for each polarity category
occurring in the set of possible combinations (in this
case, n and s),
2. computing the intersection of these automata and
3. minimising the resulting automaton.
</listItem>
<bodyText confidence="0.9999485">
In the final automaton, only the combinations that have a
null polarity are represented. These will be the combinations
actually explored by the realiser.
For the above example, the final automaton is that given in
figure 9 where each state is labelled with the cumulated polar-
ity of the path(s) leading to that state and where the transitions
are labelled with the lexical item covered. As can be seen, the
combinations that are syntactically invalid (in grey in the au-
tomaton) have been eliminated. Thus in particular, the com-
bination of the predicative tree n0Vadj with the verb ach`ete
and its two complements is ruled out (as the n requirement of
n0Vadj cannot be satisfied) and conversely, the combination
of the predicative tree p0Vadj with the relational noun achat
(because the p requirement ofp0Vadj cannot be satisfied)4 .
</bodyText>
<subsectionHeader confidence="0.977477">
4.4 Combining polarity based filtering and
tabulation
</subsectionHeader>
<bodyText confidence="0.99993425">
To preserve the factorisation supported by the use of a chart,
polarity filtering must furthermore be integrated with the re-
alisation algorithm. Indeed, each path through a polarity au-
tomaton represents a combination of lexical items whose total
semantics is the input semantics and which may lead to a syn-
tactically valid expression. But some ofthese paths may share
some subpath(s). To avoid computing these shared subpaths
several times, each selected elementary tree is annotated with
</bodyText>
<footnote confidence="0.5382292">
4For lack of space, we ignore here functional words (determiners,
prepositions). In the full algorithm, their treatment is implemented
either by means of co-anchors (a verb whose compl´ement requires a
given preposition for instance, will be assigned a tree with multiple
anchors, one for the verb, the other for the preposition) or by means
of a richer semantic (contrary to what is shown here, a quantifier will
have a non nul semantics). Note further that lexical items with multi-
literal semantics are also handled as well as items whose semantics
is reduced to an index (pronouns, control verb subject, modifiers,
etc.).
</footnote>
<bodyText confidence="0.999943444444444">
the set of automaton paths it occurs in. During realisation,
two items will be compared only if the intersection of their
path sets is not empty (they appear in the same automaton
path). The result of a combination is labelled with the in-
tersection of the labels of the combined constituents. In this
way, the elementary items appearing in several paths of the
automaton are only introduced once in the chart and the fac-
torisation of both elementary and derived items that are com-
mon to several automaton path is ensured.
</bodyText>
<sectionHeader confidence="0.983096" genericHeader="method">
5 Paraphrase selection
</sectionHeader>
<bodyText confidence="0.999461788461538">
As pointed out in the introduction, not all paraphrases are ap-
propriate in all contexts. To test the ability to generate contex-
tually appropriate sentences, we augmented the realiser with
a paraphrase selection mechanism based on the polarity fil-
tering system described in section (4.3). For instance, it is
possible to select from among the possible realisations for
regarde(j,m), jean(j), marie(m), the variant where
jean is verbalised as a cleft subject namely, C’est Jean qui re-
garde Marie (It is John who is looking at Mary).
More generally, the selection constraints allowed are
syntactico-semantic constraints of the form Synt:Semzndex
where Synt is a morpho-syntactic feature (declarative, inter-
rogative, cleft, pronoun, etc.) and Semzndex is an index oc-
curring in the input semantics.
Intuitively, a selection constraint supports the selection,
for a given semantic index, of the variant(s) obeying the
syntactico-semantic constraint set by the selection constraint
for that index.
Formally, these constraints are imposed during the polarity
filtering phase as follows. The syntactic properties supported
by the selection constraints are automatically associated dur-
ing grammar compilation to the elementary trees of the gram-
mar by means of so-called hypertags [Kinyon, 2000]. This is
made possible by the fact that the TAG used is derived from
a metagrammar [Crabb´e and Duchier, 2004] that is, from a
highly factorised way of representing the linguistic concepts
encoded in the TAG trees. Roughly, the metagrammar for-
malism is used (i) to define abstractions over these concepts
and (ii) to combine these abstractions so as to produce the el-
ementary trees of a TAG. During the metagrammar compila-
tion process, a so-called hypertag is built for each tree which
records the abstractions used to produce that tree. Thus hy-
pertags contain detailed information about the linguistic con-
tent of the TAG elementary trees. In particular, the hypertag
of the tree with clefted subject of the n0vn1 family (i.e., the
set of verbs taking two nominal arguments) will contain the
property +cleft:X where X is the semantic index associated
with the subject node.
During lexical selection, this index is instantiated by unifi-
cation with the input so that the selected elementary tree for
regarde will have the property +cleft:j.
Conversely, a restrictor is a property that a lexical item in-
tervening in the production of the generated paraphrases must
have. In the above example, the restrictor is -cleft:j mean-
ing that the j index must be realised by a clefted structure.
Paraphrase selection is implemented by parameterising the
realiser with a restrictor (for instance, -cleft:j). This re-
strictor is then used to initialise the polarity automaton and
eliminate (by polarity filtering) all these combinations which
do not contain the +cleft:j charge (since the negative
charge introduced during initialisation must be cancelled). As
a result, the realiser will only produce the variant:
</bodyText>
<listItem confidence="0.828666">
(6) C’est Jean qui regarde Marie.
</listItem>
<bodyText confidence="0.999904411764706">
More generally, the polarity mechanism permits selecting
paraphrases on the basis of the information contained in the
grammar hypertags or in the TAG tree features. This infor-
mation, which is decided upon by the grammar writer, can be
both fine grained and of different natures.
Feature values can be used to control the feature values
associated with the root node of the constructed tree, typically
requiring that it is of interrogative, declarative or imperative
mood.
Hypertags can be used more generally to control the selec-
tion of the lexical items entering in the generated construct.
Importantly, the information they contain can be specified
both at the grammar and at the lexical level so that para-
phrase selection can then operate both on features determined
by syntax and on lexically determined characteristics (level
of speech, modality, type of semantic relation, thematic and
fore/backgrounding structure, etc;).
</bodyText>
<sectionHeader confidence="0.987859" genericHeader="method">
6 Implementation and Experimentation
</sectionHeader>
<bodyText confidence="0.99999275">
The realiser described here has been implemented in Haskell.
It includes a graphical interface as well as a debugger so that
the user can inspect the content of the chart and of the agenda
at each step of the algorithm. It also supports batch process-
ing thus permitting a systematic evaluation of the impact of
various optimisations combinations. In what follows, we dis-
cuss the effect of polarity filtering and of paraphrase selection
in that system.
</bodyText>
<subsectionHeader confidence="0.997308">
6.1 The effect of polarity filtering
</subsectionHeader>
<bodyText confidence="0.99994875">
To get an estimate of how our realiser compares with exist-
ing published results, we revisited the test cases discussed
in [Carroll et al., 1999] and [Koller and Striegnitz, 2002] by
producing similar sentences in French namely (7a) and (7b).
</bodyText>
<listItem confidence="0.98979">
(7) a. Le directeur de ce bureau auditionne un nouveau consul-
tant d’Allemagne (The manager in that office interviews a
new consultant from Germany)
</listItem>
<bodyText confidence="0.976264714285714">
b. Le directeur organise un nouveau seminaire d’equipe heb-
domadaire special (The manager organises an unusual ad-
ditional weekly departmental conference).
The grammar used contains 2063 trees. In this grammar,
the verb organiser is associated with 107 trees and adjectives
with 8 trees. For the purpose of efficiency testing, we fur-
thermore treated the PP d’´equipe as an adjective. As a result,
there are 107 × 8 (856) combinations of lexical items cover-
ing the input semantics for example (7a) while for example
(7b), this number is 107 × 84. The effect of polarity filtering
for these two examples is summarised in the following table.
That is, polarity filtering reduces the number of lexical
items combinations actually explored from 856 to 55 in the
first case and from 438 272 to 232 in the second.
</bodyText>
<table confidence="0.8716305">
Example 7a Example 7b
Possible combinations 856 438 272
Combinations explored 55 232
Sentences (w/o selection) 9 216
</table>
<figureCaption confidence="0.7781276">
Figure 4: Filtering out combinations
Note furthermore that despite the overhead introduced by
the construction of the polarity automaton, polarity filtering
reduces overall processing times (cf. Figure 5).
Optimisations Example 7a Example 7b
none 14.8 s 93.8 s
pol 0.8 s 14.7 s
Carroll 1.8 s 4.3 s
Koller 1.4 s 0.8 s
Figure 5: Processing times
</figureCaption>
<bodyText confidence="0.99995264">
Thus, for the examples considered, processing times are
reduced by 95% and 84% respectively. The processing times
for (7a) compares favourably with those published for both
the Carroll et al. and the Koller and Striegnitz realisers. This
comparison is not all that meaningful, however, since we are
using different grammars and significantly faster computers,
a 3 Ghz Pentium IV to the 700 Mhz Pentium III in [Koller
and Striegnitz, 2002].
Indeed, the poor performance of our surface realiser in ex-
ample (7b) is directly related to the degree of lexical ambi-
guity in our grammar. As illustrated in section 4.1, input se-
mantics with multiple modifiers pose a problem for surface
realisers. Although performing adjunction separately from
substitution prevents this problem from spilling over into in-
complete structures, the fact remains that n translate to n!
structures. Further aggravating the situation is that our gram-
mar provides 8 trees for every adjective, leading to 85 × 5!, or
3.9 million possible structures. When we modified our gram-
mar to only have one tree per adjective, our realisation times
dropped to 9s without filtering and 2.7s with. This exam-
ple calls to attention the fact that polarity filtering does not
account for lexical ambiguity in modifiers. In section 7, we
suggest some potential mechanisms for dealing with modi-
fiers, which we expect to be complementary to the filtering
technique.
</bodyText>
<subsectionHeader confidence="0.999874">
6.2 Paraphrase selection
</subsectionHeader>
<bodyText confidence="0.999201571428571">
Paraphrase selection permits reducing the combinatorics one
step further. Thus introducing a cleft restrictor for examples
(7a) and (7b), causes the generator to produce fewer results,
2 sentences instead of 9 in the first example, and 18 instead
of 54 in the second.
These figures can be explained as follows. The grammar
allows 9 syntactic structures for the input considered namely:
</bodyText>
<listItem confidence="0.910158642857143">
(8) a. C’est par le directeur de ce bureau qu’un nouveau
consultant d’Allemagne est auditionn´e
b. C’est le directeur de ce bureau qui auditionne un
nouveau consultant d’Allemagne
c. C’est un nouveau consultant d’Allemagne
qu’auditionne le directeur de ce bureau
d. C’est un nouveau consultant d’Allemagne que le
directeur de ce bureau auditionne
e. C’est un nouveau consultant d’Allemagne qui est
auditionn´e par le directeur de ce bureau
f. Le directeur de ce bureau auditionne un nouveau
consultant d’Allemagne
g. Un nouveau consultant d’Allemagne est auditionn´e
par le directeur de ce bureau
</listItem>
<bodyText confidence="0.999553">
Since for the moment the grammar places no constraints on
the respective order of modifiers, there are 9 possible realisa-
tions for example (7a) and 9 × 3! for example (7b). With the
object cleft restrictions on “consultant”, these numbers drop
to 2 for the first example and to 2 × 3! for the second.
</bodyText>
<figure confidence="0.609611333333333">
Example 7a Example 7b
Sentences (w/o selection) 9 54
Sentences (with selection) 2 18
</figure>
<figureCaption confidence="0.997452">
Figure 6: Selection
</figureCaption>
<bodyText confidence="0.9680435">
Accordingly, the processing time drops by 63% and 88%
with respect to simple polarities (cf. Figure 7).
</bodyText>
<table confidence="0.72247925">
Optimisations Example 7a Example 7b
none 14.8 s 93.8 s
pol 0.8 s 14.7 s
pol + select 0.3 s 1.8 s
</table>
<figureCaption confidence="0.989087">
Figure 7: Polarity + Selection
</figureCaption>
<sectionHeader confidence="0.993381" genericHeader="method">
7 Related approaches
</sectionHeader>
<bodyText confidence="0.999518375">
Several recent papers focus on improving the efficiency of
surface realisation. In this section, we relate our approach to
the HPSG based approach presented in [Carroll et al., 1999],
to the statistical and semi-statistical strategies used in [Ban-
galore and Rambow, 2000] and in [White, 2004] and to the
constraint based approach described in [Koller and Striegnitz,
2002]. We also briefly relate it to the greedy strategy used in
[Stone et al., 2003].
</bodyText>
<subsectionHeader confidence="0.999576">
7.1 Copestake et al.’s HPSG approach
</subsectionHeader>
<bodyText confidence="0.999935266666667">
As mentioned in section 4.1, multiple modifiers may trig-
ger an exponential number of intermediate structures. The
“adjunction after substitution” idea is inspired from the pro-
posal made in [Carroll et al., 1999] that a complete syntactic
skeleton be built before modifiers be inserted into that tree.
Because the Carroll et al. proposal is set within the HPSG
framework however, extracted modifiers as in Which office
did John work in? need specific treatment. In contrast, in
TAG, all modifiers are treated using adjunction so that no spe-
cific treatment is required. All that is needed is that adjunc-
tion only be applied after all possible substitutions have been
carried out. A second, more meaningful difference is that no
such global optimisation as polarity filtering is proposed to
filter out on the basis of global information about the sets of
possible combinations, a priori invalid ones.
</bodyText>
<subsectionHeader confidence="0.999695">
7.2 Statistical approaches
</subsectionHeader>
<bodyText confidence="0.999908666666667">
Interestingly, [White, 2004] proposes a treatment ofmodifiers
which is in some sense the converse of the “adjunction after
substitution” treatment and where complete NPs are first built
before they are combined with the verb. This second option is
also feasible in TAG (adjunction would then apply on specific
sets of lexical entries and the results combined with the verb)
and it would be interesting to experiment and compare the
relative efficiency of both approaches within the TAG frame-
work.
Both approaches isolate the addition of modifiers to a con-
stituent, thereby avoiding spurious combinations with unre-
lated constituents; but neither directly address the fact that are
still an exponential n! ways to combine any n modifiers for
a single constituent. [White, 2004] and [Bangalore and Ram-
bow, 2000] propose statistical solutions to this problem based
on a linear n-gram language model. In White’s approach the
statistical knowledge is used to prune the chart of identical
edges representing different modifier permutations, e.g., to
choose between fierce black cat and blackfierce cat. Bangalore
assumes a single derivation tree that encodes a word lattice (a
{fierce black, black fierce} cat), and uses statistical knowledge
to select the best linearilisation. Our framework does not cur-
rently implement either approach, but we hope to adopt an ap-
proach similar to Bangalore’s. Rather than directly perform-
ing adjunction, we associate each node with the set of auxil-
iary trees (modifiers) that are to be adjoined to that node. The
order in which these modifiers are adjoined can be decided
through statistical methods.
There are three other uses for probabilistic techniques: for
lexical selection, optimisation and ranking. Such techniques
are useful for guiding the surface realiser towards a single
best result (or a relatively small number thereof). On the
other hand, we aim to produce all possible paraphrases, that
is explore the entire search space of syntactic variants, and
so with the exception of modifier ordering, we eschew the
use of probabilities in favour of an “exact method” [G. Bon-
fante, 2004]. While Bangalore uses a tree model to produce
a single most probable lexical selection, we use polarities to
filter out all the definitely impossible ones. While in White’s
system, the best paraphrase is determined on the basis of n-
gram scores that is, on the basis of frequency, in our approach
“best” means “most contextually appropriate”. Indeed, the
restrictors we use to select a paraphrase, although they are
here given by hand, could equally be set by the context and
so permit modelling the effect of contextual constraints on
paraphrases. We believe that our approach, modulo statis-
tical handling of modifiers, would be roughly equivalent to
White’s with anytime-searching disabled.
</bodyText>
<subsectionHeader confidence="0.992087">
7.3 Koller et al.’s constraint-based approach
</subsectionHeader>
<bodyText confidence="0.999965444444444">
Finally, our approach has interesting connections to the
constraint-based approach proposed by [Koller and Strieg-
nitz, 2002]. In this approach, the subset of the TAG grammar
which is used for a given realisation task is translated into a
set of lexical entries in a dependency grammar defining well
formed TAG derivation trees. This set of entries is then parsed
by an efficient constraint-based dependency parser thus pro-
ducing the derivation trees associated by the grammar with
the set of input lexical entries. A post processing phase pro-
duces the derived trees on the basis of the derivation trees
output by the first step.
The main similarity between this and our approach is that
they both use a global mechanism for filtering out combina-
tions of lexical entries that cannot possibly lead to a syntac-
tically valid sequences. In the Koller et al. approach, this
filtering is based on well formed derivation trees (only these
combinations of lexical entries that form a valid derivation
tree are considered) whereas in ours, it is based on polarities
and on the cancelling out of syntactic resources and require-
ments. As a preliminary evaluation shows, such a global op-
timisation is very efficient in pruning the search space.
There are differences though. In particular, while Koller et
al. explicitly ignores feature information, our algorithm han-
dles a TAG with fully specified feature structures. Further
while in our approach, the processing of the valid combina-
tions is done using a tabular algorithm optimised to avoid spu-
rious derivations, the postprocessing step producing derived
trees from derivation trees is left undefined in the Koller et al.
approach. Finally, while the Koller et al. approach is based
on constraint propagation, ours is based on finite state tech-
niques. These differences open up the door for interesting
comparisons and combinations. It would be interesting for
instance to combine the Koller et al approach with the tab-
ular surface realisation algorithm presented in this paper, or
to compare run times once feature structures are taken into
account.
</bodyText>
<subsectionHeader confidence="0.998527">
7.4 Stone’s greedy approach
</subsectionHeader>
<bodyText confidence="0.999961576923077">
[Stone et al., 2003] presents a greedy approach to TAG based
surface realisation. The greedy search applies iteratively to
update a single state in the search space. On each iteration,
all neighbours of the current state are produced but only one
state is chosen at the next current state, based on a heuristic
evaluation.
[Stone et al., 2003]’s search strategy is therefore markedly
different from ours. While we explore the entire search
space and use polarities to control the combinatorics, Stone’s
greedy strategy is a best first strategy which incrementally
trims the search space using heuristics. In terms of efficiency,
the greedy strategy is of course better. The goals behind the
two approaches are distinct however. Thus while Stone’s ap-
proach aims at modelling the interaction of the various mech-
anisms involved in microplanning, the present proposal is di-
rected towards generating and selecting paraphrases. In par-
ticular, we are interested in using the realiser to debug a para-
phrastic grammar that is, a grammar which alleviates the in-
ference task by assigning paraphrases the same semantics –
this can only be done by adopting an exhaustive search strat-
egy. More generally, “exhaustive surface realisation” pro-
vides a natural way to debug grammars and reduce their de-
gree of overgeneration. Since the combinatorics is not only
theoretically (worse case analysis) but also practically very
high, it is worth investigating ways of optimising surface re-
alisers which perform an exhaustive search.
</bodyText>
<sectionHeader confidence="0.994297" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999979235294118">
We have presented a surface realiser for TAG which is opti-
mised to support the generation of grammatical paraphrases
while also permitting the selection, on the basis of syntactico
semantic constraints, of a particular paraphrase. The most
efficient optimisation proposed concerns polarity filtering, a
global technique that permits the elimination of combinations
of lexical items which cannot possibly lead to a syntactically
valid sentence. While used here for generating with TAG, the
technique is fully general and can be used for parsing [Perrier,
2003] but also for generating with other grammatical frame-
works.
Future work will concentrate on extending the grammar
and the lexicon to other types of paraphrases (in particu-
lar, morphoderivational or cross categorical paraphrases), on
providing a systematic evaluation of the paraphrase selection
mechanism and on using the realiser for the debugging of an
existing TAG for French.
</bodyText>
<sectionHeader confidence="0.99597" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980071202247191">
[Bangalore and Rambow, 2000] S. Bangalore and O. Ram-
bow. Using TAGs, a tree model and a language model
for generation. In Proceedings of TAG+5, Paris, France,
2000.
[Brew, 1992] C. Brew. Letting the cat out of the bag: Gener-
ation for shake-and-bake MT. In Proceedings of COLING
’92, Nantes, France, 1992.
[Carroll et al., 1999] J. Carroll, A. Copestake, D. Flickinger,
and V. Pazna´nski. An efficient chart generator for (semi-
)lexicalist grammars. In Proceedings of EWNLG ’99,
1999.
[Copestake et al., 2001] A. Copestake, A. Lascarides, and
D. Flickinger. An algebra for semantic construction in
constraint-based grammars. In Proceedings of the 39th
ACL, Toulouse, France, 2001.
[Crabb´e and Duchier, 2004] B. Crabb´e and D. Duchier.
Metagrammar redux. In International Workshop on Con-
straint Solving and Language Processing - CSLP 2004,
Copenhagen, 2004.
[G. Bonfante, 2004] G. Perrier G. Bonfante, B. Guillaume.
Polarization and abstraction of grammatical formalisms as
methods for lexical disambiguation. In Proceedings of
CoLing 2004, 2004.
[Gardent and Kallmeyer, 2003] C. Gardent and
L. Kallmeyer. Semantic construction in ftag. In
Proceedings of the 10th EACL, Budapest, Hungary, 2003.
[Gross, 1975] M. Gross. M´ethodes en syntaxe. Masson,
Paris, 1975.
[Hepple, 1991] M. Hepple. Efficient incremental processing
with categorial grammar. In Proceedings of the 29th ACL,
Berkeley, 1991.
[Kay, 1996] M. Kay. Chart Generation. In 34th ACL, pages
200–204, Santa Cruz, California, 1996.
[Kinyon, 2000] A. Kinyon. Hypertags. In Proceedings COL-
ING, Sarrebruck, 2000.
[Koller and Striegnitz, 2002] A. Koller and K. Striegnitz.
Generation as dependency parsing. In Proceedings of the
40th ACL, Philadelphia, 2002.
[Mel’ˇcuk, 1988] I. Mel’ˇcuk. Paraphrase et lexique dans la
th´eorie linguistique sens-texte. Lexique, 6:13–54, 1988.
[Perrier, 2003] G. Perrier. Les grammaires d’interaction,
2003. Habilitation a` diriger les recherches en informa-
tique, universit´e Nancy 2.
[Stone et al., 2003] M. Stone, C. Doran, B. Webber,
T. Bleam, and M. Palmer. Microplanning with commu-
nicative intentions: the SPUD system. ComputationalIn-
telligence, 19(4):311–381, 2003.
[Vijay-Shanker and Joshi, 1988] K. Vijay-Shanker and
A. Joshi. Feature based tags. In Proceedings of the 12th
ACL, pages 573–577, Budapest, 1988.
[White, 2004] M. White. Reining in CCG chart realization.
In INLG, pages 182–191, 2004.
A Appendix
Algorithm 1 The GenI algorithm
1: procedure GENERATE(Gram,Sem)
2: AgendaA +-- 0; Agenda +-- 0; Chart +-- 0
3: for all trees t E Gram such that t’s semantics subsumes
Sem do
4: Agenda +-- Agenda + t
5: end for
6: while Agenda =� 0 do
7: t +-- any tree E Agenda
8: delete t from Agenda
9: if t has a foot node and no substitution nodes then
10: AgendaA +-- AgendaA + t
11: else
12: for all trees c E Chart which can combine with t
via substitution into a new tree ct do
13: Agenda +-- Agenda + ct
14: end for
15: Chart +-- Chart + t
16: end if
17: end while
18: delete from Chart any tree with a substitution node
19: Agenda +-- Chart
20: Chart +-- AgendaA
21: while Agenda =� 0 do
22: t +-- any tree E Agenda
23: delete t from Agenda
24: if t’s semantics is Sem then
25: return the string corresponding to t
26: else
27: for all trees c E Chart which can combine with t
via adjunction into a new tree ct do
28: Agenda +-- Agenda + ct
29: end for
30: end if
31: end while
32: end procedure
</reference>
<figure confidence="0.987550952380952">
buy(e,j,f) annoying(e) field(f)
v ach`ete (+p -2n) n0Vadj ennuyeux (+p -n) n field (+n)
Pe
N↓&apos; Ve N↓f
ach`ete
john(j)
n achat (+n -2n) p0Vadj ennuyeux (+p -p) n jean (+n)
Ne
P
N↓e V Adj
est ennuyeux
Nf
terrain
N&apos;
jean
P
P↓e V Adj
est ennuyeux
N GP GP
achat P N↓f P N↓&apos;
par de
</figure>
<figureCaption confidence="0.99998">
Figure 8: Grammar for example 5
Figure 9: A minimised polarity automaton
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.897830">
<title confidence="0.999858">Generating and selecting grammatical paraphrases</title>
<author confidence="0.999589">Claire Gardent Eric Kow</author>
<affiliation confidence="0.996117">CNRS/LORIA INRIA/LORIA</affiliation>
<address confidence="0.933898">Nancy, France Nancy, France</address>
<email confidence="0.96692">claire.gardent@loria.freric.kow@loria.fr</email>
<abstract confidence="0.999457727272727">Natural language has a high paraphrastic power yet not all paraphrases are appropriate for all contexts. In this paper, we present a TAG based surface realiser which supports both the generation and the selection of paraphrases. To deal with the combinatorial explosion typical of such an NP-complete task, we introduce a number of new optimisations in a tabular, bottom-up surface realisation algorithm. We then show that one of these optimisations supports paraphrase selection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Using TAGs, a tree model and a language model for generation.</title>
<date>2000</date>
<booktitle>In Proceedings of TAG+5,</booktitle>
<location>Paris, France,</location>
<marker>[Bangalore and Rambow, 2000]</marker>
<rawString>S. Bangalore and O. Rambow. Using TAGs, a tree model and a language model for generation. In Proceedings of TAG+5, Paris, France, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Brew</author>
</authors>
<title>Letting the cat out of the bag: Generation for shake-and-bake MT.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING ’92,</booktitle>
<location>Nantes, France,</location>
<marker>[Brew, 1992]</marker>
<rawString>C. Brew. Letting the cat out of the bag: Generation for shake-and-bake MT. In Proceedings of COLING ’92, Nantes, France, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>V Pazna´nski</author>
</authors>
<title>An efficient chart generator for (semi)lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of EWNLG ’99,</booktitle>
<marker>[Carroll et al., 1999]</marker>
<rawString>J. Carroll, A. Copestake, D. Flickinger, and V. Pazna´nski. An efficient chart generator for (semi)lexicalist grammars. In Proceedings of EWNLG ’99, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>A Lascarides</author>
<author>D Flickinger</author>
</authors>
<title>An algebra for semantic construction in constraint-based grammars.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th ACL,</booktitle>
<location>Toulouse, France,</location>
<marker>[Copestake et al., 2001]</marker>
<rawString>A. Copestake, A. Lascarides, and D. Flickinger. An algebra for semantic construction in constraint-based grammars. In Proceedings of the 39th ACL, Toulouse, France, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Crabb´e</author>
<author>D Duchier</author>
</authors>
<title>Metagrammar redux.</title>
<date>2004</date>
<booktitle>In International Workshop on Constraint Solving and Language Processing - CSLP 2004,</booktitle>
<location>Copenhagen,</location>
<marker>[Crabb´e and Duchier, 2004]</marker>
<rawString>B. Crabb´e and D. Duchier. Metagrammar redux. In International Workshop on Constraint Solving and Language Processing - CSLP 2004, Copenhagen, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Perrier G Bonfante</author>
<author>B Guillaume</author>
</authors>
<title>Polarization and abstraction of grammatical formalisms as methods for lexical disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of CoLing</booktitle>
<marker>[G. Bonfante, 2004]</marker>
<rawString>G. Perrier G. Bonfante, B. Guillaume. Polarization and abstraction of grammatical formalisms as methods for lexical disambiguation. In Proceedings of CoLing 2004, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>L Kallmeyer</author>
</authors>
<title>Semantic construction in ftag.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th EACL,</booktitle>
<location>Budapest, Hungary,</location>
<marker>[Gardent and Kallmeyer, 2003]</marker>
<rawString>C. Gardent and L. Kallmeyer. Semantic construction in ftag. In Proceedings of the 10th EACL, Budapest, Hungary, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gross</author>
</authors>
<title>M´ethodes en syntaxe.</title>
<date>1975</date>
<location>Masson, Paris,</location>
<marker>[Gross, 1975]</marker>
<rawString>M. Gross. M´ethodes en syntaxe. Masson, Paris, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hepple</author>
</authors>
<title>Efficient incremental processing with categorial grammar.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th ACL,</booktitle>
<location>Berkeley,</location>
<marker>[Hepple, 1991]</marker>
<rawString>M. Hepple. Efficient incremental processing with categorial grammar. In Proceedings of the 29th ACL, Berkeley, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Chart Generation.</title>
<date>1996</date>
<booktitle>In 34th ACL,</booktitle>
<pages>200--204</pages>
<location>Santa Cruz, California,</location>
<marker>[Kay, 1996]</marker>
<rawString>M. Kay. Chart Generation. In 34th ACL, pages 200–204, Santa Cruz, California, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kinyon</author>
</authors>
<title>Hypertags.</title>
<date>2000</date>
<booktitle>In Proceedings COLING, Sarrebruck,</booktitle>
<marker>[Kinyon, 2000]</marker>
<rawString>A. Kinyon. Hypertags. In Proceedings COLING, Sarrebruck, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>K Striegnitz</author>
</authors>
<title>Generation as dependency parsing.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL,</booktitle>
<location>Philadelphia,</location>
<marker>[Koller and Striegnitz, 2002]</marker>
<rawString>A. Koller and K. Striegnitz. Generation as dependency parsing. In Proceedings of the 40th ACL, Philadelphia, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mel’ˇcuk</author>
</authors>
<title>Paraphrase et lexique dans la th´eorie linguistique sens-texte.</title>
<date>1988</date>
<journal>Lexique,</journal>
<volume>6</volume>
<marker>[Mel’ˇcuk, 1988]</marker>
<rawString>I. Mel’ˇcuk. Paraphrase et lexique dans la th´eorie linguistique sens-texte. Lexique, 6:13–54, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Perrier</author>
</authors>
<title>Les grammaires d’interaction,</title>
<date>2003</date>
<marker>[Perrier, 2003]</marker>
<rawString>G. Perrier. Les grammaires d’interaction, 2003. Habilitation a` diriger les recherches en informatique, universit´e Nancy 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>C Doran</author>
<author>B Webber</author>
<author>T Bleam</author>
<author>M Palmer</author>
</authors>
<title>Microplanning with communicative intentions: the SPUD system.</title>
<date>2003</date>
<journal>ComputationalIntelligence,</journal>
<volume>19</volume>
<issue>4</issue>
<marker>[Stone et al., 2003]</marker>
<rawString>M. Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer. Microplanning with communicative intentions: the SPUD system. ComputationalIntelligence, 19(4):311–381, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>A Joshi</author>
</authors>
<title>Feature based tags.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th ACL,</booktitle>
<pages>573--577</pages>
<location>Budapest,</location>
<marker>[Vijay-Shanker and Joshi, 1988]</marker>
<rawString>K. Vijay-Shanker and A. Joshi. Feature based tags. In Proceedings of the 12th ACL, pages 573–577, Budapest, 1988.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M White</author>
</authors>
<title>Reining in CCG chart realization. In</title>
<date>2004</date>
<booktitle>INLG,</booktitle>
<pages>182--191</pages>
<marker>[White, 2004]</marker>
<rawString>M. White. Reining in CCG chart realization. In INLG, pages 182–191, 2004. A Appendix Algorithm 1 The GenI algorithm 1: procedure GENERATE(Gram,Sem) 2: AgendaA +-- 0; Agenda +-- 0; Chart +-- 0 3: for all trees t E Gram such that t’s semantics subsumes Sem do 4: Agenda +-- Agenda + t 5: end for 6: while Agenda =� 0 do 7: t +-- any tree E Agenda 8: delete t from Agenda 9: if t has a foot node and no substitution nodes then 10: AgendaA +-- AgendaA + t 11: else 12: for all trees c E Chart which can combine with t via substitution into a new tree ct do 13: Agenda +-- Agenda + ct 14: end for 15: Chart +-- Chart + t 16: end if 17: end while 18: delete from Chart any tree with a substitution node 19: Agenda +-- Chart 20: Chart +-- AgendaA 21: while Agenda =� 0 do 22: t +-- any tree E Agenda 23: delete t from Agenda 24: if t’s semantics is Sem then 25: return the string corresponding to t 26: else 27: for all trees c E Chart which can combine with t via adjunction into a new tree ct do 28: Agenda +-- Agenda + ct 29: end for 30: end if 31: end while 32: end procedure</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>