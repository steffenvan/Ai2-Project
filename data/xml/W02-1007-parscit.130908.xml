<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035263">
<note confidence="0.441812333333333">
Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), Philadelphia, July 2002, pp. 49-54.
Association for Computational Linguistics.
</note>
<title confidence="0.969104">
Parsing and Disfluency Placement
</title>
<author confidence="0.994882">
Donald Engelt and Eugene Charniakt and Mark Johnsont
</author>
<affiliation confidence="0.980056666666667">
Department of Physics, University of Pennsylvaniat
Brown Laboratory for Linguistic Information Processingt
Brown University
</affiliation>
<sectionHeader confidence="0.956199" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999774692307692">
It has been suggested that some forms of speech
disfluencies, most notable interjections and par-
entheticals, tend to occur disproportionally at
major clause boundaries [6] and thus might
serve to aid parsers in establishing these bound-
aries. We have tested a current statistical parser
[1] on Switchboard text with and without inter-
jections and parentheticals and found that the
parser performed better when not faced with
these extra phenomena. This suggest that for
current parsers, at least, interjection and paren-
thetical placement does not help in the parsing
process.
</bodyText>
<sectionHeader confidence="0.996303" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999556285714286">
It is generally recognized that punctuation
helps in parsing text. For example, Roark [5]
finds that removing punctuation decreases his
parser&apos;s accuracy from 86.6% to 83.8%. Our
experiments with the parser described in [1]
show a similar falloff. Unfortunately spoken
English does not come with punctuation, and
even when transcriptions add punctuation, as in
the Switchboard [4] corpus of transcribed (and
parsed) telephone calls, it&apos;s utility is small [5]
For this and other reasons there is considerable
interest in finding other aspects of speech that
might serve as a replacement.
One suggestion in this vein is that the place-
ment of some forms of speech errors might
encode useful linguistic information. Speech,
of course, contains many kinds of errors that
can make it more difficult to parse than text.
Roughly speaking the previously mentioned
Switchboard corpus distinguishes three kinds of
errors:
</bodyText>
<listItem confidence="0.9991742">
• interjections (filled pauses) &amp;quot;I, um, want
to leave&amp;quot;
• parentheticals &amp;quot;I, you know, want to
leave&amp;quot;
• speech repairs &amp;quot;I can, I want to leave&amp;quot;
</listItem>
<bodyText confidence="0.996380750000001">
Of these, speech repairs are the most injurious
to parsing. Furthermore, even if one&apos;s parser
can parse the sentence as it stands, that is not
sufficient. For example, in &amp;quot;I can, I want to
leave&amp;quot;, it is not necessarily the case that the
speaker believes that he or she can, in fact,
leave, only that he or she wants to leave. Thus
in [2] speech repairs were first detected in a sep-
arate module, and deleted before handing the
remaining text to the parser. The parser then
produced a parse of the text without the re-
paired section.
The other two kinds of errors, interjec-
tions, and parentheticals, (henceforth INTJs
and PRNs) are less problematic. In particular,
if they are left in the text either their seman-
tic content is compatible with the rest of the
utterance or there is no semantic content at all.
For example, Table 1 gives the 40 most common
INTJs, which comprise 97% of the total. (Un-
listed INTJs comprise the remaining 3%.) They
are easily recognized as not carrying much, if
any, content.
PRNs are more diverse. Table 2 lists the 40
most common PRNs. They only comprise 65%
of all cases, and many do contain semantics
content. In such cases, however, the semantic
content is compatible with the rest of the sen-
tence, so leaving them in is perfectly acceptable.
Thus [2], while endeavoring to detect and re-
move speech repairs, left interjections and par-
entheticals in the text for the parser to cope
with.
Indeed [6] finds that both interjections and
parentheticals tend to occur at major sentence
boundaries. Also [7] suggest that this prop-
</bodyText>
<table confidence="0.998723547619048">
Phrase Num. of Percent
INTJs
uh 17609 27.44
yeah 11310 17.62
uh-huh 7687 11.97
well 5287 8.238
um 3563 5.552
oh 2935 4.573
right 2873 4.477
like 1772 2.761
no 1246 1.941
okay 1237 1.927
yes 982 1.530
so 651 1.014
oh yeah 638 0.994
huh 558 0.869
now 410 0.638
really 279 0.434
sure 276 0.430
oh okay 269 0.419
see 261 0.406
oh really 260 0.405
huh-uh 185 0.288
wow 174 0.271
bye-bye 174 0.271
exactly 156 0.243
all right 146 0.227
yep 115 0.179
boy 111 0.172
oh no 102 0.158
bye 98 0.152
well yeah 91 0.141
gosh 91 0.141
oh gosh 88 0.137
oh yes 84 0.130
hey 75 0.116
uh yeah 71 0.110
anyway 71 0.110
oh uh-huh 70 0.109
say 63 0.098
oh goodness 61 0.095
uh no 56 0.087
</table>
<tableCaption confidence="0.999985">
Table 1: The 40 Most Common Interjections
</tableCaption>
<bodyText confidence="0.992474711111111">
Phrase Num. of Percent
PRNs
you know 431 37.02
I mean 105 9.020
I think 86 7.388
I guess 67 5.756
You know 44 3.780
I don&apos;t know 38 3.264
let&apos;s see 11 0.945
I I mean 10 0.859
I &apos;d say 9 0.773
I &apos;m sure 7 0.601
excuse me 6 0.515
what is it 6 0.515
I would say 5 0.429
you you know 5 0.429
let &apos;s say 5 0.429
I think it &apos;s 4 0.343
I &apos;m sorry 4 0.343
so to speak 3 0.257
I guess it &apos;s 3 0.257
I don&apos;t think 3 0.257
I think it was 3 0.257
I would think 3 0.257
it seems 3 0.257
I guess it was 2 0.171
I know 2 0.171
III mean 2 0.171
seems like 2 0.171
Shall we say 2 0.171
I guess you could say 2 0.171
You&apos;re right 2 0.171
I believe 2 0.171
I think it was uh 2 0.171
I say 2 0.171
What I call 2 0.171
I don&apos;t know what part of
New Jersey you&apos;re in but 2 0.171
I should say 2 0.171
I guess not a sore thumb 1 0.085
I &apos;m trying to think 1 0.085
And it&apos;s hard to drag 1 0.085
her away
I don&apos;t know what you 1 0.085
call that
</bodyText>
<tableCaption confidence="0.984166">
Table 2: The 40 Most Common Parentheticals
</tableCaption>
<bodyText confidence="0.999911555555556">
erty accounts for their observation that remov-
ing these disfluencies does not help in language
modeling perplexity results. This strongly sug-
gests that INTJ/PRN location information in
speech text might in fact, improve parsing per-
formance by helping the parser locate con-
stituent boundaries with high accuracy. That is,
a statistic parser such as [1] or [3] when trained
on parsed Switchboard text with these phenom-
ena left in, might learn the statistical correla-
tions between them and phrase boundaries just
as they are obviously learning the correlations
between punctuation and phrase boundaries in
written text.
In this paper then we wish to determine if the
presence of INTJs and PRNs do help parsing, at
least for one state-of-the-art statistical parser
[1].
</bodyText>
<sectionHeader confidence="0.980716" genericHeader="method">
2 Experimental Design
</sectionHeader>
<bodyText confidence="0.966622512820513">
The experimental design used was more com-
plicated than we initially expected. We had an-
ticipated that the experiments would be con-
ducted analogously to the &amp;quot;no punctuation&amp;quot; ex-
periments previously mentioned. In those ex-
periments one removes punctuation from all of
the corpus sentences, both for testing and train-
ing, and then one reports the results before and
after this removal. (Note that one must remove
punctuation from the training data as well so
that it looks like the non-punctuated testing
data it receives.) Parsing accuracy was mea-
sured in the usual way, using labeled precision
recall. Note, however, and this is a critical
point, that precision and recall are only mea-
sured on non-preterminal constituents. That is,
if we have a constituent
(PP (IN of)
(NP (DT the) (NN book)))
our measurements would note if we correctly
found the PP and the NP, but not the preter-
minals IN, DT, and NN. The logic of this is
to avoid confusing parsing results with part-of-
speech tagging, a much simpler problem.
Initially we conducted similarly designed ex-
periments, except rather than removing punc-
tuation, we removed INTJs and PRNs and com-
pared before and after precision/recall numbers.
These numbers seemed to confirm the antici-
pated results: the &amp;quot;after&amp;quot; numbers, the numbers
without INTJ/PRNs were significantly worse,
suggesting that the presence of INTJ/PRNs
helped the parser.
Unfortunately, although fine for punctuation,
this experimental design is not sufficient for
measuring the effects of INTJ/PRNs on parsing.
The difference is that punctuation itself is not
measured in the precision-recall numbers. That
is, if we had a phrase like
</bodyText>
<equation confidence="0.9957595">
(NP (NP (DT a) (NN sentence))
(, ,)
(ADJP (JJ like)
(NP (DT this) (DT one))))
</equation>
<bodyText confidence="0.9988105">
we would measure our accuracy on the three
NP&apos;s and the ADJP, but not on the pretermi-
nals, and it is only at the preterminal level that
punctuation appears.
The same cannot be said for INTJ/PRNs.
Consider the (slightly simplified) Switchboard
parse for a sentence like &amp;quot;I, you know, want to
leave&amp;quot;:
</bodyText>
<equation confidence="0.871958">
(S (NP I)
</equation>
<bodyText confidence="0.984919020408163">
(PRN , you know ,)
(VP want (S to leave)))
The parenthetical PRN is a full non-terminal
and thus is counted in precision/recall measure-
ments. Thus removing preterminals is chang-
ing what we wish to measure. In particu-
lar, when our initial results showed that re-
moval of INTJ/PRNs lowered precision/recall we
worried that it might be that INTJ/PRNs are
particularly easy to parse, and thus removing
them made things worse, not because of col-
lateral damage on our ability to parse other
constituents, but simply because we removed
a body of easily parseable constituents, leaving
the more difficult constituents to be measured.
The above tables of INTJs and PRNs lends cre-
dence to this concern.
Thus in the experiments below all measure-
ments are obtained in the following fashion:
1. The parser is trained on switchboard data
with/without INTJ/PRNs or punctuation,
creating eight configurations: 4 for neither,
both, just INTJs, and just PRNs, times
two for with and without punctuation. We
tested with and without punctuation to
confirm Roark&apos;s earlier results showing that
they have little influence in Switchboard
text.
2. The parser reads the gold standard testing
examples and depending on the configura-
tion INTJs and/or PRNS are removed from
the gold standard parse.
3. Finally the resulting parse is compared
with the gold standard. However, any re-
maining PRNs or INTJs are ignored when
computing the precision and recall statis-
tics for the parse.
To expand a bit on point (3) above, for an
experiment where we are parsing with INTJs,
but not PRNs, the resulting parse will, of course,
contain INTJs, but (a) they are not counted as
present in the gold standard (so we do not affect
recall statistics), and (b) they are not evaluated
in the guessed parse (so if one were labeled, say,
an S, it would not be counted against the parse).
The intent, again, is to not allow the results to
be influenced by the fact that interjections and
parentheticals are much easier to find than most
(if not) all other kinds of constituents.
</bodyText>
<sectionHeader confidence="0.995514" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.999858208333333">
As in [2] the Switchboard parsed/merged cor-
pus directories two and three were used for
training. In directory four, files sw4004.mrg
to sw4153.mrg were used for testing, and
sw4519.mrg to sw4936 for development. To
avoid confounding the results with problems of
edit detection, all edited nodes were deleted
from the gold standard parses.
The results of the experiment are given in
table 3. We have shown results separately
with and without punctuation. A quick look
at the data indicates that both sets show the
same trends but with punctuation helping per-
formance by about 1.0% absolute in both pre-
cision and recall. Within both groups, as is al-
ways the case, we see that the parser does better
when restricted to shorter sentences (40 words
and punctuation or less). We see that removing
PRNs or INTJs separately both improve parsing
accuracy (e.g., from 87.201% to 87.845 that
the effect of removing both is approximately
additive (e.g., from 87201% to 88.863%, again
on the with-punctuation data). Both with and
without punctuation results hint that removing
</bodyText>
<table confidence="0.9998623">
Punc. PRN INTJ Sentences Sentences
&lt; 40 &lt; 100
+ + + 88.93 87.20
+ + - 89.44 87.85
+ - + 89.13 87.99
+ - 90.00 88.86
- + + 87.40 86.23
- + - 88.0 86.8
- - + 88.41 87.45
- - - 89.13 88.30
</table>
<tableCaption confidence="0.967088">
Table 3: Average of labeled precision/recall
data for parsing with/without parentheti-
cals/interjections
</tableCaption>
<bodyText confidence="0.998397625">
parentheticals was usually more helpful than re-
moving interjections. However in one case the
reverse was true (with-punctuation, sentences
&lt; 40) and in all cases the differences are at or
under the edge of statistical reliability. In con-
trast, the differences between removing neither,
removing one, or removing both INJs and PRNs
are quite comfortably statistically reliable.
</bodyText>
<sectionHeader confidence="0.997332" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999972966101695">
Based upon Tabel 3 our tentative conclusion is
that the information present in parentheticals
and interjections does not help parsing. There
are, however, reasons that this is a tentative con-
clusion.
First, in our effort to prevent the ease of
recognizing these constructions from giving an
unfair advantage to the parser when they are
present, it could be argued that we have given
the parser an unfair advantage when they are
absent. After all, even if these constructions are
easily recognized, the parser is not perfect on
them. While our labeled precision/recall mea-
surements are made in such a way that a mis-
take in the label of, say, an interjection, would
not effect the results, a mistake on it&apos;s position
typically would have an effect because the po-
sitions of constituents either before or after it
would be made incorrect. Thus the parser has
a harder task set for it when these constituents
are left in.
It would be preferable to have an experimen-
tal design that would somehow equalize things,
but we have been unable to find one. Fur-
thermore it is instructive to contrast this situ-
ation with that of punctuation in Wall Street
Journal text. If we had found that parsing
without punctuation made things easier a sim-
ilar argument could be made that the without-
punctuation case was given an unfair advantage
since it had a lot fewer things to worry about.
But punctuation in well-edited text contains
more than enough information to overcome the
disadvantage. This does not seem to be the case
with INTJs and PRNs. Here the net information
content here seems to be negative.
A second, and in our estimation more serious,
objection to our conclusion is that we have only
done the experiment with one parser. Perhaps
there is something specific to this parser that
systematically underestimates the usefulness of
INTJ/PRN information. While we feel reason-
ably confident that any other current parser
would find similar effects, it is at least possi-
ble to imagine that quite different parsers might
not. Statistical parsers condition the probabil-
ity of a constituent on the types of neighbor-
ing constituents. Interjections and parenthet-
icals have the effect of increasing the kinds of
neighbors one might have, thus splitting the
data and making it less reliable. The same is
true for punctuation, of course, but it seems
plausible that well edited punctuation is suffi-
ciently regular that this problem is not too bad,
while spontaneous interjections and parentheti-
cals would not be so regular. Of course, finding
a parser design that might overcome this prob-
lem (assuming that this is the problem) is far
from obvious.
</bodyText>
<sectionHeader confidence="0.997696" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99988916">
We have tested a current statistical parser [1] on
Switchboard text with and without interjections
and parentheticals and found that the parser
performs better when not faced with these ex-
tra phenomena. This suggest that for current
parsers, at least, interjection and parenthetical
placement does not help in the parsing process.
This is, of course, a disappointing result. The
phenomena are not going to go away, and what
this means is that there is probably no silver
lining.
We should also note that the idea that they
might help parsing grew from the observation
that interjections and parentheticals typically
occur at major clause boundaries. One might
then ask if our results cast any doubt on this
claim as well. We do not think so. Interjections
and parentheticals do tend to identify clause
boundaries. The problem is that many other
things do so as well, most notably normal gram-
matical word ordering. The question is whether
the information content of disfluency placement
is sufficient to overcome the disruption of word
ordering that it entails. The answer, for current
parsers at least, seems to be &amp;quot;no&amp;quot;.
</bodyText>
<sectionHeader confidence="0.99864" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997404">
We would like to acknowledge the members of
the Brown Laboratory for Linguistic Informa-
tion Processing, This research has been sup-
ported in part by NSF grants IIS 0085940, IIS
0112435, and DGE 9870676.
</bodyText>
<sectionHeader confidence="0.998318" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997622">
1. CHARNIAK, E. A maximum-entropy-
inspired parser. In Proceedings of the 2000
Conference of the North American Chapter
of the Association for Computational Lin-
guistics. ACL, New Brunswick NJ, 2000,
132{139.
2. CHARNIAK, E. AND JOHNSON, M. Edit De-
tection and Parsing for Transcribed Speech.
In Proceedings of the North American As-
socation for Computational Linguistics 2001.
2001, 118{126.
3. COLLINS, M. J. Three generative lexical-
ized models for statistical parsing. In Pro-
ceedings of the 35th Annual Meeting of the
ACL. 1997, 16{23.
4. GODFREY, J. J., HOLLIMAN, E. C. AND
McDANIEL, J. SWITCHBOARD: Tele-
phone speech corpus for research and
development. . In Proceedings IEEE Con-
ference on Acoustics, Speech and Signal
Processing. San Francisco, 1992, 517{520 .
5. ROARK, B. Robust Probabilistic Predictive
Syntactic Processing: Motivations, Models,
and Applications. In Ph.D. thesis. Depart-
ment of Cognitive Science, Brown University,
Providence, RI, 2001.
6. SHRISERG, E. E. Preliminaries to a The-
ory of Speech Disfluencies. In Ph.D. Disser-
tation. Department of Psychology, University
of California-Berkeley, 1994.
7. STOLCKE, A. AND SHRIBERG, E. Auto-
matic linguistic segmantation of conversa-
tional speech. In Proceedings of the 4th In-
ternational Conference on Spoken Language
Processing (ICSLP-96). 1996.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.220378">
<note confidence="0.953289">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Philadelphia, July 2002, pp. 49-54. Association for Computational Linguistics.</note>
<title confidence="0.410658">Parsing and Disfluency Placement of Physics, University of Laboratory for Linguistic Information</title>
<affiliation confidence="0.995264">Brown University</affiliation>
<abstract confidence="0.997388928571429">It has been suggested that some forms of speech disfluencies, most notable interjections and parentheticals, tend to occur disproportionally at major clause boundaries [6] and thus might serve to aid parsers in establishing these boundaries. We have tested a current statistical parser [1] on Switchboard text with and without interjections and parentheticals and found that the parser performed better when not faced with these extra phenomena. This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E CHARNIAK</author>
</authors>
<title>A maximum-entropyinspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 Conference of the North American Chapter of the Association for Computational Linguistics. ACL,</booktitle>
<pages>132--139</pages>
<location>New Brunswick NJ,</location>
<contexts>
<context position="678" citStr="[1]" startWordPosition="92" endWordPosition="92">essing (EMNLP), Philadelphia, July 2002, pp. 49-54. Association for Computational Linguistics. Parsing and Disfluency Placement Donald Engelt and Eugene Charniakt and Mark Johnsont Department of Physics, University of Pennsylvaniat Brown Laboratory for Linguistic Information Processingt Brown University Abstract It has been suggested that some forms of speech disfluencies, most notable interjections and parentheticals, tend to occur disproportionally at major clause boundaries [6] and thus might serve to aid parsers in establishing these boundaries. We have tested a current statistical parser [1] on Switchboard text with and without interjections and parentheticals and found that the parser performed better when not faced with these extra phenomena. This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process. 1 Introduction It is generally recognized that punctuation helps in parsing text. For example, Roark [5] finds that removing punctuation decreases his parser&apos;s accuracy from 86.6% to 83.8%. Our experiments with the parser described in [1] show a similar falloff. Unfortunately spoken English does not come with punc</context>
<context position="5607" citStr="[1]" startWordPosition="1004" endWordPosition="1004"> what part of New Jersey you&apos;re in but 2 0.171 I should say 2 0.171 I guess not a sore thumb 1 0.085 I &apos;m trying to think 1 0.085 And it&apos;s hard to drag 1 0.085 her away I don&apos;t know what you 1 0.085 call that Table 2: The 40 Most Common Parentheticals erty accounts for their observation that removing these disfluencies does not help in language modeling perplexity results. This strongly suggests that INTJ/PRN location information in speech text might in fact, improve parsing performance by helping the parser locate constituent boundaries with high accuracy. That is, a statistic parser such as [1] or [3] when trained on parsed Switchboard text with these phenomena left in, might learn the statistical correlations between them and phrase boundaries just as they are obviously learning the correlations between punctuation and phrase boundaries in written text. In this paper then we wish to determine if the presence of INTJs and PRNs do help parsing, at least for one state-of-the-art statistical parser [1]. 2 Experimental Design The experimental design used was more complicated than we initially expected. We had anticipated that the experiments would be conducted analogously to the &amp;quot;no pun</context>
<context position="14562" citStr="[1]" startWordPosition="2502" endWordPosition="2502">es of neighboring constituents. Interjections and parentheticals have the effect of increasing the kinds of neighbors one might have, thus splitting the data and making it less reliable. The same is true for punctuation, of course, but it seems plausible that well edited punctuation is sufficiently regular that this problem is not too bad, while spontaneous interjections and parentheticals would not be so regular. Of course, finding a parser design that might overcome this problem (assuming that this is the problem) is far from obvious. 5 Conclusion We have tested a current statistical parser [1] on Switchboard text with and without interjections and parentheticals and found that the parser performs better when not faced with these extra phenomena. This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process. This is, of course, a disappointing result. The phenomena are not going to go away, and what this means is that there is probably no silver lining. We should also note that the idea that they might help parsing grew from the observation that interjections and parentheticals typically occur at major clause boundarie</context>
</contexts>
<marker>1.</marker>
<rawString>CHARNIAK, E. A maximum-entropyinspired parser. In Proceedings of the 2000 Conference of the North American Chapter of the Association for Computational Linguistics. ACL, New Brunswick NJ, 2000, 132{139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E CHARNIAK</author>
<author>M JOHNSON</author>
</authors>
<title>Edit Detection and Parsing for Transcribed Speech.</title>
<date>2001</date>
<booktitle>In Proceedings of the North American Assocation for Computational Linguistics</booktitle>
<pages>118--126</pages>
<contexts>
<context position="2369" citStr="[2]" startWordPosition="369" endWordPosition="369">cult to parse than text. Roughly speaking the previously mentioned Switchboard corpus distinguishes three kinds of errors: • interjections (filled pauses) &amp;quot;I, um, want to leave&amp;quot; • parentheticals &amp;quot;I, you know, want to leave&amp;quot; • speech repairs &amp;quot;I can, I want to leave&amp;quot; Of these, speech repairs are the most injurious to parsing. Furthermore, even if one&apos;s parser can parse the sentence as it stands, that is not sufficient. For example, in &amp;quot;I can, I want to leave&amp;quot;, it is not necessarily the case that the speaker believes that he or she can, in fact, leave, only that he or she wants to leave. Thus in [2] speech repairs were first detected in a separate module, and deleted before handing the remaining text to the parser. The parser then produced a parse of the text without the repaired section. The other two kinds of errors, interjections, and parentheticals, (henceforth INTJs and PRNs) are less problematic. In particular, if they are left in the text either their semantic content is compatible with the rest of the utterance or there is no semantic content at all. For example, Table 1 gives the 40 most common INTJs, which comprise 97% of the total. (Unlisted INTJs comprise the remaining 3%.) T</context>
<context position="10139" citStr="[2]" startWordPosition="1760" endWordPosition="1760">and a bit on point (3) above, for an experiment where we are parsing with INTJs, but not PRNs, the resulting parse will, of course, contain INTJs, but (a) they are not counted as present in the gold standard (so we do not affect recall statistics), and (b) they are not evaluated in the guessed parse (so if one were labeled, say, an S, it would not be counted against the parse). The intent, again, is to not allow the results to be influenced by the fact that interjections and parentheticals are much easier to find than most (if not) all other kinds of constituents. 3 Experimental Results As in [2] the Switchboard parsed/merged corpus directories two and three were used for training. In directory four, files sw4004.mrg to sw4153.mrg were used for testing, and sw4519.mrg to sw4936 for development. To avoid confounding the results with problems of edit detection, all edited nodes were deleted from the gold standard parses. The results of the experiment are given in table 3. We have shown results separately with and without punctuation. A quick look at the data indicates that both sets show the same trends but with punctuation helping performance by about 1.0% absolute in both precision an</context>
</contexts>
<marker>2.</marker>
<rawString>CHARNIAK, E. AND JOHNSON, M. Edit Detection and Parsing for Transcribed Speech. In Proceedings of the North American Assocation for Computational Linguistics 2001. 2001, 118{126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J COLLINS</author>
</authors>
<title>Three generative lexicalized models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the ACL.</booktitle>
<pages>16--23</pages>
<contexts>
<context position="5614" citStr="[3]" startWordPosition="1006" endWordPosition="1006">art of New Jersey you&apos;re in but 2 0.171 I should say 2 0.171 I guess not a sore thumb 1 0.085 I &apos;m trying to think 1 0.085 And it&apos;s hard to drag 1 0.085 her away I don&apos;t know what you 1 0.085 call that Table 2: The 40 Most Common Parentheticals erty accounts for their observation that removing these disfluencies does not help in language modeling perplexity results. This strongly suggests that INTJ/PRN location information in speech text might in fact, improve parsing performance by helping the parser locate constituent boundaries with high accuracy. That is, a statistic parser such as [1] or [3] when trained on parsed Switchboard text with these phenomena left in, might learn the statistical correlations between them and phrase boundaries just as they are obviously learning the correlations between punctuation and phrase boundaries in written text. In this paper then we wish to determine if the presence of INTJs and PRNs do help parsing, at least for one state-of-the-art statistical parser [1]. 2 Experimental Design The experimental design used was more complicated than we initially expected. We had anticipated that the experiments would be conducted analogously to the &amp;quot;no punctuatio</context>
</contexts>
<marker>3.</marker>
<rawString>COLLINS, M. J. Three generative lexicalized models for statistical parsing. In Proceedings of the 35th Annual Meeting of the ACL. 1997, 16{23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J GODFREY</author>
<author>E C HOLLIMAN</author>
<author>J McDANIEL</author>
</authors>
<title>SWITCHBOARD: Telephone speech corpus for research and development. .</title>
<date>1992</date>
<booktitle>In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing.</booktitle>
<pages>517--520</pages>
<location>San Francisco,</location>
<contexts>
<context position="1358" citStr="[4]" startWordPosition="195" endWordPosition="195">und that the parser performed better when not faced with these extra phenomena. This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process. 1 Introduction It is generally recognized that punctuation helps in parsing text. For example, Roark [5] finds that removing punctuation decreases his parser&apos;s accuracy from 86.6% to 83.8%. Our experiments with the parser described in [1] show a similar falloff. Unfortunately spoken English does not come with punctuation, and even when transcriptions add punctuation, as in the Switchboard [4] corpus of transcribed (and parsed) telephone calls, it&apos;s utility is small [5] For this and other reasons there is considerable interest in finding other aspects of speech that might serve as a replacement. One suggestion in this vein is that the placement of some forms of speech errors might encode useful linguistic information. Speech, of course, contains many kinds of errors that can make it more difficult to parse than text. Roughly speaking the previously mentioned Switchboard corpus distinguishes three kinds of errors: • interjections (filled pauses) &amp;quot;I, um, want to leave&amp;quot; • parenthetica</context>
</contexts>
<marker>4.</marker>
<rawString>GODFREY, J. J., HOLLIMAN, E. C. AND McDANIEL, J. SWITCHBOARD: Telephone speech corpus for research and development. . In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing. San Francisco, 1992, 517{520 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>B ROARK</author>
</authors>
<title>Robust Probabilistic Predictive Syntactic Processing: Motivations, Models, and Applications.</title>
<date>2001</date>
<booktitle>In Ph.D. thesis.</booktitle>
<institution>Department of Cognitive Science, Brown University,</institution>
<location>Providence, RI,</location>
<contexts>
<context position="1067" citStr="[5]" startWordPosition="152" endWordPosition="152">interjections and parentheticals, tend to occur disproportionally at major clause boundaries [6] and thus might serve to aid parsers in establishing these boundaries. We have tested a current statistical parser [1] on Switchboard text with and without interjections and parentheticals and found that the parser performed better when not faced with these extra phenomena. This suggest that for current parsers, at least, interjection and parenthetical placement does not help in the parsing process. 1 Introduction It is generally recognized that punctuation helps in parsing text. For example, Roark [5] finds that removing punctuation decreases his parser&apos;s accuracy from 86.6% to 83.8%. Our experiments with the parser described in [1] show a similar falloff. Unfortunately spoken English does not come with punctuation, and even when transcriptions add punctuation, as in the Switchboard [4] corpus of transcribed (and parsed) telephone calls, it&apos;s utility is small [5] For this and other reasons there is considerable interest in finding other aspects of speech that might serve as a replacement. One suggestion in this vein is that the placement of some forms of speech errors might encode useful l</context>
</contexts>
<marker>5.</marker>
<rawString>ROARK, B. Robust Probabilistic Predictive Syntactic Processing: Motivations, Models, and Applications. In Ph.D. thesis. Department of Cognitive Science, Brown University, Providence, RI, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E E SHRISERG</author>
</authors>
<title>Preliminaries to a Theory of Speech Disfluencies.</title>
<date>1994</date>
<booktitle>In Ph.D. Dissertation.</booktitle>
<institution>Department of Psychology, University of California-Berkeley,</institution>
<contexts>
<context position="3460" citStr="[6]" startWordPosition="559" endWordPosition="559">1 gives the 40 most common INTJs, which comprise 97% of the total. (Unlisted INTJs comprise the remaining 3%.) They are easily recognized as not carrying much, if any, content. PRNs are more diverse. Table 2 lists the 40 most common PRNs. They only comprise 65% of all cases, and many do contain semantics content. In such cases, however, the semantic content is compatible with the rest of the sentence, so leaving them in is perfectly acceptable. Thus [2], while endeavoring to detect and remove speech repairs, left interjections and parentheticals in the text for the parser to cope with. Indeed [6] finds that both interjections and parentheticals tend to occur at major sentence boundaries. Also [7] suggest that this propPhrase Num. of Percent INTJs uh 17609 27.44 yeah 11310 17.62 uh-huh 7687 11.97 well 5287 8.238 um 3563 5.552 oh 2935 4.573 right 2873 4.477 like 1772 2.761 no 1246 1.941 okay 1237 1.927 yes 982 1.530 so 651 1.014 oh yeah 638 0.994 huh 558 0.869 now 410 0.638 really 279 0.434 sure 276 0.430 oh okay 269 0.419 see 261 0.406 oh really 260 0.405 huh-uh 185 0.288 wow 174 0.271 bye-bye 174 0.271 exactly 156 0.243 all right 146 0.227 yep 115 0.179 boy 111 0.172 oh no 102 0.158 b</context>
</contexts>
<marker>6.</marker>
<rawString>SHRISERG, E. E. Preliminaries to a Theory of Speech Disfluencies. In Ph.D. Dissertation. Department of Psychology, University of California-Berkeley, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A STOLCKE</author>
<author>E SHRIBERG</author>
</authors>
<title>Automatic linguistic segmantation of conversational speech.</title>
<date>1996</date>
<booktitle>In Proceedings of the 4th International Conference on Spoken Language Processing (ICSLP-96).</booktitle>
<contexts>
<context position="3562" citStr="[7]" startWordPosition="574" endWordPosition="574">ing 3%.) They are easily recognized as not carrying much, if any, content. PRNs are more diverse. Table 2 lists the 40 most common PRNs. They only comprise 65% of all cases, and many do contain semantics content. In such cases, however, the semantic content is compatible with the rest of the sentence, so leaving them in is perfectly acceptable. Thus [2], while endeavoring to detect and remove speech repairs, left interjections and parentheticals in the text for the parser to cope with. Indeed [6] finds that both interjections and parentheticals tend to occur at major sentence boundaries. Also [7] suggest that this propPhrase Num. of Percent INTJs uh 17609 27.44 yeah 11310 17.62 uh-huh 7687 11.97 well 5287 8.238 um 3563 5.552 oh 2935 4.573 right 2873 4.477 like 1772 2.761 no 1246 1.941 okay 1237 1.927 yes 982 1.530 so 651 1.014 oh yeah 638 0.994 huh 558 0.869 now 410 0.638 really 279 0.434 sure 276 0.430 oh okay 269 0.419 see 261 0.406 oh really 260 0.405 huh-uh 185 0.288 wow 174 0.271 bye-bye 174 0.271 exactly 156 0.243 all right 146 0.227 yep 115 0.179 boy 111 0.172 oh no 102 0.158 bye 98 0.152 well yeah 91 0.141 gosh 91 0.141 oh gosh 88 0.137 oh yes 84 0.130 hey 75 0.116 uh yeah 71 </context>
</contexts>
<marker>7.</marker>
<rawString>STOLCKE, A. AND SHRIBERG, E. Automatic linguistic segmantation of conversational speech. In Proceedings of the 4th International Conference on Spoken Language Processing (ICSLP-96). 1996.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>