<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.044685">
<title confidence="0.998613">
High-quality Training Data Selection using Latent Topics
for Graph-based Semi-supervised Learning
</title>
<author confidence="0.987969">
Akiko Eriguchi
</author>
<affiliation confidence="0.98851">
Ochanomizu University
</affiliation>
<address confidence="0.81655">
2-1-1 Otsuka Bunkyo-ku Tokyo, Japan
</address>
<email confidence="0.997415">
g0920506@is.ocha.ac.jp
</email>
<author confidence="0.949866">
Ichiro Kobayashi
</author>
<affiliation confidence="0.960029">
Ochanomizu University
</affiliation>
<address confidence="0.800675">
2-1-1 Otsuka Bunkyo-ku Tokyo, Japan
</address>
<email confidence="0.998969">
koba@is.ocha.ac.jp
</email>
<sectionHeader confidence="0.993893" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99972852631579">
In a multi-class document categorization
using graph-based semi-supervised learn-
ing (GBSSL), it is essential to construct
a proper graph expressing the relation
among nodes and to use a reasonable cat-
egorization algorithm. Furthermore, it is
also important to provide high-quality cor-
rect data as training data. In this con-
text, we propose a method to construct a
similarity graph by employing both sur-
face information and latent information
to express similarity between nodes and
a method to select high-quality training
data for GBSSL by means of the PageR-
ank algorithm. Experimenting on Reuters-
21578 corpus, we have confirmed that our
proposed methods work well for raising
the accuracy of a multi-class document
categorization.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999695725490196">
Graph-based semi-supervised learning (GBSSL)
algorithm is known as a useful and promising tech-
nique in natural language processings. It has been
widely used for solving many document catego-
rization problems (Zhu and Ghahramani, 2002;
Zhu et al., 2003; Subramanya and Bilmes, 2008).
A good accuracy of GBSSL depends on success
in dealing with three crucial issues: graph con-
struction, selection of high-quality training data,
and categorization algorithm. We particularly fo-
cus on the former two issues in our study.
In a graph-based categorization of documents,
a graph is constructed based on a certain relation
between nodes (i.e. documents). It is similar-
ity that is often used to express the relation be-
tween nodes in a graph. We think of two types of
similarity: the one is between surface information
obtained by document vector (Salton and McGill,
1983) and the other is between latent information
obtained by word probabilistic distribution (Latent
Dirichlet Allocation (Blei et al., 2003)). Here,
we propose a method. We use both surface in-
formation and latent information at the ratio of
(1 − α) : α(0 &lt; α &lt; 1) to construct a similarity
graph for GBSSL, and we investigate the optimal
α for raising the accuracy in GBSSL.
In selecting high-quality training data, it is im-
portant to take two aspects of data into consider-
ation: quantity and quality. The more the train-
ing data are, the better the accuracy becomes. We
do not always, however, have a large quantity of
training data. In such a case, the quality of train-
ing data is generally a key for better accuracy. It is
required to assess the quality of training data ex-
actly. Now, we propose another method. We use
the PageRank algorithm (Brin and Page, 1998) to
select high-quality data, which have a high cen-
trality in a similarity graph of training data (i.e.
labeled data) in each category.
We apply our methods to solving the problem
of a multi-class document categorization. We in-
troduce PRBEP (precision recall break even point)
as a measure which is popular in the area of infor-
mation retrieval. We evaluate the results of exper-
iments for each category and for the whole cat-
egory. We confirm that the way of selecting the
high-quality training data from data on a similar-
ity graph based on both surface information and
latent information is superior to that of selecting
from a graph based on just surface information or
latent information.
</bodyText>
<sectionHeader confidence="0.991798" genericHeader="introduction">
2 Related studies
</sectionHeader>
<bodyText confidence="0.920196333333333">
Graph-based semi-supervised learning has re-
cently been studied so much and applied to many
applications (Subramanya and Bilmes, 2008; Sub-
ramanya and Bilmes, 2009; Subramanya et al.,
2010; Dipanjan and Petrov, 2011; Dipanjan and
Smith, 2012; Whitney and Sarkar, 2012).
</bodyText>
<page confidence="0.982431">
136
</page>
<note confidence="0.515161">
Proceedings of the ACL Student Research Workshop, pages 136–141,
</note>
<page confidence="0.363761">
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</page>
<bodyText confidence="0.999961058823529">
Subramanya and Bilmes (2008; 2009) have pro-
posed a soft-clustering method using GBSSL and
have shown that their own method is better than
the other main clustering methods of those days.
Subramanya et al. (2010) have also applied their
method to solve the problem of tagging and have
shown that it is useful. Dipanjan and Petrov
(2011) have applied a graph-based label propa-
gation method to solve the problem of part-of-
speech tagging. They have shown that their pro-
posed method exceeds a state-of-the-art baseline
of those days. Dipanjan and Smith (2012) have
also applied GBSSL to construct compact natu-
ral language lexicons. To achieve compactness,
they used the characteristics of a graph. Whitney
and Sarkar (2012) have proposed the bootstrap-
ping learning method in which a graph propaga-
tion algorithm is adopted.
There are two main issues in GBSSL: the one
is the way of constructing a graph to propagate la-
bels, and the other is the way of propagating la-
bels. It is essential to construct a good graph in
GBSSL (Zhu, 2005). On the one hand, graph con-
struction is a key to success of any GBSSL. On
the other hand, as for semi-supervised learning, it
is quite important to select better training data (i.e.
labeled data), because the effect of learning will
be changed by the data we select as training data.
Considering the above mentioned, in our study,
we focus on the way of selecting training data so
as to be well propagated in a graph. We use the
PageRank algorithm to select high-quality train-
ing data and evaluate how our proposed method
influences the way of document categorization.
</bodyText>
<sectionHeader confidence="0.976658" genericHeader="method">
3 Text classification based on a graph
</sectionHeader>
<bodyText confidence="0.999713666666667">
The details of our proposed GBSSL method in
a multi-class document categorization are as fol-
lows.
</bodyText>
<subsectionHeader confidence="0.999403">
3.1 Graph construction
</subsectionHeader>
<bodyText confidence="0.999738666666667">
In our study, we use a weighted undirected graph
G = (V, E) whose node and edge represent a doc-
ument and the similarity between nodes, respec-
tively. Similarity is regarded as weight. V and E
represent nodes and edges in a graph, respectively.
A graph G can be represented as an adjacency ma-
trix, and wij E W represents the similarity be-
tween nodes i and j. In particular, in the case of
GBSSL method, the similarity between nodes are
formed as wij = sim(xi, xj)S(j E K(i)). K(i)
is a set of i’s k-nearest neighbors, and S(z) is 1 if
z is true, otherwise 0.
</bodyText>
<subsectionHeader confidence="0.998668">
3.2 Similarity in a graph
</subsectionHeader>
<bodyText confidence="0.996664388888889">
Generally speaking, when we construct a graph
to represent some relation among documents, co-
sine similarity (simcos) of document vectors is
adopted as a similarity measure based on surface
information. In our study, we add the similarity
(simJS) based on latent information and the simi-
larity (simcos) based on surface information in the
proportion of α : (1 − α)(0 &lt; α &lt; 1). We define
the sum of simJS and simcos as simnodes (see,
Eq. (1)).
In Eq. (1), P and Q represent the latent topic
distributions of documents 5 and T, respectively.
We use Latent Dirichlet Allocation (LDA) (Blei
et al., 2003) to estimate the latent topic distribu-
tion of a document, and we use a measure Jensen-
Shannon divergence (DJS) for the similarity be-
tween topic distributions. Incidentally, simJS in
Eq (1) is expressed by Eq. (2).
</bodyText>
<equation confidence="0.998618333333333">
simnodes(5, T) - α * simJS(P, Q)
+(1 − α) * simcos(tfidf(5), tfidf(T)) (1)
simJS(P, Q) - 1 − DJS(P, Q) (2)
</equation>
<subsectionHeader confidence="0.999838">
3.3 Selection of training data
</subsectionHeader>
<bodyText confidence="0.996353434782609">
We use the graph-based document summarization
methods (Erkan and Radev, 2004; Kitajima and
Kobayashi, 2012) in order to select high-quality
training data. Erkan and Radev (2004) proposed a
multi-document summarization method using the
PageRank algorithm (Brin and Page, 1998) to ex-
tract important sentences. They showed that it
is useful to extract the important sentences which
have higher PageRank scores in a similarity graph
of sentences. Then, Kitajima and Kobayashi
(2012) have expanded the idea of Erkan and
Radev’s. They introduced latent information to
extract important sentences. They call their own
method TopicRank.
We adopt TopicRank method in our study. In or-
der to get high-quality training data, we first con-
struct a similarity graph of training data in each
category, and then compute a TopicRank score for
each training datum in every category graph. We
employ the data with a high TopicRank score as
training data in GBSSL.
In TopicRank method, Kitajima and Kobayashi
(2012) regard a sentence as a node in a graph on
</bodyText>
<page confidence="0.98937">
137
</page>
<bodyText confidence="0.999948888888889">
surface information and latent information. The
TopicRank score of each sentence is computed by
Eq. (3). Each sentence is ranked by its TopicRank
score. In Eq. (3), d indicates a damping factor.
We, however, deal with documents, so we replace
a sentence with a document (i.e. sentences) as a
node in a graph. In Eq. (3), N indicates total num-
ber of documents, adj[u] indicates the adjoining
nodes of document u.
</bodyText>
<equation confidence="0.97832125">
simnodes(u, v)
∑ simnodes(z, v)
zEadj[v]
+ 1 N d (3)
</equation>
<subsectionHeader confidence="0.970183">
3.4 Label propagation
</subsectionHeader>
<bodyText confidence="0.999989545454546">
We use the label propagation method (Zhu et al.,
2003; Zhou et al., 2004) in order to categorize doc-
uments. It is one of graph-based semi-supervised
learnings. It estimates the value of label based
on the assumption that the nodes linked to each
other in a graph should belong to the same cate-
gory. Here, W indicates an adjacency matrix. l
indicates the number of training data among all n
nodes in a graph. The estimation values f for n
nodes are obtained as the solution (Eq. (6)) of the
following objective function of an optimal prob-
lem (Eq. (4)). The first term in Eq. (4) expresses
the deviation between an estimation value and a
correct value of training data. The second term in
Eq. (4) expresses the difference between the esti-
mation values of the nodes which are next to an-
other in the adjacency graph. A(&gt; 0) is a param-
eter balancing both of the terms. Eq. (4) is trans-
formed into Eq. (5) by means of L. L(≡ D−W)
is called the Laplacian matrix. D is a diagonal ma-
trix, each diagonal element of which is equal to the
sum of elements in W’s each row (or column).
</bodyText>
<sectionHeader confidence="0.99958" genericHeader="method">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.998508">
4.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.999559526315789">
We use Reuters-21578 corpus data set1 collected
from the Reuters newswire in 1987 as target doc-
uments for a multi-class document categorization.
It consists of English news articles (classified into
135 categories). We use the “ModApte” split to
get training documents (i.e. labeled data) and
test documents (i.e. unlabeled data), extract doc-
uments which have only its title and text body,
and apply the stemming and the stop-word re-
moval processes to the documents. Then, follow-
ing the experimental settings of Subramanya and
Bilmes (2008)2 , we use 10 most frequent cate-
gories out of the 135 potential topic categories:
earn, acq, grain, wheat, money-fx, crude, trade,
interest, ship, and corn. We apply the one-versus-
the-rest method to give a category label to each
test document. Labels are given when the estima-
tion values of each document label exceed each of
the predefined thresholds.
We prepare 11 data sets. Each data set consists
of 3299 common test data and 20 training data.
We use 11 kinds of categories of training data:
the above mentioned 10 categories and a category
(other) which indicates 125 categories except 10
categories. The categories of 20 training data are
randomly chosen only if one of the 11 categories
is chosen at least once.
Selecting high-quality training data, we use the
Gibbs sampling for latent topic estimation in LDA.
The number of iteration is 200. The number of la-
tent topics in the target documents is decided by
averaging 10 trials of estimation with perplexity
(see, Eq. (7)). Here, N is the number of all words
in the target documents. wmn is the n-th word in
the m-th document. B is an occurrence probability
of the latent topics for the documents. O is an oc-
currence probability of the words for every latent
topic.
</bodyText>
<equation confidence="0.985645636363636">
∑r(u) = d
vEadj[u]
r(u)
J(f) = ∑l (y(i) − f(i))2
i=1
∑ w(i,j)(f(i) − f(j))2 (4)
+A
i&lt;j
P w ex 1
( ) = p(— N
mn
</equation>
<bodyText confidence="0.974846">
In each category, a similarity graph is con-
structed for the TopicRank method. The number
of nodes (i.e. |Vcategory|) in a graph corresponds to
</bodyText>
<equation confidence="0.9523808">
∑ BmzOzw,,J) (7)
log(
z
= ||y − f||2 2 + Af� Lf (5)
f = (I + AL)−1y (6)
</equation>
<footnote confidence="0.997826">
1http://www.daviddlewis.com/resources/testcollections/
reuters21578/
2Our data sets lack any tags and information excluding a
title and a text body. Therefore, we cannot directly
compare with Subramanya and Bilmes’ results.
</footnote>
<page confidence="0.997027">
138
</page>
<bodyText confidence="0.99983375862069">
the total number of training data in each category,
and the number of edges is E = ( Vcategory X
Vcategory ). So, the graph is a complete graph.
The parameter α in Eq (1) is varied from 0.0 to
1.0 every 0.1. We regard the average of TopicRank
scores after 5 trials as the TopicRank score of each
document. The number of training data in each
category is decided in each target data set. We
adopt training data with a higher TopicRank score
from the top up to the predefined number.
In label propagation, we construct another kind
of similarity graph. The number of nodes in a
graph is V�+,, = n(= 3319), and the similar-
ity between nodes is based on only surface infor-
mation (in the case of α = 0 in Eq. (1)). The
parameter k in the k-nearest neighbors method is
k E 12,10, 50,100, 250, 500,1000, 2000, n}, the
parameter A in the label propagation method, is
A E 11, 0.1, 0.01, 1e − 4, 1e − 81. Using one of
the 11 data sets, we decide a pair of optimal pa-
rameters (k, A) for each category. We categorize
the remaining 10 data sets by means of the decided
parameters. Then, we obtain the value of precision
recall break even point (PRBEP) and the average
of PRBEP in each category. The value of PRBEP
is that of precision or recall at the time when the
former is equal to the latter. It is often used as
an index to measure the ability of information re-
trieval.
</bodyText>
<subsectionHeader confidence="0.943825">
4.2 Result
</subsectionHeader>
<bodyText confidence="0.996276689655173">
Table 1 shows a pair of the optimal parameters
(k, A) in each category corresponding to the value
of α ranging from 0.0 to 1.0 every 0.1. Figures
from 1 to 10 show the experimental results in us-
ing these parameters in each category. The hori-
zontal axis indicates the value of α and the verti-
cal axis indicates the value of PRBEP. Each figure
shows the average of PRBEP in each category af-
ter 10 trials for each α. Fig. 11 shows how the
relative ratio of PRBEP changes corresponding to
each α in each category, when we let the PRBEP
at α = 0 an index 100. Fig. 12 shows the macro
average of PRBEP after 10 trials in the whole cat-
egory corresponding to each α. Error bars indicate
the standard deviations.
In all figures, the case at α = 0 means that only
surface information is used for selecting the train-
ing data. The case at α = 1 means that only latent
information is used. The other cases at α =� 0 or 1
mean that both latent information and surface in-
formation are mixed at the ratio of α : (1 − α)
(0 &lt; α &lt; 1).
First, we tell about Fig. 1-10. On the one hand,
in Fig. 4, 5, 6, 8, 10, the PRBEPs at α =� 0 are
greater than that at α = 0, although the PRBEP at
α = 1 is less than that at α = 0 in Fig. 4. On
the other hand, in Fig. 2, 7, the PRBEPs at α =� 0
are less than that at α = 0. In Fig. 1, 3, 9, the
PRBEPs at α =� 0 fluctuate widely or narrowly
around that at α = 0. In addition, the PRBEPs at
α = 0 range from 7.7 to 74.3 and those at α = 1
range from 8.0 to 72.6 in all 10 figures. It is hard
to find significant correlation between PRBEP and
α.
Secondly, in Fig. 11, some curves show an in-
creasing trend and others show a decreasing trend.
At best, the maximum value is three times as large
as that at α = 0. At worst, the minimum is one-
fifth. Indexes at α =� 0 are greater than or equal to
an index 100 at α = 0 in most categories.
Finally, in Fig. 12, the local maximums are
46.2, 46.9, 45.0 respectively at α = 0.2, 0.6, 0.9.
The maximum is 46.9 at α = 0.6. The mini-
mum value of the macro average is 35.8 at α = 0,
though the macro average at α = 1 is 43.4. Hence,
the maximum macro average is greater than that at
α = 1 by 3.5% and still greater than that at α = 0
by 11.1%. The macro average at α = 1 is greater
than that at α = 0 by 7.6%. Furthermore, the
macro average increases monotonically from 35.8
to 46.2 as α increases from 0.0 to 0.2. When α is
more than 0.2, the macro averages fluctuate within
the range from 40.3 to 46.9. It follows that the
macro average values at 0.1 &lt; α &lt; 1 are greater
than that at α = 0. What is more important, the
macro averages at α = 0.2, 0.4, 0.6, 0.7, 0.9 are
greater than that at α = 1 and of course greater
than that at α = 0.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999953636363636">
Looking at each Fig. 1-10, each optimal α at
which PRBEP is the maximum is different and not
uniform in respective categories. So, we cannot
simply tell a specific ratio of balancing both infor-
mation (i.e. surface information and latent infor-
mation) which gives the best accuracy.
From a total point of view, however, we can see
a definite trend or relationship. In Fig. 11, we
can see the upward tendency of PREBP in half of
categories. Indexes of the PRBEP at α &gt; 0.1 are
greater than or equal to 100 in most categories.
</bodyText>
<page confidence="0.999216">
139
</page>
<tableCaption confidence="0.998739">
Table 1: the optimal parameters (k, A) for each category
</tableCaption>
<bodyText confidence="0.898697636363636">
Category\α 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
earn (500, 1) (50, 1) (1000, 1) (1000, 1) (50, 1) (50, 1) (50, 1) (50, 1) (50, 1) (50, 1) (50, 1)
acq (100, 0.01) (100, 0.01) (100, 0.01) (2, 1) (100, 0.01) (100, 0.01) (100, 1e-8) (100, 1e-8) (100, 1e-8) (100, 1e-8) (100, 1e-8)
money-fx (250, 0.01) (100, 1e-8) (10, 1e-4) (100, 1e-8) (2, 0.1) (2, 0.1) (2, 1e-8) (250, 1e-8) (2, 0.1) (2, 1e-8) (250, 1e-8)
grain (250, 0.1) (2000, 1e-4) (100, 1) (250, 0.1) (100, 1) (50, 1) (250, 1) (50, 1) (50, 1) (50, 1) (100, 1)
crude (50, 0.1) (2, 1) (250, 0.01) (50, 1e-8) (10, 0.01) (250, 0.01) (250, 0.01) (250, 1e-8) (10, 0.01) (250, 0.01) (250, 0.01)
trade (2, 1) (10, 0.1) (50, 0.01) (10, 1e-8) (10, 1e-8) (10, 1e-8) (50, 1e-8) (10, 1e-8) (10, 1e-4) (10, 0.1) (10, 0.1)
interest (10, 1) (50, 1e-8) (50, 1e-8) (10, 1) (2, 0.1) (250, 1e-8) (250, 0.01) (250, 0.01) (2, 1) (2, 0.1) (500, 1e-8)
ship (3318, 1) (50, 1) (50, 1) (250, 0.1) (50, 0.1) (50, 0.1) (50, 1e-8) (50, 1e-8) (100, 0.1) (100, 0.1) (50, 0.01)
wheat (500, 1e-8) (500, 1e-8) (250, 1e-8) (500, 1e-8) (500, 0.01) (1000, 0.01) (500, 1e-8) (250, 1e-8) (250, 1e-8) (250, 1e-8) (250, 1e-8)
corn (10, 1e-8) (100, 1e-8) (250, 1e-8) (10, 1e-8) (250, 1e-8) (250, 1e-4) (500, 1e-8) (100, 1e-8) (250, 1e-8) (50, 0.01) (250, 1e-4)
</bodyText>
<figureCaption confidence="0.9996475">
Figure 1: earn Figure 2: acq Figure 3: money-fx
Figure 4: grain Figure 5: crude Figure 6: trade
Figure 7: interest Figure 8: ship Figure 9: wheat
Figure 10: corn Figure 11: Relative value Figure 12: Macro average
</figureCaption>
<page confidence="0.98143">
140
</page>
<bodyText confidence="0.999980583333333">
The macro average of the whole category is shown
in Fig. 12. Regarding the macro average at α = 0
as a baseline, the macro average at α = 1 is greater
than that at α = 0 by 7.6% and still more, the max-
imum at α = 0.6 is greater by 11.1%. Besides,
five macro averages at 0.1 &lt; α &lt; 1 are greater
than that at α = 1. Therefore, we can say that
using latent information gives a higher accuracy
than using only surface information and that using
both information gives a higher accuracy than us-
ing only latent information. So, if a proper α is
decided, we will get a better accuracy.
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99999465">
We have proposed methods to construct a sim-
ilarity graph based on both surface information
and latent information and to select high-quality
training data for GBSSL. Through experiments,
we have found that using both information gives
a better accuracy than using either only surface
information or only latent information. We used
the PageRank algorithm in the selection of high-
quality training data. In this condition, we have
confirmed that our proposed methods are useful
for raising the accuracy of a multi-class document
categorization using GBSSL in the whole cate-
gory.
Our future work is as follows. We will verify
in other data corpus sets that the selection of high-
quality training data with both information gives
a better accuracy and that the optimal α is around
0.6. We will revise the way of setting a pair of the
optimal parameters (k, A) and use latent informa-
tion in the process of label propagation.
</bodyText>
<sectionHeader confidence="0.998603" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994">
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research.
Sergey Brin and Lawrence Page. 1998. The Anatomy
of a Large-scale Hypertextual Web Search Engine.
Computer Networks and ISDN Systems, pages 107–
117.
Das Dipanjan and Noah A. Smith. 2012. Graph-based
lexicon expansion with sparsity-inducing penalties.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ’12, pages 677–687.
Das Dipanjan and Slav Petrov. 2011. Unsupervised
Part-of-Speech Tagging with Bilingual Graph-Based
Projections. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies - Vol. 1,
pages 600–609.
G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank:
Graph-based Lexical Centrality as Salience in Text
Summarization. Journal of Artificial Intelligence
Research 22, pages 457-479.
G¨unes¸ Erkan. 2006. Language Model-Based Docu-
ment Clustering Using Random Walks. Association
for Computational Linguistics, pages 479–486.
Risa Kitajima and Ichiro Kobayashi. 2012. Multiple-
document Summarization baed on a Graph con-
structed based on Latent Information. In Proceed-
ings of ARG Web intelligence and interaction, 2012-
WI2-1-21.
Gerard Salton and Michael J. McGill. 1983. Intro-
duction to Modern Information Retrieval. McGraw-
Hill.
Amarnag Subramanya and Jeff Bilmes. 2008. Soft-
Supervised Learning for Text Classification. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1090–
1099.
Amarnag Subramanya and Jeff Bilmes. 2009. En-
tropic graph regularization in non-parametric semi-
supervised classification. In Proceedings of NIPS.
Amarnag Subramanya, Slav Petrov and Fernando
Pereira. 2010. Efficient graph-based semi-
supervised learning of structured tagging models.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
167–176.
Dengyong Zhou, Oliver Bousquet, Thomas Navin Lal,
Jason Weston, and Bernhard Sch¨olkopf. 2004.
Learning with Local and Global Consistency. In
NIPS 16.
Xiaojin Zhu and Zoubin Ghahramani. 2002. Learning
from Labeled and Unlabeled Data with Label Prop-
agation. Technical report, Carnegie Mellon Univer-
sity.
Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.
2003. Semi-Supervised Learning Using Gaussian
Fields and Harmonic Functions. In Proceedigns of
the International Conference on Machine Learning
(ICML).
Xiaojin Zhu. 2005. Semi-Supervised Learning with
Graphs. PhD thesis, Carnegie Mellon University.
Max Whitney and Anoop Sarkar. 2012. Bootstrapping
via Graph Propagation. The 50th Annual Meeting of
the Association for Computational Linguistics.
</reference>
<page confidence="0.998214">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.048275">
<title confidence="0.857807333333333">High-quality Training Data Selection using Latent for Graph-based Semi-supervised Learning Akiko</title>
<author confidence="0.287001">Ochanomizu</author>
<affiliation confidence="0.302658">2-1-1 Otsuka Bunkyo-ku Tokyo,</affiliation>
<email confidence="0.881066">g0920506@is.ocha.ac.jp</email>
<affiliation confidence="0.503265">Ichiro Ochanomizu</affiliation>
<address confidence="0.747866">2-1-1 Otsuka Bunkyo-ku Tokyo,</address>
<email confidence="0.991855">koba@is.ocha.ac.jp</email>
<abstract confidence="0.9943936">In a multi-class document categorization using graph-based semi-supervised learning (GBSSL), it is essential to construct a proper graph expressing the relation among nodes and to use a reasonable categorization algorithm. Furthermore, it is also important to provide high-quality correct data as training data. In this context, we propose a method to construct a similarity graph by employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageRank algorithm. Experimenting on Reuters- 21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="2042" citStr="Blei et al., 2003" startWordPosition="299" endWordPosition="302">ion, selection of high-quality training data, and categorization algorithm. We particularly focus on the former two issues in our study. In a graph-based categorization of documents, a graph is constructed based on a certain relation between nodes (i.e. documents). It is similarity that is often used to express the relation between nodes in a graph. We think of two types of similarity: the one is between surface information obtained by document vector (Salton and McGill, 1983) and the other is between latent information obtained by word probabilistic distribution (Latent Dirichlet Allocation (Blei et al., 2003)). Here, we propose a method. We use both surface information and latent information at the ratio of (1 − α) : α(0 &lt; α &lt; 1) to construct a similarity graph for GBSSL, and we investigate the optimal α for raising the accuracy in GBSSL. In selecting high-quality training data, it is important to take two aspects of data into consideration: quantity and quality. The more the training data are, the better the accuracy becomes. We do not always, however, have a large quantity of training data. In such a case, the quality of training data is generally a key for better accuracy. It is required to ass</context>
<context position="6835" citStr="Blei et al., 2003" startWordPosition="1129" endWordPosition="1132">ilarity in a graph Generally speaking, when we construct a graph to represent some relation among documents, cosine similarity (simcos) of document vectors is adopted as a similarity measure based on surface information. In our study, we add the similarity (simJS) based on latent information and the similarity (simcos) based on surface information in the proportion of α : (1 − α)(0 &lt; α &lt; 1). We define the sum of simJS and simcos as simnodes (see, Eq. (1)). In Eq. (1), P and Q represent the latent topic distributions of documents 5 and T, respectively. We use Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to estimate the latent topic distribution of a document, and we use a measure JensenShannon divergence (DJS) for the similarity between topic distributions. Incidentally, simJS in Eq (1) is expressed by Eq. (2). simnodes(5, T) - α * simJS(P, Q) +(1 − α) * simcos(tfidf(5), tfidf(T)) (1) simJS(P, Q) - 1 − DJS(P, Q) (2) 3.3 Selection of training data We use the graph-based document summarization methods (Erkan and Radev, 2004; Kitajima and Kobayashi, 2012) in order to select high-quality training data. Erkan and Radev (2004) proposed a multi-document summarization method using the PageRank algor</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The Anatomy of a Large-scale Hypertextual Web Search Engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>107--117</pages>
<contexts>
<context position="2767" citStr="Brin and Page, 1998" startWordPosition="433" endWordPosition="436"> α) : α(0 &lt; α &lt; 1) to construct a similarity graph for GBSSL, and we investigate the optimal α for raising the accuracy in GBSSL. In selecting high-quality training data, it is important to take two aspects of data into consideration: quantity and quality. The more the training data are, the better the accuracy becomes. We do not always, however, have a large quantity of training data. In such a case, the quality of training data is generally a key for better accuracy. It is required to assess the quality of training data exactly. Now, we propose another method. We use the PageRank algorithm (Brin and Page, 1998) to select high-quality data, which have a high centrality in a similarity graph of training data (i.e. labeled data) in each category. We apply our methods to solving the problem of a multi-class document categorization. We introduce PRBEP (precision recall break even point) as a measure which is popular in the area of information retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior t</context>
<context position="7461" citStr="Brin and Page, 1998" startWordPosition="1231" endWordPosition="1234">timate the latent topic distribution of a document, and we use a measure JensenShannon divergence (DJS) for the similarity between topic distributions. Incidentally, simJS in Eq (1) is expressed by Eq. (2). simnodes(5, T) - α * simJS(P, Q) +(1 − α) * simcos(tfidf(5), tfidf(T)) (1) simJS(P, Q) - 1 − DJS(P, Q) (2) 3.3 Selection of training data We use the graph-based document summarization methods (Erkan and Radev, 2004; Kitajima and Kobayashi, 2012) in order to select high-quality training data. Erkan and Radev (2004) proposed a multi-document summarization method using the PageRank algorithm (Brin and Page, 1998) to extract important sentences. They showed that it is useful to extract the important sentences which have higher PageRank scores in a similarity graph of sentences. Then, Kitajima and Kobayashi (2012) have expanded the idea of Erkan and Radev’s. They introduced latent information to extract important sentences. They call their own method TopicRank. We adopt TopicRank method in our study. In order to get high-quality training data, we first construct a similarity graph of training data in each category, and then compute a TopicRank score for each training datum in every category graph. We em</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The Anatomy of a Large-scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems, pages 107– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Das Dipanjan</author>
<author>Noah A Smith</author>
</authors>
<title>Graph-based lexicon expansion with sparsity-inducing penalties.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>677--687</pages>
<contexts>
<context position="3714" citStr="Dipanjan and Smith, 2012" startWordPosition="589" endWordPosition="592">nformation retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dipanjan and Petrov (2011) have applied a graph-based label propagation method to solve the problem of part-of</context>
</contexts>
<marker>Dipanjan, Smith, 2012</marker>
<rawString>Das Dipanjan and Noah A. Smith. 2012. Graph-based lexicon expansion with sparsity-inducing penalties. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, pages 677–687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Das Dipanjan</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies -</booktitle>
<volume>1</volume>
<pages>600--609</pages>
<contexts>
<context position="3688" citStr="Dipanjan and Petrov, 2011" startWordPosition="585" endWordPosition="588">is popular in the area of information retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dipanjan and Petrov (2011) have applied a graph-based label propagation method to so</context>
</contexts>
<marker>Dipanjan, Petrov, 2011</marker>
<rawString>Das Dipanjan and Slav Petrov. 2011. Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Vol. 1, pages 600–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based Lexical Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research</journal>
<volume>22</volume>
<pages>457--479</pages>
<contexts>
<context position="7262" citStr="Erkan and Radev, 2004" startWordPosition="1203" endWordPosition="1206">d simcos as simnodes (see, Eq. (1)). In Eq. (1), P and Q represent the latent topic distributions of documents 5 and T, respectively. We use Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to estimate the latent topic distribution of a document, and we use a measure JensenShannon divergence (DJS) for the similarity between topic distributions. Incidentally, simJS in Eq (1) is expressed by Eq. (2). simnodes(5, T) - α * simJS(P, Q) +(1 − α) * simcos(tfidf(5), tfidf(T)) (1) simJS(P, Q) - 1 − DJS(P, Q) (2) 3.3 Selection of training data We use the graph-based document summarization methods (Erkan and Radev, 2004; Kitajima and Kobayashi, 2012) in order to select high-quality training data. Erkan and Radev (2004) proposed a multi-document summarization method using the PageRank algorithm (Brin and Page, 1998) to extract important sentences. They showed that it is useful to extract the important sentences which have higher PageRank scores in a similarity graph of sentences. Then, Kitajima and Kobayashi (2012) have expanded the idea of Erkan and Radev’s. They introduced latent information to extract important sentences. They call their own method TopicRank. We adopt TopicRank method in our study. In orde</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research 22, pages 457-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
</authors>
<title>Language Model-Based Document Clustering Using Random Walks. Association for Computational Linguistics,</title>
<date>2006</date>
<pages>479--486</pages>
<marker>Erkan, 2006</marker>
<rawString>G¨unes¸ Erkan. 2006. Language Model-Based Document Clustering Using Random Walks. Association for Computational Linguistics, pages 479–486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Risa Kitajima</author>
<author>Ichiro Kobayashi</author>
</authors>
<title>Multipledocument Summarization baed on a Graph constructed based on Latent Information.</title>
<date>2012</date>
<booktitle>In Proceedings of ARG Web intelligence and interaction,</booktitle>
<pages>2012--2</pages>
<contexts>
<context position="7293" citStr="Kitajima and Kobayashi, 2012" startWordPosition="1207" endWordPosition="1210">ee, Eq. (1)). In Eq. (1), P and Q represent the latent topic distributions of documents 5 and T, respectively. We use Latent Dirichlet Allocation (LDA) (Blei et al., 2003) to estimate the latent topic distribution of a document, and we use a measure JensenShannon divergence (DJS) for the similarity between topic distributions. Incidentally, simJS in Eq (1) is expressed by Eq. (2). simnodes(5, T) - α * simJS(P, Q) +(1 − α) * simcos(tfidf(5), tfidf(T)) (1) simJS(P, Q) - 1 − DJS(P, Q) (2) 3.3 Selection of training data We use the graph-based document summarization methods (Erkan and Radev, 2004; Kitajima and Kobayashi, 2012) in order to select high-quality training data. Erkan and Radev (2004) proposed a multi-document summarization method using the PageRank algorithm (Brin and Page, 1998) to extract important sentences. They showed that it is useful to extract the important sentences which have higher PageRank scores in a similarity graph of sentences. Then, Kitajima and Kobayashi (2012) have expanded the idea of Erkan and Radev’s. They introduced latent information to extract important sentences. They call their own method TopicRank. We adopt TopicRank method in our study. In order to get high-quality training </context>
</contexts>
<marker>Kitajima, Kobayashi, 2012</marker>
<rawString>Risa Kitajima and Ichiro Kobayashi. 2012. Multipledocument Summarization baed on a Graph constructed based on Latent Information. In Proceedings of ARG Web intelligence and interaction, 2012-WI2-1-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1983</date>
<publisher>McGrawHill.</publisher>
<contexts>
<context position="1905" citStr="Salton and McGill, 1983" startWordPosition="280" endWordPosition="283">u et al., 2003; Subramanya and Bilmes, 2008). A good accuracy of GBSSL depends on success in dealing with three crucial issues: graph construction, selection of high-quality training data, and categorization algorithm. We particularly focus on the former two issues in our study. In a graph-based categorization of documents, a graph is constructed based on a certain relation between nodes (i.e. documents). It is similarity that is often used to express the relation between nodes in a graph. We think of two types of similarity: the one is between surface information obtained by document vector (Salton and McGill, 1983) and the other is between latent information obtained by word probabilistic distribution (Latent Dirichlet Allocation (Blei et al., 2003)). Here, we propose a method. We use both surface information and latent information at the ratio of (1 − α) : α(0 &lt; α &lt; 1) to construct a similarity graph for GBSSL, and we investigate the optimal α for raising the accuracy in GBSSL. In selecting high-quality training data, it is important to take two aspects of data into consideration: quantity and quality. The more the training data are, the better the accuracy becomes. We do not always, however, have a la</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>Gerard Salton and Michael J. McGill. 1983. Introduction to Modern Information Retrieval. McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amarnag Subramanya</author>
<author>Jeff Bilmes</author>
</authors>
<title>SoftSupervised Learning for Text Classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1090--1099</pages>
<contexts>
<context position="1325" citStr="Subramanya and Bilmes, 2008" startWordPosition="185" endWordPosition="188">urface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageRank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization. 1 Introduction Graph-based semi-supervised learning (GBSSL) algorithm is known as a useful and promising technique in natural language processings. It has been widely used for solving many document categorization problems (Zhu and Ghahramani, 2002; Zhu et al., 2003; Subramanya and Bilmes, 2008). A good accuracy of GBSSL depends on success in dealing with three crucial issues: graph construction, selection of high-quality training data, and categorization algorithm. We particularly focus on the former two issues in our study. In a graph-based categorization of documents, a graph is constructed based on a certain relation between nodes (i.e. documents). It is similarity that is often used to express the relation between nodes in a graph. We think of two types of similarity: the one is between surface information obtained by document vector (Salton and McGill, 1983) and the other is be</context>
<context position="3607" citStr="Subramanya and Bilmes, 2008" startWordPosition="572" endWordPosition="575">ization. We introduce PRBEP (precision recall break even point) as a measure which is popular in the area of information retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dip</context>
<context position="10365" citStr="Subramanya and Bilmes (2008)" startWordPosition="1735" endWordPosition="1738">the sum of elements in W’s each row (or column). 4 Experiment 4.1 Experimental settings We use Reuters-21578 corpus data set1 collected from the Reuters newswire in 1987 as target documents for a multi-class document categorization. It consists of English news articles (classified into 135 categories). We use the “ModApte” split to get training documents (i.e. labeled data) and test documents (i.e. unlabeled data), extract documents which have only its title and text body, and apply the stemming and the stop-word removal processes to the documents. Then, following the experimental settings of Subramanya and Bilmes (2008)2 , we use 10 most frequent categories out of the 135 potential topic categories: earn, acq, grain, wheat, money-fx, crude, trade, interest, ship, and corn. We apply the one-versusthe-rest method to give a category label to each test document. Labels are given when the estimation values of each document label exceed each of the predefined thresholds. We prepare 11 data sets. Each data set consists of 3299 common test data and 20 training data. We use 11 kinds of categories of training data: the above mentioned 10 categories and a category (other) which indicates 125 categories except 10 catego</context>
</contexts>
<marker>Subramanya, Bilmes, 2008</marker>
<rawString>Amarnag Subramanya and Jeff Bilmes. 2008. SoftSupervised Learning for Text Classification. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 1090– 1099.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amarnag Subramanya</author>
<author>Jeff Bilmes</author>
</authors>
<title>Entropic graph regularization in non-parametric semisupervised classification.</title>
<date>2009</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="3636" citStr="Subramanya and Bilmes, 2009" startWordPosition="576" endWordPosition="580">precision recall break even point) as a measure which is popular in the area of information retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dipanjan and Petrov (2011) have </context>
</contexts>
<marker>Subramanya, Bilmes, 2009</marker>
<rawString>Amarnag Subramanya and Jeff Bilmes. 2009. Entropic graph regularization in non-parametric semisupervised classification. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amarnag Subramanya</author>
<author>Slav Petrov</author>
<author>Fernando Pereira</author>
</authors>
<title>Efficient graph-based semisupervised learning of structured tagging models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>167--176</pages>
<contexts>
<context position="3661" citStr="Subramanya et al., 2010" startWordPosition="581" endWordPosition="584">oint) as a measure which is popular in the area of information retrieval. We evaluate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dipanjan and Petrov (2011) have applied a graph-based lab</context>
</contexts>
<marker>Subramanya, Petrov, Pereira, 2010</marker>
<rawString>Amarnag Subramanya, Slav Petrov and Fernando Pereira. 2010. Efficient graph-based semisupervised learning of structured tagging models. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 167–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dengyong Zhou</author>
<author>Oliver Bousquet</author>
<author>Thomas Navin Lal</author>
<author>Jason Weston</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>Learning with Local and Global Consistency.</title>
<date>2004</date>
<booktitle>In NIPS 16.</booktitle>
<marker>Zhou, Bousquet, Lal, Weston, Sch¨olkopf, 2004</marker>
<rawString>Dengyong Zhou, Oliver Bousquet, Thomas Navin Lal, Jason Weston, and Bernhard Sch¨olkopf. 2004. Learning with Local and Global Consistency. In NIPS 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>Learning from Labeled and Unlabeled Data with Label Propagation.</title>
<date>2002</date>
<tech>Technical report,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="1277" citStr="Zhu and Ghahramani, 2002" startWordPosition="177" endWordPosition="180">truct a similarity graph by employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageRank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization. 1 Introduction Graph-based semi-supervised learning (GBSSL) algorithm is known as a useful and promising technique in natural language processings. It has been widely used for solving many document categorization problems (Zhu and Ghahramani, 2002; Zhu et al., 2003; Subramanya and Bilmes, 2008). A good accuracy of GBSSL depends on success in dealing with three crucial issues: graph construction, selection of high-quality training data, and categorization algorithm. We particularly focus on the former two issues in our study. In a graph-based categorization of documents, a graph is constructed based on a certain relation between nodes (i.e. documents). It is similarity that is often used to express the relation between nodes in a graph. We think of two types of similarity: the one is between surface information obtained by document vect</context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>Xiaojin Zhu and Zoubin Ghahramani. 2002. Learning from Labeled and Unlabeled Data with Label Propagation. Technical report, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
<author>John Lafferty</author>
</authors>
<title>Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.</title>
<date>2003</date>
<booktitle>In Proceedigns of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="1295" citStr="Zhu et al., 2003" startWordPosition="181" endWordPosition="184">y employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageRank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization. 1 Introduction Graph-based semi-supervised learning (GBSSL) algorithm is known as a useful and promising technique in natural language processings. It has been widely used for solving many document categorization problems (Zhu and Ghahramani, 2002; Zhu et al., 2003; Subramanya and Bilmes, 2008). A good accuracy of GBSSL depends on success in dealing with three crucial issues: graph construction, selection of high-quality training data, and categorization algorithm. We particularly focus on the former two issues in our study. In a graph-based categorization of documents, a graph is constructed based on a certain relation between nodes (i.e. documents). It is similarity that is often used to express the relation between nodes in a graph. We think of two types of similarity: the one is between surface information obtained by document vector (Salton and McG</context>
<context position="8767" citStr="Zhu et al., 2003" startWordPosition="1454" endWordPosition="1457">Kitajima and Kobayashi (2012) regard a sentence as a node in a graph on 137 surface information and latent information. The TopicRank score of each sentence is computed by Eq. (3). Each sentence is ranked by its TopicRank score. In Eq. (3), d indicates a damping factor. We, however, deal with documents, so we replace a sentence with a document (i.e. sentences) as a node in a graph. In Eq. (3), N indicates total number of documents, adj[u] indicates the adjoining nodes of document u. simnodes(u, v) ∑ simnodes(z, v) zEadj[v] + 1 N d (3) 3.4 Label propagation We use the label propagation method (Zhu et al., 2003; Zhou et al., 2004) in order to categorize documents. It is one of graph-based semi-supervised learnings. It estimates the value of label based on the assumption that the nodes linked to each other in a graph should belong to the same category. Here, W indicates an adjacency matrix. l indicates the number of training data among all n nodes in a graph. The estimation values f for n nodes are obtained as the solution (Eq. (6)) of the following objective function of an optimal problem (Eq. (4)). The first term in Eq. (4) expresses the deviation between an estimation value and a correct value of </context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. 2003. Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. In Proceedigns of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
</authors>
<title>Semi-Supervised Learning with Graphs.</title>
<date>2005</date>
<tech>PhD thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="4923" citStr="Zhu, 2005" startWordPosition="790" endWordPosition="791">fspeech tagging. They have shown that their proposed method exceeds a state-of-the-art baseline of those days. Dipanjan and Smith (2012) have also applied GBSSL to construct compact natural language lexicons. To achieve compactness, they used the characteristics of a graph. Whitney and Sarkar (2012) have proposed the bootstrapping learning method in which a graph propagation algorithm is adopted. There are two main issues in GBSSL: the one is the way of constructing a graph to propagate labels, and the other is the way of propagating labels. It is essential to construct a good graph in GBSSL (Zhu, 2005). On the one hand, graph construction is a key to success of any GBSSL. On the other hand, as for semi-supervised learning, it is quite important to select better training data (i.e. labeled data), because the effect of learning will be changed by the data we select as training data. Considering the above mentioned, in our study, we focus on the way of selecting training data so as to be well propagated in a graph. We use the PageRank algorithm to select high-quality training data and evaluate how our proposed method influences the way of document categorization. 3 Text classification based on</context>
</contexts>
<marker>Zhu, 2005</marker>
<rawString>Xiaojin Zhu. 2005. Semi-Supervised Learning with Graphs. PhD thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Whitney</author>
<author>Anoop Sarkar</author>
</authors>
<title>Bootstrapping via Graph Propagation.</title>
<date>2012</date>
<booktitle>The 50th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3741" citStr="Whitney and Sarkar, 2012" startWordPosition="593" endWordPosition="596">valuate the results of experiments for each category and for the whole category. We confirm that the way of selecting the high-quality training data from data on a similarity graph based on both surface information and latent information is superior to that of selecting from a graph based on just surface information or latent information. 2 Related studies Graph-based semi-supervised learning has recently been studied so much and applied to many applications (Subramanya and Bilmes, 2008; Subramanya and Bilmes, 2009; Subramanya et al., 2010; Dipanjan and Petrov, 2011; Dipanjan and Smith, 2012; Whitney and Sarkar, 2012). 136 Proceedings of the ACL Student Research Workshop, pages 136–141, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Subramanya and Bilmes (2008; 2009) have proposed a soft-clustering method using GBSSL and have shown that their own method is better than the other main clustering methods of those days. Subramanya et al. (2010) have also applied their method to solve the problem of tagging and have shown that it is useful. Dipanjan and Petrov (2011) have applied a graph-based label propagation method to solve the problem of part-ofspeech tagging. They have s</context>
</contexts>
<marker>Whitney, Sarkar, 2012</marker>
<rawString>Max Whitney and Anoop Sarkar. 2012. Bootstrapping via Graph Propagation. The 50th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>