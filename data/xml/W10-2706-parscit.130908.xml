<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025718">
<title confidence="0.984758">
An Embodied Dialogue System with Personality and Emotions
</title>
<author confidence="0.910904">
Stasinos Konstantopoulos
</author>
<affiliation confidence="0.817496">
NCSR ‘Demokritos’, Athens, Greece
</affiliation>
<email confidence="0.983424">
konstant@iit.demokritos.gr
</email>
<sectionHeader confidence="0.993548" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997625">
An enduring challenge in human-
computer interaction (HCI) research is the
creation of natural and intuitive interfaces.
Besides the obvious requirement that such
interfaces communicate over modalities
such as natural language (especially spo-
ken) and gesturing that are more natural
for humans, exhibiting affect and adaptiv-
ity have also been identified as important
factors to the interface’s acceptance by the
user. In the work presented here, we pro-
pose a novel architecture for affective and
multimodal dialogue systems that allows
explicit control over the personality traits
that we want the system to exhibit. More
specifically, we approach personality as
a means of synthesising different, and
possibly conflicting, adaptivity models
into an overall model to be used to drive
the interaction components of the system.
Furthermore, this synthesis is performed
in the presence of domain knowledge,
so that domain structure and relations
influence the results of the calculation.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999883452830189">
An enduring challenge in human-computer inter-
action (HCI) research is the creation of natural
and intuitive interfaces. Besides the obvious re-
quirement that such interfaces communicate over
modalities such as natural language (especially
spoken) and gesturing that are more natural for
humans, exhibiting affect and adaptivity have also
been identified as important factors to the inter-
face’s acceptance by the user.
We perceive HCI systems as ensembles of inter-
action modules, each controlling a different inter-
action modality, and able to modulate their opera-
tion depending on external (to the modules them-
selves) parameters. A central cognitive module
deliberates about dialogue acts and orchestrates
the interaction modules in order to ensure that
such dialogue acts are carried out in a coherent
way, keeping uttered content and affect consistent
within and across interaction modules.
In this paper we describe work towards this end,
carried out in the context of the INDIGO project,
and implemented in the form of a personality mod-
ule that complements INDIGO’s dialogue man-
ager by calculating parameters related to adap-
tivity and emotion to be used by the interaction
modules in the process of concretely realizing the
abstract dialogue-action directives issued by the
dialogue manager. This calculation involves the
planned act, the user adaptivity model, the sys-
tem’s own goals, but also a machine representa-
tion of the personality that we want the system to
exhibit, so that systems with different personality
will react differently even when in the same dia-
logue state and with the same user or user type.
This is motivated by the fact that, although
personality is a characteristically human quality,
it has been demonstrated that human users at-
tribute a personality to the computer interfaces
they use, regardless of whether one has been ex-
plicitly encoded in the system’s design (Nass et al.,
1995). Furthermore, personality complementarity
and similarity are important factors for the accep-
tance of an interface by a user (Moon and Nass,
1996; Nass and Lee, 2000), so that there is no ‘op-
timal’ or ‘perfect’ system personality, but rather
the need to tune system personality to best fit its
users.
In the rest of this paper, we will briefly discuss
literature on both adaptivity and personality mod-
elling (Section 2), proceed to present the interac-
tion between multimodal dialogue strategies and
our personality model (Section 3), and finally con-
clude (Section 4).
</bodyText>
<page confidence="0.99905">
31
</page>
<note confidence="0.829126">
Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 31–36,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.968961" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999946375">
INDIGO in general and our work in particular
is, to a large extend, based on work on adaptive
natural-language interfaces to databases. The do-
mains of application of these systems have var-
ied from generating personalized encyclopedia en-
tries and museum exhibit descriptions, to support-
ing the authoring of technical manuals and on-line
store catalogues.
</bodyText>
<subsectionHeader confidence="0.984514">
2.1 Adaptive HCI
</subsectionHeader>
<bodyText confidence="0.999986384615385">
The ILEX system was a major milestone in adap-
tive natural language generation (NLG), empha-
sising the separation between domain and linguis-
tic resources permitting the portability of linguis-
tic resources between domains. ILEX also intro-
duced the notion of a system agenda that rep-
resents the system’s own communicative goals,
a significant step in the direction of represent-
ing system personality. These system preferences
were combined with user preferences and a dy-
namic assimilation score (calculated from interac-
tion history) to estimate a single preference factor
for the various facts in the database for the pur-
poses of selecting the content that is to be included
in the description of each object ( O´ Donnell et al.,
2001).
ILEX, however, offered no theory about where
interest and importance come from or how to com-
bine them; arbitrary values had to be provided
for all objects in the database and the combined
preference was derived by multiplying the three
factors (importance, interest, and assimilation) re-
gardless of how each object is related to other in-
teresting or important objects in the collection or
what other relevant and semantically similar ob-
jects have been assimilated.
Building upon ILEX, the M-PIRO system ex-
tended user model preferences to influence surface
realization besides content selection, so that dif-
ferent surface forms would be generated to realize
the same abstract piece of information for differ-
ent users (Isard et al., 2003). This was achieved
by explicitly representing the grammar fragments
that could be used to realize different types of facts
(properties of the object being described) and then
extending the user interests mechanism to also se-
lect which grammar fragment is more ‘interesting’
(or, rather, appropriate) to realize a particular piece
of information for a particular user model.
By comparison to ILEX, M-PIRO offered greater
flexibility and linguistic variation, as well as lan-
guage portability by allowing the combination of
different grammars with the same domain or user
models. On the other hand, the, even rudimen-
tary, ability to combine user and system prefer-
ences was dropped and user model authoring be-
came practically unmanageable due the size and
complexity of user models.
With the emergence of the Semantic Web, it
became obvious that representation technologies
such as RDF and OWL offered an opportunity
to reduce the authoring effort by operating upon
pre-existing OWL ontologies. This motivated the
development of the NATURALOWL/ELEON sys-
tem. NATURALOWL is a template-based NLG
engine, explicitly designed for generating natu-
ral language descriptions of ontological entities,
based on such entities’ abstract properties (Gala-
nis and Androutsopoulos, 2007). The ELEON au-
thoring tool (Konstantopoulos et al., 2009) can be
used to annotate OWL ontologies with linguistic
and content-selection resources and inter-operates
with NATURALOWL which can use such anno-
tations to generate descriptions of ontological ob-
jects.
</bodyText>
<subsectionHeader confidence="0.993648">
2.2 Emotions and personality
</subsectionHeader>
<bodyText confidence="0.999969041666667">
Another relevant line of research is centred around
affective interaction and intelligent virtual agents.
The main focus here is the modelling and mim-
icking of the various affective markers that people
use when they communicate, aiming at more nat-
ural and seamless human-computer interaction.
Such affective systems are modulated by per-
sonality representations varying from fully-blown
cognitive architectures (Vankov et al., 2008) to rel-
atively simpler personality models. The OCEAN
or Big Five model, in particular, a standard frame-
work in psychology (Norman, 1963; Costa and
McCrae, 1992), is used to represent personality in
a variety of virtual agents and avatars capable for
multi-modal communication acts such as speech
and facial expressions (Strauss and Kipp, 2008;
Kasap et al., 2009). Such systems are typically
rich in visual expression, but lack sophistication
in natural language generation, knowledge repre-
sentation and dialogue structure.
The PERSONAGE and INDIGO systems, on the
other hand, move in the area between these sys-
tems and the database-access systems discussed
above: PERSONAGE develops a comprehensive
</bodyText>
<page confidence="0.997976">
32
</page>
<figureCaption confidence="0.998306">
Figure 1: An INDIGO robot interacting with Hel-
</figureCaption>
<equation confidence="0.779361333333333">
&apos;)*%.&apos;..&apos;%B%&amp;quot;3%#:7%)%
theory of using OCEAN parameters to control
,-/0-()&apos;%1
to syntax, pragmatics, and planning, but is re-
05 &amp;quot;# BCDBE9 2&amp;0%12# (. &apos;:2&amp;06&apos;-G # 5,-%&apos;0()&apos;%1
&amp;quot; 5&apos;&amp; )# &amp;&apos;)
</equation>
<bodyText confidence="0.954505166666667">
stricted to text generation and no other com-
munication modalities are covered (Mairesse and
U;
Walker, 2007). The INDIGO dialogue system em-
phasises multi-modality as it is embodied in a
robot capable of multi-modal interaction. INDIGO
uses OCEAN to combine a separate user model
and system profile into a single parameter set used
to parametrize a number of interaction compo-
nents, such as a virtual avatar capable of display-
ing emotions, the NLG engine, the text-to-speech
engine, the dialogue manager, etc.
</bodyText>
<sectionHeader confidence="0.901001" genericHeader="method">
3 A dialogue system with personality
</sectionHeader>
<bodyText confidence="0.999622111111111">
The INDIGO system has been fielded at the Hel-
lenic Cosmos cultural centre,1 where it provides
personalized tours with historical, architectural,
and cultural information about the buildings of the
Ancient Agora of Athens (Figure 1).
The dialogue manager (DM, Matheson et al.,
2009), implemented using TrindiKit,2 assumes the
information-state and update approach to dialogue
management (Traum and Larsson, 2003). The
information state stores information such as dia-
logue history and current robot position. Input
from the sensors (ASR, vision, laser tracker, and
touchscreen) is processed by update rules which
heuristically fuse multimodal (and possibly con-
tradicting) sensory input and implement generic
(i.e., domain and personality-independent) dia-
logue strategies. These strategies deliberate about
the next action that the robot will take, such as
</bodyText>
<footnote confidence="0.995414">
1See also http://www.hellenic-cosmos.gr
2See http://sourceforge.net/projects/
trindikit/
</footnote>
<bodyText confidence="0.9997005">
moving to a different section of the exhibition, of-
fering a menu of choices, or describing an item.
One notable strategy implemented in the DM is
the Move On Related strategy (Bohus and Rud-
nicky, 2008), the system’s fallback when user in-
put cannot be confidently recognized even after
fusing all input modalities. In such situations, DM
uses the combined preference factors to choose the
most preferred exhibit within the ontological class
that is the current focus of the discourse. If there
tance in this class with a clear preference,
umes this as the user response; if, on the
d, there is no instance with significantly
higher preference than the rest, DM prompts the
user to repeat their answer or use the touchscreen.
ther notable, and widely used, strategy is
that drives the two loops shown in Fig-
ure 2, in response to a user request for content:
one pertaining to dynamically realizing a person-
alized description of an object of the domain on-
tology and one pertaining to updating the system’s
emotion and mood.
</bodyText>
<subsectionHeader confidence="0.999939">
3.1 Content selection and realization loop
</subsectionHeader>
<bodyText confidence="0.999916703703704">
Once the DM has resolved that the next robot ac-
tion will be the description of a domain ontology
object, the personality-driven preferences are used
to select which properties of this object will be in-
cluded in the description. These preferences are
calculated taking into account a combined user-
system preference (Konstantopoulos et al., 2008)
as well as a dynamic assimilation score, calcu-
lated from interaction history, which balances be-
tween the gratuitous and tiring repetition of high-
preference material and simply rotating through
the list of properties of an object.
The chosen content is then used by the NAT-
URALOWL NLG engine (Galanis and Androut-
sopoulos, 2007) to plan and realize a personalized
textual description of the object. Besides selecting
what to include in a description, preference is used
by NATURALOWL to annotate the generated text
with directives, such as emphasis, for the text-to-
speech effector that drives the robot’s speakers.
The combined user-system preference stems
from associating domain objects with content-
selection parameters, using an representation de-
veloped for NATURALOWL and extended in IN-
DIGO to provide for representing not only user
models but also system profiles that establish the
system’s own goals and preferences (Konstan-
</bodyText>
<figure confidence="0.977157977777778">
lenic0Cosmos personnel#during preliminary trials,/)is2an0ins
September 2009. DM ass &apos;%
other han
% &apos;* #6&apos;.#-%
natural language interaction from lexical choice
# %&amp;&apos;()* I#&amp;# 6#&amp;1 *,/#**5,)+ .#:0-*&amp;(%&apos;-G ( /)#(&amp; (.6(-/#:#-% *2#/%
The %0o
I(*
the one
)&amp;#(.1
33
Emotion
Engine
Laser Tracker
Touchscreen
Sensors
Vision
Appraisal
Mood
ASR
Appraisal
Module
User facial gesture
User input
Dialogue
Manager
Content
Personality
Module
Chosen item
Content
Realized
Description
Effectors
Navigation
Text−to−Speech
Display
Robot head
NLG
Robot
Model
Ontology
Domain
Model
User
</figure>
<figureCaption confidence="0.9427515">
Figure 2: Overall architecture of the dialogue system.
topoulos et al., 2009).
</figureCaption>
<bodyText confidence="0.999799533333334">
Emotional and, in general, behavioural varia-
tion among different instantiations of the system is
achieved through synthetic personality models that
assert different points of balance between the (po-
tentially) conflicting user and system preferences.
What is of particular importance is that the the
combined user-system preference is not estimated
in isolation for each and every ontological object
as was the case in ILEX, but by axiomatizing how
preference is ‘transferred’ between domain objects
based on their semantic relations. This is achieved
by defining personality in terms of logic clauses
that link the preferences of an object not only to
its user and system preferences, but also to those
of objects it semantically relates with.
</bodyText>
<subsectionHeader confidence="0.99997">
3.2 Emotional appraisal and update loop
</subsectionHeader>
<bodyText confidence="0.987696051282051">
The system emotionally appraises user actions as
well as its own actions. With respect to its own
actions, the preference factors for the properties
selected to describe an object reflect the robot’s
being excited or bored to discuss the current sub-
ject.
Appraisal of user actions stems from vision and
speech analysis to reflect the impact of the manner
of what the user said. More specifically, facial ges-
ture recognition is used to detect emotional signs
(such as smiling) besides detecting affirmative and
negative nods and similar signs that are fused with
the results of speech recognition.
As user utterances are mostly short and incom-
plete answers to questions such as ‘Would you like
to hear more about this monument?’ or ‘Which
monument would you like me to talk about?’ we
cannot detect emotion based on linguistic mean-
ing or syntactic structure, but rather concentrate on
extracting useful prosodic and linguistic features
such the length of the last syllable in an utterance
or whether the first word of the utterance is an wh-
word.3 Although these features are not by them-
selves indicative of emotion, they are indicative
of prosody and their combination with segmental
features (referring to the acoustic form) extracted
directly from the speech signal was shown to im-
prove emotion estimation.
Emotional appraisal is used by an emotion sim-
ulator (Kasap et al., 2009) that uses the system’s
personality traits (OCEAN vector) to model how
dialogue acts affect the system’s emotional state.
This emotion simulator updates the system’s in-
ternal short-term emotional state and long-term
mood by applying an update function on the cur-
rent state and the emotional appraisal of each dia-
logue act. The OCEAN parameters act as param-
eters of the update function, so that, for example,
3Where, what, who, etc.
</bodyText>
<page confidence="0.997933">
34
</page>
<bodyText confidence="0.999921777777778">
neuroticism (i.e., ‘tendency to distress’) makes the
update function tend towards negative emotions,
whereas agreeableness (i.e., ‘sympathetic’) makes
it more directly reflect the user’s emotions.
The speech synthesiser and the robot’s anima-
tronic head reflect emotional state as voice mod-
ulations and facial expressions, whereas mood is
taken into account by the DM when deliberating
about the robot’s next dialogue action.
</bodyText>
<sectionHeader confidence="0.997046" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.998516105263158">
In this paper we have approached personality as a
means of synthesising different, and possibly con-
flicting, adaptivity models into an overall model to
be used to drive the interaction components of the
system. Furthermore, this synthesis is performed
in the presence of domain knowledge, so that do-
main structure and relations influence the results
of the calculation.
We thusly explore the self vs. other aspect of
personality modelling, theoretically interesting but
also practically important as we cleanly separate
adaptivity and profiling data that refers the system
from that which refers to the user. This follows up
on the tradition of the line of systems stemming
from ILEX, where increasingly separable models
(domain vs. NLG resources, the latter later broken
down between linguistic and adaptivity resources)
have allowed for such hard-to-create resources to
be re-used.
</bodyText>
<sectionHeader confidence="0.994948" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999511">
The work described in this paper was funded by
the FP6-IST project INDIGO, that developed and
advanced human-robot interaction technology, en-
abling robots to perceive natural human behaviour
and act in ways that are more familiar to humans.
To achieve its goals, INDIGO advanced various
technologies, which it integrated in a robotic plat-
form.
More details are availble from the project web-
site,http://www.ics.forth.gr/indigo
</bodyText>
<sectionHeader confidence="0.9974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.983644381818182">
Dan Bohus and Alex Rudnicky. 2008. Sorry, I
didn’t catch that. In Laila Dybkjær and Wolf-
gang Minker, editors, Recent Trends in Dis-
course and Dialogue, volume 39 of Text, Speech
and Language Technology, chapter 6, pages
123–154. Springer Netherlands.
P. T. Costa and R. R. McCrae. 1992. Normal
personality assessment in clinical practice: The
NEO personality inventory. Psychological As-
sessment, 4(5–13).
Dimitris Galanis and Ion Androutsopoulos. 2007.
Generating multilingual descriptions from lin-
guistically annotated OWL ontologies: the Nat-
uralOWL system. In Proceedings of the 11th
European Workshop on Natural Language Gen-
eration (ENLG 2007), Schloss Dagstuhl, Ger-
many, pages 143–146.
Amy Isard, Jon Oberlander, Ion Androutsopoulos,
and Colin Matheson. 2003. Speaking the users’
languages. IEEE Intelligent Systems, 18(1):40–
45.
Zerrin Kasap, Maher Ben Moussa, Parag Chaud-
huri, and Nadia Magnenat-Thalmann. 2009.
Making them remember: Emotional virtual
characters with memory. In Tiffany Barnes,
L. Miguel Encarnc¸˜ao, and Chris Shaw, editors,
Serious Games, Special Issue of IEEE Com-
puter Graphics and Applications. IEEE.
Stasinos Konstantopoulos, Vangelis Karkaletsis,
and Dimitris Bilidas. 2009. An intelligent au-
thoring environment for abstract semantic rep-
resentations of cultural object descriptions. In
Lars Borin and Piroska Lendvai, editors, Pro-
ceedings of EACL-09 Workshop on Language
Technology and Resources for Cultural Her-
itage, Social Sciences, Humanities, and Edu-
cation (LaTeCH-SHELT&amp;R 2009), Athens, 30
Mar 2009, pages 10–17.
Stasinos Konstantopoulos, Vangelis Karkaletsis,
and Colin Matheson. 2008. Robot personal-
ity: Representation and externalization. In Pro-
ceedings of ECAI-08 Workshop on Computa-
tional Aspects of Affective and Emotional In-
teraction (CAFFEi 2008), Patras, Greece, July
21st, 2008, pages 5–13.
Franc¸ois Mairesse and Marilyn Walker. 2007.
PERSONAGE: Personality generation for dia-
logue. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Lin-
guistics (ACL). Prague.
Colin Matheson, Amy Isard, Jon Oberlan-
der, Stasinos Konstantopoulos, and Vangelis
Karkaletsis. 2009. Multimodal human-robot di-
alogue management. INDIGO Deliverable 4.1
(public).
</reference>
<page confidence="0.983251">
35
</page>
<reference confidence="0.998629511111111">
Youngme Moon and Clifford Nass. 1996. Adap-
tive agents and personality change: comple-
mentarity versus similarity as forms of adap-
tation. In Proceedings SIGCHI Conference on
Human Factors in Computing Systems, Vancou-
ver, BC, Canada, 1996. SIG on Computer-
Human Interaction, ACM, New York, U.S.A.
Clifford Nass and Kwan Min Lee. 2000. Does
computer-generated speech manifest person-
ality? an experimental test of similarity-
attraction. In Proceedings SIGCHI Conference
on Human factors in Computing Systems, The
Hague, 2000. SIG on Computer-Human Inter-
action, ACM, New York, U.S.A.
Clifford Nass, Youngme Moon, B. Fogg, and
B. Reeves. 1995. Can computer personalities
be human personalities? International Journal
of Human-Computer Studies, 43:223–239.
W. T. Norman. 1963. Toward an adequate taxon-
omy of personality attributes: Replicated fac-
tor structure in peer nomination personality rat-
ing. Journal of Abnormal and Social Psychol-
ogy, 66:574–583.
Michael O´ Donnell, Chris Mellish, Jon Oberlan-
der, and A. Knott. 2001. ILEX: an architec-
ture for a dynamic hypertext generation system.
Natural Language Engineering, 7(3):225–250.
Martin Strauss and Michael Kipp. 2008. ERIC:
a generic rule-based framework for an affective
embodied commentary agent. In Proceedings
of the 7th international joint conference on Au-
tonomous agents and multiagent systems (AA-
MAS 08), Estoril, Portugal, 2008, pages 97–
104.
David Traum and Steffan Larsson. 2003. The in-
formation state approach to dialogue manage-
ment. In Jan van Kuppevelt and Ronnie Smith,
editors, Current and New Directions in Dis-
course and Dialogue. Kluwer Academic Pub-
lishers, Dordrecht, the Netherlands.
Ivan Vankov, Kiril Kiryazov, and Maurice Grin-
berg. 2008. Introducing emotions in an analogy-
making model. In Proceedings of 30th An-
nual Meeting of the Cognitive Science Society
(CogSci 2008), Washington D.C.
</reference>
<page confidence="0.998941">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.466167">
<title confidence="0.999231">An Embodied Dialogue System with Personality and Emotions</title>
<author confidence="0.623584">Stasinos Konstantopoulos</author>
<affiliation confidence="0.502041">NCSR ‘Demokritos’, Athens,</affiliation>
<email confidence="0.994984">konstant@iit.demokritos.gr</email>
<abstract confidence="0.99972672">An enduring challenge in humancomputer interaction (HCI) research is the creation of natural and intuitive interfaces. Besides the obvious requirement that such interfaces communicate over modalities such as natural language (especially spoken) and gesturing that are more natural for humans, exhibiting affect and adaptivity have also been identified as important factors to the interface’s acceptance by the user. In the work presented here, we propose a novel architecture for affective and multimodal dialogue systems that allows explicit control over the personality traits that we want the system to exhibit. More specifically, we approach personality as a means of synthesising different, and possibly conflicting, adaptivity models into an overall model to be used to drive the interaction components of the system. Furthermore, this synthesis is performed in the presence of domain knowledge, so that domain structure and relations influence the results of the calculation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Alex Rudnicky</author>
</authors>
<title>Sorry, I didn’t catch that.</title>
<date>2008</date>
<booktitle>In Laila Dybkjær and Wolfgang Minker, editors, Recent Trends in Discourse and Dialogue,</booktitle>
<volume>39</volume>
<pages>123--154</pages>
<publisher>Springer Netherlands.</publisher>
<contexts>
<context position="10268" citStr="Bohus and Rudnicky, 2008" startWordPosition="1565" endWordPosition="1569">he sensors (ASR, vision, laser tracker, and touchscreen) is processed by update rules which heuristically fuse multimodal (and possibly contradicting) sensory input and implement generic (i.e., domain and personality-independent) dialogue strategies. These strategies deliberate about the next action that the robot will take, such as 1See also http://www.hellenic-cosmos.gr 2See http://sourceforge.net/projects/ trindikit/ moving to a different section of the exhibition, offering a menu of choices, or describing an item. One notable strategy implemented in the DM is the Move On Related strategy (Bohus and Rudnicky, 2008), the system’s fallback when user input cannot be confidently recognized even after fusing all input modalities. In such situations, DM uses the combined preference factors to choose the most preferred exhibit within the ontological class that is the current focus of the discourse. If there tance in this class with a clear preference, umes this as the user response; if, on the d, there is no instance with significantly higher preference than the rest, DM prompts the user to repeat their answer or use the touchscreen. ther notable, and widely used, strategy is that drives the two loops shown in</context>
</contexts>
<marker>Bohus, Rudnicky, 2008</marker>
<rawString>Dan Bohus and Alex Rudnicky. 2008. Sorry, I didn’t catch that. In Laila Dybkjær and Wolfgang Minker, editors, Recent Trends in Discourse and Dialogue, volume 39 of Text, Speech and Language Technology, chapter 6, pages 123–154. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P T Costa</author>
<author>R R McCrae</author>
</authors>
<title>Normal personality assessment in clinical practice: The NEO personality inventory. Psychological Assessment,</title>
<date>1992</date>
<pages>4--5</pages>
<contexts>
<context position="7805" citStr="Costa and McCrae, 1992" startWordPosition="1197" endWordPosition="1200">s. 2.2 Emotions and personality Another relevant line of research is centred around affective interaction and intelligent virtual agents. The main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying from fully-blown cognitive architectures (Vankov et al., 2008) to relatively simpler personality models. The OCEAN or Big Five model, in particular, a standard framework in psychology (Norman, 1963; Costa and McCrae, 1992), is used to represent personality in a variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (Strauss and Kipp, 2008; Kasap et al., 2009). Such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure. The PERSONAGE and INDIGO systems, on the other hand, move in the area between these systems and the database-access systems discussed above: PERSONAGE develops a comprehensive 32 Figure 1: An INDIGO robot interacting with Hel&apos;)*%.&apos;..&apos;%B</context>
</contexts>
<marker>Costa, McCrae, 1992</marker>
<rawString>P. T. Costa and R. R. McCrae. 1992. Normal personality assessment in clinical practice: The NEO personality inventory. Psychological Assessment, 4(5–13).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitris Galanis</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Generating multilingual descriptions from linguistically annotated OWL ontologies: the NaturalOWL system.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th European Workshop on Natural Language Generation (ENLG 2007), Schloss Dagstuhl, Germany,</booktitle>
<pages>143--146</pages>
<contexts>
<context position="6925" citStr="Galanis and Androutsopoulos, 2007" startWordPosition="1066" endWordPosition="1070">mbine user and system preferences was dropped and user model authoring became practically unmanageable due the size and complexity of user models. With the emergence of the Semantic Web, it became obvious that representation technologies such as RDF and OWL offered an opportunity to reduce the authoring effort by operating upon pre-existing OWL ontologies. This motivated the development of the NATURALOWL/ELEON system. NATURALOWL is a template-based NLG engine, explicitly designed for generating natural language descriptions of ontological entities, based on such entities’ abstract properties (Galanis and Androutsopoulos, 2007). The ELEON authoring tool (Konstantopoulos et al., 2009) can be used to annotate OWL ontologies with linguistic and content-selection resources and inter-operates with NATURALOWL which can use such annotations to generate descriptions of ontological objects. 2.2 Emotions and personality Another relevant line of research is centred around affective interaction and intelligent virtual agents. The main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective sys</context>
<context position="11801" citStr="Galanis and Androutsopoulos, 2007" startWordPosition="1818" endWordPosition="1822">t robot action will be the description of a domain ontology object, the personality-driven preferences are used to select which properties of this object will be included in the description. These preferences are calculated taking into account a combined usersystem preference (Konstantopoulos et al., 2008) as well as a dynamic assimilation score, calculated from interaction history, which balances between the gratuitous and tiring repetition of highpreference material and simply rotating through the list of properties of an object. The chosen content is then used by the NATURALOWL NLG engine (Galanis and Androutsopoulos, 2007) to plan and realize a personalized textual description of the object. Besides selecting what to include in a description, preference is used by NATURALOWL to annotate the generated text with directives, such as emphasis, for the text-tospeech effector that drives the robot’s speakers. The combined user-system preference stems from associating domain objects with contentselection parameters, using an representation developed for NATURALOWL and extended in INDIGO to provide for representing not only user models but also system profiles that establish the system’s own goals and preferences (Kons</context>
</contexts>
<marker>Galanis, Androutsopoulos, 2007</marker>
<rawString>Dimitris Galanis and Ion Androutsopoulos. 2007. Generating multilingual descriptions from linguistically annotated OWL ontologies: the NaturalOWL system. In Proceedings of the 11th European Workshop on Natural Language Generation (ENLG 2007), Schloss Dagstuhl, Germany, pages 143–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Isard</author>
<author>Jon Oberlander</author>
<author>Ion Androutsopoulos</author>
<author>Colin Matheson</author>
</authors>
<title>Speaking the users’ languages.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>45</pages>
<contexts>
<context position="5658" citStr="Isard et al., 2003" startWordPosition="876" endWordPosition="879">es had to be provided for all objects in the database and the combined preference was derived by multiplying the three factors (importance, interest, and assimilation) regardless of how each object is related to other interesting or important objects in the collection or what other relevant and semantically similar objects have been assimilated. Building upon ILEX, the M-PIRO system extended user model preferences to influence surface realization besides content selection, so that different surface forms would be generated to realize the same abstract piece of information for different users (Isard et al., 2003). This was achieved by explicitly representing the grammar fragments that could be used to realize different types of facts (properties of the object being described) and then extending the user interests mechanism to also select which grammar fragment is more ‘interesting’ (or, rather, appropriate) to realize a particular piece of information for a particular user model. By comparison to ILEX, M-PIRO offered greater flexibility and linguistic variation, as well as language portability by allowing the combination of different grammars with the same domain or user models. On the other hand, the</context>
</contexts>
<marker>Isard, Oberlander, Androutsopoulos, Matheson, 2003</marker>
<rawString>Amy Isard, Jon Oberlander, Ion Androutsopoulos, and Colin Matheson. 2003. Speaking the users’ languages. IEEE Intelligent Systems, 18(1):40– 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zerrin Kasap</author>
<author>Maher Ben Moussa</author>
<author>Parag Chaudhuri</author>
<author>Nadia Magnenat-Thalmann</author>
</authors>
<title>Making them remember: Emotional virtual characters with memory.</title>
<date>2009</date>
<booktitle>Serious Games, Special Issue of IEEE Computer Graphics and Applications.</booktitle>
<editor>In Tiffany Barnes, L. Miguel Encarnc¸˜ao, and Chris Shaw, editors,</editor>
<publisher>IEEE.</publisher>
<contexts>
<context position="8008" citStr="Kasap et al., 2009" startWordPosition="1229" endWordPosition="1232">ective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying from fully-blown cognitive architectures (Vankov et al., 2008) to relatively simpler personality models. The OCEAN or Big Five model, in particular, a standard framework in psychology (Norman, 1963; Costa and McCrae, 1992), is used to represent personality in a variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (Strauss and Kipp, 2008; Kasap et al., 2009). Such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure. The PERSONAGE and INDIGO systems, on the other hand, move in the area between these systems and the database-access systems discussed above: PERSONAGE develops a comprehensive 32 Figure 1: An INDIGO robot interacting with Hel&apos;)*%.&apos;..&apos;%B%&amp;quot;3%#:7%)% theory of using OCEAN parameters to control ,-/0-()&apos;%1 to syntax, pragmatics, and planning, but is re05 &amp;quot;# BCDBE9 2&amp;0%12# (. &apos;:2&amp;06&apos;-G # 5,-%&apos;0()&apos;%1 &amp;quot; 5&apos;&amp; )# &amp;&apos;) stricted to text generation an</context>
<context position="15211" citStr="Kasap et al., 2009" startWordPosition="2345" endWordPosition="2348"> me to talk about?’ we cannot detect emotion based on linguistic meaning or syntactic structure, but rather concentrate on extracting useful prosodic and linguistic features such the length of the last syllable in an utterance or whether the first word of the utterance is an whword.3 Although these features are not by themselves indicative of emotion, they are indicative of prosody and their combination with segmental features (referring to the acoustic form) extracted directly from the speech signal was shown to improve emotion estimation. Emotional appraisal is used by an emotion simulator (Kasap et al., 2009) that uses the system’s personality traits (OCEAN vector) to model how dialogue acts affect the system’s emotional state. This emotion simulator updates the system’s internal short-term emotional state and long-term mood by applying an update function on the current state and the emotional appraisal of each dialogue act. The OCEAN parameters act as parameters of the update function, so that, for example, 3Where, what, who, etc. 34 neuroticism (i.e., ‘tendency to distress’) makes the update function tend towards negative emotions, whereas agreeableness (i.e., ‘sympathetic’) makes it more direct</context>
</contexts>
<marker>Kasap, Moussa, Chaudhuri, Magnenat-Thalmann, 2009</marker>
<rawString>Zerrin Kasap, Maher Ben Moussa, Parag Chaudhuri, and Nadia Magnenat-Thalmann. 2009. Making them remember: Emotional virtual characters with memory. In Tiffany Barnes, L. Miguel Encarnc¸˜ao, and Chris Shaw, editors, Serious Games, Special Issue of IEEE Computer Graphics and Applications. IEEE.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stasinos Konstantopoulos</author>
<author>Vangelis Karkaletsis</author>
<author>Dimitris Bilidas</author>
</authors>
<title>An intelligent authoring environment for abstract semantic representations of cultural object descriptions.</title>
<date>2009</date>
<booktitle>In Lars Borin and Piroska Lendvai, editors, Proceedings of EACL-09 Workshop on Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education (LaTeCH-SHELT&amp;R 2009), Athens, 30</booktitle>
<pages>10--17</pages>
<contexts>
<context position="6982" citStr="Konstantopoulos et al., 2009" startWordPosition="1076" endWordPosition="1079">uthoring became practically unmanageable due the size and complexity of user models. With the emergence of the Semantic Web, it became obvious that representation technologies such as RDF and OWL offered an opportunity to reduce the authoring effort by operating upon pre-existing OWL ontologies. This motivated the development of the NATURALOWL/ELEON system. NATURALOWL is a template-based NLG engine, explicitly designed for generating natural language descriptions of ontological entities, based on such entities’ abstract properties (Galanis and Androutsopoulos, 2007). The ELEON authoring tool (Konstantopoulos et al., 2009) can be used to annotate OWL ontologies with linguistic and content-selection resources and inter-operates with NATURALOWL which can use such annotations to generate descriptions of ontological objects. 2.2 Emotions and personality Another relevant line of research is centred around affective interaction and intelligent virtual agents. The main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying</context>
</contexts>
<marker>Konstantopoulos, Karkaletsis, Bilidas, 2009</marker>
<rawString>Stasinos Konstantopoulos, Vangelis Karkaletsis, and Dimitris Bilidas. 2009. An intelligent authoring environment for abstract semantic representations of cultural object descriptions. In Lars Borin and Piroska Lendvai, editors, Proceedings of EACL-09 Workshop on Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education (LaTeCH-SHELT&amp;R 2009), Athens, 30 Mar 2009, pages 10–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stasinos Konstantopoulos</author>
<author>Vangelis Karkaletsis</author>
<author>Colin Matheson</author>
</authors>
<title>Robot personality: Representation and externalization.</title>
<date>2008</date>
<booktitle>In Proceedings of ECAI-08 Workshop on Computational Aspects of Affective and Emotional Interaction (CAFFEi</booktitle>
<pages>5--13</pages>
<location>Patras, Greece,</location>
<contexts>
<context position="11474" citStr="Konstantopoulos et al., 2008" startWordPosition="1766" endWordPosition="1769"> the two loops shown in Figure 2, in response to a user request for content: one pertaining to dynamically realizing a personalized description of an object of the domain ontology and one pertaining to updating the system’s emotion and mood. 3.1 Content selection and realization loop Once the DM has resolved that the next robot action will be the description of a domain ontology object, the personality-driven preferences are used to select which properties of this object will be included in the description. These preferences are calculated taking into account a combined usersystem preference (Konstantopoulos et al., 2008) as well as a dynamic assimilation score, calculated from interaction history, which balances between the gratuitous and tiring repetition of highpreference material and simply rotating through the list of properties of an object. The chosen content is then used by the NATURALOWL NLG engine (Galanis and Androutsopoulos, 2007) to plan and realize a personalized textual description of the object. Besides selecting what to include in a description, preference is used by NATURALOWL to annotate the generated text with directives, such as emphasis, for the text-tospeech effector that drives the robo</context>
</contexts>
<marker>Konstantopoulos, Karkaletsis, Matheson, 2008</marker>
<rawString>Stasinos Konstantopoulos, Vangelis Karkaletsis, and Colin Matheson. 2008. Robot personality: Representation and externalization. In Proceedings of ECAI-08 Workshop on Computational Aspects of Affective and Emotional Interaction (CAFFEi 2008), Patras, Greece, July 21st, 2008, pages 5–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franc¸ois Mairesse</author>
<author>Marilyn Walker</author>
</authors>
<title>PERSONAGE: Personality generation for dialogue.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<publisher>Prague.</publisher>
<marker>Mairesse, Walker, 2007</marker>
<rawString>Franc¸ois Mairesse and Marilyn Walker. 2007. PERSONAGE: Personality generation for dialogue. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL). Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Matheson</author>
<author>Amy Isard</author>
<author>Jon Oberlander</author>
</authors>
<title>Stasinos Konstantopoulos, and Vangelis Karkaletsis.</title>
<date>2009</date>
<journal>INDIGO Deliverable</journal>
<volume>4</volume>
<pages>(public).</pages>
<contexts>
<context position="9405" citStr="Matheson et al., 2009" startWordPosition="1445" endWordPosition="1448">lti-modal interaction. INDIGO uses OCEAN to combine a separate user model and system profile into a single parameter set used to parametrize a number of interaction components, such as a virtual avatar capable of displaying emotions, the NLG engine, the text-to-speech engine, the dialogue manager, etc. 3 A dialogue system with personality The INDIGO system has been fielded at the Hellenic Cosmos cultural centre,1 where it provides personalized tours with historical, architectural, and cultural information about the buildings of the Ancient Agora of Athens (Figure 1). The dialogue manager (DM, Matheson et al., 2009), implemented using TrindiKit,2 assumes the information-state and update approach to dialogue management (Traum and Larsson, 2003). The information state stores information such as dialogue history and current robot position. Input from the sensors (ASR, vision, laser tracker, and touchscreen) is processed by update rules which heuristically fuse multimodal (and possibly contradicting) sensory input and implement generic (i.e., domain and personality-independent) dialogue strategies. These strategies deliberate about the next action that the robot will take, such as 1See also http://www.hellen</context>
</contexts>
<marker>Matheson, Isard, Oberlander, 2009</marker>
<rawString>Colin Matheson, Amy Isard, Jon Oberlander, Stasinos Konstantopoulos, and Vangelis Karkaletsis. 2009. Multimodal human-robot dialogue management. INDIGO Deliverable 4.1 (public).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngme Moon</author>
<author>Clifford Nass</author>
</authors>
<title>Adaptive agents and personality change: complementarity versus similarity as forms of adaptation.</title>
<date>1996</date>
<booktitle>In Proceedings SIGCHI Conference on Human Factors in Computing Systems,</booktitle>
<location>Vancouver, BC,</location>
<contexts>
<context position="3208" citStr="Moon and Nass, 1996" startWordPosition="485" endWordPosition="488">ty that we want the system to exhibit, so that systems with different personality will react differently even when in the same dialogue state and with the same user or user type. This is motivated by the fact that, although personality is a characteristically human quality, it has been demonstrated that human users attribute a personality to the computer interfaces they use, regardless of whether one has been explicitly encoded in the system’s design (Nass et al., 1995). Furthermore, personality complementarity and similarity are important factors for the acceptance of an interface by a user (Moon and Nass, 1996; Nass and Lee, 2000), so that there is no ‘optimal’ or ‘perfect’ system personality, but rather the need to tune system personality to best fit its users. In the rest of this paper, we will briefly discuss literature on both adaptivity and personality modelling (Section 2), proceed to present the interaction between multimodal dialogue strategies and our personality model (Section 3), and finally conclude (Section 4). 31 Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 31–36, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics 2 B</context>
</contexts>
<marker>Moon, Nass, 1996</marker>
<rawString>Youngme Moon and Clifford Nass. 1996. Adaptive agents and personality change: complementarity versus similarity as forms of adaptation. In Proceedings SIGCHI Conference on Human Factors in Computing Systems, Vancouver, BC, Canada, 1996. SIG on ComputerHuman Interaction, ACM, New York, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifford Nass</author>
<author>Kwan Min Lee</author>
</authors>
<title>Does computer-generated speech manifest personality? an experimental test of similarityattraction.</title>
<date>2000</date>
<booktitle>In Proceedings SIGCHI Conference on Human factors in Computing Systems, The Hague, 2000. SIG on Computer-Human Interaction, ACM,</booktitle>
<location>New York, U.S.A.</location>
<contexts>
<context position="3229" citStr="Nass and Lee, 2000" startWordPosition="489" endWordPosition="492">ystem to exhibit, so that systems with different personality will react differently even when in the same dialogue state and with the same user or user type. This is motivated by the fact that, although personality is a characteristically human quality, it has been demonstrated that human users attribute a personality to the computer interfaces they use, regardless of whether one has been explicitly encoded in the system’s design (Nass et al., 1995). Furthermore, personality complementarity and similarity are important factors for the acceptance of an interface by a user (Moon and Nass, 1996; Nass and Lee, 2000), so that there is no ‘optimal’ or ‘perfect’ system personality, but rather the need to tune system personality to best fit its users. In the rest of this paper, we will briefly discuss literature on both adaptivity and personality modelling (Section 2), proceed to present the interaction between multimodal dialogue strategies and our personality model (Section 3), and finally conclude (Section 4). 31 Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 31–36, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics 2 Background INDIGO in g</context>
</contexts>
<marker>Nass, Lee, 2000</marker>
<rawString>Clifford Nass and Kwan Min Lee. 2000. Does computer-generated speech manifest personality? an experimental test of similarityattraction. In Proceedings SIGCHI Conference on Human factors in Computing Systems, The Hague, 2000. SIG on Computer-Human Interaction, ACM, New York, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifford Nass</author>
<author>Youngme Moon</author>
<author>B Fogg</author>
<author>B Reeves</author>
</authors>
<title>Can computer personalities be human personalities?</title>
<date>1995</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>43--223</pages>
<contexts>
<context position="3063" citStr="Nass et al., 1995" startWordPosition="463" endWordPosition="466">This calculation involves the planned act, the user adaptivity model, the system’s own goals, but also a machine representation of the personality that we want the system to exhibit, so that systems with different personality will react differently even when in the same dialogue state and with the same user or user type. This is motivated by the fact that, although personality is a characteristically human quality, it has been demonstrated that human users attribute a personality to the computer interfaces they use, regardless of whether one has been explicitly encoded in the system’s design (Nass et al., 1995). Furthermore, personality complementarity and similarity are important factors for the acceptance of an interface by a user (Moon and Nass, 1996; Nass and Lee, 2000), so that there is no ‘optimal’ or ‘perfect’ system personality, but rather the need to tune system personality to best fit its users. In the rest of this paper, we will briefly discuss literature on both adaptivity and personality modelling (Section 2), proceed to present the interaction between multimodal dialogue strategies and our personality model (Section 3), and finally conclude (Section 4). 31 Proceedings of the 2010 Works</context>
</contexts>
<marker>Nass, Moon, Fogg, Reeves, 1995</marker>
<rawString>Clifford Nass, Youngme Moon, B. Fogg, and B. Reeves. 1995. Can computer personalities be human personalities? International Journal of Human-Computer Studies, 43:223–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W T Norman</author>
</authors>
<title>Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating.</title>
<date>1963</date>
<journal>Journal of Abnormal and Social Psychology,</journal>
<pages>66--574</pages>
<contexts>
<context position="7780" citStr="Norman, 1963" startWordPosition="1195" endWordPosition="1196">logical objects. 2.2 Emotions and personality Another relevant line of research is centred around affective interaction and intelligent virtual agents. The main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying from fully-blown cognitive architectures (Vankov et al., 2008) to relatively simpler personality models. The OCEAN or Big Five model, in particular, a standard framework in psychology (Norman, 1963; Costa and McCrae, 1992), is used to represent personality in a variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (Strauss and Kipp, 2008; Kasap et al., 2009). Such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure. The PERSONAGE and INDIGO systems, on the other hand, move in the area between these systems and the database-access systems discussed above: PERSONAGE develops a comprehensive 32 Figure 1: An INDIGO robot intera</context>
</contexts>
<marker>Norman, 1963</marker>
<rawString>W. T. Norman. 1963. Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating. Journal of Abnormal and Social Psychology, 66:574–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael O´ Donnell</author>
<author>Chris Mellish</author>
<author>Jon Oberlander</author>
<author>A Knott</author>
</authors>
<title>ILEX: an architecture for a dynamic hypertext generation system.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="4920" citStr="Donnell et al., 2001" startWordPosition="758" endWordPosition="761">n between domain and linguistic resources permitting the portability of linguistic resources between domains. ILEX also introduced the notion of a system agenda that represents the system’s own communicative goals, a significant step in the direction of representing system personality. These system preferences were combined with user preferences and a dynamic assimilation score (calculated from interaction history) to estimate a single preference factor for the various facts in the database for the purposes of selecting the content that is to be included in the description of each object ( O´ Donnell et al., 2001). ILEX, however, offered no theory about where interest and importance come from or how to combine them; arbitrary values had to be provided for all objects in the database and the combined preference was derived by multiplying the three factors (importance, interest, and assimilation) regardless of how each object is related to other interesting or important objects in the collection or what other relevant and semantically similar objects have been assimilated. Building upon ILEX, the M-PIRO system extended user model preferences to influence surface realization besides content selection, so </context>
</contexts>
<marker>Donnell, Mellish, Oberlander, Knott, 2001</marker>
<rawString>Michael O´ Donnell, Chris Mellish, Jon Oberlander, and A. Knott. 2001. ILEX: an architecture for a dynamic hypertext generation system. Natural Language Engineering, 7(3):225–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Strauss</author>
<author>Michael Kipp</author>
</authors>
<title>ERIC: a generic rule-based framework for an affective embodied commentary agent.</title>
<date>2008</date>
<booktitle>In Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems (AAMAS 08),</booktitle>
<pages>97--104</pages>
<location>Estoril,</location>
<contexts>
<context position="7987" citStr="Strauss and Kipp, 2008" startWordPosition="1225" endWordPosition="1228">cking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying from fully-blown cognitive architectures (Vankov et al., 2008) to relatively simpler personality models. The OCEAN or Big Five model, in particular, a standard framework in psychology (Norman, 1963; Costa and McCrae, 1992), is used to represent personality in a variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (Strauss and Kipp, 2008; Kasap et al., 2009). Such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure. The PERSONAGE and INDIGO systems, on the other hand, move in the area between these systems and the database-access systems discussed above: PERSONAGE develops a comprehensive 32 Figure 1: An INDIGO robot interacting with Hel&apos;)*%.&apos;..&apos;%B%&amp;quot;3%#:7%)% theory of using OCEAN parameters to control ,-/0-()&apos;%1 to syntax, pragmatics, and planning, but is re05 &amp;quot;# BCDBE9 2&amp;0%12# (. &apos;:2&amp;06&apos;-G # 5,-%&apos;0()&apos;%1 &amp;quot; 5&apos;&amp; )# &amp;&apos;) stricted </context>
</contexts>
<marker>Strauss, Kipp, 2008</marker>
<rawString>Martin Strauss and Michael Kipp. 2008. ERIC: a generic rule-based framework for an affective embodied commentary agent. In Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems (AAMAS 08), Estoril, Portugal, 2008, pages 97– 104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Steffan Larsson</author>
</authors>
<title>The information state approach to dialogue management.</title>
<date>2003</date>
<booktitle>Current and New Directions in Discourse and Dialogue.</booktitle>
<editor>In Jan van Kuppevelt and Ronnie Smith, editors,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, the Netherlands.</location>
<contexts>
<context position="9535" citStr="Traum and Larsson, 2003" startWordPosition="1461" endWordPosition="1464"> parametrize a number of interaction components, such as a virtual avatar capable of displaying emotions, the NLG engine, the text-to-speech engine, the dialogue manager, etc. 3 A dialogue system with personality The INDIGO system has been fielded at the Hellenic Cosmos cultural centre,1 where it provides personalized tours with historical, architectural, and cultural information about the buildings of the Ancient Agora of Athens (Figure 1). The dialogue manager (DM, Matheson et al., 2009), implemented using TrindiKit,2 assumes the information-state and update approach to dialogue management (Traum and Larsson, 2003). The information state stores information such as dialogue history and current robot position. Input from the sensors (ASR, vision, laser tracker, and touchscreen) is processed by update rules which heuristically fuse multimodal (and possibly contradicting) sensory input and implement generic (i.e., domain and personality-independent) dialogue strategies. These strategies deliberate about the next action that the robot will take, such as 1See also http://www.hellenic-cosmos.gr 2See http://sourceforge.net/projects/ trindikit/ moving to a different section of the exhibition, offering a menu of </context>
</contexts>
<marker>Traum, Larsson, 2003</marker>
<rawString>David Traum and Steffan Larsson. 2003. The information state approach to dialogue management. In Jan van Kuppevelt and Ronnie Smith, editors, Current and New Directions in Discourse and Dialogue. Kluwer Academic Publishers, Dordrecht, the Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vankov</author>
<author>Kiril Kiryazov</author>
<author>Maurice Grinberg</author>
</authors>
<title>Introducing emotions in an analogymaking model.</title>
<date>2008</date>
<booktitle>In Proceedings of 30th Annual Meeting of the Cognitive Science Society (CogSci</booktitle>
<location>Washington D.C.</location>
<contexts>
<context position="7645" citStr="Vankov et al., 2008" startWordPosition="1171" endWordPosition="1174">h linguistic and content-selection resources and inter-operates with NATURALOWL which can use such annotations to generate descriptions of ontological objects. 2.2 Emotions and personality Another relevant line of research is centred around affective interaction and intelligent virtual agents. The main focus here is the modelling and mimicking of the various affective markers that people use when they communicate, aiming at more natural and seamless human-computer interaction. Such affective systems are modulated by personality representations varying from fully-blown cognitive architectures (Vankov et al., 2008) to relatively simpler personality models. The OCEAN or Big Five model, in particular, a standard framework in psychology (Norman, 1963; Costa and McCrae, 1992), is used to represent personality in a variety of virtual agents and avatars capable for multi-modal communication acts such as speech and facial expressions (Strauss and Kipp, 2008; Kasap et al., 2009). Such systems are typically rich in visual expression, but lack sophistication in natural language generation, knowledge representation and dialogue structure. The PERSONAGE and INDIGO systems, on the other hand, move in the area betwee</context>
</contexts>
<marker>Vankov, Kiryazov, Grinberg, 2008</marker>
<rawString>Ivan Vankov, Kiril Kiryazov, and Maurice Grinberg. 2008. Introducing emotions in an analogymaking model. In Proceedings of 30th Annual Meeting of the Cognitive Science Society (CogSci 2008), Washington D.C.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>