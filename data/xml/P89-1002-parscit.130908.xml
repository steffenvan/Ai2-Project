<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9986835">
A Semantic-Head-Driven Generation Algorithm
for Unification-Based Formalisms
</title>
<author confidence="0.7477615">
Stuart M. Shieber,* Gertjan van Noord,t Robert C. Moore,*
and Fernando C. N. Pereira*
</author>
<affiliation confidence="0.640859">
*Artificial Intelligence Center
</affiliation>
<address confidence="0.4290795">
SRI International
Menlo Park, CA 94025, USA
</address>
<sectionHeader confidence="0.849439" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999945545454546">
We present an algorithm for generating strings
from logical form encodings that improves upon
previous algorithms in that it places fewer restric-
tions on the class of grammars to which it is ap-
plicable. In particular, unlike an Earley deduction
generator (Shieber, 1988), it allows use of seman-
tically nonmonotonic grammars, yet unlike top-
down methods, it also permits left-recursion. The
enabling design feature of the algorithm is its im-
plicit traversal of the analysis tree for the string
being generated in a semantic-head-driven fashion.
</bodyText>
<sectionHeader confidence="0.995507" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999837923076923">
The problem of generating a well-formed natural-
language expression from an encoding of its mean-
ing possesses certain properties which distinguish
it from the converse problem of recovering a mean-
ing encoding from a given natural-language ex-
pression. In previous work (Shieber, 1988), how-
ever, one of us attempted to characterize these
differing properties in such a way that a sin-
gle uniform architecture, appropriately parame-
terized, might be used for both natural-language
processes. In particular, we developed an archi-
tecture inspired by the Earley deduction work of
Pereira and Warren (1983) but which generalized
that work allowing for its use in both a parsing
and generation mode merely by setting the values
of a small number of parameters.
As a method for generating natural-language
expressions, the Earley deduction method is rea-
sonably successful along certain dimensions. It
is quite simple, general in its applicability to a
range of unification-based and logic grammar for-
malisms, and uniform, in that it places only one
restriction (discussed below) on the form of the lin-
guistic analyses allowed by the grammars used in
generation. In particular, generation from gram-
mars with recursions whose well-foundedness relies
</bodyText>
<affiliation confidence="0.476967666666667">
tDepartment of Linguistics
Rijksuniversiteit Utrecht
Utrecht, Netherlands
</affiliation>
<bodyText confidence="0.981740897435897">
on lexical information will terminate; top-down
generation regimes such as those of Wedekind
(1988) or Dymetman and Isabelle (1988) lack this
property, discussed further in Section 3.1.
Unfortunately, the bottom-up, left-to-right pro-
cessing regime of Earley generation—as it might
be called—has its own inherent frailties. Efficiency
considerations require that only grammars pos-
sessing a property of semantic monotonicity can
be effectively used, and even for those grammars,
processing can become overly nondeterministic.
The algorithm described in this paper is an at-
tempt to resolve these problems in a satisfactory
manner. Although we believe that this algorithm
could be seen as an instance of a uniform archi-
tecture for parsing and generation—just as the
extended Earley parser (Shieber, 1985b) and the
bottom-up generator were instances of the general-
ized Earley deduction architecture—our efforts to
date have been aimed foremost toward the devel-
opment of the algorithm for generation alone. We
will have little to say about its relation to parsing,
leaving such questions for later research.&apos;
2 Applicability of the Algo-
rithm
As does the Earley-based generator, the new algo-
rithm assumes that the grammar is a unification-
based or logic grammar with a phrase-structure
backbone and complex nonterminals. Further-
more, and again consistent with previous work,
we assume that the nonterminals associate to the
phrases they describe logical expressions encoding
their possible meanings. We will describe the al-
gorithm in terms of an implementation of it for
definite-clause grammars (DCG), although we be-
I Martin Kay (personal communication) has developed
a parsing algorithm that seems to be the parsing correlate
to the generation algorithm presented here. Its existence
might point the way towards a uniform architecture.
</bodyText>
<page confidence="0.998887">
7
</page>
<bodyText confidence="0.999727882352941">
lieve the underlying method to be more broadly
applicable.
A variant of our method is used in Van No-
ord&apos;s BUG (Bottom-Up Generator) system, part
of MiMo2, an experimental machine translation
system for translating international news items of
Teletext, which uses a Prolog version of PATR-II
similar to that of Hirsh (1987). According to Mar-
tin Kay (personal communication), the STREP
machine translation project at the Center for the
Study of Language and Information uses a ver-
sion of our algorithm to generate with respect to
grammars based on head-driven phrase-structure
grammar (HPSG). Finally, Calder et al. (1989)
report on a generation algorithm for unification
categorial grammar that appears to be a special
case of ours.
</bodyText>
<sectionHeader confidence="0.9945005" genericHeader="introduction">
3 Problems Yvitll Existing
Generators
</sectionHeader>
<bodyText confidence="0.9991998">
Existing generation algorithms have efficiency or
termination problems with respect to certain
classes of grammars. We review the problems of
both top-down and bottom-up regimes in this sec-
tion.
</bodyText>
<subsectionHeader confidence="0.9623805">
3.1 Problems with Top-Down Gen-
erators
</subsectionHeader>
<bodyText confidence="0.981182081632653">
Consider a naive top-down generation mechanism
that takes as input the semantics to generate from
and a corresponding syntactic category and builds
a complete tree, top-down, left-to-right by apply-
ing rules of the grammar nondeterministically to
the fringe of the expanding tree. This control
regime is realized, for instance, when running a
DCG &amp;quot;backwards&amp;quot; as a generator.
Clearly, such a generator may not terminate.
For example, consider a grammar that includes
the rule
s/S --&gt; np/NP, vp(NP)/S.
(The intention is that verb phrases like, say,
&amp;quot;loves Mary&amp;quot; be associated with a nonterminal
vp(X)/love(X, nary).) Once this rule is ap-
plied to the goal s/love(john, mary), the sub-
goal np/NP will be considered. But the generation
search space for that goal is infinite and so has
infinite branches, because all noun phrases, and
thus arbitrarily large ones, match the goal. This
is an instance of the general problem known from
logic programming that a logic program may not
terminate when called with a goal less instanti-
ated than what was intended by the program&apos;s
designer. Dymetman and Isabelle (1988), not-
ing this problem, propose allowing the grammar-
writer to specify a separate goal ordering for pars-
ing and for generation. For the case at hand,
the solution is to generate the VP first—from the
goal vp(NP)/loves(john, mary)—in the course
of which the variable NP will become bound so
that the generation from np/NP will terminate.
Wedekind (1988) achieves this goal by expanding
first nodes that are connected, that is, whose se-
mantics is instantiated. Since the NP is not con-
nected in this sense, but the VP is, the latter will
be expanded first. In essence, the technique is a
kind of goal freezing (Colmerauer, 1982) or im-
plicit wail declaration (Naish, 1986). For cases in
which the a priori ordering of goals is insufficient,
Dymetman and Isabelle also introduce goal freez-
ing to control expansion.
Although vastly superior to the naive top-down
algorithm, even this sort of amended top-down ap-
proach to generation based on goal freezing under
one guise or another fails to terminate with cer-
tain linguistically plausible analyses. For example,
the &amp;quot;complements&amp;quot; rule given by Shieber (1985a,
pages 77-78) in the PATR-II formalism
</bodyText>
<equation confidence="0.9964745">
VP&apos; VP2 X
(VPi head) = (VP2 head)
(VP2 syncat first) = (X)
(VP2 syncat rest) = (VPi syncat)
</equation>
<bodyText confidence="0.855626">
can be encoded as the DCG-style rule:
</bodyText>
<sectionHeader confidence="0.605403" genericHeader="method">
vp(Head, Syncat) --&gt;
</sectionHeader>
<subsectionHeader confidence="0.795306">
vp(Head, [CompllSyncat]), Compl.
</subsectionHeader>
<bodyText confidence="0.9934494375">
Top-down generation using this rule will be forced
to expand the lower VP before its complement,
since Compl is uninstantiated initially. But appli-
cation of the rule can recur indefinitely, leading to
nontermination.
The problem arises because there is no limit to
the size of the subcategorization list. Although
one might propose an ad hoc upper bound for lexi-
cal entries, even this expedient may be insufficient.
In analyses of Dutch cross-serial verb construc-
tions (Evers, 1975; Huybrechts, 1984), subcate-
gorization lists such as these may be appended by
syntactic rules (Moortgat, 1984; Steedman, 1985;
Pollard, 1988), resulting in indefinitely long lists.
Consider the Dutch sentence
dat [Jan [Marie [de oppasser [de olifanten
</bodyText>
<page confidence="0.995421">
8
</page>
<bodyText confidence="0.851387428571429">
that John Mary the keeper the elephants
(zag helpen voeren]]]]
saw help feed
that John saw Mary help the keeper feed the
elephants
The string of verbs is analysed by appending their
subcategorization lists as follows:
</bodyText>
<equation confidence="0.942263833333333">
V [e,k,m,j]
V [m,j] V [e,k,m]
zag y rk,m] V [e,k]
saw
helpen voeren
help feed
</equation>
<bodyText confidence="0.999748090909091">
Subcategorization lists under this analysis can
have any length, and it is impossible to predict
from a semantic structure the size of its corre-
sponding subcategorization list merely by exam-
ining the lexicon.
In summary, top-down generation algorithms,
even if controlled by the instantiation status of
goals, can fail to terminate on certain grammars.
In the case given above the well-foundedness of the
generation process resides in lexical information
unavailable to top-down regimes.
</bodyText>
<subsectionHeader confidence="0.9973355">
3.2 Problems with Bottom-Up
Generators
</subsectionHeader>
<bodyText confidence="0.999969317073171">
The bottom-up Earley-deduction generator does
not fall prey to these problems of nontermination
in the face of recursion, because lexical informa-
tion is available immediately. However, several im-
portant frailties of the Earley generation method
were noted, even in the earlier work.
For efficiency, generation using this Earley de-
duction method requires an incomplete search
strategy, filtering the search space using seman-
tic information. The semantic filter makes gen-
eration from a logical form computationally feasi-
ble, but preserves completeness of the generation
process only in the case of semantically monotonic
grammars — those grammars in which the seman-
tic component of each right-hand-side nonterminal
subsumes some portion of the semantic component
of the left-hand-side. The semantic monotonicity
constraint itself is quite restrictive. Although it is
intuitively plausible that the semantic content of
subconstituents ought to play a role in the seman-
tics of their combination—this is just a kind of
compositionality claim—there are certain cases in
which reasonable linguistic analyses might violate
this intuition. In general, these cases arise when a
particular lexical item is stipulated to occur, the
stipulation being either lexical (as in the case of
particles or idioms) or grammatical (as in the case
of expletive expressions).
Second, the left-to-right scheduling of Earley
parsing, geared as it is toward the structure
of the string rather than that of its meaning,
is inherently more appropriate for parsing than
generation.2 This manifests itself in an overly high
degree of nondeterminism in the generation pro-
cess. For instance, various nondeterministic pos-
sibilities for generating a noun phrase (using dif-
ferent cases, say) might be entertained merely be-
cause the NP occurs before the verb which would
more fully specify, and therefore limit, the options.
This nondeterminism has been observed in prac-
tice.
</bodyText>
<subsectionHeader confidence="0.998681">
3.3 Source of the Problems
</subsectionHeader>
<bodyText confidence="0.904701566666667">
We can think of a parsing or generation process
as discovering an analysis tree,3 one admitted by
the grammar and satisfying certain syntactic or se-
mantic conditions, by traversing a virtual tree and
constructing the actual tree during the traversal.
The conditions to be satisfied—possessing a given
yield in the parsing case, or having a root node la-
beled with given semantic information in the case
of generation—reflect the different premises of the
two types of problem.
From this point of view, a naive top-down parser
or generator performs a depth-first, left-to-right
traversal of the tree. Completion steps in Earley&apos;s
algorithm, whether used for parsing or generation,
correspond to a post-order traversal (with predic-
tion acting as a pre-order filter). The left-to-right
traversal order of both of these methods is geared
towards the given information in a parsing prob-
lem, the string, rather than that of a generation
problem, the goal logical form. It is exactly this
mismatch between structure of the traversal and
2Pereira and Warren (1983) point out that Earley de-
duction is not restricted to a left-to-right expansion of
goals, but this suggestion was not followed up with a spe-
cific algorithm addressing the problems discussed here.
3We use the term &amp;quot;analysis tree&amp;quot; rather than the more
familiar &amp;quot;parse tree&amp;quot; to make clear that the source of the
tree is not necessarily a parsing process; rather the tree
serves only to codify a particular analysis of the structure
of the string.
</bodyText>
<page confidence="0.99151">
9
</page>
<bodyText confidence="0.9999823">
structure of the problem premise that accounts for
the profligacy of these approaches when used for
generation.
Thus for generation, we want a traversal order
geared to the premise of the generation problem,
that is, to the semantic structure of the sentence.
The new algorithm is designed to reflect such a
traversal strategy respecting the semantic struc-
ture of the string being generated, rather than the
string itself.
</bodyText>
<sectionHeader confidence="0.984026" genericHeader="method">
4 The New Algorithm
</sectionHeader>
<bodyText confidence="0.989399702702703">
Given an analysis tree for a sentence, we define
the pivot node as the lowest node in the tree such
that it and all higher nodes up to the root have the
same semantics. Intuitively speaking, the pivot
serves as the semantic head of the root node. Our
traversal will proceed both top-down and bottom-
up from the pivot, a sort of semantic-head-driven
traversal of the tree. The choice of this traversal
allows a great reduction in the search for rules used
to build the analysis tree.
To be able to identify possible pivots, we dis-
tinguish a subset of the rules of the grammar,
the chain rules, in which the semantics of some
right-hand-side element is identical to the seman-
tics of the left-hand side. The right-hand-side ele-
ment will be called the rule&apos;s semantic head.4 The
traversal, then, will work top-down from the pivot
using a nonchain rule, for if a chain rule were used,
the pivot would not be the lowest node sharing
semantics with the root. Instead, the pivot&apos;s se-
mantic head would be. After the nonchain rule
4 In case there are two right-hand-side elements that are
semantically identical to the left-hand side, there is some
freedom in choosing the semantic head, although the choice
is not without ramifications. For instance, in some analyses
of NP structure, a rule such as
np/NP --&gt; det/NP , nbar/NP .
is postulated. In general, a chain rule is used bottom-up
from its semantic head and top-down on the non-semantic-
head siblings. Thus, if a non-semantic-head subconstituent
has the same semantics as the left-hand-side, a recursive
top-down generation with the same semantics will be in-
voked. In theory, this can lead to nontermination, unless
syntactic factors eliminate the recursion, as they would in
the rule above regardless of which element is chosen as se-
mantic head. In a rule for relative clause introduction such
as the following (in highly abbreviated form)
</bodyText>
<equation confidence="0.790334">
nbar/N --&gt; nbar/N, sbar/N.
</equation>
<bodyText confidence="0.989057909090909">
we can (and must) choose the nominal as semantic head
to effect termination. However, there are other problem-
atic cases, such as verb-movement analyses of verb-second
languages, whose detailed discussion is beyond the scope of
this paper.
is chosen, each of its children must be generated
recursively.
The bottom-up steps to connect the pivot to the
root of the analysis tree can be restricted to chain
rules only, as the pivot (along with all interme-
diate nodes) has the same semantics as the root
and must therefore be the semantic head. Again,
after a chain rule is chosen to move up one node
in the tree being constructed, the remaining (non-
semantic-head) children must be generated recur-
sively.
The top-down base case occurs when the non-
chain rule has no nonterminal children, i.e., it
introduces lexical material only. The bottom-up
base case occurs when the pivot and root are triv-
ially connected because they are one and the same
node.
</bodyText>
<subsectionHeader confidence="0.973282">
4.1 A DCG Implementation
</subsectionHeader>
<bodyText confidence="0.996105761904762">
To make the description more explicit, we will de-
velop a Prolog implementation of the algorithm for
DCGs, along the way introducing some niceties of
the algorithm previously glossed over.
In the implementation, a term of the form
node (Cat , PO, P) represents a phrase with the
syntactic and semantic information given by Cat
starting at position PO and ending at position P in
the string being generated. As usual for DCGs, a
string position is represented by the list of string
elements after the position. The generation pro-
cess starts with a goal category and attempts to
generate an appropriate node, in the process in-
stantiating the generated string.
gen(Cat , String) : -
generate (node (Cat , String , 0 ) ) .
To generate from a node, we nondeterministi-
cally choose a nonchain rule whose left-hand side
will serve as the pivot. For each right-hand-side el-
ement, we recursively generate, and then connect
the pivot to the root.
</bodyText>
<listItem confidence="0.2053805">
generate (Root) : -
% choose nonchain rule
applicable_non_chain_rule (Root,
Pivot, RHS),
% generate all subconstituents
generate_rhs(RHS) ,
% generate material on path to root
connect (Pivot , Root) .
</listItem>
<bodyText confidence="0.871298">
The processing within generate_rhs is a simple
iteration.
generate_rhs(0).
</bodyText>
<page confidence="0.967233">
10
</page>
<bodyText confidence="0.906895928571428">
generate_rhs([First 1 Rest]) :-
generate (First)
generate_rhs(Rest).
The connection of a pivot to the root, as noted
before, requires choice of a chain rule whose
semantic head matches the pivot, and the re-
cursive generation of the remaining right-hand-
side. We assume a predicate applicable_chain_
rule(SemHead, LHS, Root, RHS) that holds if
there is a chain rule admitting a node LHS as the
left-hand-side, SemHead as its semantic head, and
RHS as the remaining right-hand-side nodes, such
that the left-hand-side node and the root node
Root can themselves be connected.
</bodyText>
<equation confidence="0.48133225">
connect(Pivot, Root) :-
5 choose chain rule
applicable_chain_rule(Pivot, LHS,
Root, RHS),
</equation>
<bodyText confidence="0.934800804347826">
% generate remaining siblings
generate_rhs(RHS),
% connect the new parent to the root
connect(LHS, Root).
The base case occurs when the root and the
pivot are the same. Identity checks like this one
must be implemented correctly in the generator
by using a sound unification algorithm with the
occurs check. (The default unification in most
Prolog systems is unsound in this respect.) For
example, a grammar with a gap-threading treat-
ment of wh-movement (Pereira, 1981; Pereira and
Shieber, 1985) might include the rule
np(Agr, [np(Agr)/Seml X)-X)/Sem ---&gt; .
stating that an NP with agreement Agr and se-
mantics Sem can be empty provided that the list of
gaps in the NP can be represented as the difference
list [rip(Agr)/Sem I X] -X, that is the list contain-
ing an NP gap with the same agreement features
Agr (Pereira and Shieber, 1985, p. 128). Because
the above rule is a nonchain rule, it will be consid-
ered when trying to generate any nongap NP, such
as the proper noun np(3-sing,G-G)/john. The
base case of connect will try to unify that term
with the head of the rule above, leading to the at-
tempted unification of X with [rip (Agr) /Sem I X] ,
an occurs-check failure. The base case, incorpo-
rating the explicit call to a sound unification algo-
rithm is thus as follows:
connect(Pivot, Root) :-
% trivially connect pivot to root
unify(Pivot, Root).
Now, we need only define the notion of an ap-
plicable chain or nonchain rule. A nonchain rule
is applicable if the semantics of the left-hand-side
of the rule (which is to become the pivot) matches
that of the root. Further, we require a top-down
check that syntactically the pivot can serve as the
semantic head of the root. For this purpose, we
assume a predicate chained_nodes that codifies
the transitive closure of the semantic head rela-
tion over categories. This is the correlate of the
link relation used in left-corner parsers with top-
down filtering; we direct the reader to the discus-
sion by Matsumoto et al. (1983) or Pereira and
Shieber (1985, p. 182) for further information.
</bodyText>
<equation confidence="0.8786345">
applicable_non_chain_rule(Root, Pivot,
RHS) :-
</equation>
<listItem confidence="0.895737">
% semantics of root and pivot are same
node_semantics(Root, Sem),
node_semantics(Pivot, Sem),
% choose a nonchain rule
non_chain_rule (US RHS) ,
% ...whose lhs matches the pivot
unify(Pivot, LHS),
% make sure the categories can connect
chained_nodes(Pivot, Root).
</listItem>
<bodyText confidence="0.9996325">
A chain rule is applicable to connect a pivot to a
root if the pivot can serve as the semantic head
of the rule and the left-hand-side of the rule is
appropriate for linking to the root.
</bodyText>
<table confidence="0.6593485">
applicable_chain_rule(Pivot, Parent,
Root, RHS) :-
% choose a chain rule
chain_rule(Parent, RHS, SemHead),
</table>
<tableCaption confidence="0.170006">
... whose sem. head matches pivot
unify(Pivot, SemHead),
</tableCaption>
<bodyText confidence="0.950447588235294">
% make sure the categories can connect
chained_nodes(Parent, Root).
The information needed to guide the generation
(given as the predicates chain_rule, non_chain_-
rule, and chained_nodes) can be computed au-
tomatically from the grammar; a program to com-
pile a DCG into these tables has in fact been im-
plemented. The details of the process will not be
discussed further. The careful reader will have no-
ticed, however, that no attention has been given
to the issue of terminal symbols on the right-hand
sides of rules. During the compilation process, the
right-hand side of a rule is converted from a list of
categories and terminal strings to a list of nodes
connected together by the difference-list threading
technique used for standard DCG compilation. At
that point, terminal strings can be introduced into
</bodyText>
<page confidence="0.963056">
11
</page>
<equation confidence="0.989274125">
sentence/decl(S) ---&gt; s(finite)/S. (1)
sentence/imp(S) ---&gt; vp(nonfinite,[np(_)/you])/S.
s(Form)/S ---&gt; Subj, vp(Form,[Subj])/S. (2)
vp(Form,Subcat)/S ---&gt; vp(Form,[ComplISubcat])/S, Compl. (3)
vp(Form,[Subj])/S ---&gt; vp(Form,[Subj])/VP, adv(VP)/S.
vp(finite,[np(_)/0,np(3-sing)/S])/love(S,O) ---&gt; [loves].
vp(finite,[np(_)/0,p/up,np(3-sing)/S])/call_up(S,O) ---&gt; [calls]. (4)
vp(f inite, [np (3-sing) /S] ) /leave (S) ---&gt; [leaves] .
np(3-sing)/john ---&gt; [john]. (5)
np ( 3-pl ) /f riends ---&gt; [f ri ends] . (6)
adv(VP)/often(VP) ---&gt; [often].
det(3-sing,X,P)/qterm(every,X,P) ---&gt; [every].
n(3-sing,X)/friend(X) ---&gt; [friend].
n(3-pl,X)/friend(X) ---&gt; [friends].
p/up ---&gt; [up]. (7)
p/on ---&gt; [on].
</equation>
<figureCaption confidence="0.997366">
Figure 1: Grammar Fragment
</figureCaption>
<bodyText confidence="0.9559395">
the string threading and need never be considered
further.
</bodyText>
<subsectionHeader confidence="0.998853">
4.2 An Example
</subsectionHeader>
<bodyText confidence="0.99988925">
We turn now to a simple example to give a sense
of the order of processing pursued by this genera-
tion algorithm. The grammar fragment in Figure
1 uses an infix operator / to separate syntactic and
semantic category information. Subcategorization
for complements is performed lexically.
Consider the generation from the category
sentence/decl(call_up(john,friends)). The
analysis tree that we will be implicitly traversing
in the course of generation is given in Figure 2.
The rule numbers are keyed to the grammar. The
pivots chosen during generation and the branches
corresponding to the semantic head relation are
shown in boldface.
We begin by attempting to find a nonchain rule
that will define the pivot. This is a rule whose
left-hand-side semantics matches the root seman-
tics decl(call_up(john,friends)) (although its
syntax may differ). In fact, the only such nonchain
rule is
</bodyText>
<equation confidence="0.843682">
sentence/decl(S) ---&gt; s(finite)/S. (1)
</equation>
<bodyText confidence="0.99745025">
We conjecture that the pivot is labeled
sentence/decl(call_up( j ohn, friends) ) In
terms of the tree traversal, we are implicitly choos-
ing the root node [a] as the pivot. We recursively
generate from the child&apos;s node [b], whose category
is s(finite)/can_up(john,friends). For this
category, the pivot (which will turn out to be node
[f]) will be defined by the nonchain rule
</bodyText>
<equation confidence="0.9697455">
vp(finite,[np(J/0, (4)
p/up,
np(3-sing)/S])
/call_up(S,O) ---&gt; [calls].
</equation>
<bodyText confidence="0.999962666666667">
(If there were other forms of the verb, these would
be potential candidates, but would be eliminated
by the chained_nodes check, as the semantic head
relation requires identity of the verb form of a sen-
tence and its VP head.) Again, we recursively gen-
erate for all the nonterminal elements of the right-
hand side of this rule, of which there are none.
We must therefore connect the pivot [f] to
the root [b]. A chain rule whose semantic head
</bodyText>
<page confidence="0.977821">
12
</page>
<figure confidence="0.9995443">
[a] sentence
/decl(call_up(john,friends))
1(1)
[b] s (finite)
/can_up(j ohn , friends)
(2)
[c] np(3-sing) [d] vp(finite,[np(3-sing)/john])
/john /call_up(john,friends)
1 (5) (3) p/up [h]
John [(] vp(finite,[p/up,np(3-sing)/john]) 1(7)
/call_up(john,friends) up
[f] vp(finite,[np(3-p1)/friends,
p/up,np(3-sing)/johnj)
/call_up(john,friends)
(4)
calls
np(3-pl) [g]
/friends
1(6)
friends
</figure>
<figureCaption confidence="0.999545">
Figure 2: Analysis Tree Traversal
</figureCaption>
<bodyText confidence="0.7478605">
matches the pivot must be chosen. The only choice rule
is the rule
</bodyText>
<equation confidence="0.742822">
vp(Form,Subcat)/S ---&gt; (3)
vp(Form,[ComplISubcat])/S, Compl.
</equation>
<bodyText confidence="0.951588384615385">
Unifying in the pivot, we find that we must re-
cursively generate the remaining RHS element
np(_)/fr iends, and then connect the left-hand
side node [e] with category
vp(finite, [lex/up,
np(3-sing)/john])
/call_up(john,friends)
to the same root [b]. The recursive generation
yields a node covering the string &amp;quot;friends&amp;quot; follow-
ing the previously generated string &amp;quot;calls&amp;quot;. The
recursive connection will use the same chain rule,
generating the particle &amp;quot;up&amp;quot;, and the new node
to be connected [d]. This node requires the chain
</bodyText>
<equation confidence="0.4861465">
s(Form)/S ---&gt; (2)
Subj, vp(Form,(Subj))/S.
</equation>
<bodyText confidence="0.9999273125">
for connection. Again, the recursive generation for
the subject yields the string &amp;quot;John&amp;quot;, and the new
node to be connected s(inite)/call_up(john,
friends). This last node connects to the root [b]
by virtue of identity.
This completes the process of generating
top-down from the original pivot sentence/
decl(call_up(john,friends)). All that re-
mains is to connect this pivot to the original root.
Again, the process is trivial, by virtue of the base
case for connection. The generation process is thus
completed, yielding the string &amp;quot;John calls friends
up&amp;quot;. The drawing summarizes the generation pro-
cess by showing which steps were performed top-
down or bottom-up by arrows on the analysis tree
branches.
</bodyText>
<page confidence="0.997862">
13
</page>
<bodyText confidence="0.999959625">
The grammar presented here was perforce triv-
ial, for expository reasons. We have developed
more extensive experimental grammars that can
generate relative clauses with gaps and sentences
with quantified NPs from quantified logical forms
by using a version of Cooper storage (Cooper,
1983). We give an outline of our treatment of
quantification in Section 6.2.
</bodyText>
<sectionHeader confidence="0.960747" genericHeader="method">
5 Important Properties of
</sectionHeader>
<subsectionHeader confidence="0.790201">
the Algorithm
</subsectionHeader>
<bodyText confidence="0.99909984">
Several properties of the algorithm are exhibited
by the preceding example example.
First, the order of processing is not left-to-right.
The verb was generated before any of its comple-
ments. Because of this, the semantic information
about the particle &amp;quot;up&amp;quot; was available, even though
this information appears nowhere in the goal se-
mantics. That is, the generator operated appropri-
ately despite a semantically nonmonotonic gram-
mar.
In addition, full information about the subject,
including agreement information was available be-
fore it was generated. Thus the nondeterminism
that is an artifact of left-to-right processing, and
a source of inefficiency in the Earley generator, is
eliminated. Indeed, the example here was com-
pletely deterministic; all rule choices were forced.
Finally, even though much of the processing is
top-down, left-recursive rules (e.g., rule (3)) are
still handled in a constrained manner by the algo-
rithm.
For these reasons, we feel that the semantic-
head-driven algorithm is a significant improve-
ment over top-down methods and the previous
bottom-up method based on Earley deduction.
</bodyText>
<sectionHeader confidence="0.992324" genericHeader="method">
6 Extensions
</sectionHeader>
<bodyText confidence="0.999594666666667">
We will now outline how the algorithm and the
grammar it uses can be extended to encompass
some important analyses and constraints.
</bodyText>
<subsectionHeader confidence="0.998096">
6.1 Completeness and Coherence
</subsectionHeader>
<bodyText confidence="0.988411883333333">
Wedekind (1988) defines completeness and coher-
ence of a generation algorithm as follows. Suppose
a generator derives a string w from a logical form
s, and the grammar assigns to w the logical form
a. The generator is complete ifs always subsumes
a and coherent if a always subsumes s. The gen-
erator defined in Section 4.1 is not coherent or
complete in this sense; it requires only that a and
s be compatible, that is, unifiable.
If the logical-form language and semantic in-
terpretation system provide a sound treatment of
variable binding and scope, abstraction and appli-
cation, completeness and coherence will be irrele-
vant because the logical form of any phrase will not
contain free variables. However, neither semantic
projections in lexical-functional grammar ( LFG)
(Halvorsen and Kaplan, 1988) nor definite-clause
grammars provide the means for such a sound
treatment: logical-form variables or missing argu-
ments of predicates are both encoded as unbound
variables (attributes with unspecified values in the
LFG semantic projection) at the description level.
Then completeness and coherence become impor-
tant. For example, suppose a grammar associated
the following strings and logical forms.
eat(john, X)
&apos;John ate&apos;
eat(john, banana)
&apos;John ate a banana&apos;
eat(john, nice(yellov(banana)))
&apos;John ate a nice yellow banana&apos;
The generator of Section 4.1 would generate any
of these sentences for the logical form eat(john,
X) (because of its incoherence) and would generate
&apos;John ate&apos; for the logical form eat (john, banana)
(because of its incompleteness).
Coherence can be achieved by removing the con-
fusion between object-level and metalevel vari-
ables mentioned above, that is, by treating logical-
form variables as constants at the description level.
In practice, this can be achieved by replacing each
variable in the semantics from which we are gen-
erating by a new distinct constant (for instance
with the numbervars predicate built into some im-
plementations of Prolog). These new constants
will not unify with any augmentations to the se-
mantics. A suitable modification of our generator
would be
gen(Cat, String) :-
cat_semantics(Cat,Sem),
numbervars(Sen,0,_),
generate(node(Cat,String,0)).
This leaves us with the completeness problem.
This problem arises when there are phrases whose
semantics are not ground at the description level,
but instead subsume the goal logical form or gener-
ation. For instance, in our hypothetical example,
the string &apos;John eats&apos; will be generated for seman-
tics eat(john, banana). The solution is to test
at the end of the generation procedure whether the
</bodyText>
<page confidence="0.997762">
14
</page>
<bodyText confidence="0.999984357142857">
feature structure that is found is complete with re-
spect to the original feature structure. However,
because of the way in which top-down information
is used, it is unclear what semantic information is
derived by the rules themselves, and what seman-
tic information is available because of unifications
with the original semantics. For this reason, so-
called &amp;quot;shadow&amp;quot; variables are added to the gener-
ator that represent the feature structure derived
by the grammar itself. Furthermore a copy of the
semantics of the original feature structure is made
at the start of the generation process. Complete-
ness is achieved by testing whether the semantics
of the shadow is subsumed by the copy.
</bodyText>
<subsectionHeader confidence="0.996172">
6.2 Quantifier Storage
</subsectionHeader>
<bodyText confidence="0.996072185185185">
We will outline here how to generate from a quan-
tified logical form sentences with quantified NPs
one of whose readings is the original logical form,
that is, how to do quantifier-lowering automati-
cally. For this, we will associate a quantifier store
with certain categories and add to the grammar
suitable store-manipulation rules.
Each category whose constituents may create
store elements will have a store feature. Further-
more, for each such category whose semantics can
be the scope of a quantifier, there will be an op-
tional nonchain rule to take the top element of an
ordered store and apply it to the semantics of the
category. For example, here is the rule for sen-
tences:
s(Form, GO-G, Store)/quant(Q,X,R,S) ---&gt;
s(Form, GO-G, [qterm(Q,X,R)IStore])/S.
The term quant (Q,X,R,S) represents a quantified
formula with quantifier Q, bound variable X, re-
striction R and scope S, and qterm(Q,X,R) is the
corresponding store element.
In addition, some mechanism is needed to com-
bine the stores of the immediate constituents of a
phrase into a store for the phrase. For example,
the combination of subject and complement stores
for a verb into a clause store is done in one of our
test grammars by lexical rules such as
</bodyText>
<reference confidence="0.2522585">
vp(finite, [np(_. SO)/0,
np(3-sing, SS)/S], SC)
/love(S,O) ---&gt;
[loves], {shuffle(SS, SO, SC)}.
</reference>
<bodyText confidence="0.98610775">
which states that the store SC of a clause with
main verb &apos;love&apos; and the stores SS and SO of the
subject and object the verb subcategorizes for sat-
isfy the constraint shuffle(SS, SO, SC), mean-
ing that Sc is an interleaving of elements of SS and
SO in their original order. 5
Finally, it is necessary to deal with the noun
phrases that create store elements. Ignoring the
issue of how to treat quantifiers from within com-
plex noun phrases, we need lexical rules for deter-
miners, of the form
det(3-sing,X,P,[qterm(every,X,P)])/X ---&gt;
[every].
stating that the semantics of a quantified NP is
simply the variable bound by the store element
arising from the NP. For rules of this form to work
properly, it is essential that distinct bound logical-
form variables be represented as distinct constants
in the terms encoding the logical forms. This is an
instance of the problem of coherence discussed in
the previous section.
The rules outlined here are less efficient than
necessary because the distribution of store ele-
ments among the subject and complements of a
verb does not check whether the variable bound
by a store element actually appears in the seman-
tics of the phrase to which it is being assigned,
leading to many dead ends in the generation pro-
cess. Also, the rules are sound for generation but
not for analysis, because they do not enforce the
constraint that every occurrence of a variable in
logical form be outscoped by the variable&apos;s binder.
Adding appropriate side conditions to the rules,
following the constraints discussed by Hobbs and
Shieber (Hobbs and Shieber, 1987) would not be
difficult.
</bodyText>
<subsectionHeader confidence="0.999288">
6.3 Postponing Lexical Choice
</subsectionHeader>
<bodyText confidence="0.9995649375">
As it stands, the generation algorithm chooses par-
ticular lexical forms on-line. This approach can
lead to a certain amount of unnecessary nonde-
terminism. For instance, the choice of verb form
might depend on syntactic features of the verb&apos;s
subject available only after the subject has been
generated. This nondeterminism can be elimi-
nated by deferring lexical choice to a postprocess.
The generator will yield a list of lexical items in-
stead of a list of words. To this list a small phono-
logical front end is applied. BUG uses such a
mechanism to eliminate much of the uninterest-
ing nondeterminism in choice of word forms. Of
course, the same mechanism could be added to any
of the other generation techniques discussed to in
this paper.
</bodyText>
<footnote confidence="0.983181">
5Further details of the use of shuffle in scoping are
given by Pereira and Shieber (1985).
</footnote>
<page confidence="0.997477">
15
</page>
<sectionHeader confidence="0.987324" genericHeader="method">
7 Further Research
</sectionHeader>
<bodyText confidence="0.9999656875">
Further enhancements to the algorithm are envi-
sioned. First, any system making use of a tabular
link predicate over complex nonterminals (like the
chained_nodes predicate used by the generation
algorithm and including the link predicate used
in the BUP parser (Matsumoto et al., 1983)) is
subject to a problem of spurious redundancy in
processing if the elements in the link table are
not mutually exclusive. For instance, a single
chain rule might be considered to be applicable
twice because of the nondeterminism of the call
to chained_nodes. This general problem has to
date received little attention, and no satisfactory
solution is found in the logic grammar literature.
More generally, the backtracking regimen of our
implementation of the algorithm may lead to re-
computation of results. Again, this is a general
property of backtrack methods and is not partic-
ular to our application. The use of dynamic pro-
gramming techniques, as in chart parsing, would
be an appropriate augmentation to the implemen-
tation of the algorithm. Happily, such an augmen-
tation would serve to eliminate the redundancy
caused by the linking relation as well.
Finally, in order to incorporate a general facility
for auxiliary conditions in rules, some sort of de-
layed evaluation triggered by appropriate instanti-
ation (e.g., wait declarations (Naish, 1986)) would
be desirable. None of these changes, however, con-
stitutes restructuring of the algorithm; rather they
modify its realization in significant and important
ways.
</bodyText>
<sectionHeader confidence="0.998436" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999539416666667">
Shieber, Moore, and Pereira were supported in
this work by a contract with the Nippon Tele-
phone and Telegraph Corp. and by a gift from
the Systems Development Foundation as part of
a coordinated research effort with the Center for
the Study of Language and Information, Stanford
University; van Noord was supported by the Euro-
pean Community and the Nederlands Bureau voor
Bib liotheekwezen en Informatieverzorgin through
the Eurotra project. We would like to thank Mary
Dalrymple and Louis des Tombe for their helpful
discussions regarding this work.
</bodyText>
<sectionHeader confidence="0.95511" genericHeader="references">
Bibliography
</sectionHeader>
<reference confidence="0.999911370370371">
Jonathan Calder, Mike Reape, and Hank Zeevat.
1989. An algorithm for generation in unification
categorial grammar. In Proceedings of the .4th
Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages
233-240, Manchester, England (10-12 April).
University of Manchester Institute of Science
and Technology.
Alain Colmerauer. 1982. PROLOG II: Manuel
de reference et modele theorique. Technical re-
port, Groupe d&apos;Intelligence Artificielle, Faculte
des Sciences de Luminy, Marseille, France.
Robin Cooper. 1983. Quantification and Syntac-
tic Theory, Volume 21 of Synthese Language Li-
brary. D. Reidel, Dordrecht, Netherlands.
Marc Dymetman and Pierre Isabelle. 1988. Re-
versible logic grammars for machine transla-
tion. In Proceedings of the Second International
Conference on Theoretical and Methodologi-
cal Issues in Machine Translation of Natural
Languages, Pittsburgh, Pennsylvania. Carnegie-
Mellon University.
Arnold Evers. 1975. The transformational cycle
in German and Dutch. Ph.D. thesis, University
of Utrecht, Utrecht, Netherlands.
Per-Kristian Halvorsen and Ronald M. Kaplan.
1988. Projections and semantic description
in lexical-functional grammar. In Proceedings
of the International Conference on Fifth Gen-
eration Computer Systems, pages 1116-1122,
Tokyo, Japan. Institute for New Generation
Computer Technology.
Susan Hirsh. 1987. P-PATR, a compiler for uni-
fication based grammars. In Veronica Dahl and
Patrick Saint-Dizier, editors, Natural Language
Understanding and Logic Programming, II. El-
sevier Science Publishers.
Jerry R. Hobbs and Stuart M. Shieber. 1987.
An algorithm for generating quantifier scopings.
Computational Linguistics, 13:47-63.
Riny A.C. Huybrechts. 1984.. The weak inad-
equacy of context-free phrase structure gram-
mars. In G. de Haan, M. Trommelen, and
W. Zonneveld, editors, Van Periferie naar
Kern. Foris, Dordrecht, Holland.
Yuji Matsumoto, Hozumi Tanaka, Hideki Hi-
rakawa, Hideo Miyoshi, and Hideki Yasukawa.
1983. BUP: a bottom-up parser embedded in
Prolog. New Generation Computing, 1(2):145-
158.
Michael Moortgat. 1984. A Fregean restriction on
meta-rules. In Proceedings of NELS 14, pages
306-325, Amherst, Massachusetts. University of
Massachusetts.
</reference>
<page confidence="0.97095">
16
</page>
<reference confidence="0.907707297872341">
Lee Naish. 1986. Negation and Control in Pro-
log, Volume 238 of Lecture Notes in Computer
Science. Springer-Verlag, Berlin, Germany.
Fernando C.N. Pereira and Stuart M. Shieber.
1985. Prolog and Natural-Language Analysis,
Volume 10 of CSLI Lecture Notes. Center for
the Study of Language and Information, Stan-
ford, California. Distributed by Chicago Uni-
versity Press.
Fernando C.N. Pereira and David H.D. Warren.
1983. Parsing as deduction. In Proceedings
of the 21st Annual Meeting, Cambridge, Mas-
sachusetts (June 15-17). Association for Com-
putational Linguistics.
Fernando C.N. Pereira. 1981. Extraposi-
tion grammars. Computational Linguistics,
7(4):243-256 (October-December).
Carl Pollard. 1988. Categorial grammar and
phrase structure grammar: an excursion on
the syntax-semantics frontier. In R. Oehrle,
E. Bach, and D. Wheeler, editors, Categorial
Grammars and Natural Language Structures. D.
Reidel, Dordrecht, Holland.
Stuart M. Shieber. 1985a. An Introduction
to Unification-Based Approaches to Grammar,
Volume 4 of CSLI Lecture Notes. Center for the
Study of Language and Information, Stanford,
California. Distributed by Chicago University
Press.
Stuart M. Shieber. 1985b. Using restriction to
extend parsing algorithms for complex-feature-
based formalisms. In 23rd Annual Meeting of
the Association for Computational Linguistics,
pages 145-152, Morristown, New Jersey. Asso-
ciation for Computational Linguistics.
Stuart M. Shieber. 1988. A uniform architecture
for parsing and generation. In Proceedings of
the 12th International Conference on Compu-
tational Linguistics, pages 614-619, Budapest,
Hungary.
Mark Steedman. 1985. Dependency and coordi-
nation in the grammar of Dutch and English.
Language, 61(3):523-568.
Jürgen Wedekind. 1988. Generation as structure
driven derivation. In Proceedings of the 12th In-
ternational Conference on Computational Lin-
guistics, pages 732-737, Budapest, Hungary.
</reference>
<page confidence="0.999397">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904874">
<title confidence="0.9998655">A Semantic-Head-Driven Generation Algorithm for Unification-Based Formalisms</title>
<author confidence="0.956347">Stuart M Shieber</author>
<author confidence="0.956347">Gertjan van_Noord</author>
<author confidence="0.956347">t Robert C Moore</author>
<author confidence="0.956347">Fernando C N Pereira</author>
<affiliation confidence="0.9997125">Artificial Intelligence Center SRI International</affiliation>
<address confidence="0.999752">Menlo Park, CA 94025, USA</address>
<abstract confidence="0.99937125">We present an algorithm for generating strings from logical form encodings that improves upon previous algorithms in that it places fewer restrictions on the class of grammars to which it is applicable. In particular, unlike an Earley deduction generator (Shieber, 1988), it allows use of semantically nonmonotonic grammars, yet unlike topdown methods, it also permits left-recursion. The enabling design feature of the algorithm is its implicit traversal of the analysis tree for the string being generated in a semantic-head-driven fashion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>vp</author>
</authors>
<booktitle>SO)/0, np(3-sing, SS)/S], SC) /love(S,O) ---&gt; [loves], {shuffle(SS, SO, SC)}.</booktitle>
<marker>vp, </marker>
<rawString>vp(finite, [np(_. SO)/0, np(3-sing, SS)/S], SC) /love(S,O) ---&gt; [loves], {shuffle(SS, SO, SC)}.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Calder</author>
<author>Mike Reape</author>
<author>Hank Zeevat</author>
</authors>
<title>An algorithm for generation in unification categorial grammar.</title>
<date>1989</date>
<booktitle>In Proceedings of the .4th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>233--240</pages>
<institution>University of Manchester Institute of Science and Technology.</institution>
<location>Manchester, England</location>
<contexts>
<context position="4568" citStr="Calder et al. (1989)" startWordPosition="689" endWordPosition="692">lieve the underlying method to be more broadly applicable. A variant of our method is used in Van Noord&apos;s BUG (Bottom-Up Generator) system, part of MiMo2, an experimental machine translation system for translating international news items of Teletext, which uses a Prolog version of PATR-II similar to that of Hirsh (1987). According to Martin Kay (personal communication), the STREP machine translation project at the Center for the Study of Language and Information uses a version of our algorithm to generate with respect to grammars based on head-driven phrase-structure grammar (HPSG). Finally, Calder et al. (1989) report on a generation algorithm for unification categorial grammar that appears to be a special case of ours. 3 Problems Yvitll Existing Generators Existing generation algorithms have efficiency or termination problems with respect to certain classes of grammars. We review the problems of both top-down and bottom-up regimes in this section. 3.1 Problems with Top-Down Generators Consider a naive top-down generation mechanism that takes as input the semantics to generate from and a corresponding syntactic category and builds a complete tree, top-down, left-to-right by applying rules of the gra</context>
</contexts>
<marker>Calder, Reape, Zeevat, 1989</marker>
<rawString>Jonathan Calder, Mike Reape, and Hank Zeevat. 1989. An algorithm for generation in unification categorial grammar. In Proceedings of the .4th Conference of the European Chapter of the Association for Computational Linguistics, pages 233-240, Manchester, England (10-12 April). University of Manchester Institute of Science and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>PROLOG II: Manuel de reference et modele theorique.</title>
<date>1982</date>
<booktitle>Technical report, Groupe d&apos;Intelligence Artificielle, Faculte des Sciences de Luminy,</booktitle>
<location>Marseille, France.</location>
<contexts>
<context position="6678" citStr="Colmerauer, 1982" startWordPosition="1034" endWordPosition="1035">ng this problem, propose allowing the grammarwriter to specify a separate goal ordering for parsing and for generation. For the case at hand, the solution is to generate the VP first—from the goal vp(NP)/loves(john, mary)—in the course of which the variable NP will become bound so that the generation from np/NP will terminate. Wedekind (1988) achieves this goal by expanding first nodes that are connected, that is, whose semantics is instantiated. Since the NP is not connected in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal freezing (Colmerauer, 1982) or implicit wail declaration (Naish, 1986). For cases in which the a priori ordering of goals is insufficient, Dymetman and Isabelle also introduce goal freezing to control expansion. Although vastly superior to the naive top-down algorithm, even this sort of amended top-down approach to generation based on goal freezing under one guise or another fails to terminate with certain linguistically plausible analyses. For example, the &amp;quot;complements&amp;quot; rule given by Shieber (1985a, pages 77-78) in the PATR-II formalism VP&apos; VP2 X (VPi head) = (VP2 head) (VP2 syncat first) = (X) (VP2 syncat rest) = (VPi</context>
</contexts>
<marker>Colmerauer, 1982</marker>
<rawString>Alain Colmerauer. 1982. PROLOG II: Manuel de reference et modele theorique. Technical report, Groupe d&apos;Intelligence Artificielle, Faculte des Sciences de Luminy, Marseille, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Quantification and Syntactic Theory, Volume 21 of Synthese Language Library.</title>
<date>1983</date>
<location>D. Reidel, Dordrecht, Netherlands.</location>
<contexts>
<context position="25843" citStr="Cooper, 1983" startWordPosition="4068" endWordPosition="4069">original root. Again, the process is trivial, by virtue of the base case for connection. The generation process is thus completed, yielding the string &amp;quot;John calls friends up&amp;quot;. The drawing summarizes the generation process by showing which steps were performed topdown or bottom-up by arrows on the analysis tree branches. 13 The grammar presented here was perforce trivial, for expository reasons. We have developed more extensive experimental grammars that can generate relative clauses with gaps and sentences with quantified NPs from quantified logical forms by using a version of Cooper storage (Cooper, 1983). We give an outline of our treatment of quantification in Section 6.2. 5 Important Properties of the Algorithm Several properties of the algorithm are exhibited by the preceding example example. First, the order of processing is not left-to-right. The verb was generated before any of its complements. Because of this, the semantic information about the particle &amp;quot;up&amp;quot; was available, even though this information appears nowhere in the goal semantics. That is, the generator operated appropriately despite a semantically nonmonotonic grammar. In addition, full information about the subject, includin</context>
</contexts>
<marker>Cooper, 1983</marker>
<rawString>Robin Cooper. 1983. Quantification and Syntactic Theory, Volume 21 of Synthese Language Library. D. Reidel, Dordrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Dymetman</author>
<author>Pierre Isabelle</author>
</authors>
<title>Reversible logic grammars for machine translation.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<institution>CarnegieMellon University.</institution>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="2247" citStr="Dymetman and Isabelle (1988)" startWordPosition="333" endWordPosition="336">rley deduction method is reasonably successful along certain dimensions. It is quite simple, general in its applicability to a range of unification-based and logic grammar formalisms, and uniform, in that it places only one restriction (discussed below) on the form of the linguistic analyses allowed by the grammars used in generation. In particular, generation from grammars with recursions whose well-foundedness relies tDepartment of Linguistics Rijksuniversiteit Utrecht Utrecht, Netherlands on lexical information will terminate; top-down generation regimes such as those of Wedekind (1988) or Dymetman and Isabelle (1988) lack this property, discussed further in Section 3.1. Unfortunately, the bottom-up, left-to-right processing regime of Earley generation—as it might be called—has its own inherent frailties. Efficiency considerations require that only grammars possessing a property of semantic monotonicity can be effectively used, and even for those grammars, processing can become overly nondeterministic. The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. Although we believe that this algorithm could be seen as an instance of a uniform architecture for pars</context>
<context position="6055" citStr="Dymetman and Isabelle (1988)" startWordPosition="925" endWordPosition="928">S --&gt; np/NP, vp(NP)/S. (The intention is that verb phrases like, say, &amp;quot;loves Mary&amp;quot; be associated with a nonterminal vp(X)/love(X, nary).) Once this rule is applied to the goal s/love(john, mary), the subgoal np/NP will be considered. But the generation search space for that goal is infinite and so has infinite branches, because all noun phrases, and thus arbitrarily large ones, match the goal. This is an instance of the general problem known from logic programming that a logic program may not terminate when called with a goal less instantiated than what was intended by the program&apos;s designer. Dymetman and Isabelle (1988), noting this problem, propose allowing the grammarwriter to specify a separate goal ordering for parsing and for generation. For the case at hand, the solution is to generate the VP first—from the goal vp(NP)/loves(john, mary)—in the course of which the variable NP will become bound so that the generation from np/NP will terminate. Wedekind (1988) achieves this goal by expanding first nodes that are connected, that is, whose semantics is instantiated. Since the NP is not connected in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal free</context>
</contexts>
<marker>Dymetman, Isabelle, 1988</marker>
<rawString>Marc Dymetman and Pierre Isabelle. 1988. Reversible logic grammars for machine translation. In Proceedings of the Second International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages, Pittsburgh, Pennsylvania. CarnegieMellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnold Evers</author>
</authors>
<title>The transformational cycle in German and Dutch.</title>
<date>1975</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Utrecht,</institution>
<location>Utrecht, Netherlands.</location>
<contexts>
<context position="7860" citStr="Evers, 1975" startWordPosition="1224" endWordPosition="1225"> (X) (VP2 syncat rest) = (VPi syncat) can be encoded as the DCG-style rule: vp(Head, Syncat) --&gt; vp(Head, [CompllSyncat]), Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, even this expedient may be insufficient. In analyses of Dutch cross-serial verb constructions (Evers, 1975; Huybrechts, 1984), subcategorization lists such as these may be appended by syntactic rules (Moortgat, 1984; Steedman, 1985; Pollard, 1988), resulting in indefinitely long lists. Consider the Dutch sentence dat [Jan [Marie [de oppasser [de olifanten 8 that John Mary the keeper the elephants (zag helpen voeren]]]] saw help feed that John saw Mary help the keeper feed the elephants The string of verbs is analysed by appending their subcategorization lists as follows: V [e,k,m,j] V [m,j] V [e,k,m] zag y rk,m] V [e,k] saw helpen voeren help feed Subcategorization lists under this analysis can ha</context>
</contexts>
<marker>Evers, 1975</marker>
<rawString>Arnold Evers. 1975. The transformational cycle in German and Dutch. Ph.D. thesis, University of Utrecht, Utrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per-Kristian Halvorsen</author>
<author>Ronald M Kaplan</author>
</authors>
<title>Projections and semantic description in lexical-functional grammar.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>1116--1122</pages>
<institution>Institute for New Generation Computer Technology.</institution>
<location>Tokyo,</location>
<contexts>
<context position="28043" citStr="Halvorsen and Kaplan, 1988" startWordPosition="4412" endWordPosition="4415"> to w the logical form a. The generator is complete ifs always subsumes a and coherent if a always subsumes s. The generator defined in Section 4.1 is not coherent or complete in this sense; it requires only that a and s be compatible, that is, unifiable. If the logical-form language and semantic interpretation system provide a sound treatment of variable binding and scope, abstraction and application, completeness and coherence will be irrelevant because the logical form of any phrase will not contain free variables. However, neither semantic projections in lexical-functional grammar ( LFG) (Halvorsen and Kaplan, 1988) nor definite-clause grammars provide the means for such a sound treatment: logical-form variables or missing arguments of predicates are both encoded as unbound variables (attributes with unspecified values in the LFG semantic projection) at the description level. Then completeness and coherence become important. For example, suppose a grammar associated the following strings and logical forms. eat(john, X) &apos;John ate&apos; eat(john, banana) &apos;John ate a banana&apos; eat(john, nice(yellov(banana))) &apos;John ate a nice yellow banana&apos; The generator of Section 4.1 would generate any of these sentences for the </context>
</contexts>
<marker>Halvorsen, Kaplan, 1988</marker>
<rawString>Per-Kristian Halvorsen and Ronald M. Kaplan. 1988. Projections and semantic description in lexical-functional grammar. In Proceedings of the International Conference on Fifth Generation Computer Systems, pages 1116-1122, Tokyo, Japan. Institute for New Generation Computer Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Hirsh</author>
</authors>
<title>P-PATR, a compiler for unification based grammars.</title>
<date>1987</date>
<booktitle>In Veronica Dahl and Patrick Saint-Dizier, editors, Natural Language Understanding and Logic Programming,</booktitle>
<publisher>Elsevier Science Publishers.</publisher>
<location>II.</location>
<contexts>
<context position="4270" citStr="Hirsh (1987)" startWordPosition="645" endWordPosition="646">ementation of it for definite-clause grammars (DCG), although we beI Martin Kay (personal communication) has developed a parsing algorithm that seems to be the parsing correlate to the generation algorithm presented here. Its existence might point the way towards a uniform architecture. 7 lieve the underlying method to be more broadly applicable. A variant of our method is used in Van Noord&apos;s BUG (Bottom-Up Generator) system, part of MiMo2, an experimental machine translation system for translating international news items of Teletext, which uses a Prolog version of PATR-II similar to that of Hirsh (1987). According to Martin Kay (personal communication), the STREP machine translation project at the Center for the Study of Language and Information uses a version of our algorithm to generate with respect to grammars based on head-driven phrase-structure grammar (HPSG). Finally, Calder et al. (1989) report on a generation algorithm for unification categorial grammar that appears to be a special case of ours. 3 Problems Yvitll Existing Generators Existing generation algorithms have efficiency or termination problems with respect to certain classes of grammars. We review the problems of both top-d</context>
</contexts>
<marker>Hirsh, 1987</marker>
<rawString>Susan Hirsh. 1987. P-PATR, a compiler for unification based grammars. In Veronica Dahl and Patrick Saint-Dizier, editors, Natural Language Understanding and Logic Programming, II. Elsevier Science Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Stuart M Shieber</author>
</authors>
<title>An algorithm for generating quantifier scopings.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--47</pages>
<marker>Hobbs, Shieber, 1987</marker>
<rawString>Jerry R. Hobbs and Stuart M. Shieber. 1987. An algorithm for generating quantifier scopings. Computational Linguistics, 13:47-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riny A C Huybrechts</author>
</authors>
<title>The weak inadequacy of context-free phrase structure grammars.</title>
<date>1984</date>
<editor>In G. de Haan, M. Trommelen, and W. Zonneveld, editors, Van Periferie naar Kern. Foris,</editor>
<location>Dordrecht, Holland.</location>
<contexts>
<context position="7879" citStr="Huybrechts, 1984" startWordPosition="1226" endWordPosition="1227">cat rest) = (VPi syncat) can be encoded as the DCG-style rule: vp(Head, Syncat) --&gt; vp(Head, [CompllSyncat]), Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, even this expedient may be insufficient. In analyses of Dutch cross-serial verb constructions (Evers, 1975; Huybrechts, 1984), subcategorization lists such as these may be appended by syntactic rules (Moortgat, 1984; Steedman, 1985; Pollard, 1988), resulting in indefinitely long lists. Consider the Dutch sentence dat [Jan [Marie [de oppasser [de olifanten 8 that John Mary the keeper the elephants (zag helpen voeren]]]] saw help feed that John saw Mary help the keeper feed the elephants The string of verbs is analysed by appending their subcategorization lists as follows: V [e,k,m,j] V [m,j] V [e,k,m] zag y rk,m] V [e,k] saw helpen voeren help feed Subcategorization lists under this analysis can have any length, and </context>
</contexts>
<marker>Huybrechts, 1984</marker>
<rawString>Riny A.C. Huybrechts. 1984.. The weak inadequacy of context-free phrase structure grammars. In G. de Haan, M. Trommelen, and W. Zonneveld, editors, Van Periferie naar Kern. Foris, Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuji Matsumoto</author>
<author>Hozumi Tanaka</author>
<author>Hideki Hirakawa</author>
<author>Hideo Miyoshi</author>
<author>Hideki Yasukawa</author>
</authors>
<title>BUP: a bottom-up parser embedded in Prolog.</title>
<date>1983</date>
<journal>New Generation Computing,</journal>
<pages>1--2</pages>
<contexts>
<context position="19581" citStr="Matsumoto et al. (1983)" startWordPosition="3140" endWordPosition="3143">Now, we need only define the notion of an applicable chain or nonchain rule. A nonchain rule is applicable if the semantics of the left-hand-side of the rule (which is to become the pivot) matches that of the root. Further, we require a top-down check that syntactically the pivot can serve as the semantic head of the root. For this purpose, we assume a predicate chained_nodes that codifies the transitive closure of the semantic head relation over categories. This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al. (1983) or Pereira and Shieber (1985, p. 182) for further information. applicable_non_chain_rule(Root, Pivot, RHS) :- % semantics of root and pivot are same node_semantics(Root, Sem), node_semantics(Pivot, Sem), % choose a nonchain rule non_chain_rule (US RHS) , % ...whose lhs matches the pivot unify(Pivot, LHS), % make sure the categories can connect chained_nodes(Pivot, Root). A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root. applicable_chain_rule(Pivot, Parent, R</context>
</contexts>
<marker>Matsumoto, Tanaka, Hirakawa, Miyoshi, Yasukawa, 1983</marker>
<rawString>Yuji Matsumoto, Hozumi Tanaka, Hideki Hirakawa, Hideo Miyoshi, and Hideki Yasukawa. 1983. BUP: a bottom-up parser embedded in Prolog. New Generation Computing, 1(2):145-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>A Fregean restriction on meta-rules.</title>
<date>1984</date>
<booktitle>In Proceedings of NELS 14,</booktitle>
<pages>306--325</pages>
<institution>University of Massachusetts.</institution>
<location>Amherst, Massachusetts.</location>
<contexts>
<context position="7969" citStr="Moortgat, 1984" startWordPosition="1240" endWordPosition="1241">[CompllSyncat]), Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, even this expedient may be insufficient. In analyses of Dutch cross-serial verb constructions (Evers, 1975; Huybrechts, 1984), subcategorization lists such as these may be appended by syntactic rules (Moortgat, 1984; Steedman, 1985; Pollard, 1988), resulting in indefinitely long lists. Consider the Dutch sentence dat [Jan [Marie [de oppasser [de olifanten 8 that John Mary the keeper the elephants (zag helpen voeren]]]] saw help feed that John saw Mary help the keeper feed the elephants The string of verbs is analysed by appending their subcategorization lists as follows: V [e,k,m,j] V [m,j] V [e,k,m] zag y rk,m] V [e,k] saw helpen voeren help feed Subcategorization lists under this analysis can have any length, and it is impossible to predict from a semantic structure the size of its corresponding subcat</context>
</contexts>
<marker>Moortgat, 1984</marker>
<rawString>Michael Moortgat. 1984. A Fregean restriction on meta-rules. In Proceedings of NELS 14, pages 306-325, Amherst, Massachusetts. University of Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee Naish</author>
</authors>
<title>Negation and Control</title>
<date>1986</date>
<booktitle>in Prolog, Volume 238 of Lecture Notes in Computer Science.</booktitle>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="6721" citStr="Naish, 1986" startWordPosition="1041" endWordPosition="1042">ter to specify a separate goal ordering for parsing and for generation. For the case at hand, the solution is to generate the VP first—from the goal vp(NP)/loves(john, mary)—in the course of which the variable NP will become bound so that the generation from np/NP will terminate. Wedekind (1988) achieves this goal by expanding first nodes that are connected, that is, whose semantics is instantiated. Since the NP is not connected in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal freezing (Colmerauer, 1982) or implicit wail declaration (Naish, 1986). For cases in which the a priori ordering of goals is insufficient, Dymetman and Isabelle also introduce goal freezing to control expansion. Although vastly superior to the naive top-down algorithm, even this sort of amended top-down approach to generation based on goal freezing under one guise or another fails to terminate with certain linguistically plausible analyses. For example, the &amp;quot;complements&amp;quot; rule given by Shieber (1985a, pages 77-78) in the PATR-II formalism VP&apos; VP2 X (VPi head) = (VP2 head) (VP2 syncat first) = (X) (VP2 syncat rest) = (VPi syncat) can be encoded as the DCG-style ru</context>
</contexts>
<marker>Naish, 1986</marker>
<rawString>Lee Naish. 1986. Negation and Control in Prolog, Volume 238 of Lecture Notes in Computer Science. Springer-Verlag, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Stuart M Shieber</author>
</authors>
<title>Prolog and Natural-Language Analysis, Volume 10 of CSLI Lecture Notes. Center for the Study of Language and Information,</title>
<date>1985</date>
<publisher>Chicago University Press.</publisher>
<location>Stanford, California.</location>
<note>Distributed by</note>
<contexts>
<context position="18100" citStr="Pereira and Shieber, 1985" startWordPosition="2876" endWordPosition="2879"> node Root can themselves be connected. connect(Pivot, Root) :- 5 choose chain rule applicable_chain_rule(Pivot, LHS, Root, RHS), % generate remaining siblings generate_rhs(RHS), % connect the new parent to the root connect(LHS, Root). The base case occurs when the root and the pivot are the same. Identity checks like this one must be implemented correctly in the generator by using a sound unification algorithm with the occurs check. (The default unification in most Prolog systems is unsound in this respect.) For example, a grammar with a gap-threading treatment of wh-movement (Pereira, 1981; Pereira and Shieber, 1985) might include the rule np(Agr, [np(Agr)/Seml X)-X)/Sem ---&gt; . stating that an NP with agreement Agr and semantics Sem can be empty provided that the list of gaps in the NP can be represented as the difference list [rip(Agr)/Sem I X] -X, that is the list containing an NP gap with the same agreement features Agr (Pereira and Shieber, 1985, p. 128). Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np(3-sing,G-G)/john. The base case of connect will try to unify that term with the head of the rule above, leading to the </context>
<context position="19610" citStr="Pereira and Shieber (1985" startWordPosition="3145" endWordPosition="3148">e notion of an applicable chain or nonchain rule. A nonchain rule is applicable if the semantics of the left-hand-side of the rule (which is to become the pivot) matches that of the root. Further, we require a top-down check that syntactically the pivot can serve as the semantic head of the root. For this purpose, we assume a predicate chained_nodes that codifies the transitive closure of the semantic head relation over categories. This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al. (1983) or Pereira and Shieber (1985, p. 182) for further information. applicable_non_chain_rule(Root, Pivot, RHS) :- % semantics of root and pivot are same node_semantics(Root, Sem), node_semantics(Pivot, Sem), % choose a nonchain rule non_chain_rule (US RHS) , % ...whose lhs matches the pivot unify(Pivot, LHS), % make sure the categories can connect chained_nodes(Pivot, Root). A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root. applicable_chain_rule(Pivot, Parent, Root, RHS) :- % choose a chain</context>
</contexts>
<marker>Pereira, Shieber, 1985</marker>
<rawString>Fernando C.N. Pereira and Stuart M. Shieber. 1985. Prolog and Natural-Language Analysis, Volume 10 of CSLI Lecture Notes. Center for the Study of Language and Information, Stanford, California. Distributed by Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David H D Warren</author>
</authors>
<title>Parsing as deduction.</title>
<date>1983</date>
<booktitle>In Proceedings of the 21st Annual Meeting,</booktitle>
<location>Cambridge, Massachusetts</location>
<contexts>
<context position="1402" citStr="Pereira and Warren (1983)" startWordPosition="207" endWordPosition="210">iven fashion. 1 Introduction The problem of generating a well-formed naturallanguage expression from an encoding of its meaning possesses certain properties which distinguish it from the converse problem of recovering a meaning encoding from a given natural-language expression. In previous work (Shieber, 1988), however, one of us attempted to characterize these differing properties in such a way that a single uniform architecture, appropriately parameterized, might be used for both natural-language processes. In particular, we developed an architecture inspired by the Earley deduction work of Pereira and Warren (1983) but which generalized that work allowing for its use in both a parsing and generation mode merely by setting the values of a small number of parameters. As a method for generating natural-language expressions, the Earley deduction method is reasonably successful along certain dimensions. It is quite simple, general in its applicability to a range of unification-based and logic grammar formalisms, and uniform, in that it places only one restriction (discussed below) on the form of the linguistic analyses allowed by the grammars used in generation. In particular, generation from grammars with r</context>
<context position="11957" citStr="Pereira and Warren (1983)" startWordPosition="1855" endWordPosition="1858">fferent premises of the two types of problem. From this point of view, a naive top-down parser or generator performs a depth-first, left-to-right traversal of the tree. Completion steps in Earley&apos;s algorithm, whether used for parsing or generation, correspond to a post-order traversal (with prediction acting as a pre-order filter). The left-to-right traversal order of both of these methods is geared towards the given information in a parsing problem, the string, rather than that of a generation problem, the goal logical form. It is exactly this mismatch between structure of the traversal and 2Pereira and Warren (1983) point out that Earley deduction is not restricted to a left-to-right expansion of goals, but this suggestion was not followed up with a specific algorithm addressing the problems discussed here. 3We use the term &amp;quot;analysis tree&amp;quot; rather than the more familiar &amp;quot;parse tree&amp;quot; to make clear that the source of the tree is not necessarily a parsing process; rather the tree serves only to codify a particular analysis of the structure of the string. 9 structure of the problem premise that accounts for the profligacy of these approaches when used for generation. Thus for generation, we want a traversal o</context>
</contexts>
<marker>Pereira, Warren, 1983</marker>
<rawString>Fernando C.N. Pereira and David H.D. Warren. 1983. Parsing as deduction. In Proceedings of the 21st Annual Meeting, Cambridge, Massachusetts (June 15-17). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
</authors>
<title>Extraposition grammars.</title>
<date>1981</date>
<journal>Computational Linguistics,</journal>
<pages>7--4</pages>
<location>(October-December).</location>
<contexts>
<context position="18072" citStr="Pereira, 1981" startWordPosition="2874" endWordPosition="2875">de and the root node Root can themselves be connected. connect(Pivot, Root) :- 5 choose chain rule applicable_chain_rule(Pivot, LHS, Root, RHS), % generate remaining siblings generate_rhs(RHS), % connect the new parent to the root connect(LHS, Root). The base case occurs when the root and the pivot are the same. Identity checks like this one must be implemented correctly in the generator by using a sound unification algorithm with the occurs check. (The default unification in most Prolog systems is unsound in this respect.) For example, a grammar with a gap-threading treatment of wh-movement (Pereira, 1981; Pereira and Shieber, 1985) might include the rule np(Agr, [np(Agr)/Seml X)-X)/Sem ---&gt; . stating that an NP with agreement Agr and semantics Sem can be empty provided that the list of gaps in the NP can be represented as the difference list [rip(Agr)/Sem I X] -X, that is the list containing an NP gap with the same agreement features Agr (Pereira and Shieber, 1985, p. 128). Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np(3-sing,G-G)/john. The base case of connect will try to unify that term with the head of the</context>
</contexts>
<marker>Pereira, 1981</marker>
<rawString>Fernando C.N. Pereira. 1981. Extraposition grammars. Computational Linguistics, 7(4):243-256 (October-December).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
</authors>
<title>Categorial grammar and phrase structure grammar: an excursion on the syntax-semantics frontier. In</title>
<date>1988</date>
<booktitle>Categorial Grammars and Natural Language Structures.</booktitle>
<editor>R. Oehrle, E. Bach, and D. Wheeler, editors,</editor>
<location>Dordrecht, Holland.</location>
<contexts>
<context position="8001" citStr="Pollard, 1988" startWordPosition="1244" endWordPosition="1245"> generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, even this expedient may be insufficient. In analyses of Dutch cross-serial verb constructions (Evers, 1975; Huybrechts, 1984), subcategorization lists such as these may be appended by syntactic rules (Moortgat, 1984; Steedman, 1985; Pollard, 1988), resulting in indefinitely long lists. Consider the Dutch sentence dat [Jan [Marie [de oppasser [de olifanten 8 that John Mary the keeper the elephants (zag helpen voeren]]]] saw help feed that John saw Mary help the keeper feed the elephants The string of verbs is analysed by appending their subcategorization lists as follows: V [e,k,m,j] V [m,j] V [e,k,m] zag y rk,m] V [e,k] saw helpen voeren help feed Subcategorization lists under this analysis can have any length, and it is impossible to predict from a semantic structure the size of its corresponding subcategorization list merely by exami</context>
</contexts>
<marker>Pollard, 1988</marker>
<rawString>Carl Pollard. 1988. Categorial grammar and phrase structure grammar: an excursion on the syntax-semantics frontier. In R. Oehrle, E. Bach, and D. Wheeler, editors, Categorial Grammars and Natural Language Structures. D. Reidel, Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar,</title>
<date>1985</date>
<booktitle>of CSLI Lecture Notes. Center for the Study of Language and Information,</booktitle>
<volume>4</volume>
<publisher>Chicago University Press.</publisher>
<location>Stanford, California.</location>
<note>Distributed by</note>
<contexts>
<context position="2915" citStr="Shieber, 1985" startWordPosition="434" endWordPosition="435">Unfortunately, the bottom-up, left-to-right processing regime of Earley generation—as it might be called—has its own inherent frailties. Efficiency considerations require that only grammars possessing a property of semantic monotonicity can be effectively used, and even for those grammars, processing can become overly nondeterministic. The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation—just as the extended Earley parser (Shieber, 1985b) and the bottom-up generator were instances of the generalized Earley deduction architecture—our efforts to date have been aimed foremost toward the development of the algorithm for generation alone. We will have little to say about its relation to parsing, leaving such questions for later research.&apos; 2 Applicability of the Algorithm As does the Earley-based generator, the new algorithm assumes that the grammar is a unificationbased or logic grammar with a phrase-structure backbone and complex nonterminals. Furthermore, and again consistent with previous work, we assume that the nonterminals </context>
<context position="7154" citStr="Shieber (1985" startWordPosition="1109" endWordPosition="1110"> in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal freezing (Colmerauer, 1982) or implicit wail declaration (Naish, 1986). For cases in which the a priori ordering of goals is insufficient, Dymetman and Isabelle also introduce goal freezing to control expansion. Although vastly superior to the naive top-down algorithm, even this sort of amended top-down approach to generation based on goal freezing under one guise or another fails to terminate with certain linguistically plausible analyses. For example, the &amp;quot;complements&amp;quot; rule given by Shieber (1985a, pages 77-78) in the PATR-II formalism VP&apos; VP2 X (VPi head) = (VP2 head) (VP2 syncat first) = (X) (VP2 syncat rest) = (VPi syncat) can be encoded as the DCG-style rule: vp(Head, Syncat) --&gt; vp(Head, [CompllSyncat]), Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, </context>
<context position="18100" citStr="Shieber, 1985" startWordPosition="2878" endWordPosition="2879">an themselves be connected. connect(Pivot, Root) :- 5 choose chain rule applicable_chain_rule(Pivot, LHS, Root, RHS), % generate remaining siblings generate_rhs(RHS), % connect the new parent to the root connect(LHS, Root). The base case occurs when the root and the pivot are the same. Identity checks like this one must be implemented correctly in the generator by using a sound unification algorithm with the occurs check. (The default unification in most Prolog systems is unsound in this respect.) For example, a grammar with a gap-threading treatment of wh-movement (Pereira, 1981; Pereira and Shieber, 1985) might include the rule np(Agr, [np(Agr)/Seml X)-X)/Sem ---&gt; . stating that an NP with agreement Agr and semantics Sem can be empty provided that the list of gaps in the NP can be represented as the difference list [rip(Agr)/Sem I X] -X, that is the list containing an NP gap with the same agreement features Agr (Pereira and Shieber, 1985, p. 128). Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np(3-sing,G-G)/john. The base case of connect will try to unify that term with the head of the rule above, leading to the </context>
<context position="19610" citStr="Shieber (1985" startWordPosition="3147" endWordPosition="3148">an applicable chain or nonchain rule. A nonchain rule is applicable if the semantics of the left-hand-side of the rule (which is to become the pivot) matches that of the root. Further, we require a top-down check that syntactically the pivot can serve as the semantic head of the root. For this purpose, we assume a predicate chained_nodes that codifies the transitive closure of the semantic head relation over categories. This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al. (1983) or Pereira and Shieber (1985, p. 182) for further information. applicable_non_chain_rule(Root, Pivot, RHS) :- % semantics of root and pivot are same node_semantics(Root, Sem), node_semantics(Pivot, Sem), % choose a nonchain rule non_chain_rule (US RHS) , % ...whose lhs matches the pivot unify(Pivot, LHS), % make sure the categories can connect chained_nodes(Pivot, Root). A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root. applicable_chain_rule(Pivot, Parent, Root, RHS) :- % choose a chain</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>Stuart M. Shieber. 1985a. An Introduction to Unification-Based Approaches to Grammar, Volume 4 of CSLI Lecture Notes. Center for the Study of Language and Information, Stanford, California. Distributed by Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Using restriction to extend parsing algorithms for complex-featurebased formalisms.</title>
<date>1985</date>
<booktitle>In 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>145--152</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, New Jersey.</location>
<contexts>
<context position="2915" citStr="Shieber, 1985" startWordPosition="434" endWordPosition="435">Unfortunately, the bottom-up, left-to-right processing regime of Earley generation—as it might be called—has its own inherent frailties. Efficiency considerations require that only grammars possessing a property of semantic monotonicity can be effectively used, and even for those grammars, processing can become overly nondeterministic. The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. Although we believe that this algorithm could be seen as an instance of a uniform architecture for parsing and generation—just as the extended Earley parser (Shieber, 1985b) and the bottom-up generator were instances of the generalized Earley deduction architecture—our efforts to date have been aimed foremost toward the development of the algorithm for generation alone. We will have little to say about its relation to parsing, leaving such questions for later research.&apos; 2 Applicability of the Algorithm As does the Earley-based generator, the new algorithm assumes that the grammar is a unificationbased or logic grammar with a phrase-structure backbone and complex nonterminals. Furthermore, and again consistent with previous work, we assume that the nonterminals </context>
<context position="7154" citStr="Shieber (1985" startWordPosition="1109" endWordPosition="1110"> in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal freezing (Colmerauer, 1982) or implicit wail declaration (Naish, 1986). For cases in which the a priori ordering of goals is insufficient, Dymetman and Isabelle also introduce goal freezing to control expansion. Although vastly superior to the naive top-down algorithm, even this sort of amended top-down approach to generation based on goal freezing under one guise or another fails to terminate with certain linguistically plausible analyses. For example, the &amp;quot;complements&amp;quot; rule given by Shieber (1985a, pages 77-78) in the PATR-II formalism VP&apos; VP2 X (VPi head) = (VP2 head) (VP2 syncat first) = (X) (VP2 syncat rest) = (VPi syncat) can be encoded as the DCG-style rule: vp(Head, Syncat) --&gt; vp(Head, [CompllSyncat]), Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, </context>
<context position="18100" citStr="Shieber, 1985" startWordPosition="2878" endWordPosition="2879">an themselves be connected. connect(Pivot, Root) :- 5 choose chain rule applicable_chain_rule(Pivot, LHS, Root, RHS), % generate remaining siblings generate_rhs(RHS), % connect the new parent to the root connect(LHS, Root). The base case occurs when the root and the pivot are the same. Identity checks like this one must be implemented correctly in the generator by using a sound unification algorithm with the occurs check. (The default unification in most Prolog systems is unsound in this respect.) For example, a grammar with a gap-threading treatment of wh-movement (Pereira, 1981; Pereira and Shieber, 1985) might include the rule np(Agr, [np(Agr)/Seml X)-X)/Sem ---&gt; . stating that an NP with agreement Agr and semantics Sem can be empty provided that the list of gaps in the NP can be represented as the difference list [rip(Agr)/Sem I X] -X, that is the list containing an NP gap with the same agreement features Agr (Pereira and Shieber, 1985, p. 128). Because the above rule is a nonchain rule, it will be considered when trying to generate any nongap NP, such as the proper noun np(3-sing,G-G)/john. The base case of connect will try to unify that term with the head of the rule above, leading to the </context>
<context position="19610" citStr="Shieber (1985" startWordPosition="3147" endWordPosition="3148">an applicable chain or nonchain rule. A nonchain rule is applicable if the semantics of the left-hand-side of the rule (which is to become the pivot) matches that of the root. Further, we require a top-down check that syntactically the pivot can serve as the semantic head of the root. For this purpose, we assume a predicate chained_nodes that codifies the transitive closure of the semantic head relation over categories. This is the correlate of the link relation used in left-corner parsers with topdown filtering; we direct the reader to the discussion by Matsumoto et al. (1983) or Pereira and Shieber (1985, p. 182) for further information. applicable_non_chain_rule(Root, Pivot, RHS) :- % semantics of root and pivot are same node_semantics(Root, Sem), node_semantics(Pivot, Sem), % choose a nonchain rule non_chain_rule (US RHS) , % ...whose lhs matches the pivot unify(Pivot, LHS), % make sure the categories can connect chained_nodes(Pivot, Root). A chain rule is applicable to connect a pivot to a root if the pivot can serve as the semantic head of the rule and the left-hand-side of the rule is appropriate for linking to the root. applicable_chain_rule(Pivot, Parent, Root, RHS) :- % choose a chain</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>Stuart M. Shieber. 1985b. Using restriction to extend parsing algorithms for complex-featurebased formalisms. In 23rd Annual Meeting of the Association for Computational Linguistics, pages 145-152, Morristown, New Jersey. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>A uniform architecture for parsing and generation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>614--619</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1088" citStr="Shieber, 1988" startWordPosition="160" endWordPosition="161">n Earley deduction generator (Shieber, 1988), it allows use of semantically nonmonotonic grammars, yet unlike topdown methods, it also permits left-recursion. The enabling design feature of the algorithm is its implicit traversal of the analysis tree for the string being generated in a semantic-head-driven fashion. 1 Introduction The problem of generating a well-formed naturallanguage expression from an encoding of its meaning possesses certain properties which distinguish it from the converse problem of recovering a meaning encoding from a given natural-language expression. In previous work (Shieber, 1988), however, one of us attempted to characterize these differing properties in such a way that a single uniform architecture, appropriately parameterized, might be used for both natural-language processes. In particular, we developed an architecture inspired by the Earley deduction work of Pereira and Warren (1983) but which generalized that work allowing for its use in both a parsing and generation mode merely by setting the values of a small number of parameters. As a method for generating natural-language expressions, the Earley deduction method is reasonably successful along certain dimensio</context>
</contexts>
<marker>Shieber, 1988</marker>
<rawString>Stuart M. Shieber. 1988. A uniform architecture for parsing and generation. In Proceedings of the 12th International Conference on Computational Linguistics, pages 614-619, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Dependency and coordination in the grammar of Dutch</title>
<date>1985</date>
<pages>61--3</pages>
<contexts>
<context position="7985" citStr="Steedman, 1985" startWordPosition="1242" endWordPosition="1243"> Compl. Top-down generation using this rule will be forced to expand the lower VP before its complement, since Compl is uninstantiated initially. But application of the rule can recur indefinitely, leading to nontermination. The problem arises because there is no limit to the size of the subcategorization list. Although one might propose an ad hoc upper bound for lexical entries, even this expedient may be insufficient. In analyses of Dutch cross-serial verb constructions (Evers, 1975; Huybrechts, 1984), subcategorization lists such as these may be appended by syntactic rules (Moortgat, 1984; Steedman, 1985; Pollard, 1988), resulting in indefinitely long lists. Consider the Dutch sentence dat [Jan [Marie [de oppasser [de olifanten 8 that John Mary the keeper the elephants (zag helpen voeren]]]] saw help feed that John saw Mary help the keeper feed the elephants The string of verbs is analysed by appending their subcategorization lists as follows: V [e,k,m,j] V [m,j] V [e,k,m] zag y rk,m] V [e,k] saw helpen voeren help feed Subcategorization lists under this analysis can have any length, and it is impossible to predict from a semantic structure the size of its corresponding subcategorization list</context>
</contexts>
<marker>Steedman, 1985</marker>
<rawString>Mark Steedman. 1985. Dependency and coordination in the grammar of Dutch and English. Language, 61(3):523-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jürgen Wedekind</author>
</authors>
<title>Generation as structure driven derivation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>732--737</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2215" citStr="Wedekind (1988)" startWordPosition="330" endWordPosition="331">expressions, the Earley deduction method is reasonably successful along certain dimensions. It is quite simple, general in its applicability to a range of unification-based and logic grammar formalisms, and uniform, in that it places only one restriction (discussed below) on the form of the linguistic analyses allowed by the grammars used in generation. In particular, generation from grammars with recursions whose well-foundedness relies tDepartment of Linguistics Rijksuniversiteit Utrecht Utrecht, Netherlands on lexical information will terminate; top-down generation regimes such as those of Wedekind (1988) or Dymetman and Isabelle (1988) lack this property, discussed further in Section 3.1. Unfortunately, the bottom-up, left-to-right processing regime of Earley generation—as it might be called—has its own inherent frailties. Efficiency considerations require that only grammars possessing a property of semantic monotonicity can be effectively used, and even for those grammars, processing can become overly nondeterministic. The algorithm described in this paper is an attempt to resolve these problems in a satisfactory manner. Although we believe that this algorithm could be seen as an instance of</context>
<context position="6405" citStr="Wedekind (1988)" startWordPosition="985" endWordPosition="986">arily large ones, match the goal. This is an instance of the general problem known from logic programming that a logic program may not terminate when called with a goal less instantiated than what was intended by the program&apos;s designer. Dymetman and Isabelle (1988), noting this problem, propose allowing the grammarwriter to specify a separate goal ordering for parsing and for generation. For the case at hand, the solution is to generate the VP first—from the goal vp(NP)/loves(john, mary)—in the course of which the variable NP will become bound so that the generation from np/NP will terminate. Wedekind (1988) achieves this goal by expanding first nodes that are connected, that is, whose semantics is instantiated. Since the NP is not connected in this sense, but the VP is, the latter will be expanded first. In essence, the technique is a kind of goal freezing (Colmerauer, 1982) or implicit wail declaration (Naish, 1986). For cases in which the a priori ordering of goals is insufficient, Dymetman and Isabelle also introduce goal freezing to control expansion. Although vastly superior to the naive top-down algorithm, even this sort of amended top-down approach to generation based on goal freezing und</context>
<context position="27257" citStr="Wedekind (1988)" startWordPosition="4285" endWordPosition="4286">ated. Indeed, the example here was completely deterministic; all rule choices were forced. Finally, even though much of the processing is top-down, left-recursive rules (e.g., rule (3)) are still handled in a constrained manner by the algorithm. For these reasons, we feel that the semantichead-driven algorithm is a significant improvement over top-down methods and the previous bottom-up method based on Earley deduction. 6 Extensions We will now outline how the algorithm and the grammar it uses can be extended to encompass some important analyses and constraints. 6.1 Completeness and Coherence Wedekind (1988) defines completeness and coherence of a generation algorithm as follows. Suppose a generator derives a string w from a logical form s, and the grammar assigns to w the logical form a. The generator is complete ifs always subsumes a and coherent if a always subsumes s. The generator defined in Section 4.1 is not coherent or complete in this sense; it requires only that a and s be compatible, that is, unifiable. If the logical-form language and semantic interpretation system provide a sound treatment of variable binding and scope, abstraction and application, completeness and coherence will be </context>
</contexts>
<marker>Wedekind, 1988</marker>
<rawString>Jürgen Wedekind. 1988. Generation as structure driven derivation. In Proceedings of the 12th International Conference on Computational Linguistics, pages 732-737, Budapest, Hungary.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>