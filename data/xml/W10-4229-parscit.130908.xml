<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012221">
<title confidence="0.97425">
JU_CSE_GREC10: Named Entity Generation at GREC 2010
</title>
<author confidence="0.999011">
Amitava Das1, Tanik Saikh2, Tapabrata Mondal3, Sivaji Bandyopadhyay4
</author>
<affiliation confidence="0.939781">
Department of Computer Science and Engineering
Jadavpur University,
</affiliation>
<address confidence="0.540206">
Kolkata-700032, India
</address>
<email confidence="0.861505">
amitava.santu@gmail.com1, tanik4u@gmail.com2, tapabratamon-
dal@gmail.com3, sivaji_cse_ju@yahoo.com4
</email>
<sectionHeader confidence="0.993092" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999717928571429">
This paper presents the experiments carried
out at Jadavpur University as part of the par-
ticipation in the GREC Named Entity Genera-
tion Challenge 2010. The Baseline system is
based on the SEMCAT, SYNCAT and SYN-
FUNC features of REF and REG08-TYPE and
CASE features of REFEX elements. The dis-
course level system is based on the additional
positional features: paragraph number, sen-
tence number, word position in the sentence
and mention number of a particular named ent-
ity in the document. The inclusion of discourse
level features has improved the performance
of the system.
</bodyText>
<sectionHeader confidence="0.976008" genericHeader="method">
1 Baseline System
</sectionHeader>
<bodyText confidence="0.9981875">
The baseline system is based on the following
linguistic features of REF elements: SEMCAT
(Semantic Category), SYNCAT (Syntactic Cate-
gory) and SYNFUNC (Syntactic Function) (Anja
Belz, 2010) and the following linguistic features
of REFEX elements: REG08-TYPE (Entity type)
and CASE (Case marker). The baseline system
has been separately trained on the training set
data for the three domains: chefs, composers and
inventors. The system has been tested on each
development set by identifying the most probable
REFEX element among the possible alternatives
based on the REF element feature combination.
The probability assigned to a REFEX element
corresponding to a certain feature combination of
REF element is calculated as follows:
</bodyText>
<equation confidence="0.985209285714286">
Di
N
REFEX
=
Di
N
REF
</equation>
<bodyText confidence="0.973786739130435">
where p(R v ) is the probability of the targeted
REFEX element to be assigned, Di
NREF is the total
number of occurrences of REF element feature
combinations, i
D denotes the domain i.e., Chefs,
Composers and Inventors and Di
NREF denotes the
total number of occurrences of the REFEX ele-
ment corresponding to the REF feature combina-
tion.
It has been observed that many times the most
probable REFEX element as identified from the
training set is not present among the alternative
REFEX elements. In these cases the system as-
signs the next highest probable REFEX element
learnt from the training set that matches with one
of the REFEX elements among the alternatives.
In some cases more than one REFEX element get
same probability in the training set. In these cas-
es, the REFEX element that occurs earlier in the
alternative set is assigned. The experimental re-
sult of Baseline system is reported in Table 1.
</bodyText>
<table confidence="0.993836">
Chefs Composers Inventors
Precision 0.63 0.68 0.70
Recall 0.69 0.60 0.64
F-Measure 0.66 0.64 0.68
</table>
<tableCaption confidence="0.999811">
Table 1: Result of Baseline System
</tableCaption>
<sectionHeader confidence="0.972972" genericHeader="method">
2 Discourse Level System
</sectionHeader>
<bodyText confidence="0.9997175">
The discourse level features like paragraph num-
ber, sentence number and position of a particular
word in a sentence have been added with the fea-
tures considered in the baseline system. As men-
tioned in Section 1, more than one REFEX ele-
ment can have the same probability value. This
happens as REFEX elements are identified by
two features only REG08-TYPE and CASE.
</bodyText>
<table confidence="0.9997198">
Nam Pro- Com- Emp-
e noun mon ty
Chefs 2317 3071 55 646
Composers 2616 4037 92 858
Inventors 1959 2826 75 621
</table>
<tableCaption confidence="0.997269">
Table 2: Distribution of REFEX Types among
</tableCaption>
<bodyText confidence="0.933130333333333">
three domains.
The above problem occurs mainly for Name
type. Pronouns are very frequent in all the three
domains but they have small number of varia-
tions as: he, her, him, himself, his, she, who,
whom and whose. Common type REFEX ele-
</bodyText>
<equation confidence="0.7671725">
p ( )
Rv
</equation>
<bodyText confidence="0.9999468">
ments are too infrequent in the training set and
they are very hard to generalize. Empty type has
only one REFEX value as: “_”. The distribution
of the various REFEX types among the three
domains in the training set is shown in Table 2.
</bodyText>
<subsectionHeader confidence="0.998021">
2.1 Analysis of Name type entities
</subsectionHeader>
<bodyText confidence="0.999924607142857">
Table 2 shows that name types are very frequent
in all the three domains. Name type entities are
further differentiated by adding more features
derived from the analysis of the name type ele-
ment.
Firstly, the full name of each named entity has
been identified by Entity identification number
(id), maximum length among all occurrences of
that named entity and case marker as plain. For
example, in Figure 1, the REFEX element of id 3
has been chosen as a full name of entity “0” as it
has the longest string with case “plain”.
After identification of full name of each RE-
FEX entity, the following features are identified
for each occurrence of an entity:: Complete
Name Genitive (CNG), Complete Name (CN),
First Name Genitive (FNG), First Name (FN) ,
Last Name Genitive (LNG), Last Name (LN),
Middle Name Genitive (MNG) and Middle
Name (MN). These features are binary in nature
and for each occurrence of an entity only one of
the above features will be true.
Pronouns are kept as the REFEX element fea-
ture with its surface level pattern as they have
only 9 variations. Common types are considered
with tag level “common” as they hard to general-
ize. Empty types are tagged as “empty” as they
have only one tag value “_”.
</bodyText>
<table confidence="0.98513875">
&lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- CNG
1 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;genitive&amp;quot;&gt;Alain
Senderens&apos;s&lt;/REFEX&gt;
&lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- LNG
2 TYPE=&amp;quot;name&amp;quot;
CASE=&amp;quot;genitive&amp;quot;&gt;Senderens&apos;s&lt;/REFEX&gt;
&lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- CN
3 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;plain&amp;quot;&gt;Alain
Senderens&lt;/REFEX&gt;
&lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- LN
4 TYPE=&amp;quot;name&amp;quot;
CASE=&amp;quot;plain&amp;quot;&gt;Senderens&lt;/REFEX&gt;
</table>
<figureCaption confidence="0.997794">
Figure 1: Example of Full Name Identification
</figureCaption>
<sectionHeader confidence="0.998863" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.968527230769231">
The experimental results of the discourse level
system on the development set are reported in the
Table 3 and Table 4 respectively. Table 3 reports
the results when the system has been trained sep-
arately with domain specific training set and Ta-
ble 4 reports the results when the training has
been carried out on the complete training set.
The comparison of the results of the baseline
and the discourse level system shows an overall
improvement. But there are some interesting ob-
servations when comparing the results in Table 3
and Table 4. Currently detailed analyses of the
results are being carried out.
</bodyText>
<table confidence="0.9860585">
Chefs Composers Inventors
P R F P R F P R F
Name 0.69 0.74 0.71 0.78 0.61 0.69 0.77 0.67 0.71
Pronoun 0.81 0.76 0.79 0.70 0.84 0.76 0.76 0.87 0.81
Common 0.76 0.87 0.81 0.37 0.44 0.40 0.44 0.65 0.68
Empty 0.92 0.88 0.90 0.86 0.92 0.89 0.72 0.65 0.68
</table>
<tableCaption confidence="0.978885">
Table 3: Experimental Results of Discourse Level System on the Development Set (Training with
</tableCaption>
<table confidence="0.964090636363636">
Domain Specific Training Set)
Reg08 Type String BLEU NIST String Edit
Accuracy Distance
Precision Recall
Mean Mean
Normalized
1 2 3 4
Chefs 0.66 0.70 0.57 0.68 0.70 0.76 0.81 3.70 0.77 0.38
Composers 0.63 0.67 0.56 0.61 0.57 0.54 0.50 3.34 1.07 0.40
Inventors 0.60 0.62 0.50 0.55 0.54 0.52 0.49 2.90 1.25 0.47
Total 0.63 0.66 0.54 0.61 0.58 0.57 0.55 3.83 1.03 0.42
</table>
<tableCaption confidence="0.953949">
Table 4: Table 4: Experimental Results of Discourse Level System on the Development Set (Training
with Complete Training Set)
</tableCaption>
<sectionHeader confidence="0.993901" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.805425">
Anja Belz. 2010. GREC Named Entity Generation Challenge 2010: Participants’ Pack.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000575">
<pubnum confidence="0.574423">JU_CSE_GREC10: Named Entity Generation at GREC 2010</pubnum>
<author confidence="0.980209">Tanik Tapabrata Sivaji</author>
<affiliation confidence="0.9245285">Department of Computer Science and Jadavpur</affiliation>
<address confidence="0.962048">Kolkata-700032, India</address>
<abstract confidence="0.932468791666667">This paper presents the experiments carried out at Jadavpur University as part of the participation in the GREC Named Entity Generation Challenge 2010. The Baseline system is based on the SEMCAT, SYNCAT and SYN- FUNC features of REF and REG08-TYPE and CASE features of REFEX elements. The discourse level system is based on the additional positional features: paragraph number, sentence number, word position in the sentence and mention number of a particular named entity in the document. The inclusion of discourse level features has improved the performance of the system. 1 Baseline System The baseline system is based on the following linguistic features of REF elements: SEMCAT (Semantic Category), SYNCAT (Syntactic Category) and SYNFUNC (Syntactic Function) (Anja Belz, 2010) and the following linguistic features of REFEX elements: REG08-TYPE (Entity type) and CASE (Case marker). The baseline system has been separately trained on the training set data for the three domains: chefs, composers and inventors. The system has been tested on each development set by identifying the most probable REFEX element among the possible alternatives based on the REF element feature combination. The probability assigned to a REFEX element corresponding to a certain feature combination of REF element is calculated as follows: N REFEX = N REF v) the probability of the targeted element to be assigned, the total number of occurrences of REF element feature the domain i.e., Chefs, and Inventors and the total number of occurrences of the REFEX element corresponding to the REF feature combination. It has been observed that many times the most probable REFEX element as identified from the training set is not present among the alternative REFEX elements. In these cases the system assigns the next highest probable REFEX element learnt from the training set that matches with one of the REFEX elements among the alternatives. In some cases more than one REFEX element get same probability in the training set. In these cases, the REFEX element that occurs earlier in the alternative set is assigned. The experimental result of Baseline system is reported in Table 1. Chefs Composers Inventors Precision 0.63 0.68 0.70 Recall 0.69 0.60 0.64 F-Measure 0.66 0.64 0.68 Table 1: Result of Baseline System 2 Discourse Level System The discourse level features like paragraph number, sentence number and position of a particular word in a sentence have been added with the features considered in the baseline system. As mentioned in Section 1, more than one REFEX element can have the same probability value. This happens as REFEX elements are identified by two features only REG08-TYPE and CASE. Nam Pro- Com- Empe noun mon ty Chefs 2317 3071 55 646 Composers 2616 4037 92 858 Inventors 1959 2826 75 621 Table 2: Distribution of REFEX Types among three domains. above problem occurs mainly for type. Pronouns are very frequent in all the three domains but they have small number of variations as: he, her, him, himself, his, she, who, and whose. Common type REFEX ele- ) ments are too infrequent in the training set and are very hard to generalize. has only one REFEX value as: “_”. The distribution of the various REFEX types among the three domains in the training set is shown in Table 2. Analysis of entities 2 shows that are very frequent all the three domains. entities are further differentiated by adding more features from the analysis of the element. Firstly, the full name of each named entity has been identified by Entity identification number (id), maximum length among all occurrences of that named entity and case marker as plain. For example, in Figure 1, the REFEX element of id 3 has been chosen as a full name of entity “0” as it has the longest string with case “plain”. After identification of full name of each RE- FEX entity, the following features are identified for each occurrence of an entity:: Complete Name Genitive (CNG), Complete Name (CN), First Name Genitive (FNG), First Name (FN) , Last Name Genitive (LNG), Last Name (LN), Middle Name Genitive (MNG) and Middle Name (MN). These features are binary in nature and for each occurrence of an entity only one of the above features will be true. Pronouns are kept as the REFEX element feature with its surface level pattern as they have only 9 variations. Common types are considered with tag level “common” as they hard to generalize. Empty types are tagged as “empty” as they have only one tag value “_”.</abstract>
<note confidence="0.807947714285714">lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- CNG 1 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;genitive&amp;quot;&gt;Alain Senderens&apos;s&lt;/REFEX&gt; &lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- LNG 2 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;genitive&amp;quot;&gt;Senderens&apos;s&lt;/REFEX&gt; &lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- CN 3 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;plain&amp;quot;&gt;Alain Senderens&lt;/REFEX&gt; &lt;REFEX ENTITY=&amp;quot;0&amp;quot; REG08- LN 4 TYPE=&amp;quot;name&amp;quot; CASE=&amp;quot;plain&amp;quot;&gt;Senderens&lt;/REFEX&gt; Figure 1: Example of Full Name Identification 3 Experimental Results</note>
<abstract confidence="0.990998692307692">The experimental results of the discourse level system on the development set are reported in the Table 3 and Table 4 respectively. Table 3 reports the results when the system has been trained separately with domain specific training set and Table 4 reports the results when the training has been carried out on the complete training set. The comparison of the results of the baseline and the discourse level system shows an overall improvement. But there are some interesting observations when comparing the results in Table 3 and Table 4. Currently detailed analyses of the results are being carried out.</abstract>
<note confidence="0.708492666666667">Chefs Composers Inventors P R F P R F P R F Name 0.69 0.74 0.71 0.78 0.61 0.69 0.77 0.67 0.71 Pronoun 0.81 0.76 0.79 0.70 0.84 0.76 0.76 0.87 0.81 Common 0.76 0.87 0.81 0.37 0.44 0.40 0.44 0.65 0.68 Empty 0.92 0.88 0.90 0.86 0.92 0.89 0.72 0.65 0.68</note>
<title confidence="0.9481612">Table 3: Experimental Results of Discourse Level System on the Development Set (Training Domain Specific Training Set) Reg08 Type Accuracy BLEU NIST String Distance Precision Recall</title>
<author confidence="0.95137">Mean Normalized</author>
<note confidence="0.682808888888889">1 2 3 4 Chefs 0.66 0.70 0.57 0.68 0.70 0.76 0.81 3.70 0.77 0.38 Composers 0.63 0.67 0.56 0.61 0.57 0.54 0.50 3.34 1.07 0.40 Inventors 0.60 0.62 0.50 0.55 0.54 0.52 0.49 2.90 1.25 0.47 Total 0.63 0.66 0.54 0.61 0.58 0.57 0.55 3.83 1.03 0.42 Table 4: Table 4: Experimental Results of Discourse Level System on the Development Set (Training with Complete Training Set) References Anja Belz. 2010. GREC Named Entity Generation Challenge 2010: Participants’ Pack.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<date>2010</date>
<journal>GREC Named Entity Generation Challenge</journal>
<note>Participants’ Pack.</note>
<contexts>
<context position="1100" citStr="Belz, 2010" startWordPosition="154" endWordPosition="155">m is based on the SEMCAT, SYNCAT and SYNFUNC features of REF and REG08-TYPE and CASE features of REFEX elements. The discourse level system is based on the additional positional features: paragraph number, sentence number, word position in the sentence and mention number of a particular named entity in the document. The inclusion of discourse level features has improved the performance of the system. 1 Baseline System The baseline system is based on the following linguistic features of REF elements: SEMCAT (Semantic Category), SYNCAT (Syntactic Category) and SYNFUNC (Syntactic Function) (Anja Belz, 2010) and the following linguistic features of REFEX elements: REG08-TYPE (Entity type) and CASE (Case marker). The baseline system has been separately trained on the training set data for the three domains: chefs, composers and inventors. The system has been tested on each development set by identifying the most probable REFEX element among the possible alternatives based on the REF element feature combination. The probability assigned to a REFEX element corresponding to a certain feature combination of REF element is calculated as follows: Di N REFEX = Di N REF where p(R v ) is the probability of</context>
</contexts>
<marker>Belz, 2010</marker>
<rawString> Anja Belz. 2010. GREC Named Entity Generation Challenge 2010: Participants’ Pack.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>