<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.9894645">
An Integrated Development Environment for Spoken Dialogue
Systems
</title>
<author confidence="0.968287">
Matthias Denecke
</author>
<affiliation confidence="0.966908333333333">
Human Computer Interaction Institute
School of Computer Science
Carnegie Mellon University
</affiliation>
<email confidence="0.795055">
deneckeAcs.cmu.edu
</email>
<sectionHeader confidence="0.988421" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995006">
Development environments for spoken dialogue pro-
cessing systems are of particular interest because the
turn-around time for a dialogue system is high while
at the same time a considerable amount of compo-
nents can be reused with little or no modifications.
We describe an Integrated Development Environ-
ment (IDE) for spoken dialogue systems. The IDE
allows application designers to interactively specify
reusable building blocks called dialogue packages for
dialogue systems. Each dialogue package consists
of an assembly of data sources, including an object-
oriented domain model, a task model and grammars.
We show how the dialogue packages can be specified
through a graphical user interface with the help of a
wizard.
</bodyText>
<sectionHeader confidence="0.998518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988807655172415">
The specification and design of interactive spoken
language systems has become the focus of research
recently. Partly fueled by the increasing demand of
spoken language applications and telephony-based
services, the deployment of development environ-
ments has increased. At the time of writing, at
least three main types of dialogue tools can be dis-
tinguished. One approach to development environ-
ments consists of graphical editors for Finite State
Automata (FSA) [Sutton et al, 1996], [Cole, 1999].
These systems equate a dialogue with a possible path
from the start state to one of the accepting states.
Possible actions of the application are specified by
annotations on states or arcs or both. Besides rely-
ing on a dialogue model that has been considered as
problematic in the past, finite-state automata based
dialogue editors do not exploit the desirable charac-
teristics of software engineering, such as reusability
and orthogonality of the components. For example,
recovery strategies need to be duplicated for each
state in which they should be applied. Moreover,
they require a system designer to anticipate every
single possible path through the system, a fact that
leads to an explosion of dialogue states.
Another approach to development environments
emphasizes reusability of the domain model over
graphical design interfaces. Here, object-oriented
features of the underlying programming language
such as JAVA or C++ are used to design a class
hierarchy of speech objects or dialogue modules that
can be assembled and re-assembled for new applica-
tions. These modules are often used for basic data
types, such as date, time, credit card numbers, etc.
This approach has proven its practicability in nu-
merous commercial applications. Since the modules
can be reused, this is an improvement over finite-
state based dialogue machines. However, fine tuning
of recovery strategies requires separate fine-tuning in
each module. Moreover, the dialogue flow is partly
defined by an FSA whose nodes consist of the dia-
logue modules. When a node is reached, the dialogue
module determines the dialogue control until it gives
up control and an adjacent arc is traversed.
A third approach consists in designing a library
of reusable dialogue strategies based on the observa-
tion that the behavior of a dialogue manager should
be predictable in similar situations across several do-
mains. Araki et al [Araki et al, 1999] proposed a li-
brary of dialogue strategies to be reused. Koelzer
[Koelzer, 1999] proposed a reusable dialogue sys-
tem architecture based on specifications of knowl-
edge sources for the different components.
In this paper, we identify knowledge sources such
as grammars, task models and database conversion
rules, that characterize our dialogue manager for a
given application. Each of the knowledge sources
can be composed of smaller, modular knowledge
sources. A collection of these knowledge source mod-
ules, called a dialogue package, specifies a subdo-
main of a dialogue application. We borrow tech-
niques known from object oriented programming
languages to combine partial specifications of knowl-
edge sources to form the knowledge sources for a new
application. The specifications are mostly declara-
tive rather than procedural, leaving to the dialogue
manager the decision how best to interpret them in
the context of the dialogue. We describe the im-
plementation of a wizard-based integrated develop-
ment environment called Chapeau Clac that allows
the specification of the knowledge sources, their in-
tegration and testing.
2 The Architecture of the IDE and
the Dialogue System
2.1 The Architecture of the Dialogue
System
The dialogue manager makes use of different knowl-
edge sources. First, it contains a set of task de-
scriptions or task models. A task description can
be considered as a form to be filled in through the
dialogue, together with constraints stating the mini-
mum amount of information necessary to execute the
task. The dialogue strategy is specified in a declara-
tive programming language similar to PROLOG that
can be easily adapted to the task at hand should the
need arise.
The state of the dialogue system at any given time
is determined implicitly by the relations of the forms
with the information available in the discourse at
that time. For example, a task description whose
constraints are inconsistent with information in the
discourse can not be a description of the intent of
the user. The elements the forms can be populated
with are descriptions of objects, actions and prop-
erties of objects and actions drawn from a domain
model. The domain model can loosely be compared
to a class hierarchy in object oriented programming
languages. In addition to task model and domain
model, the dialogue manager uses data base conver-
sion rules to generate SQL queries and to transform
the result sets. As the domain model is dependent
on the particular speech application, it belongs to
the knowledge sources to be specified through the
wizard.
As the semantics of the utterances are expressed
in terms of the domain model, we need to provide
a mechanism to translate the text input from the
speech recognizer into a canonical representation.
Attributed grammar rules provide transformation
between text input and semantic representations.
The place of the dialogue manager in the system
is similar in spirit to, but different in functionality
from, the design of a Graphical User Interface for a
back-end application. In the case of the GUI, the
design of windows, dialog boxes and menus is inde-
pendent from the design of the back-end application
that uses these graphical display elements. Simi-
larly, in our approach, the design of dialogue gram-
mars, dialogue goals and domain models is indepen-
dent of the design of the back-end application. As
in GUIs, the back-end application is notified of ma-
nipulations through events and callback functions.
This approach separates clearly the speech user in-
terface from the back-end application. The call-
backs and events constitute one integration point
between speech user interface and back-end appli-
cation whose form and content needs to be specified
for each new speech application.
It should be noted, however, that the analogy be-
tween graphical and speech user interfaces ends here.
Reference in GUIs is extensional. For example, the
click of the button or a menu, together with the state
of the application and the focus, determines the in-
tended action. In spoken dialogue systems, the need
to resolve reference of noun phrases or ellipsis forces
us to provide one more integration point with the
back-end application in order to allow database re-
trieval.
Consequently, we argue that a dialogue manager
for a given speech application can be character-
ized by the specification of four knowledge sources,
namely (i) the domain model to characterize the se-
mantic content of the utterances, (ii) the conversion
from the text input into a canonical semantic rep-
resentation and vice versa, (iii) the task model to
describe the event stream from the speech user in-
terface to the back-end application, and (iv) the con-
version from semantic representation into database
retrieval requests. Figure 1 shows the place of the
knowledge sources in the dialogue manager. As can
be seen, the knowledge sources (ii) to (iv) encapsu-
late entirely the dialogue manager from the remain-
ing components of the system.
Note that we make no assumptions as to how the
dialogue manager might make use of these knowl-
edge sources. In particular, we do not make any as-
sumptions as to how the dialogue strategy might de-
termine the actions of the dialogue manager. As long
as the provided knowledge sources are sufficient for
the dialogue manager to determine its actions, the
dialogue manager could implement a simple informa-
tion seeking dialogue system or a more sophisticated
system based on speech act or discourse theories.
All four knowledge sources can be modularized
more or less straightforwardly. The domain model
can be composed of different subdomain [Denecke
and Waibel, 1999]; new concepts may use multiple
inheritance of abstract base types. Grammar rules
containing generic semantic information can be spe-
cialized and adapted to the given domain. Database
conversion and dialogue goal specification modules
may simply be joined; but see section 6 for poten-
tial problems. It is the task of the wizard to help
the user in specifying and reusing these knowledge
sources.
</bodyText>
<subsectionHeader confidence="0.827881">
2.2 Requirements for the IDE
</subsectionHeader>
<bodyText confidence="0.995034375">
The requirements for the IDE&apos;s functionality com-
prise three main items. First, it should guide the
application designer to specify and modify the spo-
ken language part of an entire application through a
GUI. The data sources relevant for the spoken lan-
guage interface currently include grammars, domain
model, data bases, task model and input/output
channels. Moreover, conversions back and forth
</bodyText>
<figure confidence="0.953869246376812">
Domain model
root
consists
consists
Speech Recpgnizer
Text toSpeech
action
of
property object
of
...
...
Dialogue Package
Dialogue Goals
consists
consists
of
of
Grammar rules
Conversion rules
reservation
DATE : date
NAME : name
Base Package
Dialogue System Application
Grammar
Database query
Conversion rules
consists
consists
of
of
[obj] -&gt; [obj] with [obj]
... ... ...
Dialogue
Manager
Conversion rules
Back-end
application
parse tree -&gt; fs
fs -&gt; text
fs -&gt; db request
result set -&gt; fs
Dialogue goals
Domain model
Text Files
modifies
Text
Editor
Dialogue Package Desc.
Dialogue Application
Conv Descriptions
Grammar Descr.
Wizard
Dialogue Package
modifies
creates
Goal Descriptions
Class Descriptions
Conversions
Grammar
Goals
Classes
end application, we introduce a method
obj_buyable.calcprice : real x set(real) x real
with the constraints
obj_buyable.baseprice real,
obj_buyable.ingredients.{baseprice} real,
obj _buyable.price real
</figure>
<bodyText confidence="0.999870083333333">
As soon as an obj_buyable whose values of the
BASEPRICE features is defined appears in the dis-
course, all values are passed on to the back-end ap-
plication. It is the task of the back-end applica-
tion to determine the price of the dish and to return
the result in the third argument of the method de-
scription. Since the third argument is described by
the constraint obj_buyable.price &gt; real (a constraint
that is always satisfied due to the feature definition),
the dialogue manager places the result returned from
the back-end application at the appropriate place in
the feature structure.
</bodyText>
<subsectionHeader confidence="0.995043">
3.2 The Dialogue Goal Specifications
</subsectionHeader>
<bodyText confidence="0.992388341463415">
The application designer needs to design a descrip-
tion of a dialogue goal for each task the back-end
system can execute. A dialogue goal can be consid-
ered as the description of a form that is filled out
through the spoken dialogue with the system [Pa-
pineni et al, 1999]. The goal description consists
of a typed feature structure [Carpenter, 1992] whose
types are drawn from the class hierarchy designed in
step 3.1. It serves as an informational lower bound,
guaranteeing that the back-end application is noti-
fied if and only if the information acquired through
the dialogue is at least as specific as the specification
in the dialogue goal.
Note that the dialogue goal specification does not
make any assumptions as to how this information
is acquired, nor as to how the acquired information
is to be processed. Thus, the dialogue goals form
the specification of a task model that is orthogonal
to any dialogue strategy specification and indepen-
dent from the implementation of the back-end sys-
tem. Furthermore, it should be noted that the spec-
ification of dialogue goals in typed feature structures
does not restrict the dialogue strategy to be a sim-
ple form filling strategy. Rather, the dialogue goal
specification is an encapsulation of a method invo-
cation which, when triggered, causes the back-end
application to do what the user intended the system
to do. The assumptions made here are similar to
those in the general PARADISE framework [Walker
et al, 1997] for dialogue evaluation where the task
model for dialogue managers is equally described in
attribute value matrices.
Example (continued)
We continue the fast food service example. We con-
centrate on the dialogue goals relevant to the pizza
and pasta objects, as we assume that we have re-
course to a dialogue package Shopping Cart that de-
fines the knowledge sources relevant to the virtual
shopping list. We thus need to introduce only one
dialogue goal, namely the one allowing the user to
seek information on the buyable objects.
</bodyText>
<subsectionHeader confidence="0.998437">
3.3 The Grammar Specification
</subsectionHeader>
<bodyText confidence="0.994697642857143">
It is the task of the grammar specification to map
an utterance onto a feature structure. We use the
robust spoken language parser described in [Gavalda
and Waibel, 1998] for context free parsing. In addi-
tion to the grammar rule specification, a set of con-
version rules needs to be created to declare the way
a parse tree is mapped onto a semantic representa-
tion. A parse tree generated by this parser contains
semantic concepts as nonterminal symbols.
Grammar rules can be either lexical rules, i.e.
rules whose right hand side consists entirely of lex-
ical entries, or phrasal rules, i.e. rules whose right
hand side consists entirely of nonterminal symbols.
A grammar nonterminal symbol consists of three
part (sem, synmai , synmin ) where sem is a type
drawn from the type hierarchy, synmai is the name
of the major syntactic category, currently one of
N,V,A or their phrasal projections NP,AP,VP,
and synmin is the name of their minor syntactic
category. Minor categories depend on the major
categories. For example, minor categories for ad-
jectives are predicative, comparative and superla-
tive. The purpose of separating syntactic and se-
mantic information in the nonterminal symbols is
threefold. First, it allows the technique of multi-
ple inheritance to be applied during grammar de-
sign and parsing. For example, a nonterminal sym-
bol (sem, synmai , synmin ) might be expanded by a
rule with a left hand symbol (sem&apos;, synmai , synmin),
provided that sem subsumes sem&apos; in the type hier-
archy. Second, it provides more information to com-
pare nonterminal symbols during parsing than plain
slot names. Third, the semantic information is help-
ful in ensuring the semantic constructions associated
with the grammar rules is well-typed. Please refer
to [Denecke, 2000] for more information on the first
two points. In this paper, we will concentrate on
the third point as it is relevant to the design of the
wizard interface.
As the syntactic structure of the input sentences
might vary, it is not sufficient to rely on the names
of the concept to extract the meaning of the utter-
ances. Rather, we pursue an approach that is re-
sembles the one found in attributed grammars used
in compiler construction or Montague grammars in
that the grammar rules contain an annotation de-
scribing how to construct the semantics. Consider a
rule
(sem, syr,, sywno,) (semi, synrni synrni
(sere, syn3, syn)
for an expression describing an object of type
sem. We assume by induction that the con-
stituents described by (sem , syn&apos;m. ai , syn&apos;m. in) are
expressions describing objects of type semi. As the
semantic representation of the phrases covered by
(sem, synmai , synmin) needs to be a feature struc-
ture of type sem, all that remains. to be done is to
define n feature paths 7&apos; = . . .f for each of the
right hand symbols such that sem.7ri is allowable
according to the type hierarchy specification and
sem.7 takes a value that is compatible with sem&apos; .
This sort of type information restricts the number of
possible feature paths. Only allowable feature paths
are offered through the wizard interface so as to en-
sure that the resulting structures correspond to the
domain model.
As an application designer sets out to develop a
new application, he can take recourse to a base ontol-
ogy and a base grammar. We make the assumptions
that the base grammar and the base ontology al-
ready cover a wide variety of surface forms of the
input sentences. The application designer simply
needs to provide the lexical rules and to specialize
existing generic rules. The nonterminals in the base
grammar do not contain any domain-specific seman-
tic information, but only rather general information
such as object, or location. It is then only necessary
for the application designer to specialize the prede-
fined rules and to provide the &amp;quot;ontological&amp;quot; part of
the grammar.
Robust Parsing
The fact that syntactic and semantic information are
represented separately in the nonterminal symbols
enables a more fine grained comparison of nontermi-
nal symbols. This can be exploited for robust pars-
ing. For example, two symbols differing only in their
minor syntactic category could be matched, with an
appropriate penalty, to allow for robust parsing. At
the time of writing, a standard context free gram-
mar to be used in the parser is created from the
rule specifications. Additional rules covering close
matches are created for robustness.
The well-typed constraint imposed on the rules by
the conversion information does not render the pars-
ing more brittle as robustness is achieved by loosely
matching the input and by a fuzzy matching of non-
terminal symbols. The form of the rules can be ex-
pected to be unaltered.
</bodyText>
<subsectionHeader confidence="0.569292">
Clarification Questions
</subsectionHeader>
<bodyText confidence="0.969035466666667">
The need to generate a clarification question arises
in the case of ambiguous reference. The dialogue
manager determines discriminating information of a
set of representations using a technique described in
[Denecke and Waibel, 1997]. As the grammar rules
contain syntactic and semantic information, they are
reversible to a limited extent. Thus, the rules can
be used to generate phrases describing the discrimi-
nating information.
Example (continued)
In the fast food application, phrases such as a pizza
with salami or tortellini with cream sauce need to be
covered. The generic grammar provides an abstract
rule of the form (obj, IV) (obj, N)(p, with)(obj, IV)
which is specialized to
</bodyText>
<equation confidence="0.97457825">
(obj_pizza, N)
(obj _pizza, N)(p, with)(obj _topping, IV) and
(obj _pasta, N)
(obj _pasta, N)(p, with)(obj _sauce, IV)
</equation>
<bodyText confidence="0.999563357142857">
respectively (minor categories are omitted for clar-
ity). Each nonterminal symbol on the right hand
side is assigned a part of the resulting semantic rep-
resentation. The first right hand symbol gets as-
signed an empty feature path, since its relation to
the left hand symbol relation needs to be an is — a
relation. The semantics of the second nonterminal
symbol is ignored. We concentrate on the third
nonterminal symbol in both rules. In this exam-
ple, TOPPINGS and SAUCE, respectively, are the only
feature paths that express an is — part — of relation
between obj_pizza and obj _topping s, and obj _pasta
and obj _sauce, respectively. This yields the follow-
ing annotated rules.
</bodyText>
<equation confidence="0.938975555555556">
(obj _pizza, N)
(obj_pizza, IV) [obj _piz za]
(p, with)
(obj _topping, IV) [obj_pizza TOP&apos;S obj _topping]
and
(obj _pasta, N)
(obj _pasta, IV) [obj _pasta]
(p, with)
(obj _sauce, IV) [obj _pasta SAUCE obj _sauce]
</equation>
<bodyText confidence="0.999976">
The type information serves to restrict the number
of admissible feature paths for the semantic con-
struction. Only admissible feature paths are offered
as choices in the wizard, thus reducing the burden on
the grammar designer. Had the designer erroneously
specialized the abstract rule to
</bodyText>
<equation confidence="0.4698075">
(obj_pizza, N)
(obj_pizza, N)(p, with)(obj _sauce, IV)
</equation>
<bodyText confidence="0.9932965">
the wizard would not be able to offer any consis-
tent semantic interpretation, thus uncovering incon-
sistencies in the specification early in the design pro-
cess.
</bodyText>
<subsectionHeader confidence="0.440391">
3.4 The Database Access Conversion Rules
</subsectionHeader>
<bodyText confidence="0.999959658536585">
The IDE provides an interface to SQL databases.
The tables of SQL databases are self-describing in
that the form, the datatypes and the relations be-
tween the tables can be determined at run-time. If
the user wishes to create a new database for some
of the objects specified in step 3.1, then the cor-
responding SQL data definition query is generated
from the domain model automatically. In this case,
there is a one-to-one relationship between a type de-
scription and a table, and conversion rules are cre-
ated automatically. However, it is more probable
that application designers are faced with the design
requirement that existing databases be reused. In
this case, the wizard interface allows the user to es-
tablish a conversion between features and entries in
tables. Please note that in this case there is not nec-
essarily a one-to-one correspondence between type
descriptions and tables. Here, the databases con-
sist typically of multiple tables T that are linked via
primary keys E.
The dialogue strategy executes database requests
at appropriate times during the dialogue with the
goal being to fill in missing feature values. It is
then the responsibility of the database manager to
determine the database that needs to be queried
and to generate the query itself based on the in-
formation available. This is done in the following
manner. First, by examining the partly filled form
and scanning the conversion rules, the set of tables
, , t E Ti for which keys are given are deter-
mined. Then, we need to obtain all pairs of pri-
mary keys that establish the links between the ta-
bles in T1. However, a link between two tables can
be given through a chain of tables not all of which
need to be in T1. Thus, we need to determine the set
E T2 of all tables involved in the query by
calculating a minimal subtree (T2, E2) of the graph
(T, E) that spans over all tables from T1. The infor-
mation in T1, T2 and E2 together with the partially
filled form is then sufficient to arrive at a query of
the form
</bodyText>
<equation confidence="0.970483125">
SELECT
,
t2m.ei, • • • , t2m.er,_
FROM
WHERE
t.ei = Vi AND
r tep VpAND
t.ek r;.e/Axe VW .61) E E2
</equation>
<bodyText confidence="0.9745339">
where the v, are the values provided by the partly
filled form. The result set returned from the query
engine is then converted back to feature structures
corresponding to the domain model. There exist ad-
ditional constraints on the size of the result set that
are verified before converting in order to avoid time
consuming conversion operations in the case of large
result sets.
Example (continued)
In the fast food application, the data is stored
in four tables, namely piz za, pasta, sauces and
toppings. The tables are assigned to the types
obj _piz za, obj _pasta, ob j _sauces and obj _toppings in
the same order; additional assignments exist be-
tween feature names and table entries. The tables
pizza and toppings, and pasta and sauces, respec-
tively, are linked in the database through unique IDs.
As the relationships between the tables is is-part-of,
the links are assigned the path prefixes SAUCES and
TOPPINGS. A feature structure
</bodyText>
<equation confidence="0.6935365">
obj_pasta
SAUCE obj_cheesesauce
is then converted to the query
SELECT
pasta.name, pasta.baseprice, pasta.size,
sauces.name, sauces.baseprice
FROM pasta, sauces
WHERE
sauces = cheesesauceAND
pasta.I D = sauce.I D
</equation>
<bodyText confidence="0.996616142857143">
Using the same conversion rules backwards, un-
derspecified feature structures are constructed from
the resulting table. Note that the database
as a relational database cannot express inheri-
tance relationships. This means that although
tortellini, greennoodles and spaghetti all are de-
rived from pasta, a query containing the constraint
pasta.name = &amp;quot;pasta&amp;quot; would return the empty set,
as the database does not know about the inheri-
tance relationships. For this reason, the conversion
rules associated with the table entries also contain
a type restricting the constraint generation. Only
types that are more specific than the restriction are
taken into consideration for query generation. In
this example, the types taken into consideration for
query generation would need to be more specific
than ob j _pasta. This is to ensure extensionality for
database access. Alternatively, one could employ
extensional feature structures as described by Car-
penter [Carpenter, 1992] and make sure that only
extensional types are used for queries.
</bodyText>
<subsectionHeader confidence="0.897709">
3.5 Interfacing the Wizard with the
Knowledge Sources
</subsectionHeader>
<bodyText confidence="0.999960333333333">
A wizard-style GUI guides the application designer
through the design process of the dialogue package.
The knowledge sources are introduced in the order in
which they are described in this section. The result
of the process is a prototypical system that needs
to be refined interactively using test sets. Figure 4
shows a screenshot of the wizard in step 1 at the
point of specifying the domain model.
In order to abstract over different input and out-
put modalities, the dialogue system contains an en-
tity to maintain input and output channels. For each
channel, there is a channel specification that allows
</bodyText>
<note confidence="0.3311505">
Neutral Selected Determined Finalized
Deselected
</note>
<figureCaption confidence="0.705523">
Figure 5: State transitions of the dialogue goals
</figureCaption>
<figure confidence="0.983778277777778">
Add Data Member __
hotelreseryation x FROM -&gt; date
hotelre,eryation x NAuP
hotelreseryabon x TO
Ele Edit Vi Project Build Test Window Help
ID°&apos;-&apos;611.X. elCriu&apos;rf&apos;lk?vl
prn
j 3 generic dlm
a input dlm
Log• He
Batch tests
a map dlm
I
El bo
Please specify the new description.
hajaka,atyaiien Description lholelre,ervation
reseryaben
restauranitesewati inherits from &apos;reservation
Add
Add
with data
I.
lease add a detainer&amp; r to your new class
.D objectE,J. —Data Member
aO!&gt; Name IPLSCENR E
3 meta_actic
OBJECT Value &apos;string
: texImput
D gestureoP
PE INPUT
&apos; !I, SOURCE
.0
D
a d method, I venlyDates date x c
Add I
Can
</figure>
<figureCaption confidence="0.973638875">
Figure 4: The wizard in action. Currently, a class
hotelreservation is being specified. The list boxes
in the larger dialog box display the base class, the
member variables and the methods associated with
the class. A new member variable is being added
through the smaller dialog box in the foreground.
The tree-shaped interface item provides a view on
the domain model.
</figureCaption>
<bodyText confidence="0.956197142857143">
to transform an array of strings into a feature struc-
ture (for an input channel) or a feature structure into
an array of strings (for an output channel). Input
and output devices communicate with the dialogue
system only through these channels. The intention
of this approach is it to abstract away the particu-
lar form of input and output events, thus achieving
modularity and extensibility.
4 Debugging of the Dialogue
Strategy
The dialogue manager is driven by a PROLOG style
program which contains the dialogue strategy. As
long as a user is engaged with the system in a dia-
logue, it is then the task of the dialogue system
</bodyText>
<listItem confidence="0.934291375">
1. to determine if the user intends to have the sys-
tem perform one of the tasks known to the sys-
tem, and if so,
2. to interactively acquire all the information that
is needed for the system to uniquely determine
the task to be executed and all its parameters,
and
3. finally to notify and pass control to the subsys-
</listItem>
<bodyText confidence="0.980167387096774">
tem responsible for the task execution once this
state has been reached.
For that purpose, each task description has an in-
ternal state that can take one of the following values:
NEUTRAL, SELECTED, DESELECTED, DETERMINED
and FINALIZED. The state transitions are as shown
in figure 5. Each state transition is passed on to
the implementation of the dialogue package in the
back-end application which may or may not choose
to make use of this information.
The state of the dialogue system is implicitly rep-
resented by the vector of dialogue goal states. The
states of the dialogue goals are updated by a set of
rules that compare the representations of the utter-
ances with the representations in the dialogue goals.
The state of a goal incompatible with the current
representation becomes DESELECTED. A goal in the
state SELECTED becomes DETERMINED as soon as
it is the only goal in the SELECTED state. A DE-
TERMINED goal becomes FINALIZED as soon as the
information acquired in the dialogue is at least as
specific as it is required by the goal.
There is a generic dialogue strategy that serves as
a starting point for system development. As possible
domains may be very distinct, it becomes necessary
to adapt the strategy to the domain at hand. For
this reason, the IDE offers an interactive debugger
interface to the rule program. It allows for single
step execution, display of call stacks and variable
substitutions as well as a direct query interface to
evaluate the effects of single rules.
</bodyText>
<sectionHeader confidence="0.991894" genericHeader="introduction">
5 Testing
</sectionHeader>
<bodyText confidence="0.9984005">
The cycle of grammar maintenance, testing and eval-
uation is a tedious and time consuming part of the
development of a new application. The IDE offers a
set of utilities simplifying the task.
</bodyText>
<subsectionHeader confidence="0.9880365">
5.1 Batch Testing
Grammar Testing
</subsectionHeader>
<bodyText confidence="0.996619148148148">
The IDE offers a tool for batch testing of grammar
coverage. Here, a text string is passed through the
semantic parser and conversion routine. The result-
ing feature structure is then presented graphically to
the user. The designer is then prompted to evaluate
the semantic representation of the utterance. Cur-
rent choices are those defined by the partial order
of feature structures. In other words, the system&apos;s
designer can specify if the semantic content contains
information that is equal to, less specific than, more
specific than or inconsistent with the information
the sentence conveys. The text string, the feature
structure and the evaluation are then automatically
entered to the batch test set. The system designer
can then run this batch test set later in the devel-
opment process and receive notification should the
resulting feature structures differ in informational
content. This procedure assumes, however, that the
domain model is not changed between the tests. Al-
ternatively, the system designer can enter the desired
feature structure directly.
Testing for Goal State Transitions
In addition to the grammar coverage batch test,
there is a dialogue goal batch test. As mentioned
above, the state of the dialogue manager is implic-
itly described by the vector of goal states. Each
utterance is assumed to represent a speech act that
performs a state transition in some of the dialogue
goals. Here, we store together with the utterance
two vectors of dialogue goal states: before the utter-
ance has been processed and after the utterance has
been processed. During batch testing, the dialogue
goals are set to the states specified in the first vec-
tor. Subsequently, the utterance is passed through
the dialogue system. Then the actual goal states af-
ter processing of the utterance are compared with
those in the batch test and differences are prompted
to the application designer.
Testing for Orthogonality between Modules
Testing for dialogue goal state transitions requires
the configuration of dialogue packages to be constant
between tests. However, there are several utterances
whose meaning can unambiguously be attributed to
one dialogue package. For this reason, the IDE of-
fers an additional batch test. Here, the utterances
are assigned a dialogue package as well as vectors of
goal states. In contrast to the state transition test,
we only represent goal states from dialogue goals in
the package in question. As above, the application
developer is notified if the desired goal configuration
in the package differs from the calculated one. More-
over, any goals not in the assigned dialogue package
whose state differs from DESELECTED are displayed
to the user.
</bodyText>
<subsectionHeader confidence="0.995308">
5.2 Dialogue Goal Activation and WOZ
</subsectionHeader>
<bodyText confidence="0.999978928571428">
Since the IDE contains a detailed description of
the dialogue goals, it is possible to present the di-
alogue goals to the application designer in form that
needs to be filled in through the standard graphi-
cal user interface rather than through speech. Once
the back-end application is in place, the application
designer may proceed to test the interface of the di-
alogue system with the back-end application. An-
other possibility would be to use this feature as a
poor man&apos;s Wizard of Oz interface, in which case
only the domain model and the task model need to
be in place (although additional support from the
database would be desirable). This feature is cur-
rently under development.
</bodyText>
<sectionHeader confidence="0.998589" genericHeader="background">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999997044444444">
We are currently using the described system to pro-
totype two spoken language applications. While it is
too early to arrive at any conclusive results, our pre-
liminary experience shows that a substantial amount
of time is saved simply by using the wizard to avoid
formatting errors and typographic errors in the sev-
eral specification files. Moreover, as the wizard dis-
plays the options available for the user to choose
from, it is easier to arrive at consistent specifications.
This is particularly true in the instances where type
information from the domain model can be used to
reduce the number of options.
Another characteristic of the system is its inte-
grated architecture. The entire system runs as a
single thread in a single process. Comparing to an
earlier version of the system in which a client/server
architecture was employed, we find debugging and
testing easier.
From a domain model perspective, the dialogue
packages as a primary building block offer a coarse
granularity compared to dialogue states, speech ob-
jects or dialogue libraries. We feel it is for this reason
more comprehensive. Whether this characteristic is
of benefit and whether the specifications in the dif-
ferent packages are sufficiently orthogonal to not in-
teract when building the final system remains to be
seen.
Although the specifications of knowledge sources
in separate modules can be independent of each
other, undesired interaction may not be excluded.
In particular, the informational content of the dia-
logue goal specifications need pairwise inconsistent.
The reason is that the dialogue manager bases its de-
cision on the compatibility of the dialogue goals with
the information in the discourse. If one dialogue goal
were less specific than another, the second dialogue
goal could never be reached as the first is satisfied
first. For this reason, the dialogue manager checks
for pairwise inconsistency of the goals at runtime.
Future work includes the integration of a speech
recognizer directly into the development environ-
ment and improvements of the graphical user in-
terface to speed up the design process. These im-
provements can only be made by experiences gained
through continuous use of the wizard.
</bodyText>
<sectionHeader confidence="0.991351" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998136666666667">
This research is supported by the Defense Advanced
Research Projects Agency under contract number
DAAD17-99-C-0061. Any opinions, findings and
conclusions or recommendations expressed in this
material are those of the author and do not neces-
sarily reflect the views of the DARPA, or any other
party. I would like to thank the members of the dia-
logue working group in the DARPA Command Post
of the Future project for valuable discussions.
</bodyText>
<sectionHeader confidence="0.997909" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999783346938776">
M. Araki, K. Komatani, T. Hirata and S.
Doshita. A Dialogue Library for Task-Oriented
Spoken Dialogue Systems Workshop on Knowl-
edge and Reasoning in Practical Dialogue Sys-
tems. Stockholm, Sweden, 1999. Available from
http://www.ida.liu.se/ext/etai.
B. Carpenter. The Logic of Typed Feature Struc-
tures. Cambridge University Press, 1992.
R. Cole. Tools for Research and Education in Speech
Science. Proceedings of the International Confer-
ence of Phonetic Sciences, San Francisco, USA,
1999.
M. Denecke and A. Waibel, Dialogue Strategies
Guiding Users to Their Communicative Goals.
Proceedings of Eurospeech, Rhodos, Greece,1997.
Available from http://www.is.cs.cmu.edu.
M. Denecke and A.H. Waibel, Integrating
Knowledge Sources for a Task-Oriented Di-
alogue System. Workshop on Knowledge
and Reasoning in Practical Dialogue Sys-
tems, Stockholm, Sweden,1999 Available from
http://www.is.cs.cmu.edu.
M. Denecke. Modularity in Grammar and On-
tology Specification. Proceedings of the MSC
2000 Workshop, Kyoto, 2000. Available from
http://www.is.cs.cmu.edu.
M. GayaIda and A. Waibel. Growing Seman-
tic Grammars. Proceedings of the COL-
ING/ACL, Montreal, Canada. Available from
http://www.is.cs.cmu.edu.
Anke Koelzer. Universal Dialogue Specification for
Conversational Systems Workshop on Knowl-
edge and Reasoning in Practical Dialogue Sys-
tems. Stockholm, Sweden, 1999. Available from
http://www.ida.liu.se/ext/etai.
K.A. Papineni, S. Roukos and R.T. Ward. Free-Flow
Dialogue Management Using Forms. Proceedings
of EUROSPEECH 99, Budapest, Ungarn, 1999.
S. Sutton, D. G. Novick, R. A. Cole, and M. Fanty.
Building 10,000 spoken-dialogue systems. Pro-
ceedings of the International Conference on Spo-
ken Language Processing, Philadelphia, PA, Oc-
tober 1996.
Walker, M.A. and Litman, D.J. and Kamm, C.A.
and AbeIla, A. PARADISE: A Framework for
Evaluating Spoken Dialogue Agents Proceedings
of the 35th Annual Meeting of the Association of
Computational Linguistics, 1997. Available from
http://www.research.att.com/ walker.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.875158">
<title confidence="0.9996805">An Integrated Development Environment for Spoken Dialogue Systems</title>
<author confidence="0.955149">Matthias</author>
<affiliation confidence="0.992608333333333">Human Computer Interaction School of Computer Carnegie Mellon</affiliation>
<email confidence="0.999264">deneckeAcs.cmu.edu</email>
<abstract confidence="0.9954146875">Development environments for spoken dialogue processing systems are of particular interest because the turn-around time for a dialogue system is high while at the same time a considerable amount of components can be reused with little or no modifications. We describe an Integrated Development Environment (IDE) for spoken dialogue systems. The IDE allows application designers to interactively specify building blocks called packages dialogue systems. Each dialogue package consists of an assembly of data sources, including an objectoriented domain model, a task model and grammars. We show how the dialogue packages can be specified through a graphical user interface with the help of a wizard.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>M Araki</author>
<author>K Komatani</author>
<author>T Hirata</author>
<author>S Doshita</author>
</authors>
<booktitle>A Dialogue Library for Task-Oriented Spoken Dialogue Systems Workshop on Knowledge and Reasoning in Practical Dialogue Sys-</booktitle>
<marker>Araki, Komatani, Hirata, Doshita, </marker>
<rawString>M. Araki, K. Komatani, T. Hirata and S. Doshita. A Dialogue Library for Task-Oriented Spoken Dialogue Systems Workshop on Knowledge and Reasoning in Practical Dialogue Sys-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stockholm</author>
</authors>
<date>1999</date>
<note>Available from http://www.ida.liu.se/ext/etai.</note>
<marker>Stockholm, 1999</marker>
<rawString>tems. Stockholm, Sweden, 1999. Available from http://www.ida.liu.se/ext/etai.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="11702" citStr="Carpenter, 1992" startWordPosition="1853" endWordPosition="1854">traint obj_buyable.price &gt; real (a constraint that is always satisfied due to the feature definition), the dialogue manager places the result returned from the back-end application at the appropriate place in the feature structure. 3.2 The Dialogue Goal Specifications The application designer needs to design a description of a dialogue goal for each task the back-end system can execute. A dialogue goal can be considered as the description of a form that is filled out through the spoken dialogue with the system [Papineni et al, 1999]. The goal description consists of a typed feature structure [Carpenter, 1992] whose types are drawn from the class hierarchy designed in step 3.1. It serves as an informational lower bound, guaranteeing that the back-end application is notified if and only if the information acquired through the dialogue is at least as specific as the specification in the dialogue goal. Note that the dialogue goal specification does not make any assumptions as to how this information is acquired, nor as to how the acquired information is to be processed. Thus, the dialogue goals form the specification of a task model that is orthogonal to any dialogue strategy specification and indepe</context>
<context position="24547" citStr="Carpenter, 1992" startWordPosition="3989" endWordPosition="3990">&amp;quot; would return the empty set, as the database does not know about the inheritance relationships. For this reason, the conversion rules associated with the table entries also contain a type restricting the constraint generation. Only types that are more specific than the restriction are taken into consideration for query generation. In this example, the types taken into consideration for query generation would need to be more specific than ob j _pasta. This is to ensure extensionality for database access. Alternatively, one could employ extensional feature structures as described by Carpenter [Carpenter, 1992] and make sure that only extensional types are used for queries. 3.5 Interfacing the Wizard with the Knowledge Sources A wizard-style GUI guides the application designer through the design process of the dialogue package. The knowledge sources are introduced in the order in which they are described in this section. The result of the process is a prototypical system that needs to be refined interactively using test sets. Figure 4 shows a screenshot of the wizard in step 1 at the point of specifying the domain model. In order to abstract over different input and output modalities, the dialogue </context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>B. Carpenter. The Logic of Typed Feature Structures. Cambridge University Press, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cole</author>
</authors>
<title>Tools for Research and Education in Speech Science.</title>
<date>1999</date>
<booktitle>Proceedings of the International Conference of Phonetic Sciences,</booktitle>
<location>San Francisco, USA,</location>
<contexts>
<context position="1433" citStr="Cole, 1999" startWordPosition="209" endWordPosition="210">e dialogue packages can be specified through a graphical user interface with the help of a wizard. 1 Introduction The specification and design of interactive spoken language systems has become the focus of research recently. Partly fueled by the increasing demand of spoken language applications and telephony-based services, the deployment of development environments has increased. At the time of writing, at least three main types of dialogue tools can be distinguished. One approach to development environments consists of graphical editors for Finite State Automata (FSA) [Sutton et al, 1996], [Cole, 1999]. These systems equate a dialogue with a possible path from the start state to one of the accepting states. Possible actions of the application are specified by annotations on states or arcs or both. Besides relying on a dialogue model that has been considered as problematic in the past, finite-state automata based dialogue editors do not exploit the desirable characteristics of software engineering, such as reusability and orthogonality of the components. For example, recovery strategies need to be duplicated for each state in which they should be applied. Moreover, they require a system des</context>
</contexts>
<marker>Cole, 1999</marker>
<rawString>R. Cole. Tools for Research and Education in Speech Science. Proceedings of the International Conference of Phonetic Sciences, San Francisco, USA, 1999.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Denecke</author>
<author>A Waibel</author>
</authors>
<title>Dialogue Strategies Guiding Users to Their Communicative Goals.</title>
<booktitle>Proceedings of Eurospeech, Rhodos, Greece,1997. Available from http://www.is.cs.cmu.edu.</booktitle>
<marker>Denecke, Waibel, </marker>
<rawString>M. Denecke and A. Waibel, Dialogue Strategies Guiding Users to Their Communicative Goals. Proceedings of Eurospeech, Rhodos, Greece,1997. Available from http://www.is.cs.cmu.edu.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Denecke</author>
<author>A H Waibel</author>
</authors>
<title>Integrating Knowledge Sources for a Task-Oriented Dialogue System.</title>
<booktitle>Workshop on Knowledge and Reasoning in Practical Dialogue Systems, Stockholm, Sweden,1999 Available from http://www.is.cs.cmu.edu.</booktitle>
<marker>Denecke, Waibel, </marker>
<rawString>M. Denecke and A.H. Waibel, Integrating Knowledge Sources for a Task-Oriented Dialogue System. Workshop on Knowledge and Reasoning in Practical Dialogue Systems, Stockholm, Sweden,1999 Available from http://www.is.cs.cmu.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denecke</author>
</authors>
<title>Modularity in Grammar and Ontology Specification.</title>
<date>2000</date>
<booktitle>Proceedings of the MSC 2000 Workshop, Kyoto,</booktitle>
<note>Available from http://www.is.cs.cmu.edu.</note>
<contexts>
<context position="15144" citStr="Denecke, 2000" startWordPosition="2421" endWordPosition="2422">nformation in the nonterminal symbols is threefold. First, it allows the technique of multiple inheritance to be applied during grammar design and parsing. For example, a nonterminal symbol (sem, synmai , synmin ) might be expanded by a rule with a left hand symbol (sem&apos;, synmai , synmin), provided that sem subsumes sem&apos; in the type hierarchy. Second, it provides more information to compare nonterminal symbols during parsing than plain slot names. Third, the semantic information is helpful in ensuring the semantic constructions associated with the grammar rules is well-typed. Please refer to [Denecke, 2000] for more information on the first two points. In this paper, we will concentrate on the third point as it is relevant to the design of the wizard interface. As the syntactic structure of the input sentences might vary, it is not sufficient to rely on the names of the concept to extract the meaning of the utterances. Rather, we pursue an approach that is resembles the one found in attributed grammars used in compiler construction or Montague grammars in that the grammar rules contain an annotation describing how to construct the semantics. Consider a rule (sem, syr,, sywno,) (semi, synrni syn</context>
</contexts>
<marker>Denecke, 2000</marker>
<rawString>M. Denecke. Modularity in Grammar and Ontology Specification. Proceedings of the MSC 2000 Workshop, Kyoto, 2000. Available from http://www.is.cs.cmu.edu.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M GayaIda</author>
<author>A Waibel</author>
</authors>
<title>Growing Semantic Grammars.</title>
<booktitle>Proceedings of the COLING/ACL,</booktitle>
<location>Montreal, Canada.</location>
<note>Available from http://www.is.cs.cmu.edu.</note>
<marker>GayaIda, Waibel, </marker>
<rawString>M. GayaIda and A. Waibel. Growing Semantic Grammars. Proceedings of the COLING/ACL, Montreal, Canada. Available from http://www.is.cs.cmu.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke Koelzer</author>
</authors>
<title>Universal Dialogue Specification for Conversational Systems Workshop on Knowledge and Reasoning in Practical Dialogue Systems.</title>
<date>1999</date>
<location>Stockholm,</location>
<note>Available from http://www.ida.liu.se/ext/etai.</note>
<contexts>
<context position="3429" citStr="Koelzer, 1999" startWordPosition="526" endWordPosition="527">egies requires separate fine-tuning in each module. Moreover, the dialogue flow is partly defined by an FSA whose nodes consist of the dialogue modules. When a node is reached, the dialogue module determines the dialogue control until it gives up control and an adjacent arc is traversed. A third approach consists in designing a library of reusable dialogue strategies based on the observation that the behavior of a dialogue manager should be predictable in similar situations across several domains. Araki et al [Araki et al, 1999] proposed a library of dialogue strategies to be reused. Koelzer [Koelzer, 1999] proposed a reusable dialogue system architecture based on specifications of knowledge sources for the different components. In this paper, we identify knowledge sources such as grammars, task models and database conversion rules, that characterize our dialogue manager for a given application. Each of the knowledge sources can be composed of smaller, modular knowledge sources. A collection of these knowledge source modules, called a dialogue package, specifies a subdomain of a dialogue application. We borrow techniques known from object oriented programming languages to combine partial specif</context>
</contexts>
<marker>Koelzer, 1999</marker>
<rawString>Anke Koelzer. Universal Dialogue Specification for Conversational Systems Workshop on Knowledge and Reasoning in Practical Dialogue Systems. Stockholm, Sweden, 1999. Available from http://www.ida.liu.se/ext/etai.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>R T Ward</author>
</authors>
<title>Free-Flow Dialogue Management Using Forms.</title>
<date>1999</date>
<booktitle>Proceedings of EUROSPEECH 99,</booktitle>
<location>Budapest, Ungarn,</location>
<contexts>
<context position="11624" citStr="Papineni et al, 1999" startWordPosition="1839" endWordPosition="1843">gument of the method description. Since the third argument is described by the constraint obj_buyable.price &gt; real (a constraint that is always satisfied due to the feature definition), the dialogue manager places the result returned from the back-end application at the appropriate place in the feature structure. 3.2 The Dialogue Goal Specifications The application designer needs to design a description of a dialogue goal for each task the back-end system can execute. A dialogue goal can be considered as the description of a form that is filled out through the spoken dialogue with the system [Papineni et al, 1999]. The goal description consists of a typed feature structure [Carpenter, 1992] whose types are drawn from the class hierarchy designed in step 3.1. It serves as an informational lower bound, guaranteeing that the back-end application is notified if and only if the information acquired through the dialogue is at least as specific as the specification in the dialogue goal. Note that the dialogue goal specification does not make any assumptions as to how this information is acquired, nor as to how the acquired information is to be processed. Thus, the dialogue goals form the specification of a t</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1999</marker>
<rawString>K.A. Papineni, S. Roukos and R.T. Ward. Free-Flow Dialogue Management Using Forms. Proceedings of EUROSPEECH 99, Budapest, Ungarn, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sutton</author>
<author>D G Novick</author>
<author>R A Cole</author>
<author>M Fanty</author>
</authors>
<title>Building 10,000 spoken-dialogue systems.</title>
<date>1996</date>
<booktitle>Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<location>Philadelphia, PA,</location>
<contexts>
<context position="1419" citStr="Sutton et al, 1996" startWordPosition="205" endWordPosition="208">ammars. We show how the dialogue packages can be specified through a graphical user interface with the help of a wizard. 1 Introduction The specification and design of interactive spoken language systems has become the focus of research recently. Partly fueled by the increasing demand of spoken language applications and telephony-based services, the deployment of development environments has increased. At the time of writing, at least three main types of dialogue tools can be distinguished. One approach to development environments consists of graphical editors for Finite State Automata (FSA) [Sutton et al, 1996], [Cole, 1999]. These systems equate a dialogue with a possible path from the start state to one of the accepting states. Possible actions of the application are specified by annotations on states or arcs or both. Besides relying on a dialogue model that has been considered as problematic in the past, finite-state automata based dialogue editors do not exploit the desirable characteristics of software engineering, such as reusability and orthogonality of the components. For example, recovery strategies need to be duplicated for each state in which they should be applied. Moreover, they requir</context>
</contexts>
<marker>Sutton, Novick, Cole, Fanty, 1996</marker>
<rawString>S. Sutton, D. G. Novick, R. A. Cole, and M. Fanty. Building 10,000 spoken-dialogue systems. Proceedings of the International Conference on Spoken Language Processing, Philadelphia, PA, October 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>D J Litman</author>
<author>C A Kamm</author>
<author>A PARADISE AbeIla</author>
</authors>
<title>A Framework for Evaluating Spoken Dialogue Agents</title>
<date>1997</date>
<booktitle>Proceedings of the 35th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<note>Available from http://www.research.att.com/ walker.</note>
<contexts>
<context position="12820" citStr="Walker et al, 1997" startWordPosition="2036" endWordPosition="2039">e specification of a task model that is orthogonal to any dialogue strategy specification and independent from the implementation of the back-end system. Furthermore, it should be noted that the specification of dialogue goals in typed feature structures does not restrict the dialogue strategy to be a simple form filling strategy. Rather, the dialogue goal specification is an encapsulation of a method invocation which, when triggered, causes the back-end application to do what the user intended the system to do. The assumptions made here are similar to those in the general PARADISE framework [Walker et al, 1997] for dialogue evaluation where the task model for dialogue managers is equally described in attribute value matrices. Example (continued) We continue the fast food service example. We concentrate on the dialogue goals relevant to the pizza and pasta objects, as we assume that we have recourse to a dialogue package Shopping Cart that defines the knowledge sources relevant to the virtual shopping list. We thus need to introduce only one dialogue goal, namely the one allowing the user to seek information on the buyable objects. 3.3 The Grammar Specification It is the task of the grammar specific</context>
</contexts>
<marker>Walker, Litman, Kamm, AbeIla, 1997</marker>
<rawString>Walker, M.A. and Litman, D.J. and Kamm, C.A. and AbeIla, A. PARADISE: A Framework for Evaluating Spoken Dialogue Agents Proceedings of the 35th Annual Meeting of the Association of Computational Linguistics, 1997. Available from http://www.research.att.com/ walker.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>