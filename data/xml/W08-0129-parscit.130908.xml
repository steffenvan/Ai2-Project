<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002305">
<title confidence="0.9966655">
The Effect of Dialogue System Output Style Variation
on Users’ Evaluation Judgments and Input Style
</title>
<author confidence="0.986355">
Ivana Kruijff-Korbayov´a and Olga Kukina
</author>
<affiliation confidence="0.9680925">
Department of Computational Linguistics
Saarland University, Germany
</affiliation>
<email confidence="0.998067">
{korbay|olgak}@coli.uni-sb.de
</email>
<sectionHeader confidence="0.998593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997212909090909">
A dialogue system can present itself and/or
address the user as an active agent by means
of linguistic constructions in personal style, or
suppress agentivity by using impersonal style.
We compare system evaluation judgments and
input style alignment of users interacting with
an in-car dialogue system generating output in
personal vs. impersonal style. Although our
results are consistent with earlier findings ob-
tained with simulated systems, the effects are
weaker.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999370772727272">
One of the goals in developing dialogue systems that
users find appealing and natural is to endow the sys-
tems with natural and contextually appropriate out-
put. This encompasses a broad range of research
issues. The one we address in this paper pertains
to style in the interpersonal dimension: does using
personal vs. impersonal style of system output have
an effect on dialogue system users, in particular, on
their judgments about the system and on the way
they formulate their input to the system?
We define the personal/impersonal style di-
chotomy as reflecting primarily a distinction with
respect to agentivity: personal style involves the ex-
plicit realization of an agent, whereas impersonal
style avoids it. In the simplest way it is manifested
by the presence of explicit reference to the dialogue
participants (typically by means of personal pro-
nouns) vs. its absence, respectively. More generally,
active voice and finite verb forms are typical for per-
sonal style, whereas impersonal style often, though
not exclusively, employs passive constructions or in-
finite verb forms:
</bodyText>
<figure confidence="0.970517">
(1) Typical personal style constructions:
a. I found 20 albums.
b. You have 20 albums.
c. Please search for albums by The Beatles.
(2) Typical impersonal style constructions:
a. 20 albums have been found.
b. There are 20 albums.
c. The database contains 20 albums.
</figure>
<figureCaption confidence="0.464114">
d. 20 albums found.
</figureCaption>
<bodyText confidence="0.998532090909091">
The designer of a dialogue system has the choice
to make it manifest (its own and the user’s) agen-
tivity linguistically through the use of personal con-
structions or not.
Previous experiments with simulated systems
have shown that a natural language interface with
a synthesized voice should not say “I” (Nass and
Brave, 2005) and that users align the style of their
input to that of the system output (Brennan and
Ohaeri, 1994). (See Section 2 for more detail.)
The dialogue system SAMMIE developed in the
TALK project (Becker et al., 2007) can use either per-
sonal or impersonal output style. In personal style, it
generates constructions making explicit reference to
the agent (both the user and the system itself), such
as (1a–1c); in impersonal style, it avoids explicit ref-
erence to any agent, as in (2a–2d). The system can
be set either to use one style consistently throughout
a dialogue session, or to align to the user’s style, i.e.,
mimic the user’s style on a turn-by-turn basis.
Inspired by the earlier results obtained with sim-
ulated systems (Nass and Brave, 2005; Brennan and
</bodyText>
<page confidence="0.968418">
190
</page>
<note confidence="0.868226">
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 190–197,
Columbus, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997509375">
Ohaeri, 1994), we ran an experiment to test the ef-
fects of style manipulation in the SAMMIE system.
In this paper, we compare two versions of the sys-
tem, one using consistently the personal output style
and the other the impersonal style. We designed
our experiment to test (i) whether the users’ judg-
ments of the system’s usability and performance dif-
fer among the system versions using the personal vs.
impersonal style, and (ii) whether users align to the
system style.
In Section 2 we review previous experiments con-
cerning the effect of system output style on users’
judgments and style. We describe our own experi-
ment in Section 3, present the results in Section 4,
and provide a discussion and conclusions in Sec-
tion 5.
</bodyText>
<sectionHeader confidence="0.997682" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999941423076923">
(Nass and Brave, 2005) address the issue whether a
voice interface should say “I” by investigating sev-
eral dimensions of user attitudes to their simulated
system with a synthetic vs. recorded voice. Gen-
erally, agents that use “I” are perceived more like
a person than those that do not. However, systems
tend to be more positively rated when consistent
with respect to such parameters as personality, gen-
der, ontology (human vs. machine), etc. A system
with a recorded voice is perceived as more human-
like and thus entitled to the use of “I”, whereas a
synthetic-voice interface is not perceived as human
enough to use “I” to refer to itself (Nass et al., 2006).
Another question is whether system output style
influences users’ input formulation, as would be ex-
pected due to the phenomenon of alignment, which
is generally considered a basic principle in natural
language dialogue (Garrod and Pickering, 2004).1
Experiments targeting human-human conversa-
tion show that in spite of the variety of linguistic
expressions available, speakers in spontaneous dia-
logues tend to express themselves in similar ways at
lexical and syntactic levels. For example, the sur-
face form of a question can affect the format of the
answer: the question “What time do you close?” will
more likely get the response “Five o’clock” than“At
</bodyText>
<footnote confidence="0.89133925">
1This dialogue phenomenon goes under a variety of terms in
the literature, besides alignment, e.g., accommodation, adapta-
tion, convergence, entrainment or shaping (used, e.g., by (Bren-
nan and Ohaeri, 1994)).
</footnote>
<bodyText confidence="0.998575428571429">
five o’clock”. On the other hand, “At five o’clock”
is a more probable answer to “At what time do you
close?” (Levelt and Kelter, 1982). There is evi-
dence that alignment happens automatically as a re-
sult of priming, e.g., (Hadelich et al., 2004) for lexi-
cal alignment.
Lexical and syntactic alignment is present in
human-computer interaction, too. (Brennan, 1996)
suggested that users adopt system’s terms to avoid
errors, expecting the system to be inflexible. How-
ever, recent experiments show that alignment in
human-computer interaction is also automatic and
its strength is comparable to that in human-human
communication (Branigan et al., 2003; Pearson et
al., 2006).
Early results concerning users’ alignment to sys-
tem output style in the interpersonal dimension are
reported in (Brennan and Ohaeri, 1994): They dis-
tinguish three styles: anthropomorphic (the system
refers to itself using first person pronouns, like in
(1a) above, fluent (complete sentences, but no self-
reference) and telegraphic, like (2d). They found no
difference in users’ perception of the system’s in-
telligence across the different conditions. However,
they observed that the anthropomorphic group was
more than twice as likely to refer to the computer
using the second person pronoun “you” and it used
more indirect requests and conventional politeness
then the other groups. They concluded that the an-
thropomorphic style is undesirable for dialogue sys-
tems because it encourages more complex user input
which is harder to recognize and interpret.
The described experiments used either the
Wizard-of-Oz paradigm (Brennan, 1996) or prepro-
grammed system output (Branigan et al., 2003; Nass
and Brave, 2005) and involved written communica-
tion. Such methods allow one to test assumptions
about idealized human-computer interaction. The
purpose of our experiment was to test whether sim-
ilar effects arise in an interaction with an actual di-
alogue system, which may be plagued, among other
factors, by speech recognition problems.
</bodyText>
<sectionHeader confidence="0.997724" genericHeader="method">
3 Experiment
</sectionHeader>
<footnote confidence="0.667608666666667">
Dialogue System We used the SAMMIE in-car sys-
tem developed in the TALK project (Becker et al.,
2006; Becker et al., 2007). SAMMIE provides a mul-
</footnote>
<page confidence="0.998086">
191
</page>
<bodyText confidence="0.999753111111111">
timodal interface to an MP3 player through speech
and haptic input with a button which can be turned,
pushed down and pushed sideways in four direc-
tions. System output is by speech and a graphical
display. The user can perform a range of tasks: con-
trol the MP3 player (play/stop/pause playing song,
next/previous/go-to track, turn shuffle mode on/off),
search and browse by looking for various fields in
the MP3 database (song, artist, album, etc.), search
and select playlists, edit them or construct new ones.
The SAMMIE system was designed with the aim
to support natural, intuitive mixed-initiative interac-
tion. Input can be given through any modality at
any point and is not restricted to answers to sys-
tem queries: the user can initiate new tasks as well
as give any information relevant to the current task
at any time. A sample interaction is shown below
(Becker et al., 2006).
</bodyText>
<listItem confidence="0.826019">
(3) U: Show me the Beatles albums.
</listItem>
<bodyText confidence="0.95065416">
S: I have these four Beatles albums. [shows a list
of album names]
U: Which songs are on this one? [selects the Red
Album]
S: The Red Album contains these songs [shows a
list of the songs]
U: Play the third one.
S: [song “From Me To You” plays]
The SAMMIE system has a German and an En-
glish version which both provide the same function-
ality. The experiment employed the German ver-
sion. See (Kruijff-Korbayov´a et al., 2008) for a de-
scription of the natural language generation module.
Setup Figure 1 shows a picture of the experiment
setup. To simulate the driving situation, we used
the “3D-Fahrschule” software.2 The driving simu-
lator visuals were projected on a wall-sized back-
projection screen. The graphical interface of the
SAMMIE system was shown on a display next to the
steering wheel. Participants wore headphones with
a microphone for the spoken input and output. The
button for manual input was positioned to the right
of their chair. The experimenter was sitting in an ad-
jacent room and could see and hear everything hap-
pening in the experiment lab. The subjects could not
</bodyText>
<footnote confidence="0.942894">
2http://www.3d-fahrschule.de/index.htm
</footnote>
<figureCaption confidence="0.999738">
Figure 1: Experiment setup
</figureCaption>
<bodyText confidence="0.999982193548387">
see the experimenter, but heard her instructions, in-
cluding the task assignments, from loudspeakers. If
necessary, the subjects were able to talk to the ex-
perimenter.
Participants A total of 28 participants were paid
to take part in the experiment. All were native Ger-
man speakers, 22 female and 6 male, 22 students of
the Saarland University and 6 employees. All but
two participants had a driver’s license and 20 partic-
ipants reported driving more than 500km a year. 10
participants had previous experience with a driving
simulation and 6 had used a dialogue system before.
Each participant was assigned to one style condition,
14 to personal and 14 to impersonal style. To ensure
as even a distribution as possible, there were 11 fe-
male and 3 male participants in each style condition,
one of whom was a non-driver. There were 4 em-
ployees in impersonal style condition and 2 in the
personal one.
Procedure Each participant was welcomed by the
experimenter, seated in the experiment lab, and
given brief written instructions concerning the driv-
ing simulator, the SAMMIE system and the evalua-
tion procedure. The participants were instructed to
use mainly spoken input to accomplish the tasks, al-
though they were allowed to use manual input, too.
The participants first made a ca. 2-minute drive
to get familiar with the driving simulator. Then they
were asked to chose a destination city (Amsterdam,
Madrid or London) and drive there on a highway.
During the driving, the experimenter successively
</bodyText>
<page confidence="0.991641">
192
</page>
<bodyText confidence="0.999937125">
read to the participant 2 trial tasks and 11 experi-
mental tasks to be solved using the SAMMIE system.
The tasks involved exploring the contents of a
database of about 25 music albums and were of four
types: (1) finding some specified title(s); (2) select-
ing some title(s) satisfying certain constraints; (3)
manipulating the playlists by adding or removing
songs and (4) free-use of the system.
The experimental tasks were presented to each
participant in randomized order apart from the free
use of the system, which was always the last task.
To avoid priming by the style of the task formula-
tion, and to help the participants memorize the task,
the experimenter (E) repeated each task assignment
twice to the participant, once in personal and once
in impersonal style, as shown in the example below.
</bodyText>
<figure confidence="0.504088666666667">
(4) E: Bitte frage das System nach den Liedern von
“Pur”. Du willst also wissen welche Lieder von
“Pur” es gibt.
</figure>
<figureCaption confidence="0.558498">
E: Please ask the the system about the songs by
“Pur”. You would like to know which songs by
“Pur” there are.
</figureCaption>
<bodyText confidence="0.999861818181818">
The time the participants spent completing the in-
dividual tasks was not constrained. It took them
about 40 minutes to complete all the tasks.
Afterwards, each participant was asked to fill in a
questionnaire about their attitudes towards the sys-
tem, consisting of questions with a 6-point scale
ranging from 1 (low grade) to 6 (high grade). The
questions were a subset of those used in (Nass and
Brave, 2005) and (Mutschler et al., 2007), for ex-
ample: How do you assess the system in general:
technical (1) – human-like (6); Communication with
the system seemed to you: boring (1) – exciting (6);
In terms of usability, the system is: inefficient (1)
—efficient(6).
Upon completing the questionnaire, the partici-
pant was paid and discharged.
Collected data The questionnaire responses have
been tabulated and the dialogues of the subjects with
the system have been recorded and transcribed.3
The utterances of the participants (on average 95
per session) were subsequently manually anno-
tated with the following features for further analysis:
</bodyText>
<footnote confidence="0.779063">
3We did not record the data from the driving simulator.
</footnote>
<listItem confidence="0.979935">
• Construction type:
</listItem>
<bodyText confidence="0.965842375">
Personal (+/-) Is the utterance a complete sen-
tence in active voice or imperative form
Impersonal (+/-) Is the utterance expressed
by passive voice, infinite verb form (e.g.,
“Lied abspielen” (lit. “song play”)), or ex-
pletive “es-gibt” (“there-is”) construction
Telegraphic (+/-) Is the utterance expressed
by a phrase, e.g., “weiter” (“next”)
</bodyText>
<listItem confidence="0.963709833333333">
• Personal pronouns: (+/-) Does the utterance
contain a first or second person pronoun
• Politeness marking: (+/-) Does the utterance
contain a politeness marker, such as “bitte”
(“please”), “danke” (“thanks”) and verbs in
subjunctive mood (eg. “ich h¨atte gerne”)
</listItem>
<sectionHeader confidence="0.999952" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.998669">
4.1 Style and Users’ Attitudes
</subsectionHeader>
<bodyText confidence="0.9947816">
The first issue addressed in the experiment was
whether the users have different judgments of the
personal vs. impersonal version of the system. Since
the system used a synthetic voice, the judgments
were expected to be more positive in the impersonal
style condition (Nass and Brave, 2005). Based on
factor analysis performed on attitudinal data from
the user questionnaires we created the six indices
listed below. All indices were meaningful and re-
liable
</bodyText>
<listItem confidence="0.99954125">
1. General satisfaction with the communication
with the system was composed of 3 pairs of
adjectives describing communication with the
system: disappointing/motivating, uninterest-
ing/interesting and boring/exciting (Cronbach’s
α=0.86; t(26)=0.29, p=0.39 (one-tailed))
2. Ease of communication with the system com-
prised 5 parameters: naturalness of the commu-
nication with the system, formality/informality
and indifference/sympathy of the system’s
communicative style, participants feelings dur-
ing the conversation: tensed/relaxed and pleas-
ant/unpleasant (α=0.83; t(26)=0.00, p=0.5
(one-tailed))
3. Usability of the system consisted of 1
pair of adjectives referring to the success
</listItem>
<page confidence="0.991414">
193
</page>
<figureCaption confidence="0.9982415">
Figure 2: Perceived humanness of the system depending
on system output style
</figureCaption>
<bodyText confidence="0.998070333333333">
of communication with the system: un-
successful/successful, and 4 pairs of adjec-
tives describing the usability of the sys-
tem: unpractical/practical, inefficient/efficient,
complicated/simple, inconvenient/convenient
(α=0.76; t(26)=0.08, p=0.47 (one-tailed))
</bodyText>
<listItem confidence="0.999408166666667">
4. Clarity of the system’s speech comprised 2
pairs of adjectives describing the system’s
speech: unpredictable/predictable and confus-
ing/clear (α=0.88; t(25)=0.87, p=0.2 (one-
tailed))
5. Perceived “humanness” of the system was
composed of 3 parameters: perceived tech-
nicality/humanness, perceived unfriend-
liness/friendliness and attributed conser-
vatism/innovation (α=0.69; t(25)=1.64, p=0.06
(one-tailed))
6. System’s perceived flexibility and creativity
</listItem>
<bodyText confidence="0.881552666666667">
comprised 3 parameters: rigidness/flexibility
of system’s speech, perceived creativity of the
system and intelligence attributed to the system
(α=0.78; t(26)=0.40, p=0.35 (one-tailed))
We did not find any significant influence of sys-
tem output style on users’ attitudes. The only in-
dex with a weak tendency in the predicted direction
is perceived humanness of the system (t(25)=1.64,
p=.06 (one-tailed); see Figure 2). This goes in line
with the earlier observation that an interface that
refers to itself by means of a personal pronoun is
perceived to be more human-like than one that does
</bodyText>
<figureCaption confidence="0.996989">
Figure 3: Distribution chart for syntactic construction
types in user utterances depending on system output style
</figureCaption>
<bodyText confidence="0.531551">
not (Nass and Brave, 2005).
</bodyText>
<subsectionHeader confidence="0.895048">
4.2 Style and Alignment
</subsectionHeader>
<bodyText confidence="0.979606625">
The next issue we investigated was whether the users
formulated their input differently with the personal
vs. impersonal system version. For each dialogue
session, we calculated the percentage of utterances
containing the feature of interest relative to the total
number of user utterances in the session.
First we analyzed the distribution of personal,
impersonal and telegraphic constructions across the
personal and impersonal style conditions. (The rea-
son we separated telegraphic constructions is be-
cause they seem to be neutral with respect to style.)
We compared the means of the obtained numbers be-
tween the two style conditions. Figure 3 shows the
distribution of the types of syntactic constructions
across the system output style conditions.
1. We expected the participants to use more per-
sonal constructions with the personal style ver-
sion of the system. Independent samples t-
test showed a significant result in the predicted
direction (t(19)=1.8, p=0.05 (one-tailed); see
Figure 3).
2. We expected to find the reverse effect with
regard to the proportion of impersonal verb
forms: participants using the personal style
</bodyText>
<page confidence="0.997703">
194
</page>
<bodyText confidence="0.999255666666667">
version of the system were expected to have
less infinite, passive and “es-gibt” forms than
those in the impersonal style condition. How-
ever, we did not find any significant difference
between the two style conditions (t(26)=1.0,
p=0.17 (one-tailed)).
</bodyText>
<listItem confidence="0.8583206">
3. According to expectation we also did not find
any significant difference in the proportion of
telegraphic constructions per style condition
(t(26)=1.4, p=0.09 (one-tailed)).
4. In the impersonal style condition we found
</listItem>
<bodyText confidence="0.968435477272727">
a significantly lower proportion of verb-
containing utterances than utterances in tele-
graphic form (t(13)=3.5, p=0.00 (one-tailed)).
But in the personal style condition there was no
statistically significant difference (t(13)=0.7,
p=0.25 (one-tailed)).
Next we analyzed the distribution of first and sec-
ond person pronouns across style conditions. We ex-
pected to find more personal pronouns in personal
than in impersonal style condition (Brennan and
Ohaeri, 1994). However, the results showed no sta-
tistically significant difference (t(26)=0.67, p=0.25
(one-tailed)).
Another prediction based on (Brennan and
Ohaeri, 1994) was to find more politeness markers
in the personal style. However, the analysis showed
that participants in the personal style condition did
not use significantly more politeness markers than
those in the impersonal style condition (t(20)=1.06,
p=0.15 (one-tailed)).
Finally, (Brennan and Ohaeri, 1994) predicted
that personal style, being more flexible, might cause
more speech recognition problems than input in im-
personal style. We checked whether participants in
the personal style condition had a higher rate of un-
recognized utterances than those in the impersonal
style condition and found no significant difference
(t(26)=0.60, p = 0.28 (one-tailed)).
To summarize, we observed a significant differ-
ence in the number of personal constructions across
style conditions, in accordance with the expectation
based on style alignment in terms of agentivity. But
we did not find a significant difference in the distri-
bution of impersonal constructions across style con-
ditions. Not surprisingly, there was also no signifi-
cant difference in the distribution of telegraphic con-
structions. An unexpected finding was the higher
proportion of telegraphic constructions than verb-
containing ones within the impersonal style condi-
tion. However, the personal style condition showed
no significant effect. Contrary to expectations, we
also did not find any significant effect of style-
manipulation on the number of personal pronouns,
nor on the number of politeness markers.
</bodyText>
<subsectionHeader confidence="0.999538">
4.3 Style Alignment over Time
</subsectionHeader>
<bodyText confidence="0.999979095238095">
Since alignment can also be seen as a process of
gradual adjustment among dialogue participants in
the course of their interaction, we were interested
in whether participants tended to converge to using
particular constructions as their session with the sys-
tem progressed. For each participant we divided the
transcribed conversation in two halves. Using paired
samples t-test, we compared the proportion of per-
sonal, impersonal and telegraphic constructions in
the first and second halves of the conversations for
both style conditions.
In the personal style condition, we found no sig-
nificant change in the usage of construction types
between the first and the second half of the dialogue.
In the impersonal style condition, we did not find
any significant difference in the distribution of im-
personal and telegraphic constructions either. How-
ever, we found a significant change in the number
of personal constructions (t(13)=2.5, p=0.02 (one-
tailed)): The participants cut down on the use of per-
sonal constructions in the second half.
</bodyText>
<sectionHeader confidence="0.99328" genericHeader="conclusions">
5 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.999324153846154">
We presented the results of an experiment with the
in-car multimodal dialogue system SAMMIE, aimed
to test whether we obtain effects similar to earlier
findings concerning the influence of system output
style in the interpersonal dimension on the users’
subjective judgments of a system (Nass and Brave,
2005) as well as their formulation of input (Bren-
nan and Ohaeri, 1994). Although our results are not
conclusive, they point at a range of issues for further
research.
Regarding users’ attitudes to the system, we
found no significant difference among the styles.
This is similar to (Brennan and Ohaeri, 1994) who
</bodyText>
<page confidence="0.997857">
195
</page>
<bodyText confidence="0.99998609375">
found no difference in intelligence attributed to the
system by the users, but it is at odds with the earlier
finding that a synthetic voice interface was judged
to be more useful when avoiding self-reference by
personal pronouns (Nass and Brave, 2005).
Whereas (Brennan and Ohaeri, 1994) used a flight
reservation dialogue system, (Nass and Brave, 2005)
used a phone-based auction system which read out
an introduction and five object descriptions. There
are two points to note: First, the subjects were ex-
posed to system output that was a read out contin-
uous text rather than turns in an interaction. This
may have reinforced the activation of particular style
features. Second, the auction task may have sensi-
bilized the subjects to the distinction between sub-
jective (the system’s) vs. objective information pre-
sentation, and thus make them more sensitive to
whether the system presents itself as an active agent
or not.
Regarding the question whether users align their
style to that of the system, where previous experi-
ments showed strong effects of alignment (Brennan
and Ohaeri, 1994), our experiment shows some ef-
fects, but some of the results seem conflicting. On
the one hand, subjects interacting with the personal
style version of the system used more personal con-
structions than those interacting with the impersonal
style version. However, subjects in either condi-
tion did not show any significant difference with re-
spect to the use of impersonal constructions or tele-
graphic forms. We also found a higher proportion of
telegraphic constructions than verb-containing ones
within the impersonal style condition, but no such
difference in the personal style. Finally, when we
consider alignment over time, we find no change in
construction usage in the personal style, whereas we
find a decrease in the use of personal constructions
in the impersonal style.
That there is no difference in the use of tele-
graphic constructions across conditions is not sur-
prising. Being just phrasal sentence fragments, these
constructions are neutral with respect to style. But
why does there seem to be an alignment effect for
personal constructions and not for others? One way
of explaining this is that (some of) the constructions
that we counted as impersonal are common in both
styles. Besides their deliberate use as means to avoid
explicit reference to oneself, the constructions typi-
cal for impersonal style also have their normal, neu-
tral usage, and therefore, some of the utterances that
we have classified as impersonal style might just be
neutral formulations, rather than cases of distancing
or “de-agentivization”. However, we could not test
this hypothesis, because we have not found a way
to reliably distinguish between neutral and marked,
truly impersonal utterances. This is an issue requir-
ing further work.
The difference between our results concerning
alignment and those of (Brennan and Ohaeri, 1994)
is not likely to be due to a difference in the degree
of interactivity (as with (Nass and Brave, 2005)).
We now comment on other differences between our
systems, which might have contributed to the differ-
ences in results.
One aspect where we differ concerns our distinc-
tion between personal and impersonal style, both in
the implementation of the SAMMIE system and in
the experiment: We include the presence/absence
of agentivity not only in the system’s reference to
itself (akin to (Nass and Brave, 2005) and (Bren-
nan and Ohaeri, 1994)), but also in addressing the
user. This concept of the personal/impersonal dis-
tinction was inspired by such differences observed
in a study of instructional texts in several languages
(Kruijff et al., 1999), where the latter dimension is
predominant. The present experiment results make
it pertinent that more research into the motives be-
hind expressing or suppressing agentivity in both di-
mensions is needed.
Apart from the linguistic design of the system’s
output, other factors influence users’ behavior and
perception of the system, and thus might confound
experiment results, e.g., functionality, design, er-
gonomics, speech synthesis and speech recognition.
Earlier experiments reported in (Nass and Brave,
2005) suggest that a system with synthesized speech
should be more positively rated when it does not
refer to itself as an active agent by personal con-
structions. Whereas the system used by (Brennan
and Ohaeri, 1994) used written interaction, we used
the MARY text-to-speech synthesis system (Schr¨oder
and Trouvain, 2003) with an MBROLA diphone
synthesizer, which produces an acceptable though
not outstanding output quality. But as discussed ear-
lier, contrary to (Nass and Brave, 2005) we have not
observed a difference in the users’ attitudes depend-
</bodyText>
<page confidence="0.996829">
196
</page>
<bodyText confidence="0.999817714285714">
ing on style. It thus remains an open issue what ef-
fect speech output quality has on on the users’ atti-
tudes and alignment behavior.
Regarding a possible influence of speech recogni-
tion on our results, we performed a post-hoc analysis
(Kruijff-Korbayov´a et al., 2008), which did not re-
veal significant differences in user attitudes or align-
ment behavior depending on better or worse speech
recognition performance experienced by the users.
A future experiment should address the possibility
of an interaction between system style and speech
recognition performance as both factors might be in-
fluencing the user simultaneously.
One radical difference between our experiment
and the earlier ones is that the users of our system
are occupied by the driving task, and therefore only
have a limited cognitive capacity left to devote to the
interaction with the system. This may make them
less susceptible to the subtleties of style manipula-
tion than would be the case if they were free of other
tasks. A possible future experiment could address
this issue by including a non-driving condition.
Finally, as we pointed out in the introduction,
the SAMMIE system can also be used in an style-
alignment mode, where it mimics the user’s style on
turn-to-turn basis. We plan to present experimental
results comparing the alignment-mode with the fixed
personal/impersonal style in a future publication.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999967333333333">
This work was carried out in the TALK project
(www.talk-project.org) funded by the EU as project
No. IST-507802 within the 61h Framework Program.
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999954626865672">
T. Becker, N. Blaylock, C. Gerstenberger, I. Kruijff-
Korbayov´a, A. Korthauer, M. Pinkal, M. Pitz, P. Poller,
and J. Schehl. 2006. Natural and intuitive multimodal
dialogue for in-car applications: The SAMMIE system.
In Proceedings of ECAI, PAIS Special section.
T. Becker, N. Blaylock, C. Gerstenberger, A. Korthauer,
M. Pitz, P. Poller, J. Schehl, F. Steffens, R. Stegmann,
and J. Steigner. 2007. Deliverable D5.3: In-car
showcase based on TALK libraries. Technical report,
TALK Project, EU FP6, IST-507802.
H. Branigan, M. Pickering, J. Pearson, J. F. McLean, and
C. Nass. 2003. Syntactic alignment between com-
puter and people: the role of belief about mental states.
In Proceedings of the Annual Conference of the Cog-
nitive Science Society.
S. Brennan and J.O. Ohaeri. 1994. Effects of mes-
sage style on user’s attribution toward agents. In Pro-
ceedings of CHI’94 Conference Companion Human
Factors in Computing Systems, pages 281–282. ACM
Press.
S. Brennan. 1996. Lexical entrainment in spontaneous
dialogue. In Proceedings of the International Sympo-
sium on Spoken Dialogue (ISSD-96), pages 41–44.
S. Garrod and M. Pickering. 2004. Why is conversation
so easy? TRENDS in Cognitive Sciences, 8.
K. Hadelich, H. Branigan, M. Pickering, and M. Crocker.
2004. Alignment in dialogue: Effects of feedback
on lexical overlap within and between participants.
In Proceedings of the AMLaP Conference. Aix en
Provence, France.
G.J.M. Kruijff, I. Kruijff-Korbayov´a, J. Bateman,
D. Dochev, N. Gromova, T. Hartley, E. Teich,
S. Sharoff, L. Sokolova, and K. Staykova. 1999.
Deliverable TEXS2: Specification of elaborated text
structures. Technical report, AGILE Project, EU
INCO COPERNICUS PL961104.
I. Kruijff-Korbayov´a, C. Gerstenberger, O. Kukina, and
J. Schehl. 2008. Generation of output style variation
in the SAMMIE dialogue system. In Proceedings of
INLG’08, Salt Fork Resort, Ohio.
W.J.M. Levelt and S. Kelter. 1982. Surface form and
memory in question answering. Cognitive Psychol-
ogy, 14:78–106.
H. Mutschler, F. Steffens, and A. Korthauer. 2007. De-
liverable D6.4: Final report on multimodal experi-
ments Part I: Evaluation of the SAMMIE system. Tech-
nical report, TALK Project, EU FP6, IST-507802.
C. Nass and S. Brave, 2005. Should voice interfaces say
”I”? Recorded and synthetic voice interfaces’ claims
to humanity, chapter 10, pages 113–124. The MIT
Press, Cambridge.
C. Nass, S. Brave, and L. Takayama. 2006. Socializing
consistency: from technical homogeneity to human
epitome. In P. Zhang &amp; D. Galletta (Eds.), Human-
computer interaction in management information sys-
tems: Foundations, pages 373–390. Armonk, NY: M.
E. Sharpe.
J. Pearson, J. Hu, H. Branigan, M. J. Pickering, and C. I.
Nass. 2006. Adaptive language behavior in HCI: how
expectations and beliefs about a system affect users’
word choice. In CHI ’06: Proceedings of the SIGCHI
conference on Human Factors in computing systems,
pages 1177–1180, New York, NY, USA. ACM.
M. Schr¨oder and J. Trouvain. 2003. The German text-to-
speech synthesis system MARY: A tool for research,
development and teaching. International Journal of
Speech Technology, 6:365–377.
</reference>
<page confidence="0.998194">
197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.655062">
<title confidence="0.96522">The Effect of Dialogue System Output Style on Users’ Evaluation Judgments and Input Style</title>
<author confidence="0.803572">Kruijff-Korbayov´a</author>
<affiliation confidence="0.999934">Department of Computational Saarland University,</affiliation>
<abstract confidence="0.98519725">A dialogue system can present itself and/or address the user as an active agent by means of linguistic constructions in personal style, or suppress agentivity by using impersonal style. We compare system evaluation judgments and input style alignment of users interacting with an in-car dialogue system generating output in personal vs. impersonal style. Although our results are consistent with earlier findings obtained with simulated systems, the effects are weaker.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Becker</author>
<author>N Blaylock</author>
<author>C Gerstenberger</author>
<author>I KruijffKorbayov´a</author>
<author>A Korthauer</author>
<author>M Pinkal</author>
<author>M Pitz</author>
<author>P Poller</author>
<author>J Schehl</author>
</authors>
<title>Natural and intuitive multimodal dialogue for in-car applications: The SAMMIE system.</title>
<date>2006</date>
<booktitle>In Proceedings of ECAI, PAIS Special section.</booktitle>
<marker>Becker, Blaylock, Gerstenberger, KruijffKorbayov´a, Korthauer, Pinkal, Pitz, Poller, Schehl, 2006</marker>
<rawString>T. Becker, N. Blaylock, C. Gerstenberger, I. KruijffKorbayov´a, A. Korthauer, M. Pinkal, M. Pitz, P. Poller, and J. Schehl. 2006. Natural and intuitive multimodal dialogue for in-car applications: The SAMMIE system. In Proceedings of ECAI, PAIS Special section.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Becker</author>
<author>N Blaylock</author>
<author>C Gerstenberger</author>
<author>A Korthauer</author>
<author>M Pitz</author>
<author>P Poller</author>
<author>J Schehl</author>
<author>F Steffens</author>
<author>R Stegmann</author>
<author>J Steigner</author>
</authors>
<title>Deliverable D5.3: In-car showcase based on TALK libraries.</title>
<date>2007</date>
<tech>Technical report, TALK Project, EU FP6,</tech>
<pages>507802</pages>
<contexts>
<context position="2644" citStr="Becker et al., 2007" startWordPosition="410" endWordPosition="413">b. There are 20 albums. c. The database contains 20 albums. d. 20 albums found. The designer of a dialogue system has the choice to make it manifest (its own and the user’s) agentivity linguistically through the use of personal constructions or not. Previous experiments with simulated systems have shown that a natural language interface with a synthesized voice should not say “I” (Nass and Brave, 2005) and that users align the style of their input to that of the system output (Brennan and Ohaeri, 1994). (See Section 2 for more detail.) The dialogue system SAMMIE developed in the TALK project (Becker et al., 2007) can use either personal or impersonal output style. In personal style, it generates constructions making explicit reference to the agent (both the user and the system itself), such as (1a–1c); in impersonal style, it avoids explicit reference to any agent, as in (2a–2d). The system can be set either to use one style consistently throughout a dialogue session, or to align to the user’s style, i.e., mimic the user’s style on a turn-by-turn basis. Inspired by the earlier results obtained with simulated systems (Nass and Brave, 2005; Brennan and 190 Proceedings of the 9th SIGdial Workshop on Disc</context>
<context position="7758" citStr="Becker et al., 2007" startWordPosition="1231" endWordPosition="1234">terpret. The described experiments used either the Wizard-of-Oz paradigm (Brennan, 1996) or preprogrammed system output (Branigan et al., 2003; Nass and Brave, 2005) and involved written communication. Such methods allow one to test assumptions about idealized human-computer interaction. The purpose of our experiment was to test whether similar effects arise in an interaction with an actual dialogue system, which may be plagued, among other factors, by speech recognition problems. 3 Experiment Dialogue System We used the SAMMIE in-car system developed in the TALK project (Becker et al., 2006; Becker et al., 2007). SAMMIE provides a mul191 timodal interface to an MP3 player through speech and haptic input with a button which can be turned, pushed down and pushed sideways in four directions. System output is by speech and a graphical display. The user can perform a range of tasks: control the MP3 player (play/stop/pause playing song, next/previous/go-to track, turn shuffle mode on/off), search and browse by looking for various fields in the MP3 database (song, artist, album, etc.), search and select playlists, edit them or construct new ones. The SAMMIE system was designed with the aim to support natura</context>
</contexts>
<marker>Becker, Blaylock, Gerstenberger, Korthauer, Pitz, Poller, Schehl, Steffens, Stegmann, Steigner, 2007</marker>
<rawString>T. Becker, N. Blaylock, C. Gerstenberger, A. Korthauer, M. Pitz, P. Poller, J. Schehl, F. Steffens, R. Stegmann, and J. Steigner. 2007. Deliverable D5.3: In-car showcase based on TALK libraries. Technical report, TALK Project, EU FP6, IST-507802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Branigan</author>
<author>M Pickering</author>
<author>J Pearson</author>
<author>J F McLean</author>
<author>C Nass</author>
</authors>
<title>Syntactic alignment between computer and people: the role of belief about mental states.</title>
<date>2003</date>
<booktitle>In Proceedings of the Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="6266" citStr="Branigan et al., 2003" startWordPosition="1000" endWordPosition="1003"> hand, “At five o’clock” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that in human-human communication (Branigan et al., 2003; Pearson et al., 2006). Early results concerning users’ alignment to system output style in the interpersonal dimension are reported in (Brennan and Ohaeri, 1994): They distinguish three styles: anthropomorphic (the system refers to itself using first person pronouns, like in (1a) above, fluent (complete sentences, but no selfreference) and telegraphic, like (2d). They found no difference in users’ perception of the system’s intelligence across the different conditions. However, they observed that the anthropomorphic group was more than twice as likely to refer to the computer using the secon</context>
</contexts>
<marker>Branigan, Pickering, Pearson, McLean, Nass, 2003</marker>
<rawString>H. Branigan, M. Pickering, J. Pearson, J. F. McLean, and C. Nass. 2003. Syntactic alignment between computer and people: the role of belief about mental states. In Proceedings of the Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brennan</author>
<author>J O Ohaeri</author>
</authors>
<title>Effects of message style on user’s attribution toward agents.</title>
<date>1994</date>
<booktitle>In Proceedings of CHI’94 Conference Companion Human Factors in Computing Systems,</booktitle>
<pages>281--282</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="2531" citStr="Brennan and Ohaeri, 1994" startWordPosition="391" endWordPosition="394">c. Please search for albums by The Beatles. (2) Typical impersonal style constructions: a. 20 albums have been found. b. There are 20 albums. c. The database contains 20 albums. d. 20 albums found. The designer of a dialogue system has the choice to make it manifest (its own and the user’s) agentivity linguistically through the use of personal constructions or not. Previous experiments with simulated systems have shown that a natural language interface with a synthesized voice should not say “I” (Nass and Brave, 2005) and that users align the style of their input to that of the system output (Brennan and Ohaeri, 1994). (See Section 2 for more detail.) The dialogue system SAMMIE developed in the TALK project (Becker et al., 2007) can use either personal or impersonal output style. In personal style, it generates constructions making explicit reference to the agent (both the user and the system itself), such as (1a–1c); in impersonal style, it avoids explicit reference to any agent, as in (2a–2d). The system can be set either to use one style consistently throughout a dialogue session, or to align to the user’s style, i.e., mimic the user’s style on a turn-by-turn basis. Inspired by the earlier results obtai</context>
<context position="5615" citStr="Brennan and Ohaeri, 1994" startWordPosition="897" endWordPosition="901">ering, 2004).1 Experiments targeting human-human conversation show that in spite of the variety of linguistic expressions available, speakers in spontaneous dialogues tend to express themselves in similar ways at lexical and syntactic levels. For example, the surface form of a question can affect the format of the answer: the question “What time do you close?” will more likely get the response “Five o’clock” than“At 1This dialogue phenomenon goes under a variety of terms in the literature, besides alignment, e.g., accommodation, adaptation, convergence, entrainment or shaping (used, e.g., by (Brennan and Ohaeri, 1994)). five o’clock”. On the other hand, “At five o’clock” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that </context>
<context position="18918" citStr="Brennan and Ohaeri, 1994" startWordPosition="2976" endWordPosition="2979">ant difference in the proportion of telegraphic constructions per style condition (t(26)=1.4, p=0.09 (one-tailed)). 4. In the impersonal style condition we found a significantly lower proportion of verbcontaining utterances than utterances in telegraphic form (t(13)=3.5, p=0.00 (one-tailed)). But in the personal style condition there was no statistically significant difference (t(13)=0.7, p=0.25 (one-tailed)). Next we analyzed the distribution of first and second person pronouns across style conditions. We expected to find more personal pronouns in personal than in impersonal style condition (Brennan and Ohaeri, 1994). However, the results showed no statistically significant difference (t(26)=0.67, p=0.25 (one-tailed)). Another prediction based on (Brennan and Ohaeri, 1994) was to find more politeness markers in the personal style. However, the analysis showed that participants in the personal style condition did not use significantly more politeness markers than those in the impersonal style condition (t(20)=1.06, p=0.15 (one-tailed)). Finally, (Brennan and Ohaeri, 1994) predicted that personal style, being more flexible, might cause more speech recognition problems than input in impersonal style. We chec</context>
<context position="22012" citStr="Brennan and Ohaeri, 1994" startWordPosition="3443" endWordPosition="3447">phic constructions either. However, we found a significant change in the number of personal constructions (t(13)=2.5, p=0.02 (onetailed)): The participants cut down on the use of personal constructions in the second half. 5 Discussion and Conclusions We presented the results of an experiment with the in-car multimodal dialogue system SAMMIE, aimed to test whether we obtain effects similar to earlier findings concerning the influence of system output style in the interpersonal dimension on the users’ subjective judgments of a system (Nass and Brave, 2005) as well as their formulation of input (Brennan and Ohaeri, 1994). Although our results are not conclusive, they point at a range of issues for further research. Regarding users’ attitudes to the system, we found no significant difference among the styles. This is similar to (Brennan and Ohaeri, 1994) who 195 found no difference in intelligence attributed to the system by the users, but it is at odds with the earlier finding that a synthetic voice interface was judged to be more useful when avoiding self-reference by personal pronouns (Nass and Brave, 2005). Whereas (Brennan and Ohaeri, 1994) used a flight reservation dialogue system, (Nass and Brave, 2005)</context>
<context position="23349" citStr="Brennan and Ohaeri, 1994" startWordPosition="3661" endWordPosition="3664">ints to note: First, the subjects were exposed to system output that was a read out continuous text rather than turns in an interaction. This may have reinforced the activation of particular style features. Second, the auction task may have sensibilized the subjects to the distinction between subjective (the system’s) vs. objective information presentation, and thus make them more sensitive to whether the system presents itself as an active agent or not. Regarding the question whether users align their style to that of the system, where previous experiments showed strong effects of alignment (Brennan and Ohaeri, 1994), our experiment shows some effects, but some of the results seem conflicting. On the one hand, subjects interacting with the personal style version of the system used more personal constructions than those interacting with the impersonal style version. However, subjects in either condition did not show any significant difference with respect to the use of impersonal constructions or telegraphic forms. We also found a higher proportion of telegraphic constructions than verb-containing ones within the impersonal style condition, but no such difference in the personal style. Finally, when we con</context>
<context position="25175" citStr="Brennan and Ohaeri, 1994" startWordPosition="3950" endWordPosition="3953">s their deliberate use as means to avoid explicit reference to oneself, the constructions typical for impersonal style also have their normal, neutral usage, and therefore, some of the utterances that we have classified as impersonal style might just be neutral formulations, rather than cases of distancing or “de-agentivization”. However, we could not test this hypothesis, because we have not found a way to reliably distinguish between neutral and marked, truly impersonal utterances. This is an issue requiring further work. The difference between our results concerning alignment and those of (Brennan and Ohaeri, 1994) is not likely to be due to a difference in the degree of interactivity (as with (Nass and Brave, 2005)). We now comment on other differences between our systems, which might have contributed to the differences in results. One aspect where we differ concerns our distinction between personal and impersonal style, both in the implementation of the SAMMIE system and in the experiment: We include the presence/absence of agentivity not only in the system’s reference to itself (akin to (Nass and Brave, 2005) and (Brennan and Ohaeri, 1994)), but also in addressing the user. This concept of the person</context>
<context position="26642" citStr="Brennan and Ohaeri, 1994" startWordPosition="4183" endWordPosition="4186">t more research into the motives behind expressing or suppressing agentivity in both dimensions is needed. Apart from the linguistic design of the system’s output, other factors influence users’ behavior and perception of the system, and thus might confound experiment results, e.g., functionality, design, ergonomics, speech synthesis and speech recognition. Earlier experiments reported in (Nass and Brave, 2005) suggest that a system with synthesized speech should be more positively rated when it does not refer to itself as an active agent by personal constructions. Whereas the system used by (Brennan and Ohaeri, 1994) used written interaction, we used the MARY text-to-speech synthesis system (Schr¨oder and Trouvain, 2003) with an MBROLA diphone synthesizer, which produces an acceptable though not outstanding output quality. But as discussed earlier, contrary to (Nass and Brave, 2005) we have not observed a difference in the users’ attitudes depend196 ing on style. It thus remains an open issue what effect speech output quality has on on the users’ attitudes and alignment behavior. Regarding a possible influence of speech recognition on our results, we performed a post-hoc analysis (Kruijff-Korbayov´a et al</context>
</contexts>
<marker>Brennan, Ohaeri, 1994</marker>
<rawString>S. Brennan and J.O. Ohaeri. 1994. Effects of message style on user’s attribution toward agents. In Proceedings of CHI’94 Conference Companion Human Factors in Computing Systems, pages 281–282. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brennan</author>
</authors>
<title>Lexical entrainment in spontaneous dialogue.</title>
<date>1996</date>
<booktitle>In Proceedings of the International Symposium on Spoken Dialogue (ISSD-96),</booktitle>
<pages>41--44</pages>
<contexts>
<context position="5981" citStr="Brennan, 1996" startWordPosition="960" endWordPosition="961">ly get the response “Five o’clock” than“At 1This dialogue phenomenon goes under a variety of terms in the literature, besides alignment, e.g., accommodation, adaptation, convergence, entrainment or shaping (used, e.g., by (Brennan and Ohaeri, 1994)). five o’clock”. On the other hand, “At five o’clock” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that in human-human communication (Branigan et al., 2003; Pearson et al., 2006). Early results concerning users’ alignment to system output style in the interpersonal dimension are reported in (Brennan and Ohaeri, 1994): They distinguish three styles: anthropomorphic (the system refers to itself using first person pronouns, like in (1a) above, fluent (complete sentence</context>
<context position="7226" citStr="Brennan, 1996" startWordPosition="1147" endWordPosition="1148">legraphic, like (2d). They found no difference in users’ perception of the system’s intelligence across the different conditions. However, they observed that the anthropomorphic group was more than twice as likely to refer to the computer using the second person pronoun “you” and it used more indirect requests and conventional politeness then the other groups. They concluded that the anthropomorphic style is undesirable for dialogue systems because it encourages more complex user input which is harder to recognize and interpret. The described experiments used either the Wizard-of-Oz paradigm (Brennan, 1996) or preprogrammed system output (Branigan et al., 2003; Nass and Brave, 2005) and involved written communication. Such methods allow one to test assumptions about idealized human-computer interaction. The purpose of our experiment was to test whether similar effects arise in an interaction with an actual dialogue system, which may be plagued, among other factors, by speech recognition problems. 3 Experiment Dialogue System We used the SAMMIE in-car system developed in the TALK project (Becker et al., 2006; Becker et al., 2007). SAMMIE provides a mul191 timodal interface to an MP3 player throug</context>
</contexts>
<marker>Brennan, 1996</marker>
<rawString>S. Brennan. 1996. Lexical entrainment in spontaneous dialogue. In Proceedings of the International Symposium on Spoken Dialogue (ISSD-96), pages 41–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>M Pickering</author>
</authors>
<title>Why is conversation so easy?</title>
<date>2004</date>
<journal>TRENDS in Cognitive Sciences,</journal>
<volume>8</volume>
<contexts>
<context position="5002" citStr="Garrod and Pickering, 2004" startWordPosition="803" endWordPosition="806">ot. However, systems tend to be more positively rated when consistent with respect to such parameters as personality, gender, ontology (human vs. machine), etc. A system with a recorded voice is perceived as more humanlike and thus entitled to the use of “I”, whereas a synthetic-voice interface is not perceived as human enough to use “I” to refer to itself (Nass et al., 2006). Another question is whether system output style influences users’ input formulation, as would be expected due to the phenomenon of alignment, which is generally considered a basic principle in natural language dialogue (Garrod and Pickering, 2004).1 Experiments targeting human-human conversation show that in spite of the variety of linguistic expressions available, speakers in spontaneous dialogues tend to express themselves in similar ways at lexical and syntactic levels. For example, the surface form of a question can affect the format of the answer: the question “What time do you close?” will more likely get the response “Five o’clock” than“At 1This dialogue phenomenon goes under a variety of terms in the literature, besides alignment, e.g., accommodation, adaptation, convergence, entrainment or shaping (used, e.g., by (Brennan and </context>
</contexts>
<marker>Garrod, Pickering, 2004</marker>
<rawString>S. Garrod and M. Pickering. 2004. Why is conversation so easy? TRENDS in Cognitive Sciences, 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hadelich</author>
<author>H Branigan</author>
<author>M Pickering</author>
<author>M Crocker</author>
</authors>
<title>Alignment in dialogue: Effects of feedback on lexical overlap within and between participants.</title>
<date>2004</date>
<booktitle>In Proceedings of the AMLaP Conference. Aix en Provence,</booktitle>
<contexts>
<context position="5863" citStr="Hadelich et al., 2004" startWordPosition="942" endWordPosition="945">ple, the surface form of a question can affect the format of the answer: the question “What time do you close?” will more likely get the response “Five o’clock” than“At 1This dialogue phenomenon goes under a variety of terms in the literature, besides alignment, e.g., accommodation, adaptation, convergence, entrainment or shaping (used, e.g., by (Brennan and Ohaeri, 1994)). five o’clock”. On the other hand, “At five o’clock” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that in human-human communication (Branigan et al., 2003; Pearson et al., 2006). Early results concerning users’ alignment to system output style in the interpersonal dimension are reported in (Brennan and Ohaeri, 1994): They distinguish three styles: a</context>
</contexts>
<marker>Hadelich, Branigan, Pickering, Crocker, 2004</marker>
<rawString>K. Hadelich, H. Branigan, M. Pickering, and M. Crocker. 2004. Alignment in dialogue: Effects of feedback on lexical overlap within and between participants. In Proceedings of the AMLaP Conference. Aix en Provence, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J M Kruijff</author>
<author>I Kruijff-Korbayov´a</author>
<author>J Bateman</author>
<author>D Dochev</author>
<author>N Gromova</author>
<author>T Hartley</author>
<author>E Teich</author>
<author>S Sharoff</author>
<author>L Sokolova</author>
<author>K Staykova</author>
</authors>
<title>Deliverable TEXS2: Specification of elaborated text structures.</title>
<date>1999</date>
<tech>Technical report, AGILE Project, EU INCO COPERNICUS PL961104.</tech>
<marker>Kruijff, Kruijff-Korbayov´a, Bateman, Dochev, Gromova, Hartley, Teich, Sharoff, Sokolova, Staykova, 1999</marker>
<rawString>G.J.M. Kruijff, I. Kruijff-Korbayov´a, J. Bateman, D. Dochev, N. Gromova, T. Hartley, E. Teich, S. Sharoff, L. Sokolova, and K. Staykova. 1999. Deliverable TEXS2: Specification of elaborated text structures. Technical report, AGILE Project, EU INCO COPERNICUS PL961104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Kruijff-Korbayov´a</author>
<author>C Gerstenberger</author>
<author>O Kukina</author>
<author>J Schehl</author>
</authors>
<title>Generation of output style variation in the SAMMIE dialogue system.</title>
<date>2008</date>
<booktitle>In Proceedings of INLG’08, Salt Fork Resort,</booktitle>
<location>Ohio.</location>
<marker>Kruijff-Korbayov´a, Gerstenberger, Kukina, Schehl, 2008</marker>
<rawString>I. Kruijff-Korbayov´a, C. Gerstenberger, O. Kukina, and J. Schehl. 2008. Generation of output style variation in the SAMMIE dialogue system. In Proceedings of INLG’08, Salt Fork Resort, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J M Levelt</author>
<author>S Kelter</author>
</authors>
<title>Surface form and memory in question answering.</title>
<date>1982</date>
<pages>14--78</pages>
<publisher>Cognitive Psychology,</publisher>
<contexts>
<context position="5753" citStr="Levelt and Kelter, 1982" startWordPosition="923" endWordPosition="926">rs in spontaneous dialogues tend to express themselves in similar ways at lexical and syntactic levels. For example, the surface form of a question can affect the format of the answer: the question “What time do you close?” will more likely get the response “Five o’clock” than“At 1This dialogue phenomenon goes under a variety of terms in the literature, besides alignment, e.g., accommodation, adaptation, convergence, entrainment or shaping (used, e.g., by (Brennan and Ohaeri, 1994)). five o’clock”. On the other hand, “At five o’clock” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that in human-human communication (Branigan et al., 2003; Pearson et al., 2006). Early results concerning users’ alignment to system output sty</context>
</contexts>
<marker>Levelt, Kelter, 1982</marker>
<rawString>W.J.M. Levelt and S. Kelter. 1982. Surface form and memory in question answering. Cognitive Psychology, 14:78–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mutschler</author>
<author>F Steffens</author>
<author>A Korthauer</author>
</authors>
<title>Deliverable D6.4: Final report on multimodal experiments Part I: Evaluation of the SAMMIE system.</title>
<date>2007</date>
<tech>Technical report, TALK Project, EU FP6,</tech>
<pages>507802</pages>
<contexts>
<context position="12823" citStr="Mutschler et al., 2007" startWordPosition="2088" endWordPosition="2091">n Liedern von “Pur”. Du willst also wissen welche Lieder von “Pur” es gibt. E: Please ask the the system about the songs by “Pur”. You would like to know which songs by “Pur” there are. The time the participants spent completing the individual tasks was not constrained. It took them about 40 minutes to complete all the tasks. Afterwards, each participant was asked to fill in a questionnaire about their attitudes towards the system, consisting of questions with a 6-point scale ranging from 1 (low grade) to 6 (high grade). The questions were a subset of those used in (Nass and Brave, 2005) and (Mutschler et al., 2007), for example: How do you assess the system in general: technical (1) – human-like (6); Communication with the system seemed to you: boring (1) – exciting (6); In terms of usability, the system is: inefficient (1) —efficient(6). Upon completing the questionnaire, the participant was paid and discharged. Collected data The questionnaire responses have been tabulated and the dialogues of the subjects with the system have been recorded and transcribed.3 The utterances of the participants (on average 95 per session) were subsequently manually annotated with the following features for further analy</context>
</contexts>
<marker>Mutschler, Steffens, Korthauer, 2007</marker>
<rawString>H. Mutschler, F. Steffens, and A. Korthauer. 2007. Deliverable D6.4: Final report on multimodal experiments Part I: Evaluation of the SAMMIE system. Technical report, TALK Project, EU FP6, IST-507802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nass</author>
<author>S Brave</author>
</authors>
<title>Should voice interfaces say ”I”? Recorded and synthetic voice interfaces’ claims to humanity, chapter 10,</title>
<date>2005</date>
<pages>113--124</pages>
<publisher>The MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="2429" citStr="Nass and Brave, 2005" startWordPosition="372" endWordPosition="375">erb forms: (1) Typical personal style constructions: a. I found 20 albums. b. You have 20 albums. c. Please search for albums by The Beatles. (2) Typical impersonal style constructions: a. 20 albums have been found. b. There are 20 albums. c. The database contains 20 albums. d. 20 albums found. The designer of a dialogue system has the choice to make it manifest (its own and the user’s) agentivity linguistically through the use of personal constructions or not. Previous experiments with simulated systems have shown that a natural language interface with a synthesized voice should not say “I” (Nass and Brave, 2005) and that users align the style of their input to that of the system output (Brennan and Ohaeri, 1994). (See Section 2 for more detail.) The dialogue system SAMMIE developed in the TALK project (Becker et al., 2007) can use either personal or impersonal output style. In personal style, it generates constructions making explicit reference to the agent (both the user and the system itself), such as (1a–1c); in impersonal style, it avoids explicit reference to any agent, as in (2a–2d). The system can be set either to use one style consistently throughout a dialogue session, or to align to the use</context>
<context position="4114" citStr="Nass and Brave, 2005" startWordPosition="656" endWordPosition="659">e system, one using consistently the personal output style and the other the impersonal style. We designed our experiment to test (i) whether the users’ judgments of the system’s usability and performance differ among the system versions using the personal vs. impersonal style, and (ii) whether users align to the system style. In Section 2 we review previous experiments concerning the effect of system output style on users’ judgments and style. We describe our own experiment in Section 3, present the results in Section 4, and provide a discussion and conclusions in Section 5. 2 Previous Work (Nass and Brave, 2005) address the issue whether a voice interface should say “I” by investigating several dimensions of user attitudes to their simulated system with a synthetic vs. recorded voice. Generally, agents that use “I” are perceived more like a person than those that do not. However, systems tend to be more positively rated when consistent with respect to such parameters as personality, gender, ontology (human vs. machine), etc. A system with a recorded voice is perceived as more humanlike and thus entitled to the use of “I”, whereas a synthetic-voice interface is not perceived as human enough to use “I”</context>
<context position="7303" citStr="Nass and Brave, 2005" startWordPosition="1158" endWordPosition="1161"> the system’s intelligence across the different conditions. However, they observed that the anthropomorphic group was more than twice as likely to refer to the computer using the second person pronoun “you” and it used more indirect requests and conventional politeness then the other groups. They concluded that the anthropomorphic style is undesirable for dialogue systems because it encourages more complex user input which is harder to recognize and interpret. The described experiments used either the Wizard-of-Oz paradigm (Brennan, 1996) or preprogrammed system output (Branigan et al., 2003; Nass and Brave, 2005) and involved written communication. Such methods allow one to test assumptions about idealized human-computer interaction. The purpose of our experiment was to test whether similar effects arise in an interaction with an actual dialogue system, which may be plagued, among other factors, by speech recognition problems. 3 Experiment Dialogue System We used the SAMMIE in-car system developed in the TALK project (Becker et al., 2006; Becker et al., 2007). SAMMIE provides a mul191 timodal interface to an MP3 player through speech and haptic input with a button which can be turned, pushed down and </context>
<context position="12794" citStr="Nass and Brave, 2005" startWordPosition="2083" endWordPosition="2086">te frage das System nach den Liedern von “Pur”. Du willst also wissen welche Lieder von “Pur” es gibt. E: Please ask the the system about the songs by “Pur”. You would like to know which songs by “Pur” there are. The time the participants spent completing the individual tasks was not constrained. It took them about 40 minutes to complete all the tasks. Afterwards, each participant was asked to fill in a questionnaire about their attitudes towards the system, consisting of questions with a 6-point scale ranging from 1 (low grade) to 6 (high grade). The questions were a subset of those used in (Nass and Brave, 2005) and (Mutschler et al., 2007), for example: How do you assess the system in general: technical (1) – human-like (6); Communication with the system seemed to you: boring (1) – exciting (6); In terms of usability, the system is: inefficient (1) —efficient(6). Upon completing the questionnaire, the participant was paid and discharged. Collected data The questionnaire responses have been tabulated and the dialogues of the subjects with the system have been recorded and transcribed.3 The utterances of the participants (on average 95 per session) were subsequently manually annotated with the followi</context>
<context position="14445" citStr="Nass and Brave, 2005" startWordPosition="2339" endWordPosition="2342"> e.g., “weiter” (“next”) • Personal pronouns: (+/-) Does the utterance contain a first or second person pronoun • Politeness marking: (+/-) Does the utterance contain a politeness marker, such as “bitte” (“please”), “danke” (“thanks”) and verbs in subjunctive mood (eg. “ich h¨atte gerne”) 4 Results 4.1 Style and Users’ Attitudes The first issue addressed in the experiment was whether the users have different judgments of the personal vs. impersonal version of the system. Since the system used a synthetic voice, the judgments were expected to be more positive in the impersonal style condition (Nass and Brave, 2005). Based on factor analysis performed on attitudinal data from the user questionnaires we created the six indices listed below. All indices were meaningful and reliable 1. General satisfaction with the communication with the system was composed of 3 pairs of adjectives describing communication with the system: disappointing/motivating, uninteresting/interesting and boring/exciting (Cronbach’s α=0.86; t(26)=0.29, p=0.39 (one-tailed)) 2. Ease of communication with the system comprised 5 parameters: naturalness of the communication with the system, formality/informality and indifference/sympathy o</context>
<context position="16818" citStr="Nass and Brave, 2005" startWordPosition="2661" endWordPosition="2664">ligence attributed to the system (α=0.78; t(26)=0.40, p=0.35 (one-tailed)) We did not find any significant influence of system output style on users’ attitudes. The only index with a weak tendency in the predicted direction is perceived humanness of the system (t(25)=1.64, p=.06 (one-tailed); see Figure 2). This goes in line with the earlier observation that an interface that refers to itself by means of a personal pronoun is perceived to be more human-like than one that does Figure 3: Distribution chart for syntactic construction types in user utterances depending on system output style not (Nass and Brave, 2005). 4.2 Style and Alignment The next issue we investigated was whether the users formulated their input differently with the personal vs. impersonal system version. For each dialogue session, we calculated the percentage of utterances containing the feature of interest relative to the total number of user utterances in the session. First we analyzed the distribution of personal, impersonal and telegraphic constructions across the personal and impersonal style conditions. (The reason we separated telegraphic constructions is because they seem to be neutral with respect to style.) We compared the </context>
<context position="21947" citStr="Nass and Brave, 2005" startWordPosition="3432" endWordPosition="3435">cant difference in the distribution of impersonal and telegraphic constructions either. However, we found a significant change in the number of personal constructions (t(13)=2.5, p=0.02 (onetailed)): The participants cut down on the use of personal constructions in the second half. 5 Discussion and Conclusions We presented the results of an experiment with the in-car multimodal dialogue system SAMMIE, aimed to test whether we obtain effects similar to earlier findings concerning the influence of system output style in the interpersonal dimension on the users’ subjective judgments of a system (Nass and Brave, 2005) as well as their formulation of input (Brennan and Ohaeri, 1994). Although our results are not conclusive, they point at a range of issues for further research. Regarding users’ attitudes to the system, we found no significant difference among the styles. This is similar to (Brennan and Ohaeri, 1994) who 195 found no difference in intelligence attributed to the system by the users, but it is at odds with the earlier finding that a synthetic voice interface was judged to be more useful when avoiding self-reference by personal pronouns (Nass and Brave, 2005). Whereas (Brennan and Ohaeri, 1994) </context>
<context position="25278" citStr="Nass and Brave, 2005" startWordPosition="3970" endWordPosition="3973">sonal style also have their normal, neutral usage, and therefore, some of the utterances that we have classified as impersonal style might just be neutral formulations, rather than cases of distancing or “de-agentivization”. However, we could not test this hypothesis, because we have not found a way to reliably distinguish between neutral and marked, truly impersonal utterances. This is an issue requiring further work. The difference between our results concerning alignment and those of (Brennan and Ohaeri, 1994) is not likely to be due to a difference in the degree of interactivity (as with (Nass and Brave, 2005)). We now comment on other differences between our systems, which might have contributed to the differences in results. One aspect where we differ concerns our distinction between personal and impersonal style, both in the implementation of the SAMMIE system and in the experiment: We include the presence/absence of agentivity not only in the system’s reference to itself (akin to (Nass and Brave, 2005) and (Brennan and Ohaeri, 1994)), but also in addressing the user. This concept of the personal/impersonal distinction was inspired by such differences observed in a study of instructional texts i</context>
<context position="26913" citStr="Nass and Brave, 2005" startWordPosition="4222" endWordPosition="4225">s, e.g., functionality, design, ergonomics, speech synthesis and speech recognition. Earlier experiments reported in (Nass and Brave, 2005) suggest that a system with synthesized speech should be more positively rated when it does not refer to itself as an active agent by personal constructions. Whereas the system used by (Brennan and Ohaeri, 1994) used written interaction, we used the MARY text-to-speech synthesis system (Schr¨oder and Trouvain, 2003) with an MBROLA diphone synthesizer, which produces an acceptable though not outstanding output quality. But as discussed earlier, contrary to (Nass and Brave, 2005) we have not observed a difference in the users’ attitudes depend196 ing on style. It thus remains an open issue what effect speech output quality has on on the users’ attitudes and alignment behavior. Regarding a possible influence of speech recognition on our results, we performed a post-hoc analysis (Kruijff-Korbayov´a et al., 2008), which did not reveal significant differences in user attitudes or alignment behavior depending on better or worse speech recognition performance experienced by the users. A future experiment should address the possibility of an interaction between system style </context>
</contexts>
<marker>Nass, Brave, 2005</marker>
<rawString>C. Nass and S. Brave, 2005. Should voice interfaces say ”I”? Recorded and synthetic voice interfaces’ claims to humanity, chapter 10, pages 113–124. The MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nass</author>
<author>S Brave</author>
<author>L Takayama</author>
</authors>
<title>Socializing consistency: from technical homogeneity to human epitome. In</title>
<date>2006</date>
<pages>373--390</pages>
<location>Armonk, NY:</location>
<contexts>
<context position="4753" citStr="Nass et al., 2006" startWordPosition="766" endWordPosition="769">ether a voice interface should say “I” by investigating several dimensions of user attitudes to their simulated system with a synthetic vs. recorded voice. Generally, agents that use “I” are perceived more like a person than those that do not. However, systems tend to be more positively rated when consistent with respect to such parameters as personality, gender, ontology (human vs. machine), etc. A system with a recorded voice is perceived as more humanlike and thus entitled to the use of “I”, whereas a synthetic-voice interface is not perceived as human enough to use “I” to refer to itself (Nass et al., 2006). Another question is whether system output style influences users’ input formulation, as would be expected due to the phenomenon of alignment, which is generally considered a basic principle in natural language dialogue (Garrod and Pickering, 2004).1 Experiments targeting human-human conversation show that in spite of the variety of linguistic expressions available, speakers in spontaneous dialogues tend to express themselves in similar ways at lexical and syntactic levels. For example, the surface form of a question can affect the format of the answer: the question “What time do you close?” </context>
</contexts>
<marker>Nass, Brave, Takayama, 2006</marker>
<rawString>C. Nass, S. Brave, and L. Takayama. 2006. Socializing consistency: from technical homogeneity to human epitome. In P. Zhang &amp; D. Galletta (Eds.), Humancomputer interaction in management information systems: Foundations, pages 373–390. Armonk, NY: M. E. Sharpe.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pearson</author>
<author>J Hu</author>
<author>H Branigan</author>
<author>M J Pickering</author>
<author>C I Nass</author>
</authors>
<title>Adaptive language behavior in HCI: how expectations and beliefs about a system affect users’ word choice.</title>
<date>2006</date>
<booktitle>In CHI ’06: Proceedings of the SIGCHI conference on Human Factors in computing systems,</booktitle>
<pages>1177--1180</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6289" citStr="Pearson et al., 2006" startWordPosition="1004" endWordPosition="1007">” is a more probable answer to “At what time do you close?” (Levelt and Kelter, 1982). There is evidence that alignment happens automatically as a result of priming, e.g., (Hadelich et al., 2004) for lexical alignment. Lexical and syntactic alignment is present in human-computer interaction, too. (Brennan, 1996) suggested that users adopt system’s terms to avoid errors, expecting the system to be inflexible. However, recent experiments show that alignment in human-computer interaction is also automatic and its strength is comparable to that in human-human communication (Branigan et al., 2003; Pearson et al., 2006). Early results concerning users’ alignment to system output style in the interpersonal dimension are reported in (Brennan and Ohaeri, 1994): They distinguish three styles: anthropomorphic (the system refers to itself using first person pronouns, like in (1a) above, fluent (complete sentences, but no selfreference) and telegraphic, like (2d). They found no difference in users’ perception of the system’s intelligence across the different conditions. However, they observed that the anthropomorphic group was more than twice as likely to refer to the computer using the second person pronoun “you” </context>
</contexts>
<marker>Pearson, Hu, Branigan, Pickering, Nass, 2006</marker>
<rawString>J. Pearson, J. Hu, H. Branigan, M. J. Pickering, and C. I. Nass. 2006. Adaptive language behavior in HCI: how expectations and beliefs about a system affect users’ word choice. In CHI ’06: Proceedings of the SIGCHI conference on Human Factors in computing systems, pages 1177–1180, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Schr¨oder</author>
<author>J Trouvain</author>
</authors>
<title>The German text-tospeech synthesis system MARY: A tool for research, development and teaching.</title>
<date>2003</date>
<journal>International Journal of Speech Technology,</journal>
<pages>6--365</pages>
<marker>Schr¨oder, Trouvain, 2003</marker>
<rawString>M. Schr¨oder and J. Trouvain. 2003. The German text-tospeech synthesis system MARY: A tool for research, development and teaching. International Journal of Speech Technology, 6:365–377.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>