<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.036596">
<title confidence="0.9952275">
Zones of conceptualisation in scientific papers: a window to negative and
speculative statements
</title>
<author confidence="0.996218">
Maria Liakata
</author>
<affiliation confidence="0.9971495">
Department of Computing Science, Aberystwyth University
European Bioinformatics Institute, Cambridge
</affiliation>
<email confidence="0.998653">
liakata@ebi.ac.uk
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995841">
In view of the increasing need to facilitate
processing the content of scientific papers,
we present an annotation scheme for anno-
tating full papers with zones of conceptu-
alisation, reflecting the information struc-
ture and knowledge types which constitute
a scientific investigation. The latter are the
Core Scientific Concepts (CoreSCs) and
include Hypothesis, Motivation, Goal, Ob-
ject, Background, Method, Experiment,
Model, Observation, Result and Conclu-
sion. The CoreSC scheme has been used
to annotate a corpus of 265 full papers in
physical chemistry and biochemistry and
we are currently automating the recogni-
tion of CoreSCs in papers. We discuss
how the CoreSC scheme relates to other
views of scientific papers and indeed how
the former could be used to help identify
negation and speculation in scientific texts.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999965714285714">
The recent surge in the numbers of papers pro-
duced, especially in the biosciences, has high-
lighted the need for automatic processing meth-
ods. Work by [Lin (2009)] has shown that methods
such as information retrieval are more effective if
zones of interest are specified within the papers.
Various corpora and annotation schemes have
been proposed for designating a variety of linguis-
tic phenomena permeating scientific papers, in-
cluding negation, hedges, dependencies and se-
mantic relations [Vincze et al. (2008); Pyysalo
et al. (2007); Medlock and Briscoe (2007); McIn-
tosh and Curran (2009)]. Other schemes follow
the argumentation and citation flow within pa-
pers [Teufel et al. (2009); Teufel and Siddharthan
(2007)] or indeed a combination of some of the
above along multiple dimensions [Shatkay et al.
(2008)].
In the following we present the CoreSC anno-
tation scheme and a corpus with CoreSC anno-
tations. The CoreSC scheme is used at the sen-
tence level to identify the core components that
constitute a scientific investigation. We discuss
how the CoreSC scheme relates to other annota-
tion schemes representing alternate views of sci-
entific papers and how CoreSCs could be used to
guide the identification of negation and specula-
tion.
</bodyText>
<sectionHeader confidence="0.987933" genericHeader="method">
2 The CoreSC scheme
</sectionHeader>
<bodyText confidence="0.998758178571429">
The CoreSC annotation scheme adopts the view
that a scientific paper is the human-readable repre-
sentation of a scientific investigation and therefore
seeks to mark the components of a scientific
investigation as expressed in the text. CoreSC
is ontology-motivated and originates from the
CISP meta-data [Soldatova and Liakata (2007)],
a subset of classes from EXPO [Soldatova and
King (2006)], an ontology for the description of
scientific investigations. CISP consists of the con-
cepts: Motivation, Goal, Object, Method,
Experiment, Observation, Result and
Conclusion, which were validated using an
on-line survey as constituting the indispensable
set of concepts necessary for the description of
a scientific investigation. CoreSC implements
these as well as Hypothesis, Model and
Background, as a sentence-based annotation
scheme for 3-layered annotation. The first layer
pertains to the previously mentioned 11 cate-
gories, the second layer is for the annotation of
properties of the concepts (e.g. “New”, “Old”)
and the third layer caters for identifiers (concep-
tID), which link together instances of the same
concept, e.g. all the sentences pertaining to the
same method will be linked together with the
same conceptID (e.g. “Met1”).
If we combine the layers of annotation so as to
</bodyText>
<page confidence="0.769799">
1
</page>
<note confidence="0.322214">
Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 1–4,
</note>
<tableCaption confidence="0.6482175">
Uppsala, July 2010.
Table 1: The CoreSC Annotation scheme
</tableCaption>
<table confidence="0.999007842105263">
Category Description
Hypothesis A statement not yet confirmed rather than a factual statement
Motivation The reasons behind an investigation
Background Generally accepted background knowledge and previous work
Goal A target state of the investigation where intended discoveries are made
Object-New An entity which is a product or main theme of the investigation
Object-New-Advantage Advantage of an object
Object-New-Disadvantage Disadvantage of an object
Method-New Means by which authors seek to achieve a goal of the investigation
Method-New-Advantage Advantage of a Method
Method-New-Disadvantage Disadvantage of a Method
Method-Old A method mentioned pertaining to previous work
Method-Old-Advantage Advantage of a Method
Method-Old-Disadvantage Disadvantage of a Method
Experiment An experimental method
Model A statement about a theoretical model or framework
Observation the data/phenomena recorded in an investigation
Result factual statements about the outputs of an investigation
Conclusion statements inferred from observations &amp; results relating to research hypothesis
</table>
<listItem confidence="0.5171375">
give flat labels, we cater for the categories in table
1.
</listItem>
<bodyText confidence="0.998772166666667">
The CoreSC scheme was accompanied by a set of
45 page guidelines which contain a decision tree,
detailed description of the semantics of the cate-
gories, 6 rules for pairwise distinction and exam-
ples from chemistry papers. These guidelines are
available from http://ie-repository.jisc.ac.uk/88/.
</bodyText>
<sectionHeader confidence="0.989126" genericHeader="method">
3 The CoreSC corpus
</sectionHeader>
<bodyText confidence="0.999914238095238">
We used the CoreSC annotation scheme and the
semantic annotation tool SAPIENT [Liakata et al.
(2009)] to construct a corpus of 265 annotated pa-
pers [Liakata and Soldatova (2009)] from physi-
cal chemistry and biochemistry. The CoreSC cor-
pus was developed in two different phases. Dur-
ing phase I, fifteen Chemistry experts were split
into five groups of three, each of which anno-
tated eight different papers; A 16th expert anno-
tated across groups as a consistency check. This
resulted in a total of 41 papers being annotated,
all of which received multiple annotations. We
ranked annotators according to median success in
terms of inter-annotator agreement (as measured
by Cohen’s kappa) both within their groups and
for a paper common across groups. In phase II,
the 9 best annotators of phase I each annotated 25
papers, amounting to a total of 225 papers.
The CoreSC corpus is now being used to train
a classifier for the automation of Core Scientific
concepts in papers.
</bodyText>
<sectionHeader confidence="0.9960065" genericHeader="method">
4 Correlating CoreSCs to other zones of
interest
</sectionHeader>
<bodyText confidence="0.99997590625">
Given the plethora of annotation schemes, it is in-
teresting to investigate the correlation between dif-
ferent views of scientific papers and how different
schemes map to each other. We recently looked
at the correlation between the CoreSC scheme,
which views papers as the humanly readable rep-
resentation of scientific investigations and seeks
to recover the investigation components within the
paper, and AZ-II [Teufel et al. (2009)], which as-
sumes a paper is the attempt of claiming owner-
ship for a new piece of knowledge and aims to
recover the rhetorical structure and the relevant
stages in the argumentation.
By definition, the two schemes focus on differ-
ent aspects of the papers, with CoreSCs provid-
ing more detail with respect to different types of
methods and results and AZ-II looking mostly at
the appropriation of knowledge claims. Based on
a set of 36 papers annotated with both schemes,
we were able to confirm that the two schemes
are indeed complementary [Liakata et al. (2010)].
CoreSC categories provide a greater level of gran-
ularity when it comes to the content-related cate-
gories whereas AZ-II categories cover aspects of
the knowledge claims that permeate across differ-
ent CoreSC concepts.
In [Guo et al. (2010)] we followed a simi-
lar methodology for annotating abstracts with
CoreSCs and an independently produced annota-
tion scheme for abstract sections [Hirohata et al.
(2008)]. We found a subsumption relation be-
tween the schemes, with CoreSCs providing the
</bodyText>
<page confidence="0.98584">
2
</page>
<bodyText confidence="0.999151333333333">
finer granularity.
To obtain the mapping between annotation
schemes, which allows annotation schemes to be
defined in a wider context, we ideally require an-
notations from different schemes to be made avail-
able for the same set of papers. However, a first
interpretation of the relation between schemes can
be made by mapping between annotation guide-
lines.
</bodyText>
<sectionHeader confidence="0.9618265" genericHeader="method">
5 Thoughts on using CoreSCs for
Negation and Speculation
</sectionHeader>
<bodyText confidence="0.9999845">
Current work of ours involves automating the
recognition of CoreSCs and we plan to use them
to produce extractive summaries for papers. We
are also in the process of evaluating the usefulness
of CoreSCs for Cancer Risk Assessment (CRA).
An important aspect of the latter is being able
to distinguish between positive and negative re-
sults and assess the confidence in any conclusions
drawn. This naturally leads us to the need for ex-
ploring negation and speculation, both of which
are prominent in scientific papers, as well as how
these two phenomena correlate to CoreSCs.
While it seems that negation can be identified
by means of certain linguistic patterns [Morante
(2010)], different types of negation can appear
throughout the paper, some pertaining to back-
ground work, problems serving as the motivation
of the paper, others referring to intermediate re-
sults or conclusions. It is interesting to look at
these different types of negation in the context of
each of the different CoreSCs, the type of linguis-
tic patterns used to express it and their distribution
across CoreSCs. This can provide a more target-
ted approach to negation, while at the same time it
can be used in combination with a CoreSC to infer
the type of knowledge obtained (e.g. a positive or
negative result). We plan to use automatic meth-
ods for recognising negation patterns in CoreSCs
and relate them to specific CoreSC categories.
There is a consensus that identifying specula-
tion is a harder task than identifying negation.
Part of the problem is that “speculative assertions
are to be identified on the basis of the judge-
ments about the author’s intended meaning, rather
than on the presence of certain designated hedge
terms” [Medlock and Briscoe (2007); Light et al.
(2004)]. When annotating papers with CoreSCs,
annotators are required to understand the paper
content rather than base category assignments en-
tirely on linguistic patterns. This is why we have
chosen experts as annotators for the creation of
the CoreSC corpus. So both speculation and
CoreSC annotation appear to be higher level an-
notation tasks requiring comprehension of the in-
tended meaning. Looking at the annotation guide-
lines for hedges [Medlock and Briscoe (2007)],
it would seem that cases of hedge type 1 corre-
spond to to CoreSC Conclusion, hedge type
2 pertains to Background, hedge type 3 would
mainly be cases of Motivation, hedge type 4
maps to Motivation or Hypothesis, hedge
type 5 maps to Goal and hedge type 6 maps to
Conclusion. One can look at speculation in the
zones/windows identified by the previously men-
tioned CoreSCs. Indeed, two of the categories,
Hypothesis and Motivation are speculative
by definition. We intend to port the issue of iden-
tifying speculation in our papers to that of identi-
fying the corresponding CoreSCs. We also plan to
annotate the hedge classification data of [Medlock
and Briscoe (2007)] with CoreSCs to confirm the
mapping between the two schemes.
</bodyText>
<sectionHeader confidence="0.998897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998188870967742">
Y. Guo, A. Korhonen, M. Liakata, I Silins, L. LiSun,
and U. Stenius. Identifying the information struc-
ture of scientific abstracts: An investigation of three
different schemes. In Proceedings of BioNLP 2010.
To appear., Uppsala, Sweden, 2010.
K. Hirohata, N. Okazaki, S. Ananiadou, and
M. Ishizuka. Identifying sections in scientific ab-
stracts using conditional random fields. In Proc. of
the IJCNLP 2008, 2008.
M. Liakata and L.N. Soldatova. The art cor-
pus. Technical report, Aberystwyth University,
2009. URL http://www.aber.ac.uk/
en/cs/research/cb/projects/art/
art-corpus/.
M. Liakata, Claire Q, and S. Soldatova. Semantic anno-
tation of papers: Interface &amp; enrichment tool (sapi-
ent). In Proceedings of BioNLP-09, pages 193–200,
Boulder, Colorado, 2009.
M. Liakata, S. Teufel, A. Siddharthan, and C. Batche-
lor. Corpora for the conceptualisation and zoning of
scientific papers. 2010.
M. Light, X.Y. Qiu, and P. Srinivasan. The language
of bioscience: Facts, speculations and statements in
between. In Proceedings of BioLink 2004 Work-
shop on Linking Biological Literature, Ontologies
and Databases: Tools for Users, Boston, 2004.
J. Lin. Is searching full text more effective than search-
ing abstracts? BMC Bioinformatics, 10:46, 2009.
T. McIntosh and J.R. Curran. Challenges for automati-
cally extracting molecular interactions from full-text
articles. BMC Bioinformatics, 10(311), 2009.
</reference>
<page confidence="0.988577">
3
</page>
<reference confidence="0.995110894736842">
B. Medlock and T. Briscoe. Weakly supervised learn-
ing for hedge classification in scientific literature.
In 45th Annual Meeting of the ACL, pages 23–30,
Prague, Czech Republic, 2007.
R. Morante. Descriptive analysis of negation cues
in biomedical texts. In Proceedings of the Sev-
enth International Language Resources and Evalu-
ation (LREC’10), pages 1429–1436, Valletta, Malta,
2010.
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjorne,
J. Boberg, J. Jarvinen, and T. Salakoski. Bioinfer:
a corpus for information extraction in the biomedi-
cal domain. BMC Bioinformatics, 8(1), 2007.
H. Shatkay, F. Pan, A. Rzhetsky, and W.J. Wilbur.
Multi-dimensional classification of biomedical text:
Toward automated, practical provision of high-
utility text to diverse users. Journal of Bioinformat-
ics, 24:18:2086–2093, 2008.
L.N. Soldatova and R.D. King. An ontology of scien-
tific experiments. Journal of the Royal Society In-
terface, 3:795–803, 2006.
L.N. Soldatova and M. Liakata. An ontology method-
ology and cisp-the proposed core information about
scientific papers. Technical Report JISC Project Re-
port, Aberystwyth University, 2007. URL http:
//ie-repository.jisc.ac.uk/137/.
S. Teufel and A. Siddharthan. Whose idea was this,
and why does it matter? attributing sicentific work to
citations. In Proceedings of NAACL-HLT-07, 2007.
Simone Teufel, Advaith Siddharthan, and Colin Batch-
elor. Towards discipline-independent argumenta-
tive zoning: Evidence from chemistry and compu-
tational linguistics. In Proceedings of EMNLP-09,
Singapore, 2009.
V. Vincze, G. Szarvas, R. Farkas, G. Mra, and J. Csirik.
The bioscope corpus: biomedical texts annotated for
uncertainty, negation and their scopes. BMC Bioin-
formatics, 9(Suppl 11):S9, 2008.
</reference>
<page confidence="0.996476">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.303984">
<title confidence="0.986488">Zones of conceptualisation in scientific papers: a window to negative and speculative statements</title>
<author confidence="0.998055">Maria</author>
<affiliation confidence="0.99846">Department of Computing Science, Aberystwyth European Bioinformatics Institute,</affiliation>
<email confidence="0.996117">liakata@ebi.ac.uk</email>
<abstract confidence="0.916937523809524">In view of the increasing need to facilitate processing the content of scientific papers, we present an annotation scheme for annotating full papers with zones of conceptualisation, reflecting the information structure and knowledge types which constitute a scientific investigation. The latter are the Core Scientific Concepts (CoreSCs) and include Hypothesis, Motivation, Goal, Object, Background, Method, Experiment, Model, Observation, Result and Conclusion. The CoreSC scheme has been used to annotate a corpus of 265 full papers in physical chemistry and biochemistry and we are currently automating the recognition of CoreSCs in papers. We discuss how the CoreSC scheme relates to other views of scientific papers and indeed how the former could be used to help identify negation and speculation in scientific texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Guo</author>
<author>A Korhonen</author>
<author>M Liakata</author>
<author>I Silins</author>
<author>L LiSun</author>
<author>U Stenius</author>
</authors>
<title>Identifying the information structure of scientific abstracts: An investigation of three different schemes.</title>
<date>2010</date>
<booktitle>In Proceedings of BioNLP</booktitle>
<location>Uppsala, Sweden,</location>
<note>To appear.,</note>
<contexts>
<context position="7492" citStr="Guo et al. (2010)" startWordPosition="1147" endWordPosition="1150"> definition, the two schemes focus on different aspects of the papers, with CoreSCs providing more detail with respect to different types of methods and results and AZ-II looking mostly at the appropriation of knowledge claims. Based on a set of 36 papers annotated with both schemes, we were able to confirm that the two schemes are indeed complementary [Liakata et al. (2010)]. CoreSC categories provide a greater level of granularity when it comes to the content-related categories whereas AZ-II categories cover aspects of the knowledge claims that permeate across different CoreSC concepts. In [Guo et al. (2010)] we followed a similar methodology for annotating abstracts with CoreSCs and an independently produced annotation scheme for abstract sections [Hirohata et al. (2008)]. We found a subsumption relation between the schemes, with CoreSCs providing the 2 finer granularity. To obtain the mapping between annotation schemes, which allows annotation schemes to be defined in a wider context, we ideally require annotations from different schemes to be made available for the same set of papers. However, a first interpretation of the relation between schemes can be made by mapping between annotation guid</context>
</contexts>
<marker>Guo, Korhonen, Liakata, Silins, LiSun, Stenius, 2010</marker>
<rawString>Y. Guo, A. Korhonen, M. Liakata, I Silins, L. LiSun, and U. Stenius. Identifying the information structure of scientific abstracts: An investigation of three different schemes. In Proceedings of BioNLP 2010. To appear., Uppsala, Sweden, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hirohata</author>
<author>N Okazaki</author>
<author>S Ananiadou</author>
<author>M Ishizuka</author>
</authors>
<title>Identifying sections in scientific abstracts using conditional random fields.</title>
<date>2008</date>
<booktitle>In Proc. of the IJCNLP</booktitle>
<contexts>
<context position="7659" citStr="Hirohata et al. (2008)" startWordPosition="1172" endWordPosition="1175">nd AZ-II looking mostly at the appropriation of knowledge claims. Based on a set of 36 papers annotated with both schemes, we were able to confirm that the two schemes are indeed complementary [Liakata et al. (2010)]. CoreSC categories provide a greater level of granularity when it comes to the content-related categories whereas AZ-II categories cover aspects of the knowledge claims that permeate across different CoreSC concepts. In [Guo et al. (2010)] we followed a similar methodology for annotating abstracts with CoreSCs and an independently produced annotation scheme for abstract sections [Hirohata et al. (2008)]. We found a subsumption relation between the schemes, with CoreSCs providing the 2 finer granularity. To obtain the mapping between annotation schemes, which allows annotation schemes to be defined in a wider context, we ideally require annotations from different schemes to be made available for the same set of papers. However, a first interpretation of the relation between schemes can be made by mapping between annotation guidelines. 5 Thoughts on using CoreSCs for Negation and Speculation Current work of ours involves automating the recognition of CoreSCs and we plan to use them to produce</context>
</contexts>
<marker>Hirohata, Okazaki, Ananiadou, Ishizuka, 2008</marker>
<rawString>K. Hirohata, N. Okazaki, S. Ananiadou, and M. Ishizuka. Identifying sections in scientific abstracts using conditional random fields. In Proc. of the IJCNLP 2008, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liakata</author>
<author>L N Soldatova</author>
</authors>
<title>The art corpus.</title>
<date>2009</date>
<tech>Technical report,</tech>
<institution>Aberystwyth University,</institution>
<note>URL http://www.aber.ac.uk/ en/cs/research/cb/projects/art/ art-corpus/.</note>
<contexts>
<context position="5415" citStr="Liakata and Soldatova (2009)" startWordPosition="803" endWordPosition="806">atements inferred from observations &amp; results relating to research hypothesis give flat labels, we cater for the categories in table 1. The CoreSC scheme was accompanied by a set of 45 page guidelines which contain a decision tree, detailed description of the semantics of the categories, 6 rules for pairwise distinction and examples from chemistry papers. These guidelines are available from http://ie-repository.jisc.ac.uk/88/. 3 The CoreSC corpus We used the CoreSC annotation scheme and the semantic annotation tool SAPIENT [Liakata et al. (2009)] to construct a corpus of 265 annotated papers [Liakata and Soldatova (2009)] from physical chemistry and biochemistry. The CoreSC corpus was developed in two different phases. During phase I, fifteen Chemistry experts were split into five groups of three, each of which annotated eight different papers; A 16th expert annotated across groups as a consistency check. This resulted in a total of 41 papers being annotated, all of which received multiple annotations. We ranked annotators according to median success in terms of inter-annotator agreement (as measured by Cohen’s kappa) both within their groups and for a paper common across groups. In phase II, the 9 best annot</context>
</contexts>
<marker>Liakata, Soldatova, 2009</marker>
<rawString>M. Liakata and L.N. Soldatova. The art corpus. Technical report, Aberystwyth University, 2009. URL http://www.aber.ac.uk/ en/cs/research/cb/projects/art/ art-corpus/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liakata</author>
<author>Q Claire</author>
<author>S Soldatova</author>
</authors>
<title>Semantic annotation of papers: Interface &amp; enrichment tool (sapient).</title>
<date>2009</date>
<booktitle>In Proceedings of BioNLP-09,</booktitle>
<pages>193--200</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="5338" citStr="Liakata et al. (2009)" startWordPosition="790" endWordPosition="793">factual statements about the outputs of an investigation Conclusion statements inferred from observations &amp; results relating to research hypothesis give flat labels, we cater for the categories in table 1. The CoreSC scheme was accompanied by a set of 45 page guidelines which contain a decision tree, detailed description of the semantics of the categories, 6 rules for pairwise distinction and examples from chemistry papers. These guidelines are available from http://ie-repository.jisc.ac.uk/88/. 3 The CoreSC corpus We used the CoreSC annotation scheme and the semantic annotation tool SAPIENT [Liakata et al. (2009)] to construct a corpus of 265 annotated papers [Liakata and Soldatova (2009)] from physical chemistry and biochemistry. The CoreSC corpus was developed in two different phases. During phase I, fifteen Chemistry experts were split into five groups of three, each of which annotated eight different papers; A 16th expert annotated across groups as a consistency check. This resulted in a total of 41 papers being annotated, all of which received multiple annotations. We ranked annotators according to median success in terms of inter-annotator agreement (as measured by Cohen’s kappa) both within the</context>
</contexts>
<marker>Liakata, Claire, Soldatova, 2009</marker>
<rawString>M. Liakata, Claire Q, and S. Soldatova. Semantic annotation of papers: Interface &amp; enrichment tool (sapient). In Proceedings of BioNLP-09, pages 193–200, Boulder, Colorado, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liakata</author>
<author>S Teufel</author>
<author>A Siddharthan</author>
<author>C Batchelor</author>
</authors>
<title>Corpora for the conceptualisation and zoning of scientific papers.</title>
<date>2010</date>
<contexts>
<context position="7252" citStr="Liakata et al. (2010)" startWordPosition="1109" endWordPosition="1112">components within the paper, and AZ-II [Teufel et al. (2009)], which assumes a paper is the attempt of claiming ownership for a new piece of knowledge and aims to recover the rhetorical structure and the relevant stages in the argumentation. By definition, the two schemes focus on different aspects of the papers, with CoreSCs providing more detail with respect to different types of methods and results and AZ-II looking mostly at the appropriation of knowledge claims. Based on a set of 36 papers annotated with both schemes, we were able to confirm that the two schemes are indeed complementary [Liakata et al. (2010)]. CoreSC categories provide a greater level of granularity when it comes to the content-related categories whereas AZ-II categories cover aspects of the knowledge claims that permeate across different CoreSC concepts. In [Guo et al. (2010)] we followed a similar methodology for annotating abstracts with CoreSCs and an independently produced annotation scheme for abstract sections [Hirohata et al. (2008)]. We found a subsumption relation between the schemes, with CoreSCs providing the 2 finer granularity. To obtain the mapping between annotation schemes, which allows annotation schemes to be d</context>
</contexts>
<marker>Liakata, Teufel, Siddharthan, Batchelor, 2010</marker>
<rawString>M. Liakata, S. Teufel, A. Siddharthan, and C. Batchelor. Corpora for the conceptualisation and zoning of scientific papers. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Light</author>
<author>X Y Qiu</author>
<author>P Srinivasan</author>
</authors>
<title>The language of bioscience: Facts, speculations and statements in between.</title>
<date>2004</date>
<booktitle>In Proceedings of BioLink 2004 Workshop on Linking Biological Literature, Ontologies and Databases: Tools for Users,</booktitle>
<location>Boston,</location>
<contexts>
<context position="9912" citStr="Light et al. (2004)" startWordPosition="1543" endWordPosition="1546">n, while at the same time it can be used in combination with a CoreSC to infer the type of knowledge obtained (e.g. a positive or negative result). We plan to use automatic methods for recognising negation patterns in CoreSCs and relate them to specific CoreSC categories. There is a consensus that identifying speculation is a harder task than identifying negation. Part of the problem is that “speculative assertions are to be identified on the basis of the judgements about the author’s intended meaning, rather than on the presence of certain designated hedge terms” [Medlock and Briscoe (2007); Light et al. (2004)]. When annotating papers with CoreSCs, annotators are required to understand the paper content rather than base category assignments entirely on linguistic patterns. This is why we have chosen experts as annotators for the creation of the CoreSC corpus. So both speculation and CoreSC annotation appear to be higher level annotation tasks requiring comprehension of the intended meaning. Looking at the annotation guidelines for hedges [Medlock and Briscoe (2007)], it would seem that cases of hedge type 1 correspond to to CoreSC Conclusion, hedge type 2 pertains to Background, hedge type 3 would </context>
</contexts>
<marker>Light, Qiu, Srinivasan, 2004</marker>
<rawString>M. Light, X.Y. Qiu, and P. Srinivasan. The language of bioscience: Facts, speculations and statements in between. In Proceedings of BioLink 2004 Workshop on Linking Biological Literature, Ontologies and Databases: Tools for Users, Boston, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
</authors>
<title>Is searching full text more effective than searching abstracts?</title>
<date>2009</date>
<journal>BMC Bioinformatics,</journal>
<volume>10</volume>
<contexts>
<context position="1239" citStr="Lin (2009)" startWordPosition="182" endWordPosition="183">ckground, Method, Experiment, Model, Observation, Result and Conclusion. The CoreSC scheme has been used to annotate a corpus of 265 full papers in physical chemistry and biochemistry and we are currently automating the recognition of CoreSCs in papers. We discuss how the CoreSC scheme relates to other views of scientific papers and indeed how the former could be used to help identify negation and speculation in scientific texts. 1 Introduction The recent surge in the numbers of papers produced, especially in the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the abo</context>
</contexts>
<marker>Lin, 2009</marker>
<rawString>J. Lin. Is searching full text more effective than searching abstracts? BMC Bioinformatics, 10:46, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McIntosh</author>
<author>J R Curran</author>
</authors>
<title>Challenges for automatically extracting molecular interactions from full-text articles.</title>
<date>2009</date>
<journal>BMC Bioinformatics,</journal>
<volume>10</volume>
<issue>311</issue>
<contexts>
<context position="1669" citStr="McIntosh and Curran (2009)" startWordPosition="244" endWordPosition="248">n scientific texts. 1 Introduction The recent surge in the numbers of papers produced, especially in the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide</context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>T. McIntosh and J.R. Curran. Challenges for automatically extracting molecular interactions from full-text articles. BMC Bioinformatics, 10(311), 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Medlock</author>
<author>T Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2007</date>
<booktitle>In 45th Annual Meeting of the ACL,</booktitle>
<pages>23--30</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1641" citStr="Medlock and Briscoe (2007)" startWordPosition="240" endWordPosition="243">y negation and speculation in scientific texts. 1 Introduction The recent surge in the numbers of papers produced, especially in the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how Co</context>
<context position="9891" citStr="Medlock and Briscoe (2007)" startWordPosition="1539" endWordPosition="1542">argetted approach to negation, while at the same time it can be used in combination with a CoreSC to infer the type of knowledge obtained (e.g. a positive or negative result). We plan to use automatic methods for recognising negation patterns in CoreSCs and relate them to specific CoreSC categories. There is a consensus that identifying speculation is a harder task than identifying negation. Part of the problem is that “speculative assertions are to be identified on the basis of the judgements about the author’s intended meaning, rather than on the presence of certain designated hedge terms” [Medlock and Briscoe (2007); Light et al. (2004)]. When annotating papers with CoreSCs, annotators are required to understand the paper content rather than base category assignments entirely on linguistic patterns. This is why we have chosen experts as annotators for the creation of the CoreSC corpus. So both speculation and CoreSC annotation appear to be higher level annotation tasks requiring comprehension of the intended meaning. Looking at the annotation guidelines for hedges [Medlock and Briscoe (2007)], it would seem that cases of hedge type 1 correspond to to CoreSC Conclusion, hedge type 2 pertains to Background</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>B. Medlock and T. Briscoe. Weakly supervised learning for hedge classification in scientific literature. In 45th Annual Meeting of the ACL, pages 23–30, Prague, Czech Republic, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Morante</author>
</authors>
<title>Descriptive analysis of negation cues in biomedical texts.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>1429--1436</pages>
<location>Valletta, Malta,</location>
<contexts>
<context position="8832" citStr="Morante (2010)" startWordPosition="1365" endWordPosition="1366">oreSCs and we plan to use them to produce extractive summaries for papers. We are also in the process of evaluating the usefulness of CoreSCs for Cancer Risk Assessment (CRA). An important aspect of the latter is being able to distinguish between positive and negative results and assess the confidence in any conclusions drawn. This naturally leads us to the need for exploring negation and speculation, both of which are prominent in scientific papers, as well as how these two phenomena correlate to CoreSCs. While it seems that negation can be identified by means of certain linguistic patterns [Morante (2010)], different types of negation can appear throughout the paper, some pertaining to background work, problems serving as the motivation of the paper, others referring to intermediate results or conclusions. It is interesting to look at these different types of negation in the context of each of the different CoreSCs, the type of linguistic patterns used to express it and their distribution across CoreSCs. This can provide a more targetted approach to negation, while at the same time it can be used in combination with a CoreSC to infer the type of knowledge obtained (e.g. a positive or negative </context>
</contexts>
<marker>Morante, 2010</marker>
<rawString>R. Morante. Descriptive analysis of negation cues in biomedical texts. In Proceedings of the Seventh International Language Resources and Evaluation (LREC’10), pages 1429–1436, Valletta, Malta, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pyysalo</author>
<author>F Ginter</author>
<author>J Heimonen</author>
<author>J Bjorne</author>
<author>J Boberg</author>
<author>J Jarvinen</author>
<author>T Salakoski</author>
</authors>
<title>Bioinfer: a corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="1613" citStr="Pyysalo et al. (2007)" startWordPosition="236" endWordPosition="239">be used to help identify negation and speculation in scientific texts. 1 Introduction The recent surge in the numbers of papers produced, especially in the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of </context>
</contexts>
<marker>Pyysalo, Ginter, Heimonen, Bjorne, Boberg, Jarvinen, Salakoski, 2007</marker>
<rawString>S. Pyysalo, F. Ginter, J. Heimonen, J. Bjorne, J. Boberg, J. Jarvinen, and T. Salakoski. Bioinfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8(1), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Shatkay</author>
<author>F Pan</author>
<author>A Rzhetsky</author>
<author>W J Wilbur</author>
</authors>
<title>Multi-dimensional classification of biomedical text: Toward automated, practical provision of highutility text to diverse users.</title>
<date>2008</date>
<journal>Journal of Bioinformatics,</journal>
<volume>24</volume>
<contexts>
<context position="1890" citStr="Shatkay et al. (2008)" startWordPosition="280" endWordPosition="283">as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide the identification of negation and speculation. 2 The CoreSC scheme The CoreSC annotation scheme adopts the view that a scientific paper is the human-readable representation of a scientific investigation and therefore se</context>
</contexts>
<marker>Shatkay, Pan, Rzhetsky, Wilbur, 2008</marker>
<rawString>H. Shatkay, F. Pan, A. Rzhetsky, and W.J. Wilbur. Multi-dimensional classification of biomedical text: Toward automated, practical provision of highutility text to diverse users. Journal of Bioinformatics, 24:18:2086–2093, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L N Soldatova</author>
<author>R D King</author>
</authors>
<title>An ontology of scientific experiments.</title>
<date>2006</date>
<journal>Journal of the Royal Society Interface,</journal>
<volume>3</volume>
<contexts>
<context position="2729" citStr="Soldatova and King (2006)" startWordPosition="414" endWordPosition="417">gation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide the identification of negation and speculation. 2 The CoreSC scheme The CoreSC annotation scheme adopts the view that a scientific paper is the human-readable representation of a scientific investigation and therefore seeks to mark the components of a scientific investigation as expressed in the text. CoreSC is ontology-motivated and originates from the CISP meta-data [Soldatova and Liakata (2007)], a subset of classes from EXPO [Soldatova and King (2006)], an ontology for the description of scientific investigations. CISP consists of the concepts: Motivation, Goal, Object, Method, Experiment, Observation, Result and Conclusion, which were validated using an on-line survey as constituting the indispensable set of concepts necessary for the description of a scientific investigation. CoreSC implements these as well as Hypothesis, Model and Background, as a sentence-based annotation scheme for 3-layered annotation. The first layer pertains to the previously mentioned 11 categories, the second layer is for the annotation of properties of the conce</context>
</contexts>
<marker>Soldatova, King, 2006</marker>
<rawString>L.N. Soldatova and R.D. King. An ontology of scientific experiments. Journal of the Royal Society Interface, 3:795–803, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L N Soldatova</author>
<author>M Liakata</author>
</authors>
<title>An ontology methodology and cisp-the proposed core information about scientific papers.</title>
<date>2007</date>
<tech>Technical Report JISC Project Report,</tech>
<institution>Aberystwyth University,</institution>
<note>URL http: //ie-repository.jisc.ac.uk/137/.</note>
<contexts>
<context position="2670" citStr="Soldatova and Liakata (2007)" startWordPosition="404" endWordPosition="407">ntify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide the identification of negation and speculation. 2 The CoreSC scheme The CoreSC annotation scheme adopts the view that a scientific paper is the human-readable representation of a scientific investigation and therefore seeks to mark the components of a scientific investigation as expressed in the text. CoreSC is ontology-motivated and originates from the CISP meta-data [Soldatova and Liakata (2007)], a subset of classes from EXPO [Soldatova and King (2006)], an ontology for the description of scientific investigations. CISP consists of the concepts: Motivation, Goal, Object, Method, Experiment, Observation, Result and Conclusion, which were validated using an on-line survey as constituting the indispensable set of concepts necessary for the description of a scientific investigation. CoreSC implements these as well as Hypothesis, Model and Background, as a sentence-based annotation scheme for 3-layered annotation. The first layer pertains to the previously mentioned 11 categories, the se</context>
</contexts>
<marker>Soldatova, Liakata, 2007</marker>
<rawString>L.N. Soldatova and M. Liakata. An ontology methodology and cisp-the proposed core information about scientific papers. Technical Report JISC Project Report, Aberystwyth University, 2007. URL http: //ie-repository.jisc.ac.uk/137/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
<author>A Siddharthan</author>
</authors>
<title>Whose idea was this, and why does it matter? attributing sicentific work to citations.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL-HLT-07,</booktitle>
<contexts>
<context position="1795" citStr="Teufel and Siddharthan (2007)" startWordPosition="264" endWordPosition="267">ighlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide the identification of negation and speculation. 2 The CoreSC scheme The CoreSC annotation scheme adopts the view that a scien</context>
</contexts>
<marker>Teufel, Siddharthan, 2007</marker>
<rawString>S. Teufel and A. Siddharthan. Whose idea was this, and why does it matter? attributing sicentific work to citations. In Proceedings of NAACL-HLT-07, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Teufel</author>
<author>Advaith Siddharthan</author>
<author>Colin Batchelor</author>
</authors>
<title>Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP-09,</booktitle>
<contexts>
<context position="1764" citStr="Teufel et al. (2009)" startWordPosition="260" endWordPosition="263">the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes representing alternate views of scientific papers and how CoreSCs could be used to guide the identification of negation and speculation. 2 The CoreSC scheme The CoreSC annotation sche</context>
<context position="6691" citStr="Teufel et al. (2009)" startWordPosition="1012" endWordPosition="1015">a total of 225 papers. The CoreSC corpus is now being used to train a classifier for the automation of Core Scientific concepts in papers. 4 Correlating CoreSCs to other zones of interest Given the plethora of annotation schemes, it is interesting to investigate the correlation between different views of scientific papers and how different schemes map to each other. We recently looked at the correlation between the CoreSC scheme, which views papers as the humanly readable representation of scientific investigations and seeks to recover the investigation components within the paper, and AZ-II [Teufel et al. (2009)], which assumes a paper is the attempt of claiming ownership for a new piece of knowledge and aims to recover the rhetorical structure and the relevant stages in the argumentation. By definition, the two schemes focus on different aspects of the papers, with CoreSCs providing more detail with respect to different types of methods and results and AZ-II looking mostly at the appropriation of knowledge claims. Based on a set of 36 papers annotated with both schemes, we were able to confirm that the two schemes are indeed complementary [Liakata et al. (2010)]. CoreSC categories provide a greater </context>
</contexts>
<marker>Teufel, Siddharthan, Batchelor, 2009</marker>
<rawString>Simone Teufel, Advaith Siddharthan, and Colin Batchelor. Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics. In Proceedings of EMNLP-09, Singapore, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vincze</author>
<author>G Szarvas</author>
<author>R Farkas</author>
<author>G Mra</author>
<author>J Csirik</author>
</authors>
<title>The bioscope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9,</title>
<date>2008</date>
<contexts>
<context position="1590" citStr="Vincze et al. (2008)" startWordPosition="232" endWordPosition="235"> how the former could be used to help identify negation and speculation in scientific texts. 1 Introduction The recent surge in the numbers of papers produced, especially in the biosciences, has highlighted the need for automatic processing methods. Work by [Lin (2009)] has shown that methods such as information retrieval are more effective if zones of interest are specified within the papers. Various corpora and annotation schemes have been proposed for designating a variety of linguistic phenomena permeating scientific papers, including negation, hedges, dependencies and semantic relations [Vincze et al. (2008); Pyysalo et al. (2007); Medlock and Briscoe (2007); McIntosh and Curran (2009)]. Other schemes follow the argumentation and citation flow within papers [Teufel et al. (2009); Teufel and Siddharthan (2007)] or indeed a combination of some of the above along multiple dimensions [Shatkay et al. (2008)]. In the following we present the CoreSC annotation scheme and a corpus with CoreSC annotations. The CoreSC scheme is used at the sentence level to identify the core components that constitute a scientific investigation. We discuss how the CoreSC scheme relates to other annotation schemes represent</context>
</contexts>
<marker>Vincze, Szarvas, Farkas, Mra, Csirik, 2008</marker>
<rawString>V. Vincze, G. Szarvas, R. Farkas, G. Mra, and J. Csirik. The bioscope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>