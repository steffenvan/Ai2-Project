<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.506292">
<title confidence="0.995075">
An Analysis of Verbs in Financial News Articles and their Impact on
Stock Price
</title>
<author confidence="0.984148">
Robert P. Schumaker
</author>
<affiliation confidence="0.966487">
Iona College
</affiliation>
<address confidence="0.9525445">
715 North Ave
New Rochelle, NY 10801, USA
</address>
<email confidence="0.999214">
rob.schumaker@gmail.com
</email>
<sectionHeader confidence="0.995615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999156111111111">
Article terms can move stock prices. By ana-
lyzing verbs in financial news articles and
coupling their usage with a discrete machine
learning algorithm tied to stock price move-
ment, we can build a model of price move-
ment based upon the verbs used, to not only
identify those terms that can move a stock
price the most, but also whether they move the
predicted price up or down.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999777555555555">
Predicting market movements is a difficult prob-
lem that deals mostly with trying to model human
behavior. However, with the advent of quantita-
tive trading systems its now easier to dissect their
trading decisions. These systems are nearly instan-
taneous in their ability to make trades, but their
Achilles heel is a reliance on human counterparts
to translate relevant news into numeric data. This
introduces a serious lag-time in trading decisions.
</bodyText>
<sectionHeader confidence="0.911939" genericHeader="method">
2 Literature Review
</sectionHeader>
<bodyText confidence="0.999953">
Information is fed into the market all the time.
While some information sources can move a stock
price, e.g., rumors and scandals; financial news
articles are considered more stable and a form of
its own commodity (Mowshowitz, 1992).
The first challenge of a textual financial predic-
tion system is to manage the large amounts of tex-
tual information that exist for securities such as
periodic SEC filings, press releases and financial
news articles. These textual documents can then
be parsed using Natural Language Processing
(NLP) techniques to identify specific article terms
most likely to cause share price changes. By au-
tomating this process, machines can take advan-
tage of arbitrage opportunities faster than human
counterparts by repeatedly forecasting price fluctu-
ations and executing immediate trades.
Once financial news articles have been gathered,
we need to represent their important features in
machine-friendly form. We chose to implement a
verb representation scheme which was found to be
most predictive for financial news articles.
Assigning a representational mechanism is not
sufficient to address scalability issues associated
with large datasets. A common solution is to in-
troduce a term frequency threshold (Joachims,
1998). This technique not only eliminates noise
from lesser used terms, but also reduces the num-
ber of features to represent. Once scalability issues
have been addressed, the data needs to be prepared
in a more machine-friendly manner. One popular
method is to represent article terms in binary where
the term is either present or not in a given article.
This solution leads to large but sparse matrices
where the number of represented terms throughout
the dataset will greatly outnumber the terms used
in an individual article.
Once financial news articles have been
represented, learning algorithms can then begin to
identify patterns of predictable behavior. One ac-
</bodyText>
<page confidence="0.979076">
3
</page>
<note confidence="0.8729325">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 3–4,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.989389714285714">
cepted method, Support Vector Regression (SVR),
is a regression equivalent of Support Vector Ma-
chines (SVM) but without the aspect of classifica-
tion. This method is also well-suited to handling
textual input as binary representations and has
been used in similar financial news studies (Schu-
maker &amp; Chen, 2006; Tay &amp; Cao, 2001).
</bodyText>
<sectionHeader confidence="0.992971" genericHeader="method">
3 System Design
</sectionHeader>
<bodyText confidence="0.999333666666667">
To analyze our data, we constructed the AZFin-
Text system. The numeric component gathers
price data in one minute increments from a stock
price database. The textual piece gathers financial
news articles from Yahoo! Finance and represents
them by their verbs.
For the machine learning algorithm we chose to
implement the SVR Sequential Minimal Optimiza-
tion function through Weka. This function allows
discrete numeric prediction instead of classifica-
tion. We selected a linear kernel and ten-fold
cross-validation.
</bodyText>
<sectionHeader confidence="0.998654" genericHeader="method">
4 Experimental Design
</sectionHeader>
<bodyText confidence="0.9999676">
For the experiment, we selected a consecutive five
week period of time to serve as our experimental
baseline. This period of research from Oct. 26,
2005 to Nov. 28, 2005 was selected because it did
not have unusual market conditions and was a
good testbed for our evaluation. We further li-
mited our scope of activity to only those compa-
nies listed in the S&amp;P 500 as of Oct. 3, 2005.
Articles gathered during this period were restricted
to occur between the hours of 10:30am and
3:40pm. A further constraint to reduce the effects
of confounding variables was introduced where
two articles on the same company cannot exist
within twenty minutes of each other or both will be
discarded. The above processes filtered the 9,211
candidate news articles gathered during this period
to 2,802, and 10,259,042 stock quotations.
The first task is to extract financial news ar-
ticles. The entire corpus of financial news articles
are represented by their verbs in binary. If a par-
ticular verb is present in the article, that feature is
given a 1, else a 0 and then stored in the database.
To build a model, we first pair together the repre-
sentational verb and stock quotation at the time the
article was released, for each financial news ar-
ticle. This data is then passed to the SVR algo-
rithm where a multi-dimensional price prediction
model is constructed. This weighted model can
then be dissected to determine the most relevant
factors that can influence price movement.
</bodyText>
<sectionHeader confidence="0.996995" genericHeader="conclusions">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999676833333333">
From the trained AZFinText system, it was unsur-
prising that a majority of weight was placed on the
stock price at the time the article was released and
is consistent with prior observation where the ar-
ticle terms were found to be important and were
used to fine-tune price prediction. Of the verbs,
211 were used by the system as support vectors.
An abbreviated multi-dimensional price prediction
model is as follows. The constants represent the
weight given by the SVR algorithm and the verbs
are binary, representing their existence within the
financial news article.
</bodyText>
<equation confidence="0.907478">
0.9997Intial_Price + 0.0045planted +
0.004announcing + 0.003front +
0.0029smaller + 0.0028crude – 0.0029hereto –
0.002comparable – 0.0018charge –
0.0015summit – 0.0015green
</equation>
<bodyText confidence="0.9995381">
The five verbs with highest negative impact on
stock price are hereto, comparable, charge, summit
and green. If the verb hereto were to appear in a
financial article, AZFinText would discount the
price by $0.0029. While this movement may not
appear to be much, the continued usage of negative
verbs is additive.
The five verbs with the highest positive impact
on stock prices are planted, announcing, front,
smaller and crude.
</bodyText>
<sectionHeader confidence="0.999221" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999366266666667">
Joachims, T. 1998. Text Categorization with Support
Vector Machines: Learning with Many Relevant Fea-
tures. European Conference on Machine Learning,
Chemnitz, Germany.
Mowshowitz, A. 1992. On the Market Value of Infor-
mation Commodities. The Nature of Information and
Information Commodities. Journal of the American
Society for Information Science 43(3): 225-232.
Schumaker, R. P. &amp; H. Chen 2006. Textual Analysis of
Stock Market Prediction Using Financial News Ar-
ticles. Americas Conference on Information Systems,
Acapulco, Mexico.
Tay, F. &amp; L. Cao 2001. Application of Support Vector
Machines in Financial Time Series Forecasting.
Omega 29: 309-317.
</reference>
<page confidence="0.996668">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.408617">
<title confidence="0.997392">An Analysis of Verbs in Financial News Articles and their Impact on</title>
<author confidence="0.7580215">Stock Price Robert P Schumaker</author>
<affiliation confidence="0.970154">Iona</affiliation>
<address confidence="0.9830105">715 North New Rochelle, NY 10801,</address>
<email confidence="0.999766">rob.schumaker@gmail.com</email>
<abstract confidence="0.9842445">Article terms can move stock prices. By analyzing verbs in financial news articles and coupling their usage with a discrete machine learning algorithm tied to stock price movement, we can build a model of price movement based upon the verbs used, to not only identify those terms that can move a stock price the most, but also whether they move the predicted price up or down.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machines: Learning with Many Relevant Features.</title>
<date>1998</date>
<booktitle>European Conference on Machine Learning,</booktitle>
<location>Chemnitz, Germany.</location>
<contexts>
<context position="2295" citStr="Joachims, 1998" startWordPosition="361" endWordPosition="362">ng this process, machines can take advantage of arbitrage opportunities faster than human counterparts by repeatedly forecasting price fluctuations and executing immediate trades. Once financial news articles have been gathered, we need to represent their important features in machine-friendly form. We chose to implement a verb representation scheme which was found to be most predictive for financial news articles. Assigning a representational mechanism is not sufficient to address scalability issues associated with large datasets. A common solution is to introduce a term frequency threshold (Joachims, 1998). This technique not only eliminates noise from lesser used terms, but also reduces the number of features to represent. Once scalability issues have been addressed, the data needs to be prepared in a more machine-friendly manner. One popular method is to represent article terms in binary where the term is either present or not in a given article. This solution leads to large but sparse matrices where the number of represented terms throughout the dataset will greatly outnumber the terms used in an individual article. Once financial news articles have been represented, learning algorithms can </context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Joachims, T. 1998. Text Categorization with Support Vector Machines: Learning with Many Relevant Features. European Conference on Machine Learning, Chemnitz, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mowshowitz</author>
</authors>
<title>On the Market Value of Information Commodities.</title>
<date>1992</date>
<journal>The Nature of Information and Information Commodities. Journal of the American Society for Information Science</journal>
<volume>43</volume>
<issue>3</issue>
<pages>225--232</pages>
<contexts>
<context position="1281" citStr="Mowshowitz, 1992" startWordPosition="210" endWordPosition="211">model human behavior. However, with the advent of quantitative trading systems its now easier to dissect their trading decisions. These systems are nearly instantaneous in their ability to make trades, but their Achilles heel is a reliance on human counterparts to translate relevant news into numeric data. This introduces a serious lag-time in trading decisions. 2 Literature Review Information is fed into the market all the time. While some information sources can move a stock price, e.g., rumors and scandals; financial news articles are considered more stable and a form of its own commodity (Mowshowitz, 1992). The first challenge of a textual financial prediction system is to manage the large amounts of textual information that exist for securities such as periodic SEC filings, press releases and financial news articles. These textual documents can then be parsed using Natural Language Processing (NLP) techniques to identify specific article terms most likely to cause share price changes. By automating this process, machines can take advantage of arbitrage opportunities faster than human counterparts by repeatedly forecasting price fluctuations and executing immediate trades. Once financial news a</context>
</contexts>
<marker>Mowshowitz, 1992</marker>
<rawString>Mowshowitz, A. 1992. On the Market Value of Information Commodities. The Nature of Information and Information Commodities. Journal of the American Society for Information Science 43(3): 225-232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Schumaker</author>
<author>H Chen</author>
</authors>
<title>Textual Analysis of Stock Market Prediction Using Financial News Articles. Americas Conference on Information Systems,</title>
<date>2006</date>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="3465" citStr="Schumaker &amp; Chen, 2006" startWordPosition="542" endWordPosition="546">cles have been represented, learning algorithms can then begin to identify patterns of predictable behavior. One ac3 Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 3–4, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics cepted method, Support Vector Regression (SVR), is a regression equivalent of Support Vector Machines (SVM) but without the aspect of classification. This method is also well-suited to handling textual input as binary representations and has been used in similar financial news studies (Schumaker &amp; Chen, 2006; Tay &amp; Cao, 2001). 3 System Design To analyze our data, we constructed the AZFinText system. The numeric component gathers price data in one minute increments from a stock price database. The textual piece gathers financial news articles from Yahoo! Finance and represents them by their verbs. For the machine learning algorithm we chose to implement the SVR Sequential Minimal Optimization function through Weka. This function allows discrete numeric prediction instead of classification. We selected a linear kernel and ten-fold cross-validation. 4 Experimental Design For the experiment, we selec</context>
</contexts>
<marker>Schumaker, Chen, 2006</marker>
<rawString>Schumaker, R. P. &amp; H. Chen 2006. Textual Analysis of Stock Market Prediction Using Financial News Articles. Americas Conference on Information Systems, Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Tay</author>
<author>L Cao</author>
</authors>
<title>Application of Support Vector Machines in Financial Time Series Forecasting.</title>
<date>2001</date>
<journal>Omega</journal>
<volume>29</volume>
<pages>309--317</pages>
<contexts>
<context position="3483" citStr="Tay &amp; Cao, 2001" startWordPosition="547" endWordPosition="550">ed, learning algorithms can then begin to identify patterns of predictable behavior. One ac3 Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 3–4, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics cepted method, Support Vector Regression (SVR), is a regression equivalent of Support Vector Machines (SVM) but without the aspect of classification. This method is also well-suited to handling textual input as binary representations and has been used in similar financial news studies (Schumaker &amp; Chen, 2006; Tay &amp; Cao, 2001). 3 System Design To analyze our data, we constructed the AZFinText system. The numeric component gathers price data in one minute increments from a stock price database. The textual piece gathers financial news articles from Yahoo! Finance and represents them by their verbs. For the machine learning algorithm we chose to implement the SVR Sequential Minimal Optimization function through Weka. This function allows discrete numeric prediction instead of classification. We selected a linear kernel and ten-fold cross-validation. 4 Experimental Design For the experiment, we selected a consecutive </context>
</contexts>
<marker>Tay, Cao, 2001</marker>
<rawString>Tay, F. &amp; L. Cao 2001. Application of Support Vector Machines in Financial Time Series Forecasting. Omega 29: 309-317.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>