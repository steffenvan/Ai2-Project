<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001061">
<title confidence="0.9915305">
Semantic Forensics:
An Application of Ontological Semantics to Information Assurance
</title>
<author confidence="0.939502">
Victor Raskin, Christian F. Hempelmann, and Katrina E. Triezenberg
</author>
<affiliation confidence="0.670483">
NLP Lab and CERIAS
Purdue University
</affiliation>
<email confidence="0.995715">
{vraskin, hempelma, kattriez}@purdue.edu
</email>
<sectionHeader confidence="0.993866" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999984076923077">
The paper deals with the latest application of
natural language processing (NLP), specifically of
ontological semantics (ONSE) to natural language
information assurance and security (NL IAS). It
demonstrates how the existing ideas, methods,
and resources of ontological semantics can be
applied to detect deception in NL text (and,
eventually, in data and other media as well). After
stating the problem, the paper proceeds to a brief
introduction to ONSE, followed by an equally
brief survey of our 5-year-old effort in
“colonizing” IAS. The main part of the paper
deals with the following issues:
</bodyText>
<listItem confidence="0.991667">
• human deception detection abilities and NLP
modeling of it;
• manipulation of fact repositories for this
purpose beyond the current state of the art;
• acquisition of scripts for complex ontological
concepts;
• degrees of lying complexity and feasibility of
their automatic detection.
</listItem>
<bodyText confidence="0.999861214285714">
This is not a report on a system
implementation but rather an application-
establishing proof-of-concept effort based on the
algorithmic and machine-tractable recombination
and extension of the previously implemented
ONSE modules. The strength of the approach is
that it emphasizes the use of the existing NLP
applications, with very few domain- and goal-
specific adjustments, in a most promising and
growing new area of IAS. So, while clearly
dealing with a new application, the paper
addresses theoretical and methodological
extensions of ONSE, as defined currently, that
will be useful for other applications as well.
</bodyText>
<sectionHeader confidence="0.988399" genericHeader="keywords">
1 The Problem
</sectionHeader>
<bodyText confidence="0.999949076923077">
The proposed application falls within the rapidly
growing domain of cyber forensics, and the
inclusion of NLP in it is a desirable and mutually
beneficial goal. Forensic science, in general,
encompasses any scientific discipline that is
concerned with the direct application of scientific
principles and theories to law enforcement
(Saferstein 2004), that is, the systematic search
for, discovery, and application of clues to event
reconstruction—for the purposes of justice. As
with any of the other traditional forensic sciences
(e.g., DNA, Serology, Latent Fingerprint Analysis
etc.) the development of the cyber forensics
</bodyText>
<figureCaption confidence="0.999372">
Figure 1: Resources of Ontological Semantics
</figureCaption>
<bodyText confidence="0.999944235294118">
discipline is based on a sound scientific
foundation, compliance with legal requirements,
and a unified maturation process (Palmer 2002;
Rogers &amp; Seigfried 2004; Whitcomb 2002). The
current foundation for cyber forensics is
multidisciplinary in nature and combines
established pure sciences (e.g., computer science,
math) and applied sciences (e.g., information
technology, engineering, and now NLP). Cyber
forensics is still in search of its theory and
methodology; NLP comes into it on strong and
explicit theoretical foundations (see Nirenburg
and Raskin 2004: 34-91).
As far as we know, no similar research has
been undertaken yet. The Patrick group at the
University of Sydney reported on a &amp;quot;bag-of-
words&amp;quot; system comparing the Nigerian e-mails
with Reuters&apos; financial reports and concluding that
the presence of the personal pronouns I/me and
you in the former but not in the latter violates the
interpersonal relations of the register in the
former, thus leading to characterizing them as
scams (Herke-Couchman et al. 2003; Whitelaw
and Argamon 2004). The difference in the
proposed approach is that it goes beyond treating
words as just character strings and represents their
meanings, as well as those of the sentences and of
their text, explicitly and manipulates them
logically, as it were, rather than statistically. The
result, typical for the comparison of
computational semantics with computational
statistics, is that a semantic forensics system is
capable of identifying specific facts/events that
contribute to the deception and of understanding
what those events are—the characterization of the
text as fraudulent comes then as a trivial side
effect. The Patrick approach can, however, be
used to assists semantic forensics by pre-
identifying some texts as suspicious cheaply and
thus reducing the general semantic forensics to a
more targeted and feasible task (see Section 6
below). Also, their ScamSeek Project has declared
an intention to move towards true meaning
features (http://www.cs.usyd.edu.au/~lkmrl/scam-
seek.htm).
Outside of NLP, the British-centered
linguistic forensics community (IAFL) has been
engaged in traditional largely qualitative stylistic
research in the spirit of the 1960s’ text attribution,
an effort to break the anonymity of a text and to
identify its authorship for the purposes of law
enforcement (McMenamin 2002, Gibbons 2003,
Olsson 2004).
While other disciplines within cyber forensics
explore largely non-textual materials—and those
which look at texts, with the above-mentioned
exceptions. do not do so linguistically—semantic
forensics, as defined here, uses NLP to identify
the clues of deception in NL texts in order to
reconstruct the described events as they actually
occurred. Now, it can be argued, with reason, that
the truthful elements in NL texts are also clues for
event reconstruction and should be included in
semantic forensics, and, of course, in a way they
are. But those, if indeed truthful, do not come
under the task of reconstructing events; rather,
they establish the events. Besides, the truthful
elements of NL texts get the text meaning
representation (TMR) in the normal course of
events, so no special semantic forensic effort
needs to be developed with regard to them. This is
not set in concrete, however, because the
identification and exploration of deception clues
clearly involves the non-deceptive TMRs and
their fragments.
Semantic forensics is firmly based on ONSE,
and a semantic forensic analysis of the text
presupposes and follows the regular ONSE
process of automatic meaning representation of
each input sentence and, ultimately, the text. The
next section offers a brief introduction into the
ONSE process of meaning representation, with an
emphasis on analysis rather than generation and
with a bias towards IAS applications. It can be
largely skipped by those familiar with ONSE.
</bodyText>
<sectionHeader confidence="0.888897" genericHeader="introduction">
2 Ontological Semantics in Brief
</sectionHeader>
<bodyText confidence="0.9998625">
ONSE contains several modules, with an ontology
at the center; the other important modules are
lexicons of languages and a fact repository, in
which information about the world is stored, and,
of course, the analyzer and generator. The
analytical goal of ONSE is to produce a TMR for
NL input as well as NL or other output for each
TMR (see figure 1).
</bodyText>
<figure confidence="0.38704925">
PAY
definition value “to compensate
somebody for goods
or services rendered”
is-a value EVERYDAY-
FINANCIAL-EVENT
subclasses value PAY-TAX
SUBSCRIBE-TO
</figure>
<footnote confidence="0.936379">
agent sem HUMAN
relaxable-to ORGANIZATION
theme default MONEY
sem COMMODITY
relaxable-to EVENT
patient sem HUMAN
relaxable-to ORGANIZATION
</footnote>
<figureCaption confidence="0.996734">
Figure 2: Ontological Concept PAY
</figureCaption>
<bodyText confidence="0.996710375">
The ontology is a tangled hierarchy (lattice)
of concepts, beginning at the root ALL, branching
into OBJECT, EVENT, and PROPERTY, and so forth.
Each node of the hierarchy is a concept with a set
of properties, many of which are inherited from
its ancestors, and at least one property other than
the IS-A property is distinguished from its parent
node as well as from its sibling nodes. The
ontological concept for PAY might therefore look
like figure 2 (cf. Nirenburg and Raskin 2004:
196ff.).
As we see, the IS-A and SUBCLASSES slots are
filled with other ontological concepts, as are
AGENT, THEME, and PATIENT, the case-role slots.
VALUE, SEM, RELAXABLE-TO and DEFAULT are all
facets of their slots.
</bodyText>
<figure confidence="0.9963010625">
good-adj1
cat adj
SYN-STRUC
1 root $var1
cat n
mods root good
2 root $var0
cat adj
subj root $var1
cat n
SEM-STRUC
modality type evaluative
value value &gt;0.75
relaxable-to &gt;0.6
scope ^$var1
attributed-to *speaker*
</figure>
<figureCaption confidence="0.999949">
Figure 3: Lexical Entry for “good”
</figureCaption>
<bodyText confidence="0.999961794117647">
Lexicons contain the actual words of a
language, in contrast to the ontology’s universal,
language-independent concepts. The entry for
each word in the lexicon contains all possible
senses of that word, labeled with a part of speech
and a sense number. The lexical entry for the
English word pay contains three senses,
respectively pay-n1, pay-n2, and pay-v1. Each of
the senses is then assigned, most importantly, the
information about the acceptable syntactic
environments for the sense, or SYN-STRUC, and
information about the word’s meaning, or SEM-
STRUC. It is in SEM-STRUC that each lexical item
is linked to one or more ontological concepts, or
to literals. The lexical entry for the English
adjective good looks something like figure 3.
When a text is fed into the ONSE system, its
lexical items are identified, as well as several
TMR parameters, such as discourse relations
including modalities, aspect, information about
ordering and duration in time, style, and sets of
concepts working together. The first step in
building a TMR is finding meanings for heads of
clauses in the syntactic representation of input,
which are most commonly verbs. The TMR,
however, will typically end up containing more
event instances than there are verbs in the original
text. After identifying these events, building the
TMR is a (non-trivial) matter of fitting all the
other information of the text into the filler slots of
the events and the additional parameters. In figure
4 are the much-simplified TMRs for three related
sentences, which demonstrate how small changes
in texts affect TMRs.
</bodyText>
<figure confidence="0.988920714285714">
Who won the match?
win-1
theme value sports-match-2
request-information-1
theme value win-1.agent
Did Arsenal win the match?
win-1
agent value Arsenal
theme value sports-match-1
request-information-1
theme value win-1
Was it Arsenal who won the match?
win-1
agent value Arsenal
theme value sports-match-1
request-information-1
theme value win-1
modality-1
type salience
scope win-1.theme
value 1
</figure>
<figureCaption confidence="0.999993">
Figure 4: TMR Example
</figureCaption>
<bodyText confidence="0.9999606">
The next section reviews the NL IAS
applications discovered and explored—from
initial steps to pilot implementations—in the
ongoing effort to export NLP into computer and
information security.
</bodyText>
<sectionHeader confidence="0.989325" genericHeader="method">
3 Applications of NLP to Information
Assurance and Security
</sectionHeader>
<bodyText confidence="0.999992722222222">
In the last 5 years, a CERIAS-based team led by a
computer scientist and an NLP expert has steadily
expanded its groundbreaking effort in improving,
focusing, and strengthening information assurance
and security by applying the NLP resources to
them. The result has been a growing number of
applications, some of them NL counterparts of
pre-existing applications, others NL extensions
and developments of known applications, and still
others unique to NL IAS. In the most
implemented one, NL watermarking (see Atallah
et al. 2002), a sophisticated mathematical
procedure, based on a secret large prime number,
selects certain sentences in a text for watermark
bearing and transforms their TMRs into bitstrings
A new TMR contradicting a previously
processed one should lead to a fact repository
flag, and this is where we are moving next.
</bodyText>
<sectionHeader confidence="0.8893825" genericHeader="method">
5 Using the Fact Repository for
Deception Detection
</sectionHeader>
<bodyText confidence="0.986206681818182">
The fact repository (FR—see Nirenburg and
Raskin 2004: 350-1), so far the least developed
static resource in ONSE, records the remembered
event instances. In principle, it should record all
of them. Realistically, it records them selectively
to suit the needs of an implementation. Thus, in
CRESP, a small QA system for queries about the
2000 Olympics in Sydney, the FR remembered all
the nations, all the participants, all the competitive
events, and all the results. A SF NLP system may
start at the same level of prominence (and detect
one’s lie about having participated in the Games
and/or achieved a better result), but like almost all
NLP systems with reasoning abilities, it will be
only as powerful as its FR allows.
A contradiction will be flagged when two
TMR (fragments) are discovered: For example,
one having been just processed for John
is/was/will be in Barcelona at noon on the 25th (of
July 2004) and the other in the FR for John
is/was/will be in Valencia at noon on the 25th (of
July 2004)—or their paraphrases (see figure 5).
</bodyText>
<table confidence="0.9535745">
human-17
name John-23
location Barcelona
time noon, July 25, 2004
human-89
name John-23
location Valencia
time noon, July 25, 2004
</table>
<figureCaption confidence="0.994163">
Figure 5: Fact Repository Sample Entries
</figureCaption>
<bodyText confidence="0.983687515151515">
In the case of Papa Dean’s occupation,
apparently too shameful for the reporter to
mention even after he had divulged the Park
Avenue childhood, hereditary Republicanism, and
discriminatory country club and even though there
are still a few stockbrokers on this side of the
bars, the FR will easily detect it by presenting this
information, very simplistically, as in figure 6.
To detect a gloss-over, it is not quite enough
to receive a new TMR which contains an event
involving a different interaction between these
two individuals at the same time. The co-
reference microtheory (see Nirenburg and Raskin
2004: 301-5) will have to be able to determine or
at least to suspect that these events are indeed one
and the same event rather than two consecutive or
even parallel events. Even the time parameters are
not a trivial task to equate, as in the case of I have
not much opportunity to talk to John lately and
John insulted me last May. It would be trivial, of
course, if the temporal adverbials were since that
night at Maude’s and that night at Maude’s,
respectively, but a human sleuth does not get such
incredibly easy clues most of the time and has to
operate on crude proximity and hypothesizing.
Also helping him or her is a powerful inferencing
engine, obviously a must for an NLP system of
any reasonable complexity, reinforced by a
microtheory of euphemisms, which must contain
representative sets of event types that people lie
about and of fossilized, cliché-like ways of lying
about them, as in How is this paper?—Well... it’s
different!
</bodyText>
<figure confidence="0.997673333333333">
human-1
name Howard Dean
age adult
occupation physician
human-2
name Judy Dean
age adult
occupation physician
human-3
name Papa Dean
age adult (very: rather dead, actually)
occupation unknown
</figure>
<figureCaption confidence="0.999947">
Figure 6: Fact Repository Sample Entries
</figureCaption>
<bodyText confidence="0.999989545454545">
The reason we think that the loyal secretary’s
type of lying is harder to detect is not because it
may involve more inferencing of a more complex
kind—this is not necessarily so. It has to do with
the notion of the whole truth: It is not realistic to
expect a human, let alone an SF NLP to suspect
any information to be incomplete and subject
every single TMR to the ‘and what else did he do
downtown’ type of query. But, in many cases, this
is necessary to do, which brings up the useful
distinction between general and targeted SF.
</bodyText>
<sectionHeader confidence="0.935855" genericHeader="method">
6 Feasibility of Semantic Forensic
Systems
</sectionHeader>
<bodyText confidence="0.999953976744186">
A general SF (GSF) task is, basically, a fishing
expedition. An SF NLP system may indeed
expose obvious contradictions and many
omissions. It is a long and expensive process,
however, definitely overloading the system’s FR.
Inferring from every established contradiction or
omission, while possibly valuable forensically, is
an unaffordable luxury in this kind of task. It may,
however, be a necessary evil: for instance, if an
SF NLP system is to address a source that is
known to be tainted or if it to be used to classify
texts by the degree of their trustworthiness—quite
a possible assignment.
Humans do a degree of general SF under
similar circumstances. But even in an exchange
without a prior agenda, such as a conversation
with a stranger under neutral, casual, indifferent
circumstances, the SF/DD module may not be
activated unless flagged by, again, a
contradiction, an omission, etc. And such a flag
will transform general SF into targeted SF (TSF).
Now, TSF is what professional forensics does
for a living, and there is no reason why the entry-
level SF NLP systems should not be all TSF.
Even in the case of the Dean text, a TSF system
(“look for anything compromising in the
candidate’s background”) will be able to detect
the occupation omission much faster. A TSF is
simpler and cheaper, and the FR use is much more
reasonable and manageable: it can store only very
selective, limited material. The flip side of a TSF
system is the easy ability to overlook highly
related information an inference away, so we have
reasons to suspect that a quality TSF NLP system
is not that much simpler than, say, a limited
domain GSF system.
What is important to realize is that some NLP
systems with SF capabilities are within reach in
ONSE, using the already available resources,
possibly with some modifications, primarily if not
entirely on the static side, and that is not much
different than changing domains for a “regular”
NLP system (see Raskin et al. 2002b).
</bodyText>
<sectionHeader confidence="0.9038515" genericHeader="method">
7 Using Scripts of Complex Events for
Deception Detection
</sectionHeader>
<bodyText confidence="0.999816192307692">
A main tool for DD, in particular TSF, is the
expansion of the ontology by acquiring scripts of
complex events, already found necessary for other
higher-end NLP tasks (see Raskin et al. 2003).
There are strong connections among elements
of many texts. These have to do with the
understanding that individual propositions may
hold well-defined places in “routine,” “typical”
sequences of events (often called complex events,
scripts or scenarios) that happen in the world,
with a well-specified set of object-like entities
that appear in different roles throughout that
sequence. A script captures the entities of such an
event and their temporal and causal sequences, as
shown for the complex event BANKRUPTCY in
figure 7.
As a general tool in ONSE, the scripts that get
instantiated from the text input provide
expectations for processing further sentences in a
text. Indeed, if a sentence in a text can be seen as
instantiating a script in the nascent TMR, the
analysis and disambiguation of subsequent
sentences can be aided by the expectation that
propositions contained in them are instantiations
of event types that are listed as components of the
activated script.
</bodyText>
<figure confidence="0.999072125000001">
BANKRUPTCY
is-a financial-event
agent corporation-1
human-1
lending-institution-1
corporation-2
human-2
precondition approach-bankruptcy
has-parts (IF
AND
modality.scope = pay
modality.value &lt; .5
THEN bankruptcy-chapter-7
ELSE bankruptcy-chapter-11)
BANKRUPTCY-APPROACH-STATE
is-a financial-event
agent bankruptcy.agent
destination bankruptcy
agent bankruptcy.agent
has-parts
(IF
AND
owe
agent corporation-1
human-1
beneficiary human-2
employed-by corporation-1
lending-institution-2
corporation-2
theme money
pay
agent corporation-1
human-1
beneficiary human-2
lending-institution-1
corporation-2
theme money
THEN bankruptcy
agent corporation-1
human-1
CONCEAL
is-a sales-event
agent bankruptcy.agent
theme assets
owned-by bankruptcy.agent
precondition bankruptcy
agent bankruptcy.agent
time.sales-event ≥ time.bankruptcy-approach-state
</figure>
<figureCaption confidence="0.912201">
Figure 7: Simplified Fragments of Scripts in the
BANKRUPTCY Domain
</figureCaption>
<bodyText confidence="0.99998462">
In addition, the expectations that scripts
provide play a crucial role for DD, namely in the
detection of omission, in two complementary
ways.
The more obvious one is the need for an
expectation of what information is to be found in
a text in order to be able to infer gaps. A common
attempt at deception in bankruptcy cases, for
example, is concealment of pre-bankruptcy
conversions of property from creditors, which is a
major factor considered by the courts in
determining whether there was an intent to hinder,
delay or defraud in a bankruptcy. Thus, if a sale of
assets by a company prior to its filing bankruptcy
is found in a text and there is no mention of how
closely to the filing this conversion took place,
this needs to raise a flag that possibly
concealment took place. This can be established
since CONCEALMENT is defined as part of the
script BANKRUPTCY, which is instantiated for the
TMR of the text. If it can be established, from the
text itself or the FR, that the sale of the assets took
place while the company was approaching the
state of bankruptcy, the omission of the specific
time of sale in the report constitutes deception.
Here, the script facilitates the targeting of SF (see
previous section) by mapping where omissions in
the text point to the omission of crucial
information.
The second mechanism by which scripts
facilitate DD is when an event that occurs
commonly or exclusively as a subevent of a
script, which is otherwise not mentioned, is found
in a text. Here, the inference should be that the
larger context of this subevent, captured by the
script, is to be concealed. If, for example, a
company issues a report that mentions the layoff
of some of its employees, this should lead to the
inference that it approaches the state of
bankruptcy, for which layoffs are a possible
subevent.
Simplified to a few subevents, these two
DD mechanisms on the basis of scripts can be
summarized as follows (cf. figure 8): 1. If a
necessary element of a script is missing it is likely
to be intentionally omitted. 2. If an element that
commonly occurs as part of a script is found in a
text, but no other element of it, that is, the script is
underinstantiated, the script is likely to be
intentionally omitted.
</bodyText>
<table confidence="0.7917818">
SCRIPT
has-part
AND
event-1 found in text
event-2 found in text
event-3 not found in text
event-4 found in text
SCRIPT
has-part
AND
</table>
<tableCaption confidence="0.59428275">
event-1 not found in text
event-2 not found in text
event-3 found in text
event-4 not found in text
</tableCaption>
<figureCaption confidence="0.995748">
Figure 8: Simplified Script Structures
</figureCaption>
<sectionHeader confidence="0.986232" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.99998747826087">
The main thrust of the paper has been not so much
the establishment of a sexy application as to
demonstrate that the rich resources of NLP, in
general, and ONSE, in particular, are versatile
enough to be extended to interesting new uses and
that getting there involves theoretical and
methodological developments that are generally
good for the field rather than just for SF (e.g.,
who will refuse a microtheory of euphemisms?).
Throughout, we have insinuated, ever so subtly,
that the tasks in hand are not manageable by any
of the past or current meaning-avoiding, non-
representational approaches. This is not to say that
a good SF NLP system must be statistics-free:
Crude measures are good to have for heuristic and
other startup purposes—but it is TMR elements
that such statistics will be counting. We have left
out many aspects of SF, such as potential demand,
which is great, and other practical considerations.
As resources permit, we have been moving
consistently to enrich our ONSE resources with
IAS capabilities and functionalities, and SF is the
latest but, very probably, not the last of those.
</bodyText>
<sectionHeader confidence="0.996603" genericHeader="acknowledgments">
9 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999954333333333">
We are grateful to the two anonymous referees for
their thought-provoking remarks. We appreciate
Professor Jon Patrick’s unsolicited comments as
well as his making two hard-to-access papers
from his research group available to us. We have
profited greatly from the cooperation with our
CERIAS colleagues and from the Center’s
support for the NL IAS endeavors over the last 5
years.
</bodyText>
<sectionHeader confidence="0.999338" genericHeader="references">
10 References
</sectionHeader>
<reference confidence="0.999853851485148">
Atallah, M. J., V. Raskin, M. Crogan, C. F.
Hempelmann, F. Kerschbaum, D. Mohamed,
and S. Naik. 2001. Natural Language
Watermarking: Design, Analysis, and a Proof-
of-Concept Implementation. In: I. S.
Moskowitz (ed.), Information Hiding: 4th
International Workshop, IH 2001, Pittsburgh,
PA, USA, April 2001 Proceedings. Berlin:
Springer, 185-199.
Atallah, M. J., V. Raskin, C. F. Hempelmann, M.
Karahan, R. Sion, U. Topkara, and K. E.
Triezenberg. 2002. Natural Language
Watermarking and Tamperproofing. In: F. A.
P. Petitcolas (ed.), Information Hiding: 5th
International Workshop, IH 2002,
Proceedings. Berlin: Springer, 196-210.
Barwise, J., and J. Perry. 1983. Situations and
Attitudes. Cambridge, MA: MIT Press.
Bennett, K. 2003. Semantic mimicking. CERIAS
TR (www.cerias.purdue.edu), Purdue
University, W. Lafayette, IN.
Herke-Couchman, M., C. Whitelaw, and J. Patrick
2003. Identifying interpersonal features using
systemic features, AAAI Symposium.
Gibbons, J. 2003. Forensic Linguistics: An
Introduction to Language in the Justice
System. Oxford: Blackwell.
McMenamin, G. R. 2002. Forensic Linguistics:
Advances in Forensic Stylistics. Boca Raton,
LA: CRC Press.
Mohamed, D. 2001. Ontological Semantics
Methods for Automatic Downgrading. An
unpublished Masters’ thesis, Program in
Linguistics and CERIAS, Purdue University.
Nirenburg, S. and V. Raskin. 2004. Ontological
Semantics. Cambridge, MA: MIT Press
(forthcoming).
Olsson, J. 2004. Forensic Linguistics: An
Introduction to Language, Crime and the
Law. London-New York: Continuum.
Palmer, G. 2002. Forensic analysis in a digital
world. International Journal of Digital
Evidence, Spring 2002, 1.
Raskin, V. 1987. The semantics of lying. In: R.
Crespo, B. D. Smith, and H. Schultinik (eds.),
Aspects of Language: Studies in Honour of
Mario Alinei, Vol. II. Theoretical and Applied
Semantics. Amsterdam: Rodopi, 443-469.
Raskin, V. 2004. Natural Language Information
Assurance and Security. Tutorial, COLING
2004, Geneva, Switzerland. August 22.
Raskin, V., M. J. Atallah, C. J. McDonough, and
S. Nirenburg. 2001a. Natural Language
Processing for Information Assurance and
Security: An Overview and Implementations.
In: M. Schaefer (ed.), Proceedings. New
Security Paradigm Workshop. September
18th-22nd, 2000, Ballycotton, County Cork
Ireland. New York: ACM Press, 51-65.
Raskin, V., M. J. Atallah, C. F. Hempelmann, and
D. Mohamed. 2001b. Hybrid Data and Text
System for Downgrading Sensitive
Documents. CERIAS TR.
Raskin, V., C. F. Hempelmann, K. E.
Triezenberg, and S. Nirenburg. 2002a.
Ontology in information security: A useful
theoretical foundation and methodological
tool. In: V. Raskin &amp; C. F. Hempelmann
(eds.), Proceedings. New Security Paradigms
Workshop 2001. September 10th-13th,
Cloudcroft, NM, USA, New York: ACM
Press, 53-59.
Raskin, V., S. Nirenburg, M. J. Atallah, C. F.
Hempelmann, and K. E. Triezenberg. 2002b.
Why NLP should move into IAS. In: Steven
Krauwer (ed.), Proceedings of the Workshop
on a Roadmap for Computational Linguistics,
Taipei, Taiwan: Academia Sinica, 2002, 1-7.
Raskin, V., S. Nirenburg, C. F. Hempelmann, I.
Nirenburg, K. E. Triezenberg. 2003. The
Genesis of a Script for Bankruptcy in
Ontological Semantics. Proceedings of the
HLT-NAACL 2003 Workshop on Text
Meaning. Available at:
http://acl.ldc.upenn.edu/W/W03/W03-
0905.pdf
Rogers, M. and K. Seigfried. 2004. The future of
computer forensics: A needs analysis survey.
Computers and Security, 23, 1, 12-16.
Saferstein, R. 2004. Criminalistics: An
introduction to forensic science. New York:
Prentice Hall.
Whitcomb, C. 2002. A historical perspective of
digital evidence: A forensic scientist’s view.
International Journal of Digital Evidence,
Spring 2002, 1
Whitelaw, C., and Sh. Argamon 2004. Systemic
functional features in stylistic text
classification. Ms., Sydney Language
Technology Research Group, University of
Sydney, Sydney, Australia.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.241047">
<title confidence="0.99953">Semantic Forensics: An Application of Ontological Semantics to Information Assurance</title>
<author confidence="0.990332">Victor Raskin</author>
<author confidence="0.990332">Christian F Hempelmann</author>
<author confidence="0.990332">E Katrina</author>
<affiliation confidence="0.4467405">NLP Lab and Purdue</affiliation>
<email confidence="0.997668">vraskin@purdue.edu</email>
<email confidence="0.997668">hempelma@purdue.edu</email>
<email confidence="0.997668">kattriez@purdue.edu</email>
<abstract confidence="0.975467">The paper deals with the latest application of natural language processing (NLP), specifically of ontological semantics (ONSE) to natural language information assurance and security (NL IAS). It demonstrates how the existing ideas, methods, and resources of ontological semantics can be applied to detect deception in NL text (and, eventually, in data and other media as well). After stating the problem, the paper proceeds to a brief</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M J Atallah</author>
<author>V Raskin</author>
<author>M Crogan</author>
<author>C F Hempelmann</author>
<author>F Kerschbaum</author>
<author>D Mohamed</author>
<author>S Naik</author>
</authors>
<title>Natural Language Watermarking: Design, Analysis, and a Proofof-Concept Implementation. In:</title>
<date>2001</date>
<booktitle>Information Hiding: 4th International Workshop, IH 2001,</booktitle>
<pages>185--199</pages>
<editor>I. S. Moskowitz (ed.),</editor>
<publisher>Springer,</publisher>
<location>Pittsburgh, PA, USA,</location>
<marker>Atallah, Raskin, Crogan, Hempelmann, Kerschbaum, Mohamed, Naik, 2001</marker>
<rawString>Atallah, M. J., V. Raskin, M. Crogan, C. F. Hempelmann, F. Kerschbaum, D. Mohamed, and S. Naik. 2001. Natural Language Watermarking: Design, Analysis, and a Proofof-Concept Implementation. In: I. S. Moskowitz (ed.), Information Hiding: 4th International Workshop, IH 2001, Pittsburgh, PA, USA, April 2001 Proceedings. Berlin: Springer, 185-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Atallah</author>
<author>V Raskin</author>
<author>C F Hempelmann</author>
<author>M Karahan</author>
<author>R Sion</author>
<author>U Topkara</author>
<author>K E Triezenberg</author>
</authors>
<title>Natural Language Watermarking and Tamperproofing.</title>
<date>2002</date>
<booktitle>Information Hiding: 5th International Workshop, IH 2002, Proceedings.</booktitle>
<pages>196--210</pages>
<editor>In: F. A. P. Petitcolas (ed.),</editor>
<publisher>Springer,</publisher>
<location>Berlin:</location>
<contexts>
<context position="10753" citStr="Atallah et al. 2002" startWordPosition="1645" endWordPosition="1648">ter and information security. 3 Applications of NLP to Information Assurance and Security In the last 5 years, a CERIAS-based team led by a computer scientist and an NLP expert has steadily expanded its groundbreaking effort in improving, focusing, and strengthening information assurance and security by applying the NLP resources to them. The result has been a growing number of applications, some of them NL counterparts of pre-existing applications, others NL extensions and developments of known applications, and still others unique to NL IAS. In the most implemented one, NL watermarking (see Atallah et al. 2002), a sophisticated mathematical procedure, based on a secret large prime number, selects certain sentences in a text for watermark bearing and transforms their TMRs into bitstrings A new TMR contradicting a previously processed one should lead to a fact repository flag, and this is where we are moving next. 5 Using the Fact Repository for Deception Detection The fact repository (FR—see Nirenburg and Raskin 2004: 350-1), so far the least developed static resource in ONSE, records the remembered event instances. In principle, it should record all of them. Realistically, it records them selectivel</context>
</contexts>
<marker>Atallah, Raskin, Hempelmann, Karahan, Sion, Topkara, Triezenberg, 2002</marker>
<rawString>Atallah, M. J., V. Raskin, C. F. Hempelmann, M. Karahan, R. Sion, U. Topkara, and K. E. Triezenberg. 2002. Natural Language Watermarking and Tamperproofing. In: F. A. P. Petitcolas (ed.), Information Hiding: 5th International Workshop, IH 2002, Proceedings. Berlin: Springer, 196-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Barwise</author>
<author>J Perry</author>
</authors>
<title>Situations and Attitudes.</title>
<date>1983</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Barwise, Perry, 1983</marker>
<rawString>Barwise, J., and J. Perry. 1983. Situations and Attitudes. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bennett</author>
</authors>
<title>Semantic mimicking.</title>
<date>2003</date>
<tech>CERIAS TR (www.cerias.purdue.edu),</tech>
<institution>Purdue University,</institution>
<location>W. Lafayette, IN.</location>
<marker>Bennett, 2003</marker>
<rawString>Bennett, K. 2003. Semantic mimicking. CERIAS TR (www.cerias.purdue.edu), Purdue University, W. Lafayette, IN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Herke-Couchman</author>
<author>C Whitelaw</author>
<author>J Patrick</author>
</authors>
<title>Identifying interpersonal features using systemic features,</title>
<date>2003</date>
<journal>AAAI Symposium.</journal>
<contexts>
<context position="3455" citStr="Herke-Couchman et al. 2003" startWordPosition="512" endWordPosition="515">Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters&apos; financial reports and concluding that the presence of the personal pronouns I/me and you in the former but not in the latter violates the interpersonal relations of the register in the former, thus leading to characterizing them as scams (Herke-Couchman et al. 2003; Whitelaw and Argamon 2004). The difference in the proposed approach is that it goes beyond treating words as just character strings and represents their meanings, as well as those of the sentences and of their text, explicitly and manipulates them logically, as it were, rather than statistically. The result, typical for the comparison of computational semantics with computational statistics, is that a semantic forensics system is capable of identifying specific facts/events that contribute to the deception and of understanding what those events are—the characterization of the text as fraudul</context>
</contexts>
<marker>Herke-Couchman, Whitelaw, Patrick, 2003</marker>
<rawString>Herke-Couchman, M., C. Whitelaw, and J. Patrick 2003. Identifying interpersonal features using systemic features, AAAI Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gibbons</author>
</authors>
<title>Forensic Linguistics: An Introduction to Language in the Justice System.</title>
<date>2003</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="4802" citStr="Gibbons 2003" startWordPosition="713" endWordPosition="714">e texts as suspicious cheaply and thus reducing the general semantic forensics to a more targeted and feasible task (see Section 6 below). Also, their ScamSeek Project has declared an intention to move towards true meaning features (http://www.cs.usyd.edu.au/~lkmrl/scamseek.htm). Outside of NLP, the British-centered linguistic forensics community (IAFL) has been engaged in traditional largely qualitative stylistic research in the spirit of the 1960s’ text attribution, an effort to break the anonymity of a text and to identify its authorship for the purposes of law enforcement (McMenamin 2002, Gibbons 2003, Olsson 2004). While other disciplines within cyber forensics explore largely non-textual materials—and those which look at texts, with the above-mentioned exceptions. do not do so linguistically—semantic forensics, as defined here, uses NLP to identify the clues of deception in NL texts in order to reconstruct the described events as they actually occurred. Now, it can be argued, with reason, that the truthful elements in NL texts are also clues for event reconstruction and should be included in semantic forensics, and, of course, in a way they are. But those, if indeed truthful, do not come</context>
</contexts>
<marker>Gibbons, 2003</marker>
<rawString>Gibbons, J. 2003. Forensic Linguistics: An Introduction to Language in the Justice System. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R McMenamin</author>
</authors>
<title>Forensic Linguistics: Advances in Forensic Stylistics.</title>
<date>2002</date>
<publisher>CRC Press.</publisher>
<location>Boca Raton, LA:</location>
<contexts>
<context position="4788" citStr="McMenamin 2002" startWordPosition="711" endWordPosition="712">eidentifying some texts as suspicious cheaply and thus reducing the general semantic forensics to a more targeted and feasible task (see Section 6 below). Also, their ScamSeek Project has declared an intention to move towards true meaning features (http://www.cs.usyd.edu.au/~lkmrl/scamseek.htm). Outside of NLP, the British-centered linguistic forensics community (IAFL) has been engaged in traditional largely qualitative stylistic research in the spirit of the 1960s’ text attribution, an effort to break the anonymity of a text and to identify its authorship for the purposes of law enforcement (McMenamin 2002, Gibbons 2003, Olsson 2004). While other disciplines within cyber forensics explore largely non-textual materials—and those which look at texts, with the above-mentioned exceptions. do not do so linguistically—semantic forensics, as defined here, uses NLP to identify the clues of deception in NL texts in order to reconstruct the described events as they actually occurred. Now, it can be argued, with reason, that the truthful elements in NL texts are also clues for event reconstruction and should be included in semantic forensics, and, of course, in a way they are. But those, if indeed truthfu</context>
</contexts>
<marker>McMenamin, 2002</marker>
<rawString>McMenamin, G. R. 2002. Forensic Linguistics: Advances in Forensic Stylistics. Boca Raton, LA: CRC Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mohamed</author>
</authors>
<title>Ontological Semantics Methods for Automatic Downgrading. An unpublished</title>
<date>2001</date>
<booktitle>Masters’ thesis, Program in Linguistics and CERIAS,</booktitle>
<institution>Purdue University.</institution>
<marker>Mohamed, 2001</marker>
<rawString>Mohamed, D. 2001. Ontological Semantics Methods for Automatic Downgrading. An unpublished Masters’ thesis, Program in Linguistics and CERIAS, Purdue University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nirenburg</author>
<author>V Raskin</author>
</authors>
<title>Ontological Semantics.</title>
<date>2004</date>
<publisher>MIT Press</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="2990" citStr="Nirenburg and Raskin 2004" startWordPosition="436" endWordPosition="439">e cyber forensics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established pure sciences (e.g., computer science, math) and applied sciences (e.g., information technology, engineering, and now NLP). Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters&apos; financial reports and concluding that the presence of the personal pronouns I/me and you in the former but not in the latter violates the interpersonal relations of the register in the former, thus leading to characterizing them as scams (Herke-Couchman et al. 2003; Whitelaw and Argamon 2004). The difference in the proposed approach is that it goes beyond treating words as just character strings a</context>
<context position="7497" citStr="Nirenburg and Raskin 2004" startWordPosition="1138" endWordPosition="1141">GANIZATION theme default MONEY sem COMMODITY relaxable-to EVENT patient sem HUMAN relaxable-to ORGANIZATION Figure 2: Ontological Concept PAY The ontology is a tangled hierarchy (lattice) of concepts, beginning at the root ALL, branching into OBJECT, EVENT, and PROPERTY, and so forth. Each node of the hierarchy is a concept with a set of properties, many of which are inherited from its ancestors, and at least one property other than the IS-A property is distinguished from its parent node as well as from its sibling nodes. The ontological concept for PAY might therefore look like figure 2 (cf. Nirenburg and Raskin 2004: 196ff.). As we see, the IS-A and SUBCLASSES slots are filled with other ontological concepts, as are AGENT, THEME, and PATIENT, the case-role slots. VALUE, SEM, RELAXABLE-TO and DEFAULT are all facets of their slots. good-adj1 cat adj SYN-STRUC 1 root $var1 cat n mods root good 2 root $var0 cat adj subj root $var1 cat n SEM-STRUC modality type evaluative value value &gt;0.75 relaxable-to &gt;0.6 scope ^$var1 attributed-to *speaker* Figure 3: Lexical Entry for “good” Lexicons contain the actual words of a language, in contrast to the ontology’s universal, language-independent concepts. The entry fo</context>
<context position="11166" citStr="Nirenburg and Raskin 2004" startWordPosition="1710" endWordPosition="1713">NL counterparts of pre-existing applications, others NL extensions and developments of known applications, and still others unique to NL IAS. In the most implemented one, NL watermarking (see Atallah et al. 2002), a sophisticated mathematical procedure, based on a secret large prime number, selects certain sentences in a text for watermark bearing and transforms their TMRs into bitstrings A new TMR contradicting a previously processed one should lead to a fact repository flag, and this is where we are moving next. 5 Using the Fact Repository for Deception Detection The fact repository (FR—see Nirenburg and Raskin 2004: 350-1), so far the least developed static resource in ONSE, records the remembered event instances. In principle, it should record all of them. Realistically, it records them selectively to suit the needs of an implementation. Thus, in CRESP, a small QA system for queries about the 2000 Olympics in Sydney, the FR remembered all the nations, all the participants, all the competitive events, and all the results. A SF NLP system may start at the same level of prominence (and detect one’s lie about having participated in the Games and/or achieved a better result), but like almost all NLP systems</context>
<context position="12942" citStr="Nirenburg and Raskin 2004" startWordPosition="2006" endWordPosition="2009">Sample Entries In the case of Papa Dean’s occupation, apparently too shameful for the reporter to mention even after he had divulged the Park Avenue childhood, hereditary Republicanism, and discriminatory country club and even though there are still a few stockbrokers on this side of the bars, the FR will easily detect it by presenting this information, very simplistically, as in figure 6. To detect a gloss-over, it is not quite enough to receive a new TMR which contains an event involving a different interaction between these two individuals at the same time. The coreference microtheory (see Nirenburg and Raskin 2004: 301-5) will have to be able to determine or at least to suspect that these events are indeed one and the same event rather than two consecutive or even parallel events. Even the time parameters are not a trivial task to equate, as in the case of I have not much opportunity to talk to John lately and John insulted me last May. It would be trivial, of course, if the temporal adverbials were since that night at Maude’s and that night at Maude’s, respectively, but a human sleuth does not get such incredibly easy clues most of the time and has to operate on crude proximity and hypothesizing. Also</context>
</contexts>
<marker>Nirenburg, Raskin, 2004</marker>
<rawString>Nirenburg, S. and V. Raskin. 2004. Ontological Semantics. Cambridge, MA: MIT Press (forthcoming).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Olsson</author>
</authors>
<title>Forensic Linguistics: An Introduction to Language, Crime and the Law.</title>
<date>2004</date>
<publisher>Continuum.</publisher>
<location>London-New York:</location>
<contexts>
<context position="4816" citStr="Olsson 2004" startWordPosition="715" endWordPosition="716">picious cheaply and thus reducing the general semantic forensics to a more targeted and feasible task (see Section 6 below). Also, their ScamSeek Project has declared an intention to move towards true meaning features (http://www.cs.usyd.edu.au/~lkmrl/scamseek.htm). Outside of NLP, the British-centered linguistic forensics community (IAFL) has been engaged in traditional largely qualitative stylistic research in the spirit of the 1960s’ text attribution, an effort to break the anonymity of a text and to identify its authorship for the purposes of law enforcement (McMenamin 2002, Gibbons 2003, Olsson 2004). While other disciplines within cyber forensics explore largely non-textual materials—and those which look at texts, with the above-mentioned exceptions. do not do so linguistically—semantic forensics, as defined here, uses NLP to identify the clues of deception in NL texts in order to reconstruct the described events as they actually occurred. Now, it can be argued, with reason, that the truthful elements in NL texts are also clues for event reconstruction and should be included in semantic forensics, and, of course, in a way they are. But those, if indeed truthful, do not come under the tas</context>
</contexts>
<marker>Olsson, 2004</marker>
<rawString>Olsson, J. 2004. Forensic Linguistics: An Introduction to Language, Crime and the Law. London-New York: Continuum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Palmer</author>
</authors>
<title>Forensic analysis in a digital world.</title>
<date>2002</date>
<journal>International Journal of Digital Evidence, Spring</journal>
<pages>1</pages>
<contexts>
<context position="2563" citStr="Palmer 2002" startWordPosition="377" endWordPosition="378">mpasses any scientific discipline that is concerned with the direct application of scientific principles and theories to law enforcement (Saferstein 2004), that is, the systematic search for, discovery, and application of clues to event reconstruction—for the purposes of justice. As with any of the other traditional forensic sciences (e.g., DNA, Serology, Latent Fingerprint Analysis etc.) the development of the cyber forensics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established pure sciences (e.g., computer science, math) and applied sciences (e.g., information technology, engineering, and now NLP). Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nige</context>
</contexts>
<marker>Palmer, 2002</marker>
<rawString>Palmer, G. 2002. Forensic analysis in a digital world. International Journal of Digital Evidence, Spring 2002, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
</authors>
<title>The semantics of lying. In:</title>
<date>1987</date>
<booktitle>Aspects of Language: Studies in Honour of Mario Alinei, Vol. II. Theoretical and Applied Semantics.</booktitle>
<pages>443--469</pages>
<editor>R. Crespo, B. D. Smith, and H. Schultinik (eds.),</editor>
<publisher>Rodopi,</publisher>
<location>Amsterdam:</location>
<marker>Raskin, 1987</marker>
<rawString>Raskin, V. 1987. The semantics of lying. In: R. Crespo, B. D. Smith, and H. Schultinik (eds.), Aspects of Language: Studies in Honour of Mario Alinei, Vol. II. Theoretical and Applied Semantics. Amsterdam: Rodopi, 443-469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
</authors>
<title>Natural Language Information Assurance and Security.</title>
<date>2004</date>
<location>Tutorial, COLING</location>
<contexts>
<context position="2990" citStr="Raskin 2004" startWordPosition="438" endWordPosition="439">ics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established pure sciences (e.g., computer science, math) and applied sciences (e.g., information technology, engineering, and now NLP). Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters&apos; financial reports and concluding that the presence of the personal pronouns I/me and you in the former but not in the latter violates the interpersonal relations of the register in the former, thus leading to characterizing them as scams (Herke-Couchman et al. 2003; Whitelaw and Argamon 2004). The difference in the proposed approach is that it goes beyond treating words as just character strings a</context>
<context position="7497" citStr="Raskin 2004" startWordPosition="1140" endWordPosition="1141">me default MONEY sem COMMODITY relaxable-to EVENT patient sem HUMAN relaxable-to ORGANIZATION Figure 2: Ontological Concept PAY The ontology is a tangled hierarchy (lattice) of concepts, beginning at the root ALL, branching into OBJECT, EVENT, and PROPERTY, and so forth. Each node of the hierarchy is a concept with a set of properties, many of which are inherited from its ancestors, and at least one property other than the IS-A property is distinguished from its parent node as well as from its sibling nodes. The ontological concept for PAY might therefore look like figure 2 (cf. Nirenburg and Raskin 2004: 196ff.). As we see, the IS-A and SUBCLASSES slots are filled with other ontological concepts, as are AGENT, THEME, and PATIENT, the case-role slots. VALUE, SEM, RELAXABLE-TO and DEFAULT are all facets of their slots. good-adj1 cat adj SYN-STRUC 1 root $var1 cat n mods root good 2 root $var0 cat adj subj root $var1 cat n SEM-STRUC modality type evaluative value value &gt;0.75 relaxable-to &gt;0.6 scope ^$var1 attributed-to *speaker* Figure 3: Lexical Entry for “good” Lexicons contain the actual words of a language, in contrast to the ontology’s universal, language-independent concepts. The entry fo</context>
<context position="11166" citStr="Raskin 2004" startWordPosition="1712" endWordPosition="1713">s of pre-existing applications, others NL extensions and developments of known applications, and still others unique to NL IAS. In the most implemented one, NL watermarking (see Atallah et al. 2002), a sophisticated mathematical procedure, based on a secret large prime number, selects certain sentences in a text for watermark bearing and transforms their TMRs into bitstrings A new TMR contradicting a previously processed one should lead to a fact repository flag, and this is where we are moving next. 5 Using the Fact Repository for Deception Detection The fact repository (FR—see Nirenburg and Raskin 2004: 350-1), so far the least developed static resource in ONSE, records the remembered event instances. In principle, it should record all of them. Realistically, it records them selectively to suit the needs of an implementation. Thus, in CRESP, a small QA system for queries about the 2000 Olympics in Sydney, the FR remembered all the nations, all the participants, all the competitive events, and all the results. A SF NLP system may start at the same level of prominence (and detect one’s lie about having participated in the Games and/or achieved a better result), but like almost all NLP systems</context>
<context position="12942" citStr="Raskin 2004" startWordPosition="2008" endWordPosition="2009"> In the case of Papa Dean’s occupation, apparently too shameful for the reporter to mention even after he had divulged the Park Avenue childhood, hereditary Republicanism, and discriminatory country club and even though there are still a few stockbrokers on this side of the bars, the FR will easily detect it by presenting this information, very simplistically, as in figure 6. To detect a gloss-over, it is not quite enough to receive a new TMR which contains an event involving a different interaction between these two individuals at the same time. The coreference microtheory (see Nirenburg and Raskin 2004: 301-5) will have to be able to determine or at least to suspect that these events are indeed one and the same event rather than two consecutive or even parallel events. Even the time parameters are not a trivial task to equate, as in the case of I have not much opportunity to talk to John lately and John insulted me last May. It would be trivial, of course, if the temporal adverbials were since that night at Maude’s and that night at Maude’s, respectively, but a human sleuth does not get such incredibly easy clues most of the time and has to operate on crude proximity and hypothesizing. Also</context>
</contexts>
<marker>Raskin, 2004</marker>
<rawString>Raskin, V. 2004. Natural Language Information Assurance and Security. Tutorial, COLING 2004, Geneva, Switzerland. August 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>M J Atallah</author>
<author>C J McDonough</author>
<author>S Nirenburg</author>
</authors>
<title>Natural Language Processing for Information Assurance and Security: An Overview and Implementations.</title>
<date>2001</date>
<booktitle>Proceedings. New Security Paradigm Workshop. September 18th-22nd, 2000, Ballycotton, County Cork Ireland.</booktitle>
<pages>51--65</pages>
<editor>In: M. Schaefer (ed.),</editor>
<publisher>ACM Press,</publisher>
<location>New York:</location>
<marker>Raskin, Atallah, McDonough, Nirenburg, 2001</marker>
<rawString>Raskin, V., M. J. Atallah, C. J. McDonough, and S. Nirenburg. 2001a. Natural Language Processing for Information Assurance and Security: An Overview and Implementations. In: M. Schaefer (ed.), Proceedings. New Security Paradigm Workshop. September 18th-22nd, 2000, Ballycotton, County Cork Ireland. New York: ACM Press, 51-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>M J Atallah</author>
<author>C F Hempelmann</author>
<author>D Mohamed</author>
</authors>
<title>Hybrid Data and Text System for Downgrading Sensitive Documents.</title>
<date>2001</date>
<tech>CERIAS TR.</tech>
<marker>Raskin, Atallah, Hempelmann, Mohamed, 2001</marker>
<rawString>Raskin, V., M. J. Atallah, C. F. Hempelmann, and D. Mohamed. 2001b. Hybrid Data and Text System for Downgrading Sensitive Documents. CERIAS TR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>C F Hempelmann</author>
<author>K E Triezenberg</author>
<author>S Nirenburg</author>
</authors>
<title>Ontology in information security: A useful theoretical foundation and methodological tool.</title>
<date>2002</date>
<booktitle>Proceedings. New Security Paradigms Workshop 2001. September 10th-13th,</booktitle>
<pages>53--59</pages>
<editor>In: V. Raskin &amp; C. F. Hempelmann (eds.),</editor>
<publisher>ACM Press,</publisher>
<location>Cloudcroft, NM, USA, New York:</location>
<contexts>
<context position="16664" citStr="Raskin et al. 2002" startWordPosition="2645" endWordPosition="2648">nageable: it can store only very selective, limited material. The flip side of a TSF system is the easy ability to overlook highly related information an inference away, so we have reasons to suspect that a quality TSF NLP system is not that much simpler than, say, a limited domain GSF system. What is important to realize is that some NLP systems with SF capabilities are within reach in ONSE, using the already available resources, possibly with some modifications, primarily if not entirely on the static side, and that is not much different than changing domains for a “regular” NLP system (see Raskin et al. 2002b). 7 Using Scripts of Complex Events for Deception Detection A main tool for DD, in particular TSF, is the expansion of the ontology by acquiring scripts of complex events, already found necessary for other higher-end NLP tasks (see Raskin et al. 2003). There are strong connections among elements of many texts. These have to do with the understanding that individual propositions may hold well-defined places in “routine,” “typical” sequences of events (often called complex events, scripts or scenarios) that happen in the world, with a well-specified set of object-like entities that appear in d</context>
</contexts>
<marker>Raskin, Hempelmann, Triezenberg, Nirenburg, 2002</marker>
<rawString>Raskin, V., C. F. Hempelmann, K. E. Triezenberg, and S. Nirenburg. 2002a. Ontology in information security: A useful theoretical foundation and methodological tool. In: V. Raskin &amp; C. F. Hempelmann (eds.), Proceedings. New Security Paradigms Workshop 2001. September 10th-13th, Cloudcroft, NM, USA, New York: ACM Press, 53-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>S Nirenburg</author>
<author>M J Atallah</author>
<author>C F Hempelmann</author>
<author>K E Triezenberg</author>
</authors>
<title>Why NLP should move into IAS.</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on a Roadmap for Computational Linguistics,</booktitle>
<pages>1--7</pages>
<editor>In: Steven Krauwer (ed.),</editor>
<location>Taipei, Taiwan: Academia Sinica,</location>
<contexts>
<context position="16664" citStr="Raskin et al. 2002" startWordPosition="2645" endWordPosition="2648">nageable: it can store only very selective, limited material. The flip side of a TSF system is the easy ability to overlook highly related information an inference away, so we have reasons to suspect that a quality TSF NLP system is not that much simpler than, say, a limited domain GSF system. What is important to realize is that some NLP systems with SF capabilities are within reach in ONSE, using the already available resources, possibly with some modifications, primarily if not entirely on the static side, and that is not much different than changing domains for a “regular” NLP system (see Raskin et al. 2002b). 7 Using Scripts of Complex Events for Deception Detection A main tool for DD, in particular TSF, is the expansion of the ontology by acquiring scripts of complex events, already found necessary for other higher-end NLP tasks (see Raskin et al. 2003). There are strong connections among elements of many texts. These have to do with the understanding that individual propositions may hold well-defined places in “routine,” “typical” sequences of events (often called complex events, scripts or scenarios) that happen in the world, with a well-specified set of object-like entities that appear in d</context>
</contexts>
<marker>Raskin, Nirenburg, Atallah, Hempelmann, Triezenberg, 2002</marker>
<rawString>Raskin, V., S. Nirenburg, M. J. Atallah, C. F. Hempelmann, and K. E. Triezenberg. 2002b. Why NLP should move into IAS. In: Steven Krauwer (ed.), Proceedings of the Workshop on a Roadmap for Computational Linguistics, Taipei, Taiwan: Academia Sinica, 2002, 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>S Nirenburg</author>
<author>C F Hempelmann</author>
<author>I Nirenburg</author>
<author>K E Triezenberg</author>
</authors>
<title>The Genesis of a Script for Bankruptcy in Ontological Semantics.</title>
<date>2003</date>
<booktitle>Proceedings of the HLT-NAACL 2003 Workshop on Text Meaning. Available at:</booktitle>
<pages>03--03</pages>
<contexts>
<context position="16917" citStr="Raskin et al. 2003" startWordPosition="2687" endWordPosition="2690">er than, say, a limited domain GSF system. What is important to realize is that some NLP systems with SF capabilities are within reach in ONSE, using the already available resources, possibly with some modifications, primarily if not entirely on the static side, and that is not much different than changing domains for a “regular” NLP system (see Raskin et al. 2002b). 7 Using Scripts of Complex Events for Deception Detection A main tool for DD, in particular TSF, is the expansion of the ontology by acquiring scripts of complex events, already found necessary for other higher-end NLP tasks (see Raskin et al. 2003). There are strong connections among elements of many texts. These have to do with the understanding that individual propositions may hold well-defined places in “routine,” “typical” sequences of events (often called complex events, scripts or scenarios) that happen in the world, with a well-specified set of object-like entities that appear in different roles throughout that sequence. A script captures the entities of such an event and their temporal and causal sequences, as shown for the complex event BANKRUPTCY in figure 7. As a general tool in ONSE, the scripts that get instantiated from th</context>
</contexts>
<marker>Raskin, Nirenburg, Hempelmann, Nirenburg, Triezenberg, 2003</marker>
<rawString>Raskin, V., S. Nirenburg, C. F. Hempelmann, I. Nirenburg, K. E. Triezenberg. 2003. The Genesis of a Script for Bankruptcy in Ontological Semantics. Proceedings of the HLT-NAACL 2003 Workshop on Text Meaning. Available at: http://acl.ldc.upenn.edu/W/W03/W03-0905.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rogers</author>
<author>K Seigfried</author>
</authors>
<title>The future of computer forensics: A needs analysis survey.</title>
<date>2004</date>
<journal>Computers and Security,</journal>
<volume>23</volume>
<pages>12--16</pages>
<contexts>
<context position="2588" citStr="Rogers &amp; Seigfried 2004" startWordPosition="379" endWordPosition="382">cientific discipline that is concerned with the direct application of scientific principles and theories to law enforcement (Saferstein 2004), that is, the systematic search for, discovery, and application of clues to event reconstruction—for the purposes of justice. As with any of the other traditional forensic sciences (e.g., DNA, Serology, Latent Fingerprint Analysis etc.) the development of the cyber forensics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established pure sciences (e.g., computer science, math) and applied sciences (e.g., information technology, engineering, and now NLP). Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters</context>
</contexts>
<marker>Rogers, Seigfried, 2004</marker>
<rawString>Rogers, M. and K. Seigfried. 2004. The future of computer forensics: A needs analysis survey. Computers and Security, 23, 1, 12-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Saferstein</author>
</authors>
<title>Criminalistics: An introduction to forensic science.</title>
<date>2004</date>
<publisher>Prentice Hall.</publisher>
<location>New York:</location>
<contexts>
<context position="2106" citStr="Saferstein 2004" startWordPosition="312" endWordPosition="313">stments, in a most promising and growing new area of IAS. So, while clearly dealing with a new application, the paper addresses theoretical and methodological extensions of ONSE, as defined currently, that will be useful for other applications as well. 1 The Problem The proposed application falls within the rapidly growing domain of cyber forensics, and the inclusion of NLP in it is a desirable and mutually beneficial goal. Forensic science, in general, encompasses any scientific discipline that is concerned with the direct application of scientific principles and theories to law enforcement (Saferstein 2004), that is, the systematic search for, discovery, and application of clues to event reconstruction—for the purposes of justice. As with any of the other traditional forensic sciences (e.g., DNA, Serology, Latent Fingerprint Analysis etc.) the development of the cyber forensics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established p</context>
</contexts>
<marker>Saferstein, 2004</marker>
<rawString>Saferstein, R. 2004. Criminalistics: An introduction to forensic science. New York: Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Whitcomb</author>
</authors>
<title>A historical perspective of digital evidence: A forensic scientist’s view.</title>
<date>2002</date>
<journal>International Journal of Digital Evidence, Spring</journal>
<pages>1</pages>
<contexts>
<context position="2604" citStr="Whitcomb 2002" startWordPosition="383" endWordPosition="384"> is concerned with the direct application of scientific principles and theories to law enforcement (Saferstein 2004), that is, the systematic search for, discovery, and application of clues to event reconstruction—for the purposes of justice. As with any of the other traditional forensic sciences (e.g., DNA, Serology, Latent Fingerprint Analysis etc.) the development of the cyber forensics Figure 1: Resources of Ontological Semantics discipline is based on a sound scientific foundation, compliance with legal requirements, and a unified maturation process (Palmer 2002; Rogers &amp; Seigfried 2004; Whitcomb 2002). The current foundation for cyber forensics is multidisciplinary in nature and combines established pure sciences (e.g., computer science, math) and applied sciences (e.g., information technology, engineering, and now NLP). Cyber forensics is still in search of its theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters&apos; financial repo</context>
</contexts>
<marker>Whitcomb, 2002</marker>
<rawString>Whitcomb, C. 2002. A historical perspective of digital evidence: A forensic scientist’s view. International Journal of Digital Evidence, Spring 2002, 1</rawString>
</citation>
<citation valid="true">
<authors>
<author>Argamon</author>
</authors>
<title>Systemic functional features in stylistic text classification.</title>
<date>2004</date>
<institution>Ms., Sydney Language Technology Research Group, University of Sydney,</institution>
<location>Sydney, Australia.</location>
<contexts>
<context position="3483" citStr="Argamon 2004" startWordPosition="518" endWordPosition="519"> theory and methodology; NLP comes into it on strong and explicit theoretical foundations (see Nirenburg and Raskin 2004: 34-91). As far as we know, no similar research has been undertaken yet. The Patrick group at the University of Sydney reported on a &amp;quot;bag-ofwords&amp;quot; system comparing the Nigerian e-mails with Reuters&apos; financial reports and concluding that the presence of the personal pronouns I/me and you in the former but not in the latter violates the interpersonal relations of the register in the former, thus leading to characterizing them as scams (Herke-Couchman et al. 2003; Whitelaw and Argamon 2004). The difference in the proposed approach is that it goes beyond treating words as just character strings and represents their meanings, as well as those of the sentences and of their text, explicitly and manipulates them logically, as it were, rather than statistically. The result, typical for the comparison of computational semantics with computational statistics, is that a semantic forensics system is capable of identifying specific facts/events that contribute to the deception and of understanding what those events are—the characterization of the text as fraudulent comes then as a trivial </context>
</contexts>
<marker>Argamon, 2004</marker>
<rawString>Whitelaw, C., and Sh. Argamon 2004. Systemic functional features in stylistic text classification. Ms., Sydney Language Technology Research Group, University of Sydney, Sydney, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>