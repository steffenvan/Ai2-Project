<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000088">
<title confidence="0.749009">
UMCC_DLSI-(EPS): Paraphrases Detection Based on Semantic
Distance
</title>
<author confidence="0.45809">
Andrés Montoyo, Rafael Muñoz
</author>
<affiliation confidence="0.405882">
DLSI, University of Alicante Carretera
</affiliation>
<note confidence="0.7798385">
de San Vicente S/N Alicante, Spain.
{montoyo,
rafael}@dlsi.ua.es
Héctor Dávila, Antonio Fernández Orquín,
Alexander Chávez, Yoan Gutiérrez, Armando
Collazo, José I. Abreu
DI, University of Matanzas
Autopista a Varadero km 3 1/2
</note>
<keyword confidence="0.6907232">
Matanzas, Cuba.
{hector.davila, tony,
alexander.chavez, yoan.gutierrez,
armando.collazo,
jose.abreu}@umcc.cu
</keyword>
<sectionHeader confidence="0.969546" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908714285714">
This paper describes the specifications and
results of UMCC_DLSI-(EPS) system, which
participated in the first Evaluating Phrasal
Semantics of SemEval-2013. Our supervised
system uses different kinds of semantic
features to train a bagging classifier used to
select the correct similarity option. Related to
the different features we can highlight the
resource WordNet used to extract semantic
relations among words and the use of different
algorithms to establish semantic similarities.
Our system obtains promising results with a
precision value around 78% for the English
corpus and 71.84% for the Italian corpus.
</bodyText>
<sectionHeader confidence="0.99517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984">
It is well known finding words similarity, even
when it is lexical or semantic can improve
entailment recognition and paraphrase
identification; and ultimately lead to improvements
in a wide range of applications in Natural
Language Processing (NLP). Several areas like
question answering, query expansion, information
retrieval, and many others, depend on phrasal
semantics (PS). PS, is concerned with how the
meaning of a sentence is composed both from the
meaning of the constituent words, and from extra
meaning contained within the structural
organization of the sentence itself (Dominey,
2005).
The aim of SemEval 2013 competition is also
discovering similarity, specifically in Evaluating
Phrasal Semantics (EPS). The goal of this task is to
evaluate how well systems can judge the semantic
similarity of a word and a short sequence of words.
That is, given a set of pairs of this type; classify it
on negative (if the meaning of the word is
semantically different to the meaning of the
sequence) or positive (if the meaning of the
sequence, as a whole, is semantically close to the
meaning of the word).
Based on this, we developed a system capable to
detect if two phrases are semantically close.
The rest of this paper, specifically section 2 is a
brief Related Work. Section 3 describes the system
architecture and our run. Continuing with section 4
we describe the training phase. Following that,
section 5 presents the results and discussion for our
Machine Learning System. Finally we conclude
and propose our future works (Section 6).
</bodyText>
<sectionHeader confidence="0.999346" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999982285714286">
There have been many WordNet-based similarity
measures, among other highlights the work of
researchers like (Budanitsky and Hirst, 2006;
Leacock and Chodorow, 1998; Mihalcea et al.,
2006; Richardson et al., 1994).
On the other hand, WordNet::Similarity1
(Pedersen et al., 2004) has been used by other
researchers in an interesting array of domains.
WordNet::Similarity implements measures of
similarity and relatedness between a pair of
concepts (or synsets2) based on the structure and
content of WordNet. According to (Pedersen et al.,
2004), three of the six measures of similarity are
based on the information content of the least
</bodyText>
<footnote confidence="0.9434195">
1http://sourceforge.net/projects/wn-similarity/
2 A group of English words into sets of synonyms.
</footnote>
<page confidence="0.79858">
93
</page>
<bodyText confidence="0.986776363636363">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 93–97, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
common subsumer (LCS). These measures include
res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang
and Conrath, 1997).
Pursuant to Pedersen, there are three other
similarity measures based on path lengths between
a pair of concepts: lch (Leacock and Chodorow,
1998), wup (Wu and Palmer, 1994), and path.
Our proposal differs from those of
WordNet::Similarity and other measures of
similarity in the way we selected the relevant
WordNet relations (see section 3.2 for detail).
Unlike others, our measure assign weight to
WordNet relations (any we consider relevant)
depending to the place they occupy in the
minimum path and the previously visited relations.
Besides these, the novelty of our approach is
using the weights as a function of semantic
relations in a minimal distance path and also the
method we used to arrive to those weight functions
or rules.
</bodyText>
<subsectionHeader confidence="0.547698">
3 System Architecture and description of
the run
</subsectionHeader>
<bodyText confidence="0.999923625">
As we can see in Figure 1 our run begin with the
pre-processing of SemEval 2013’s training set.
Every sentence pair is tokenized, lemmatized and
POS-tagged using Freeling 2.2 tool (Atserias et al.,
2006). Afterwards, several methods and algorithms
are applied in order to extract all features for our
Machine Learning System (MLS). The system
trains the classifier using a model based on
bagging (using JRip3). The training corpus has
been provided by SemEval-2013 competition, in
concrete by the EPS task. As a result, we obtain a
trained model capable to detect if one phrase
implies other. Finally, we test our system with the
SemEval 2013 test set (see Table 2 with the results
of our run). The following section describes the
features extraction process.
</bodyText>
<subsectionHeader confidence="0.9998875">
3.1 Description of the features used in the
Machine Learning System
</subsectionHeader>
<bodyText confidence="0.940807210526316">
In order to detect entailment between a pair of
phrases, we developed an algorithm that searches a
semantic distance, according to WordNet (Miller et
al., 1990), between each word in the first phrase
with each one in the second phrase.
We used four features which intend to measure
the level of proximity between both sentences:
3 JRip is an inference and rules-based learner.
— The minimum distance to align the first
phrase with the second (MinDist). See section
3.2 for details.
— The maximal distance to align the first phrase
with the second (MaxDist).
— The average of all distances results to align
the first phrase with the second one.
(AverageDistance).
— The absolute relative error of all distances
results to align the first phrase with the
second respect to the average of them.
</bodyText>
<note confidence="0.459188">
Semeval 2013 test
</note>
<figureCaption confidence="0.999044">
Figure 1. System Architecture.
</figureCaption>
<bodyText confidence="0.99985">
Other features included are the most frequent
relations contained in the shorted path of the
minimum distance; result to align the first phrase
with the second one. Following table shows the
relations selected as most frequent.
A weight was added to each of them, according
to the place it occupy in the shortest path between
two synsets. The shortest path was calculated using
Breadth -First-Search algorithm (BFS) (Cormen et
al., 2001).
In addition, there is one feature that takes into
account any other relationship that is not
previously considered.
Finally, as a result we obtain 22 features from
this alignment method.
</bodyText>
<figure confidence="0.890158714285714">
Run 1 Bagging Classifier (JRip)
Paraphrases Detection
Training process (using Weka)
Bagging Classifier (JRip)
MinDistance MaxDistance error
Tokenizing
Supervised Model
MinDistance MaxDistance error ...
Tokenizing
Pre-Processing (using Freeling 2.2)
Feature Extraction
Pre-Processing (using Freeling 2.2)
Training set from
Semeval2013
Feature Extraction
Lemmatizing POS Tagging
Lemmatizing
set
POS Tagging
...
94
</figure>
<table confidence="0.999241322580645">
Relation Weight (W function)
Antonym 1000
Synonym 0
Hyponym/ Hypernym 100 if exist an antonym
before, 30 if exist other
relation before (except
synonym, hyponym,
hypernym), 5 otherwise.
Meber_Holonym/ 100 if exist an antonym
PartHolonym before, 20 if exist a
hyponym or a hypernym,10
otherwise.
Cause/ Entailment 100 if exist an antonym
before, 2 otherwise.
Similar To 100 if exist an antonym
_ before, 3 otherwise.
Attribute 100 if exist an antonym
before, 8 otherwise.
Also See 100 if exist an antonym
_ before, 10 otherwise.
Derivationaly_Related_Form 100 if exist an antonym
before, 5 otherwise.
Domain Of Synset Topic 100 if exist an antonym
__before, 13 otherwise.
Domain_Of_Synset_Usage 100 if exist an antonym
before, 60 otherwise.
Member Of Domain Topic 100 if exist an antonym
_ __before, 13 otherwise.
Member Of Domain Usage 100 if exist an antonym
_ __before, 60 otherwise.
Other 100
</table>
<tableCaption confidence="0.999253">
Table 1. Most frequents relations with their weight.
</tableCaption>
<subsectionHeader confidence="0.996012">
3.2 Semantic Distance
</subsectionHeader>
<bodyText confidence="0.999995">
As aforementioned, our distance depends on
calculating the similarity between sentences, based
on the analysis of WordNet relations, and we only
took into account the most frequent ones. When
searching the shortest path between two WordNet
synsets, frequents relations were considered the
ones extracted according to the analysis made in
the training corpus, provided by SemEval-2013.
The distance between two synsets is calculated
with the relations found; and simply it is the sum
of the weights assigned to each connection.
</bodyText>
<equation confidence="0.9773875">
MinDistP(P, Q) = MinDistS(Px, Qy), V (X, Y)
MinDistS(X, Y) = Min(Xl, Y ), V(i, j)
k=m
Min(X1;Y) = W(Rel(L[k],L[k+1]))
k=0
L = BFS(X1;Y)
</equation>
<bodyText confidence="0.999959222222222">
Where i and j represents the i-th and j-th sense of
the word; P and Q represents words collections; Px
is the X-th word of P; Qy is the Y-th word of Q;
MinDistP obtains a value that represents a
minimal semantic distance across WordNet (Miller
et al., 2006) resource (this resource is involved into
the integrator resource, ISR-WN (Gutiérrez et al.,
2011a; 2010a); MinDistS the minimal semantic
distance between two words; Min represents the
minimal semantic distance between two senses
collections; L is a collection of synsets that
represents the minimal path between two synsets
using BFS; Rel obtains semantic relation types
between two synsets; W is a functions that apply
the rules described in Table 1. The maximum and
average distance is calculated in a similar fashion
but using the maximum and average instead of the
minimum.
</bodyText>
<subsectionHeader confidence="0.998637">
3.3 Semantic Alignment
</subsectionHeader>
<bodyText confidence="0.9991645">
First, the two sentences are pre-processed with
Freeling 2.2 and the words are classified according
to their parts-of-speech. Then, all senses of every
word are taken and treated as a group. Distance
between two groups will be the minimal distance
(described in 3.1) between senses of any pair of
words belonging to the group.
In the example of Figure 2, Dist=280 is selected
for the pair “Balance-Culture” (minimal cost).
Following the explanation on section 3.1 we
extract the features guided to measure the level of
proximity between both sentences.
</bodyText>
<figureCaption confidence="0.860501">
Figure 2. Distance between “Balance” and “Culture”.
</figureCaption>
<bodyText confidence="0.998144">
A maximum and average distance is calculated in a
similar fashion, but using the maximum and
average instead of the minimum.
</bodyText>
<sectionHeader confidence="0.589362" genericHeader="method">
4 Description of the training phase
</sectionHeader>
<bodyText confidence="0.9997175">
For the training process, we used a supervised
learning framework (based on Weka4), including
all the training set (positive and negative instances)
as a training corpus. We conduct several
experiments in order to select the correct classifier,
the best result being obtained with a model based
on bagging (using JRip algorithm). Finally, we
used 10-fold cross validation technique with the
selected classifier, obtaining a classification value
of 73.21%.
</bodyText>
<figure confidence="0.972615916666667">
4 http://prdownloads.sourceforge.net/weka/
Lemma: Balance
Sense 1
Sense 2
1030 280
Dist=280
880
3350
Lemma: Culture
Sense 1
Sense 2
95
</figure>
<sectionHeader confidence="0.981384" genericHeader="evaluation">
5 Results and discussion
</sectionHeader>
<bodyText confidence="0.999017818181818">
EPS task of SemEval-2013 offered many official
measures to rank the systems. Some of them are
the following:
o F-Measure (FM): Correct Response (CR),
Instances correctly classified, True positives
(TP), Instances correctly classified as
positive. False Positives (FP), Instances
incorrectly classified as positive, True
Negatives (TN), Instances correctly
classified as negative, False Negatives (FN),
Instances incorrectly classified as negative.
</bodyText>
<table confidence="0.954954333333333">
Corpus FM CR TP FP TI FI
English 0.6892 2826 1198 325 1628 755
Italian 0.6396 574 245 96 329 180
</table>
<tableCaption confidence="0.99873">
Table 2. Official SemEval 2013 results.
</tableCaption>
<bodyText confidence="0.999338857142857">
The behavior of our system, for English and
Italian corpus is shown in Table 2.
The only thing that changes to process the
Italian corpus is that Freeling is used as input to
identify Italian words and it returns the English
WN synsets. The process continues in the same
way as English.
</bodyText>
<figureCaption confidence="0.9841735">
Figure 3: Semantic Distance distribution between
negative and positive instances.
</figureCaption>
<bodyText confidence="0.999958529411765">
As shown in Table 2, our main drawback is to
classify positive instances. Sometimes, the distance
between positive phrases is very far. This is due to
the relations found in the minimum path are very
similar to the one found in other pairs of negatives
instances; this can be the cause of our MLS
classifies them as negatives (see Figure 3).
Figure 3 shows a distributional graphics that
take a sample of 200 negative and positive
instances. The graphics illustrate how close to zero
value the positive instances are, while the
negatives are far away from this value. However,
in the approximate range between 80 and 200, we
can see values of positive and negative instances
positioning together. This can be the cause that our
MLS misclassified some positive instances as
negative.
</bodyText>
<sectionHeader confidence="0.888528" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999723555555556">
This paper introduced a new framework for EPS,
which depends on the extraction of several features
from WordNet relations. We have conducted the
semantic features extraction in a multidimensional
context using the resource ISR-WN(Gutiérrez et
al., 2010a).
Our semantic distance provides an appealing
approach for dealing with phrasal detection based
on WordNet relation. Our team reached the sixth
position of ten runs for English corpus, with a
small difference of 0.07 points compared to the
best results with respect to accuracy parameter.
Despite the problems caused by poorly selected
positive instances, our distance (labeled as Our)
obtained very similar results to those obtained by
the best team (labeled as First5), which indicates
that our work is well underway (see Table 3 for
details).
</bodyText>
<table confidence="0.980805333333333">
Team accuracy recall precision
First 0.802611 0.751664 0.836944128
Our 0.723502 0.613415 0.786605384
</table>
<tableCaption confidence="0.99871">
Table 3. Comparative results (English corpus).
</tableCaption>
<bodyText confidence="0.9998431">
It is important to remark that our system has
been the only competitor to evaluate Italian texts.
It has been possible due to our system include
Freeling in the preprocessing stage.
Our future work will aim to resolve instances
misclassified by our algorithm. In addition, we will
introduce lexical substitutions (synonyms) to
expand the corpus, we will also apply conceptual
semantic similarity using relevant semantic trees
(Gutiérrez et al., 2010b; Gutiérrez et al., 2011b).
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998903888888889">
This research work has been partially funded by
the Spanish Government through the project
TEXT-MESS 2.0 (TIN2009-13391-C04), &amp;quot;Análisis
de Tendencias Mediante Técnicas de Opinión
Semántica&amp;quot; (TIN2012-38536-C03-03) and
“Técnicas de Deconstrucción en la Tecnologías del
Lenguaje Humano” (TIN2012-31224); and by the
Valencian Government through the project
PROMETEO (PROMETEO/2009/199).
</bodyText>
<sectionHeader confidence="0.98277" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.913559">
Atserias, J.; B. Casas; E. Comelles; M. González; L.
Padró and M. Padró. FreeLing 1.3: Syntactic and
</reference>
<figure confidence="0.911616">
5 christian_wartena. Team HsH.
1000
500
0
Positive Instances Negative Instances
Semantic Distance Distribution
96
</figure>
<reference confidence="0.9993761625">
semantic services in an open-source NLP library.
Proceedings of the 5th International Conference on
Language Resources and Evaluation (LREC’06),
2006. 48-55 p.
Budanitsky, A. and G. Hirst Evaluating wordnet-based
measures of lexical semantic relatedness
Computational Linguistics, 2006, 32(1): 13-47.
Cormen, T. H.; C. E. Leiserson; R. L. Rivest and C.
Stein. Introduction to algorithms. MIT press, 2001.
0262032937.
Dominey, P. F. Aspects of descriptive, referential, and
information structure in phrasal semantics: A
construction-based model Interaction Studies, 2005,
6(2): 287-310.
Gutiérrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez. Integration of semantic resources based on
WordNet. XXVI Congreso de la Sociedad Española
para el Procesamiento del Lenguaje Natural,
Universidad Politécnica de Valencia, Valencia,
SEPLN 2010, 2010a. 161-168 p. 1135-5948.
Gutiérrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez. UMCC-DLSI: Integrative resource for
disambiguation task. Proceedings of the 5th
International Workshop on Semantic Evaluation,
Uppsala, Sweden, Association for Computational
Linguistics, 2010b. 427-432 p.
Gutiérrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez Enriching the Integration of Semantic
Resources based on WordNet Procesamiento del
Lenguaje Natural, 2011a, 47: 249-257.
Gutiérrez, Y.; S. Vázquez and A. Montoyo. Improving
WSD using ISR-WN with Relevant Semantic Trees
and SemCor Senses Frequency. Proceedings of the
International Conference Recent Advances in Natural
Language Processing 2011, Hissar, Bulgaria,
RANLP 2011 Organising Committee, 2011b. 233--
239 p.
Jiang, J. J. and D. W. Conrath Semantic similarity based
on corpus statistics and lexical taxonomy arXiv
preprint cmp-lg/9709008, 1997.
Leacock, C. and M. Chodorow Combining local context
and WordNet similarity for word sense identification
WordNet: An electronic lexical database, 1998,
49(2): 265-283.
Lin, D. An information-theoretic definition of
similarity. Proceedings of the 15th international
conference on Machine Learning, San Francisco,
1998. 296-304 p.
Mihalcea, R.; C. Corley and C. Strapparava. Corpus-
based and knowledge-based measures of text
semantic similarity. Proceedings of the national
conference on artificial intelligence, Menlo Park,
CA; Cambridge, MA; London; AAAI Press; MIT
Press; 1999, 2006. 775 p.
Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross and
K. Miller Introduction to WordNet: An On-line
Lexical Database International Journal of
Lexicography, 3(4):235-244., 1990.
Miller, G. A.; C. Fellbaum; R. Tengi; P. Wakefield; H.
Langone and B. R. Haskell. WordNet a lexical
database for the English language. Cognitive Science
Laboratory Princeton University 2006.
Pedersen, T.; S. Patwardhan and J. Michelizzi.
WordNet:: Similarity: measuring the relatedness of
concepts. Demonstration Papers at HLT-NAACL
2004, Association for Computational Linguistics,
2004. 38-41 p.
Resnik, P. Using information content to evaluate
semantic similarity in a taxonomy arXiv preprint
cmp-lg/9511007, 1995.
Richardson, R.; A. F. Smeaton and J. Murphy. Using
WordNet as a knowledge base for measuring
semantic similarity between words, Technical Report
Working Paper CA-1294, School of Computer
Applications, Dublin City University, 1994.
Wu, Z. and M. Palmer. Verbs semantics and lexical
selection. Proceedings of the 32nd annual meeting on
Association for Computational Linguistics,
Association for Computational Linguistics, 1994.
133-138 p.
</reference>
<page confidence="0.973279">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.171705">
<title confidence="0.9794035">UMCC_DLSI-(EPS): Paraphrases Detection Based on Semantic Distance</title>
<author confidence="0.979138">Andrés Montoyo</author>
<author confidence="0.979138">Rafael Muñoz</author>
<affiliation confidence="0.9949405">DLSI, University of Alicante de San Vicente S/N Alicante,</affiliation>
<email confidence="0.920072">rafael}@dlsi.ua.es</email>
<author confidence="0.877953">Héctor Dávila</author>
<author confidence="0.877953">Antonio Fernández Alexander Chávez</author>
<author confidence="0.877953">Yoan Gutiérrez</author>
<author confidence="0.877953">José I Abreu Collazo</author>
<affiliation confidence="0.712284">DI, University of Autopista a Varadero km 3 Matanzas,</affiliation>
<email confidence="0.930407">hector.davila@umcc.cu</email>
<email confidence="0.930407">alexander.chavez@umcc.cu</email>
<email confidence="0.930407">jose.abreu@umcc.cu</email>
<abstract confidence="0.994274666666667">This paper describes the specifications and results of UMCC_DLSI-(EPS) system, which participated in the first Evaluating Phrasal Semantics of SemEval-2013. Our supervised system uses different kinds of semantic features to train a bagging classifier used to select the correct similarity option. Related to the different features we can highlight the resource WordNet used to extract semantic relations among words and the use of different algorithms to establish semantic similarities. Our system obtains promising results with a precision value around 78% for the English corpus and 71.84% for the Italian corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Atserias</author>
<author>B Casas</author>
<author>E Comelles</author>
<author>M González</author>
<author>L Padró</author>
<author>M Padró</author>
</authors>
<title>FreeLing 1.3: Syntactic and semantic services in an open-source NLP library.</title>
<date>2006</date>
<booktitle>Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<pages>48--55</pages>
<contexts>
<context position="4772" citStr="Atserias et al., 2006" startWordPosition="717" endWordPosition="720">, our measure assign weight to WordNet relations (any we consider relevant) depending to the place they occupy in the minimum path and the previously visited relations. Besides these, the novelty of our approach is using the weights as a function of semantic relations in a minimal distance path and also the method we used to arrive to those weight functions or rules. 3 System Architecture and description of the run As we can see in Figure 1 our run begin with the pre-processing of SemEval 2013’s training set. Every sentence pair is tokenized, lemmatized and POS-tagged using Freeling 2.2 tool (Atserias et al., 2006). Afterwards, several methods and algorithms are applied in order to extract all features for our Machine Learning System (MLS). The system trains the classifier using a model based on bagging (using JRip3). The training corpus has been provided by SemEval-2013 competition, in concrete by the EPS task. As a result, we obtain a trained model capable to detect if one phrase implies other. Finally, we test our system with the SemEval 2013 test set (see Table 2 with the results of our run). The following section describes the features extraction process. 3.1 Description of the features used in the</context>
</contexts>
<marker>Atserias, Casas, Comelles, González, Padró, Padró, 2006</marker>
<rawString>Atserias, J.; B. Casas; E. Comelles; M. González; L. Padró and M. Padró. FreeLing 1.3: Syntactic and semantic services in an open-source NLP library. Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’06), 2006. 48-55 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Budanitsky</author>
<author>G Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of lexical semantic relatedness Computational Linguistics,</title>
<date>2006</date>
<volume>32</volume>
<issue>1</issue>
<pages>13--47</pages>
<contexts>
<context position="2812" citStr="Budanitsky and Hirst, 2006" startWordPosition="417" endWordPosition="420">ly close to the meaning of the word). Based on this, we developed a system capable to detect if two phrases are semantically close. The rest of this paper, specifically section 2 is a brief Related Work. Section 3 describes the system architecture and our run. Continuing with section 4 we describe the training phase. Following that, section 5 presents the results and discussion for our Machine Learning System. Finally we conclude and propose our future works (Section 6). 2 Related Work There have been many WordNet-based similarity measures, among other highlights the work of researchers like (Budanitsky and Hirst, 2006; Leacock and Chodorow, 1998; Mihalcea et al., 2006; Richardson et al., 1994). On the other hand, WordNet::Similarity1 (Pedersen et al., 2004) has been used by other researchers in an interesting array of domains. WordNet::Similarity implements measures of similarity and relatedness between a pair of concepts (or synsets2) based on the structure and content of WordNet. According to (Pedersen et al., 2004), three of the six measures of similarity are based on the information content of the least 1http://sourceforge.net/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Budanitsky, A. and G. Hirst Evaluating wordnet-based measures of lexical semantic relatedness Computational Linguistics, 2006, 32(1): 13-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Cormen</author>
<author>C E Leiserson</author>
<author>R L Rivest</author>
<author>C Stein</author>
</authors>
<title>Introduction to algorithms.</title>
<date>2001</date>
<pages>0262032937</pages>
<publisher>MIT press,</publisher>
<contexts>
<context position="6675" citStr="Cormen et al., 2001" startWordPosition="1031" endWordPosition="1034">ce). — The absolute relative error of all distances results to align the first phrase with the second respect to the average of them. Semeval 2013 test Figure 1. System Architecture. Other features included are the most frequent relations contained in the shorted path of the minimum distance; result to align the first phrase with the second one. Following table shows the relations selected as most frequent. A weight was added to each of them, according to the place it occupy in the shortest path between two synsets. The shortest path was calculated using Breadth -First-Search algorithm (BFS) (Cormen et al., 2001). In addition, there is one feature that takes into account any other relationship that is not previously considered. Finally, as a result we obtain 22 features from this alignment method. Run 1 Bagging Classifier (JRip) Paraphrases Detection Training process (using Weka) Bagging Classifier (JRip) MinDistance MaxDistance error Tokenizing Supervised Model MinDistance MaxDistance error ... Tokenizing Pre-Processing (using Freeling 2.2) Feature Extraction Pre-Processing (using Freeling 2.2) Training set from Semeval2013 Feature Extraction Lemmatizing POS Tagging Lemmatizing set POS Tagging ... 94</context>
</contexts>
<marker>Cormen, Leiserson, Rivest, Stein, 2001</marker>
<rawString>Cormen, T. H.; C. E. Leiserson; R. L. Rivest and C. Stein. Introduction to algorithms. MIT press, 2001. 0262032937.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Dominey</author>
</authors>
<title>Aspects of descriptive, referential, and information structure in phrasal semantics: A construction-based model Interaction Studies,</title>
<date>2005</date>
<volume>6</volume>
<issue>2</issue>
<pages>287--310</pages>
<contexts>
<context position="1711" citStr="Dominey, 2005" startWordPosition="236" endWordPosition="237">1 Introduction It is well known finding words similarity, even when it is lexical or semantic can improve entailment recognition and paraphrase identification; and ultimately lead to improvements in a wide range of applications in Natural Language Processing (NLP). Several areas like question answering, query expansion, information retrieval, and many others, depend on phrasal semantics (PS). PS, is concerned with how the meaning of a sentence is composed both from the meaning of the constituent words, and from extra meaning contained within the structural organization of the sentence itself (Dominey, 2005). The aim of SemEval 2013 competition is also discovering similarity, specifically in Evaluating Phrasal Semantics (EPS). The goal of this task is to evaluate how well systems can judge the semantic similarity of a word and a short sequence of words. That is, given a set of pairs of this type; classify it on negative (if the meaning of the word is semantically different to the meaning of the sequence) or positive (if the meaning of the sequence, as a whole, is semantically close to the meaning of the word). Based on this, we developed a system capable to detect if two phrases are semantically </context>
</contexts>
<marker>Dominey, 2005</marker>
<rawString>Dominey, P. F. Aspects of descriptive, referential, and information structure in phrasal semantics: A construction-based model Interaction Studies, 2005, 6(2): 287-310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Gutiérrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S Vázquez</author>
</authors>
<title>Integration of semantic resources based on WordNet.</title>
<date>2010</date>
<booktitle>XXVI Congreso de la Sociedad Española para el Procesamiento del Lenguaje Natural, Universidad Politécnica de</booktitle>
<pages>2010--161</pages>
<location>Valencia, Valencia, SEPLN</location>
<contexts>
<context position="13169" citStr="Gutiérrez et al., 2010" startWordPosition="2049" endWordPosition="2052">The graphics illustrate how close to zero value the positive instances are, while the negatives are far away from this value. However, in the approximate range between 80 and 200, we can see values of positive and negative instances positioning together. This can be the cause that our MLS misclassified some positive instances as negative. 6 Conclusion and future work This paper introduced a new framework for EPS, which depends on the extraction of several features from WordNet relations. We have conducted the semantic features extraction in a multidimensional context using the resource ISR-WN(Gutiérrez et al., 2010a). Our semantic distance provides an appealing approach for dealing with phrasal detection based on WordNet relation. Our team reached the sixth position of ten runs for English corpus, with a small difference of 0.07 points compared to the best results with respect to accuracy parameter. Despite the problems caused by poorly selected positive instances, our distance (labeled as Our) obtained very similar results to those obtained by the best team (labeled as First5), which indicates that our work is well underway (see Table 3 for details). Team accuracy recall precision First 0.802611 0.7516</context>
</contexts>
<marker>Gutiérrez, Fernández, Montoyo, Vázquez, 2010</marker>
<rawString>Gutiérrez, Y.; A. Fernández; A. Montoyo and S. Vázquez. Integration of semantic resources based on WordNet. XXVI Congreso de la Sociedad Española para el Procesamiento del Lenguaje Natural, Universidad Politécnica de Valencia, Valencia, SEPLN 2010, 2010a. 161-168 p. 1135-5948.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Gutiérrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S Vázquez</author>
</authors>
<title>UMCC-DLSI: Integrative resource for disambiguation task.</title>
<booktitle>Proceedings of the 5th International Workshop on Semantic Evaluation, Uppsala, Sweden, Association for Computational Linguistics,</booktitle>
<pages>2010--427</pages>
<marker>Gutiérrez, Fernández, Montoyo, Vázquez, </marker>
<rawString>Gutiérrez, Y.; A. Fernández; A. Montoyo and S. Vázquez. UMCC-DLSI: Integrative resource for disambiguation task. Proceedings of the 5th International Workshop on Semantic Evaluation, Uppsala, Sweden, Association for Computational Linguistics, 2010b. 427-432 p.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Gutiérrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S</author>
</authors>
<booktitle>Vázquez Enriching the Integration of Semantic Resources based on WordNet Procesamiento del Lenguaje Natural, 2011a,</booktitle>
<volume>47</volume>
<pages>249--257</pages>
<marker>Gutiérrez, Fernández, Montoyo, S, </marker>
<rawString>Gutiérrez, Y.; A. Fernández; A. Montoyo and S. Vázquez Enriching the Integration of Semantic Resources based on WordNet Procesamiento del Lenguaje Natural, 2011a, 47: 249-257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Gutiérrez</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
</authors>
<title>Improving WSD using ISR-WN with Relevant Semantic Trees and SemCor Senses Frequency.</title>
<date>2011</date>
<booktitle>Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<pages>233--239</pages>
<location>Hissar, Bulgaria, RANLP</location>
<contexts>
<context position="9264" citStr="Gutiérrez et al., 2011" startWordPosition="1433" endWordPosition="1436">ce between two synsets is calculated with the relations found; and simply it is the sum of the weights assigned to each connection. MinDistP(P, Q) = MinDistS(Px, Qy), V (X, Y) MinDistS(X, Y) = Min(Xl, Y ), V(i, j) k=m Min(X1;Y) = W(Rel(L[k],L[k+1])) k=0 L = BFS(X1;Y) Where i and j represents the i-th and j-th sense of the word; P and Q represents words collections; Px is the X-th word of P; Qy is the Y-th word of Q; MinDistP obtains a value that represents a minimal semantic distance across WordNet (Miller et al., 2006) resource (this resource is involved into the integrator resource, ISR-WN (Gutiérrez et al., 2011a; 2010a); MinDistS the minimal semantic distance between two words; Min represents the minimal semantic distance between two senses collections; L is a collection of synsets that represents the minimal path between two synsets using BFS; Rel obtains semantic relation types between two synsets; W is a functions that apply the rules described in Table 1. The maximum and average distance is calculated in a similar fashion but using the maximum and average instead of the minimum. 3.3 Semantic Alignment First, the two sentences are pre-processed with Freeling 2.2 and the words are classified accor</context>
</contexts>
<marker>Gutiérrez, Vázquez, Montoyo, 2011</marker>
<rawString>Gutiérrez, Y.; S. Vázquez and A. Montoyo. Improving WSD using ISR-WN with Relevant Semantic Trees and SemCor Senses Frequency. Proceedings of the International Conference Recent Advances in Natural Language Processing 2011, Hissar, Bulgaria, RANLP 2011 Organising Committee, 2011b. 233--239 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Jiang</author>
<author>D W</author>
</authors>
<title>Conrath Semantic similarity based on corpus statistics and lexical taxonomy arXiv preprint cmp-lg/9709008,</title>
<date>1997</date>
<marker>Jiang, W, 1997</marker>
<rawString>Jiang, J. J. and D. W. Conrath Semantic similarity based on corpus statistics and lexical taxonomy arXiv preprint cmp-lg/9709008, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M</author>
</authors>
<title>Chodorow Combining local context and WordNet similarity for word sense identification WordNet: An electronic lexical database,</title>
<date>1998</date>
<volume>49</volume>
<issue>2</issue>
<pages>265--283</pages>
<marker>Leacock, M, 1998</marker>
<rawString>Leacock, C. and M. Chodorow Combining local context and WordNet similarity for word sense identification WordNet: An electronic lexical database, 1998, 49(2): 265-283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>Proceedings of the 15th international conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<location>San Francisco,</location>
<contexts>
<context position="3743" citStr="Lin, 1998" startWordPosition="551" endWordPosition="552">s2) based on the structure and content of WordNet. According to (Pedersen et al., 2004), three of the six measures of similarity are based on the information content of the least 1http://sourceforge.net/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 93–97, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics common subsumer (LCS). These measures include res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997). Pursuant to Pedersen, there are three other similarity measures based on path lengths between a pair of concepts: lch (Leacock and Chodorow, 1998), wup (Wu and Palmer, 1994), and path. Our proposal differs from those of WordNet::Similarity and other measures of similarity in the way we selected the relevant WordNet relations (see section 3.2 for detail). Unlike others, our measure assign weight to WordNet relations (any we consider relevant) depending to the place they occupy in the minimum path and the previously visited relations. Besides these, the novel</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, D. An information-theoretic definition of similarity. Proceedings of the 15th international conference on Machine Learning, San Francisco, 1998. 296-304 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Corley</author>
<author>C Strapparava</author>
</authors>
<title>Corpusbased and knowledge-based measures of text semantic similarity.</title>
<date>1999</date>
<booktitle>Proceedings of the national conference on artificial intelligence,</booktitle>
<pages>775</pages>
<publisher>AAAI Press; MIT Press;</publisher>
<location>Menlo Park, CA; Cambridge, MA; London;</location>
<marker>Mihalcea, Corley, Strapparava, 1999</marker>
<rawString>Mihalcea, R.; C. Corley and C. Strapparava. Corpusbased and knowledge-based measures of text semantic similarity. Proceedings of the national conference on artificial intelligence, Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2006. 775 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Introduction to WordNet: An On-line Lexical Database</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="5557" citStr="Miller et al., 1990" startWordPosition="845" endWordPosition="848">ng a model based on bagging (using JRip3). The training corpus has been provided by SemEval-2013 competition, in concrete by the EPS task. As a result, we obtain a trained model capable to detect if one phrase implies other. Finally, we test our system with the SemEval 2013 test set (see Table 2 with the results of our run). The following section describes the features extraction process. 3.1 Description of the features used in the Machine Learning System In order to detect entailment between a pair of phrases, we developed an algorithm that searches a semantic distance, according to WordNet (Miller et al., 1990), between each word in the first phrase with each one in the second phrase. We used four features which intend to measure the level of proximity between both sentences: 3 JRip is an inference and rules-based learner. — The minimum distance to align the first phrase with the second (MinDist). See section 3.2 for details. — The maximal distance to align the first phrase with the second (MaxDist). — The average of all distances results to align the first phrase with the second one. (AverageDistance). — The absolute relative error of all distances results to align the first phrase with the second </context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross and K. Miller Introduction to WordNet: An On-line Lexical Database International Journal of Lexicography, 3(4):235-244., 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>C Fellbaum</author>
<author>R Tengi</author>
<author>P Wakefield</author>
<author>H Langone</author>
<author>B R Haskell</author>
</authors>
<title>WordNet a lexical database for the English language.</title>
<date>2006</date>
<institution>Cognitive Science Laboratory Princeton University</institution>
<contexts>
<context position="9167" citStr="Miller et al., 2006" startWordPosition="1419" endWordPosition="1422">ted according to the analysis made in the training corpus, provided by SemEval-2013. The distance between two synsets is calculated with the relations found; and simply it is the sum of the weights assigned to each connection. MinDistP(P, Q) = MinDistS(Px, Qy), V (X, Y) MinDistS(X, Y) = Min(Xl, Y ), V(i, j) k=m Min(X1;Y) = W(Rel(L[k],L[k+1])) k=0 L = BFS(X1;Y) Where i and j represents the i-th and j-th sense of the word; P and Q represents words collections; Px is the X-th word of P; Qy is the Y-th word of Q; MinDistP obtains a value that represents a minimal semantic distance across WordNet (Miller et al., 2006) resource (this resource is involved into the integrator resource, ISR-WN (Gutiérrez et al., 2011a; 2010a); MinDistS the minimal semantic distance between two words; Min represents the minimal semantic distance between two senses collections; L is a collection of synsets that represents the minimal path between two synsets using BFS; Rel obtains semantic relation types between two synsets; W is a functions that apply the rules described in Table 1. The maximum and average distance is calculated in a similar fashion but using the maximum and average instead of the minimum. 3.3 Semantic Alignmen</context>
</contexts>
<marker>Miller, Fellbaum, Tengi, Wakefield, Langone, Haskell, 2006</marker>
<rawString>Miller, G. A.; C. Fellbaum; R. Tengi; P. Wakefield; H. Langone and B. R. Haskell. WordNet a lexical database for the English language. Cognitive Science Laboratory Princeton University 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet:: Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>Demonstration Papers at HLT-NAACL 2004, Association for Computational Linguistics,</booktitle>
<pages>38--41</pages>
<contexts>
<context position="2954" citStr="Pedersen et al., 2004" startWordPosition="438" endWordPosition="441">is paper, specifically section 2 is a brief Related Work. Section 3 describes the system architecture and our run. Continuing with section 4 we describe the training phase. Following that, section 5 presents the results and discussion for our Machine Learning System. Finally we conclude and propose our future works (Section 6). 2 Related Work There have been many WordNet-based similarity measures, among other highlights the work of researchers like (Budanitsky and Hirst, 2006; Leacock and Chodorow, 1998; Mihalcea et al., 2006; Richardson et al., 1994). On the other hand, WordNet::Similarity1 (Pedersen et al., 2004) has been used by other researchers in an interesting array of domains. WordNet::Similarity implements measures of similarity and relatedness between a pair of concepts (or synsets2) based on the structure and content of WordNet. According to (Pedersen et al., 2004), three of the six measures of similarity are based on the information content of the least 1http://sourceforge.net/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEv</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T.; S. Patwardhan and J. Michelizzi. WordNet:: Similarity: measuring the relatedness of concepts. Demonstration Papers at HLT-NAACL 2004, Association for Computational Linguistics, 2004. 38-41 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy arXiv preprint cmp-lg/9511007,</title>
<date>1995</date>
<contexts>
<context position="3726" citStr="Resnik, 1995" startWordPosition="548" endWordPosition="549"> concepts (or synsets2) based on the structure and content of WordNet. According to (Pedersen et al., 2004), three of the six measures of similarity are based on the information content of the least 1http://sourceforge.net/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 93–97, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics common subsumer (LCS). These measures include res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997). Pursuant to Pedersen, there are three other similarity measures based on path lengths between a pair of concepts: lch (Leacock and Chodorow, 1998), wup (Wu and Palmer, 1994), and path. Our proposal differs from those of WordNet::Similarity and other measures of similarity in the way we selected the relevant WordNet relations (see section 3.2 for detail). Unlike others, our measure assign weight to WordNet relations (any we consider relevant) depending to the place they occupy in the minimum path and the previously visited relations. Besides</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, P. Using information content to evaluate semantic similarity in a taxonomy arXiv preprint cmp-lg/9511007, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Richardson</author>
<author>A F Smeaton</author>
<author>J Murphy</author>
</authors>
<title>Using WordNet as a knowledge base for measuring semantic similarity between words,</title>
<date>1994</date>
<tech>Technical Report Working Paper CA-1294,</tech>
<institution>School of Computer Applications, Dublin City University,</institution>
<contexts>
<context position="2889" citStr="Richardson et al., 1994" startWordPosition="429" endWordPosition="432">ble to detect if two phrases are semantically close. The rest of this paper, specifically section 2 is a brief Related Work. Section 3 describes the system architecture and our run. Continuing with section 4 we describe the training phase. Following that, section 5 presents the results and discussion for our Machine Learning System. Finally we conclude and propose our future works (Section 6). 2 Related Work There have been many WordNet-based similarity measures, among other highlights the work of researchers like (Budanitsky and Hirst, 2006; Leacock and Chodorow, 1998; Mihalcea et al., 2006; Richardson et al., 1994). On the other hand, WordNet::Similarity1 (Pedersen et al., 2004) has been used by other researchers in an interesting array of domains. WordNet::Similarity implements measures of similarity and relatedness between a pair of concepts (or synsets2) based on the structure and content of WordNet. According to (Pedersen et al., 2004), three of the six measures of similarity are based on the information content of the least 1http://sourceforge.net/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volum</context>
</contexts>
<marker>Richardson, Smeaton, Murphy, 1994</marker>
<rawString>Richardson, R.; A. F. Smeaton and J. Murphy. Using WordNet as a knowledge base for measuring semantic similarity between words, Technical Report Working Paper CA-1294, School of Computer Applications, Dublin City University, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd annual meeting on Association for Computational Linguistics, Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<contexts>
<context position="3953" citStr="Wu and Palmer, 1994" startWordPosition="583" endWordPosition="586">et/projects/wn-similarity/ 2 A group of English words into sets of synonyms. 93 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 93–97, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics common subsumer (LCS). These measures include res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997). Pursuant to Pedersen, there are three other similarity measures based on path lengths between a pair of concepts: lch (Leacock and Chodorow, 1998), wup (Wu and Palmer, 1994), and path. Our proposal differs from those of WordNet::Similarity and other measures of similarity in the way we selected the relevant WordNet relations (see section 3.2 for detail). Unlike others, our measure assign weight to WordNet relations (any we consider relevant) depending to the place they occupy in the minimum path and the previously visited relations. Besides these, the novelty of our approach is using the weights as a function of semantic relations in a minimal distance path and also the method we used to arrive to those weight functions or rules. 3 System Architecture and descrip</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Z. and M. Palmer. Verbs semantics and lexical selection. Proceedings of the 32nd annual meeting on Association for Computational Linguistics, Association for Computational Linguistics, 1994. 133-138 p.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>