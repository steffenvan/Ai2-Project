<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003421">
<title confidence="0.990447">
Automatic Detection of Cognates Using Orthographic Alignment
</title>
<author confidence="0.993753">
Alina Maria Ciobanu, Liviu P. Dinu
</author>
<affiliation confidence="0.979297">
Faculty of Mathematics and Computer Science, University of Bucharest
Center for Computational Linguistics, University of Bucharest
</affiliation>
<email confidence="0.982004">
alina.ciobanu@my.fmi.unibuc.ro,ldinu@fmi.unibuc.ro
</email>
<sectionHeader confidence="0.993554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99969552631579">
Words undergo various changes when en-
tering new languages. Based on the as-
sumption that these linguistic changes fol-
low certain rules, we propose a method
for automatically detecting pairs of cog-
nates employing an orthographic align-
ment method which proved relevant for se-
quence alignment in computational biol-
ogy. We use aligned subsequences as fea-
tures for machine learning algorithms in
order to infer rules for linguistic changes
undergone by words when entering new
languages and to discriminate between
cognates and non-cognates. Given a list
of known cognates, our approach does not
require any other linguistic information.
However, it can be customized to integrate
historical information regarding language
evolution.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939113636364">
Cognates are words in different languages having
the same etymology and a common ancestor. In-
vestigating pairs of cognates is very useful in his-
torical and comparative linguistics, in the study
of language relatedness (Ng et al., 2010), phy-
logenetic inference (Atkinson et al., 2005) and
in identifying how and to what extent languages
change over time. In other several research ar-
eas, such as language acquisition, bilingual word
recognition (Dijkstra et al., 2012), corpus lin-
guistics (Simard et al., 1992), cross-lingual infor-
mation retrieval (Buckley et al., 1997) and ma-
chine translation (Kondrak et al., 2003), the con-
dition of common etymology is usually not essen-
tial and cognates are regarded as words with high
cross-lingual meaning and orthographic or pho-
netic similarity.
The wide range of applications in which cog-
nates prove useful attracted more and more at-
tention on methods for detecting such related
pairs of words. This task is most challenging
for resource-poor languages, for which etymologi-
cally related information is not accessible. There-
fore, the research (Inkpen et al., 2005; Mulloni and
Pekar, 2006; Hauer and Kondrak, 2011) focused
on automatic identification of cognate pairs, start-
ing from lists of known cognates.
In this paper, we propose a method for automat-
ically determining pairs of cognates across lan-
guages. The proposed method requires a list of
known cognates and, for languages for which ad-
ditional linguistic information is available, it can
be customized to integrate historical information
regarding the evolution of the language. The rest
of the paper is organized as follows: in Section
2 we present and analyze alternative methods and
related work in this area. In Section 3 we intro-
duce our approach for detection of cognates us-
ing orthographic alignment. In Section 4 we de-
scribe the experiments we conduct and we report
and analyze the results, together with a compari-
son with previous methods. Finally, in Section 5
we draw the conclusions of our study and describe
our plans for extending the method.
</bodyText>
<sectionHeader confidence="0.999833" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999964285714286">
There are three important aspects widely investi-
gated in the task of cognate identification: seman-
tic, phonetic and orthographic similarity. They
were employed both individually (Simard et al.,
1992; Inkpen et al., 2005; Church, 1993) and com-
bined (Kondrak, 2004; Steiner et al., 2011) in or-
der to detect pairs of cognates across languages.
For determining semantic similarity, external lexi-
cal resources, such as WordNet (Fellbaum, 1998),
or large corpora, might be necessary. For measur-
ing phonetic and orthographic proximity of cog-
nate candidates, string similarity metrics can be
applied, using the phonetic or orthographic word
forms as input. Various measures were investi-
</bodyText>
<page confidence="0.984488">
99
</page>
<bodyText confidence="0.973161163265306">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
gated and compared (Inkpen et al., 2005; Hall and
Klein, 2010); Levenshtein distance (Levenshtein,
1965), XDice (Brew and McKelvie, 1996) and
the longest common subsequence ratio (Melamed,
1995) are among the most frequently used metrics
in this field. Gomes and Lopes (2011) proposed
SpSim, a more complex method for computing the
similarity of cognate pairs which tolerates learned
transitions between words.
Algorithms for string alignment were success-
fully used for identifying cognates based on both
their forms, orthographic and phonetic. Delmestri
and Cristianini (2010) used basic sequence align-
ment algorithms (Needleman and Wunsch, 1970;
Smith and Waterman, 1981; Gotoh, 1982) to ob-
tain orthographic alignment scores for cognate
candidates. Kondrak (2000) developed the ALINE
system, which aligns words’ phonetic transcrip-
tions based on multiple phonetic features and com-
putes similarity scores using dynamic program-
ming. List (2012) proposed a framework for au-
tomatic detection of cognate pairs, LexStat, which
combines different approaches to sequence com-
parison and alignment derived from those used in
historical linguistics and evolutionary biology.
The changes undergone by words when enter-
ing from one language into another and the trans-
formation rules they follow have been successfully
employed in various approaches to cognate detec-
tion (Koehn and Knight, 2000; Mulloni and Pekar,
2006; Navlea and Todirascu, 2011). These ortho-
graphic changes have also been used in cognate
production, which is closely related to the task of
cognate detection, but has not yet been as inten-
sively studied. While the purpose of cognate de-
tection is to determine whether two given words
form a cognate pair, the aim of cognate produc-
tion is, given a word in a source language, to
automatically produce its cognate pair in a tar-
get language. Beinborn et al. (2013) proposed a
method for cognate production relying on statis-
tical character-based machine translation, learn-
ing orthographic production patterns, and Mul-
loni (2007) introduced an algorithm for cognate
production based on edit distance alignment and
the identification of orthographic cues when words
enter a new language.
</bodyText>
<sectionHeader confidence="0.982195" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999969151515151">
Although there are multiple aspects that are rel-
evant in the study of language relatedness, such
as orthographic, phonetic, syntactic and semantic
differences, in this paper we focus only on lexical
evidence. The orthographic approach relies on the
idea that sound changes leave traces in the orthog-
raphy and alphabetic character correspondences
represent, to a fairly large extent, sound correspon-
dences (Delmestri and Cristianini, 2010).
Words undergo various changes when entering
new languages. We assume that rules for adapting
foreign words to the orthographic system of the
target languages might not have been very well
defined in their period of early development, but
they may have since become complex and proba-
bly language-specific. Detecting pairs of cognates
based on etymology is useful and reliable, but, for
resource-poor languages, methods which require
less linguistic knowledge might be necessary. Ac-
cording to Gusfield (1997), an edit transcript (rep-
resenting the conversion of one string to another)
and an alignment are mathematically equivalent
ways of describing relationships between strings.
Therefore, because the edit distance was widely
used in this research area and produced good re-
sults, we are encouraged to employ orthographic
alignment for identifying pairs of cognates, not
only to compute similarity scores, as was previ-
ously done, but to use aligned subsequences as
features for machine learning algorithms. Our in-
tuition is that inferring language-specific rules for
aligning words will lead to better performance in
the task of cognate identification.
</bodyText>
<subsectionHeader confidence="0.996476">
3.1 Orthographic Alignment
</subsectionHeader>
<bodyText confidence="0.9999855">
String alignment is closely related to the task
of sequence alignment in computational biology.
Therefore, to align pairs of words we employ the
Needleman-Wunsch global alignment algorithm
(Needleman and Wunsch, 1970), which is mainly
used for aligning sequences of proteins or nu-
cleotides. Global sequence alignment aims at de-
termining the best alignment over the entire length
of the input sequences. The algorithm uses dy-
namic programming and, thus, guarantees to find
the optimal alignment. Its main idea is that any
partial path of the alignment along the optimal
path should be the optimal path leading up to that
point. Therefore, the optimal path can be deter-
mined by incremental extension of the optimal
subpaths (Schuler, 2002). For orthographic align-
ment, we consider words as input sequences and
we use a very simple substitution matrix, which
</bodyText>
<page confidence="0.956669">
100
</page>
<bodyText confidence="0.998993333333333">
gives equal scores to all substitutions, disregard-
ing diacritics (e.g., we ensure that e and e` are
matched).
</bodyText>
<subsectionHeader confidence="0.999713">
3.2 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999886285714286">
Using aligned pairs of words as input, we extract
features around mismatches in the alignments.
There are three types of mismatches, correspond-
ing to the following operations: insertion, deletion
and substitution. For example, for the Romanian
word exhaustiv and its Italian cognate pair esaus-
tivo, the alignment is as follows:
</bodyText>
<equation confidence="0.812912">
e x h a u s t i v -
e s - a u s t i v o
</equation>
<bodyText confidence="0.979608733333333">
The first mismatch (between x and s) is caused
by a substitution, the second mismatch (between
h and -) is caused by a deletion from source lan-
guage to target language, and the third mismatch
(between - and o) is caused by an insertion from
source language to target language. The features
we use are character n-grams around mismatches.
We experiment with two types of features:
i) n-grams around gaps, i.e., we account only
for insertions and deletions;
ii) n-grams around any type of mismatch, i.e.,
we account for all three types of mismatches.
The second alternative leads to better perfor-
mance, so we account for all mismatches. As
for the length of the grams, we experiment with
n ∈ {1, 2, 3}. We achieve slight improvements by
combining n-grams, i.e., for a given n, we use all
i-grams, where i ∈ {1, ..., n}. In order to provide
information regarding the position of the features,
we mark the beginning and the end of the word
with a $ symbol. Thus, for the above-mentioned
pair of cognates, (exhaustiv, esaustivo), we extract
the following features when n = 2:
x&gt;s ex&gt;es xh&gt;s-
h&gt;- xh&gt;s- ha&gt;-a
-&gt;o v-&gt;vo -$&gt;o$
For identical features we account only once.
Therefore, because there is one feature (xh&gt;s-)
which occurs twice in our example, we have 8 fea-
tures for the pair (exhaustiv, esaustivo).
</bodyText>
<subsectionHeader confidence="0.999559">
3.3 Learning Algorithms
</subsectionHeader>
<bodyText confidence="0.999980666666667">
We use Naive Bayes as a baseline and we exper-
iment with Support Vector Machines (SVMs) to
learn orthographic changes and to discriminate be-
tween pairs of cognates and non-cognates. We
put our system together using the Weka work-
bench (Hall et al., 2009), a suite of machine learn-
ing algorithms and tools. For SVM, we use the
wrapper provided by Weka for LibSVM (Chang
and Lin, 2011). We use the radial basis function
kernel (RBF), which can handle the case when
the relation between class labels and attributes is
non-linear, as it maps samples non-linearly into a
higher dimensional space. Given two instances xi
and xj, where xi ∈ Rn, the RBF kernel function
for xi and xj is defined as follows:
</bodyText>
<equation confidence="0.568423">
K(xi, xj) = exp(−γ||xi − xj||2), γ &gt; 0,
</equation>
<bodyText confidence="0.999595">
where γ is a kernel parameter.
We split the data in two subsets, for training
and testing, with a 3:1 ratio, and we perform grid
search and 3-fold cross validation over the train-
ing set in order to optimize hyperparameters c
and γ. We search over {1, 2, ...,10} for c and
over {10−5, 10−4, ...,104,105} for γ. The values
which optimize accuracy on the training set are re-
ported, for each pair of languages, in Table 3.
</bodyText>
<sectionHeader confidence="0.999599" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.941168">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.99987752631579">
We apply our method on an automatically ex-
tracted dataset of cognates for four pairs of
languages: Romanian-French, Romanian-Italian,
Romanian-Spanish and Romanian-Portuguese. In
order to build the dataset, we apply the method-
ology proposed by Ciobanu and Dinu (2014) on
the DexOnline1 machine-readable dictionary for
Romanian. We discard pairs of words for which
the forms across languages are identical (i.e., the
Romanian word matrice and its Italian cognate
pair matrice, having the same form), because these
pairs do not provide any orthographic changes to
be learned. For each pair of languages we de-
termine a number of non-cognate pairs equal to
the number of cognate pairs. Finally, we ob-
tain 445 pairs of cognates for Romanian-French2,
3,477 for Romanian-Italian, 5,113 for Romanian-
Spanish and 7,858 for Romanian-Portuguese. Be-
cause we need sets of approximately equal size for
</bodyText>
<footnote confidence="0.9981365">
1http://dexonline.ro
2The number of pairs of cognates is much lower for
French than for the other languages because there are numer-
ous Romanian words which have French etymology and, in
this paper, we do not consider these words to be cognate can-
didates.
</footnote>
<page confidence="0.979916">
101
</page>
<table confidence="0.9996716">
1st 2nd 3rd 4th 5th
IT iu&gt;io un&gt;on l-&gt;le t$&gt;-$ -$&gt;e$
FR un&gt;on ne&gt;n- iu&gt;io ji&gt;ti e$&gt;-$
ES -$&gt;o$ t¸i&gt;ci –&gt;´on ie&gt;i´o at&gt;ad
PT ie&gt;˜ao aj&gt;ac¸ t¸i&gt;c¸˜a i$&gt;-$ ˘a$&gt;a$
</table>
<tableCaption confidence="0.84955575">
Table 1: The most relevant orthographic cues for
each pair of languages determined on the entire
datasets using the x2 attribute evaluation method
implemented in Weka.
</tableCaption>
<table confidence="0.9996876">
1st 2nd 3rd 4th 5th
IT -$&gt;e$ -$&gt;o$ ˘a$&gt;a$ –&gt;re ji&gt;zi
FR e$&gt;-$ un&gt;on ne&gt;n- iu&gt;io t¸i&gt;ti
ES -$&gt;o$ e$&gt;-$ t¸i&gt;ci ˘a$&gt;a$ at&gt;ad
PT -$&gt;o$ ˘a$&gt;a$ e$&gt;-$ -$&gt;r$ -$&gt;a$
</table>
<tableCaption confidence="0.703233666666667">
Table 2: The most frequent orthographic cues for
each pair of languages determined on the cognate
lists using the raw frequencies.
</tableCaption>
<bodyText confidence="0.999503916666667">
comparison across languages, we keep 400 pairs
of cognates and 400 pairs of non-cognates for each
pair of languages. In Tables 1 and 2 we provide,
for each pair of languages, the five most relevant
2-gram orthographic changes, determined using
the x2 distribution implemented in Weka, and the
five most frequent 2-gram orthographic changes in
the cognate pairs from our dataset3. None of the
top ranked orthographic cues occurs at the begin-
ning of the word, while many of them occur at the
end of the word. The most frequent operation in
Tables 1 and 2 is substitution.
</bodyText>
<subsectionHeader confidence="0.820419">
4.2 Results Analysis
</subsectionHeader>
<bodyText confidence="0.93413547826087">
We propose a method for automatic detection
of cognate pairs using orthographic alignment.
We experiment with two machine-learning ap-
proaches: Naive Bayes and SVM. In Table 3 we
report the results of our research. We report the
n-gram values for which the best results are ob-
tained and the hyperparameters for SVM, c and γ.
The best results are obtained for French and Span-
ish, while the lowest accuracy is obtained for Por-
tuguese. The SVM produces better results for all
languages except Portuguese, where the accuracy
is equal. For Portuguese, both Naive Bayes and
SVM misclassify more non-cognates as cognates
3For brevity, we use in the tables the ISO 639-1 codes for
language abbreviation. We denote pairs of languages by the
target language, given the fact that Romanian is always the
source language in our experiments.
than viceversa. A possible explanation might be
the occurrence, in the dataset, of more remotely
related words, which are not labeled as cognates.
We plan to investigate this assumption and to ap-
ply the proposed method on other datasets in our
future work.
</bodyText>
<subsectionHeader confidence="0.999769">
4.3 Comparison with Previous Methods
</subsectionHeader>
<bodyText confidence="0.996842608695652">
We investigate the performance of the method we
propose in comparison to previous approaches for
automatic detection of cognate pairs based on or-
thographic similarity. We employ several ortho-
graphic metrics widely used in this research area:
the edit distance (Levenshtein, 1965), the longest
common subsequence ratio (Melamed, 1995) and
the XDice metric (Brew and McKelvie, 1996)4.
In addition, we use SpSim (Gomes and Lopes,
2011), which outperformed the longest common
subsequence ratio and a similarity measure based
on the edit distance in previous experiments. To
evaluate these metrics on our dataset, we use the
same train/test sets as we did in our previous ex-
periments and we follow the strategy described in
(Inkpen et al., 2005). First, we compute the pair-
wise distances between pairs of words for each
orthographic metric individually, as a single fea-
ture5. In order to detect the best threshold for dis-
criminating between cognates and non-cognates,
we run a decision stump classifier (provided by
Weka) on the training set for each pair of lan-
guages and for each metric. A decision stump is a
decision tree classifier with only one internal node
and two leaves corresponding to our two class la-
bels. Using the best threshold value selected for
each metric and pair of languages, we further clas-
sify the pairs of words in our test sets as cognates
or non-cognates. In Table 4 we report the results
for each approach. Our method performs better
than the orthographic metrics considered as indi-
vidual features. Out of the four similarity met-
rics, SpSim obtains, overall, the best performance.
These results support the relevance of accounting
for orthographic cues in cognate identification.
4We use normalized similarity metrics. For the edit dis-
tance, we subtract the normalized value from 1 in order to
obtain similarity.
5SpSim cannot be computed directly, as the other metrics,
so we introduce an additional step in which we use 1/3 of the
training set (only cognates are needed) to learn orthographic
changes. In order to maintain a stratified dataset, we discard
an equal number of non-cognates in the training set and then
we compute the distances for the rest of the training set and
for the test set. We use the remaining of the initial training
set for the next step of the procedure.
</bodyText>
<page confidence="0.994978">
102
</page>
<table confidence="0.999888833333333">
P Naive Bayes n P R SVM n c γ
R A A
IT 0.72 0.93 79.0 1 0.76 0.92 81.5 1 1 0.10
FR 0.81 0.91 82.0 2 0.84 0.89 87.0 2 10 0.01
ES 0.79 0.92 84.0 1 0.85 0.88 86.5 2 4 0.01
PT 0.67 0.88 73.0 2 0.70 0.78 73.0 2 10 0.01
</table>
<tableCaption confidence="0.618927666666667">
Table 3: Results for automatic detection of cognates using orthographic alignment. We report the preci-
sion (P), recall (R) and accuracy (A) obtained on the test sets and the optimal n-gram values. For SVM
we also report the optimal hyperparameters c and γ obtained during cross-validation on the training sets.
</tableCaption>
<table confidence="0.999907333333333">
P EDIT t P LCSR t P XDICE t P SPSIM t
R A R A R A R A
IT 0.67 0.97 75.0 0.43 0.68 0.91 75.0 0.51 0.66 0.98 74.0 0.21 0.66 0.98 74.5 0.44
FR 0.76 0.93 82.0 0.30 0.76 0.90 81.5 0.42 0.77 0.79 78.0 0.26 0.86 0.83 85.0 0.59
ES 0.77 0.91 82.0 0.56 0.72 0.97 80.0 0.47 0.72 0.99 80.5 0.19 0.81 0.90 85.0 0.64
PT 0.62 0.99 69.5 0.34 0.59 0.99 65.5 0.34 0.57 0.99 63.5 0.10 0.62 0.97 69.0 0.39
</table>
<tableCaption confidence="0.946486333333333">
Table 4: Comparison with previous methods for automatic detection of cognate pairs based on orthog-
raphy. We report the precision (P), recall (R) and accuracy (A) obtained on the test sets and the optimal
threshold t for discriminating between cognates and non-cognates.
</tableCaption>
<sectionHeader confidence="0.981306" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99967042">
In this paper we proposed a method for automatic
detection of cognates based on orthographic align-
ment. We employed the Needleman-Wunsch al-
gorithm (Needleman and Wunsch, 1970) for se-
quence alignment widely-used in computational
biology and we used aligned pairs of words to
extract rules for lexical changes occurring when
words enter new languages. We applied our
method on an automatically extracted dataset of
cognates for four pairs of languages.
As future work, we plan to extend our method
on a few levels. In this paper we used a very
simple substitution matrix for the alignment algo-
rithm, but the method can be adapted to integrate
historical information regarding language evolu-
tion. The substitution matrix for the alignment al-
gorithm can be customized with language-specific
information, in order to reflect the probability of
a character to change into another. An important
achievement in this direction belongs to Delmestri
and Cristianini (2010), who introduced PAM-like
matrices, linguistic-inspired substitution matrices
which are based on information regarding ortho-
graphic changes. We plan to investigate the con-
tribution of using this type of substitution matrices
for our method.
We intend to investigate other approaches to
string alignment, such as local alignment (Smith
and Waterman, 1981), and other learning algo-
rithms for discriminating between cognates and
non-cognates. We plan to extend our analysis with
more language-specific features, where linguistic
knowledge is available. First, we intend to use the
part of speech as an additional feature. We assume
that some orthographic changes are dependent on
the part of speech of the words. Secondly, we want
to investigate whether accounting for the common
ancestor language influences the results. We are
interested to find out if the orthographic rules de-
pend on the source language, or if they are rather
specific to the target language. Finally, we plan to
make a performance comparison on cognate pairs
versus word-etymon pairs and to investigate false
friends (Nakov et al., 2007).
We further intend to adapt our method for cog-
nate detection to a closely related task, namely
cognate production, i.e., given an input word w,
a related language L and a set of learned rules for
orthographic changes, to produce the cognate pair
of win L.
</bodyText>
<sectionHeader confidence="0.980157" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9984508">
We thank the anonymous reviewers for their help-
ful and constructive comments. The contribution
of the authors to this paper is equal. Research sup-
ported by CNCS UEFISCDI, project number PN-
II-ID-PCE-2011-3-0959.
</bodyText>
<page confidence="0.999342">
103
</page>
<sectionHeader confidence="0.950287" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997715743119267">
Quentin D. Atkinson, Russell D. Gray, Geoff K.
Nicholls, and David J. Welch. 2005. From Words
to Dates: Water into Wine, Mathemagic or Phylo-
genetic Inference? Transactions of the Philological
Society, 103:193–219.
Lisa Beinborn, Torsten Zesch, and Iryna Gurevych.
2013. Cognate Production using Character-based
Machine Translation. In Proceedings of the 6th In-
ternational Joint Conference on Natural Language
Processing, IJCNLP 2013, pages 883–891.
Chris Brew and David McKelvie. 1996. Word-Pair
Extraction for Lexicography. In Proceeding of Text,
Speech and Dialogue, TSD 1996, pages 45–55.
Chris Buckley, Mandar Mitra, Janet A. Walz, and
Claire Cardie. 1997. Using Clustering and Super-
Concepts Within SMART: TREC 6. In Proceedings
of the 6th Text Retrieval Conference, TREC 1997,
pages 107–124.
Chih-Chung Chang and Chih-Jen Lin. 2011.
LIBSVM: A Library for Support Vector Ma-
chines. ACM Transactions on Intelligent Sys-
tems and Technology, 2:27:1–27:27. Soft-
ware available at http://www.csie.ntu.
edu.tw/˜cjlin/libsvm.
Kenneth W. Church. 1993. Char align: A program
for aligning parallel texts at the character level. In
Proceedings of the 31st Annual Meeting of the As-
sociation for Computational Linguistics, ACL 1993,
pages 1–8.
Alina Maria Ciobanu and Liviu P. Dinu. 2014. Build-
ing a Dataset of Multilingual Cognates for the Ro-
manian Lexicon. In Proceedings of the 9th Interna-
tional Conference on Language Resources and Eval-
uation, LREC 2014.
Antonella Delmestri and Nello Cristianini. 2010.
String Similarity Measures and PAM-like Matrices
for Cognate Identification. Bucharest Working Pa-
pers in Linguistics, 12(2):71–82.
Ton Dijkstra, Franc Grootjen, and Job Schepens. 2012.
Distributions of Cognates in Europe as Based on
Levenshtein Distance. Bilingualism: Language and
Cognition, 15:157–166.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Massachusetts.
Lu´ıs Gomes and Jos´e Gabriel Pereira Lopes. 2011.
Measuring spelling similarity for cognate identifi-
cation. In Proceedings of the 15th Portugese Con-
ference on Progress in Artificial Intelligence, EPIA
2011, pages 624–633. Software available at http:
//research.variancia.com/spsim.
Osamu Gotoh. 1982. An improved algorithm for
matching biological sequences. Journal of Molec-
ular Biology, 162(3):705–708.
Dan Gusfield. 1997. Algorithms on Strings, Trees and
Sequences: computer science and computational bi-
ology. Cambridge University Press New York, NY,
USA.
David Hall and Dan Klein. 2010. Finding Cognate
Groups Using Phylogenies. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2010, pages 1030–1039.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an up-
date. SIGKDD Explorations, 11(1):10–18. Soft-
ware available at http://www.cs.waikato.
ac.nz/ml/weka.
Bradley Hauer and Grzegorz Kondrak. 2011. Cluster-
ing semantically equivalent words into cognate sets
in multilingual lists. In 5th International Joint Con-
ference on Natural Language Processing, IJCNLP
2011, pages 865–873.
Diana Inkpen, Oana Frunza, and Grzegorz Kondrak.
2005. Automatic Identification of Cognates and
False Friends in French and English. In Proceed-
ings of the International Conference on Recent Ad-
vances in Natural Language Processing, RANLP
2005, pages 251–257.
Philipp Koehn and Kevin Knight. 2000. Estimat-
ing Word Translation Probabilities from Unrelated
Monolingual Corpora Using the EM Algorithm. In
Proceedings of the 17th National Conference on Ar-
tificial Intelligence and 12th Conference on Inno-
vative Applications of Artificial Intelligence, pages
711–715.
Grzegorz Kondrak, Daniel Marcu, and Keven Knight.
2003. Cognates Can Improve Statistical Translation
Models. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology, HLT-NAACL 2003, pages 46–48.
Grzegorz Kondrak. 2000. A New Algorithm for the
Alignment of Phonetic Sequences. In Proceedings
of the 1st North American Chapter of the Asso-
ciation for Computational Linguistics Conference,
NAACL 2000, pages 288–295.
Grzegorz Kondrak. 2004. Combining Evidence in
Cognate Identification. In Proceedings of the 17th
Conference of the Canadian Society for Computa-
tional Studies of Intelligence on Advances in Artifi-
cial Intelligence, pages 44–59.
Vladimir I. Levenshtein. 1965. Binary Codes Capable
of Correcting Deletions, Insertions, and Reversals.
Soviet Physics Doklady, 10:707–710.
Johann-Mattis List. 2012. LexStat: Automatic De-
tection of Cognates in Multilingual Wordlists. In
Proceedings of the EACL 2012 Joint Workshop of
LINGVIS and UNCLH, pages 117–125.
</reference>
<page confidence="0.983834">
104
</page>
<reference confidence="0.999878529411765">
Dan Melamed. 1995. Automatic Evaluation and Uni-
form Filter Cascades for Inducing N-Best Transla-
tion Lexicons. In Proceedings of the 3rd Workshop
on Very Large Corpora.
Andrea Mulloni and Viktor Pekar. 2006. Automatic
detection of orthographic cues for cognate recog-
nition. In In Proceedings of the 5th International
Conference on Language Resources and Evaluation,
LREC 2006, pages 2387–2390.
Andrea Mulloni. 2007. Automatic Prediction of Cog-
nate Orthography Using Support Vector Machines.
In Proceedings of the 45th Annual Meeting of the
ACL: Student Research Workshop, ACL 2007, pages
25–30.
Svetlin Nakov, Preslav Nakov, and Elena Paskaleva.
2007. Cognate or False Friend? Ask the Web! In
Proceedings of the RANLP 2007 Workshop ”Acqui-
sition and Management of Multilingual Lexicons”,
pages 55–62.
Mirabela Navlea and Amalia Todirascu. 2011. Using
Cognates in a French-Romanian Lexical Alignment
System: A Comparative Study. In Proceedings of
the International Conference on Recent Advances in
Natural Language Processing, RANLP 2011, pages
247–253.
Saul B. Needleman and Christian D. Wunsch. 1970.
A general method applicable to the search for simi-
larities in the amino acid sequence of two proteins.
Journal of Molecular Biology, 48(3):443 – 453.
Ee-Lee Ng, Beatrice Chin, Alvin W. Yeo, and Bali
Ranaivo-Malanc¸on. 2010. Identification of Closely-
Related Indigenous Languages: An Orthographic
Approach. Int. J. of Asian Lang. Proc., 20(2):43–
62.
Gregory D. Schuler. 2002. Sequence Alignment and
Database Searching. Bioinformatics: A Practical
Guide to the Analysis of Genes and Proteins, 43. A.
D. Baxevanis and B. F. F. Ouellette, John Wiley &amp;
Sons, Inc., New York, USA.
Michel Simard, George F. Foster, and Pierre Isabelle.
1992. Using Cognates to Align Sentences in Bilin-
gual Corpora. In Proceedings of the 4th Interna-
tional Conference on Theoretical and Methodologi-
cal Issues in Machine Translation.
Temple F. Smith and Michael S. Waterman. 1981.
Identification of common molecular subsequences.
Journal of Molecular Biology, 147(1):195–197.
Lydia Steiner, Peter F. Stadler, and Michael Cysouw.
2011. A pipeline for computational historical lin-
guistics. Language Dynamics and Change, 1(1):89–
127.
</reference>
<page confidence="0.999008">
105
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.611448">
<title confidence="0.997579">Automatic Detection of Cognates Using Orthographic Alignment</title>
<author confidence="0.868686">Alina Maria Ciobanu</author>
<author confidence="0.868686">P Liviu</author>
<affiliation confidence="0.9405315">Faculty of Mathematics and Computer Science, University of Center for Computational Linguistics, University of</affiliation>
<email confidence="0.794149">alina.ciobanu@my.fmi.unibuc.ro,ldinu@fmi.unibuc.ro</email>
<abstract confidence="0.9950725">Words undergo various changes when entering new languages. Based on the assumption that these linguistic changes follow certain rules, we propose a method for automatically detecting pairs of cognates employing an orthographic alignment method which proved relevant for sequence alignment in computational biology. We use aligned subsequences as features for machine learning algorithms in order to infer rules for linguistic changes undergone by words when entering new languages and to discriminate between cognates and non-cognates. Given a list of known cognates, our approach does not require any other linguistic information. However, it can be customized to integrate historical information regarding language evolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Quentin D Atkinson</author>
<author>Russell D Gray</author>
<author>Geoff K Nicholls</author>
<author>David J Welch</author>
</authors>
<title>From Words to Dates: Water into Wine, Mathemagic or Phylogenetic Inference?</title>
<date>2005</date>
<journal>Transactions of the Philological Society,</journal>
<pages>103--193</pages>
<contexts>
<context position="1313" citStr="Atkinson et al., 2005" startWordPosition="184" endWordPosition="187"> rules for linguistic changes undergone by words when entering new languages and to discriminate between cognates and non-cognates. Given a list of known cognates, our approach does not require any other linguistic information. However, it can be customized to integrate historical information regarding language evolution. 1 Introduction Cognates are words in different languages having the same etymology and a common ancestor. Investigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness (Ng et al., 2010), phylogenetic inference (Atkinson et al., 2005) and in identifying how and to what extent languages change over time. In other several research areas, such as language acquisition, bilingual word recognition (Dijkstra et al., 2012), corpus linguistics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on</context>
</contexts>
<marker>Atkinson, Gray, Nicholls, Welch, 2005</marker>
<rawString>Quentin D. Atkinson, Russell D. Gray, Geoff K. Nicholls, and David J. Welch. 2005. From Words to Dates: Water into Wine, Mathemagic or Phylogenetic Inference? Transactions of the Philological Society, 103:193–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Beinborn</author>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
</authors>
<title>Cognate Production using Character-based Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Natural Language Processing, IJCNLP</booktitle>
<pages>883--891</pages>
<contexts>
<context position="5856" citStr="Beinborn et al. (2013)" startWordPosition="893" endWordPosition="896">d the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn and Knight, 2000; Mulloni and Pekar, 2006; Navlea and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied. While the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language. Beinborn et al. (2013) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni (2007) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language. 3 Our Approach Although there are multiple aspects that are relevant in the study of language relatedness, such as orthographic, phonetic, syntactic and semantic differences, in this paper we focus only on lexical evidence. The orthographic approach relies on the idea that sound</context>
</contexts>
<marker>Beinborn, Zesch, Gurevych, 2013</marker>
<rawString>Lisa Beinborn, Torsten Zesch, and Iryna Gurevych. 2013. Cognate Production using Character-based Machine Translation. In Proceedings of the 6th International Joint Conference on Natural Language Processing, IJCNLP 2013, pages 883–891.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Brew</author>
<author>David McKelvie</author>
</authors>
<title>Word-Pair Extraction for Lexicography.</title>
<date>1996</date>
<booktitle>In Proceeding of Text, Speech and Dialogue, TSD</booktitle>
<pages>45--55</pages>
<contexts>
<context position="4128" citStr="Brew and McKelvie, 1996" startWordPosition="625" endWordPosition="628">, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognat</context>
<context position="15530" citStr="Brew and McKelvie, 1996" startWordPosition="2484" endWordPosition="2487">e occurrence, in the dataset, of more remotely related words, which are not labeled as cognates. We plan to investigate this assumption and to apply the proposed method on other datasets in our future work. 4.3 Comparison with Previous Methods We investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity. We employ several orthographic metrics widely used in this research area: the edit distance (Levenshtein, 1965), the longest common subsequence ratio (Melamed, 1995) and the XDice metric (Brew and McKelvie, 1996)4. In addition, we use SpSim (Gomes and Lopes, 2011), which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments. To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in (Inkpen et al., 2005). First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature5. In order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision</context>
</contexts>
<marker>Brew, McKelvie, 1996</marker>
<rawString>Chris Brew and David McKelvie. 1996. Word-Pair Extraction for Lexicography. In Proceeding of Text, Speech and Dialogue, TSD 1996, pages 45–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
<author>Mandar Mitra</author>
<author>Janet A Walz</author>
<author>Claire Cardie</author>
</authors>
<title>Using Clustering and SuperConcepts Within SMART: TREC 6.</title>
<date>1997</date>
<booktitle>In Proceedings of the 6th Text Retrieval Conference, TREC</booktitle>
<pages>107--124</pages>
<contexts>
<context position="1599" citStr="Buckley et al., 1997" startWordPosition="228" endWordPosition="231">mation regarding language evolution. 1 Introduction Cognates are words in different languages having the same etymology and a common ancestor. Investigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness (Ng et al., 2010), phylogenetic inference (Atkinson et al., 2005) and in identifying how and to what extent languages change over time. In other several research areas, such as language acquisition, bilingual word recognition (Dijkstra et al., 2012), corpus linguistics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mulloni and Pekar, 2006; Hauer and Kondrak, 2011) focused on auto</context>
</contexts>
<marker>Buckley, Mitra, Walz, Cardie, 1997</marker>
<rawString>Chris Buckley, Mandar Mitra, Janet A. Walz, and Claire Cardie. 1997. Using Clustering and SuperConcepts Within SMART: TREC 6. In Proceedings of the 6th Text Retrieval Conference, TREC 1997, pages 107–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology,</booktitle>
<pages>2--27</pages>
<note>Software available at http://www.csie.ntu. edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="10879" citStr="Chang and Lin, 2011" startWordPosition="1709" endWordPosition="1712">&gt;- xh&gt;s- ha&gt;-a -&gt;o v-&gt;vo -$&gt;o$ For identical features we account only once. Therefore, because there is one feature (xh&gt;s-) which occurs twice in our example, we have 8 features for the pair (exhaustiv, esaustivo). 3.3 Learning Algorithms We use Naive Bayes as a baseline and we experiment with Support Vector Machines (SVMs) to learn orthographic changes and to discriminate between pairs of cognates and non-cognates. We put our system together using the Weka workbench (Hall et al., 2009), a suite of machine learning algorithms and tools. For SVM, we use the wrapper provided by Weka for LibSVM (Chang and Lin, 2011). We use the radial basis function kernel (RBF), which can handle the case when the relation between class labels and attributes is non-linear, as it maps samples non-linearly into a higher dimensional space. Given two instances xi and xj, where xi ∈ Rn, the RBF kernel function for xi and xj is defined as follows: K(xi, xj) = exp(−γ||xi − xj||2), γ &gt; 0, where γ is a kernel parameter. We split the data in two subsets, for training and testing, with a 3:1 ratio, and we perform grid search and 3-fold cross validation over the training set in order to optimize hyperparameters c and γ. We search ov</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http://www.csie.ntu. edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>Char align: A program for aligning parallel texts at the character level.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<pages>1--8</pages>
<contexts>
<context position="3334" citStr="Church, 1993" startWordPosition="511" endWordPosition="512"> work in this area. In Section 3 we introduce our approach for detection of cognates using orthographic alignment. In Section 4 we describe the experiments we conduct and we report and analyze the results, together with a comparison with previous methods. Finally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method. 2 Related Work There are three important aspects widely investigated in the task of cognate identification: semantic, phonetic and orthographic similarity. They were employed both individually (Simard et al., 1992; Inkpen et al., 2005; Church, 1993) and combined (Kondrak, 2004; Steiner et al., 2011) in order to detect pairs of cognates across languages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-2</context>
</contexts>
<marker>Church, 1993</marker>
<rawString>Kenneth W. Church. 1993. Char align: A program for aligning parallel texts at the character level. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, ACL 1993, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Maria Ciobanu</author>
<author>Liviu P Dinu</author>
</authors>
<title>Building a Dataset of Multilingual Cognates for the Romanian Lexicon.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC</booktitle>
<contexts>
<context position="11944" citStr="Ciobanu and Dinu (2014)" startWordPosition="1894" endWordPosition="1897">ing, with a 3:1 ratio, and we perform grid search and 3-fold cross validation over the training set in order to optimize hyperparameters c and γ. We search over {1, 2, ...,10} for c and over {10−5, 10−4, ...,104,105} for γ. The values which optimize accuracy on the training set are reported, for each pair of languages, in Table 3. 4 Experiments 4.1 Data We apply our method on an automatically extracted dataset of cognates for four pairs of languages: Romanian-French, Romanian-Italian, Romanian-Spanish and Romanian-Portuguese. In order to build the dataset, we apply the methodology proposed by Ciobanu and Dinu (2014) on the DexOnline1 machine-readable dictionary for Romanian. We discard pairs of words for which the forms across languages are identical (i.e., the Romanian word matrice and its Italian cognate pair matrice, having the same form), because these pairs do not provide any orthographic changes to be learned. For each pair of languages we determine a number of non-cognate pairs equal to the number of cognate pairs. Finally, we obtain 445 pairs of cognates for Romanian-French2, 3,477 for Romanian-Italian, 5,113 for RomanianSpanish and 7,858 for Romanian-Portuguese. Because we need sets of approxima</context>
</contexts>
<marker>Ciobanu, Dinu, 2014</marker>
<rawString>Alina Maria Ciobanu and Liviu P. Dinu. 2014. Building a Dataset of Multilingual Cognates for the Romanian Lexicon. In Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonella Delmestri</author>
<author>Nello Cristianini</author>
</authors>
<title>String Similarity Measures and PAM-like Matrices for Cognate Identification. Bucharest Working Papers in Linguistics,</title>
<date>2010</date>
<pages>12--2</pages>
<contexts>
<context position="4568" citStr="Delmestri and Cristianini (2010)" startWordPosition="689" endWordPosition="692">2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes </context>
<context position="6630" citStr="Delmestri and Cristianini, 2010" startWordPosition="1006" endWordPosition="1009">s, and Mulloni (2007) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language. 3 Our Approach Although there are multiple aspects that are relevant in the study of language relatedness, such as orthographic, phonetic, syntactic and semantic differences, in this paper we focus only on lexical evidence. The orthographic approach relies on the idea that sound changes leave traces in the orthography and alphabetic character correspondences represent, to a fairly large extent, sound correspondences (Delmestri and Cristianini, 2010). Words undergo various changes when entering new languages. We assume that rules for adapting foreign words to the orthographic system of the target languages might not have been very well defined in their period of early development, but they may have since become complex and probably language-specific. Detecting pairs of cognates based on etymology is useful and reliable, but, for resource-poor languages, methods which require less linguistic knowledge might be necessary. According to Gusfield (1997), an edit transcript (representing the conversion of one string to another) and an alignment</context>
<context position="19633" citStr="Delmestri and Cristianini (2010)" startWordPosition="3203" endWordPosition="3206">enter new languages. We applied our method on an automatically extracted dataset of cognates for four pairs of languages. As future work, we plan to extend our method on a few levels. In this paper we used a very simple substitution matrix for the alignment algorithm, but the method can be adapted to integrate historical information regarding language evolution. The substitution matrix for the alignment algorithm can be customized with language-specific information, in order to reflect the probability of a character to change into another. An important achievement in this direction belongs to Delmestri and Cristianini (2010), who introduced PAM-like matrices, linguistic-inspired substitution matrices which are based on information regarding orthographic changes. We plan to investigate the contribution of using this type of substitution matrices for our method. We intend to investigate other approaches to string alignment, such as local alignment (Smith and Waterman, 1981), and other learning algorithms for discriminating between cognates and non-cognates. We plan to extend our analysis with more language-specific features, where linguistic knowledge is available. First, we intend to use the part of speech as an a</context>
</contexts>
<marker>Delmestri, Cristianini, 2010</marker>
<rawString>Antonella Delmestri and Nello Cristianini. 2010. String Similarity Measures and PAM-like Matrices for Cognate Identification. Bucharest Working Papers in Linguistics, 12(2):71–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ton Dijkstra</author>
<author>Franc Grootjen</author>
<author>Job Schepens</author>
</authors>
<date>2012</date>
<booktitle>Distributions of Cognates in Europe as Based on Levenshtein Distance. Bilingualism: Language and Cognition,</booktitle>
<pages>15--157</pages>
<contexts>
<context position="1497" citStr="Dijkstra et al., 2012" startWordPosition="213" endWordPosition="216">t require any other linguistic information. However, it can be customized to integrate historical information regarding language evolution. 1 Introduction Cognates are words in different languages having the same etymology and a common ancestor. Investigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness (Ng et al., 2010), phylogenetic inference (Atkinson et al., 2005) and in identifying how and to what extent languages change over time. In other several research areas, such as language acquisition, bilingual word recognition (Dijkstra et al., 2012), corpus linguistics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore</context>
</contexts>
<marker>Dijkstra, Grootjen, Schepens, 2012</marker>
<rawString>Ton Dijkstra, Franc Grootjen, and Job Schepens. 2012. Distributions of Cognates in Europe as Based on Levenshtein Distance. Bilingualism: Language and Cognition, 15:157–166.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Gomes</author>
<author>Jos´e Gabriel Pereira Lopes</author>
</authors>
<title>Measuring spelling similarity for cognate identification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th Portugese Conference on Progress in Artificial Intelligence, EPIA 2011,</booktitle>
<pages>624--633</pages>
<note>Software available at http: //research.variancia.com/spsim.</note>
<contexts>
<context position="4266" citStr="Gomes and Lopes (2011)" startWordPosition="647" endWordPosition="650">dates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features a</context>
<context position="15582" citStr="Gomes and Lopes, 2011" startWordPosition="2493" endWordPosition="2496"> words, which are not labeled as cognates. We plan to investigate this assumption and to apply the proposed method on other datasets in our future work. 4.3 Comparison with Previous Methods We investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity. We employ several orthographic metrics widely used in this research area: the edit distance (Levenshtein, 1965), the longest common subsequence ratio (Melamed, 1995) and the XDice metric (Brew and McKelvie, 1996)4. In addition, we use SpSim (Gomes and Lopes, 2011), which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments. To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in (Inkpen et al., 2005). First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature5. In order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision stump classifier (provided by Weka) on the training</context>
</contexts>
<marker>Gomes, Lopes, 2011</marker>
<rawString>Lu´ıs Gomes and Jos´e Gabriel Pereira Lopes. 2011. Measuring spelling similarity for cognate identification. In Proceedings of the 15th Portugese Conference on Progress in Artificial Intelligence, EPIA 2011, pages 624–633. Software available at http: //research.variancia.com/spsim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Osamu Gotoh</author>
</authors>
<title>An improved algorithm for matching biological sequences.</title>
<date>1982</date>
<journal>Journal of Molecular Biology,</journal>
<volume>162</volume>
<issue>3</issue>
<contexts>
<context position="4677" citStr="Gotoh, 1982" startWordPosition="707" endWordPosition="708">n distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have</context>
</contexts>
<marker>Gotoh, 1982</marker>
<rawString>Osamu Gotoh. 1982. An improved algorithm for matching biological sequences. Journal of Molecular Biology, 162(3):705–708.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Gusfield</author>
</authors>
<title>Algorithms on Strings, Trees and Sequences: computer science and computational biology.</title>
<date>1997</date>
<publisher>Cambridge University Press</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7138" citStr="Gusfield (1997)" startWordPosition="1085" endWordPosition="1086">orrespondences represent, to a fairly large extent, sound correspondences (Delmestri and Cristianini, 2010). Words undergo various changes when entering new languages. We assume that rules for adapting foreign words to the orthographic system of the target languages might not have been very well defined in their period of early development, but they may have since become complex and probably language-specific. Detecting pairs of cognates based on etymology is useful and reliable, but, for resource-poor languages, methods which require less linguistic knowledge might be necessary. According to Gusfield (1997), an edit transcript (representing the conversion of one string to another) and an alignment are mathematically equivalent ways of describing relationships between strings. Therefore, because the edit distance was widely used in this research area and produced good results, we are encouraged to employ orthographic alignment for identifying pairs of cognates, not only to compute similarity scores, as was previously done, but to use aligned subsequences as features for machine learning algorithms. Our intuition is that inferring language-specific rules for aligning words will lead to better perf</context>
</contexts>
<marker>Gusfield, 1997</marker>
<rawString>Dan Gusfield. 1997. Algorithms on Strings, Trees and Sequences: computer science and computational biology. Cambridge University Press New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Dan Klein</author>
</authors>
<title>Finding Cognate Groups Using Phylogenies.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<pages>1030--1039</pages>
<contexts>
<context position="4053" citStr="Hall and Klein, 2010" startWordPosition="616" endWordPosition="619">nguages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Wate</context>
</contexts>
<marker>Hall, Klein, 2010</marker>
<rawString>David Hall and Dan Klein. 2010. Finding Cognate Groups Using Phylogenies. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL 2010, pages 1030–1039.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<note>Software available at http://www.cs.waikato. ac.nz/ml/weka.</note>
<contexts>
<context position="10750" citStr="Hall et al., 2009" startWordPosition="1685" endWordPosition="1688">for the above-mentioned pair of cognates, (exhaustiv, esaustivo), we extract the following features when n = 2: x&gt;s ex&gt;es xh&gt;sh&gt;- xh&gt;s- ha&gt;-a -&gt;o v-&gt;vo -$&gt;o$ For identical features we account only once. Therefore, because there is one feature (xh&gt;s-) which occurs twice in our example, we have 8 features for the pair (exhaustiv, esaustivo). 3.3 Learning Algorithms We use Naive Bayes as a baseline and we experiment with Support Vector Machines (SVMs) to learn orthographic changes and to discriminate between pairs of cognates and non-cognates. We put our system together using the Weka workbench (Hall et al., 2009), a suite of machine learning algorithms and tools. For SVM, we use the wrapper provided by Weka for LibSVM (Chang and Lin, 2011). We use the radial basis function kernel (RBF), which can handle the case when the relation between class labels and attributes is non-linear, as it maps samples non-linearly into a higher dimensional space. Given two instances xi and xj, where xi ∈ Rn, the RBF kernel function for xi and xj is defined as follows: K(xi, xj) = exp(−γ||xi − xj||2), γ &gt; 0, where γ is a kernel parameter. We split the data in two subsets, for training and testing, with a 3:1 ratio, and we</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explorations, 11(1):10–18. Software available at http://www.cs.waikato. ac.nz/ml/weka.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Hauer</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Clustering semantically equivalent words into cognate sets in multilingual lists.</title>
<date>2011</date>
<booktitle>In 5th International Joint Conference on Natural Language Processing, IJCNLP</booktitle>
<pages>865--873</pages>
<contexts>
<context position="2183" citStr="Hauer and Kondrak, 2011" startWordPosition="322" endWordPosition="325">rmation retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mulloni and Pekar, 2006; Hauer and Kondrak, 2011) focused on automatic identification of cognate pairs, starting from lists of known cognates. In this paper, we propose a method for automatically determining pairs of cognates across languages. The proposed method requires a list of known cognates and, for languages for which additional linguistic information is available, it can be customized to integrate historical information regarding the evolution of the language. The rest of the paper is organized as follows: in Section 2 we present and analyze alternative methods and related work in this area. In Section 3 we introduce our approach for</context>
</contexts>
<marker>Hauer, Kondrak, 2011</marker>
<rawString>Bradley Hauer and Grzegorz Kondrak. 2011. Clustering semantically equivalent words into cognate sets in multilingual lists. In 5th International Joint Conference on Natural Language Processing, IJCNLP 2011, pages 865–873.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Inkpen</author>
<author>Oana Frunza</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Automatic Identification of Cognates and False Friends in French and English.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing, RANLP</booktitle>
<pages>251--257</pages>
<contexts>
<context position="2132" citStr="Inkpen et al., 2005" startWordPosition="314" endWordPosition="317">tics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mulloni and Pekar, 2006; Hauer and Kondrak, 2011) focused on automatic identification of cognate pairs, starting from lists of known cognates. In this paper, we propose a method for automatically determining pairs of cognates across languages. The proposed method requires a list of known cognates and, for languages for which additional linguistic information is available, it can be customized to integrate historical information regarding the evolution of the language. The rest of the paper is organized as follows: in Section 2 we present and analyze alternative methods and related work in th</context>
<context position="4030" citStr="Inkpen et al., 2005" startWordPosition="612" endWordPosition="615">of cognates across languages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsc</context>
<context position="15890" citStr="Inkpen et al., 2005" startWordPosition="2544" endWordPosition="2547">cognate pairs based on orthographic similarity. We employ several orthographic metrics widely used in this research area: the edit distance (Levenshtein, 1965), the longest common subsequence ratio (Melamed, 1995) and the XDice metric (Brew and McKelvie, 1996)4. In addition, we use SpSim (Gomes and Lopes, 2011), which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments. To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in (Inkpen et al., 2005). First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature5. In order to detect the best threshold for discriminating between cognates and non-cognates, we run a decision stump classifier (provided by Weka) on the training set for each pair of languages and for each metric. A decision stump is a decision tree classifier with only one internal node and two leaves corresponding to our two class labels. Using the best threshold value selected for each metric and pair of languages, we further classify the pairs of words in our t</context>
</contexts>
<marker>Inkpen, Frunza, Kondrak, 2005</marker>
<rawString>Diana Inkpen, Oana Frunza, and Grzegorz Kondrak. 2005. Automatic Identification of Cognates and False Friends in French and English. In Proceedings of the International Conference on Recent Advances in Natural Language Processing, RANLP 2005, pages 251–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Estimating Word Translation Probabilities from Unrelated Monolingual Corpora Using the EM Algorithm.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence,</booktitle>
<pages>711--715</pages>
<contexts>
<context position="5371" citStr="Koehn and Knight, 2000" startWordPosition="808" endWordPosition="811"> (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn and Knight, 2000; Mulloni and Pekar, 2006; Navlea and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied. While the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language. Beinborn et al. (2013) proposed a method for cognate production relying on statistical character-based machine translation, learning orth</context>
</contexts>
<marker>Koehn, Knight, 2000</marker>
<rawString>Philipp Koehn and Kevin Knight. 2000. Estimating Word Translation Probabilities from Unrelated Monolingual Corpora Using the EM Algorithm. In Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, pages 711–715.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
<author>Daniel Marcu</author>
<author>Keven Knight</author>
</authors>
<title>Cognates Can Improve Statistical Translation Models.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, HLT-NAACL</booktitle>
<pages>46--48</pages>
<contexts>
<context position="1646" citStr="Kondrak et al., 2003" startWordPosition="236" endWordPosition="239">tion Cognates are words in different languages having the same etymology and a common ancestor. Investigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness (Ng et al., 2010), phylogenetic inference (Atkinson et al., 2005) and in identifying how and to what extent languages change over time. In other several research areas, such as language acquisition, bilingual word recognition (Dijkstra et al., 2012), corpus linguistics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mulloni and Pekar, 2006; Hauer and Kondrak, 2011) focused on automatic identification of cognate pairs, starting</context>
</contexts>
<marker>Kondrak, Marcu, Knight, 2003</marker>
<rawString>Grzegorz Kondrak, Daniel Marcu, and Keven Knight. 2003. Cognates Can Improve Statistical Translation Models. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, HLT-NAACL 2003, pages 46–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A New Algorithm for the Alignment of Phonetic Sequences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL</booktitle>
<pages>288--295</pages>
<contexts>
<context position="4756" citStr="Kondrak (2000)" startWordPosition="718" endWordPosition="719">st common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn a</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A New Algorithm for the Alignment of Phonetic Sequences. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL 2000, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Combining Evidence in Cognate Identification.</title>
<date>2004</date>
<booktitle>In Proceedings of the 17th Conference of the Canadian Society for Computational Studies of Intelligence on Advances in Artificial Intelligence,</booktitle>
<pages>44--59</pages>
<contexts>
<context position="3362" citStr="Kondrak, 2004" startWordPosition="516" endWordPosition="517">on 3 we introduce our approach for detection of cognates using orthographic alignment. In Section 4 we describe the experiments we conduct and we report and analyze the results, together with a comparison with previous methods. Finally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method. 2 Related Work There are three important aspects widely investigated in the task of cognate identification: semantic, phonetic and orthographic similarity. They were employed both individually (Simard et al., 1992; Inkpen et al., 2005; Church, 1993) and combined (Kondrak, 2004; Steiner et al., 2011) in order to detect pairs of cognates across languages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association f</context>
</contexts>
<marker>Kondrak, 2004</marker>
<rawString>Grzegorz Kondrak. 2004. Combining Evidence in Cognate Identification. In Proceedings of the 17th Conference of the Canadian Society for Computational Studies of Intelligence on Advances in Artificial Intelligence, pages 44–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions, and Reversals. Soviet Physics Doklady,</title>
<date>1965</date>
<pages>10--707</pages>
<contexts>
<context position="4095" citStr="Levenshtein, 1965" startWordPosition="622" endWordPosition="623"> external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthogr</context>
<context position="15429" citStr="Levenshtein, 1965" startWordPosition="2471" endWordPosition="2472">ways the source language in our experiments. than viceversa. A possible explanation might be the occurrence, in the dataset, of more remotely related words, which are not labeled as cognates. We plan to investigate this assumption and to apply the proposed method on other datasets in our future work. 4.3 Comparison with Previous Methods We investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity. We employ several orthographic metrics widely used in this research area: the edit distance (Levenshtein, 1965), the longest common subsequence ratio (Melamed, 1995) and the XDice metric (Brew and McKelvie, 1996)4. In addition, we use SpSim (Gomes and Lopes, 2011), which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments. To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in (Inkpen et al., 2005). First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature5. In order</context>
</contexts>
<marker>Levenshtein, 1965</marker>
<rawString>Vladimir I. Levenshtein. 1965. Binary Codes Capable of Correcting Deletions, Insertions, and Reversals. Soviet Physics Doklady, 10:707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johann-Mattis List</author>
</authors>
<title>LexStat: Automatic Detection of Cognates in Multilingual Wordlists.</title>
<date>2012</date>
<booktitle>In Proceedings of the EACL 2012 Joint Workshop of LINGVIS and UNCLH,</booktitle>
<pages>117--125</pages>
<contexts>
<context position="4934" citStr="List (2012)" startWordPosition="744" endWordPosition="745">similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn and Knight, 2000; Mulloni and Pekar, 2006; Navlea and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task </context>
</contexts>
<marker>List, 2012</marker>
<rawString>Johann-Mattis List. 2012. LexStat: Automatic Detection of Cognates in Multilingual Wordlists. In Proceedings of the EACL 2012 Joint Workshop of LINGVIS and UNCLH, pages 117–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Melamed</author>
</authors>
<title>Automatic Evaluation and Uniform Filter Cascades for Inducing N-Best Translation Lexicons.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="4185" citStr="Melamed, 1995" startWordPosition="635" endWordPosition="636">ssary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics gated and compared (Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, </context>
<context position="15483" citStr="Melamed, 1995" startWordPosition="2478" endWordPosition="2479">a. A possible explanation might be the occurrence, in the dataset, of more remotely related words, which are not labeled as cognates. We plan to investigate this assumption and to apply the proposed method on other datasets in our future work. 4.3 Comparison with Previous Methods We investigate the performance of the method we propose in comparison to previous approaches for automatic detection of cognate pairs based on orthographic similarity. We employ several orthographic metrics widely used in this research area: the edit distance (Levenshtein, 1965), the longest common subsequence ratio (Melamed, 1995) and the XDice metric (Brew and McKelvie, 1996)4. In addition, we use SpSim (Gomes and Lopes, 2011), which outperformed the longest common subsequence ratio and a similarity measure based on the edit distance in previous experiments. To evaluate these metrics on our dataset, we use the same train/test sets as we did in our previous experiments and we follow the strategy described in (Inkpen et al., 2005). First, we compute the pairwise distances between pairs of words for each orthographic metric individually, as a single feature5. In order to detect the best threshold for discriminating betwe</context>
</contexts>
<marker>Melamed, 1995</marker>
<rawString>Dan Melamed. 1995. Automatic Evaluation and Uniform Filter Cascades for Inducing N-Best Translation Lexicons. In Proceedings of the 3rd Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Mulloni</author>
<author>Viktor Pekar</author>
</authors>
<title>Automatic detection of orthographic cues for cognate recognition. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC</booktitle>
<pages>2387--2390</pages>
<contexts>
<context position="2157" citStr="Mulloni and Pekar, 2006" startWordPosition="318" endWordPosition="321">1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mulloni and Pekar, 2006; Hauer and Kondrak, 2011) focused on automatic identification of cognate pairs, starting from lists of known cognates. In this paper, we propose a method for automatically determining pairs of cognates across languages. The proposed method requires a list of known cognates and, for languages for which additional linguistic information is available, it can be customized to integrate historical information regarding the evolution of the language. The rest of the paper is organized as follows: in Section 2 we present and analyze alternative methods and related work in this area. In Section 3 we </context>
<context position="5396" citStr="Mulloni and Pekar, 2006" startWordPosition="812" endWordPosition="815">INE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn and Knight, 2000; Mulloni and Pekar, 2006; Navlea and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied. While the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language. Beinborn et al. (2013) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patte</context>
</contexts>
<marker>Mulloni, Pekar, 2006</marker>
<rawString>Andrea Mulloni and Viktor Pekar. 2006. Automatic detection of orthographic cues for cognate recognition. In In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC 2006, pages 2387–2390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Mulloni</author>
</authors>
<title>Automatic Prediction of Cognate Orthography Using Support Vector Machines.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL: Student Research Workshop, ACL</booktitle>
<pages>25--30</pages>
<contexts>
<context position="6019" citStr="Mulloni (2007)" startWordPosition="916" endWordPosition="918">and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied. While the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language. Beinborn et al. (2013) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni (2007) introduced an algorithm for cognate production based on edit distance alignment and the identification of orthographic cues when words enter a new language. 3 Our Approach Although there are multiple aspects that are relevant in the study of language relatedness, such as orthographic, phonetic, syntactic and semantic differences, in this paper we focus only on lexical evidence. The orthographic approach relies on the idea that sound changes leave traces in the orthography and alphabetic character correspondences represent, to a fairly large extent, sound correspondences (Delmestri and Cristia</context>
</contexts>
<marker>Mulloni, 2007</marker>
<rawString>Andrea Mulloni. 2007. Automatic Prediction of Cognate Orthography Using Support Vector Machines. In Proceedings of the 45th Annual Meeting of the ACL: Student Research Workshop, ACL 2007, pages 25–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svetlin Nakov</author>
<author>Preslav Nakov</author>
<author>Elena Paskaleva</author>
</authors>
<title>Cognate or False Friend? Ask the Web! In</title>
<date>2007</date>
<booktitle>Proceedings of the RANLP 2007 Workshop ”Acquisition and Management of Multilingual Lexicons”,</booktitle>
<pages>55--62</pages>
<marker>Nakov, Nakov, Paskaleva, 2007</marker>
<rawString>Svetlin Nakov, Preslav Nakov, and Elena Paskaleva. 2007. Cognate or False Friend? Ask the Web! In Proceedings of the RANLP 2007 Workshop ”Acquisition and Management of Multilingual Lexicons”, pages 55–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirabela Navlea</author>
<author>Amalia Todirascu</author>
</authors>
<title>Using Cognates in a French-Romanian Lexical Alignment System: A Comparative Study.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing, RANLP</booktitle>
<pages>247--253</pages>
<contexts>
<context position="5425" citStr="Navlea and Todirascu, 2011" startWordPosition="816" endWordPosition="819">words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules they follow have been successfully employed in various approaches to cognate detection (Koehn and Knight, 2000; Mulloni and Pekar, 2006; Navlea and Todirascu, 2011). These orthographic changes have also been used in cognate production, which is closely related to the task of cognate detection, but has not yet been as intensively studied. While the purpose of cognate detection is to determine whether two given words form a cognate pair, the aim of cognate production is, given a word in a source language, to automatically produce its cognate pair in a target language. Beinborn et al. (2013) proposed a method for cognate production relying on statistical character-based machine translation, learning orthographic production patterns, and Mulloni (2007) intro</context>
</contexts>
<marker>Navlea, Todirascu, 2011</marker>
<rawString>Mirabela Navlea and Amalia Todirascu. 2011. Using Cognates in a French-Romanian Lexical Alignment System: A Comparative Study. In Proceedings of the International Conference on Recent Advances in Natural Language Processing, RANLP 2011, pages 247–253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saul B Needleman</author>
<author>Christian D Wunsch</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>Journal of Molecular Biology,</journal>
<volume>48</volume>
<issue>3</issue>
<pages>453</pages>
<contexts>
<context position="4637" citStr="Needleman and Wunsch, 1970" startWordPosition="699" endWordPosition="702">Inkpen et al., 2005; Hall and Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and t</context>
<context position="8029" citStr="Needleman and Wunsch, 1970" startWordPosition="1214" endWordPosition="1217">d results, we are encouraged to employ orthographic alignment for identifying pairs of cognates, not only to compute similarity scores, as was previously done, but to use aligned subsequences as features for machine learning algorithms. Our intuition is that inferring language-specific rules for aligning words will lead to better performance in the task of cognate identification. 3.1 Orthographic Alignment String alignment is closely related to the task of sequence alignment in computational biology. Therefore, to align pairs of words we employ the Needleman-Wunsch global alignment algorithm (Needleman and Wunsch, 1970), which is mainly used for aligning sequences of proteins or nucleotides. Global sequence alignment aims at determining the best alignment over the entire length of the input sequences. The algorithm uses dynamic programming and, thus, guarantees to find the optimal alignment. Its main idea is that any partial path of the alignment along the optimal path should be the optimal path leading up to that point. Therefore, the optimal path can be determined by incremental extension of the optimal subpaths (Schuler, 2002). For orthographic alignment, we consider words as input sequences and we use a </context>
<context position="18847" citStr="Needleman and Wunsch, 1970" startWordPosition="3079" endWordPosition="3082">2.0 0.56 0.72 0.97 80.0 0.47 0.72 0.99 80.5 0.19 0.81 0.90 85.0 0.64 PT 0.62 0.99 69.5 0.34 0.59 0.99 65.5 0.34 0.57 0.99 63.5 0.10 0.62 0.97 69.0 0.39 Table 4: Comparison with previous methods for automatic detection of cognate pairs based on orthography. We report the precision (P), recall (R) and accuracy (A) obtained on the test sets and the optimal threshold t for discriminating between cognates and non-cognates. 5 Conclusions and Future Work In this paper we proposed a method for automatic detection of cognates based on orthographic alignment. We employed the Needleman-Wunsch algorithm (Needleman and Wunsch, 1970) for sequence alignment widely-used in computational biology and we used aligned pairs of words to extract rules for lexical changes occurring when words enter new languages. We applied our method on an automatically extracted dataset of cognates for four pairs of languages. As future work, we plan to extend our method on a few levels. In this paper we used a very simple substitution matrix for the alignment algorithm, but the method can be adapted to integrate historical information regarding language evolution. The substitution matrix for the alignment algorithm can be customized with langua</context>
</contexts>
<marker>Needleman, Wunsch, 1970</marker>
<rawString>Saul B. Needleman and Christian D. Wunsch. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48(3):443 – 453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ee-Lee Ng</author>
<author>Beatrice Chin</author>
<author>Alvin W Yeo</author>
<author>Bali Ranaivo-Malanc¸on</author>
</authors>
<title>Identification of CloselyRelated Indigenous Languages: An Orthographic Approach.</title>
<date>2010</date>
<journal>Int. J. of Asian Lang. Proc.,</journal>
<volume>20</volume>
<issue>2</issue>
<pages>62</pages>
<marker>Ng, Chin, Yeo, Ranaivo-Malanc¸on, 2010</marker>
<rawString>Ee-Lee Ng, Beatrice Chin, Alvin W. Yeo, and Bali Ranaivo-Malanc¸on. 2010. Identification of CloselyRelated Indigenous Languages: An Orthographic Approach. Int. J. of Asian Lang. Proc., 20(2):43– 62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory D Schuler</author>
</authors>
<title>Sequence Alignment and Database Searching. Bioinformatics: A Practical Guide to the Analysis of Genes</title>
<date>2002</date>
<publisher>John Wiley &amp; Sons, Inc.,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="8549" citStr="Schuler, 2002" startWordPosition="1302" endWordPosition="1303">f words we employ the Needleman-Wunsch global alignment algorithm (Needleman and Wunsch, 1970), which is mainly used for aligning sequences of proteins or nucleotides. Global sequence alignment aims at determining the best alignment over the entire length of the input sequences. The algorithm uses dynamic programming and, thus, guarantees to find the optimal alignment. Its main idea is that any partial path of the alignment along the optimal path should be the optimal path leading up to that point. Therefore, the optimal path can be determined by incremental extension of the optimal subpaths (Schuler, 2002). For orthographic alignment, we consider words as input sequences and we use a very simple substitution matrix, which 100 gives equal scores to all substitutions, disregarding diacritics (e.g., we ensure that e and e` are matched). 3.2 Feature Extraction Using aligned pairs of words as input, we extract features around mismatches in the alignments. There are three types of mismatches, corresponding to the following operations: insertion, deletion and substitution. For example, for the Romanian word exhaustiv and its Italian cognate pair esaustivo, the alignment is as follows: e x h a u s t i </context>
</contexts>
<marker>Schuler, 2002</marker>
<rawString>Gregory D. Schuler. 2002. Sequence Alignment and Database Searching. Bioinformatics: A Practical Guide to the Analysis of Genes and Proteins, 43. A. D. Baxevanis and B. F. F. Ouellette, John Wiley &amp; Sons, Inc., New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>George F Foster</author>
<author>Pierre Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation.</booktitle>
<contexts>
<context position="1539" citStr="Simard et al., 1992" startWordPosition="220" endWordPosition="223">However, it can be customized to integrate historical information regarding language evolution. 1 Introduction Cognates are words in different languages having the same etymology and a common ancestor. Investigating pairs of cognates is very useful in historical and comparative linguistics, in the study of language relatedness (Ng et al., 2010), phylogenetic inference (Atkinson et al., 2005) and in identifying how and to what extent languages change over time. In other several research areas, such as language acquisition, bilingual word recognition (Dijkstra et al., 2012), corpus linguistics (Simard et al., 1992), cross-lingual information retrieval (Buckley et al., 1997) and machine translation (Kondrak et al., 2003), the condition of common etymology is usually not essential and cognates are regarded as words with high cross-lingual meaning and orthographic or phonetic similarity. The wide range of applications in which cognates prove useful attracted more and more attention on methods for detecting such related pairs of words. This task is most challenging for resource-poor languages, for which etymologically related information is not accessible. Therefore, the research (Inkpen et al., 2005; Mullo</context>
<context position="3298" citStr="Simard et al., 1992" startWordPosition="503" endWordPosition="506">nd analyze alternative methods and related work in this area. In Section 3 we introduce our approach for detection of cognates using orthographic alignment. In Section 4 we describe the experiments we conduct and we report and analyze the results, together with a comparison with previous methods. Finally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method. 2 Related Work There are three important aspects widely investigated in the task of cognate identification: semantic, phonetic and orthographic similarity. They were employed both individually (Simard et al., 1992; Inkpen et al., 2005; Church, 1993) and combined (Kondrak, 2004; Steiner et al., 2011) in order to detect pairs of cognates across languages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105,</context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>Michel Simard, George F. Foster, and Pierre Isabelle. 1992. Using Cognates to Align Sentences in Bilingual Corpora. In Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Temple F Smith</author>
<author>Michael S Waterman</author>
</authors>
<title>Identification of common molecular subsequences.</title>
<date>1981</date>
<journal>Journal of Molecular Biology,</journal>
<volume>147</volume>
<issue>1</issue>
<contexts>
<context position="4663" citStr="Smith and Waterman, 1981" startWordPosition="703" endWordPosition="706">d Klein, 2010); Levenshtein distance (Levenshtein, 1965), XDice (Brew and McKelvie, 1996) and the longest common subsequence ratio (Melamed, 1995) are among the most frequently used metrics in this field. Gomes and Lopes (2011) proposed SpSim, a more complex method for computing the similarity of cognate pairs which tolerates learned transitions between words. Algorithms for string alignment were successfully used for identifying cognates based on both their forms, orthographic and phonetic. Delmestri and Cristianini (2010) used basic sequence alignment algorithms (Needleman and Wunsch, 1970; Smith and Waterman, 1981; Gotoh, 1982) to obtain orthographic alignment scores for cognate candidates. Kondrak (2000) developed the ALINE system, which aligns words’ phonetic transcriptions based on multiple phonetic features and computes similarity scores using dynamic programming. List (2012) proposed a framework for automatic detection of cognate pairs, LexStat, which combines different approaches to sequence comparison and alignment derived from those used in historical linguistics and evolutionary biology. The changes undergone by words when entering from one language into another and the transformation rules th</context>
<context position="19987" citStr="Smith and Waterman, 1981" startWordPosition="3253" endWordPosition="3256">on. The substitution matrix for the alignment algorithm can be customized with language-specific information, in order to reflect the probability of a character to change into another. An important achievement in this direction belongs to Delmestri and Cristianini (2010), who introduced PAM-like matrices, linguistic-inspired substitution matrices which are based on information regarding orthographic changes. We plan to investigate the contribution of using this type of substitution matrices for our method. We intend to investigate other approaches to string alignment, such as local alignment (Smith and Waterman, 1981), and other learning algorithms for discriminating between cognates and non-cognates. We plan to extend our analysis with more language-specific features, where linguistic knowledge is available. First, we intend to use the part of speech as an additional feature. We assume that some orthographic changes are dependent on the part of speech of the words. Secondly, we want to investigate whether accounting for the common ancestor language influences the results. We are interested to find out if the orthographic rules depend on the source language, or if they are rather specific to the target lan</context>
</contexts>
<marker>Smith, Waterman, 1981</marker>
<rawString>Temple F. Smith and Michael S. Waterman. 1981. Identification of common molecular subsequences. Journal of Molecular Biology, 147(1):195–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lydia Steiner</author>
<author>Peter F Stadler</author>
<author>Michael Cysouw</author>
</authors>
<title>A pipeline for computational historical linguistics. Language Dynamics and Change,</title>
<date>2011</date>
<volume>1</volume>
<issue>1</issue>
<pages>127</pages>
<contexts>
<context position="3385" citStr="Steiner et al., 2011" startWordPosition="518" endWordPosition="521">ce our approach for detection of cognates using orthographic alignment. In Section 4 we describe the experiments we conduct and we report and analyze the results, together with a comparison with previous methods. Finally, in Section 5 we draw the conclusions of our study and describe our plans for extending the method. 2 Related Work There are three important aspects widely investigated in the task of cognate identification: semantic, phonetic and orthographic similarity. They were employed both individually (Simard et al., 1992; Inkpen et al., 2005; Church, 1993) and combined (Kondrak, 2004; Steiner et al., 2011) in order to detect pairs of cognates across languages. For determining semantic similarity, external lexical resources, such as WordNet (Fellbaum, 1998), or large corpora, might be necessary. For measuring phonetic and orthographic proximity of cognate candidates, string similarity metrics can be applied, using the phonetic or orthographic word forms as input. Various measures were investi99 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 99–105, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Lingui</context>
</contexts>
<marker>Steiner, Stadler, Cysouw, 2011</marker>
<rawString>Lydia Steiner, Peter F. Stadler, and Michael Cysouw. 2011. A pipeline for computational historical linguistics. Language Dynamics and Change, 1(1):89– 127.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>