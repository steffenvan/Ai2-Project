<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.6767225">
AN EFFICIENT PARSING ALGORITHM FOR TREE ADJOINING
GRAMMARS
</note>
<address confidence="0.410605">
Karin Harbusch
DFKI - Deutsches Forschungszentrum für Kiinstliche Intelligenz
Stuhlsatzenhausweg 3, D-6600 Saarbracken 11, F.R.G.
</address>
<email confidence="0.57475">
harbuschadfki.uni-sb.de
</email>
<sectionHeader confidence="0.90764" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999593461538462">
In the literature, Tree Adjoining Grammars
(TAGs) are propagated to be adequate for nat-
ural language description — analysis as well as
generation. In this paper we concentrate on the
direction of&apos; analysis. Especially important for an
implementation of that task is how efficiently this
can be done, i.e., how readily the word problem
can be solved for TAGs. Up to now, a parser with
0(n6) steps in the worst case was known where 71.
is the length of the input string. In this paper, the
result is improved to 0(0 log n) as a new lowest
upper bound. The paper demonstrates how local
interpretion of TAG trees allows this reduction.
</bodyText>
<sectionHeader confidence="0.999395" genericHeader="keywords">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999512902439025">
Compared with the formalism of context-free
grammars (CFGs), the rules of Tree Adjoining
Grammars (TAGs) can be imagined intuitively
as parts of context-free derivation trees. Without
paying attention to the fact that there are some
more restrictions for these rules, the recursion op-
eration (adjoining) is represented as replacing a
node in a TAG rule by another TAG rule so that
larger derivation trees are built.
This close relation between CFGs and TAGs
can iinply that they are equivalent. But TAGs
are more powerful than context-free grammars.
This additional power — characterized as mildly
context-sensitive — leads to the question of
whether there are efficient algorithms to solve the
word problem for TAGs.
Up to now, the algorithm of Vijay-Shanker and
Joshi with a time complexity of 0(n6) for the
worst case was known, in addition to several un-
successful attempts to improve this result. This
paper&apos;s main emphasis is on the improvement of
this result. An efficient parser for Tree Adjoining
Grammars with a worst case time complexity of
0(n4 log n) is discussed.
Al! known parsing algorithms for TAGs use
the close structural similarity between TAGs and
CFGs, which can be expressed by writing all inner
nodes and all their sons in a TAG as the rule set
of a context-free grammar (the context-free ker-
nel of a TAG). Additionally, the constraint has to
be tested that all further context-free rules corre-
sponding to the same TAG tree must appear in
the derivation tree, if one rule of that TAG tree
is in use. Therefore, it is clear that a context-free
parser can be the basis for extensions representing
the test of the additional constraint.
On the basis of the two fundamental context-
free analysers, the different approaches for TAGs
can be divided into two classes. One class extends
an Earley parser and the second class extends a
Cocke-Kasami-Younger (CKY) parser for CFGs.
Here, we focus on the approaches with a CKY
basis, because the relation between the resulting
triangle mairtz and the encoded derivation trees
is closer than for the ;tem lists of an Earley parser.
In particular, the paper is divided into the fol-
lowing sections. First, a short overview of the
TAG formalism is given in order to have a com-
mon terminological basis with the reader.
In the second section, the approach of Vway-
Shanker and Joshi is presented as the natural way
of extending the CKY algorithm for context-free
grammars to TAGs. As a precondition for that
analysis, it has to be proven that each TAG can
be transformed into two form, a normal form re-
stricting the outdegree of a node to be less three.
In section 4, the main section of this paper,
a normal form is defined as a precondition for a
new and more efficient parsing algorithm. This
form is more restricted than the two form, and is
closely related to the Chomsky normal form for
CFGs. The main emphasis lies on the description
of the new parsing approach. The general idea is
to separate the context-free parsing and the addi-
tional testing so that the test can run locally. On
the triangle matrix which is the result of the CKY
analysis with the context-free kernel, all complete
TAG trees encoded in the triangle matrix are
computed recursively. It is intuitively motivated
that this approach needs fewer steps than the
strategy of Vijay-Shanker and Joshi, which stores
all intermediate states of TAG derivations, be-
cause the locally represented elementary trees can
be interpreted as TAG derivations where equal
parts are computed exactly once instead of indi-
vidual representations in each derivation.
In the summary, our experience with an imple-
mentation in CommonLISP on a Hewlett Packard
machine is mentioned to illustrate the response
time in an average case. Finally, different ap-
proaches for TAG parsing are characterized and
compared with the approaches presented here.
</bodyText>
<sectionHeader confidence="0.996784" genericHeader="introduction">
2 TAGS BRIEFLY REVISITED
</sectionHeader>
<bodyText confidence="0.983546875">
First of all, the basic definitions for TAGs are re-
visited in order to have a common terminology
with the reader (even though not defined explic-
itly here, CFGs are used as described, e.g., in
[Hoperoft, Ullman 79D.
In 1975, the formalism of Tree Adjoining Gram-
mars (TAGs) was introduced by Aravind K.
Joshi, Leon S. Levy and Masako Takahashi ([Joshi
</bodyText>
<page confidence="0.995633">
284
</page>
<bodyText confidence="0.999106402985075">
et al. 75]). Since then, a wide variety of prop-
erties — formal properties as well as linguisti-
cally relevant ones — have been studied (see, e.g.,
Poshi 85} for a good overview).
The following example describing the crossed
dependencies in Dutch should illustrate the for-
malism (see Figure 1, where the node numbers
written in slanted font should be ignored here;
they make sense in combination with the descrip-
tion of the new algorithm, especially step (tag2)).
A TAG is a tree generation system. It consists,
in addition to the set of nonterminais N, the set
of terminals T and the start symbol S, an extraor-
dinary symbol in N, of two different sets of trees,
which specify the rules of a TAG. Intuitively, the
set I of initial trees can be seen as context-free
derivation trees. This means the start symbol
is the root node, all inner nodes are nontermi-
nals and all leaves are terminals (e.g., in Figure
1 tree a). The second set A, the auxiliary trees,
which can replace a node in an initial tree (which
is possibly modified by further adjoinings) dur-
ing the recursion process, must have a form, so
that again a derivation tree results. The trees /31
and /32 demonstrate that restriction. A special
leaf (the foot node) must exist, labelled with the
same nonterminal as the root node. Further, it is
obligatory that an auxiliary tree derives at least
one terminal. The union of the initial and the
auxiliary trees, so to speak the rule set of a TAG,
is called the set of elementary trees.
Tree -y in Figure 1 shows a TAG derivation
tree, which means an initial tree with an arbi-
trary number of adjoinings (here is adjoined
at the node S1 in a and /32 at the node S in the
adjoined tree fit). During the recursion process
(adjoining), a node X in an initial tree a, which
can be modified by further adjoinings, is replaced
by an auxiliary tree with the same nontermi-
nal label at root and foot node, that X is labelled
with. The incoming edge in X (if it exists; this is
true if X is not the root node of a) now ends in
the root node of /3, and all outgoing edges of X in
a now start at the foot node of 13.
The set of all initial trees modified by an arbi-
trary number of adjoinings (at least zero) is called
T(G), the tree set of a TAG G. The elements in
this set can also be specified by building a series
of triples (af, f3,, )i) (0 &lt; i &lt; n) — the deriva-
tion — where ao E 1, ai (1 &lt; i &lt; n) is the result
of the adjoining of /3i_i in node X1...1 in ai_1&apos; A
(0 &lt; i &lt; n-1) is the auxiliary tree, which is ad-
joined in node Xi in tree a, and Xi (0 &lt; i &lt; n-1)
is a unique node number in ai. This description
has the advantage that structurally equal trees in
T(G) which result from different adjoinings can
be uniquely represented.
L(G), the language of a TAG, is defined as the
set containing all leaf strings of trees in T(G)&apos;
respectively all trees which can be constructed
by adjoining as described in the corresponding
derivation. Here, a leaf string means all labels of
leaves in a tree are concatenated in order from
left to right. In the tree 7 in Figure 1 Van Piet
Marie c c zag laten zwemmen&apos; is in L(G).
The relation between TAGs and CFGs can be
characterized by defining the context-free kernel
</bodyText>
<figure confidence="0.96685775">
a: Soo 01. S to /32 Sao
/\ /\ /&apos;\
12
/TR?... Vro2 ;*s Vri2 N7121V
1
711 ve mom- 1411:;// Xlittan
1012 man 211 522 1222
N S V2 Jan
Vrorzr no
Nial&amp;quot; 11111 1121 1 1122
c
Marla c Piet
</figure>
<figureCaption confidence="0.9965675">
Figure 1: A small sample TAG demonstrating the
process of ADJOINING
</figureCaption>
<bodyText confidence="0.999667607142857">
K of a TAG G. K is a CFG and consists of the
same sets N, T and S of G, but P(K) is the set
of all inner nodes of all elementary trees in G
interpreted as the lefthand side of a rule, where
all sons in their order from left to right build the
righthand side of that rule. E.g., in Figure I /32
has the corresponding context-free rules: (S, NP
VP), (NP, N), (N, Jan), (VP, S V1), (V1, zag)•
It is clear that having a context-free derivation
tree (on the basis of the context-free kernel K of
a TAG G) is a necessary, but not sufficient prop-
erty for an input string, which is tested to be an
element in L(G). In the following, this property
motivates the extension of context-free parsing al-
gorithms to accept TAGs a.s well.
The following parsing algorithms are able to ac-
cept some extensions of the pure TAG definition
without changing the upper time bound. Here,
only TA Gs with Constraints are mentioned (for
more information about other extensions, e.g.,
TAGs with Links, with Unification or Multi Com-
ponent TAGs — some extending the generative
capacity — see, e.g., [Joshi 85]).
The motivation for TAGs with Constraints
(TA G Cs) is to restrict the recursion operation of
TAGs. Each node X in an elementary tree la-
belled with a nonterminal has an associated con-
straint set C, which has one of the following forms:
</bodyText>
<listItem confidence="0.99871425">
• NA stands for null adjoining and means that
at node X no adjoining can take place,
• SA(B) stands for selective adjoining and
means that at X the adjoining of an auxii-
</listItem>
<figure confidence="0.90425475">
7&apos;
vro2
ZWOM-
men
</figure>
<page confidence="0.996353">
285
</page>
<bodyText confidence="0.953758843137255">
iary tree (€ B) can take place (where each
tree in B has the same root and foot node
label as X) or
• 0A(B) stands for obligatory adjogntng and
means that at X the adjoining of an auxiliary
tree (E B) must take place (where each tree
in B has the same root and foot node label
as X).
When TAGs are mentioned in the following, the
same result can be shown for TAGs with Con-
straints, which it is not explicitly outlined. Only
the property of generative power is illustrated, to
make clear that finding a parsing algorithm is not
a trivial task. For more information about the lin-
guistic relevance of TAGs, the reader is referred,
e.g., to [Kroch, Joshi 851.
A first impression comparing the generative
power of TAGs and CFGs can be that they are
equivalent, but TAGs are more powerful, e.g., the
famous language an bn e en can be produced by
a TAG with Constraints (the main idea in con-
structing this grammar is to represent the produc-
tion of an a, a b and a c in one auxiliary tree).
Thinking of the application domain of natural
language processing, the discussion in the linguis-
tic community becomes relevant as to how pow-
erfu] a linguistic formalism should be (see, e.g.,
[Pullum 841 or [Shieber 85]). TAGs are mildly
context-sensitive, which means that they can de-
scribe some context-sensitive languages, but not
all (e.g., www with w E {O}, but ww is accept-
able for a TAG). One thesis holds that natural
language can be described very well by a mildly
context-sensitive formalism. But this can only be
empirically confirmed by describing difficult lin-
guistic phenomena (here, the example in Figure
1 can only give an idea of the appropriateness of
TAGs for natural language description).
This property leads to the question of whether
the word problem is solvable and if so, how ef-
ficiently. In the following section, two differ-
ent polynomial approaches are presented in de-
tail. The property of efficiency becomes impor-
tant when a TAG should be used in the applica-
tion domain mentioned above, e.g., one can think
of a syntax description encoded in TAG rules
which is part of a natural language dialogue sys-
tem. The execution time is responsible for the
acceptance of the whole system. Later on, our
experience with the response time of an imple-
mentation of the new algorithm is described.
</bodyText>
<sectionHeader confidence="0.99705" genericHeader="method">
3 THE VIJAY-SHANKER AND
JOSHI APPROACH
</sectionHeader>
<bodyText confidence="0.999970363636363">
First, the approach of Vijay-Shanker and Joshi
(see [Vijay-Shanker, Joshi 85]) is discussed as the
natural way of extending the context-free CKY
algorithm (see, e.g., [Hoperoft, Ullman 79]) to an-
alyze TAGs as well. As for the context-free anal-
ysis with CKY, the grammar is required in nor-
mal form a-s a precondition for the TAG parser.
Therefore, first the two form is defined and the
idea of the constructive proof for transforming a
TAG into two form is given. The TAG parser is
then presented in more detail.
</bodyText>
<sectionHeader confidence="0.7581735" genericHeader="method">
3.1 TWO FORM TRANSFOR-
MATION
</sectionHeader>
<bodyText confidence="0.999990708333333">
The parsing algorithm of Vijay-Shanker and Josh!
uses a special CKY algorithm for CFGs which
requires fewer restrictive constraints than the
Chomsky normal form for the ordinary CKY al-
gorithm does. Here, the righthand side of all rules
of the grammar should have at most two elements.
This definition has to he adapted for TAG rules
to extend this CKY parser to analyze TAGs as
well.
A TAG G is in two form, if each node in each
elementary tree has at most two sons. It can be
proven that each TAG G can be transformed into
a TAG G&apos; in two form with L(G) = L(G&apos;).
The proof of that theorem uses the same tech-
niques as in the context-free case which allow the
reduction of the number of elements on the right-
hand side to build the Chomsky normal form. If
there are more than two sons, the second and all
additional sons are replaced by a new nontermi-
nal which becomes the lefthand side of a new rule
with all replaced symbols on the righthand side
(for more details see [Vijay-Shanker, Joshi 85]).
We always refer to a TAG in two form, even when
it is not explicitly confirmed.
</bodyText>
<sectionHeader confidence="0.706475" genericHeader="method">
3.2 THE STEPS OF THE ALGO-
RITHM
</sectionHeader>
<bodyText confidence="0.999830324324325">
Now the idea of extending each context-free anal-
ysis step by additional tests to ensure that whole
TAG trees are in use (sufficient property) is moti-
vated. This approach was proposed to be natural
because it tries to build TAG derivation trees at
once. In contrast, a two level approach is pre-
sented which constructs all context-free deriva-
tion trees before the TAG derivations are com-
puted in a second step.
In the CKY analysis used here, a cell [row
i,column in the triangle matrix (1 &lt;i, j &lt;
n, the length of the input string w = t1 ...t„,
where without loss of generality n &gt; 1, because
the test for c, the empty string, E L(G) sim-
ply consists of searching for initial trees with all
leaves labelled with c) contains an element X (E
N) if there are rules to produce the derivation for
ti+1...t1_1. This invariant is extended to repre-
sent a TAG derivation for ti+1...tj_i iff X E [i,j].
Therefore additional information of each nonter-
minal in a cell has to be stored as to which el-
ementary trees are under completion and what
subtrees have been analyzed up to now. Impor-
tant to note is that the list of trees which are
under completion, can be longer than one. E.g.,
think of adjoinings which have taken place in ad-
joined trees as described in Figure 1.
For realization of that information, a stack can
he imagined. Here, the different stack elements
are stored separately to use intermediate states
in common. A stack element contains the infor-
mation of exactly one auxiliary tree which is un-
der construction, and a pointer to the next stack
element. This pointer is realized by two addi-
tional positions for each cell in the triangle matrix
([i,j ,k ,ID, where k and I in the third and fourth
position characterize the fact that from tk+i to
</bodyText>
<page confidence="0.9923425">
286
287
</page>
<bodyText confidence="0.999469489795919">
t/_1 no information about the structure of the
TAG derivation is known in this element and has
to be reconstructed by examination of all cells
[k,l,v,w] (k &lt; v &lt; to &lt; 1). The stack cells which
the elements point at must also be recursively in-
terpreted until the whole subtree is examined (left
and right stack pointer are equal). It is clear that
in interpreting these chains of pointers the stack
at each node X in the triangle matrix represents
all intermediate states of TAG derivations with X
as root node in an individual cell of the triangle
matrix.
The algorithm starts initializing cells for all ter-
minal leaves (X E for ti with father X,
1 &lt; i &lt; n) and all foot nodes which can be seen
as nonterminal leaves (X E [i, j, i,jJ where X is a
foot node in an auxiliary tree, 0 &lt; I &lt; j &lt; n-1).
Just as the CKY algorithm tests all combina-
tions of neighboring strings, here new elements of
cells are computed together with the context-free
invariant computation, e.g., if (Z,X Y) is a rule
in the context-free kernel of the input TAG and
X [i, j, k, 1],Y E[j-1,m, pi p] and X and IT are
root nodes of neighboring parts in the same ele-
mentary tree, then Z is added to [i, m, k,1]). With
the additional test to determine whether the rule
(in the example (Z,X Y)) is in the same TAG tree
as the two sons (X and Y) and whether the same
holds for the subtrees below X and Y, it is clear
that a whole TAG tree can be detected. If this
is the case, i.e., that two neighboring stack ele-
ments should be combined, all elements of cells
[k,l,m,p] are added to [i, j, m, p] iff X E
is the root of an identified auxiliary tree.
The time complexity becomes obvious when
the range of the loops for all four dimensions
of the array is described explicitly (see [Vijay-
Shanker, Joshi 85]). From a more abstract point
of view, the main difference between the CKY
analysis for a CFG and a TAG is that, the sub-
trees below the foot nodes are stored. This fact
extends the input of length n to n2 to describe the
two additional dimensions. On the basis of that
input, the ordinary CKY analysis can be done,
and so the expected time complexity is 0((n2)3)
= 0(n6). With the explicitly defined ranges of
the four dimensions for the positions in the array,
it is clear that the worst case and the best case
for this algorithm are equal.
</bodyText>
<sectionHeader confidence="0.9996965" genericHeader="method">
4 A NEW AND MORE EFFI-
CIENT APPROACH
</sectionHeader>
<bodyText confidence="0.9999276">
A time bound of 0(n6) in the best and worst
case must be seen as a more theoretical result, be-
cause an implementation of the algorithm shows
that the execution time is unacceptable. In order
to use the formalism for any application domain,
this result should be improved. In this section, a
TAG parser with an upper bound of 0(724 log n)
in the worst case is presented. The best case is
0(n3), because a CKY analysis has to at least be
done.
</bodyText>
<sectionHeader confidence="0.9835395" genericHeader="method">
4.1 NORMAL FORM TRANS-
FORMATION
</sectionHeader>
<bodyText confidence="0.999926333333333">
As precondition of the new parsing algorithm, the
TAG has to be transformed into a normal form
which contains only trees with nodes and their
sons, following the Chornsky normal form defini-
tion. This means that the following three condi-
tions hold for a TAG G:
</bodyText>
<listItem confidence="0.994003083333333">
1. e E L(G) if a tree with root node S (NA),
the start symbol, which allows no further ad-
joinings (null adjoining), and a single termi-
nal son c is element in the set of initial trees
I (this tree is called the c tree),
2. except the c tree, no leaf in another elemen-
tary tree is labelled with c, and
3. for each node in each elementary tree, the
condition holds that either the node has two
sans both labelled with a nonterminal or that
the node has one son labelled with a termi-
nal.
</listItem>
<bodyText confidence="0.999947137931035">
In a first step, each TAG is transformed in two
form so that condition 3 can be satisfied easier.
This transformation is accomplished by the con-
structive proof for the theorem that for each TAG
(or TAG with Constraints for which the definition
holds as well) there exists an equivalent TAG with
Constraints in normal.
Important to note is that the idea of the trans-
formation into Chomsky normal form for CFCs
cannot be adopted further on because this con-
struction allows the erasure of nonterminal sym-
bols if their derived structure is added to the
grammar. In TAGs, a nonterminal not only rep-
resents the derivation of its subtree in an elemen-
tary tree, but can be replaced by an adjoining.
Therefore, the general idea of the proof is to erase
parts of elementary trees which are not in normal
form, and represent those parts as new auxiliary
trees. After this step, the original grammar is in
normal form and therefore the encoded auxiliary
trees can be used for explicit adjoinings, always
producing structures in normal form. &amp;pilot
adjoinings mean adjoinings in the new auxiliary
trees which were bunt out of the erased parts of
the original grammar. These adjoinings replace
the nodes which are not in normal form. Since
the details of the different steps are of no further
interest here, the reader is referred to [Harbusch
89] for the complete proof.
</bodyText>
<sectionHeader confidence="0.9703175" genericHeader="method">
4.2 THE STEPS OF THE NEW
PARSING ALGORITHM
</sectionHeader>
<bodyText confidence="0.987225703703704">
The input of the new parser consists of a TAG G
in normal form, and a string w = t1 ...tn. With
condition one in the normal form definition, the
test for c E L(G) is trivial again. From now on
this case is ignored, i.e., n 1.
The algorithm is divided into two steps. First
a CKY analysis is done with the context-free ker-
nel K of the input TAG G. Here, the standard
CKY algorithm as described in [Hop croft, Ullman
79] is taken, which requires a CFG in Chomsky
normal form. K satisfies the requirement that
the TAG G is in normal form. One can think
that it would be sufficient to simply transform the
context-free kernel into Chornsky normal form in-
stead of transforming the input TAG. But with
this strategy one would loose the one-to-one map-
ping of context-free rules in the CFK and father-
son-relations in a TAG rule which becomes impor-
tant for finding complete TAG rules in the second
step of the new parser.
Here the invariant of the CKY analysis is X
E [i, j] if there are rules to produce a derivation
for t, This information is slightly ex-
tended to recognize complete subtrees of elemen-
tary trees in the triangle matrix. In the terminol-
ogy of Vticiy-Shanker and Joshi, a stack element is
constructed. But it&apos;s important to note that the
pointers are not interpreted, so that here local in-
formation is computed relative to an elementary
tree,
Actually, the correspondence between an ele-
ment in the triangle matrix and a TAG tree is
represented as a pointer from the node in a tri-
angle cell to a node in an elementary tree as de-
scribed in Figure 2 (ignore the dotted lines at the
moment). An equivalent description is presented
in Figure 3 by storing the unique node number at
which the pointer ends in the elementary tree and
additionally a flag indicating whether the TAG
tree is initial (I) or auxiliary (A) and whether the
node is root node (T) of the tree or not (L). E.g.,
in Figure 2 the NP-son of the root node S in tree
7 carries the flag TA.
In this terminology, the special case that the
subtree contains the foot node has to be repre-
sented explicitly, because the foot node is a leaf
in the sense of elementary trees, but not in the
sense of a derivation tree. To know where this
leaf is positioned in the triangle matrix, a foot
node pointer (FP) is defined from the root of the
subtree to the foot node if one exists in that tree
(in Figure 2 the dashed arc).
initial tree a: auxiliary tree fl: -di. whereP is adjoined in a:
. . ..--. • ....--. ..-.. • --a. . —.. . &apos; .-=- .,s- . i
</bodyText>
<figure confidence="0.883303833333333">
,■-•&apos;....■..
Nt&apos; —1, VP —I) DETH NP VP
11/ DET -.k
--....\,. DET
DITirrIJ
N
</figure>
<figureCaption confidence="0.8694195">
Figure 2: Example illustrating the inductive basis
of the new invariant
</figureCaption>
<bodyText confidence="0.9995835">
So, the invariant in the first step of the new
parsing algorithm is computed during the CKY
analysis — in our second terminology — by re-
cursively defining extended node numbers (ENNs)
by triples (NN,TK,FP) as follows:
Initialization
Each element X in level 1 (father of a terminal
t) is initialized with an ENN, where NN is the
node number of X in a father-son-relation in an
elementary tree a (X --v t), the free kind TK :=
LU (U=I,A) if a E U and NN doesn&apos;t end with
zero (X is not the root of a) else TK := TU, and
the foot node pointer PP := nil, because the fa-
ther of a terminal is never a foot node in the same
auxiliary tree.
For each node X in level 1 the ENN (NN=node
number of a foot node in an auxiliary tree, LA,
pointer to that ENN) is added if X is the label
of the foot node with node number NN — to de-
scribe foot node leaves.
</bodyText>
<sectionHeader confidence="0.570211" genericHeader="method">
P
</sectionHeader>
<subsectionHeader confidence="0.779478">
Recursion along the CKY analysis
</subsectionHeader>
<bodyText confidence="0.999909120689655">
For each new context-free element Z (Z —4 X Y),
the following tests are done in addition:
If X has an ENN (NN1,T1(1,FP1) and Y has
an ENN (NN2,TK2,FP2) and NN1-(1 in the last
positition) = NN2-(2 in the last position) and
TKI TK2 and at least FPI or FP2 = nil then for
Z an ENN (NN1-1,TK,FP) is added where TK =
TKi if Z is not the root node of the whole tree (in
this case TK = TK1-(L+T in the first position));
FP = FP i (i=1,2), which is not equal nil, else it
is nil.
If an auxiliary tree with Z the label of the
foot node exists, the ENN (NI1=-node number of
the foot node in that tree, LA, pointer to that
element) is added to Z in the currently manipu-
lated triangle cell — to represent the possibility
of an adjoining in that node.
It is obvious that this invariant consisting of
the nonterminaI in a cell of the triangle matrix to
represent the context-free invariant, the pointers
to elementary trees, and the foot node pointers
to represent which part of an elementary tree is
analyzed computes less information than an array
cell in the approach of Vijay-Shanker and Joshi
does, where whole subtrees of the derivation tree
are stored not stopping at a foot node as we do.
Also, it is clear that this invariant can be com-
puted recursively during the ordinary CKY steps
within the upper time bound of 0(n3). The num-
ber of pointers to elementary trees at each node
can be restricted by the number of occurences of a
nonterminal as the left-hand side symbol of a rule
in the context-free kernel (which is a constant).
The number of foot node pointers is restricted by
the outdegree of each cell in the triangle matrix
(&lt; n), because only for such an edge can an FP
be recursively defined.
In the second step, whole TAG derivations are
computed by combining the subtrees of elemen-
tary trees (represented by the invariant after step
1), according to the adjoining definition inter-
preted inversely. Inversely means that the equiva-
lence in the adjoining definition is not interpreted
in the direction that a node is replaced by a tree,
but in the opposite direction, where trees have to
be detected and are eliminated.
Since all TAG derivation trees of a string w
and a TAG G are encoded in the triangle matrix
(necessary condition w E CFK(G)) and have to
be found in the triangle matrix, the derivation
definition has to be modified as well to support
the &apos;inverse&apos; adjoining definition. It means that
a string w E L(G) if there exists a tree, where
recursively all complete auxiliary trees can be de-
tected and replaced by the label of the root node
of the auxiliary tree until this process terminates
in an initial tree.
The second step formulates the algorithm for
</bodyText>
<page confidence="0.552439">
2 88
</page>
<bodyText confidence="0.992357565789474">
exactly this definition. An auxiliary tree in the
derivation tree which contains no further adjoin-
ings is called an innermost free. As long as the
termination condition isn&apos;t satisfied, at least one
innermost tree must exist in the derivation tree.
Returning to the invariant in the first step, in-
nermost trees are characterized as a pointers to
the root node of an auxiliary tree or in the rep-
resentation of ENNs as the node number of the
root node (in our numbering algorithm visible by
the end number zero) and the tree kind flag TA
(total auxiliary).
These trees are dirriinated by identifying the
root and the foot nodes of innermost trees, so to
speak, as interpretation of the foot node point-
ers as e edges. This can be represented sim-
ply as propagation of the pointers from the foot
node to the root node. This information is suffi-
cient because the strategy of the algorithm checks
whether an incoming edge in a node and the in-
formation of an outgoing edge (without loss of
generality represented at the start node of the
edge) belong to the same elementary tree. Note
that this bottom-up interpretation of the deriva-
tion trees (propagation) realizes that the finding
of larger subtrees is computed only once (the
father-son relation is only interpreted in the up-
ward direction). In Figure 2 the dotted line from
the NP node in 7 describes the elimination of 0
by propagation of the information from the foot
node to the root node.
Since it doesn&apos;t matter in the algorithm what
history an information in a node has (especially
how much and exactly what trees are eliminated)
all possibilities of producing new extended node
numbers — representing the new invariant — are
simply called elimination. The information in a
node represents what further parts of the same
elementary tree are expected to be found in the
triangle matrix above that node. A subclassifica-
tion differentiates what kinds of incoming edges
should be compared to find these parts. One class
describes whether such a further piece is detected
— by interpreting incoming and outgoing edges
of the same node (simple elimination). E.g., this
is the ease in the inductive basis of the invariant
definition. The second class realizes the elimina-
tion of a detected innermost tree, where its foot
node pointer ends in that node. Then the neigh-
borhood of the incoming edges in the root node of
the innermost tree and the outgoing edges in the
foot node (the currently examined node where the
invariant contains the information of the outgoing
edges from this node) has to be tested (complex
ehmination). By this classification, each neigh-
borhood — the explicitly represented ones in the
triangle matrix as well as the neighborhoods via
c respectively foot node pointer edges — is exam-
ined exactly once during the algorithm.
The fact that a derivation tree again results
after an elimination which is encoded in the tri-
angle matrix as well, becomes clear by looking
at the invariant after an elimination. In the first
step the invariant describes complete subtrees of
elementary trees. If a complete innermost tree is
eliminated by propagating the complete subtrees
of elementary trees derived by the foot node to
the root node, this represents the fact that the
root node can derive both trees, but the subtrees
below the foot node have to be completed. This
can be done again by elimination (in Figure 2 the
dotted line from node S represents the computa-
tion of a TAG tree after an elimination).
Since this is not the place to present the algo-
rithm in detail, it is described in informal terms:
(tagl) Treatment of the Empty String
</bodyText>
<sectionHeader confidence="0.35508" genericHeader="method">
ACCEPT := false;
</sectionHeader>
<construct confidence="0.575940333333333">
if w = e then if 4- tree El
then ACCEPT := true; fl;
goto (tag7); fi;
</construct>
<bodyText confidence="0.6813398">
From now on, G is interpreted without the c
tree.
(tag2) Definition of Unique Node Numbers
V nodes X in a G (I U A) a unique node
number NN is defined recursively as follows:
</bodyText>
<listItem confidence="0.945109454545455">
• a has a unique number k all over the
grammar (starting with zero),
• if X is root node NN := kO, for X the
left or only son of the root NN := kl, for
X the right son of the root (if existing)
NN := k2, and
• for the left or only son of a node with
node number kx (a E {LW) NN :=
kxl, for the right son of kx NN := kx2.
(tag3) Computation of the Context-Free
Kernel for The TAG (CFK)
</listItem>
<bodyText confidence="0.99825075">
Each inner node of an elementary tree in G
and its sons are interpreted as a context-free
rule where the node number and the con-
straints are represented as well.
</bodyText>
<listItem confidence="0.4185225">
(tag4) Cocke-Kasami-Younger- Analysis
with CFK and w
</listItem>
<bodyText confidence="0.965678461538461">
The slightly extended CKY algorithm is ap-
plied to w and CFK. The result is a triangle
matrix if the following holds:
if w L(CFK) then goto (tag7)
else goto (tag5); fi;
(tag5) Computation of the Initial State
All possible extended node numbers are com-
puted, which means that all auxiliary trees,
or respectively all subtrees of elementary
trees, are computed on the triangle matrix
and gathered in SAT, the set of active
trees.
(tag6) Iteration on the Elimination and the
</bodyText>
<subsectionHeader confidence="0.592153">
Initial State
</subsectionHeader>
<bodyText confidence="0.902341416666667">
NEWSAT1 and NEWSAT2 are empty sets
and COUNT := 1.
(it0) if an extended node number with tree
kind TK = TI E [1,n] then ACCEPT
:= true and COUNT := n; fl;
(itl) if COUNT = n then goto (tag7); fi;
(it2) V nodes k with extended node num-
ber ENN E SAT and tree kind of ENN
= TA : propagate the extended node
number of the node which the foot node
pointer points at to the root node and
add this information to NEWSAT1;
</bodyText>
<page confidence="0.995315">
289
</page>
<bodyText confidence="0.9860865">
(it 3) V nodes k E NEWSAT1 : do all sim-
ple and complex eluninations and add
the new extended node numbers to
NEWSAT2;
</bodyText>
<equation confidence="0.673144666666667">
(it4) SAT := NEWSAT2; NEWSAT1 and
NEWSAT2 := 0, COUNT :=
COUNT+1 and goto OW.
</equation>
<bodyText confidence="0.849699461538461">
(tag7) Output of the Result
If ACCEPT = true then w G L(G)
else w ji L(G); fi.
Figure 3 illustrates the recursion step (tag6) for
a single, but arbitrary innermost tree represent-
ing an auxiliary tree with the root node number
nurni.
lor ail auxiliary trees in SAT: all extended node numbers (12)
(num! ,TA,FP,) In the node FR1 points at
and OF
( , F P2) (nurn2,LA or TI or LW)
nuX
propagate these extended node numbers to the root node:
</bodyText>
<equation confidence="0.82989">
(num2,LA,F 2) (hurA2,LA or TI or L 1,0)
espectively
</equation>
<bodyText confidence="0.976643285714286">
New extended node numbers and all trees with tree kind LA at the root are
added to NEWSATt.
here exists a context-Iree IWO here exists an eliminated tree
(num4, num, num„) and below num, with a loot node pointer
the subtree is completely analyzed, (dashed tine) to the bcal root
this means num,. nurn2-1. num3-2 node (nurn2,LA,F P2)
in this case nurr14 not equal root).
</bodyText>
<note confidence="0.9149635">
(i14): Results are added to SAT, an other sets are redefined with&apos;.
START —ft- End al recursion (t0) after at most n-1 lineations (111)
</note>
<figureCaption confidence="0.999843">
Figure 3: Illustration of the step of recursion
</figureCaption>
<bodyText confidence="0.999975229885058">
Here, the question of correctness is not dis-
cussed in more detail (see [Harbusch 89]). It
should be intuitively clear with the correspon-
dence between the derivation definition and it&apos;s
interpretation in the recursion step.
Actually, the main emphasis lies on the ex-
planation of the time complexity (for the formal
proof see [Harbusch 89]). A good intuition can
be won by concentrating for a first glance on a
single, but arbitrary TAG derivation tree 6 for w
= ti...tr, in the triangle matrix after step one. It
is clear that 6 contains at most n-1 adjoinings,
because each TAG tree must produce at least one
terminal. Therefore the recursion, which finds in-
dependent (unnested) adjoinings simultaneously
(after elimination of nested adjoinings identified
in the last recursion step), terminates definitively
after n-1 loops.
At the beginning, at most 0(n2) innermost
trees can exist in the triangle matrix. Each ter-
minal can be a leaf in a constant number of ele-
mentary trees and with an indegree of 0(n-1) in
row 1 of the triangle matrix, the number of oc-
curences of elementary trees containing the input
symbol ti (1 &lt; i &lt; n) encoded in the invariant
after step one is restricted.
Since an elimination is defined along the path
between root and foot node of an auxiliary tree,
which has at least length 1 (i.e., root and foot
node are father and son), the foot node informa-
tion is always propagated to a higher row in the
triangle matrix. The triangle matrix has depth
n so that the information of a node in 6 — our
explicitly chosen derivation tree — can only be
passed to 0(n-1) nodes because each node has
indegree 1 in a derivation tree. The passing of
information (propagation) stands for the elimi-
nation of 0(n-1) innermost trees along the path
to the root node. So, the invariant of that node
(a constant number of ENNs) can be propagated
to 0(n) nodes. As a result, the number of in-
variants at a node increases to 0(n). This must
be done for all nodes (0(n2)) so that the overall
number of steps to find a special, but arbitrary
TAG derivation tree is 0(0).
These suggestions can be used as a basis for
finding all derivation trees in parallel instead of a
single, but arbitrary one, because all intermedi-
ate states in the triangle matrix are shared. The
only difference is that the indegree of a node can-
not be restricted to 1, but to 0(n) so that the
exponent 3 increases to 4. The extension &amp;quot;log n&amp;quot;
results from storing the foot node pointers, where
addresses have to be represented instead of num-
bers of other cells as in the Vvay-Shanker-Joshi
approach.
In other words, an intuition for an upper time
bound of the algorithm is that the recursion step
can be seen as a CKY analysis, because particu-
larly neighboring subtrees are combined to build
a larger structure, where the constant number of
nonterminals in a cell has to he replaced by 0(n)
candidates (0(n3) x
Another intuition gives a comparison with the
Vijay-Shanker and Joshi approach. It is obvious
that our new approach has a different time bound
for the best and the worst case, because all possi-
bilities violating the necessary condition to have a
context-free derivation are filtered out before step
two is started. In the Vi jay-Shanker ancl Joshi ap-
proach for all context-free subtrees of the triangle
matrix, the invariant is computed. But this fact
doesn&apos;t modify the upper time hound. The main
difference lies in the execution time for the two
different invariants. In the Vijay-Shaither-Joshi
approach, all different TAG derivations for a. sub-
tree are gathered in the stack of a node in a cell.
For all these possibilities, the building process of
larger structures is done separately, although the
differences in the derivation tree doesn&apos;t concern
the auxiliary tree actually mentioned. Our local
invariant always handles an auxiliary tree with no
further information about the derivation. There-
fore each elimination of an auxiliary tree is done
once only for all derivation trees. From this point
of view, the different exponent results from the
existence of 0(n2) stack pointers at each node in
</bodyText>
<equation confidence="0.655249">
case a) a sorpki earrinarion (113) for case b) a complex Wit:Ikea/A far
(num2,LA,F P2) is descrbed: (nurn2,LA,F R2) is descrbed:
(num ,LA,FP2) (nurn2,LA,FP2)
ralm2
</equation>
<page confidence="0.987374">
290
</page>
<bodyText confidence="0.999767125">
the triangle matrix.
For both approaches, the integration of TAGs
with Constraints is mentioned in common. For
the new approach, this extension is obligatory be-
cause the normal form transformation produces
a TAGC. Anyway, this additional computation
doesn&apos;t change the upper time bound, because
constraints are local and their satisfaction has
only to be tested if an innermost tree should
be eliminated ( i.e., a stack pointer has to be
extended). In this case it had to be checked
whether all obligatory constraints in the elimi-
nated tree are satisfied and whether the adjoining
was allowed (by analyzing to which tree the rule
of the incoming edge in the root node belongs and
what constraint the end point of that edge has).
</bodyText>
<sectionHeader confidence="0.999657" genericHeader="conclusions">
5 SUMMARY
</sectionHeader>
<bodyText confidence="0.999566333333334">
In the application domain of natural language
processing, the execution time in an average case
is of great interest as well. For the new parsing
algorithm, a result is not yet known, but in basic
considerations the main idea is to take the depth
of analyzed parts of derivation trees as a constant
term to come up with a result of 0(n3).
Actually, an implementation of the presented
formalism exists written in Common LISP on
a Hewlett Packard machine of the 9000 series
(for more details about the implementation see
[Buschauer et al. 89]). To give an idea of the re-
sponse time, the analysis of a sentence of about 10
to 15 words and a grammar of about 20 to 30 ele-
mentary trees takes at most 6 milliseconds. Cur-
rently, this implementation is extended to build
a workbench supporting a linguist in writing and
testing large TAG grammars (respectively TAGs
with Unification).
Finally, other approaches for TAG parsing
should be mentioned and compared with the pre-
sented result. In the literature, the two ear-
leybased approaches of Schabes and Joshi (see
[Schabes, Joshi 89]) and of Lang gang 86]) are
proposed. The lowest upper time bound for the
Schabes-Joshi approach is 0(n9) and for the ap-
proach of Lang 0(10). But both algorithms come
up with better results in the best and in the av-
erage case. In the framework of parallel parsing,
results for TAGs are also proposed. In [Palis et
al. 87] a linear time approach on 0(n9) proces-
sors and in [Palm, Shende 88] a sublinear (0(log2
n)) algorithm is described.
One future perspective is to parallelize the
new approach by the same method so that the
expected result should be a linear time bound
on 0(n2) processors. More concretely, an op-
timal layout for two processors is looked for,
where independent subtrees have to be specified
(candidates are not always total innermost trees,
e.g., if only one TAG derivation exists where all
innermost trees are nested).
Further on, we concentrate on appropriate ex-
tensions of the TAG formalism for analysis as well
as generation of natural language with the ambi-
tious aim to verify that TAGs (in some extension)
are appropriate for a bidirectional and integrated
description of syntax, semantics and pragmatics.
</bodyText>
<sectionHeader confidence="0.996216" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.732083333333333">
This paper is based on thesis work done under
supervision of Wolfgang Wahlster and Gunther
Hob. I would like to gratefully acknowledge Hans
Arz, Bela Buschauer, Gunther Holz, Paul Moli-
tor, Peter Poller, Anne Schauder and Wolfgang
Wahlster for their valuable interactions.
I would like to thank Aravind Joshi for his helpful
comments in earlier discussions and especially on
this paper.
</bodyText>
<sectionHeader confidence="0.999621" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999941745454545">
B. Buschauer, P. Poller, A. Schauder, K. Har-
bin&amp; 1989. Parsing von TAGs mit Unifikation.
Saarbriicken, F.R.G.: &amp;quot;AI-Laboratory&amp;quot; Memo,
Dept. of Computer Science, Univ. of Saarland.
K. Harbusch. 1989. Effiziente Strukturanalyse
nattirticher Sprache mit Tree Adjoining Gram-
mars. PhD Thesis, Saarbriicken, F.R.G.: Dept.
of Computer Science, Univ. of Saarland.
J. E. Hoperoft, J. D. Ullman. 1979. In-
troduction to Automata Theory, Languages, and
Computation. Addison-Wesley, Reading, Mas-
sachusetts.
A. K. Joshi. 1985. An Introduction to Tree Ad-
joining Grammars. Philadelphia, Pennsylvania:
Technical Report MS-CIS-86-64, Dept. of Com-
puter and Information Science, Moore School,
Univ. of Pennsylvania.
A. K. Joshi, L. S. Levy, M. Takahashi. 1975.
Tree Adjoining Grammars. Journal of Computer
and Systems Science 10:1, Seite 136-163.
T. Kroch, A. K. Joshi. 1985 Linguistic Rel-
evance of Tree Adjoining Grammars. Philadel-
phia, Pennsylvania: Technical Report MS-CIS-
85-16, Dept. of Computer and Information Sci-
ence, Moore School, Univ. of Pennsylvania.
B. Lang. 1989 forthcominF. A Uniform Frame-
work for Parsing, Proceedings of the Interna-
tional Workshop on Parsing Technologies in Pitts-
burgh, 2814-31rd of August.
G. Pullum. 1984. On Two Recent Attempts to
Show That English Is Not a CFL. Computational
Linguistics 10(4): 182-186.
M. A. Pallis, S. Shende, D. S. L. Wei. 1987.
An Optimal Linear-Time Parallel Parser for Tree
Adjoining Languages. Philadelphia, Pennsyl-
vania: Technical Report MS-CIS-87-36, Dept.
of Computer and Information Science, Moore
School, Univ. of Pennsylvania.
Y. Schabes, A. Joshi. 1988. An Earley-Type
Parsing Algorithm for Tree Adjoining Grammars.
Philadelphia, Pennsylvania: Technical Rep.MS-
CIS-88-36, Dept. of Computer and Information
Science, Moore School, Univ. of Pennsylvania.
S. M. Shieber. 1985. Evidence against the
Context-Freeness of Natural Language. Linguis-
tics and Philosophy 8: 333-343.
K. Vijay-Shanker. 1987. A Study of Tree Ad-
joining Grammars, Philadelphia, Pennsylvania:
PhD Thesis, Dept. of Computer and Information
Science, Moore School, Univ. of Pennsylvania.
K. Vijay-Shanker, A. K. Joshi. 1985.
Some Computational Properties of Tree Adjoin-
ing Grammars. Chicago, Illinois: Proceedings of
the 23&amp;quot; Annual Meeting of the Association for
Computational Linguistics: 82-93.
</reference>
<page confidence="0.997859">
291
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.522109">
<title confidence="0.995689">AN EFFICIENT PARSING ALGORITHM FOR TREE ADJOINING GRAMMARS</title>
<author confidence="0.988858">Karin Harbusch</author>
<affiliation confidence="0.603407">DFKI - Deutsches Forschungszentrum für Kiinstliche Intelligenz</affiliation>
<address confidence="0.602715">Stuhlsatzenhausweg 3, D-6600 Saarbracken 11, F.R.G.</address>
<email confidence="0.912519">harbuschadfki.uni-sb.de</email>
<abstract confidence="0.999443071428571">In the literature, Tree Adjoining Grammars (TAGs) are propagated to be adequate for natural language description — analysis as well as generation. In this paper we concentrate on the direction of&apos; analysis. Especially important for an implementation of that task is how efficiently this can be done, i.e., how readily the word problem can be solved for TAGs. Up to now, a parser with steps in the worst case was known where 71. is the length of the input string. In this paper, the result is improved to 0(0 log n) as a new lowest upper bound. The paper demonstrates how local interpretion of TAG trees allows this reduction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Buschauer</author>
<author>P Poller</author>
<author>A Schauder</author>
<author>K Harbin&amp;</author>
</authors>
<title>Parsing von TAGs mit Unifikation. Saarbriicken, F.R.G.: &amp;quot;AI-Laboratory&amp;quot;</title>
<date>1989</date>
<tech>PhD Thesis,</tech>
<institution>Memo, Dept. of Computer Science, Univ. of</institution>
<marker>Buschauer, Poller, Schauder, Harbin&amp;, 1989</marker>
<rawString>B. Buschauer, P. Poller, A. Schauder, K. Harbin&amp; 1989. Parsing von TAGs mit Unifikation. Saarbriicken, F.R.G.: &amp;quot;AI-Laboratory&amp;quot; Memo, Dept. of Computer Science, Univ. of Saarland. K. Harbusch. 1989. Effiziente Strukturanalyse nattirticher Sprache mit Tree Adjoining Grammars. PhD Thesis, Saarbriicken, F.R.G.: Dept. of Computer Science, Univ. of Saarland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>J. E. Hoperoft, J. D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>An Introduction to Tree Adjoining Grammars.</title>
<date>1985</date>
<tech>Technical Report MS-CIS-86-64,</tech>
<institution>Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</institution>
<location>Philadelphia, Pennsylvania:</location>
<marker>Joshi, 1985</marker>
<rawString>A. K. Joshi. 1985. An Introduction to Tree Adjoining Grammars. Philadelphia, Pennsylvania: Technical Report MS-CIS-86-64, Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree Adjoining Grammars.</title>
<date>1975</date>
<booktitle>Journal of Computer and Systems Science 10:1, Seite</booktitle>
<pages>136--163</pages>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>A. K. Joshi, L. S. Levy, M. Takahashi. 1975. Tree Adjoining Grammars. Journal of Computer and Systems Science 10:1, Seite 136-163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kroch</author>
<author>A K Joshi</author>
</authors>
<title>Linguistic Relevance of Tree Adjoining Grammars.</title>
<date>1985</date>
<tech>Technical Report MS-CIS85-16,</tech>
<institution>Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</institution>
<location>Philadelphia, Pennsylvania:</location>
<marker>Kroch, Joshi, 1985</marker>
<rawString>T. Kroch, A. K. Joshi. 1985 Linguistic Relevance of Tree Adjoining Grammars. Philadelphia, Pennsylvania: Technical Report MS-CIS85-16, Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>forthcominF. A Uniform Framework for Parsing,</title>
<date>1989</date>
<booktitle>Proceedings of the International Workshop on Parsing Technologies in Pittsburgh, 2814-31rd of</booktitle>
<marker>Lang, 1989</marker>
<rawString>B. Lang. 1989 forthcominF. A Uniform Framework for Parsing, Proceedings of the International Workshop on Parsing Technologies in Pittsburgh, 2814-31rd of August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pullum</author>
</authors>
<title>On Two Recent Attempts to Show That English Is Not a CFL.</title>
<date>1984</date>
<journal>Computational Linguistics</journal>
<volume>10</volume>
<issue>4</issue>
<pages>182--186</pages>
<marker>Pullum, 1984</marker>
<rawString>G. Pullum. 1984. On Two Recent Attempts to Show That English Is Not a CFL. Computational Linguistics 10(4): 182-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Pallis</author>
<author>S Shende</author>
<author>D S L Wei</author>
</authors>
<title>An Optimal Linear-Time Parallel Parser for Tree Adjoining Languages.</title>
<date>1987</date>
<tech>Technical Report MS-CIS-87-36,</tech>
<institution>Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</institution>
<location>Philadelphia, Pennsylvania:</location>
<marker>Pallis, Shende, Wei, 1987</marker>
<rawString>M. A. Pallis, S. Shende, D. S. L. Wei. 1987. An Optimal Linear-Time Parallel Parser for Tree Adjoining Languages. Philadelphia, Pennsylvania: Technical Report MS-CIS-87-36, Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A Joshi</author>
</authors>
<title>An Earley-Type Parsing Algorithm for Tree Adjoining Grammars.</title>
<date>1988</date>
<tech>Technical Rep.MSCIS-88-36,</tech>
<institution>Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</institution>
<location>Philadelphia, Pennsylvania:</location>
<marker>Schabes, Joshi, 1988</marker>
<rawString>Y. Schabes, A. Joshi. 1988. An Earley-Type Parsing Algorithm for Tree Adjoining Grammars. Philadelphia, Pennsylvania: Technical Rep.MSCIS-88-36, Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Evidence against the Context-Freeness of Natural Language.</title>
<date>1985</date>
<journal>Linguistics and Philosophy</journal>
<volume>8</volume>
<pages>333--343</pages>
<marker>Shieber, 1985</marker>
<rawString>S. M. Shieber. 1985. Evidence against the Context-Freeness of Natural Language. Linguistics and Philosophy 8: 333-343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
</authors>
<title>A Study of Tree Adjoining Grammars,</title>
<date>1987</date>
<tech>PhD Thesis,</tech>
<institution>Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</institution>
<location>Philadelphia, Pennsylvania:</location>
<marker>Vijay-Shanker, 1987</marker>
<rawString>K. Vijay-Shanker. 1987. A Study of Tree Adjoining Grammars, Philadelphia, Pennsylvania: PhD Thesis, Dept. of Computer and Information Science, Moore School, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>A K Joshi</author>
</authors>
<title>Some Computational Properties of Tree Adjoining Grammars.</title>
<date>1985</date>
<booktitle>Proceedings of the 23&amp;quot; Annual Meeting of the Association for Computational Linguistics:</booktitle>
<pages>82--93</pages>
<location>Chicago, Illinois:</location>
<marker>Vijay-Shanker, Joshi, 1985</marker>
<rawString>K. Vijay-Shanker, A. K. Joshi. 1985. Some Computational Properties of Tree Adjoining Grammars. Chicago, Illinois: Proceedings of the 23&amp;quot; Annual Meeting of the Association for Computational Linguistics: 82-93.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>