<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000056">
<title confidence="0.985574">
Automatic Extraction of Arabic Multiword Expressions
</title>
<author confidence="0.980261">
Mohammed Attia, Antonio Toral, Lamia Tounsi, Pavel Pecina and Josef van Genabith
</author>
<affiliation confidence="0.967056">
School of Computing, Dublin City University
</affiliation>
<email confidence="0.989291">
{mattia,atoral,ltounsi,ppecina,josef}@computing.dcu.ie
</email>
<sectionHeader confidence="0.993889" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996695842105263">
In this paper we investigate the automatic
acquisition of Arabic Multiword Expres-
sions (MWE). We propose three com-
plementary approaches to extract MWEs
from available data resources. The first
approach relies on the correspondence
asymmetries between Arabic Wikipedia
titles and titles in 21 different languages.
The second approach collects English
MWEs from Princeton WordNet 3.0,
translates the collection into Arabic us-
ing Google Translate, and utilizes differ-
ent search engines to validate the output.
The third uses lexical association mea-
sures to extract MWEs from a large unan-
notated corpus. We experimentally ex-
plore the feasibility of each approach and
measure the quality and coverage of the
output against gold standards.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949157894737">
A lexicon of multiword expressions (MWEs) has
a significant importance as a linguistic resource
because MWEs cannot usually be analyzed lit-
erally, or word-for-word. In this paper we ap-
ply three approaches to the extraction of Arabic
MWEs from multilingual, bilingual, and monolin-
gual data sources. We rely on linguistic informa-
tion, frequency counts, and statistical measures to
create a refined list of candidates. We validate the
results with manual and automatic testing.
The paper is organized as follows: in this intro-
duction we describe MWEs and provide a sum-
mary of previous related research. Section 2 gives
a brief description of the data sources used. Sec-
tion 3 presents the three approaches used in our
experiments, and each approach is tested and eval-
uated in its relevant sub-section. In Section 4 we
discuss the results of the experiments. Finally, we
conclude in Section 5.
</bodyText>
<subsectionHeader confidence="0.989369">
1.1 What Are Multiword Expressions?
</subsectionHeader>
<bodyText confidence="0.999897785714286">
Multiword expressions (MWEs) are defined
as idiosyncratic interpretations that cross word
boundaries or spaces (Sag et al., 2002). The exact
meaning of an MWE is not directly obtained from
its component parts. Accommodating MWEs in
NLP applications has been reported to improve
tasks, such as text mining (SanJuan and Ibekwe-
SanJuan, 2006), syntactic parsing (Nivre and Nils-
son, 2004; Attia, 2006), and Machine Translation
(Deksne, 2008).
There are two basic criteria for identifying
MWEs: first, component words exhibit statisti-
cally significant co-occurrence, and second, they
show a certain level of semantic opaqueness or
non-compositionality. Statistically significant co-
occurrence can give a good indication of how
likely a sequence of words is to form an MWE.
This is particularly interesting for statistical tech-
niques which utilize the fact that a large number
of MWEs are composed of words that co-occur to-
gether more often than can be expected by chance.
The compositionality, or decomposabil-
ity (Villavicencio et al. 2004), of MWEs is also
a core issue that presents a challenge for NLP ap-
plications because the meaning of the expression
is not directly predicted from the meaning of the
component words. In this respect, composition-
alily varies between phrases that are highly com-
</bodyText>
<page confidence="0.997182">
19
</page>
<note confidence="0.902004">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 19–27,
Beijing, August 2010
</note>
<bodyText confidence="0.9489508">
positional, such as, qd-
adatun iaskariyyatun, “military base”, and those
that show a degree of idiomaticity, such as,
madiynatu ’l-maldhiy, “amusement park”,
☎
lit. “city of amusements”. In extreme cases the
meaning of the expression as a whole is utterly
unrelated to the component words, such as,
farasu ’l-nabiyyi, “grasshopper”, lit. “the
horse of the Prophet”.
</bodyText>
<sectionHeader confidence="0.936091" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<bodyText confidence="0.999244381818182">
A considerable amount of research has focused on
the identification and extraction of MWEs. Given
the heterogeneity of MWEs, different approaches
were devised. Broadly speaking, work on the
extraction of MWEs revolves around four ap-
proaches: (a) statistical methods which use asso-
ciation measures to rank MWE candidates (Van de
Cruys and Moir´on, 2006); (b) symbolic methods
which use morpho-syntactic patterns (Vintar and
Fiˇser, 2008); (c) hybrid methods which use both
statistical measures and linguistic filters (Boulak-
nadel et al. 2009; Duan et al., 2009); and (d) word
alignment (Moir´on and Tiedemann, 2006).
None of the approaches is without limitations.
It is difficult to apply symbolic methods to data
with no syntactic annotations. Furthermore, due
to corpus size, statistical measures have mostly
been applied to bigrams and trigrams, and it be-
comes more problematic to extract MWEs of
more than three words. As a consequence, each
approach requires specific resources and is suit-
able for dealing with only one side of a multi-
faceted problem.
Pecina (2010) evaluates 82 lexical association
measures for the ranking of collocation candi-
dates and concludes that it is not possible to se-
lect a single best universal measure, and that dif-
ferent measures give different results for different
tasks depending on data, language, and the types
of MWE that the task is focused on. Similarly,
Ramisch et al. (2008) investigate the hypothesis
that MWEs can be detected solely by looking at
the distinct statistical properties of their individ-
ual words and conclude that the association mea-
sures can only detect trends and preferences in the
co-occurrences of words.
A lot of effort has concentrated on the task of
automatically extracting MWEs for various lan-
guages besides English, including Slovene (Vin-
tar and Fiˇser, 2008), Chinese (Duan et al., 2009),
Czech (Pecina, 2010), Dutch (Van de Cruys and
Moir´on, 2006), Latvian (Deksne, 2008) and Ger-
man ( Zarrieß and Kuhn, 2009).
A few papers, however, focus on Arabic
MWEs. Boulaknadel et al. (2009) develop a hy-
brid multiword term extraction tool for Arabic in
the “environment” domain. Attia (2006) reports
on the semi-automatic extraction of various types
of MWEs in Arabic and how they are used in an
LFG-based parser.
In this paper we report on three different meth-
ods for the extraction of MWEs for Arabic, a less
resourced language. Our approach is linguisti-
cally motivated and can be applied to other lan-
guages.
</bodyText>
<sectionHeader confidence="0.978531" genericHeader="method">
2 Data Resources
</sectionHeader>
<bodyText confidence="0.99969776">
In this project we use three data resources for ex-
tracting MWEs. These resources differ widely in
nature, size, structure and the main purpose they
are used for. In this section we give a brief intro-
duction to each of these data resources.
Wikipedia (WK) is a freely-available mul-
tilingual encyclopedia built by a large number
of contributors. Currently WK is published
in 271 languages, with each language varying
in the number of articles and the average size
(number of words) of articles. WK contains
additional information that proved to be helpful
for linguistic processing such as a category
taxonomy and cross-referencing. Each article
in WK is assigned a category and may be also
linked to equivalent articles in other languages
through what are called “interwiki links”. It also
contains “disambiguation pages” for resolving
the ambiguity related to names that have variant
spellings. Arabic Wikipedia (AWK) has about
117,000 articles (as of March 20101) compared
to 3.2 million articles in the English Wikipedia.
Arabic is ranked 271h according to size (article
count) and 171h according to usage (views per
hour).
</bodyText>
<footnote confidence="0.379882">
lhttp://stats.wikimedia.org/EN/Sitemap.htm
</footnote>
<page confidence="0.988393">
20
</page>
<bodyText confidence="0.997058818181818">
Princeton WordNet2 (PWN) is an electronic
lexical database for English where nouns, verbs,
adjectives and adverbs are grouped into sets of
synonyms called synsets. In our analysis of PWN
3.0 we find that MWEs are widespread among
all the categories, yet with different proportions,
as shown by Table 1. Arabic WordNet (AWN)
(Elkateb et al., 2006) is constructed according to
the methods and techniques used in the develop-
ment of PWN, but it is limited in size, containing
only 11,269 synsets (including 2,348 MWEs).
</bodyText>
<table confidence="0.999670142857143">
POS Unique MWEs Percentage
Strings of MWEs
Nouns 117,798 60,292 51.18
Verbs 11,529 2,829 24.53
Adjectives 21,479 496 2.31
Adverbs 4,481 714 15.93
Total 155,287 64,331 41.43
</table>
<tableCaption confidence="0.999506">
Table 1: Size and distribution of MWEs in PWN.
</tableCaption>
<bodyText confidence="0.9901945">
Arabic Gigaword Fourth Edition is an unan-
notated corpus distributed by the Linguistic Data
Consortium (LDC), catalog no. LDC2009T30.3
It is the largest publicly available corpus of Ara-
bic to date, containing 848 million words. It
comprises articles from newspapers from different
Arab regions, such as Al-Ahram in Egypt, An Na-
har in Lebanon and Assabah in Tunisia, in addi-
tion to news agencies, such as Xinhua and Agence
France Presse.
</bodyText>
<sectionHeader confidence="0.998479" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9999185">
The identification and extraction of MWEs is a
problem more complex than can be dealt with by
one simple solution. The choice of approach de-
pends on the nature of the task and the type of
the resources used. We discuss the experiments
we conducted to extract and validate MWEs from
three types of data resources each with a different
technique and different validation and evaluation
methodology. A crucial factor in the selection of
the approach is the availability of rich resources
that have not been exploited in similar tasks be-
fore.
We focus on nominal MWEs because the vast
majority of MWEs are nouns, as evidenced by
</bodyText>
<footnote confidence="0.919644333333333">
2http://wordnet.princeton.edu
3http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2009T30
</footnote>
<bodyText confidence="0.996380129032258">
statistics in Table 1 above. We define nominal
MWEs as MWEs that act as nouns and have the
internal structure of either:
- noun–noun, such as duwdatu ’l-
Izrd., “earthworm”;
- noun–adjective, such as 4ssafatun
Izwwaliyyatun, “first aid”4; ✶
- noun–preposition–noun, such as,
al-tazallug Sala ’l-galiyd, “Skiing”, lit.
“sliding on ice”; or
- noun–conjunction–noun, such as
al-qanuwn wa-’l-niz. am, “law and order”.
We use three approaches to identify and extract
MWEs: (a) crosslingual correspondence asym-
metries, (b) translation-based extraction, and (c)
corpus-based statistics. For each approach we use
a number of linguistic and statistical validation
techniques and both automatic and manual eval-
uation.
In the first approach (Section 3.1) we make use
of the crosslingual correspondence asymmetry, or
many-to-one relations between the titles in the
Arabic Wikipedia (AWK) and the corresponding
titles in other languages to harvest MWEs. In the
second approach (Section 3.2) we assume that au-
tomatic translation of MWEs collected from PWN
into Arabic are high likelihood MWE candidates
that need to be automatically checked and vali-
dated. In the third approach (Section 3.3) we try
to detect MWEs in a large raw corpus relying on
statistical measures and POS-annotation filtering.
</bodyText>
<subsectionHeader confidence="0.9683405">
3.1 Crosslingual Correspondence
Asymmetries
</subsectionHeader>
<bodyText confidence="0.999989692307692">
In this approach, our focus is on semantic non-
decomposable MWEs and we rely on Crosslin-
gual Correspondence Asymmetries (CCAs) for
capturing them. Semantic non-compositionality
can be considered as a powerful indication that a
phrase is an MWE. Baldwin et al. (2003) clas-
sify MWEs, with respect to compositionality, into
three categories: (a) non-compositional MWEs,
where the expression is semantically impenetra-
ble, such as hot dog, (b) idiosyncratically compo-
sitional, where the component words are forced
to take semantics unavailable outside the MWE,
such as radar footprint, and (c) simply composi-
</bodyText>
<footnote confidence="0.888922">
4In Arabic, the adjective follows the noun.
</footnote>
<page confidence="0.997299">
21
</page>
<bodyText confidence="0.999971055555556">
tional, where the phrase is institutionalized, such
as traffic light. This, however, can only serve
as an approximation, not as a clear-cut division.
As Moon (1998) indicates, compositionality can
be viewed more as a gradient along a continuum
with no clear demarcations, ranging from conven-
tionalized, fully transparent literal expressions to
completely opaque idioms.
There are many signs, or indications, of non-
compositionality, two well-known among them
are “non-substitutability”, when a word in the ex-
pression cannot be substituted by a semantically
equivalent word, and “single-word paraphrasabil-
ity”, when the expression can be paraphrased or
translated by a single word. These two indi-
cations have been exploited differently by dif-
ferent researchers. Van de Cruys and Moir´on
(2006) develop an unsupervised method for de-
tecting MWEs using clusters of semantically re-
lated words and taking the ratio of the word pref-
erence over the cluster preference as an indica-
tion of how likely a particular expression is to
be an MWE. Melamed (1997) investigates tech-
niques for identifying non-compositional com-
pounds in English-French parallel corpora and
emphasises that translation models that take non-
compositional compounds into account are more
accurate. Moir´on and Tiedemann (2006) use word
alignment of parallel corpora to locate the transla-
tion of an MWE in a target language and decide
whether the original expression is idiomatic or lit-
eral.
The technique used here is inspired by that of
ZarrieB and Kuhn (2009) who rely on the linguis-
tic intuition that if a group of words in one lan-
guage is translated as a single word in another
language, this can be considered as an indica-
tion that we have a fixed expression with a non-
compositional meaning. They applied their data-
driven method to the German-English section of
the Europarl corpus after preprocessing with de-
pendency parsing and word alignment, and tested
their method on four German verb lemmas.
We also utilize CCAs for the task of MWE
extraction. As an approximation we make
a binary decision between whether an expres-
sion is decomposable or non-decomposable based
on the criterion of single word translatabil-
ity. This technique follows ZarrieB and Kuhn’s
(2009) assumption that the idiosyncrasy and non-
compositionality of MWEs makes it unlikely, to
some extent, to have a mirrored representation in
the other languages. We consider many-to-one
correspondence relationships (an MWE in one
language has a single-word translation in another
language) as empirical evidence for the detection
of MWEs. Here our candidate MWEs are the
AWK titles that are made up of more than one
word. For each of them we check whether there
exists a many-to-one correspondence relation for
this title in other languages (the translations are
obtained by exploiting the inter-lingual links of
AWK). To increase the predictive power of our ap-
proach and ensure that the results are more repre-
sentative we expand the search space into 21 lan-
guages5, rather than only one, as in ZarrieB and
Kuhn (2009). This approach helps us with id-
iomatic MWEs. For non-idiomatic MWEs we rely
on the second and third methods discussed in 3.2
and 3.3 respectively.
The steps undertaken in this approach are: (1)
Candidate Selection. All AWK multiword titles
are taken as candidates. (2) Filtering. We exclude
titles of disambiguation and administrative pages.
(3) Validation. This includes two steps. First, we
check if there is a single-word translation in any
of the target languages. Second, we look for the
candidate and/or its translations in LRs; the Ital-
ian, Spanish, and English translations are looked
up in the corresponding WordNets while both the
AWK title and its translations are looked up in
a multilingual lexicon of Named Entities (NEs),
MINELex (Attia et al., 2010). If the candidate ti-
tle is found in MINELex or if any of its transla-
tions is a single word or is found in any WordNet
or in MINELex, then the AWK title is classified as
a MWE. Otherwise, it is considered a non-MWE.
It is worth-noting that many titles in the AWK
are named entities (NEs). We conduct our evalua-
tion on a set of 1100 multiword titles from AWK
</bodyText>
<construct confidence="0.541858857142857">
5These languages are: Dutch, Catalan, Czech, Danish,
German, Greek, English, Esperanto, Spanish, French, He-
brew, Indonesian, Italian, Latin, Norwegian, Portuguese,
Polish, Romanian, Russian, Swedish and Turkish. The se-
lection is based on three criteria: (a) number of articles, (b)
cultural association with Arabic and (c) relevance to scien-
tific terminology.
</construct>
<page confidence="0.991717">
22
</page>
<bodyText confidence="0.9932494">
that have been manually tagged as: non-NE-
MWEs (181), NE-MWEs (849) or non-MWEs
(70). Given the high percentage of NE-MWEs in
the set we derive two gold standards: the first in-
cludes NEs as MWEs, and is made up of 1030
MWEs and 70 non-MWEs, and the second drops
NEs and hence consists of 251 entries (181 MWEs
and 70 non-MWEs). In the experiment these sets
are matched with our validation approach. Table
2 compares the results of our experiment (CCA)
with a baseline, which considers all multiword ti-
tles as MWEs, in terms of precision, recall, Fβ=1
and Fβ=0.5. We notice that our precision is sub-
stantially higher for both sets. Some examples of
the CCA method are given in Table 3.
</bodyText>
<table confidence="0.999610571428571">
P R F-1 F-0.5
With NEs
Baseline 93.63 100.00 96.71 94.83
CCA 98.28 44.47 61.23 79.13
Without NEs
Baseline 72.11 100.00 83.80 76.37
CCA 82.99 21.55 34.21 52.85
</table>
<tableCaption confidence="0.994301">
Table 2: Evaluation (in percent) of the CCA approach.
</tableCaption>
<table confidence="0.999966153846154">
Arabic Phrase Translation Langs M-1
Anemia 21 100%
colitis 12 92%
wallpaper 11 82%
cockpit 17 76%
teamwork 9 67%
hippopotamus 21 52%
database 20 45%
toothbrush 19 37%
volcanic crater 14 21%
abstract art 20 15%
electrical network 20 5%
aviation history 12 0%
</table>
<tableCaption confidence="0.793982555555556">
Table 3: MWE identification through correspondence
asymmetries. The first column shows the Arabic candidate
MWE. The second column is the English translation of the
expression. The third column is the number of languages that
have correspondences for the Arabic expression. The last
column is the ratio of many-to-one correspondences where
100% means that all other the languages have the expression
as one word, and 0% means that all other languages have a
parallel compositional phrase.
</tableCaption>
<subsectionHeader confidence="0.991497">
3.2 Translation-Based Approach
</subsectionHeader>
<bodyText confidence="0.999993711111111">
This approach is bilingual and complements the
first approach by focusing on compositional com-
pound nouns which the many-to-one correspon-
dence approach is not likely to identify. We col-
lect English MWEs from PWN, translate them
into Arabic, and automatically validate the results.
This technique also has an ontological advantage
as the translated and validated expressions can be
used to extend the Arabic WordNet by linking the
expressions to their respective synsets.
This method is partly similar to that of Vin-
tar and Fiˇser (2008) who automatically extended
the Slovene WordNet with nominal multiword ex-
pressions by translating the MWEs in PWN using
a technique based on word alignment and lexico-
syntactic patterns. Here we also use the MWEs in
PWN as a starting point to collect MWEs in our
target language, Arabic. We depart from Vintar
and Fiˇser (2008) in that instead of using a paral-
lel corpus to find the translation, we use an off-
the-shelf SMT system, namely Google Translate.
The reason we did not use an alignment-based ap-
proach is that word alignment, per se, is complex
and the quality of the output is dependent on the
size and domain of the corpus as well as on the
quality of the alignment process itself. Therefore,
we use a state-of-art MT system and concentrate
on validating the results using frequency statistics.
The rationale behind this technique is that we
try to discover MWEs by inducing and analysing
a translation model. We assume that an MWE in
one language is likely to be translated as an MWE
in another language, although we are aware that
translations into single words or paraphrases are
also possible. First, we extract the list of nominal
MWEs from PWN 3.0. This provides us with pre-
defined knowledge of what concepts are likely to
be represented as MWEs in the target language.
Second, we translate the list into Arabic using
Google Translate. Third, we validate the results,
by asking a different question: given a list of can-
didate translations, how likely are they to be cor-
rect translations and how well do they correspond
to MWEs? We try to answer this question using
pure frequency counts from three search engines,
</bodyText>
<page confidence="0.995729">
23
</page>
<bodyText confidence="0.999313277777778">
namely, Al-Jazeera6, BBC Arabic7 and AWK.I
We conduct automatic evaluation using as a
gold standard the PWN–MWEs that are found in
English Wikipedia and have a correspondence in
Arabic. The number of gold standard translations
is 6322. We test the Google translation without
any filtering, and consider this as the baseline,
then we filter the output based on the number of
combined hits9 from the search engines. The re-
sults are shown in Table 4. The best f-measure
achieved is when we accept a candidate transla-
tion if it is found only once. The reason for this
is that when Google Translate does not know the
correct translation of an MWE, it produces an un-
grammatical sequence of words that does not re-
turn any matches by the search engines. This
process gives 13,656 successful MWE candidates
from the list of 60,292 translations.
</bodyText>
<table confidence="0.994854875">
SE Filteration Recall Precision F-Measure
Baseline 100.00 45.84 62.86
1 hit 62.56 73.85 67.74
2 hits 55.58 75.07 63.87
3 hits 50.87 75.29 60.71
4 hits 47.37 74.68 57.97
5 hits 44.51 74.19 55.64
10 hits 36.08 71.99 48.07
</table>
<tableCaption confidence="0.9953425">
Table 4: Automatic evaluation (in percent) of the
translation-based approach.
</tableCaption>
<subsectionHeader confidence="0.994801">
3.3 Corpus-Based Approach
</subsectionHeader>
<bodyText confidence="0.999989571428571">
The starting point in this approach is the Arabic
Gigaword corpus, which is an unannotated collec-
tion of texts that contains 848 million words. In
this monolingual setting the only practical solu-
tion to extract MWEs is to use lexical association
measures based on the frequency distribution of
candidate MWEs and to detect any idiosyncratic
co-occurrence patterns. Association measures
are inexpensive language-independent means for
discovering recurrent patterns, or habitual collo-
cates. Association measures are defined by Pecina
(2010) as mathematical formulas that determine
the strength of the association, or degree of con-
nectedness, between two or more words based on
</bodyText>
<footnote confidence="0.8828838">
6http://aljazeera.net/portal/search.aspx
7http://www.bbc.co.uk/arabic/
8http://ar.wikipedia.org/wiki/
9The hits are combined by taking the aggregate sum of
the number of documents returned by the search engines.
</footnote>
<bodyText confidence="0.999838941176471">
their occurrences and co-occurrences in a text.
The higher the connectedness between words, the
better the chance they form a collocation.
The corpus is conceived as a randomly gen-
erated sequence of words and consecutive bi-
grams and trigrams in this sequence are observed.
Then joint and marginal occurrence frequencies
are used to estimate how much the word occur-
rence is accidental or habitual. For the purpose of
this experiment, we use the two following associ-
ation measures:
Pointwise Mutual Information (PMI) compares
the cooccurrence probability of words given their
joint distribution and given their individual (mar-
ginal) distributions under the assumption of inde-
pendence. For two-word expressions, it is defined
as:
</bodyText>
<equation confidence="0.994619">
p(x, y)
PMI2(x, y) = log2
p(x, *)p(*, y)
</equation>
<bodyText confidence="0.999106">
where p(x, y) is the maximum likelihood (ML)
estimation of the joint probability (N is the cor-
pus size):
</bodyText>
<equation confidence="0.60431">
p(x, y) = N
</equation>
<bodyText confidence="0.972272666666667">
and p(x, *), p(*, y) are estimations of marginal
probabilities computed in the following manner:
p(x, *) = f (x, *) = Ey f (x, y)
N N
and analogically for p(*, y). For three words, PMI
can be extended as follows:
</bodyText>
<equation confidence="0.9740195">
PMI x p(x, y, z)
s( y� z) — to g2 p(x, *, *)p(*, y, *)p(*, *, z),
</equation>
<bodyText confidence="0.90193">
Here, the marginal probabilities are estimated as:
</bodyText>
<equation confidence="0.827889">
p(*, y, *) = f (*, y, *) = Ex,z f (x, y, z)
N N
</equation>
<bodyText confidence="0.9992756">
and analogically for p(x, *, *) and p(*, *, z).
Chi-square compares differences between the ob-
served frequencies fi,9 and the expected (under
the assumption of independence) frequencies ei,9
from the two-way contingency table as follows:
</bodyText>
<equation confidence="0.954876">
�
χ22(x,y) =
i,9∈{0,1}
f(x, y)
(fi,9 − ei,9)2
,
</equation>
<page confidence="0.8394825">
ei,9
24
</page>
<bodyText confidence="0.994763">
where the table cells are referred to by the index
pair i, j E 10, 11. The observed frequencies fi,j
for a bigram (x, y) are computed in this manner:
</bodyText>
<equation confidence="0.9381675">
f0,0 = f(x, y), f0,1 = f(x, -y) = � f(x, v)
v=,4y
</equation>
<bodyText confidence="0.9537423125">
and analogically for f1,0 and f1,1. The expected
frequencies ei,j are then estimated using marginal
frequencies as in the following equations:
(4) Filtering the list using the MADA POS-tagger
(Habash et al., 2009) to exclude patterns that gen-
erate unlikely collocates and to select those can-
didates that match the relevant POS patterns. The
patterns that we include for bigrams are: NN NA,
and for trigrams: NNN NNA NAA. Table 5 shows
the number of phrases extracted for each step.
n = 2 n = 3
words 875,920,195
base form n-grams 134,411,475
after frequency filtering 1,497,214 560,604
after base-form collapsing 777,830 415,528
after POS filtering 217,630 39,269
</bodyText>
<equation confidence="0.9872904">
e0,0 = e(x, y) = f(x, *)f(*, y)
N
,
e0,1 = e(x, -y) = f(x, *)f(*, -y)
N
</equation>
<tableCaption confidence="0.736726">
Table 5: Bigram and trigram experiment statistics.
,
</tableCaption>
<bodyText confidence="0.933419571428571">
and analogically for e1,0 and e1,1. For three words,
the Chi-square formula can be extended and ap-
plied to a three-way contingency table as follows:
(fi,j,k − ei,j,k)2
ei,j,k
with the observed (fi,j,k) frequencies computed
analogically as in this example:
</bodyText>
<equation confidence="0.956091">
�f0,1,0 = f(x, -y, z) = f(x,v, z).
v=,4y
</equation>
<bodyText confidence="0.9999425">
And similarly for the expected frequencies (ei,j,k)
with the marginal probabilities as in this example:
</bodyText>
<equation confidence="0.9835835">
e0,1,0 = f(x, -y, z) = f(x,*,*)f(*,-y,*)f(*,*,z)
N2
</equation>
<bodyText confidence="0.862186321428571">
This corpus-based process involves four steps:
(1) We compute the frequency of all the unigrams,
bigrams, and trigrams in the corpus.
(2) The association measures are computed for all
the bigrams and trigrams with frequency above a
threshold which we set to 50. Then the bigrams
and trigrams are ranked in descending order.
(3) We conduct lemmatization using MADA
(Habash et al., 2009). This step is necessary be-
cause Arabic is a clitic language where conjunc-
tions, prepositions and the definite article are at-
tached to nouns which creates data sparsity and
obscures the frequency statistics. Using lemmati-
zation helps to collapse all variant forms together,
and thus create a more meaningful list of candi-
dates.
The evaluation is based on measuring the qual-
ity of ranking the candidates according to their
chance to form collocations. To evaluate the re-
sults, 3600 expressions were randomly selected
and classified into MWE or non-MWE by a hu-
man annotator. The performance of the methods is
compared by precision scores. The method is fo-
cused on two-word (bigram) and three-word (tri-
gram) collocations. The results are reported in Ta-
ble 6. We notice that the best score for the bigrams
is for 10,000 terms using PMI, and for the trigrams
5,000 using χ2.
</bodyText>
<table confidence="0.9997535">
# top candidates n = 2 χ22
PMI2
10,000 71 70
25,000 66 69
50,000 57 59
n = 3
PMI3 χ23
2,000 40 46
5,000 56 63
10,000 56 57
</table>
<tableCaption confidence="0.996636">
Table 6: Bigram and trigram experiment results.
</tableCaption>
<sectionHeader confidence="0.97794" genericHeader="method">
4 Discussion of Experiments and Results
</sectionHeader>
<bodyText confidence="0.9999455">
It is an underestimation to view MWEs as a sin-
gle phenomenon. In fact MWEs encompass a set
of diverse and related phenomena that include id-
ioms, proper nouns, compounds, collocations, in-
stitutionalised phrases, etc. They can also be of
any degree of compositionality, idiosyncrasy and
lexical and syntactic flexibility. This complicates
the task of MWE identification. Moreover, we
</bodyText>
<equation confidence="0.9761535">
χ23(x, y, z ) = E
i,j,kE{0,1}
</equation>
<page confidence="0.987983">
25
</page>
<bodyText confidence="0.999774692307692">
have used three data sources with a large degree of
discrepancy: (a) titles of articles in the AWK, (b)
induced translation of English MWEs collected
from PWN, and (b) Arabic Gigaword, which is
a collection of free texts.
For each of the data types we apply a differ-
ent technique that we deem suitable for the task
at hand. The results of the experiments have been
subjected to testing and evaluation in their respec-
tive sections. Table 7 combines and compares the
outcomes of the experiments. The column “Inter-
section” refers to how many MWE candidates are
already found through the other methods.
</bodyText>
<table confidence="0.994974142857143">
MWEs Intersection
Crosslingual 7,792 -
NE–MWEs 38,712 -
Translation-based 13,656 2658
Corpus-based 15,000 697
Union without NEs 33,093 -
Union including NEs 71,805 -
</table>
<tableCaption confidence="0.999888">
Table 7: Comparison of outcomes from each approach.
</tableCaption>
<bodyText confidence="0.985343625">
We notice that the heterogeneity of the data
sources which we used for the task of MWE ex-
traction, helped to enrich our MWE lexicon, as
they are complementary to each other. We also
notice that the intersection between the corpus-
based approach and the other approaches is very
low. On examining the results, we assume that the
reasons for the low intersection are:
1. A lot of named entities in the news corpus are
not famous enough to be included in standard Ara-
bic lexical resources (Wikipedia and WordNet),
such as, minah. im mazuwz, “Men-
achem Mazuz”.
2. We lemmatize according to clitics and ignore
inflection. If we include morphological inflec-
tion in the lemmatization this may produce a less
marked list and allow better matching, such as,
h. ukmani giyabiyyayni, “two
sentences in absentia”.
3. The set of collocations detected by the as-
sociation measures may differ from the those
which capture the interest of lexicographers and
Wikipedians, such as, al-
hud.rawatu ’l-t.azigatu, “fresh vegetables”.
</bodyText>
<sectionHeader confidence="0.997701" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999831277777778">
The identification of MWEs is too complex to be
dealt with by one simple solution. The choice of
approach depends, to a large extent, on the type
of data resources used. In this paper, we extract
MWEs from heterogeneous data resources using
three approaches: (a) crosslingual correspondence
asymmetries which relied on the many-to-one re-
lations in interwiki links, (b) translation-based ex-
traction, which employs the automatic translation
of PWN–MWEs into Arabic and uses different
search engines to filter the translation output, and
(c) corpus-based statistics, which applies lexical
association measures to detect habitual colloca-
tions in a large unannotated corpus. As Arabic
has a rich and complex morphology, we lemma-
tize the text to reduce inflectional forms. These
approaches prove to be a fruitful ground for large-
scale extraction of Arabic MWEs.
</bodyText>
<sectionHeader confidence="0.997473" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996976">
This research is funded by Enterprise Ireland
(PC/09/037), the Irish Research Council for Sci-
ence Engineering and Technology (IRCSET), and
the EU projects PANACEA (7FP-ITC-248064)
and META-NET (FP7-ICT-249119).
</bodyText>
<sectionHeader confidence="0.998586" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99874755">
Attia, Mohammed. 2006. Accommodating Mul-
tiword Expressions in an Arabic LFG Grammar.
In Salakoski, Tapio, Filip Ginter, Sampo Pyysalo,
Tapio Pahikkala (Eds.): Advances in Natural Lan-
guage Processing. Vol. 4139, pp. 87–98. Springer-
Verlag: Berlin, Heidelberg.
Attia, Mohammed, Antonio Toral, Lamia Tounsi,
Monica Monachini and Josef van Genabith. 2010.
An automatically built Named Entity lexicon for
Arabic. In the 7t International Conference on Lan-
guage Resources and Evaluation (LREC 2010), pp.
3614–3621. Valletta, Malta.
Baldwin, Timothy, Colin Bannard, Takaaki Tanaka and
Dominic Widdows. 2003. An Empirical Model of
Multiword Expressions Decomposability. In Work-
shop on Multiword Expressions, the 4111 Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2003), pp. 89–96, Sapporo, Japan.
Boulaknadel, Siham, Beatrice Daille, Driss Aboutaj-
dine. 2009. A multi-word term extraction program
</reference>
<page confidence="0.949223">
26
</page>
<reference confidence="0.998170774509804">
for Arabic language In the 6th International Confer-
ence on Language Resources and Evaluation (LREC
2008), pp. 630–634, Marrakech, Morocco.
Deksne, Daiga, Raivis Skadin.ˇs, Inguna Skadin.a. 2008.
Dictionary of Multiword Expressions for Transla-
tion into Highly Inflected Languages. In the 6th In-
ternational Conference on Language Resources and
Evaluation (LREC 2008), Marrakech, Morocco.
Duan, Jianyong, Mei Zhang, Lijing Tong, and Feng
Guo. 2009. A Hybrid Approach to Improve Bilin-
gual Multiword Expression Extraction. In the 13th
Pacific-Asia Conference on Knowledge Discovery
and Data (PAKDD 2009), pp. 541–547. Bangkok,
Thailand.
Elkateb, Sabri, William Black, Horacio Rodr´ıguez,
Musa Alkhalifa, Piek Vossen, Adam Pease, Chris-
tiane Fellbaum. 2006. Building a Wordnet for Ara-
bic. In the 5th International Conference on Lan-
guage Resources and Evaluation (LREC 2006),
Genoa, Italy.
Habash, Nizar, Owen Rambow and Ryan Roth. 2009.
A Toolkit for Arabic Tokenization, Diacritiza-
tion, Morphological Disambiguation, POS Tagging,
Stemming and Lemmatization. In the 2nd Interna-
tional Conference on Arabic Language Resources
and Tools (MEDAR 2009), pp. 102–109. Cairo,
Egypt.
Hoang, Huu Hoang, Su Nam Kim and Min-Yen
Kan. 2009. A Re-examination of Lexical Associa-
tion Measures. In the Workshop on Multiword Ex-
pressions, the Joint Conference of the 47th An-
nual Meeting of the Association for Computational
Linguistics and the 4th International Joint Confer-
ence on Natural Language Processing of the Asian
Federation of Natural Language Processing (ACL-
IJCNLP 2009), pp. 31–39, Suntec, Singapore.
Melamed, I. Dan. 1997. Automatic Discovery of Non-
Compositional Compounds in Parallel Data. In the
2nd Conference on Empirical Methods in Natural
Language Processing (EMNLP 1997), pp. 97–108.
Providence, RI.
Moir´on, Bego˜na Villada and J¨org Tiedemann. 2006.
Identifying idiomatic expressions using automatic
word-alignment. In the Workshop on Multiword Ex-
pressions in a Multilingual Context, the 11th Con-
ference of the European Association of Computa-
tional Linguistics (EACL 2006), pp. 33–40. Trento,
Italy.
Moon, Rosamund 1998. Fixed Expressions and Idioms
in English: A Corpus-Based Approach. Clarendom
Press, Oxford.
Nivre, Joakim and Jens Nilsson. 2004. Multiword
Units in Syntactic Parsing. In Workshop on Method-
ologies and Evaluation of Multiword Units in Real-
World Applications, the 4th International Confer-
ence on Language Resources and Evaluation (LREC
2004), pp. 39–46. Lisbon, Portugal.
Pecina, Pavel 2010. Lexical association measures and
collocation extraction. In Language Resources and
Evaluation (2010), 44:137-158.
Ramisch, Carlos, Paulo Schreiner, Marco Idiart and
Aline Villavicencio. 2008. An Evaluation of Meth-
ods for the Extraction of Multiword Expressions. In
the Workshop on Multiword Expressions, the 6th
International Conference on Language Resources
and Evaluation (LREC 2008), pp. 50–53. Mar-
rakech, Morocco.
Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann
Copestake and Dan Flickinger. 2002. Multiword
Expressions: A Pain in the Neck for NLP. In
the 3rd International Conference on Intelligent
Text Processing and Computational Linguistics
(CICLing-2002), volume 2276 of Lecture Notes
in Computer Science, pp. 1–15, London, UK.
Springer-Verlag.
SanJuan, Eric and Fidelia Ibekwe-SanJuan. 2006. Text
mining without document context. In Information
Processing and Management. Volume 42, Issue 6,
pp. 1532–1552.
Van de Cruys, Tim and Bego˜na Villada Moir´on. 2006.
Lexico-Semantic Multiword Expression Extraction.
In P. Dirix et al. (eds.), Computational Linguistics
in the Netherlands 2006, pp. 175–190.
Villavicencio, Aline, Ann Copestake, Benjamin Wal-
dron and Fabre Lambeau. 2004. The Lexical En-
coding of MWEs. In the Workshop on Multiword
Expressions, the 42nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2004),
pp. 80–87. Barcelona, Spain.
Vintar, ˇSpela and Darja Fiˇser. 2008. Harvesting Multi-
Word Expressions from Parallel Corpora. In the 6th
International Conference on Language Resources
and Evaluation (LREC 2008). Marrakech, Morocco.
Zarrieß, Sina and Jonas Kuhn. 2009. Exploiting Trans-
lational Correspondences for Pattern-Independent
MWE Identification. In the Workshop on Multiword
Expressions, the Joint Conference of the 47th An-
nual Meeting of the Association for Computational
Linguistics and the 4th International Joint Confer-
ence on Natural Language Processing of the Asian
Federation of Natural Language Processing (ACL-
IJCNLP 2009), pp. 23–30. Suntec, Singapore.
</reference>
<page confidence="0.998784">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944573">
<title confidence="0.999965">Automatic Extraction of Arabic Multiword Expressions</title>
<author confidence="0.999974">Mohammed Attia</author>
<author confidence="0.999974">Antonio Toral</author>
<author confidence="0.999974">Lamia Tounsi</author>
<author confidence="0.999974">Pavel Pecina</author>
<author confidence="0.999974">Josef van</author>
<affiliation confidence="0.953363">School of Computing, Dublin City</affiliation>
<abstract confidence="0.99951305">In this paper we investigate the automatic acquisition of Arabic Multiword Expressions (MWE). We propose three complementary approaches to extract MWEs from available data resources. The first approach relies on the correspondence asymmetries between Arabic Wikipedia titles and titles in 21 different languages. The second approach collects English MWEs from Princeton WordNet 3.0, translates the collection into Arabic using Google Translate, and utilizes different search engines to validate the output. The third uses lexical association measures to extract MWEs from a large unannotated corpus. We experimentally explore the feasibility of each approach and measure the quality and coverage of the output against gold standards.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohammed Attia</author>
</authors>
<title>Accommodating Multiword Expressions in an Arabic LFG Grammar. In Salakoski, Tapio, Filip Ginter, Sampo Pyysalo, Tapio Pahikkala (Eds.):</title>
<date>2006</date>
<booktitle>Advances in Natural Language Processing.</booktitle>
<volume>4139</volume>
<pages>87--98</pages>
<publisher>SpringerVerlag:</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="2312" citStr="Attia, 2006" startWordPosition="348" endWordPosition="349"> our experiments, and each approach is tested and evaluated in its relevant sub-section. In Section 4 we discuss the results of the experiments. Finally, we conclude in Section 5. 1.1 What Are Multiword Expressions? Multiword expressions (MWEs) are defined as idiosyncratic interpretations that cross word boundaries or spaces (Sag et al., 2002). The exact meaning of an MWE is not directly obtained from its component parts. Accommodating MWEs in NLP applications has been reported to improve tasks, such as text mining (SanJuan and IbekweSanJuan, 2006), syntactic parsing (Nivre and Nilsson, 2004; Attia, 2006), and Machine Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a sequence of words is to form an MWE. This is particularly interesting for statistical techniques which utilize the fact that a large number of MWEs are composed of words that co-occur together more often than can be expected by chance. The compositionality, or decomp</context>
<context position="5862" citStr="Attia (2006)" startWordPosition="909" endWordPosition="910">vidual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 2 Data Resources In this project we use three data resources for extracting MWEs. These resources differ widely in nature, size, structure and the main purpose they are used for. In this section we give a brief introduction to each of these data resources. Wikipedia (WK) is a fre</context>
</contexts>
<marker>Attia, 2006</marker>
<rawString>Attia, Mohammed. 2006. Accommodating Multiword Expressions in an Arabic LFG Grammar. In Salakoski, Tapio, Filip Ginter, Sampo Pyysalo, Tapio Pahikkala (Eds.): Advances in Natural Language Processing. Vol. 4139, pp. 87–98. SpringerVerlag: Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammed Attia</author>
<author>Antonio Toral</author>
<author>Lamia Tounsi</author>
<author>Monica Monachini</author>
<author>Josef van Genabith</author>
</authors>
<title>An automatically built Named Entity lexicon for Arabic.</title>
<date>2010</date>
<booktitle>In the 7t International Conference on Language Resources and Evaluation (LREC 2010),</booktitle>
<pages>3614--3621</pages>
<location>Valletta,</location>
<marker>Attia, Toral, Tounsi, Monachini, van Genabith, 2010</marker>
<rawString>Attia, Mohammed, Antonio Toral, Lamia Tounsi, Monica Monachini and Josef van Genabith. 2010. An automatically built Named Entity lexicon for Arabic. In the 7t International Conference on Language Resources and Evaluation (LREC 2010), pp. 3614–3621. Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An Empirical Model of Multiword Expressions Decomposability.</title>
<date>2003</date>
<booktitle>In Workshop on Multiword Expressions, the 4111 Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="10876" citStr="Baldwin et al. (2003)" startWordPosition="1692" endWordPosition="1695"> 3.2) we assume that automatic translation of MWEs collected from PWN into Arabic are high likelihood MWE candidates that need to be automatically checked and validated. In the third approach (Section 3.3) we try to detect MWEs in a large raw corpus relying on statistical measures and POS-annotation filtering. 3.1 Crosslingual Correspondence Asymmetries In this approach, our focus is on semantic nondecomposable MWEs and we rely on Crosslingual Correspondence Asymmetries (CCAs) for capturing them. Semantic non-compositionality can be considered as a powerful indication that a phrase is an MWE. Baldwin et al. (2003) classify MWEs, with respect to compositionality, into three categories: (a) non-compositional MWEs, where the expression is semantically impenetrable, such as hot dog, (b) idiosyncratically compositional, where the component words are forced to take semantics unavailable outside the MWE, such as radar footprint, and (c) simply composi4In Arabic, the adjective follows the noun. 21 tional, where the phrase is institutionalized, such as traffic light. This, however, can only serve as an approximation, not as a clear-cut division. As Moon (1998) indicates, compositionality can be viewed more as a</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Baldwin, Timothy, Colin Bannard, Takaaki Tanaka and Dominic Widdows. 2003. An Empirical Model of Multiword Expressions Decomposability. In Workshop on Multiword Expressions, the 4111 Annual Meeting of the Association for Computational Linguistics (ACL 2003), pp. 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siham Boulaknadel</author>
<author>Beatrice Daille</author>
<author>Driss Aboutajdine</author>
</authors>
<title>A multi-word term extraction program for Arabic language In</title>
<date>2009</date>
<booktitle>the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>630--634</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="4249" citStr="Boulaknadel et al. 2009" startWordPosition="643" endWordPosition="647">arasu ’l-nabiyyi, “grasshopper”, lit. “the horse of the Prophet”. 1.2 Related Work A considerable amount of research has focused on the identification and extraction of MWEs. Given the heterogeneity of MWEs, different approaches were devised. Broadly speaking, work on the extraction of MWEs revolves around four approaches: (a) statistical methods which use association measures to rank MWE candidates (Van de Cruys and Moir´on, 2006); (b) symbolic methods which use morpho-syntactic patterns (Vintar and Fiˇser, 2008); (c) hybrid methods which use both statistical measures and linguistic filters (Boulaknadel et al. 2009; Duan et al., 2009); and (d) word alignment (Moir´on and Tiedemann, 2006). None of the approaches is without limitations. It is difficult to apply symbolic methods to data with no syntactic annotations. Furthermore, due to corpus size, statistical measures have mostly been applied to bigrams and trigrams, and it becomes more problematic to extract MWEs of more than three words. As a consequence, each approach requires specific resources and is suitable for dealing with only one side of a multifaceted problem. Pecina (2010) evaluates 82 lexical association measures for the ranking of collocati</context>
<context position="5761" citStr="Boulaknadel et al. (2009)" startWordPosition="891" endWordPosition="894">te the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 2 Data Resources In this project we use three data resources for extracting MWEs. These resources differ widely in nature, size, structure and the main purpose they are used for. </context>
</contexts>
<marker>Boulaknadel, Daille, Aboutajdine, 2009</marker>
<rawString>Boulaknadel, Siham, Beatrice Daille, Driss Aboutajdine. 2009. A multi-word term extraction program for Arabic language In the 6th International Conference on Language Resources and Evaluation (LREC 2008), pp. 630–634, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daiga Deksne</author>
</authors>
<title>Raivis Skadin.ˇs, Inguna Skadin.a.</title>
<date>2008</date>
<booktitle>In the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="2352" citStr="Deksne, 2008" startWordPosition="353" endWordPosition="354">tested and evaluated in its relevant sub-section. In Section 4 we discuss the results of the experiments. Finally, we conclude in Section 5. 1.1 What Are Multiword Expressions? Multiword expressions (MWEs) are defined as idiosyncratic interpretations that cross word boundaries or spaces (Sag et al., 2002). The exact meaning of an MWE is not directly obtained from its component parts. Accommodating MWEs in NLP applications has been reported to improve tasks, such as text mining (SanJuan and IbekweSanJuan, 2006), syntactic parsing (Nivre and Nilsson, 2004; Attia, 2006), and Machine Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a sequence of words is to form an MWE. This is particularly interesting for statistical techniques which utilize the fact that a large number of MWEs are composed of words that co-occur together more often than can be expected by chance. The compositionality, or decomposability (Villavicencio et al. 2004), o</context>
<context position="5652" citStr="Deksne, 2008" startWordPosition="873" endWordPosition="874">age, and the types of MWE that the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 2 Data Resources In this project we use three data resources for extra</context>
</contexts>
<marker>Deksne, 2008</marker>
<rawString>Deksne, Daiga, Raivis Skadin.ˇs, Inguna Skadin.a. 2008. Dictionary of Multiword Expressions for Translation into Highly Inflected Languages. In the 6th International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianyong Duan</author>
<author>Mei Zhang</author>
<author>Lijing Tong</author>
<author>Feng Guo</author>
</authors>
<title>A Hybrid Approach to Improve Bilingual Multiword Expression Extraction.</title>
<date>2009</date>
<booktitle>In the 13th Pacific-Asia Conference on Knowledge Discovery and Data (PAKDD</booktitle>
<pages>541--547</pages>
<location>Bangkok, Thailand.</location>
<contexts>
<context position="4269" citStr="Duan et al., 2009" startWordPosition="648" endWordPosition="651">opper”, lit. “the horse of the Prophet”. 1.2 Related Work A considerable amount of research has focused on the identification and extraction of MWEs. Given the heterogeneity of MWEs, different approaches were devised. Broadly speaking, work on the extraction of MWEs revolves around four approaches: (a) statistical methods which use association measures to rank MWE candidates (Van de Cruys and Moir´on, 2006); (b) symbolic methods which use morpho-syntactic patterns (Vintar and Fiˇser, 2008); (c) hybrid methods which use both statistical measures and linguistic filters (Boulaknadel et al. 2009; Duan et al., 2009); and (d) word alignment (Moir´on and Tiedemann, 2006). None of the approaches is without limitations. It is difficult to apply symbolic methods to data with no syntactic annotations. Furthermore, due to corpus size, statistical measures have mostly been applied to bigrams and trigrams, and it becomes more problematic to extract MWEs of more than three words. As a consequence, each approach requires specific resources and is suitable for dealing with only one side of a multifaceted problem. Pecina (2010) evaluates 82 lexical association measures for the ranking of collocation candidates and co</context>
<context position="5566" citStr="Duan et al., 2009" startWordPosition="858" endWordPosition="861">that different measures give different results for different tasks depending on data, language, and the types of MWE that the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to o</context>
</contexts>
<marker>Duan, Zhang, Tong, Guo, 2009</marker>
<rawString>Duan, Jianyong, Mei Zhang, Lijing Tong, and Feng Guo. 2009. A Hybrid Approach to Improve Bilingual Multiword Expression Extraction. In the 13th Pacific-Asia Conference on Knowledge Discovery and Data (PAKDD 2009), pp. 541–547. Bangkok, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabri Elkateb</author>
<author>William Black</author>
<author>Horacio Rodr´ıguez</author>
<author>Musa Alkhalifa</author>
<author>Piek Vossen</author>
<author>Adam Pease</author>
<author>Christiane Fellbaum</author>
</authors>
<title>Building a Wordnet for Arabic.</title>
<date>2006</date>
<booktitle>In the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Genoa, Italy.</location>
<marker>Elkateb, Black, Rodr´ıguez, Alkhalifa, Vossen, Pease, Fellbaum, 2006</marker>
<rawString>Elkateb, Sabri, William Black, Horacio Rodr´ıguez, Musa Alkhalifa, Piek Vossen, Adam Pease, Christiane Fellbaum. 2006. Building a Wordnet for Arabic. In the 5th International Conference on Language Resources and Evaluation (LREC 2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>A Toolkit for Arabic Tokenization, Diacritization, Morphological Disambiguation, POS Tagging, Stemming and Lemmatization.</title>
<date>2009</date>
<booktitle>In the 2nd International Conference on Arabic Language Resources and Tools (MEDAR</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="23652" citStr="Habash et al., 2009" startWordPosition="3801" endWordPosition="3804"> the observed frequencies fi,9 and the expected (under the assumption of independence) frequencies ei,9 from the two-way contingency table as follows: � χ22(x,y) = i,9∈{0,1} f(x, y) (fi,9 − ei,9)2 , ei,9 24 where the table cells are referred to by the index pair i, j E 10, 11. The observed frequencies fi,j for a bigram (x, y) are computed in this manner: f0,0 = f(x, y), f0,1 = f(x, -y) = � f(x, v) v=,4y and analogically for f1,0 and f1,1. The expected frequencies ei,j are then estimated using marginal frequencies as in the following equations: (4) Filtering the list using the MADA POS-tagger (Habash et al., 2009) to exclude patterns that generate unlikely collocates and to select those candidates that match the relevant POS patterns. The patterns that we include for bigrams are: NN NA, and for trigrams: NNN NNA NAA. Table 5 shows the number of phrases extracted for each step. n = 2 n = 3 words 875,920,195 base form n-grams 134,411,475 after frequency filtering 1,497,214 560,604 after base-form collapsing 777,830 415,528 after POS filtering 217,630 39,269 e0,0 = e(x, y) = f(x, *)f(*, y) N , e0,1 = e(x, -y) = f(x, *)f(*, -y) N Table 5: Bigram and trigram experiment statistics. , and analogically for e1,</context>
<context position="25066" citStr="Habash et al., 2009" startWordPosition="4037" endWordPosition="4040">uted analogically as in this example: �f0,1,0 = f(x, -y, z) = f(x,v, z). v=,4y And similarly for the expected frequencies (ei,j,k) with the marginal probabilities as in this example: e0,1,0 = f(x, -y, z) = f(x,*,*)f(*,-y,*)f(*,*,z) N2 This corpus-based process involves four steps: (1) We compute the frequency of all the unigrams, bigrams, and trigrams in the corpus. (2) The association measures are computed for all the bigrams and trigrams with frequency above a threshold which we set to 50. Then the bigrams and trigrams are ranked in descending order. (3) We conduct lemmatization using MADA (Habash et al., 2009). This step is necessary because Arabic is a clitic language where conjunctions, prepositions and the definite article are attached to nouns which creates data sparsity and obscures the frequency statistics. Using lemmatization helps to collapse all variant forms together, and thus create a more meaningful list of candidates. The evaluation is based on measuring the quality of ranking the candidates according to their chance to form collocations. To evaluate the results, 3600 expressions were randomly selected and classified into MWE or non-MWE by a human annotator. The performance of the meth</context>
</contexts>
<marker>Habash, Rambow, Roth, 2009</marker>
<rawString>Habash, Nizar, Owen Rambow and Ryan Roth. 2009. A Toolkit for Arabic Tokenization, Diacritization, Morphological Disambiguation, POS Tagging, Stemming and Lemmatization. In the 2nd International Conference on Arabic Language Resources and Tools (MEDAR 2009), pp. 102–109. Cairo, Egypt.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Huu Hoang Hoang</author>
<author>Su Nam Kim</author>
<author>Min-Yen Kan</author>
</authors>
<title>A Re-examination of Lexical Association Measures.</title>
<date>2009</date>
<booktitle>In the Workshop on Multiword Expressions, the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACLIJCNLP</booktitle>
<pages>31--39</pages>
<location>Suntec, Singapore.</location>
<marker>Hoang, Kim, Kan, 2009</marker>
<rawString>Hoang, Huu Hoang, Su Nam Kim and Min-Yen Kan. 2009. A Re-examination of Lexical Association Measures. In the Workshop on Multiword Expressions, the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACLIJCNLP 2009), pp. 31–39, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic Discovery of NonCompositional Compounds in Parallel Data.</title>
<date>1997</date>
<booktitle>In the 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>97--108</pages>
<location>Providence, RI.</location>
<contexts>
<context position="12305" citStr="Melamed (1997)" startWordPosition="1914" endWordPosition="1915"> two well-known among them are “non-substitutability”, when a word in the expression cannot be substituted by a semantically equivalent word, and “single-word paraphrasability”, when the expression can be paraphrased or translated by a single word. These two indications have been exploited differently by different researchers. Van de Cruys and Moir´on (2006) develop an unsupervised method for detecting MWEs using clusters of semantically related words and taking the ratio of the word preference over the cluster preference as an indication of how likely a particular expression is to be an MWE. Melamed (1997) investigates techniques for identifying non-compositional compounds in English-French parallel corpora and emphasises that translation models that take noncompositional compounds into account are more accurate. Moir´on and Tiedemann (2006) use word alignment of parallel corpora to locate the translation of an MWE in a target language and decide whether the original expression is idiomatic or literal. The technique used here is inspired by that of ZarrieB and Kuhn (2009) who rely on the linguistic intuition that if a group of words in one language is translated as a single word in another lang</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>Melamed, I. Dan. 1997. Automatic Discovery of NonCompositional Compounds in Parallel Data. In the 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP 1997), pp. 97–108. Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bego˜na Villada Moir´on</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Identifying idiomatic expressions using automatic word-alignment.</title>
<date>2006</date>
<booktitle>In the Workshop on Multiword Expressions in a Multilingual Context, the 11th Conference of the European Association of Computational Linguistics (EACL</booktitle>
<pages>33--40</pages>
<location>Trento, Italy.</location>
<marker>Moir´on, Tiedemann, 2006</marker>
<rawString>Moir´on, Bego˜na Villada and J¨org Tiedemann. 2006. Identifying idiomatic expressions using automatic word-alignment. In the Workshop on Multiword Expressions in a Multilingual Context, the 11th Conference of the European Association of Computational Linguistics (EACL 2006), pp. 33–40. Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosamund Moon</author>
</authors>
<title>Fixed Expressions and Idioms in English: A Corpus-Based Approach.</title>
<date>1998</date>
<publisher>Clarendom Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="11424" citStr="Moon (1998)" startWordPosition="1777" endWordPosition="1778">erful indication that a phrase is an MWE. Baldwin et al. (2003) classify MWEs, with respect to compositionality, into three categories: (a) non-compositional MWEs, where the expression is semantically impenetrable, such as hot dog, (b) idiosyncratically compositional, where the component words are forced to take semantics unavailable outside the MWE, such as radar footprint, and (c) simply composi4In Arabic, the adjective follows the noun. 21 tional, where the phrase is institutionalized, such as traffic light. This, however, can only serve as an approximation, not as a clear-cut division. As Moon (1998) indicates, compositionality can be viewed more as a gradient along a continuum with no clear demarcations, ranging from conventionalized, fully transparent literal expressions to completely opaque idioms. There are many signs, or indications, of noncompositionality, two well-known among them are “non-substitutability”, when a word in the expression cannot be substituted by a semantically equivalent word, and “single-word paraphrasability”, when the expression can be paraphrased or translated by a single word. These two indications have been exploited differently by different researchers. Van </context>
</contexts>
<marker>Moon, 1998</marker>
<rawString>Moon, Rosamund 1998. Fixed Expressions and Idioms in English: A Corpus-Based Approach. Clarendom Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Multiword Units in Syntactic Parsing.</title>
<date>2004</date>
<booktitle>In Workshop on Methodologies and Evaluation of Multiword Units in RealWorld Applications, the 4th International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<pages>39--46</pages>
<location>Lisbon,</location>
<contexts>
<context position="2298" citStr="Nivre and Nilsson, 2004" startWordPosition="343" endWordPosition="347"> three approaches used in our experiments, and each approach is tested and evaluated in its relevant sub-section. In Section 4 we discuss the results of the experiments. Finally, we conclude in Section 5. 1.1 What Are Multiword Expressions? Multiword expressions (MWEs) are defined as idiosyncratic interpretations that cross word boundaries or spaces (Sag et al., 2002). The exact meaning of an MWE is not directly obtained from its component parts. Accommodating MWEs in NLP applications has been reported to improve tasks, such as text mining (SanJuan and IbekweSanJuan, 2006), syntactic parsing (Nivre and Nilsson, 2004; Attia, 2006), and Machine Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a sequence of words is to form an MWE. This is particularly interesting for statistical techniques which utilize the fact that a large number of MWEs are composed of words that co-occur together more often than can be expected by chance. The compositional</context>
</contexts>
<marker>Nivre, Nilsson, 2004</marker>
<rawString>Nivre, Joakim and Jens Nilsson. 2004. Multiword Units in Syntactic Parsing. In Workshop on Methodologies and Evaluation of Multiword Units in RealWorld Applications, the 4th International Conference on Language Resources and Evaluation (LREC 2004), pp. 39–46. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>Lexical association measures and collocation extraction.</title>
<date>2010</date>
<booktitle>In Language Resources and Evaluation</booktitle>
<pages>44--137</pages>
<contexts>
<context position="4778" citStr="Pecina (2010)" startWordPosition="732" endWordPosition="733"> which use both statistical measures and linguistic filters (Boulaknadel et al. 2009; Duan et al., 2009); and (d) word alignment (Moir´on and Tiedemann, 2006). None of the approaches is without limitations. It is difficult to apply symbolic methods to data with no syntactic annotations. Furthermore, due to corpus size, statistical measures have mostly been applied to bigrams and trigrams, and it becomes more problematic to extract MWEs of more than three words. As a consequence, each approach requires specific resources and is suitable for dealing with only one side of a multifaceted problem. Pecina (2010) evaluates 82 lexical association measures for the ranking of collocation candidates and concludes that it is not possible to select a single best universal measure, and that different measures give different results for different tasks depending on data, language, and the types of MWE that the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A</context>
<context position="21333" citStr="Pecina (2010)" startWordPosition="3408" endWordPosition="3409"> (in percent) of the translation-based approach. 3.3 Corpus-Based Approach The starting point in this approach is the Arabic Gigaword corpus, which is an unannotated collection of texts that contains 848 million words. In this monolingual setting the only practical solution to extract MWEs is to use lexical association measures based on the frequency distribution of candidate MWEs and to detect any idiosyncratic co-occurrence patterns. Association measures are inexpensive language-independent means for discovering recurrent patterns, or habitual collocates. Association measures are defined by Pecina (2010) as mathematical formulas that determine the strength of the association, or degree of connectedness, between two or more words based on 6http://aljazeera.net/portal/search.aspx 7http://www.bbc.co.uk/arabic/ 8http://ar.wikipedia.org/wiki/ 9The hits are combined by taking the aggregate sum of the number of documents returned by the search engines. their occurrences and co-occurrences in a text. The higher the connectedness between words, the better the chance they form a collocation. The corpus is conceived as a randomly generated sequence of words and consecutive bigrams and trigrams in this s</context>
</contexts>
<marker>Pecina, 2010</marker>
<rawString>Pecina, Pavel 2010. Lexical association measures and collocation extraction. In Language Resources and Evaluation (2010), 44:137-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Aline Villavicencio</author>
</authors>
<title>An Evaluation of Methods for the Extraction of Multiword Expressions.</title>
<date>2008</date>
<booktitle>In the Workshop on Multiword Expressions, the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>50--53</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="5126" citStr="Ramisch et al. (2008)" startWordPosition="788" endWordPosition="791">s have mostly been applied to bigrams and trigrams, and it becomes more problematic to extract MWEs of more than three words. As a consequence, each approach requires specific resources and is suitable for dealing with only one side of a multifaceted problem. Pecina (2010) evaluates 82 lexical association measures for the ranking of collocation candidates and concludes that it is not possible to select a single best universal measure, and that different measures give different results for different tasks depending on data, language, and the types of MWE that the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Ara</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Ramisch, Carlos, Paulo Schreiner, Marco Idiart and Aline Villavicencio. 2008. An Evaluation of Methods for the Extraction of Multiword Expressions. In the Workshop on Multiword Expressions, the 6th International Conference on Language Resources and Evaluation (LREC 2008), pp. 50–53. Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword Expressions: A Pain in the Neck for NLP.</title>
<date>2002</date>
<booktitle>In the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002),</booktitle>
<volume>2276</volume>
<pages>1--15</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="2045" citStr="Sag et al., 2002" startWordPosition="303" endWordPosition="306">ts with manual and automatic testing. The paper is organized as follows: in this introduction we describe MWEs and provide a summary of previous related research. Section 2 gives a brief description of the data sources used. Section 3 presents the three approaches used in our experiments, and each approach is tested and evaluated in its relevant sub-section. In Section 4 we discuss the results of the experiments. Finally, we conclude in Section 5. 1.1 What Are Multiword Expressions? Multiword expressions (MWEs) are defined as idiosyncratic interpretations that cross word boundaries or spaces (Sag et al., 2002). The exact meaning of an MWE is not directly obtained from its component parts. Accommodating MWEs in NLP applications has been reported to improve tasks, such as text mining (SanJuan and IbekweSanJuan, 2006), syntactic parsing (Nivre and Nilsson, 2004; Attia, 2006), and Machine Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann Copestake and Dan Flickinger. 2002. Multiword Expressions: A Pain in the Neck for NLP. In the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002), volume 2276 of Lecture Notes in Computer Science, pp. 1–15, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric SanJuan</author>
<author>Fidelia Ibekwe-SanJuan</author>
</authors>
<title>Text mining without document context.</title>
<date>2006</date>
<booktitle>In Information Processing and Management. Volume 42, Issue 6,</booktitle>
<pages>1532--1552</pages>
<marker>SanJuan, Ibekwe-SanJuan, 2006</marker>
<rawString>SanJuan, Eric and Fidelia Ibekwe-SanJuan. 2006. Text mining without document context. In Information Processing and Management. Volume 42, Issue 6, pp. 1532–1552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Van de Cruys</author>
</authors>
<title>Tim and Bego˜na Villada Moir´on.</title>
<date>2006</date>
<booktitle>Computational Linguistics in the Netherlands</booktitle>
<pages>175--190</pages>
<editor>P. Dirix et al. (eds.),</editor>
<marker>Van de Cruys, 2006</marker>
<rawString>Van de Cruys, Tim and Bego˜na Villada Moir´on. 2006. Lexico-Semantic Multiword Expression Extraction. In P. Dirix et al. (eds.), Computational Linguistics in the Netherlands 2006, pp. 175–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
<author>Ann Copestake</author>
<author>Benjamin Waldron</author>
<author>Fabre Lambeau</author>
</authors>
<title>The Lexical Encoding of MWEs.</title>
<date>2004</date>
<booktitle>In the Workshop on Multiword Expressions, the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<pages>80--87</pages>
<location>Barcelona,</location>
<contexts>
<context position="2949" citStr="Villavicencio et al. 2004" startWordPosition="443" endWordPosition="446">ne Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a sequence of words is to form an MWE. This is particularly interesting for statistical techniques which utilize the fact that a large number of MWEs are composed of words that co-occur together more often than can be expected by chance. The compositionality, or decomposability (Villavicencio et al. 2004), of MWEs is also a core issue that presents a challenge for NLP applications because the meaning of the expression is not directly predicted from the meaning of the component words. In this respect, compositionalily varies between phrases that are highly com19 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 19–27, Beijing, August 2010 positional, such as, qdadatun iaskariyyatun, “military base”, and those that show a degree of idiomaticity, such as, madiynatu ’l-maldhiy, “amusement park”, ☎ lit. “city of amusements”. In extreme cases the meaning of the </context>
</contexts>
<marker>Villavicencio, Copestake, Waldron, Lambeau, 2004</marker>
<rawString>Villavicencio, Aline, Ann Copestake, Benjamin Waldron and Fabre Lambeau. 2004. The Lexical Encoding of MWEs. In the Workshop on Multiword Expressions, the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), pp. 80–87. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ˇSpela Vintar</author>
<author>Darja Fiˇser</author>
</authors>
<title>Harvesting MultiWord Expressions from Parallel Corpora.</title>
<date>2008</date>
<booktitle>In the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Marrakech, Morocco.</location>
<marker>Vintar, Fiˇser, 2008</marker>
<rawString>Vintar, ˇSpela and Darja Fiˇser. 2008. Harvesting MultiWord Expressions from Parallel Corpora. In the 6th International Conference on Language Resources and Evaluation (LREC 2008). Marrakech, Morocco.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sina Zarrieß</author>
<author>Jonas Kuhn</author>
</authors>
<title>Exploiting Translational Correspondences for Pattern-Independent MWE Identification.</title>
<date>2009</date>
<booktitle>In the Workshop on Multiword Expressions, the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACLIJCNLP</booktitle>
<pages>23--30</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="5689" citStr="Zarrieß and Kuhn, 2009" startWordPosition="879" endWordPosition="882">hat the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 2 Data Resources In this project we use three data resources for extracting MWEs. These resources differ wi</context>
</contexts>
<marker>Zarrieß, Kuhn, 2009</marker>
<rawString>Zarrieß, Sina and Jonas Kuhn. 2009. Exploiting Translational Correspondences for Pattern-Independent MWE Identification. In the Workshop on Multiword Expressions, the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACLIJCNLP 2009), pp. 23–30. Suntec, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>