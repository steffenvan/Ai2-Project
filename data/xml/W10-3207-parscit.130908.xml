<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003258">
<title confidence="0.9991375">
Labeling Emotion in Bengali Blog Corpus – A Fine Grained
Tagging at Sentence Level
</title>
<author confidence="0.996737">
Dipankar Das
</author>
<affiliation confidence="0.883616333333333">
Department of Computer Science
&amp; Engineering,
Jadavpur University
</affiliation>
<email confidence="0.987562">
dipankar.dipnil2005@gmail.com
</email>
<author confidence="0.972621">
Sivaji Bandyopadhyay
</author>
<affiliation confidence="0.883679666666667">
Department of Computer Science
&amp; Engineering,
Jadavpur University
</affiliation>
<email confidence="0.996045">
sivaji_cse_ju@yahoo.com
</email>
<sectionHeader confidence="0.99735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999950142857143">
Emotion, the private state of a human
entity, is becoming an important topic
in Natural Language Processing (NLP)
with increasing use of search engines.
The present task aims to manually an-
notate the sentences in a web based
Bengali blog corpus with the emotional
components such as emotional expres-
sion (word/phrase), intensity, associ-
ated holder and topic(s). Ekman’s six
emotion classes (anger, disgust, fear,
happy, sad and surprise) along with
three types of intensities (high, general
and low) are considered for the sen-
tence level annotation. Presence of dis-
course markers, punctuation marks,
negations, conjuncts, reduplication,
rhetoric knowledge and especially
emoticons play the contributory roles
in the annotation process. Different
types of fixed and relaxed strategies
have been employed to measure the
agreement of the sentential emotions,
intensities, emotional holders and top-
ics respectively. Experimental results
for each emotion class at word level on
a small set of the whole corpus have
been found satisfactory.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976244444445">
Human emotion described in texts is an impor-
tant cue for our daily communication but the
identification of emotional state from texts is
not an easy task as emotion is not open to any
objective observation or verification (Quirk et
al., 1985). Emails, weblogs, chat rooms, online
forums and even twitter are considered as the
affective communication substrates to analyze
the reaction of emotional catalysts. Among
these media, blog is one of the communicative
and informative repository of text based emo-
tional contents in the Web 2.0 (Lin et al.,
2007).
Rapidly growing web users from multilin-
gual communities focus the attention to im-
prove the multilingual search engines on the
basis of sentiment or emotion. Major studies
on Opinion Mining and Sentiment Analyses
have been attempted with more focused per-
spectives rather than fine-grained emotions.
The analyses of emotion or sentiment require
some basic resource. An emotion-annotated
corpus is one of the primary ones to start with.
The proposed annotation task has been car-
ried out at sentence level. Three annotators
have manually annotated the Bengali blog sen-
tences retrieved from a web blog archive1 with
Ekman’s six basic emotion tags (anger (A),
disgust (D), fear (F), happy (H), sad (Sa) and
surprise (Su)). The emotional sentences are
tagged with three types of intensities such as
high, general and low. The sentences of non-
emotional (neutral) and multiple (mixed) cate-
gories are also identified. The identification of
emotional words or phrases and fixing the
scope of emotional expressions in the sen-
tences are carried out in the present task. Each
of the emoticons is also considered as individ-
ual emotional expressions. The emotion holder
and relevant topics associated with the emo-
tional expressions are annotated considering
the punctuation marks, conjuncts, rhetorical
structures and other discourse information. The
knowledge of rhetorical structure helps in re-
moving the subjective discrepancies from the
</bodyText>
<footnote confidence="0.905788">
1 www.amarblog.com
</footnote>
<page confidence="0.981432">
47
</page>
<note confidence="0.957436">
Proceedings of the 8th Workshop on Asian Language Resources, pages 47–55,
Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing
</note>
<bodyText confidence="0.999202411764706">
writer’s point of view. The annotation scheme
is used to annotate 123 blog posts containing
4,740 emotional sentences having single emo-
tion tag and 322 emotional sentences for mixed
emotion tagss along with 7087 neutral sen-
tences in Bengali. Three types of standard
agreement measures such as Cohen’s kappa
(x) (Cohen, 1960; Carletta, 1996), Measure of
Agreement on Set-valued Items (MASI) (Pas-
sonneau, 2004) and agr (Wiebe et al., 2005)
metrics are employed for annotating the emo-
tion related components. The relaxed agree-
ment schemes like MASI and agr are specially
considered for fixing the boundaries of emo-
tional expressions and topic spans in the emo-
tional sentences. The inter annotator agreement
of some emotional components such as senten-
tial emotions, holders, topics show satisfactory
performance but the sentences of mixed emo-
tion and intensities of general and low show
the disagreement. A preliminary experiment
for word level emotion classification on a
small set of the whole corpus yielded satisfac-
tory results.
The rest of the paper is organized as fol-
lows. Section 2 describes the related work. The
annotation of emotional expressions, sentential
emotion and intensities are described in Sec-
tion 3. In Section 4, the annotation scheme for
emotion holder is described. The issues of
emotional topic annotation are discussed in
Section 5. Section 6 describes the preliminary
experiments carried out on the annotated cor-
pus. Finally, Section 7 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999914626865672">
One of the most well known tasks of annotat-
ing the private states in texts is carried out by
(Wiebe et al., 2005). They manually annotated
the private states including emotions, opinions,
and sentiment in a 10,000-sentence corpus (the
MPQA corpus) of news articles. The opinion
holder information is also annotated in the
MPQA corpus but the topic annotation task has
been initiated later by (Stoyanov and Cardie,
2008a). In contrast, the present annotation
strategy includes the fine-grained emotion
classes and specially handles the emoticons
present in the blog posts.
(Alm et al., 2005) have considered eight
emotion categories (angry, disgusted, fearful,
happy, sad, positively surprised, negatively
surprised) to accomplish the emotion annota-
tion task at sentence level. They have manually
annotated 1580 sentences extracted from 22
Grimms’ tales. The present approach discusses
the issues of annotating unstructured blog text
considering rhetoric knowledge along with the
attributes, e.g. negation, conjunct, reduplica-
tion etc.
Mishne (2005) experimented with mood
classification in a blog corpus of 815,494 posts
from Livejournal
(http://www.livejournal.com), a free weblog
service with a large community. (Mihalcea and
Liu, 2006) have used the same data source for
classifying the blog posts into two particular
emotions – happiness and sadness. The blog
posts are self-annotated by the blog writers
with happy and sad mood labels. In contrast,
the present approach includes Ekman’s six
emotions, emotion holders and topics to ac-
complish the whole annotation task.
(Neviarouskaya et al., 2007) collected 160
sentences labeled with one of the nine emo-
tions categories (anger, disgust, fear, guilt, in-
terest, joy, sadness, shame, and surprise) and a
corresponding intensity value from a corpus of
online diary-like blog posts. On the other hand,
(Aman and Szpakowicz, 2007) prepare an
emotion-annotated corpus with a rich set of
emotion information such as category, inten-
sity and word or phrase based expressions. The
present task considers all the above emotion
information during annotation. But, the present
annotation task additionally includes the com-
ponents like emotion holder, single or multiple
topic spans.
The emotion corpora for Japanese were built
for recognizing emotions (Tokuhisa et al.,
2008). An available emotion corpus in Chinese
is Yahoo!’s Chinese news
(http://tw.news.yahoo.com), which is used for
Chinese emotion classification of news readers
(Lin, et al., 2007). The manual annotation of
eight emotional categories (expect, joy, love,
surprise, anxiety, sorrow, angry and hate)
along with intensity, holder, word/phrase, de-
gree word, negative word, conjunction, rheto-
ric, punctuation and other linguistic expres-
sions are carried out at sentence, paragraph as
well as document level on 1,487 Chinese blog
documents (Quan and Ren, 2009). In addition
</bodyText>
<page confidence="0.998553">
48
</page>
<bodyText confidence="0.999849888888889">
to the above emotion entities, the present ap-
proach also includes the annotation of single or
multiple emotion topics in a target span.
Recent study shows that non-native English
speakers support the growing use of the Inter-
net 2. This raises the demand of linguistic re-
sources for languages other than English. Ben-
gali is the fifth popular language in the World,
second in India and the national language in
Bangladesh but it is less computerized com-
pared to English. To the best of our knowl-
edge, at present, there is no such available cor-
pus that is annotated with detailed linguistic
expressions for emotion in Bengali or even for
other Indian languages. Thus we believe that
this corpus would help the development and
evaluation of emotion analysis systems in
Bengali.
</bodyText>
<sectionHeader confidence="0.995203" genericHeader="method">
3 Emotion Annotation
</sectionHeader>
<bodyText confidence="0.999927470588235">
Random collection of 123 blog posts contain-
ing a total of 12,149 sentences are retrieved
from Bengali web blog archive 3 (especially
from comics, politics, sports and short stories)
to prepare the corpus. No prior training was
provided to the annotators but they were in-
structed to annotate each sentence of the blog
corpus based on some illustrated samples of
the annotated sentences. Specially for annotat-
ing the emotional expressions and topic(s) in
emotional sentences, the annotators are free in
selecting the texts spans. This annotation
scheme is termed as relaxed scheme. For other
emotional components, the annotators are
given items with fixed text spans and in-
structed to annotation the items with definite
tags.
</bodyText>
<subsectionHeader confidence="0.999">
3.1 Identifying Emotional Expressions for
Sentential Emotion and Intensity
</subsectionHeader>
<bodyText confidence="0.999967625">
The identification of emotion or affect affixed
in the text segments is a puzzle. But, the puzzle
can be solved partially using some lexical
clues (e.g. discourse markers, punctuation
marks (sym), negations (NEG), conjuncts
(CONJ), reduplication (Redup)), structural
clues (e.g. rhetoric and syntactic knowledge)
and especially some direct affective clues (e.g.
</bodyText>
<footnote confidence="0.964708">
2 http://www.internetworldstats.com/stats.htm
3 www.amarblog.com
</footnote>
<bodyText confidence="0.999533461538462">
emoticons (emo_icon)). The identification of
structural clues indeed requires the identifica-
tion of lexical clues.
Rhetorical Structure Theory (RST) de-
scribes the various parts of a text, how they
can be arranged and connected to form a whole
text (Azar, 1999). The theory maintains that
consecutive discourse elements, termed text
spans, which can be in the form of clauses,
sentences, or units larger than sentences, are
related by a relatively small set (20–25) of rhe-
torical relations (Mann and Thompson, 1988).
RST distinguishes between the part of a text
that realizes the primary goal of the writer,
termed as nucleus, and the part that provides
supplementary material, termed satellite. The
separation of nucleus from satellite is done
based on punctuation marks (, ! @?), emoti-
cons, discourse markers (cam jehetu [as], mrq
jemon [e.g.], Tr,.Tr karon [because], alta mane
[means]), conjuncts (ea; ebong [and], F4in
kintu [but], amTT athoba [or]), causal verbs
(4w ghotay [caused]) if they are explicitly
specified in the sentences.
Use of emotion-related words is not the sole
means of expressing emotion. Often a
sentence, which otherwise may not have an
emotional word, may become emotion bearing
depending on the context or underlying
semantic meaning (Aman and Szpakowicz,
2007). An empirical analysis of the blog texts
shows two types of emotional expressions. The
first category contains explicitly stated
emotion word (EW) or phrases (EP) mentioned
in the nucleus or in the satellite. Another
category contains the implicit emotional clues
that are identified based on the context or from
the metaphoric knowledge of the expressions.
Sometimes, the emotional expressions contain
direct emotion words (EW) (cam koutuk
[joke], zuir­r ananda [happy], zP6-4
ashcharjyo [surprise]), reduplication (Redup)
(3r-7 3r-7 sanda sanda [doubt with fear],
question words (EW_Q) (i�y ki [what], wg kobe
[when]), colloquial words (kTm kshyama
[perdon]) and foreign words (,Tm;f thanku
[thanks], carr gossya [anger]). On the other
hand, the emotional expressions contain
indirect emotion words e.g. proverbs, idioms
(tea 1a taser ghar [weakly built], 79w grri-
hadaho [family disturbance]) and emoticons
(0,0).
</bodyText>
<page confidence="0.996743">
49
</page>
<bodyText confidence="0.999854653846154">
A large number of emoticons (emo_icon)
present in the Bengali blog texts vary accord-
ing to their emotional categories and slant.
Each of the emoticons is treated as individual
emotional expression and its corresponding
intensity is set based on the image denoted by
the emoticon. The labeling of the emoticons
with Ekman’s six emotion classes is verified
through the inter-annotator agreement that is
considered for emotion expressions.
The intensifiers (!�� khub [too much/very],
aciff anek [huge/large], &amp;quot;#$� bhishon
[heavy/too much]) associated with the emo-
tional phrases are also acknowledged in anno-
tating sentential intensities. As the intensifiers
depend solely on the context, their identifica-
tion along with the effects of negation and con-
juncts play a role in annotating the intensity.
Negations (iT na [no], zrq noy [not]) and con-
juncts freely occur in the sentence and change
the emotion of the sentence. For that very rea-
son, a crucial analysis of negation and con-
juncts is carried out both at intra and inter
phrase level to obtain the sentential emotions
and intensities. An example set of the anno-
tated blog corpus is shown in Figure 1.
</bodyText>
<equation confidence="0.8815605625">
&lt;ES_S%&gt;&lt;hold&amp;r&gt;M5,&apos;M:&lt;/hold&amp;r&gt; &amp;quot; i(
&lt;sym&gt;!&lt;/sym&gt; &lt;EW_D&gt;CA*R&lt;/EW_D&gt;
ti ?&lt;/ES_S%&gt;
&lt;ES_A&gt;&lt;ES_Su&gt;ft# &lt;EW_Su&gt;&lt;EW_Q&gt;
f�7&lt;/EW_Q&gt;&lt;/EW_Su&gt; ��,�-q
&lt;EW_Su&gt;&lt;EW_Q&gt; R7&lt;/EW_Q&gt;&lt;/EW_Su&gt;
*rF&lt;EW_Su&gt;!&lt;/EW_Su&gt; &lt;R&amp;-
dup&gt;&lt;EW_A&gt;GdtqUTM&lt;/EW_A&gt;&lt;/R&amp;dup&gt; z&amp;quot;5�.
&apos;F MC-q I WMTCW &lt;EW_F&gt;M0~~ &lt;/EW_F&gt;
fsau 1TCaa
&lt;NEG&gt;Fq&lt;/NEG&gt; I &lt;/ES_Su&gt;&lt;/ES_A&gt;
&lt;ES_H&gt;�f1��d &lt;top2c&gt; &lt;/top2c&gt; 13~e
f?M ei &lt;EW_H&gt;
4~~
~~&lt;/EW_H&gt; 3TC-T
13t T &lt;/ES_H&gt;
</equation>
<figureCaption confidence="0.57852">
“Figure 1. Annotated sample of the corpus”
</figureCaption>
<subsectionHeader confidence="0.9732915">
3.2 Agreement of Sentential Emotion and
Intensity
</subsectionHeader>
<bodyText confidence="0.9999714">
Three annotators identified as A1, A2 and A3
have used an open source graphical tool to
carry out the annotation 4. As the Ekman’s
emotion classes and intensity types belong to
some definite categories, the annotation
</bodyText>
<sectionHeader confidence="0.435678" genericHeader="method">
4 http://gate.ac.uk/gate/doc/releases.html
</sectionHeader>
<bodyText confidence="0.999920290322581">
agreement for emotion and intensities are
measured using standard Cohen&apos;s kappa coef-
ficient (tc) (Cohen, 1960). The annotation
agreement for emoticons is also measured us-
ing the kappa metric. It is a statistical measure
of inter-rater agreement for qualitative (cate-
gorical) items. It measures the agreement be-
tween two raters who separately classify items
into some mutually exclusive categories.
The agreement of classifying sentential in-
tensities into three classes (high, general and
low) is also measured using kappa (x). The
intensities of mixed emotional sentences are
also considered. Agreement results of emo-
tional, non-emotional and mixed sentences,
emoticons, along with results for each emotion
class, intensity types are shown in Table 1.
Sentential emotions with happy, sad or sur-
prise classes produce comparatively higher
kappa coefficient than the other emotion
classes as the emotional expressions of these
types were explicitly specified in the blog
texts. It has been observed that the emotion
pairs such as “sad-anger” and “anger-disgust”
often cause the trouble in distinguishing the
emotion at sentence level. Mixed emotion
category, general and low intensity types give
poor agreement results as expected. Instead of
specifying agreement results of emoticons for
each emotion class, the average results for the
three annotation sets are shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.999825">
3.3 Agreement of Emotional Expressions
</subsectionHeader>
<bodyText confidence="0.998470333333333">
Emotional expressions are words or strings of
words that are selected by the annotators. The
agreement is carried out between the sets of
text spans selected by the two annotators for
each of the emotional expressions. As there is
no fixed category in this case, we have em-
ployed two different strategies instead of
kappa (x) to calculate the agreement between
annotators. Firstly, we chose the measure of
agreement on set-valued items (MASI) (Pas-
sonneau, 2006) that was used for measuring
agreement on co reference annotation (Passon-
neau, 2004) and in the semantic and pragmatic
annotation (Passonneau, 2006). MASI is a dis-
tance between sets whose value is 1 for identi-
cal sets, and 0 for disjoint sets. For sets A and
B it is defined as: MASI = J * M, where the
Jaccard metric is:
</bodyText>
<page confidence="0.718313">
50
</page>
<equation confidence="0.996557666666667">
s = |AnB |/ |AUB|
Monotonicity (M) is defined as,
ifA B
_
2 / 3, ifAcBorBcA
1/3,ifAnB#0,A-B#0,
</equation>
<bodyText confidence="0.9987341">
Secondly, the annotators will annotate dif-
ferent emotional expressions by identifying the
responsible text anchors and the agreement is
measured using agr metric (Wiebe et al.,
2005). If A and B are the sets of anchors anno-
tated by annotators a and b, respectively, agr is
a directional measure of agreement that meas-
ures what proportion of a was also marked by
b. Specifically, we compute the agreement of b
to a as:
</bodyText>
<equation confidence="0.917690666666667">
agr(a  ||b) _  |AmatchingB |
 ||
A
</equation>
<bodyText confidence="0.998760818181818">
The agr (a ||b) metric corresponds to the re-
call if a is the gold standard and b the system,
and to precision, if b is the gold standard and a
is the system. The results of two agreement
strategies for each emotion class are shown in
Table 1. The annotation agreement of
emotional expressions produces slightly less
values for both kappa and agr. It leads to the
fact that the relaxed annotation scheme that is
provided for fixing the boundaries of the
expressions causes the disagreements.
</bodyText>
<sectionHeader confidence="0.996894" genericHeader="method">
4 Identifying Emotion Holder
</sectionHeader>
<bodyText confidence="0.999439076923077">
The source or holder of an emotional expres-
sion is the speaker or writer or experiencer.
The main criteria considered for annotating
emotion holders are based on the nested source
hypothesis as described in (Wiebe et al.,
2005). The structure of Bengali blog corpus (as
shown in Figure 2) helps in the holder annota-
tion process. Sometimes, the comments of one
blogger are annotated by other bloggers in the
blog posts. Thus the holder annotation task in
user comments sections was less cumbersome
than annotating the holders inscribed in the
topic section.
</bodyText>
<table confidence="0.999645290322581">
Classes Agreement (pair of annota-
(# Sentences tors)
or Instances) A1-A2 A2-A3 A1-A3 Avg.
Emotion / 0.88 0.83 0.86 0.85
Non-Emotion
(5,234/7,087)
Happy (804) 0.79 0.72 0.83 0.78
Sad (826) 0.82 0.75 0.72 0.76
Anger (765) 0.75 0.71 0.69 0.71
Disgust (766) 0.76 0.69 0.77 0.74
Fear (757) 0.65 0.61 0.65 0.63
Surprise (822) 0.84 0.82 0.85 0.83
Mixed (322) 0.42 0.21 0.53 0.38
High (2,330) 0.66 0.72 0.68 0.68
General 0.42 0.46 0.48 0.45
(1,765)
Low (1345) 0.21 0.34 0.26 0.27
Emoticons 0.85 0.73 0.84 0.80
w.r.t six Emo-
tion Classes
(678)
Emoticons 0.72 0.66 0.63 0.67
w.r.t three In-
tensities
Emotional Ex- 0.64 0.61 0.66 0.63
pressions
(7,588)
[MASI]
Emotional Ex- 0.67 0.63 0.68 0.66
pressions
(7,588) [agr]
</table>
<tableCaption confidence="0.865208666666667">
Table 1: Inter-Annotator Agreements for sen-
tence level Emotions, Intensities, Emoticons
and Emotional Expressions
</tableCaption>
<figure confidence="0.640337555555555">
-&lt;DOC docid = xyz&gt;
-&lt;Topic&gt;.... &lt;/Topic&gt;
-&lt;User Comments&gt;
-&lt;U uid=1&gt;... &lt;/U&gt;
-&lt;U uid=2&gt;... &lt;/U&gt;
-&lt;U uid=3&gt;....
-&lt;U uid=1&gt;... &lt;/U&gt; ...&lt;/U&gt;...
&lt;/User Comments&gt;
&lt;/DOC&gt;
</figure>
<figureCaption confidence="0.5948285">
“Figure. 2. General structure of a blog docu-
ment”
</figureCaption>
<bodyText confidence="0.986061">
Prior work in identification of opinion hold-
ers has sometimes identified only a single
opinion per sentence (Bethard et al., 2004),
</bodyText>
<figure confidence="0.987062714285714">
1,
#0
andB A
-
0
0,
ifAnB
</figure>
<page confidence="0.99561">
51
</page>
<bodyText confidence="0.999601777777778">
and sometimes several (Choi et al., 2005). As
the blog corpus has sentence level emotion
annotations, the former category is adopted.
But, it is observed that the long sentences con-
tain more than one emotional expression and
hence associated with multiple emotion hold-
ers (EH). All probable emotion holders of a
sentence are stored in an anchoring vector suc-
cessively according to their order of occur-
rence.
The annotation of emotion holder at sen-
tence level requires the knowledge of two ba-
sic constraints (implicit and explicit) sepa-
rately. The explicit constraints qualify single
prominent emotion holder that is directly in-
volved with the emotional expression whereas
the implicit constraints qualify all direct and
indirect nested sources as emotion holders. For
example, in the following Bengali sentences,
the pattern shown in bold face denotes the
emotion holder. In the second example, the
appositive case (e.g. mum V (Ram’s pleasure))
is also identified and placed in the vector by
removing the inflectional suffix (-ea in this
case). Example 2 and Example 3 contain the
emotion holders qw (Ram) and widP&apos;w f-om
(Nasrin Sultana) based on implicit constraints.
</bodyText>
<equation confidence="0.985348777777778">
Example 1. EH_Vector: &lt; qrgr &gt;
qwq &amp;quot;#$K INI-11ti aT&amp;quot;~
(Sayan) (bhishon) (anondo) (anubhob)
qiuqR-
(korechilo)
Sayan felt very happy.
Example 2. EH_Vector: &lt; wg5�, qx &gt;
~~~5~ a ~&amp;quot;~ ����+- F WIMN
(Rashed) (anubhob) (korechilo) (je) (Ramer)
V a6tlif
(sukh) (antohin)
Rashed felt that Ram’s pleasure is endless.
Example 3. EH_Vector: &lt;m�, &apos;�&apos;�, w1VP-- T- w
&gt;
���� &apos;�&apos;� ��- : ��� ������ ��-�����
(GeduChaCha) (bole) (ami) (Nasrin Sultanar)
T-ma ����� c499q C-WRI
(dookher) (kathate) (kende) (feli)
</equation>
<bodyText confidence="0.9841055">
Gedu Chacha says: No my sister, I fall into cry
on the sad speech of Nasrin Sultana
</bodyText>
<subsectionHeader confidence="0.970812">
4.1 Agreement of Emotion Holder
Annotation
</subsectionHeader>
<bodyText confidence="0.988709461538461">
The emotion holders containing multi word
Named Entities (NEs) are assumed as single
emotion holders. As there is no agreement dis-
crepancy in selecting the boundary of the sin-
gle or multiple emotion holders, we have used
the standard metric, Cohen’s kappa (x) for
measuring the inter-annotator agreement. Each
of the elementary emotion holders in an an-
choring vector is treated as a separate emotion
holder and the agreement between two annota-
tors is carried out on each separate entity. It is
to be mentioned that the anchoring vectors
provided by the two annotators may be dis-
joint.
To emphasize the fact, a different technique
is employed to measure the annotation agree-
ment. If X is a set of emotion holders selected
by the first annotator and Y is a set of emotion
holders selected by the second annotator for an
emotional sentence containing multiple emo-
tion holders, inter-annotator agreement IAA
for that sentence is equal to quotient of number
of emotion holders in X and Y intersection
divided by number of emotion holders in X
and Y union:
IAA = X f1 Y / X U Y
Two types of agreement results per emotion
class for annotating emotion holders (EH) are
shown in Table 2. Both types of agreements
have been found satisfactory and the difference
between the two agreement types is signifi-
cantly less. The small difference indicates the
minimal error involved in the annotation proc-
ess. It is found that the agreement is highly
moderate in case of single emotion holder, but
is less in case of multiple holders. The dis-
agreement occurs mostly in the case of satisfy-
ing the implicit constrains but some issues are
resolved by mutual understanding.
</bodyText>
<sectionHeader confidence="0.885732" genericHeader="method">
5 Topic Annotation and Agreement
</sectionHeader>
<bodyText confidence="0.999965285714286">
Topic is the real world object, event, or ab-
stract entity that is the primary subject of the
opinion as intended by the opinion holder
(Stoyanov and Cardie, 2008). They mention
that the topic identification is difficult within
the single target span of the opinion as there
are multiple potential topics, each identified
</bodyText>
<page confidence="0.996297">
52
</page>
<bodyText confidence="0.999877666666667">
with its own topic span and the topic of an
opinion depends on the context in which its
associated opinion expression occurs. Hence,
the actual challenge lies on identification of the
topics spans from the emotional sentences. The
writer’s emotional intentions in a sentence are
reflected in the target span by mentioning one
or more topics that are related to the emotional
expressions. Topics are generally distributed in
different text spans of writer’s text and can be
distinguished by capturing the rhetorical struc-
ture of the text.
</bodyText>
<table confidence="0.999677588235294">
Emotion Agreement between pair of anno-
Classes tators (1c) [IAA]
[# Sen- A1-A2 A2-A3 A1-A3 Avg.
tences,
# Holders]
Happy (0.87) (0.79) (0.76) (0.80)
[804, 918] [0.88] [0.81] [0.77] [0.82]
Sad (0.82) (0.85) (0.78) (0.81)
[826, 872] [0.81] [0.83] [0.80] [0.81]
Anger (0.80) (0.75) (0.74) (0.76)
[765,780] [0.79] [0.73] [0.71] [0.74]
Disgust (0.70) (0.72) (0.83) (0.75)
[766, 770] [0.68] [0.69] [0.84] [0.73]
Fear (0.85) (0.78) (0.79) (0.80)
[757, 764] [0.82] [0.77] [0.81] [0.80]
Surprise (0.78) (0.81) (0.85) (0.81)
[822, 851] [0.80] [0.79] [0.83] [0.80]
</table>
<tableCaption confidence="0.9711085">
Table 2: Inter-Annotator Agreement for Emo-
tion Holder Annotation
</tableCaption>
<bodyText confidence="0.998445">
In blog texts, it is observed that an emotion
topic can occur in nucleus as well as in satel-
lite. Thus, the whole sentence is assumed as
the scope for the potential emotion topics. The
text spans containing emotional expression and
emotion holder can also be responsible for be-
ing the candidate seeds of target span. In Ex-
ample 3 of Section 4, the target span (iu i
Twiiw T-siq- w4Tcz- ‘sad speech of Nasrin Sul-
tana’) contains emotion holder (gm5W TPFF4K
‘Nasrin Sultana’) as well as the emotional ex-
pression (T.sa w4Tcz- ‘sad speech’) For that
reason, the annotators are instructed to con-
sider the whole sentence as their target span
and to identify one or more topics related to
the emotional expressions in that sentence.
As the topics are multi word components or
string of words, the scope of the individual
topics inside a target span is hard to identify.
To accomplish the goal, we have not used the
standard metrics Cohen’s kappa (x). We em-
ployed MASI and agr metric (as mentioned in
Section 3) for measuring the agreement of
topic spans annotation. The emotional sen-
tences containing single emotion topic has
shown less disagreement than the sentences
that contain multiple topics. It is observed that
the agreement for annotating target span is (--
0.9). It means that the annotation is almost sat-
isfactory. But, the disagreement occurs in an-
notating the boundaries of topic spans. The
inter-annotator agreement for each emotion
class is shown in Table 3. The selection of
emotion topic from other relevant topics
causes the disagreement.
</bodyText>
<table confidence="0.999684666666667">
Emotion Agreement between Pair of annota-
Classes tors (MASI) [agr]
[# Sen- A1-A2 A2-A3 A1-A3 Avg
tences,
# topics]
Happy (0.83) (0.81) (0.79) (0.81)
[804, 848] [0.85] [0.83] [0.82] [0.83]
Sad (0.84) (0.77) (0.81) (0.80)
[826, 862] [0.86] [0.79] [0.83] [0.82]
Anger (0.80) (0.81) (0.86) (0.82)
[765,723] [0.78] [0.78] [0.84] [0.80]
Disgust (0.77) (0.78) (0.72) (0.75)
[766, 750] [0.76] [0.74] [0.70] [0.73]
Fear (0.78) (0.77) (0.79)
[757, 784] [0.79] [0.80] [0.81] (0.78)
[0.80
Surprise (0.90) (0.85) (0.82) (0.85)
[822, 810] [0.86] [0.82] [0.80] [0.82]
</table>
<tableCaption confidence="0.859019">
Table 3: Inter-Annotator Agreement for Topic
Annotation
</tableCaption>
<sectionHeader confidence="0.9984325" genericHeader="method">
6 Experiments on Emotion Classifica-
tion
</sectionHeader>
<bodyText confidence="0.999826076923077">
A preliminary experiment (Das and Bandyop-
adhyay, 2009b) was carried out on a small set
of 1200 sentences of the annotated blog corpus
using Conditional Random Field (CRF)
(McCallum et al., 2001). We have employed
the same corpus and similar features (e.g. POS,
punctuation symbols, sentiment words etc.) for
classifying the emotion words using Support
Vector Machine (SVM) (Joachims, 1999). The
results on 200 test sentences are shown in Ta-
ble 4. The results of the automatic emotion
classification at word level show that SVM
outperforms CRF significantly. It is observed
</bodyText>
<page confidence="0.99561">
53
</page>
<bodyText confidence="0.997691375">
that both classifiers fail to identify the emotion
words that are enriched by morphological in-
flections. Although SVM outperforms CRF but
both CRF and SVM suffer from sequence la-
beling and label bias problem with other non-
emotional words of a sentence. (For error
analysis and detail experiments, see Das and
Bandyopadhyay, 2009b).
</bodyText>
<table confidence="0.999541222222222">
Emotion Test Set
Classes (# Words)
CRF SVM
Happy (106) 67.67 80.55
Sad (143) 63.12 78.34
Anger (70) 51.00 66.15
Disgust (65) 49.75 53.35
Fear (37) 52.46 64.78
Surprise (204) 68.23 79.37
</table>
<tableCaption confidence="0.9818595">
Table 4: Word level Emotion tagging Accura-
cies (in %) using CRF and SVM
</tableCaption>
<bodyText confidence="0.999716342857143">
Another experiment (Das and Bandyop-
adhyay, 2009a) was carried out on a small set
of 1300 sentences of the annotated blog cor-
pus. They assign any of the Ekman’s (1993)
six basic emotion tags to the Bengali blog sen-
tences. Conditional Random Field (CRF)
based word level emotion classifier classifies
the emotion words not only in emotion or non-
emotion classes but also the emotion words
into Ekman’s six emotion classes. Corpus
based and sense based tag weights that are cal-
culated for each of the six emotion tags are
used to identify sentence level emotion tag.
Sentence level accuracies for each emotion
class were also satisfactory.
Knowledge resources can be leveraged in
identifying emotion-related words in text and
the lexical coverage of these resources may be
limited, given the informal nature of online
discourse (Aman and Szpakowicz, 2007). The
identification of direct emotion words
incorporates the lexicon lookup approach. A
recently developed Bengali WordNet Affect
lists (Das and Bandyopadhyay, 2010) have
been used in determining the directly stated
emotion words. But, the affect lists covers only
52.79% of the directly stated emotion words.
The fact leads not only to the problem of
morphological enrichment but also to refer the
problem of identifying emoticons, proverbs,
idioms and colloquial or foreign words. But, in
our experiments, the case of typographical er-
rors and orthographic features (for e.g. �srsrsrsr
‘disgusting’, arm ‘surprising’) that express or
emphasize emotion in text are not considered.
</bodyText>
<sectionHeader confidence="0.998439" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99997425">
The present task addresses the issues of identi-
fying emotional expressions in Bengali blog
texts along with the annotation of sentences
with emotional components such as intensity,
holders and topics. Nested sources are consid-
ered for annotating the emotion holder infor-
mation. The major contribution in the task is
the identification and fixing the text spans de-
noted for emotional expressions and multiple
topics in a sentence. Although the preliminary
experiments carried out on the small sets of the
corpus show satisfactory performance, but the
future task is to adopt a corpus-driven ap-
proach for building a lexicon of emotion words
and phrases and extend the emotion analysis
tasks in Bengali.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999178038461539">
Aman Saima and Stan Szpakowicz. 2007. Identify-
ing Expressions of Emotion in Text. V. Ma-
toušek and P. Mautner (Eds.): TSD 2007, LNAI,
vol. 4629, pp.196-205.
Azar, M. 1999. Argumentative Text as Rhetorical
Structure: An Application of Rhetorical Struc-
ture Theory. Argumentation, vol 13, pp. 97–114.
Bethard Steven, Yu H., Thornton A., Hatzivassi-
loglou V., and Jurafsky, D. 2004. Automatic Ex-
traction of Opinion Propositions and their Hold-
ers. In AAAI Spring Symposium on Exploring
Attitude and Affect in Text: Theories and Appli-
cations.
Carletta Jean. 1996. Assessing Agreement on Clas-
sification Tasks: The Kappa Statistic. Computa-
tional Linguistics, vol. 22(2), pp.249-254.
Choi, Y., Cardie, C., Riloff, E., and Patwardhan, S.
2005. Identifying Sources of Opinions with
Conditional Random Fields and Extraction Pat-
terns. Human Language Technology / Empirical
Method in Natural Language Processing.
Alm, Cecilia Ovesdotter, Dan Roth, and Richard
Sproat. 2005. Emotions from text: Machine
learning for text-based emotion prediction. Hu-
man Language Technology - Empirical Method
in Natural Language Processing, pp. 579-586.
</reference>
<page confidence="0.978512">
54
</page>
<reference confidence="0.99983053164557">
Cohen, J. 1960. A coefficient of agreement for
nominal scales. Educational and Psychological
Measurement, vol. 20, pp. 37–46.
Das Dipankar and Sivaji Bandyopadhyay. 2009a.
Word to Sentence Level Emotion Tagging for
Bengali Blogs. Association for Computational
Linguistics –International Joint Conference of
Natural Language Processing-2009, pp. 149-
152. Suntec, Singapore.
Das Dipankar and Sivaji Bandyopadhyay. 2009b.
Emotion Tagging – A Comparative Study on
Bengali and English Blogs. 7th International
Conference On Natural Language Processing-
09, pp.177-184, India.
Das Dipankar and Sivaji Bandyopadhyay. 2010.
Developing Bengali WordNet Affect for Analyz-
ing Emotion. International Conference on the
Computer Processing of Oriental Languages-
International Conference on Software Engineer-
ing and Knowledge Engineering-2010, USA.
Ekman, P. 1992. An Argument for Basic Emotions.
Cognition and Emotion. vol. 6, pp.169–200.
Joachims, Thorsten. 1998. Text Categorization with
Support Machines: Learning with Many Rele-
vant Features. In European Conference on Ma-
chine Learning (ECML),137-142
Lin K. H.-Y., C. Yang and H.-H. Chen. 2007. What
Emotions News Articles Trigger in Their Read-
ers?. Proceedings of SIGIR, pp. 733-734.
Mann, W. C. and S. A. Thompson. 1988. Rhetorical
Structure Theory: Toward a Functional Theory
of Text Organization, TEXT 8, pp. 243–281.
McCallum Andrew, Fernando Pereira and John
Lafferty. 2001. Conditional Random Fields:
Probabilistic Models for Segmenting and label-
ing Sequence Data. ISBN, 282 – 289.
Mihalcea Rada and Hugo Liu. 2006. A corpus-
based approach to finding happiness. Association
for the Advancement of Artificial Intelligence,
pp. 139-144.
Mishne Gilad. 2005. Emotions from text: Machine
learning for text-based emotion prediction.
SIGIR’05, pp. 15-19.
Neviarouskaya Alena, Helmut Prendinger, and Mi-
tsuru Ishizuka. 2007. Textual Affect Sensing for
Social and Expressive Online Communication.
2nd international conference on Affective Com-
puting and Intelligent Interaction, pp. 218-229.
Passonneau, R. 2004. Computing reliability for
coreference annotation. Language Resources and
Evaluation, Lisbon.
Passonneau, R.J. 2006. Measuring agreement on
set-valued items (MASI) for semantic and prag-
matic annotation. Language Resources and
Evaluation.
Quan Changqin and Fuji Ren. 2009. Construction
of a Blog Emotion Corpus for Chinese Emo-
tional Expression Analysis. Empirical Method in
Natural Language Processing- Association for
Computational Linguistics, pp. 1446-1454, Sin-
gapore
Quirk, R., Greenbaum, S., Leech, G., Svartvik, J.
1985. A Comprehensive Grammar of the English
Language. Longman, New York.
Stoyanov, V., and C. Cardie. 2008. Annotating top-
ics of opinions. Language Resources and
Evaluation.
Tokuhisa Ryoko, Kentaro Inui, and Yuji. Matsu-
moto. 2008. Emotion Classification Using Mas-
sive Examples Extracted from the Web. COL-
ING 2008, pp. 881-888.
Wiebe Janyce, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and
emotions in language. Language Resources and
Evaluation, vol. 39, pp.164–210.
Yang C., K. H.-Y. Lin, and H.-H. Chen. 2007.
Building Emotion Lexicon from Weblog Cor-
pora. Association for Computational Linguis-
tics, pp. 133-136.
</reference>
<page confidence="0.999061">
55
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.507359">
<title confidence="0.9922165">Labeling Emotion in Bengali Blog Corpus – A Fine Grained Tagging at Sentence Level</title>
<author confidence="0.686222">Dipankar</author>
<affiliation confidence="0.988687">Department of Computer &amp; Jadavpur University</affiliation>
<email confidence="0.989652">dipankar.dipnil2005@gmail.com</email>
<author confidence="0.81892">Sivaji</author>
<affiliation confidence="0.989582">Department of Computer &amp; Jadavpur University</affiliation>
<email confidence="0.998943">sivaji_cse_ju@yahoo.com</email>
<abstract confidence="0.99908224137931">Emotion, the private state of a human entity, is becoming an important topic Natural Language Processing with increasing use of search engines. The present task aims to manually annotate the sentences in a web based Bengali blog corpus with the emotional components such as emotional expression (word/phrase), intensity, associated holder and topic(s). Ekman’s six classes disgust, fear, along with types of intensities are considered for the sentence level annotation. Presence of discourse markers, punctuation marks, negations, conjuncts, reduplication, rhetoric knowledge and especially emoticons play the contributory roles in the annotation process. Different types of fixed and relaxed strategies have been employed to measure the agreement of the sentential emotions, intensities, emotional holders and topics respectively. Experimental results for each emotion class at word level on a small set of the whole corpus have been found satisfactory.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aman Saima</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Identifying Expressions of Emotion in</title>
<date>2007</date>
<volume>4629</volume>
<pages>196--205</pages>
<marker>Saima, Szpakowicz, 2007</marker>
<rawString>Aman Saima and Stan Szpakowicz. 2007. Identifying Expressions of Emotion in Text. V. Matoušek and P. Mautner (Eds.): TSD 2007, LNAI, vol. 4629, pp.196-205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Azar</author>
</authors>
<title>Argumentative Text as Rhetorical Structure: An Application of Rhetorical Structure Theory.</title>
<date>1999</date>
<journal>Argumentation,</journal>
<volume>13</volume>
<pages>97--114</pages>
<contexts>
<context position="10192" citStr="Azar, 1999" startWordPosition="1551" endWordPosition="1552">zzle. But, the puzzle can be solved partially using some lexical clues (e.g. discourse markers, punctuation marks (sym), negations (NEG), conjuncts (CONJ), reduplication (Redup)), structural clues (e.g. rhetoric and syntactic knowledge) and especially some direct affective clues (e.g. 2 http://www.internetworldstats.com/stats.htm 3 www.amarblog.com emoticons (emo_icon)). The identification of structural clues indeed requires the identification of lexical clues. Rhetorical Structure Theory (RST) describes the various parts of a text, how they can be arranged and connected to form a whole text (Azar, 1999). The theory maintains that consecutive discourse elements, termed text spans, which can be in the form of clauses, sentences, or units larger than sentences, are related by a relatively small set (20–25) of rhetorical relations (Mann and Thompson, 1988). RST distinguishes between the part of a text that realizes the primary goal of the writer, termed as nucleus, and the part that provides supplementary material, termed satellite. The separation of nucleus from satellite is done based on punctuation marks (, ! @?), emoticons, discourse markers (cam jehetu [as], mrq jemon [e.g.], Tr,.Tr karon [</context>
</contexts>
<marker>Azar, 1999</marker>
<rawString>Azar, M. 1999. Argumentative Text as Rhetorical Structure: An Application of Rhetorical Structure Theory. Argumentation, vol 13, pp. 97–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bethard Steven</author>
<author>H Yu</author>
<author>A Thornton</author>
<author>V Hatzivassiloglou</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Extraction of Opinion Propositions and their Holders.</title>
<date>2004</date>
<booktitle>In AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</booktitle>
<marker>Steven, Yu, Thornton, Hatzivassiloglou, Jurafsky, 2004</marker>
<rawString>Bethard Steven, Yu H., Thornton A., Hatzivassiloglou V., and Jurafsky, D. 2004. Automatic Extraction of Opinion Propositions and their Holders. In AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carletta Jean</author>
</authors>
<title>Assessing Agreement on Classification Tasks: The Kappa Statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>249--254</pages>
<marker>Jean, 1996</marker>
<rawString>Carletta Jean. 1996. Assessing Agreement on Classification Tasks: The Kappa Statistic. Computational Linguistics, vol. 22(2), pp.249-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
<author>E Riloff</author>
<author>S Patwardhan</author>
</authors>
<date>2005</date>
<booktitle>Identifying Sources of Opinions with Conditional Random Fields and Extraction Patterns. Human Language Technology / Empirical Method in Natural Language Processing.</booktitle>
<contexts>
<context position="19103" citStr="Choi et al., 2005" startWordPosition="2958" endWordPosition="2961">.63 pressions (7,588) [MASI] Emotional Ex- 0.67 0.63 0.68 0.66 pressions (7,588) [agr] Table 1: Inter-Annotator Agreements for sentence level Emotions, Intensities, Emoticons and Emotional Expressions -&lt;DOC docid = xyz&gt; -&lt;Topic&gt;.... &lt;/Topic&gt; -&lt;User Comments&gt; -&lt;U uid=1&gt;... &lt;/U&gt; -&lt;U uid=2&gt;... &lt;/U&gt; -&lt;U uid=3&gt;.... -&lt;U uid=1&gt;... &lt;/U&gt; ...&lt;/U&gt;... &lt;/User Comments&gt; &lt;/DOC&gt; “Figure. 2. General structure of a blog document” Prior work in identification of opinion holders has sometimes identified only a single opinion per sentence (Bethard et al., 2004), 1, #0 andB A - 0 0, ifAnB 51 and sometimes several (Choi et al., 2005). As the blog corpus has sentence level emotion annotations, the former category is adopted. But, it is observed that the long sentences contain more than one emotional expression and hence associated with multiple emotion holders (EH). All probable emotion holders of a sentence are stored in an anchoring vector successively according to their order of occurrence. The annotation of emotion holder at sentence level requires the knowledge of two basic constraints (implicit and explicit) separately. The explicit constraints qualify single prominent emotion holder that is directly involved with th</context>
</contexts>
<marker>Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Choi, Y., Cardie, C., Riloff, E., and Patwardhan, S. 2005. Identifying Sources of Opinions with Conditional Random Fields and Extraction Patterns. Human Language Technology / Empirical Method in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecilia Ovesdotter Alm</author>
<author>Dan Roth</author>
<author>Richard Sproat</author>
</authors>
<title>Emotions from text: Machine learning for text-based emotion prediction.</title>
<date>2005</date>
<booktitle>Human Language Technology - Empirical Method in Natural Language Processing,</booktitle>
<pages>579--586</pages>
<contexts>
<context position="5616" citStr="Alm et al., 2005" startWordPosition="858" endWordPosition="861"> the paper. 2 Related Work One of the most well known tasks of annotating the private states in texts is carried out by (Wiebe et al., 2005). They manually annotated the private states including emotions, opinions, and sentiment in a 10,000-sentence corpus (the MPQA corpus) of news articles. The opinion holder information is also annotated in the MPQA corpus but the topic annotation task has been initiated later by (Stoyanov and Cardie, 2008a). In contrast, the present annotation strategy includes the fine-grained emotion classes and specially handles the emoticons present in the blog posts. (Alm et al., 2005) have considered eight emotion categories (angry, disgusted, fearful, happy, sad, positively surprised, negatively surprised) to accomplish the emotion annotation task at sentence level. They have manually annotated 1580 sentences extracted from 22 Grimms’ tales. The present approach discusses the issues of annotating unstructured blog text considering rhetoric knowledge along with the attributes, e.g. negation, conjunct, reduplication etc. Mishne (2005) experimented with mood classification in a blog corpus of 815,494 posts from Livejournal (http://www.livejournal.com), a free weblog service </context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>Alm, Cecilia Ovesdotter, Dan Roth, and Richard Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. Human Language Technology - Empirical Method in Natural Language Processing, pp. 579-586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<journal>Educational and Psychological Measurement,</journal>
<volume>20</volume>
<pages>37--46</pages>
<contexts>
<context position="3853" citStr="Cohen, 1960" startWordPosition="581" endWordPosition="582">ation. The knowledge of rhetorical structure helps in removing the subjective discrepancies from the 1 www.amarblog.com 47 Proceedings of the 8th Workshop on Asian Language Resources, pages 47–55, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing writer’s point of view. The annotation scheme is used to annotate 123 blog posts containing 4,740 emotional sentences having single emotion tag and 322 emotional sentences for mixed emotion tagss along with 7087 neutral sentences in Bengali. Three types of standard agreement measures such as Cohen’s kappa (x) (Cohen, 1960; Carletta, 1996), Measure of Agreement on Set-valued Items (MASI) (Passonneau, 2004) and agr (Wiebe et al., 2005) metrics are employed for annotating the emotion related components. The relaxed agreement schemes like MASI and agr are specially considered for fixing the boundaries of emotional expressions and topic spans in the emotional sentences. The inter annotator agreement of some emotional components such as sentential emotions, holders, topics show satisfactory performance but the sentences of mixed emotion and intensities of general and low show the disagreement. A preliminary experime</context>
<context position="14153" citStr="Cohen, 1960" startWordPosition="2142" endWordPosition="2143">CW &lt;EW_F&gt;M0~~ &lt;/EW_F&gt; fsau 1TCaa &lt;NEG&gt;Fq&lt;/NEG&gt; I &lt;/ES_Su&gt;&lt;/ES_A&gt; &lt;ES_H&gt;�f1��d &lt;top2c&gt; &lt;/top2c&gt; 13~e f?M ei &lt;EW_H&gt; 4~~ ~~&lt;/EW_H&gt; 3TC-T 13t T &lt;/ES_H&gt; “Figure 1. Annotated sample of the corpus” 3.2 Agreement of Sentential Emotion and Intensity Three annotators identified as A1, A2 and A3 have used an open source graphical tool to carry out the annotation 4. As the Ekman’s emotion classes and intensity types belong to some definite categories, the annotation 4 http://gate.ac.uk/gate/doc/releases.html agreement for emotion and intensities are measured using standard Cohen&apos;s kappa coefficient (tc) (Cohen, 1960). The annotation agreement for emoticons is also measured using the kappa metric. It is a statistical measure of inter-rater agreement for qualitative (categorical) items. It measures the agreement between two raters who separately classify items into some mutually exclusive categories. The agreement of classifying sentential intensities into three classes (high, general and low) is also measured using kappa (x). The intensities of mixed emotional sentences are also considered. Agreement results of emotional, non-emotional and mixed sentences, emoticons, along with results for each emotion cla</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Cohen, J. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, vol. 20, pp. 37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Das Dipankar</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Word to Sentence Level Emotion Tagging for Bengali Blogs. Association for</title>
<date>2009</date>
<booktitle>Computational Linguistics –International Joint Conference of Natural Language Processing-2009,</booktitle>
<pages>149--152</pages>
<location>Suntec, Singapore.</location>
<marker>Dipankar, Bandyopadhyay, 2009</marker>
<rawString>Das Dipankar and Sivaji Bandyopadhyay. 2009a. Word to Sentence Level Emotion Tagging for Bengali Blogs. Association for Computational Linguistics –International Joint Conference of Natural Language Processing-2009, pp. 149-152. Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Das Dipankar</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<date>2009</date>
<booktitle>Emotion Tagging – A Comparative Study on Bengali and English Blogs. 7th International Conference On Natural Language Processing09,</booktitle>
<pages>177--184</pages>
<marker>Dipankar, Bandyopadhyay, 2009</marker>
<rawString>Das Dipankar and Sivaji Bandyopadhyay. 2009b. Emotion Tagging – A Comparative Study on Bengali and English Blogs. 7th International Conference On Natural Language Processing09, pp.177-184, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Das Dipankar</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Developing Bengali WordNet Affect for Analyzing Emotion.</title>
<date>2010</date>
<booktitle>International Conference on the Computer Processing of Oriental LanguagesInternational Conference on Software Engineering and Knowledge Engineering-2010,</booktitle>
<location>USA.</location>
<marker>Dipankar, Bandyopadhyay, 2010</marker>
<rawString>Das Dipankar and Sivaji Bandyopadhyay. 2010. Developing Bengali WordNet Affect for Analyzing Emotion. International Conference on the Computer Processing of Oriental LanguagesInternational Conference on Software Engineering and Knowledge Engineering-2010, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ekman</author>
</authors>
<title>An Argument for Basic Emotions. Cognition and Emotion.</title>
<date>1992</date>
<volume>6</volume>
<pages>169--200</pages>
<marker>Ekman, 1992</marker>
<rawString>Ekman, P. 1992. An Argument for Basic Emotions. Cognition and Emotion. vol. 6, pp.169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text Categorization with Support Machines: Learning with Many Relevant Features.</title>
<date>1998</date>
<booktitle>In European Conference on Machine Learning</booktitle>
<pages>137--142</pages>
<marker>Joachims, 1998</marker>
<rawString>Joachims, Thorsten. 1998. Text Categorization with Support Machines: Learning with Many Relevant Features. In European Conference on Machine Learning (ECML),137-142</rawString>
</citation>
<citation valid="true">
<authors>
<author>K H-Y Lin</author>
<author>C Yang</author>
<author>H-H Chen</author>
</authors>
<title>What Emotions News Articles Trigger in Their Readers?.</title>
<date>2007</date>
<booktitle>Proceedings of SIGIR,</booktitle>
<pages>733--734</pages>
<contexts>
<context position="1916" citStr="Lin et al., 2007" startWordPosition="281" endWordPosition="284"> the whole corpus have been found satisfactory. 1 Introduction Human emotion described in texts is an important cue for our daily communication but the identification of emotional state from texts is not an easy task as emotion is not open to any objective observation or verification (Quirk et al., 1985). Emails, weblogs, chat rooms, online forums and even twitter are considered as the affective communication substrates to analyze the reaction of emotional catalysts. Among these media, blog is one of the communicative and informative repository of text based emotional contents in the Web 2.0 (Lin et al., 2007). Rapidly growing web users from multilingual communities focus the attention to improve the multilingual search engines on the basis of sentiment or emotion. Major studies on Opinion Mining and Sentiment Analyses have been attempted with more focused perspectives rather than fine-grained emotions. The analyses of emotion or sentiment require some basic resource. An emotion-annotated corpus is one of the primary ones to start with. The proposed annotation task has been carried out at sentence level. Three annotators have manually annotated the Bengali blog sentences retrieved from a web blog a</context>
<context position="7521" citStr="Lin, et al., 2007" startWordPosition="1137" endWordPosition="1140">07) prepare an emotion-annotated corpus with a rich set of emotion information such as category, intensity and word or phrase based expressions. The present task considers all the above emotion information during annotation. But, the present annotation task additionally includes the components like emotion holder, single or multiple topic spans. The emotion corpora for Japanese were built for recognizing emotions (Tokuhisa et al., 2008). An available emotion corpus in Chinese is Yahoo!’s Chinese news (http://tw.news.yahoo.com), which is used for Chinese emotion classification of news readers (Lin, et al., 2007). The manual annotation of eight emotional categories (expect, joy, love, surprise, anxiety, sorrow, angry and hate) along with intensity, holder, word/phrase, degree word, negative word, conjunction, rhetoric, punctuation and other linguistic expressions are carried out at sentence, paragraph as well as document level on 1,487 Chinese blog documents (Quan and Ren, 2009). In addition 48 to the above emotion entities, the present approach also includes the annotation of single or multiple emotion topics in a target span. Recent study shows that non-native English speakers support the growing us</context>
</contexts>
<marker>Lin, Yang, Chen, 2007</marker>
<rawString>Lin K. H.-Y., C. Yang and H.-H. Chen. 2007. What Emotions News Articles Trigger in Their Readers?. Proceedings of SIGIR, pp. 733-734.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a Functional Theory of Text Organization,</title>
<date>1988</date>
<journal>TEXT</journal>
<volume>8</volume>
<pages>243--281</pages>
<contexts>
<context position="10446" citStr="Mann and Thompson, 1988" startWordPosition="1589" endWordPosition="1592">especially some direct affective clues (e.g. 2 http://www.internetworldstats.com/stats.htm 3 www.amarblog.com emoticons (emo_icon)). The identification of structural clues indeed requires the identification of lexical clues. Rhetorical Structure Theory (RST) describes the various parts of a text, how they can be arranged and connected to form a whole text (Azar, 1999). The theory maintains that consecutive discourse elements, termed text spans, which can be in the form of clauses, sentences, or units larger than sentences, are related by a relatively small set (20–25) of rhetorical relations (Mann and Thompson, 1988). RST distinguishes between the part of a text that realizes the primary goal of the writer, termed as nucleus, and the part that provides supplementary material, termed satellite. The separation of nucleus from satellite is done based on punctuation marks (, ! @?), emoticons, discourse markers (cam jehetu [as], mrq jemon [e.g.], Tr,.Tr karon [because], alta mane [means]), conjuncts (ea; ebong [and], F4in kintu [but], amTT athoba [or]), causal verbs (4w ghotay [caused]) if they are explicitly specified in the sentences. Use of emotion-related words is not the sole means of expressing emotion. </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann, W. C. and S. A. Thompson. 1988. Rhetorical Structure Theory: Toward a Functional Theory of Text Organization, TEXT 8, pp. 243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>McCallum Andrew</author>
<author>Fernando Pereira</author>
<author>John Lafferty</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and labeling Sequence Data.</title>
<date>2001</date>
<journal>ISBN, 282 –</journal>
<pages>289</pages>
<marker>Andrew, Pereira, Lafferty, 2001</marker>
<rawString>McCallum Andrew, Fernando Pereira and John Lafferty. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and labeling Sequence Data. ISBN, 282 – 289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihalcea Rada</author>
<author>Hugo Liu</author>
</authors>
<title>A corpusbased approach to finding happiness.</title>
<date>2006</date>
<journal>Association for the Advancement of Artificial Intelligence,</journal>
<pages>139--144</pages>
<marker>Rada, Liu, 2006</marker>
<rawString>Mihalcea Rada and Hugo Liu. 2006. A corpusbased approach to finding happiness. Association for the Advancement of Artificial Intelligence, pp. 139-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mishne Gilad</author>
</authors>
<title>Emotions from text: Machine learning for text-based emotion prediction.</title>
<date>2005</date>
<booktitle>SIGIR’05,</booktitle>
<pages>15--19</pages>
<marker>Gilad, 2005</marker>
<rawString>Mishne Gilad. 2005. Emotions from text: Machine learning for text-based emotion prediction. SIGIR’05, pp. 15-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neviarouskaya Alena</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Textual Affect Sensing for Social and Expressive</title>
<date>2007</date>
<booktitle>Online Communication. 2nd international conference on Affective Computing and Intelligent Interaction,</booktitle>
<pages>218--229</pages>
<marker>Alena, Prendinger, Ishizuka, 2007</marker>
<rawString>Neviarouskaya Alena, Helmut Prendinger, and Mitsuru Ishizuka. 2007. Textual Affect Sensing for Social and Expressive Online Communication. 2nd international conference on Affective Computing and Intelligent Interaction, pp. 218-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Passonneau</author>
</authors>
<title>Computing reliability for coreference annotation. Language Resources and Evaluation,</title>
<date>2004</date>
<location>Lisbon.</location>
<contexts>
<context position="3938" citStr="Passonneau, 2004" startWordPosition="592" endWordPosition="594">iscrepancies from the 1 www.amarblog.com 47 Proceedings of the 8th Workshop on Asian Language Resources, pages 47–55, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing writer’s point of view. The annotation scheme is used to annotate 123 blog posts containing 4,740 emotional sentences having single emotion tag and 322 emotional sentences for mixed emotion tagss along with 7087 neutral sentences in Bengali. Three types of standard agreement measures such as Cohen’s kappa (x) (Cohen, 1960; Carletta, 1996), Measure of Agreement on Set-valued Items (MASI) (Passonneau, 2004) and agr (Wiebe et al., 2005) metrics are employed for annotating the emotion related components. The relaxed agreement schemes like MASI and agr are specially considered for fixing the boundaries of emotional expressions and topic spans in the emotional sentences. The inter annotator agreement of some emotional components such as sentential emotions, holders, topics show satisfactory performance but the sentences of mixed emotion and intensities of general and low show the disagreement. A preliminary experiment for word level emotion classification on a small set of the whole corpus yielded s</context>
<context position="16005" citStr="Passonneau, 2004" startWordPosition="2426" endWordPosition="2428">ation sets are shown in Table 1. 3.3 Agreement of Emotional Expressions Emotional expressions are words or strings of words that are selected by the annotators. The agreement is carried out between the sets of text spans selected by the two annotators for each of the emotional expressions. As there is no fixed category in this case, we have employed two different strategies instead of kappa (x) to calculate the agreement between annotators. Firstly, we chose the measure of agreement on set-valued items (MASI) (Passonneau, 2006) that was used for measuring agreement on co reference annotation (Passonneau, 2004) and in the semantic and pragmatic annotation (Passonneau, 2006). MASI is a distance between sets whose value is 1 for identical sets, and 0 for disjoint sets. For sets A and B it is defined as: MASI = J * M, where the Jaccard metric is: 50 s = |AnB |/ |AUB| Monotonicity (M) is defined as, ifA B _ 2 / 3, ifAcBorBcA 1/3,ifAnB#0,A-B#0, Secondly, the annotators will annotate different emotional expressions by identifying the responsible text anchors and the agreement is measured using agr metric (Wiebe et al., 2005). If A and B are the sets of anchors annotated by annotators a and b, respectively</context>
</contexts>
<marker>Passonneau, 2004</marker>
<rawString>Passonneau, R. 2004. Computing reliability for coreference annotation. Language Resources and Evaluation, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Passonneau</author>
</authors>
<title>Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation. Language Resources and Evaluation.</title>
<date>2006</date>
<contexts>
<context position="15921" citStr="Passonneau, 2006" startWordPosition="2413" endWordPosition="2415">results of emoticons for each emotion class, the average results for the three annotation sets are shown in Table 1. 3.3 Agreement of Emotional Expressions Emotional expressions are words or strings of words that are selected by the annotators. The agreement is carried out between the sets of text spans selected by the two annotators for each of the emotional expressions. As there is no fixed category in this case, we have employed two different strategies instead of kappa (x) to calculate the agreement between annotators. Firstly, we chose the measure of agreement on set-valued items (MASI) (Passonneau, 2006) that was used for measuring agreement on co reference annotation (Passonneau, 2004) and in the semantic and pragmatic annotation (Passonneau, 2006). MASI is a distance between sets whose value is 1 for identical sets, and 0 for disjoint sets. For sets A and B it is defined as: MASI = J * M, where the Jaccard metric is: 50 s = |AnB |/ |AUB| Monotonicity (M) is defined as, ifA B _ 2 / 3, ifAcBorBcA 1/3,ifAnB#0,A-B#0, Secondly, the annotators will annotate different emotional expressions by identifying the responsible text anchors and the agreement is measured using agr metric (Wiebe et al., 200</context>
</contexts>
<marker>Passonneau, 2006</marker>
<rawString>Passonneau, R.J. 2006. Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quan Changqin</author>
<author>Fuji Ren</author>
</authors>
<title>Construction of a Blog Emotion Corpus for Chinese Emotional Expression Analysis.</title>
<date>2009</date>
<booktitle>Empirical Method in Natural Language Processing- Association for Computational Linguistics,</booktitle>
<pages>1446--1454</pages>
<marker>Changqin, Ren, 2009</marker>
<rawString>Quan Changqin and Fuji Ren. 2009. Construction of a Blog Emotion Corpus for Chinese Emotional Expression Analysis. Empirical Method in Natural Language Processing- Association for Computational Linguistics, pp. 1446-1454, Singapore</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<publisher>Longman,</publisher>
<location>New York.</location>
<contexts>
<context position="1604" citStr="Quirk et al., 1985" startWordPosition="232" endWordPosition="235">oticons play the contributory roles in the annotation process. Different types of fixed and relaxed strategies have been employed to measure the agreement of the sentential emotions, intensities, emotional holders and topics respectively. Experimental results for each emotion class at word level on a small set of the whole corpus have been found satisfactory. 1 Introduction Human emotion described in texts is an important cue for our daily communication but the identification of emotional state from texts is not an easy task as emotion is not open to any objective observation or verification (Quirk et al., 1985). Emails, weblogs, chat rooms, online forums and even twitter are considered as the affective communication substrates to analyze the reaction of emotional catalysts. Among these media, blog is one of the communicative and informative repository of text based emotional contents in the Web 2.0 (Lin et al., 2007). Rapidly growing web users from multilingual communities focus the attention to improve the multilingual search engines on the basis of sentiment or emotion. Major studies on Opinion Mining and Sentiment Analyses have been attempted with more focused perspectives rather than fine-graine</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Quirk, R., Greenbaum, S., Leech, G., Svartvik, J. 1985. A Comprehensive Grammar of the English Language. Longman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>C Cardie</author>
</authors>
<title>Annotating topics of opinions. Language Resources and Evaluation.</title>
<date>2008</date>
<contexts>
<context position="5444" citStr="Stoyanov and Cardie, 2008" startWordPosition="833" endWordPosition="836">e issues of emotional topic annotation are discussed in Section 5. Section 6 describes the preliminary experiments carried out on the annotated corpus. Finally, Section 7 concludes the paper. 2 Related Work One of the most well known tasks of annotating the private states in texts is carried out by (Wiebe et al., 2005). They manually annotated the private states including emotions, opinions, and sentiment in a 10,000-sentence corpus (the MPQA corpus) of news articles. The opinion holder information is also annotated in the MPQA corpus but the topic annotation task has been initiated later by (Stoyanov and Cardie, 2008a). In contrast, the present annotation strategy includes the fine-grained emotion classes and specially handles the emoticons present in the blog posts. (Alm et al., 2005) have considered eight emotion categories (angry, disgusted, fearful, happy, sad, positively surprised, negatively surprised) to accomplish the emotion annotation task at sentence level. They have manually annotated 1580 sentences extracted from 22 Grimms’ tales. The present approach discusses the issues of annotating unstructured blog text considering rhetoric knowledge along with the attributes, e.g. negation, conjunct, re</context>
<context position="22697" citStr="Stoyanov and Cardie, 2008" startWordPosition="3556" endWordPosition="3559">atisfactory and the difference between the two agreement types is significantly less. The small difference indicates the minimal error involved in the annotation process. It is found that the agreement is highly moderate in case of single emotion holder, but is less in case of multiple holders. The disagreement occurs mostly in the case of satisfying the implicit constrains but some issues are resolved by mutual understanding. 5 Topic Annotation and Agreement Topic is the real world object, event, or abstract entity that is the primary subject of the opinion as intended by the opinion holder (Stoyanov and Cardie, 2008). They mention that the topic identification is difficult within the single target span of the opinion as there are multiple potential topics, each identified 52 with its own topic span and the topic of an opinion depends on the context in which its associated opinion expression occurs. Hence, the actual challenge lies on identification of the topics spans from the emotional sentences. The writer’s emotional intentions in a sentence are reflected in the target span by mentioning one or more topics that are related to the emotional expressions. Topics are generally distributed in different text</context>
</contexts>
<marker>Stoyanov, Cardie, 2008</marker>
<rawString>Stoyanov, V., and C. Cardie. 2008. Annotating topics of opinions. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matsumoto</author>
</authors>
<title>Emotion Classification Using Massive Examples Extracted from the Web. COLING</title>
<date>2008</date>
<pages>881--888</pages>
<marker>Matsumoto, 2008</marker>
<rawString>Tokuhisa Ryoko, Kentaro Inui, and Yuji. Matsumoto. 2008. Emotion Classification Using Massive Examples Extracted from the Web. COLING 2008, pp. 881-888.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiebe Janyce</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<pages>164--210</pages>
<marker>Janyce, Wilson, Cardie, 2005</marker>
<rawString>Wiebe Janyce, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, vol. 39, pp.164–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Yang</author>
<author>K H-Y Lin</author>
<author>H-H Chen</author>
</authors>
<title>Building Emotion Lexicon from Weblog Corpora. Association for Computational Linguistics,</title>
<date>2007</date>
<pages>133--136</pages>
<marker>Yang, Lin, Chen, 2007</marker>
<rawString>Yang C., K. H.-Y. Lin, and H.-H. Chen. 2007. Building Emotion Lexicon from Weblog Corpora. Association for Computational Linguistics, pp. 133-136.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>