<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<note confidence="0.294108333333333">
What&apos;s Necessary to Hide?:
Modeling Action Verbs
James F. Allen
Computer Science Department
University of Rochester
Rochester, NY 14627
</note>
<sectionHeader confidence="0.695723" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888307692308">
This paper considers what types of knowledge one
must possess in order to reason about actions. Rather than
concentrating on how actions are performed, as is done in
the problem-solving literature, it examines the set of
conditions under which an action can be said to have
occurred. In other words, if one is told that action A
occurred, what can be inferred about the state of the
world? In particular, if the representation can define such
conditions, it must have good models of time, belief, and
intention. This paper discusses these issues and suggests a
formalism in which general actions and events can be
defined. Throughout, the action of hiding a book from
someone is used as a motivating example.
</bodyText>
<sectionHeader confidence="0.934035" genericHeader="method">
I. Introduction
</sectionHeader>
<bodyText confidence="0.999272989690722">
This paper suggests a formulation of events and
actions that seems powerful enough to define a wide range
of event and action verbs in English. This problem is
interesting for two reasons. The first is that such a model is
necessary to express the meaning of many sentences. The
second is to analyze the language production and
comprehension processes themselves as purposeful action.
This was suggested some time ago by 13ruce [1975] and
Schmidt [1975]. Detailed proposals have been
implemented recently for some aspects of language
production [Cohen, 1978] and comprehension [Allen,
1979]. As interest in these methods grows (e.g., see [Grosz,
1979; 13rachman, 1979]), the inadequacy of existing action
models becomes increasingly obvious.
The formalism for actions used in most natural
language understanding systems is based on case grammar.
Each action is represented by a set of assertions about the
semantic roles the noun phrases play with respect to the
verb. Such a formalism is a start, but does not explain how
to represent what an action actually signifies. Hone is told
that a certain action occurred, what does one know about
how the world changed (or didn&apos;t change!). This paper
attempts to answer this question by outlining a temporal
logic in which the occurrence of actions can be tied to
descriptions of the world over time.
One possibility for such a mechanism is found in the
work on problem-solving systems (e.g. [Fikes and Nilsson,
1971; Sacerdoti, 1975]), which suggests one common
formulation of action. An action is a function from one
world state to a succeeding world state and is described by
a set of prerequisites and effects, or by decomposition into
more primitive actions. While this model is extremely
useful for modeling physical actions by a single actor, it
does not cover a large class of actions describable in
English. For instance, many actions seemingly describe
non-activity (e.g. standing still), or acting in some non-
specified manner to preserve a state (e.g. preventing your
television set from being stolen). Furthermore, many
action descriptions appear to be a composition of simpler
actions that are simultaneously executed. For instance,
&apos;Walking to the store while juggling three balls&apos;&apos;
seems to be composed of the actions of
&amp;quot;walking to the store
and
&amp;quot;juggling three balls.&amp;quot;
It is not clear how such an action could be defined
from the two simpler actions if we view actions as
functions from one state to another.
The approach suggested here models events simply as
partial descriptions of the world over some time interval.
Actions are then defined as a subclass of events that
involve agents. Thus, it is simple to combine two actions
into a new action. The new description simply consists of
the two simpler descriptions holding over the same
interval.
The notions of prerequisite, result, and methods of
performing actions will not arise in this study. While they
are important for reasoning about how to attain goals, they
don&apos;t play an explicit role in defining when an action can
be said to have occurred. To make this point clear,
consider the simple action of turning on a light.
There are few physical activities that are a necessary
part of performing this action. Depending on the context,
vastly different patterns of behavior can be classified as
the same action. For example, turning on a light usually
involves flipping a light switch, but in some circumstances
it may involve tightening the light bulb (in the basement).
or hitting the wall (in an old house). Although we have
knowledge about how the action can be performed, this
does not define what the action is. The key defining
characteristic of turning on the light seems to be that the
agent is performing some activity which will cause the
light, which is off when the action starts, to become on
when the action ends. The importance of this observation
is that we could recognize an observed pattern of activity
as &amp;quot;turning on the light&amp;quot; even if we had never seen or
thought about that pattern previously.
The model described here is in many ways similar to
that of Jackendoff [1976]. He provides a classification of
event verbs that includes verbs of change cgo verbs) and
verbs that assert a state remaining constant over an
interval of time (STAY verbs), and defines a
representation of action verbs of both typesâ€¢hy introducing
the notion of agentive causality and permission. However,
Jackendoff does not consider in detail how specific actions
might be precisely defined with respect to a world model.
The next two sections of this paper will introduce the
temporal logic and then define the framework for defining
events and actions. To be as precise as possible, I have
remained within the notation of the first order predicate
calculus. Once the various concepts are precisely defined,
the next necessary step in this work is to define a
computationally feasible representation and inference
process. Some of this work has already been done. For
example, a computational model of the temporal logic can
be found in Allen [1981]. Other areas are currently under
investigation.
</bodyText>
<page confidence="0.997394">
77
</page>
<bodyText confidence="0.9996185">
The final section demonstrates the generality of the
approach by analyzing the action of hiding a book from
someone. In this study, various other important conceptual
entities such as belief, intention, and causality are briefly
discussed. Finally, a definition of, what it means to hide
something is presented using these tools.
</bodyText>
<sectionHeader confidence="0.720839" genericHeader="method">
2. A Temporal Logic
</sectionHeader>
<bodyText confidence="0.999563473684211">
Before we can characterize events and actions, we need
to specify a temporal logic. The logic described here is
based on temporal intervals. Events that appear to refer to
a point in time (i.e., finishing a race) are considered to be
implicitly referring to another event&apos;s beginning or ending.
Thus the only time points we will see will be the endpoints
of intervals.
The logic is a typed first order predicate calculus, in
which the terms fall into the following three broad
categories:
- terms of type TIME-INTERVAL denoting time
intervals;
- terms of type PROPERTY, denoting descriptions
that can hold or not hold during a particular time:
and
- terms corresponding to objects in the domain.
There are a small number of predicates. One of the most
important is HOLDS, which asserts that a &apos;property holds
(i.e., is true) during a time interval,, &apos;[&apos;bus
</bodyText>
<equation confidence="0.420346">
HO I.DS(p,t)
</equation>
<bodyText confidence="0.993322517241379">
is true only if property p holds during t. As a subsequent
axiom will state, this is intended to mean that p holds at
every subinterval of t as well.
There is no need to investigate the behavior of
HO I,DS fully here, but in Allen [forthcoming) various
functional forms are defined that can be used within the
scope of a HOLDS predicate that correspond to logical
connectives and quantifiers outside the scope of the
HOLDS predicate.
There is a basic set of mutually exclusive relations that
can hold between temporal intervals. Each of these is
represented by a predicate in the logic. The most
important are:
D UR ING(11,t2)- -lime interval ti is fully contained
within t2, although they may coincide on their
endpoints.
BEFORE(ti,t2)--time interval tl is before interval 12,
and they do not overlap in any way;
OVER LA P(11,12)- -interval ti starts before 12. and
they overlap;
MEETS(t1,12)--interval ti is before interval 12, but
there is no interval between them, i.e., ti ends
where 12 starts.
Given these predicates, there is a set of axioms
defining their interrelations. For example, there are
axioms dealing with the transitivity of the temporal
relationships. Also, there is the axiom mentioned
previously when the HOLDS predicate was introduced:
namely
</bodyText>
<equation confidence="0.895372">
(A.1) HO 1,DS(p, t) &amp; D UR INGO I, =) HO I,DS(pt I)
</equation>
<bodyText confidence="0.9944855">
This gives us enough tools to define the notion of action in
the next section.
</bodyText>
<listItem confidence="0.728644">
3. Events and Actions
</listItem>
<bodyText confidence="0.99996352">
In order to define the role that events and actions play
in the logic, the logical form of sentences asserting that an
event has occurred must be discussed. Once events have
been defined, actions will he defined in terms of them.
One suggestion for the logical form is to &apos;define for each
class of events a property such that the property HOLDS
only if the event occurred. This can be discarded
immediately as axiom (A.1) is inappropriate for events. If
an event occurred over some time interval T. it does not
mean that the event also occurred over all subintervals of
&apos;I&apos;. So we introduce a new type of object in the logic,
namely events, and a new predicate OCCUR. By
representing events as objects in the logic, we have
avoided the difficulties described in Davidson [1967].
Simply giving the logical form of an event is only a
small part of the analysis. We must also define for each
event the set of conditions that constitute its occurrence.
As mentioned in the introduction, there seems to be no
restriction on what kind of conditions can he used to
define an event except that they must partially describe
the world over some time interval.
For example, the event &amp;quot;the ball moving from x to y&amp;quot;
could be modeled by a predicate MOVE with four
arguments: the object, the source, the goal location, and
the move event itself. Thus,
</bodyText>
<equation confidence="0.313247">
MO VE(Balt x, y, m)
</equation>
<bodyText confidence="0.94635575">
asserts that m is an event consisting of the ball moving
from x to y. We assert that this event occurred over time t
by adding the assertion
OCCUROrtt).
With these details out of the way, we can now define
necessary and sufficient conditions for the event&apos;s
occurrence. For this simple class ot&apos; move events, we need
an axiom such as:
</bodyText>
<equation confidence="0.994044714285714">
Â°broil object,source,goal,:. e)
MO VE(object,source,goal,e) &amp; OCCUR( et)
(exists t1,0)
OVER LAPS(11,0 &amp; OVER LA PS0,12) &amp;
BEFORE(:I,12)
H 0 LDS(at(objectsource), tl)
H 0 LDS(at(object,goal),t2)
</equation>
<bodyText confidence="0.9560785">
A simple class of events consists of those that occur
only if some property remains constant over a particular
interval (cf. Jackendoffs STAY verbs). For example, we
may assert in English
â€”Ile ball was in the room during T.&amp;quot;
â€”Ile ball remained in the room during T.&amp;quot;
</bodyText>
<page confidence="0.991882">
78
</page>
<bodyText confidence="0.844222571428571">
While these appear to be logically equivalent, they may
have very different consequences in a conversation. This
formalism supports this difference. The former sentence
asserts a proposition, and hence is of the form
HO LOS(in(BalI,Room),D
while the latter sentence describes an event, and hence is
of the form
</bodyText>
<equation confidence="0.922797666666667">
REMAIN-IN(Ball,Room,e) &amp; OCCURS(e,T).
We may capture the logical equivalence of the two
with the axiom:
(forall b.r,e,t)
REMAIN-IN(b,r,e) &amp; OCCUR(e,t)
(=7) HOLDS(in(b,r),t) ,
</equation>
<bodyText confidence="0.923111">
The problem remains as to how the differences
between these logically equivalent formulas arise in
context. One possible difference is that the second may
lead the reader to believe that it easily might not have
been the case.
Actions are events that involve an agent in one of two
ways. The agent may cause the event or may allow the
event (cf. [Jackendoff, 1976]). Corresponding to these two
types of agency, there are two predicates, ACA USE and
ALLOW, that take an agent, an event, and an action as
arguments. Thus the assertion corresponding to
</bodyText>
<equation confidence="0.80688375">
&amp;quot;John moved B from S to G&amp;quot;
is
MOVE(B,G,S,el)ci ACAUSF:(Johnel,a1)&amp;
OCCUR(al,t)
</equation>
<bodyText confidence="0.9887985">
The axiomatization for ACAUSE and ALLOW is
tricky, but Jackendoff provides a reasonable starting set. In
this paper, I shall only consider agency by causation
further. The most important axiom about causality is
</bodyText>
<equation confidence="0.949429">
(A.2) (forall a.eact,t)
ACAUSE(a.eact) &amp; OCCUR(act,t)
=7) OCCUR(et)
</equation>
<bodyText confidence="0.964878555555555">
For our purposes, one of the most important facts
about the ACAUSE relation is that it suggests the
possibility of intentionality on the part of the agent. This
will be discussed in the next section.
Note that in this formalism composition of events and
actions is trivial. For example, we can define an action
composition function together which produces an action or
event that consists of two actions or events occuring
simultaneously as follows:
</bodyText>
<equation confidence="0.890778666666667">
(A.3) (forall a,b,t)
OCCURS(together(a,b).0 )
OCCURS(at) &amp; OCCURS(b.t)
</equation>
<sectionHeader confidence="0.536975" genericHeader="method">
4. What&apos;s Necessary to Hide?
</sectionHeader>
<bodyText confidence="0.988517418181818">
The remainder of this paper applies the above
formalism to the analysis of the action of hiding a book
from someone. Along the way, we shall need to introduce
some new representational tools for the notions of belief,
intention, and causality.
The definition of hiding a book should be
independent of any method by which the action was
performed, for, depending on the context, the actor could
hide a book in many different ways. For instance, the
actor could
- put the book behind a desk,
- stand between the book and the other agent while
they are in the same room, or
- call a friend Y and get her or him to do one of the
above.
Furthermore, the actor might hide the book by simply
not doing something s/he intended to do. For example,
assume Sam is planning to go to lunch with Carole after
picking Carole up at Carole&apos;s office. If, on the way out of
Sam&apos;s office, Sam decides not to take his coat because he
doesn&apos;t want Carole to see it, then Sam has hidden the
coat from Carole. Of course, it is crucial here that Sam
believed that he normally would have taken the coat. Sam
couldn&apos;t have hidden his coat by forgetting to bring it.
This example brings up a few key points that may not
be noticed from the first three examples. First, Sam must
have intended to hide the coat. Without this intention (i.e.,
in the forgetting case), no such action occurs. Second, Sam
must have believed that it was likely that Carole would see
the coat in the future course of events. Finally, Sam must
have acted in such a way that he then believed that Carole
would not see the coat in the future course of events. Of
course, in this case, the action Sam performed was &amp;quot;not
bringing the coat,&amp;quot; which would normally not be
considered an action unless it was intentionally not done.
I claim that these three conditions provide a
reasonably accurate definition of what it means to hide
something. They certainly cover the four examples
presented above. As stated previously, however, the
definition is rather unsatisfactory, as many extremely
difficult concepts, such as belief and intention, were
thrown about casually.
There is much recent work on models of belief (e.g.,
[Cohen, 1978; Moore, 1979; Perlis, 1981; Haas, 1981]). 1
have little to add to these efforts, so the reader may
assume his or her favorite model. I will assume that belief
is a modal operator and is described by a set of axioms
along the lines of Hintikka 119621. The one important
thing to notice, though, is that there are two relevant time
indices to each belief; namely, the time over which the
belief is held, and the time over which the proposition that
is believed holds. For example, I might believe today that
it rained last weekend. This point wiil be crucial in
modeling the action of hiding. To introduce some
notation, let
</bodyText>
<footnote confidence="0.529122333333333">
&amp;quot;A believes (during Tb) that p holds (during Tp)&amp;quot;
be expressed as
HO LDS(belieyes(A.holds(p.Tp)),Tb).
</footnote>
<page confidence="0.997242">
79
</page>
<bodyText confidence="0.978581121951219">
The notion of intention is much less understood than
the notion of belief. However, let us approximate the
statement
&amp;quot;A intends (during Ti) that action a happen (during
Ta)&amp;quot;
by
&amp;quot;A believes (during Ti) that a happen (during Ta)&amp;quot;
and
&amp;quot;A wants (during Ti) that a happen (during Ta)&amp;quot;
This is obviously not a philosophically adequate
definition (e.g., see [Searle, 1980, but seems sufficient for
our present purposes. The notion of wanting indicates that
the actor finds the action desirable given the alternatives.
This notion appears impossible to axiomatize as wants do
not appear to be rational (e.g. Hare [197]]). However, by
adding the belief that the action will occur into the notion
of intention, we ensure that intentions must be at least as
consistent as beliefs.
Actions may be performed intentionally or
unintentionally. For example, consider the action of
breaking a window. Inferring intentionality from observed
action is a crucial ability needed in order to communicate
and cooperate with other agents. While it is difficult to
express a logical connection between action and intention,
one can identify pragmatic or plausible inferences that can
be used in a computational model (see [Allen, 1979)).
With these tools, we can attempt a more precise
definition of hiding. The time intervals that will be
required are:
Thâ€”the time of the hiding event;
Tsâ€”the time that Y is expected to see the book;
&apos;111â€”the time when X believes Y will see the book
during Ts, which must be BEFORE Th;
Tb3â€” the time when X believes Y will not see the
book during Ts, which must be BEFORE or
DURING Th and A1TER Tbl.
We will now define the predicate
HIDE(agent,observer,object,ac))
which asserts that act is an action of hiding. Since it
describes an action, we have the simple axiom capturing
agency:
</bodyText>
<figure confidence="0.7440404375">
(Jo rail agent,observer,object,act
HIDE(agemobserver,object,act)
=) (Exists e ACAUSE(agent.eact)))
Let us also introduce an event predicate
SEE(agent,object,e)
which asserts that e is an event consisting of agent seeing
the object.
Now we can define HIDE as follows:
(JoraII agobs,o.a.771,
H lDE&apos;ag. obs. o.a &amp; OCCUR(a,Th)
=) (Exists 7&apos;s,Tbl,Tb3,e)
I) HOLDS(intends(ag.occur(a.Th)).Th)
2) HOLDS(believe.Riag,occur(eTs)),Tb1)
3) HOLDS(beiieves(ag,â€”,occurleTs)),Tb3)
where
4) SEE(obzo,e)
</figure>
<figureCaption confidence="0.861335">
and the intervals Th, Ts, Tb], Tb3 are related as discussed
above. Condition (4) defines e as a seeing event, and
might also need to be within ag&apos;s beliefs.
</figureCaption>
<bodyText confidence="0.997267">
This definition is lacking part of our analysis; namely
that there is no mention that the agent&apos;s beliefs changed
because of something s/he did. We can assert that the
agent believes (between Tb] and Tb3) he or she will do an
action (between Tb] and Th) as follows:
</bodyText>
<figure confidence="0.845534666666667">
(exists al,e1,Tb2
5) ACAUSE(agel,a1)
6) HOLDS(believes(ag,OCCUR(al,Tal)),Tb2)
where Tb! Tb2 Tb3 and
Tb! Tal &lt; rh
But this has not captured the notion that belief (6)
</figure>
<bodyText confidence="0.990463111111111">
caused the change in belief from (2) to (3). Since (6) and
(3) are true, asserting a logical implication from (6) to (3)
would have no force. It is essential that the belief (6) be a
key -element in the reasoning that leads to belief (3).
To capture this we must introduce a notion of
causality. This notion differs from ACA USE in many ways
(e.g. see (Taylor, 19661), but for us the major difference is
that, unlike ACA USE, it suggests no relation to
intentionality. While ACA USE relates an agent to an
event, CAUSE relates events to events. The events in
question here would be coming to the belief (6), which
CAUSES coming to the belief (3).
One can see that much of what it means to hide is
captured by the above. In particular, the following can be
extracted directly from the definition:
if you hide something, you intended to hide it, and
thus can be held responsible for the action&apos;s
consequences:
one cannot hide something if it were not possible
that it could be seen, or if it were certain that it
would be seen anyway;
one cannot hide something simply by changing
one&apos;s mind about whether it will be seen.
In addition, there are many other possibilities related
to the temporal order of events. For instance, you can&apos;t
hide something by performing an action after the hiding is
supposed to be done.
</bodyText>
<page confidence="0.994594">
80
</page>
<sectionHeader confidence="0.801062" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.9992896875">
I have introduced a representation for events and
actions that is based on an interval-based temporal logic.
This model is sufficiently powerful to describe events and
actions that involve change, as well as those that involve
maintaining a state. In addition, the model readily allows
the composition and modification of events and actions.
In order to demonstrate the power of the model, the
action of hiding was examined in detail. This forced the
introduction of the notions of belief, intention, and
causality. While this paper does not suggest any
breakthroughs in representing these three concepts, it does
suggest how they should interact with the notions of time,
event, and action.
At present, this action model is being extended so that
reasoning about performing actions can be modeled. This
work is along the lines described in [Goldman, 1970].
</bodyText>
<sectionHeader confidence="0.997987" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998317142857143">
The author wishes to thank Jerry Feldman, Alan
Frisch, Margery Lucas, and Dan Russell for many
enlightening comments on previous versions of this paper.
This research was supported in part by the National
Science.Foundation under Grant No. 1ST-80-12418, and
in part by the Office of Naval Research under Grant No.
N00014-80-C-0197.
</bodyText>
<sectionHeader confidence="0.997973" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999758263157895">
Allen, I.E., &amp;quot;A General View of Action and lime,&amp;quot; TR,
Dept. Computer Science, U. Rochester, forthcoming.
Allen, J.F., &amp;quot;A Plan-Based Approach to Speech Act
Recognition,&amp;quot; Ph.D. thesis, Dept. Computer Science,
U. Toronto, 1979.
Allen, J.F., &amp;quot;Maintaining Knowledge about Temporal
Intervals,&amp;quot; TR86, Dept. Computer Science, U.
Rochester, January 1981.
13rachman, R.J., â€”Taxonomy, Descriptions, and Individuals
in Natural language Understanding,&amp;quot; in Proc., 17th
Annual Meeting of the Assoc&apos;n. for Computational
Linguistics, 33-37, UCSD, La Jolla. CA, August 1979.
Bruce, If., &amp;quot;Belief Systems and language Understanding,&apos;&apos;
Report 2973, Bolt, Beranek &amp; Newman, Inc., 1975.
Cohen, P.R., &amp;quot;On Knowing What to Say: Planning Speech
Acts,&amp;quot; TR 118, Dept. Computer Science, U. Toronto,
1978.
Davidson, D., â€”The Logical Form of Action Sentences,&amp;quot; in
N. Rescher (Ed). The Logic of Decision and Action.
Pittsburgh, PA: U. Pittsburgh Press, 1967.
Pikes, R.E. and N.J. Nilsson. &amp;quot;STRIPS: A New Approach
to the Application of Theorem Proving to Problem
Solving,&amp;quot; Artificial Intelligence 2, 189-205, 1971.
Goldman, A. A Theory of Human Action. New Jersey:
Princeton U. Press, 1970.
Grosz, Bi., &amp;quot;Utterance and Objective: Issues in Natural
Language Communication,&amp;quot; in Proc.. 6th IJCAI, 1067-
1076, Tokyo, August 1979.
Haas, A., &amp;quot;Sententialism and the Logic of Belief and
Action,&amp;quot; Ph.D. thesis, Dept. Computer Science, U.
Rochester, expected 1981.
Hare, R.M. &amp;quot;Wanting: Some Pitfalls,&amp;quot; in Binkley,
13ronaugh, and Morras (Eds). Agent. Action, and
Reason. Toronto: U. Toronto Press, 1971.
Hintikka, J. Knowledge and Belief Ithaca, NY: Cornell U.
Press, 1962.
Jackendoff, R., &amp;quot;Toward an Explanatory Semantic
Representation,&amp;quot; Linguistic &apos;Inquiry 7, 1, 89-150,
Winter 1976.
Moore, R.C., &amp;quot;Reasoning about Knowledge and Action,&amp;quot;
Ph.D. thesis, MIT, February 1979.
Perlis D., &amp;quot;Language, Computation, and Reality,&amp;quot; Ph.D.
thesis, Dept. Computer Science, U. Rochester, 1981,
Sacerdoti, E.D. A Structure for Plans and Behavior. New
York: Elsevier North-Holland, Inc., 1977.
Schank, R. and R. Abelson. Scripi Plan Goal .g and
Understanding. Hillsdale, NJ: Lawrence Erlbaum
Associates, 1977.
Schmidt, C.F., &amp;quot;Understanding Human Action,&amp;quot; in Proc.,
Theoretical Issues in Natural Language Processing,
Cambridge, MA, 1975.
Searle, J.R., &amp;quot;The Intentionality of Intention and Action,&amp;quot;
Cognitive Science 4, 1, 1980.
Taylor, R. Action and Purpose. New Jersey: Prentice Hall,
1966.
Wilensky, R., &amp;quot;Understanding Goal-Based Stories,&amp;quot; Ph.D.
thesis, Yale U., 1978.
</reference>
<page confidence="0.999264">
81
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.992098">
<title confidence="0.998275">What&apos;s Necessary to Hide?: Modeling Action Verbs</title>
<author confidence="0.999959">James F Allen</author>
<affiliation confidence="0.99994">Computer Science Department University of Rochester</affiliation>
<address confidence="0.999815">Rochester, NY 14627</address>
<abstract confidence="0.999699142857143">This paper considers what types of knowledge one must possess in order to reason about actions. Rather than concentrating on how actions are performed, as is done in the problem-solving literature, it examines the set of conditions under which an action can be said to have occurred. In other words, if one is told that action A occurred, what can be inferred about the state of the world? In particular, if the representation can define such conditions, it must have good models of time, belief, and intention. This paper discusses these issues and suggests a formalism in which general actions and events can be defined. Throughout, the action of hiding a book from someone is used as a motivating example.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>I E Allen</author>
</authors>
<title>A General View of Action and lime,&amp;quot;</title>
<journal>TR, Dept. Computer Science, U. Rochester, forthcoming.</journal>
<marker>Allen, </marker>
<rawString>Allen, I.E., &amp;quot;A General View of Action and lime,&amp;quot; TR, Dept. Computer Science, U. Rochester, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>A Plan-Based Approach to Speech Act Recognition,&amp;quot;</title>
<date>1979</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. Computer Science, U.</institution>
<location>Toronto,</location>
<contexts>
<context position="1459" citStr="Allen, 1979" startWordPosition="233" endWordPosition="234">mple. I. Introduction This paper suggests a formulation of events and actions that seems powerful enough to define a wide range of event and action verbs in English. This problem is interesting for two reasons. The first is that such a model is necessary to express the meaning of many sentences. The second is to analyze the language production and comprehension processes themselves as purposeful action. This was suggested some time ago by 13ruce [1975] and Schmidt [1975]. Detailed proposals have been implemented recently for some aspects of language production [Cohen, 1978] and comprehension [Allen, 1979]. As interest in these methods grows (e.g., see [Grosz, 1979; 13rachman, 1979]), the inadequacy of existing action models becomes increasingly obvious. The formalism for actions used in most natural language understanding systems is based on case grammar. Each action is represented by a set of assertions about the semantic roles the noun phrases play with respect to the verb. Such a formalism is a start, but does not explain how to represent what an action actually signifies. Hone is told that a certain action occurred, what does one know about how the world changed (or didn&apos;t change!). This </context>
<context position="16842" citStr="Allen, 1979" startWordPosition="2815" endWordPosition="2816">. Hare [197]]). However, by adding the belief that the action will occur into the notion of intention, we ensure that intentions must be at least as consistent as beliefs. Actions may be performed intentionally or unintentionally. For example, consider the action of breaking a window. Inferring intentionality from observed action is a crucial ability needed in order to communicate and cooperate with other agents. While it is difficult to express a logical connection between action and intention, one can identify pragmatic or plausible inferences that can be used in a computational model (see [Allen, 1979)). With these tools, we can attempt a more precise definition of hiding. The time intervals that will be required are: Thâ€”the time of the hiding event; Tsâ€”the time that Y is expected to see the book; &apos;111â€”the time when X believes Y will see the book during Ts, which must be BEFORE Th; Tb3â€” the time when X believes Y will not see the book during Ts, which must be BEFORE or DURING Th and A1TER Tbl. We will now define the predicate HIDE(agent,observer,object,ac)) which asserts that act is an action of hiding. Since it describes an action, we have the simple axiom capturing agency: (Jo rail agent,</context>
</contexts>
<marker>Allen, 1979</marker>
<rawString>Allen, J.F., &amp;quot;A Plan-Based Approach to Speech Act Recognition,&amp;quot; Ph.D. thesis, Dept. Computer Science, U. Toronto, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Maintaining Knowledge about Temporal Intervals,&amp;quot;</title>
<date>1981</date>
<tech>TR86,</tech>
<institution>Dept. Computer Science,</institution>
<marker>Allen, 1981</marker>
<rawString>Allen, J.F., &amp;quot;Maintaining Knowledge about Temporal Intervals,&amp;quot; TR86, Dept. Computer Science, U. Rochester, January 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J 13rachman</author>
<author>â€”Taxonomy</author>
</authors>
<title>Descriptions, and Individuals in Natural language Understanding,&amp;quot;</title>
<date>1979</date>
<booktitle>in Proc., 17th Annual Meeting of the Assoc&apos;n. for Computational Linguistics, 33-37,</booktitle>
<location>UCSD, La Jolla. CA,</location>
<marker>13rachman, â€”Taxonomy, 1979</marker>
<rawString>13rachman, R.J., â€”Taxonomy, Descriptions, and Individuals in Natural language Understanding,&amp;quot; in Proc., 17th Annual Meeting of the Assoc&apos;n. for Computational Linguistics, 33-37, UCSD, La Jolla. CA, August 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>If Bruce</author>
</authors>
<title>Belief Systems and language Understanding,&apos;&apos;</title>
<date>1975</date>
<tech>Report 2973,</tech>
<location>Bolt, Beranek &amp; Newman, Inc.,</location>
<marker>Bruce, 1975</marker>
<rawString>Bruce, If., &amp;quot;Belief Systems and language Understanding,&apos;&apos; Report 2973, Bolt, Beranek &amp; Newman, Inc., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
</authors>
<title>On Knowing What to Say: Planning Speech Acts,&amp;quot;</title>
<date>1978</date>
<tech>TR 118,</tech>
<institution>Dept. Computer Science, U.</institution>
<location>Toronto,</location>
<contexts>
<context position="1427" citStr="Cohen, 1978" startWordPosition="229" endWordPosition="230">eone is used as a motivating example. I. Introduction This paper suggests a formulation of events and actions that seems powerful enough to define a wide range of event and action verbs in English. This problem is interesting for two reasons. The first is that such a model is necessary to express the meaning of many sentences. The second is to analyze the language production and comprehension processes themselves as purposeful action. This was suggested some time ago by 13ruce [1975] and Schmidt [1975]. Detailed proposals have been implemented recently for some aspects of language production [Cohen, 1978] and comprehension [Allen, 1979]. As interest in these methods grows (e.g., see [Grosz, 1979; 13rachman, 1979]), the inadequacy of existing action models becomes increasingly obvious. The formalism for actions used in most natural language understanding systems is based on case grammar. Each action is represented by a set of assertions about the semantic roles the noun phrases play with respect to the verb. Such a formalism is a start, but does not explain how to represent what an action actually signifies. Hone is told that a certain action occurred, what does one know about how the world ch</context>
<context position="14903" citStr="Cohen, 1978" startWordPosition="2495" endWordPosition="2496">e the coat in the future course of events. Of course, in this case, the action Sam performed was &amp;quot;not bringing the coat,&amp;quot; which would normally not be considered an action unless it was intentionally not done. I claim that these three conditions provide a reasonably accurate definition of what it means to hide something. They certainly cover the four examples presented above. As stated previously, however, the definition is rather unsatisfactory, as many extremely difficult concepts, such as belief and intention, were thrown about casually. There is much recent work on models of belief (e.g., [Cohen, 1978; Moore, 1979; Perlis, 1981; Haas, 1981]). 1 have little to add to these efforts, so the reader may assume his or her favorite model. I will assume that belief is a modal operator and is described by a set of axioms along the lines of Hintikka 119621. The one important thing to notice, though, is that there are two relevant time indices to each belief; namely, the time over which the belief is held, and the time over which the proposition that is believed holds. For example, I might believe today that it rained last weekend. This point wiil be crucial in modeling the action of hiding. To intro</context>
</contexts>
<marker>Cohen, 1978</marker>
<rawString>Cohen, P.R., &amp;quot;On Knowing What to Say: Planning Speech Acts,&amp;quot; TR 118, Dept. Computer Science, U. Toronto, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidson</author>
</authors>
<title>The Logical Form of Action Sentences,&amp;quot; in N. Rescher (Ed). The Logic of Decision and Action.</title>
<date>1967</date>
<publisher>U. Pittsburgh Press,</publisher>
<location>Pittsburgh, PA:</location>
<marker>Davidson, 1967</marker>
<rawString>Davidson, D., â€”The Logical Form of Action Sentences,&amp;quot; in N. Rescher (Ed). The Logic of Decision and Action. Pittsburgh, PA: U. Pittsburgh Press, 1967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Pikes</author>
<author>N J Nilsson</author>
</authors>
<title>STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving,&amp;quot;</title>
<date>1971</date>
<journal>Artificial Intelligence</journal>
<volume>2</volume>
<pages>189--205</pages>
<marker>Pikes, Nilsson, 1971</marker>
<rawString>Pikes, R.E. and N.J. Nilsson. &amp;quot;STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving,&amp;quot; Artificial Intelligence 2, 189-205, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goldman</author>
</authors>
<title>A Theory of Human Action.</title>
<date>1970</date>
<publisher>U. Press,</publisher>
<location>New Jersey: Princeton</location>
<marker>Goldman, 1970</marker>
<rawString>Goldman, A. A Theory of Human Action. New Jersey: Princeton U. Press, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bi Grosz</author>
</authors>
<title>Utterance and Objective: Issues in Natural Language Communication,&amp;quot;</title>
<date>1979</date>
<booktitle>in Proc.. 6th IJCAI,</booktitle>
<pages>1067--1076</pages>
<location>Tokyo,</location>
<contexts>
<context position="1520" citStr="Grosz, 1979" startWordPosition="243" endWordPosition="244">ents and actions that seems powerful enough to define a wide range of event and action verbs in English. This problem is interesting for two reasons. The first is that such a model is necessary to express the meaning of many sentences. The second is to analyze the language production and comprehension processes themselves as purposeful action. This was suggested some time ago by 13ruce [1975] and Schmidt [1975]. Detailed proposals have been implemented recently for some aspects of language production [Cohen, 1978] and comprehension [Allen, 1979]. As interest in these methods grows (e.g., see [Grosz, 1979; 13rachman, 1979]), the inadequacy of existing action models becomes increasingly obvious. The formalism for actions used in most natural language understanding systems is based on case grammar. Each action is represented by a set of assertions about the semantic roles the noun phrases play with respect to the verb. Such a formalism is a start, but does not explain how to represent what an action actually signifies. Hone is told that a certain action occurred, what does one know about how the world changed (or didn&apos;t change!). This paper attempts to answer this question by outlining a tempora</context>
</contexts>
<marker>Grosz, 1979</marker>
<rawString>Grosz, Bi., &amp;quot;Utterance and Objective: Issues in Natural Language Communication,&amp;quot; in Proc.. 6th IJCAI, 1067-1076, Tokyo, August 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haas</author>
</authors>
<title>Sententialism and the Logic of Belief and Action,&amp;quot;</title>
<date>1981</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. Computer Science,</institution>
<location>U. Rochester, expected</location>
<contexts>
<context position="14942" citStr="Haas, 1981" startWordPosition="2501" endWordPosition="2502">s. Of course, in this case, the action Sam performed was &amp;quot;not bringing the coat,&amp;quot; which would normally not be considered an action unless it was intentionally not done. I claim that these three conditions provide a reasonably accurate definition of what it means to hide something. They certainly cover the four examples presented above. As stated previously, however, the definition is rather unsatisfactory, as many extremely difficult concepts, such as belief and intention, were thrown about casually. There is much recent work on models of belief (e.g., [Cohen, 1978; Moore, 1979; Perlis, 1981; Haas, 1981]). 1 have little to add to these efforts, so the reader may assume his or her favorite model. I will assume that belief is a modal operator and is described by a set of axioms along the lines of Hintikka 119621. The one important thing to notice, though, is that there are two relevant time indices to each belief; namely, the time over which the belief is held, and the time over which the proposition that is believed holds. For example, I might believe today that it rained last weekend. This point wiil be crucial in modeling the action of hiding. To introduce some notation, let &amp;quot;A believes (du</context>
</contexts>
<marker>Haas, 1981</marker>
<rawString>Haas, A., &amp;quot;Sententialism and the Logic of Belief and Action,&amp;quot; Ph.D. thesis, Dept. Computer Science, U. Rochester, expected 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Hare</author>
</authors>
<title>Wanting: Some Pitfalls,&amp;quot;</title>
<date>1971</date>
<booktitle>in Binkley, 13ronaugh, and Morras (Eds). Agent. Action, and Reason. Toronto: U.</booktitle>
<publisher>Toronto Press,</publisher>
<marker>Hare, 1971</marker>
<rawString>Hare, R.M. &amp;quot;Wanting: Some Pitfalls,&amp;quot; in Binkley, 13ronaugh, and Morras (Eds). Agent. Action, and Reason. Toronto: U. Toronto Press, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hintikka</author>
</authors>
<title>Knowledge and Belief</title>
<date>1962</date>
<publisher>Cornell U. Press,</publisher>
<location>Ithaca, NY:</location>
<marker>Hintikka, 1962</marker>
<rawString>Hintikka, J. Knowledge and Belief Ithaca, NY: Cornell U. Press, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jackendoff</author>
</authors>
<title>Toward an Explanatory Semantic Representation,&amp;quot; Linguistic &apos;Inquiry</title>
<date>1976</date>
<volume>7</volume>
<pages>89--150</pages>
<location>Winter</location>
<contexts>
<context position="11634" citStr="Jackendoff, 1976" startWordPosition="1937" endWordPosition="1938">oom),D while the latter sentence describes an event, and hence is of the form REMAIN-IN(Ball,Room,e) &amp; OCCURS(e,T). We may capture the logical equivalence of the two with the axiom: (forall b.r,e,t) REMAIN-IN(b,r,e) &amp; OCCUR(e,t) (=7) HOLDS(in(b,r),t) , The problem remains as to how the differences between these logically equivalent formulas arise in context. One possible difference is that the second may lead the reader to believe that it easily might not have been the case. Actions are events that involve an agent in one of two ways. The agent may cause the event or may allow the event (cf. [Jackendoff, 1976]). Corresponding to these two types of agency, there are two predicates, ACA USE and ALLOW, that take an agent, an event, and an action as arguments. Thus the assertion corresponding to &amp;quot;John moved B from S to G&amp;quot; is MOVE(B,G,S,el)ci ACAUSF:(Johnel,a1)&amp; OCCUR(al,t) The axiomatization for ACAUSE and ALLOW is tricky, but Jackendoff provides a reasonable starting set. In this paper, I shall only consider agency by causation further. The most important axiom about causality is (A.2) (forall a.eact,t) ACAUSE(a.eact) &amp; OCCUR(act,t) =7) OCCUR(et) For our purposes, one of the most important facts abou</context>
</contexts>
<marker>Jackendoff, 1976</marker>
<rawString>Jackendoff, R., &amp;quot;Toward an Explanatory Semantic Representation,&amp;quot; Linguistic &apos;Inquiry 7, 1, 89-150, Winter 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Reasoning about Knowledge and Action,&amp;quot;</title>
<date>1979</date>
<booktitle>Ph.D. thesis, MIT,</booktitle>
<contexts>
<context position="14916" citStr="Moore, 1979" startWordPosition="2497" endWordPosition="2498"> the future course of events. Of course, in this case, the action Sam performed was &amp;quot;not bringing the coat,&amp;quot; which would normally not be considered an action unless it was intentionally not done. I claim that these three conditions provide a reasonably accurate definition of what it means to hide something. They certainly cover the four examples presented above. As stated previously, however, the definition is rather unsatisfactory, as many extremely difficult concepts, such as belief and intention, were thrown about casually. There is much recent work on models of belief (e.g., [Cohen, 1978; Moore, 1979; Perlis, 1981; Haas, 1981]). 1 have little to add to these efforts, so the reader may assume his or her favorite model. I will assume that belief is a modal operator and is described by a set of axioms along the lines of Hintikka 119621. The one important thing to notice, though, is that there are two relevant time indices to each belief; namely, the time over which the belief is held, and the time over which the proposition that is believed holds. For example, I might believe today that it rained last weekend. This point wiil be crucial in modeling the action of hiding. To introduce some not</context>
</contexts>
<marker>Moore, 1979</marker>
<rawString>Moore, R.C., &amp;quot;Reasoning about Knowledge and Action,&amp;quot; Ph.D. thesis, MIT, February 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Perlis</author>
</authors>
<title>Language, Computation, and Reality,&amp;quot;</title>
<date>1981</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. Computer Science,</institution>
<location>U. Rochester,</location>
<contexts>
<context position="14930" citStr="Perlis, 1981" startWordPosition="2499" endWordPosition="2500">ourse of events. Of course, in this case, the action Sam performed was &amp;quot;not bringing the coat,&amp;quot; which would normally not be considered an action unless it was intentionally not done. I claim that these three conditions provide a reasonably accurate definition of what it means to hide something. They certainly cover the four examples presented above. As stated previously, however, the definition is rather unsatisfactory, as many extremely difficult concepts, such as belief and intention, were thrown about casually. There is much recent work on models of belief (e.g., [Cohen, 1978; Moore, 1979; Perlis, 1981; Haas, 1981]). 1 have little to add to these efforts, so the reader may assume his or her favorite model. I will assume that belief is a modal operator and is described by a set of axioms along the lines of Hintikka 119621. The one important thing to notice, though, is that there are two relevant time indices to each belief; namely, the time over which the belief is held, and the time over which the proposition that is believed holds. For example, I might believe today that it rained last weekend. This point wiil be crucial in modeling the action of hiding. To introduce some notation, let &amp;quot;A </context>
</contexts>
<marker>Perlis, 1981</marker>
<rawString>Perlis D., &amp;quot;Language, Computation, and Reality,&amp;quot; Ph.D. thesis, Dept. Computer Science, U. Rochester, 1981,</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Sacerdoti</author>
</authors>
<title>A Structure for Plans and Behavior.</title>
<date>1977</date>
<publisher>Elsevier North-Holland, Inc.,</publisher>
<location>New York:</location>
<marker>Sacerdoti, 1977</marker>
<rawString>Sacerdoti, E.D. A Structure for Plans and Behavior. New York: Elsevier North-Holland, Inc., 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>R Abelson</author>
</authors>
<title>Scripi Plan Goal .g and Understanding. Hillsdale, NJ: Lawrence Erlbaum Associates,</title>
<date>1977</date>
<marker>Schank, Abelson, 1977</marker>
<rawString>Schank, R. and R. Abelson. Scripi Plan Goal .g and Understanding. Hillsdale, NJ: Lawrence Erlbaum Associates, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Schmidt</author>
</authors>
<title>Understanding Human Action,&amp;quot;</title>
<date>1975</date>
<booktitle>in Proc., Theoretical Issues in Natural Language Processing,</booktitle>
<location>Cambridge, MA,</location>
<marker>Schmidt, 1975</marker>
<rawString>Schmidt, C.F., &amp;quot;Understanding Human Action,&amp;quot; in Proc., Theoretical Issues in Natural Language Processing, Cambridge, MA, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>The Intentionality of Intention and Action,&amp;quot;</title>
<date>1980</date>
<journal>Cognitive Science</journal>
<volume>4</volume>
<contexts>
<context position="15996" citStr="Searle, 1980" startWordPosition="2683" endWordPosition="2684"> might believe today that it rained last weekend. This point wiil be crucial in modeling the action of hiding. To introduce some notation, let &amp;quot;A believes (during Tb) that p holds (during Tp)&amp;quot; be expressed as HO LDS(belieyes(A.holds(p.Tp)),Tb). 79 The notion of intention is much less understood than the notion of belief. However, let us approximate the statement &amp;quot;A intends (during Ti) that action a happen (during Ta)&amp;quot; by &amp;quot;A believes (during Ti) that a happen (during Ta)&amp;quot; and &amp;quot;A wants (during Ti) that a happen (during Ta)&amp;quot; This is obviously not a philosophically adequate definition (e.g., see [Searle, 1980, but seems sufficient for our present purposes. The notion of wanting indicates that the actor finds the action desirable given the alternatives. This notion appears impossible to axiomatize as wants do not appear to be rational (e.g. Hare [197]]). However, by adding the belief that the action will occur into the notion of intention, we ensure that intentions must be at least as consistent as beliefs. Actions may be performed intentionally or unintentionally. For example, consider the action of breaking a window. Inferring intentionality from observed action is a crucial ability needed in ord</context>
</contexts>
<marker>Searle, 1980</marker>
<rawString>Searle, J.R., &amp;quot;The Intentionality of Intention and Action,&amp;quot; Cognitive Science 4, 1, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Taylor</author>
</authors>
<title>Action and Purpose.</title>
<date>1966</date>
<publisher>Prentice Hall,</publisher>
<location>New Jersey:</location>
<contexts>
<context position="18867" citStr="Taylor, 1966" startWordPosition="3147" endWordPosition="3148">etween Tb] and Tb3) he or she will do an action (between Tb] and Th) as follows: (exists al,e1,Tb2 5) ACAUSE(agel,a1) 6) HOLDS(believes(ag,OCCUR(al,Tal)),Tb2) where Tb! Tb2 Tb3 and Tb! Tal &lt; rh But this has not captured the notion that belief (6) caused the change in belief from (2) to (3). Since (6) and (3) are true, asserting a logical implication from (6) to (3) would have no force. It is essential that the belief (6) be a key -element in the reasoning that leads to belief (3). To capture this we must introduce a notion of causality. This notion differs from ACA USE in many ways (e.g. see (Taylor, 19661), but for us the major difference is that, unlike ACA USE, it suggests no relation to intentionality. While ACA USE relates an agent to an event, CAUSE relates events to events. The events in question here would be coming to the belief (6), which CAUSES coming to the belief (3). One can see that much of what it means to hide is captured by the above. In particular, the following can be extracted directly from the definition: if you hide something, you intended to hide it, and thus can be held responsible for the action&apos;s consequences: one cannot hide something if it were not possible that it</context>
</contexts>
<marker>Taylor, 1966</marker>
<rawString>Taylor, R. Action and Purpose. New Jersey: Prentice Hall, 1966.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Understanding Goal-Based Stories,&amp;quot; Ph.D. thesis, Yale U.,</title>
<date>1978</date>
<marker>Wilensky, 1978</marker>
<rawString>Wilensky, R., &amp;quot;Understanding Goal-Based Stories,&amp;quot; Ph.D. thesis, Yale U., 1978.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>