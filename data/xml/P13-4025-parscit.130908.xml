<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004732">
<title confidence="0.991974">
ParaQuery: Making Sense of Paraphrase Collections
</title>
<author confidence="0.986062">
Lili Kotlerman Nitin Madnani and Aoife Cahill
</author>
<affiliation confidence="0.987663">
Bar-Ilan University Educational Testing Service
Israel Princeton, NJ, USA
</affiliation>
<email confidence="0.99336">
lili.dav@gmail.com {nmadnani,acahill}@ets.org
</email>
<sectionHeader confidence="0.993749" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999753666666667">
Pivoting on bilingual parallel corpora is a
popular approach for paraphrase acquisi-
tion. Although such pivoted paraphrase
collections have been successfully used to
improve the performance of several dif-
ferent NLP applications, it is still difficult
to get an intrinsic estimate of the qual-
ity and coverage of the paraphrases con-
tained in these collections. We present
ParaQuery, a tool that helps a user inter-
actively explore and characterize a given
pivoted paraphrase collection, analyze its
utility for a particular domain, and com-
pare it to other popular lexical similarity
resources – all within a single interface.
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999857411764706">
Paraphrases are widely used in many Natural Lan-
guage Processing (NLP) tasks, such as informa-
tion retrieval, question answering, recognizing
textual entailment, text simplification etc. For ex-
ample, a question answering system facing a ques-
tion “Who invented bifocals and lightning rods?”
could retrieve the correct answer from the text
“Benjamin Franklin invented strike termination
devices and bifocal reading glasses” given the in-
formation that “bifocal reading glasses” is a para-
phrase of “bifocals” and “strike termination de-
vices” is a paraphrase of “lightning rods”.
There are numerous approaches for automati-
cally extracting paraphrases from text (Madnani
and Dorr, 2010). We focus on generating para-
phrases by pivoting on bilingual parallel corpora
as originally suggested by Bannard and Callison-
Burch (2005). This technique operates by attempt-
ing to infer semantic equivalence between phrases
in the same language by using a second language
as a bridge. It builds on one of the initial steps used
to train a phrase-based statistical machine transla-
tion system. Such systems rely on phrase tables –
a tabulation of correspondences between phrases
in the source language and phrases in the target
language. These tables are usually extracted by in-
ducing word alignments between sentence pairs in
a parallel training corpus and then incrementally
building longer phrasal correspondences from in-
dividual words and shorter phrases. Once such a
tabulation of bilingual correspondences is avail-
able, correspondences between phrases in one lan-
guage may be inferred simply by using the phrases
in the other language as pivots, e.g., if both “man”
and “person” correspond to “personne” in French,
then they can be considered paraphrases. Each
paraphrase pair (rule) in a pivoted paraphrase col-
lection is defined by a source phrase e1, the target
phrase e2 that has been inferred as its paraphrase,
and a probability score p(e2|e1) obtained from the
probability values in the bilingual phrase table.1
Pivoted paraphrase collections have been suc-
cessfully used in different NLP tasks including
automated document summarization (Zhou et al.,
2006), question answering (Riezler et al., 2007),
and machine translation (Madnani, 2010). Yet, it
is still difficult to get an estimate of the intrinsic
quality and coverage of the paraphrases contained
in these collections. To remedy this, we propose
ParaQuery – a tool that can help explore and ana-
lyze pivoted paraphrase collections.
</bodyText>
<sectionHeader confidence="0.989207" genericHeader="introduction">
2 ParaQuery
</sectionHeader>
<bodyText confidence="0.999881285714286">
In this section we first briefly describe how to set
up ParaQuery (§2.1) and then demonstrate its use
in detail for interactively exploring and character-
izing a paraphrase collection, analyzing its util-
ity for a particular domain, and comparing it with
other word-similarity resources (§2.2). Detailed
documentation will be included in the tool.
</bodyText>
<footnote confidence="0.9995275">
1There may be other values associated with each pair, but
we ignore them for the purposes of this paper.
</footnote>
<page confidence="0.939967">
145
</page>
<note confidence="0.454031">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 145–150,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.999538">
2.1 Setting up
</subsectionHeader>
<bodyText confidence="0.9999852">
ParaQuery operates on pivoted paraphrase collec-
tions and can accept collections generated using
any set of tools that are preferred by the user, as
long as the collection is stored in a pre-defined
plain-text format containing the source and target
phrases, the probability values, as well as informa-
tion on pivots (optional but useful for pivot-driven
analysis, as shown later). This format is com-
monly used in the machine translation and para-
phrase generation community. In this paper, we
adapt the Thrax and Joshua (Ganitkevitch et al.,
2012) toolkits to generate a pivoted paraphrase
collection using the English-French EuroParl par-
allel corpus, which we use as our example col-
lection for demonstrating ParaQuery. Once a piv-
oted collection is generated, ParaQuery needs to
convert it into an SQLite database against which
queries can be run. This is done by issuing the
index command at the ParaQuery command-line
interface (described in §2.2.1).
</bodyText>
<subsectionHeader confidence="0.99931">
2.2 Exploration and Analysis
</subsectionHeader>
<bodyText confidence="0.9995602">
In order to provide meaningful exploration and
analysis, we studied various scenarios in which
paraphrase collections are used, and found that the
following issues typically interest the developers
and users of such collections:
</bodyText>
<listItem confidence="0.99700275">
1. Semantic relations between the paraphrases
in the collection (e.g. synonymy, hyponymy)
and their frequency.
2. The frequency of inaccurate paraphrases,
possible ways of de-noising the collection,
and the meaningfulness of scores (better
paraphrases should be scored higher).
3. The utility of the collection for a specific do-
main, i.e. whether domain terms of interest
are present in the collection.
4. Comparison of different collections based on
the above dimensions.
</listItem>
<bodyText confidence="0.999887777777778">
We note that paraphrase collections are used in
many tasks with different acceptability thresholds
for semantic relations, noisy paraphrases etc. We
do not intend to provide an exhaustive judgment
of paraphrase quality, but instead allow users to
characterize a collection, enabling an analysis of
the aforesaid issues and providing information for
them to decide whether a given collection is suit-
able for their specific task and/or domain.
</bodyText>
<subsectionHeader confidence="0.805043">
2.2.1 Command line interface
</subsectionHeader>
<bodyText confidence="0.999397692307692">
ParaQuery allows interactive exploration and
analysis via a simple command line interface, by
processing user issued queries such as:
show &lt;query&gt;: display the rules which satisfy
the conditions of the given query.
show count &lt;query&gt;: display the number of
such rules.
explain &lt;query&gt;: display information about the
pivots which yielded each of these rules.
analyze &lt;query&gt;: display statistics about these
rules and save a report to an output file.
The following information is stored in the
SQLite database for each paraphrase rule:2
</bodyText>
<listItem confidence="0.859627642857143">
• The source and the target phrases, and the
probability score of the rule.
• Are the source and the target identical?
• Do the source and the target have the same
part of speech?3
• Length of the source and the target, and the
difference in their lengths.
• Number of pivots and the list of pivots.
• Are both the source and the target found in
WordNet (WN)? If yes, the WN relation be-
tween them (synonym, derivation, hypernym,
hyponym, co-hyponym, antonym, meronym,
holonym, pertainym) or the minimal dis-
tance, if they are not connected directly.
</listItem>
<bodyText confidence="0.999801818181818">
Therefore, all of the above can be used, alone or
in combination, to constrain the queries and de-
fine the rule(s) of interest. Figure 1 presents sim-
ple queries processed by the show command: the
first query displays top-scoring rules with “man”
as their source phrase, while the second adds re-
striction on the rules’ score. By default, the tool
displays the 10 best-scoring rules per query, but
this limit can be changed as shown. For each
rule, the corresponding score and semantic rela-
tion/distance is displayed.
</bodyText>
<footnote confidence="0.495563125">
2Although some of this information is available in the
paraphrase collection that was indexed, the remaining is auto-
matically computed and injected into the database during the
indexing process. Indexing the French-pivoted paraphrase
collection (containing 3,633,015 paraphrase rules) used in
this paper took about 6 hours.
3We use the simple parts of speech provided by WordNet
(nouns, verbs, adjectives and adverbs).
</footnote>
<page confidence="0.996209">
146
</page>
<bodyText confidence="0.986654909090909">
The queries provide a flexible way to define and
work with the rule set of interest, starting from fil-
tering low-scoring rules till extracting specific se-
mantic relations or constraining on the number of
pivots. Figure 2 presents additional examples of
queries. The tool also enables filtering out target
terms with a recurrent lemma, as illustrated in the
same figure. Note that ParaQuery also contains a
batch mode (in addition to the interactive mode il-
lustrated so far) to automatically extract the output
for a set of queries contained in a batch script.
</bodyText>
<figureCaption confidence="0.994956">
Figure 1: Examples of the show command and the
probability constraint.
</figureCaption>
<subsectionHeader confidence="0.85167">
2.2.2 Analyzing pivot information
</subsectionHeader>
<bodyText confidence="0.999995157894737">
It is well known that pivoted paraphrase collec-
tions contain a lot of noisy rules. To understand
the origins of such rules, an explain query can be
used, which displays the pivots that yielded each
paraphrase rule, and the probability share of each
pivot in the final probability score. Figure 3 shows
an example of this command.
We see that noisy rules can originate from stop-
word pivots, e.g. “l”. It is common to filter rules
containing stop-words, yet perhaps it is also im-
portant to exclude stop-word pivots, which was
never considered in the past. We can use Para-
Query to further explore whether discarding stop-
word pivots is a good idea. Figure 4 presents
a more complex query showing paraphrase rules
that were extracted via a single pivot “l”. We see
that the top 5 such rules are indeed noisy, indicat-
ing that perhaps all of the 5,360 rules satisfying
the query can be filtered out.
</bodyText>
<subsectionHeader confidence="0.969329">
2.2.3 Analysis of rule sets
</subsectionHeader>
<bodyText confidence="0.985111">
In order to provide an overall analysis of a rule set
or a complete collection, ParaQuery includes the
</bodyText>
<figureCaption confidence="0.99925425">
Figure 2: Restricting the output of the show com-
mand using WordNet relations and distance, and
the unique lemma constraint.
Figure 3: An example of the explain command.
</figureCaption>
<bodyText confidence="0.999723916666667">
analyze command. Figure 5 shows the typical in-
formation provided by this command. In addition,
a report is generated to a file, including the anal-
ysis information for the whole rule set and for its
three parts: top, middle and bottom, as defined by
the scores of the rules in the set. The output to the
file is more detailed and expands on the informa-
tion presented in Figure 5. For example, it also
includes, for each part, rule samples and score dis-
tributions for each semantic relation and different
WordNet distances.
The information contained in the report can be
</bodyText>
<page confidence="0.997096">
147
</page>
<figureCaption confidence="0.999754">
Figure 4: Exploring French stop-word pivots using the pivots condition of the show command.
Figure 5: An example of the analyze command (full output not shown for space reasons).
</figureCaption>
<page confidence="0.971337">
148
</page>
<table confidence="0.998861857142857">
TOP BOTTOM
finest ⇒ better approach ⇒ el
outdoors ⇒ external effect ⇒ parliament
unsettled ⇒ unstable comment ⇒ speak up
intelligentsia ⇒ intelligence propose ⇒ allotted
caretaker ⇒ provisional prevent ⇒ aimed
luckily ⇒ happily energy ⇒ subject matter
</table>
<tableCaption confidence="0.962586">
Table 1: A random sample of undefined relation
rules from our collection’s top and bottom parts.
</tableCaption>
<bodyText confidence="0.996434393939394">
easily used for generating graphs and tables. For
example, Figure 6 shows the distribution of se-
mantic relations in the three parts of our exam-
ple paraphrase collection. The figure character-
izes the collection in terms of semantic relations
it contains and illustrates the fact that the scores
agree with their desired behavior: (1) the collec-
tion’s top-scoring part contains significantly more
synonyms than its middle and bottom parts, (2)
similar trends hold for derivations and hypernyms,
which are more suitable for paraphrasing than co-
hyponyms and other relations not defined in Word-
Net (we refer to these relations as undefined rela-
tions), (3) such undefined relations have the high-
est frequency in the collection’s bottom part, and
are least frequent in its top part. Among other
conclusions, the figure shows, that discarding the
lower-scoring middle and bottom parts of the col-
lection would allow retaining almost all the syn-
onyms and derivations, while filtering out most of
the co-hyponyms and a considerable number of
undefined relations.
Yet from Figure 6 we see that undefined rela-
tions constitute the majority of the rules in the col-
lection. To better understand this, random rule
samples provided in the analysis output can be
used, as shown in Table 1. From this table, we see
that the top-part rules are indeed mostly valid for
paraphrasing, unlike the noisy bottom-part rules.
The score distributions reported as part of the anal-
ysis can be used to further explore the collec-
tion and set sound thresholds suitable for different
tasks and needs.
</bodyText>
<subsectionHeader confidence="0.997046">
2.2.4 Analysis of domain utility
</subsectionHeader>
<bodyText confidence="0.999941625">
One of the frequent questions of interest is
whether a given collection is suitable for a specific
domain. To answer this question, ParaQuery al-
lows the user to run the analysis from §2.2.3 over
rules whose source phrases belong to a specific
domain, by means of the analyze &lt;query&gt; us-
ing &lt;file&gt; command. The file can hold either a
list of domain terms or a representative domain
text, from which frequent terms and term collo-
cations will be automatically extracted, presented
to the user, and utilized for analysis. The analysis
includes the coverage of the domain terms in the
paraphrase collection, and can also be restricted to
top-K rules per source term, a common practice in
many NLP applications. We do not show an exam-
ple of this command due to space considerations.
</bodyText>
<subsectionHeader confidence="0.986988">
2.2.5 Comparison with other collections
</subsectionHeader>
<bodyText confidence="0.999940259259259">
The output of the analyze command can also be
used to compare different collections, either in
general or for a given domain. Although Para-
Query is designed for pivoted paraphrase collec-
tions, it allows comparing them to non-pivoted
paraphrase collections as well. Next we present an
example of such a comparative study, performed
using ParaQuery via several analyze commands.
Table 2 compares three different collections:
the French pivoted paraphrase collection, a dis-
tributional similarity resource (Kotlerman et al.,
2010) and a Wikipedia-based resource (Shnarch et
al., 2009). The table shows the collection sizes,
as well as the number of different (unique) source
phrases in them and, correspondingly, the average
number of target phrases per source. From the
table we can see that the distributional similarity
resource contains a lot of general language terms
found in WordNet, while the Wikipedia resource
includes only a small amount of such terms. A
sample of rules from the Wikipedia collection ex-
plains this behavior, e.g. ‘Yamaha SR500 ⇒ mo-
torcycle’. The table provides helpful information
to decide which collection is (more) suitable for
specific tasks, such as paraphrase recognition and
generation, query expansion, automatic generation
of training data for different supervised tasks, etc.
</bodyText>
<sectionHeader confidence="0.998708" genericHeader="conclusions">
3 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999988">
We presented ParaQuery—a tool for interactive
exploration and analysis of pivoted paraphrase
collections—and showed that it can be used to
estimate the intrinsic quality and coverage of the
paraphrases contained in these collections, a task
that is still somewhat difficult. ParaQuery can also
be used to answer the questions that users of such
collections are most interested in. We plan to re-
lease ParaQuery under an open-source license, in-
cluding our code for generating paraphrase col-
lections that can then be indexed and analyzed by
</bodyText>
<page confidence="0.994309">
149
</page>
<figure confidence="0.417387">
Synonym Derivation Hypernym Hyponym Co-hyponym Antonym Undefined
</figure>
<figureCaption confidence="0.95817">
Figure 6: Distribution of semantic relations in the top, middle and bottom parts of the example collection.
The parts are defined by binning the scores of the rules in the collection.
</figureCaption>
<table confidence="0.998947">
Collection Size (rules) In WordNet Unique Src Avg. Tgts per Src davg for UR
Pivoted (FR) 3,633,015 757,994 (21%) 188,898 16.064 2.567
Dist.Sim. 7,298,321 3,252,967 (45%) 113,444 64.334 6.043
Wikipedia 7,880,962 295,161 (4%) 2,727,362 2.890 8.556
</table>
<tableCaption confidence="0.982773">
Table 2: Comparing the French-pivoted paraphrase collection to distributional-similarity based and
</tableCaption>
<bodyText confidence="0.860576">
Wikipedia-based similarity collections, in terms of total size, percentage of rules in WordNet, number
of unique source phrases, average number of target phrases per source phrase, and the average WordNet
distance between the two sides of the undefined relation (UR) rules.
</bodyText>
<figure confidence="0.99733535">
22%
6%
Top Middle Bottom
1%
11%
1% 0% 8% 4% 1% 4% 4% 8%
1%
17%
11%
0%
0%
0%
45%
68%
86%
80%
60%
40%
20%
0%
</figure>
<bodyText confidence="0.983527357142857">
ParaQuery. We also plan to include pre-generated
paraphrase collections in the release so that users
of ParaQuery can use it immediately.
In the future, we plan to use this tool for analyz-
ing the nature of pivoted paraphrases. The quality
and coverage of these paraphrases is known to de-
pend on several factors, including (a) the genre of
the bilingual corpus, (b) the word-alignment algo-
rithm used during bilingual training, and (c) the
pivot language itself. However, there have been
no explicit studies designed to measure such vari-
ations. We believe that ParaQuery is perfectly
suited to conducting such studies and moving the
field of automated paraphrase generation forward.
</bodyText>
<sectionHeader confidence="0.998435" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.946495">
This work was partially supported by the European Commu-
nity’s Seventh Framework Programme (FP7/2007-2013) un-
der grant agreement no. 287923 (EXCITEMENT).
</bodyText>
<sectionHeader confidence="0.998422" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999935931034483">
Colin Bannard and Chris Callison-Burch. 2005. Paraphras-
ing with Bilingual Parallel Corpora. In Proceedings of
ACL, pages 597–604.
Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, and
Chris Callison-Burch. 2012. Joshua 4.0: Packing, PRO,
and Paraphrases. In Proceedings of WMT, pages 283–291.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional Distributional
Similarity for Lexical Inference. Natural Language En-
gineering, 16(4):359–389.
Nitin Madnani and Bonnie J. Dorr. 2010. Generating
Phrasal and Sentential Paraphrases: A Survey of Data-
driven Methods. Computational Linguistics, 36(3):341–
387.
Nitin Madnani. 2010. The Circle of Meaning: From Trans-
lation to Paraphrasing and Back. Ph.D. thesis, Depart-
ment of Computer Science, University of Maryland Col-
lege Park.
Stefan Riezler, Alexander Vasserman, Ioannis Tsochan-
taridis, Vibhu O. Mittal, and Yi Liu. 2007. Statistical
Machine Translation for Query Expansion in Answer Re-
trieval. In Proceedings of ACL, pages 464–471.
Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Extracting
lexical reference rules from Wikipedia. In Proceedings of
ACL-IJCNLP, pages 450–458.
Liang Zhou, Chin-Yew Lin, Dragos Stefan Muntenau, and
Eduard Hovy. 2006. ParaEval: Using Paraphrases to
Evaluate Summaries Automatically. In Proceedings of
HLT-NAACL, pages 447–454.
</reference>
<page confidence="0.998319">
150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909803">
<title confidence="0.999932">ParaQuery: Making Sense of Paraphrase Collections</title>
<author confidence="0.979117">Lili Kotlerman Nitin Madnani</author>
<author confidence="0.979117">Aoife Cahill</author>
<affiliation confidence="0.987729">Bar-Ilan University Educational Testing Service</affiliation>
<address confidence="0.953854">Israel Princeton, NJ, USA</address>
<abstract confidence="0.9985845625">Pivoting on bilingual parallel corpora is a popular approach for paraphrase acquisition. Although such pivoted paraphrase collections have been successfully used to improve the performance of several different NLP applications, it is still difficult to get an intrinsic estimate of the quality and coverage of the paraphrases contained in these collections. We present a tool that helps a user interactively explore and characterize a given pivoted paraphrase collection, analyze its utility for a particular domain, and compare it to other popular lexical similarity resources – all within a single interface.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with Bilingual Parallel Corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>597--604</pages>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with Bilingual Parallel Corpora. In Proceedings of ACL, pages 597–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Yuan Cao</author>
<author>Jonathan Weese</author>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Joshua 4.0: Packing, PRO, and Paraphrases.</title>
<date>2012</date>
<booktitle>In Proceedings of WMT,</booktitle>
<pages>283--291</pages>
<contexts>
<context position="4552" citStr="Ganitkevitch et al., 2012" startWordPosition="691" endWordPosition="694">August 4-9 2013. c�2013 Association for Computational Linguistics 2.1 Setting up ParaQuery operates on pivoted paraphrase collections and can accept collections generated using any set of tools that are preferred by the user, as long as the collection is stored in a pre-defined plain-text format containing the source and target phrases, the probability values, as well as information on pivots (optional but useful for pivot-driven analysis, as shown later). This format is commonly used in the machine translation and paraphrase generation community. In this paper, we adapt the Thrax and Joshua (Ganitkevitch et al., 2012) toolkits to generate a pivoted paraphrase collection using the English-French EuroParl parallel corpus, which we use as our example collection for demonstrating ParaQuery. Once a pivoted collection is generated, ParaQuery needs to convert it into an SQLite database against which queries can be run. This is done by issuing the index command at the ParaQuery command-line interface (described in §2.2.1). 2.2 Exploration and Analysis In order to provide meaningful exploration and analysis, we studied various scenarios in which paraphrase collections are used, and found that the following issues t</context>
</contexts>
<marker>Ganitkevitch, Cao, Weese, Post, Callison-Burch, 2012</marker>
<rawString>Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, and Chris Callison-Burch. 2012. Joshua 4.0: Packing, PRO, and Paraphrases. In Proceedings of WMT, pages 283–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lili Kotlerman</author>
<author>Ido Dagan</author>
<author>Idan Szpektor</author>
<author>Maayan Zhitomirsky-Geffet</author>
</authors>
<title>Directional Distributional Similarity for Lexical Inference.</title>
<date>2010</date>
<journal>Natural Language Engineering,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="14085" citStr="Kotlerman et al., 2010" startWordPosition="2243" endWordPosition="2246"> an example of this command due to space considerations. 2.2.5 Comparison with other collections The output of the analyze command can also be used to compare different collections, either in general or for a given domain. Although ParaQuery is designed for pivoted paraphrase collections, it allows comparing them to non-pivoted paraphrase collections as well. Next we present an example of such a comparative study, performed using ParaQuery via several analyze commands. Table 2 compares three different collections: the French pivoted paraphrase collection, a distributional similarity resource (Kotlerman et al., 2010) and a Wikipedia-based resource (Shnarch et al., 2009). The table shows the collection sizes, as well as the number of different (unique) source phrases in them and, correspondingly, the average number of target phrases per source. From the table we can see that the distributional similarity resource contains a lot of general language terms found in WordNet, while the Wikipedia resource includes only a small amount of such terms. A sample of rules from the Wikipedia collection explains this behavior, e.g. ‘Yamaha SR500 ⇒ motorcycle’. The table provides helpful information to decide which colle</context>
</contexts>
<marker>Kotlerman, Dagan, Szpektor, Zhitomirsky-Geffet, 2010</marker>
<rawString>Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-Geffet. 2010. Directional Distributional Similarity for Lexical Inference. Natural Language Engineering, 16(4):359–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating Phrasal and Sentential Paraphrases: A Survey of Datadriven Methods.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<pages>387</pages>
<contexts>
<context position="1540" citStr="Madnani and Dorr, 2010" startWordPosition="220" endWordPosition="223">ocessing (NLP) tasks, such as information retrieval, question answering, recognizing textual entailment, text simplification etc. For example, a question answering system facing a question “Who invented bifocals and lightning rods?” could retrieve the correct answer from the text “Benjamin Franklin invented strike termination devices and bifocal reading glasses” given the information that “bifocal reading glasses” is a paraphrase of “bifocals” and “strike termination devices” is a paraphrase of “lightning rods”. There are numerous approaches for automatically extracting paraphrases from text (Madnani and Dorr, 2010). We focus on generating paraphrases by pivoting on bilingual parallel corpora as originally suggested by Bannard and CallisonBurch (2005). This technique operates by attempting to infer semantic equivalence between phrases in the same language by using a second language as a bridge. It builds on one of the initial steps used to train a phrase-based statistical machine translation system. Such systems rely on phrase tables – a tabulation of correspondences between phrases in the source language and phrases in the target language. These tables are usually extracted by inducing word alignments b</context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>Nitin Madnani and Bonnie J. Dorr. 2010. Generating Phrasal and Sentential Paraphrases: A Survey of Datadriven Methods. Computational Linguistics, 36(3):341– 387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
</authors>
<title>The Circle of Meaning: From Translation to Paraphrasing and Back.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, University of Maryland College Park.</institution>
<contexts>
<context position="3089" citStr="Madnani, 2010" startWordPosition="462" endWordPosition="463">ge as pivots, e.g., if both “man” and “person” correspond to “personne” in French, then they can be considered paraphrases. Each paraphrase pair (rule) in a pivoted paraphrase collection is defined by a source phrase e1, the target phrase e2 that has been inferred as its paraphrase, and a probability score p(e2|e1) obtained from the probability values in the bilingual phrase table.1 Pivoted paraphrase collections have been successfully used in different NLP tasks including automated document summarization (Zhou et al., 2006), question answering (Riezler et al., 2007), and machine translation (Madnani, 2010). Yet, it is still difficult to get an estimate of the intrinsic quality and coverage of the paraphrases contained in these collections. To remedy this, we propose ParaQuery – a tool that can help explore and analyze pivoted paraphrase collections. 2 ParaQuery In this section we first briefly describe how to set up ParaQuery (§2.1) and then demonstrate its use in detail for interactively exploring and characterizing a paraphrase collection, analyzing its utility for a particular domain, and comparing it with other word-similarity resources (§2.2). Detailed documentation will be included in the</context>
</contexts>
<marker>Madnani, 2010</marker>
<rawString>Nitin Madnani. 2010. The Circle of Meaning: From Translation to Paraphrasing and Back. Ph.D. thesis, Department of Computer Science, University of Maryland College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Alexander Vasserman</author>
<author>Ioannis Tsochantaridis</author>
<author>Vibhu O Mittal</author>
<author>Yi Liu</author>
</authors>
<title>Statistical Machine Translation for Query Expansion in Answer Retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>464--471</pages>
<contexts>
<context position="3048" citStr="Riezler et al., 2007" startWordPosition="455" endWordPosition="458"> simply by using the phrases in the other language as pivots, e.g., if both “man” and “person” correspond to “personne” in French, then they can be considered paraphrases. Each paraphrase pair (rule) in a pivoted paraphrase collection is defined by a source phrase e1, the target phrase e2 that has been inferred as its paraphrase, and a probability score p(e2|e1) obtained from the probability values in the bilingual phrase table.1 Pivoted paraphrase collections have been successfully used in different NLP tasks including automated document summarization (Zhou et al., 2006), question answering (Riezler et al., 2007), and machine translation (Madnani, 2010). Yet, it is still difficult to get an estimate of the intrinsic quality and coverage of the paraphrases contained in these collections. To remedy this, we propose ParaQuery – a tool that can help explore and analyze pivoted paraphrase collections. 2 ParaQuery In this section we first briefly describe how to set up ParaQuery (§2.1) and then demonstrate its use in detail for interactively exploring and characterizing a paraphrase collection, analyzing its utility for a particular domain, and comparing it with other word-similarity resources (§2.2). Detai</context>
</contexts>
<marker>Riezler, Vasserman, Tsochantaridis, Mittal, Liu, 2007</marker>
<rawString>Stefan Riezler, Alexander Vasserman, Ioannis Tsochantaridis, Vibhu O. Mittal, and Yi Liu. 2007. Statistical Machine Translation for Query Expansion in Answer Retrieval. In Proceedings of ACL, pages 464–471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eyal Shnarch</author>
<author>Libby Barak</author>
<author>Ido Dagan</author>
</authors>
<title>Extracting lexical reference rules from Wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>450--458</pages>
<contexts>
<context position="14139" citStr="Shnarch et al., 2009" startWordPosition="2251" endWordPosition="2254"> 2.2.5 Comparison with other collections The output of the analyze command can also be used to compare different collections, either in general or for a given domain. Although ParaQuery is designed for pivoted paraphrase collections, it allows comparing them to non-pivoted paraphrase collections as well. Next we present an example of such a comparative study, performed using ParaQuery via several analyze commands. Table 2 compares three different collections: the French pivoted paraphrase collection, a distributional similarity resource (Kotlerman et al., 2010) and a Wikipedia-based resource (Shnarch et al., 2009). The table shows the collection sizes, as well as the number of different (unique) source phrases in them and, correspondingly, the average number of target phrases per source. From the table we can see that the distributional similarity resource contains a lot of general language terms found in WordNet, while the Wikipedia resource includes only a small amount of such terms. A sample of rules from the Wikipedia collection explains this behavior, e.g. ‘Yamaha SR500 ⇒ motorcycle’. The table provides helpful information to decide which collection is (more) suitable for specific tasks, such as p</context>
</contexts>
<marker>Shnarch, Barak, Dagan, 2009</marker>
<rawString>Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Extracting lexical reference rules from Wikipedia. In Proceedings of ACL-IJCNLP, pages 450–458.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Chin-Yew Lin</author>
<author>Dragos Stefan Muntenau</author>
<author>Eduard Hovy</author>
</authors>
<title>ParaEval: Using Paraphrases to Evaluate Summaries Automatically.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>447--454</pages>
<contexts>
<context position="3005" citStr="Zhou et al., 2006" startWordPosition="449" endWordPosition="452"> phrases in one language may be inferred simply by using the phrases in the other language as pivots, e.g., if both “man” and “person” correspond to “personne” in French, then they can be considered paraphrases. Each paraphrase pair (rule) in a pivoted paraphrase collection is defined by a source phrase e1, the target phrase e2 that has been inferred as its paraphrase, and a probability score p(e2|e1) obtained from the probability values in the bilingual phrase table.1 Pivoted paraphrase collections have been successfully used in different NLP tasks including automated document summarization (Zhou et al., 2006), question answering (Riezler et al., 2007), and machine translation (Madnani, 2010). Yet, it is still difficult to get an estimate of the intrinsic quality and coverage of the paraphrases contained in these collections. To remedy this, we propose ParaQuery – a tool that can help explore and analyze pivoted paraphrase collections. 2 ParaQuery In this section we first briefly describe how to set up ParaQuery (§2.1) and then demonstrate its use in detail for interactively exploring and characterizing a paraphrase collection, analyzing its utility for a particular domain, and comparing it with ot</context>
</contexts>
<marker>Zhou, Lin, Muntenau, Hovy, 2006</marker>
<rawString>Liang Zhou, Chin-Yew Lin, Dragos Stefan Muntenau, and Eduard Hovy. 2006. ParaEval: Using Paraphrases to Evaluate Summaries Automatically. In Proceedings of HLT-NAACL, pages 447–454.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>