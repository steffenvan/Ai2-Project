<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001618">
<title confidence="0.998103">
A Distant Supervision Approach to Semantic Role Labeling
</title>
<author confidence="0.998734">
Peter Exner Marcus Klang Pierre Nugues
</author>
<affiliation confidence="0.999055">
Lund University
Department of Computer Science
</affiliation>
<address confidence="0.789412">
Lund, Sweden
</address>
<email confidence="0.993403">
{Peter.Exner, Marcus.Klang, Pierre.Nugues}@cs.lth.se
</email>
<sectionHeader confidence="0.998558" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999773346153846">
Semantic role labeling has become a key mod-
ule for many language processing applica-
tions such as question answering, information
extraction, sentiment analysis, and machine
translation. To build an unrestricted semantic
role labeler, the first step is to develop a com-
prehensive proposition bank. However, creat-
ing such a bank is a costly enterprise, which
has only been achieved for a handful of lan-
guages.
In this paper, we describe a technique to build
proposition banks for new languages using
distant supervision. Starting from PropBank
in English and loosely parallel corpora such as
versions of Wikipedia in different languages,
we carried out a mapping of semantic propo-
sitions we extracted from English to syntactic
structures in Swedish using named entities.
We trained a semantic parser on the generated
Swedish propositions and we report the results
we obtained. Using the CoNLL 2009 evalua-
tion script, we could reach the scores of 52.25
for labeled propositions and 62.44 for the un-
labeled ones. We believe our approach can be
applied to train semantic role labelers for other
resource-scarce languages.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981641025641">
Semantic role labeling has become a key module for
many language processing applications and its im-
portance is growing in fields like question answer-
ing (Shen and Lapata, 2007), information extraction
(Christensen et al., 2010), sentiment analysis (Jo-
hansson and Moschitti, 2011), and machine trans-
lation (Liu and Gildea, 2010; Wu et al., 2011). To
build an unrestricted semantic role labeler, the first
step is to develop a comprehensive proposition bank.
However, building proposition banks is a costly en-
terprise and as a consequence of that, they only exist
for a handful of languages such as English, Chinese,
German, or Spanish.
In this paper, we describe a technique to create
proposition banks for new languages using distant
supervision. Our approach builds on the transfer of
semantic information through named entities. Start-
ing from an existing proposition bank, PropBank in
English (Palmer et al., 2005), and loosely parallel
corpora such as versions of Wikipedia in different
languages, we carried out a mapping of the semantic
propositions we extracted from English to syntactic
structures in the target language.
We parsed the English edition of Wikipedia up
to the predicate–argument structures using a se-
mantic role labeler (Bj¨orkelund et al., 2010a) and
the Swedish Wikipedia using a dependency parser
(Nivre et al., 2006). We extracted all the named
entities we found in the propositions and we dis-
ambiguated them using the Wikidata nomenclature1.
Using recurring entities, we aligned sentences in the
two languages; we transferred the semantic annota-
tion from English sentences to Swedish sentences;
and we could identify 2,333 predicate–argument
frames in Swedish.
Finally, we used the resulting corpus to train a
semantic role labeler for Swedish that enabled us
to evaluate the validity of our approach. Beyond
Swedish, we believe it can apply to any resource-
</bodyText>
<footnote confidence="0.995693">
1http://www.wikidata.org
</footnote>
<page confidence="0.939993">
239
</page>
<note confidence="0.967384">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 239–248,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.472689">
scarce language.
</bodyText>
<sectionHeader confidence="0.993578" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999965617647059">
The techniques we applied in this paper are simi-
lar to those used in the extraction of relations be-
tween entity mentions in a sentence, where rela-
tional facts are often expressed in the form of triples,
such as: (Seoul, CapitalOf, South Korea). While su-
pervised and unsupervised techniques have been ap-
plied to the extraction of such relations, they both
suffer from drawbacks. Supervised learning relies
on labor-intensive, hand-annotated corpora, while
unsupervised approaches have lower precision and
recall levels.
Distant supervision is an alternative to these ap-
proaches that was introduced by Craven and Kum-
lien (1999). They used a knowledge base of ex-
isting biological relations, automatically identified
sentences containing these relations, and trained a
classifier to recognize the relations. Distant supervi-
sion has been successfully transferred to other fields.
Mintz et al. (2009) describe a method for creat-
ing training data and relation classifiers without a
hand-labeled corpus. The authors used Freebase and
its binary relations between entities, such as (/loca-
tion/location/contains, Belgium, Nijlen). They ex-
tracted entity pairs from the sentences of a text and
matched them to those found in Freebase. Using
the entity pairs, the relations, and the corresponding
sentence text, they could train a relation extractor.
Pad´o and Lapata (2009) used parallel corpora and
constituent-based models to automatically project
FrameNet annotations from English to German.
Hoffmann et al. (2010) introduced Wikipedia in-
foboxes in relation extraction, where the authors
trained a classifier to predict the infobox schema of
an article prior to the extraction step. They used
relation-specific lexicons created from a web crawl
to train individual extractors for 5,025 relations and,
rather than running all these extractors on every ar-
ticle and sentence, they first predicted the schema of
an article and then executed the set of correspond-
ing extractors. Early work in distant supervision
assumed that an entity pair expresses a unique ex-
plicit relation type. Surdeanu et al. (2012) describe
an extended model, where each entity pair may link
multiple instances to multiple relations. Ritter et al.
(2013) used a latent-variable approach to model in-
formation gaps present in either the knowledge base
or the corresponding text.
As far as we know, all the work on relation extrac-
tion focused on the detection of specific semantic re-
lations between entities. In this paper, we describe
an extension and a generalization of it that poten-
tially covers all the relations tied to a predicate and
results in the systematic extraction of the semantic
propositions observed in a corpus.
Similarly to Mintz et al. (2009), we used an ex-
ternal resource of relational facts and we matched
the entity pairs in the relations to a Swedish text
corpus. However, our approach substantially dif-
fers from theirs by the form of the external resource,
which is a parsed corpus. To our best knowledge,
there is no Swedish repository of relational facts be-
tween entities in existence. Instead, we semantically
parsed an English corpus, in our case the English
edition of Wikipedia, and we matched, article by ar-
ticle, the resulting semantic structures to sentences
in the Swedish edition of Wikipedia. Using the gen-
erated Swedish semantic structures, we could train a
semantic role labeler.
</bodyText>
<sectionHeader confidence="0.991914" genericHeader="method">
3 Extending Semantic Role Labeling
</sectionHeader>
<bodyText confidence="0.999606222222222">
In our approach, we employ distantly supervised
techniques by combining semantic role labeling
(SRL) with entity linking. SRL goes beyond the
extraction of n-ary relations and captures a seman-
tic meaning of relations in the form of predicates–
argument structures. Since SRL extracts relations
between a predicate and its arguments, it can be con-
sidered as a form of relation extraction which in-
volves a deeper analysis.
However, the semantic units produced by classi-
cal semantic role labeling are still shallow, as they
do not resolve coreference or disambiguate named
entities. In this work, we selected the propositions,
where the arguments corresponded to named entities
and we resolved these entities in unique identifiers.
This results in a limited set of extended propositions
that we think are closer to the spirit of logical forms
and can apply in a cross-lingual setting.
</bodyText>
<page confidence="0.994711">
240
</page>
<table confidence="0.99947675">
Input Explanation # cand. Output
helsingborg c Railway station in Helsingborg 1 wikidata:Q3062731
k¨arna Medieval tower in Helsingborg 27 wikidata:Q1779457
berga District in Helsingborg 33 wikidata:Q25411
</table>
<tableCaption confidence="0.991916">
Table 1: Entries in the detection dictionary, all related to the city of Helsingborg in Sweden, with their unique Wikidata
Q-number and a short explanation in italics.
</tableCaption>
<sectionHeader confidence="0.975828" genericHeader="method">
4 Named Entity Linking
</sectionHeader>
<bodyText confidence="0.999930285714286">
Named entity linking (or disambiguation) (NED) is
the core step of distant supervision to anchor the par-
allel sentences and propositions. NED usually con-
sists of two steps: first, extract the entity mentions,
usually noun phrases, and if a mention corresponds
to a proper noun – a named entity –, link it to a
unique identifier.
For the English part, we used Wikifier (Ratinov
et al., 2011) to disambiguate entities. There was
no similar disambiguator for Swedish and those de-
scribed for English are not directly adaptable be-
cause they require resources that do not exist for this
language. We created a disambiguator targeted to
Swedish: NEDforia. NEDforia uses a Wikipedia
dump as input and automatically collects a list of
named entities from the corpus. It then extracts the
links and contexts of these entities to build disam-
biguation models. Given an input text, NEDforia
recognizes and disambiguates the named entities,
and annotates them with their corresponding Wiki-
data number.
</bodyText>
<subsectionHeader confidence="0.994523">
4.1 Entity Detection
</subsectionHeader>
<bodyText confidence="0.999865444444444">
We created a dictionary of entities from Wikipedia
using the combination of a POS tagger ( ¨Ostling,
2013), language-dependent uppercase rules, and
two entity databases: Freebase (Bollacker et al.,
2008) and YAGO2 (Hoffart et al., 2010). Ta-
ble 1 shows three dictionary entries, where an en-
try consists of a normalized form and the out-
put is a list of Wikidata candidates in the form
of Q-numbers. The output can be the native
Wikipedia page, if a Wikidata mapping could
not be found, as for “wikipedia.sv:Processork¨arna”
(“wikipedia.en:Multi-core processor” in the English
Wikipedia).
The entity detection module identifies the strings
in the corpus representing named entities. It tok-
enizes the text and uses the longest match to find the
sequences of tokens that can be associated to a list
of entity candidates in the dictionary.
</bodyText>
<subsectionHeader confidence="0.991331">
4.2 Disambiguation
</subsectionHeader>
<bodyText confidence="0.999953814814815">
We disambiguated the entities in a list of candi-
dates using a binary classifier. We trained this
classifier with a set of resolved links that we re-
trieved from the Swedish Wikipedia articles. As
in Bunescu and Pas¸ca (2006), we extracted all the
manually created mention–entity pairs, encoded as
[[target|label]] in the Wikipedia markup,
and we marked them as positive instances. We cre-
ated the negative instances with the other mention–
candidate pairs that we generated with our dictio-
nary.
As classifier, we used the L2-regularized logis-
tic regression (dual) from LIBLINEAR (Fan et al.,
2008) with three features and we ranked the candi-
dates according to the classifier output. The features
are the popularity, commonness (Milne and Witten,
2008), and context. The popularity is the probability
that a candidate is linked to an entity. We estimate
it through the count of unique inbound links to the
candidate article (Table 2). The commonness is the
probability the sequence of tokens could be the can-
didate: P(candidatelsequence of tokens). We com-
pute it from the target–label pairs (Table 3). The
context is the count of unique words extracted from
the two sentences before the input string that we in-
tersect with the words found in the candidate’s arti-
cle.
</bodyText>
<subsubsectionHeader confidence="0.485549">
Entity Occupation Popularity
</subsubsectionHeader>
<table confidence="0.819873666666667">
G¨oran Persson Sk˚ane politician 4
G¨oran Persson Musician 5
G¨oran Persson Prime minister 257
</table>
<tableCaption confidence="0.998898">
Table 2: The popularity of some entities.
</tableCaption>
<page confidence="0.974077">
241
</page>
<table confidence="0.958894833333333">
Entity Mention Common.
Scandinavian Airlines SAS 90.4%
Special Air Service SAS 5.4%
SAS System SAS 0.4%
Cable News Network CNN 99.2%
Cable News Network Int. CNN 0.8%
</table>
<tableCaption confidence="0.999944">
Table 3: The commonness of some entities.
</tableCaption>
<sectionHeader confidence="0.8884965" genericHeader="method">
5 Distant Supervision to Extract Semantic
Propositions
</sectionHeader>
<bodyText confidence="0.9882505">
The distant supervision module consists of three
parts:
</bodyText>
<listItem confidence="0.997653555555556">
1. The first one parses the Swedish Wikipedia up
to the syntactic layer and carries out a named
entity disambiguation.
2. The second part carries out a semantic parsing
of the English Wikipedia and applies a named
entity disambiguation.
3. The third part identifies the propositions hav-
ing identical named entities in both languages
using the Wikidata Q-number and aligns them.
</listItem>
<subsectionHeader confidence="0.972682">
5.1 Semantic and Syntactic Parsing
</subsectionHeader>
<bodyText confidence="0.999963222222222">
As first step, we parsed the English edition of
Wikipedia up to the predicate–argument structures
using the Mate-Tools dependency parser and seman-
tic role labeler (Bj¨orkelund et al., 2010a) and the
Swedish Wikipedia using MaltParser (Nivre et al.,
2006). To carry out these parsing tasks, we used
a Hadoop-based architecture, Koshik (Exner and
Nugues, 2014), that we ran on a cluster of 12 ma-
chines.
</bodyText>
<subsectionHeader confidence="0.998279">
5.2 Named Entity Disambiguation
</subsectionHeader>
<bodyText confidence="0.998164545454545">
The named entity disambiguation links strings to
unique Wikidata and is instrumental to the proposi-
tion alignment. For the two English-Swedish equiv-
alent sentences:
Cologne is located on both sides of the
Rhine River
and
K¨oln ligger p˚a b˚ada sidorna av floden
Rhen,
Wikifier, on the English version, identi-
fies Cologne and Rhine river as named en-
tities and links them respectively to the
en.wikipedia.org/wiki/Cologne and
en.wikipedia.org/wiki/Rhine pages,
while NEDforia, on the Swedish text, produces
a ranked list of entity candidates for the words
K¨oln and Rhen shown in Table 4. We assign the
named entities to the top candidates, Q365 for K¨oln
‘Cologne’ and Q584 for Rhen ‘Rhine.’ We import
the resulting annotated Wikipedia into Koshik,
where we map the document titles and anchor
targets to Q-numbers.
</bodyText>
<figure confidence="0.913785111111111">
Words Entities English pages
K¨oln Q365 Cologne
Q54096 University of Cologne
Q104770 1. FC K¨oln
Q7927 Cologne (region)
Q157741 Cologne Bonn Airport
... ...
Rhen Q584 Rhine
Q10650601 No English page
</figure>
<tableCaption confidence="0.715135666666667">
Table 4: The ranked entity candidates matching the words
K¨oln ‘Cologne’ and Rhen ‘Rhine.’ The entities are iden-
tified by their Wikidata Q-numbers.
</tableCaption>
<subsectionHeader confidence="0.999541">
5.3 Alignment of Parallel Sentences
</subsectionHeader>
<bodyText confidence="0.999978888888889">
We ran the alignment of loosely parallel sentences
using MapReduce (Dean and Ghemawat, 2008)
jobs. Both the English and Swedish articles are se-
quentially read by mappers. For each sentence, the
mappers build and emit key-value pairs. The map-
pers create keys from the entity Q-numbers in each
sentence and we use the sentences as values.
The shuffle-and-sort mechanism in Hadoop en-
sures that, for a given key, each reducer receives
all the sentences. In this process, the sentences are
aligned by their Q-numbers and given as a group
to the reducers with each call. The reducers pro-
cess each group of aligned sentences and anno-
tate the Swedish sentence by linking the entities by
their Q-numbers and by inferring the semantic roles
from the aligned English sentences. The annotated
Swedish sentences are then emitted from the reduc-
ers. For each newly formed Swedish predicate, we
</bodyText>
<page confidence="0.986761">
242
</page>
<bodyText confidence="0.999927833333333">
select the most frequent alignments to form the fi-
nal Swedish predicate–argument frames. Figure 1
shows this alignment process.
We believe that by only using pairs of correspond-
ing articles in different language editions and, hence,
by restraining cross-article supervision using the
unique identifiers given by Wikipedia, we can de-
crease the number of false negatives. We based this
conviction on the observation that many Swedish
Wikipedia articles are loosely translated from their
corresponding English article and therefore express
the same facts or relations.
</bodyText>
<subsectionHeader confidence="0.964903">
5.4 Semantic Annotation Transfer
</subsectionHeader>
<bodyText confidence="0.994231818181818">
Figure 2 shows the parsing results for the sentences
Cologne is located on both sides of the Rhine River
and K¨oln ligger p˚a b˚ada sidorna av floden Rhen in
terms of predicate–argument structures for English,
and functions for Swedish. We identify the named
entities in the two languages and we align the pred-
icates and arguments. We obtain the complete ar-
gument spans by projecting the yield from the argu-
ment token. If the argument token is dominated by a
preposition, the preposition token is used as the root
token for the projection.
</bodyText>
<subsectionHeader confidence="0.923268">
5.4.1 Forming Swedish Predicates
</subsectionHeader>
<bodyText confidence="0.999922533333333">
During the alignment of English and Swedish sen-
tences, we collect token-level mappings between
sentences. The mappings keep a record of how many
times an English predicate is aligned with a Swedish
verb. For each Swedish verb, we then select the most
frequent English predicate it is aligned with. We cre-
ate a new Swedish frame by using the lemmatized
form of the verb and attaching the sense of the En-
glish predicate. We use the sentences representing
the most frequent mappings to generate our final cor-
pus of Swedish propositions. Table 6 shows how two
Swedish frames, vinna.01 and vinna.03, are created
by selecting the most frequent mappings. Table 7
shows the ten most frequent Swedish frames created
using this process.
</bodyText>
<sectionHeader confidence="0.991045" genericHeader="method">
6 A Swedish Corpus of Propositions
</sectionHeader>
<bodyText confidence="0.99847275">
We processed more than 4 million English
Wikipedia articles and almost 3 million Swedish
Wikipedia pages from which we could align over
17,000 English sentences with over 16,000 Swedish
</bodyText>
<table confidence="0.998371272727273">
English
Cologne SBJ Q365 A1
is ROOT
located VC locate.01
on LOC AM-LOC
both NMOD
sides PMOD
of NMOD
the NMOD
Rhine NAME Q584
River PMOD
</table>
<figureCaption confidence="0.997686625">
Figure 2: Transfer of the predicate–argument structure
from an English sentence to a corresponding Swedish
sentence. The sentences are aligned by the two entities
that they both share: Cologne (Q365) and the Rhine River
(Q584). The argument roles are transferred using the Q-
number entity links. The Swedish predicate is formed
using the lemma of the verb token, that is the syntactical
parent of the arguments.
</figureCaption>
<table confidence="0.998857333333333">
Type Count
English articles 4,152,283
Swedish articles 2,792,089
Supervising sentences (English) 17,115
Supervised sentences (Swedish) 16,636
Number of supervisions 19,121
</table>
<tableCaption confidence="0.99973">
Table 5: An overview of distant supervision statistics.
</tableCaption>
<bodyText confidence="0.999908181818182">
sentences. This resulted into 19,000 supervisions
and the generation of a corpus of Swedish propo-
sitions. Table 5 shows an overview of the statistics
of this distant supervision process.
The generated corpus consists of over 4,000 sen-
tences, a subset of the 16,000 Swedish sentences
used in the supervision process. These 4,000 sen-
tences participate in the most frequent English to
Swedish mappings, as detailed in Sect 5.4.1. Table 8
shows an overview of the corpus statistics.
Table 7 shows the ten most frequent mappings and
we can see that all of them form meaningful Swedish
frames. We can with caution state that our method
of selecting the most frequent mapping works sur-
prisingly well. However, if we examine Table 6,
we observe some drawbacks to this approach. Al-
though some unlikely mappings, such as pay.01 are
filtered out, defeat.01 and prevail.01 could be used to
form new Swedish predicates with different senses
of the verb vinna ‘win’. In addition, the predicates,
help.01, take.01, and scoring.01, might participate
as auxiliary verbs or otherwise form propositions
</bodyText>
<figure confidence="0.99912919047619">
AM-LOC
ligga.01
A1 Q365
Q584
Swedish
ROOT
SS
RA
DT
DT
PA
PA
ET
sidorna
floden
ligger
bŒda
Rhen
Köln
pŒ
av
</figure>
<page confidence="0.55622">
243
</page>
<figure confidence="0.998023068965517">
MAP SHUFFLE &amp; SORT REDUCE
SWEDISH
SWEDISH
ENGLISH
ENGLISH
ENGLISH
Q365 Q584
Q365 Q584
Q1 Q8
Q1 Q8
Q1 Q8
Sentence
Sentence
Sentence
Sentence
Sentence
Q365 Q584
Q1 Q8
Sentence
Sentence
Sentence
Sentence
Sentence
Transfer
Semantic
Annotation
Transfer
Semantic
Annotation
</figure>
<figureCaption confidence="0.9987985">
Figure 1: Automatic parallel alignment of sentences through MapReduce. The Map phase creates a key-value pair
consisting of list of entities and a sentence. The Shuffle &amp; Sort mechanism groups the key-value pairs by the list
of entities, effectively aligning sentences across the languages. The Reduce phase steps through the list of aligned
sentences and transfers semantic annotation from a language to another. Figure 2 shows this latter process.
</figureCaption>
<bodyText confidence="0.770653">
English predicate Count Swedish predicate
</bodyText>
<equation confidence="0.99604325">
win.01 125 vinna.01
defeat.01 24 –
beat.03 10 vinna.03
help.01 4 –
take.01 4 –
scoring.01 2 –
pay.01 1 –
prevail.01 1 –
</equation>
<tableCaption confidence="0.676194333333333">
Table 6: Selecting the most frequent English to Swedish
mapping to form new Swedish predicates for the verb
vinna ‘win’. A bold typeface indicates a newly formed
Swedish predicate. A dash indicates that a Swedish pred-
icate for the verb vinna was not formed using the corre-
sponding English predicate.
</tableCaption>
<figure confidence="0.848706272727273">
English predicate Swedish predicate Count
win.01 vinna.01 125
follow.01 f¨olja.01 107
become.01 bli.01 93
play.01 spela.01 67
locate.01 ligga.01 55
move.01 flytta.01 55
find.01 f¨orekomma.01 41
bear.02 f¨oda.02 41
use.01 anv¨anda.01 39
release.01 sl¨appa.01 37
</figure>
<figureCaption confidence="0.704501">
Table 7: The ten most frequent Swedish frames and their
mappings from English predicates.
</figureCaption>
<bodyText confidence="0.999812833333333">
having the same meaning as win.01. A more thor-
ough investigation of the roles played by the enti-
ties, possibly in combination with the use of addi-
tional semantic information from Wikidata, would
certainly aid in improving the extraction of Swedish
predicates.
</bodyText>
<sectionHeader confidence="0.982721" genericHeader="method">
7 Semantic Role Labeling
</sectionHeader>
<bodyText confidence="0.999961692307692">
To assess the usefulness of the proposition corpus,
we trained a semantic role labeler on it and we com-
pared its performance with that of a baseline parser.
Some roles are frequently associated with grammat-
ical functions, such as A0 and the subject in Prop-
Bank. We created the baseline using such associa-
tion rules and we measured the gains brought by the
corpus and a statistical training.
We split the generated corpus into a training, de-
velopment, and test sets with a 60/20/20 ratio. We
used the training and development sets for selecting
features during training and we carried out a final
evaluation on the test set.
</bodyText>
<subsectionHeader confidence="0.998925">
7.1 Baseline Parser
</subsectionHeader>
<bodyText confidence="0.999830333333333">
The baseline parser creates a Swedish predicate
from the lemma of each verbal token and assigns it
the sense 01. Any token governed by the verbal to-
</bodyText>
<page confidence="0.995305">
244
</page>
<bodyText confidence="0.999756125">
ken having a syntactic dependency function is iden-
tified as an argument. The Talbanken corpus (Tele-
man, 1974) serves as training set for the Swedish
model of MaltParser. We used four of its grammat-
ical functions: subject (SS), object (OO), temporal
adjunct (TA), and location adjunct (RA) to create the
roles A0, A1, AM-TMP (temporal), and AM-LOC
(locative), respectively.
</bodyText>
<subsectionHeader confidence="0.999452">
7.2 Training a Semantic Role Labeler
</subsectionHeader>
<bodyText confidence="0.999737470588235">
The SRL pipeline, modified from Bj¨orkelund et al.
(2010b), consists of four steps: Predicate identifica-
tion, predicate disambiguation, argument identifica-
tion, and argument classification.
During predicate identification, a classifier deter-
mines if a verb is a predicate and identifies their pos-
sible sense. Predicates may have different senses
together with a different set of arguments. As an
example, the predicate open.01 describes opening
something, for example, opening a company branch
or a bottle. This differs from the predicate sense,
open.02, having the meaning of something begin-
ning in a certain state, such as a stock opening at
a certain price.
The argument identification and classification
steps identify the arguments corresponding to a
predicate and label them with their roles.
</bodyText>
<subsectionHeader confidence="0.997559">
7.3 Feature Selection
</subsectionHeader>
<bodyText confidence="0.999927842105263">
We considered a large number of features and we
evaluated them both as single features and in pairs to
model interactions. We used the same set as Johans-
son and Nugues (2008) and Bj¨orkelund et al. (2009),
who provide a description of them. We used a
greedy forward selection and greedy backward elim-
ination procedure to select the features (Bj¨orkelund
et al., 2010a). We ran the selection process in multi-
ple iterations, until we reached a stable F1 score. Ta-
ble 10 shows the list of single features we found for
the different steps of semantic role labeling: Pred-
icate identification, predicate disambiguation, argu-
ment identification, and argument classification.
Interestingly, the amount of features used in ar-
gument identification and classification, by far ex-
ceeds those used for predicate identification and dis-
ambiguation. This hints that, although our gen-
erated corpus only considers entities for argument
roles, the diverse nature of entities creates a corpus
</bodyText>
<table confidence="0.999232">
Property Unfiltered Filtered
Count Count
Generated frames 2,333 457
Number of propositions 4,369 2,663
Number of sentences 4,152 2,562
Number of tokens 77,015 43,617
</table>
<tableCaption confidence="0.999831">
Table 8: An overview of corpus statistics.
</tableCaption>
<bodyText confidence="0.996255">
in which arguments hold a wide variety of syntacti-
cal and lexical roles.
</bodyText>
<subsectionHeader confidence="0.990348">
7.4 The Effect of Singleton Predicate Filtering
</subsectionHeader>
<bodyText confidence="0.999971285714286">
We performed a secondary analysis of our generated
corpus and we observed that a large number of pred-
icates occurs in only one single sentence. In addi-
tion, these predicates were often the result of errors
that had propagated through the parsing pipeline.
We filtered out the sentences having mentions of
singleton predicates and we built a second corpus to
determine what kind of influence it had on the qual-
ity of the semantic model. Table 8, right column,
shows the statistics of this second corpus. Singleton
predicates account for a large part of the corpus and
removing them shrinks the number of sentences by
almost a half and dramatically reduces the overall
number of predicates.
</bodyText>
<subsectionHeader confidence="0.983843">
7.5 Validation on the Test Set
</subsectionHeader>
<bodyText confidence="0.999966133333333">
Table 9 shows the final evaluation of the base-
line parser and the semantic role labeler trained
on the generated corpus using distant supervision.
The baseline parser reached a labeled F1 score of
22.38%. Clearly, the indiscriminating choice of
predicates made by the baseline parser gives a higher
recall but a poor precision. The semantic role la-
beler, trained on our generated corpus, outperforms
the baseline parser by a large margin with a labeled
F1 score of 39.88%. Filtering the corpus for single-
ton mention predicates has a dramatic effect on the
parsing quality, increasing the labeled F1 score to
52.25%. We especially note a F1 score of 62.44%
in unlabeled proposition identification showing the
validity of the approach.
</bodyText>
<page confidence="0.995733">
245
</page>
<table confidence="0.9992894">
Labeled Unlabeled
Method Precision Recall F1 Precision Recall F1
Baseline 15.74 38.73 22.38 25.10 61.78 35.70
Distant supervision (Unfiltered corpus) 46.99 34.65 39.88 67.06 49.45 56.92
Distant supervision (Filtered corpus) 58.23 47.38 52.25 69.59 56.62 62.44
</table>
<tableCaption confidence="0.9968065">
Table 9: Summary of semantic role labeling results. The table shows precision, recall, and F1 scores for our baseline
and distant supervision methods. Evaluation performed on test set.
</tableCaption>
<figure confidence="0.992661291666667">
Feature PI PD AI AC
ArgDeprel • •
ArgPOS • •
ArgWord • •
ChildDepSet • •
ChildPOSSet • •
ChildWordSet • •
DepSubCat • •
DeprelPath • •
LeftPOS •
LeftSiblingPOS •
LeftSiblingWord •
LeftWord •
POSPath • •
Position • • •
PredLemma • • •
PredLemmaSense •
PredPOS • • •
PredParentPOS • • • •
PredParentWord • • •
PredWord • •
RightPOS • •
RightSiblingWord •
RightWord • •
</figure>
<tableCaption confidence="0.828176">
Table 10: List of features used in the four stages of se-
mantic role labeling. PI stands for predicate identifica-
tion, PD for predicate disambiguations, AI for argument
identification, and AC for argument classification.
</tableCaption>
<sectionHeader confidence="0.997493" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999964153846154">
By aligning English and Swedish sentences from
two language editions of Wikipedia, we have shown
how semantic annotation can be transferred to gen-
erate a corpus of Swedish propositions. We trained
a semantic role labeler on the generated corpus and
showed promising results in proposition identifica-
tion.
We aligned the sentences using entities and fre-
quency counts to select the most likely frames.
While this relatively simple approach could be con-
sidered inadequate for other distant supervision ap-
plications, such as relation extraction, it worked sur-
prisingly well in our case. We believe this can be at-
tributed to the named entity disambiguation, which
goes beyond a simple surface form comparison and
uniquely identifies the entities used in the supervi-
sion. In addition, we believe that the implicit entity
types that a set of named entities infer, constrain a
sentence to a certain predicate and sense. This in-
creases the likelihood that the Swedish aligned sen-
tence contains a predicate which preserves the same
semantics as the English verb of the source sentence.
Furthermore, we go beyond infobox relations as we
infer new predicates with different senses. Using in-
fobox relations would have limited us to relations
already described by the infobox ontology.
Since our technique builds on a repository of en-
tities extracted from Wikipedia, one future improve-
ment could be to exploit the semantic information
residing in it, possible from other repositories such
as DBpedia (Bizer et al., 2009) or YAGO2. Another
possible improvement would be to increase the size
of the generated corpus. We envision this being done
either by applying a coreference solver to anaphoric
mentions to increase the number of sentences that
could be aligned or by synthetically generating sen-
tences through the use of a semantic repository. An
additional avenue of exploration lies in extending
our work to other languages.
</bodyText>
<sectionHeader confidence="0.996181" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998869666666667">
This research was supported by Vetenskapsr˚adet un-
der grant 621-2010-4800, and the Det digitaliserade
samh¨allet and eSSENCE programs.
</bodyText>
<page confidence="0.997539">
246
</page>
<sectionHeader confidence="0.996365" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999773371428572">
Christian Bizer, Jens Lehmann, Georgi Kobilarov, S¨oren
Auer, Christian Becker, Richard Cyganiak, and Se-
bastian Hellmann. 2009. DBpedia—a crystallization
point for the web of data. Journal of Web Semantics,
pages 154–165.
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of The Thirteenth Conference on Compu-
tational Natural Language Learning (CoNLL-2009),
pages 43–48, Boulder, June 4-5.
Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and
Pierre Nugues. 2010a. A high-performance syntac-
tic and semantic dependency parser. In Coling 2010:
Demonstration Volume, pages 33–36, Beijing, August
23-27. Coling 2010 Organizing Committee.
Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and
Pierre Nugues. 2010b. A high-performance syntac-
tic and semantic dependency parser. In COLING (De-
mos), pages 33–36. Demonstrations Volume.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: A col-
laboratively created graph database for structuring hu-
man knowledge. In Proceedings of the 2008 ACM
SIGMOD International Conference on Management of
Data, SIGMOD ’08, pages 1247–1250.
Razvan Bunescu and Marius Pas¸ca. 2006. Using ency-
clopedic knowledge for named entity disambiguation.
In Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 9–16, Trento, April. Association for Com-
putational Linguistics.
Janara Christensen, Mausam, Stephen Soderland, and
Oren Etzioni. 2010. Semantic role labeling for
open information extraction. In Proceedings of the
NAACL HLT 2010 First International Workshop on
Formalisms and Methodology for Learning by Read-
ing, FAM-LbR ’10, pages 52–60.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting information
from text sources. In Proceedings of the Seventh Inter-
national Conference on Intelligent Systems for Molec-
ular Biology (ISMB’99), pages 77–86.
Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce:
simplified data processing on large clusters. Commu-
nications of the ACM, 51(1):107–113.
Peter Exner and Pierre Nugues. 2014. KOSHIK: A
large-scale distributed computing framework for nlp.
In Proceedings of ICPRAM 2014 – The 3rd Interna-
tional Conference on Pattern Recognition Applications
and Methods, pages 464–470, Angers, March 6-8.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A li-
brary for large linear classification. Journal of Ma-
chine Learning Research, 9:1871–1874.
Johannes Hoffart, Fabian M. Suchanek, Klaus Berberich,
and Gerhard Weikum. 2010. YAGO2: a spa-
tially and temporally enhanced knowledge base from
Wikipedia. Research Report MPI-I-2010-5-007, Max-
Planck-Institut f¨ur Informatik, Stuhlsatzenhausweg
85, 66123 Saarbr¨ucken, Germany, November.
Raphael Hoffmann, Congle Zhang, and Daniel S Weld.
2010. Learning 5000 relational extractors. In Pro-
ceedings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 286–295.
Richard Johansson and Alessandro Moschitti. 2011. Ex-
tracting opinion expressions and their polarities: ex-
ploration of pipelines and joint models. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies: short papers. Volume 2, pages 101–106.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic–semantic analysis
with PropBank and NomBank. In Proceedings of
CoNLL-2008: The Twelfth Conference on Computa-
tional Natural Language Learning, pages 183–187,
Manchester, August 16-17.
Ding Liu and Daniel Gildea. 2010. Semantic role
features for machine translation. In COLING ’10
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 716–724, Beijing,
June.
David Milne and Ian H. Witten. 2008. Learning to link
with wikipedia. In Proceedings of the 17th ACM con-
ference on Information and knowledge management,
CIKM ’08, pages 509–518.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP: Volume 2-Volume 2, pages
1003–1011.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006.
MaltParser: A data-driven parser-generator for depen-
dency parsing. In Proceedings of the fifth interna-
tional conference on Language Resources and Eval-
uation (LREC2006), pages 2216–2219, Genoa.
Robert ¨Ostling. 2013. Stagger: an open-source part of
speech tagger for Swedish. Northern European Jour-
nal of Language Technology, 3:1–18.
Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual
annotation projection for semantic roles. Journal of
Artificial Intelligence Research, 36(1):307–340.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: an annotated corpus of
</reference>
<page confidence="0.967679">
247
</page>
<reference confidence="0.999676705882353">
semantic roles. Computational Linguistics, 31(1):71–
105.
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to wikipedia. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Volume
1, HLT ’11, pages 1375–1384.
Alan Ritter, Luke Zettlemoyer, Oren Etzioni, et al. 2013.
Modeling missing data in distant supervision for infor-
mation extraction. Transactions of the Association for
Computational Linguistics, 1:367–378.
Dan Shen and Mirella Lapata. 2007. Using semantic
roles to improve question answering. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 12–21, Prague,
June.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 455–465.
Ulf Teleman. 1974. Manual f¨or grammatisk beskrivning
av talad och skriven svenska. Studentlitteratur, Lund.
Dekai Wu, Pascale Fung, Marine Carpuat, Chi kiu Lo,
Yongsheng Yang, and Zhaojun Wu. 2011. Lexical se-
mantics for statistical machine translation. In Joseph
Olive, Caitlin Christianson, and John McCary, editors,
Handbook of Natural Language Processing and Ma-
chine Translation: DARPA Global Autonomous Lan-
guage Exploitation, pages 236–252. Springer, Heidel-
berg.
</reference>
<page confidence="0.997002">
248
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.370199">
<title confidence="0.999918">A Distant Supervision Approach to Semantic Role Labeling</title>
<author confidence="0.975102">Peter Exner Marcus Klang Pierre Nugues</author>
<affiliation confidence="0.78373">Lund Department of Computer Lund,</affiliation>
<email confidence="0.863268">Marcus.Klang,</email>
<abstract confidence="0.999624037037037">Semantic role labeling has become a key module for many language processing applications such as question answering, information extraction, sentiment analysis, and machine translation. To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, creating such a bank is a costly enterprise, which has only been achieved for a handful of languages. In this paper, we describe a technique to build proposition banks for new languages using distant supervision. Starting from PropBank in English and loosely parallel corpora such as versions of Wikipedia in different languages, we carried out a mapping of semantic propositions we extracted from English to syntactic structures in Swedish using named entities. We trained a semantic parser on the generated Swedish propositions and we report the results we obtained. Using the CoNLL 2009 evaluation script, we could reach the scores of 52.25 for labeled propositions and 62.44 for the unlabeled ones. We believe our approach can be applied to train semantic role labelers for other resource-scarce languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christian Bizer</author>
<author>Jens Lehmann</author>
<author>Georgi Kobilarov</author>
<author>S¨oren Auer</author>
<author>Christian Becker</author>
<author>Richard Cyganiak</author>
<author>Sebastian Hellmann</author>
</authors>
<title>DBpedia—a crystallization point for the web of data.</title>
<date>2009</date>
<journal>Journal of Web Semantics,</journal>
<pages>154--165</pages>
<marker>Bizer, Lehmann, Kobilarov, Auer, Becker, Cyganiak, Hellmann, 2009</marker>
<rawString>Christian Bizer, Jens Lehmann, Georgi Kobilarov, S¨oren Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009. DBpedia—a crystallization point for the web of data. Journal of Web Semantics, pages 154–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of The Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009),</booktitle>
<pages>43--48</pages>
<location>Boulder,</location>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In Proceedings of The Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 43–48, Boulder, June 4-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Bernd Bohnet</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>A high-performance syntactic and semantic dependency parser.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Coling 2010: Demonstration Volume,</booktitle>
<pages>33--36</pages>
<location>Beijing,</location>
<marker>Bj¨orkelund, Bohnet, Hafdell, Nugues, 2010</marker>
<rawString>Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and Pierre Nugues. 2010a. A high-performance syntactic and semantic dependency parser. In Coling 2010: Demonstration Volume, pages 33–36, Beijing, August 23-27. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Bernd Bohnet</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>A high-performance syntactic and semantic dependency parser.</title>
<date>2010</date>
<booktitle>In COLING (Demos),</booktitle>
<pages>33--36</pages>
<note>Demonstrations Volume.</note>
<marker>Bj¨orkelund, Bohnet, Hafdell, Nugues, 2010</marker>
<rawString>Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and Pierre Nugues. 2010b. A high-performance syntactic and semantic dependency parser. In COLING (Demos), pages 33–36. Demonstrations Volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: A collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08,</booktitle>
<pages>1247--1250</pages>
<contexts>
<context position="9346" citStr="Bollacker et al., 2008" startWordPosition="1450" endWordPosition="1453">. We created a disambiguator targeted to Swedish: NEDforia. NEDforia uses a Wikipedia dump as input and automatically collects a list of named entities from the corpus. It then extracts the links and contexts of these entities to build disambiguation models. Given an input text, NEDforia recognizes and disambiguates the named entities, and annotates them with their corresponding Wikidata number. 4.1 Entity Detection We created a dictionary of entities from Wikipedia using the combination of a POS tagger ( ¨Ostling, 2013), language-dependent uppercase rules, and two entity databases: Freebase (Bollacker et al., 2008) and YAGO2 (Hoffart et al., 2010). Table 1 shows three dictionary entries, where an entry consists of a normalized form and the output is a list of Wikidata candidates in the form of Q-numbers. The output can be the native Wikipedia page, if a Wikidata mapping could not be found, as for “wikipedia.sv:Processork¨arna” (“wikipedia.en:Multi-core processor” in the English Wikipedia). The entity detection module identifies the strings in the corpus representing named entities. It tokenizes the text and uses the longest match to find the sequences of tokens that can be associated to a list of entity</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08, pages 1247–1250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Marius Pas¸ca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Trento,</location>
<marker>Bunescu, Pas¸ca, 2006</marker>
<rawString>Razvan Bunescu and Marius Pas¸ca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 9–16, Trento, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janara Christensen</author>
<author>Stephen Soderland Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Semantic role labeling for open information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, FAM-LbR ’10,</booktitle>
<pages>52--60</pages>
<contexts>
<context position="1577" citStr="Christensen et al., 2010" startWordPosition="236" endWordPosition="239">s in Swedish using named entities. We trained a semantic parser on the generated Swedish propositions and we report the results we obtained. Using the CoNLL 2009 evaluation script, we could reach the scores of 52.25 for labeled propositions and 62.44 for the unlabeled ones. We believe our approach can be applied to train semantic role labelers for other resource-scarce languages. 1 Introduction Semantic role labeling has become a key module for many language processing applications and its importance is growing in fields like question answering (Shen and Lapata, 2007), information extraction (Christensen et al., 2010), sentiment analysis (Johansson and Moschitti, 2011), and machine translation (Liu and Gildea, 2010; Wu et al., 2011). To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, building proposition banks is a costly enterprise and as a consequence of that, they only exist for a handful of languages such as English, Chinese, German, or Spanish. In this paper, we describe a technique to create proposition banks for new languages using distant supervision. Our approach builds on the transfer of semantic information through named entiti</context>
</contexts>
<marker>Christensen, Mausam, Etzioni, 2010</marker>
<rawString>Janara Christensen, Mausam, Stephen Soderland, and Oren Etzioni. 2010. Semantic role labeling for open information extraction. In Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, FAM-LbR ’10, pages 52–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB’99),</booktitle>
<pages>77--86</pages>
<contexts>
<context position="4065" citStr="Craven and Kumlien (1999)" startWordPosition="620" endWordPosition="624">The techniques we applied in this paper are similar to those used in the extraction of relations between entity mentions in a sentence, where relational facts are often expressed in the form of triples, such as: (Seoul, CapitalOf, South Korea). While supervised and unsupervised techniques have been applied to the extraction of such relations, they both suffer from drawbacks. Supervised learning relies on labor-intensive, hand-annotated corpora, while unsupervised approaches have lower precision and recall levels. Distant supervision is an alternative to these approaches that was introduced by Craven and Kumlien (1999). They used a knowledge base of existing biological relations, automatically identified sentences containing these relations, and trained a classifier to recognize the relations. Distant supervision has been successfully transferred to other fields. Mintz et al. (2009) describe a method for creating training data and relation classifiers without a hand-labeled corpus. The authors used Freebase and its binary relations between entities, such as (/location/location/contains, Belgium, Nijlen). They extracted entity pairs from the sentences of a text and matched them to those found in Freebase. Us</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB’99), pages 77–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dean</author>
<author>Sanjay Ghemawat</author>
</authors>
<title>MapReduce: simplified data processing on large clusters.</title>
<date>2008</date>
<journal>Communications of the ACM,</journal>
<volume>51</volume>
<issue>1</issue>
<contexts>
<context position="13884" citStr="Dean and Ghemawat, 2008" startWordPosition="2174" endWordPosition="2177">nd Q584 for Rhen ‘Rhine.’ We import the resulting annotated Wikipedia into Koshik, where we map the document titles and anchor targets to Q-numbers. Words Entities English pages K¨oln Q365 Cologne Q54096 University of Cologne Q104770 1. FC K¨oln Q7927 Cologne (region) Q157741 Cologne Bonn Airport ... ... Rhen Q584 Rhine Q10650601 No English page Table 4: The ranked entity candidates matching the words K¨oln ‘Cologne’ and Rhen ‘Rhine.’ The entities are identified by their Wikidata Q-numbers. 5.3 Alignment of Parallel Sentences We ran the alignment of loosely parallel sentences using MapReduce (Dean and Ghemawat, 2008) jobs. Both the English and Swedish articles are sequentially read by mappers. For each sentence, the mappers build and emit key-value pairs. The mappers create keys from the entity Q-numbers in each sentence and we use the sentences as values. The shuffle-and-sort mechanism in Hadoop ensures that, for a given key, each reducer receives all the sentences. In this process, the sentences are aligned by their Q-numbers and given as a group to the reducers with each call. The reducers process each group of aligned sentences and annotate the Swedish sentence by linking the entities by their Q-numbe</context>
</contexts>
<marker>Dean, Ghemawat, 2008</marker>
<rawString>Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Communications of the ACM, 51(1):107–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Exner</author>
<author>Pierre Nugues</author>
</authors>
<title>KOSHIK: A large-scale distributed computing framework for nlp.</title>
<date>2014</date>
<booktitle>In Proceedings of ICPRAM 2014 – The 3rd International Conference on Pattern Recognition Applications and Methods,</booktitle>
<pages>464--470</pages>
<location>Angers,</location>
<contexts>
<context position="12520" citStr="Exner and Nugues, 2014" startWordPosition="1959" endWordPosition="1962">t a semantic parsing of the English Wikipedia and applies a named entity disambiguation. 3. The third part identifies the propositions having identical named entities in both languages using the Wikidata Q-number and aligns them. 5.1 Semantic and Syntactic Parsing As first step, we parsed the English edition of Wikipedia up to the predicate–argument structures using the Mate-Tools dependency parser and semantic role labeler (Bj¨orkelund et al., 2010a) and the Swedish Wikipedia using MaltParser (Nivre et al., 2006). To carry out these parsing tasks, we used a Hadoop-based architecture, Koshik (Exner and Nugues, 2014), that we ran on a cluster of 12 machines. 5.2 Named Entity Disambiguation The named entity disambiguation links strings to unique Wikidata and is instrumental to the proposition alignment. For the two English-Swedish equivalent sentences: Cologne is located on both sides of the Rhine River and K¨oln ligger p˚a b˚ada sidorna av floden Rhen, Wikifier, on the English version, identifies Cologne and Rhine river as named entities and links them respectively to the en.wikipedia.org/wiki/Cologne and en.wikipedia.org/wiki/Rhine pages, while NEDforia, on the Swedish text, produces a ranked list of ent</context>
</contexts>
<marker>Exner, Nugues, 2014</marker>
<rawString>Peter Exner and Pierre Nugues. 2014. KOSHIK: A large-scale distributed computing framework for nlp. In Proceedings of ICPRAM 2014 – The 3rd International Conference on Pattern Recognition Applications and Methods, pages 464–470, Angers, March 6-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>Xiang-Rui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="10591" citStr="Fan et al., 2008" startWordPosition="1652" endWordPosition="1655">y. 4.2 Disambiguation We disambiguated the entities in a list of candidates using a binary classifier. We trained this classifier with a set of resolved links that we retrieved from the Swedish Wikipedia articles. As in Bunescu and Pas¸ca (2006), we extracted all the manually created mention–entity pairs, encoded as [[target|label]] in the Wikipedia markup, and we marked them as positive instances. We created the negative instances with the other mention– candidate pairs that we generated with our dictionary. As classifier, we used the L2-regularized logistic regression (dual) from LIBLINEAR (Fan et al., 2008) with three features and we ranked the candidates according to the classifier output. The features are the popularity, commonness (Milne and Witten, 2008), and context. The popularity is the probability that a candidate is linked to an entity. We estimate it through the count of unique inbound links to the candidate article (Table 2). The commonness is the probability the sequence of tokens could be the candidate: P(candidatelsequence of tokens). We compute it from the target–label pairs (Table 3). The context is the count of unique words extracted from the two sentences before the input strin</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Fabian M Suchanek</author>
<author>Klaus Berberich</author>
<author>Gerhard Weikum</author>
</authors>
<title>YAGO2: a spatially and temporally enhanced knowledge base from Wikipedia. Research Report MPI-I-2010-5-007, MaxPlanck-Institut f¨ur Informatik,</title>
<date>2010</date>
<journal>Stuhlsatzenhausweg</journal>
<volume>85</volume>
<pages>66123</pages>
<location>Saarbr¨ucken, Germany,</location>
<contexts>
<context position="9379" citStr="Hoffart et al., 2010" startWordPosition="1456" endWordPosition="1459">ed to Swedish: NEDforia. NEDforia uses a Wikipedia dump as input and automatically collects a list of named entities from the corpus. It then extracts the links and contexts of these entities to build disambiguation models. Given an input text, NEDforia recognizes and disambiguates the named entities, and annotates them with their corresponding Wikidata number. 4.1 Entity Detection We created a dictionary of entities from Wikipedia using the combination of a POS tagger ( ¨Ostling, 2013), language-dependent uppercase rules, and two entity databases: Freebase (Bollacker et al., 2008) and YAGO2 (Hoffart et al., 2010). Table 1 shows three dictionary entries, where an entry consists of a normalized form and the output is a list of Wikidata candidates in the form of Q-numbers. The output can be the native Wikipedia page, if a Wikidata mapping could not be found, as for “wikipedia.sv:Processork¨arna” (“wikipedia.en:Multi-core processor” in the English Wikipedia). The entity detection module identifies the strings in the corpus representing named entities. It tokenizes the text and uses the longest match to find the sequences of tokens that can be associated to a list of entity candidates in the dictionary. 4.</context>
</contexts>
<marker>Hoffart, Suchanek, Berberich, Weikum, 2010</marker>
<rawString>Johannes Hoffart, Fabian M. Suchanek, Klaus Berberich, and Gerhard Weikum. 2010. YAGO2: a spatially and temporally enhanced knowledge base from Wikipedia. Research Report MPI-I-2010-5-007, MaxPlanck-Institut f¨ur Informatik, Stuhlsatzenhausweg 85, 66123 Saarbr¨ucken, Germany, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Daniel S Weld</author>
</authors>
<title>Learning 5000 relational extractors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>286--295</pages>
<contexts>
<context position="4945" citStr="Hoffmann et al. (2010)" startWordPosition="749" endWordPosition="752"> al. (2009) describe a method for creating training data and relation classifiers without a hand-labeled corpus. The authors used Freebase and its binary relations between entities, such as (/location/location/contains, Belgium, Nijlen). They extracted entity pairs from the sentences of a text and matched them to those found in Freebase. Using the entity pairs, the relations, and the corresponding sentence text, they could train a relation extractor. Pad´o and Lapata (2009) used parallel corpora and constituent-based models to automatically project FrameNet annotations from English to German. Hoffmann et al. (2010) introduced Wikipedia infoboxes in relation extraction, where the authors trained a classifier to predict the infobox schema of an article prior to the extraction step. They used relation-specific lexicons created from a web crawl to train individual extractors for 5,025 relations and, rather than running all these extractors on every article and sentence, they first predicted the schema of an article and then executed the set of corresponding extractors. Early work in distant supervision assumed that an entity pair expresses a unique explicit relation type. Surdeanu et al. (2012) describe an </context>
</contexts>
<marker>Hoffmann, Zhang, Weld, 2010</marker>
<rawString>Raphael Hoffmann, Congle Zhang, and Daniel S Weld. 2010. Learning 5000 relational extractors. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 286–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Extracting opinion expressions and their polarities: exploration of pipelines and joint models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<volume>2</volume>
<pages>101--106</pages>
<contexts>
<context position="1629" citStr="Johansson and Moschitti, 2011" startWordPosition="242" endWordPosition="246"> semantic parser on the generated Swedish propositions and we report the results we obtained. Using the CoNLL 2009 evaluation script, we could reach the scores of 52.25 for labeled propositions and 62.44 for the unlabeled ones. We believe our approach can be applied to train semantic role labelers for other resource-scarce languages. 1 Introduction Semantic role labeling has become a key module for many language processing applications and its importance is growing in fields like question answering (Shen and Lapata, 2007), information extraction (Christensen et al., 2010), sentiment analysis (Johansson and Moschitti, 2011), and machine translation (Liu and Gildea, 2010; Wu et al., 2011). To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, building proposition banks is a costly enterprise and as a consequence of that, they only exist for a handful of languages such as English, Chinese, German, or Spanish. In this paper, we describe a technique to create proposition banks for new languages using distant supervision. Our approach builds on the transfer of semantic information through named entities. Starting from an existing proposition bank, Prop</context>
</contexts>
<marker>Johansson, Moschitti, 2011</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2011. Extracting opinion expressions and their polarities: exploration of pipelines and joint models. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers. Volume 2, pages 101–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic–semantic analysis with PropBank and NomBank.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL-2008: The Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>183--187</pages>
<location>Manchester,</location>
<contexts>
<context position="22781" citStr="Johansson and Nugues (2008)" startWordPosition="3607" endWordPosition="3611">ent set of arguments. As an example, the predicate open.01 describes opening something, for example, opening a company branch or a bottle. This differs from the predicate sense, open.02, having the meaning of something beginning in a certain state, such as a stock opening at a certain price. The argument identification and classification steps identify the arguments corresponding to a predicate and label them with their roles. 7.3 Feature Selection We considered a large number of features and we evaluated them both as single features and in pairs to model interactions. We used the same set as Johansson and Nugues (2008) and Bj¨orkelund et al. (2009), who provide a description of them. We used a greedy forward selection and greedy backward elimination procedure to select the features (Bj¨orkelund et al., 2010a). We ran the selection process in multiple iterations, until we reached a stable F1 score. Table 10 shows the list of single features we found for the different steps of semantic role labeling: Predicate identification, predicate disambiguation, argument identification, and argument classification. Interestingly, the amount of features used in argument identification and classification, by far exceeds t</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic–semantic analysis with PropBank and NomBank. In Proceedings of CoNLL-2008: The Twelfth Conference on Computational Natural Language Learning, pages 183–187, Manchester, August 16-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation.</title>
<date>2010</date>
<booktitle>In COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>716--724</pages>
<location>Beijing,</location>
<contexts>
<context position="1676" citStr="Liu and Gildea, 2010" startWordPosition="251" endWordPosition="254">d we report the results we obtained. Using the CoNLL 2009 evaluation script, we could reach the scores of 52.25 for labeled propositions and 62.44 for the unlabeled ones. We believe our approach can be applied to train semantic role labelers for other resource-scarce languages. 1 Introduction Semantic role labeling has become a key module for many language processing applications and its importance is growing in fields like question answering (Shen and Lapata, 2007), information extraction (Christensen et al., 2010), sentiment analysis (Johansson and Moschitti, 2011), and machine translation (Liu and Gildea, 2010; Wu et al., 2011). To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, building proposition banks is a costly enterprise and as a consequence of that, they only exist for a handful of languages such as English, Chinese, German, or Spanish. In this paper, we describe a technique to create proposition banks for new languages using distant supervision. Our approach builds on the transfer of semantic information through named entities. Starting from an existing proposition bank, PropBank in English (Palmer et al., 2005), and loos</context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic role features for machine translation. In COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics, pages 716–724, Beijing, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management, CIKM ’08,</booktitle>
<pages>509--518</pages>
<contexts>
<context position="10745" citStr="Milne and Witten, 2008" startWordPosition="1676" endWordPosition="1679">lved links that we retrieved from the Swedish Wikipedia articles. As in Bunescu and Pas¸ca (2006), we extracted all the manually created mention–entity pairs, encoded as [[target|label]] in the Wikipedia markup, and we marked them as positive instances. We created the negative instances with the other mention– candidate pairs that we generated with our dictionary. As classifier, we used the L2-regularized logistic regression (dual) from LIBLINEAR (Fan et al., 2008) with three features and we ranked the candidates according to the classifier output. The features are the popularity, commonness (Milne and Witten, 2008), and context. The popularity is the probability that a candidate is linked to an entity. We estimate it through the count of unique inbound links to the candidate article (Table 2). The commonness is the probability the sequence of tokens could be the candidate: P(candidatelsequence of tokens). We compute it from the target–label pairs (Table 3). The context is the count of unique words extracted from the two sentences before the input string that we intersect with the words found in the candidate’s article. Entity Occupation Popularity G¨oran Persson Sk˚ane politician 4 G¨oran Persson Musici</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, CIKM ’08, pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<contexts>
<context position="4334" citStr="Mintz et al. (2009)" startWordPosition="659" endWordPosition="662">sed techniques have been applied to the extraction of such relations, they both suffer from drawbacks. Supervised learning relies on labor-intensive, hand-annotated corpora, while unsupervised approaches have lower precision and recall levels. Distant supervision is an alternative to these approaches that was introduced by Craven and Kumlien (1999). They used a knowledge base of existing biological relations, automatically identified sentences containing these relations, and trained a classifier to recognize the relations. Distant supervision has been successfully transferred to other fields. Mintz et al. (2009) describe a method for creating training data and relation classifiers without a hand-labeled corpus. The authors used Freebase and its binary relations between entities, such as (/location/location/contains, Belgium, Nijlen). They extracted entity pairs from the sentences of a text and matched them to those found in Freebase. Using the entity pairs, the relations, and the corresponding sentence text, they could train a relation extractor. Pad´o and Lapata (2009) used parallel corpora and constituent-based models to automatically project FrameNet annotations from English to German. Hoffmann et</context>
<context position="6160" citStr="Mintz et al. (2009)" startWordPosition="946" endWordPosition="949"> an extended model, where each entity pair may link multiple instances to multiple relations. Ritter et al. (2013) used a latent-variable approach to model information gaps present in either the knowledge base or the corresponding text. As far as we know, all the work on relation extraction focused on the detection of specific semantic relations between entities. In this paper, we describe an extension and a generalization of it that potentially covers all the relations tied to a predicate and results in the systematic extraction of the semantic propositions observed in a corpus. Similarly to Mintz et al. (2009), we used an external resource of relational facts and we matched the entity pairs in the relations to a Swedish text corpus. However, our approach substantially differs from theirs by the form of the external resource, which is a parsed corpus. To our best knowledge, there is no Swedish repository of relational facts between entities in existence. Instead, we semantically parsed an English corpus, in our case the English edition of Wikipedia, and we matched, article by article, the resulting semantic structures to sentences in the Swedish edition of Wikipedia. Using the generated Swedish sema</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>MaltParser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth international conference on Language Resources and Evaluation (LREC2006),</booktitle>
<pages>2216--2219</pages>
<location>Genoa.</location>
<contexts>
<context position="2692" citStr="Nivre et al., 2006" startWordPosition="411" endWordPosition="414">ng distant supervision. Our approach builds on the transfer of semantic information through named entities. Starting from an existing proposition bank, PropBank in English (Palmer et al., 2005), and loosely parallel corpora such as versions of Wikipedia in different languages, we carried out a mapping of the semantic propositions we extracted from English to syntactic structures in the target language. We parsed the English edition of Wikipedia up to the predicate–argument structures using a semantic role labeler (Bj¨orkelund et al., 2010a) and the Swedish Wikipedia using a dependency parser (Nivre et al., 2006). We extracted all the named entities we found in the propositions and we disambiguated them using the Wikidata nomenclature1. Using recurring entities, we aligned sentences in the two languages; we transferred the semantic annotation from English sentences to Swedish sentences; and we could identify 2,333 predicate–argument frames in Swedish. Finally, we used the resulting corpus to train a semantic role labeler for Swedish that enabled us to evaluate the validity of our approach. Beyond Swedish, we believe it can apply to any resource1http://www.wikidata.org 239 Proceedings of the Fourth Joi</context>
<context position="12416" citStr="Nivre et al., 2006" startWordPosition="1943" endWordPosition="1946"> to the syntactic layer and carries out a named entity disambiguation. 2. The second part carries out a semantic parsing of the English Wikipedia and applies a named entity disambiguation. 3. The third part identifies the propositions having identical named entities in both languages using the Wikidata Q-number and aligns them. 5.1 Semantic and Syntactic Parsing As first step, we parsed the English edition of Wikipedia up to the predicate–argument structures using the Mate-Tools dependency parser and semantic role labeler (Bj¨orkelund et al., 2010a) and the Swedish Wikipedia using MaltParser (Nivre et al., 2006). To carry out these parsing tasks, we used a Hadoop-based architecture, Koshik (Exner and Nugues, 2014), that we ran on a cluster of 12 machines. 5.2 Named Entity Disambiguation The named entity disambiguation links strings to unique Wikidata and is instrumental to the proposition alignment. For the two English-Swedish equivalent sentences: Cologne is located on both sides of the Rhine River and K¨oln ligger p˚a b˚ada sidorna av floden Rhen, Wikifier, on the English version, identifies Cologne and Rhine river as named entities and links them respectively to the en.wikipedia.org/wiki/Cologne a</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2006. MaltParser: A data-driven parser-generator for dependency parsing. In Proceedings of the fifth international conference on Language Resources and Evaluation (LREC2006), pages 2216–2219, Genoa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert ¨Ostling</author>
</authors>
<title>Stagger: an open-source part of speech tagger for Swedish.</title>
<date>2013</date>
<journal>Northern European Journal of Language Technology,</journal>
<pages>3--1</pages>
<marker>¨Ostling, 2013</marker>
<rawString>Robert ¨Ostling. 2013. Stagger: an open-source part of speech tagger for Swedish. Northern European Journal of Language Technology, 3:1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Cross-lingual annotation projection for semantic roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>36</volume>
<issue>1</issue>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual annotation projection for semantic roles. Journal of Artificial Intelligence Research, 36(1):307–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: an annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>105</pages>
<contexts>
<context position="2266" citStr="Palmer et al., 2005" startWordPosition="345" endWordPosition="348">nslation (Liu and Gildea, 2010; Wu et al., 2011). To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, building proposition banks is a costly enterprise and as a consequence of that, they only exist for a handful of languages such as English, Chinese, German, or Spanish. In this paper, we describe a technique to create proposition banks for new languages using distant supervision. Our approach builds on the transfer of semantic information through named entities. Starting from an existing proposition bank, PropBank in English (Palmer et al., 2005), and loosely parallel corpora such as versions of Wikipedia in different languages, we carried out a mapping of the semantic propositions we extracted from English to syntactic structures in the target language. We parsed the English edition of Wikipedia up to the predicate–argument structures using a semantic role labeler (Bj¨orkelund et al., 2010a) and the Swedish Wikipedia using a dependency parser (Nivre et al., 2006). We extracted all the named entities we found in the propositions and we disambiguated them using the Wikidata nomenclature1. Using recurring entities, we aligned sentences </context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: an annotated corpus of semantic roles. Computational Linguistics, 31(1):71– 105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1375--1384</pages>
<contexts>
<context position="8524" citStr="Ratinov et al., 2011" startWordPosition="1324" endWordPosition="1327">trict in Helsingborg 33 wikidata:Q25411 Table 1: Entries in the detection dictionary, all related to the city of Helsingborg in Sweden, with their unique Wikidata Q-number and a short explanation in italics. 4 Named Entity Linking Named entity linking (or disambiguation) (NED) is the core step of distant supervision to anchor the parallel sentences and propositions. NED usually consists of two steps: first, extract the entity mentions, usually noun phrases, and if a mention corresponds to a proper noun – a named entity –, link it to a unique identifier. For the English part, we used Wikifier (Ratinov et al., 2011) to disambiguate entities. There was no similar disambiguator for Swedish and those described for English are not directly adaptable because they require resources that do not exist for this language. We created a disambiguator targeted to Swedish: NEDforia. NEDforia uses a Wikipedia dump as input and automatically collects a list of named entities from the corpus. It then extracts the links and contexts of these entities to build disambiguation models. Given an input text, NEDforia recognizes and disambiguates the named entities, and annotates them with their corresponding Wikidata number. 4.</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1375–1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Luke Zettlemoyer</author>
<author>Oren Etzioni</author>
</authors>
<title>Modeling missing data in distant supervision for information extraction.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--367</pages>
<contexts>
<context position="5655" citStr="Ritter et al. (2013)" startWordPosition="861" endWordPosition="864">fier to predict the infobox schema of an article prior to the extraction step. They used relation-specific lexicons created from a web crawl to train individual extractors for 5,025 relations and, rather than running all these extractors on every article and sentence, they first predicted the schema of an article and then executed the set of corresponding extractors. Early work in distant supervision assumed that an entity pair expresses a unique explicit relation type. Surdeanu et al. (2012) describe an extended model, where each entity pair may link multiple instances to multiple relations. Ritter et al. (2013) used a latent-variable approach to model information gaps present in either the knowledge base or the corresponding text. As far as we know, all the work on relation extraction focused on the detection of specific semantic relations between entities. In this paper, we describe an extension and a generalization of it that potentially covers all the relations tied to a predicate and results in the systematic extraction of the semantic propositions observed in a corpus. Similarly to Mintz et al. (2009), we used an external resource of relational facts and we matched the entity pairs in the relat</context>
</contexts>
<marker>Ritter, Zettlemoyer, Etzioni, 2013</marker>
<rawString>Alan Ritter, Luke Zettlemoyer, Oren Etzioni, et al. 2013. Modeling missing data in distant supervision for information extraction. Transactions of the Association for Computational Linguistics, 1:367–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Mirella Lapata</author>
</authors>
<title>Using semantic roles to improve question answering.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>12--21</pages>
<location>Prague,</location>
<contexts>
<context position="1526" citStr="Shen and Lapata, 2007" startWordPosition="230" endWordPosition="233">we extracted from English to syntactic structures in Swedish using named entities. We trained a semantic parser on the generated Swedish propositions and we report the results we obtained. Using the CoNLL 2009 evaluation script, we could reach the scores of 52.25 for labeled propositions and 62.44 for the unlabeled ones. We believe our approach can be applied to train semantic role labelers for other resource-scarce languages. 1 Introduction Semantic role labeling has become a key module for many language processing applications and its importance is growing in fields like question answering (Shen and Lapata, 2007), information extraction (Christensen et al., 2010), sentiment analysis (Johansson and Moschitti, 2011), and machine translation (Liu and Gildea, 2010; Wu et al., 2011). To build an unrestricted semantic role labeler, the first step is to develop a comprehensive proposition bank. However, building proposition banks is a costly enterprise and as a consequence of that, they only exist for a handful of languages such as English, Chinese, German, or Spanish. In this paper, we describe a technique to create proposition banks for new languages using distant supervision. Our approach builds on the tr</context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>Dan Shen and Mirella Lapata. 2007. Using semantic roles to improve question answering. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 12–21, Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multilabel learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>455--465</pages>
<contexts>
<context position="5532" citStr="Surdeanu et al. (2012)" startWordPosition="842" endWordPosition="845">h to German. Hoffmann et al. (2010) introduced Wikipedia infoboxes in relation extraction, where the authors trained a classifier to predict the infobox schema of an article prior to the extraction step. They used relation-specific lexicons created from a web crawl to train individual extractors for 5,025 relations and, rather than running all these extractors on every article and sentence, they first predicted the schema of an article and then executed the set of corresponding extractors. Early work in distant supervision assumed that an entity pair expresses a unique explicit relation type. Surdeanu et al. (2012) describe an extended model, where each entity pair may link multiple instances to multiple relations. Ritter et al. (2013) used a latent-variable approach to model information gaps present in either the knowledge base or the corresponding text. As far as we know, all the work on relation extraction focused on the detection of specific semantic relations between entities. In this paper, we describe an extension and a generalization of it that potentially covers all the relations tied to a predicate and results in the systematic extraction of the semantic propositions observed in a corpus. Simi</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Teleman</author>
</authors>
<title>Manual f¨or grammatisk beskrivning av talad och skriven svenska.</title>
<date>1974</date>
<location>Studentlitteratur, Lund.</location>
<contexts>
<context position="21485" citStr="Teleman, 1974" startWordPosition="3408" endWordPosition="3410"> such association rules and we measured the gains brought by the corpus and a statistical training. We split the generated corpus into a training, development, and test sets with a 60/20/20 ratio. We used the training and development sets for selecting features during training and we carried out a final evaluation on the test set. 7.1 Baseline Parser The baseline parser creates a Swedish predicate from the lemma of each verbal token and assigns it the sense 01. Any token governed by the verbal to244 ken having a syntactic dependency function is identified as an argument. The Talbanken corpus (Teleman, 1974) serves as training set for the Swedish model of MaltParser. We used four of its grammatical functions: subject (SS), object (OO), temporal adjunct (TA), and location adjunct (RA) to create the roles A0, A1, AM-TMP (temporal), and AM-LOC (locative), respectively. 7.2 Training a Semantic Role Labeler The SRL pipeline, modified from Bj¨orkelund et al. (2010b), consists of four steps: Predicate identification, predicate disambiguation, argument identification, and argument classification. During predicate identification, a classifier determines if a verb is a predicate and identifies their possib</context>
</contexts>
<marker>Teleman, 1974</marker>
<rawString>Ulf Teleman. 1974. Manual f¨or grammatisk beskrivning av talad och skriven svenska. Studentlitteratur, Lund.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Marine Carpuat, Chi kiu Lo, Yongsheng Yang, and Zhaojun Wu.</title>
<date>2011</date>
<booktitle>Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation,</booktitle>
<pages>236--252</pages>
<editor>In Joseph Olive, Caitlin Christianson, and John McCary, editors,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg.</location>
<marker>Wu, Fung, 2011</marker>
<rawString>Dekai Wu, Pascale Fung, Marine Carpuat, Chi kiu Lo, Yongsheng Yang, and Zhaojun Wu. 2011. Lexical semantics for statistical machine translation. In Joseph Olive, Caitlin Christianson, and John McCary, editors, Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation, pages 236–252. Springer, Heidelberg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>