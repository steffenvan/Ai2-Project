<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.815841">
L1 Regularized Regression for Reranking and System Combination in
Machine Translation
</title>
<author confidence="0.873997">
Ergun Bic¸ici
</author>
<affiliation confidence="0.857467">
Koc¸ University
</affiliation>
<address confidence="0.601973">
34450 Sariyer, Istanbul, Turkey
</address>
<email confidence="0.997981">
ebicici@ku.edu.tr
</email>
<sectionHeader confidence="0.994775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999943">
We use L1 regularized transductive regres-
sion to learn mappings between source
and target features of the training sets
derived for each test sentence and use
these mappings to rerank translation out-
puts. We compare the effectiveness of L1
regularization techniques for regression to
learn mappings between features given in
a sparse feature matrix. The results show
the effectiveness of using L1 regulariza-
tion versus L2 used in ridge regression.
We show that regression mapping is ef-
fective in reranking translation outputs and
in selecting the best system combinations
with encouraging results on different lan-
guage pairs.
</bodyText>
<sectionHeader confidence="0.998753" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999340095238096">
Regression can be used to find mappings be-
tween the source and target feature sets derived
from given parallel corpora. Transduction learn-
ing uses a subset of the training examples that
are closely related to the test set without using
the model induced by the full training set. In
the context of SMT, we select a few training in-
stances for each test instance to guide the transla-
tion process. This also gives us a computational
advantage when considering the high dimension-
ality of the problem. The goal in transductive
regression based machine translation (TRegMT)
is both reducing the computational burden of the
regression approach by reducing the dimension-
ality of the training set and the feature set and
also improving the translation quality by using
transduction. Transductive regression is shown to
achieve higher accuracy than L2 regularized ridge
regression on some machine learning benchmark
datasets (Chapelle et al., 1999).
In an idealized feature mapping matrix where
</bodyText>
<note confidence="0.980282">
Deniz Yuret
Koc¸ University
34450 Sariyer, Istanbul, Turkey
</note>
<email confidence="0.948577">
dyuret@ku.edu.tr
</email>
<bodyText confidence="0.998207692307692">
features are word sequences, we would like to ob-
serve few target features for each source feature
derived from a source sentence. In this setting, we
can think of feature mappings being close to per-
mutation matrices with one nonzero item for each
column. L1 regularization helps us achieve solu-
tions close to the permutation matrices by increas-
ing sparsity.
We show that L1 regularized regression map-
ping is effective in reranking translation outputs
and present encouraging results on different lan-
guage pairs in the translation task of WMT10. In
the system combination task, different translation
outputs of different translation systems are com-
bined to find a better translation. We model system
combination task as a reranking problem among
the competing translation models and present en-
couraging results with the TRegMT system.
Related Work: Regression techniques can
be used to model the relationship between
strings (Cortes et al., 2007). Wang et al. (2007)
applies a string-to-string mapping approach
to machine translation by using ordinary least
squares regression and n-gram string kernels to
a small dataset. Later they use L2 regularized
least squares regression (Wang and Shawe-Taylor,
2008). Although the translation quality they
achieve is not better than Moses (Koehn et al.,
2007), which is accepted to be the state-of-the-art,
they show the feasibility of the approach. Ser-
rano et al. (2009) use kernel regression to find
translation mappings from source to target feature
vectors and experiment with translating hotel
front desk requests. Ueffing (2007) approaches
the transductive learning problem for SMT by
bootstrapping the training using the translations
produced by the SMT system that have a scoring
performance above some threshold as estimated
by the SMT system itself.
</bodyText>
<page confidence="0.94894">
282
</page>
<note confidence="0.456991">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 282–289,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9983798">
Outline: Section 2 gives an overview of regres-
sion based machine translation, which is used to
find the mappings between the source and target
features of the training set. In section 3 we present
L1 regularized transductive regression for align-
ment learning. Section 4 presents our experiments,
instance selection techniques, and results on the
translation task for WMT10. In section 5, we
present the results on the system combination task
using reranking. The last section concludes.
</bodyText>
<subsectionHeader confidence="0.5608185">
2 An Overview of Regression Based
Machine Translation
</subsectionHeader>
<bodyText confidence="0.996431888888889">
Let X and Y correspond to the token sets used to
represent source and target strings, then a train-
ing sample of m inputs can be represented as
(x1, y1), ... , (xm, ym) E X∗ X Y ∗, where (xi, yi)
corresponds to a pair of source and target language
token sequences. Our goal is to find a mapping
f : X∗ —* Y ∗ that can convert a given set of
source tokens to a set of target tokens that share
the same meaning in the target language.
</bodyText>
<equation confidence="0.783195">
Φ−1
Y
</equation>
<figureCaption confidence="0.9593305">
Figure 1: String-to-string mapping.
Figure 1 depicts the mappings between different
</figureCaption>
<equation confidence="0.4352765">
representations. ΦX : X∗ —* FX = RNX and
ΦY : Y ∗ —* FY = RNY map each string sequence
</equation>
<bodyText confidence="0.9904495">
to a point in high dimensional real number space
where dim(FX) = NX and dim(FY ) = NY .
</bodyText>
<equation confidence="0.9188605">
Let MX E RNX×m and MY E RNY ×m such
that MX = [ΦX(x1),... , ΦX(xm)] and MY =
[ΦY (y1), . . . , ΦY (ym)]. The ridge regression so-
lution using L2 regularization is found as:
HL2 = arg min 11MY −HMX 112 F +A11H112 F .(1)
H∈[PNY xNX
</equation>
<bodyText confidence="0.7358465">
Proposition 1 Solution to the cost function given
in Equation 1 is found by the following identities:
</bodyText>
<equation confidence="0.998335333333333">
H = MY MTX(MXMTX + AINX)−1 (primal)
H = MY (KX + AIm)−1MT (dual)
X
</equation>
<bodyText confidence="0.98394">
(2)
where KX = MTXMX is the Gram matrix with
KX(i, j) = kX(xi, xj) and kX(xi, xj) is the ker-
nel function defined as kX(xi, xj) = O(xi)T O(xj).
The primal solution involves the inversion of the
</bodyText>
<page confidence="0.750609">
3
</page>
<bodyText confidence="0.9976543">
covariance matrix in the feature space (O(NX))
and the dual solution involves the inversion of the
kernel matrix in the instance space (O(m3)) and
L2 regularization term prevents the normal equa-
tions to be singular. We use the dual solution when
computing HL2.
Two main challenges of the RegMT approach
are learning the regression function, g : X∗ —*
FY , and solving the pre-image problem, which,
given the features of the estimated target string se-
quence, g(x) = ΦY (ˆy), attempts to find y E Y ∗:
f(x) = arg miny∈Y * ||g(x)−ΦY (y)||2. Pre-image
calculation involves a search over possible transla-
tions minimizing the cost function:
where KyY =[kY (y,y1), . . . , kY (y,ym)]T E Rm×1
and KxX E Rm×1 is defined similarly.
We use n-spectrum weighted word ker-
nel (Shawe-Taylor and Cristianini, 2004) as fea-
ture mappers which consider all word sequences
up to order n:
</bodyText>
<equation confidence="0.9976312">
|x&apos;|−p+1
E
p I(x[i:i+p−1]=x�[� : +p−1])
j=1
(4)
</equation>
<bodyText confidence="0.999940666666667">
where x[i : j] denotes a substring of x with the
words in the range [i, j], I(.) is the indicator func-
tion, and p is the number of words in the feature.
</bodyText>
<sectionHeader confidence="0.736818" genericHeader="method">
3 L1 Regularized Regression
</sectionHeader>
<bodyText confidence="0.999973222222222">
In statistical machine translation, parallel cor-
pora, which contain translations of the same doc-
uments in source and target languages, are used
to estimate a likely target translation for a given
source sentence based on the observed transla-
tions. String kernels lead to very sparse represen-
tations of the feature space and we examine the ef-
fectiveness of L1 regularized regression to find the
mappings between sparsely observed feature sets.
</bodyText>
<subsectionHeader confidence="0.998733">
3.1 Sparsity in Translation Mappings
</subsectionHeader>
<bodyText confidence="0.999306666666667">
We would like to observe only a few nonzero tar-
get feature coefficients corresponding to a source
feature in the coefficient matrix. An example solu-
tion matrix representing a possible alignment be-
tween unigram source and target features could be
the following:
</bodyText>
<equation confidence="0.998792833333333">
X∗ f = Y ∗
ΦX
�
ΦY
� � �
h
FX = FY
g
f(x) = arg min kDY (y) − HDX(x)k2
yEY*
= arg min kY (y, y) − 2(KyY )T (KX + AI�)−1KxX,(3)
yEY ,
n
k(x, X) E
p=1
|x|−p+1
�
i=1
</equation>
<page confidence="0.732126">
283
</page>
<figure confidence="0.57762">
h+i , hz ∈ RNXx1 such that hi = h+i − hz :
hi = arg min 11Myi − hMX112F +a
h
NX
E JhkJ, (6)
k=1
H
f1
f2
f3
e1
e2
e3
1
1
1
1
</figure>
<bodyText confidence="0.999593090909091">
Here ei represents unigram source features and fi
represent unigram target features. e1 and e3 have
unambiguous translations whereas e2 is ambigu-
ous. Even if unigram features lead to ambiguity,
we expect higher order features like bigrams and
trigrams to help us resolve the ambiguity. Typical
H matrices have thousands of features. L1 regu-
larization helps us achieve solutions close to per-
mutation matrices by increasing sparsity (Bishop,
2006). In contrast, L2 solutions give us dense ma-
trices.
</bodyText>
<subsectionHeader confidence="0.999555">
3.2 L1 Regularized Regression for Learning
</subsectionHeader>
<bodyText confidence="0.999805">
HL2 does not give us a sparse solution and most
of the coefficients remain non-zero. L1 norm be-
haves both as a feature selection technique and a
method for reducing coefficient values.
</bodyText>
<equation confidence="0.9897945">
HL1 = arg min
HERNY xNX kMy − HMX k2� +AkHk1 .(5)
</equation>
<bodyText confidence="0.9990825">
Equation 5 presents the lasso (least absolute
shrinkage and selection operator) (Tibshirani,
1996) solution where the regularization term is
now the L1 matrix norm defined as k H k1=
</bodyText>
<equation confidence="0.655166">
E
</equation>
<bodyText confidence="0.975266952380953">
i,l |Hi,l|. Since L1 regularization cost is not
differentiable, HL1 is found by optimization or ap-
proximation techniques. We briefly describe three
techniques to obtain L1 regularized regression co-
efficients.
Forward Stagewise Regression (FSR): We
experiment with forward stagewise regression
(FSR) (Hastie et al., 2006), which approximates
the lasso. The incremental forward stagewise re-
gression algorithm increases the weight of the pre-
dictor variable that is most correlated with the
residual by a small amount, E, multiplied with
the sign of the correlation at each step. As
E → 0, the profile of the coefficients resemble the
lasso (Hastie et al., 2009).
Quadratic Programming (QP): We also use
quadratic programming (QP) to find HL1. We can
pose lasso as a QP problem as follows (Mørup
and Clemmensen, 2007). We assume that the
rows of My are independent and solve for each
row i, Myi ∈ R1&apos;&apos;, using non-negative variables
</bodyText>
<equation confidence="0.912323">
T hiiT − �hi(�MXMTyi − A1), (7)
s.t. hi &gt; 0, MX = L−MX,�hi = �h+i h% .
</equation>
<bodyText confidence="0.908472181818182">
Linear Programming (LP): L1 minimization
can also be posed as a linear programming (LP)
problem by interpreting the error term as the con-
straint (Chen et al., 1998) and solving for each row
i:
hi = arg min
h khk1 subject to Myi = hMX, (8)
which can again be solved using non-negative
variables. This is a slightly different optimization
and the results can be different but linear program-
ming solvers offer computational advantages.
</bodyText>
<subsectionHeader confidence="0.979987">
3.3 Transductive Regression
</subsectionHeader>
<bodyText confidence="0.9997358">
Transduction uses test instances, which can some-
times be accessible at training time, to learn spe-
cific models tailored towards the test set. Trans-
duction has computational advantages by not us-
ing the full training set and by having to satisfy a
smaller set of constraints. For each test sentence,
we pick a limited number of training instances de-
signed to improve the coverage of correct features
to build a regression model. Section 4.2 details our
instance selection methods.
</bodyText>
<sectionHeader confidence="0.996419" genericHeader="method">
4 Translation Experiments
</sectionHeader>
<bodyText confidence="0.999948">
We perform experiments on the translation task
of the English-German, German-English, English-
French, English-Spanish, and English-Czech lan-
guage pairs using the training corpus provided in
WMT10.
</bodyText>
<subsectionHeader confidence="0.991924">
4.1 Datasets and Baseline
</subsectionHeader>
<bodyText confidence="0.99998">
We developed separate SMT models using
Moses (Koehn et al., 2007) with default settings
with maximum sentence length set to 80 using 5-
gram language model and obtained distinct 100-
best lists for the test sets. All systems were tuned
with 2051 sentences and tested with 2525 sen-
tences. We have randomly picked 100 instances
from the development set to be used in tuning the
regression experiments (dev.100). The translation
challenge test set contains 2489 sentences. Num-
ber of sentences in the training set of each system
</bodyText>
<equation confidence="0.602516">
hi = arg min 1 hi MXMX
˜hi 2
</equation>
<page confidence="0.98491">
284
</page>
<tableCaption confidence="0.857407">
and baseline performances for uncased output (test
set BLEU, challenge test set BLEU) are given in
Table 1.
</tableCaption>
<table confidence="0.9997105">
Corpus # sent BLEU BLEU Challenge
en-de 1609988 .1471 .1309
de-en 1609988 .1943 .1556
en-fr 1728965 .2281 .2049
en-es 1715158 .2237 .2106
en-cz 7320238 .1452 .1145
</table>
<tableCaption confidence="0.975384">
Table 1: Initial uncased performances of the trans-
lation systems.
</tableCaption>
<bodyText confidence="0.9887622">
Feature mappers used are 3-spectrum counting
word kernels, which consider all N-grams up to
order 3 weighted by the number of tokens in the
feature. We segment sentences using some of the
punctuation for managing the feature set better and
do not consider N-grams that cross segments.
We use BLEU (Papineni et al., 2001) and
NIST (Doddington, 2002) evaluation metrics for
measuring the performance of translations auto-
matically.
</bodyText>
<subsectionHeader confidence="0.945468">
4.2 Instance Selection
</subsectionHeader>
<bodyText confidence="0.999964909090909">
Proper selection of training instances plays an im-
portant role to learn feature mappings with limited
computational resources accurately. In previous
work (Wang and Shawe-Taylor, 2008), sentence
based training instances were selected using tf-idf
retrieval. We transform test sentences to feature
sets obtained by the kernel mapping before mea-
suring their similarities and index the sentences
based on the features. Given a source sentence
of length 20, its feature representation would have
a total of 57 uni/bi/tri-gram features. If we select
closest sentences from the training set, we may not
have translations for all the features in this repre-
sentation. But if we search for translations of each
feature, then we have a higher chance of covering
all the features found in the sentence we are try-
ing to translate. The index acts as a dictionary of
source phrases storing training set entries whose
source sentence match the given source phrase.
The number of instances per feature is chosen
inversely proportional to the frequency of the fea-
ture determined by the following formula:
</bodyText>
<equation confidence="0.992325">
#instance(f) = n/ ln(1 + idfScore(f)/9.0), (9)
</equation>
<bodyText confidence="0.999924333333333">
where idfScore(f) sums the idf (inverse document
frequency) of the tokens in feature f and n is a
small number.
</bodyText>
<subsectionHeader confidence="0.999486">
4.3 Addition of Brevity Penalty
</subsectionHeader>
<bodyText confidence="0.999718666666667">
Detailed analysis of the results shows TRegMT
score achieves better N-gram match percentages
than Moses translation but suffers from the brevity
penalty due to selecting shorter translations. Due
to using a cost function that minimizes the squared
loss, TRegMT score tends to select shorter trans-
lations when the coverage is low. We also observe
that we are able to achieve higher scores for NIST,
which suggests the addition of a brevity penalty to
the score.
Precision based BLEU scoring divides N-gram
match counts to N-gram counts found in the trans-
lation and this gives an advantage to shorter trans-
lations. Therefore, a brevity penalty (BP) is added
to penalize short translations:
</bodyText>
<equation confidence="0.999810333333333">
BP = min(1 − ref-length,0) (10)
trans-length
BLEU = e(log(ngram,,,.)+BP) (11)
</equation>
<bodyText confidence="0.999698785714286">
where ngramprec represent the sum of n-gram
precisions. Moses rarely incurs BP as it has a word
penalty parameter optimized against BLEU which
penalizes translations that are too long or too short.
For instance, Moses 1-best translation for en-de
system achieves .1309 BLEU versus .1320 BLEU
without BP.
We handle short translations in two ways. We
optimize the A parameter of QP, which manages
the sparsity of the solution (larger A values cor-
respond to sparser solutions) against BLEU score
rather than the squared loss. Optimization yields
A = 20.744. We alternatively add a BP cost to the
squared loss:
</bodyText>
<equation confidence="0.999856">
|bY (y)|
BP = e(min(1− |IHIDX (x)+.BP , |, ) (12)
114) &apos; (y) − Hd)X(x)112 +ABPBP (13)
</equation>
<bodyText confidence="0.997784153846154">
where |. |denotes the length of the feature vector,
&apos;_., rounds feature weights to integers, αBP is a
constant weight added to the estimation, and ABP
is the weight given for the BP cost. |1-H-bX(x) +
αBP, |represents an estimate of the length of the
reference as found by the TRegMT system. This
BP cost estimate is similar to the cost used in (Ser-
rano et al., 2009) normalized by the length of the
reference. We found αBP = 0.1316 and ABP =
−13.68 when optimized on the en-de system. We
add a BP penalty to all of the reranking results
given in the next section and QP results also use
optimized A.
</bodyText>
<equation confidence="0.9991885">
f(x) = arg min
yE &apos; *
</equation>
<page confidence="0.995758">
285
</page>
<table confidence="0.999581375">
Score en-de NIST de -en en -fr en -es en -cz
BLEU BLEU NIST BLEU NIST BLEU NIST BLEU NIST
Baseline .1309 5.1417 .1556 5.4164 .2049 6.3194 .2106 6.3611 .1145 4.5008
Oracle .1811 6.0252 .2101 6.2103 .2683 7.2409 .2770 7.3190 .1628 5.4501
L2 .1319 5.1680 .1555 5.4344 .2044 6.3370 .2132 6.4093 .1148 4.5187
FSR .1317* 5.1639 .1559 5.4383 .2053 6.3458 .2144 6.4168 .1150 4.5172
LP .1317 5.1695 .1561 5.4304 .2048 6.3245 .2109 6.4176 .1124 4.5143
QP .1309 5.1664 .1550 5.4553 .2033 6.3354* .2121 6.4271 .1150 4.5264
</table>
<tableCaption confidence="0.987166">
Table 2: Reranking results using TRegMT, TM, and LM scores. We use approximate randomization
</tableCaption>
<bodyText confidence="0.777678333333333">
test (Riezler and Maxwell, 2005) with 1000 repetitions to determine score difference significance: results
in bold are significant with p G 0.01 and italic results with (*) are significant with p G .05. The
difference of the remaining from the baseline are not statistically significant.
</bodyText>
<subsectionHeader confidence="0.998915">
4.4 Reranking Experiments
</subsectionHeader>
<bodyText confidence="0.99955">
We rerank N-best lists by using linear combina-
tions of the following scoring functions:
</bodyText>
<listItem confidence="0.992971555555556">
1. TRegMT: Transductive regression based ma-
chine translation scores as found by Equa-
tion 3.
2. TM: Translation model scores we obtain
from the baseline SMT system that is used
to generate the N-best lists.
3. LM: 5-gram language model scores that the
baseline SMT system uses when calculating
the translation model scores.
</listItem>
<bodyText confidence="0.867044333333333">
The training set we obtain may not contain all
of the features of the reference target due to low
coverage. Therefore, when performing reranking,
we also add the cost coming from the features of
4bY (y) that are not represented in the training set
to the squared loss as in:
</bodyText>
<equation confidence="0.985735">
11.bY (y) \ FY 112 + 11-bY (y) − H-bX(x)112, (14)
</equation>
<bodyText confidence="0.99996534">
where 4bY (y) \ FY represent the features of y not
represented in the training set.
We note that TRegMT score only contains or-
dering information as present in the bi/tri-gram
features in the training set. Therefore, the ad-
dition of a 5-gram LM score as well as the TM
score, which also incorporates the LM score in
itself, improves the performance. We are not
able to improve the BLEU score when we use
TRegMT score by itself however we are able to
achieve improvements in the NIST and 1-WER
scores. The performance increase is important for
two reasons. First of all, we are able to improve
the performance using blended spectrum 3-gram
features against translations obtained with 5-gram
language model and higher order features. Out-
performing higher order n-gram models is known
to be a difficult task (Galley and Manning, 2009).
Secondly, increasing the performance with rerank-
ing itself is a hard task since possible translations
are already constrained by the ones observed in N-
best lists. Therefore, an increase in the N-best list
size may increase the score gaps.
Table 2 presents reranking results on all of the
language pairs we considered, using TRegMT,
TM, and LM scores with the combination weights
learned in the development set. We are able to
achieve better BLEU and NIST scores on all of the
listed systems. We are able to see up to .38 BLEU
points increase for the en-es pair. Oracle reranking
performances are obtained by using BLEU scoring
metric.
If we used only the TM and LM scores when
reranking with the en-de system, then we would
obtain .1309 BLEU and 5.1472 NIST scores. We
only see a minor increase in the NIST score and no
change in the BLEU score with this setting when
compared with the baseline given in Table 2.
Due to computational reasons, we do not use
the same number of instances to train different
models. In our experiments, we used n = 3 for
L2, n = 1.5 for FSR, and n = 1.2 for QP and
LP solutions to select the number of instances in
Equation 9. The average number of instances used
per sentence in training corresponding to these
choices are approximately 140, 74, and 61. Even
with these decreased number of training instances,
L1 regularized regression techniques are able to
achieve comparable scores to L2 regularized re-
gression model in Table 2.
</bodyText>
<sectionHeader confidence="0.982441" genericHeader="method">
5 System Combination Experiments
</sectionHeader>
<bodyText confidence="0.9985975">
We perform experiments on the system com-
bination task for the English-German, German-
English, English-French, English-Spanish, and
English-Czech language pairs using the training
</bodyText>
<page confidence="0.994549">
286
</page>
<table confidence="0.99635375">
Score en -de de -en en -fr en -es en -cz
BLEU NIST BLEU NIST BLEU NIST BLEU NIST BLEU NIST
Random .1490 5.6555 .2088 6.4886 .2415 6.8948 .2648 7.2563 .1283 4.9238
Best model .1658 5.9610 .2408 6.9861 .2864 7.5272 .3047 7.7559 .1576 5.4480
L2 .1694 5.9974 .2336 6.9398 .2948 7.7037 .3036 7.8120 .1657 5.5654
FSR .1689 5.9638 .2357 6.9254 .2947 7.7107 .3049 7.8156 .1657 5.5632
LP .1694 5.9954 .2368 6.8850 .2928 7.7157 .3027 7.7838 .1659 5.5680
QP .1692 5.9983 .2368 6.9172 .2913 7.6949 .3040 7.8086 .1662 5.5785
</table>
<tableCaption confidence="0.998639">
Table 3: Reranking results using TRegMT, TM, and LM scores. bold correspond to the best score in
each rectangle of scores.
</tableCaption>
<bodyText confidence="0.450966">
corpus provided in WMT10.
</bodyText>
<subsectionHeader confidence="0.977928">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999983235294118">
We use the training set provided in WMT10 to in-
dex and select transductive instances from. The
challenge split the test set for the translation task
of 2489 sentences into a tuning set of 455 sen-
tences and a test set with the remaining 2034 sen-
tences. Translation outputs for each system is
given in a separate file and the number of sys-
tem outputs per translation pair varies. We have
tokenized and lowercased each of the system out-
puts and combined these in a single N-best file per
language pair. We also segment sentences using
some of the punctuation for managing the feature
set better. We use these N-best lists for TRegMT
reranking to select the best translation model. Fea-
ture mappers used are 3-spectrum counting word
kernels, which consider all n-grams up to order 3
weighted by the number of tokens in the feature.
</bodyText>
<subsectionHeader confidence="0.993049">
5.2 Experiments
</subsectionHeader>
<bodyText confidence="0.9991965">
We rerank N-best lists by using combinations of
the following scoring functions:
</bodyText>
<listItem confidence="0.998557125">
1. TRegMT: Transductive regression based ma-
chine translation scores as found by Equa-
tion 3.
2. TM’: Translation model scores are obtained
by measuring the average BLEU perfor-
mance of each translation relative to the other
translations in the N-best list.
3. LM: We calculate 5-gram language model
</listItem>
<bodyText confidence="0.970412282608696">
scores for each translation using the language
model trained over the target corpus provided
in the translation task.
Since we do not have access to the reference
translations nor to the translation model scores
each system obtained for each sentence, we es-
timate translation model performance (TM’) by
measuring the average BLEU performance of each
translation relative to the other translations in the
N-best list. Thus, each possible translation in the
N-best list is BLEU scored against other transla-
tions and the average of these scores is selected
as the TM score for the sentence. Sentence level
BLEU score calculation avoids singularities in n-
gram precisions by taking the maximum of the
match count and 1
2|�i |for |sz |denoting the length
of the source sentence sz as used in (Macherey and
Och, 2007).
Table 3 presents reranking results on all of the
language pairs we considered, using TRegMT,
TM, and LM scores with the same combination
weights as above. Random model score lists the
random model performance selected among the
competing translations randomly and it is used as
a baseline. Best model score lists the performance
of the best model performance. We are able to
achieve better BLEU and NIST scores in all of the
listed systems except for the de-en language pair
when compared with the performance of the best
competing translation system. The lower perfor-
mance in the de-en language pair may be due to
having a single best translation system that outper-
forms others significantly. The difference between
the best model performance and the mean as well
as the variance of the scores in the de-en language
pair is about twice their counterparts in en-de lan-
guage pair.
Due to computational reasons, we do not use
the same number of instances to train different
models. In our experiments, we used n = 4 for
L2, n = 1.5 for FSR, and n = 1.2 for QP and
LP solutions to select the number of instances in
Equation 9. The average number of instances used
per sentence in training corresponding to these
choices are approximately 189, 78, and 64.
</bodyText>
<page confidence="0.994264">
287
</page>
<sectionHeader confidence="0.997795" genericHeader="conclusions">
6 Contributions
</sectionHeader>
<bodyText confidence="0.999991285714286">
We use transductive regression to learn mappings
between source and target features of given paral-
lel corpora and use these mappings to rerank trans-
lation outputs. We compare the effectiveness of L1
regularization techniques for regression. TRegMT
score has a tendency to select shorter transla-
tions when the coverage is low. We incorporate a
brevity penalty to the squared loss and optimize A
parameter of QP to tackle this problem and further
improve the performance of the system.
The results show the effectiveness of using L1
regularization versus L2 used in ridge regression.
Proper selection of training instances plays an im-
portant role to learn correct feature mappings with
limited computational resources accurately. We
plan to investigate better instance selection meth-
ods for improving the translation performance.
TRegMT score has a tendency to select shorter
translations when the coverage is low. We incor-
porate a brevity penalty to the score and optimize
the A parameter of QP to tackle this problem.
</bodyText>
<sectionHeader confidence="0.997238" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998547">
The research reported here was supported in
part by the Scientific and Technological Research
Council of Turkey (TUBITAK).
</bodyText>
<sectionHeader confidence="0.997792" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999436894736842">
Christopher M. Bishop. 2006. Pattern Recognition
and Machine Learning. Springer.
Olivier Chapelle, Vladimir Vapnik, and Jason Weston.
1999. Transductive inference for estimating values
of functions. In NIPS, pages 421–427.
Scott Shaobing Chen, David L. Donoho, and
Michael A. Saunders. 1998. Atomic decomposition
by basis pursuit. SIAM Journal on Scientific Com-
puting, 20(1):33–61.
Corinna Cortes, Mehryar Mohri, and Jason Weston.
2007. A general regression framework for learn-
ing string-to-string mappings. In Gokhan H. Bakir,
Thomas Hofmann, and Bernhard Sch editors, Pre-
dicting Structured Data, pages 143–168. The MIT
Press, September.
George Doddington. 2002. Automatic evaluation
of machine translation quality using n-gram co-
occurrence statistics. In Proceedings of the second
international conference on Human Language Tech-
nology Research, pages 138–145, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Michel Galley and Christopher D. Manning. 2009.
Quadratic-time dependency parsing for machine
translation. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 773–781,
Suntec, Singapore, August. Association for Compu-
tational Linguistics.
Trevor Hastie, Jonathan Taylor, Robert Tibshirani, and
Guenther Walther. 2006. Forward stagewise regres-
sion and the monotone lasso. Electronic Journal of
Statistics, 1.
Trevor Hastie, Robert Tibshirani, and Jerome Fried-
man. 2009. The Elements of Statistical Learning:
Data Mining, Inference and Prediction. Springer-
Verlag, 2nd edition.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Annual Meeting of the Assoc. for Compu-
tational Linguistics, pages 177–180, Prague, Czech
Republic, June.
Wolfgang Macherey and Franz J. Och. 2007. An
empirical study on computing consensus transla-
tions from multiple machine translation systems. In
EMNLP-CoNLL, pages 986–995.
M. Mørup and L. H. Clemmensen. 2007. Multiplica-
tive updates for the lasso. In Machine Learning for
Signal Processing MLSP, IEEE Workshop on, pages
33 –38, Aug.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic
evaluation of machine translation. In ACL ’02: Pro-
ceedings of the 40th Annual Meeting on Associa-
tion for Computational Linguistics, pages 311–318,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Stefan Riezler and John T. Maxwell. 2005. On some
pitfalls in automatic evaluation and significance test-
ing for MT. In Proceedings of the ACL Workshop
on Intrinsic and Extrinsic Evaluation Measures for
Machine Translation and/or Summarization, pages
57–64, Ann Arbor, Michigan, June. Association for
Computational Linguistics.
Nicolas Serrano, Jesus Andres-Ferrer, and Francisco
Casacuberta. 2009. On a kernel regression approach
to machine translation. In Iberian Conference on
Pattern Recognition and Image Analysis, pages 394–
401.
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
</reference>
<page confidence="0.968072">
288
</page>
<reference confidence="0.999909625">
Robert J. Tibshirani. 1996. Regression shrinkage and
selection via the lasso. Journal of the Royal Statisti-
cal Society, Series B, 58(1):267–288.
Nicola Ueffing, Gholamreza Haffari, and Anoop
Sarkar. 2007. Transductive learning for statistical
machine translation. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 25–32, Prague, Czech Republic,
June. The Association for Computer Linguistics.
Zhuoran Wang and John Shawe-Taylor. 2008. Kernel
regression framework for machine translation: UCL
system description for WMT 2008 shared transla-
tion task. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 155–158,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
Zhuoran Wang, John Shawe-Taylor, and Sandor Szed-
mak. 2007. Kernel regression based machine trans-
lation. In Human Language Technologies 2007:
The Conference of the North American Chapter
of the Association for Computational Linguistics;
Companion Volume, Short Papers, pages 185–188,
Rochester, New York, April. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.998641">
289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914756">
<title confidence="0.980682">Regression for Reranking and System Combination Machine Translation</title>
<address confidence="0.985775">34450 Sariyer, Istanbul,</address>
<email confidence="0.998273">ebicici@ku.edu.tr</email>
<abstract confidence="0.997971764705882">use transductive regression to learn mappings between source and target features of the training sets derived for each test sentence and use these mappings to rerank translation out- We compare the effectiveness of regularization techniques for regression to learn mappings between features given in a sparse feature matrix. The results show effectiveness of using regularizaversus in ridge regression. We show that regression mapping is effective in reranking translation outputs and in selecting the best system combinations with encouraging results on different language pairs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<date>2006</date>
<booktitle>Pattern Recognition and Machine Learning.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="8273" citStr="Bishop, 2006" startWordPosition="1404" endWordPosition="1405">(3) yEY , n k(x, X) E p=1 |x|−p+1 � i=1 283 h+i , hz ∈ RNXx1 such that hi = h+i − hz : hi = arg min 11Myi − hMX112F +a h NX E JhkJ, (6) k=1 H f1 f2 f3 e1 e2 e3 1 1 1 1 Here ei represents unigram source features and fi represent unigram target features. e1 and e3 have unambiguous translations whereas e2 is ambiguous. Even if unigram features lead to ambiguity, we expect higher order features like bigrams and trigrams to help us resolve the ambiguity. Typical H matrices have thousands of features. L1 regularization helps us achieve solutions close to permutation matrices by increasing sparsity (Bishop, 2006). In contrast, L2 solutions give us dense matrices. 3.2 L1 Regularized Regression for Learning HL2 does not give us a sparse solution and most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL1 = arg min HERNY xNX kMy − HMX k2� +AkHk1 .(5) Equation 5 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is now the L1 matrix norm defined as k H k1= E i,l |Hi,l|. Since L1 regularization cost is not differentiable, HL1 is found by optim</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Chapelle</author>
<author>Vladimir Vapnik</author>
<author>Jason Weston</author>
</authors>
<title>Transductive inference for estimating values of functions.</title>
<date>1999</date>
<booktitle>In NIPS,</booktitle>
<pages>421--427</pages>
<contexts>
<context position="1754" citStr="Chapelle et al., 1999" startWordPosition="266" endWordPosition="269">ew training instances for each test instance to guide the translation process. This also gives us a computational advantage when considering the high dimensionality of the problem. The goal in transductive regression based machine translation (TRegMT) is both reducing the computational burden of the regression approach by reducing the dimensionality of the training set and the feature set and also improving the translation quality by using transduction. Transductive regression is shown to achieve higher accuracy than L2 regularized ridge regression on some machine learning benchmark datasets (Chapelle et al., 1999). In an idealized feature mapping matrix where Deniz Yuret Koc¸ University 34450 Sariyer, Istanbul, Turkey dyuret@ku.edu.tr features are word sequences, we would like to observe few target features for each source feature derived from a source sentence. In this setting, we can think of feature mappings being close to permutation matrices with one nonzero item for each column. L1 regularization helps us achieve solutions close to the permutation matrices by increasing sparsity. We show that L1 regularized regression mapping is effective in reranking translation outputs and present encouraging r</context>
</contexts>
<marker>Chapelle, Vapnik, Weston, 1999</marker>
<rawString>Olivier Chapelle, Vladimir Vapnik, and Jason Weston. 1999. Transductive inference for estimating values of functions. In NIPS, pages 421–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Shaobing Chen</author>
<author>David L Donoho</author>
<author>Michael A Saunders</author>
</authors>
<title>Atomic decomposition by basis pursuit.</title>
<date>1998</date>
<journal>SIAM Journal on Scientific Computing,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="9951" citStr="Chen et al., 1998" startWordPosition="1686" endWordPosition="1689"> the correlation at each step. As E → 0, the profile of the coefficients resemble the lasso (Hastie et al., 2009). Quadratic Programming (QP): We also use quadratic programming (QP) to find HL1. We can pose lasso as a QP problem as follows (Mørup and Clemmensen, 2007). We assume that the rows of My are independent and solve for each row i, Myi ∈ R1&apos;&apos;, using non-negative variables T hiiT − �hi(�MXMTyi − A1), (7) s.t. hi &gt; 0, MX = L−MX,�hi = �h+i h% . Linear Programming (LP): L1 minimization can also be posed as a linear programming (LP) problem by interpreting the error term as the constraint (Chen et al., 1998) and solving for each row i: hi = arg min h khk1 subject to Myi = hMX, (8) which can again be solved using non-negative variables. This is a slightly different optimization and the results can be different but linear programming solvers offer computational advantages. 3.3 Transductive Regression Transduction uses test instances, which can sometimes be accessible at training time, to learn specific models tailored towards the test set. Transduction has computational advantages by not using the full training set and by having to satisfy a smaller set of constraints. For each test sentence, we pi</context>
</contexts>
<marker>Chen, Donoho, Saunders, 1998</marker>
<rawString>Scott Shaobing Chen, David L. Donoho, and Michael A. Saunders. 1998. Atomic decomposition by basis pursuit. SIAM Journal on Scientific Computing, 20(1):33–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Mehryar Mohri</author>
<author>Jason Weston</author>
</authors>
<title>A general regression framework for learning string-to-string mappings.</title>
<date>2007</date>
<booktitle>Predicting Structured Data,</booktitle>
<pages>143--168</pages>
<editor>In Gokhan H. Bakir, Thomas Hofmann, and Bernhard Sch editors,</editor>
<publisher>The MIT Press,</publisher>
<contexts>
<context position="2823" citStr="Cortes et al., 2007" startWordPosition="431" endWordPosition="434">matrices by increasing sparsity. We show that L1 regularized regression mapping is effective in reranking translation outputs and present encouraging results on different language pairs in the translation task of WMT10. In the system combination task, different translation outputs of different translation systems are combined to find a better translation. We model system combination task as a reranking problem among the competing translation models and present encouraging results with the TRegMT system. Related Work: Regression techniques can be used to model the relationship between strings (Cortes et al., 2007). Wang et al. (2007) applies a string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to a small dataset. Later they use L2 regularized least squares regression (Wang and Shawe-Taylor, 2008). Although the translation quality they achieve is not better than Moses (Koehn et al., 2007), which is accepted to be the state-of-the-art, they show the feasibility of the approach. Serrano et al. (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front </context>
</contexts>
<marker>Cortes, Mohri, Weston, 2007</marker>
<rawString>Corinna Cortes, Mehryar Mohri, and Jason Weston. 2007. A general regression framework for learning string-to-string mappings. In Gokhan H. Bakir, Thomas Hofmann, and Bernhard Sch editors, Predicting Structured Data, pages 143–168. The MIT Press, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research,</booktitle>
<pages>138--145</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="12219" citStr="Doddington, 2002" startWordPosition="2058" endWordPosition="2059">e test set BLEU) are given in Table 1. Corpus # sent BLEU BLEU Challenge en-de 1609988 .1471 .1309 de-en 1609988 .1943 .1556 en-fr 1728965 .2281 .2049 en-es 1715158 .2237 .2106 en-cz 7320238 .1452 .1145 Table 1: Initial uncased performances of the translation systems. Feature mappers used are 3-spectrum counting word kernels, which consider all N-grams up to order 3 weighted by the number of tokens in the feature. We segment sentences using some of the punctuation for managing the feature set better and do not consider N-grams that cross segments. We use BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) evaluation metrics for measuring the performance of translations automatically. 4.2 Instance Selection Proper selection of training instances plays an important role to learn feature mappings with limited computational resources accurately. In previous work (Wang and Shawe-Taylor, 2008), sentence based training instances were selected using tf-idf retrieval. We transform test sentences to feature sets obtained by the kernel mapping before measuring their similarities and index the sentences based on the features. Given a source sentence of length 20, its feature representation would have a to</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the second international conference on Human Language Technology Research, pages 138–145, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>Quadratic-time dependency parsing for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>773--781</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="18172" citStr="Galley and Manning, 2009" startWordPosition="3053" endWordPosition="3056">Therefore, the addition of a 5-gram LM score as well as the TM score, which also incorporates the LM score in itself, improves the performance. We are not able to improve the BLEU score when we use TRegMT score by itself however we are able to achieve improvements in the NIST and 1-WER scores. The performance increase is important for two reasons. First of all, we are able to improve the performance using blended spectrum 3-gram features against translations obtained with 5-gram language model and higher order features. Outperforming higher order n-gram models is known to be a difficult task (Galley and Manning, 2009). Secondly, increasing the performance with reranking itself is a hard task since possible translations are already constrained by the ones observed in Nbest lists. Therefore, an increase in the N-best list size may increase the score gaps. Table 2 presents reranking results on all of the language pairs we considered, using TRegMT, TM, and LM scores with the combination weights learned in the development set. We are able to achieve better BLEU and NIST scores on all of the listed systems. We are able to see up to .38 BLEU points increase for the en-es pair. Oracle reranking performances are ob</context>
</contexts>
<marker>Galley, Manning, 2009</marker>
<rawString>Michel Galley and Christopher D. Manning. 2009. Quadratic-time dependency parsing for machine translation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 773–781, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Jonathan Taylor</author>
<author>Robert Tibshirani</author>
<author>Guenther Walther</author>
</authors>
<title>Forward stagewise regression and the monotone lasso.</title>
<date>2006</date>
<journal>Electronic Journal of Statistics,</journal>
<volume>1</volume>
<contexts>
<context position="9108" citStr="Hastie et al., 2006" startWordPosition="1536" endWordPosition="1539">election technique and a method for reducing coefficient values. HL1 = arg min HERNY xNX kMy − HMX k2� +AkHk1 .(5) Equation 5 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is now the L1 matrix norm defined as k H k1= E i,l |Hi,l|. Since L1 regularization cost is not differentiable, HL1 is found by optimization or approximation techniques. We briefly describe three techniques to obtain L1 regularized regression coefficients. Forward Stagewise Regression (FSR): We experiment with forward stagewise regression (FSR) (Hastie et al., 2006), which approximates the lasso. The incremental forward stagewise regression algorithm increases the weight of the predictor variable that is most correlated with the residual by a small amount, E, multiplied with the sign of the correlation at each step. As E → 0, the profile of the coefficients resemble the lasso (Hastie et al., 2009). Quadratic Programming (QP): We also use quadratic programming (QP) to find HL1. We can pose lasso as a QP problem as follows (Mørup and Clemmensen, 2007). We assume that the rows of My are independent and solve for each row i, Myi ∈ R1&apos;&apos;, using non-negative va</context>
</contexts>
<marker>Hastie, Taylor, Tibshirani, Walther, 2006</marker>
<rawString>Trevor Hastie, Jonathan Taylor, Robert Tibshirani, and Guenther Walther. 2006. Forward stagewise regression and the monotone lasso. Electronic Journal of Statistics, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Robert Tibshirani</author>
<author>Jerome Friedman</author>
</authors>
<date>2009</date>
<booktitle>The Elements of Statistical Learning: Data Mining, Inference and Prediction.</booktitle>
<publisher>SpringerVerlag,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="9446" citStr="Hastie et al., 2009" startWordPosition="1593" endWordPosition="1596">st is not differentiable, HL1 is found by optimization or approximation techniques. We briefly describe three techniques to obtain L1 regularized regression coefficients. Forward Stagewise Regression (FSR): We experiment with forward stagewise regression (FSR) (Hastie et al., 2006), which approximates the lasso. The incremental forward stagewise regression algorithm increases the weight of the predictor variable that is most correlated with the residual by a small amount, E, multiplied with the sign of the correlation at each step. As E → 0, the profile of the coefficients resemble the lasso (Hastie et al., 2009). Quadratic Programming (QP): We also use quadratic programming (QP) to find HL1. We can pose lasso as a QP problem as follows (Mørup and Clemmensen, 2007). We assume that the rows of My are independent and solve for each row i, Myi ∈ R1&apos;&apos;, using non-negative variables T hiiT − �hi(�MXMTyi − A1), (7) s.t. hi &gt; 0, MX = L−MX,�hi = �h+i h% . Linear Programming (LP): L1 minimization can also be posed as a linear programming (LP) problem by interpreting the error term as the constraint (Chen et al., 1998) and solving for each row i: hi = arg min h khk1 subject to Myi = hMX, (8) which can again be s</context>
</contexts>
<marker>Hastie, Tibshirani, Friedman, 2009</marker>
<rawString>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference and Prediction. SpringerVerlag, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Assoc. for Computational Linguistics,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="3177" citStr="Koehn et al., 2007" startWordPosition="484" endWordPosition="487">n. We model system combination task as a reranking problem among the competing translation models and present encouraging results with the TRegMT system. Related Work: Regression techniques can be used to model the relationship between strings (Cortes et al., 2007). Wang et al. (2007) applies a string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to a small dataset. Later they use L2 regularized least squares regression (Wang and Shawe-Taylor, 2008). Although the translation quality they achieve is not better than Moses (Koehn et al., 2007), which is accepted to be the state-of-the-art, they show the feasibility of the approach. Serrano et al. (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests. Ueffing (2007) approaches the transductive learning problem for SMT by bootstrapping the training using the translations produced by the SMT system that have a scoring performance above some threshold as estimated by the SMT system itself. 282 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages</context>
<context position="11040" citStr="Koehn et al., 2007" startWordPosition="1858" endWordPosition="1861">advantages by not using the full training set and by having to satisfy a smaller set of constraints. For each test sentence, we pick a limited number of training instances designed to improve the coverage of correct features to build a regression model. Section 4.2 details our instance selection methods. 4 Translation Experiments We perform experiments on the translation task of the English-German, German-English, EnglishFrench, English-Spanish, and English-Czech language pairs using the training corpus provided in WMT10. 4.1 Datasets and Baseline We developed separate SMT models using Moses (Koehn et al., 2007) with default settings with maximum sentence length set to 80 using 5- gram language model and obtained distinct 100- best lists for the test sets. All systems were tuned with 2051 sentences and tested with 2525 sentences. We have randomly picked 100 instances from the development set to be used in tuning the regression experiments (dev.100). The translation challenge test set contains 2489 sentences. Number of sentences in the training set of each system hi = arg min 1 hi MXMX ˜hi 2 284 and baseline performances for uncased output (test set BLEU, challenge test set BLEU) are given in Table 1.</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Annual Meeting of the Assoc. for Computational Linguistics, pages 177–180, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz J Och</author>
</authors>
<title>An empirical study on computing consensus translations from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>986--995</pages>
<contexts>
<context position="22557" citStr="Macherey and Och, 2007" startWordPosition="3797" endWordPosition="3800">translation model scores each system obtained for each sentence, we estimate translation model performance (TM’) by measuring the average BLEU performance of each translation relative to the other translations in the N-best list. Thus, each possible translation in the N-best list is BLEU scored against other translations and the average of these scores is selected as the TM score for the sentence. Sentence level BLEU score calculation avoids singularities in ngram precisions by taking the maximum of the match count and 1 2|�i |for |sz |denoting the length of the source sentence sz as used in (Macherey and Och, 2007). Table 3 presents reranking results on all of the language pairs we considered, using TRegMT, TM, and LM scores with the same combination weights as above. Random model score lists the random model performance selected among the competing translations randomly and it is used as a baseline. Best model score lists the performance of the best model performance. We are able to achieve better BLEU and NIST scores in all of the listed systems except for the de-en language pair when compared with the performance of the best competing translation system. The lower performance in the de-en language pa</context>
</contexts>
<marker>Macherey, Och, 2007</marker>
<rawString>Wolfgang Macherey and Franz J. Och. 2007. An empirical study on computing consensus translations from multiple machine translation systems. In EMNLP-CoNLL, pages 986–995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mørup</author>
<author>L H Clemmensen</author>
</authors>
<title>Multiplicative updates for the lasso.</title>
<date>2007</date>
<booktitle>In Machine Learning for Signal Processing MLSP, IEEE Workshop on,</booktitle>
<pages>33--38</pages>
<contexts>
<context position="9601" citStr="Mørup and Clemmensen, 2007" startWordPosition="1619" endWordPosition="1622">gression coefficients. Forward Stagewise Regression (FSR): We experiment with forward stagewise regression (FSR) (Hastie et al., 2006), which approximates the lasso. The incremental forward stagewise regression algorithm increases the weight of the predictor variable that is most correlated with the residual by a small amount, E, multiplied with the sign of the correlation at each step. As E → 0, the profile of the coefficients resemble the lasso (Hastie et al., 2009). Quadratic Programming (QP): We also use quadratic programming (QP) to find HL1. We can pose lasso as a QP problem as follows (Mørup and Clemmensen, 2007). We assume that the rows of My are independent and solve for each row i, Myi ∈ R1&apos;&apos;, using non-negative variables T hiiT − �hi(�MXMTyi − A1), (7) s.t. hi &gt; 0, MX = L−MX,�hi = �h+i h% . Linear Programming (LP): L1 minimization can also be posed as a linear programming (LP) problem by interpreting the error term as the constraint (Chen et al., 1998) and solving for each row i: hi = arg min h khk1 subject to Myi = hMX, (8) which can again be solved using non-negative variables. This is a slightly different optimization and the results can be different but linear programming solvers offer computa</context>
</contexts>
<marker>Mørup, Clemmensen, 2007</marker>
<rawString>M. Mørup and L. H. Clemmensen. 2007. Multiplicative updates for the lasso. In Machine Learning for Signal Processing MLSP, IEEE Workshop on, pages 33 –38, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="12191" citStr="Papineni et al., 2001" startWordPosition="2052" endWordPosition="2055">d output (test set BLEU, challenge test set BLEU) are given in Table 1. Corpus # sent BLEU BLEU Challenge en-de 1609988 .1471 .1309 de-en 1609988 .1943 .1556 en-fr 1728965 .2281 .2049 en-es 1715158 .2237 .2106 en-cz 7320238 .1452 .1145 Table 1: Initial uncased performances of the translation systems. Feature mappers used are 3-spectrum counting word kernels, which consider all N-grams up to order 3 weighted by the number of tokens in the feature. We segment sentences using some of the punctuation for managing the feature set better and do not consider N-grams that cross segments. We use BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) evaluation metrics for measuring the performance of translations automatically. 4.2 Instance Selection Proper selection of training instances plays an important role to learn feature mappings with limited computational resources accurately. In previous work (Wang and Shawe-Taylor, 2008), sentence based training instances were selected using tf-idf retrieval. We transform test sentences to feature sets obtained by the kernel mapping before measuring their similarities and index the sentences based on the features. Given a source sentence of length 20, its feature re</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. BLEU: a method for automatic evaluation of machine translation. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>John T Maxwell</author>
</authors>
<title>On some pitfalls in automatic evaluation and significance testing for MT.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>57--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="16324" citStr="Riezler and Maxwell, 2005" startWordPosition="2740" endWordPosition="2743">e NIST de -en en -fr en -es en -cz BLEU BLEU NIST BLEU NIST BLEU NIST BLEU NIST Baseline .1309 5.1417 .1556 5.4164 .2049 6.3194 .2106 6.3611 .1145 4.5008 Oracle .1811 6.0252 .2101 6.2103 .2683 7.2409 .2770 7.3190 .1628 5.4501 L2 .1319 5.1680 .1555 5.4344 .2044 6.3370 .2132 6.4093 .1148 4.5187 FSR .1317* 5.1639 .1559 5.4383 .2053 6.3458 .2144 6.4168 .1150 4.5172 LP .1317 5.1695 .1561 5.4304 .2048 6.3245 .2109 6.4176 .1124 4.5143 QP .1309 5.1664 .1550 5.4553 .2033 6.3354* .2121 6.4271 .1150 4.5264 Table 2: Reranking results using TRegMT, TM, and LM scores. We use approximate randomization test (Riezler and Maxwell, 2005) with 1000 repetitions to determine score difference significance: results in bold are significant with p G 0.01 and italic results with (*) are significant with p G .05. The difference of the remaining from the baseline are not statistically significant. 4.4 Reranking Experiments We rerank N-best lists by using linear combinations of the following scoring functions: 1. TRegMT: Transductive regression based machine translation scores as found by Equation 3. 2. TM: Translation model scores we obtain from the baseline SMT system that is used to generate the N-best lists. 3. LM: 5-gram language m</context>
</contexts>
<marker>Riezler, Maxwell, 2005</marker>
<rawString>Stefan Riezler and John T. Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing for MT. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 57–64, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Serrano</author>
<author>Jesus Andres-Ferrer</author>
<author>Francisco Casacuberta</author>
</authors>
<title>On a kernel regression approach to machine translation.</title>
<date>2009</date>
<booktitle>In Iberian Conference on Pattern Recognition and Image Analysis,</booktitle>
<pages>394--401</pages>
<contexts>
<context position="3289" citStr="Serrano et al. (2009)" startWordPosition="502" endWordPosition="506">encouraging results with the TRegMT system. Related Work: Regression techniques can be used to model the relationship between strings (Cortes et al., 2007). Wang et al. (2007) applies a string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to a small dataset. Later they use L2 regularized least squares regression (Wang and Shawe-Taylor, 2008). Although the translation quality they achieve is not better than Moses (Koehn et al., 2007), which is accepted to be the state-of-the-art, they show the feasibility of the approach. Serrano et al. (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests. Ueffing (2007) approaches the transductive learning problem for SMT by bootstrapping the training using the translations produced by the SMT system that have a scoring performance above some threshold as estimated by the SMT system itself. 282 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 282–289, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Outline: Section 2 </context>
<context position="15428" citStr="Serrano et al., 2009" startWordPosition="2581" endWordPosition="2585">s correspond to sparser solutions) against BLEU score rather than the squared loss. Optimization yields A = 20.744. We alternatively add a BP cost to the squared loss: |bY (y)| BP = e(min(1− |IHIDX (x)+.BP , |, ) (12) 114) &apos; (y) − Hd)X(x)112 +ABPBP (13) where |. |denotes the length of the feature vector, &apos;_., rounds feature weights to integers, αBP is a constant weight added to the estimation, and ABP is the weight given for the BP cost. |1-H-bX(x) + αBP, |represents an estimate of the length of the reference as found by the TRegMT system. This BP cost estimate is similar to the cost used in (Serrano et al., 2009) normalized by the length of the reference. We found αBP = 0.1316 and ABP = −13.68 when optimized on the en-de system. We add a BP penalty to all of the reranking results given in the next section and QP results also use optimized A. f(x) = arg min yE &apos; * 285 Score en-de NIST de -en en -fr en -es en -cz BLEU BLEU NIST BLEU NIST BLEU NIST BLEU NIST Baseline .1309 5.1417 .1556 5.4164 .2049 6.3194 .2106 6.3611 .1145 4.5008 Oracle .1811 6.0252 .2101 6.2103 .2683 7.2409 .2770 7.3190 .1628 5.4501 L2 .1319 5.1680 .1555 5.4344 .2044 6.3370 .2132 6.4093 .1148 4.5187 FSR .1317* 5.1639 .1559 5.4383 .2053</context>
</contexts>
<marker>Serrano, Andres-Ferrer, Casacuberta, 2009</marker>
<rawString>Nicolas Serrano, Jesus Andres-Ferrer, and Francisco Casacuberta. 2009. On a kernel regression approach to machine translation. In Iberian Conference on Pattern Recognition and Image Analysis, pages 394– 401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6498" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="1072" endWordPosition="1075">on term prevents the normal equations to be singular. We use the dual solution when computing HL2. Two main challenges of the RegMT approach are learning the regression function, g : X∗ —* FY , and solving the pre-image problem, which, given the features of the estimated target string sequence, g(x) = ΦY (ˆy), attempts to find y E Y ∗: f(x) = arg miny∈Y * ||g(x)−ΦY (y)||2. Pre-image calculation involves a search over possible translations minimizing the cost function: where KyY =[kY (y,y1), . . . , kY (y,ym)]T E Rm×1 and KxX E Rm×1 is defined similarly. We use n-spectrum weighted word kernel (Shawe-Taylor and Cristianini, 2004) as feature mappers which consider all word sequences up to order n: |x&apos;|−p+1 E p I(x[i:i+p−1]=x�[� : +p−1]) j=1 (4) where x[i : j] denotes a substring of x with the words in the range [i, j], I(.) is the indicator function, and p is the number of words in the feature. 3 L1 Regularized Regression In statistical machine translation, parallel corpora, which contain translations of the same documents in source and target languages, are used to estimate a likely target translation for a given source sentence based on the observed translations. String kernels lead to very sparse representations of </context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J Tibshirani</author>
</authors>
<title>Regression shrinkage and selection via the lasso.</title>
<date>1996</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>58</volume>
<issue>1</issue>
<contexts>
<context position="8701" citStr="Tibshirani, 1996" startWordPosition="1476" endWordPosition="1477">elp us resolve the ambiguity. Typical H matrices have thousands of features. L1 regularization helps us achieve solutions close to permutation matrices by increasing sparsity (Bishop, 2006). In contrast, L2 solutions give us dense matrices. 3.2 L1 Regularized Regression for Learning HL2 does not give us a sparse solution and most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL1 = arg min HERNY xNX kMy − HMX k2� +AkHk1 .(5) Equation 5 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is now the L1 matrix norm defined as k H k1= E i,l |Hi,l|. Since L1 regularization cost is not differentiable, HL1 is found by optimization or approximation techniques. We briefly describe three techniques to obtain L1 regularized regression coefficients. Forward Stagewise Regression (FSR): We experiment with forward stagewise regression (FSR) (Hastie et al., 2006), which approximates the lasso. The incremental forward stagewise regression algorithm increases the weight of the predictor variable that is most correlated with the residual by a small amount</context>
</contexts>
<marker>Tibshirani, 1996</marker>
<rawString>Robert J. Tibshirani. 1996. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58(1):267–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Gholamreza Haffari</author>
<author>Anoop Sarkar</author>
</authors>
<title>Transductive learning for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>25--32</pages>
<location>Prague, Czech Republic,</location>
<marker>Ueffing, Haffari, Sarkar, 2007</marker>
<rawString>Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar. 2007. Transductive learning for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 25–32, Prague, Czech Republic, June. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhuoran Wang</author>
<author>John Shawe-Taylor</author>
</authors>
<title>Kernel regression framework for machine translation: UCL system description for WMT</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>155--158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="3084" citStr="Wang and Shawe-Taylor, 2008" startWordPosition="469" endWordPosition="472">ifferent translation outputs of different translation systems are combined to find a better translation. We model system combination task as a reranking problem among the competing translation models and present encouraging results with the TRegMT system. Related Work: Regression techniques can be used to model the relationship between strings (Cortes et al., 2007). Wang et al. (2007) applies a string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to a small dataset. Later they use L2 regularized least squares regression (Wang and Shawe-Taylor, 2008). Although the translation quality they achieve is not better than Moses (Koehn et al., 2007), which is accepted to be the state-of-the-art, they show the feasibility of the approach. Serrano et al. (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests. Ueffing (2007) approaches the transductive learning problem for SMT by bootstrapping the training using the translations produced by the SMT system that have a scoring performance above some threshold as estimated by the SMT system itself. 282 Pr</context>
<context position="12507" citStr="Wang and Shawe-Taylor, 2008" startWordPosition="2095" endWordPosition="2098">mappers used are 3-spectrum counting word kernels, which consider all N-grams up to order 3 weighted by the number of tokens in the feature. We segment sentences using some of the punctuation for managing the feature set better and do not consider N-grams that cross segments. We use BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) evaluation metrics for measuring the performance of translations automatically. 4.2 Instance Selection Proper selection of training instances plays an important role to learn feature mappings with limited computational resources accurately. In previous work (Wang and Shawe-Taylor, 2008), sentence based training instances were selected using tf-idf retrieval. We transform test sentences to feature sets obtained by the kernel mapping before measuring their similarities and index the sentences based on the features. Given a source sentence of length 20, its feature representation would have a total of 57 uni/bi/tri-gram features. If we select closest sentences from the training set, we may not have translations for all the features in this representation. But if we search for translations of each feature, then we have a higher chance of covering all the features found in the se</context>
</contexts>
<marker>Wang, Shawe-Taylor, 2008</marker>
<rawString>Zhuoran Wang and John Shawe-Taylor. 2008. Kernel regression framework for machine translation: UCL system description for WMT 2008 shared translation task. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 155–158, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhuoran Wang</author>
<author>John Shawe-Taylor</author>
<author>Sandor Szedmak</author>
</authors>
<title>Kernel regression based machine translation.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers,</booktitle>
<pages>185--188</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="2843" citStr="Wang et al. (2007)" startWordPosition="435" endWordPosition="438"> sparsity. We show that L1 regularized regression mapping is effective in reranking translation outputs and present encouraging results on different language pairs in the translation task of WMT10. In the system combination task, different translation outputs of different translation systems are combined to find a better translation. We model system combination task as a reranking problem among the competing translation models and present encouraging results with the TRegMT system. Related Work: Regression techniques can be used to model the relationship between strings (Cortes et al., 2007). Wang et al. (2007) applies a string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to a small dataset. Later they use L2 regularized least squares regression (Wang and Shawe-Taylor, 2008). Although the translation quality they achieve is not better than Moses (Koehn et al., 2007), which is accepted to be the state-of-the-art, they show the feasibility of the approach. Serrano et al. (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests. Ueffi</context>
</contexts>
<marker>Wang, Shawe-Taylor, Szedmak, 2007</marker>
<rawString>Zhuoran Wang, John Shawe-Taylor, and Sandor Szedmak. 2007. Kernel regression based machine translation. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers, pages 185–188, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>