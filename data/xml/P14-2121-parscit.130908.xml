<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.266614">
<title confidence="0.961526">
Measuring metaphoricity
</title>
<author confidence="0.998135">
Jonathan Dunn
</author>
<affiliation confidence="0.999629">
Department of Computer Science / Illinois Institute of Technology
</affiliation>
<email confidence="0.990761">
jonathan.edwin.dunn@gmail.com
</email>
<sectionHeader confidence="0.993751" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999353">
This paper presents the first
computationally-derived scalar mea-
surement of metaphoricity. Each input
sentence is given a value between 0
and 1 which represents how metaphoric
that sentence is. This measure achieves
a correlation of 0.450 (Pearson’s R, p
&lt;0.01) with an experimental measure of
metaphoricity involving human partici-
pants. While far from perfect, this scalar
measure of metaphoricity allows different
thresholds for metaphoricity so that
metaphor identification can be fitted for
specific tasks and datasets. When reduced
to a binary classification evaluation using
the VU Amsterdam Metaphor Corpus,
the system achieves an F-Measure of
0.608, slightly lower than the comparable
binary classification system’s 0.638 and
competitive with existing approaches.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963396551724">
Metaphor is a cognitive phenomenon (Lakoff &amp;
Johnson, 1980, 1999) which has a significant im-
pact on human reasoning abilities (Casasanto &amp;
Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012)
and which, as a result, commonly appears in lan-
guage in the form of metaphoric expressions (e.g.,
Deignan, 2005). The most comprehensive non-
computational study of metaphoric expressions in
large corpora (Steen, et al., 2010) found that up
to 18.5% of words in the British National Cor-
pus were used metaphorically. This means that
metaphorically used words not only have very dif-
ferent interpretations than literally used words, but
they are also common enough to pose a significant
challenge for computational linguistics.
Starting with Wilks (1978), the problem of
metaphor has been approached as an identifica-
tion task: first identify or detect metaphoric ex-
pressions and then (1) prevent them from inter-
fering with computational treatments of literal ex-
pressions and (2) use them to gain additional in-
sight about a text (e.g., Carbonell, 1980; Neuman
&amp; Nave, 2009). The identification or detection
task has been approached as a binary classification
problem: for a given unit of language (e.g., word,
phrase, sentence) decide whether it is metaphoric
or non-metaphoric. Wilks (1978) used selectional
restrictions for this purpose; Mason (2004) used
hand-crafted knowledge resources to detect sim-
ilar selectional mismatches; another approach is
to detect selectional mismatches using statistically
created resources (e.g., Shutova, et al. 2013;
Shutova &amp; Sun, 2013). A second general approach
to the binary classification problem has been to use
mismatches in properties like abstractness (Gandy,
et al., 2013; Assaf, et al., 2013; Tsvetkov, et al.,
2013; Turney, et al., 2011), semantic similarity
(Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010),
and domain membership (Dunn, 2013a, 2013b) to
identify metaphoric units of language. A third ap-
proach has been to use forms of topic modelling
to identify linguistic units which represent both a
metaphoric topic and a literal topic (Strzalkowski,
2013; Bracewell, et al, 2013; Mohler, et al., 2013).
The single constant across all of these ap-
proaches is that the task is viewed as a binary clas-
sification problem of distinguishing metaphoric
language from non-metaphoric language. This
binary distinction assumes a clear boundary be-
tween the two; in other words, it assumes that
metaphoricity is a discrete property. However,
three strands of theoretical research show that
metaphoricity is not a discrete property. First,
psycholinguistic studies of metaphor processing
show that there is no difference between the pro-
cessing of metaphoric and non-metaphoric lan-
guage (Coulson &amp; Matlock, 2001; Gibbs, 2002;
Evans, 2010). The most plausible interpretation
</bodyText>
<page confidence="0.977183">
745
</page>
<bodyText confidence="0.989669571428571">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745–751,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
of this psycholinguistic evidence is that most lin-
guistic units fall somewhere between metaphoric
and literal, so that metaphoricity is a scalar value
which influences processing gradually (and is dif-
ficult to uncover because of related factors like
salience; Giora, 2002). Second, linguistic stud-
ies of metaphor have found that the metaphoric-
ity of a linguistic unit can be predicted given
certain factors (Dunn, 2011, 2013c). Third, the
high frequency of metaphorically used language
implies that it is hard to set a boundary beyond
which a word is used metaphorically. In other
words, it seems clear that 18.5% of the BNC is not
highly metaphoric, but rather is the sort of slightly
metaphoric language that speakers are not con-
sciously aware of because it is used so frequently.
This paper introduces a system for produc-
ing a scalar measurement of metaphoricity which
places sentences anywhere between 0 (literal) and
1 (highly metaphoric). The goal is to produce a
computationally derived measurement that mod-
els the gradient nature of metaphoricity, with the
result that metaphors which are clearly and con-
sciously seen as metaphors score closer to 1 and
metaphors which are not realized by speakers to
be metaphoric score further from 1. This scalar
measurement approach has two advantages: (1) it
adheres more closely to the current theoretical un-
derstanding of metaphor, thus being more cogni-
tively accurate; (2) it allows applications to control
the threshold of metaphoricity when identifying
metaphor, thus allowing the treatment of metaphor
to be optimized for a given task.
</bodyText>
<sectionHeader confidence="0.896642" genericHeader="method">
2 Measuring Gradient Metaphoricity
</sectionHeader>
<bodyText confidence="0.999602686567165">
An experiment was conducted to set a standard for
evaluating scalar measurements of metaphoricity.
A corpus of 60 sentences of varying metaphoric-
ity, drawn equally from four top-level domains
(PHYSICAL, MENTAL, SOCIAL, and ABSTRACT),
was created using the Corpus of Contemporary
American English. Each domain was represented
by five verbs and each verb by three sentences:
one literal, one slightly metaphoric, and one very
metaphoric (as judged by the author).
The selection of various domains, verbs, and
hypothesized metaphoricity levels helps to control
for other factors, like abstractness, which might be
only indirectly related to metaphoricity. It also en-
sures that the experiment covers a wide-range of
metaphors. It should be noted that the purpose
of the experiment is not to (1) test a three-way
distinction between metaphoricity levels (which is
simply used to ensure a representative selection
of metaphors) or (2) test the author’s intuitions
of metaphoricity. Rather, the purpose is to have
a representative selection of metaphors rated for
metaphoricity against which to test scalar mea-
surements of metaphoricity.
Three survey tasks were used. The first
tested speakers’ ability to consistently separate
metaphoric and non-metaphoric sentences. Partic-
ipants were given a sentence and asked to iden-
tify it as “Literal” or “Metaphoric.” The second
task tested speakers’ ability to consistently label
a given sentence as “Not Metaphoric”, “Slightly
Metaphoric”, and “Very Metaphoric.” The addi-
tional label was added in order to provide partic-
ipants with a middle ground between metaphoric
and literal. The third task tested speakers’ ability
to consistently rank three sentences according to
their metaphoricity. In order to ensure comparabil-
ity, each set of three sentences contained a literal, a
slightly metaphoric, and a very metaphoric use of
a single verb (e.g., three uses of “butcher”). The
purpose of this task was to allow participants to
directly compare different uses of the same verb.
The surveys were conducted using the Mechan-
icalTurk platform. Each participant took a particu-
lar survey only once and the sentences to be rated
were drawn randomly from the corpus. Partici-
pants were given eight questions for the identifica-
tion and labeling tasks and four questions for the
ranking task. This was done in order to keep the
survey short and prevent participants from losing
interest. All participants were asked if they had at-
tended a primary or elementary school conducted
in English in order to ensure consistent language
ability. Further, a test question was positioned part
way through the survey to ensure that participants
read the prompts correctly. Only answers valid ac-
cording to these two tests are considered in the fol-
lowing results. Each task had 100 unique partici-
pants who gave valid answers, for a total of 300
participants. Participants did not see any domain
information for the sentence prompts.
For the first task, the binary identification task,
the metaphoricity of a sentence was computed by
taking the percentage of participants who iden-
tified it as metaphoric. Thus, if all participants
agreed that a sentence was metaphoric, then it re-
ceives a 1, while if half of the participants agreed,
</bodyText>
<page confidence="0.990835">
746
</page>
<bodyText confidence="0.999708227272727">
then it receives a 0.5. The idea here is that high
metaphoricity is consciously available to partici-
pants, so that the more agreement there is about
metaphor the more the participants are aware of
the sentence’s metaphoricity and thus the higher
its metaphoricity value should be. The results of
this first experiment are summarized in Table 1
with the mean, standard deviation, and range of
the metaphoricity measurements. The results are
strong on the low end of the scale, with every
domain having sentences with either 0 values or
close to 0 values. The high end is more problem-
atic, with the highest values in each domain be-
ing below 0.9. This is a result of not having per-
fect agreement across all participants. However,
in spite of this, the measure makes a good distinc-
tion between utterances. For example, it assigns
the metaphoricity value of 0.833 to the sentence
in (1), but a metaphoricity value of only 0.153 to
the sentence in (2). This reflects a distinction in
metaphoricity, although the extreme top and bot-
tom of the scale are problematic.
</bodyText>
<listItem confidence="0.999165833333333">
(1) “A lady on high heels clacked along, the type
my mother says invests all of her brainpower in her
looks.”
(2) “The banks and the corporations in America
today have lots of money that they can invest right
now.”
</listItem>
<table confidence="0.988858666666667">
Domain Mean Std. Dev. Range
Abstract 0.373 0.282 0.065–0.833
Mental 0.289 0.278 0.000–0.888
Physical 0.417 0.331 0.000–0.846
Social 0.389 0.351 0.000–0.812
All 0.367 0.316 0.000–0.888
</table>
<tableCaption confidence="0.99973">
Table 1: Metaphoricity by identification.
</tableCaption>
<bodyText confidence="0.995439592592592">
The second experiment asks participants to
label metaphoricity, this time including a dis-
tinction between slightly metaphoric and highly
metaphoric sentences. The purpose of this is not
to test a three-way distinction in metaphoricity
values, but rather to improve the scale by mov-
ing intermediate sentences out of the Literal or
Metaphoric categories. The metaphoricity values
for this experiment were calculated in the same
way: the percentage of participants who rated a
sentence as highly metaphoric. Thus, this mea-
surement also is based on the idea that more
participants will be consciously aware of highly
metaphoric sentences, with a third category avail-
able to allow an extra distinction to be made. This
measurement, summarized in Table 2, is more ac-
curate at the lower end of the scale, with many
sentences receiving a 0 because participants were
able to choose a category other than metaphoric.
At the same time, the values tend to be further
from 1 at the upper end of the scale. The sentence
in (2) above, for example, received a 0; however,
the sentence in (1) above received only a 0.571,
which, while high given the range of values, is still
far from 1. Thus, while the measurement makes
distinctions at the top of the scale, it does not ap-
proach 1.
</bodyText>
<table confidence="0.999563833333333">
Domain Mean Std. Dev. Range
Abstract 0.170 0.165 0.000–0.571
Mental 0.096 0.119 0.000–0.455
Physical 0.220 0.248 0.000–0.778
Social 0.258 0.281 0.000–0.769
All 0.186 0.222 0.000–0.778
</table>
<tableCaption confidence="0.997633">
Table 2: Metaphoricity by labelling.
</tableCaption>
<bodyText confidence="0.999985482758621">
The third task gathered ordering information by
presenting participants with three sentences, all of
which contained the same main verb. The par-
ticipants were asked to order the sentences from
the least metaphoric to the most metaphoric. The
purpose of this experiment was to give partici-
pants context in the form of other uses of a given
verb against which to make their judgments. The
metaphoricity value was computed by taking the
percentage of participants who identified a sen-
tence as the most metaphoric of the three given
sentences. This measurement, shown in Table 3,
has similar averages across domains, unlike the
previous measurements. It tends to be better than
the previous measures on the upper bound, likely
because of the contextual comparison it allows.
However, because sentences with the same main
verb were forced into a three-way ordering, par-
ticipants could not, for example, label two of the
sentences as equally metaphoric. Thus, it is possi-
ble that some of this advantage on the upper bound
is a result of the task itself.
Given these three experiments for measuring
the metaphoricity of sentences, Table 4 shows the
correlations between each measure using Pear-
son’s R. Each correlation is significant at the 0.01
level (2-tailed). The highest correlation is between
the first and second tasks, at 0.819. The lowest
is between the first and third (which differ in the
</bodyText>
<page confidence="0.977692">
747
</page>
<table confidence="0.999767833333333">
Domain Mean Std. Dev. Range
Abstract 0.333 0.211 0.056–0.773
Mental 0.331 0.175 0.071–0.632
Physical 0.331 0.235 0.050–0.941
Social 0.327 0.280 0.050–0.783
All 0.331 0.227 0.050–0.941
</table>
<tableCaption confidence="0.996992">
Table 3: Metaphoricity by ordering.
</tableCaption>
<bodyText confidence="0.645572">
number of distinctions allowed) at 0.699. How-
ever, this is still a high correlation.
</bodyText>
<table confidence="0.99955825">
Task Identify Label Order
Identify – 0.819 0.699
Label 0.819 – 0.702
Order 0.699 0.702 –
</table>
<tableCaption confidence="0.999844">
Table 4: Correlation between measurements.
</tableCaption>
<bodyText confidence="0.999415545454546">
This section has put forward a robust series of
scalar measurements of metaphoricity. Each ex-
periment had 100 participants and operationalized
the task of rating metaphoricity in different ways
across a representative section of domains, verbs,
and metaphoricity levels. The resulting highly cor-
related measures show that we have a good stan-
dard of metaphoricity against which to evaluate
computational models which produce scalar mea-
surements of metaphoricity. The next section in-
troduces such a system.
</bodyText>
<sectionHeader confidence="0.917408" genericHeader="method">
3 Description of the System
</sectionHeader>
<bodyText confidence="0.999984785714286">
We approach the problem by starting with an exist-
ing binary identification system and converting it
to a scalar system. In principle any of the property-
based systems listed above could be converted in
this way. We have chosen to start with the do-
main interaction system (Dunn, 2013a, 2013b),
which performed competitively in an evaluation
with other systems (Dunn, 2013b). The original
system uses the properties of domain-membership
and event-status of concepts to identify metaphors
at the sentence-level using a logistic regression
classifier. The scalar version of the system will
have to evaluate the features in a different way.
The first step is to increase the robustness of the
system’s representation of sentences by adding ad-
ditional properties. We split the original system’s
domain membership feature into two: the domain
of a word’s referent and the domain of a word’s
sense. The idea is to capture cases like MINISTER,
in which a physical object (a human) is defined by
its social role (being a minister). The event-status
property is unchanged.
Several additional properties are added; these
properties were not used in the original system.
First, animacy-status allows a distinction to be
made between inanimate objects like rocks and
stones and animate or human objects. Second,
the fact-status property allows a distinction to be
made between objects which exist as such in-
dependently of humans (e.g., rocks and stones)
and those which exist to some degree dependent
on human consciousness (e.g., laws and ideas).
Third, the function-status property allows a dis-
tinction to be made between objects which en-
code a function (e.g., a screwdriver is specifically
an object meant to turn screws) and those which
do not encode a function (e.g., rocks are simply
objects). A finer distinction within the function-
status property distinguishes social functions (e.g.,
laws) from physical-use functions (e.g., screw-
drivers).
Following the original system, these properties
are taken from a knowledge-base and used to cre-
ate feature vectors. The text is first processed us-
ing Apache OpenNLP for tokenization, named en-
tity recognition, and part of speech tagging. Mor-
pha (Minnen, et al., 2001) is used for lemmati-
zation. At this point word sense disambiguation
is performed using SenseRelate (Pedersen &amp; Kol-
hatkar, 2009), mapping the lexical words to the
corresponding WordNet senses. These WordNet
senses are first mapped to SynSets and then to con-
cepts in the SUMO ontology, using existing map-
pings (Niles &amp; Pease, 2001, 2003).
Thus, each sentence is represented by the SUMO
concepts which it contains and each concept is
represented by its six concept properties. The fea-
tures used are computed as follows: First, the rela-
tive frequency of each value of each concept prop-
erty in the sentence is determined; Second, the
number of instances of the most common value for
each property is determined, as well as the number
of instances of all other values (both relativized to
the number of concepts present in the sentence).
Third, the number of types of values for each con-
cept property is determined, relative to the number
of possible types. This gives a total of 41 features
for each sentence.
These features were computed for each of
the sentences used in the experiments and then
</bodyText>
<page confidence="0.994846">
748
</page>
<bodyText confidence="0.9997568">
the correlation between the features and the
metaphoricity measurements were computed us-
ing Pearson’s R. Those features which had a sig-
nificant positive relationship with the experimen-
tal results, shown in Table 5, were added to-
gether to create a rough computational measure of
metaphoricity and then converted so that they fall
between 0 and 1. The resulting computationally-
derived measure correlates significantly with each
of the experiments: 0.450, 0.416, and 0.337.
</bodyText>
<table confidence="0.998860833333334">
Properties Values
Domain of the Referent Mental
Domain of the Referent Other / Concepts
Event-Status State
Animacy-Status Undetermined
Animacy-Status Other / Concepts
Fact-Status Physical
Function-Status None
Domain of the Referent Types / Possible
Event-Status Types / Possible
Animacy-Status Types / Possible
Function-Status (negative) Types / Possible
</table>
<tableCaption confidence="0.999308">
Table 5: Predictive features.
</tableCaption>
<sectionHeader confidence="0.984033" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.99958625">
A scalar measurement of metaphoricity allows
the threshold for metaphor in metaphor identifi-
cation tasks to be fitted for specific purposes and
datasets. The scalar system was evaluated on the
VU Amsterdam Metaphor Corpus (Steen, et al.,
2010) which consists of 200,000 words from the
British National Corpus divided into four gen-
res (academic, news, fiction, and spoken; per-
formance on the spoken genre was not evaluated
for this task because it consists of many short
fragmentary utterances) and manually annotated
for metaphor by five raters. Previous evaluations
using this corpus (Dunn, 2013b) concluded that
prepositions annotated as metaphoric in the cor-
pus should not be considered metaphoric for com-
putational purposes. Thus, metaphorically used
prepositions have been untagged as metaphoric.
Further, we have also untagged the ambiguously
metaphoric sentences. Sentences with an insuffi-
ciently robust conceptual representation were re-
moved (e.g., fragments). The evaluation dataset
thus consists of 6,893 sentences, distributed as
shown in Table 6.
For the purposes of this evaluation, the thresh-
</bodyText>
<table confidence="0.9996514">
Subset Literal Metaphor Total
Academic 759 1,550 2,309
Fiction 1,215 1,389 2,604
News 366 1,614 1,980
Total 2,340 4,553 6,893
</table>
<tableCaption confidence="0.999044">
Table 6: Size of evaluation dataset in sentences.
</tableCaption>
<bodyText confidence="0.998089615384615">
old for metaphor was set independently for each
genre and tied to the number of sentences con-
taining metaphorically used words, as rated by
the annotators of the corpus. Thus, for the num-
ber x of metaphors in the genre, the x sentences
with the top metaphoricity values were identified
as metaphoric. This illustrates the flexibility of
such a scalar approach to metaphor identification.
The baseline results are taken from a binary classi-
fication evaluation of the corpus using the full set
of 41 features produced by the system and eval-
uated using the logistic regression algorithm with
100-fold cross-validation.
</bodyText>
<table confidence="0.999692">
System Subset Prec. Recall F-Meas.
Scalar Acad. 0.578 0.686 0.578
Binary Acad. 0.649 0.682 0.623
Scalar News 0.712 0.822 0.712
Binary News 0.750 0.812 0.748
Scalar Fict. 0.554 0.582 0.554
Binary Fict. 0.632 0.633 0.630
Scalar All 0.608 0.703 0.608
Binary All 0.663 0.685 0.638
</table>
<tableCaption confidence="0.999728">
Table 7: Evaluation results.
</tableCaption>
<bodyText confidence="0.999631055555555">
The binary classification system, with access to
the full range of features, out-performs the scalar
measurement in most cases. It is important to note,
however, that the binary classification system re-
quires labelled training data and is restricted to a
single threshold of metaphoricity, in this case the
threshold embedded in the corpus by the raters.
The scalar system, however, was trained only on
the experimental data and was not influenced by
the evaluation corpus (except, of course, that it
had access to the number of metaphoric sentences
in the dataset, which is a parameter and not part
of the model itself). Further, it can be applied
to any English text without the need for labelled
training data. Thus, the scalar approach performs
competitively on a binary task (0.608 vs. 0.638
F-Measure) but can also produce scalar identifica-
tions, which binary systems cannot produce.
</bodyText>
<page confidence="0.997784">
749
</page>
<sectionHeader confidence="0.990314" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998218095238095">
Assaf, D., Neuman, Y., Cohen, Y., Argamon, S.,
Howard, N., Last, M., Koppel, M. 2013. Why “dark
thoughts” aren’t really dark: A novel algorithm for
metaphor identification. 2013 IEEE Symposium on
Computational Intelligence, Cognitive Algorithms,
Mind, and Brain: 60–65. Institute of Electrical and
Electronics Engineers.
Bracewell, D. B., Tomlinson, M. T., Mohler, M. 2013.
Determining the Conceptual Space of Metaphoric
Expressions. Proceedings of the 14th International
Conference on Computational Linguistics and Intel-
ligent Text Processing, Volume I: 487–500. Berlin,
Heidelberg: Springer-Verlag.
Carbonell, J. 1980. Metaphor - A Key to Extensible
Semantic Analysis. Proceedings of the 18th Meet-
ing of the Association for Computational Linguis-
tics: 17–21. Association for Computational Linguis-
tics.
Casasanto, D., Jasmin, K. 2012. The Hands of Time:
Temporal gestures in English speakers. Cognitive
Linguistics, 23(4): 643–674.
Coulson, S., Matlock, T. 2001. Metaphor and the
space structuring model. Metaphor &amp; Symbol,
16(3), 295-316.
Deignan, A. 2005. Metaphor and Corpus Linguistics.
Amsterdam: John Benjamins.
Dunn, J. 2011. Gradient Semantic Intuitions of
Metaphoric Expressions. Metaphor &amp; Symbol,
26(1), 53-67.
Dunn, J. 2013a. Evaluating the premises and results of
four metaphor identification systems. Proceedings
of the 14th International Conference on Computa-
tional Linguistics and Intelligent Text Processing,
Volume I: 471-486. Berlin, Heidelberg: Springer-
Verlag.
Dunn, J. 2013b. What metaphor identification systems
can tell us about metaphor-in-language. Proceed-
ings of the First Workshop on Metaphor in NLP: 1-
10. Association for Computational Linguistics.
Dunn, J. 2013c. How linguistic structure influences
and helps to predict metaphoric meaning. Cognitive
Linguistics, 24(1), 33-66.
Evans, V. 2010. Figurative language understanding in
LCCM Theory. Cognitive Linguistics, 21(4), 601-
662.
Gandy, L., Allan, N., Atallah, M., Frieder, O., Howard,
N., Kanareykin, S., Argamon, S. 2013. Automatic
Identification of Conceptual Metaphors With Lim-
ited Knowledge. Proceedings of the 27th Confer-
ence on Artificial Intelligence: 328–334. Associa-
tion for the Advancement of Artificial Intelligence.
Gibbs Jr., R. W. 2002. A new look at literal meaning in
understanding what is said and implicated. Journal
of Pragmatics, 34(4), 457-486.
Giora, R. 2002. Literal vs. figurative language: Dif-
ferent or equal? Journal of Pragmatics, 34(4), 487-
506.
Johansson Falck, M., Gibbs, Jr., R. W. 2012. Embod-
ied motivations for metaphorical meanings. Cogni-
tive Linguistics, 23(2): 251–272.
Lakoff, G., Johnson, M. 1980. Metaphors we live by.
Chicago: University Of Chicago Press.
Lakoff, G., Johnson, M. 1999. Philosophy in the
flesh: The embodied mind and its challenge to west-
ern thought. Chicago: University Of Chicago Press.
Li, L., Sporleder, C. 2010a. Linguistic Cues for Distin-
guishing Literal and Non-literal Usages. Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Posters: 683-691. Associa-
tion for Computational Linguistics.
Li, L., Sporleder, C. 2010b. Using Gaussian Mix-
ture Models to Detect Figurative Language in Con-
text. Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics: 297–
300. Association for Computational Linguistics.
Mason, Z. 2004. CorMet: A Computational, Corpus-
Based Conventional Metaphor Extraction System.
Computational Linguistics, 30(1), 23-44.
Minnen, G., Carroll, J., Pearce, D. 2001. Applied
morphological processing of English. Natural Lan-
guage Engineering, 7(3), 207-223.
Mohler, M., Bracewell, D., Tomlinson, M., Hinote,
D. 2013. Semantic Signatures for Example-Based
Linguistic Metaphor Detection. Proceedings of the
First Workshop on Metaphor in NLP: 27-35. Asso-
ciation for Computational Linguistics.
Neuman, Y., Nave, O. 2009. Metaphor-based meaning
excavation. Information Sciences, 179, 2719-2728.
Niles, I., Pease, A. 2001. Towards a standard upper
ontology. Proceedings of the International Confer-
ence on Formal Ontology in Information Systems:
2-9. Association for Computing Machinery.
Niles, I., Pease, A. 2003. Linking lexicons and on-
tologies: Mapping WordNet to the Suggested Upper
Merged Ontology. Proceedings of the 2003 Inter-
national Conference on Information and Knowledge
Engineering: 412-416. World Congress in Com-
puter Science, Computer Engineering, and Applied
Computing.
Pedersen, T., Kolhatkar, V. 2009. Word-
Net::SenseRelate::AllWords - A broad coverage
word sense tagger that maximimizes semantic re-
latedness. Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
</reference>
<page confidence="0.969837">
750
</page>
<reference confidence="0.999727114285714">
American Chapter of the Association for Computa-
tional Linguistics, Companion Volume: Demonstra-
tion Session: 17-20. Association for Computational
Linguistics.
Shutova, E., Sun, L. 2013. Unsupervised Metaphor
Identification using Hierarchical Graph Factoriza-
tion Clustering. Proceedings of Human Language
Technologies: The 2013 Annual Conference of the
North American Chapter of the Association for
Computational Linguistics: 978-988. Association
for Computational Linguistics.
Shutova, E., Teufel, S., Korhonen, A. 2013. Statis-
tical Metaphor Processing. Computational Linguis-
tics, 39(2), 301-353.
Steen, G. J., Dorst, A. G., Herrmann, J. B., Kaal, A. A.,
Krennmayr, T. 2010. Metaphor in usage. Cognitive
Linguistics, 21(4), 765-796.
Strzalkowski, T., Broadwell, G. A., Taylor, S., Feld-
man, L., Shaikh, S., Liu, T., Elliot, K. 2013. Robust
Extraction of Metaphor from Novel Data. Proceed-
ings of the First Workshop on Metaphor in NLP: 67-
76. Association for Computational Linguistics.
Tsvetkov, Y., Mukomel, E., Gershman, A. 2013.
Cross-Lingual Metaphor Detection Using Common
Semantic Features. Proceedings of the First Work-
shop on Metaphor in NLP: 45-51. Association for
Computational Linguistics.
Turney, P. D., Neuman, Y., Assaf, D., Cohen, Y.
2011. Literal and Metaphorical Sense Identifica-
tion Through Concrete and Abstract Context. Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing: 680-690. Associ-
ation for Computational Linguistics.
Wilks, Y. 1978. Making preferences more active. Ar-
tificialIntelligence, 11(3), 197-223.
</reference>
<page confidence="0.998291">
751
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981407">
<title confidence="0.999883">Measuring metaphoricity</title>
<author confidence="0.999994">Jonathan Dunn</author>
<affiliation confidence="0.997221">Department of Computer Science / Illinois Institute of</affiliation>
<email confidence="0.998786">jonathan.edwin.dunn@gmail.com</email>
<abstract confidence="0.999270095238095">This paper presents the first computationally-derived scalar measurement of metaphoricity. Each input sentence is given a value between 0 and 1 which represents how metaphoric that sentence is. This measure achieves a correlation of 0.450 (Pearson’s R, p with an experimental measure of metaphoricity involving human participants. While far from perfect, this scalar measure of metaphoricity allows different thresholds for metaphoricity so that metaphor identification can be fitted for specific tasks and datasets. When reduced to a binary classification evaluation using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Assaf</author>
<author>Y Neuman</author>
<author>Y Cohen</author>
<author>S Argamon</author>
<author>N Howard</author>
<author>M Last</author>
<author>M Koppel</author>
</authors>
<title>Why “dark thoughts” aren’t really dark: A novel algorithm for metaphor identification.</title>
<date>2013</date>
<booktitle>IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain: 60–65. Institute of Electrical and Electronics Engineers.</booktitle>
<contexts>
<context position="2645" citStr="Assaf, et al., 2013" startWordPosition="387" endWordPosition="390">n approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This</context>
</contexts>
<marker>Assaf, Neuman, Cohen, Argamon, Howard, Last, Koppel, 2013</marker>
<rawString>Assaf, D., Neuman, Y., Cohen, Y., Argamon, S., Howard, N., Last, M., Koppel, M. 2013. Why “dark thoughts” aren’t really dark: A novel algorithm for metaphor identification. 2013 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain: 60–65. Institute of Electrical and Electronics Engineers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Bracewell</author>
<author>M T Tomlinson</author>
<author>M Mohler</author>
</authors>
<title>Determining the Conceptual Space of Metaphoric Expressions.</title>
<date>2013</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, Volume I:</booktitle>
<pages>487--500</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg:</location>
<contexts>
<context position="3035" citStr="Bracewell, et al, 2013" startWordPosition="449" endWordPosition="452">created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three strands of theoretical research show that metaphoricity is not a discrete property. First, psycholinguistic studies of metaphor processing show that there is no difference between the processing of metaphoric and non-metaphoric language (Couls</context>
</contexts>
<marker>Bracewell, Tomlinson, Mohler, 2013</marker>
<rawString>Bracewell, D. B., Tomlinson, M. T., Mohler, M. 2013. Determining the Conceptual Space of Metaphoric Expressions. Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, Volume I: 487–500. Berlin, Heidelberg: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carbonell</author>
</authors>
<title>Metaphor - A Key to Extensible Semantic Analysis.</title>
<date>1980</date>
<booktitle>Proceedings of the 18th Meeting of the Association for Computational Linguistics: 17–21. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1958" citStr="Carbonell, 1980" startWordPosition="289" endWordPosition="290"> that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to u</context>
</contexts>
<marker>Carbonell, 1980</marker>
<rawString>Carbonell, J. 1980. Metaphor - A Key to Extensible Semantic Analysis. Proceedings of the 18th Meeting of the Association for Computational Linguistics: 17–21. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Casasanto</author>
<author>K Jasmin</author>
</authors>
<title>The Hands of Time: Temporal gestures in English speakers.</title>
<date>2012</date>
<journal>Cognitive Linguistics,</journal>
<volume>23</volume>
<issue>4</issue>
<pages>643--674</pages>
<contexts>
<context position="1081" citStr="Casasanto &amp; Jasmin, 2012" startWordPosition="147" endWordPosition="150">ing human participants. While far from perfect, this scalar measure of metaphoricity allows different thresholds for metaphoricity so that metaphor identification can be fitted for specific tasks and datasets. When reduced to a binary classification evaluation using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches. 1 Introduction Metaphor is a cognitive phenomenon (Lakoff &amp; Johnson, 1980, 1999) which has a significant impact on human reasoning abilities (Casasanto &amp; Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g., Deignan, 2005). The most comprehensive noncomputational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of me</context>
</contexts>
<marker>Casasanto, Jasmin, 2012</marker>
<rawString>Casasanto, D., Jasmin, K. 2012. The Hands of Time: Temporal gestures in English speakers. Cognitive Linguistics, 23(4): 643–674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Coulson</author>
<author>T Matlock</author>
</authors>
<title>Metaphor and the space structuring model.</title>
<date>2001</date>
<journal>Metaphor &amp; Symbol,</journal>
<volume>16</volume>
<issue>3</issue>
<pages>295--316</pages>
<contexts>
<context position="3653" citStr="Coulson &amp; Matlock, 2001" startWordPosition="543" endWordPosition="546"> 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three strands of theoretical research show that metaphoricity is not a discrete property. First, psycholinguistic studies of metaphor processing show that there is no difference between the processing of metaphoric and non-metaphoric language (Coulson &amp; Matlock, 2001; Gibbs, 2002; Evans, 2010). The most plausible interpretation 745 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745–751, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics of this psycholinguistic evidence is that most linguistic units fall somewhere between metaphoric and literal, so that metaphoricity is a scalar value which influences processing gradually (and is difficult to uncover because of related factors like salience; Giora, 2002). Second, linguistic studies of metaphor have foun</context>
</contexts>
<marker>Coulson, Matlock, 2001</marker>
<rawString>Coulson, S., Matlock, T. 2001. Metaphor and the space structuring model. Metaphor &amp; Symbol, 16(3), 295-316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Deignan</author>
</authors>
<title>Metaphor and Corpus Linguistics.</title>
<date>2005</date>
<location>Amsterdam: John Benjamins.</location>
<contexts>
<context position="1225" citStr="Deignan, 2005" startWordPosition="173" endWordPosition="174">fication can be fitted for specific tasks and datasets. When reduced to a binary classification evaluation using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches. 1 Introduction Metaphor is a cognitive phenomenon (Lakoff &amp; Johnson, 1980, 1999) which has a significant impact on human reasoning abilities (Casasanto &amp; Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g., Deignan, 2005). The most comprehensive noncomputational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering</context>
</contexts>
<marker>Deignan, 2005</marker>
<rawString>Deignan, A. 2005. Metaphor and Corpus Linguistics. Amsterdam: John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dunn</author>
</authors>
<title>Gradient Semantic Intuitions of Metaphoric Expressions.</title>
<date>2011</date>
<journal>Metaphor &amp; Symbol,</journal>
<volume>26</volume>
<issue>1</issue>
<pages>53--67</pages>
<contexts>
<context position="4349" citStr="Dunn, 2011" startWordPosition="646" endWordPosition="647">52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745–751, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics of this psycholinguistic evidence is that most linguistic units fall somewhere between metaphoric and literal, so that metaphoricity is a scalar value which influences processing gradually (and is difficult to uncover because of related factors like salience; Giora, 2002). Second, linguistic studies of metaphor have found that the metaphoricity of a linguistic unit can be predicted given certain factors (Dunn, 2011, 2013c). Third, the high frequency of metaphorically used language implies that it is hard to set a boundary beyond which a word is used metaphorically. In other words, it seems clear that 18.5% of the BNC is not highly metaphoric, but rather is the sort of slightly metaphoric language that speakers are not consciously aware of because it is used so frequently. This paper introduces a system for producing a scalar measurement of metaphoricity which places sentences anywhere between 0 (literal) and 1 (highly metaphoric). The goal is to produce a computationally derived measurement that models </context>
</contexts>
<marker>Dunn, 2011</marker>
<rawString>Dunn, J. 2011. Gradient Semantic Intuitions of Metaphoric Expressions. Metaphor &amp; Symbol, 26(1), 53-67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dunn</author>
</authors>
<title>Evaluating the premises and results of four metaphor identification systems.</title>
<date>2013</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, Volume I:</booktitle>
<pages>471--486</pages>
<publisher>SpringerVerlag.</publisher>
<location>Berlin, Heidelberg:</location>
<contexts>
<context position="2793" citStr="Dunn, 2013" startWordPosition="412" endWordPosition="413">c. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three s</context>
<context position="14437" citStr="Dunn, 2013" startWordPosition="2273" endWordPosition="2274">epresentative section of domains, verbs, and metaphoricity levels. The resulting highly correlated measures show that we have a good standard of metaphoricity against which to evaluate computational models which produce scalar measurements of metaphoricity. The next section introduces such a system. 3 Description of the System We approach the problem by starting with an existing binary identification system and converting it to a scalar system. In principle any of the propertybased systems listed above could be converted in this way. We have chosen to start with the domain interaction system (Dunn, 2013a, 2013b), which performed competitively in an evaluation with other systems (Dunn, 2013b). The original system uses the properties of domain-membership and event-status of concepts to identify metaphors at the sentence-level using a logistic regression classifier. The scalar version of the system will have to evaluate the features in a different way. The first step is to increase the robustness of the system’s representation of sentences by adding additional properties. We split the original system’s domain membership feature into two: the domain of a word’s referent and the domain of a word’</context>
<context position="18918" citStr="Dunn, 2013" startWordPosition="2977" endWordPosition="2978"> 4 Evaluation A scalar measurement of metaphoricity allows the threshold for metaphor in metaphor identification tasks to be fitted for specific purposes and datasets. The scalar system was evaluated on the VU Amsterdam Metaphor Corpus (Steen, et al., 2010) which consists of 200,000 words from the British National Corpus divided into four genres (academic, news, fiction, and spoken; performance on the spoken genre was not evaluated for this task because it consists of many short fragmentary utterances) and manually annotated for metaphor by five raters. Previous evaluations using this corpus (Dunn, 2013b) concluded that prepositions annotated as metaphoric in the corpus should not be considered metaphoric for computational purposes. Thus, metaphorically used prepositions have been untagged as metaphoric. Further, we have also untagged the ambiguously metaphoric sentences. Sentences with an insufficiently robust conceptual representation were removed (e.g., fragments). The evaluation dataset thus consists of 6,893 sentences, distributed as shown in Table 6. For the purposes of this evaluation, the threshSubset Literal Metaphor Total Academic 759 1,550 2,309 Fiction 1,215 1,389 2,604 News 366 </context>
</contexts>
<marker>Dunn, 2013</marker>
<rawString>Dunn, J. 2013a. Evaluating the premises and results of four metaphor identification systems. Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, Volume I: 471-486. Berlin, Heidelberg: SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dunn</author>
</authors>
<title>What metaphor identification systems can tell us about metaphor-in-language.</title>
<date>2013</date>
<booktitle>Proceedings of the First Workshop on Metaphor in NLP:</booktitle>
<pages>1--10</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2793" citStr="Dunn, 2013" startWordPosition="412" endWordPosition="413">c. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three s</context>
<context position="14437" citStr="Dunn, 2013" startWordPosition="2273" endWordPosition="2274">epresentative section of domains, verbs, and metaphoricity levels. The resulting highly correlated measures show that we have a good standard of metaphoricity against which to evaluate computational models which produce scalar measurements of metaphoricity. The next section introduces such a system. 3 Description of the System We approach the problem by starting with an existing binary identification system and converting it to a scalar system. In principle any of the propertybased systems listed above could be converted in this way. We have chosen to start with the domain interaction system (Dunn, 2013a, 2013b), which performed competitively in an evaluation with other systems (Dunn, 2013b). The original system uses the properties of domain-membership and event-status of concepts to identify metaphors at the sentence-level using a logistic regression classifier. The scalar version of the system will have to evaluate the features in a different way. The first step is to increase the robustness of the system’s representation of sentences by adding additional properties. We split the original system’s domain membership feature into two: the domain of a word’s referent and the domain of a word’</context>
<context position="18918" citStr="Dunn, 2013" startWordPosition="2977" endWordPosition="2978"> 4 Evaluation A scalar measurement of metaphoricity allows the threshold for metaphor in metaphor identification tasks to be fitted for specific purposes and datasets. The scalar system was evaluated on the VU Amsterdam Metaphor Corpus (Steen, et al., 2010) which consists of 200,000 words from the British National Corpus divided into four genres (academic, news, fiction, and spoken; performance on the spoken genre was not evaluated for this task because it consists of many short fragmentary utterances) and manually annotated for metaphor by five raters. Previous evaluations using this corpus (Dunn, 2013b) concluded that prepositions annotated as metaphoric in the corpus should not be considered metaphoric for computational purposes. Thus, metaphorically used prepositions have been untagged as metaphoric. Further, we have also untagged the ambiguously metaphoric sentences. Sentences with an insufficiently robust conceptual representation were removed (e.g., fragments). The evaluation dataset thus consists of 6,893 sentences, distributed as shown in Table 6. For the purposes of this evaluation, the threshSubset Literal Metaphor Total Academic 759 1,550 2,309 Fiction 1,215 1,389 2,604 News 366 </context>
</contexts>
<marker>Dunn, 2013</marker>
<rawString>Dunn, J. 2013b. What metaphor identification systems can tell us about metaphor-in-language. Proceedings of the First Workshop on Metaphor in NLP: 1-10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dunn</author>
</authors>
<title>How linguistic structure influences and helps to predict metaphoric meaning.</title>
<date>2013</date>
<journal>Cognitive Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>33--66</pages>
<contexts>
<context position="2793" citStr="Dunn, 2013" startWordPosition="412" endWordPosition="413">c. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three s</context>
<context position="14437" citStr="Dunn, 2013" startWordPosition="2273" endWordPosition="2274">epresentative section of domains, verbs, and metaphoricity levels. The resulting highly correlated measures show that we have a good standard of metaphoricity against which to evaluate computational models which produce scalar measurements of metaphoricity. The next section introduces such a system. 3 Description of the System We approach the problem by starting with an existing binary identification system and converting it to a scalar system. In principle any of the propertybased systems listed above could be converted in this way. We have chosen to start with the domain interaction system (Dunn, 2013a, 2013b), which performed competitively in an evaluation with other systems (Dunn, 2013b). The original system uses the properties of domain-membership and event-status of concepts to identify metaphors at the sentence-level using a logistic regression classifier. The scalar version of the system will have to evaluate the features in a different way. The first step is to increase the robustness of the system’s representation of sentences by adding additional properties. We split the original system’s domain membership feature into two: the domain of a word’s referent and the domain of a word’</context>
<context position="18918" citStr="Dunn, 2013" startWordPosition="2977" endWordPosition="2978"> 4 Evaluation A scalar measurement of metaphoricity allows the threshold for metaphor in metaphor identification tasks to be fitted for specific purposes and datasets. The scalar system was evaluated on the VU Amsterdam Metaphor Corpus (Steen, et al., 2010) which consists of 200,000 words from the British National Corpus divided into four genres (academic, news, fiction, and spoken; performance on the spoken genre was not evaluated for this task because it consists of many short fragmentary utterances) and manually annotated for metaphor by five raters. Previous evaluations using this corpus (Dunn, 2013b) concluded that prepositions annotated as metaphoric in the corpus should not be considered metaphoric for computational purposes. Thus, metaphorically used prepositions have been untagged as metaphoric. Further, we have also untagged the ambiguously metaphoric sentences. Sentences with an insufficiently robust conceptual representation were removed (e.g., fragments). The evaluation dataset thus consists of 6,893 sentences, distributed as shown in Table 6. For the purposes of this evaluation, the threshSubset Literal Metaphor Total Academic 759 1,550 2,309 Fiction 1,215 1,389 2,604 News 366 </context>
</contexts>
<marker>Dunn, 2013</marker>
<rawString>Dunn, J. 2013c. How linguistic structure influences and helps to predict metaphoric meaning. Cognitive Linguistics, 24(1), 33-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Evans</author>
</authors>
<title>Figurative language understanding in LCCM Theory.</title>
<date>2010</date>
<journal>Cognitive Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>601--662</pages>
<contexts>
<context position="3680" citStr="Evans, 2010" startWordPosition="549" endWordPosition="550">le constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three strands of theoretical research show that metaphoricity is not a discrete property. First, psycholinguistic studies of metaphor processing show that there is no difference between the processing of metaphoric and non-metaphoric language (Coulson &amp; Matlock, 2001; Gibbs, 2002; Evans, 2010). The most plausible interpretation 745 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745–751, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics of this psycholinguistic evidence is that most linguistic units fall somewhere between metaphoric and literal, so that metaphoricity is a scalar value which influences processing gradually (and is difficult to uncover because of related factors like salience; Giora, 2002). Second, linguistic studies of metaphor have found that the metaphoricity of</context>
</contexts>
<marker>Evans, 2010</marker>
<rawString>Evans, V. 2010. Figurative language understanding in LCCM Theory. Cognitive Linguistics, 21(4), 601-662.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Gandy</author>
<author>N Allan</author>
<author>M Atallah</author>
<author>O Frieder</author>
<author>N Howard</author>
<author>S Kanareykin</author>
<author>S Argamon</author>
</authors>
<title>Automatic Identification of Conceptual Metaphors With Limited Knowledge.</title>
<date>2013</date>
<booktitle>Proceedings of the 27th Conference on Artificial Intelligence: 328–334. Association for the Advancement of Artificial Intelligence.</booktitle>
<contexts>
<context position="2624" citStr="Gandy, et al., 2013" startWordPosition="383" endWordPosition="386">etection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-meta</context>
</contexts>
<marker>Gandy, Allan, Atallah, Frieder, Howard, Kanareykin, Argamon, 2013</marker>
<rawString>Gandy, L., Allan, N., Atallah, M., Frieder, O., Howard, N., Kanareykin, S., Argamon, S. 2013. Automatic Identification of Conceptual Metaphors With Limited Knowledge. Proceedings of the 27th Conference on Artificial Intelligence: 328–334. Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gibbs Jr</author>
<author>R W</author>
</authors>
<title>A new look at literal meaning in understanding what is said and implicated.</title>
<date>2002</date>
<journal>Journal of Pragmatics,</journal>
<volume>34</volume>
<issue>4</issue>
<pages>457--486</pages>
<marker>Jr, W, 2002</marker>
<rawString>Gibbs Jr., R. W. 2002. A new look at literal meaning in understanding what is said and implicated. Journal of Pragmatics, 34(4), 457-486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Giora</author>
</authors>
<title>Literal vs. figurative language: Different or equal?</title>
<date>2002</date>
<journal>Journal of Pragmatics,</journal>
<volume>34</volume>
<issue>4</issue>
<pages>487--506</pages>
<contexts>
<context position="4203" citStr="Giora, 2002" startWordPosition="622" endWordPosition="623">etaphoric and non-metaphoric language (Coulson &amp; Matlock, 2001; Gibbs, 2002; Evans, 2010). The most plausible interpretation 745 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745–751, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics of this psycholinguistic evidence is that most linguistic units fall somewhere between metaphoric and literal, so that metaphoricity is a scalar value which influences processing gradually (and is difficult to uncover because of related factors like salience; Giora, 2002). Second, linguistic studies of metaphor have found that the metaphoricity of a linguistic unit can be predicted given certain factors (Dunn, 2011, 2013c). Third, the high frequency of metaphorically used language implies that it is hard to set a boundary beyond which a word is used metaphorically. In other words, it seems clear that 18.5% of the BNC is not highly metaphoric, but rather is the sort of slightly metaphoric language that speakers are not consciously aware of because it is used so frequently. This paper introduces a system for producing a scalar measurement of metaphoricity which </context>
</contexts>
<marker>Giora, 2002</marker>
<rawString>Giora, R. 2002. Literal vs. figurative language: Different or equal? Journal of Pragmatics, 34(4), 487-506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johansson Falck</author>
<author>M Gibbs</author>
<author>R W</author>
</authors>
<title>Embodied motivations for metaphorical meanings.</title>
<date>2012</date>
<journal>Cognitive Linguistics,</journal>
<volume>23</volume>
<issue>2</issue>
<pages>251--272</pages>
<marker>Falck, Gibbs, W, 2012</marker>
<rawString>Johansson Falck, M., Gibbs, Jr., R. W. 2012. Embodied motivations for metaphorical meanings. Cognitive Linguistics, 23(2): 251–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>M Johnson</author>
</authors>
<title>Metaphors we live by.</title>
<date>1980</date>
<publisher>Chicago: University Of Chicago Press.</publisher>
<contexts>
<context position="988" citStr="Lakoff &amp; Johnson, 1980" startWordPosition="132" endWordPosition="135">lation of 0.450 (Pearson’s R, p &lt;0.01) with an experimental measure of metaphoricity involving human participants. While far from perfect, this scalar measure of metaphoricity allows different thresholds for metaphoricity so that metaphor identification can be fitted for specific tasks and datasets. When reduced to a binary classification evaluation using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches. 1 Introduction Metaphor is a cognitive phenomenon (Lakoff &amp; Johnson, 1980, 1999) which has a significant impact on human reasoning abilities (Casasanto &amp; Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g., Deignan, 2005). The most comprehensive noncomputational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a signi</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>Lakoff, G., Johnson, M. 1980. Metaphors we live by. Chicago: University Of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>M Johnson</author>
</authors>
<title>Philosophy in the flesh: The embodied mind and its challenge to western thought.</title>
<date>1999</date>
<publisher>University Of Chicago Press.</publisher>
<location>Chicago:</location>
<marker>Lakoff, Johnson, 1999</marker>
<rawString>Lakoff, G., Johnson, M. 1999. Philosophy in the flesh: The embodied mind and its challenge to western thought. Chicago: University Of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Li</author>
<author>C Sporleder</author>
</authors>
<title>Linguistic Cues for Distinguishing Literal and Non-literal Usages.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics: Posters:</booktitle>
<pages>683--691</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2735" citStr="Li &amp; Sporleder, 2010" startWordPosition="401" endWordPosition="404">, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes t</context>
</contexts>
<marker>Li, Sporleder, 2010</marker>
<rawString>Li, L., Sporleder, C. 2010a. Linguistic Cues for Distinguishing Literal and Non-literal Usages. Proceedings of the 23rd International Conference on Computational Linguistics: Posters: 683-691. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Li</author>
<author>C Sporleder</author>
</authors>
<title>Using Gaussian Mixture Models to Detect Figurative Language in Context. Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics: 297– 300. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2735" citStr="Li &amp; Sporleder, 2010" startWordPosition="401" endWordPosition="404">, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes t</context>
</contexts>
<marker>Li, Sporleder, 2010</marker>
<rawString>Li, L., Sporleder, C. 2010b. Using Gaussian Mixture Models to Detect Figurative Language in Context. Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics: 297– 300. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Mason</author>
</authors>
<title>CorMet: A Computational, CorpusBased Conventional Metaphor Extraction System.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<pages>23--44</pages>
<contexts>
<context position="2259" citStr="Mason (2004)" startWordPosition="333" endWordPosition="334">th Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approa</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Mason, Z. 2004. CorMet: A Computational, CorpusBased Conventional Metaphor Extraction System. Computational Linguistics, 30(1), 23-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Minnen</author>
<author>J Carroll</author>
<author>D Pearce</author>
</authors>
<title>Applied morphological processing of English.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>207--223</pages>
<contexts>
<context position="16356" citStr="Minnen, et al., 2001" startWordPosition="2571" endWordPosition="2574">istinction to be made between objects which encode a function (e.g., a screwdriver is specifically an object meant to turn screws) and those which do not encode a function (e.g., rocks are simply objects). A finer distinction within the functionstatus property distinguishes social functions (e.g., laws) from physical-use functions (e.g., screwdrivers). Following the original system, these properties are taken from a knowledge-base and used to create feature vectors. The text is first processed using Apache OpenNLP for tokenization, named entity recognition, and part of speech tagging. Morpha (Minnen, et al., 2001) is used for lemmatization. At this point word sense disambiguation is performed using SenseRelate (Pedersen &amp; Kolhatkar, 2009), mapping the lexical words to the corresponding WordNet senses. These WordNet senses are first mapped to SynSets and then to concepts in the SUMO ontology, using existing mappings (Niles &amp; Pease, 2001, 2003). Thus, each sentence is represented by the SUMO concepts which it contains and each concept is represented by its six concept properties. The features used are computed as follows: First, the relative frequency of each value of each concept property in the sentenc</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Minnen, G., Carroll, J., Pearce, D. 2001. Applied morphological processing of English. Natural Language Engineering, 7(3), 207-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohler</author>
<author>D Bracewell</author>
<author>M Tomlinson</author>
<author>D Hinote</author>
</authors>
<title>Semantic Signatures for Example-Based Linguistic Metaphor Detection.</title>
<date>2013</date>
<booktitle>Proceedings of the First Workshop on Metaphor in NLP:</booktitle>
<pages>27--35</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="3058" citStr="Mohler, et al., 2013" startWordPosition="453" endWordPosition="456"> Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary between the two; in other words, it assumes that metaphoricity is a discrete property. However, three strands of theoretical research show that metaphoricity is not a discrete property. First, psycholinguistic studies of metaphor processing show that there is no difference between the processing of metaphoric and non-metaphoric language (Coulson &amp; Matlock, 2001; Gib</context>
</contexts>
<marker>Mohler, Bracewell, Tomlinson, Hinote, 2013</marker>
<rawString>Mohler, M., Bracewell, D., Tomlinson, M., Hinote, D. 2013. Semantic Signatures for Example-Based Linguistic Metaphor Detection. Proceedings of the First Workshop on Metaphor in NLP: 27-35. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Neuman</author>
<author>O Nave</author>
</authors>
<title>Metaphor-based meaning excavation.</title>
<date>2009</date>
<journal>Information Sciences,</journal>
<volume>179</volume>
<pages>2719--2728</pages>
<contexts>
<context position="1980" citStr="Neuman &amp; Nave, 2009" startWordPosition="291" endWordPosition="294"> of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in prope</context>
</contexts>
<marker>Neuman, Nave, 2009</marker>
<rawString>Neuman, Y., Nave, O. 2009. Metaphor-based meaning excavation. Information Sciences, 179, 2719-2728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Towards a standard upper ontology.</title>
<date>2001</date>
<booktitle>Proceedings of the International Conference on Formal Ontology in Information Systems:</booktitle>
<pages>2--9</pages>
<publisher>Association for Computing Machinery.</publisher>
<contexts>
<context position="16684" citStr="Niles &amp; Pease, 2001" startWordPosition="2625" endWordPosition="2628">ns (e.g., screwdrivers). Following the original system, these properties are taken from a knowledge-base and used to create feature vectors. The text is first processed using Apache OpenNLP for tokenization, named entity recognition, and part of speech tagging. Morpha (Minnen, et al., 2001) is used for lemmatization. At this point word sense disambiguation is performed using SenseRelate (Pedersen &amp; Kolhatkar, 2009), mapping the lexical words to the corresponding WordNet senses. These WordNet senses are first mapped to SynSets and then to concepts in the SUMO ontology, using existing mappings (Niles &amp; Pease, 2001, 2003). Thus, each sentence is represented by the SUMO concepts which it contains and each concept is represented by its six concept properties. The features used are computed as follows: First, the relative frequency of each value of each concept property in the sentence is determined; Second, the number of instances of the most common value for each property is determined, as well as the number of instances of all other values (both relativized to the number of concepts present in the sentence). Third, the number of types of values for each concept property is determined, relative to the nu</context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>Niles, I., Pease, A. 2001. Towards a standard upper ontology. Proceedings of the International Conference on Formal Ontology in Information Systems: 2-9. Association for Computing Machinery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Linking lexicons and ontologies: Mapping WordNet to the Suggested Upper Merged Ontology.</title>
<date>2003</date>
<journal>World Congress in Computer Science, Computer Engineering, and Applied Computing.</journal>
<booktitle>Proceedings of the 2003 International Conference on Information and Knowledge Engineering:</booktitle>
<pages>412--416</pages>
<marker>Niles, Pease, 2003</marker>
<rawString>Niles, I., Pease, A. 2003. Linking lexicons and ontologies: Mapping WordNet to the Suggested Upper Merged Ontology. Proceedings of the 2003 International Conference on Information and Knowledge Engineering: 412-416. World Congress in Computer Science, Computer Engineering, and Applied Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>V Kolhatkar</author>
</authors>
<title>WordNet::SenseRelate::AllWords - A broad coverage word sense tagger that maximimizes semantic relatedness.</title>
<date>2009</date>
<booktitle>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North</booktitle>
<contexts>
<context position="16483" citStr="Pedersen &amp; Kolhatkar, 2009" startWordPosition="2590" endWordPosition="2594">n screws) and those which do not encode a function (e.g., rocks are simply objects). A finer distinction within the functionstatus property distinguishes social functions (e.g., laws) from physical-use functions (e.g., screwdrivers). Following the original system, these properties are taken from a knowledge-base and used to create feature vectors. The text is first processed using Apache OpenNLP for tokenization, named entity recognition, and part of speech tagging. Morpha (Minnen, et al., 2001) is used for lemmatization. At this point word sense disambiguation is performed using SenseRelate (Pedersen &amp; Kolhatkar, 2009), mapping the lexical words to the corresponding WordNet senses. These WordNet senses are first mapped to SynSets and then to concepts in the SUMO ontology, using existing mappings (Niles &amp; Pease, 2001, 2003). Thus, each sentence is represented by the SUMO concepts which it contains and each concept is represented by its six concept properties. The features used are computed as follows: First, the relative frequency of each value of each concept property in the sentence is determined; Second, the number of instances of the most common value for each property is determined, as well as the numbe</context>
</contexts>
<marker>Pedersen, Kolhatkar, 2009</marker>
<rawString>Pedersen, T., Kolhatkar, V. 2009. WordNet::SenseRelate::AllWords - A broad coverage word sense tagger that maximimizes semantic relatedness. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North</rawString>
</citation>
<citation valid="false">
<title>American Chapter of the Association for Computational Linguistics, Companion Volume: Demonstration Session: 17-20. Association for Computational Linguistics.</title>
<marker></marker>
<rawString>American Chapter of the Association for Computational Linguistics, Companion Volume: Demonstration Session: 17-20. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
<author>L Sun</author>
</authors>
<title>Unsupervised Metaphor Identification using Hierarchical Graph Factorization Clustering.</title>
<date>2013</date>
<booktitle>Proceedings of Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics:</booktitle>
<pages>978--988</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2480" citStr="Shutova &amp; Sun, 2013" startWordPosition="361" endWordPosition="364">iteral expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant </context>
</contexts>
<marker>Shutova, Sun, 2013</marker>
<rawString>Shutova, E., Sun, L. 2013. Unsupervised Metaphor Identification using Hierarchical Graph Factorization Clustering. Proceedings of Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics: 978-988. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
<author>S Teufel</author>
<author>A Korhonen</author>
</authors>
<date>2013</date>
<booktitle>Statistical Metaphor Processing. Computational Linguistics,</booktitle>
<volume>39</volume>
<issue>2</issue>
<pages>301--353</pages>
<contexts>
<context position="2458" citStr="Shutova, et al. 2013" startWordPosition="357" endWordPosition="360">tional treatments of literal expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013)</context>
</contexts>
<marker>Shutova, Teufel, Korhonen, 2013</marker>
<rawString>Shutova, E., Teufel, S., Korhonen, A. 2013. Statistical Metaphor Processing. Computational Linguistics, 39(2), 301-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Steen</author>
<author>A G Dorst</author>
<author>J B Herrmann</author>
<author>A A Kaal</author>
<author>T Krennmayr</author>
</authors>
<title>Metaphor in usage.</title>
<date>2010</date>
<journal>Cognitive Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>765--796</pages>
<contexts>
<context position="1337" citStr="Steen, et al., 2010" startWordPosition="187" endWordPosition="190"> using the VU Amsterdam Metaphor Corpus, the system achieves an F-Measure of 0.608, slightly lower than the comparable binary classification system’s 0.638 and competitive with existing approaches. 1 Introduction Metaphor is a cognitive phenomenon (Lakoff &amp; Johnson, 1980, 1999) which has a significant impact on human reasoning abilities (Casasanto &amp; Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g., Deignan, 2005). The most comprehensive noncomputational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (</context>
<context position="18565" citStr="Steen, et al., 2010" startWordPosition="2920" endWordPosition="2923">ain of the Referent Mental Domain of the Referent Other / Concepts Event-Status State Animacy-Status Undetermined Animacy-Status Other / Concepts Fact-Status Physical Function-Status None Domain of the Referent Types / Possible Event-Status Types / Possible Animacy-Status Types / Possible Function-Status (negative) Types / Possible Table 5: Predictive features. 4 Evaluation A scalar measurement of metaphoricity allows the threshold for metaphor in metaphor identification tasks to be fitted for specific purposes and datasets. The scalar system was evaluated on the VU Amsterdam Metaphor Corpus (Steen, et al., 2010) which consists of 200,000 words from the British National Corpus divided into four genres (academic, news, fiction, and spoken; performance on the spoken genre was not evaluated for this task because it consists of many short fragmentary utterances) and manually annotated for metaphor by five raters. Previous evaluations using this corpus (Dunn, 2013b) concluded that prepositions annotated as metaphoric in the corpus should not be considered metaphoric for computational purposes. Thus, metaphorically used prepositions have been untagged as metaphoric. Further, we have also untagged the ambigu</context>
</contexts>
<marker>Steen, Dorst, Herrmann, Kaal, Krennmayr, 2010</marker>
<rawString>Steen, G. J., Dorst, A. G., Herrmann, J. B., Kaal, A. A., Krennmayr, T. 2010. Metaphor in usage. Cognitive Linguistics, 21(4), 765-796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Strzalkowski</author>
<author>G A Broadwell</author>
<author>S Taylor</author>
<author>L Feldman</author>
<author>S Shaikh</author>
<author>T Liu</author>
<author>K Elliot</author>
</authors>
<date>2013</date>
<booktitle>Robust Extraction of Metaphor from Novel Data. Proceedings of the First Workshop on Metaphor in NLP:</booktitle>
<pages>67--76</pages>
<institution>Association for Computational Linguistics.</institution>
<marker>Strzalkowski, Broadwell, Taylor, Feldman, Shaikh, Liu, Elliot, 2013</marker>
<rawString>Strzalkowski, T., Broadwell, G. A., Taylor, S., Feldman, L., Shaikh, S., Liu, T., Elliot, K. 2013. Robust Extraction of Metaphor from Novel Data. Proceedings of the First Workshop on Metaphor in NLP: 67-76. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsvetkov</author>
<author>E Mukomel</author>
<author>A Gershman</author>
</authors>
<title>Cross-Lingual Metaphor Detection Using Common Semantic Features.</title>
<date>2013</date>
<booktitle>Proceedings of the First Workshop on Metaphor in NLP:</booktitle>
<pages>45--51</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2669" citStr="Tsvetkov, et al., 2013" startWordPosition="391" endWordPosition="394">ary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assu</context>
</contexts>
<marker>Tsvetkov, Mukomel, Gershman, 2013</marker>
<rawString>Tsvetkov, Y., Mukomel, E., Gershman, A. 2013. Cross-Lingual Metaphor Detection Using Common Semantic Features. Proceedings of the First Workshop on Metaphor in NLP: 45-51. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
<author>Y Neuman</author>
<author>D Assaf</author>
<author>Y Cohen</author>
</authors>
<title>Literal and Metaphorical Sense Identification Through Concrete and Abstract Context.</title>
<date>2011</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing:</booktitle>
<pages>680--690</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2692" citStr="Turney, et al., 2011" startWordPosition="395" endWordPosition="398">em: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) used hand-crafted knowledge resources to detect similar selectional mismatches; another approach is to detect selectional mismatches using statistically created resources (e.g., Shutova, et al. 2013; Shutova &amp; Sun, 2013). A second general approach to the binary classification problem has been to use mismatches in properties like abstractness (Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov, et al., 2013; Turney, et al., 2011), semantic similarity (Li &amp; Sporleder, 2010; Sporleder &amp; Li, 2010), and domain membership (Dunn, 2013a, 2013b) to identify metaphoric units of language. A third approach has been to use forms of topic modelling to identify linguistic units which represent both a metaphoric topic and a literal topic (Strzalkowski, 2013; Bracewell, et al, 2013; Mohler, et al., 2013). The single constant across all of these approaches is that the task is viewed as a binary classification problem of distinguishing metaphoric language from non-metaphoric language. This binary distinction assumes a clear boundary be</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Turney, P. D., Neuman, Y., Assaf, D., Cohen, Y. 2011. Literal and Metaphorical Sense Identification Through Concrete and Abstract Context. Proceedings of the Conference on Empirical Methods in Natural Language Processing: 680-690. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Making preferences more active.</title>
<date>1978</date>
<journal>ArtificialIntelligence,</journal>
<volume>11</volume>
<issue>3</issue>
<pages>197--223</pages>
<contexts>
<context position="1662" citStr="Wilks (1978)" startWordPosition="240" endWordPosition="241">ities (Casasanto &amp; Jasmin, 2012; Johansson Falk &amp; Gibbs, 2012) and which, as a result, commonly appears in language in the form of metaphoric expressions (e.g., Deignan, 2005). The most comprehensive noncomputational study of metaphoric expressions in large corpora (Steen, et al., 2010) found that up to 18.5% of words in the British National Corpus were used metaphorically. This means that metaphorically used words not only have very different interpretations than literally used words, but they are also common enough to pose a significant challenge for computational linguistics. Starting with Wilks (1978), the problem of metaphor has been approached as an identification task: first identify or detect metaphoric expressions and then (1) prevent them from interfering with computational treatments of literal expressions and (2) use them to gain additional insight about a text (e.g., Carbonell, 1980; Neuman &amp; Nave, 2009). The identification or detection task has been approached as a binary classification problem: for a given unit of language (e.g., word, phrase, sentence) decide whether it is metaphoric or non-metaphoric. Wilks (1978) used selectional restrictions for this purpose; Mason (2004) us</context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Wilks, Y. 1978. Making preferences more active. ArtificialIntelligence, 11(3), 197-223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>