<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.964515">
Lightly Supervised Learning of Procedural Dialog Systems
</title>
<note confidence="0.7800615">
Svitlana Volkova
CLSP
Johns Hopkins University
Baltimore, MD
</note>
<email confidence="0.766327">
svitlana@jhu.edu
</email>
<author confidence="0.827328">
Pallavi Choudhury, Chris Quirk, Bill Dolan
</author>
<affiliation confidence="0.744088">
NLP Group
Microsoft Research
</affiliation>
<address confidence="0.612083">
Redmond, WA
pallavic,chrisq,
</address>
<email confidence="0.991673">
billdol@microsoft.com
</email>
<author confidence="0.997539">
Luke Zettlemoyer
</author>
<affiliation confidence="0.99812">
Computer Science and Engineering
University of Washington
</affiliation>
<address confidence="0.795786">
Seattle, WA
</address>
<email confidence="0.995735">
lsz@cs.washington.edu
</email>
<sectionHeader confidence="0.998582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993688">
Procedural dialog systems can help users
achieve a wide range of goals. However,
such systems are challenging to build,
currently requiring manual engineering of
substantial domain-specific task knowl-
edge and dialog management strategies. In
this paper, we demonstrate that it is pos-
sible to learn procedural dialog systems
given only light supervision, of the type
that can be provided by non-experts. We
consider domains where the required task
knowledge exists in textual form (e.g., in-
structional web pages) and where system
builders have access to statements of user
intent (e.g., search query logs or dialog
interactions). To learn from such tex-
tual resources, we describe a novel ap-
proach that first automatically extracts task
knowledge from instructions, then learns a
dialog manager over this task knowledge
to provide assistance. Evaluation in a Mi-
crosoft Office domain shows that the indi-
vidual components are highly accurate and
can be integrated into a dialog system that
provides effective help to users.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.972835833333333">
Procedural dialog systems aim to assist users
with a wide range of goals. For example, they
can guide visitors through a museum (Traum et
al., 2012; Aggarwal et al., 2012), teach students
physics (Steinhauser et al., 2011; Dzikovska et
al., 2011), or enable interaction with a health care
</bodyText>
<figure confidence="0.489394111111111">
U: “I want to add page numbers and a title”
S: “Top or Bottom of the page?”
U: “Top”
S: “Please select page design from the tem-
plates” (*System shows drop down menu*)
U: *User selects from menu*
S: “Enter header or footer content”
U: “C.V.”
S: “Task completed.”
</figure>
<figureCaption confidence="0.987352">
Figure 1: An example dialog interaction between
a system (S) and user (U) that can be automatically
achieved by learning from instructional web page
and query click logs.
</figureCaption>
<bodyText confidence="0.999794764705882">
system (Morbini et al., 2012; Rizzo et al., 2011).
However, such systems are challenging to build,
currently requiring expensive, expert engineering
of significant domain-specific task knowledge and
dialog management strategies.
In this paper, we present a new approach for
learning procedural dialog systems from task-
oriented textual resources in combination with
light, non-expert supervision. Specifically, we as-
sume access to task knowledge in textual form
(e.g., instructional web pages) and examples of
user intent statements (e.g., search query logs or
dialog interactions). Such instructional resources
are available in many domains, ranging from
recipes that describe how to cook meals to soft-
ware help web pages that describe how to achieve
goals by interacting with a user interface.1
</bodyText>
<footnote confidence="0.711071">
1ehow.com,wikianswers.com
</footnote>
<page confidence="0.927004">
1669
</page>
<note confidence="0.915173">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1669–1679,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999956378378378">
There are two key challenges: we must (1)
learn to convert the textual knowledge into a us-
able form and (2) learn a dialog manager that pro-
vides robust assistance given such knowledge. For
example, Figure 1 shows the type of task assis-
tance that we are targeting in the Microsoft Office
setting, where the system should learn from web
pages and search query logs. Our central contribu-
tion is to show that such systems can be built with-
out the help of knowledge engineers or domain ex-
perts. We present new approaches for both of our
core problems. First, we introduce a method for
learning to map instructions to tree representations
of the procedures they describe. Nodes in the tree
represent points of interaction with the questions
the system can ask the user, while edges represent
user responses. Next, we present an approach that
uses example user intent statements to simulate di-
alog interactions, and learns how to best map user
utterances to nodes in these induced dialog trees.
When combined, these approaches produce a com-
plete dialog system that can engage in conversa-
tions by automatically moving between the nodes
of a large collection of induced dialog trees.
Experiments in the Windows Office help do-
main demonstrate that it is possible to build an
effective end-to-end dialog system. We evaluate
the dialog tree construction and dialog manage-
ment components in isolation, demonstrating high
accuracy (in the 80-90% range). We also conduct
a small-scale user study which demonstrates that
users can interact productively with the system,
successfully completing over 80% of their tasks.
Even when the system does fail, it often does so in
a graceful way, for example by asking redundant
questions but still reaching the goal within a few
additional turns.
</bodyText>
<sectionHeader confidence="0.776662" genericHeader="introduction">
2 Overview of Approach
</sectionHeader>
<bodyText confidence="0.998660532258065">
Our task-oriented dialog system understands user
utterances by mapping them to nodes in dialog
trees generated from instructional text. Figure 2
shows an example of a set of instructions and the
corresponding dialog tree. This section describes
the problems that we must solve to enable such in-
teractions, and outlines our approach for each.
Knowledge Acquisition We extract task knowl-
edge from instructional text (e.g., Figure 2, left)
that describes (1) actions to be performed, such
as clicking a button, and (2) places where input
is needed from the user, for example to enter the
contents of the footer or header they are trying to
create. We aim to convert this text into a form that
will enable a dialog system to automatically assist
with the described task. To this end, we construct
dialog trees (e.g., Figure 2, right) with nodes to
represent entire documents (labeled as topics t),
nodes to represent user goals or intents (g), and
system action nodes (a) that enable execution of
specific commands. Finally, each node has an as-
sociated system action as, which can prompt user
input (e.g., with the question “Top or bottom of
the page?”) and one or more user actions au that
represent possible responses. All nodes connect
to form a tree structure that follows the workflow
described in the document. Section 3 presents a
scalable approach for inducing dialog trees.
Dialog Management To understand user intent
and provide task assistance, we need a dialog man-
agement approach that specifies what the system
should do and say. We adopt a simple approach
that at all times maintains an index into a node in
a dialog tree. Each system utterance is then simply
the action as for that node. However, the key chal-
lenge comes in interpreting user utterances. After
each user statement, we must automatically up-
date our node index. At any point, the user can
state a general goal (e.g., “I want to add page num-
bers”), refine their goal (e.g., “in a footer”), or both
(e.g.,“I want to add page numbers in the footer”).
Users can also change their goals in the process of
completing the tasks.
We develop a simple classification approach
that is robust to these different types of user behav-
ior. Specifically, we learn classifiers that, given the
dialog interaction history, predict how to pick the
next tree node from the space of all nodes in the di-
alog trees that define the task knowledge. We iso-
late two specific cases, classifying initial user ut-
terances (Section 4) and classifying all subsequent
utterances (Section 5). This approach allows us to
isolate the difference in language for the two cases,
and bias the second case to prefer tree nodes near
the current one. The resulting approach allows for
significant flexibility in traversing the dialog trees.
Data and Evaluation We collected a large set of
such naturally-occurring web search queries that
resulted in a user click on a URL in the Microsoft
Office help domain.2 We found that queries longer
that 4-5 words often resembled natural language
utterances that could be used for dialog interac-
</bodyText>
<footnote confidence="0.994249">
2http://office.microsoft.com
</footnote>
<page confidence="0.988168">
1670
</page>
<figureCaption confidence="0.999144">
Figure 2: An example instructional text paired with a section of the corresponding dialog tree.
</figureCaption>
<bodyText confidence="0.998652272727273">
tions, for example how do you add borders, how
can I add a footer, how to insert continuous page
numbers, and where is the header and footer.
We also collected instructional texts from the
web pages that describe how to solve 76 of the
most pressing user goals, as indicated by query
click log statistics. On average 1,000 user queries
were associated with each goal. To some extent
clickthroughs can be treated as a proxy for user
frustration; popular search targets probably repre-
sent user pain points.
</bodyText>
<sectionHeader confidence="0.9779585" genericHeader="method">
3 Building Dialog Trees from
Instructions
</sectionHeader>
<bodyText confidence="0.93427725">
Our first problem is to convert sets of instructions
for user goals to dialog trees, as shown in Figure
2. These goals are broadly grouped into topics
(instructional pages). In addition, we manually
associate each node in a dialog tree with a train-
ing set of 10 queries. For the 76 goals (246 in-
structions) in our data, this annotation effort took
a single annotator a total of 41 hours. Scaling this
approach to the entire Office help domain would
require a focused annotation effort. Crucially,
though, this annotation work can be carried out by
non-specialists, and could even be crowdsourced
(Bernstein et al., 2010).
Problem Definition As input, we are given in-
structional text (p1 ... p,,,), comprised of topics
(t1 ... t,,,) describing:
</bodyText>
<listItem confidence="0.864424">
(1) high-level user intents (e.g., t1 – “add and for-
mat page numbers”)
(2) goals (g1, ... , gk) that represent more spe-
cific user intents (e.g., g1 – “add header or
footer content to a preformatted page number
design”, g2 – “place the page number in the
side margin of the page”).
</listItem>
<bodyText confidence="0.910178">
Given instructional text p1 ... p,,, and queries
q1 ... q. per topic ti, our goals are as follows:
</bodyText>
<figureCaption confidence="0.529056">
Figure 3: Relationships between user queries and
OHP with goals, instructions and dialog trees.
</figureCaption>
<bodyText confidence="0.964698962962963">
- for every instructional page pi extract a topic
ti and a set of goals g1 ... gk;
- for every goal gj for a topic ti, extract a set of
instructions i1 ... il;
- from topics, goals and instructions, construct
dialog trees f1 ... f,,, (one dialog tree per
topic). Classify instructions to user interac-
tion types thereby identifying system action
nodes a1� ... al�. Transitions between these
nodes are the user actions a1u ... alu.
Figure 2 (left) presents an example of a topic
extracted from the help page, and a set of goals
and instructions annotated with user action types.
In the next few sections of the paper, we out-
line an overall system component design demon-
strating how queries and topics are mapped to the
dialog trees in Figure 3. The figure shows many-
to-one relations between queries and topics, one-
to-many relations between topics and goals, goals
and instructions, and one-to-one relations between
topics and dialog trees.
User Action Classification We aim to classify
instructional text (i1 ... il) for every goal gj in the
decision tree into four categories: binary, selec-
tion, input or none.
Given a single instruction i with category au,
we use a log-linear model to represent the distri-
</bodyText>
<page confidence="0.949005">
1671
</page>
<bodyText confidence="0.999774666666667">
bution over the space of possible user actions. Un-
der this representation, the user action distribution
is defined as:
</bodyText>
<equation confidence="0.9425595">
eθ·φ(au,i)
p(au|i, θ) = Eau eθ·φ(au,i) ,(1)
</equation>
<bodyText confidence="0.999965894736842">
where φ(au, i) ∈ Rn is an n-dimensional fea-
ture representation and θ~ is a parameter vector we
aim to learn. Features are indicator functions of
properties of the instructions and a particular class.
For smoothing we use a zero mean, unit variance
Gaussian prior (0, 1) that penalizes θ~ for drifting
too far from the mean, along with the following
optimization function:
We use L-BFGS (Nocedal and Wright, 2000) as
an optimizer.
Experimental Setup As described in Section 2,
our dataset consists of 76 goals grouped into 30
topics (average 2-3 goals per topic) for a total of
246 instructions (average 3 instructions per goal).
We manually label all instructions with user ac-
tion au categories. The distribution over cate-
gories is binary=14, input=23, selection=80 and
none=129. The data is skewed towards the cat-
egories none and selection. Many instruction do
not require any user input and can be done auto-
matically, e.g., “On the Insert tab, in the Header
and Footer group, click Page Number”. The ex-
ample instructions with corresponding user action
labels are shown in Figure 2 (left) . Finally, we di-
vide the 246 instructions into 2 sets: 80% training
and 20% test, 199 and 47 instructions respectively.
Results We apply the user action type classifi-
cation model described in the Eq.1 and Eq.2 to
classify instructions from the test set into 4 cate-
gories. In Table 1 we report classification results
for 2 baselines: a majority class and heuristic-
based approach, and 2 models with different fea-
ture types: ngrams and ngrams + stems. For a
heuristic baseline, we use simple lexical clues to
classify instructions (e.g., X or Yfor binary, select
Y for selection and type X, insert Y for input). Ta-
ble 1 summarizes the results of mapping instruc-
tional text to user actions.
</bodyText>
<table confidence="0.9983472">
Features # Features Accuracy
Baseline 1: Majority 0.53
Baseline 2: Heuristic – 0.64
Ngrams 10,556 0.89
Ngrams + Stems 12,196 0.89
</table>
<tableCaption confidence="0.999748">
Table 1: Instruction classification results.
</tableCaption>
<bodyText confidence="0.9996311">
Building the Dialog Trees Based on the classi-
fied user action types, we identify system actions
a1s ... als which correspond to 3 types of user ac-
tions a1s ... als (excluding none type) for every goal
in a topic ti. This involved associating all words
from an instruction il with a system action als. Fi-
nally, for every topic we automatically construct a
dialog tree as shown in Figure 2 (right). The dia-
log tree includes a topic t1 with goals g1 ... g4, and
actions (user actions au and system actions as).
</bodyText>
<construct confidence="0.5784515">
Definition 1. A dialog tree encodes a user-system
dialog flow about a topic ti represented as a di-
</construct>
<bodyText confidence="0.997472315789474">
rected unweighted graph fi = (V, E) where top-
ics, goals and actions are nodes of correspond-
ing types {t1 ... tn}, {g1 ... gk}, {a1 ... al} ∈ V .
There is a hierarchical dependency between topic,
goal and action nodes. User interactions are
represented by edges ti → {g1 ... gk}, a1u =
(gj, a1) ... alu = ( ak−1, ak) ∈ E.
For example, in the dialog tree in Figure 2 there
is a relation t1 → g4 between the topic t1 “add
and format page numbers” and the goal g4 “in-
clude page of page X of Y with the page number”.
Moreover, in the dialog tree, the topic level node
has one index i ∈ [1..n], where n is the number
of topics. Every goal node includes information
about its parent (topic) node and has double index
i.j, where j ∈ [1..k]. Finally, action nodes include
information about their parent (goal) and grand-
parent (topic) nodes and have triple index i.j.z,
where z ∈ [1..l].
</bodyText>
<sectionHeader confidence="0.932968" genericHeader="method">
4 Understanding Initial Queries
</sectionHeader>
<bodyText confidence="0.999921">
This section presents a model for classifying ini-
tial user queries to nodes in a dialog tree, which
allows for a variety of different types of queries.
They can be under-specified, including informa-
tion about a topic only (e.g., “add or delete page
numbers”); partially specified, including informa-
tion about a goal (e.g., “insert page number”); or
over-specified, including information about an ac-
tion ( e.g., “page numbering at bottom page”.)
</bodyText>
<equation confidence="0.9781232">
log p(Au, θ|I) = log p(Au|I, θ) − log p(θ) =
1: = 1: (θ − µi)2
au,iE(Au,I) p(au|i, θ) − + k
i 2σ2 i
(2)
</equation>
<page confidence="0.957519">
1672
</page>
<figureCaption confidence="0.7470065">
Figure 4: Mapping initial user queries to the nodes
on different depth in a dialog tree.
</figureCaption>
<bodyText confidence="0.999742208333333">
Problem Definition Given an initial query, the
dialog system initializes to a state s0, searches for
the deepest relevant node given a query, and maps
the query to a node on a topic ti, goal gj or action
ak level in the dialog tree fi, as shown in Figure 4.
More formally, as input, we are given automati-
cally constructed dialog trees f1 ... fn for instruc-
tional text (help pages) annotated with topic, goal
and action nodes and associated with system ac-
tions as shown in Figure 2 (right). From the query
logs, we associate queries with each node type:
topic qt, goal qg and action qa. This is shown in
Figure 2 and 4. We join these dialog trees repre-
senting different topics into a dialog network by
introducing a global root. Within the network,
we aim to find (1) an initial dialog state s0 that
maximizes the probability of state given a query
p(s0|q, θ); and (2) the deepest relevant node v E V
on topic ti, goal gj or action ak depth in the tree.
Initial Dialog State Model We aim to predict
the best node in a dialog tree ti, gj, al E V based
on a user query q. A query-to-node mapping is en-
coded as an initial dialog state s0 represented by a
binary vector over all nodes in the dialog network:
</bodyText>
<equation confidence="0.996921">
s0 = [t1,g1.1,g1.2,g1.2.1 ... ,tn,gn.1,gn.1.1].
</equation>
<bodyText confidence="0.999783666666667">
We employ a log-linear model and try to maxi-
mize initial dialog state distribution over the space
of all nodes in a dialog network:
</bodyText>
<equation confidence="0.9947825">
epi θiφi(s0,q)
p(s0|q, θ) = re
s, eEi θiφi(s,0,q),(3)
0
</equation>
<bodyText confidence="0.994917166666667">
Optimization follows Eq. 2.
We experimented with a variety of features.
Lexical features included query ngrams (up to 3-
grams) associated with every node in a dialog tree
with removed stopwords and stemming query un-
igrams. We also used network structural features:
</bodyText>
<table confidence="0.999219111111111">
Accuracy
Features Topic Goal Action
Random 0.10 0.04 0.04
TFIDF 1Best 0.81 0.21 0.45
Lexical (L) 0.92 0.66 0.63
L + 10TFIDF 0.94 0.66 0.64
L + 10TFIDF + PO 0.94 0.65 0.65
L + 10TFIDF + QO 0.95 0.72 0.69
All above + QHistO 0.96 0.73 0.71
</table>
<tableCaption confidence="0.98277">
Table 2: Initial dialog state classification results
</tableCaption>
<bodyText confidence="0.999428875">
where L stands for lexical features, 10TFIDF - 10
best tf-idf scores, PO - prompt overlap, QO - query
overlap, and QHistO - query history overlap.
tf-idf scores, query ngram overlap with the topic
and goal descriptions, as well as system action
prompts, and query ngram overlap with a history
including queries from parent nodes.
Experimental Setup For each dialog tree,
nodes corresponding to single instructions were
hand-annotated with a small set of user queries,
as described in Section 3. Approximately 60% of
all action nodes have no associated queries3 For
the 76 goals, the resulting dataset consists of 972
node-query pairs, 80% training and 20% test.
Results The initial dialog state classification
model of finding a single node given an initial
query is described in Eq. 3.
We chose two simple baselines: (1) randomly
select a node in a dialog network and (2) use a tf-
idf 1-best model.4 Stemming, stopword removal
and including top 10 tf-idf results as features led
to a 19% increase in accuracy on an action node
level over baseline (2). Adding the following fea-
tures led to an overall 26% improvement: query
overlap with a system prompt (PO), query overlap
with other node queries (QO), and query overlap
with its parent queries (QHistO) .
We present more detailed results for topic, goal
and action nodes in Table 2. For nodes deeper in
the network, the task of mapping a user query to an
action becomes more challenging. Note, however,
that the action node accuracy numbers actually un-
</bodyText>
<footnote confidence="0.99865975">
3There are multiple possible reasons for this: the soft-
ware user interface may already make it clear how to accom-
plish this intent, the user may not understand that the software
makes this fine-grained option available to them, or their ex-
perience with search engines may lead them to state their in-
tent in a more coarse-grained way.
4We use cosine similarity to rank all nodes in a dialog
network and select the node with the highest rank.
</footnote>
<page confidence="0.978658">
1673
</page>
<bodyText confidence="0.999943875">
derstate the utility of the resulting dialog system.
The reason is that even incorrect node assignments
can lead to useful system performance. As long
as a misclassification results being assigned to a
too-high node within the correct dialog tree, the
user will experience a graceful failure: they may
be forced to answer some redundant questions, but
they will still be able to accomplish the task.
</bodyText>
<sectionHeader confidence="0.955375" genericHeader="method">
5 Understanding Query Refinements
</sectionHeader>
<bodyText confidence="0.999949684210526">
We also developed a classifier model for mapping
followup queries to the nodes in a dialog network,
while maintaining a dialog state that summarizes
the history of the current interaction.
Problem Definition Similar to the problem def-
inition in Section 4, we are given a network of di-
alog trees fi ... fn and a query q&apos;, but in addition
we are given the previous dialog state s, which
contains the previous user utterance q and the last
system action as. We aim to find a new dialog
state s&apos; that pairs a node from the dialog tree with
updated history information, thereby undergoing a
dialog state update.
We learn a linear classifier that models
p(s&apos;|q&apos;, q, as, B), the dialog state update distribu-
tion, where we constrain the new state s&apos; to contain
the new utterance q&apos; we are interpreting. This dis-
tribution models 3 transition types: append, over-
ride and reset.
</bodyText>
<construct confidence="0.822431">
Definition 2. An append action defines a dialog
state update when transitioning from a node to its
children at any depth in the same dialog tree e.g.,
ti → gi.j (from a topic to a goal node), gi.j →
ai.j.z (from a goal to an action node) etc.
Definition 3. An override action defines a dialog
state update when transitioning from a goal to its
sibling node. It could also be from an action node5
to another in its parent sibling node in the same di-
alog tree e.g., gi.j_i → gi.j (from one goal to an-
other goal in the same topic tree), ai.j.z → ai.,j.z
(from an action node to another action node in a
different goal in the same dialog tree) etc.
Definition 4. A reset action defines a dialog state
update when transitioning from a node in a current
dialog tree to any other node at any depth in a
dialog tree other than the current dialog tree e.g.,
ti → t,i, (from one topic node to another topic
5A transition from ai.j.z must be to a different goal or an
action node in a different goal but in the same dialog tree.
</construct>
<figure confidence="0.972592">
(a) Updates from topic node ti
</figure>
<figureCaption confidence="0.957872333333333">
Figure 5: Information state updates: append, reset
and override updates based on Definition 2, 3 and
4, respectively, from topic, goal and action nodes.
</figureCaption>
<bodyText confidence="0.998699307692308">
node) ti → g,i.j (from a topic node to a goal node
in a different topic subtree), etc.
The append action should be selected when the
user’s intent is to clarify a previous query (e.g.,
“insert page numbers” → “page numbers in the
footer”). An override action is appropriate when
the user’s intent is to change a goal within the
same topic (e.g., “insert page number → “change
page number”). Finally, a reset action should be
used when the user’s intent is to restart the dialog
(e.g., “insert page x of y” → “set default font”).
We present more examples for append, override
and reset dialog state update actions in Table 3.
</bodyText>
<figure confidence="0.923793">
(b) Updates from goal node gj
(c) Updates from action node al
</figure>
<page confidence="0.97713">
1674
</page>
<bodyText confidence="0.9665859375">
Previous Utterance, q User Utterance, q0 Transition Update Action, a
inserting page numbers qt1 add a background ti → t¬i 2, reset-T, reset
how to number pages qt2 insert numbers on pages in margin ti → si.j 1.4, append-G, append
page numbers qt3 set a page number in a footer ti → ai.j.z 1.2.1, append-A, append
page number a document qt4 insert a comment ti → g¬i.j 21.1, reset-G, reset
page number qt5 add a comment “redo” ti → a¬i.j.z 21.2.1, reset-A, reset
page x of y qg1 add a border gi.j → t¬i 6, reset-T, reset
format page x of x qg2 enter text and page numbers gi.j → gi.¬j 1.1, override-G, override
enter page x of y qg3 page x of y in footer gi.j → ai.j.z 1.3.1, append-A, append
inserting page x of y qg4 setting a default font gi.j → g¬i.j 6.1, reset-G, reset
showing page x of x qg5 set default font and style gi.j → a¬i.j.z 6.4.1, reset-A, reset
page numbers bottom qa1 make a degree symbol ai.j.z → t¬i 13, reset-T, reset
numbering at bottom page qa2 insert page numbers ai.j.z → gi.¬j 1.1, override-G, override
insert footer page numbers qa3 page number design ai.j.z−1 → ai.j.z 1.2.2, append-A, append
headers page number qa4 comments in document ai.j.z → g¬i.j 21.1, reset-G, reset
page number in a footer qa5 changing initials in a comment ai.j.z → a¬i.j.z 21.2.1, reset-A, reset
</bodyText>
<tableCaption confidence="0.995467">
Table 3: Example q and q0 queries for append, override and reset dialog state updates.
</tableCaption>
<bodyText confidence="0.973951857142857">
Figure 5 illustrates examples of append, over-
ride and reset dialog state updates. All transitions
presented in Figure 5 are aligned with the example
q and q0 queries in Table 3.
Dialog State Update Model We use a log-linear
model to maximize a dialog state distribution over
the space of all nodes in a dialog network:
</bodyText>
<equation confidence="0.988982">
eEi θi φi (s0,q0,as,q)
p(s0|q0, q, asθ) = ,s00 eEi θiφi(s00,q0,as,q) (4)
</equation>
<bodyText confidence="0.989116086956522">
Optimization is done as described in Section 3.
Experimental Setup Ideally, dialog systems
should be evaluated relative to large volumes of
real user interaction data. Our query log data,
however, does not include dialog turns, and so we
turn to simulated user behavior to test our system.
Our approach, inspired by recent work (Schatz-
mann et al., 2006; Scheffler and Young, 2002;
Georgila et al., 2005), involves simulating dialog
turns as follows. To define a state s we sam-
ple a query q from a set of queries per node v
and get a corresponding system action as for this
node; to define a state s0, we sample a new query
q0 from another node v0 ∈ V, v =� v0 which
is sampled using a prior probability biased to-
wards append: p(append)=0.7, p(override)=0.2,
p(reset)=0.1. This prior distribution defines a dia-
log strategy where the user primarily continues the
current goal and rarely resets.
We simulate 1100 previous state and new query
pairs for training and 440 pairs for testing. The
features were lexical, including word ngrams,
stems with no stopwords; we also tested network
structure, such as:
- old q and new q0 query overlap (QO);
- q0 overlap with a system prompt as (PO);
- q0 ngram overlap with all queries from the old
state s (SQO);
- q0 ngram overlap with all queries from the
new state s0 (S0QO);
- q0 ngram overlap with all queries from the
new state parents (S0ParQO).
Results Table 4 reports results for dialog state
updates for topic, goal and action nodes. We also
report performance for two types of dialog updates
such as: append (App.) and override (Over.).
We found that the combination of lexical and
query overlap with the previous and new state
queries yielded the best accuracies: 0.95, 0.84 and
0.83 for topic, goal and action node level, respec-
tively. As in Section 4, the accuracy on the topic
level node was highest. Perhaps surprisingly, the
reset action was perfectly predicted (accuracy is
100% for all feature combinations, not included
in figure). The accuracies for append and override
actions are also high (append 95%, override 90%).
</bodyText>
<table confidence="0.999127">
Features Topic Goal Action App. Over.
L 0.92 0.76 0.78 0.90 0.89
L+Q 0.93 0.80 0.80 0.92 0.83
L+P 0.93 0.80 0.79 0.91 0.85
L+Q+P 0.94 0.80 0.80 0.93 0.85
L+SQ 0.94 0.82 0.81 0.93 0.85
L+S0Q 0.93 0.80 0.80 0.91 0.90
L+S0+ParQ 0.94 0.80 0.80 0.91 0.86
L+Q+S0Q 0.94 0.81 0.81 0.91 0.88
L+SQ+S0Q 0.95 0.84 0.83 0.94 0.88
</table>
<tableCaption confidence="0.6109772">
Table 4: Dialog state updates classification ac-
curacies where L stands for lexical features, Q -
query overlap, P - prompt overlap, SQ - previous
state query overlap, S0Q - new state query overlap,
S0ParQ - new state parent query overlap.
</tableCaption>
<page confidence="0.99349">
1675
</page>
<sectionHeader confidence="0.988283" genericHeader="method">
6 The Complete Dialog System
</sectionHeader>
<bodyText confidence="0.996179567567568">
Following the overall setup described in Section 2,
we integrate the learned models into a complete
dialog system. To evaluate the quality of the in-
teractions with this system, we performed a small
scale user study, as described here.
Experimental Setup We randomly chose 8
goals, across topics, from the 76 used to train our
models. For each goal, six users were shown a Mi-
crosoft Word document before and after the goal
was executed. Users were allowed to interact with
the system in an unconstrained manner providing a
total of 48 interactions. If at any point they thought
the system response was irrelevant to their intent,
they could either rephrase or start over.
User Study We objectively measured task com-
pletion and the quality of individual system utter-
ances. We also asked the users to rate the system
(on a scale of 1-5, with 5 being best) on various
measures, including whether the system asked rel-
evant questions. Table 5 summarizes the results.
In general, users were able to complete the tasks
and were reasonably satisfied.
Discussion Figure 6 shows four example di-
alogs. User utterances ranged from single key-
words to rich, sentence-like goal descriptions. For
the shorter inputs, the system was generally able
to identify a small cohort of high-probability in-
tents. For longer inputs, especially with explicitly
specified parameter settings, the system was usu-
ally able to elicit whatever additional information
was required to complete the task. The majority of
errors fell into two categories when the system:
I. missed key information in the input and
asked redundant questions – Figure 6 (C);
II. failed to correctly identify the intent, and
asked an irrelevant question – Figure 6 (D).
Table 5 shows the frequency of each error type.
</bodyText>
<table confidence="0.685056625">
Objective Measures Observed Rates
User achieved task 83%
System asked irrelevant questions 19%
System asked redundant questions 18%
User Satisfaction Score Std.Dev.
Overall satisfaction 3.42 0.49
Questions were relevant 4.17 0.41
Ambiguity was managed 4.00 0.89
</table>
<tableCaption confidence="0.992569">
Table 5: User study results.
</tableCaption>
<bodyText confidence="0.913814625">
U: “I want a page number and title at the bot-
tom of the page”
S: “Choose a page number design from the
gallery of designs”
U: *User selects design*
S: “To insert header or footer content before the
page number, type the content, and then press
TAB to position the content”
</bodyText>
<table confidence="0.991180631578947">
U: “Professional Resume”
S: “Task Completed”
U: “Alphabetize bullets”
S: “Do you want to sort a list alphabetically”
U: “Sort a list”
S: “Select the text in a bulleted or numbered
list”
U: *User selection*
S: “Ascending or Descending?”
U: “Ascending”
S: “Task Completed”
U: “I want the background color to be yellow”
S: “Choose a color for the document”
U: “Yellow ”
S: “Task completed”
U: “I want to change the font face and size”
S: “Choose the default font”
U: “No, reduce the size of the text”
S: *System Restarts*
</table>
<figureCaption confidence="0.6327835">
Figure 6: Four example dialogs from the user
study, including cases that (A and B) complete
successfully, (C) have a redundant question, and
(D) fail to recognize the user intent.
</figureCaption>
<sectionHeader confidence="0.999867" genericHeader="method">
7 Related work
</sectionHeader>
<bodyText confidence="0.999844">
To the best of our knowledge, this paper presents
the first effort to induce full procedural dialog sys-
tems from instructional text and query click logs.
Grounded Language Learning There has been
significant interest in grounded language learn-
ing. Perhaps the most closely related work
learns to understand instructions and automati-
</bodyText>
<page confidence="0.972707">
1676
</page>
<bodyText confidence="0.997734157894737">
cally complete the tasks they describe (Branavan
et al., 2009; Vogel and Jurafsky, 2010; Kush-
man et al., 2009; Branavan et al., 2010; Artzi and
Zettlemoyer, 2013). However, these approaches
did not model user interaction. There are also
many related approaches for other grounded lan-
guage problems, including understanding game
strategy guides (Branavan et al., 2011), model-
ing users goals in a Windows domain (Horvitz
et al., 1998), learning from conversational inter-
action (Artzi and Zettlemoyer, 2011), learning
to sportscast (Chen and Mooney, 2011), learning
from event streams (Liang et al., 2009), and learn-
ing paraphrases from crowdsourced captions of
video snippets (Chen and Dolan, 2011).
Dialog Generation from Text Similarly to Pi-
wek’s work (2007; 2010; 2011), we study extract-
ing dialog knowledge from documents (mono-
logues or instructions). However, Piwek’s ap-
proach generates static dialogs, for example to
generate animations of virtual characters having a
conversation. There is no model of dialog man-
agement or user interaction, and the approach does
not use any machine learning. In contrast, to the
best of our knowledge, we are the first to demon-
strate it is possible to learn complete, interactive
dialog systems using instructional texts (and non-
expert annotation).
Learning from Web Query Logs Web query
logs have been extensively studied. For example,
they are widely used to represent user intents in
spoken language dialogs (T¨ur et al., 2011; Celiky-
ilmaz et al., 2011; Celikyilmaz and Hakkani-Tur,
2012). Web query logs are also used in many other
NLP tasks, including entity linking (Pantel et al.,
2012) and training product and job intent classi-
fiers (Li et al., 2008).
Dialog Modeling and User Simulation Many
existing dialog systems learn dialog strategies
from user interactions (Young, 2010; Rieser and
Lemon, 2008). Moreover, dialog data is often lim-
ited and, therefore, user simulation is commonly
used (Scheffler and Young, 2002; Schatzmann et
al., 2006; Georgila et al., 2005).
Our overall approach is also related to many
other dialog management approaches, including
those that construct dialog graphs from dialog data
via clustering (Lee et al., 2009), learn information
state updates using discriminative classification
models (Hakkani-Tur et al., 2012; Mairesse et al.,
2009), optimize dialog strategy using reinforce-
ment learning (RL) (Scheffler and Young, 2002;
Rieser and Lemon, 2008), or combine RL with
information state update rules (Heeman, 2007).
However, our approach is unique in the use of in-
ducing task and domain knowledge with light su-
pervision to assist the user with many goals.
</bodyText>
<sectionHeader confidence="0.997386" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999932625">
This paper presented a novel approach for au-
tomatically constructing procedural dialog sys-
tems with light supervision, given only textual re-
sources such as instructional text and search query
click logs. Evaluations demonstrated highly accu-
rate performance, on automatic benchmarks and
through a user study.
Although we showed it is possible to build com-
plete systems, more work will be required to scale
the approach to new domains, scale the complex-
ity of the dialog manager, and explore the range of
possible textual knowledge sources that could be
incorporated. We are particularly interested in sce-
narios that would enable end users to author new
goals by writing procedural instructions in natural
language.
</bodyText>
<sectionHeader confidence="0.998384" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999832">
The authors would like to thank Jason Williams
and the anonymous reviewers for their helpful
comments and suggestions.
</bodyText>
<sectionHeader confidence="0.999151" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997268368421053">
Priti Aggarwal, Ron Artstein, Jillian Gerten, An-
thanasios Katsamanis, Shrikanth Narayanan, Angela
Nazarian, and David R. Traum. 2012. The twins
corpus of museum visitor questions. In Proceedings
of LREC.
Yoav Artzi and Luke Zettlemoyer. 2011. Learning
to recover meaning from unannotated conversational
interactions. In NIPS Workshop In Learning Seman-
tics.
Yoav Artzi and Luke Zettlemoyer. 2013. Weakly su-
pervised learning of semantic parsers for mapping
instructions to actions. Transactions of the Associa-
tion for Computational Linguistics, 1(1):49–62.
Michael S. Bernstein, Greg Little, Robert C. Miller,
Bj¨orn Hartmann, Mark S. Ackerman, David R.
Karger, David Crowell, and Katrina Panovich.
2010. Soylent: a word processor with a crowd in-
side. In Proceedings of ACM Symposium on User
Interface Software and Technology.
</reference>
<page confidence="0.99633">
1677
</page>
<bodyText confidence="0.87159975">
S. R. K. Branavan, Harr Chen, Luke S. Zettlemoyer,
and Regina Barzilay. 2009. Reinforcement learning
for mapping instructions to actions. In Proceedings
of ACL.
</bodyText>
<note confidence="0.799613333333333">
Xiao Li, Ye-Yi Wang, and Alex Acero. 2008. Learn-
ing query intent from regularized click graphs. In
Proceedings of SIGIR.
</note>
<reference confidence="0.989550929292929">
S. R. K. Branavan, Luke S. Zettlemoyer, and Regina
Barzilay. 2010. Reading between the lines: learn-
ing to map high-level instructions to commands. In
Proceedings of ACL.
S. R. K. Branavan, David Silver, and Regina Barzi-
lay. 2011. Learning to win by reading manuals in
a monte-carlo framework. In Proceedings of ACL.
Asli Celikyilmaz and Dilek Hakkani-Tur. 2012. A
joint model for discovery of aspects in utterances.
In Proceedings of ACL.
Asli Celikyilmaz, Dilek Hakkani-T¨ur, and Gokhan T¨ur.
2011. Mining search query logs for spoken language
understanding. In Proceedings of ICML.
David L. Chen and William B. Dolan. 2011. Collect-
ing highly parallel data for paraphrase evaluation. In
Proceedings of ACL.
David L. Chen and Raymond J. Mooney. 2011. Learn-
ing to interpret natural language navigation instruc-
tions from observations. In Proceedings ofAAAI.
Myroslava Dzikovska, Amy Isard, Peter Bell, Jo-
hanna D. Moore, Natalie B. Steinhauser, Gwen-
dolyn E. Campbell, Leanne S. Taylor, Simon Caine,
and Charlie Scott. 2011. Adaptive intelligent tuto-
rial dialogue in the beetle ii system. In Proceedings
ofAIED.
Kallirroi Georgila, James Henderson, and Oliver
Lemon. 2005. Learning user simulations for infor-
mation state update dialogue systems. In Proceed-
ings of Eurospeech.
Dilek Hakkani-Tur, Gokhan Tur, Larry Heck, Ashley
Fidler, and Asli Celikyilmaz. 2012. A discrimi-
native classification-based approach to information
state updates for a multi-domain dialog system. In
Proceedings of Interspeech.
Peter Heeman. 2007. Combining Reinforcement
Learning with Information-State Update Rules. In
Proceedings of ACL.
Eric Horvitz, Jack Breese, David Heckerman, David
Hovel, and Koos Rommelse. 1998. The Lumiere
project: Bayesian user modeling for inferring the
goals and needs of software users. In Proceedings
of Uncertainty in Artificial Intelligence.
Nate Kushman, Micah Brodsky, S. R. K. Branavan,
Dina Katabi, Regina Barzilay, and Martin Rinard.
2009. WikiDo. In ACM HotNets.
Cheongjae Lee, Sangkeun Jung, Kyungduk Kim, and
Gary Geunbae Lee. 2009. Automatic agenda graph
construction from human-human dialogs using clus-
tering method. In Proceedings of NAACL.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less super-
vision. In Proceedings of ACL-IJCNLP.
F. Mairesse, M. Gasic, F. Jurcicek, S. Keizer, B. Thom-
son, K. Yu, and S. Young. 2009. Spoken lan-
guage understanding from unaligned data using dis-
criminative classification models. In Proceedings of
Acoustics, Speech and Signal Processing.
Fabrizio Morbini, Eric Forbell, David DeVault, Kenji
Sagae, David R. Traum, and Albert A. Rizzo. 2012.
A mixed-initiative conversational dialogue system
for healthcare. In Proceedings of SIGDIAL.
Jorge Nocedal and Stephen J. Wright. 2000. Numeri-
cal Optimization. Springer.
Patric Pantel, Thomas Lin, and Michael Gamon. 2012.
Mining entity types from query logs via user intent.
In Proceedings ofACL.
Paul Piwek and Svetlana Stoyanchev. 2010. Generat-
ing expository dialogue from monologue: Motiva-
tion, corpus and preliminary rules. In Proceedings
of NAACL.
Paul Piwek and Svetlana Stoyanchev. 2011. Data-
oriented monologue-to-dialogue generation. In Pro-
ceedings of ACL, pages 242–247.
Paul Piwek, Hugo Hernault, Helmut Prendinger, and
Mitsuru Ishizuka. 2007. T2d: Generating dialogues
between virtual agents automatically from text. In
Proceedings of Intelligent Virtual Agents.
Verena Rieser and Oliver Lemon. 2008. Learning ef-
fective multimodal dialogue strategies from wizard-
of-oz data: Bootstrapping and evaluation. In Pro-
ceedings of ACL.
A. Rizzo, Kenji Sagae, E. Forbell, J. Kim, B. Lange,
J. Buckwalter, J. Williams, T. Parsons, P. Kenny,
David R. Traum, J. Difede, and B. Rothbaum. 2011.
Simcoach: An intelligent virtual human system for
providing healthcare information and support. In
Proceedings of ITSEC.
Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and
Steve Young. 2006. A survey of statistical user sim-
ulation techniques for reinforcement-learning of dia-
logue management strategies. Knowledge Engineer-
ing Review, 21(2).
Konrad Scheffler and Steve Young. 2002. Automatic
learning of dialogue strategy using dialogue simula-
tion and reinforcement learning. In Proceedings of
Human Language Technology Research.
Natalie B. Steinhauser, Gwendolyn E. Campbell,
Leanne S. Taylor, Simon Caine, Charlie Scott, My-
roslava Dzikovska, and Johanna D. Moore. 2011.
</reference>
<page confidence="0.825193">
1678
</page>
<reference confidence="0.9932088125">
Talk like an electrician: Student dialogue mimick-
ing behavior in an intelligent tutoring system. In
Proceedings of AIED.
David R. Traum, Priti Aggarwal, Ron Artstein, Susan
Foutz, Jillian Gerten, Athanasios Katsamanis, Anton
Leuski, Dan Noren, and William R. Swartout. 2012.
Ada and grace: Direct interaction with museum vis-
itors. In Proceedings of Intelligent Virtual Agents.
G¨okhan T¨ur, Dilek Z. Hakkani-T¨ur, Dustin Hillard, and
Asli C¸elikyilmaz. 2011. Towards unsupervised spo-
ken language understanding: Exploiting query click
logs for slot filling. In Proceedings of Interspeech.
Adam Vogel and Dan Jurafsky. 2010. Learning to fol-
low navigational directions. In Proceedings of ACL.
Steve Young. 2010. Cognitive user interfaces. In IEEE
Signal Processing Magazine.
</reference>
<page confidence="0.995816">
1679
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.080699">
<title confidence="0.7817395">Lightly Supervised Learning of Procedural Dialog Systems Svitlana</title>
<author confidence="0.737475">Johns Hopkins</author>
<affiliation confidence="0.651352">Baltimore,</affiliation>
<email confidence="0.999817">svitlana@jhu.edu</email>
<author confidence="0.993839">Pallavi Choudhury</author>
<author confidence="0.993839">Chris Quirk</author>
<author confidence="0.993839">Bill</author>
<affiliation confidence="0.7984555">NLP Microsoft</affiliation>
<address confidence="0.558493">Redmond,</address>
<email confidence="0.999886">billdol@microsoft.com</email>
<author confidence="0.967772">Luke</author>
<affiliation confidence="0.857905333333333">Computer Science and University of Seattle,</affiliation>
<email confidence="0.999949">lsz@cs.washington.edu</email>
<abstract confidence="0.999825346153846">Procedural dialog systems can help users achieve a wide range of goals. However, such systems are challenging to build, currently requiring manual engineering of substantial domain-specific task knowledge and dialog management strategies. In this paper, we demonstrate that it is possible to learn procedural dialog systems given only light supervision, of the type that can be provided by non-experts. We consider domains where the required task exists in textual form instructional web pages) and where system builders have access to statements of user search query logs or dialog interactions). To learn from such textual resources, we describe a novel approach that first automatically extracts task knowledge from instructions, then learns a dialog manager over this task knowledge to provide assistance. Evaluation in a Microsoft Office domain shows that the individual components are highly accurate and can be integrated into a dialog system that provides effective help to users.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Priti Aggarwal</author>
<author>Ron Artstein</author>
<author>Jillian Gerten</author>
<author>Anthanasios Katsamanis</author>
<author>Shrikanth Narayanan</author>
<author>Angela Nazarian</author>
<author>David R Traum</author>
</authors>
<title>The twins corpus of museum visitor questions.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="1582" citStr="Aggarwal et al., 2012" startWordPosition="230" endWordPosition="233">, search query logs or dialog interactions). To learn from such textual resources, we describe a novel approach that first automatically extracts task knowledge from instructions, then learns a dialog manager over this task knowledge to provide assistance. Evaluation in a Microsoft Office domain shows that the individual components are highly accurate and can be integrated into a dialog system that provides effective help to users. 1 Introduction Procedural dialog systems aim to assist users with a wide range of goals. For example, they can guide visitors through a museum (Traum et al., 2012; Aggarwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2012; Rizzo et al., 2011)</context>
</contexts>
<marker>Aggarwal, Artstein, Gerten, Katsamanis, Narayanan, Nazarian, Traum, 2012</marker>
<rawString>Priti Aggarwal, Ron Artstein, Jillian Gerten, Anthanasios Katsamanis, Shrikanth Narayanan, Angela Nazarian, and David R. Traum. 2012. The twins corpus of museum visitor questions. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Learning to recover meaning from unannotated conversational interactions.</title>
<date>2011</date>
<booktitle>In NIPS Workshop In Learning Semantics.</booktitle>
<contexts>
<context position="30854" citStr="Artzi and Zettlemoyer, 2011" startWordPosition="5263" endWordPosition="5266">est in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user interaction, and the approach does not use any machine learning. In con</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2011. Learning to recover meaning from unannotated conversational interactions. In NIPS Workshop In Learning Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Weakly supervised learning of semantic parsers for mapping instructions to actions.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="30512" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="5213" endWordPosition="5216">s that (A and B) complete successfully, (C) have a redundant question, and (D) fail to recognize the user intent. 7 Related work To the best of our knowledge, this paper presents the first effort to induce full procedural dialog systems from instructional text and query click logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 201</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2013. Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics, 1(1):49–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael S Bernstein</author>
<author>Greg Little</author>
<author>Robert C Miller</author>
<author>Bj¨orn Hartmann</author>
<author>Mark S Ackerman</author>
<author>David R Karger</author>
<author>David Crowell</author>
<author>Katrina Panovich</author>
</authors>
<title>Soylent: a word processor with a crowd inside.</title>
<date>2010</date>
<booktitle>In Proceedings of ACM Symposium on User Interface Software and Technology.</booktitle>
<contexts>
<context position="9305" citStr="Bernstein et al., 2010" startWordPosition="1498" endWordPosition="1501">ns Our first problem is to convert sets of instructions for user goals to dialog trees, as shown in Figure 2. These goals are broadly grouped into topics (instructional pages). In addition, we manually associate each node in a dialog tree with a training set of 10 queries. For the 76 goals (246 instructions) in our data, this annotation effort took a single annotator a total of 41 hours. Scaling this approach to the entire Office help domain would require a focused annotation effort. Crucially, though, this annotation work can be carried out by non-specialists, and could even be crowdsourced (Bernstein et al., 2010). Problem Definition As input, we are given instructional text (p1 ... p,,,), comprised of topics (t1 ... t,,,) describing: (1) high-level user intents (e.g., t1 – “add and format page numbers”) (2) goals (g1, ... , gk) that represent more specific user intents (e.g., g1 – “add header or footer content to a preformatted page number design”, g2 – “place the page number in the side margin of the page”). Given instructional text p1 ... p,,, and queries q1 ... q. per topic ti, our goals are as follows: Figure 3: Relationships between user queries and OHP with goals, instructions and dialog trees. </context>
</contexts>
<marker>Bernstein, Little, Miller, Hartmann, Ackerman, Karger, Crowell, Panovich, 2010</marker>
<rawString>Michael S. Bernstein, Greg Little, Robert C. Miller, Bj¨orn Hartmann, Mark S. Ackerman, David R. Karger, David Crowell, and Katrina Panovich. 2010. Soylent: a word processor with a crowd inside. In Proceedings of ACM Symposium on User Interface Software and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Luke S Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reading between the lines: learning to map high-level instructions to commands.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="30482" citStr="Branavan et al., 2010" startWordPosition="5209" endWordPosition="5212">r study, including cases that (A and B) complete successfully, (C) have a redundant question, and (D) fail to recognize the user intent. 7 Related work To the best of our knowledge, this paper presents the first effort to induce full procedural dialog systems from instructional text and query click logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Simila</context>
</contexts>
<marker>Branavan, Zettlemoyer, Barzilay, 2010</marker>
<rawString>S. R. K. Branavan, Luke S. Zettlemoyer, and Regina Barzilay. 2010. Reading between the lines: learning to map high-level instructions to commands. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>David Silver</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning to win by reading manuals in a monte-carlo framework.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="30717" citStr="Branavan et al., 2011" startWordPosition="5242" endWordPosition="5245">procedural dialog systems from instructional text and query click logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters havi</context>
</contexts>
<marker>Branavan, Silver, Barzilay, 2011</marker>
<rawString>S. R. K. Branavan, David Silver, and Regina Barzilay. 2011. Learning to win by reading manuals in a monte-carlo framework. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
</authors>
<title>A joint model for discovery of aspects in utterances.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="31880" citStr="Celikyilmaz and Hakkani-Tur, 2012" startWordPosition="5424" endWordPosition="5427"> dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user interaction, and the approach does not use any machine learning. In contrast, to the best of our knowledge, we are the first to demonstrate it is possible to learn complete, interactive dialog systems using instructional texts (and nonexpert annotation). Learning from Web Query Logs Web query logs have been extensively studied. For example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct di</context>
</contexts>
<marker>Celikyilmaz, Hakkani-Tur, 2012</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-Tur. 2012. A joint model for discovery of aspects in utterances. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Gokhan T¨ur</author>
</authors>
<title>Mining search query logs for spoken language understanding.</title>
<date>2011</date>
<booktitle>In Proceedings of ICML.</booktitle>
<marker>Celikyilmaz, Hakkani-T¨ur, T¨ur, 2011</marker>
<rawString>Asli Celikyilmaz, Dilek Hakkani-T¨ur, and Gokhan T¨ur. 2011. Mining search query logs for spoken language understanding. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>William B Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="31046" citStr="Chen and Dolan, 2011" startWordPosition="5292" endWordPosition="5295">rafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user interaction, and the approach does not use any machine learning. In contrast, to the best of our knowledge, we are the first to demonstrate it is possible to learn complete, interactive dialog systems using instructional texts (and nonexpert annotation). Learning</context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David L. Chen and William B. Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings ofAAAI.</booktitle>
<contexts>
<context position="30902" citStr="Chen and Mooney, 2011" startWordPosition="5270" endWordPosition="5273">osely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user interaction, and the approach does not use any machine learning. In contrast, to the best of our knowledge, we are the </context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings ofAAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myroslava Dzikovska</author>
<author>Amy Isard</author>
<author>Peter Bell</author>
<author>Johanna D Moore</author>
<author>Natalie B Steinhauser</author>
<author>Gwendolyn E Campbell</author>
<author>Leanne S Taylor</author>
<author>Simon Caine</author>
<author>Charlie Scott</author>
</authors>
<title>Adaptive intelligent tutorial dialogue in the beetle ii system.</title>
<date>2011</date>
<booktitle>In Proceedings ofAIED.</booktitle>
<contexts>
<context position="1657" citStr="Dzikovska et al., 2011" startWordPosition="241" endWordPosition="244">sources, we describe a novel approach that first automatically extracts task knowledge from instructions, then learns a dialog manager over this task knowledge to provide assistance. Evaluation in a Microsoft Office domain shows that the individual components are highly accurate and can be integrated into a dialog system that provides effective help to users. 1 Introduction Procedural dialog systems aim to assist users with a wide range of goals. For example, they can guide visitors through a museum (Traum et al., 2012; Aggarwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2012; Rizzo et al., 2011). However, such systems are challenging to build, currently requiring expen</context>
</contexts>
<marker>Dzikovska, Isard, Bell, Moore, Steinhauser, Campbell, Taylor, Caine, Scott, 2011</marker>
<rawString>Myroslava Dzikovska, Amy Isard, Peter Bell, Johanna D. Moore, Natalie B. Steinhauser, Gwendolyn E. Campbell, Leanne S. Taylor, Simon Caine, and Charlie Scott. 2011. Adaptive intelligent tutorial dialogue in the beetle ii system. In Proceedings ofAIED.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kallirroi Georgila</author>
<author>James Henderson</author>
<author>Oliver Lemon</author>
</authors>
<title>Learning user simulations for information state update dialogue systems.</title>
<date>2005</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="24712" citStr="Georgila et al., 2005" startWordPosition="4226" endWordPosition="4229">e 3. Dialog State Update Model We use a log-linear model to maximize a dialog state distribution over the space of all nodes in a dialog network: eEi θi φi (s0,q0,as,q) p(s0|q0, q, asθ) = ,s00 eEi θiφi(s00,q0,as,q) (4) Optimization is done as described in Section 3. Experimental Setup Ideally, dialog systems should be evaluated relative to large volumes of real user interaction data. Our query log data, however, does not include dialog turns, and so we turn to simulated user behavior to test our system. Our approach, inspired by recent work (Schatzmann et al., 2006; Scheffler and Young, 2002; Georgila et al., 2005), involves simulating dialog turns as follows. To define a state s we sample a query q from a set of queries per node v and get a corresponding system action as for this node; to define a state s0, we sample a new query q0 from another node v0 ∈ V, v =� v0 which is sampled using a prior probability biased towards append: p(append)=0.7, p(override)=0.2, p(reset)=0.1. This prior distribution defines a dialog strategy where the user primarily continues the current goal and rarely resets. We simulate 1100 previous state and new query pairs for training and 440 pairs for testing. The features were </context>
<context position="32364" citStr="Georgila et al., 2005" startWordPosition="5501" endWordPosition="5504">used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light supervision to assist th</context>
</contexts>
<marker>Georgila, Henderson, Lemon, 2005</marker>
<rawString>Kallirroi Georgila, James Henderson, and Oliver Lemon. 2005. Learning user simulations for information state update dialogue systems. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Hakkani-Tur</author>
<author>Gokhan Tur</author>
<author>Larry Heck</author>
<author>Ashley Fidler</author>
<author>Asli Celikyilmaz</author>
</authors>
<title>A discriminative classification-based approach to information state updates for a multi-domain dialog system.</title>
<date>2012</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<contexts>
<context position="32644" citStr="Hakkani-Tur et al., 2012" startWordPosition="5540" endWordPosition="5543">lassifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light supervision to assist the user with many goals. 8 Conclusions and Future Work This paper presented a novel approach for automatically constructing procedural dialog systems with light supervision, given only textual resources such as instructional text and search query click logs. Evaluations demonstrat</context>
</contexts>
<marker>Hakkani-Tur, Tur, Heck, Fidler, Celikyilmaz, 2012</marker>
<rawString>Dilek Hakkani-Tur, Gokhan Tur, Larry Heck, Ashley Fidler, and Asli Celikyilmaz. 2012. A discriminative classification-based approach to information state updates for a multi-domain dialog system. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Heeman</author>
</authors>
<title>Combining Reinforcement Learning with Information-State Update Rules.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="32846" citStr="Heeman, 2007" startWordPosition="5572" endWordPosition="5573">imited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light supervision to assist the user with many goals. 8 Conclusions and Future Work This paper presented a novel approach for automatically constructing procedural dialog systems with light supervision, given only textual resources such as instructional text and search query click logs. Evaluations demonstrated highly accurate performance, on automatic benchmarks and through a user study. Although we showed it is possible to build complete systems, more work will be required to scale the approach to new dom</context>
</contexts>
<marker>Heeman, 2007</marker>
<rawString>Peter Heeman. 2007. Combining Reinforcement Learning with Information-State Update Rules. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Horvitz</author>
<author>Jack Breese</author>
<author>David Heckerman</author>
<author>David Hovel</author>
<author>Koos Rommelse</author>
</authors>
<title>The Lumiere project: Bayesian user modeling for inferring the goals and needs of software users.</title>
<date>1998</date>
<booktitle>In Proceedings of Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="30782" citStr="Horvitz et al., 1998" startWordPosition="5254" endWordPosition="5257">logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user</context>
</contexts>
<marker>Horvitz, Breese, Heckerman, Hovel, Rommelse, 1998</marker>
<rawString>Eric Horvitz, Jack Breese, David Heckerman, David Hovel, and Koos Rommelse. 1998. The Lumiere project: Bayesian user modeling for inferring the goals and needs of software users. In Proceedings of Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nate Kushman</author>
<author>Micah Brodsky</author>
<author>S R K Branavan</author>
<author>Dina Katabi</author>
<author>Regina Barzilay</author>
<author>Martin Rinard</author>
</authors>
<date>2009</date>
<journal>WikiDo. In ACM HotNets.</journal>
<contexts>
<context position="30459" citStr="Kushman et al., 2009" startWordPosition="5204" endWordPosition="5208">e dialogs from the user study, including cases that (A and B) complete successfully, (C) have a redundant question, and (D) fail to recognize the user intent. 7 Related work To the best of our knowledge, this paper presents the first effort to induce full procedural dialog systems from instructional text and query click logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Gene</context>
</contexts>
<marker>Kushman, Brodsky, Branavan, Katabi, Barzilay, Rinard, 2009</marker>
<rawString>Nate Kushman, Micah Brodsky, S. R. K. Branavan, Dina Katabi, Regina Barzilay, and Martin Rinard. 2009. WikiDo. In ACM HotNets.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cheongjae Lee</author>
<author>Sangkeun Jung</author>
<author>Kyungduk Kim</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>Automatic agenda graph construction from human-human dialogs using clustering method.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="32542" citStr="Lee et al., 2009" startWordPosition="5528" endWordPosition="5531">NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light supervision to assist the user with many goals. 8 Conclusions and Future Work This paper presented a novel approach for automatically constructing procedural dialog systems with light supervision, given</context>
</contexts>
<marker>Lee, Jung, Kim, Lee, 2009</marker>
<rawString>Cheongjae Lee, Sangkeun Jung, Kyungduk Kim, and Gary Geunbae Lee. 2009. Automatic agenda graph construction from human-human dialogs using clustering method. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="30952" citStr="Liang et al., 2009" startWordPosition="5278" endWordPosition="5281">and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dolan, 2011). Dialog Generation from Text Similarly to Piwek’s work (2007; 2010; 2011), we study extracting dialog knowledge from documents (monologues or instructions). However, Piwek’s approach generates static dialogs, for example to generate animations of virtual characters having a conversation. There is no model of dialog management or user interaction, and the approach does not use any machine learning. In contrast, to the best of our knowledge, we are the first to demonstrate it is possible to learn compl</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M Gasic</author>
<author>F Jurcicek</author>
<author>S Keizer</author>
<author>B Thomson</author>
<author>K Yu</author>
<author>S Young</author>
</authors>
<title>Spoken language understanding from unaligned data using discriminative classification models.</title>
<date>2009</date>
<booktitle>In Proceedings of Acoustics, Speech and Signal Processing.</booktitle>
<contexts>
<context position="32668" citStr="Mairesse et al., 2009" startWordPosition="5544" endWordPosition="5547">8). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light supervision to assist the user with many goals. 8 Conclusions and Future Work This paper presented a novel approach for automatically constructing procedural dialog systems with light supervision, given only textual resources such as instructional text and search query click logs. Evaluations demonstrated highly accurate perfo</context>
</contexts>
<marker>Mairesse, Gasic, Jurcicek, Keizer, Thomson, Yu, Young, 2009</marker>
<rawString>F. Mairesse, M. Gasic, F. Jurcicek, S. Keizer, B. Thomson, K. Yu, and S. Young. 2009. Spoken language understanding from unaligned data using discriminative classification models. In Proceedings of Acoustics, Speech and Signal Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Morbini</author>
<author>Eric Forbell</author>
<author>David DeVault</author>
<author>Kenji Sagae</author>
<author>David R Traum</author>
<author>Albert A Rizzo</author>
</authors>
<title>A mixed-initiative conversational dialogue system for healthcare.</title>
<date>2012</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="2161" citStr="Morbini et al., 2012" startWordPosition="330" endWordPosition="333">raum et al., 2012; Aggarwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2012; Rizzo et al., 2011). However, such systems are challenging to build, currently requiring expensive, expert engineering of significant domain-specific task knowledge and dialog management strategies. In this paper, we present a new approach for learning procedural dialog systems from taskoriented textual resources in combination with light, non-expert supervision. Specifically, we assume access to task knowledge in textual form (e.g., instructional web pages) and examples of user intent statements (e.g., search query logs or dialog interactions). Such instructional resources are available in </context>
</contexts>
<marker>Morbini, Forbell, DeVault, Sagae, Traum, Rizzo, 2012</marker>
<rawString>Fabrizio Morbini, Eric Forbell, David DeVault, Kenji Sagae, David R. Traum, and Albert A. Rizzo. 2012. A mixed-initiative conversational dialogue system for healthcare. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Nocedal</author>
<author>Stephen J Wright</author>
</authors>
<title>Numerical Optimization.</title>
<date>2000</date>
<publisher>Springer.</publisher>
<contexts>
<context position="11691" citStr="Nocedal and Wright, 2000" startWordPosition="1910" endWordPosition="1913">se a log-linear model to represent the distri1671 bution over the space of possible user actions. Under this representation, the user action distribution is defined as: eθ·φ(au,i) p(au|i, θ) = Eau eθ·φ(au,i) ,(1) where φ(au, i) ∈ Rn is an n-dimensional feature representation and θ~ is a parameter vector we aim to learn. Features are indicator functions of properties of the instructions and a particular class. For smoothing we use a zero mean, unit variance Gaussian prior (0, 1) that penalizes θ~ for drifting too far from the mean, along with the following optimization function: We use L-BFGS (Nocedal and Wright, 2000) as an optimizer. Experimental Setup As described in Section 2, our dataset consists of 76 goals grouped into 30 topics (average 2-3 goals per topic) for a total of 246 instructions (average 3 instructions per goal). We manually label all instructions with user action au categories. The distribution over categories is binary=14, input=23, selection=80 and none=129. The data is skewed towards the categories none and selection. Many instruction do not require any user input and can be done automatically, e.g., “On the Insert tab, in the Header and Footer group, click Page Number”. The example in</context>
</contexts>
<marker>Nocedal, Wright, 2000</marker>
<rawString>Jorge Nocedal and Stephen J. Wright. 2000. Numerical Optimization. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patric Pantel</author>
<author>Thomas Lin</author>
<author>Michael Gamon</author>
</authors>
<title>Mining entity types from query logs via user intent.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="31982" citStr="Pantel et al., 2012" startWordPosition="5442" endWordPosition="5445">g management or user interaction, and the approach does not use any machine learning. In contrast, to the best of our knowledge, we are the first to demonstrate it is possible to learn complete, interactive dialog systems using instructional texts (and nonexpert annotation). Learning from Web Query Logs Web query logs have been extensively studied. For example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using </context>
</contexts>
<marker>Pantel, Lin, Gamon, 2012</marker>
<rawString>Patric Pantel, Thomas Lin, and Michael Gamon. 2012. Mining entity types from query logs via user intent. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Piwek</author>
<author>Svetlana Stoyanchev</author>
</authors>
<title>Generating expository dialogue from monologue: Motivation, corpus and preliminary rules.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<marker>Piwek, Stoyanchev, 2010</marker>
<rawString>Paul Piwek and Svetlana Stoyanchev. 2010. Generating expository dialogue from monologue: Motivation, corpus and preliminary rules. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Piwek</author>
<author>Svetlana Stoyanchev</author>
</authors>
<title>Dataoriented monologue-to-dialogue generation.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>242--247</pages>
<marker>Piwek, Stoyanchev, 2011</marker>
<rawString>Paul Piwek and Svetlana Stoyanchev. 2011. Dataoriented monologue-to-dialogue generation. In Proceedings of ACL, pages 242–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Piwek</author>
<author>Hugo Hernault</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>T2d: Generating dialogues between virtual agents automatically from text.</title>
<date>2007</date>
<booktitle>In Proceedings of Intelligent Virtual Agents.</booktitle>
<marker>Piwek, Hernault, Prendinger, Ishizuka, 2007</marker>
<rawString>Paul Piwek, Hugo Hernault, Helmut Prendinger, and Mitsuru Ishizuka. 2007. T2d: Generating dialogues between virtual agents automatically from text. In Proceedings of Intelligent Virtual Agents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Verena Rieser</author>
<author>Oliver Lemon</author>
</authors>
<title>Learning effective multimodal dialogue strategies from wizardof-oz data: Bootstrapping and evaluation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="32199" citStr="Rieser and Lemon, 2008" startWordPosition="5475" endWordPosition="5478">systems using instructional texts (and nonexpert annotation). Learning from Web Query Logs Web query logs have been extensively studied. For example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL wit</context>
</contexts>
<marker>Rieser, Lemon, 2008</marker>
<rawString>Verena Rieser and Oliver Lemon. 2008. Learning effective multimodal dialogue strategies from wizardof-oz data: Bootstrapping and evaluation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rizzo</author>
<author>Kenji Sagae</author>
<author>E Forbell</author>
<author>J Kim</author>
<author>B Lange</author>
<author>J Buckwalter</author>
<author>J Williams</author>
<author>T Parsons</author>
<author>P Kenny</author>
<author>David R Traum</author>
<author>J Difede</author>
<author>B Rothbaum</author>
</authors>
<title>Simcoach: An intelligent virtual human system for providing healthcare information and support.</title>
<date>2011</date>
<booktitle>In Proceedings of ITSEC.</booktitle>
<contexts>
<context position="2182" citStr="Rizzo et al., 2011" startWordPosition="334" endWordPosition="337">arwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2012; Rizzo et al., 2011). However, such systems are challenging to build, currently requiring expensive, expert engineering of significant domain-specific task knowledge and dialog management strategies. In this paper, we present a new approach for learning procedural dialog systems from taskoriented textual resources in combination with light, non-expert supervision. Specifically, we assume access to task knowledge in textual form (e.g., instructional web pages) and examples of user intent statements (e.g., search query logs or dialog interactions). Such instructional resources are available in many domains, ranging</context>
</contexts>
<marker>Rizzo, Sagae, Forbell, Kim, Lange, Buckwalter, Williams, Parsons, Kenny, Traum, Difede, Rothbaum, 2011</marker>
<rawString>A. Rizzo, Kenji Sagae, E. Forbell, J. Kim, B. Lange, J. Buckwalter, J. Williams, T. Parsons, P. Kenny, David R. Traum, J. Difede, and B. Rothbaum. 2011. Simcoach: An intelligent virtual human system for providing healthcare information and support. In Proceedings of ITSEC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jost Schatzmann</author>
<author>Karl Weilhammer</author>
<author>Matt Stuttle</author>
<author>Steve Young</author>
</authors>
<title>A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies.</title>
<date>2006</date>
<journal>Knowledge Engineering Review,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="24661" citStr="Schatzmann et al., 2006" startWordPosition="4217" endWordPosition="4221">re aligned with the example q and q0 queries in Table 3. Dialog State Update Model We use a log-linear model to maximize a dialog state distribution over the space of all nodes in a dialog network: eEi θi φi (s0,q0,as,q) p(s0|q0, q, asθ) = ,s00 eEi θiφi(s00,q0,as,q) (4) Optimization is done as described in Section 3. Experimental Setup Ideally, dialog systems should be evaluated relative to large volumes of real user interaction data. Our query log data, however, does not include dialog turns, and so we turn to simulated user behavior to test our system. Our approach, inspired by recent work (Schatzmann et al., 2006; Scheffler and Young, 2002; Georgila et al., 2005), involves simulating dialog turns as follows. To define a state s we sample a query q from a set of queries per node v and get a corresponding system action as for this node; to define a state s0, we sample a new query q0 from another node v0 ∈ V, v =� v0 which is sampled using a prior probability biased towards append: p(append)=0.7, p(override)=0.2, p(reset)=0.1. This prior distribution defines a dialog strategy where the user primarily continues the current goal and rarely resets. We simulate 1100 previous state and new query pairs for tra</context>
<context position="32340" citStr="Schatzmann et al., 2006" startWordPosition="5497" endWordPosition="5500">example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and domain knowledge with light </context>
</contexts>
<marker>Schatzmann, Weilhammer, Stuttle, Young, 2006</marker>
<rawString>Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and Steve Young. 2006. A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. Knowledge Engineering Review, 21(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Konrad Scheffler</author>
<author>Steve Young</author>
</authors>
<title>Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning.</title>
<date>2002</date>
<booktitle>In Proceedings of Human Language Technology Research.</booktitle>
<contexts>
<context position="24688" citStr="Scheffler and Young, 2002" startWordPosition="4222" endWordPosition="4225">le q and q0 queries in Table 3. Dialog State Update Model We use a log-linear model to maximize a dialog state distribution over the space of all nodes in a dialog network: eEi θi φi (s0,q0,as,q) p(s0|q0, q, asθ) = ,s00 eEi θiφi(s00,q0,as,q) (4) Optimization is done as described in Section 3. Experimental Setup Ideally, dialog systems should be evaluated relative to large volumes of real user interaction data. Our query log data, however, does not include dialog turns, and so we turn to simulated user behavior to test our system. Our approach, inspired by recent work (Schatzmann et al., 2006; Scheffler and Young, 2002; Georgila et al., 2005), involves simulating dialog turns as follows. To define a state s we sample a query q from a set of queries per node v and get a corresponding system action as for this node; to define a state s0, we sample a new query q0 from another node v0 ∈ V, v =� v0 which is sampled using a prior probability biased towards append: p(append)=0.7, p(override)=0.2, p(reset)=0.1. This prior distribution defines a dialog strategy where the user primarily continues the current goal and rarely resets. We simulate 1100 previous state and new query pairs for training and 440 pairs for tes</context>
<context position="32315" citStr="Scheffler and Young, 2002" startWordPosition="5493" endWordPosition="5496">n extensively studied. For example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon, 2008), or combine RL with information state update rules (Heeman, 2007). However, our approach is unique in the use of inducing task and dom</context>
</contexts>
<marker>Scheffler, Young, 2002</marker>
<rawString>Konrad Scheffler and Steve Young. 2002. Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning. In Proceedings of Human Language Technology Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie B Steinhauser</author>
<author>Gwendolyn E Campbell</author>
<author>Leanne S Taylor</author>
<author>Simon Caine</author>
<author>Charlie Scott</author>
<author>Myroslava Dzikovska</author>
<author>Johanna D Moore</author>
</authors>
<date>2011</date>
<contexts>
<context position="1632" citStr="Steinhauser et al., 2011" startWordPosition="237" endWordPosition="240">learn from such textual resources, we describe a novel approach that first automatically extracts task knowledge from instructions, then learns a dialog manager over this task knowledge to provide assistance. Evaluation in a Microsoft Office domain shows that the individual components are highly accurate and can be integrated into a dialog system that provides effective help to users. 1 Introduction Procedural dialog systems aim to assist users with a wide range of goals. For example, they can guide visitors through a museum (Traum et al., 2012; Aggarwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2012; Rizzo et al., 2011). However, such systems are challenging to build, </context>
</contexts>
<marker>Steinhauser, Campbell, Taylor, Caine, Scott, Dzikovska, Moore, 2011</marker>
<rawString>Natalie B. Steinhauser, Gwendolyn E. Campbell, Leanne S. Taylor, Simon Caine, Charlie Scott, Myroslava Dzikovska, and Johanna D. Moore. 2011.</rawString>
</citation>
<citation valid="false">
<title>Talk like an electrician: Student dialogue mimicking behavior in an intelligent tutoring system.</title>
<booktitle>In Proceedings of AIED.</booktitle>
<marker></marker>
<rawString>Talk like an electrician: Student dialogue mimicking behavior in an intelligent tutoring system. In Proceedings of AIED.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Traum</author>
<author>Priti Aggarwal</author>
<author>Ron Artstein</author>
<author>Susan Foutz</author>
<author>Jillian Gerten</author>
<author>Athanasios Katsamanis</author>
<author>Anton Leuski</author>
<author>Dan Noren</author>
<author>William R Swartout</author>
</authors>
<title>Ada and grace: Direct interaction with museum visitors.</title>
<date>2012</date>
<booktitle>In Proceedings of Intelligent Virtual Agents.</booktitle>
<contexts>
<context position="1558" citStr="Traum et al., 2012" startWordPosition="226" endWordPosition="229">of user intent (e.g., search query logs or dialog interactions). To learn from such textual resources, we describe a novel approach that first automatically extracts task knowledge from instructions, then learns a dialog manager over this task knowledge to provide assistance. Evaluation in a Microsoft Office domain shows that the individual components are highly accurate and can be integrated into a dialog system that provides effective help to users. 1 Introduction Procedural dialog systems aim to assist users with a wide range of goals. For example, they can guide visitors through a museum (Traum et al., 2012; Aggarwal et al., 2012), teach students physics (Steinhauser et al., 2011; Dzikovska et al., 2011), or enable interaction with a health care U: “I want to add page numbers and a title” S: “Top or Bottom of the page?” U: “Top” S: “Please select page design from the templates” (*System shows drop down menu*) U: *User selects from menu* S: “Enter header or footer content” U: “C.V.” S: “Task completed.” Figure 1: An example dialog interaction between a system (S) and user (U) that can be automatically achieved by learning from instructional web page and query click logs. system (Morbini et al., 2</context>
</contexts>
<marker>Traum, Aggarwal, Artstein, Foutz, Gerten, Katsamanis, Leuski, Noren, Swartout, 2012</marker>
<rawString>David R. Traum, Priti Aggarwal, Ron Artstein, Susan Foutz, Jillian Gerten, Athanasios Katsamanis, Anton Leuski, Dan Noren, and William R. Swartout. 2012. Ada and grace: Direct interaction with museum visitors. In Proceedings of Intelligent Virtual Agents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨okhan T¨ur</author>
<author>Dilek Z Hakkani-T¨ur</author>
<author>Dustin Hillard</author>
<author>Asli C¸elikyilmaz</author>
</authors>
<title>Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling.</title>
<date>2011</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<marker>T¨ur, Hakkani-T¨ur, Hillard, C¸elikyilmaz, 2011</marker>
<rawString>G¨okhan T¨ur, Dilek Z. Hakkani-T¨ur, Dustin Hillard, and Asli C¸elikyilmaz. 2011. Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Dan Jurafsky</author>
</authors>
<title>Learning to follow navigational directions.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="30437" citStr="Vogel and Jurafsky, 2010" startWordPosition="5200" endWordPosition="5203">rts* Figure 6: Four example dialogs from the user study, including cases that (A and B) complete successfully, (C) have a redundant question, and (D) fail to recognize the user intent. 7 Related work To the best of our knowledge, this paper presents the first effort to induce full procedural dialog systems from instructional text and query click logs. Grounded Language Learning There has been significant interest in grounded language learning. Perhaps the most closely related work learns to understand instructions and automati1676 cally complete the tasks they describe (Branavan et al., 2009; Vogel and Jurafsky, 2010; Kushman et al., 2009; Branavan et al., 2010; Artzi and Zettlemoyer, 2013). However, these approaches did not model user interaction. There are also many related approaches for other grounded language problems, including understanding game strategy guides (Branavan et al., 2011), modeling users goals in a Windows domain (Horvitz et al., 1998), learning from conversational interaction (Artzi and Zettlemoyer, 2011), learning to sportscast (Chen and Mooney, 2011), learning from event streams (Liang et al., 2009), and learning paraphrases from crowdsourced captions of video snippets (Chen and Dol</context>
</contexts>
<marker>Vogel, Jurafsky, 2010</marker>
<rawString>Adam Vogel and Dan Jurafsky. 2010. Learning to follow navigational directions. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
</authors>
<title>Cognitive user interfaces.</title>
<date>2010</date>
<booktitle>In IEEE Signal Processing Magazine.</booktitle>
<contexts>
<context position="32174" citStr="Young, 2010" startWordPosition="5473" endWordPosition="5474">ctive dialog systems using instructional texts (and nonexpert annotation). Learning from Web Query Logs Web query logs have been extensively studied. For example, they are widely used to represent user intents in spoken language dialogs (T¨ur et al., 2011; Celikyilmaz et al., 2011; Celikyilmaz and Hakkani-Tur, 2012). Web query logs are also used in many other NLP tasks, including entity linking (Pantel et al., 2012) and training product and job intent classifiers (Li et al., 2008). Dialog Modeling and User Simulation Many existing dialog systems learn dialog strategies from user interactions (Young, 2010; Rieser and Lemon, 2008). Moreover, dialog data is often limited and, therefore, user simulation is commonly used (Scheffler and Young, 2002; Schatzmann et al., 2006; Georgila et al., 2005). Our overall approach is also related to many other dialog management approaches, including those that construct dialog graphs from dialog data via clustering (Lee et al., 2009), learn information state updates using discriminative classification models (Hakkani-Tur et al., 2012; Mairesse et al., 2009), optimize dialog strategy using reinforcement learning (RL) (Scheffler and Young, 2002; Rieser and Lemon,</context>
</contexts>
<marker>Young, 2010</marker>
<rawString>Steve Young. 2010. Cognitive user interfaces. In IEEE Signal Processing Magazine.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>