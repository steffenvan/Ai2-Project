<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.9845335">
Dialogue and Domain Knowledge Management in Dialogue
Systems
</title>
<author confidence="0.896639">
Annika Flycht-Eriksson and Arne Jonsson
</author>
<affiliation confidence="0.6202115">
Department of Computer and Information Science
Linkoping University, SE-581 83, LINKOPING, SWEDEN
</affiliation>
<email confidence="0.972905">
annfl@ida.liu.se arnjo@ida.liu.se
</email>
<sectionHeader confidence="0.996987" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973368421053">
Intelligent dialogue systems must be able
to respond properly to a variety of re-
quests involving knowledge of the dia-
logue, the task at hand, and the domain.
This requires advanced knowledge rea-
soning performed by various processing
modules. We argue that it is impor-
tant to understand the nature of the var-
ious reasoning mechanisms involved and
to separate not only, for instance, inter-
pretation, generation, and dialogue man-
agement but also domain knowledge and
task reasoning. This facilitates portabili-
ty of the dialogue system to new domains
and makes it easier to enhance its capa-
bilities. In this paper we will focus on the
dialogue and domain knowledge reason-
ing components and show how they can
cooperate to achieve natural interaction.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999990935483871">
As information services and domains grow more
complex the complexity of dialogue systems in-
creases. They tend to need more and more domain
knowledge and the domain reasoning mechanisms
also have to become more sophisticated. Utilis-
ing domain knowledge reasoning is in many cases
necessary for a dialogue system to interpret and
respond to a request in an intelligent manner, es-
pecially as requests can be vague and sometimes
ambiguous. This involves not only requests for
information from application specific knowledge
sources, but also requests related to the properties
and structures of the application and requests that
are outside the scope of the application. Thus,
dialogue systems must be able to access, gath-
er and integrate knowledge from various domain
knowledge sources and application systems in or-
der to determine the precise meaning of a request
and produce an appropriate response. However,
although the dialogue system gather information
from various sources it differs from the informa-
tion retrieval problem discussed for instance in
Stein et al. (1999). We assume that the tasks are
well-defined and that the users have articulated
information needs that they can express in specif-
ic terms.
In this paper we will discuss how these different
tasks can be performed in dialogue systems of sim-
ple service character, i.e. dialogue systems that
can provide information given a set of parameters
collected from the user (Hayes and Reddy, 1983).
</bodyText>
<sectionHeader confidence="0.991579" genericHeader="method">
2 Types of requests and
clarifications
</sectionHeader>
<bodyText confidence="0.996910375">
Users interacting with a dialogue system utilise
various communicative acts. Bunt (1989) makes a
distinction between factual information acts and
dialogue control acts. The latter is used to control
the dialogue and the former involves any transfer
of factual information. Factual information re-
quests can be further divided into two basic types
of requests:
</bodyText>
<listItem confidence="0.788748571428571">
• Task related requests. Requests where the
response from the dialogue system includes
domain and task specific information
• System related requests. Requests where the
response includes information on what can be
done with the system or pointers to other in-
formation sources
</listItem>
<bodyText confidence="0.999972307692308">
To be able to respond to questions on the sys-
tem&apos;s capabilities and how to interpret the pro-
vided information, the dialogue system needs to
represent knowledge about itself, here called sys-
tem information. Also, if an answer can not be
found in the application system(s) the dialogue
system should give as helpful information as pos-
sible, for example suggesting other resources the
user can consult. For this purpose knowledge is
needed on where such information can be found.
The requests for task related information can be
divided into simple and complex requests. Sim-
ple requests are basically requests for information
</bodyText>
<page confidence="0.996588">
121
</page>
<figureCaption confidence="0.97937575">
Figure 1: A dialogue system architecture. The picture shows different processing modules: Interpreter,
Generator, Dialogue Manager and Domain Knowledge Manager. Some of the knowledge sources: dia-
logue model, domain task model, system task model, and various knowledge modules, are also depicted,
but not the grammar and lexicon.
</figureCaption>
<figure confidence="0.997102458333333">
Interpreter
Knowledge
Module I
Knowledge
Module 2
Knowledge
Module 3
Dialogue
\ history
Generator
Dialogue
Manager
System task
model
Domain
Knowledge
Manager
1
Domain task
model
Knowledge
Module n
Dialogue
model
</figure>
<bodyText confidence="0.999831285714286">
concerning properties of and relations between
simple objects, for which the answers can be val-
ues of properties or names of objects. A simple
object is typically an entity that can be identified
by a name or a set of distinguishing features. Sim-
ple requests can be specified by an arbitrary set
of parameters. The parameters describe certain
properties which constraints the search for an ob-
ject, or the requested properties of an object or
set of objects. A typical example of a simple re-
quest is How fast is a Volvo 850?, which can be
directly mapped onto a structure specifying that
the requested object is &apos;Volvo 850&apos; and the prop-
erty requested is its &apos;speed&apos;, which in turn can be
converted to an application system request.
Complex requests on the other hand are con-
cerned with the specification and construction of
compound objects. The specification of such an
object requires that the user provides information
on a specific set of parameters, which often in-
volves several dialogue turns. The specification is
used to construct a matching object by retriev-
ing, and sometimes integrating, knowledge from
one or several domain and application knowledge
sources. Examples of complex requests are found
in timetable information applications, such as the
ATIS dialogues. To answer requests on a trip,
the system needs to have a number of parame-
ters specified, such as departure and arrival time
and place, before it is able to access the time-
tables. However, for such systems there are al-
so simple requests that can be directly mapped
to a request from the background system, for in-
stance, requests regarding meals on a flight that
can be identified by a flight number, e.g. Is break-
fast served on flight SK2818?.
Since requests are specified by a set of entities
the system needs capabilities to identify entities
from descriptions (Hayes and Reddy, 1983). An
attempt to map a description to an entity can have
three different outcomes, a unique entity is found,
the description is ambiguous and corresponds to
several objects, or the description is unsatisfiable
and no matching object can be found. There exist
several strategies to deal with these problems, but
all of them include some clarification from the user
or domain reasoning. In dealing with ambiguous
descriptions the system should be able to provide
options or find a distinguishing feature that can
be used to ask the user for clarification. Unsatisfi-
able descriptions can be dealt with in three differ-
ent ways: inform the user of the problem giving
as helpful information as possible, find near misses
by relaxing some of the features in the description,
or find and inform the user of faulty presupposi-
tions.
</bodyText>
<sectionHeader confidence="0.973611" genericHeader="method">
3 Dialogue system architectures
</sectionHeader>
<bodyText confidence="0.999835833333333">
Dialogue systems often have a modular archi-
tecture with processing modules for interpreta-
tion, dialogue management, background system
access, and generation, see figure 1. The pro-
cessing modules utilise a number of knowledge
sources, such as, grammar, lexicon, dialogue mod-
</bodyText>
<page confidence="0.996439">
122
</page>
<bodyText confidence="0.995222">
el, domain model, and task model (for an overview
of some systems, see Flycht-Eriksson (1999)). In
this paper focus is on dialogue management and
domain knowledge management, which includes
background system access.
</bodyText>
<subsectionHeader confidence="0.999178">
3.1 Dialogue management
</subsectionHeader>
<bodyText confidence="0.999944820512821">
The role of the Dialogue Manager differs slightly
between different dialogue system architectures,
but it&apos;s primary responsibility is to control the
flow of the dialogue by deciding how the system
should respond to a user utterance. This is done
by inspecting and contextually specifying the in-
formation structure produced by an interpreta-
tion module. If some information is missing or
a request is ambiguous, clarification questions are
specified by the Dialogue Manager and posed to
the user. Should a request be fully specified and
unambiguous the background system can be ac-
cessed and an answer be produced. As a basis
for these tasks the Dialogue Manager can utilise
a dialogue model, a task model, and a dialogue
history.
The Dialogue model holds a generic description
of how the dialogue is to be constructed, i.e. to
decide what action to take in a certain situation.
It is used to control the interaction, which in-
volves determining: 1) what the system should
do next (and what module is responsible for car-
rying out the task) and 2) deciding what com-
municative action is appropriate at a given dia-
logue state. There are various proposals on dia-
logue models which can be divided in two groups:
intention-based and structurally based. They dif-
fer in how they model the dialogue, especially
if the user&apos;s goals and intentions behind the ut-
terance need to be captured or not. Structural-
ly based models are often controlled using a di-
alogue grammar whereas intention-based utilise
plan operators. Furthermore, plan-based sys-
tems use plan operators to model not only dia-
logue knowledge but also task, domain and meta
knowledge (c.f. Lambert and Carberry (1991),
Ramshaw (1991), Ferguson et al. (1996)). This
allows for plan recognition to be the only process-
ing mechanism needed.
The System Task model represents how the sys-
tem&apos;s tasks are performed, cf. Application De-
scription (Hagen, 1999). However, the terms task
and task model can refer to very different phe-
nomena. It is important to make a clear distinc-
tion between the system&apos;s task(s) and the user&apos;s
task(s) (van Loo and Bego, 1993; Dahlback and
Jonsson, 1999). A user task is non-linguistic and
takes place in the real world. Models of such
tasks involve the user&apos;s goals and how they can be
achieved (c.f. Wahlster and Kobsa (1989)). Mod-
els of system tasks describe how the system&apos;s com-
municative and other tasks, e.g. database access,
are carried out.
A typical example of the difference between
the two types of task models can be found in a
time-table system where the user states that (s)he
needs to be at the train station to catch a cer-
tain train and requests information on buses go-
ing there. The information that the user is going
to the train station is user task model informa-
tion, indicating that buses arriving after the de-
parture time of the train are not relevant. The
system task model on the other hand models the
information required for complex requests, such as
date and departure place in a time-table system
(cf. Bennacef et al. (1996)). It is used by the Di-
alogue Manager when collecting user information
in order to perform a background system access.
In plan-based systems the domain models takes a
similar role, but wider as they often also involves
advanced problem solving. We will in this paper
not consider user task models, only system task
models.
The Dialogue history records the focus of atten-
tion (Grosz and Sidner, 1986) and contains infor-
mation about objects, properties, and relations as
well as other dialogue information such as speech
act information and system task information.
</bodyText>
<subsectionHeader confidence="0.999209">
3.2 Domain Knowledge Management
</subsectionHeader>
<bodyText confidence="0.9974374">
If a request is fully specified it can be used to re-
trieve the desired information from a background
system. This task is seldom discussed in litera-
ture on dialogue systems, perhaps because it is
considered a rather straight forward task. There
are, however, several problems related to this. For
example, in cases where the background system is
distributed and consists of several domain and ap-
plication system knowledge sources the dialogue
system must know which of them to access, in
what order, and how the results should be inte-
grated into one answer. This type of knowledge
can be represented in a domain task model.
Other problems related to domain knowledge
reasoning and application access where mentioned
in section 2. Although fully specified, requests can
contain vague or ambiguous information or even
some errors that can not be detected and han-
dled without extensive domain knowledge. This
type of domain knowledge is stored in domain
knowledge sources, called knowledge modules in
figure 1. They contain knowledge of the world
that is talked about and can vary much in form
and content. Information from a domain knowl-
edge source is primarily used to find the relevant
</bodyText>
<page confidence="0.959646">
123
</page>
<figure confidence="0.925151">
Spatial Temporal
Reasoning Reasoning
Timetable
database
Dialogue
tree
Interpreter
Dialogue
Domain
System
and Help
Manager Knowledge
Manager
Generator Information
[
&apos;---Dialogue
...FaMmar....„.
Information
Specification
Recipes
Integration rule___.s
</figure>
<figureCaption confidence="0.997833">
Figure 2: The MALIN dialogue system architecture in an application for local bus traffic time-table
</figureCaption>
<bodyText confidence="0.997688837837838">
information. The dialogue model used is a dialogue grammar, the dialogue history is modelled as a
dialogue tree, and Information Specification Forms correspond to the system task model. The domain
and application knowledge modules perform spatial and temporal reasoning, and provide time-table and
system information controlled by recipes and integration rules.
items and relations that are discussed, to supply
default values, etc. The knowledge represented
in a domain knowledge source is often coupled to
the application system, e.g. a database system.
In such cases it is often used to map information
from a Dialogue Manager to concepts suitable for
database search. It is for example common that
user&apos;s give vague temporal descriptions that has to
be mapped to more precise time intervals before
the information can be used to access an applica-
tion system.
To develop a Dialogue Manager that easily can
be customized to new domains and in which dif-
ferent dialogue strategies can be explored, the Di-
alogue Manager should only be concerned with
phenomena related to the dialogue with the user.
It should not be involved in the process of access-
ing the background system or performing domain
reasoning. These tasks should instead be carried
out by a separate module, a Domain Knowledge
Manager.
The Domain Knowledge Manager is responsible
for retrieving and coordinating knowledge from
the different domain knowledge sources and ap-
plication systems that constitutes the background
system. The Dialogue Manager can deliver a re-
quest to the Domain Knowledge Manager and in
return expects an answer retrieved from the back-
ground system. If a request is under-specified or
contains inconsistencies from the Domain Knowl-
edge Manager&apos;s point of view, a specification of
what clarifying information is needed will instead
be returned to the Dialogue Manager.
</bodyText>
<sectionHeader confidence="0.992885" genericHeader="evaluation">
4 MALIN
</sectionHeader>
<bodyText confidence="0.959635076923077">
In what follows we describe and exemplify a di-
alogue system with separate modules for dia-
logue management and domain knowledge man-
agement. The presentation will be based on the
MALIN dialogue system architecture&apos;, figure 2,
which has been used to implement an application
for time-table information for local bus traffic in
Ostergotland.
One issue in the design of a dialogue system is
how to control the various modules and the user
interaction. In some systems there is no module
responsible for the communication, instead a sep-
arate module, called hub (Aberdeen et al., 1999)
or facilitator (Martin et al., 1999), is used for co-
ordinating the modules and the internal informa-
tion flow. Alternatively, the Dialogue Manager is
the central unit of the system where the overall
system behaviour is determined.
The approach taken in MALIN is a combina-
tion where a Dialogue Manager is the central con-
troller of the interaction and the Domain Knowl-
edge Manager is based on an agent architecture.
&apos;MALIN (Multi-modal Application of LINLIN) is a re-
finement of the LINLINsystem (Ahrenberg et al., 1990;
Jonsson, 1997) to handle also multi-modal interaction
and more advanced applications.
</bodyText>
<page confidence="0.990897">
124
</page>
<subsectionHeader confidence="0.975725">
4.1 The Dialogue Manager
</subsectionHeader>
<bodyText confidence="0.999727018518519">
In the MALIN dialogue model the dialogue is struc-
tured in terms of discourse segments, and a dis-
course segment in terms of moves and embed-
ded segments. Utterances are analysed as linguis-
tic objects which function as vehicles for atom-
ic move segments. An initiative-response (IR)
structure determines the compound discourse seg-
ments, where an initiative opens the IR-segment
by introducing a new goal and the response clos-
es the IR-segment (Dahlback, 1991). The dis-
course segments are classified by general speech
act categories, such as question (Q) and an-
swer (A) (Jonsson, 1997), rather than specialised
(cf. (Hagen, 1999)), or domain related (Alexander-
sson and Reithinger, 1995). The action to carry
out for the Dialogue Manager, as modeled in a di-
alogue grammar, depends on how domain entities
are specified and their relation to other entities in
the domain and the dialogue history.
In the MALIN dialogue system architecture there
is only one dialogue history maintained by the Di-
alogue Manager. Thus, the other modules in the
system have no memory of the previous interac-
tion since this could cause conflicts. The dialogue
history records focal information, that is, what
has been talked about and what is being talked
about at the moment. It is used for dialogue con-
trol, disambiguation of context dependent utter-
ances, and context sensitive interpretation. The
dialogue history is represented as a dialogue tree.
The nodes in the dialogue tree record information
utilising various information structures depending
on the application.
For simple information requests we have identi-
fied two important concepts, termed Objects and
Properties (Jonsson, 1997) where Objects models
the set of objects in the database and Proper-
ties denotes a complex predicate ascribed to this
set. The parameters Objects and Properties are
application dependent. We also utilise Markers for
various purposes (Jonsson and Stromback, 1998),
but they will not be further discussed in this pa-
per. Structures that represent information about
objects and properties (and markers) are termed
OPMs. Figure 3 shows an example OPM which
represents the request Which bus lines passes the
North gate?.
For complex requests the Dialogue Manager
needs an information structure that holds the pa-
rameters needed before successful access of the
background system can be performed. We call
such structures Information Specification Forms
(ISFs) (Dahlback and Jonsson, 1999). Just like
OPMs the ISFs are application dependent and be-
</bodyText>
<equation confidence="0.97443825">
[Obj : #1[ Busline: ? ]
#2{ Stop: North gate ]
Prop: [ PassesBy : Line: #11]
[Stop: #2
</equation>
<bodyText confidence="0.999008125">
sides holding information they are also used as sys-
tem task models, i.e. to inform the Dialogue Man-
ager which parameters that has to be provided by
the user. We have identified a number of differ-
ent user information needs (Qvarfordt, 1998) for
which ISFs are needed. The most common, called
trip information, occurs when the user needs to
know how and when on a particular day, most of-
ten the present day, one can travel from one point
to another in town by bus. An ISF for such re-
quests model information on departure and arrival
destinations and information on arrival and/or de-
parture time, which is required information. The
user can also give information about the travel
type, but this is optional. Figure 4 shows an emp-
ty Trip ISF.
</bodyText>
<figure confidence="0.677989">
Type:
Arr :
Dep:
TTime:
TType :
</figure>
<figureCaption confidence="0.593184">
Figure4: An empty trip ISF.
</figureCaption>
<bodyText confidence="0.999503">
Another common information need, called route
information, is when the caller wants information
on which busses or trains that go from one point
to another. This ISF is similar to the Trip ISF
but time information is no longer required.
For the time-table information application both
structures, ISF and OPM, are needed. This is not
the case for all types of applications but we believe
that if an ISF is needed an OPM can also often
be useful.
</bodyText>
<subsectionHeader confidence="0.981254">
4.2 The Domain Knowledge Manager
</subsectionHeader>
<bodyText confidence="0.999813888888889">
The domain knowledge sources and application
systems in MALIN are implemented as agents and
will from now on be called domain agents. Do-
main agents provide different services, typically to
retrieve and reason about some information giv-
en some parameters, and can also request services
from each other. Communication and cooperation
among the agents are achieved by passing mes-
sages.
</bodyText>
<figureCaption confidence="0.987884">
Figure 3: An OPM for the utterance Which bus
lines passes the North gate?.
</figureCaption>
<figure confidence="0.8828678">
Trip
req.
req.
req.
opt.
</figure>
<page confidence="0.98678">
125
</page>
<table confidence="0.994824428571428">
Agent Service
Spatial Reasoning Agent getBusStops(From.BusStop, From.Place, From.Street, From.Area,
From.Town, FromBusStops)
Spatial Reasoning Agent getBusStops(To.BusStop, To.Place, To.Street, To.Area, To.Town,
ToBusStops)
Temporal Reasoning Agent getTime(TTime.Time, TravelTime)
Timetable Agent getTrips(FromBusStops, ToBusStops, TravelTime)
</table>
<figureCaption confidence="0.997339">
Figure 5: An example of an uninstantiated recipe for trip information.
</figureCaption>
<bodyText confidence="0.7364995">
Ul: I want to go to the city center.
S2: The city center is a big area. Can you point in the map or give more specific information like
a landmark or a street?
U3: Are there any bus stops near the Garden square?
S4: There are several bus stops near the Garden square.
&lt; Shows the bus stops in the map &gt;
1J5: Then I want to go there from the University.
S6: When do you want to go?
U7: On the 31st of April before lunch.
S8: The 31st is not a valid date, there are only 30 days in April. Give a new date please.
U9: The 30th of April.
S10: The alternative trips are shown in the table.
</bodyText>
<figure confidence="0.562118">
&lt; Shows a table of trips &gt;
</figure>
<figureCaption confidence="0.983542">
Figure 6: A hypothetical dialogue with the MALIN dialogue system for a local bus time-table information
</figureCaption>
<bodyText confidence="0.939354435897436">
application. The dialogue is constructed based on a corpus of 43 dialogues collected with users of the
current information service in order to illustrate some of the features of the dialogue and domain
knowledge managers and our multi-modal system.
In the application of MALIN to time-table in-
formation, four different domain agents are used,
see figure 2. The Temporal Reasoning Agent con-
tains a calendar and reasons about temporal ex-
pressions. The Spatial Reasoning Agent utilises
a Geographical Information System and reason-
ing mechanism used to deduce the relations be-
tween geographical objects (Flycht-Eriksson and
Jonsson, 1998). The Timetable Agent retrieves
time-table information for local bus and train traf-
fic from an Internet source. There is also a Sys-
tem Information Agent which provides system in-
formation like references to human operators for
questions outside the scope of time-table informa-
tion.
The processing of a request performed by the
Domain Knowledge Manager is based on a knowl-
edge structure called recipe. A recipe is applica-
tion specific and consists of a series of service calls
from different agents, which axe executed in order
to construct an answer to a specific request, see
figure 5 for an example. Domain Knowledge Man-
agement in general involves three steps. First the
Domain Knowledge Manager has to decide how
to treat the request, i.e. to produce one or more
recipes. In most cases one recipe is enough, but
sometimes the user has provided ambiguous infor-
mation that cannot be resolved by the interpreter
or the Dialogue Manager, in which cases several
recipes are needed. The next step is to process
the recipe(s). The processing must be carefully
monitored and aborted if an error occurs. Final-
ly, alternatives must be inspected and integrated
into one answer that can be sent back to the Di-
alogue Manager. For more details on the Domain
Knowledge Manager, see Flycht-Eriksson (2000).
</bodyText>
<subsectionHeader confidence="0.855824">
4.3 Communication between DM and
DKM
</subsectionHeader>
<bodyText confidence="0.999948444444444">
To illustrate how the Dialogue Manager (DM) and
the Domain Knowledge Manager (DKM) coop-
erates in processing of requests and handling of
clarifications, consider the hypothetical dialogue
shown in figure 6. The dialogue tree in figure 7
shows the resulting structure of the dialogue.
The first utterance, Ul, initiates a trip ISF. In-
formation about the arrival location provided by
the user is inserted in the ISF in the field Arr,
</bodyText>
<page confidence="0.98766">
126
</page>
<figure confidence="0.881566666666667">
IR1
UI IR2 IR4 IR5
S2 U5 S6 U7 S8 U9
IR3
U3 S4
S10
</figure>
<figureCaption confidence="0.999981">
Figure 7: The dialogue tree resulting from the dialogue in figure 6.
</figureCaption>
<bodyText confidence="0.993923833333333">
which results in the structure presented in figure 8
included in IR1 in the dialogue tree. The ISF indi-
cates that information about the departure place
and time has to be farther specified by the user
by the marker req in the fields Dep and TTime
(TravelTime).
</bodyText>
<figure confidence="0.9966263125">
Error
Area: City center 3
TooMany : BusStops
[ Up : 5]
SpecIn fo : {Point,
Landmark,
Street}
Status:
Item:
Type:
Solution:
Type: Trip
Arr : [ Area: City center
Dep: req.
TTime : req.
TType opt.
</figure>
<figureCaption confidence="0.999994">
Figure 8: The ISF in IR1 after processing of Ul.
</figureCaption>
<bodyText confidence="0.99796748">
However, before continuing the dialogue and
asking the user for the information that is miss-
ing in the ISF, the DM asks the DKM to validate
the provided values. This validation is performed
in order to detect vague or erroneous information
that might have been given by the user.
The arrival location in a trip ISF will be used to
find suitable bus stops that can be used to search
the time-table database. The validation of the
arrival location therefore means that the Spatial
Reasoning Agent tries to map the location to a
small set of bus stops. In this case it discovers
that Area: City Centre is a too vague description
since it corresponds to too many stops, in our case
more than 5 stops. The DM is informed of this and
is also given the information that more specific
information like a point, a landmark or a street is
required, figure 9. Thus, the user will not be asked
to provide the value of another parameter since it
would be an implicit confirmation that the arrival
place is correct, instead a new IR-unit, IR2 in the
dialogue tree, is created and a clarification, S2, is
initiated based on the information from the DKM
that indicates the problematic item, the type of
problem, and a possible solution to the problem.
</bodyText>
<figureCaption confidence="0.983447">
Figure 9: The response from the DKM to the do-
main validation of the arrival location.
</figureCaption>
<bodyText confidence="0.999034">
Instead of answering the system&apos;s question the
user takes the initiative by requesting new infor-
mation, U3. This request results in a new IR-unit,
IR3, to be inserted in the dialogue tree as a clar-
ification of the system&apos;s clarification in IR2, as
shown in figure 7. The utterance is a simple re-
quest and the DM utilises an OPM to model this,
figure 10.
</bodyText>
<equation confidence="0.636552333333333">
#1Stop : ?
Obj : #2 Landmark:
Prop: Near:
</equation>
<bodyText confidence="0.860655769230769">
Figure 10: The OPM in IRS after processing of
U3.
To answer this request means reasoning about
spatial relations between geographical objects.
The request is therefore sent to the DKM which
asks the Spatial Reasoning Agent for information.
The request is successfully processed and some
nearby bus stops are found and sent back to the
DM utilising the structure in figure 11. The DM
can then ask the generator to present them to the
user, S4.
Garden ill I
square
</bodyText>
<equation confidence="0.700735">
[Placel : #1 I
Place2 : #2
</equation>
<page confidence="0.755209">
127
</page>
<figure confidence="0.9527671875">
Success
- Name:
Id:
Name:
Id:
Name :
Id:
Centrum
Snickareg. 30
1268
Linnegatan
1220
Stora tor get
450
Status:
Stops:
</figure>
<note confidence="0.93356275">
Obj : Date: Day: 31
Prop: #1[ Month: April
Time: POD: lunch
[ TTime: Mod: before
</note>
<figureCaption confidence="0.995587">
Figure 14: The OPM in IR4 after processing of
</figureCaption>
<figure confidence="0.7528">
137.
1 I
</figure>
<figureCaption confidence="0.9832035">
Figure 11: The response from the DKM to the
OPM in IR3.
</figureCaption>
<bodyText confidence="0.9966748">
The user responds to this answer by confirming
his departure location, U5, and thereby responds
to the request S2 of IR2. He also provides an
arrival location. This new information is repre-
sented in the OPM of 1R2, figure 12.
</bodyText>
<equation confidence="0.687965">
#1Landmark :
#2 Landmark:
Arr : #1
Dep: #2
</equation>
<figureCaption confidence="0.8199">
Figure 12: The OPM in 1R2 after processing of
U5.
</figureCaption>
<bodyText confidence="0.998187272727273">
The DM resumes processing of the ISF in HU
and updates it with the arrival and departure loca-
tion based on the information in the OPM of IR2.
Information about the arrival location is added to
the previously provided information in the field
Arr. The new information about the departure
location is inserted in the field Dep, yielding the
structure in figure 13.
The new information from IRA is then inserted
as TTime in the ISF of IR1. This results in a fully
specified Trip ISF, figure 15.
</bodyText>
<figure confidence="0.9651598">
Trip
Area: Landmark: Garden square
City center I
Landmark: University 1
Date: Day : 31
T Month: April
POD: lunch
ime :
Mod: before
TType : opt.
</figure>
<figureCaption confidence="0.803331">
Fgure 15: The ISF of IR1 after updates with in-
formation from MA.
</figureCaption>
<bodyText confidence="0.999911625">
The ISF is again sent to the DKM for valida-
tion. When the Temporal Reasoning Agent tries
to map the temporal description in TTime to a
format suitable for time-table database search it
discovers the erroneous date. The DKM then re-
turns a response, figure 16, to the DM informing it
of the error. The DM initiates a new clarification
lR-unit, IR5, and a clarification is formulated, S8.
</bodyText>
<figure confidence="0.998169642857143">
Obj :
Prop:
Garden
square
University
Type:
Arr :
Dep:
TTime:
Area:
Dep: Landmark:
[
Lamark :
Landmark:
TTime: req.
TType : opt.
City center
Garden square
University
Type:
Arr :
Status: Error
Item: Date: [Day : 31
Month : April
Month : April
[Up: 30
Solution: SpecInfo : {Date}
Type: NotValid:
</figure>
<figureCaption confidence="0.937509">
Figure 13: The ISF in IR1 after updates with in-
formation from the subtree in IR2.
</figureCaption>
<bodyText confidence="0.9969009">
Again the DM asks the DKM for domain val-
idation of the partially specified LSF. Since both
locations can be mapped to a limited number of
bus stops the ISF is approved by the DKM. The
DM now needs to have a time to complete the
ISF, and consequently a new 1R-unit, IR4 in the
dialogue tree, is created and the user is, in utter-
ance S6, asked for this. The answer U7 is a valid
response to S6 and produces a new OPM, see fig-
ure 14.
</bodyText>
<figureCaption confidence="0.761057">
Figure 16: The response from the DKM to the
domain validation of the time description.
</figureCaption>
<bodyText confidence="0.910942">
Trip
The user responds to the system&apos;s clarification
request and provides a new date, U9. The re-
sponse is modelled in an OPM in IRS, figure 17.
</bodyText>
<figure confidence="0.790464">
[Obj : #1[ Date : [DaY 3°il ] ]
Month : Apr
Prop: [ TTime: #1
</figure>
<figureCaption confidence="0.995586">
Figure 17: The OPM of IRS after 139.
</figureCaption>
<page confidence="0.992014">
128
</page>
<bodyText confidence="0.9997592">
The information in the clarification request lit-
unit, IR5, is propagated to the ISF of IR1 which is
updated. This time the new information replaces
the old in TTime since it was erroneous. The re-
sulting ISF is presented in figure 18.
</bodyText>
<figure confidence="0.997983769230769">
Type: Trip
Arr
Area: Citycenter
:
Landmark: Gardens quare
Dep: I Landmark: University
[Day : 30
Trime : Date:
Month: April
POD: lunch
Time:
Mod: before
TT ype : opt.
</figure>
<figureCaption confidence="0.9948205">
Figure 18: The ISF of IR1 after integration with
the information in IR5.
</figureCaption>
<bodyText confidence="0.99964025">
Once more a validation of the ISF is performed
by the DKM. This time no problems are detected
and a search for suitable trips can finally be done.
The DKM does this by first asking the Spatial
Reasoning Agent to map the departure and arrival
locations to two sets of bus stops, then asking the
Temporal Reasoning Agent to map the vague tem-
poral description to a precise time interval. Given
this information the DKM then searches the time-
table database to find one or more trips that ful-
fill the requirements. The resulting trips are sent
back to the DM and displayed to the user, S10.
</bodyText>
<subsectionHeader confidence="0.935377">
4.4 Implementation
</subsectionHeader>
<bodyText confidence="0.999968375">
The MALIN dialogue system customised for the
traffic information application is currently un-
der development. The Dialogue Manager from
the LINLIN dialogue system architecture has been
adapted to allow also ISFs and we are currently
specifying the dialogue grammar and how to han-
dle focus tracking utilising ISFs and OPMs at the
same time.
The Domain Knowledge Manager is function-
al utilising a Spatial Reasoner for one sub-area
of Ostergotland and a Temporal Reasoner. The
Timetable Agent retrieves trip information from
the current Internet based timetables. Recipes
are developed for accessing these modules, but the
System and Help Information knowledge source is
not yet implemented.
</bodyText>
<sectionHeader confidence="0.9961" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999628793103448">
In this paper we have presented an architecture
for dialogue systems where a Domain Knowledge
Manager and a Dialogue Manager cooperate to
achieve natural interaction. Information provid-
ing dialogue systems based on this architecture
can handle a variety of requests; simple and com-
plex concerning the domain, and requests for sys-
tem related information.
Separating domain knowledge reasoning from
dialogue and task knowledge reasoning has a num-
ber of advantages. First of all, it is clearer what
the responsibilities and possibilities of the differ-
ent modules are, e.g. the dialogue manager han-
dles the dialogue and not domain reasoning. Fur-
thermore, it facilitates customisation to new ap-
plication domains. Another important feature is
that domain knowledge sources can easily be re-
placed, added, removed, and reused. This implies
that a system can be made more intelligent by
adding new domain agents without changing the
dialogue and task models.
Future challenges are to apply the proposed ar-
chitecture, utilising a Domain Knowledge Manag-
er, to other domains and types of dialogue sys-
tems, such as advisory or tutoring systems. For
such systems other knowledge sources like user
models and argumentation models are relevant
and have to be incorporated in the system archi-
tecture.
</bodyText>
<sectionHeader confidence="0.999567" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998405">
This work is supported by The Swedish Transport
Sc Communications Research Board (KFB) and
the Center for Industrial Information Technology
(CENIIT). We are indebted to Lars Degerstedt,
Hakan Johansson and Lena Santamarta for fruit-
ful discussions.
</bodyText>
<sectionHeader confidence="0.999256" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981383315789474">
John Aberdeen, Sam Bayer, Sasha Caskey,
Lauire Damianos, Alan Goldschen, Lynette
Hirschman, Dan Loehr, and Hugo Trappe.
1999. Implementing practical dialogue sys-
tems with the DARPA communicator architec-
ture. In Proceedings of IJCAI&apos;99 Workshop on
Knowledge and Reasoning in Practical Dialogue
Systems, August, Stockholm.
Lars Ahrenberg, Arne Jonsson, and Nils
Dahlback. 1990. Discourse representation
and discourse management for natural lan-
guage interfaces. In Proceedings of the Second
Nordic Conference on Tact Comprehension in
Man and Machine, Taby, Sweden.
Jan Alexandersson and Norbert Reithinger. 1995.
Designing the dialogue component in a speech
translation system. In Proceedings of the
Ninth Twente Workshop on Language Technol-
ogy (TWLT-9), pages 35-43.
</reference>
<page confidence="0.984837">
129
</page>
<reference confidence="0.998620615384616">
S. Bennacef, L. Devillers, S. Rosset, and L. Lamel.
1996. Dialog in the RAILTEL telephone-based
system. In Proceedings of International Con-
ference on Spoken Language Processing, IC-
SLP&apos;96, volume 1, pages 550-553, Philadelphia,
USA, October.
Harry C. Bunt. 1989. Information dialogues
as communicative action in relation to part-
ner modelling and information processing. In
M. M. Taylor, F. Neel, and D. G. Bouwhuis,
editors, The Structure of Multimodal Dialogue,
pages 47-73. Elsevier Science Publishers B.V.
(North-Holland).
Nils Dahlbic.k and Arne Jonsson. 1999. Knowl-
edge sources in spoken dialogue systems. In
Proceedings of Eurospeech&apos;99, Budapest, Hun-
gary.
Nils Dahlb5.ck. 1991. Representations of Dis-
course, Cognitive and Computational Aspects.
Ph.D. thesis, Linkoping University.
George Ferguson, James Allen, and Brad Miller.
1996. TRAINS-95: Towards a mixed-initiative
planning assistant. In Proceedings of the Third
Conference on Artificial Intelligence Planning
Systems, AIPS-96, pages 70-77.
Annika. Flycht-Eriksson and Arne J8nsson. 1998.
A spoken dialogue system utilizing spatial infor-
mation. In Proceedings of International Con-
ference on Spoken Language Processing, IC-
SLP&apos;98, page 1207, Sydney, Australia.
Annika Flycht-Eriksson. 1999. A survey of knowl-
edge sources in dialogue systems. In Proceed-
ings of IJCAP99 workshop on Knowledge and
Reasoning in Practical Dialogue Systems, Au-
gust, Stockholm, pages 41-48.
Annika Flycht-Eriksson. 2000. A domain knowl-
edge manager for dialogue systems. In Proceed-
ings of the 14th European Conference on Arti-
ficial Intelligence, ECAI 2000. IOS Press, Am-
sterdam.
Barbara J. Grosz and Candace L. Sidner. 1986.
Attention, intention and the structure of dis-
course. Computational Linguistics, 12(3):175-
204.
Eli Hagen. 1999. An approach to mixed initia-
tive spoken information retrieval dialogue. Us-
er modeling and User-Adapted Interaction, 9(1-
2):167-213.
Philip J. Hayes and D. Raj Reddy. 1983. Steps
toward graceful interaction in spoken and writ-
ten man-machine communication. Internation-
al Journal of Man-Machine Studies, 19:231-
284.
Arne Jonsson and Lena Stromback. 1998. Ro-
bust interaction through partial interpretation
and dialogue management. In Proceedings of
Coling / A CL &apos;98, Montréal.
Arne J8nsson. 1997. A model for habitable and
efficient dialogue management for natural lan-
guage interaction. Natural Language Engineer-
ing, 3(2/3):103-122.
Lynn Lambert and Sandra Carberry. 1991. A
tripartite plan-based model of dialogue. In Pro-
ceedings of the 29th Annual Meeting of the ACL,
Berkeley, pages 193-200.
David L. Martin, Adam J. Cheyer, and Douglas B.
Moran. 1999. The open agent architecture:
A framework for building distributed software
systems. Applied Artificial Intelligence, 13(1-
2):91-128, January-March.
Pernilla Qvarfordt. 1998. Usability of multi-
modal timetables: Effects of different levels of
domain knowledge on usability. Master&apos;s thesis,
Linkoping University.
Lance A. Ramshaw. 1991. A three-level model for
plan exploration. In Proceedings of the 29th An-
nual Meeting of the ACL, Berkeley, pages 39-
46.
Adelheit Stein, Jon Atle Gulla, and Ulrich Thiel.
1999. User-tailored planning of mixed initiative
information-seeking dialogues. User Modeling
and User-Adapted Interaction, (9):133-166.
Wim van Loo and Harry Bego. 1993. Agent tasks
and dialogue management. In Workshop on
Pragmatics in Dialogue, The XIV:th Scandina-
vian Conference of Linguistics and the VIII:th
Conference of Nordic and General Linguistics,
Gateborg, Sweden.
Wolfgang Wahlster and Alfred Kobsa. 1989. User
models in dialog systems. In User Models in
Dialog Systems. Springer-Verlag.
</reference>
<page confidence="0.997613">
130
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.226983">
<title confidence="0.99925">Dialogue and Domain Knowledge Management in Dialogue Systems</title>
<author confidence="0.805774">Flycht-Eriksson</author>
<affiliation confidence="0.804019">Department of Computer and Information Linkoping University, SE-581 83, LINKOPING,</affiliation>
<abstract confidence="0.970775333333333">annfl@ida.liu.se arnjo@ida.liu.se Abstract Intelligent dialogue systems must be able to respond properly to a variety of requests involving knowledge of the dialogue, the task at hand, and the domain. This requires advanced knowledge reasoning performed by various processing modules. We argue that it is important to understand the nature of the various reasoning mechanisms involved and to separate not only, for instance, interpretation, generation, and dialogue management but also domain knowledge and task reasoning. This facilitates portability of the dialogue system to new domains and makes it easier to enhance its capabilities. In this paper we will focus on the dialogue and domain knowledge reasoning components and show how they can cooperate to achieve natural interaction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Aberdeen</author>
<author>Sam Bayer</author>
<author>Sasha Caskey</author>
<author>Lauire Damianos</author>
<author>Alan Goldschen</author>
<author>Lynette Hirschman</author>
<author>Dan Loehr</author>
<author>Hugo Trappe</author>
</authors>
<title>Implementing practical dialogue systems with the DARPA communicator architecture.</title>
<date>1999</date>
<booktitle>In Proceedings of IJCAI&apos;99 Workshop on Knowledge and Reasoning in Practical Dialogue Systems,</booktitle>
<location>August, Stockholm.</location>
<contexts>
<context position="15135" citStr="Aberdeen et al., 1999" startWordPosition="2427" endWordPosition="2430">e returned to the Dialogue Manager. 4 MALIN In what follows we describe and exemplify a dialogue system with separate modules for dialogue management and domain knowledge management. The presentation will be based on the MALIN dialogue system architecture&apos;, figure 2, which has been used to implement an application for time-table information for local bus traffic in Ostergotland. One issue in the design of a dialogue system is how to control the various modules and the user interaction. In some systems there is no module responsible for the communication, instead a separate module, called hub (Aberdeen et al., 1999) or facilitator (Martin et al., 1999), is used for coordinating the modules and the internal information flow. Alternatively, the Dialogue Manager is the central unit of the system where the overall system behaviour is determined. The approach taken in MALIN is a combination where a Dialogue Manager is the central controller of the interaction and the Domain Knowledge Manager is based on an agent architecture. &apos;MALIN (Multi-modal Application of LINLIN) is a refinement of the LINLINsystem (Ahrenberg et al., 1990; Jonsson, 1997) to handle also multi-modal interaction and more advanced applicatio</context>
</contexts>
<marker>Aberdeen, Bayer, Caskey, Damianos, Goldschen, Hirschman, Loehr, Trappe, 1999</marker>
<rawString>John Aberdeen, Sam Bayer, Sasha Caskey, Lauire Damianos, Alan Goldschen, Lynette Hirschman, Dan Loehr, and Hugo Trappe. 1999. Implementing practical dialogue systems with the DARPA communicator architecture. In Proceedings of IJCAI&apos;99 Workshop on Knowledge and Reasoning in Practical Dialogue Systems, August, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Ahrenberg</author>
<author>Arne Jonsson</author>
<author>Nils Dahlback</author>
</authors>
<title>Discourse representation and discourse management for natural language interfaces.</title>
<date>1990</date>
<booktitle>In Proceedings of the Second Nordic Conference on Tact Comprehension in Man and Machine,</booktitle>
<location>Taby, Sweden.</location>
<contexts>
<context position="15651" citStr="Ahrenberg et al., 1990" startWordPosition="2513" endWordPosition="2516">no module responsible for the communication, instead a separate module, called hub (Aberdeen et al., 1999) or facilitator (Martin et al., 1999), is used for coordinating the modules and the internal information flow. Alternatively, the Dialogue Manager is the central unit of the system where the overall system behaviour is determined. The approach taken in MALIN is a combination where a Dialogue Manager is the central controller of the interaction and the Domain Knowledge Manager is based on an agent architecture. &apos;MALIN (Multi-modal Application of LINLIN) is a refinement of the LINLINsystem (Ahrenberg et al., 1990; Jonsson, 1997) to handle also multi-modal interaction and more advanced applications. 124 4.1 The Dialogue Manager In the MALIN dialogue model the dialogue is structured in terms of discourse segments, and a discourse segment in terms of moves and embedded segments. Utterances are analysed as linguistic objects which function as vehicles for atomic move segments. An initiative-response (IR) structure determines the compound discourse segments, where an initiative opens the IR-segment by introducing a new goal and the response closes the IR-segment (Dahlback, 1991). The discourse segments are</context>
</contexts>
<marker>Ahrenberg, Jonsson, Dahlback, 1990</marker>
<rawString>Lars Ahrenberg, Arne Jonsson, and Nils Dahlback. 1990. Discourse representation and discourse management for natural language interfaces. In Proceedings of the Second Nordic Conference on Tact Comprehension in Man and Machine, Taby, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Alexandersson</author>
<author>Norbert Reithinger</author>
</authors>
<title>Designing the dialogue component in a speech translation system.</title>
<date>1995</date>
<booktitle>In Proceedings of the Ninth Twente Workshop on Language Technology (TWLT-9),</booktitle>
<pages>35--43</pages>
<contexts>
<context position="16449" citStr="Alexandersson and Reithinger, 1995" startWordPosition="2637" endWordPosition="2641">ructured in terms of discourse segments, and a discourse segment in terms of moves and embedded segments. Utterances are analysed as linguistic objects which function as vehicles for atomic move segments. An initiative-response (IR) structure determines the compound discourse segments, where an initiative opens the IR-segment by introducing a new goal and the response closes the IR-segment (Dahlback, 1991). The discourse segments are classified by general speech act categories, such as question (Q) and answer (A) (Jonsson, 1997), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The action to carry out for the Dialogue Manager, as modeled in a dialogue grammar, depends on how domain entities are specified and their relation to other entities in the domain and the dialogue history. In the MALIN dialogue system architecture there is only one dialogue history maintained by the Dialogue Manager. Thus, the other modules in the system have no memory of the previous interaction since this could cause conflicts. The dialogue history records focal information, that is, what has been talked about and what is being talked about at the moment. It is used for dialogue control, d</context>
</contexts>
<marker>Alexandersson, Reithinger, 1995</marker>
<rawString>Jan Alexandersson and Norbert Reithinger. 1995. Designing the dialogue component in a speech translation system. In Proceedings of the Ninth Twente Workshop on Language Technology (TWLT-9), pages 35-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bennacef</author>
<author>L Devillers</author>
<author>S Rosset</author>
<author>L Lamel</author>
</authors>
<title>Dialog in the RAILTEL telephone-based system.</title>
<date>1996</date>
<booktitle>In Proceedings of International Conference on Spoken Language Processing, ICSLP&apos;96,</booktitle>
<volume>1</volume>
<pages>550--553</pages>
<location>Philadelphia, USA,</location>
<contexts>
<context position="10559" citStr="Bennacef et al. (1996)" startWordPosition="1705" endWordPosition="1708">, are carried out. A typical example of the difference between the two types of task models can be found in a time-table system where the user states that (s)he needs to be at the train station to catch a certain train and requests information on buses going there. The information that the user is going to the train station is user task model information, indicating that buses arriving after the departure time of the train are not relevant. The system task model on the other hand models the information required for complex requests, such as date and departure place in a time-table system (cf. Bennacef et al. (1996)). It is used by the Dialogue Manager when collecting user information in order to perform a background system access. In plan-based systems the domain models takes a similar role, but wider as they often also involves advanced problem solving. We will in this paper not consider user task models, only system task models. The Dialogue history records the focus of attention (Grosz and Sidner, 1986) and contains information about objects, properties, and relations as well as other dialogue information such as speech act information and system task information. 3.2 Domain Knowledge Management If a</context>
</contexts>
<marker>Bennacef, Devillers, Rosset, Lamel, 1996</marker>
<rawString>S. Bennacef, L. Devillers, S. Rosset, and L. Lamel. 1996. Dialog in the RAILTEL telephone-based system. In Proceedings of International Conference on Spoken Language Processing, ICSLP&apos;96, volume 1, pages 550-553, Philadelphia, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry C Bunt</author>
</authors>
<title>Information dialogues as communicative action in relation to partner modelling and information processing.</title>
<date>1989</date>
<booktitle>The Structure of Multimodal Dialogue,</booktitle>
<pages>47--73</pages>
<editor>In M. M. Taylor, F. Neel, and D. G. Bouwhuis, editors,</editor>
<publisher>Elsevier Science Publishers B.V. (North-Holland).</publisher>
<contexts>
<context position="2589" citStr="Bunt (1989)" startWordPosition="400" endWordPosition="401">s it differs from the information retrieval problem discussed for instance in Stein et al. (1999). We assume that the tasks are well-defined and that the users have articulated information needs that they can express in specific terms. In this paper we will discuss how these different tasks can be performed in dialogue systems of simple service character, i.e. dialogue systems that can provide information given a set of parameters collected from the user (Hayes and Reddy, 1983). 2 Types of requests and clarifications Users interacting with a dialogue system utilise various communicative acts. Bunt (1989) makes a distinction between factual information acts and dialogue control acts. The latter is used to control the dialogue and the former involves any transfer of factual information. Factual information requests can be further divided into two basic types of requests: • Task related requests. Requests where the response from the dialogue system includes domain and task specific information • System related requests. Requests where the response includes information on what can be done with the system or pointers to other information sources To be able to respond to questions on the system&apos;s c</context>
</contexts>
<marker>Bunt, 1989</marker>
<rawString>Harry C. Bunt. 1989. Information dialogues as communicative action in relation to partner modelling and information processing. In M. M. Taylor, F. Neel, and D. G. Bouwhuis, editors, The Structure of Multimodal Dialogue, pages 47-73. Elsevier Science Publishers B.V. (North-Holland).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Dahlbic k</author>
<author>Arne Jonsson</author>
</authors>
<title>Knowledge sources in spoken dialogue systems.</title>
<date>1999</date>
<booktitle>In Proceedings of Eurospeech&apos;99,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="9661" citStr="k and Jonsson, 1999" startWordPosition="1545" endWordPosition="1548">rthermore, plan-based systems use plan operators to model not only dialogue knowledge but also task, domain and meta knowledge (c.f. Lambert and Carberry (1991), Ramshaw (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieved (c.f. Wahlster and Kobsa (1989)). Models of system tasks describe how the system&apos;s communicative and other tasks, e.g. database access, are carried out. A typical example of the difference between the two types of task models can be found in a time-table system where the user states that (s)he needs to be at the train station to catch a certain train and requests information on buses going there. The information that the user is going to the train statio</context>
<context position="18210" citStr="k and Jonsson, 1999" startWordPosition="2912" endWordPosition="2915"> are application dependent. We also utilise Markers for various purposes (Jonsson and Stromback, 1998), but they will not be further discussed in this paper. Structures that represent information about objects and properties (and markers) are termed OPMs. Figure 3 shows an example OPM which represents the request Which bus lines passes the North gate?. For complex requests the Dialogue Manager needs an information structure that holds the parameters needed before successful access of the background system can be performed. We call such structures Information Specification Forms (ISFs) (Dahlback and Jonsson, 1999). Just like OPMs the ISFs are application dependent and be[Obj : #1[ Busline: ? ] #2{ Stop: North gate ] Prop: [ PassesBy : Line: #11] [Stop: #2 sides holding information they are also used as system task models, i.e. to inform the Dialogue Manager which parameters that has to be provided by the user. We have identified a number of different user information needs (Qvarfordt, 1998) for which ISFs are needed. The most common, called trip information, occurs when the user needs to know how and when on a particular day, most often the present day, one can travel from one point to another in town </context>
</contexts>
<marker>k, Jonsson, 1999</marker>
<rawString>Nils Dahlbic.k and Arne Jonsson. 1999. Knowledge sources in spoken dialogue systems. In Proceedings of Eurospeech&apos;99, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Dahlb5 ck</author>
</authors>
<title>Representations of Discourse, Cognitive and Computational Aspects.</title>
<date>1991</date>
<tech>Ph.D. thesis,</tech>
<institution>Linkoping University.</institution>
<contexts>
<context position="16223" citStr="ck, 1991" startWordPosition="2605" endWordPosition="2606"> LINLINsystem (Ahrenberg et al., 1990; Jonsson, 1997) to handle also multi-modal interaction and more advanced applications. 124 4.1 The Dialogue Manager In the MALIN dialogue model the dialogue is structured in terms of discourse segments, and a discourse segment in terms of moves and embedded segments. Utterances are analysed as linguistic objects which function as vehicles for atomic move segments. An initiative-response (IR) structure determines the compound discourse segments, where an initiative opens the IR-segment by introducing a new goal and the response closes the IR-segment (Dahlback, 1991). The discourse segments are classified by general speech act categories, such as question (Q) and answer (A) (Jonsson, 1997), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The action to carry out for the Dialogue Manager, as modeled in a dialogue grammar, depends on how domain entities are specified and their relation to other entities in the domain and the dialogue history. In the MALIN dialogue system architecture there is only one dialogue history maintained by the Dialogue Manager. Thus, the other modules in the system have no memory </context>
</contexts>
<marker>ck, 1991</marker>
<rawString>Nils Dahlb5.ck. 1991. Representations of Discourse, Cognitive and Computational Aspects. Ph.D. thesis, Linkoping University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James Allen</author>
<author>Brad Miller</author>
</authors>
<title>TRAINS-95: Towards a mixed-initiative planning assistant.</title>
<date>1996</date>
<booktitle>In Proceedings of the Third Conference on Artificial Intelligence Planning Systems, AIPS-96,</booktitle>
<pages>70--77</pages>
<contexts>
<context position="9241" citStr="Ferguson et al. (1996)" startWordPosition="1474" endWordPosition="1477">ppropriate at a given dialogue state. There are various proposals on dialogue models which can be divided in two groups: intention-based and structurally based. They differ in how they model the dialogue, especially if the user&apos;s goals and intentions behind the utterance need to be captured or not. Structurally based models are often controlled using a dialogue grammar whereas intention-based utilise plan operators. Furthermore, plan-based systems use plan operators to model not only dialogue knowledge but also task, domain and meta knowledge (c.f. Lambert and Carberry (1991), Ramshaw (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieved (c.f. Wahlster and Kobsa (1989)). Mode</context>
</contexts>
<marker>Ferguson, Allen, Miller, 1996</marker>
<rawString>George Ferguson, James Allen, and Brad Miller. 1996. TRAINS-95: Towards a mixed-initiative planning assistant. In Proceedings of the Third Conference on Artificial Intelligence Planning Systems, AIPS-96, pages 70-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flycht-Eriksson</author>
<author>Arne J8nsson</author>
</authors>
<title>A spoken dialogue system utilizing spatial information.</title>
<date>1998</date>
<booktitle>In Proceedings of International Conference on Spoken Language Processing, ICSLP&apos;98,</booktitle>
<pages>1207</pages>
<location>Sydney, Australia.</location>
<marker>Flycht-Eriksson, J8nsson, 1998</marker>
<rawString>Annika. Flycht-Eriksson and Arne J8nsson. 1998. A spoken dialogue system utilizing spatial information. In Proceedings of International Conference on Spoken Language Processing, ICSLP&apos;98, page 1207, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annika Flycht-Eriksson</author>
</authors>
<title>A survey of knowledge sources in dialogue systems.</title>
<date>1999</date>
<booktitle>In Proceedings of IJCAP99 workshop on Knowledge and Reasoning in Practical Dialogue Systems,</booktitle>
<pages>41--48</pages>
<location>August, Stockholm,</location>
<contexts>
<context position="7390" citStr="Flycht-Eriksson (1999)" startWordPosition="1174" endWordPosition="1175">hree different ways: inform the user of the problem giving as helpful information as possible, find near misses by relaxing some of the features in the description, or find and inform the user of faulty presuppositions. 3 Dialogue system architectures Dialogue systems often have a modular architecture with processing modules for interpretation, dialogue management, background system access, and generation, see figure 1. The processing modules utilise a number of knowledge sources, such as, grammar, lexicon, dialogue mod122 el, domain model, and task model (for an overview of some systems, see Flycht-Eriksson (1999)). In this paper focus is on dialogue management and domain knowledge management, which includes background system access. 3.1 Dialogue management The role of the Dialogue Manager differs slightly between different dialogue system architectures, but it&apos;s primary responsibility is to control the flow of the dialogue by deciding how the system should respond to a user utterance. This is done by inspecting and contextually specifying the information structure produced by an interpretation module. If some information is missing or a request is ambiguous, clarification questions are specified by th</context>
</contexts>
<marker>Flycht-Eriksson, 1999</marker>
<rawString>Annika Flycht-Eriksson. 1999. A survey of knowledge sources in dialogue systems. In Proceedings of IJCAP99 workshop on Knowledge and Reasoning in Practical Dialogue Systems, August, Stockholm, pages 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annika Flycht-Eriksson</author>
</authors>
<title>A domain knowledge manager for dialogue systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the 14th European Conference on Artificial Intelligence, ECAI</booktitle>
<publisher>IOS Press,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="23176" citStr="Flycht-Eriksson (2000)" startWordPosition="3748" endWordPosition="3749">he Domain Knowledge Manager has to decide how to treat the request, i.e. to produce one or more recipes. In most cases one recipe is enough, but sometimes the user has provided ambiguous information that cannot be resolved by the interpreter or the Dialogue Manager, in which cases several recipes are needed. The next step is to process the recipe(s). The processing must be carefully monitored and aborted if an error occurs. Finally, alternatives must be inspected and integrated into one answer that can be sent back to the Dialogue Manager. For more details on the Domain Knowledge Manager, see Flycht-Eriksson (2000). 4.3 Communication between DM and DKM To illustrate how the Dialogue Manager (DM) and the Domain Knowledge Manager (DKM) cooperates in processing of requests and handling of clarifications, consider the hypothetical dialogue shown in figure 6. The dialogue tree in figure 7 shows the resulting structure of the dialogue. The first utterance, Ul, initiates a trip ISF. Information about the arrival location provided by the user is inserted in the ISF in the field Arr, 126 IR1 UI IR2 IR4 IR5 S2 U5 S6 U7 S8 U9 IR3 U3 S4 S10 Figure 7: The dialogue tree resulting from the dialogue in figure 6. which </context>
</contexts>
<marker>Flycht-Eriksson, 2000</marker>
<rawString>Annika Flycht-Eriksson. 2000. A domain knowledge manager for dialogue systems. In Proceedings of the 14th European Conference on Artificial Intelligence, ECAI 2000. IOS Press, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intention and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="10958" citStr="Grosz and Sidner, 1986" startWordPosition="1772" endWordPosition="1775"> departure time of the train are not relevant. The system task model on the other hand models the information required for complex requests, such as date and departure place in a time-table system (cf. Bennacef et al. (1996)). It is used by the Dialogue Manager when collecting user information in order to perform a background system access. In plan-based systems the domain models takes a similar role, but wider as they often also involves advanced problem solving. We will in this paper not consider user task models, only system task models. The Dialogue history records the focus of attention (Grosz and Sidner, 1986) and contains information about objects, properties, and relations as well as other dialogue information such as speech act information and system task information. 3.2 Domain Knowledge Management If a request is fully specified it can be used to retrieve the desired information from a background system. This task is seldom discussed in literature on dialogue systems, perhaps because it is considered a rather straight forward task. There are, however, several problems related to this. For example, in cases where the background system is distributed and consists of several domain and applicatio</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intention and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eli Hagen</author>
</authors>
<title>An approach to mixed initiative spoken information retrieval dialogue. User modeling and User-Adapted Interaction,</title>
<date>1999</date>
<pages>9--1</pages>
<contexts>
<context position="9433" citStr="Hagen, 1999" startWordPosition="1507" endWordPosition="1508">e, especially if the user&apos;s goals and intentions behind the utterance need to be captured or not. Structurally based models are often controlled using a dialogue grammar whereas intention-based utilise plan operators. Furthermore, plan-based systems use plan operators to model not only dialogue knowledge but also task, domain and meta knowledge (c.f. Lambert and Carberry (1991), Ramshaw (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieved (c.f. Wahlster and Kobsa (1989)). Models of system tasks describe how the system&apos;s communicative and other tasks, e.g. database access, are carried out. A typical example of the difference between the two types of task models can </context>
<context position="16392" citStr="Hagen, 1999" startWordPosition="2632" endWordPosition="2633"> dialogue model the dialogue is structured in terms of discourse segments, and a discourse segment in terms of moves and embedded segments. Utterances are analysed as linguistic objects which function as vehicles for atomic move segments. An initiative-response (IR) structure determines the compound discourse segments, where an initiative opens the IR-segment by introducing a new goal and the response closes the IR-segment (Dahlback, 1991). The discourse segments are classified by general speech act categories, such as question (Q) and answer (A) (Jonsson, 1997), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The action to carry out for the Dialogue Manager, as modeled in a dialogue grammar, depends on how domain entities are specified and their relation to other entities in the domain and the dialogue history. In the MALIN dialogue system architecture there is only one dialogue history maintained by the Dialogue Manager. Thus, the other modules in the system have no memory of the previous interaction since this could cause conflicts. The dialogue history records focal information, that is, what has been talked about and what is being talke</context>
</contexts>
<marker>Hagen, 1999</marker>
<rawString>Eli Hagen. 1999. An approach to mixed initiative spoken information retrieval dialogue. User modeling and User-Adapted Interaction, 9(1-2):167-213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Hayes</author>
<author>D Raj Reddy</author>
</authors>
<title>Steps toward graceful interaction in spoken and written man-machine communication.</title>
<date>1983</date>
<journal>International Journal of Man-Machine Studies,</journal>
<pages>19--231</pages>
<contexts>
<context position="2460" citStr="Hayes and Reddy, 1983" startWordPosition="380" endWordPosition="383">ecise meaning of a request and produce an appropriate response. However, although the dialogue system gather information from various sources it differs from the information retrieval problem discussed for instance in Stein et al. (1999). We assume that the tasks are well-defined and that the users have articulated information needs that they can express in specific terms. In this paper we will discuss how these different tasks can be performed in dialogue systems of simple service character, i.e. dialogue systems that can provide information given a set of parameters collected from the user (Hayes and Reddy, 1983). 2 Types of requests and clarifications Users interacting with a dialogue system utilise various communicative acts. Bunt (1989) makes a distinction between factual information acts and dialogue control acts. The latter is used to control the dialogue and the former involves any transfer of factual information. Factual information requests can be further divided into two basic types of requests: • Task related requests. Requests where the response from the dialogue system includes domain and task specific information • System related requests. Requests where the response includes information </context>
<context position="6166" citStr="Hayes and Reddy, 1983" startWordPosition="976" endWordPosition="979">cations, such as the ATIS dialogues. To answer requests on a trip, the system needs to have a number of parameters specified, such as departure and arrival time and place, before it is able to access the timetables. However, for such systems there are also simple requests that can be directly mapped to a request from the background system, for instance, requests regarding meals on a flight that can be identified by a flight number, e.g. Is breakfast served on flight SK2818?. Since requests are specified by a set of entities the system needs capabilities to identify entities from descriptions (Hayes and Reddy, 1983). An attempt to map a description to an entity can have three different outcomes, a unique entity is found, the description is ambiguous and corresponds to several objects, or the description is unsatisfiable and no matching object can be found. There exist several strategies to deal with these problems, but all of them include some clarification from the user or domain reasoning. In dealing with ambiguous descriptions the system should be able to provide options or find a distinguishing feature that can be used to ask the user for clarification. Unsatisfiable descriptions can be dealt with in</context>
</contexts>
<marker>Hayes, Reddy, 1983</marker>
<rawString>Philip J. Hayes and D. Raj Reddy. 1983. Steps toward graceful interaction in spoken and written man-machine communication. International Journal of Man-Machine Studies, 19:231-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne Jonsson</author>
<author>Lena Stromback</author>
</authors>
<title>Robust interaction through partial interpretation and dialogue management.</title>
<date>1998</date>
<booktitle>In Proceedings of Coling / A CL &apos;98,</booktitle>
<location>Montréal.</location>
<contexts>
<context position="17692" citStr="Jonsson and Stromback, 1998" startWordPosition="2833" endWordPosition="2836">f context dependent utterances, and context sensitive interpretation. The dialogue history is represented as a dialogue tree. The nodes in the dialogue tree record information utilising various information structures depending on the application. For simple information requests we have identified two important concepts, termed Objects and Properties (Jonsson, 1997) where Objects models the set of objects in the database and Properties denotes a complex predicate ascribed to this set. The parameters Objects and Properties are application dependent. We also utilise Markers for various purposes (Jonsson and Stromback, 1998), but they will not be further discussed in this paper. Structures that represent information about objects and properties (and markers) are termed OPMs. Figure 3 shows an example OPM which represents the request Which bus lines passes the North gate?. For complex requests the Dialogue Manager needs an information structure that holds the parameters needed before successful access of the background system can be performed. We call such structures Information Specification Forms (ISFs) (Dahlback and Jonsson, 1999). Just like OPMs the ISFs are application dependent and be[Obj : #1[ Busline: ? ] </context>
</contexts>
<marker>Jonsson, Stromback, 1998</marker>
<rawString>Arne Jonsson and Lena Stromback. 1998. Robust interaction through partial interpretation and dialogue management. In Proceedings of Coling / A CL &apos;98, Montréal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne J8nsson</author>
</authors>
<title>A model for habitable and efficient dialogue management for natural language interaction.</title>
<date>1997</date>
<journal>Natural Language Engineering,</journal>
<pages>3--2</pages>
<marker>J8nsson, 1997</marker>
<rawString>Arne J8nsson. 1997. A model for habitable and efficient dialogue management for natural language interaction. Natural Language Engineering, 3(2/3):103-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Lambert</author>
<author>Sandra Carberry</author>
</authors>
<title>A tripartite plan-based model of dialogue.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the ACL,</booktitle>
<pages>193--200</pages>
<publisher>Berkeley,</publisher>
<contexts>
<context position="9201" citStr="Lambert and Carberry (1991)" startWordPosition="1468" endWordPosition="1471">nd 2) deciding what communicative action is appropriate at a given dialogue state. There are various proposals on dialogue models which can be divided in two groups: intention-based and structurally based. They differ in how they model the dialogue, especially if the user&apos;s goals and intentions behind the utterance need to be captured or not. Structurally based models are often controlled using a dialogue grammar whereas intention-based utilise plan operators. Furthermore, plan-based systems use plan operators to model not only dialogue knowledge but also task, domain and meta knowledge (c.f. Lambert and Carberry (1991), Ramshaw (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieve</context>
</contexts>
<marker>Lambert, Carberry, 1991</marker>
<rawString>Lynn Lambert and Sandra Carberry. 1991. A tripartite plan-based model of dialogue. In Proceedings of the 29th Annual Meeting of the ACL, Berkeley, pages 193-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Martin</author>
<author>Adam J Cheyer</author>
<author>Douglas B Moran</author>
</authors>
<title>The open agent architecture: A framework for building distributed software systems.</title>
<date>1999</date>
<journal>Applied Artificial Intelligence,</journal>
<pages>13--1</pages>
<location>January-March.</location>
<contexts>
<context position="15172" citStr="Martin et al., 1999" startWordPosition="2433" endWordPosition="2436">ALIN In what follows we describe and exemplify a dialogue system with separate modules for dialogue management and domain knowledge management. The presentation will be based on the MALIN dialogue system architecture&apos;, figure 2, which has been used to implement an application for time-table information for local bus traffic in Ostergotland. One issue in the design of a dialogue system is how to control the various modules and the user interaction. In some systems there is no module responsible for the communication, instead a separate module, called hub (Aberdeen et al., 1999) or facilitator (Martin et al., 1999), is used for coordinating the modules and the internal information flow. Alternatively, the Dialogue Manager is the central unit of the system where the overall system behaviour is determined. The approach taken in MALIN is a combination where a Dialogue Manager is the central controller of the interaction and the Domain Knowledge Manager is based on an agent architecture. &apos;MALIN (Multi-modal Application of LINLIN) is a refinement of the LINLINsystem (Ahrenberg et al., 1990; Jonsson, 1997) to handle also multi-modal interaction and more advanced applications. 124 4.1 The Dialogue Manager In t</context>
</contexts>
<marker>Martin, Cheyer, Moran, 1999</marker>
<rawString>David L. Martin, Adam J. Cheyer, and Douglas B. Moran. 1999. The open agent architecture: A framework for building distributed software systems. Applied Artificial Intelligence, 13(1-2):91-128, January-March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pernilla Qvarfordt</author>
</authors>
<title>Usability of multimodal timetables: Effects of different levels of domain knowledge on usability. Master&apos;s thesis,</title>
<date>1998</date>
<institution>Linkoping University.</institution>
<contexts>
<context position="18594" citStr="Qvarfordt, 1998" startWordPosition="2985" endWordPosition="2986"> Manager needs an information structure that holds the parameters needed before successful access of the background system can be performed. We call such structures Information Specification Forms (ISFs) (Dahlback and Jonsson, 1999). Just like OPMs the ISFs are application dependent and be[Obj : #1[ Busline: ? ] #2{ Stop: North gate ] Prop: [ PassesBy : Line: #11] [Stop: #2 sides holding information they are also used as system task models, i.e. to inform the Dialogue Manager which parameters that has to be provided by the user. We have identified a number of different user information needs (Qvarfordt, 1998) for which ISFs are needed. The most common, called trip information, occurs when the user needs to know how and when on a particular day, most often the present day, one can travel from one point to another in town by bus. An ISF for such requests model information on departure and arrival destinations and information on arrival and/or departure time, which is required information. The user can also give information about the travel type, but this is optional. Figure 4 shows an empty Trip ISF. Type: Arr : Dep: TTime: TType : Figure4: An empty trip ISF. Another common information need, called </context>
</contexts>
<marker>Qvarfordt, 1998</marker>
<rawString>Pernilla Qvarfordt. 1998. Usability of multimodal timetables: Effects of different levels of domain knowledge on usability. Master&apos;s thesis, Linkoping University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
</authors>
<title>A three-level model for plan exploration.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the ACL,</booktitle>
<pages>39--46</pages>
<publisher>Berkeley,</publisher>
<contexts>
<context position="9217" citStr="Ramshaw (1991)" startWordPosition="1472" endWordPosition="1473">tive action is appropriate at a given dialogue state. There are various proposals on dialogue models which can be divided in two groups: intention-based and structurally based. They differ in how they model the dialogue, especially if the user&apos;s goals and intentions behind the utterance need to be captured or not. Structurally based models are often controlled using a dialogue grammar whereas intention-based utilise plan operators. Furthermore, plan-based systems use plan operators to model not only dialogue knowledge but also task, domain and meta knowledge (c.f. Lambert and Carberry (1991), Ramshaw (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieved (c.f. Wahlster</context>
</contexts>
<marker>Ramshaw, 1991</marker>
<rawString>Lance A. Ramshaw. 1991. A three-level model for plan exploration. In Proceedings of the 29th Annual Meeting of the ACL, Berkeley, pages 39-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adelheit Stein</author>
<author>Jon Atle Gulla</author>
<author>Ulrich Thiel</author>
</authors>
<title>User-tailored planning of mixed initiative information-seeking dialogues. User Modeling and User-Adapted Interaction,</title>
<date>1999</date>
<pages>9--133</pages>
<contexts>
<context position="2075" citStr="Stein et al. (1999)" startWordPosition="316" endWordPosition="319"> only requests for information from application specific knowledge sources, but also requests related to the properties and structures of the application and requests that are outside the scope of the application. Thus, dialogue systems must be able to access, gather and integrate knowledge from various domain knowledge sources and application systems in order to determine the precise meaning of a request and produce an appropriate response. However, although the dialogue system gather information from various sources it differs from the information retrieval problem discussed for instance in Stein et al. (1999). We assume that the tasks are well-defined and that the users have articulated information needs that they can express in specific terms. In this paper we will discuss how these different tasks can be performed in dialogue systems of simple service character, i.e. dialogue systems that can provide information given a set of parameters collected from the user (Hayes and Reddy, 1983). 2 Types of requests and clarifications Users interacting with a dialogue system utilise various communicative acts. Bunt (1989) makes a distinction between factual information acts and dialogue control acts. The l</context>
</contexts>
<marker>Stein, Gulla, Thiel, 1999</marker>
<rawString>Adelheit Stein, Jon Atle Gulla, and Ulrich Thiel. 1999. User-tailored planning of mixed initiative information-seeking dialogues. User Modeling and User-Adapted Interaction, (9):133-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim van Loo</author>
<author>Harry Bego</author>
</authors>
<title>Agent tasks and dialogue management.</title>
<date>1993</date>
<booktitle>In Workshop on Pragmatics in Dialogue, The XIV:th Scandinavian Conference of Linguistics and the VIII:th Conference of Nordic and General Linguistics,</booktitle>
<location>Gateborg,</location>
<marker>van Loo, Bego, 1993</marker>
<rawString>Wim van Loo and Harry Bego. 1993. Agent tasks and dialogue management. In Workshop on Pragmatics in Dialogue, The XIV:th Scandinavian Conference of Linguistics and the VIII:th Conference of Nordic and General Linguistics, Gateborg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
<author>Alfred Kobsa</author>
</authors>
<title>User models in dialog systems. In User Models in Dialog Systems.</title>
<date>1989</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="9834" citStr="Wahlster and Kobsa (1989)" startWordPosition="1576" endWordPosition="1579">w (1991), Ferguson et al. (1996)). This allows for plan recognition to be the only processing mechanism needed. The System Task model represents how the system&apos;s tasks are performed, cf. Application Description (Hagen, 1999). However, the terms task and task model can refer to very different phenomena. It is important to make a clear distinction between the system&apos;s task(s) and the user&apos;s task(s) (van Loo and Bego, 1993; Dahlback and Jonsson, 1999). A user task is non-linguistic and takes place in the real world. Models of such tasks involve the user&apos;s goals and how they can be achieved (c.f. Wahlster and Kobsa (1989)). Models of system tasks describe how the system&apos;s communicative and other tasks, e.g. database access, are carried out. A typical example of the difference between the two types of task models can be found in a time-table system where the user states that (s)he needs to be at the train station to catch a certain train and requests information on buses going there. The information that the user is going to the train station is user task model information, indicating that buses arriving after the departure time of the train are not relevant. The system task model on the other hand models the i</context>
</contexts>
<marker>Wahlster, Kobsa, 1989</marker>
<rawString>Wolfgang Wahlster and Alfred Kobsa. 1989. User models in dialog systems. In User Models in Dialog Systems. Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>