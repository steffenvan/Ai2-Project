<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001822">
<title confidence="0.994242">
Semantic Roles for String to Tree Machine Translation
</title>
<author confidence="0.993227">
Marzieh Bazrafshan and Daniel Gildea
</author>
<affiliation confidence="0.9964825">
Department of Computer Science
University of Rochester
</affiliation>
<address confidence="0.278985">
Rochester, NY 14627
</address>
<sectionHeader confidence="0.96188" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999647">
We experiment with adding semantic role
information to a string-to-tree machine
translation system based on the rule ex-
traction procedure of Galley et al. (2004).
We compare methods based on augment-
ing the set of nonterminals by adding se-
mantic role labels, and altering the rule
extraction process to produce a separate
set of rules for each predicate that encom-
pass its entire predicate-argument struc-
ture. Our results demonstrate that the sec-
ond approach is effective in increasing the
quality of translations.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939321428572">
Statistical machine translation (SMT) has made
considerable advances in using syntactic proper-
ties of languages in both the training and the de-
coding of translation systems. Over the past few
years, many researchers have started to realize that
incorporating semantic features of languages can
also be effective in increasing the quality of trans-
lations, as they can model relationships that often
are not derivable from syntactic structures.
Wu and Fung (2009) demonstrated the promise
of using features based on semantic predicate-
argument structure in machine translation, using
these feature to re-rank machine translation out-
put. In general, re-ranking approaches are lim-
ited by the set of translation hypotheses, leading
to a desire to incorporate semantic features into
the translation model used during MT decoding.
Liu and Gildea (2010) introduced two types of
semantic features for tree-to-string machine trans-
lation. These features model the reorderings and
deletions of the semantic roles in the source sen-
tence during decoding. They showed that addition
of these semantic features helps improve the qual-
ity of translations. Since tree-to-string systems are
trained on parse trees, they are constrained by the
tree structures and are generally outperformed by
string-to-tree systems.
Xiong et al. (2012) integrated two discrimi-
native feature-based models into a phrase-based
SMT system, which used the semantic predicate-
argument structure of the source language. Their
first model defined features based on the context of
a verbal predicate, to predict the target translation
for that verb. Their second model predicted the re-
ordering direction between a predicate and its ar-
guments from the source to the target sentence.
Wu et al. (2010) use a head-driven phrase struc-
ture grammar (HPSG) parser to add semantic rep-
resentations to their translation rules.
In this paper, we use semantic role labels to en-
rich a string-to-tree translation system, and show
that this approach can increase the BLEU (Pap-
ineni et al., 2002) score of the translations. We
extract GHKM-style (Galley et al., 2004) transla-
tion rules from training data where the target side
has been parsed and labeled with semantic roles.
Our general method of adding information to the
syntactic tree is similar to the “tree grafting” ap-
proach of Baker et al. (2010), although we fo-
cus on predicate-argument structure, rather than
named entity tags and modality. We modify the
rule extraction procedure of Galley et al. (2004) to
produce rules representing the overall predicate-
argument structure of each verb, allowing us to
model alternations in the mapping from syntax to
semantics of the type described by Levin (1993).
</bodyText>
<sectionHeader confidence="0.996052" genericHeader="method">
2 Semantic Roles for String-to-Tree
Translation
</sectionHeader>
<subsectionHeader confidence="0.999223">
2.1 Semantic Role Labeling
</subsectionHeader>
<bodyText confidence="0.99920625">
Semantic Role Labeling (SRL) is the task of iden-
tifying the arguments of the predicates in a sen-
tence, and classifying them into different argu-
ment labels. Semantic roles can provide a level
</bodyText>
<page confidence="0.983246">
419
</page>
<bodyText confidence="0.92349595">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 419–423,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
of understanding that cannot be derived from syn-
tactic analysis of a sentence. For example, in
sentences “Ali opened the door.” and “The door
opened”, the word door has two different syntac-
tic roles but only one semantic role in the two sen-
tences.
Semantic arguments can be classified into core
and non-core arguments (Palmer et al., 2010).
Core arguments are necessary for understanding
the sentence. Non-core arguments add more infor-
mation about the predicate but are not essential.
Automatic semantic role labelers have been de-
veloped by training classifiers on hand annotated
data (Gildea and Jurafsky, 2000; Srikumar and
Roth, 2011; Toutanova et al., 2005; F¨urstenau and
Lapata, 2012). State-of-the-art semantic role la-
belers can predict the labels with accuracies of
around 90%.
</bodyText>
<subsectionHeader confidence="0.994309">
2.2 String-to-Tree Translation
</subsectionHeader>
<bodyText confidence="0.999985555555555">
We adopt the GHKM framework of Galley et al.
(2004) using the parses produced by the split-
merge parser of Petrov et al. (2006) as the English
trees. As shown by Wang et al. (2010), the refined
nonterminals produced by the split-merge method
can aid machine translation. Furthermore, in all
of our experiments, we exclude unary rules during
extraction by ensuring that no rules will have the
same span in the source side (Chung et al., 2011).
</bodyText>
<subsectionHeader confidence="0.999703">
2.3 Using Semantic Role Labels in SMT
</subsectionHeader>
<bodyText confidence="0.9827025">
To incorporate semantic information into a string-
to-tree SMT system, we tried two approaches:
</bodyText>
<listItem confidence="0.958139">
• Using semantically enriched GHKM rules,
and
• Extracting semantic rules separately from the
regular GHKM rules, and adding a new fea-
</listItem>
<bodyText confidence="0.875745333333333">
ture for distinguishing the semantic rules.
The next two sections will explain these two
methods in detail.
</bodyText>
<subsectionHeader confidence="0.99913">
2.4 Semantically Enriched Rules (Method 1)
</subsectionHeader>
<bodyText confidence="0.999953714285714">
In this method, we tag the target trees in the train-
ing corpus with semantic role labels, and extract
the translation rules from the tagged corpus. Since
the SCFG rule extraction methods do not assume
any specific set of non-terminals for the target
parse trees, we can attach the semantic roles of
each constituent to its label in the tree, and use
</bodyText>
<figure confidence="0.9961455">
S
a hand
</figure>
<figureCaption confidence="0.98124775">
Figure 1: A target tree after inserting semantic
roles. “Lending” is the predicate, “everybody” is
argument 0, and “a hand” is argument 1 for the
predicate.
</figureCaption>
<figure confidence="0.903424">
S-8
NP-7-ARG1 1 victimized by NP-7-ARG0 2
</figure>
<figureCaption confidence="0.99974">
Figure 2: A complete semantic rule.
</figureCaption>
<bodyText confidence="0.999980666666667">
these new labels for rule extraction. We only la-
bel the core arguments of each predicate, to make
sure that the rules are not too specific to the train-
ing data. We attach each semantic label to the root
of the subtree that it is labeling. Figure 1 shows
an example target tree after attaching the semantic
roles. We then run a GHKM rule extractor on the
labeled training corpus and use the semantically
enriched rules with a syntax-based decoder.
</bodyText>
<subsectionHeader confidence="0.9951085">
2.5 Complete Semantic Rules with Added
Feature (Method 2)
</subsectionHeader>
<bodyText confidence="0.999983846153846">
This approach uses the semantic role labels to
extract a set of special translation rules, that on
the target side form the smallest tree fragments in
which one predicate and all of its core arguments
are present. These rules model the complete se-
mantic structure of each predicate, and are used
by the decoder in addition to the normal GHKM
rules, which are extracted separately.
Starting by semantic role labeling the target
parse trees, we modify the GHKM component of
the system to extract a semantic rule for each pred-
icate. We define labels p as the set of semantic
role labels related to predicate p. That includes all
</bodyText>
<figure confidence="0.995365636363636">
NP–ARG0
NPB
NN
everybody
VP
VBG–PRED
lending
NP–ARG1
NPB
DT NN
NP-7-ARG1 1 受 NP-7-ARG0 2
</figure>
<page confidence="0.989655">
420
</page>
<tableCaption confidence="0.747004">
Table 1: The number of the translation rules used
by the three experimented methods
</tableCaption>
<bodyText confidence="0.997392129032258">
of the labels of the arguments of p, and the label
of p itself. Then we add the following condition
to the definition of the “frontier node” defined in
Galley et al. (2004):
A frontier node must have either all or none of
the semantic role labels from labels p in its de-
scendants in the tree.
Adding this new condition, we extract one se-
mantic rule for each predicate, and for that rule we
discard the labels related to the other predicates.
This semantic rule will then have on its target side,
the smallest tree fragment that contains all of the
arguments of predicate p and the predicate itself.
Figure 2 depicts an example of a complete se-
mantic rule. Numbers following grammatical cat-
egories (for example, S-8 at the root) are the re-
fined nonterminals produced by the split-merge
parser. In general, the tree side of the rule may
extend below the nodes with semantic role labels
because of the general constraint on frontier nodes
that they must have a continuous span in the source
(Chinese) side. Also, the internal nodes of the
rules (such as a node with PRED label in Figure
2) are removed because they are not used in de-
coding.
We also extract the regular GHKM rules using
the original definition of the frontier nodes, and
add the semantic rules to them. To differentiate
the semantic rules from the non-semantic ones, we
add a new binary feature that is set to 1 for the
semantic rules and to 0 for the rest of the rules.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="evaluation">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999976595744681">
Semantic role labeling was done using the Prop-
Bank standard (Palmer et al., 2005). Our labeler
uses a maximum entropy classifier and for iden-
tification and classification of semantic roles, and
has a percision of 90% and a recall of 88%. The
features used for training the labeler are a subset of
the features used by Gildea and Jurafsky (2000),
Xue and Palmer (2004), and Pradhan et al. (2004).
The string-to-tree training data that we used is
a Chinese to English parallel corpus that contains
more than 250K sentence pairs, which consist of
6.3M English words. The corpus was drawn from
the newswire texts available from LDC.1 We used
a 392-sentence development set with four refer-
ences for parameter tuning, and a 428-sentence
test set with four references for testing. They are
drawn from the newswire portion of NIST evalua-
tion (2004, 2005, 2006). The development set and
the test set only had sentences with less than 30
words for decoding speed. A set of nine standard
features, which include globally normalized count
of rules, lexical weighting (Koehn et al., 2003),
length penalty, and number of rules used, was used
for the experiments. In all of our experiments, we
used the split-merge parsing method of Petrov et
al. on the training corpus, and mapped the seman-
tic roles from the original trees to the result of the
split-merge parser. We used a syntax-based de-
coder with Earley parsing and cube pruning (Chi-
ang, 2007). We used the Minimum Error Rate
Training (Och, 2003) to tune the decoding param-
eters for the development set and tested the best
weights that were found on the test set.
We ran three sets of experiments: Baseline
experiments, where we did not do any seman-
tic role labeling prior to rule extraction and only
extracted regular GHKM rules, experiments with
our method of Section 2.4 (Method 1), and a set
of experiments with our method of Section 2.5
(Method 2).
Table 1 contains the numbers of the GHKM
translation rules used by our three method. The
rules were filtered by the development and the test
to increase the decoding speed. The increases in
the number of rules were expected, but they were
not big enough to significantly change the perfor-
mance of the decoder.
</bodyText>
<subsectionHeader confidence="0.775078">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.988086692307692">
For every set of experiments, we ran MERT on the
development set with 8 different starting weight
vectors picked randomly. For Method 2 we added
a new random weight for the new feature. We then
tested the system on the test set, using for each
experiment the weight vector from the iteration of
MERT with the maximum BLEU score on the de-
velopment set. Table 3 shows the BLEU scores
that we found on the test set, and their correspond-
ing scores on the development set.
1We randomly sampled our data from various different
sources. The language model is trained on the English side
of entire data (1.65M sentences, which is 39.3M words.)
</bodyText>
<figure confidence="0.980977181818182">
Number of rules
dev test
Method 1
Method 2
Baseline
1292175
1340314
1416491
1300589
1349070
1426159
</figure>
<page confidence="0.995332">
421
</page>
<table confidence="0.927407333333333">
Source 解决 13 TL 1,, 的 问题 , T能 靠 别1,, , 只能 靠 自己 .
Reference to solve the problem of 1.3 billion people, we can only rely on ourselves and nobody else.
Baseline cannot rely on others, can only resolve the problem of 13 billion people, on their own.
Method 2 to resolve the issue of 1.3 billion people , they can’t rely on others , and it can only rely on themselves .
Source 在 新t纪 新形势 � , �洲 的 发展 面IYw 着 新 的 机遇 .
Reference in the new situation of the millennium, the development of asia is facing new opportunities.
Baseline facing new opportunities in the new situation in the new century, the development of asia .
Method 2 under the new situation in the new century, the development of asia are facing a new opportunity.
Source h说,阿盟 是 同 美国 讨论 �� 地区 进行 民�改革 的 最佳 伙伴 .
Reference he said the arab league is the best partner to discuss with the united states about carrying out democratic reforms in the middle east.
Baseline arab league is the best with democratic reform in the middle east region in the discussion of the united states, he said.
Method 2 arab league is the best partner to discuss the middle east region democratic reform with the united states , he said.
</table>
<tableCaption confidence="0.999852">
Table 2: Comparison of example translations from the baseline method and our Method 2.
</tableCaption>
<bodyText confidence="0.999617358974359">
The best BLEU score on the test set is 25.92,
which is from the experiments of Method 2.
Method 1 system seems to behave slightly worse
than the baseline and Method 2. The reason for
this behavior is that the rules that were extracted
from the semantic role labeled corpus could have
isolated semantic roles in them which would not
necessarily get connected to the right predicate
or argument during decoding. In other words,
it is possible for a rule to only contain one or
some of the semantic arguments of a predicate,
and not even include the predicate itself, and there-
fore there is no guarantee that the predicate will be
translated with the right arguments and in the right
order. The difference between the BLEU scores
of the best Method 2 results and the baseline is
0.92. This improvement is statistically significant
(p = 0.032) and it shows that incorporating se-
mantic roles in machine translation is an effective
approach.
Table 2 compares some translations from the
baseline decoder and our Method 2. The first line
of each example is the Chinese source sentence,
and the second line is one of the reference trans-
lations. The last two lines compare the baseline
and Method 2. These examples show how our
Method 2 can outperform the baseline method, by
translating complete semantic structures, and gen-
erating the semantic roles in the correct order in
the target language. In the first example, the pred-
icate rely on for the argument themselves was not
translated by the baseline decoder, but it was cor-
rectly translated by Method 2. The second ex-
ample is a case where the baseline method gener-
ated the arguments in the wrong order (in the case
offacing and development), but the translation by
Method 2 has the correct order. In the last example
we see that the arguments of the predicate discuss
have the wrong order in the baseline translation,
</bodyText>
<tableCaption confidence="0.53540875">
Table 3: BLEU scores on the test and development
sets, of 8 experiments with random initial feature
weights.
but Method 2 generated the correct oder.
</tableCaption>
<sectionHeader confidence="0.982529" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.998457130434783">
We proposed two methods for incorporating se-
mantic role labels in a string-to-tree machine
translation system, by learning translation rules
that are semantically enriched. In one approach,
the system learned the translation rules by us-
ing a semantic role labeled corpus and augment-
ing the set of nonterminals used in the rules, and
in the second approach, in addition to the regu-
lar SCFG rules, the system learned semantic roles
which contained the complete semantic structure
of a predicate, and added a feature to distinguish
those rules.
The first approach did not perform any better
than the baseline, which we explained as being due
to having rules with only partial semantic struc-
tures and not having a way to guarantee that those
rules will be used with each other in the right way.
The second approach significantly outperformed
the baseline of our experiments, which shows that
complete predicate-argument structures can im-
prove the quality of machine translation.
Acknowledgments Partially funded by NSF
grant IIS-0910611.
</bodyText>
<figure confidence="0.979019454545455">
BLEU Score
dev test
Method 1
Method 2
Baseline
26.01
26.12
26.5
25.00
24.84
25.92
</figure>
<page confidence="0.995556">
422
</page>
<sectionHeader confidence="0.989843" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99976091011236">
Kathryn Baker, Michael Bloodgood, Chris Callison-
Burch, Bonnie J. Dorr, Nathaniel W. Filardo, Lori
Levin, Scott Miller, and Christine Piatko. 2010.
Semantically-informed machine translation: A tree-
grafting approach. In Proceedings of The Ninth Bi-
ennial Conference of the Association for Machine
Translation in the Americas, Denver, Colorado.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201–228.
Tagyoung Chung, Licheng Fang, and Daniel Gildea.
2011. Issues concerning decoding with synchronous
context-free grammar. In Proceedings of the ACL
2011 Conference Short Papers, Portland, Oregon.
Association for Computational Linguistics.
Hagen F¨urstenau and Mirella Lapata. 2012. Semi-
supervised semantic role labeling via structural
alignment. Computational Linguistics, 38(1):135–
171.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation
rule? In Proceedings ofNAACL-04, pages 273–280,
Boston.
Daniel Gildea and Daniel Jurafsky. 2000. Automatic
labeling of semantic roles. In Proceedings of ACL-
00, pages 512–520, Hong Kong, October.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of NAACL-03, pages 48–54, Edmonton,
Alberta.
Beth Levin. 1993. English Verb Classes And Alter-
nations: A Preliminary Investigation. University of
Chicago Press, Chicago.
Ding Liu and Daniel Gildea. 2010. Semantic role fea-
tures for machine translation. In COLING-10, Bei-
jing.
Franz Josef Och. 2003. Minimum error rate training
for statistical machine translation. In Proceedings
ofACL-03, pages 160–167.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Martha Palmer, Daniel Gildea, and Nianwen Xue.
2010. Semantic Role Labeling. Synthesis Lec-
tures on Human Language Technology Series. Mor-
gan and Claypool.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings
ofACL-02, pages 311–318.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 433–440,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James
Martin, and Dan Jurafsky. 2004. Shallow semantic
parsing using support vector machines. In Proceed-
ings ofNAACL-04.
V. Srikumar and D. Roth. 2011. A joint model for
extended semantic role labeling. In EMNLP, Edin-
burgh, Scotland.
Kristina Toutanova, Aria Haghighi, and Christopher
Manning. 2005. Joint learning improves semantic
role labeling. In Proceedings ofACL-05, pages 589–
596.
Wei Wang, Jonathan May, Kevin Knight, and Daniel
Marcu. 2010. Re-structuring, re-labeling, and
re-aligning for syntax-based machine translation.
Computational Linguistics, 36:247–277, June.
Dekai Wu and Pascale Fung. 2009. Semantic roles for
smt: A hybrid two-pass model. In Proceedings of
the HLT-NAACL 2009: Short Papers, Boulder, Col-
orado.
Xianchao Wu, Takuya Matsuzaki, and Jun’ichi Tsujii.
2010. Fine-grained tree-to-string translation rule ex-
traction. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, ACL ’10, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Mod-
eling the translation of predicate-argument structure
for smt. In ACL (1), pages 902–911.
Nianwen Xue and Martha Palmer. 2004. Calibrating
features for semantic role labeling. In Proceedings
ofEMNLP.
</reference>
<page confidence="0.999423">
423
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.983891">
<title confidence="0.999915">Semantic Roles for String to Tree Machine Translation</title>
<author confidence="0.988046">Bazrafshan</author>
<affiliation confidence="0.999797">Department of Computer University of</affiliation>
<address confidence="0.999061">Rochester, NY 14627</address>
<abstract confidence="0.999791714285714">We experiment with adding semantic role information to a string-to-tree machine translation system based on the rule extraction procedure of Galley et al. (2004). We compare methods based on augmenting the set of nonterminals by adding semantic role labels, and altering the rule extraction process to produce a separate set of rules for each predicate that encompass its entire predicate-argument structure. Our results demonstrate that the second approach is effective in increasing the quality of translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kathryn Baker</author>
<author>Michael Bloodgood</author>
<author>Chris CallisonBurch</author>
<author>Bonnie J Dorr</author>
<author>Nathaniel W Filardo</author>
<author>Lori Levin</author>
<author>Scott Miller</author>
<author>Christine Piatko</author>
</authors>
<title>Semantically-informed machine translation: A treegrafting approach.</title>
<date>2010</date>
<booktitle>In Proceedings of The Ninth Biennial Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="3043" citStr="Baker et al. (2010)" startWordPosition="470" endWordPosition="473">get sentence. Wu et al. (2010) use a head-driven phrase structure grammar (HPSG) parser to add semantic representations to their translation rules. In this paper, we use semantic role labels to enrich a string-to-tree translation system, and show that this approach can increase the BLEU (Papineni et al., 2002) score of the translations. We extract GHKM-style (Galley et al., 2004) translation rules from training data where the target side has been parsed and labeled with semantic roles. Our general method of adding information to the syntactic tree is similar to the “tree grafting” approach of Baker et al. (2010), although we focus on predicate-argument structure, rather than named entity tags and modality. We modify the rule extraction procedure of Galley et al. (2004) to produce rules representing the overall predicateargument structure of each verb, allowing us to model alternations in the mapping from syntax to semantics of the type described by Levin (1993). 2 Semantic Roles for String-to-Tree Translation 2.1 Semantic Role Labeling Semantic Role Labeling (SRL) is the task of identifying the arguments of the predicates in a sentence, and classifying them into different argument labels. Semantic ro</context>
</contexts>
<marker>Baker, Bloodgood, CallisonBurch, Dorr, Filardo, Levin, Miller, Piatko, 2010</marker>
<rawString>Kathryn Baker, Michael Bloodgood, Chris CallisonBurch, Bonnie J. Dorr, Nathaniel W. Filardo, Lori Levin, Scott Miller, and Christine Piatko. 2010. Semantically-informed machine translation: A treegrafting approach. In Proceedings of The Ninth Biennial Conference of the Association for Machine Translation in the Americas, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="10317" citStr="Chiang, 2007" startWordPosition="1705" endWordPosition="1707">ST evaluation (2004, 2005, 2006). The development set and the test set only had sentences with less than 30 words for decoding speed. A set of nine standard features, which include globally normalized count of rules, lexical weighting (Koehn et al., 2003), length penalty, and number of rules used, was used for the experiments. In all of our experiments, we used the split-merge parsing method of Petrov et al. on the training corpus, and mapped the semantic roles from the original trees to the result of the split-merge parser. We used a syntax-based decoder with Earley parsing and cube pruning (Chiang, 2007). We used the Minimum Error Rate Training (Och, 2003) to tune the decoding parameters for the development set and tested the best weights that were found on the test set. We ran three sets of experiments: Baseline experiments, where we did not do any semantic role labeling prior to rule extraction and only extracted regular GHKM rules, experiments with our method of Section 2.4 (Method 1), and a set of experiments with our method of Section 2.5 (Method 2). Table 1 contains the numbers of the GHKM translation rules used by our three method. The rules were filtered by the development and the tes</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tagyoung Chung</author>
<author>Licheng Fang</author>
<author>Daniel Gildea</author>
</authors>
<title>Issues concerning decoding with synchronous context-free grammar.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL 2011 Conference Short Papers,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon.</location>
<contexts>
<context position="5115" citStr="Chung et al., 2011" startWordPosition="798" endWordPosition="801">Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side (Chung et al., 2011). 2.3 Using Semantic Role Labels in SMT To incorporate semantic information into a stringto-tree SMT system, we tried two approaches: • Using semantically enriched GHKM rules, and • Extracting semantic rules separately from the regular GHKM rules, and adding a new feature for distinguishing the semantic rules. The next two sections will explain these two methods in detail. 2.4 Semantically Enriched Rules (Method 1) In this method, we tag the target trees in the training corpus with semantic role labels, and extract the translation rules from the tagged corpus. Since the SCFG rule extraction me</context>
</contexts>
<marker>Chung, Fang, Gildea, 2011</marker>
<rawString>Tagyoung Chung, Licheng Fang, and Daniel Gildea. 2011. Issues concerning decoding with synchronous context-free grammar. In Proceedings of the ACL 2011 Conference Short Papers, Portland, Oregon. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen F¨urstenau</author>
<author>Mirella Lapata</author>
</authors>
<title>Semisupervised semantic role labeling via structural alignment.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<pages>171</pages>
<marker>F¨urstenau, Lapata, 2012</marker>
<rawString>Hagen F¨urstenau and Mirella Lapata. 2012. Semisupervised semantic role labeling via structural alignment. Computational Linguistics, 38(1):135– 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings ofNAACL-04,</booktitle>
<pages>273--280</pages>
<location>Boston.</location>
<contexts>
<context position="2806" citStr="Galley et al., 2004" startWordPosition="429" endWordPosition="432">rst model defined features based on the context of a verbal predicate, to predict the target translation for that verb. Their second model predicted the reordering direction between a predicate and its arguments from the source to the target sentence. Wu et al. (2010) use a head-driven phrase structure grammar (HPSG) parser to add semantic representations to their translation rules. In this paper, we use semantic role labels to enrich a string-to-tree translation system, and show that this approach can increase the BLEU (Papineni et al., 2002) score of the translations. We extract GHKM-style (Galley et al., 2004) translation rules from training data where the target side has been parsed and labeled with semantic roles. Our general method of adding information to the syntactic tree is similar to the “tree grafting” approach of Baker et al. (2010), although we focus on predicate-argument structure, rather than named entity tags and modality. We modify the rule extraction procedure of Galley et al. (2004) to produce rules representing the overall predicateargument structure of each verb, allowing us to model alternations in the mapping from syntax to semantics of the type described by Levin (1993). 2 Sem</context>
<context position="4726" citStr="Galley et al. (2004)" startWordPosition="731" endWordPosition="734">Semantic arguments can be classified into core and non-core arguments (Palmer et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side (Chung et al., 2011). 2.3 Using Semantic Role Labels in SMT To incorporate semantic information into a stringto-tree SMT system, we tried two approaches: • Using semantically enriched GHKM rules, and • Extracting semantic rules sep</context>
<context position="7608" citStr="Galley et al. (2004)" startWordPosition="1230" endWordPosition="1233">are extracted separately. Starting by semantic role labeling the target parse trees, we modify the GHKM component of the system to extract a semantic rule for each predicate. We define labels p as the set of semantic role labels related to predicate p. That includes all NP–ARG0 NPB NN everybody VP VBG–PRED lending NP–ARG1 NPB DT NN NP-7-ARG1 1 受 NP-7-ARG0 2 420 Table 1: The number of the translation rules used by the three experimented methods of the labels of the arguments of p, and the label of p itself. Then we add the following condition to the definition of the “frontier node” defined in Galley et al. (2004): A frontier node must have either all or none of the semantic role labels from labels p in its descendants in the tree. Adding this new condition, we extract one semantic rule for each predicate, and for that rule we discard the labels related to the other predicates. This semantic rule will then have on its target side, the smallest tree fragment that contains all of the arguments of predicate p and the predicate itself. Figure 2 depicts an example of a complete semantic rule. Numbers following grammatical categories (for example, S-8 at the root) are the refined nonterminals produced by the</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings ofNAACL-04, pages 273–280, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL00,</booktitle>
<pages>512--520</pages>
<location>Hong Kong,</location>
<contexts>
<context position="4469" citStr="Gildea and Jurafsky, 2000" startWordPosition="692" endWordPosition="695">l Linguistics of understanding that cannot be derived from syntactic analysis of a sentence. For example, in sentences “Ali opened the door.” and “The door opened”, the word door has two different syntactic roles but only one semantic role in the two sentences. Semantic arguments can be classified into core and non-core arguments (Palmer et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the sam</context>
<context position="9228" citStr="Gildea and Jurafsky (2000)" startWordPosition="1520" endWordPosition="1523">GHKM rules using the original definition of the frontier nodes, and add the semantic rules to them. To differentiate the semantic rules from the non-semantic ones, we add a new binary feature that is set to 1 for the semantic rules and to 0 for the rest of the rules. 3 Experiments Semantic role labeling was done using the PropBank standard (Palmer et al., 2005). Our labeler uses a maximum entropy classifier and for identification and classification of semantic roles, and has a percision of 90% and a recall of 88%. The features used for training the labeler are a subset of the features used by Gildea and Jurafsky (2000), Xue and Palmer (2004), and Pradhan et al. (2004). The string-to-tree training data that we used is a Chinese to English parallel corpus that contains more than 250K sentence pairs, which consist of 6.3M English words. The corpus was drawn from the newswire texts available from LDC.1 We used a 392-sentence development set with four references for parameter tuning, and a 428-sentence test set with four references for testing. They are drawn from the newswire portion of NIST evaluation (2004, 2005, 2006). The development set and the test set only had sentences with less than 30 words for decodi</context>
</contexts>
<marker>Gildea, Jurafsky, 2000</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2000. Automatic labeling of semantic roles. In Proceedings of ACL00, pages 512–520, Hong Kong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-03,</booktitle>
<pages>48--54</pages>
<location>Edmonton, Alberta.</location>
<contexts>
<context position="9959" citStr="Koehn et al., 2003" startWordPosition="1641" endWordPosition="1644">o English parallel corpus that contains more than 250K sentence pairs, which consist of 6.3M English words. The corpus was drawn from the newswire texts available from LDC.1 We used a 392-sentence development set with four references for parameter tuning, and a 428-sentence test set with four references for testing. They are drawn from the newswire portion of NIST evaluation (2004, 2005, 2006). The development set and the test set only had sentences with less than 30 words for decoding speed. A set of nine standard features, which include globally normalized count of rules, lexical weighting (Koehn et al., 2003), length penalty, and number of rules used, was used for the experiments. In all of our experiments, we used the split-merge parsing method of Petrov et al. on the training corpus, and mapped the semantic roles from the original trees to the result of the split-merge parser. We used a syntax-based decoder with Earley parsing and cube pruning (Chiang, 2007). We used the Minimum Error Rate Training (Och, 2003) to tune the decoding parameters for the development set and tested the best weights that were found on the test set. We ran three sets of experiments: Baseline experiments, where we did no</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of NAACL-03, pages 48–54, Edmonton, Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes And Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="3399" citStr="Levin (1993)" startWordPosition="528" endWordPosition="529">alley et al., 2004) translation rules from training data where the target side has been parsed and labeled with semantic roles. Our general method of adding information to the syntactic tree is similar to the “tree grafting” approach of Baker et al. (2010), although we focus on predicate-argument structure, rather than named entity tags and modality. We modify the rule extraction procedure of Galley et al. (2004) to produce rules representing the overall predicateargument structure of each verb, allowing us to model alternations in the mapping from syntax to semantics of the type described by Levin (1993). 2 Semantic Roles for String-to-Tree Translation 2.1 Semantic Role Labeling Semantic Role Labeling (SRL) is the task of identifying the arguments of the predicates in a sentence, and classifying them into different argument labels. Semantic roles can provide a level 419 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 419–423, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics of understanding that cannot be derived from syntactic analysis of a sentence. For example, in sentences “Ali opened the door.” and “The door</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes And Alternations: A Preliminary Investigation. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation. In</title>
<date>2010</date>
<booktitle>COLING-10,</booktitle>
<location>Beijing.</location>
<contexts>
<context position="1548" citStr="Liu and Gildea (2010)" startWordPosition="232" endWordPosition="235">arted to realize that incorporating semantic features of languages can also be effective in increasing the quality of translations, as they can model relationships that often are not derivable from syntactic structures. Wu and Fung (2009) demonstrated the promise of using features based on semantic predicateargument structure in machine translation, using these feature to re-rank machine translation output. In general, re-ranking approaches are limited by the set of translation hypotheses, leading to a desire to incorporate semantic features into the translation model used during MT decoding. Liu and Gildea (2010) introduced two types of semantic features for tree-to-string machine translation. These features model the reorderings and deletions of the semantic roles in the source sentence during decoding. They showed that addition of these semantic features helps improve the quality of translations. Since tree-to-string systems are trained on parse trees, they are constrained by the tree structures and are generally outperformed by string-to-tree systems. Xiong et al. (2012) integrated two discriminative feature-based models into a phrase-based SMT system, which used the semantic predicateargument stru</context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic role features for machine translation. In COLING-10, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL-03,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="10370" citStr="Och, 2003" startWordPosition="1715" endWordPosition="1716">d the test set only had sentences with less than 30 words for decoding speed. A set of nine standard features, which include globally normalized count of rules, lexical weighting (Koehn et al., 2003), length penalty, and number of rules used, was used for the experiments. In all of our experiments, we used the split-merge parsing method of Petrov et al. on the training corpus, and mapped the semantic roles from the original trees to the result of the split-merge parser. We used a syntax-based decoder with Earley parsing and cube pruning (Chiang, 2007). We used the Minimum Error Rate Training (Och, 2003) to tune the decoding parameters for the development set and tested the best weights that were found on the test set. We ran three sets of experiments: Baseline experiments, where we did not do any semantic role labeling prior to rule extraction and only extracted regular GHKM rules, experiments with our method of Section 2.4 (Method 1), and a set of experiments with our method of Section 2.5 (Method 2). Table 1 contains the numbers of the GHKM translation rules used by our three method. The rules were filtered by the development and the test to increase the decoding speed. The increases in th</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In Proceedings ofACL-03, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="8965" citStr="Palmer et al., 2005" startWordPosition="1474" endWordPosition="1477">nstraint on frontier nodes that they must have a continuous span in the source (Chinese) side. Also, the internal nodes of the rules (such as a node with PRED label in Figure 2) are removed because they are not used in decoding. We also extract the regular GHKM rules using the original definition of the frontier nodes, and add the semantic rules to them. To differentiate the semantic rules from the non-semantic ones, we add a new binary feature that is set to 1 for the semantic rules and to 0 for the rest of the rules. 3 Experiments Semantic role labeling was done using the PropBank standard (Palmer et al., 2005). Our labeler uses a maximum entropy classifier and for identification and classification of semantic roles, and has a percision of 90% and a recall of 88%. The features used for training the labeler are a subset of the features used by Gildea and Jurafsky (2000), Xue and Palmer (2004), and Pradhan et al. (2004). The string-to-tree training data that we used is a Chinese to English parallel corpus that contains more than 250K sentence pairs, which consist of 6.3M English words. The corpus was drawn from the newswire texts available from LDC.1 We used a 392-sentence development set with four re</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Nianwen Xue</author>
</authors>
<date>2010</date>
<booktitle>Semantic Role Labeling. Synthesis Lectures on Human Language Technology Series.</booktitle>
<publisher>Morgan</publisher>
<contexts>
<context position="4197" citStr="Palmer et al., 2010" startWordPosition="652" endWordPosition="655">, and classifying them into different argument labels. Semantic roles can provide a level 419 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 419–423, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics of understanding that cannot be derived from syntactic analysis of a sentence. For example, in sentences “Ali opened the door.” and “The door opened”, the word door has two different syntactic roles but only one semantic role in the two sentences. Semantic arguments can be classified into core and non-core arguments (Palmer et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2</context>
</contexts>
<marker>Palmer, Gildea, Xue, 2010</marker>
<rawString>Martha Palmer, Daniel Gildea, and Nianwen Xue. 2010. Semantic Role Labeling. Synthesis Lectures on Human Language Technology Series. Morgan and Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL-02,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="2735" citStr="Papineni et al., 2002" startWordPosition="417" endWordPosition="421">the semantic predicateargument structure of the source language. Their first model defined features based on the context of a verbal predicate, to predict the target translation for that verb. Their second model predicted the reordering direction between a predicate and its arguments from the source to the target sentence. Wu et al. (2010) use a head-driven phrase structure grammar (HPSG) parser to add semantic representations to their translation rules. In this paper, we use semantic role labels to enrich a string-to-tree translation system, and show that this approach can increase the BLEU (Papineni et al., 2002) score of the translations. We extract GHKM-style (Galley et al., 2004) translation rules from training data where the target side has been parsed and labeled with semantic roles. Our general method of adding information to the syntactic tree is similar to the “tree grafting” approach of Baker et al. (2010), although we focus on predicate-argument structure, rather than named entity tags and modality. We modify the rule extraction procedure of Galley et al. (2004) to produce rules representing the overall predicateargument structure of each verb, allowing us to model alternations in the mappin</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings ofACL-02, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="4801" citStr="Petrov et al. (2006)" startWordPosition="745" endWordPosition="748">er et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side (Chung et al., 2011). 2.3 Using Semantic Role Labels in SMT To incorporate semantic information into a stringto-tree SMT system, we tried two approaches: • Using semantically enriched GHKM rules, and • Extracting semantic rules separately from the regular GHKM rules, and adding a new feature for distingui</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433–440, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>Kadri Hacioglu</author>
<author>James Martin</author>
<author>Dan Jurafsky</author>
</authors>
<title>Shallow semantic parsing using support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings ofNAACL-04.</booktitle>
<contexts>
<context position="9278" citStr="Pradhan et al. (2004)" startWordPosition="1529" endWordPosition="1532">r nodes, and add the semantic rules to them. To differentiate the semantic rules from the non-semantic ones, we add a new binary feature that is set to 1 for the semantic rules and to 0 for the rest of the rules. 3 Experiments Semantic role labeling was done using the PropBank standard (Palmer et al., 2005). Our labeler uses a maximum entropy classifier and for identification and classification of semantic roles, and has a percision of 90% and a recall of 88%. The features used for training the labeler are a subset of the features used by Gildea and Jurafsky (2000), Xue and Palmer (2004), and Pradhan et al. (2004). The string-to-tree training data that we used is a Chinese to English parallel corpus that contains more than 250K sentence pairs, which consist of 6.3M English words. The corpus was drawn from the newswire texts available from LDC.1 We used a 392-sentence development set with four references for parameter tuning, and a 428-sentence test set with four references for testing. They are drawn from the newswire portion of NIST evaluation (2004, 2005, 2006). The development set and the test set only had sentences with less than 30 words for decoding speed. A set of nine standard features, which i</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James Martin, and Dan Jurafsky. 2004. Shallow semantic parsing using support vector machines. In Proceedings ofNAACL-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Srikumar</author>
<author>D Roth</author>
</authors>
<title>A joint model for extended semantic role labeling.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="4494" citStr="Srikumar and Roth, 2011" startWordPosition="696" endWordPosition="699">ing that cannot be derived from syntactic analysis of a sentence. For example, in sentences “Ali opened the door.” and “The door opened”, the word door has two different syntactic roles but only one semantic role in the two sentences. Semantic arguments can be classified into core and non-core arguments (Palmer et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side</context>
</contexts>
<marker>Srikumar, Roth, 2011</marker>
<rawString>V. Srikumar and D. Roth. 2011. A joint model for extended semantic role labeling. In EMNLP, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher Manning</author>
</authors>
<title>Joint learning improves semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL-05,</booktitle>
<pages>589--596</pages>
<contexts>
<context position="4518" citStr="Toutanova et al., 2005" startWordPosition="700" endWordPosition="703">d from syntactic analysis of a sentence. For example, in sentences “Ali opened the door.” and “The door opened”, the word door has two different syntactic roles but only one semantic role in the two sentences. Semantic arguments can be classified into core and non-core arguments (Palmer et al., 2010). Core arguments are necessary for understanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side (Chung et al., 2011). 2</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2005</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher Manning. 2005. Joint learning improves semantic role labeling. In Proceedings ofACL-05, pages 589– 596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Re-structuring, re-labeling, and re-aligning for syntax-based machine translation.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<contexts>
<context position="4854" citStr="Wang et al. (2010)" startWordPosition="756" endWordPosition="759">rstanding the sentence. Non-core arguments add more information about the predicate but are not essential. Automatic semantic role labelers have been developed by training classifiers on hand annotated data (Gildea and Jurafsky, 2000; Srikumar and Roth, 2011; Toutanova et al., 2005; F¨urstenau and Lapata, 2012). State-of-the-art semantic role labelers can predict the labels with accuracies of around 90%. 2.2 String-to-Tree Translation We adopt the GHKM framework of Galley et al. (2004) using the parses produced by the splitmerge parser of Petrov et al. (2006) as the English trees. As shown by Wang et al. (2010), the refined nonterminals produced by the split-merge method can aid machine translation. Furthermore, in all of our experiments, we exclude unary rules during extraction by ensuring that no rules will have the same span in the source side (Chung et al., 2011). 2.3 Using Semantic Role Labels in SMT To incorporate semantic information into a stringto-tree SMT system, we tried two approaches: • Using semantically enriched GHKM rules, and • Extracting semantic rules separately from the regular GHKM rules, and adding a new feature for distinguishing the semantic rules. The next two sections will </context>
</contexts>
<marker>Wang, May, Knight, Marcu, 2010</marker>
<rawString>Wei Wang, Jonathan May, Kevin Knight, and Daniel Marcu. 2010. Re-structuring, re-labeling, and re-aligning for syntax-based machine translation. Computational Linguistics, 36:247–277, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Semantic roles for smt: A hybrid two-pass model.</title>
<date>2009</date>
<booktitle>In Proceedings of the HLT-NAACL 2009: Short Papers,</booktitle>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1165" citStr="Wu and Fung (2009)" startWordPosition="175" endWordPosition="178">entire predicate-argument structure. Our results demonstrate that the second approach is effective in increasing the quality of translations. 1 Introduction Statistical machine translation (SMT) has made considerable advances in using syntactic properties of languages in both the training and the decoding of translation systems. Over the past few years, many researchers have started to realize that incorporating semantic features of languages can also be effective in increasing the quality of translations, as they can model relationships that often are not derivable from syntactic structures. Wu and Fung (2009) demonstrated the promise of using features based on semantic predicateargument structure in machine translation, using these feature to re-rank machine translation output. In general, re-ranking approaches are limited by the set of translation hypotheses, leading to a desire to incorporate semantic features into the translation model used during MT decoding. Liu and Gildea (2010) introduced two types of semantic features for tree-to-string machine translation. These features model the reorderings and deletions of the semantic roles in the source sentence during decoding. They showed that addi</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009. Semantic roles for smt: A hybrid two-pass model. In Proceedings of the HLT-NAACL 2009: Short Papers, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianchao Wu</author>
<author>Takuya Matsuzaki</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Fine-grained tree-to-string translation rule extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2454" citStr="Wu et al. (2010)" startWordPosition="371" endWordPosition="374">. Since tree-to-string systems are trained on parse trees, they are constrained by the tree structures and are generally outperformed by string-to-tree systems. Xiong et al. (2012) integrated two discriminative feature-based models into a phrase-based SMT system, which used the semantic predicateargument structure of the source language. Their first model defined features based on the context of a verbal predicate, to predict the target translation for that verb. Their second model predicted the reordering direction between a predicate and its arguments from the source to the target sentence. Wu et al. (2010) use a head-driven phrase structure grammar (HPSG) parser to add semantic representations to their translation rules. In this paper, we use semantic role labels to enrich a string-to-tree translation system, and show that this approach can increase the BLEU (Papineni et al., 2002) score of the translations. We extract GHKM-style (Galley et al., 2004) translation rules from training data where the target side has been parsed and labeled with semantic roles. Our general method of adding information to the syntactic tree is similar to the “tree grafting” approach of Baker et al. (2010), although </context>
</contexts>
<marker>Wu, Matsuzaki, Tsujii, 2010</marker>
<rawString>Xianchao Wu, Takuya Matsuzaki, and Jun’ichi Tsujii. 2010. Fine-grained tree-to-string translation rule extraction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Modeling the translation of predicate-argument structure for smt.</title>
<date>2012</date>
<journal>In ACL</journal>
<volume>1</volume>
<pages>902--911</pages>
<contexts>
<context position="2018" citStr="Xiong et al. (2012)" startWordPosition="302" endWordPosition="305">ranslation hypotheses, leading to a desire to incorporate semantic features into the translation model used during MT decoding. Liu and Gildea (2010) introduced two types of semantic features for tree-to-string machine translation. These features model the reorderings and deletions of the semantic roles in the source sentence during decoding. They showed that addition of these semantic features helps improve the quality of translations. Since tree-to-string systems are trained on parse trees, they are constrained by the tree structures and are generally outperformed by string-to-tree systems. Xiong et al. (2012) integrated two discriminative feature-based models into a phrase-based SMT system, which used the semantic predicateargument structure of the source language. Their first model defined features based on the context of a verbal predicate, to predict the target translation for that verb. Their second model predicted the reordering direction between a predicate and its arguments from the source to the target sentence. Wu et al. (2010) use a head-driven phrase structure grammar (HPSG) parser to add semantic representations to their translation rules. In this paper, we use semantic role labels to </context>
</contexts>
<marker>Xiong, Zhang, Li, 2012</marker>
<rawString>Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Modeling the translation of predicate-argument structure for smt. In ACL (1), pages 902–911.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="9251" citStr="Xue and Palmer (2004)" startWordPosition="1524" endWordPosition="1527">l definition of the frontier nodes, and add the semantic rules to them. To differentiate the semantic rules from the non-semantic ones, we add a new binary feature that is set to 1 for the semantic rules and to 0 for the rest of the rules. 3 Experiments Semantic role labeling was done using the PropBank standard (Palmer et al., 2005). Our labeler uses a maximum entropy classifier and for identification and classification of semantic roles, and has a percision of 90% and a recall of 88%. The features used for training the labeler are a subset of the features used by Gildea and Jurafsky (2000), Xue and Palmer (2004), and Pradhan et al. (2004). The string-to-tree training data that we used is a Chinese to English parallel corpus that contains more than 250K sentence pairs, which consist of 6.3M English words. The corpus was drawn from the newswire texts available from LDC.1 We used a 392-sentence development set with four references for parameter tuning, and a 428-sentence test set with four references for testing. They are drawn from the newswire portion of NIST evaluation (2004, 2005, 2006). The development set and the test set only had sentences with less than 30 words for decoding speed. A set of nine</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating features for semantic role labeling. In Proceedings ofEMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>