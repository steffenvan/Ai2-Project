<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.042437">
<title confidence="0.992595">
A Collaborative Tool for the Computational Modelling of Child
Language Acquisition
</title>
<author confidence="0.771569">
Kris Jack
</author>
<note confidence="0.497976">
CEA LIST, Laboratoire d&apos;ing6nerie de la connaissance multim6dia multilingue
18 route du Panorama, BP6
Fontenay-aux-Roses, F-92265 France
</note>
<email confidence="0.996682">
mrkrisjack@gmail.com
</email>
<sectionHeader confidence="0.983051" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999563857142857">
A large number of computational language
learners have been proposed for modelling the
process of child language acquisition. Com-
paring them, however, can be difficult due to
the different assumptions that they make, the
diverse test results presented, and the different
linguistic behaviours investigated. This paper
introduces a toolkit that allows different lan-
guage learners to be trained, tested and ana-
lysed under standardised conditions. The res-
ults can be easily compared with one another
and with typical child language development
to highlight the relative advantages and disad-
vantages of learners.
</bodyText>
<sectionHeader confidence="0.996283" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973456140351">
The computational modelling of language acquis-
ition can help in understanding the acquisition
process by estimating the problem faced by chil-
dren and designing algorithms that solve it in a
similar way as they do. Many such models have
been produced in recent years, tackling various
linguistic behaviours. Like in any relatively new
domain of research, however, the treatment of
one problem often reveals the presence of several
more that in turn require new solutions of their
own. This has led to the design and implementa-
tion of numerous learners that differ in either
subtle or fundamental ways. Given such variety,
it is not yet clear which kind of model, or com-
bination of models, can best account for the over-
all behaviour witnessed during child language de-
velopment.
When surveying the computational language
acquisition literature, the relative advantages and
disadvantages of language learners are not al-
ways clear. As such, it can be very difficult to
compare different learners with one another. The
main problem is the lack of standardisation in the
field. Language learners are constructed with
different underlying assumptions, largely due to
the lack of consensus in linguistic theory, are
trained using different data (that can vary from
miniature languages to full blown natural lan-
guages) and are tested using different testing
measures (some of which include the &apos;Looks
good to me&apos; approach).
In this paper, a toolkit for investigating the
computational modelling of child language ac-
quisition is proposed. The Language Acquisition
Toolkit (LAT) allows researchers to work collab-
oratively in solving the modelling task, while ad-
dressing the problems introduced. It is an at-
tempt to bring the field forward by creating a
standardised way for testing and implementing
language acquisition learners. The issues ad-
dressed in this paper are largely driven by engin-
eering concerns although the choices that are
made by the modeller will impact not only on
their learner but also on the associated language
theory. The driving motivation behind the LAT
is that the best way to compare different language
learners is to compare the behaviours that they
produce. The closer a learner&apos;s behaviour is to
the behaviour witnessed in children, the better the
model.
The LAT is a computational framework that
can train, test and analyse the linguistic perform-
ance of a computational language learner in order
to chart developmental linguistic trajectories.
The motivation for the LAT shall first be ex-
plored before describing it in detail, discussing its
features and considering future directions.
</bodyText>
<note confidence="0.949499">
Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 10–17,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997873">
10
</page>
<sectionHeader confidence="0.981867" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999977370370371">
The process of modelling child language acquisi-
tion is very complex, as many of the first at-
tempts confirmed (Feldman et al., 1990; Suppes,
Liang &amp; Bottner, 1991). Rather than modelling
the process in entirety, an undoubtedly daunting
task, modellers took the simplified approach of
focusing upon individual linguistic behaviours,
leading to much research into relatively con-
strained problems such as understanding over-
and under-generalisation errors (Plunkett, Sinha,
Moller &amp; Strandsby, 1992), single word learning
(Regier, 2005), syntactic category acquisition
(Redington, Chater &amp; Finch, 1988) and past-
tense learning (Rumelhart &amp; Mcclelland, 1986).
While such models have led to valuable insights
in the domain, it can be difficult to see how each
of them is related to one another given the lack of
standardised learning, testing and analysis.
Often, the variety found in computational
models reflects the divisions between linguistic
theories pertaining to child language acquisition
(Kaplan, Oudeyer &amp; Bergen, 2008). Given that
linguists remain divided about how children learn
language, it is not surprising to find a similar di-
vision in the computational modelling com-
munity as well. One of the fundamental issues
that separates modellers is the kind of data that
the learner learns. This can range from the use of
plain textual data (Elman, 1993), to grounded
sensor-based input (Roy, 2008). Standardising
the type of learning data would thus be useful for
comparing language learners.
Typical computational models are often tested
under different circumstances and using different
techniques. For example, while some papers of-
fer a general analysis of the model&apos;s behaviour,
others focus on particular features, while some
test language comprehension, others test lan-
guage production, and while some consider de-
velopmental growth, others consider only the
start and end points of training. Although this is
often justifiable in the context of the research
problem, it makes it difficult to directly compare
two models. It would be useful to put all models
through the same set of rigorous tests in order to
find out how they are similar and how they differ
from one another. Such standardised testing will
often reveal important differences that may have
previously been hidden.
Practically, however, not all models that are
described in the literature are made available for
download. As a result, researchers often have to
spend time recreating models. This assumes, of
course, that the model has been described in
enough detail that it can be faithfully recreated.
Much time could be saved if such models were
available for download, from a common reposit-
ory, such as the Weka makes machine learning
algorithms freely available in a software work-
bench (http://www.cs.waikato.ac.nz/~ml/).
A good language learner should not just solve
language learning problems, but should do so in a
similar way as is witnessed in children. Based on
psycho-linguistic evidence, several linguistic
timetables have been derived containing import-
ant linguistic milestones (Brown, 1973; Ingram,
1989; Pinker, 1994; Tomasello, 2005). The char-
acter of language development is a significant
feature in child language acquisition and model-
lers should be encouraged to model it to better
understand the process. A language learner that
demonstrates a good use of syntax at the same
time as producing its first words is not very real-
istic. Instead, there should be a prolonged period
in which words are learned followed by the emer-
gence of syntax. Unfortunately, a language mod-
el can often produce behaviours at unexpected
times, signalling a problem with the linguistic
theory that it embodies. A standardised approach
to analysing the linguistic development of a lan-
guage learner would be an advantage.
</bodyText>
<sectionHeader confidence="0.875629" genericHeader="method">
3 The Language Acquisition Toolkit
3.1 Introduction
</sectionHeader>
<bodyText confidence="0.993391555555556">
The Language Acquisition Toolkit (LAT) is a
piece of software that allows researchers to de-
velop and test computational language learners
within a standardised environment. The LAT&apos;s
target users are researchers who have basic skills
in software development and are comfortable us-
ing the programming language Java. It assumes
that the language learner operates under the re-
strictions imposed in the miniature language
paradigm (Feldman et al., 1990). The LAT can
be obtained from www.langac.com and is avail-
able under a GNU public license meaning that
the code can be reproduced and modified without
obtaining permission.
The LAT is an attempt to standardise the train-
ing, testing and analysing of language learners
within an open an accessible environment (Figure
1). In training, the language learner observes a
</bodyText>
<page confidence="0.998646">
11
</page>
<bodyText confidence="0.999740333333333">
simulated world in which action-based events oc-
cur. Both simulated descriptions and visual data
are sent to the language learner for analysis. The
LAT then tests both the language learner&apos;s com-
prehension and production capacities. Compre-
hension is tested by sending a description to the
language learner and scoring the visual data that
are produced. Similarly, production is tested by
sending visual data to language learner and scor-
ing the descriptions produced. The LAT then
analyses the results obtained from testing and de-
velops data describing the learner&apos;s development.
</bodyText>
<figure confidence="0.844658">
Training
Analysing
</figure>
<figureCaption confidence="0.678436">
Figure 1: LAT Overview. A language learner is
placed in the LAT&apos;s simulated world where it
learns from simulated audio and visual data. The
LAT tests the learner and the results are used to
produce data describing its development.
</figureCaption>
<subsectionHeader confidence="0.998094">
3.2 Training
</subsectionHeader>
<bodyText confidence="0.999989557142858">
The LAT can be configured to train different
language learners by generating a simulated en-
vironment in which action-based events occur.
The simulated environment operates within the
miniature language acquisition paradigm (Feld-
man et al., 1990), a simplified simulation of the
real-world. A simulation is employed rather than
grounding the model in the real-world in order to
better control the number and type of problems
that are being investigated in a single experiment.
While the miniature language paradigm imposes
a number of constraints, the proposed simulation
contains enough complexity to justify its use.
The learner is trained by watching an event
that is simulated in the blocks world in which a
number of geometric objects can be found.
When an event occurs, a symbolic representation
of the description and visual data are generated.
More concretely, an event is the pairing of a sim-
ulated description and a action, e=〈d , a〉 .
Events are represented following evidence from
child studies. First, it is assumed that the learner
can establish a triadic relationship between an
object, a speaker and themselves in order to asso-
ciate a description with an action. This kind of
relationship is typically called joint-attention and
does not appear in children until around 12
months-old (Tomasello, 1995). As such, the
symbolic content present in descriptions and ac-
tions are limited to those found in child literature
during the first year of life.
An infant&apos;s acoustic sensitivity is so attuned
that from four-days-old she demonstrates the
ability to differentiate between native and non-
native speech (Mehler et al., 1988). Such dis-
crimination lies in rhythmic properties that differ
over language groups (Dehaene-Lambertz &amp;
Houston, 1998; Mehler, Dupoux, Nazzi &amp; De-
haene-Lambertz, 1996) and is likely to be syl-
lable-based since infants detect change in syllable
quantity, but not in phoneme quantity over
samples of speech (Bijeljac-Babic, Bertoncini &amp;
Mehler, 1993). Infants also detect vowel change,
a syllable covariant, more readily than consonant
change (Bertoncini et al., 1988), further support-
ing a syllabic base. A description is thus repres-
ented as a non-zero length ordered list of syl-
lables in the LAT. Word segmentations are not
included as there is no acoustic equivalent of the
blank space in written language.
In terms of visual sensitivity, infants can
identify objects through retinal and object dis-
placement during motion from four months-old
(Kellman, Gleitman &amp; Spelke, 1987), and make
relative spacial distinctions between left and
right, and above and below, from three to ten
months old (Quinn &amp; Schyns, 2003). Infants can
also make use of shape and colour to differentiate
between objects in the first year of life (Landau,
Smith &amp; Jones, 1988). The LAT thus describes
the physical properties of objects that inhabit the
blocks world (e.g. shape, colour, size and posi-
tion), referred to as features. An action is defined
as a non-zero length ordered list of feature sets,
where each feature set is associated with a unique
time interval. A set of features describes all ob-
jects that can be seen in an event. Note that ac-
tions in this terminology do not relate to actions
in terms of verbs in natural language, but to a list
of descriptions of scenes. Properties such as
</bodyText>
<figure confidence="0.995810166666667">
Testing
comprehension
production
Language Learner
Developmental
Data
</figure>
<page confidence="0.979108">
12
</page>
<bodyText confidence="0.999694802816902">
push and pull are thus not explicitly represented
as symbolic features.
Two types of events can occur in the blocks
world: action-based; and descriptive. In the case
of an action-based event, an object performs an
action while in the case of a descriptive event,
objects do not change. As a result, action-based
events contain different feature sets, giving the
impression of change, while descriptive events
contain the same feature sets, indicating no
change. The description in an action-based event
describes the action while the description in a de-
scriptive event describes an object in the static
scene. Objects can perform several actions in-
cluding moving, flashing, growing, shrinking, ap-
pearing, disappearing, destroying another object,
hitting another object, pushing another object and
pulling another object.
The LAT randomly generate events that can be
used as training data. It can create objects, make
them perform actions, and describe the events by
instantiating appropriate grammar fragments. To
encourage the use of standardised sets of training
data, a number of sets of data have been ran-
domly generated that each contain 10,000 events.
These data have been generated from different
parameters (e.g. amount of noise, probability that
an object will perform an action in an event,
probabilities for each action to occur, number of
time intervals for an event, number of
colours/shapes/sizes/actions possible) with differ-
ent language properties (e.g. recursion present/
not present, number of rules, language in use).
To provide concrete examples of typical LAT
training data, one data set, called the Appearance
data set will be presented in detail. The appear-
ance data set is inspired from a study with real
participants. Participants sat in front of a com-
puter screen that initially showed a blank white
screen. They were asked to describe all changes
that were made to the screen in enough detail that
a stranger could recreate the scene using only
their descriptions. By pressing a key on the key-
board, a new geometric object appeared on the
screen and the change was described by the parti-
cipant. While the addition of an object to a scene
appears to be a trivial change, participants pro-
duced complex linguistic descriptions that re-
vealed a deep knowledge of their language. For
example, descriptions such as “a blue circle ap-
peared to the upper right of the green square at
the bottom” and “a red circle appeared between
the four squares making the shape of a cross”
(Jack, 2005).
Given the complexity of the language pro-
duced, a simplified version the task was construc-
ted in which only the appearance of one object
next to another object was considered. By re-
stricting the context, there is less demand for a
computational language learner to have a rich se-
mantic representation of scenes. This served as a
reasonable starting point from which to conduct
the investigation. The actions in the Appearance
data set were constructed by randomly generating
one object and placing it in the middle of a 3x3
grid scene and then adding a second object,
which was also randomly generated, in a differ-
ent position. Eight colours and shapes were used.
Each action was also accompanied by an appro-
priate description that was generated using a
grammar fragment (Figure 2).
</bodyText>
<table confidence="0.992655923076923">
E → NP1 PAR 2
PAR1 → NP1 PART PAR2 → REL NP2
RELT → REL Det2 REL → REL1  |REL2
REL1 → a bove  |be low  |REL2 → REL3 REL4
to the REL4
REL3 → to the low er  |to REL4 → left of  |right of
the u pper
NP1 → Det1 Nbar NP2 → Det2 Nbar
Nbar → SHP COL
Det1 → a Det2 → the
COL → black  |blue  |grey SHP → cir cle  |cross  |dia
 |green  |pink  |black  |red mond  |heart  |rec tang gle
 |ye low  |star |square  |tri ang gle
</table>
<figureCaption confidence="0.992933666666667">
Figure 2: Miniature Language from Appearance
Data Set. All strings are syllable segmented rather
than word segmented.
</figureCaption>
<bodyText confidence="0.999969083333333">
Events from this data set have actions that are
described using a 2-frame time interval, where
the first set of features describes the state of the
scene before the action occurs and the second set
of features describes the scene after the action oc-
curs (Figure 3). Note that it is assumed that the
learner can identify concepts such as colour,
shape and position and that such symbolic in-
formation is associated with a particular object.
The notion of object-hood, where the first object
in the scene is O1 and the second object is O2, is
carried across time intervals with O1 being recog-
</bodyText>
<page confidence="0.995635">
13
</page>
<bodyText confidence="0.990963">
nised as the same object before and after an ac-
tion occurs.
</bodyText>
<table confidence="0.993620444444444">
Before action (t=1) After action (t=2)
3 3
2 2
1 1
1 2 3 1 2 3
O1: square O1: square O2: circle
O1: blue O1: blue O2: yellow
O1: x2 O1: x2 O2: x3
O1: y2 O1: y2 O2: y3
</table>
<figure confidence="0.9669995">
a ye low cir cle to the u pper right of the blue
square
</figure>
<figureCaption confidence="0.998298">
Figure 3: Sample Event from Appearance Data
Set. Two time frames represented graphically and
as feature sets. The accompanying syllable seg-
mented description of the event is also shown.
</figureCaption>
<bodyText confidence="0.99999648">
The remaining data sets contain more complex
events in which more actions and richer mini-
ature languages are employed. Actions are ran-
domly generated, with respect to the constraints
imposed on the data set (e.g. number of colours,
shapes, and actions) and appropriate descriptions
are generated. These descriptions are produced
by following a heuristic that minimises the num-
ber of syllables that can appear in a single de-
scription. This reduces the production of unnat-
ural sentences. For example, take the case where
an object appears in a scene amongst 10 other ob-
jects. A description could be generated to de-
scribe the action with respect to one other object,
two other objects or as many as 10 other objects.
While such descriptions are all valid, many of
them would sound unnatural if employed. The
algorithm selects descriptions by favouring those
that have fewer syllables. A parser is then em-
ployed that eliminates invalid descriptions that
can be misinterpreted. By making a parsimoni-
ous use of syllables, more natural descriptions
tend to be produced. More abstract language can
also be found such as the use of the word &apos;bully-
ing&apos; to describe pushing, pulling and hitting.
</bodyText>
<subsectionHeader confidence="0.997969">
3.3 Testing
</subsectionHeader>
<bodyText confidence="0.999983339285714">
The LAT monitors the linguistic development
of a language leaner by testing its comprehension
and production capacities. The learner&apos;s compre-
hension and production are tested at every round
of training.
For each set of training data, there is an associ-
ated set of testing data, ensuring a standardised
test procedure for language learners. Test data is
produced using grammar rules for producing de-
scriptions and heuristics for producing actions.
The tests are constructed to reflect the properties
found in the training data&apos;s miniature language.
As such, the learner is only tested on the kind of
descriptions and actions that it has the opportun-
ity to learn through observing events. Con-
cretely, a testing set is a set of events where each
event relates one or more descriptions to one or
more actions. The set of testing data associated
with the Appearance training data set can be used
to test the learner&apos;s vocabulary, certain multi-
word combinations and full sentences. Using the
terminology found in Appearance&apos;s grammar
fragment (Figure 2), the LAT tests for the com-
prehension of shapes (SHP), colours (COL), ob-
jects (Nbar), indefinite objects (NP1), definite ob-
jects (NP2) and events (E).
In testing the learner&apos;s comprehension, the
LAT sends a description as input and receives a
set of actions as output. The output is automatic-
ally scored by comparing it with the expected
output that is associated with the description.
Actions are compared based on the feature values
that are relevant to the given description. Given
the description “a ye low cir cle to the u pper
right of the blue square” (Figure 3), the colours,
shapes and relative positions of the objects are
relevant whereas their exact positions are not.
The LAT equally accepts a yellow circle that ap-
pears higher or further right than its idealised po-
sition with respect to the blue square, as long as
the relative positions remain correct.
Borrowing from research in child language ac-
quisition studies, four kinds of incorrect re-
sponses are identified: over-extended; under-ex-
tended; mismatched; or incorrect. For example,
the meaning of the description “square” is under-
extended if the learner only uses it to refer to red
squares, blue squares and green squares, but not
to squares of other colours. Similarly, the mean-
ing of the description “red square” is over-exten-
ded if it refers to red squares, blue squares and
red circles. A mismatch is found if the descrip-
tion “square” is used to refer to objects other than
squares, for examples circles and triangles, but
never to squares themselves. Results that deviate
from these cases are simply considered incorrect.
</bodyText>
<page confidence="0.997885">
14
</page>
<bodyText confidence="0.999617705882353">
The LAT can score both single words and
phrases based on these categories.
In addition, the output produced by the learner
can also be described using the standard informa-
tion retrieval measures of precision, recall, and
the e-measure which is a weighted combination
of the two former values (van Rijsbergen, 1979).
The process of testing the learner&apos;s production
is similar to that of testing comprehension.
Rather than the LAT sending a description as in-
put, however, it sends an action. The learner then
produces a set of descriptions as output. Results
from production are scored using the same prin-
ciples as applied during comprehension. That is,
the learner&apos;s output is compared to the expected
output and it is scored as either correct, over-ex-
tended, under-extended, mismatched or incorrect.
</bodyText>
<subsectionHeader confidence="0.993087">
3.4 Analysing
</subsectionHeader>
<bodyText confidence="0.999885541666667">
Both the comprehension and production res-
ults that are produced from testing are used to
evaluate the learner&apos;s linguistic stage of develop-
ment. Several types of analysis have been de-
signed to ease learner comparisons: round-based;
trial-based; and learner-based. Round-based ana-
lyses analyse the results produced from a single
round of testing. Trial-based analyses take
round-based statistics and compare them with
previous rounds in order to find behavioural
trends in the data. Finally, learner-based ana-
lyses compare trial-based data for several trials in
order to extract general behavioural trends. By
performing analyses at all three levels of detail, a
more complete account of the learner&apos;s behaviour
is produced.
The LAT is currently able to perform a num-
ber of round-based analyses that are often found
in the literature: summary of test results in terms
of correct results and errors; chart the linguistic
generativity of the learner; and present evidence
of syntactic activity.
Round-based analyses produce results that are
then used to determine the model&apos;s stage of lin-
guistic development using data from child lan-
guage studies: pre-linguistic; holophrastic; early
multi-word; late multi-word; and abstract stages.
A number of trial-based analyses are per-
formed using these data, in order to identify par-
ticular linguistic behaviours: linguistic develop-
ment; vocabulary acquisition; comprehension/
production imbalance. With the creation of a lin-
guistic development timetable, all data can also
be presented in terms of stages. For example, the
number of words that are correctly comprehen-
ded and the rate of vocabulary acquisition can be
shown by stage.
Model-based analyses can performed when the
results from several trials are available. Each of
the results, such as the rate of vocabulary acquisi-
tion during a stage, are compared across trials to
identify general behavioural trends.
The LAT thus offers a standardised platform
for training, testing and analysing language mod-
els. The results from all analyses can be auto-
matically compared to determine the differences
between learners and which learner best fits child
language data.
</bodyText>
<sectionHeader confidence="0.997208" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999987205882353">
The LAT is a freely available tool that offers a
standardised environment from which language
modellers can develop their language learners. It
is an attempt to advance the domain by offering a
platform where common goals can be focussed
upon in a collaborative environment. It aims to
standardise the training, testing and analysing of
language learners by understanding the needs of
language modellers through collaboration.
By using the LAT, the language modeller ac-
cepts the need to work with standardised training
data. Such standardisation is widespread in com-
putational linguistics. For example, in the field
of automatic text classification, there are several
databases of pre-classified documents (e.g. Reu-
ters-21578, Reuters Corpus Volume 1 and 20
Newsgroups) that researchers can use to evaluate
different algorithms and to compare their results.
The LAT offers different sets of training data that
are constrained by principles of the miniature
language paradigm. In using such data, the mod-
elling task differs from the task that a child faces
in a number of ways. In particular, the learning
problem is simplified in that the real-world con-
tains many more objects and that natural lan-
guage has far more linguistic structures and
words than the language fragments. It is for
these reasons, however, that such a paradigm is
attractive. Many language learning problems can
be effectively investigated by first simplifying
the problem and then developing solutions.
When such problems in the miniature language
paradigm have been adequately solved, it is en-
visaged that the LAT can be grounded in a real
</bodyText>
<page confidence="0.994915">
15
</page>
<bodyText confidence="0.999887039215687">
environment where vast volumes of data are
available for processing.
The results from learning can then be tested
using a standardised set of tests. The learner is
treated as a black box, meaning that the LAT
evaluates its output alone without entering into
its inner workings. This helps to keep the LAT&apos;s
functionality independent from the learner by fo-
cussing on the way in which it behaves rather
than how it produces particular behaviours, simil-
ar to the relationship found between the linguist
and child in the real world. By testing both com-
prehension and production on a large set of de-
scriptions and actions, a complete picture of the
learner&apos;s linguistic state can be derived. The
LAT also checks for language errors such as
over-extensions, under-extensions and mis-
matches. Individual results are made available to
the researcher in a tabular format as well as
providing overall recall, precision and e-measure
scores.
By standardising the test results, different lan-
guage learners can be easily compared with one
another. The LAT can analyse these results to
discover behavioural trends in the data with can
be used in further comparisons. It is also inter-
esting to note that the LAT makes an attempt to
compare the behaviour produced by a language
learner with that of children. Inspired by child
language development timetables, a set of mile-
stones has been derived that are used to charac-
terise the learner&apos;s behaviour in terms of stages.
The LAT attempts to encourage researchers to
consider the developmental behaviour of their
language learners over time.
It is important to note that the LAT is a work
in progress. This disclaimer is likely to remain
true for many years. Developing a gold standard
is a difficult task and one that risks to evolve over
time. The LAT should be regarded as a proposal
for standardisation. Being a collaborative pro-
ject, any contributor can challenge this proposal
by offering their own solutions. Contributors are
encouraged to create their own data and al-
gorithms and to upload them to the LAT. A gold
standard can only emerge from the selections that
are made by other modellers, who vote by using
certain data and algorithms in their own model-
ling tasks. In this sense, the proposed instanti-
ation of the LAT described in this article is less
important than the idea behind the LAT itself.
</bodyText>
<sectionHeader confidence="0.995777" genericHeader="method">
5 Future Considerations
</sectionHeader>
<bodyText confidence="0.999989039215686">
In designing the LAT, it quickly became clear
that the task was not straight-forward. Designing
a tool that can make useful and standardised
comparisons between language learners is a com-
plex task. A balancing act between not excluding
certain types of learners and creating a con-
strained, manageable environment is not without
its difficulties. As such, it is worth considering
future developments for the LAT. While still in a
preliminary state of development, it is hoped that
a collaborative approach to the task will allow it
to be steered in the directions that are best adap-
ted to its potential users. A number of these dir-
ections are now considered.
The miniature language paradigm is at the
heart of the LAT. This language can be extended
to include more complex linguistic constructions
and a larger vocabulary. It is suggested that a
systematic approach is followed in which the
learning task is made progressively complex by
adding linguistic features that tend to be wit-
nessed in children during development. It seems
reasonable to follow a longitudinal approach to
development. Contributors are also encouraged
to create and submit new training data sets in or-
der to explore how complex a miniature language
can become.
The type of information that is available to the
learner could also be changed. At present, the
descriptions lack acoustic information such as
tone. Such data is indispensable in investigating
certain languages such as Mandarin and Swahili.
Similarly, the symbolic representations of visual
objects can be refined to better represent reality.
Colours can be represented by RGB values rather
than linguistically-related symbols, as it is un-
likely that children start with such pre-defined se-
mantic categories from the outset of learning.
It is also worthwhile considering more com-
plex testing and analysis algorithms. It is likely
that they will be developed in step with new lin-
guistic phenomena that are investigated, building
a useful catalogue of tools. In addition, it may be
useful to develop learner-dependant analysis
tools in order to demonstrate how the inner work-
ings are related to the outward behaviour.
Finally, it is hoped that the LAT will become a
useful resource not just for modellers who are
comfortable with coding but also non-program-
mers. They should be able to implement and ex-
periment with different kinds of models with the
</bodyText>
<page confidence="0.99015">
16
</page>
<bodyText confidence="0.999957125">
flexibility of looking at different aspects of ac-
quisition under different settings and with differ-
ent types of data. They can then inform language
modellers directly about how particular language
models perform well and poorly in certain cases.
The collaborative aspect of the LAT encourages
not just programmers to share their code, but for
everyone to share their ideas.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999962875">
This article proposes a tool that facilitates the
consolidation of research into the computational
modelling of child language acquisition under the
miniature language paradigm. The workshop is
being used to launch a first version of the LAT,
that is hoped to help language modellers and
child language experts to communicate and share
their knowledge.
</bodyText>
<sectionHeader confidence="0.999139" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9979352">
This research was supported by the Jean-Luc
Lagardère Foundation (http://www.fondation-
jeanluclagardere.com).
Many thanks to the anonymous reviewers for
their constructive comments.
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999932202531645">
Bertoncini, J., Bijeljac-Babic, R., Jusczyk, P., Kennedy, L.
&amp; Mehler, J. (1988). An investigation of Young infants&apos;
perceptual representations of speech sounds. Journal of
experimental psychology, 117, pp. 21-33.
Bijeljac-Babic, R., Bertoncini, J. &amp; Mehler, J. (1993). How
Do 4-Day-Old Infants Categorize Multisyllabic Utter-
ances?. Developmental Psychology, 29, pp. 711-721.
Brown, R. (1973). A First Language: The Early Stages.
Harvard University Press.
Dehaene-Lambertz, G. &amp; Houston, D. (1998). Faster Ori-
entation Latencies Toward Native Language in Two-
Month-Old Infants. Language and Speech, 41, pp.
21-43.
Elman, J. (1993). Learning and development in neural net-
works: the importance of starting small. Cognition, 48,
pp. 71-99.
Feldman, J., Lakoff, G., Stolcke, A. &amp; Weber, S. (1990,).
Miniature Language Acquisition: A Touchstone for
Cognitive Science.
Ingram, D. (1989). First Language Acquisition: Method,
Description and Explanation. Cambridge University
Press.
Jack, K. (2005,). Introducing a Scene Building Game to
Model Early First Language Acquisition, CLUK,
Manchester, England.
Kaplan, F., Oudeyer, P. &amp; Bergen, B. (2008). Computa-
tional models in the debate over language learnability.
Infant and Child Development, 17, pp. 55-80.
Kellman, P., Gleitman, H. &amp; Spelke, E. (1987). Object and
observer motion in the perception of objects by infants.
Journal of experimental psychology. Human perception
and performance, 13, pp. 586-593.
Landau, B., Smith, L. &amp; Jones, S. (1988). The importance
of shape in early lexical learning. Cognitive Develop-
ment, 3, pp. 299-321.
Mehler, J., Dupoux, T., Nazzi, T. &amp; Dehaene-Lambertz, G.
(1996). Coping with linguistic diversity: The infant&apos;s
viewpoint. Lawrence Erlbaum.
Mehler, J., Jusczyk, P., Lambertz, G., Halsted, N., Berton-
cini, J. &amp; Amiel-Tison, C. (1988). A precursor of lan-
guage acquisition in young infants. Cognition, 29, pp.
143-178.
Pinker, S. (1994). The Language Instinct. William Mor-
row.
Plunkett, K., Sinha, C., Moller, M. &amp; Strandsby, O. (1992).
Symbol grounding or the emergence of symbols?
Vocabulary growth in children and a connectionist net.
Connection Science, 4, pp. 293-312.
Quinn, P. &amp; Schyns, P. (2003). What goes up may come
down: perceptual process and knowledge access in the
organization of complex visual patterns by young in-
fants. Cognitive Science, 27, pp. 923-935.
Redington, M., Chater, N. &amp; Finch, S. (1988). Distribu-
tional Information: A powerful cue for acquiring syn-
tactic categories. Cognitive Science, 22, pp. 425-469.
Regier, T. (2005). The emergence of words : Attentional
learning in form and meaning. Cognitive Science, 29,
pp. 819-865.
Roy, D. (2008). A mechanistic model of three facets of
meaning. In M. D. Vega, G. Glennberg &amp; G. Graesser
(Eds.), Symbols and Embodiment. Oxford University
Press.
Rumelhart, D. &amp; Mcclelland, J. (1986). On learning the
past tenses of English verbs. In D. Rumelhart &amp; J. Mc-
clelland (Eds.), Parallel distributed processing: explor-
ations in the microstructure of cognition. MIT Press.
pp. 216-271.
Suppes, P., Liang, L. &amp; Bottner, M. (1991). Complexity Is-
sues in Robotic Machine Learning of Natural Language.
In L. Lam &amp; V. Naroditsky (Eds.), Modeling Complex
Phenomena. Springer Verlag.
Tomasello, M. (1995). Joint attention as social cognition.
In C. Moore &amp; P. J. Dunham (Eds.), Joint attention: Its
origins and role in development. Erlbaum.
Tomasello, M. (2005). Constructing a Language : A Us-
age-Based Theory of Language Acquisition. Harvard
University Press.
van Rijsbergen, C. J. (1979). Information Retrieval. Lon-
don, Butterworths.
</reference>
<page confidence="0.99941">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.168304">
<title confidence="0.9995275">A Collaborative Tool for the Computational Modelling of Language Acquisition</title>
<author confidence="0.5684395">Kris LIST</author>
<author confidence="0.5684395">Laboratoire de_la connaissance</author>
<affiliation confidence="0.360139">18 route du Panorama,</affiliation>
<address confidence="0.70079">Fontenay-aux-Roses, F-92265</address>
<email confidence="0.999668">mrkrisjack@gmail.com</email>
<abstract confidence="0.998321666666667">A large number of computational language learners have been proposed for modelling the process of child language acquisition. Comparing them, however, can be difficult due to the different assumptions that they make, the diverse test results presented, and the different linguistic behaviours investigated. This paper introduces a toolkit that allows different language learners to be trained, tested and analysed under standardised conditions. The results can be easily compared with one another and with typical child language development to highlight the relative advantages and disadvantages of learners.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bertoncini</author>
<author>R Bijeljac-Babic</author>
<author>P Jusczyk</author>
<author>L Kennedy</author>
<author>J Mehler</author>
</authors>
<title>An investigation of Young infants&apos; perceptual representations of speech sounds.</title>
<date>1988</date>
<journal>Journal of experimental psychology,</journal>
<volume>117</volume>
<pages>21--33</pages>
<contexts>
<context position="11297" citStr="Bertoncini et al., 1988" startWordPosition="1747" endWordPosition="1750">coustic sensitivity is so attuned that from four-days-old she demonstrates the ability to differentiate between native and nonnative speech (Mehler et al., 1988). Such discrimination lies in rhythmic properties that differ over language groups (Dehaene-Lambertz &amp; Houston, 1998; Mehler, Dupoux, Nazzi &amp; Dehaene-Lambertz, 1996) and is likely to be syllable-based since infants detect change in syllable quantity, but not in phoneme quantity over samples of speech (Bijeljac-Babic, Bertoncini &amp; Mehler, 1993). Infants also detect vowel change, a syllable covariant, more readily than consonant change (Bertoncini et al., 1988), further supporting a syllabic base. A description is thus represented as a non-zero length ordered list of syllables in the LAT. Word segmentations are not included as there is no acoustic equivalent of the blank space in written language. In terms of visual sensitivity, infants can identify objects through retinal and object displacement during motion from four months-old (Kellman, Gleitman &amp; Spelke, 1987), and make relative spacial distinctions between left and right, and above and below, from three to ten months old (Quinn &amp; Schyns, 2003). Infants can also make use of shape and colour to </context>
</contexts>
<marker>Bertoncini, Bijeljac-Babic, Jusczyk, Kennedy, Mehler, 1988</marker>
<rawString>Bertoncini, J., Bijeljac-Babic, R., Jusczyk, P., Kennedy, L. &amp; Mehler, J. (1988). An investigation of Young infants&apos; perceptual representations of speech sounds. Journal of experimental psychology, 117, pp. 21-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bijeljac-Babic</author>
<author>J Bertoncini</author>
<author>J Mehler</author>
</authors>
<title>How Do 4-Day-Old Infants Categorize Multisyllabic Utterances?.</title>
<date>1993</date>
<journal>Developmental Psychology,</journal>
<volume>29</volume>
<pages>711--721</pages>
<marker>Bijeljac-Babic, Bertoncini, Mehler, 1993</marker>
<rawString>Bijeljac-Babic, R., Bertoncini, J. &amp; Mehler, J. (1993). How Do 4-Day-Old Infants Categorize Multisyllabic Utterances?. Developmental Psychology, 29, pp. 711-721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brown</author>
</authors>
<title>A First Language: The Early Stages.</title>
<date>1973</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="6775" citStr="Brown, 1973" startWordPosition="1038" endWordPosition="1039">is assumes, of course, that the model has been described in enough detail that it can be faithfully recreated. Much time could be saved if such models were available for download, from a common repository, such as the Weka makes machine learning algorithms freely available in a software workbench (http://www.cs.waikato.ac.nz/~ml/). A good language learner should not just solve language learning problems, but should do so in a similar way as is witnessed in children. Based on psycho-linguistic evidence, several linguistic timetables have been derived containing important linguistic milestones (Brown, 1973; Ingram, 1989; Pinker, 1994; Tomasello, 2005). The character of language development is a significant feature in child language acquisition and modellers should be encouraged to model it to better understand the process. A language learner that demonstrates a good use of syntax at the same time as producing its first words is not very realistic. Instead, there should be a prolonged period in which words are learned followed by the emergence of syntax. Unfortunately, a language model can often produce behaviours at unexpected times, signalling a problem with the linguistic theory that it embod</context>
</contexts>
<marker>Brown, 1973</marker>
<rawString>Brown, R. (1973). A First Language: The Early Stages. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dehaene-Lambertz</author>
<author>D Houston</author>
</authors>
<title>Faster Orientation Latencies Toward Native Language in TwoMonth-Old Infants.</title>
<date>1998</date>
<journal>Language and Speech,</journal>
<volume>41</volume>
<pages>21--43</pages>
<contexts>
<context position="10950" citStr="Dehaene-Lambertz &amp; Houston, 1998" startWordPosition="1695" endWordPosition="1698">elves in order to associate a description with an action. This kind of relationship is typically called joint-attention and does not appear in children until around 12 months-old (Tomasello, 1995). As such, the symbolic content present in descriptions and actions are limited to those found in child literature during the first year of life. An infant&apos;s acoustic sensitivity is so attuned that from four-days-old she demonstrates the ability to differentiate between native and nonnative speech (Mehler et al., 1988). Such discrimination lies in rhythmic properties that differ over language groups (Dehaene-Lambertz &amp; Houston, 1998; Mehler, Dupoux, Nazzi &amp; Dehaene-Lambertz, 1996) and is likely to be syllable-based since infants detect change in syllable quantity, but not in phoneme quantity over samples of speech (Bijeljac-Babic, Bertoncini &amp; Mehler, 1993). Infants also detect vowel change, a syllable covariant, more readily than consonant change (Bertoncini et al., 1988), further supporting a syllabic base. A description is thus represented as a non-zero length ordered list of syllables in the LAT. Word segmentations are not included as there is no acoustic equivalent of the blank space in written language. In terms of</context>
</contexts>
<marker>Dehaene-Lambertz, Houston, 1998</marker>
<rawString>Dehaene-Lambertz, G. &amp; Houston, D. (1998). Faster Orientation Latencies Toward Native Language in TwoMonth-Old Infants. Language and Speech, 41, pp. 21-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Elman</author>
</authors>
<title>Learning and development in neural networks: the importance of starting small.</title>
<date>1993</date>
<journal>Cognition,</journal>
<volume>48</volume>
<pages>71--99</pages>
<contexts>
<context position="5052" citStr="Elman, 1993" startWordPosition="773" endWordPosition="774">ow each of them is related to one another given the lack of standardised learning, testing and analysis. Often, the variety found in computational models reflects the divisions between linguistic theories pertaining to child language acquisition (Kaplan, Oudeyer &amp; Bergen, 2008). Given that linguists remain divided about how children learn language, it is not surprising to find a similar division in the computational modelling community as well. One of the fundamental issues that separates modellers is the kind of data that the learner learns. This can range from the use of plain textual data (Elman, 1993), to grounded sensor-based input (Roy, 2008). Standardising the type of learning data would thus be useful for comparing language learners. Typical computational models are often tested under different circumstances and using different techniques. For example, while some papers offer a general analysis of the model&apos;s behaviour, others focus on particular features, while some test language comprehension, others test language production, and while some consider developmental growth, others consider only the start and end points of training. Although this is often justifiable in the context of th</context>
</contexts>
<marker>Elman, 1993</marker>
<rawString>Elman, J. (1993). Learning and development in neural networks: the importance of starting small. Cognition, 48, pp. 71-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Feldman</author>
<author>G Lakoff</author>
<author>A Stolcke</author>
<author>S Weber</author>
</authors>
<title>Miniature Language Acquisition: A Touchstone for Cognitive Science.</title>
<date>1990</date>
<contexts>
<context position="3826" citStr="Feldman et al., 1990" startWordPosition="586" endWordPosition="589">in, test and analyse the linguistic performance of a computational language learner in order to chart developmental linguistic trajectories. The motivation for the LAT shall first be explored before describing it in detail, discussing its features and considering future directions. Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 10–17, Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics 10 2 Background The process of modelling child language acquisition is very complex, as many of the first attempts confirmed (Feldman et al., 1990; Suppes, Liang &amp; Bottner, 1991). Rather than modelling the process in entirety, an undoubtedly daunting task, modellers took the simplified approach of focusing upon individual linguistic behaviours, leading to much research into relatively constrained problems such as understanding overand under-generalisation errors (Plunkett, Sinha, Moller &amp; Strandsby, 1992), single word learning (Regier, 2005), syntactic category acquisition (Redington, Chater &amp; Finch, 1988) and pasttense learning (Rumelhart &amp; Mcclelland, 1986). While such models have led to valuable insights in the domain, it can be diff</context>
<context position="7990" citStr="Feldman et al., 1990" startWordPosition="1227" endWordPosition="1230"> embodies. A standardised approach to analysing the linguistic development of a language learner would be an advantage. 3 The Language Acquisition Toolkit 3.1 Introduction The Language Acquisition Toolkit (LAT) is a piece of software that allows researchers to develop and test computational language learners within a standardised environment. The LAT&apos;s target users are researchers who have basic skills in software development and are comfortable using the programming language Java. It assumes that the language learner operates under the restrictions imposed in the miniature language paradigm (Feldman et al., 1990). The LAT can be obtained from www.langac.com and is available under a GNU public license meaning that the code can be reproduced and modified without obtaining permission. The LAT is an attempt to standardise the training, testing and analysing of language learners within an open an accessible environment (Figure 1). In training, the language learner observes a 11 simulated world in which action-based events occur. Both simulated descriptions and visual data are sent to the language learner for analysis. The LAT then tests both the language learner&apos;s comprehension and production capacities. C</context>
<context position="9443" citStr="Feldman et al., 1990" startWordPosition="1454" endWordPosition="1458"> The LAT then analyses the results obtained from testing and develops data describing the learner&apos;s development. Training Analysing Figure 1: LAT Overview. A language learner is placed in the LAT&apos;s simulated world where it learns from simulated audio and visual data. The LAT tests the learner and the results are used to produce data describing its development. 3.2 Training The LAT can be configured to train different language learners by generating a simulated environment in which action-based events occur. The simulated environment operates within the miniature language acquisition paradigm (Feldman et al., 1990), a simplified simulation of the real-world. A simulation is employed rather than grounding the model in the real-world in order to better control the number and type of problems that are being investigated in a single experiment. While the miniature language paradigm imposes a number of constraints, the proposed simulation contains enough complexity to justify its use. The learner is trained by watching an event that is simulated in the blocks world in which a number of geometric objects can be found. When an event occurs, a symbolic representation of the description and visual data are gener</context>
</contexts>
<marker>Feldman, Lakoff, Stolcke, Weber, 1990</marker>
<rawString>Feldman, J., Lakoff, G., Stolcke, A. &amp; Weber, S. (1990,). Miniature Language Acquisition: A Touchstone for Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ingram</author>
</authors>
<title>First Language Acquisition: Method, Description and Explanation.</title>
<date>1989</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6789" citStr="Ingram, 1989" startWordPosition="1040" endWordPosition="1041">f course, that the model has been described in enough detail that it can be faithfully recreated. Much time could be saved if such models were available for download, from a common repository, such as the Weka makes machine learning algorithms freely available in a software workbench (http://www.cs.waikato.ac.nz/~ml/). A good language learner should not just solve language learning problems, but should do so in a similar way as is witnessed in children. Based on psycho-linguistic evidence, several linguistic timetables have been derived containing important linguistic milestones (Brown, 1973; Ingram, 1989; Pinker, 1994; Tomasello, 2005). The character of language development is a significant feature in child language acquisition and modellers should be encouraged to model it to better understand the process. A language learner that demonstrates a good use of syntax at the same time as producing its first words is not very realistic. Instead, there should be a prolonged period in which words are learned followed by the emergence of syntax. Unfortunately, a language model can often produce behaviours at unexpected times, signalling a problem with the linguistic theory that it embodies. A standar</context>
</contexts>
<marker>Ingram, 1989</marker>
<rawString>Ingram, D. (1989). First Language Acquisition: Method, Description and Explanation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jack</author>
</authors>
<title>Introducing a Scene Building Game to Model Early First Language Acquisition,</title>
<date>2005</date>
<location>CLUK, Manchester, England.</location>
<contexts>
<context position="15086" citStr="Jack, 2005" startWordPosition="2371" endWordPosition="2372"> screen in enough detail that a stranger could recreate the scene using only their descriptions. By pressing a key on the keyboard, a new geometric object appeared on the screen and the change was described by the participant. While the addition of an object to a scene appears to be a trivial change, participants produced complex linguistic descriptions that revealed a deep knowledge of their language. For example, descriptions such as “a blue circle appeared to the upper right of the green square at the bottom” and “a red circle appeared between the four squares making the shape of a cross” (Jack, 2005). Given the complexity of the language produced, a simplified version the task was constructed in which only the appearance of one object next to another object was considered. By restricting the context, there is less demand for a computational language learner to have a rich semantic representation of scenes. This served as a reasonable starting point from which to conduct the investigation. The actions in the Appearance data set were constructed by randomly generating one object and placing it in the middle of a 3x3 grid scene and then adding a second object, which was also randomly generat</context>
</contexts>
<marker>Jack, 2005</marker>
<rawString>Jack, K. (2005,). Introducing a Scene Building Game to Model Early First Language Acquisition, CLUK, Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Kaplan</author>
<author>P Oudeyer</author>
<author>B Bergen</author>
</authors>
<title>Computational models in the debate over language learnability.</title>
<date>2008</date>
<journal>Infant and Child Development,</journal>
<volume>17</volume>
<pages>55--80</pages>
<marker>Kaplan, Oudeyer, Bergen, 2008</marker>
<rawString>Kaplan, F., Oudeyer, P. &amp; Bergen, B. (2008). Computational models in the debate over language learnability. Infant and Child Development, 17, pp. 55-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kellman</author>
<author>H Gleitman</author>
<author>E Spelke</author>
</authors>
<title>Object and observer motion in the perception of objects by infants. Journal of experimental psychology. Human perception and performance, 13,</title>
<date>1987</date>
<pages>586--593</pages>
<marker>Kellman, Gleitman, Spelke, 1987</marker>
<rawString>Kellman, P., Gleitman, H. &amp; Spelke, E. (1987). Object and observer motion in the perception of objects by infants. Journal of experimental psychology. Human perception and performance, 13, pp. 586-593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Landau</author>
<author>L Smith</author>
<author>S Jones</author>
</authors>
<title>The importance of shape in early lexical learning.</title>
<date>1988</date>
<journal>Cognitive Development,</journal>
<volume>3</volume>
<pages>299--321</pages>
<marker>Landau, Smith, Jones, 1988</marker>
<rawString>Landau, B., Smith, L. &amp; Jones, S. (1988). The importance of shape in early lexical learning. Cognitive Development, 3, pp. 299-321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mehler</author>
<author>T Dupoux</author>
<author>T Nazzi</author>
<author>G Dehaene-Lambertz</author>
</authors>
<title>Coping with linguistic diversity: The infant&apos;s viewpoint. Lawrence Erlbaum.</title>
<date>1996</date>
<marker>Mehler, Dupoux, Nazzi, Dehaene-Lambertz, 1996</marker>
<rawString>Mehler, J., Dupoux, T., Nazzi, T. &amp; Dehaene-Lambertz, G. (1996). Coping with linguistic diversity: The infant&apos;s viewpoint. Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mehler</author>
<author>P Jusczyk</author>
<author>G Lambertz</author>
<author>N Halsted</author>
<author>J Bertoncini</author>
<author>C Amiel-Tison</author>
</authors>
<title>A precursor of language acquisition in young infants.</title>
<date>1988</date>
<journal>Cognition,</journal>
<volume>29</volume>
<pages>143--178</pages>
<contexts>
<context position="10834" citStr="Mehler et al., 1988" startWordPosition="1679" endWordPosition="1682"> is assumed that the learner can establish a triadic relationship between an object, a speaker and themselves in order to associate a description with an action. This kind of relationship is typically called joint-attention and does not appear in children until around 12 months-old (Tomasello, 1995). As such, the symbolic content present in descriptions and actions are limited to those found in child literature during the first year of life. An infant&apos;s acoustic sensitivity is so attuned that from four-days-old she demonstrates the ability to differentiate between native and nonnative speech (Mehler et al., 1988). Such discrimination lies in rhythmic properties that differ over language groups (Dehaene-Lambertz &amp; Houston, 1998; Mehler, Dupoux, Nazzi &amp; Dehaene-Lambertz, 1996) and is likely to be syllable-based since infants detect change in syllable quantity, but not in phoneme quantity over samples of speech (Bijeljac-Babic, Bertoncini &amp; Mehler, 1993). Infants also detect vowel change, a syllable covariant, more readily than consonant change (Bertoncini et al., 1988), further supporting a syllabic base. A description is thus represented as a non-zero length ordered list of syllables in the LAT. Word s</context>
</contexts>
<marker>Mehler, Jusczyk, Lambertz, Halsted, Bertoncini, Amiel-Tison, 1988</marker>
<rawString>Mehler, J., Jusczyk, P., Lambertz, G., Halsted, N., Bertoncini, J. &amp; Amiel-Tison, C. (1988). A precursor of language acquisition in young infants. Cognition, 29, pp. 143-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pinker</author>
</authors>
<title>The Language Instinct.</title>
<date>1994</date>
<location>William Morrow.</location>
<contexts>
<context position="6803" citStr="Pinker, 1994" startWordPosition="1042" endWordPosition="1043"> the model has been described in enough detail that it can be faithfully recreated. Much time could be saved if such models were available for download, from a common repository, such as the Weka makes machine learning algorithms freely available in a software workbench (http://www.cs.waikato.ac.nz/~ml/). A good language learner should not just solve language learning problems, but should do so in a similar way as is witnessed in children. Based on psycho-linguistic evidence, several linguistic timetables have been derived containing important linguistic milestones (Brown, 1973; Ingram, 1989; Pinker, 1994; Tomasello, 2005). The character of language development is a significant feature in child language acquisition and modellers should be encouraged to model it to better understand the process. A language learner that demonstrates a good use of syntax at the same time as producing its first words is not very realistic. Instead, there should be a prolonged period in which words are learned followed by the emergence of syntax. Unfortunately, a language model can often produce behaviours at unexpected times, signalling a problem with the linguistic theory that it embodies. A standardised approach</context>
</contexts>
<marker>Pinker, 1994</marker>
<rawString>Pinker, S. (1994). The Language Instinct. William Morrow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Plunkett</author>
<author>C Sinha</author>
<author>M Moller</author>
<author>O Strandsby</author>
</authors>
<title>Symbol grounding or the emergence of symbols? Vocabulary growth in children and a connectionist net.</title>
<date>1992</date>
<journal>Connection Science,</journal>
<volume>4</volume>
<pages>293--312</pages>
<marker>Plunkett, Sinha, Moller, Strandsby, 1992</marker>
<rawString>Plunkett, K., Sinha, C., Moller, M. &amp; Strandsby, O. (1992). Symbol grounding or the emergence of symbols? Vocabulary growth in children and a connectionist net. Connection Science, 4, pp. 293-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Quinn</author>
<author>P Schyns</author>
</authors>
<title>What goes up may come down: perceptual process and knowledge access in the organization of complex visual patterns by young infants.</title>
<date>2003</date>
<journal>Cognitive Science,</journal>
<volume>27</volume>
<pages>923--935</pages>
<contexts>
<context position="11846" citStr="Quinn &amp; Schyns, 2003" startWordPosition="1837" endWordPosition="1840"> covariant, more readily than consonant change (Bertoncini et al., 1988), further supporting a syllabic base. A description is thus represented as a non-zero length ordered list of syllables in the LAT. Word segmentations are not included as there is no acoustic equivalent of the blank space in written language. In terms of visual sensitivity, infants can identify objects through retinal and object displacement during motion from four months-old (Kellman, Gleitman &amp; Spelke, 1987), and make relative spacial distinctions between left and right, and above and below, from three to ten months old (Quinn &amp; Schyns, 2003). Infants can also make use of shape and colour to differentiate between objects in the first year of life (Landau, Smith &amp; Jones, 1988). The LAT thus describes the physical properties of objects that inhabit the blocks world (e.g. shape, colour, size and position), referred to as features. An action is defined as a non-zero length ordered list of feature sets, where each feature set is associated with a unique time interval. A set of features describes all objects that can be seen in an event. Note that actions in this terminology do not relate to actions in terms of verbs in natural language</context>
</contexts>
<marker>Quinn, Schyns, 2003</marker>
<rawString>Quinn, P. &amp; Schyns, P. (2003). What goes up may come down: perceptual process and knowledge access in the organization of complex visual patterns by young infants. Cognitive Science, 27, pp. 923-935.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Redington</author>
<author>N Chater</author>
<author>S Finch</author>
</authors>
<title>Distributional Information: A powerful cue for acquiring syntactic categories.</title>
<date>1988</date>
<journal>Cognitive Science,</journal>
<volume>22</volume>
<pages>425--469</pages>
<marker>Redington, Chater, Finch, 1988</marker>
<rawString>Redington, M., Chater, N. &amp; Finch, S. (1988). Distributional Information: A powerful cue for acquiring syntactic categories. Cognitive Science, 22, pp. 425-469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Regier</author>
</authors>
<title>The emergence of words : Attentional learning in form and meaning.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<volume>29</volume>
<pages>819--865</pages>
<contexts>
<context position="4227" citStr="Regier, 2005" startWordPosition="642" endWordPosition="643">, 31 March 2009. c�2009 Association for Computational Linguistics 10 2 Background The process of modelling child language acquisition is very complex, as many of the first attempts confirmed (Feldman et al., 1990; Suppes, Liang &amp; Bottner, 1991). Rather than modelling the process in entirety, an undoubtedly daunting task, modellers took the simplified approach of focusing upon individual linguistic behaviours, leading to much research into relatively constrained problems such as understanding overand under-generalisation errors (Plunkett, Sinha, Moller &amp; Strandsby, 1992), single word learning (Regier, 2005), syntactic category acquisition (Redington, Chater &amp; Finch, 1988) and pasttense learning (Rumelhart &amp; Mcclelland, 1986). While such models have led to valuable insights in the domain, it can be difficult to see how each of them is related to one another given the lack of standardised learning, testing and analysis. Often, the variety found in computational models reflects the divisions between linguistic theories pertaining to child language acquisition (Kaplan, Oudeyer &amp; Bergen, 2008). Given that linguists remain divided about how children learn language, it is not surprising to find a simil</context>
</contexts>
<marker>Regier, 2005</marker>
<rawString>Regier, T. (2005). The emergence of words : Attentional learning in form and meaning. Cognitive Science, 29, pp. 819-865.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roy</author>
</authors>
<title>A mechanistic model of three facets of meaning. In</title>
<date>2008</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="5096" citStr="Roy, 2008" startWordPosition="779" endWordPosition="780">n the lack of standardised learning, testing and analysis. Often, the variety found in computational models reflects the divisions between linguistic theories pertaining to child language acquisition (Kaplan, Oudeyer &amp; Bergen, 2008). Given that linguists remain divided about how children learn language, it is not surprising to find a similar division in the computational modelling community as well. One of the fundamental issues that separates modellers is the kind of data that the learner learns. This can range from the use of plain textual data (Elman, 1993), to grounded sensor-based input (Roy, 2008). Standardising the type of learning data would thus be useful for comparing language learners. Typical computational models are often tested under different circumstances and using different techniques. For example, while some papers offer a general analysis of the model&apos;s behaviour, others focus on particular features, while some test language comprehension, others test language production, and while some consider developmental growth, others consider only the start and end points of training. Although this is often justifiable in the context of the research problem, it makes it difficult to</context>
</contexts>
<marker>Roy, 2008</marker>
<rawString>Roy, D. (2008). A mechanistic model of three facets of meaning. In M. D. Vega, G. Glennberg &amp; G. Graesser (Eds.), Symbols and Embodiment. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rumelhart</author>
<author>J Mcclelland</author>
</authors>
<title>On learning the past tenses of English verbs. In</title>
<date>1986</date>
<pages>216--271</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4347" citStr="Rumelhart &amp; Mcclelland, 1986" startWordPosition="656" endWordPosition="659">ng child language acquisition is very complex, as many of the first attempts confirmed (Feldman et al., 1990; Suppes, Liang &amp; Bottner, 1991). Rather than modelling the process in entirety, an undoubtedly daunting task, modellers took the simplified approach of focusing upon individual linguistic behaviours, leading to much research into relatively constrained problems such as understanding overand under-generalisation errors (Plunkett, Sinha, Moller &amp; Strandsby, 1992), single word learning (Regier, 2005), syntactic category acquisition (Redington, Chater &amp; Finch, 1988) and pasttense learning (Rumelhart &amp; Mcclelland, 1986). While such models have led to valuable insights in the domain, it can be difficult to see how each of them is related to one another given the lack of standardised learning, testing and analysis. Often, the variety found in computational models reflects the divisions between linguistic theories pertaining to child language acquisition (Kaplan, Oudeyer &amp; Bergen, 2008). Given that linguists remain divided about how children learn language, it is not surprising to find a similar division in the computational modelling community as well. One of the fundamental issues that separates modellers is </context>
</contexts>
<marker>Rumelhart, Mcclelland, 1986</marker>
<rawString>Rumelhart, D. &amp; Mcclelland, J. (1986). On learning the past tenses of English verbs. In D. Rumelhart &amp; J. Mcclelland (Eds.), Parallel distributed processing: explorations in the microstructure of cognition. MIT Press. pp. 216-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Suppes</author>
<author>L Liang</author>
<author>M Bottner</author>
</authors>
<title>Complexity Issues in Robotic Machine Learning of Natural Language. In</title>
<date>1991</date>
<publisher>Springer Verlag.</publisher>
<marker>Suppes, Liang, Bottner, 1991</marker>
<rawString>Suppes, P., Liang, L. &amp; Bottner, M. (1991). Complexity Issues in Robotic Machine Learning of Natural Language. In L. Lam &amp; V. Naroditsky (Eds.), Modeling Complex Phenomena. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomasello</author>
</authors>
<title>Joint attention as social cognition. In</title>
<date>1995</date>
<publisher>Erlbaum.</publisher>
<contexts>
<context position="10514" citStr="Tomasello, 1995" startWordPosition="1630" endWordPosition="1631">in which a number of geometric objects can be found. When an event occurs, a symbolic representation of the description and visual data are generated. More concretely, an event is the pairing of a simulated description and a action, e=〈d , a〉 . Events are represented following evidence from child studies. First, it is assumed that the learner can establish a triadic relationship between an object, a speaker and themselves in order to associate a description with an action. This kind of relationship is typically called joint-attention and does not appear in children until around 12 months-old (Tomasello, 1995). As such, the symbolic content present in descriptions and actions are limited to those found in child literature during the first year of life. An infant&apos;s acoustic sensitivity is so attuned that from four-days-old she demonstrates the ability to differentiate between native and nonnative speech (Mehler et al., 1988). Such discrimination lies in rhythmic properties that differ over language groups (Dehaene-Lambertz &amp; Houston, 1998; Mehler, Dupoux, Nazzi &amp; Dehaene-Lambertz, 1996) and is likely to be syllable-based since infants detect change in syllable quantity, but not in phoneme quantity o</context>
</contexts>
<marker>Tomasello, 1995</marker>
<rawString>Tomasello, M. (1995). Joint attention as social cognition. In C. Moore &amp; P. J. Dunham (Eds.), Joint attention: Its origins and role in development. Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomasello</author>
</authors>
<title>Constructing a Language : A Usage-Based Theory of Language Acquisition.</title>
<date>2005</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="6821" citStr="Tomasello, 2005" startWordPosition="1044" endWordPosition="1045"> been described in enough detail that it can be faithfully recreated. Much time could be saved if such models were available for download, from a common repository, such as the Weka makes machine learning algorithms freely available in a software workbench (http://www.cs.waikato.ac.nz/~ml/). A good language learner should not just solve language learning problems, but should do so in a similar way as is witnessed in children. Based on psycho-linguistic evidence, several linguistic timetables have been derived containing important linguistic milestones (Brown, 1973; Ingram, 1989; Pinker, 1994; Tomasello, 2005). The character of language development is a significant feature in child language acquisition and modellers should be encouraged to model it to better understand the process. A language learner that demonstrates a good use of syntax at the same time as producing its first words is not very realistic. Instead, there should be a prolonged period in which words are learned followed by the emergence of syntax. Unfortunately, a language model can often produce behaviours at unexpected times, signalling a problem with the linguistic theory that it embodies. A standardised approach to analysing the </context>
</contexts>
<marker>Tomasello, 2005</marker>
<rawString>Tomasello, M. (2005). Constructing a Language : A Usage-Based Theory of Language Acquisition. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<location>London, Butterworths.</location>
<marker>van Rijsbergen, 1979</marker>
<rawString>van Rijsbergen, C. J. (1979). Information Retrieval. London, Butterworths.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>