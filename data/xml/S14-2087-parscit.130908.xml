<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.046594">
<title confidence="0.976685">
SA-UZH: Verb-based Sentiment Analysis
</title>
<author confidence="0.992528">
Nora Hollenstein, Michi Amsler, Martina Bachmann, Manfred Klenner
</author>
<affiliation confidence="0.990877">
Institute of Computational Linguistics, University of Zurich
</affiliation>
<address confidence="0.94283">
Binzmuehlestrasse 14, CH-8050 Zurich, Switzerland
</address>
<email confidence="0.996581">
{hollenstein,mamsler,bachmann,klenner}@ifi.uzh.ch
</email>
<sectionHeader confidence="0.994742" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999851875">
This paper describes the details of our
system submitted to the SemEval-2014
shared task about aspect-based sentiment
analysis on review texts. We participated
in subtask 2 (prediction of the polarity
of aspect terms) and 4 (prediction of the
polarity of aspect categories). Our ap-
proach to determine the sentiment of as-
pect terms and categories is based on lin-
guistic preprocessing, including a com-
positional analysis and a verb resource,
task-specific feature engineering and su-
pervised machine learning techniques. We
used a Logistic Regression classifier to
make predictions, which were ranked
above-average in the shared task.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999703705882353">
Aspect-based sentiment analysis refers to the
problem of predicting the polarity of an explicit
or implicit mention of a target in a sentence or
text. The SemEval-2014 shared task required sen-
timent analysis of laptop and restaurant reviews
on sentence level and comprised four subtasks
(Pontiki et al., 2014). The organizers created and
shared manually labelled domain-specific training
and test data sets. Two of the four subtasks dealt
with determining the sentiment of a given aspect
term (explicitly mentioned) or aspect category (ex-
plicitly or implicitly mentioned) in a sentence.
The subtasks we participated in do not include the
recognition of aspects. Given the sentence “The
sushi rolls were perfect, but overall it was too ex-
pensive.”, “sushi rolls” is an aspect term, and the
corresponding aspect categories are “food” and
</bodyText>
<footnote confidence="0.91877525">
This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.8061975">
“price”. The correct predictions would be the fol-
lowing:
</bodyText>
<listItem confidence="0.99075975">
• Subtask 2 (aspect terms): {sushi rolls ➝ pos-
itive}
• Subtask 4 (aspect categories): {food ➝ posi-
tive, price ➝ negative}
</listItem>
<bodyText confidence="0.9999168">
To solve these tasks, we introduce a Logis-
tic Regression Model for target-specific sentiment
analysis. Features are derived from a fine-grained
polarity lexicon, a verb resource specifying expec-
tations and effects of the verbs functional roles,
and a compositional analysis. In our experiments
on the restaurant and laptop reviews data for the
SemEval-2014 shared task, we found that im-
provements over the baseline are possible for all
classes except “conflict”.
</bodyText>
<sectionHeader confidence="0.999732" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999604">
We focus on the question whether fine-grained lin-
guistic sentiment analysis improves target-specific
polarity classification. Existing approaches to
aspect-based sentiment detection have focused on
different aspects of this task, e.g. the identifi-
cation of targets and their components (Popescu
and Etzioni, 2005) and sentence-level composition
(Moilanen and Pulman, 2007). Ding et al. (2008)
and Hu and Liu (2004) produced lexicon-based
approaches, which perform quite well in a large
number of domains, and Blair-Goldensohn et al.
(2008) combined lexicon-based methods and su-
pervised learning. Jiang et al. (2011) used a depen-
dency parser to generate a set of aspect dependent
features for classification. For our system we built
a sentiment composition resembling the one of
L¨aubli et al. (2012), which was developed for Ger-
man. Moreover, our verb resource has some simi-
larity with the one of Neviarouskaya et al. (2009):
both rely on verb classes and utilize verb-specific
</bodyText>
<page confidence="0.981744">
503
</page>
<note confidence="0.7282565">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 503–507,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.995556">
behavior. However, only we specify the individ-
ual verb’s (default) perspective on each role (and
are, thus, able to count polar propagations). See
also Reschke and Anand (2011), who describe in
detail how polar (verb) complements combine to
verb frame polarity (again without recording and
using role perspectives as we do).
</bodyText>
<sectionHeader confidence="0.984739" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.999939111111111">
In this section we present the details of our senti-
ment analysis system. We used the same prepro-
cessing and learning algorithm for both subtasks
(2 &amp; 4). Only the feature extraction was expanded
in subtask 4 for determining the polarities of as-
pect categories (see section 3.3). The data sets
consisted of restaurant and laptop reviews, which
comprise about 3’000 manually classified target-
specific sentences for each domain.
</bodyText>
<subsectionHeader confidence="0.99961">
3.1 Sentiment Composition
</subsectionHeader>
<bodyText confidence="0.999985714285714">
The fundamental steps of our sentiment analysis
system are parsing the sentences, rule-based sen-
timent analysis using a polarity lexicon and a verb
resource, feature extraction and training a machine
learning algorithm. In this section we will de-
scribe the composition of the lexicon as well as the
structure of the sentiment composition pipeline.
</bodyText>
<subsectionHeader confidence="0.769019">
Category Example
</subsectionHeader>
<bodyText confidence="0.993058625">
POS strong “awesome”
POS weak “adequate”
NEG strong “catastrophe”
NEG weak “demotivated”
POS active “generous”
POS passive “noteworthy”
NEG active “rebellion”
NEG passive “orphaned”
</bodyText>
<tableCaption confidence="0.5204195">
Table 1: Additional categories in our fine-grained
polarity lexicon
</tableCaption>
<bodyText confidence="0.999975181818182">
The same polarity lexicon was used for both
domains. After mapping the polarities from the
lexicon to the words and multi-word expressions,
we calculated the polarity of nominal (NPs) and
prepositional phrases (PPs) by means of lexical
marking and the syntactic analysis of a depen-
dency parser (Choi and Palmer, 2011). We did not
implement any rules for neutral phrases, all words
and phrases not marked as positive or negative are
considered as neutral. In general, the polarities are
propagated bottom-up to their respective heads of
the NPs/PPs in composition with the subordinates.
Shifters and negation words are also taken into ac-
count. The parser output is converted into a con-
straint grammar (CG) format for the subsequent
analysis of words and phrases. To conduct this
composition of polarity for the phrases we imple-
mented a CG with the vislcg3 tools (VISL-group,
2013). The next stage of our sentiment detection
is the verb resource, which was also implemented
with the vislcg3 tools and will be explained in the
next section.
</bodyText>
<subsectionHeader confidence="0.999839">
3.2 Verb-based Sentiment Analysis
</subsectionHeader>
<bodyText confidence="0.9999925">
In order to combine the composition of the po-
lar phrases with verb information, we encoded the
impact of the verbs on polarity using three di-
mensions: effects, expectations and verb polarity.
While effects should be understood as the outcome
instantiated through the verb, expectations can be
understood as anticipated polarities induced by the
verb. Effects and expectations are assigned to sub-
jects or objects, not to the verb itself. A positive
or negative verb effect propagates from the verb to
a subject or object if the latter receives the polar-
ity of the verb. For a verb expectation, the subject
or object is expected to be polar and thus receives
a polarity even if the sentiment composition re-
sulted neutral (see examples below). The verb po-
larity as such is the evaluation of the whole verbal
phrase. Moreover, we process predicative and pas-
sive verbs, adapting the effects and expectations to
the syntactic structure.
Since these effects and expectations match di-
rectly to the subject and objects of a sentence,
they are of great use detecting the polarity of as-
pect terms (which are predominantly subjects or
objects). We present the following examples ex-
tracted from the training data to illustrate three di-
mensions annotated by the verb analysis:
</bodyText>
<listItem confidence="0.967961454545454">
• Example of a positive effect on the direct ob-
ject of a sentence induced by the verb: “I
love (verb POS) the operating system and the
preloaded software (POS EFF).”
• Example for a negative expectation on a
prepositional object induced by the verb:
“[...] the guy, who constantly com-
plains (verb NEG) about the noise level
(NEG EXP).”
• Example of positive predicative effects
with an auxiliary, non-polar verb: “Ser-
</listItem>
<page confidence="0.99408">
504
</page>
<bodyText confidence="0.999930375">
vice (POS predicative) is (verb PRED) great,
takeout (POS predicative) is (verb PRED)
good too.”
Furthermore, we make a distinction between the
different prepositions a verb can invoke and the
succeeding semantic changes. For example, the
verb “to die” can be annotated in three different
manners, depending on the prepositional object:
</bodyText>
<listItem confidence="0.9892494">
1. “My phone died (verb NEG).”
2. “Their pizza (POS EFF) is to die (verb POS)
for.”
3. “He died (verb NEG) of cancer
(NEG EXP).”
</listItem>
<bodyText confidence="0.9945595">
To summarize, in addition to verb polarity, we
introduce effects and expectations to verb frames,
which are determined through the syntactic pattern
found, the bottom-up calculated phrase polarities
and the meaning of the verb itself. We manually
categorized approx. 300 of the most frequent pos-
itive and negative English verbs and their respec-
tive verb frames.
</bodyText>
<table confidence="0.999391916666667">
Laptop reviews
Feature Occurrences in %
Verbs effects 367 12.05
Verb expectations 6 0.02
Predicatives 298 9.78
Polar verbs 530 17.39
Restaurant reviews
Feature Occurrences in %
Verbs effects 246 8.09
Verb expectations 12 0.04
Predicatives 378 12.43
Polar verbs 521 17.13
</table>
<tableCaption confidence="0.9636">
Table 2: Occurrences and percentage of sentences
</tableCaption>
<bodyText confidence="0.994083692307692">
of annotated polar verb features in the training data
of the shared task
In table 2, we illustrate the relevance of the lin-
guistic features of this verb resource by showing in
how many sentences of the training set these anno-
tations appear. Since we merely annotated the verb
frames of the most frequent English verbs, it is
conceivable that this resource may have a consid-
erably greater effect if more domain-specific verbs
are modelled.
After this final sentiment composition step, all
derived polarity chunks are converted into a set of
features for machine learning algorithms.
</bodyText>
<subsectionHeader confidence="0.998283">
3.3 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.998279333333333">
In a first step of our system, the sentences are
parsed, phrase polarities are calculated and verb
effects and expectations are assigned. Subse-
quently, a feature extractor, which extracts and ag-
gregates polar information, operates on the out-
put. The Simple Logistic Regression classifier
from weka Hall et al. (2009) is then trained on
these features.
We developed a feature extraction pipeline that
retrieves information about various polarity levels
in words, syntactic functions and phrases of the
sentences in the data set. In order to use our senti-
ment composition approach for machine learning,
we extract three different sets of features, result-
ing in a total of 32 features for subtask 2 and 39
features for subtask 4.
In short, the feature sets are constructed as fol-
lows:
</bodyText>
<listItem confidence="0.99921925">
• Lexicon-based features: These features com-
prise simple frequency counts of positive and
negative words in the sentences and binary
features showing whether any positive or
negative, strong or active tokens are present
at all. Furthermore, these features not only
include absolute counts but also token ratios.
• Composition-based features: This feature set
</listItem>
<bodyText confidence="0.959784428571429">
describes the information found in nomi-
nal, prepositional and verbal phrases, such
as the number of positive/negative phrase
heads or predicative verb effects found. It
is also possible to distinguish between fea-
tures which represent frequency counts and
features which represent polarity ratios.
</bodyText>
<listItem confidence="0.959210785714286">
• Target-specific features: This set includes
features from the previous two sets in con-
nection with the aspect terms, e.g. whether
the aspect term has a verb expectation or
whether the aspect term is the head of a neg-
ative/positive phrase, the subject or direct ob-
ject, etc. In this set we also include accu-
mulative features that represent the complete
amount of polar information in connection
with an aspect term.
• (only for subtask 4) Category-specific fea-
tures: These features are based on a co-
occurrence analysis of the most frequent
words used in each category. That is to
</listItem>
<page confidence="0.997538">
505
</page>
<bodyText confidence="0.999970933333333">
say, we calculated the frequencies of all po-
lar nouns, verbs and adjectives that appear in
sentences of the same category in order to
find category-specific words which have an
influence on the polarity. This set includes
features such as the number of category-
specific words occurring in the sentence, etc.
For the classification of the aspect terms and
categories of the sentences into the four classes
(positive, negative, neutral and conflict), we
trained a Simple Logistic Regression classifier on
the features described above. We also explored
other machine learning algorithms such as SVMs
and artificial neural networks, however, the Logis-
tic Regression proved to yield the best results.
</bodyText>
<sectionHeader confidence="0.999048" genericHeader="evaluation">
4 Results &amp; Discussion
</sectionHeader>
<bodyText confidence="0.999642555555556">
In this section we present and discuss the results
of our system in the SemEval 2014 shared task.
The results of our submission for subtasks 2 and 4,
compared to the majority baselines, can be found
in table 3. Our system performs significantly bet-
ter on restaurant reviews than on laptop reviews,
probably due to the fact that our polarity lexi-
con comprises more restaurant-specific vocabu-
lary than computer-specific vocabulary.
</bodyText>
<table confidence="0.96601025">
Subtask Data Baseline Acc.
(2) Laptops 47.06 58.30
(2) Restaurants 57.8 70.98
(4) Restaurants 59.84 73.10
</table>
<tableCaption confidence="0.987208">
Table 3: Shared-Task results for subtask 2 (aspect
</tableCaption>
<bodyText confidence="0.989418346938776">
term polarity) and subtask 4 (aspect category po-
larity)
In both subtasks, calculating the polarity of the
aspect terms and the aspect categories, the class
positive scores better than the three other classes.
In all data sets and all subtasks positive was the
majority class of the four-partite classification:
42% in the aspect terms of the laptop reviews, 59%
in the aspect terms and aspect categories of the
laptop reviews equally (measured in the training
data). Thus, it is not surprising that the most fre-
quent error of our system is to categorize neutral
aspect terms and categories as positive.
We do not achieve any improvements for the
class conflict. The latter is very hard to detect, not
only because this class is difficult to define but also
because of the lack of training data given for this
class. This could not be improved even though
we included lexical features to address this par-
ticular class, for example, Boolean features show-
ing whether an adversative conjunction is present
in the sentence or whether the count of positive
chunks equals the count of negative chunks in the
same sentence. These features are in line with
the theory that aspects are considered controver-
sial if positive and negative occurrences are bal-
anced and no polarity clearly prevails. Further-
more, the conflictive facet of a sentence is fre-
quently not represented in the words (e.g. “It has
no camera, but I can always buy and install one
easy.”; camera = conflict). Thus, it becomes chal-
lenging to generate features for this class conflict
with a lexicon-based approach.
Furthermore, since our verb resource was newly
implemented, there are still many verbs (espe-
cially domain-specific verbs) which will have to
be modelled in addition to the most frequent En-
glish verbs included in the analysis by now. An-
other limitation of our current system is the fact
that verb negation is not yet implemented: We
process negation occurring in noun phrases (e.g.
“a not so tasty chicken curry”), but not when the
negation word relates to the verb (e.g. “we didn’t
complain”).
In summary, our aspect-based sentiment anal-
ysis pipeline takes into consideration many lin-
guistic characteristics relevant for detecting opin-
ion, and still provides the possibility to expand our
compositional resources.
</bodyText>
<sectionHeader confidence="0.998925" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999328">
Given the above-average results obtained in the
shared task system ranking, we conclude that the
method for aspect-based sentiment analysis in re-
view texts presented in this paper yields competi-
tive results. We showed that the performance for
this task can be improved by using linguistically
motivated features for all classes except conflict.
We presented a supervised aspect-based senti-
ment analysis system to detect target-specific po-
larity with features derived from a fine-grained po-
larity lexicon, a verb resource and compositional
analysis based on a dependency parser. Our results
have shown that deeper linguistic analysis can pos-
itively influence the detection of target-specific
polarities on sentence level in review texts.
</bodyText>
<page confidence="0.997117">
506
</page>
<sectionHeader confidence="0.996524" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999956">
We would like to thank the organizers of the
shared task for their effort, as well as the reviewers
for their helpful comments on the paper.
</bodyText>
<sectionHeader confidence="0.981086" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997324061538462">
Sasha Blair-Goldensohn, Kerry Hannan, Ryan
McDonald, Tyler Neylon, George A. Reis, , and
Jeff Reynar. Building a sentiment summarizer
for local service reviews. In WWW Workshop on
NLP in the Information Explosion Era, 2008.
Jinho D. Choi and Martha Palmer. Getting the
most out of transition-based dependency pars-
ing. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguis-
tics: Human Language Technologies, HLT ’11,
pages 687–692, Stroudsburg, PA, USA, 2011.
ACL.
Xiaowen Ding, Bing Liu, and Philip S. Yu. A
holistic lexicon-based approach to opinion min-
ing. In Proceedings of the 2008 International
Conference on Web Search and Data Mining,
WSDM ’08, pages 231–240, New York, NY,
USA, 2008. ACM.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-
hard Pfahringer, Peter Reutemann, and Ian H.
Witten. The weka data mining software: An
update. SIGKDD Explor. Newsl., 11(1):10–18,
November 2009.
Minqing Hu and Bing Liu. Mining and sum-
marizing customer reviews. In Proceedings of
the Tenth ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Min-
ing, KDD ’04, pages 168–177, New York, NY,
USA, 2004. ACM.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu,
and Tiejun Zhao. Target-dependent twitter sen-
timent classification. In Proceedings of the 49th
Annual Meeting of the Association for Compu-
tational Linguistics, pages 151–160. Associa-
tion for Computational Linguistics, 2011.
Samuel L¨aubli, Mario Schranz, Urs Christen, and
Manfred Klenner. Sentiment Analysis for Me-
dia Reputation Research. In Proceedings of
KONVENS 2012 (PATHOS 2012 workshop),
pages 274–281, Vienna, Austria, 2012.
Karo Moilanen and Stephen Pulman. Sentiment
composition. In Proceedings of RANLP-2007,
pages 378–382, Borovets, Bulgaria, 2007.
Alena Neviarouskaya, Helmut Prendinger, and
Mitsuru Ishizuka. Semantically distinct verb
classes involved in sentiment analysis. IADIS
AC (1), 2009.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos,
and Suresh Manandhar. SemEval-2014 Task 4:
Aspect Based Sentiment Analysis. In Proceed-
ings of the 8th International Workshop on Se-
mantic Evaluation (SemEval 2014), Dublin, Ire-
land, 2014.
Ana-Maria Popescu and Oren Etzioni. Extraction
of product features and opinions from reviews.
In Proceedings of HLT-EMNLP-05, pages 339–
349, Vancouver, Canada, 2005.
Kevin Reschke and Pranav Anand. Extracting
contextual evaluativity. In Proceedings of the
Ninth International Conference on Computa-
tional Semantics, pages 370–374, 2011.
VISL-group. http://beta.visl.sdu.dk/cg3.html. In-
stitute of Language and Communication (ISK),
University of Southern Denmark, 2013.
</reference>
<page confidence="0.997164">
507
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.593779">
<title confidence="0.998863">SA-UZH: Verb-based Sentiment Analysis</title>
<author confidence="0.997482">Nora Hollenstein</author>
<author confidence="0.997482">Michi Amsler</author>
<author confidence="0.997482">Martina Bachmann</author>
<author confidence="0.997482">Manfred</author>
<affiliation confidence="0.955575">Institute of Computational Linguistics, University of</affiliation>
<address confidence="0.604972">Binzmuehlestrasse 14, CH-8050 Zurich,</address>
<abstract confidence="0.998971117647059">This paper describes the details of our system submitted to the SemEval-2014 shared task about aspect-based sentiment analysis on review texts. We participated in subtask 2 (prediction of the polarity of aspect terms) and 4 (prediction of the polarity of aspect categories). Our approach to determine the sentiment of aspect terms and categories is based on linguistic preprocessing, including a compositional analysis and a verb resource, task-specific feature engineering and supervised machine learning techniques. We used a Logistic Regression classifier to make predictions, which were ranked above-average in the shared task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
<author>Tyler Neylon</author>
<author>George A Reis</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In WWW Workshop on NLP in the Information Explosion Era,</booktitle>
<contexts>
<context position="3166" citStr="Blair-Goldensohn et al. (2008)" startWordPosition="457" endWordPosition="460">rovements over the baseline are possible for all classes except “conflict”. 2 Related Work We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-specific 503 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 503–507, Dublin, Ireland, August 23-24, 2014. behavior. However, o</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, 2008</marker>
<rawString>Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George A. Reis, , and Jeff Reynar. Building a sentiment summarizer for local service reviews. In WWW Workshop on NLP in the Information Explosion Era, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
<author>Martha Palmer</author>
</authors>
<title>Getting the most out of transition-based dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11,</booktitle>
<pages>687--692</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="5476" citStr="Choi and Palmer, 2011" startWordPosition="814" endWordPosition="817">f the sentiment composition pipeline. Category Example POS strong “awesome” POS weak “adequate” NEG strong “catastrophe” NEG weak “demotivated” POS active “generous” POS passive “noteworthy” NEG active “rebellion” NEG passive “orphaned” Table 1: Additional categories in our fine-grained polarity lexicon The same polarity lexicon was used for both domains. After mapping the polarities from the lexicon to the words and multi-word expressions, we calculated the polarity of nominal (NPs) and prepositional phrases (PPs) by means of lexical marking and the syntactic analysis of a dependency parser (Choi and Palmer, 2011). We did not implement any rules for neutral phrases, all words and phrases not marked as positive or negative are considered as neutral. In general, the polarities are propagated bottom-up to their respective heads of the NPs/PPs in composition with the subordinates. Shifters and negation words are also taken into account. The parser output is converted into a constraint grammar (CG) format for the subsequent analysis of words and phrases. To conduct this composition of polarity for the phrases we implemented a CG with the vislcg3 tools (VISL-group, 2013). The next stage of our sentiment dete</context>
</contexts>
<marker>Choi, Palmer, 2011</marker>
<rawString>Jinho D. Choi and Martha Palmer. Getting the most out of transition-based dependency parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11, pages 687–692, Stroudsburg, PA, USA, 2011. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 International Conference on Web Search and Data Mining, WSDM ’08,</booktitle>
<pages>231--240</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="3019" citStr="Ding et al. (2008)" startWordPosition="434" endWordPosition="437">ompositional analysis. In our experiments on the restaurant and laptop reviews data for the SemEval-2014 shared task, we found that improvements over the baseline are possible for all classes except “conflict”. 2 Related Work We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-specific 503 Proceeding</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. A holistic lexicon-based approach to opinion mining. In Proceedings of the 2008 International Conference on Web Search and Data Mining, WSDM ’08, pages 231–240, New York, NY, USA, 2008. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="9984" citStr="Hall et al. (2009)" startWordPosition="1551" endWordPosition="1554"> English verbs, it is conceivable that this resource may have a considerably greater effect if more domain-specific verbs are modelled. After this final sentiment composition step, all derived polarity chunks are converted into a set of features for machine learning algorithms. 3.3 Feature Extraction In a first step of our system, the sentences are parsed, phrase polarities are calculated and verb effects and expectations are assigned. Subsequently, a feature extractor, which extracts and aggregates polar information, operates on the output. The Simple Logistic Regression classifier from weka Hall et al. (2009) is then trained on these features. We developed a feature extraction pipeline that retrieves information about various polarity levels in words, syntactic functions and phrases of the sentences in the data set. In order to use our sentiment composition approach for machine learning, we extract three different sets of features, resulting in a total of 32 features for subtask 2 and 39 features for subtask 4. In short, the feature sets are constructed as follows: • Lexicon-based features: These features comprise simple frequency counts of positive and negative words in the sentences and binary f</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. The weka data mining software: An update. SIGKDD Explor. Newsl., 11(1):10–18, November 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="3041" citStr="Hu and Liu (2004)" startWordPosition="439" endWordPosition="442">In our experiments on the restaurant and laptop reviews data for the SemEval-2014 shared task, we found that improvements over the baseline are possible for all classes except “conflict”. 2 Related Work We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-specific 503 Proceedings of the 8th Internati</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. Mining and summarizing customer reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04, pages 168–177, New York, NY, USA, 2004. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="3242" citStr="Jiang et al. (2011)" startWordPosition="468" endWordPosition="471">ork We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-specific 503 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 503–507, Dublin, Ireland, August 23-24, 2014. behavior. However, only we specify the individual verb’s (default) perspective on each role (and</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 151–160. Association for Computational Linguistics, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel L¨aubli</author>
<author>Mario Schranz</author>
<author>Urs Christen</author>
<author>Manfred Klenner</author>
</authors>
<title>Sentiment Analysis for Media Reputation Research.</title>
<date>2012</date>
<booktitle>In Proceedings of KONVENS 2012 (PATHOS 2012 workshop),</booktitle>
<pages>274--281</pages>
<location>Vienna, Austria,</location>
<marker>L¨aubli, Schranz, Christen, Klenner, 2012</marker>
<rawString>Samuel L¨aubli, Mario Schranz, Urs Christen, and Manfred Klenner. Sentiment Analysis for Media Reputation Research. In Proceedings of KONVENS 2012 (PATHOS 2012 workshop), pages 274–281, Vienna, Austria, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment composition.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP-2007,</booktitle>
<pages>378--382</pages>
<location>Borovets, Bulgaria,</location>
<contexts>
<context position="2999" citStr="Moilanen and Pulman, 2007" startWordPosition="430" endWordPosition="433">bs functional roles, and a compositional analysis. In our experiments on the restaurant and laptop reviews data for the SemEval-2014 shared task, we found that improvements over the baseline are possible for all classes except “conflict”. 2 Related Work We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-spe</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. Sentiment composition. In Proceedings of RANLP-2007, pages 378–382, Borovets, Bulgaria, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
</authors>
<title>Helmut Prendinger, and Mitsuru Ishizuka. Semantically distinct verb classes involved in sentiment analysis.</title>
<date>2009</date>
<journal>IADIS AC</journal>
<volume>1</volume>
<marker>Neviarouskaya, 2009</marker>
<rawString>Alena Neviarouskaya, Helmut Prendinger, and Mitsuru Ishizuka. Semantically distinct verb classes involved in sentiment analysis. IADIS AC (1), 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
</authors>
<title>Dimitrios Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. SemEval-2014 Task 4: Aspect Based Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<location>Dublin, Ireland,</location>
<marker>Pontiki, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. SemEval-2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Ireland, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extraction of product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP-05,</booktitle>
<pages>339--349</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="2940" citStr="Popescu and Etzioni, 2005" startWordPosition="423" endWordPosition="426">erb resource specifying expectations and effects of the verbs functional roles, and a compositional analysis. In our experiments on the restaurant and laptop reviews data for the SemEval-2014 shared task, we found that improvements over the baseline are possible for all classes except “conflict”. 2 Related Work We focus on the question whether fine-grained linguistic sentiment analysis improves target-specific polarity classification. Existing approaches to aspect-based sentiment detection have focused on different aspects of this task, e.g. the identification of targets and their components (Popescu and Etzioni, 2005) and sentence-level composition (Moilanen and Pulman, 2007). Ding et al. (2008) and Hu and Liu (2004) produced lexicon-based approaches, which perform quite well in a large number of domains, and Blair-Goldensohn et al. (2008) combined lexicon-based methods and supervised learning. Jiang et al. (2011) used a dependency parser to generate a set of aspect dependent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. Extraction of product features and opinions from reviews. In Proceedings of HLT-EMNLP-05, pages 339– 349, Vancouver, Canada, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Reschke</author>
<author>Pranav Anand</author>
</authors>
<title>Extracting contextual evaluativity.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics,</booktitle>
<pages>370--374</pages>
<contexts>
<context position="3922" citStr="Reschke and Anand (2011)" startWordPosition="576" endWordPosition="579">pendent features for classification. For our system we built a sentiment composition resembling the one of L¨aubli et al. (2012), which was developed for German. Moreover, our verb resource has some similarity with the one of Neviarouskaya et al. (2009): both rely on verb classes and utilize verb-specific 503 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 503–507, Dublin, Ireland, August 23-24, 2014. behavior. However, only we specify the individual verb’s (default) perspective on each role (and are, thus, able to count polar propagations). See also Reschke and Anand (2011), who describe in detail how polar (verb) complements combine to verb frame polarity (again without recording and using role perspectives as we do). 3 System Description In this section we present the details of our sentiment analysis system. We used the same preprocessing and learning algorithm for both subtasks (2 &amp; 4). Only the feature extraction was expanded in subtask 4 for determining the polarities of aspect categories (see section 3.3). The data sets consisted of restaurant and laptop reviews, which comprise about 3’000 manually classified targetspecific sentences for each domain. 3.1 </context>
</contexts>
<marker>Reschke, Anand, 2011</marker>
<rawString>Kevin Reschke and Pranav Anand. Extracting contextual evaluativity. In Proceedings of the Ninth International Conference on Computational Semantics, pages 370–374, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>http beta visl sdu dkcg3 html</author>
</authors>
<date>2013</date>
<institution>Institute of Language and Communication (ISK), University of Southern</institution>
<marker>html, 2013</marker>
<rawString>VISL-group. http://beta.visl.sdu.dk/cg3.html. Institute of Language and Communication (ISK), University of Southern Denmark, 2013.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>