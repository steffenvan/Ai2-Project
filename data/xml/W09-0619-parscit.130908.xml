<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.9957215">
The effect of linguistic devices in information presentation messages on
comprehension and recall
</title>
<author confidence="0.991936">
Martin I. Tietze and Andi Winterboer and Johanna D. Moore
</author>
<affiliation confidence="0.999665">
University of Edinburgh, Edinburgh, United Kingdom
</affiliation>
<email confidence="0.991196">
mtietze@inf.ed.ac.uk, A.Winterboer@ed.ac.uk, J.Moore@ed.ac.uk
</email>
<sectionHeader confidence="0.993892" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99804">
In this paper we examine the effect of
linguistic devices on recall and compre-
hension in information presentation using
both recall and eye-tracking data. In ad-
dition, the results were validated via an
experiment using Amazon’s Mechanical
Turk micro-task environment.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949041666667">
In this paper, we present two experiments de-
signed to examine the impact of linguistic devices,
such as discourse cues and connectives, on com-
prehension and recall in information presentation
for natural language generation (NLG) as used in
spoken dialogue systems (SDS).
Spoken dialogue systems have traditionally
used simple templates to present options (e.g.,
flights, restaurants) and their attributes to users
(Walker et al., 2004). Recently, however, re-
searchers have proposed approaches to informa-
tion presentation that use linguistic devices (e.g.,
but, however, moreover, only, just, also etc.) in
order to highlight specific properties of and rela-
tions between items presented to the user, e.g. as-
sociations (Polifroni and Walker, 2006) and con-
trasts (Winterboer and Moore, 2007). Previous
research indicates that linguistic devices such as
connectives facilitate comprehension (see Ben-
Anath, 2005, for a review). However, to our
knowledge, no empirical validation has been per-
formed to test whether using linguistic devices has
an effect on comprehension and recall of the infor-
mation presentated.
</bodyText>
<sectionHeader confidence="0.997143" genericHeader="method">
2 Experiment 1: Recall of written
materials
</sectionHeader>
<bodyText confidence="0.967676555555556">
In order to test whether there are differences in
recall, we performed a within-participants read-
ing experiment comparing recall for experiment
material presented with or without linguistic de-
vices1 A total of 24 participants, native English
speakers and mostly students of the University of
Edinburgh, were paid to participate in the study.
They were naive to the purpose of the experi-
ment but were told that they were about to be pre-
sented with a number of consumer products and
that they were supposed to answer questions about
these. Each participant read 14 short texts describ-
ing consumer products from 14 domains, see Ta-
ble 1 and Table 2 for examples. The texts are the
type of presentation typically produced by spoken
dialogue systems designed to help users select an
entity from a set of available options. Participants’
eye-movements during reading were recorded as
described in section 3.
�
Messina’s price is £22. It has very good food
quality, attentive service, and decent d´ecor.
Ray’s price is £34. It has very good food qual-
ity, excellent service, and impressive d´ecor.
Alhambra’s price is £16. It has good food
quality, bad service, and plain d´ecor.
✁
</bodyText>
<figureCaption confidence="0.7540785">
Figure 1: Experiment material without discourse
cues
</figureCaption>
<bodyText confidence="0.940866333333333">
�
Messina’s price is £22. It has very good food
quality, attentive service, and decent d´ecor.
Ray’s price is £34. It has also very good food
quality, but excellent service, and moreover
impressive d´ecor.
Alhambra’s price is only £16. It has good
food quality, but bad service, and only plain
d´ecor.
</bodyText>
<figure confidence="0.367011">
✁
</figure>
<figureCaption confidence="0.970307">
Figure 2: Experiment material with discourse cues
</figureCaption>
<bodyText confidence="0.997616">
There were two types of messages, one con-
taining linguistic devices to point out similari-
</bodyText>
<footnote confidence="0.955828">
1This experiment has been presented as an one-page ab-
stract, (Winterboer et al., 2008)
</footnote>
<equation confidence="0.38043675">
✄
✂
✄
✂
</equation>
<bodyText confidence="0.2718795">
Proceedings of the 12th European Workshop on Natural Language Generation, pages 114–117,
Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.998196">
114
</page>
<bodyText confidence="0.972648">
ties and differences among the options, and one
without these linguistic markers. Each participant
read seven texts of each type, alternating between
types. Ordering of both the domains and the text
type was controlled for. We took particular care
to add discourse devices without modifying the
propositions in any other way. After each mes-
sage, the participant had to answer three questions
testing different levels of recall. Examples of each
type of question are given in figure 3.
�
</bodyText>
<listItem confidence="0.912434285714286">
1. Verbatim questions: Which restaurant’s
price is £34?
2. Comparison questions: Which restau-
rant is the cheapest?
3. Evaluation questions: Which restaurant
would you like to go to and why?
✁
</listItem>
<figureCaption confidence="0.968572">
Figure 3: The three types of evaluation questions
with examples
</figureCaption>
<subsectionHeader confidence="0.993385">
2.1 Experimental procedure
</subsectionHeader>
<bodyText confidence="0.999888375">
In each trial, participants read a text presented
for up to 45 seconds on the screen. Users could
press Enter on the keyboard when they were fin-
ished reading. They were then presented with the
questions, which they had to answer one after the
other. After a question was presented, the partic-
ipant pressed Enter to be prompted to type in an
answer.
</bodyText>
<subsectionHeader confidence="0.825427">
2.2 Results
</subsectionHeader>
<bodyText confidence="0.997791666666667">
Overall, we found a consistent numerical trend
indicating that items in messages containing lin-
guistic devices could be recalled more easily (see
Table 2.2). In particular, answers to compari-
son questions were correctly recalled significantly
more often when linguistic markers were present.
Verb. Q. Comp. Q. Eval. Q.
w/o cues 0.79 0.68* 0.73
with cues 0.82 0.79* 0.81
</bodyText>
<figureCaption confidence="0.732156666666667">
Figure 4: Average recall on a scale from 0 to 1 for
the 3 questions. t-test, “*” indicates a significant
difference with p &lt; 0.5.
</figureCaption>
<sectionHeader confidence="0.830092" genericHeader="method">
3 Comprehension of written materials
</sectionHeader>
<bodyText confidence="0.999989692307692">
In this experiment we used an eye-tracker in or-
der to measure reading times, because reading
times are considered to be sensitive to people’s on-
going discourse processing/comprehension (Hav-
iland and Clark, 1974). We found that read-
ing the presentation messages containing linguis-
tic devices took generally slightly longer, with par-
ticipants reading messages containing discourse
cues taking 37.93 seconds per message on aver-
age, and messages without discourse cues taking
35.28 seconds on average to read. The question,
however, was whether this difference could be at-
tributed exclusively to the number of additional
words or whether readers also spent more time to
build a mental representation of the presentation’s
content by reading the parts marked by discourse
cues more carefully. Alternatively, sentence com-
plexity might also increase with the introduction
of linguistic cues, which in turn increases read-
ing times. In order to answer this question, we
compared the reading times of interest areas (IA)
located directly (one word) after the (potential) lo-
cation of the discourse marker. In total, we deter-
mined 46 IAs within the 14 messages, each one
consisting of two words or around nine characters
on average.
</bodyText>
<subsectionHeader confidence="0.652374">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.999984826086957">
The results of the different reading time mea-
sures, established with linear-mixed effects model
(LME) analyses in R2 (see Table 1), do not reveal
any significant differences between the two con-
ditions, although, surprisingly, IAs had a numer-
ically shorter reading time when linguistic mark-
ers were used. In this repeated measures de-
sign experiment, participant, IA, and item were
random-effect factors and the fixed-effect factor
was whether the presentation contained linguis-
tic devices. We compared first pass and remain-
ing pass reading times per IA, the total number of
passes, and regressions in and out of the IA.
Although sentences containing linguistic de-
vices are more complex and thus should incur
longer reading times, our analyses do not any dif-
ferences in reading times for the words directly
following the linguistic devices. The differences
in the overall reading times noted above are there-
fore due to the additional words (the linguistic de-
vices) and not caused by differences in sentence
complexity or increased effort towards the marked
parts of the text.
</bodyText>
<footnote confidence="0.934361">
2www.r-project.org
</footnote>
<figure confidence="0.3555115">
✄
✂
</figure>
<page confidence="0.738461">
115
</page>
<table confidence="0.9966224">
RT FPRT NoP RegrIn RegrOut
with cues 473.83 1055.56 3.639 0.430 0.322
w/o cues 510.24 1150.70 3.567 0.494 0.350
t = -1.511 t = -0.820 t = 0.625 t = -1.002 t = -0.519
p = 0.131 p = 0.412 p = 0.5321 p = 0.3164 p =0.6039
</table>
<tableCaption confidence="0.988937">
Table 1: Eye-tracking data per IA (first pass reading times, remaining time reading times, number of
passes, regressions out and in) for messages with and without discourse cues
</tableCaption>
<sectionHeader confidence="0.8983465" genericHeader="method">
4 Experiment 2: Web-based recall of
written materials
</sectionHeader>
<bodyText confidence="0.99979968">
We carried out a web-based user study on Ama-
zon’s Mechanical Turk3 (MT) platform both in or-
der to verify the results obtained in the previous
recall experiment and in order to test whether re-
sults obtained from casual website users are com-
parable to those obtained from laboratory partici-
pants who focus exclusively on performing the ex-
periment in the lab. We recruited native English
speakers online to carry out the same experiment
previously conducted in the lab. MT is a web-
based micro-task platform that allows researchers
and developers to put small tasks requiring human
intelligence on the web. Deploying MT is advan-
tageous because it attracts many visitors due to its
affiliation with the well established Amazon web-
site and thus eases recruitment of new participants
especially from outside the usual student popula-
tion. In addition, conducting experiments online
significantly reduces the effort involved in data
collection for the experimenter. Moreover, the
website allows for convenient payment for both
participants and the experimenter. For these rea-
sons, MT has recently been used in a number of
language experiments (e.g., Kaisser et al., 2008;
Kittur et al., 2008).
</bodyText>
<subsectionHeader confidence="0.96564">
4.1 Participants
</subsectionHeader>
<bodyText confidence="0.999996454545455">
We had 60 participants reading the same mate-
rials that were used in experiment 1. MT does
allow to place restrictions on participant location
(only users from the US were allowed to partic-
ipate to ensure English language skills), for in-
stance, or the number of trials (each participant
was only allowed to participate once). However,
one cannot balance gender of participants or con-
trol for age and literacy reliably, as user provided
data cannot be verified. Also, one does not know
whether participants are conducting another task
</bodyText>
<footnote confidence="0.736343">
3https://www.mturk.com/mturk/
</footnote>
<bodyText confidence="0.999989285714286">
simultaneously, or are otherwise distracted. We
paid $ 2.50 for participation, which was, given
that we expected the experiment to last less than
30 minutes, considerably more than participants
would receive for most other tasks available. We
hoped that the higher reward would encourage par-
ticipants to take the task more seriously.
</bodyText>
<subsectionHeader confidence="0.998214">
4.2 Experimental setup and procedure
</subsectionHeader>
<bodyText confidence="0.999996875">
In order to resemble the interface that was used in
the previous experiment as closely as possible in
terms of the general “look and feel”, a web-based
interface was implemented using Adobe’s Flash
format. We chose the widely used Flash format be-
cause it can be integrated into the MT environment
easily and allows for tighter user control in com-
parison with standard HTML pages. For example,
we made it impossible for users to reread the pre-
sented information once they read the correspond-
ing question. With standard HMTL users would
have been able to use their browser’s back button
to do just that. The experiment was then made
available to the users on Amazon’s MT website.
The procedure was otherwise exactly the same as
in experiment 1.
</bodyText>
<subsectionHeader confidence="0.949192">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999988133333333">
The first thing we noticed when evaluating the data
was that it took only a couple of hours from mak-
ing the tasks available on the MT website to re-
ceiving the results. In addition, we learnt from the
submitted answers that the general answer qual-
ity was comparable to answers obtained in the
lab-based experiment. Average recall rate was
nearly identical with 0.76 (web-based) and 0.77
(lab-based). In addition, the average answer time
was also almost identical 23 minutes (web-based)
and 26 minutes (lab-based) per participant. How-
ever, the results from three of the 60 participants
had to be excluded from the analysis (and payment
withheld), as they answered less than 50% of the
questions while performing the task in less than
</bodyText>
<page confidence="0.997724">
116
</page>
<bodyText confidence="0.8953358">
half of the average time.
We did not find an effect on the comparison
questions. Instead, this time the difference be-
tween the two conditions was significant in terms
of correct answers to the evaluation question.
Thus, we again found that using linguistic mark-
ers facilitates recall of information.
Verb. Q. Comp. Q. Eval. Q.
w/o cues 0.83 0.62 0.83*
with cues 0.80 0.65 0.88*
</bodyText>
<figureCaption confidence="0.789742">
Figure 5: Average recall on a scale from 0 to 1
</figureCaption>
<bodyText confidence="0.740766333333333">
for the 3 questions in the web-based experiment.
t-test, “*” indicates a significant difference with
p &lt; 0.5.
</bodyText>
<sectionHeader confidence="0.993532" genericHeader="discussions">
5 Discussion and outlook
</sectionHeader>
<bodyText confidence="0.999986439024391">
Taken together, we found a small but significant
effect of discourse cues on recall. The combi-
nation of eye-tracking and recall data seems to
provide a relatively clear picture: Although sen-
tences with linguistic devices took more time to
read, this is exclusively due to the additional words
and not caused by a differences in the construction
of the internal representation. While these find-
ings are in line with results from psycholinguistics
which demonstrated that linguistic devices may
improve comprehension and recall (Ben-Anath,
2005), given the small effect, it does not fully ex-
plain the improvements in terms of task effective-
ness found in information presentation for SDS
(Winterboer and Moore, 2007).
We additionally validated the results using par-
ticipants recruited online. The similar results show
that this method is applicable to the evaluation
of written language materials and adds further
strength to its establishment as an alternative to
lab-based experiments.
Nonetheless, in real-world SDSs users are pre-
sented with information about different options
auditorily. Listening to auditory stimuli should
be more difficult than reading the same stimuli,
because readers can always re-read a problematic
word or sentence, whereas auditory stimuli are
presented sequentially and are transient. However,
research on the differences between reading and
listening comprehension seems to suggest that the
findings found in reading can also be applied to
spoken stimuli due to the commonality of process-
ing between the two modalities (Sinatra, 1990).
However, to confirm this, we are repeating the ex-
periments in order to examine whether linguistic
devices also facilitate recall and comprehension in
auditorily presented messages, using stimuli cre-
ated with a speech synthesiser. We plan to use the
auditory moving window paradigm (Ferreira et al.,
1996) to assess the impact of lingustic devices in
this modality in more detail.
</bodyText>
<sectionHeader confidence="0.999182" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999598818181818">
D. Ben-Anath. 2005. The Role of Connectives in Text
Comprehension. Working Papers in TESOL and Ap-
plied Linguistics, 5(2):1–27.
F. Ferreira, JM Henderson, MD Anes, PA Weeks,
and DK McFarlane. 1996. Effects of Lexical
Frequency and Syntactic complexity in Spoken-
Language Comprehension: Evidence From the Au-
ditory Moving-Window Technique. Journal of ex-
perimental psychology. Learning, memory, and cog-
nition, 22(2):324–335.
S.E. Haviland and H.H. Clark. 1974. What’s new?
acquiring new information as a process in compre-
hension. Journal of Verbal Learning and Verbal Be-
haviour, 13:512–521.
Michael Kaisser, Marti Hearst, and John Lowe. 2008.
Improving Search Result Quality by Customizing
Summary Lengths. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics.
Aniket Kittur, Ed H. Chi, and Bongwon Suh. 2008.
Crowdsourcing user studies with Mechanical Turk.
In Proceeding of the twenty-sixth annual SIGCHI
conference on Human factors in computing systems.
J. Polifroni and M. Walker. 2006. Learning database
content for spoken dialogue system design. In 5th
International Conference on Language Resources
and Evaluation (LREC).
G.M. Sinatra. 1990. Convergence of listening and
reading processing. Reading Research Quarterly,
25:115–130.
Marilyn A. Walker, Steve Whittaker, Amanda Stent,
Preetam Maloor, Johanna D. Moore, Michael John-
ston, and Gunaranjan Vasireddy. 2004. Generation
and evaluation of user tailored responses in multi-
modal dialogue. Cognitive Science, 28:811–840.
Andi Winterboer and Johanna D. Moore. 2007. Evalu-
ating information presentation strategies for spoken
recommendations. In Proceedings of the ACM con-
ference on Recommender Systems (RecSys ’07).
Andi Winterboer, Johanna D. Moore, and Fernanda
Ferreira. 2008. Do discourse cues facilitate recall
in information presentation messages? In Proceed-
ings of the 9th International Conference on Spoken
Language Processing.
</reference>
<page confidence="0.998095">
117
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904811">
<title confidence="0.9907315">The effect of linguistic devices in information presentation messages comprehension and recall</title>
<author confidence="0.999155">Martin I Tietze</author>
<author confidence="0.999155">Andi Winterboer</author>
<author confidence="0.999155">D Johanna</author>
<affiliation confidence="0.997379">University of Edinburgh, Edinburgh, United Kingdom</affiliation>
<email confidence="0.987811">mtietze@inf.ed.ac.uk,A.Winterboer@ed.ac.uk,J.Moore@ed.ac.uk</email>
<abstract confidence="0.991090875">In this paper we examine the effect of linguistic devices on recall and comprehension in information presentation using both recall and eye-tracking data. In addition, the results were validated via an experiment using Amazon’s Mechanical Turk micro-task environment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Ben-Anath</author>
</authors>
<title>The Role of Connectives in Text Comprehension.</title>
<date>2005</date>
<booktitle>Working Papers in TESOL and Applied Linguistics,</booktitle>
<pages>5--2</pages>
<contexts>
<context position="12839" citStr="Ben-Anath, 2005" startWordPosition="2068" endWordPosition="2069">ndicates a significant difference with p &lt; 0.5. 5 Discussion and outlook Taken together, we found a small but significant effect of discourse cues on recall. The combination of eye-tracking and recall data seems to provide a relatively clear picture: Although sentences with linguistic devices took more time to read, this is exclusively due to the additional words and not caused by a differences in the construction of the internal representation. While these findings are in line with results from psycholinguistics which demonstrated that linguistic devices may improve comprehension and recall (Ben-Anath, 2005), given the small effect, it does not fully explain the improvements in terms of task effectiveness found in information presentation for SDS (Winterboer and Moore, 2007). We additionally validated the results using participants recruited online. The similar results show that this method is applicable to the evaluation of written language materials and adds further strength to its establishment as an alternative to lab-based experiments. Nonetheless, in real-world SDSs users are presented with information about different options auditorily. Listening to auditory stimuli should be more difficul</context>
</contexts>
<marker>Ben-Anath, 2005</marker>
<rawString>D. Ben-Anath. 2005. The Role of Connectives in Text Comprehension. Working Papers in TESOL and Applied Linguistics, 5(2):1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ferreira</author>
<author>JM Henderson</author>
<author>PA Weeks Anes</author>
<author>DK McFarlane</author>
</authors>
<date>1996</date>
<booktitle>Effects of Lexical Frequency and Syntactic complexity in SpokenLanguage Comprehension: Evidence From the Auditory Moving-Window Technique. Journal of experimental psychology. Learning, memory, and cognition,</booktitle>
<pages>22--2</pages>
<marker>Ferreira, Henderson, Anes, McFarlane, 1996</marker>
<rawString>F. Ferreira, JM Henderson, MD Anes, PA Weeks, and DK McFarlane. 1996. Effects of Lexical Frequency and Syntactic complexity in SpokenLanguage Comprehension: Evidence From the Auditory Moving-Window Technique. Journal of experimental psychology. Learning, memory, and cognition, 22(2):324–335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Haviland</author>
<author>H H Clark</author>
</authors>
<title>What’s new? acquiring new information as a process in comprehension.</title>
<date>1974</date>
<journal>Journal of Verbal Learning and Verbal Behaviour,</journal>
<pages>13--512</pages>
<contexts>
<context position="5535" citStr="Haviland and Clark, 1974" startWordPosition="870" endWordPosition="874">alled more easily (see Table 2.2). In particular, answers to comparison questions were correctly recalled significantly more often when linguistic markers were present. Verb. Q. Comp. Q. Eval. Q. w/o cues 0.79 0.68* 0.73 with cues 0.82 0.79* 0.81 Figure 4: Average recall on a scale from 0 to 1 for the 3 questions. t-test, “*” indicates a significant difference with p &lt; 0.5. 3 Comprehension of written materials In this experiment we used an eye-tracker in order to measure reading times, because reading times are considered to be sensitive to people’s ongoing discourse processing/comprehension (Haviland and Clark, 1974). We found that reading the presentation messages containing linguistic devices took generally slightly longer, with participants reading messages containing discourse cues taking 37.93 seconds per message on average, and messages without discourse cues taking 35.28 seconds on average to read. The question, however, was whether this difference could be attributed exclusively to the number of additional words or whether readers also spent more time to build a mental representation of the presentation’s content by reading the parts marked by discourse cues more carefully. Alternatively, sentence</context>
</contexts>
<marker>Haviland, Clark, 1974</marker>
<rawString>S.E. Haviland and H.H. Clark. 1974. What’s new? acquiring new information as a process in comprehension. Journal of Verbal Learning and Verbal Behaviour, 13:512–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaisser</author>
<author>Marti Hearst</author>
<author>John Lowe</author>
</authors>
<title>Improving Search Result Quality by Customizing Summary Lengths.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9269" citStr="Kaisser et al., 2008" startWordPosition="1478" endWordPosition="1481">s to put small tasks requiring human intelligence on the web. Deploying MT is advantageous because it attracts many visitors due to its affiliation with the well established Amazon website and thus eases recruitment of new participants especially from outside the usual student population. In addition, conducting experiments online significantly reduces the effort involved in data collection for the experimenter. Moreover, the website allows for convenient payment for both participants and the experimenter. For these reasons, MT has recently been used in a number of language experiments (e.g., Kaisser et al., 2008; Kittur et al., 2008). 4.1 Participants We had 60 participants reading the same materials that were used in experiment 1. MT does allow to place restrictions on participant location (only users from the US were allowed to participate to ensure English language skills), for instance, or the number of trials (each participant was only allowed to participate once). However, one cannot balance gender of participants or control for age and literacy reliably, as user provided data cannot be verified. Also, one does not know whether participants are conducting another task 3https://www.mturk.com/mtu</context>
</contexts>
<marker>Kaisser, Hearst, Lowe, 2008</marker>
<rawString>Michael Kaisser, Marti Hearst, and John Lowe. 2008. Improving Search Result Quality by Customizing Summary Lengths. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aniket Kittur</author>
<author>Ed H Chi</author>
<author>Bongwon Suh</author>
</authors>
<title>Crowdsourcing user studies with Mechanical Turk.</title>
<date>2008</date>
<booktitle>In Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems.</booktitle>
<contexts>
<context position="9291" citStr="Kittur et al., 2008" startWordPosition="1482" endWordPosition="1485">equiring human intelligence on the web. Deploying MT is advantageous because it attracts many visitors due to its affiliation with the well established Amazon website and thus eases recruitment of new participants especially from outside the usual student population. In addition, conducting experiments online significantly reduces the effort involved in data collection for the experimenter. Moreover, the website allows for convenient payment for both participants and the experimenter. For these reasons, MT has recently been used in a number of language experiments (e.g., Kaisser et al., 2008; Kittur et al., 2008). 4.1 Participants We had 60 participants reading the same materials that were used in experiment 1. MT does allow to place restrictions on participant location (only users from the US were allowed to participate to ensure English language skills), for instance, or the number of trials (each participant was only allowed to participate once). However, one cannot balance gender of participants or control for age and literacy reliably, as user provided data cannot be verified. Also, one does not know whether participants are conducting another task 3https://www.mturk.com/mturk/ simultaneously, or</context>
</contexts>
<marker>Kittur, Chi, Suh, 2008</marker>
<rawString>Aniket Kittur, Ed H. Chi, and Bongwon Suh. 2008. Crowdsourcing user studies with Mechanical Turk. In Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Polifroni</author>
<author>M Walker</author>
</authors>
<title>Learning database content for spoken dialogue system design.</title>
<date>2006</date>
<booktitle>In 5th International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="1307" citStr="Polifroni and Walker, 2006" startWordPosition="182" endWordPosition="185">and connectives, on comprehension and recall in information presentation for natural language generation (NLG) as used in spoken dialogue systems (SDS). Spoken dialogue systems have traditionally used simple templates to present options (e.g., flights, restaurants) and their attributes to users (Walker et al., 2004). Recently, however, researchers have proposed approaches to information presentation that use linguistic devices (e.g., but, however, moreover, only, just, also etc.) in order to highlight specific properties of and relations between items presented to the user, e.g. associations (Polifroni and Walker, 2006) and contrasts (Winterboer and Moore, 2007). Previous research indicates that linguistic devices such as connectives facilitate comprehension (see BenAnath, 2005, for a review). However, to our knowledge, no empirical validation has been performed to test whether using linguistic devices has an effect on comprehension and recall of the information presentated. 2 Experiment 1: Recall of written materials In order to test whether there are differences in recall, we performed a within-participants reading experiment comparing recall for experiment material presented with or without linguistic dev</context>
</contexts>
<marker>Polifroni, Walker, 2006</marker>
<rawString>J. Polifroni and M. Walker. 2006. Learning database content for spoken dialogue system design. In 5th International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G M Sinatra</author>
</authors>
<title>Convergence of listening and reading processing. Reading Research Quarterly,</title>
<date>1990</date>
<pages>25--115</pages>
<marker>Sinatra, 1990</marker>
<rawString>G.M. Sinatra. 1990. Convergence of listening and reading processing. Reading Research Quarterly, 25:115–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Steve Whittaker</author>
<author>Amanda Stent</author>
<author>Preetam Maloor</author>
<author>Johanna D Moore</author>
<author>Michael Johnston</author>
<author>Gunaranjan Vasireddy</author>
</authors>
<title>Generation and evaluation of user tailored responses in multimodal dialogue.</title>
<date>2004</date>
<journal>Cognitive Science,</journal>
<pages>28--811</pages>
<contexts>
<context position="997" citStr="Walker et al., 2004" startWordPosition="136" endWordPosition="139">n presentation using both recall and eye-tracking data. In addition, the results were validated via an experiment using Amazon’s Mechanical Turk micro-task environment. 1 Introduction In this paper, we present two experiments designed to examine the impact of linguistic devices, such as discourse cues and connectives, on comprehension and recall in information presentation for natural language generation (NLG) as used in spoken dialogue systems (SDS). Spoken dialogue systems have traditionally used simple templates to present options (e.g., flights, restaurants) and their attributes to users (Walker et al., 2004). Recently, however, researchers have proposed approaches to information presentation that use linguistic devices (e.g., but, however, moreover, only, just, also etc.) in order to highlight specific properties of and relations between items presented to the user, e.g. associations (Polifroni and Walker, 2006) and contrasts (Winterboer and Moore, 2007). Previous research indicates that linguistic devices such as connectives facilitate comprehension (see BenAnath, 2005, for a review). However, to our knowledge, no empirical validation has been performed to test whether using linguistic devices h</context>
</contexts>
<marker>Walker, Whittaker, Stent, Maloor, Moore, Johnston, Vasireddy, 2004</marker>
<rawString>Marilyn A. Walker, Steve Whittaker, Amanda Stent, Preetam Maloor, Johanna D. Moore, Michael Johnston, and Gunaranjan Vasireddy. 2004. Generation and evaluation of user tailored responses in multimodal dialogue. Cognitive Science, 28:811–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andi Winterboer</author>
<author>Johanna D Moore</author>
</authors>
<title>Evaluating information presentation strategies for spoken recommendations.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACM conference on Recommender Systems (RecSys ’07).</booktitle>
<contexts>
<context position="1350" citStr="Winterboer and Moore, 2007" startWordPosition="189" endWordPosition="192">l in information presentation for natural language generation (NLG) as used in spoken dialogue systems (SDS). Spoken dialogue systems have traditionally used simple templates to present options (e.g., flights, restaurants) and their attributes to users (Walker et al., 2004). Recently, however, researchers have proposed approaches to information presentation that use linguistic devices (e.g., but, however, moreover, only, just, also etc.) in order to highlight specific properties of and relations between items presented to the user, e.g. associations (Polifroni and Walker, 2006) and contrasts (Winterboer and Moore, 2007). Previous research indicates that linguistic devices such as connectives facilitate comprehension (see BenAnath, 2005, for a review). However, to our knowledge, no empirical validation has been performed to test whether using linguistic devices has an effect on comprehension and recall of the information presentated. 2 Experiment 1: Recall of written materials In order to test whether there are differences in recall, we performed a within-participants reading experiment comparing recall for experiment material presented with or without linguistic devices1 A total of 24 participants, native En</context>
<context position="13009" citStr="Winterboer and Moore, 2007" startWordPosition="2094" endWordPosition="2097">he combination of eye-tracking and recall data seems to provide a relatively clear picture: Although sentences with linguistic devices took more time to read, this is exclusively due to the additional words and not caused by a differences in the construction of the internal representation. While these findings are in line with results from psycholinguistics which demonstrated that linguistic devices may improve comprehension and recall (Ben-Anath, 2005), given the small effect, it does not fully explain the improvements in terms of task effectiveness found in information presentation for SDS (Winterboer and Moore, 2007). We additionally validated the results using participants recruited online. The similar results show that this method is applicable to the evaluation of written language materials and adds further strength to its establishment as an alternative to lab-based experiments. Nonetheless, in real-world SDSs users are presented with information about different options auditorily. Listening to auditory stimuli should be more difficult than reading the same stimuli, because readers can always re-read a problematic word or sentence, whereas auditory stimuli are presented sequentially and are transient.</context>
</contexts>
<marker>Winterboer, Moore, 2007</marker>
<rawString>Andi Winterboer and Johanna D. Moore. 2007. Evaluating information presentation strategies for spoken recommendations. In Proceedings of the ACM conference on Recommender Systems (RecSys ’07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andi Winterboer</author>
<author>Johanna D Moore</author>
<author>Fernanda Ferreira</author>
</authors>
<title>Do discourse cues facilitate recall in information presentation messages?</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="3469" citStr="Winterboer et al., 2008" startWordPosition="533" endWordPosition="536">quality, bad service, and plain d´ecor. ✁ Figure 1: Experiment material without discourse cues � Messina’s price is £22. It has very good food quality, attentive service, and decent d´ecor. Ray’s price is £34. It has also very good food quality, but excellent service, and moreover impressive d´ecor. Alhambra’s price is only £16. It has good food quality, but bad service, and only plain d´ecor. ✁ Figure 2: Experiment material with discourse cues There were two types of messages, one containing linguistic devices to point out similari1This experiment has been presented as an one-page abstract, (Winterboer et al., 2008) ✄ ✂ ✄ ✂ Proceedings of the 12th European Workshop on Natural Language Generation, pages 114–117, Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics 114 ties and differences among the options, and one without these linguistic markers. Each participant read seven texts of each type, alternating between types. Ordering of both the domains and the text type was controlled for. We took particular care to add discourse devices without modifying the propositions in any other way. After each message, the participant had to answer three questions testing different lev</context>
</contexts>
<marker>Winterboer, Moore, Ferreira, 2008</marker>
<rawString>Andi Winterboer, Johanna D. Moore, and Fernanda Ferreira. 2008. Do discourse cues facilitate recall in information presentation messages? In Proceedings of the 9th International Conference on Spoken Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>