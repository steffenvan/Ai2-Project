<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000557">
<title confidence="0.8450482">
The intersection of Finite State Automata and Definite Clause
Grammars
Gertjan van Noord
Vakgroep Alfa-informatica Sr BCN
Rijksuniversiteit Groningen
</title>
<email confidence="0.986705">
vannoord@let.rug.n1
</email>
<sectionHeader confidence="0.997215" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999787041666667">
Bernard Lang defines parsing as the cal-
culation of the intersection of a FSA (the
input) and a CFG. Viewing the input for
parsing as a FSA rather than as a string
combines well with some approaches in
speech understanding systems, in which
parsing takes a word lattice as input
(rather than a word string). Furthermore,
certain techniques for robust parsing can
be modelled as finite state transducers.
In this paper we investigate how we can
generalize this approach for unification
grammars. In particular we will concen-
trate on how we might the calculation of
the intersection of a FSA and a DCG. It
is shown that existing parsing algorithms
can be easily extended for FSA inputs.
However, we also show that the termi-
nation properties change drastically: we
show that it is undecidable whether the in-
tersection of a FSA and a DCG is empty
(even if the DCG is off-line parsable).
Furthermore we discuss approaches to
cope with the problem.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997813244897959">
In this paper we are concerned with the syntactic
analysis phase of a natural language understanding
system. Ordinarily, the input of such a system is
a sequence of words. However, following Bernard
Lang we argue that it might be fruitful to take the
input more generally as afinite state automaton (FSA)
to model cases in which we are uncertain about the
actual input. Parsing uncertain input might be nec-
essary in case of ill-formed textual input, or in case
of speech input.
For example, if a natural language understand-
ing system is interfaced with a speech recognition
component, chances are that this compenent is un-
certain about the actual string of words that has
been uttered, and thus produces a word lattice of the
most promising hypotheses, rather than a single se-
quence of words. FSA of course generalizes such
word lattices.
As another example, certain techniques to deal
with ill-formed input can be characterized as finite
state transducers (Lang, 1989); the composition of
an input string with such a finite state transducer
results in a FSA that can then be input for syntac-
tic parsing. Such an approach allows for the treat-
ment of missing, extraneous, interchanged or mis-
used words (Teitelbaum, 1973; Saito and Tomita,
1988; Nederhof and Bertsch, 1994).
Such techniques might be of use both in the case
of written and spoken language input In the latter
case another possible application concerns the treat-
ment of phenomena such as repairs (Carter, 1994).
Note that we allow the input to be a full FSA
(possibly including cycles, etc.) since some of the
above-mentioned techniques indeed result in cy-
cles. Whereas an ordinary word-graph always de-
fines a finite language, a FSA of course can easily de-
fine an infinite number of sentences. Cycles might
emerge to treat unknown sequences of words, i.e.
sentences with unknown parts of unknown lengths
(Lang, 1988).
As suggested by an ACL reviewer, one could
also try to model haplology phenomena (such as
the &apos;s in English sentences like &apos;The chef at Joe&apos;s
hat&apos;, where &apos;Joe&apos;s&apos; is the name of a restaurant)
using a finite state transducer. In a straightforward
approach this would also lead to a finite-state
automaton with cycles.
It can be shown that the computation of the in-
tersection of a FSA and a CFG requires only a min-
</bodyText>
<equation confidence="0.709198">
1 5 9
</equation>
<bodyText confidence="0.9981207">
hnal generalization of existing parsing algorithms.
We simply replace the usual string positions with
the names of the states in the FSA. It is also straight-
forward to show that the complexity of this process
is cubic in the number of states of the FSA (in the
case of ordinary parsing the number of states equals
n +1) (Lang, 1974; Billot and Lang, 1989) (assuming
the right-hand-sides of grammar rules have at most
two categories).
In this paper we investigate whether the same
techniques can be applied in case the grammar is
a constraint-based grammar rather than a CFG. For
specificity we will take the grammar to be a Definite
Clause Grammar (DCG) (Pereira and Warren, 1980).
A DCG is a simple example of a family of constraint-
based grammar formalisms that are widely used
in natural language analysis (and generation). The
main findings of this paper can be extended to other
members of that family of constraint-based gram-
mar formalisms.
</bodyText>
<sectionHeader confidence="0.846374" genericHeader="method">
2 The intersection of a CFG and a FSA
</sectionHeader>
<bodyText confidence="0.991101957446809">
The calculation of the intersection of a CFG and
a FSA is very simple (Bar-Hillel et al., 1961). The
(context-free) grammar defining this intersection
is simply constructed by keeping track of the
state names in the non-terminal category sym-
bols. For each rule Xo -4 Xi . Xn there are
rules (Xogog) (X10341)(X24022) • • (Xnqn-ig),
for all go . gn. Furthermore for each transition
6(qi, a) = qk we have a rule (crqiqk) -+ a. Thus
the intersection of a FSA and a CFG is a CFG that
exactly derives all parse-trees. Such a grammar
might be called the parse-forest grammar.
Although this construction shows that the in-
tersection of a FSA and a CFG is itself a CFG, it
is not of practical interest. The reason is that this
• construction typically yields an enormous amount
of rules that are &apos;useless&apos;. In fact the (possibly enor-
mously large) parse forest grammar might define
an empty language (if the intersection was empty).
Luckily &apos;ordinary&apos; recognizers /parsers for CFG can
be easily generalized to construct this intersection
yielding (in typical cases) a much smaller grammar.
Checking whether the intersection is empty or not
is then usually very simple as well: only in the
latter case will the parser terminate succesfully.
To illustrate how a parser can be generalized to
accept a FSA as input we present a simple top-down
parser.
A context-free grammar is represented as a
definite-clause specification as follows. We do not
wish to define the sets of terminal and non-terminal
symbols explicitly, these can be understood from
the rules that are defined using the relation rule / 2,
and where symbols of the rhs are prefixed with
&apos;-&apos; in the case of terminals and &apos;+&apos; in the case of
non-terminals. The relation top/1 defines the start
symbol. The language L&apos; = ab n is defined as:
top(s).
rule(s,[-a,+s,-b]). rule(s,[]).
In order to illustrate how ordinary parsers can be
used to compute the intersection of a FSA and a
CFG consider first the definite-clause specification
of a top-down parser. This parser runs in polyno-
mial time if implemented using Earley deduction
or XOLDT resolution (Warren, 1992). It is assumed
that the input string is represented by the trans /3
predicate.
</bodyText>
<equation confidence="0.988946923076923">
parse(PO,P) :-
top(Cat), parse(+Cat,PO,P).
parse(-Cat,PO,P) :-
trans(PO,Cat,P),
side_effect(p(Cat,PO,P) --&gt; Cat).
parse(+Cat,PO,P) :-
rule(Cat,Ds),
parse_ds(Ds,PO,P,His),
side_effect(p(Cat,PO,P) --&gt; His).
parse_ds(M,P,P,[]).
parse_ds([HIT],P0,P,[p(H,P0,P1)1His]) :-
parse(H,PO,P1),
parse_ds(T,P1,P,His).
</equation>
<bodyText confidence="0.9977676">
The predicate side_effect is used to construct
the parse forest grammar. The predicate always suc-
ceeds, and as a side-effect asserts that its argument
is a rule of the parse forest grammar. For the sen-
tence &apos;a a b b&apos; we obtain the parse forest grammar:
</bodyText>
<equation confidence="0.999162">
p(s,2,2) --&gt; [J.
P(s,1,3) --&gt;
[P(-a,1,2),P0(+s,2,2),10(-1D,2,3)].
p(s,0,4) --&gt;
(P(-a,0,1),P(+s,1,3),P(-1D,3,4)].
p(a,1,2) --&gt; a.
p(a,0,1) --&gt; a.
p(b,2,3) --&gt; b.
p(b,3,4) --&gt; b.
</equation>
<bodyText confidence="0.999900666666667">
The reader easily verifies that indeed this grammar
generates (a isomorphism of) the single parse tree
of this example, assuming of course that the start
symbol for this parse-forest grammar is p (s, 0, 4).
In the parse-forest grammar, complex symbols are
non-terminals, atomic symbols are terminals.
Next consider the definite clause specification
of a FSA. We define the transition relation using
the relation trans/3. For start states, the relation
</bodyText>
<page confidence="0.962169">
160
</page>
<figure confidence="0.996910285714286">
s,q0,q2
a,q0,q1 s,q1,q2 b,q2,q2
a a,q1,q0 s,q0,q2 b,q2,q2 b
I
a a,q0,q1 s,q1,q2 b,q2,q2 b
I
a a,q1,q0 s,q0,q0 b,q2,q2 b
</figure>
<figureCaption confidence="0.999973">
Figure 1: A parse-tree extracted from the parse forest grammar
</figureCaption>
<bodyText confidence="0.999925">
start/1 should hold, and for final states the relation
final/1 should hold. Thus the following FSA, defin-
ing the regular language L = (aa)* b+ (i.e. an even
number of a&apos;s followed by at least one b) is given as:
</bodyText>
<construct confidence="0.871462">
start (q0) . final (q2) .
trans (q0, a, ql ) . trans (ql, a, q0 ) .
trans (q0, b, q2 ) . trans (q2 , b, q2 ) .
</construct>
<bodyText confidence="0.999025">
Interestingly, nothing needs to be changed to use
the same parser for the computation of the intersec-
tion of a FSA and a CFG. If our input &apos;sentence&apos; now
is the definition of trans / 3 as given above, we ob-
tain the following parse forest grammar (where the
start symbol is p ( s , q0 , q2 )):
</bodyText>
<equation confidence="0.999532916666667">
p(s,q0,q0) --&gt; [] .
p(s,q1,q1) --&gt;
p(s,q1,q2) --&gt;
[p(-a,q1,q0) ,p(+s,q0,q0) ,p(-b,q0,q2) ]
p(s,q0,q2) --&gt;
[p(-a,q0,q1) ,p(+s,q1,q2) ,p(-b,q2,q2) ]
p(s,q1,q2) --&gt;
[p (-a, q1, q0) ,p (+s,q0,q2 ) ,p (-b, q2,q2 )]
p(a,q0,q1) --&gt; a.
p(a,q1,q0) --&gt; a.
p (b,q0,q2) --&gt; b.
p(b,q2,q2) --&gt; b.
</equation>
<bodyText confidence="0.99981825">
Thus, even though we now use the same parser
for an infinite set of input sentences (represented
by the FSA) the parser still is able to come up
with a parse forest grammar. A possible derivation
for this grammar constructs the following (abbrevi-
ated) parse tree in figure 1. Note that the construc-
tion of Bar Hillel would have yielded a grammar
with 88 rules.
</bodyText>
<sectionHeader confidence="0.991922" genericHeader="method">
3 The intersection of a DCG and a FSA
</sectionHeader>
<bodyText confidence="0.990228037037037">
In this section we want to generalize the ideas de-
scribed above for CFG to DCG.
First note that the problem of calculating the in-
tersection of a DCG and a FSA can be solved triv-
ially by a generalization of the construction by (Bar-
Hillel et al., 1961). However, if we use that method
we will end up (typically) with an enormously large
forest grammar that is not even guaranteed to con-
tain solutions 1. Therefore, we are interested in
methods that only generate a small subset of this;
e.g. if the intersection is empty we want an empty
parse-forest grammar.
The straightforward approach is to generalize ex-
isting recognition algorithms. The same techniques
that are used for cakulating the intersection of a
FSA and a CFG can be applied in the case of DCGs.
In order to compute the intersection of a DCG and a
FSA we assume that FSA are represented as before.
DCGs are represented using the same notation we
used for context-free grammars, but now of course
the category symbols can be first-order terms of ar-
bitrary complexity (note that without loss of gener-
ality we don&apos;t take into account DCGs having exter-
&apos;In fact, the standard compilation of DCG into Prolog
clauses does something similar using variables instead of
actual state names. This also illustrates that this method
is not very useful yet; all the work has still to be done.
</bodyText>
<page confidence="0.974907">
161
</page>
<table confidence="0.804762875">
A1 A2 A3
1 10111 10
B1 B2 B3
111 10 0
Figure 2: Instance of a PCP problem.
A2 10111 A1 A1 1 A3 10 = 101111110
1 = 101111110
B2 10 111 B1 111 B3 0
</table>
<figureCaption confidence="0.997016">
Figure 3: Illustration of a solution for the PCP problem of figure 2.
</figureCaption>
<bodyText confidence="0.997968633333334">
nal actions defined in curly braces).
But if we use existing techniques for parsing
DCGs, then we are also confronted with an undecid-
ability problem: the recognition problem for DCGs
is undecidable (Pereira and Warren, 1983). A for-
tiori the problem of deciding whether the intersec-
tion of a FSA and a DCG is empty or not is undecid-
able.
This undecidability result is usually circum-
vented by considering subsets of DCGs which can
be recognized effectively. For example, we can
restrict the attention to DCGs of which the context-
free skeleton does not contain cycles. Recognition
for such &apos;off-line parsable&apos; grammars is decidable
(Pereira and Warren, 1983).
Most existing constraint-based parsing algo-
rithms will terminate for grammars that exhibit the
property that for each string there is only a finite
number of possible derivations. Note that off-line
parsability is one possible way of ensuring that this
is the case.
This observation is not very helpful in establish-
ing insights concerning interesting subclasses of
DCGs for which termination can be guaranteed
(in the case of FSA input). The reason is that there
are now two sources of recursion: in the DCG and
in the FSA (cycles). As we saw earlier: even for
CFG it holds that there can be an infinite number
of analyses for a given FSA (but in the CFG this of
course does not imply undecidability).
</bodyText>
<subsectionHeader confidence="0.953289">
3.1 Intersection of FSA and off-line parsable
DCG is undecidable
</subsectionHeader>
<bodyText confidence="0.998417947368421">
I now show that the question whether the intersec-
tion of a FSA and an off-line parsable DCG is empty
is undecidable. A yes-no problem is undecidable (cf.
(Hoperoft and Ullman, 1979, pp.178-179)) if there is
no algorithm that takes as its input an instance of
the problem and determines whether the answer to
that instance is &apos;yes&apos; or &apos;no&apos;. An instance of a prob-
lem consists of a particular choice of the parameters
of that problem.
I use Post&apos;s Correspondence Problem (PCP) as a
well-known undecidable problem. I show that if the
above mentioned intersection problem were decid-
able, then we could solve the PCP too. The follow-
ing definition and example of a PCP are taken from
(Hoperoft and Ullman, 1979)[chapter 8.5].
An instance of PCP consists of two lists, A =
Vi vk and B = wi wk of strings over some al-
phabet E. This instance has a solution if there is any
sequence of integers im, with m &gt; 1, such that
</bodyText>
<subsectionHeader confidence="0.581441">
Vil Vi„ , Vim
</subsectionHeader>
<bodyText confidence="0.9994678">
The sequence i 1,••, im is a solution to this instance
of PCP. As an example, assume that E = {0,1}.
Furthermore, let A = (1, 10111, 10) and B =
(111, 10,0). A solution to this instance of PCP is the
sequence 2,1,1,3 (obtaining the sequence 101111110).
For an illustration, cf. figure 3.
Clearly there are PCP&apos;s that do not have a solu-
tion. Assume again that E = (0, 1}. Furthermore
let A = (1) and B = (0). Clearly this PCP does not
have a solution. In general, however, the problem
</bodyText>
<page confidence="0.976552">
162
</page>
<table confidence="0.609324090909091">
trans(q0,x,q0). start(q0).
top(s).
rule(s,[-r(X,[I,X,(l))).
final(q0). % FSA
% start symbol DCG
% require A&apos;s and B&apos;s match
rule(r(A0,A,B0,B),[-r(A0,A1,B0,B1), % combine two sequences of
-r(A1,A,B1,B)]). % blocks
rule(r([11A], A,[1,1,1113],B),[+x]). % block Al/B1
rule(r([1,0,1,1,11A],A,[1,0IB], B),[+x]). % block A2/B2
rule(r((1,0IA], A,[0113], B), [+x] % block A3/B3
</table>
<figureCaption confidence="0.9989">
Figure 4: The encoding for the PCP problem of figure 2.
</figureCaption>
<bodyText confidence="0.960773454545454">
whether some PCP has a solution or not is not de-
cidable. This result is proved by (Hopc_roft and Ull-
man, 1979) by showing that the halting problem for
Turing Machines can be encoded as an instance of
Post&apos;s Correspondence Problem.
First I give a simple algorithm to encode any in-
stance of a PCP as a pair, consisting of a FSA and an
off-line parsable DCG, in such a way that the ques-
tion whether there is a solution to this PCP is equiv-
alent to the question whether the intersection of this
FSA and DCG is empty.
</bodyText>
<subsectionHeader confidence="0.529014">
Encoding of PCP.
</subsectionHeader>
<listItem confidence="0.91284675">
1. For each 1 &lt;i &lt; k (k the length of lists A and
B) define a DCG rule (the i — th member of A is
al . . . am, and the i—th member of B is bi . • • bn):
rgal amIA], A, [61 .. .bIB],B) [x].
2. Furthermore, there is a rule r(A0, A, Bo, B)
r(A0,AI,B0,B1),r(AI,A,B1,B).
3. Furthermore, there is a rule s r(X, [ ], X , []) .
Also, s is the start category of the DCG.
4. Finally, the FSA consists of a single state q
which is both the start state and the final state,
and a single transition 6(q, x) = q. This FSA
generates e.
</listItem>
<bodyText confidence="0.994020608695652">
Observe that the DCG is off-line parsable.
The underlying idea of the algorithm is really
very simple. For each pair of strings from the lists
A and B there will be one lexical entry (deriving the
terminal x) where these strings are represented by a
difference-list encoding. Furthermore there is a gen-
eral combination rule that simply concatenates A-
strings and concatenates B-strings. Finally the rule
for s states that in order to construct a succesful top
category the A and B lists must match.
The resulting DCG, FSA pair for the example PCI&apos;
is given in figure 4:
Proposition The question whether the intersec-
tion of a FSA and an off-line parsable DCG is empty
is undecidable.
Proof. Suppose the problem was decidable. In that
case there would exist an algorithm for solving the
problem. This algorithm could then be used to solve
the PCP, because a PCP ir has a solution if and only
if its encoding given above as a FSA and an off-line
parsable DCG is not empty The PCP problem how-
ever is known to be undecidable. Hence the inter-
section question is undecidable too.
</bodyText>
<subsectionHeader confidence="0.999777">
3.2 What to do?
</subsectionHeader>
<bodyText confidence="0.9990645">
The following approaches towards the undecidabil-
ity problem can be taken:
</bodyText>
<listItem confidence="0.9990635">
• limit the power of the FSA
• limit the power of the DCG
• compromise completeness
• compromise soundness
</listItem>
<bodyText confidence="0.9714478125">
These approaches are discussed now in turn.
Limit the FSA Rather than assuming the input for
parsing is a FSA in its full generality, we might as-
sume that the input is an ordinary word graph (a
FSA without cycles).
Thus the techniques for robust processing that
give rise to such cycles cannot be used. One exam-
ple is the processing of an unknown sequence of
words, e.g. in case there is noise in the input and
it is not clear how many words have been uttered
during this noise. It is not clear to me right now
what we loose (in practical terms) if we give up
such cycles.
Note that it is easy to verify that the question
whether the intersection of a word-graph and an off-
line parsable DCG is empty or not is decidable since
</bodyText>
<page confidence="0.996841">
163
</page>
<bodyText confidence="0.99982631372549">
it reduces to checking whether the DCG derives one
of a finite number of strings.
Limit the DCG Another approach is to limit the
size of the categories that are being employed. This
is the GPSG and F-TAG approach. In that case we
are not longer dealing with DCGs but rather with
CFGs (which have been shown to be insufficient in
general for the description of natural languages).
Compromise completeness Completeness in this
context means: the parse forest gratnmar contains
all possible parses. It is possible to compromise
here, in such a way that the parser is guaranteed to
terminate, but sometimes misses a few parse-trees.
For example, if we assume that each edge in the
FSA is associated with a probability it is possible to
define a threshold such that each partial result that
is derived has a probability higher than the thres-
hold. Thus, it is still possible to have cycles in the
FSA, but anytime the cycle is &apos;used&apos; the probabil-
ity decreases and if too many cycles are encountered
the threshold will cut off that derivation.
Of course this implies that sometimes the in-
tersection is considered empty by this procedure
whereas in fact the intersection is not. For any thres-
hold it is the case that the intersection problem of
off-line parsable DCGs and FSA is decidable.
Compromise soundness Soundness in this con-
text should be understood as the property that all
parse trees in the parse forest grammar are valid
parse trees. A possible way to ensure termination
is to remove all constraints from the DCG and parse
according to this context-free skeleton. The result-
ing parse-forest grammar will be too general most
of the times.
A practical variation can be conceived as fol-
lows. From the DCG we take its context-free skele-
ton. This skeleton is obtained by removing the con-
straints from each of the grammar rules. Then we
compute the intersection of the skeleton with the in-
put FSA. This results in a parse forest grammar. Fi-
nally, we add the corresponding constraints from
the DCG to the grammar rules of the parse forest
grammar.
This has the advantage that the result is still
sound and complete, although the size of the parse
forest grammar is not optimal (as a consequence it is
not guaranteed that the parse forest grammar con-
tains a parse tree). Of course it is possible to experi-
ment with different ways of taking the context-free
skeleton (including as much information as possible
/ useful).
</bodyText>
<sectionHeader confidence="0.995409" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999755">
I would like to thank Gosse Bouma, Mark-Jan
Nederhof and John Nerbonne for comments on this
paper. Furthermore the paper benefitted from re-
marks made by the anonymous ACL reviewers.
</bodyText>
<sectionHeader confidence="0.998431" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999038209302326">
Y. Bar-Hillel, M. Perles, and E. Shamir. 1961.
On formal properties of simple phrase structure
grammars. Zeitschrtft fur Phonetik, SprachWis-
senschaft und Kommunicationsforschung, 14:143-
172. Reprinted in Bar-Hillel&apos;s Language and
Information — Selected Essays on their Theory
and Application, Addison Wesley series in Logic,
1964, pp. 116-150.
S. Billot and B. Lang. 1989. The structure of shared
parse forests in ambiguous parsing. In 27th An-
nual Meeting of the Association for Computational
Linguistics, pages 143-151, Vancouver.
David Carter. 1994. Chapter 4: Linguistic analysis.
In M-S. Agnas, H. Alshawi, I. Bretan, D. Carter,
K. Ceder, M. Collins, R. Crouch, V. Digalalds,
B Ekholm, B. Gamback, J. IC*, J. Karlwen, B. Ly-
berg, P. Price, S. Pulman, M. Rayner, C. Samuels-
son, and T. Svensson, editors, Spoken Language
Translator: First Year Report. SICS Sweden / SRI
Cambridge. SICS research report R94:03, ISSN
0283-3638.
Barbara Grosz, Karen Sparck Jones, and
Bonny Lynn Webber, editors. 1986. Readings
in Natural Language Processing. Morgan Kauf-
mann.
John E. Hoperoft and Jeffrey D. Ullman. 1979. In-
troduction to Automata Theory, Languages and Com-
putation. Addison Wesley.
Bernard Lang. 1974. Deterministic techniques for
efficient non-deterministic parsers. In J. Loecloc,
editor, Proceedings of the Second Colloquium on Au-
tomata, Languages and Programming. Also: Rap-
port de Recherche 72, IRIA-Laboria, Rocquen-
court (France).
Bernard Lang. 1988. Parsing incomplete sentences.
In Proceedings of the 12th International Conference on
Computational Linguistics (COLING), Budapest.
Bernard Lang. 1989. A generative view of in-
formed input processing. In ATR Symposium on
Basic Research for Telephone Interpretation (ASTI),
Kyoto Japan.
Mark-Jan Nederhof and Eberhard Bertsch. 1994.
Linear-time suffix recognition for deterministic
</reference>
<page confidence="0.985149">
164
</page>
<reference confidence="0.997770047619048">
languages. Technical Report CSI-R9409, Comput-
ing Science Institute, KUN Nijmegen.
Fernando C.N. Pereira and David Warren. 1980.
Definite clause grammars for language analysis -
a survey of the formalism and a comparison with
augmented transition networks. Artificial Intelli-
gence, 13. reprinted in (Grosz et al., 1986).
Fernando C.N. Pereira and David Warren. 1983.
Parsing as deduction. In 21st Annual Meeting of
the Association for Computational Linguistics, Cam-
bridge Massachusetts.
H. Saito and M. Tomita. 1988. Parsing noisy
sentences. In Proceedings of the 12th International
Conference on Computational Linguistics (COLING),
pages 561-566, Budapest.
R. Teitelbaum. 1973. Context-free error analysis by
evaluation of algebraic power series. In Proceed-
ings of the Fifth Annual ACM Symposium on Theory
of Computing, Austin, Texas.
David S. Warren. 1992. Memoing for logic pro-
grams. Communications of the ACM, 35(3):94-111.
</reference>
<page confidence="0.998739">
165
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.235257">
<title confidence="0.998772">The intersection of Finite State Automata and Definite Clause Grammars</title>
<author confidence="0.825950333333333">Gertjan van_Noord Alfa-informatica BCN Rijksuniversiteit Groningen</author>
<email confidence="0.350825">vannoord@let.rug.n1</email>
<abstract confidence="0.99684268">Bernard Lang defines parsing as the calculation of the intersection of a FSA (the input) and a CFG. Viewing the input for parsing as a FSA rather than as a string combines well with some approaches in speech understanding systems, in which parsing takes a word lattice as input (rather than a word string). Furthermore, certain techniques for robust parsing can be modelled as finite state transducers. In this paper we investigate how we can generalize this approach for unification grammars. In particular we will concentrate on how we might the calculation of the intersection of a FSA and a DCG. It is shown that existing parsing algorithms can be easily extended for FSA inputs. However, we also show that the termination properties change drastically: we show that it is undecidable whether the intersection of a FSA and a DCG is empty (even if the DCG is off-line parsable). Furthermore we discuss approaches to cope with the problem.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>M Perles</author>
<author>E Shamir</author>
</authors>
<date>1961</date>
<contexts>
<context position="4513" citStr="Bar-Hillel et al., 1961" startWordPosition="761" endWordPosition="764">stigate whether the same techniques can be applied in case the grammar is a constraint-based grammar rather than a CFG. For specificity we will take the grammar to be a Definite Clause Grammar (DCG) (Pereira and Warren, 1980). A DCG is a simple example of a family of constraintbased grammar formalisms that are widely used in natural language analysis (and generation). The main findings of this paper can be extended to other members of that family of constraint-based grammar formalisms. 2 The intersection of a CFG and a FSA The calculation of the intersection of a CFG and a FSA is very simple (Bar-Hillel et al., 1961). The (context-free) grammar defining this intersection is simply constructed by keeping track of the state names in the non-terminal category symbols. For each rule Xo -4 Xi . Xn there are rules (Xogog) (X10341)(X24022) • • (Xnqn-ig), for all go . gn. Furthermore for each transition 6(qi, a) = qk we have a rule (crqiqk) -+ a. Thus the intersection of a FSA and a CFG is a CFG that exactly derives all parse-trees. Such a grammar might be called the parse-forest grammar. Although this construction shows that the intersection of a FSA and a CFG is itself a CFG, it is not of practical interest. Th</context>
</contexts>
<marker>Bar-Hillel, Perles, Shamir, 1961</marker>
<rawString>Y. Bar-Hillel, M. Perles, and E. Shamir. 1961.</rawString>
</citation>
<citation valid="true">
<title>On formal properties of simple phrase structure grammars. Zeitschrtft fur Phonetik, SprachWissenschaft und Kommunicationsforschung, 14:143-172. Reprinted</title>
<date>1964</date>
<booktitle>in Bar-Hillel&apos;s Language and Information — Selected Essays on their Theory and Application, Addison Wesley series in Logic,</booktitle>
<pages>116--150</pages>
<marker>1964</marker>
<rawString>On formal properties of simple phrase structure grammars. Zeitschrtft fur Phonetik, SprachWissenschaft und Kommunicationsforschung, 14:143-172. Reprinted in Bar-Hillel&apos;s Language and Information — Selected Essays on their Theory and Application, Addison Wesley series in Logic, 1964, pp. 116-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The structure of shared parse forests in ambiguous parsing.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>143--151</pages>
<location>Vancouver.</location>
<contexts>
<context position="3789" citStr="Billot and Lang, 1989" startWordPosition="637" endWordPosition="640">ere &apos;Joe&apos;s&apos; is the name of a restaurant) using a finite state transducer. In a straightforward approach this would also lead to a finite-state automaton with cycles. It can be shown that the computation of the intersection of a FSA and a CFG requires only a min1 5 9 hnal generalization of existing parsing algorithms. We simply replace the usual string positions with the names of the states in the FSA. It is also straightforward to show that the complexity of this process is cubic in the number of states of the FSA (in the case of ordinary parsing the number of states equals n +1) (Lang, 1974; Billot and Lang, 1989) (assuming the right-hand-sides of grammar rules have at most two categories). In this paper we investigate whether the same techniques can be applied in case the grammar is a constraint-based grammar rather than a CFG. For specificity we will take the grammar to be a Definite Clause Grammar (DCG) (Pereira and Warren, 1980). A DCG is a simple example of a family of constraintbased grammar formalisms that are widely used in natural language analysis (and generation). The main findings of this paper can be extended to other members of that family of constraint-based grammar formalisms. 2 The int</context>
</contexts>
<marker>Billot, Lang, 1989</marker>
<rawString>S. Billot and B. Lang. 1989. The structure of shared parse forests in ambiguous parsing. In 27th Annual Meeting of the Association for Computational Linguistics, pages 143-151, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Carter</author>
</authors>
<title>Chapter 4: Linguistic analysis.</title>
<date>1994</date>
<booktitle>Spoken Language Translator: First Year Report. SICS Sweden / SRI Cambridge. SICS research report R94:03, ISSN</booktitle>
<pages>0283--3638</pages>
<editor>In M-S. Agnas, H. Alshawi, I. Bretan, D. Carter, K. Ceder, M. Collins, R. Crouch, V. Digalalds, B Ekholm, B. Gamback, J. IC*, J. Karlwen, B. Lyberg, P. Price, S. Pulman, M. Rayner, C. Samuelsson, and T. Svensson, editors,</editor>
<contexts>
<context position="2609" citStr="Carter, 1994" startWordPosition="429" endWordPosition="430">ertain techniques to deal with ill-formed input can be characterized as finite state transducers (Lang, 1989); the composition of an input string with such a finite state transducer results in a FSA that can then be input for syntactic parsing. Such an approach allows for the treatment of missing, extraneous, interchanged or misused words (Teitelbaum, 1973; Saito and Tomita, 1988; Nederhof and Bertsch, 1994). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of the above-mentioned techniques indeed result in cycles. Whereas an ordinary word-graph always defines a finite language, a FSA of course can easily define an infinite number of sentences. Cycles might emerge to treat unknown sequences of words, i.e. sentences with unknown parts of unknown lengths (Lang, 1988). As suggested by an ACL reviewer, one could also try to model haplology phenomena (such as the &apos;s in English sentences like &apos;The chef at Joe&apos;s hat&apos;, where &apos;Joe&apos;s&apos; is the name of a restaurant) u</context>
</contexts>
<marker>Carter, 1994</marker>
<rawString>David Carter. 1994. Chapter 4: Linguistic analysis. In M-S. Agnas, H. Alshawi, I. Bretan, D. Carter, K. Ceder, M. Collins, R. Crouch, V. Digalalds, B Ekholm, B. Gamback, J. IC*, J. Karlwen, B. Lyberg, P. Price, S. Pulman, M. Rayner, C. Samuelsson, and T. Svensson, editors, Spoken Language Translator: First Year Report. SICS Sweden / SRI Cambridge. SICS research report R94:03, ISSN 0283-3638.</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>Readings in Natural Language Processing.</booktitle>
<editor>Barbara Grosz, Karen Sparck Jones, and Bonny Lynn Webber, editors.</editor>
<publisher>Morgan Kaufmann.</publisher>
<marker>1986</marker>
<rawString>Barbara Grosz, Karen Sparck Jones, and Bonny Lynn Webber, editors. 1986. Readings in Natural Language Processing. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John E Hoperoft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation.</title>
<date>1979</date>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="12442" citStr="Hoperoft and Ullman, 1979" startWordPosition="2115" endWordPosition="2118">ights concerning interesting subclasses of DCGs for which termination can be guaranteed (in the case of FSA input). The reason is that there are now two sources of recursion: in the DCG and in the FSA (cycles). As we saw earlier: even for CFG it holds that there can be an infinite number of analyses for a given FSA (but in the CFG this of course does not imply undecidability). 3.1 Intersection of FSA and off-line parsable DCG is undecidable I now show that the question whether the intersection of a FSA and an off-line parsable DCG is empty is undecidable. A yes-no problem is undecidable (cf. (Hoperoft and Ullman, 1979, pp.178-179)) if there is no algorithm that takes as its input an instance of the problem and determines whether the answer to that instance is &apos;yes&apos; or &apos;no&apos;. An instance of a problem consists of a particular choice of the parameters of that problem. I use Post&apos;s Correspondence Problem (PCP) as a well-known undecidable problem. I show that if the above mentioned intersection problem were decidable, then we could solve the PCP too. The following definition and example of a PCP are taken from (Hoperoft and Ullman, 1979)[chapter 8.5]. An instance of PCP consists of two lists, A = Vi vk and B = w</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>John E. Hoperoft and Jeffrey D. Ullman. 1979. Introduction to Automata Theory, Languages and Computation. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Deterministic techniques for efficient non-deterministic parsers.</title>
<date>1974</date>
<booktitle>Proceedings of the Second Colloquium on Automata, Languages and Programming. Also: Rapport de Recherche 72,</booktitle>
<editor>In J. Loecloc, editor,</editor>
<location>IRIA-Laboria, Rocquencourt</location>
<contexts>
<context position="3765" citStr="Lang, 1974" startWordPosition="635" endWordPosition="636">e&apos;s hat&apos;, where &apos;Joe&apos;s&apos; is the name of a restaurant) using a finite state transducer. In a straightforward approach this would also lead to a finite-state automaton with cycles. It can be shown that the computation of the intersection of a FSA and a CFG requires only a min1 5 9 hnal generalization of existing parsing algorithms. We simply replace the usual string positions with the names of the states in the FSA. It is also straightforward to show that the complexity of this process is cubic in the number of states of the FSA (in the case of ordinary parsing the number of states equals n +1) (Lang, 1974; Billot and Lang, 1989) (assuming the right-hand-sides of grammar rules have at most two categories). In this paper we investigate whether the same techniques can be applied in case the grammar is a constraint-based grammar rather than a CFG. For specificity we will take the grammar to be a Definite Clause Grammar (DCG) (Pereira and Warren, 1980). A DCG is a simple example of a family of constraintbased grammar formalisms that are widely used in natural language analysis (and generation). The main findings of this paper can be extended to other members of that family of constraint-based gramm</context>
</contexts>
<marker>Lang, 1974</marker>
<rawString>Bernard Lang. 1974. Deterministic techniques for efficient non-deterministic parsers. In J. Loecloc, editor, Proceedings of the Second Colloquium on Automata, Languages and Programming. Also: Rapport de Recherche 72, IRIA-Laboria, Rocquencourt (France).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Parsing incomplete sentences.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Budapest.</location>
<contexts>
<context position="3015" citStr="Lang, 1988" startWordPosition="497" endWordPosition="498">94). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of the above-mentioned techniques indeed result in cycles. Whereas an ordinary word-graph always defines a finite language, a FSA of course can easily define an infinite number of sentences. Cycles might emerge to treat unknown sequences of words, i.e. sentences with unknown parts of unknown lengths (Lang, 1988). As suggested by an ACL reviewer, one could also try to model haplology phenomena (such as the &apos;s in English sentences like &apos;The chef at Joe&apos;s hat&apos;, where &apos;Joe&apos;s&apos; is the name of a restaurant) using a finite state transducer. In a straightforward approach this would also lead to a finite-state automaton with cycles. It can be shown that the computation of the intersection of a FSA and a CFG requires only a min1 5 9 hnal generalization of existing parsing algorithms. We simply replace the usual string positions with the names of the states in the FSA. It is also straightforward to show that the</context>
</contexts>
<marker>Lang, 1988</marker>
<rawString>Bernard Lang. 1988. Parsing incomplete sentences. In Proceedings of the 12th International Conference on Computational Linguistics (COLING), Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>A generative view of informed input processing.</title>
<date>1989</date>
<booktitle>In ATR Symposium on Basic Research for Telephone Interpretation</booktitle>
<location>(ASTI), Kyoto</location>
<contexts>
<context position="2105" citStr="Lang, 1989" startWordPosition="344" endWordPosition="345">tual input. Parsing uncertain input might be necessary in case of ill-formed textual input, or in case of speech input. For example, if a natural language understanding system is interfaced with a speech recognition component, chances are that this compenent is uncertain about the actual string of words that has been uttered, and thus produces a word lattice of the most promising hypotheses, rather than a single sequence of words. FSA of course generalizes such word lattices. As another example, certain techniques to deal with ill-formed input can be characterized as finite state transducers (Lang, 1989); the composition of an input string with such a finite state transducer results in a FSA that can then be input for syntactic parsing. Such an approach allows for the treatment of missing, extraneous, interchanged or misused words (Teitelbaum, 1973; Saito and Tomita, 1988; Nederhof and Bertsch, 1994). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of </context>
<context position="3789" citStr="Lang, 1989" startWordPosition="639" endWordPosition="640"> is the name of a restaurant) using a finite state transducer. In a straightforward approach this would also lead to a finite-state automaton with cycles. It can be shown that the computation of the intersection of a FSA and a CFG requires only a min1 5 9 hnal generalization of existing parsing algorithms. We simply replace the usual string positions with the names of the states in the FSA. It is also straightforward to show that the complexity of this process is cubic in the number of states of the FSA (in the case of ordinary parsing the number of states equals n +1) (Lang, 1974; Billot and Lang, 1989) (assuming the right-hand-sides of grammar rules have at most two categories). In this paper we investigate whether the same techniques can be applied in case the grammar is a constraint-based grammar rather than a CFG. For specificity we will take the grammar to be a Definite Clause Grammar (DCG) (Pereira and Warren, 1980). A DCG is a simple example of a family of constraintbased grammar formalisms that are widely used in natural language analysis (and generation). The main findings of this paper can be extended to other members of that family of constraint-based grammar formalisms. 2 The int</context>
</contexts>
<marker>Lang, 1989</marker>
<rawString>Bernard Lang. 1989. A generative view of informed input processing. In ATR Symposium on Basic Research for Telephone Interpretation (ASTI), Kyoto Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark-Jan Nederhof</author>
<author>Eberhard Bertsch</author>
</authors>
<title>Linear-time suffix recognition for deterministic languages.</title>
<date>1994</date>
<tech>Technical Report CSI-R9409,</tech>
<institution>Computing Science Institute, KUN Nijmegen.</institution>
<contexts>
<context position="2407" citStr="Nederhof and Bertsch, 1994" startWordPosition="393" endWordPosition="396">al string of words that has been uttered, and thus produces a word lattice of the most promising hypotheses, rather than a single sequence of words. FSA of course generalizes such word lattices. As another example, certain techniques to deal with ill-formed input can be characterized as finite state transducers (Lang, 1989); the composition of an input string with such a finite state transducer results in a FSA that can then be input for syntactic parsing. Such an approach allows for the treatment of missing, extraneous, interchanged or misused words (Teitelbaum, 1973; Saito and Tomita, 1988; Nederhof and Bertsch, 1994). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of the above-mentioned techniques indeed result in cycles. Whereas an ordinary word-graph always defines a finite language, a FSA of course can easily define an infinite number of sentences. Cycles might emerge to treat unknown sequences of words, i.e. sentences with unknown parts of unknown lengths (Lan</context>
</contexts>
<marker>Nederhof, Bertsch, 1994</marker>
<rawString>Mark-Jan Nederhof and Eberhard Bertsch. 1994. Linear-time suffix recognition for deterministic languages. Technical Report CSI-R9409, Computing Science Institute, KUN Nijmegen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David Warren</author>
</authors>
<title>Definite clause grammars for language analysis -a survey of the formalism and a comparison with augmented transition networks.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<volume>13</volume>
<note>reprinted in (Grosz et al.,</note>
<contexts>
<context position="4114" citStr="Pereira and Warren, 1980" startWordPosition="690" endWordPosition="693">simply replace the usual string positions with the names of the states in the FSA. It is also straightforward to show that the complexity of this process is cubic in the number of states of the FSA (in the case of ordinary parsing the number of states equals n +1) (Lang, 1974; Billot and Lang, 1989) (assuming the right-hand-sides of grammar rules have at most two categories). In this paper we investigate whether the same techniques can be applied in case the grammar is a constraint-based grammar rather than a CFG. For specificity we will take the grammar to be a Definite Clause Grammar (DCG) (Pereira and Warren, 1980). A DCG is a simple example of a family of constraintbased grammar formalisms that are widely used in natural language analysis (and generation). The main findings of this paper can be extended to other members of that family of constraint-based grammar formalisms. 2 The intersection of a CFG and a FSA The calculation of the intersection of a CFG and a FSA is very simple (Bar-Hillel et al., 1961). The (context-free) grammar defining this intersection is simply constructed by keeping track of the state names in the non-terminal category symbols. For each rule Xo -4 Xi . Xn there are rules (Xogo</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Fernando C.N. Pereira and David Warren. 1980. Definite clause grammars for language analysis -a survey of the formalism and a comparison with augmented transition networks. Artificial Intelligence, 13. reprinted in (Grosz et al., 1986).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David Warren</author>
</authors>
<title>Parsing as deduction.</title>
<date>1983</date>
<booktitle>In 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Cambridge Massachusetts.</location>
<contexts>
<context position="11062" citStr="Pereira and Warren, 1983" startWordPosition="1880" endWordPosition="1883">olog clauses does something similar using variables instead of actual state names. This also illustrates that this method is not very useful yet; all the work has still to be done. 161 A1 A2 A3 1 10111 10 B1 B2 B3 111 10 0 Figure 2: Instance of a PCP problem. A2 10111 A1 A1 1 A3 10 = 101111110 1 = 101111110 B2 10 111 B1 111 B3 0 Figure 3: Illustration of a solution for the PCP problem of figure 2. nal actions defined in curly braces). But if we use existing techniques for parsing DCGs, then we are also confronted with an undecidability problem: the recognition problem for DCGs is undecidable (Pereira and Warren, 1983). A fortiori the problem of deciding whether the intersection of a FSA and a DCG is empty or not is undecidable. This undecidability result is usually circumvented by considering subsets of DCGs which can be recognized effectively. For example, we can restrict the attention to DCGs of which the contextfree skeleton does not contain cycles. Recognition for such &apos;off-line parsable&apos; grammars is decidable (Pereira and Warren, 1983). Most existing constraint-based parsing algorithms will terminate for grammars that exhibit the property that for each string there is only a finite number of possible </context>
</contexts>
<marker>Pereira, Warren, 1983</marker>
<rawString>Fernando C.N. Pereira and David Warren. 1983. Parsing as deduction. In 21st Annual Meeting of the Association for Computational Linguistics, Cambridge Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saito</author>
<author>M Tomita</author>
</authors>
<title>Parsing noisy sentences.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>561--566</pages>
<location>Budapest.</location>
<contexts>
<context position="2378" citStr="Saito and Tomita, 1988" startWordPosition="389" endWordPosition="392">uncertain about the actual string of words that has been uttered, and thus produces a word lattice of the most promising hypotheses, rather than a single sequence of words. FSA of course generalizes such word lattices. As another example, certain techniques to deal with ill-formed input can be characterized as finite state transducers (Lang, 1989); the composition of an input string with such a finite state transducer results in a FSA that can then be input for syntactic parsing. Such an approach allows for the treatment of missing, extraneous, interchanged or misused words (Teitelbaum, 1973; Saito and Tomita, 1988; Nederhof and Bertsch, 1994). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of the above-mentioned techniques indeed result in cycles. Whereas an ordinary word-graph always defines a finite language, a FSA of course can easily define an infinite number of sentences. Cycles might emerge to treat unknown sequences of words, i.e. sentences with unknown </context>
</contexts>
<marker>Saito, Tomita, 1988</marker>
<rawString>H. Saito and M. Tomita. 1988. Parsing noisy sentences. In Proceedings of the 12th International Conference on Computational Linguistics (COLING), pages 561-566, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Teitelbaum</author>
</authors>
<title>Context-free error analysis by evaluation of algebraic power series.</title>
<date>1973</date>
<booktitle>In Proceedings of the Fifth Annual ACM Symposium on Theory of Computing,</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="2354" citStr="Teitelbaum, 1973" startWordPosition="387" endWordPosition="388">this compenent is uncertain about the actual string of words that has been uttered, and thus produces a word lattice of the most promising hypotheses, rather than a single sequence of words. FSA of course generalizes such word lattices. As another example, certain techniques to deal with ill-formed input can be characterized as finite state transducers (Lang, 1989); the composition of an input string with such a finite state transducer results in a FSA that can then be input for syntactic parsing. Such an approach allows for the treatment of missing, extraneous, interchanged or misused words (Teitelbaum, 1973; Saito and Tomita, 1988; Nederhof and Bertsch, 1994). Such techniques might be of use both in the case of written and spoken language input In the latter case another possible application concerns the treatment of phenomena such as repairs (Carter, 1994). Note that we allow the input to be a full FSA (possibly including cycles, etc.) since some of the above-mentioned techniques indeed result in cycles. Whereas an ordinary word-graph always defines a finite language, a FSA of course can easily define an infinite number of sentences. Cycles might emerge to treat unknown sequences of words, i.e.</context>
</contexts>
<marker>Teitelbaum, 1973</marker>
<rawString>R. Teitelbaum. 1973. Context-free error analysis by evaluation of algebraic power series. In Proceedings of the Fifth Annual ACM Symposium on Theory of Computing, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David S Warren</author>
</authors>
<title>Memoing for logic programs.</title>
<date>1992</date>
<journal>Communications of the ACM,</journal>
<pages>35--3</pages>
<contexts>
<context position="6527" citStr="Warren, 1992" startWordPosition="1103" endWordPosition="1104">licitly, these can be understood from the rules that are defined using the relation rule / 2, and where symbols of the rhs are prefixed with &apos;-&apos; in the case of terminals and &apos;+&apos; in the case of non-terminals. The relation top/1 defines the start symbol. The language L&apos; = ab n is defined as: top(s). rule(s,[-a,+s,-b]). rule(s,[]). In order to illustrate how ordinary parsers can be used to compute the intersection of a FSA and a CFG consider first the definite-clause specification of a top-down parser. This parser runs in polynomial time if implemented using Earley deduction or XOLDT resolution (Warren, 1992). It is assumed that the input string is represented by the trans /3 predicate. parse(PO,P) :- top(Cat), parse(+Cat,PO,P). parse(-Cat,PO,P) :- trans(PO,Cat,P), side_effect(p(Cat,PO,P) --&gt; Cat). parse(+Cat,PO,P) :- rule(Cat,Ds), parse_ds(Ds,PO,P,His), side_effect(p(Cat,PO,P) --&gt; His). parse_ds(M,P,P,[]). parse_ds([HIT],P0,P,[p(H,P0,P1)1His]) :- parse(H,PO,P1), parse_ds(T,P1,P,His). The predicate side_effect is used to construct the parse forest grammar. The predicate always succeeds, and as a side-effect asserts that its argument is a rule of the parse forest grammar. For the sentence &apos;a a b b&apos;</context>
</contexts>
<marker>Warren, 1992</marker>
<rawString>David S. Warren. 1992. Memoing for logic programs. Communications of the ACM, 35(3):94-111.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>