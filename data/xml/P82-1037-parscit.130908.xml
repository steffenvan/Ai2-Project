<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017181">
<note confidence="0.367983">
Ill-Formed and Non-Standard Language Problems
</note>
<author confidence="0.873139">
Stan Kwasny
</author>
<affiliation confidence="0.9771065">
Computer Science Department
Indiana University
</affiliation>
<sectionHeader confidence="0.7056475" genericHeader="method">
Bloomington, IN 47405
Abstract
</sectionHeader>
<bodyText confidence="0.998826428571429">
Prospects look good for making real improve-
ments in Natural Language Processing systems with
regard to dealing with unconventional inputs in a
practical way. Research which is expected to have
an influence on this progress as well as some
predictions about accomplishments in both the
short and long term are discussed.
</bodyText>
<sectionHeader confidence="0.97304" genericHeader="method">
1, Introduction
</sectionHeader>
<bodyText confidence="0.995775238095238">
Developing Natural Language Understanding
systems which permit language in expected forms in
anticipated environments having a well-defined
semantics is in many ways a solved problem with
today&apos;s technology. Unfortunately, few interest-
ing situations in which Natural Language is useful
live up to this description. Even a modicum of
machine intelligence is not possible, we believe,
without continuing the pursuit for more sophisti-
cated models which deal with such problems and
which degrade gracefully (see Hayes and Reddy,
1979).
Language as spoken (or typed) breaks the
&amp;quot;rules&amp;quot;. Every study substantiates this fact.
Halhotra (1975) discovered this in his studies of
live subjects in designing a system to support
decision-making activities. An extensive investi-
gation by Thompson (1980) provides further evi-
dence that providing a grammar of &amp;quot;standard
English&amp;quot; does not go far enough in meeting the
prospective needs of the user. Studies by Fromkin
and her co-workers (1980), likewise, provide new
insights into the range of errors that can occur
in the use of language in various situations.
Studies of this sort are essential in identifying
the nature of such non-standard usages.
But more than merely anticipating user inputs
is required. Grammaticality is a continuum
phenomenon with many dimensions. So is intelligi-
bility. In hearing language used in a strange
way, we often pass off the variation as dialectic,
or we might unconsciously correct an errorful
utterance. Occasionally, we might. not understand
or even misunderstand. What are the rules (meta-
rules, etc.) under which we operate in doing this?
Can introspection be trusted to provide the proper
perspectives? The results of at least one
investigator argue against the use of intuitions
in discovering these rules (Spencer, 1973). Com-
putational linguists must continue to conduct stu-
dies and consider the results of studies conducted
by others.
</bodyText>
<sectionHeader confidence="0.980108" genericHeader="method">
2. Perzoectives
</sectionHeader>
<bodyText confidence="0.991193666666667">
Several perspectives exist which may give
insights on the problem. We present some of
these, not to pretend to exhaustively summarize
them, but •to hopefully stimulate interest among
researchers to pursue one or more of these views
of what is needed.
Certain telegraphic forms of language occur
in situations where two or more speakers of dif-
ferent languages must communicate. A pidgin form
of language develops which borrows features from
each of the languages. Characteristically, it has
limited vocabulary and lacks several grammatical
devices (like number and gender, for example) and
exhibits a reduced number of redundant features.
This phenomenon can similarly be observed in some
styles of man-machine dialogue. Once the user
achieves some success in conversing with the
machine, whether the conversation is being con-
ducted in Natural Language or not, there is a ten-
dency to continue to use those forms and words
which were previously handled correctly. The
result is a type of pidginization between the
machine dialect and the user dialect which exhi-
bits pidgin-like characteristics: limited vocabu-
lary, limited use of some grammatical devices,
etc. It is therefore reasonable to study these
forms of language and to attempt to accomodate
them in some natural way within our language
models. Woods (1977) points out that the use of
Natural Language:
&amp;quot;... does not preclude the introduction of
abbreviations and telegraphic shorthands for
complex or high frequency concepts -- the
ability of natural English to accommodate such
abbreviations is one of its strengths.&amp;quot; (p.18)
Specialized sublanguages can often be identified
which enhance the quality of the communication and
prove to be quite convenient especially to fre-
quent users.
</bodyText>
<page confidence="0.993941">
164
</page>
<bodyText confidence="0.985023266666667">
Conjunction is an extremely common and yet
poorly understood phenomenon. The wide variety of
ways in which sentence fragments may be joined
argues against any approach which attempts to
account for conjunction within the same set of
rules used in processing other sentences. Also,
constituents being joined are often fragments,
rather than complete sentences, and, therefore,
any serious attempt to address the problem of con-
junction must necessarily investigate ellipsis as
well. Since conjunction-handling involves
ellipsis-handling, techniques which treat non-
standard linguistic forms must explicate both.
a. Technioues
What approaches work well in such situta-
tions? Once a non-standard language form has been
identified, the rules of the language processing
component could simply be expanded to accomodate
that new form. But that approach has limitations
and misses the general phenomenon in most cases.
Dejong (1979) demonstrated that wire service
stories could be &amp;quot;skimmed&amp;quot; for prescribed concepts
without much regard to grammaticality or accepta-
bility issues. Instead, as long as coherency
existed among the individual concepts, the overall
content of the story could be summarized. The
whole problem of addressing what to do with non-
standard inputs was finessed because of the con-
text.
Techniques based on meta-rules have been
explored by various researchers. Kwasny (1980)
investigated specialized techniques for dealing
with cooccurrence violations, ellipsis, and con-
junction within an ATN grammar. Sondheimer and
Weischedel (1981) have generalized and refined
this approach by making the meta-rules more expli-
cit and by designing strategies which manipulate
the rules of the grammar using meta-rules.
Other systems have taken the approach that
the user should play a major role in exercising
choices about the interpretations proposed by the
system. With such feedback to the user, no time-
consuming actions are performed without his appro-
val. This approach works well in database
retrieval tasks.
</bodyText>
<listItem confidence="0.569875">
4. Near and Long Term Prospects
</listItem>
<bodyText confidence="0.999983829787234">
In the short term, we must look to what we
understand and know about the language phenomena
and apply those techniques that appear promising.
. Non-standard language forms appear as errors in
the expected processing paths.
One of the functions of a style-checking pro-
gram (for example the EPISTLE system by Miller et
al., 1981) is to detect and, in some cases,
correct certain types of errors made by the author
of a document. Since such programs are expected
to become more of a necessary part of any author
support system, a great deal of research can be
expected to be directed at that problem.
A great deal of research which deals with
errors in language inputs comes from attempts to
process continuous speech (see, for example,
Bates, 1976). The techniques associate with non-
left-to-right processing strategies should prove
useful in narrowing the number of legal alterna-
tives to be attempted when identifying and
correcting some types of error. It is quite con-
ceivable that an approach to this problem that
parallels the work on speech understanding would
be very fruitful. Note that this does not involve
inventing new methods, but rather borrows from
related studies. The primary impediment, at the
moment, to this approach, as with some of the
other approaches mentioned, is the time involved
in considering viable alternatives. As these
problems are reduced over the next few years, I
feel that we should see Natural Language systems
with greatly improved communication abilities.
In the long term, some form of language
learning capability will be critical. Both rules
and meta-rules will need to be modifiable. The
system behavior will need to improve and adapt to
the user over time. User models of style and pre-
ferred forms as well as common mistakes will be
developed as a necessary part of such systems. As
speed increases, more opportunity will be avail-
able for creative architectures such as was seen
in the speech projects, but which still respond
within a reasonable time frame.
Finally, formal studies of user responses
will need to be conducted in an ongoing fashion to
assure that the systems we build conform to user
needs.
</bodyText>
<sectionHeader confidence="0.92825" genericHeader="method">
5. yeferences
</sectionHeader>
<reference confidence="0.971515071428572">
Bates, M., &amp;quot;Syntax in Automatic Speech Understand-
ing,&amp;quot; American Journal 91 Computational Linguis-
tics, Microfiche 45, 1976.
DeJong, G.F., &amp;quot;Skimming Stories in Real Time: An
Experiment in Integrated Understanding,&amp;quot; Techni-
cal Report 158, Yale University, Computer Sci-
ence Department, 1979.
Fromkin, V.A., ed., Errors la Linguistic Yerfor-
mance: Slips of the Tongue, Ear, Pen, and Hand,
Academic Press, New York, 1980.
Hayes, P.J., and R. Reddy, &amp;quot;An Anatomy of Graceful
Interaction in Spoken and Written Man-Machine
Communication,&amp;quot; Technical Report, Carnegie-
Mellon University, August, 1979.
</reference>
<page confidence="0.993262">
165
</page>
<reference confidence="0.998552075">
Kwasny, S.C., &amp;quot;Treatment of Ungrammatical and
Extra-grammatical Phenomena in Natural Language
Understanding Systems,&amp;quot; Ph.D. Thesis, Ohio State
University, 1980, (available through the Indiana
University Linguistics Club, Bloomington, Indi-
aria).
Kwasny, S.C., and N.K. Sondheimer, &amp;quot;Relaxation
Techniques for Parsing III-Formed Input,&amp;quot; Ameri-
can Journal of Computational Linguistics, Vol.
7, No. 2, April-June, 1981, 99-108.
Malhotra, A., &amp;quot;Design Criteria for a Knowledge-
Based English Language System for Management: An
Experimental Analysis,&amp;quot; MAC TR 146, Cambridge,
MA, M.I.T., February, 1975.
Miller, L.A., G.E. Heidorn, and K. Jensen, &amp;quot;Text-
Critiquing with the EPISTLE System: An Author&apos;s
Aid to Better Syntax,&amp;quot; Proceedings of the
National Computer Conference, AFIPS Press,
Montvale, NJ, 1981.
-Sondheimer, N.K., and R.M. Weischedel, &amp;quot;A Computa-
tional Linguistic Approach to Ungrammaticality
Based on Meta-Rules&amp;quot; Annual Melling of the
Linguistic Society .pj America New York, NY,
December, 1981.
Spencer, N.J., &amp;quot;Differences Between Linguists and
Nonlinguists in Intuitions of Grammaticality-
Acceptability&amp;quot; Journal of Ysycholinguistic
Research, 2, 2, 1973, 83-99.
Thompson, B.H., &amp;quot;Linguistic Analysis of Natural
Language Communication with Computers,&amp;quot; Proceed-
j,pgs of the Eighth International Conference on
Computational Linguistics, Tokyo, October, 1980,
190-201.
Weischedel, R.M., and N.K. Sondheimer, &amp;quot;A Frame-
work for Processing Ill-Formed Input,&amp;quot; Technical
Memorandum 11-00519, Sperry-Univac, Blue Bell,
PA, October 16, 1981.
Woods, W.A., &amp;quot;A Personal View of Natural Language
Understanding,&amp;quot; SIGART Newsletter, No. 61,
February, 1977, 17-18.
</reference>
<page confidence="0.998764">
166
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.679963">
<title confidence="0.999906">Ill-Formed and Non-Standard Language Problems</title>
<author confidence="0.999987">Stan Kwasny</author>
<affiliation confidence="0.999985">Computer Science Department Indiana University</affiliation>
<address confidence="0.999914">Bloomington, IN 47405</address>
<abstract confidence="0.999278632911392">Prospects look good for making real improvements in Natural Language Processing systems with regard to dealing with unconventional inputs in a practical way. Research which is expected to have an influence on this progress as well as some predictions about accomplishments in both the short and long term are discussed. Developing Natural Language Understanding systems which permit language in expected forms in anticipated environments having a well-defined semantics is in many ways a solved problem with today&apos;s technology. Unfortunately, few interesting situations in which Natural Language is useful live up to this description. Even a modicum of machine intelligence is not possible, we believe, without continuing the pursuit for more sophisticated models which deal with such problems and which degrade gracefully (see Hayes and Reddy, 1979). Language as spoken (or typed) breaks the &amp;quot;rules&amp;quot;. Every study substantiates this fact. Halhotra (1975) discovered this in his studies of live subjects in designing a system to support decision-making activities. An extensive investigation by Thompson (1980) provides further evidence that providing a grammar of &amp;quot;standard English&amp;quot; does not go far enough in meeting the prospective needs of the user. Studies by Fromkin and her co-workers (1980), likewise, provide new insights into the range of errors that can occur in the use of language in various situations. Studies of this sort are essential in identifying nature of such usages. But more than merely anticipating user inputs is required. Grammaticality is a continuum with many dimensions. So is intelligibility. In hearing language used in a strange way, we often pass off the variation as dialectic, or we might unconsciously correct an errorful utterance. Occasionally, we might. not understand or even misunderstand. What are the rules (metarules, etc.) under which we operate in doing this? Can introspection be trusted to provide the proper perspectives? The results of at least one investigator argue against the use of intuitions discovering these rules (Spencer, putational linguists must continue to conduct studies and consider the results of studies conducted by others. Several perspectives exist which may give insights on the problem. We present some of these, not to pretend to exhaustively summarize them, but •to hopefully stimulate interest among researchers to pursue one or more of these views of what is needed. Certain telegraphic forms of language occur in situations where two or more speakers of different languages must communicate. A pidgin form of language develops which borrows features from each of the languages. Characteristically, it has limited vocabulary and lacks several grammatical devices (like number and gender, for example) and exhibits a reduced number of redundant features. This phenomenon can similarly be observed in some styles of man-machine dialogue. Once the user achieves some success in conversing with the machine, whether the conversation is being conducted in Natural Language or not, there is a tendency to continue to use those forms and words which were previously handled correctly. The is a type of pidginization the machine dialect and the user dialect which exhibits pidgin-like characteristics: limited vocabulary, limited use of some grammatical devices, etc. It is therefore reasonable to study these forms of language and to attempt to accomodate them in some natural way within our language models. Woods (1977) points out that the use of</abstract>
<intro confidence="0.705984">Natural Language:</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bates</author>
</authors>
<title>Syntax in Automatic Speech Understanding,&amp;quot;</title>
<date>1976</date>
<journal>American Journal 91 Computational Linguistics, Microfiche</journal>
<volume>45</volume>
<contexts>
<context position="6934" citStr="Bates, 1976" startWordPosition="1070" endWordPosition="1071">mising. . Non-standard language forms appear as errors in the expected processing paths. One of the functions of a style-checking program (for example the EPISTLE system by Miller et al., 1981) is to detect and, in some cases, correct certain types of errors made by the author of a document. Since such programs are expected to become more of a necessary part of any author support system, a great deal of research can be expected to be directed at that problem. A great deal of research which deals with errors in language inputs comes from attempts to process continuous speech (see, for example, Bates, 1976). The techniques associate with nonleft-to-right processing strategies should prove useful in narrowing the number of legal alternatives to be attempted when identifying and correcting some types of error. It is quite conceivable that an approach to this problem that parallels the work on speech understanding would be very fruitful. Note that this does not involve inventing new methods, but rather borrows from related studies. The primary impediment, at the moment, to this approach, as with some of the other approaches mentioned, is the time involved in considering viable alternatives. As thes</context>
</contexts>
<marker>Bates, 1976</marker>
<rawString>Bates, M., &amp;quot;Syntax in Automatic Speech Understanding,&amp;quot; American Journal 91 Computational Linguistics, Microfiche 45, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G F DeJong</author>
</authors>
<title>Skimming Stories in Real Time: An Experiment in Integrated Understanding,&amp;quot;</title>
<date>1979</date>
<tech>Technical Report 158,</tech>
<institution>Yale University, Computer Science Department,</institution>
<marker>DeJong, 1979</marker>
<rawString>DeJong, G.F., &amp;quot;Skimming Stories in Real Time: An Experiment in Integrated Understanding,&amp;quot; Technical Report 158, Yale University, Computer Science Department, 1979.</rawString>
</citation>
<citation valid="true">
<date>1980</date>
<booktitle>Errors la Linguistic Yerformance: Slips of the Tongue,</booktitle>
<editor>Fromkin, V.A., ed.,</editor>
<publisher>Hand, Academic Press,</publisher>
<location>Ear, Pen, and</location>
<contexts>
<context position="1261" citStr="(1980)" startWordPosition="184" endWordPosition="184">with today&apos;s technology. Unfortunately, few interesting situations in which Natural Language is useful live up to this description. Even a modicum of machine intelligence is not possible, we believe, without continuing the pursuit for more sophisticated models which deal with such problems and which degrade gracefully (see Hayes and Reddy, 1979). Language as spoken (or typed) breaks the &amp;quot;rules&amp;quot;. Every study substantiates this fact. Halhotra (1975) discovered this in his studies of live subjects in designing a system to support decision-making activities. An extensive investigation by Thompson (1980) provides further evidence that providing a grammar of &amp;quot;standard English&amp;quot; does not go far enough in meeting the prospective needs of the user. Studies by Fromkin and her co-workers (1980), likewise, provide new insights into the range of errors that can occur in the use of language in various situations. Studies of this sort are essential in identifying the nature of such non-standard usages. But more than merely anticipating user inputs is required. Grammaticality is a continuum phenomenon with many dimensions. So is intelligibility. In hearing language used in a strange way, we often pass of</context>
<context position="5529" citStr="(1980)" startWordPosition="842" endWordPosition="842">d simply be expanded to accomodate that new form. But that approach has limitations and misses the general phenomenon in most cases. Dejong (1979) demonstrated that wire service stories could be &amp;quot;skimmed&amp;quot; for prescribed concepts without much regard to grammaticality or acceptability issues. Instead, as long as coherency existed among the individual concepts, the overall content of the story could be summarized. The whole problem of addressing what to do with nonstandard inputs was finessed because of the context. Techniques based on meta-rules have been explored by various researchers. Kwasny (1980) investigated specialized techniques for dealing with cooccurrence violations, ellipsis, and conjunction within an ATN grammar. Sondheimer and Weischedel (1981) have generalized and refined this approach by making the meta-rules more explicit and by designing strategies which manipulate the rules of the grammar using meta-rules. Other systems have taken the approach that the user should play a major role in exercising choices about the interpretations proposed by the system. With such feedback to the user, no timeconsuming actions are performed without his approval. This approach works well in</context>
</contexts>
<marker>1980</marker>
<rawString>Fromkin, V.A., ed., Errors la Linguistic Yerformance: Slips of the Tongue, Ear, Pen, and Hand, Academic Press, New York, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
<author>R Reddy</author>
</authors>
<title>An Anatomy of Graceful Interaction in Spoken and Written Man-Machine Communication,&amp;quot;</title>
<date>1979</date>
<tech>Technical Report,</tech>
<institution>CarnegieMellon University,</institution>
<contexts>
<context position="1002" citStr="Hayes and Reddy, 1979" startWordPosition="143" endWordPosition="146">ctions about accomplishments in both the short and long term are discussed. 1, Introduction Developing Natural Language Understanding systems which permit language in expected forms in anticipated environments having a well-defined semantics is in many ways a solved problem with today&apos;s technology. Unfortunately, few interesting situations in which Natural Language is useful live up to this description. Even a modicum of machine intelligence is not possible, we believe, without continuing the pursuit for more sophisticated models which deal with such problems and which degrade gracefully (see Hayes and Reddy, 1979). Language as spoken (or typed) breaks the &amp;quot;rules&amp;quot;. Every study substantiates this fact. Halhotra (1975) discovered this in his studies of live subjects in designing a system to support decision-making activities. An extensive investigation by Thompson (1980) provides further evidence that providing a grammar of &amp;quot;standard English&amp;quot; does not go far enough in meeting the prospective needs of the user. Studies by Fromkin and her co-workers (1980), likewise, provide new insights into the range of errors that can occur in the use of language in various situations. Studies of this sort are essential </context>
</contexts>
<marker>Hayes, Reddy, 1979</marker>
<rawString>Hayes, P.J., and R. Reddy, &amp;quot;An Anatomy of Graceful Interaction in Spoken and Written Man-Machine Communication,&amp;quot; Technical Report, CarnegieMellon University, August, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
</authors>
<title>Treatment of Ungrammatical and Extra-grammatical Phenomena in Natural Language Understanding Systems,&amp;quot;</title>
<date>1980</date>
<tech>Ph.D. Thesis,</tech>
<institution>Ohio State University,</institution>
<location>Bloomington, Indiaria).</location>
<note>available through the</note>
<contexts>
<context position="5529" citStr="Kwasny (1980)" startWordPosition="841" endWordPosition="842">nt could simply be expanded to accomodate that new form. But that approach has limitations and misses the general phenomenon in most cases. Dejong (1979) demonstrated that wire service stories could be &amp;quot;skimmed&amp;quot; for prescribed concepts without much regard to grammaticality or acceptability issues. Instead, as long as coherency existed among the individual concepts, the overall content of the story could be summarized. The whole problem of addressing what to do with nonstandard inputs was finessed because of the context. Techniques based on meta-rules have been explored by various researchers. Kwasny (1980) investigated specialized techniques for dealing with cooccurrence violations, ellipsis, and conjunction within an ATN grammar. Sondheimer and Weischedel (1981) have generalized and refined this approach by making the meta-rules more explicit and by designing strategies which manipulate the rules of the grammar using meta-rules. Other systems have taken the approach that the user should play a major role in exercising choices about the interpretations proposed by the system. With such feedback to the user, no timeconsuming actions are performed without his approval. This approach works well in</context>
</contexts>
<marker>Kwasny, 1980</marker>
<rawString>Kwasny, S.C., &amp;quot;Treatment of Ungrammatical and Extra-grammatical Phenomena in Natural Language Understanding Systems,&amp;quot; Ph.D. Thesis, Ohio State University, 1980, (available through the Indiana University Linguistics Club, Bloomington, Indiaria).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
<author>N K Sondheimer</author>
</authors>
<title>Relaxation Techniques for Parsing III-Formed Input,&amp;quot;</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>7</volume>
<pages>99--108</pages>
<location>April-June,</location>
<marker>Kwasny, Sondheimer, 1981</marker>
<rawString>Kwasny, S.C., and N.K. Sondheimer, &amp;quot;Relaxation Techniques for Parsing III-Formed Input,&amp;quot; American Journal of Computational Linguistics, Vol. 7, No. 2, April-June, 1981, 99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Malhotra</author>
</authors>
<title>Design Criteria for a KnowledgeBased English Language System for Management: An Experimental Analysis,&amp;quot;</title>
<date>1975</date>
<tech>MAC TR 146,</tech>
<location>Cambridge, MA, M.I.T.,</location>
<marker>Malhotra, 1975</marker>
<rawString>Malhotra, A., &amp;quot;Design Criteria for a KnowledgeBased English Language System for Management: An Experimental Analysis,&amp;quot; MAC TR 146, Cambridge, MA, M.I.T., February, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Miller</author>
<author>G E Heidorn</author>
<author>K Jensen</author>
</authors>
<title>TextCritiquing with the EPISTLE System: An Author&apos;s Aid to Better Syntax,&amp;quot;</title>
<date>1981</date>
<booktitle>Proceedings of the National Computer Conference,</booktitle>
<publisher>AFIPS Press,</publisher>
<location>Montvale, NJ,</location>
<contexts>
<context position="6515" citStr="Miller et al., 1981" startWordPosition="994" endWordPosition="997">ch that the user should play a major role in exercising choices about the interpretations proposed by the system. With such feedback to the user, no timeconsuming actions are performed without his approval. This approach works well in database retrieval tasks. 4. Near and Long Term Prospects In the short term, we must look to what we understand and know about the language phenomena and apply those techniques that appear promising. . Non-standard language forms appear as errors in the expected processing paths. One of the functions of a style-checking program (for example the EPISTLE system by Miller et al., 1981) is to detect and, in some cases, correct certain types of errors made by the author of a document. Since such programs are expected to become more of a necessary part of any author support system, a great deal of research can be expected to be directed at that problem. A great deal of research which deals with errors in language inputs comes from attempts to process continuous speech (see, for example, Bates, 1976). The techniques associate with nonleft-to-right processing strategies should prove useful in narrowing the number of legal alternatives to be attempted when identifying and correct</context>
</contexts>
<marker>Miller, Heidorn, Jensen, 1981</marker>
<rawString>Miller, L.A., G.E. Heidorn, and K. Jensen, &amp;quot;TextCritiquing with the EPISTLE System: An Author&apos;s Aid to Better Syntax,&amp;quot; Proceedings of the National Computer Conference, AFIPS Press, Montvale, NJ, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N K -Sondheimer</author>
<author>R M Weischedel</author>
</authors>
<title>A Computational Linguistic Approach to Ungrammaticality Based on Meta-Rules&amp;quot;</title>
<date>1981</date>
<booktitle>Annual Melling of the Linguistic Society .pj America</booktitle>
<location>New York, NY,</location>
<marker>-Sondheimer, Weischedel, 1981</marker>
<rawString>-Sondheimer, N.K., and R.M. Weischedel, &amp;quot;A Computational Linguistic Approach to Ungrammaticality Based on Meta-Rules&amp;quot; Annual Melling of the Linguistic Society .pj America New York, NY, December, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N J Spencer</author>
</authors>
<title>Differences Between Linguists and Nonlinguists in Intuitions of GrammaticalityAcceptability&amp;quot;</title>
<date>1973</date>
<journal>Journal of Ysycholinguistic Research,</journal>
<volume>2</volume>
<pages>83--99</pages>
<contexts>
<context position="2269" citStr="Spencer, 1973" startWordPosition="343" endWordPosition="344">. But more than merely anticipating user inputs is required. Grammaticality is a continuum phenomenon with many dimensions. So is intelligibility. In hearing language used in a strange way, we often pass off the variation as dialectic, or we might unconsciously correct an errorful utterance. Occasionally, we might. not understand or even misunderstand. What are the rules (metarules, etc.) under which we operate in doing this? Can introspection be trusted to provide the proper perspectives? The results of at least one investigator argue against the use of intuitions in discovering these rules (Spencer, 1973). Computational linguists must continue to conduct studies and consider the results of studies conducted by others. 2. Perzoectives Several perspectives exist which may give insights on the problem. We present some of these, not to pretend to exhaustively summarize them, but •to hopefully stimulate interest among researchers to pursue one or more of these views of what is needed. Certain telegraphic forms of language occur in situations where two or more speakers of different languages must communicate. A pidgin form of language develops which borrows features from each of the languages. Chara</context>
</contexts>
<marker>Spencer, 1973</marker>
<rawString>Spencer, N.J., &amp;quot;Differences Between Linguists and Nonlinguists in Intuitions of GrammaticalityAcceptability&amp;quot; Journal of Ysycholinguistic Research, 2, 2, 1973, 83-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B H Thompson</author>
</authors>
<title>Linguistic Analysis of Natural Language Communication with Computers,&amp;quot;</title>
<date>1980</date>
<booktitle>Proceedj,pgs of the Eighth International Conference on Computational Linguistics,</booktitle>
<pages>190--201</pages>
<location>Tokyo,</location>
<contexts>
<context position="1261" citStr="Thompson (1980)" startWordPosition="183" endWordPosition="184"> problem with today&apos;s technology. Unfortunately, few interesting situations in which Natural Language is useful live up to this description. Even a modicum of machine intelligence is not possible, we believe, without continuing the pursuit for more sophisticated models which deal with such problems and which degrade gracefully (see Hayes and Reddy, 1979). Language as spoken (or typed) breaks the &amp;quot;rules&amp;quot;. Every study substantiates this fact. Halhotra (1975) discovered this in his studies of live subjects in designing a system to support decision-making activities. An extensive investigation by Thompson (1980) provides further evidence that providing a grammar of &amp;quot;standard English&amp;quot; does not go far enough in meeting the prospective needs of the user. Studies by Fromkin and her co-workers (1980), likewise, provide new insights into the range of errors that can occur in the use of language in various situations. Studies of this sort are essential in identifying the nature of such non-standard usages. But more than merely anticipating user inputs is required. Grammaticality is a continuum phenomenon with many dimensions. So is intelligibility. In hearing language used in a strange way, we often pass of</context>
</contexts>
<marker>Thompson, 1980</marker>
<rawString>Thompson, B.H., &amp;quot;Linguistic Analysis of Natural Language Communication with Computers,&amp;quot; Proceedj,pgs of the Eighth International Conference on Computational Linguistics, Tokyo, October, 1980, 190-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Weischedel</author>
<author>N K Sondheimer</author>
</authors>
<title>A Framework for Processing Ill-Formed Input,&amp;quot;</title>
<date>1981</date>
<tech>Technical Memorandum 11-00519,</tech>
<location>Sperry-Univac, Blue Bell, PA,</location>
<marker>Weischedel, Sondheimer, 1981</marker>
<rawString>Weischedel, R.M., and N.K. Sondheimer, &amp;quot;A Framework for Processing Ill-Formed Input,&amp;quot; Technical Memorandum 11-00519, Sperry-Univac, Blue Bell, PA, October 16, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>A Personal View of Natural Language Understanding,&amp;quot;</title>
<date>1977</date>
<journal>SIGART Newsletter,</journal>
<volume>61</volume>
<pages>17--18</pages>
<contexts>
<context position="3714" citStr="Woods (1977)" startWordPosition="570" endWordPosition="571">-machine dialogue. Once the user achieves some success in conversing with the machine, whether the conversation is being conducted in Natural Language or not, there is a tendency to continue to use those forms and words which were previously handled correctly. The result is a type of pidginization between the machine dialect and the user dialect which exhibits pidgin-like characteristics: limited vocabulary, limited use of some grammatical devices, etc. It is therefore reasonable to study these forms of language and to attempt to accomodate them in some natural way within our language models. Woods (1977) points out that the use of Natural Language: &amp;quot;... does not preclude the introduction of abbreviations and telegraphic shorthands for complex or high frequency concepts -- the ability of natural English to accommodate such abbreviations is one of its strengths.&amp;quot; (p.18) Specialized sublanguages can often be identified which enhance the quality of the communication and prove to be quite convenient especially to frequent users. 164 Conjunction is an extremely common and yet poorly understood phenomenon. The wide variety of ways in which sentence fragments may be joined argues against any approach</context>
</contexts>
<marker>Woods, 1977</marker>
<rawString>Woods, W.A., &amp;quot;A Personal View of Natural Language Understanding,&amp;quot; SIGART Newsletter, No. 61, February, 1977, 17-18.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>