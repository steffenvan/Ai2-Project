<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004867">
<title confidence="0.9977495">
Improving Arabic-Chinese Statistical Machine Translation
using English as Pivot Language
</title>
<author confidence="0.99827">
Nizar Habash Jun Hu
</author>
<affiliation confidence="0.9993155">
Center for Computational Learning Systems Computer Science Department
Columbia University Columbia University
</affiliation>
<address confidence="0.986882">
New York, NY 10115, USA New York, NY 10115, USA
</address>
<email confidence="0.999065">
habash@ccls.columbia.edu jh2740@columbia.edu
</email>
<sectionHeader confidence="0.99389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.982252545454545">
We present a comparison of two approaches for
Arabic-Chinese machine translation using Eng-
lish as a pivot language: sentence pivoting and
phrase-table pivoting. Our results show that
using English as a pivot in either approach out-
performs direct translation from Arabic to Chi-
nese. Our best result is the phrase-pivot system
which scores higher than direct translation by
1.1 BLEU points. An error analysis of our best
system shows that we successfully handle many
complex Arabic-Chinese syntactic variations.
</bodyText>
<sectionHeader confidence="0.998561" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999869533333333">
Arabic and Chinese are two languages with a
very large global presence; however, there has
not been, to our knowledge, any work on MT
for this pair. Given the cost involved in creat-
ing parallel corpora for Arabic and Chinese and
given that there are lots of available resources
(in particular parallel corpora) for Arabic and
English and for Chinese and English, we are
interested in exploring the role English might
serve as a pivot (or bridge) language. In this
paper we explore different ways of pivoting
through English to translate Arabic to Chinese.
Our work is similar to previous research on
pivot languages except in that our three lan-
guages (source, pivot and target) are very dif-
ferent and from completely unrelated families.
We focus our experiments on a trilingual paral-
lel corpus to keep all conditions experimentally
clean. Our results show that using English as a
pivot language for translating Arabic to Chinese
actually outperforms direct translation. We be-
lieve this may be a result of English being a sort
of middle ground between Arabic and Chinese
in terms of different linguistic features and, in
particular, word order.
Section 2 describes previous work. Section 3
discusses relevant linguistic issues of Arabic,
Chinese and English. Section 4 describes our
system and different pivoting techniques. And
Section 5 presents our experimental results.
</bodyText>
<sectionHeader confidence="0.997214" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99971659375">
There has been a lot of work on translation
from Chinese to English (Wang et al., 2007;
Crego and Mariño, 2007; Carpuat and Wu,
2007; among others) and from Arabic to Eng-
lish (Sadat and Habash, 2006, Al-Onaizan and
Papineni, 2006; among others). There is also a
fair amount of work on translation into Chinese
from Japanese, Korean and English (Isahara et
al., 2007; Kim et al., 2002; Ye et al., 2007;
among others). In 2008, the National Institute
of Standards and Technology (NIST) MT
Evaluation competition introduced English-
Chinese as a new evaluation track.1
Much work has been done on exploiting multi-
lingual corpora for MT or related tasks such as
lexical induction or word alignment. Schafer
and Yarowsky (2002) induced translation lexi-
cons for languages without common parallel
corpora using a bridge language that is related
to the target languages. Simard (1999) de-
scribed a sentence aligner that makes simulta-
neous decisions in a trilingual parallel text.
Kumar et al. (2007) improved Arabic-English
MT by using available parallel data in other
languages. Callison-Burch et al (2006) ex-
ploited the existence of multiple parallel cor-
pora to learn paraphrases for Phrase-based MT.
Filali and Bilmes (2005) improved word align-
ment by leveraging multilingual parallel trans-
lations.
Most related to our work on pivoting are the
following: Utiyama and Isahara (2007) studied
</bodyText>
<footnote confidence="0.815982">
1 http://www.nist.gov/speech/tests/mt/2008/doc/
</footnote>
<note confidence="0.9594815">
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998972">
173
</page>
<bodyText confidence="0.999797">
sentence and phrase pivoting strategies using
three European languages (Spanish, French and
German). Their results showed that pivoting
does not work as well as direct translation. Wu
and Wang (2007) focused on phrase pivoting.
They proposed an interpolated scheme that em-
ploys two phrase tables: one extracted from a
small amount of direct parallel data; and the
other extracted from large amounts of indirect
data with a third pivoting language. They com-
pared results for different European language as
well as Chinese-Japanese translation using Eng-
lish as a pivoting language. Their results show
that simple pivoting does not improve over di-
rect MT; however, extending the direct MT sys-
tem with phrases learned through pivoting
helps. Babych et al. (2007) compared two
methods for translating into English from
Ukrainian: direct Ukrainian-English MT versus
translation via a cognate language, Russian.
Their comparison showed that it is possible to
achieve better translation quality via pivoting.
In this paper we use a standard phrase-based
MT approach (Koehn, 2004) that is in the same
spirit of most statistical MT nowadays. We be-
lieve that we are the first to explore the Arabic-
Chinese language pair in MT. We differ from
previous pivoting research in showing that piv-
oting can outperform direct translation even
when the source, target and pivot languages are
all linguistically unrelated.
</bodyText>
<sectionHeader confidence="0.993917" genericHeader="method">
3 Linguistic Issues
</sectionHeader>
<bodyText confidence="0.999219">
In this section we discuss different linguistic
phenomena in which Arabic, English and Chi-
nese are divergent. We consider orthography,
morphology and syntax. We also present a new
metric for quantifying linguistic differences.
</bodyText>
<subsectionHeader confidence="0.995153">
3.1 Orthography
</subsectionHeader>
<bodyText confidence="0.999886894736842">
Arabic is written from right-to-left using an al-
phabet of 36 letters and eight optional diacriti-
cal marks. Arabic is written in a cursive mostly
word-internal connected form, but words are
separated by white spaces. The absence of Ara-
bic diacritics adds a lot of ambiguity.
Chinese uses a complex orthography that in-
cludes around 10,000 characters in common
use. Characters convey semantic rather than
phonological information. Chinese is written
from left-to-right or top-down. Chinese words
can be made out of one, two or more charac-
ters. However, words are written without sepa-
rating spaces. Word segmentation is a major
challenge for processing Chinese (Wu, 1998).
English uses the Roman alphabet and its words
are written with separating white spaces. Eng-
lish orthography is much closer to Arabic than
it is to Chinese.
</bodyText>
<subsectionHeader confidence="0.998245">
3.2 Morphology
</subsectionHeader>
<bodyText confidence="0.999937677419355">
Arabic is a morphologically rich language with
a large set of morphological features such per-
son, number, gender, voice, aspect, mood, case,
and state. Arabic features are realized using
both concatenative (affixes and stems) and
templatic (root and patterns) morphology with
a variety of morphological, phonological and
orthographic adjustments. In addition, Arabic
has a set of very common clitics that are writ-
ten attached to the word, e.g., the conjunction
+و w+ ‘and’, the preposition +ب b+2 ‘with/in’,
the definite article +لا Al+ ‘the’ and a range of
pronominal clitics that can attach to nouns (as
possessives) or verbs and prepositions (as ob-
jects).
In stark contrast to Arabic, Chinese is an isolat-
ing language with no morphology to talk of.
However, what Chinese lacks in morphology it
replaces with a complex system of nominal
quantifiers and verbal aspects. For example, in
Figure 1 (at the end of this paper), Chinese
marks the definiteness and humanness of the
word lk&apos;t Xue Sheng ‘student’ using the two
characters ik Zhe Wei ‘this person’, while
the indefiniteness and book-ness of the word 45
Shu ‘book’ are indicated through the characters
—* Yi Ben ‘one book-type’.
English has a simple limited morphology pri-
marily indicating number and tense. English
stands in the middle between Arabic and Chi-
nese in terms of morphological complexity.
</bodyText>
<subsectionHeader confidence="0.996196">
3.3 Syntax
</subsectionHeader>
<bodyText confidence="0.9988328">
Arabic is morpho-syntactically complex with
many differences from Chinese and English.
We describe here three prominent syntactic
issues in which Arabic, Chinese and English
vary widely: subject-verb order, verb-
</bodyText>
<footnote confidence="0.6051605">
2 Arabic transliteration is in the Habash-Soudi-Buckwalter
scheme (Habash et al. 2007).
</footnote>
<page confidence="0.998209">
174
</page>
<bodyText confidence="0.999270724137931">
prepositional phrase order and nominal modifi-
cation.
First, Arabic verb subjects may be: (a.) pro-
dropped (verb conjugated), (b.) pre-verbal, or
(c.) post-verbal. The morphology of the Arabic
verb varies in the three cases. By contrast Eng-
lish and Chinese are both generally subject-verb
languages. When translating from Arabic, the
challenge is to determine whether there is an
explicit subject and, if there is, whether it is pre-
or post-verbal. Since Arabic objects also follow
the verb, a sequence of Verb NounPhrase may
be a verb subject or a pro drop verb object. In
the example in Figure 1, the subject (student)
appears after the sentence initial verb in Arabic,
but at the beginning of the sentence in Chinese
and English.
Secondly, as for the word order of prepositional
phrases (PP), Arabic and English are similar in
that PPs generally appear at the end of the sen-
tence (after all the verbal arguments) and to a
lesser extent at its beginning. In Chinese, how-
ever, some PPs (in particular locatives and tem-
porals) must appear between subject and verb.
Other PPs may appear at end of sentence. In the
example in Figure 1, the location of the reading,
‘in the classroom’ appears at the end of the
Arabic and English sentences; however, it is
between subject and verb in Chinese.
Finally, we distinguish three types of nominal
modification: adjectival (as in ‘red book’), pos-
sessive (as in ‘John’s book’) and relative (as in
‘the book [which] John gave me’). All of these
modification types are handled in a similar
manner in Chinese: using the particle 0 De to
connect modifier with modified. Modifiers al-
ways precede the modified. For example, in
Figure 1, ‘a book about China’ appears as )c-T
I-PP9 04� Guan Yu Zhong Guo De Shu ‘about
China De book’. Similarly, ‘the student’s
book’ would be translated as lkt 0 4� Xue
Sheng De Shu ‘student DE book’. Like Chinese,
English adjectival modifiers precede what they
modify. However, relative modifiers follow.
Possessive modifiers in English can appear be-
fore or after: ‘the student’s book’ or ‘the book
of the student’. Unlike English and Chinese,
Arabic adjectival modifiers typically follow
their nouns (with a small exception of some su-
perlative adjectives). However, similar to Eng-
lish but not Chinese, Arabic relative modifiers
follow what they modify. As for possessive
modifiers, Arabic has a special construction
called Idafa, in which modifiers immediately
follow what they modify without connecting
particles. For example, ‘the student’s book’ can
only be translated in Arabic as - ا ب�1;آ ktAb
AlTAlb ‘book the student’.3
</bodyText>
<tableCaption confidence="0.7614924">
These different phenomena are summarized in
Table 1. It is interesting to point out that Eng-
lish phenomena are a middle ground for Arabic
and Chinese: in some cases English is closer to
Arabic and in others to Chinese.
</tableCaption>
<table confidence="0.999700666666667">
Arabic English Chinese
Orthography reduced alphabet Characters
alphabet
Morphology Rich Poor Very Poor
Subject-Verb V Subj Subj V Subj ... V
Subj V
Vsubj
Verb-PP V...PP V...PP PP V
V PP
Adjectival N Adj Adj N Adj DE N
Modifier
Possessive N Poss N of Poss Poss DE N
Modifier Poss ’s N
Relative N Rel N Rel Rel DE N
Modifier
</table>
<tableCaption confidence="0.9035315">
Table 1: Comparing different linguistic phenomena
in Arabic, English and Chinese
</tableCaption>
<subsectionHeader confidence="0.999205">
3.4 Quantifying Linguistic Differences
</subsectionHeader>
<bodyText confidence="0.966808823529412">
The previous section described specific types
of linguistic phenomena without distinguishing
them in terms of frequency or effect distance.
For example, Arabic nominals (nouns, adjec-
tives and adverbs) are seven times as frequent
as verbs; and nominal modification phenomena
are more likely local than long distance com-
pared to verb-subject order. A proper quantifi-
cation of these different phenomena requires
trilingual parallel treebanks, which are not
available. As such, we propose a simple metric
to quantify linguistic differences by measuring
the translation complexity of different language
pairs. The metric is Average Relative Align-
ment Length (ARAL):
3 Arabic dialects allow an additional construction. We
focus here on Modern Standard Arabic.
</bodyText>
<figure confidence="0.976741555555555">
1
ARAL =
 |L |
E pa
Sa
lab ∈ L
pb
−
Sb
</figure>
<page confidence="0.992473">
175
</page>
<bodyText confidence="0.999937266666667">
We define L as the set of all alignment links
linking words in a parallel corpus of languages
A and B. For each alignment link, lab, linking
words a and b, we define pa and pb as the posi-
tion of words a and b in their respective sen-
tences. We also define Sa and Sb as the lengths
of the sentences in which a and b appear, re-
spectively. ARAL is the mean of the absolute
difference in relative word position (pi/Si) of the
words of every alignment link. The larger
ARAL is, the more reordering and inser-
tions/deletions we expect, and the more com-
plexity and difference. ARAL is a harsh metric
since it ignores syntactic structure facts that ex-
plain how clusters of words move together.
</bodyText>
<table confidence="0.9590405">
A-C A-E E-C
0.1679 0.0846 0.1531
</table>
<tableCaption confidence="0.9740975">
Table 2: Average Relative Alignment Length for
pairs of Arabic (A), English (E) and Chinese (C)
</tableCaption>
<bodyText confidence="0.998680526315789">
Table 2 presents the ARAL scores for each lan-
guage pair. These scores are computed over the
grow diag final symmetrized alignment we use
in our system (Koehn, 2004). ARALAC is the
highest and ARALAE is the lowest. The average
length of sentences is generally close among
these languages (given the segmentation we
use): Arabic is —32 words, English is —31 and
Chinese is —29. Arabic and English are much
closer to each other than either to Chinese. This
may be the result of Arabic tokenization and
Chinese segmentation technologies which have
been developed for translation into English. We
address this issue in section 4.1. The ARAL
scores agree with our assessment that English is
closer to Arabic and to Chinese than Arabic is
to Chinese. As a result, we believe it may serve
as a good pivot language for translating Arabic
to Chinese.
</bodyText>
<sectionHeader confidence="0.995802" genericHeader="method">
4 System Description
</sectionHeader>
<bodyText confidence="0.998467">
In this section, we describe the different sys-
tems we compare.
</bodyText>
<subsectionHeader confidence="0.967066">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.9995572">
Our data collection is the United Nations (UN)
multilingual corpus, provided by the LDC 4
(catalog no. LDC2004E12). The UN corpus has
in principle parallel sentences for Arabic, Eng-
lish and Chinese. However, the Arabic-English
</bodyText>
<sectionHeader confidence="0.561444" genericHeader="method">
4 http://www.ldc.upenn.edu
</sectionHeader>
<bodyText confidence="0.999805222222222">
(A-E) data and Chinese-English (C-E) data sets
were not in synch. The A-E data set has 3.2M
lines while the C-E data set has 5.0M lines. We
used the document ID provided in the data to
match sentences from A-E against those in C-E
to generate a three-way parallel corpus with
2.6M lines.
We tokenized the Arabic data in the Arabic
Treebank scheme (Sadat and Habash, 2006).
Chinese was segmented into words using a
segmenter developed by Howard Johnson for
the Portage Chinese-English MT system.5 So a
sentence consists of multiple words with spaces
between them and each word is comprised of
one or more characters. English was simply
processed to split punctuation and “’s”. The
same preprocessing was used in all systems
compared.
We are aware of two potentially biased aspects
of our experimental setting. First, the Arabic
and Chinese portions of our data collection, the
UN corpus, are known to be generated from
English originals. And secondly, the preproc-
essing techniques we used on Arabic and Chi-
nese were developed for translation from these
languages into English. These two aspects
make English potentially more central to our
experiments than if the data collection and pre-
processing were done on Arabic and Chinese
independent of English. Of course, it must be
noted that the data bias is not unique to our
work but rather a challenge for any bilingual
corpus, in which translation is done from one
language to another. Additionally, we can ar-
gue that the English bias in data and preproc-
essing does not only affect the Arabic-English
and English-Chinese pipelines, but it also
makes the Arabic and Chinese data potentially
closer. Finally, given the expense involved in
creating direct Arabic-Chinese parallel text and
given the large amounts of Arabic-English and
English-Chinese data, we think our results
(with English bias) are still valid and interest-
ing. That said, we leave the question of Arabic-
Chinese optimization to future work.
</bodyText>
<subsectionHeader confidence="0.957076">
4.2 Direct A-C MT System
</subsectionHeader>
<bodyText confidence="0.99969425">
In our baseline direct A-C system, we used the
Arabic and Chinese portions of our parallel
corpus to train a direct phrase-based MT sys-
tem. We use GIZA++ (Och and Ney, 2003) for
</bodyText>
<footnote confidence="0.781906">
5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html
</footnote>
<page confidence="0.996222">
176
</page>
<bodyText confidence="0.999572571428571">
word alignment, and the Pharaoh system suite
to build the phrase table and decode (Koehn,
2004). The Chinese language model (LM) used
200M words from the UN corpus segmented in
a manner consistent with our training. The tri-
gram LM was built using the SRILM toolkit
(Stolcke, 2002).
</bodyText>
<subsectionHeader confidence="0.999487">
4.3 Sentence Pivoting MT System
</subsectionHeader>
<bodyText confidence="0.99990575">
The sentence pivoting system (A-s-C) used
English as an interface between two separate
pharse-based MT systems: an Arabic-English
direct system and an English-Chinese direct
system. When translating Arabic to Chinese, the
English top-1 output of the Arabic-English sys-
tem was passed as input to the English-Chinese
system. The English LM used to train the Ara-
bic-English system is built from the counterpart
of the Chinese data used to build the Chinese
LM in our parallel corpus. We use 210M Eng-
lish words in total.
</bodyText>
<subsectionHeader confidence="0.998314">
4.4 Phrase Pivoting MT System
</subsectionHeader>
<bodyText confidence="0.999769363636364">
The phrase pivoting system (A-p-C) extracts a
new Arabic to Chinese phrase table using the
Arabic-English phrase table and the English-
Chinese phrase table. We consider a Chinese
phrase a translation of an Arabic phrase only if
some English phrase can bridge the two. We use
the following formulae to compute the lexical
and phrase probabilities in the new phrase table
in a similar manner to Utiyama and Isahara
(2007). Here, O is the lexical probability and
pw is the phrase probability.
</bodyText>
<equation confidence="0.956917083333333">
O a c _ E O a e O e c
&apos;(  |) (  |) (  |)
e
O c a _ E O c e O e a
&apos;(  |) (  |) (  |)
e
p a c _ E p a e p e c
w &apos;(  |) w (  |) w (  |)
e
p c a _ E p c e p e a
w &apos;(  |) w (  |) w (  |)
e
</equation>
<bodyText confidence="0.999424">
The left hand side of the formulae represents the
four required probabilities in a Pharaoh Arabic-
Chinese phrase table.
</bodyText>
<sectionHeader confidence="0.998512" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99912425">
For each of the direct system, the sentence-
pivoting system and the phrase-pivoting system,
we conduct four sets of experiments with dif-
ferent data sizes. Table 3 illustrates the training
data size for each experiment. The training data
is collected from the beginning of the same
parallel corpus, so the larger training sets in-
clude the smaller ones.
</bodyText>
<table confidence="0.9972092">
Lines Words (Arabic)
S 32500 1 Million
M 65000 2 Million
L 130000 4 Million
XL 260000 8 Million
</table>
<tableCaption confidence="0.999452">
Table 3: Training Data Size
</tableCaption>
<bodyText confidence="0.999968947368421">
We use two other data sets (1K lines each) for
tuning and testing. Each sentence in these sets
has only one reference. Tuning and testing data
sets are the same across all experiments and
systems. In all our experiments, we decode
using Pharaoh (Koehn, 2004) with a distortion
limit of 4 and a maximum phrase length of 7.
Tuning is done for each experimental condition
using Och’s Minimum Error Training (Och,
2003).
Note that for each set of experiments with the
same data size, we draw Chinese, Arabic and
English from the same chunk of three way par-
allel corpus. For example, in S size experi-
ments, the two phrase tables used to build a
new table in the phrase-pivoting approach are
extracted respectively from the A-E and E-C
systems built in the sentence-pivoting approach
with size S corpora.
</bodyText>
<subsectionHeader confidence="0.995975">
5.1 Direct System Results
</subsectionHeader>
<bodyText confidence="0.999924470588235">
Table 4 shows the results of the direct transla-
tion system A-C. It also includes the result for
A-E and E-C direct translation. As expected, as
we double the size of the data, the BLEU score
(Papineni et al., 2002) increases. However, the
rate of increase is not always consistent. In par-
ticular, the M and L conditions vary highly in
A-E compared to A-C. This is odd especially
given that we are comparing the same set of
data from the three parallel corpora. We specu-
late that this may have to do with an oddity in
that portion of the data set that may have a dif-
ferent quality than the rest. We see the effect of
this drop in A-E in the next section. BLEU is
measured on English case-insensitively. BLEU
is measured on Chinese using segmented words
not characters.
</bodyText>
<page confidence="0.99621">
177
</page>
<table confidence="0.999099125">
A-C A-E E-C
S 11.17 21.89 19.29
M 13.43 23.86 20.85
(+20.2%) (+9.0%) (+8.1%)
L 14.62 24.86 22.42
(+8.9%) (+4.2%) (+7.5%)
XL 16.17 27.96 24.11
(+10.6%) (+12.5%) (+7.5%)
</table>
<tableCaption confidence="0.9863274">
Table 4: BLEU-4 scores comparing performance of
direct translation of Arabic-Chinese (A-C), Arabic-
English (A-E) and English-Chinese (E-C) for four
training data sizes. The percentage increases are
against the immediately lower data size.
</tableCaption>
<subsectionHeader confidence="0.999602">
5.2 Pivoting System Results
</subsectionHeader>
<bodyText confidence="0.99995435">
In Table 5, we present the results of the sen-
tence pivoting system (A-s-C) and the phrase
pivoting system (A-p-C). Under all conditions,
A-s-C and A-p-C outperform A-C. A-p-C gen-
erally outperforms A-s-C except in the M data
condition. The effect in the S conditions is big-
ger than the XL condition. In our best result
(XL), we increase the BLEU score by over 1.12
points. Furthermore, the relative BLEU score
increase from the L condition for A-p-C is
15.5% as opposed to A-C’s 10.6%. The A-s-C
relative increase from L to XL is 12.8%. This
suggests that we are making better use of the
available resources. The differences between A-
s-C and A-C and between A-p-C and A-C are
statistically significant at the 95% confidence
level (Zhang et al., 2004). The differences be-
tween the two pivoting systems are not statisti-
cally significant. Examples from our best
performing system are shown in Figure 2.
</bodyText>
<table confidence="0.9991846">
A-C A-s-C A-p-C
S 11.17 12.24 9.6% 13.12 17.5%
M 13.43 14.10 5.0% 13.75 2.4%
L 14.62 14.96 2.3% 14.97 2.4%
XL 16.17 16.88 4.4% 17.29 6.9%
</table>
<tableCaption confidence="0.9033456">
Table 5: Word-based BLEU-4 scores. A-C is direct
translation. A-s-C is indirect translation through sen-
tence pivoting and A-p-C is indirect translation
through phrase pivoting. The percentages indicate
relative improvement over A-C.
</tableCaption>
<bodyText confidence="0.994191636363636">
Our results are consistent with (Utiyama and
Isahara, 2007) in that phrase-pivoting generally
does better than sentence pivoting. However,
we disagree with them in that, for us, direct
translation is not the best system to use. We be-
lieve that this effect is caused by the combina-
tion of the very different languages we use.
English is truly bridging between Arabic and
Chinese in many linguistic dimensions. We
think it’s English’s middle-ground-ness that
makes these results possible.
</bodyText>
<table confidence="0.999869384615385">
A-C A-s-C A-p-C
BLEU-1 S 53.75 54.38 1.2% 54.64 1.7%
M 56.65 57.00 0.6% 55.88 -1.4%
L 58.37 57.69 -1.2% 58.79 0.7%
XL 59.90 60.34 0.7% 60.28 0.6%
BLEU-4 S 21.32 21.80 2.3% 22.88 7.3%
M 23.84 24.22 1.6% 23.76 -0.3%
L 24.98 25.14 0.6% 25.87 3.6%
XL 25.95 27.11 4.5% 27.70 6.7%
BLEU-7 S 9.82 10.02 2.0% 11.42 16.3%
M 11.56 11.84 2.4% 11.64 0.7%
L 12.23 12.52 2.4% 13.09 7.0%
XL 12.69 13.52 6.5% 14.57 14.8%
</table>
<tableCaption confidence="0.98335">
Table 6: Character-based BLEU scores for n-grams
of maximum size 1, 4, and 7. The percentages are
relative to the direct system.
</tableCaption>
<bodyText confidence="0.99996128">
In Table 6, we present additional scores using
BLEU-1, BLEU-4 and BLEU-7 measured at
the character level as opposed to the harsher
measure at word level. Ignoring the odd behav-
ior in M and L conditions, the sentence-pivot
and phrase-pivot approaches improve over the
direct translation baseline in terms of fluency
(BLEU-7) and accuracy (BLEU-1). Under the
small data condition, the phrase-pivot approach
increases the BLEU-4 score three times the
increase of the sentence-pivot approach. That
ratio reduces to 1.5 times in the XL condition.
The relative improvements of the pivoting sys-
tems over the direct system are small at BLEU-
1 and much bigger at higher BLEU scores.
This suggests that differences between the piv-
oting systems and the direct system are not in
terms of lexical coverage but rather in terms of
better reordering.
The lengths of the outputs of all the systems
(direct and pivoting) are larger than the refer-
ence length which means no brevity penalty
was applied in BLEU calculation. Also, no
BLEU-gaming was done by OOV deletion: all
OOV words were left in the output.
</bodyText>
<subsectionHeader confidence="0.989175">
5.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999743333333333">
We conducted an error analysis of our best per-
forming system (Phrase Pivot XL) to under-
stand what issues need to be addressed in the
</bodyText>
<page confidence="0.996218">
178
</page>
<bodyText confidence="0.999800204081633">
future. We took a sample of 50 sentences re-
stricted in length to be between 15 and 35 Chi-
nese words. A Chinese native speaker compared
our output to the reference translation and
judged its quality in terms of two categories:
syntax and lexical choice.
In terms of syntax, our judge identified all the
occurrences of (a) subjects and verbs, (b) prepo-
sitional phrases and verbs and (c) modified
nouns. Each case was judged as acceptable or
wrong. Placing a verb before its subject, a pre-
verbal prepositional phrase after its verb, or a
modifier after the noun it modifies are all con-
sidered wrong. We correctly produce subject-
verb order 73% of the time; and we produce
nominal modification order correctly 64% of
the time. Our biggest weakness in terms of syn-
tax is prepositional phrase order. It is worth
noting that the two phenomena we do better on
are addressed in translation from Arabic to Eng-
lish, unlike prepositional phrase order which is
where Chinese is different from both Arabic and
English.
In terms of lexical choice our judge considered
the translation quality of three classes of words:
Nominals (nouns, pronouns, adjectives and ad-
verbs), Verbs, and other particles (prepositions,
conjunctions and quantifiers). An incorrectly
translated or deleted word is considered wrong.
We perform on nominals and particles at about
the same level of 90%. Verbs are our biggest
challenge with accuracy below 80%. The ratio
of deleted words among all wrong words is
rather high at about 30% (for nominals and for
verbs). The detailed results of the error analysis
are shown in Table 7.
Finally, there are 27 instances of Arabic Out-of-
Vocabulary (OOV) words (1.93% of all words)
that are not handled. Ten (37%) of these are
proper nouns. The rest belong to mostly nouns
and adjectives. Orthogonally, 19 (70%) of all
OOV words belong to the genre of science re-
ports, which is quite different from the data we
train on. The OOVs include complex terms like
c����آs�و�����ا AlsybrwflwksAsyn ‘ciproflox-
acin’ and Lرا-,o ت����ر rjAjAt mdAryħ ‘[chemi-
cal] orbital shakers’. Other less frequent OOV
cases involve bad tokenization and less com-
mon morphological constructions.
</bodyText>
<table confidence="0.999683375">
Total Acceptable Wrong
Syntax Subj-Verb 48 35(73%) 13 (27%)
Verb-PP 46 17 (37%) 29 (63%)
Noun-Mod 97 62 (64%) 35 (36%)
Lexical Nominal 408 368 (90%) 40 (10%)
Choice
Verb 124 98 (79%) 26 (21%)
Particle 116 106 (91%) 10 (9%)
</table>
<tableCaption confidence="0.980048">
Table 7: Results of human error analysis on a
sample from the A-p-C system (XL)
</tableCaption>
<sectionHeader confidence="0.990859" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999923107142857">
We presented a comparison of two approaches
for Arabic-Chinese MT using English as a piv-
ot language against direct MT. Our results
show that using English as a pivot in either ap-
proach outperforms direct translation from
Arabic to Chinese. We believe that this is a
result of English being a sort of middle ground
between Arabic and Chinese in terms of differ-
ent linguistic features (in particular word or-
der). Our best result is the phrase-pivot system
which scores higher than direct translation by
1.1 BLEU points. An error analysis of our sys-
tem shows that we successfully handle many
complex Arabic-Chinese syntactic variations
although there is a large space for improvement
still.
In the future, we plan on exploring tighter cou-
pling of Arabic and Chinese through compar-
ing different methods of preprocessing Arabic
for Arabic-Chinese MT, in a similar manner to
Sadat and Habash (2006). We also plan to
study how well these results carry on to differ-
ent corpora (bilingual Arabic-English and Eng-
lish-Chinese) as opposed to the trilingual
corpus used in this paper. We also plan to in-
vestigate whether our findings in Arabic-
English-Chinese can be used for other different
language triples.
</bodyText>
<sectionHeader confidence="0.994948" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998177">
We would like to thank Roland Kuhn, George
Foster and Howard Johnson of the National
Research Council Canada for helpful advice
and discussions and for providing us with the
Chinese preprocessing tools.
</bodyText>
<page confidence="0.997588">
179
</page>
<figureCaption confidence="0.988034">
Figure 1: An example highlighting Arabic$English$Chinese syntactic differences
</figureCaption>
<figure confidence="0.5343625">
. 8 Oا 7e 6_`Oا 5_ 4PpPRآ 3 kROا 2NOPQOا 1أfi
yqrÂ1 AlTAlb2 Almjthd3 ktAbA4 ςn5 AlSyn6 fy7 AlSf8 .
read1 the$student2 the$diligent3 a$book4 about5 china6 in7 the$classroom8 . 这 1位 2勤奋 3 的 4 学生 5 在 6教室 7 读 8 一 9 本 10 关于 11 中国 12 的 13书 14。
this1 quant2 diligent3 de4 student5 in6 classroom7 read8 one9 quant10 about11 china12 de13 book14
Zhe1 Wei2 Qin Fen3 De4 Xue Sheng5 Zai6 Jiao Shi7 Du8 Yi9 Ben10 Guan Yu11 Zhong Guo12 De13 Shu14
The diligent student is reading a book about China in the classroom.
</figure>
<figureCaption confidence="0.877817">
Figure 2: Examples of Arabic$Chinese MT output. English references and English
glosses for Arabic and Chinese are provided to ease readability.
</figureCaption>
<table confidence="0.993232">
Arabic . k`op kq rOا ةءPuvOا ماkoxاو دPbudO hzfol h{`gOا |}ه نPe ، Oذ rd ءPpو
and$building upon this, therefore this environment susceptible to$corruption and$lack qualifica$
tion to extent big .
Eng$Ref Consequently, this environment lends itself to significant degrees of corruption and inefficiency.
Chn$Ref 因此,这种环境导致了高度腐败和效率低下。
Therefore, this kind environment caused have high$degree corruption and efficiency low.
Chn$Out 因此,这种环境中的腐败和缺乏效率在很大程度上 。
Therefore , this kind environment inside DE corruption and lack efficiency on big degree top.
Arabic . NdQOا bi ، ىfا Plci 90 نc e hpcdQOا تPlcdoOا دf O اذاو
and$if did$not arrive information requested in period 90 day other, lapse application.
Eng$Ref If the requested information is not received within a further 90 days , the application will lapse.
Chn$Ref 如果再过 90 天仍未收到所 要求的资料,则申请失效。
If again pass 90 day yet not received requested DE information , then application loose validity.
Chn$Out 如果没有收到所 要求的资料 90 天内提供更多的要求。
If not receive requested DE information 90 day within provide more DE request.
Arabic . h`lcvOا ةnا _`p دراcOا e كرPROاو تPlcdoOا لدPg f`b` ...
... facilitation exchanging the$information and$the$sharing in the$resources between the$agencies
the$governmental .
Eng$Ref ... to facilitate the sharing of information and resources between government agencies .
Chn$Ref ...为各政府机构之间交流信息和资源提供便利 。
...for all government agencies among exchanging information and resource offer convenience.
Chn$Out ...旨在促进信息交流和分享资源政府间机构。
...purpose in facilitate information exchanging and sharing resource governments among agency.
Arabic . دPbuOا تPRqا _l rxدا kOا rOا `dRdO hOPoeو hgaPl f`pاk ثاkRaا e f نا تPlcvdO giو
and$should to$government that look in introducing measures appropriate and$effective to$reduce
to extent least from possibilities the$corruption
Eng$Ref Governments should consider introducing appropriate and effective measures to minimize the
potential for corruption.
Chn$Ref 各国政府应考虑采取适当的有效措施,最大 限度地 减少产生腐败的可能性 。
all countries governments should consider adopt appropriate DE effective methods , to$biggest$
extent DE reduce producing corruption DE possibility.
Chn$Out 各 国政府应考虑建立适当的有效措施,最大限度地减少腐败的可能性 。
all countries governments should consider build appropriate DE effective methods , to$biggest$
extent DE reduce corruption DE possibility.
</table>
<page confidence="0.990276">
180
</page>
<sectionHeader confidence="0.988748" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999419128440367">
Yaser Al-Onaizan and Kishore Papineni. 2006 Dis-
tortion models for statistical machine transla-
tion. In Proceedings of Coling-ACL’06.
Sydney, Australia.
Bogdan Babych, Anthony Hartley, and Serge
Sharoff. 2007. Translating from under-
resourced languages: comparing direct transfer
against pivot translation. In Proceedings of MT
Summit XI, Copenhagen, Denmark.
Tim Buckwalter. 2002. Buckwalter Arabic morpho-
logical analyzer version 1.0.
Chris Callison-Burch, Philipp Koehn, and Miles
Osborne. 2006. Improved statistical machine
translation using paraphrases. In Proceedings
ofHLT NAACL’06. New York, NY, USA.
Marine Carpuat and Dekai Wu. 2007. Context-
dependent phrasal translation lexicons for sta-
tistical machine translation. In Proceedings of
MT Summit XI, Copenhagen, Denmark.
Josep M. Crego and José B. Mariño. 2007. Syntax-
enhanced n-gram-based SMT. In Proceedings
of MT Summit XI, Copenhagen, Denmark.
Karim Filali and Jeff Bilmes. Leveraging Multiple
Languages to Improve Statistical MT Word
Alignments. In Proceedings of ASRU’05, Can-
cun, Mexico.
Nizar Habash. 2007. Syntactic preprocessing for
statistical machine translation. In Proceedings
of MT Summit XI, Copenhagen, Denmark.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwal-
ter. 2007. On Arabic Transliteration. In A. van
den Bosch and A. Soudi, editors, Arabic Com-
putational Morphology: Knowledge-based and
Empirical Methods. Springer.
Hitoshi Isahara, Sadao Kurohashi, Jun’ichi Tsujii,
Kiyotaka Uchimoto, Hiroshi Nakagawa, Hiro-
yuki Kaji, and Shun’ichi Kikuchi. 2007. De-
velopment of a Japanese-Chinese machine
translation system. In Proceedings of MT
Summit XI, Copenhagen, Denmark.
Philipp Koehn. 2004. Pharaoh: a Beam Search De-
coder for Phrase-based Statistical Machine
Translation Models. In Proceedings of
AMTA’04, Washington, DC, USA.
Shankar Kumar, Franz Och, and Wolfgang Ma-
cherey. 2007. Improving word alignment with
bridge languages. In Proceedings of EMNLP-
CoNLL’07, Prague, Czech Republic.
Young-Suk Lee. 2004. Morphological Analysis for
Statistical Machine Translation. In Proceedings
of HLT-NAACL’04, Boston, MA, USA.
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical
Alignment Models. Computational Linguistics,
29 (1):19–52.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing for Statistical Machine Translation. In Pro
ceedings of ACL’03, Sapporo, Japan.
Fatiha Sadat and Nizar Habash. 2006. Combination
of Arabic preprocessing schemes for statistical
machine translation. In Proceedings of Coling-
ACL’06. Sydney, Australia.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a Method for
Automatic Evaluation of Machine Translation.
In Proceedings of ACL’02, Philadelphia, PA,
USA.
Charles Schafer &amp; David Yarowsky. 2002. Induc-
ing translation lexicons via diverse similarity
measures and bridge languages. In Proceedings
of CoNLL’02, Taipei, Taiwan.
Micheal. Simard. 1999. Text translation alignment:
Three languages are better than two. In Pro
ceedings of EMNLP VLC’99, College Park,
MD, USA.
Michel Simard, Nicola Ueffing, Pierre Isabelle, and
Roland Kuhn. 2007. Rule-based translation
with statistical phrase-based post-editing. In
Proceedings of the workshop on Statistical
Machine Translation, ACL’07, Prague, Czech
Republic.
Andreas Stolcke. 2002. SRILM - an Extensible
Language Modeling Toolkit. In Proceedings of
ICSLP’02, Denver, CO, USA.
Masao Utiyama and Hitoshi Isahara. 2007. A com-
parison of pivot methods for phrase-based sta-
tistical machine translation. In Proceedings of
NAACL-HLT’07, Rochester, NY, USA.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statisti-
cal machine translation. In Proceedings of
EMNLP-CoNLL’07, Prague, Czech Republic.
Dekai Wu. 1998. A Position Statement on Chinese
Segmentation. Presented at the Chinese Lan
guage Processing Workshop. http://www.
cs.ust.hk/~dekai/papers/segmentation.html.
Hua Wu and Haifeng Wang. 2007. Pivot language
aproach for phrase-based statistical machine
translation. In Proceedings of ACL’07, Prague,
Czech Republic.
Yang Ye, Karl-Michael Schneider, and Steven
Abney. 2007. Aspect marker generation in
English-to-Chinese machine translation. In
Proceedings of MT Summit XI, Copenhagen,
Denmark.
Ying Zhang, Stephan Vogel and Alex Waibel, In-
terpreting Bleu/NIST scores: How much im-
provement do we need to have a better system?,
In Proceedings of LREC’04, Lisbon, Portugal.
</reference>
<page confidence="0.998375">
181
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.979273">
<title confidence="0.996776">Improving Arabic-Chinese Statistical Machine using English as Pivot Language</title>
<author confidence="0.999663">Nizar Habash Jun Hu</author>
<affiliation confidence="0.9999565">Center for Computational Learning Systems Computer Science Department Columbia University Columbia University</affiliation>
<address confidence="0.999784">New York, NY 10115, USA New York, NY 10115, USA</address>
<email confidence="0.998993">habash@ccls.columbia.edujh2740@columbia.edu</email>
<abstract confidence="0.998931">We present a comparison of two approaches for Arabic-Chinese machine translation using English as a pivot language: sentence pivoting and phrase-table pivoting. Our results show that using English as a pivot in either approach outperforms direct translation from Arabic to Chinese. Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our best system shows that we successfully handle many complex Arabic-Chinese syntactic variations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kishore Papineni</author>
</authors>
<title>Distortion models for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of Coling-ACL’06.</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2464" citStr="Al-Onaizan and Papineni, 2006" startWordPosition="381" endWordPosition="384"> be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is re</context>
</contexts>
<marker>Al-Onaizan, Papineni, 2006</marker>
<rawString>Yaser Al-Onaizan and Kishore Papineni. 2006 Distortion models for statistical machine translation. In Proceedings of Coling-ACL’06. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bogdan Babych</author>
<author>Anthony Hartley</author>
<author>Serge Sharoff</author>
</authors>
<title>Translating from underresourced languages: comparing direct transfer against pivot translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="4604" citStr="Babych et al. (2007)" startWordPosition="710" endWordPosition="713">es not work as well as direct translation. Wu and Wang (2007) focused on phrase pivoting. They proposed an interpolated scheme that employs two phrase tables: one extracted from a small amount of direct parallel data; and the other extracted from large amounts of indirect data with a third pivoting language. They compared results for different European language as well as Chinese-Japanese translation using English as a pivoting language. Their results show that simple pivoting does not improve over direct MT; however, extending the direct MT system with phrases learned through pivoting helps. Babych et al. (2007) compared two methods for translating into English from Ukrainian: direct Ukrainian-English MT versus translation via a cognate language, Russian. Their comparison showed that it is possible to achieve better translation quality via pivoting. In this paper we use a standard phrase-based MT approach (Koehn, 2004) that is in the same spirit of most statistical MT nowadays. We believe that we are the first to explore the ArabicChinese language pair in MT. We differ from previous pivoting research in showing that pivoting can outperform direct translation even when the source, target and pivot lan</context>
</contexts>
<marker>Babych, Hartley, Sharoff, 2007</marker>
<rawString>Bogdan Babych, Anthony Hartley, and Serge Sharoff. 2007. Translating from underresourced languages: comparing direct transfer against pivot translation. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic morphological analyzer version 1.0.</title>
<date>2002</date>
<marker>Buckwalter, 2002</marker>
<rawString>Tim Buckwalter. 2002. Buckwalter Arabic morphological analyzer version 1.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings ofHLT NAACL’06.</booktitle>
<location>New York, NY, USA.</location>
<contexts>
<context position="3330" citStr="Callison-Burch et al (2006)" startWordPosition="518" endWordPosition="521">chnology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 173 sentence and phrase pivoting strategies using three European languages (Spanish, Fre</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings ofHLT NAACL’06. New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Contextdependent phrasal translation lexicons for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="2367" citStr="Carpuat and Wu, 2007" startWordPosition="365" endWordPosition="368">anslating Arabic to Chinese actually outperforms direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced tran</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Contextdependent phrasal translation lexicons for statistical machine translation. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josep M Crego</author>
<author>José B Mariño</author>
</authors>
<title>Syntaxenhanced n-gram-based SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="2345" citStr="Crego and Mariño, 2007" startWordPosition="361" endWordPosition="364"> a pivot language for translating Arabic to Chinese actually outperforms direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarows</context>
</contexts>
<marker>Crego, Mariño, 2007</marker>
<rawString>Josep M. Crego and José B. Mariño. 2007. Syntaxenhanced n-gram-based SMT. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Karim Filali</author>
<author>Jeff Bilmes</author>
</authors>
<title>Leveraging Multiple Languages to Improve Statistical MT Word Alignments.</title>
<booktitle>In Proceedings of ASRU’05,</booktitle>
<location>Cancun, Mexico.</location>
<marker>Filali, Bilmes, </marker>
<rawString>Karim Filali and Jeff Bilmes. Leveraging Multiple Languages to Improve Statistical MT Word Alignments. In Proceedings of ASRU’05, Cancun, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Syntactic preprocessing for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<marker>Habash, 2007</marker>
<rawString>Nizar Habash. 2007. Syntactic preprocessing for statistical machine translation. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="8015" citStr="Habash et al. 2007" startWordPosition="1246" endWordPosition="1249">person’, while the indefiniteness and book-ness of the word 45 Shu ‘book’ are indicated through the characters —* Yi Ben ‘one book-type’. English has a simple limited morphology primarily indicating number and tense. English stands in the middle between Arabic and Chinese in terms of morphological complexity. 3.3 Syntax Arabic is morpho-syntactically complex with many differences from Chinese and English. We describe here three prominent syntactic issues in which Arabic, Chinese and English vary widely: subject-verb order, verb2 Arabic transliteration is in the Habash-Soudi-Buckwalter scheme (Habash et al. 2007). 174 prepositional phrase order and nominal modification. First, Arabic verb subjects may be: (a.) prodropped (verb conjugated), (b.) pre-verbal, or (c.) post-verbal. The morphology of the Arabic verb varies in the three cases. By contrast English and Chinese are both generally subject-verb languages. When translating from Arabic, the challenge is to determine whether there is an explicit subject and, if there is, whether it is preor post-verbal. Since Arabic objects also follow the verb, a sequence of Verb NounPhrase may be a verb subject or a pro drop verb object. In the example in Figure 1</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi Isahara</author>
<author>Sadao Kurohashi</author>
<author>Jun’ichi Tsujii</author>
<author>Kiyotaka Uchimoto</author>
<author>Hiroshi Nakagawa</author>
<author>Hiroyuki Kaji</author>
<author>Shun’ichi Kikuchi</author>
</authors>
<title>Development of a Japanese-Chinese machine translation system.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="2600" citStr="Isahara et al., 2007" startWordPosition="404" endWordPosition="407">rd order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel tex</context>
</contexts>
<marker>Isahara, Kurohashi, Tsujii, Uchimoto, Nakagawa, Kaji, Kikuchi, 2007</marker>
<rawString>Hitoshi Isahara, Sadao Kurohashi, Jun’ichi Tsujii, Kiyotaka Uchimoto, Hiroshi Nakagawa, Hiroyuki Kaji, and Shun’ichi Kikuchi. 2007. Development of a Japanese-Chinese machine translation system. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a Beam Search Decoder for Phrase-based Statistical Machine Translation Models.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA’04,</booktitle>
<location>Washington, DC, USA.</location>
<contexts>
<context position="4917" citStr="Koehn, 2004" startWordPosition="757" endWordPosition="758">ed results for different European language as well as Chinese-Japanese translation using English as a pivoting language. Their results show that simple pivoting does not improve over direct MT; however, extending the direct MT system with phrases learned through pivoting helps. Babych et al. (2007) compared two methods for translating into English from Ukrainian: direct Ukrainian-English MT versus translation via a cognate language, Russian. Their comparison showed that it is possible to achieve better translation quality via pivoting. In this paper we use a standard phrase-based MT approach (Koehn, 2004) that is in the same spirit of most statistical MT nowadays. We believe that we are the first to explore the ArabicChinese language pair in MT. We differ from previous pivoting research in showing that pivoting can outperform direct translation even when the source, target and pivot languages are all linguistically unrelated. 3 Linguistic Issues In this section we discuss different linguistic phenomena in which Arabic, English and Chinese are divergent. We consider orthography, morphology and syntax. We also present a new metric for quantifying linguistic differences. 3.1 Orthography Arabic is</context>
<context position="13046" citStr="Koehn, 2004" startWordPosition="2099" endWordPosition="2100">ute difference in relative word position (pi/Si) of the words of every alignment link. The larger ARAL is, the more reordering and insertions/deletions we expect, and the more complexity and difference. ARAL is a harsh metric since it ignores syntactic structure facts that explain how clusters of words move together. A-C A-E E-C 0.1679 0.0846 0.1531 Table 2: Average Relative Alignment Length for pairs of Arabic (A), English (E) and Chinese (C) Table 2 presents the ARAL scores for each language pair. These scores are computed over the grow diag final symmetrized alignment we use in our system (Koehn, 2004). ARALAC is the highest and ARALAE is the lowest. The average length of sentences is generally close among these languages (given the segmentation we use): Arabic is —32 words, English is —31 and Chinese is —29. Arabic and English are much closer to each other than either to Chinese. This may be the result of Arabic tokenization and Chinese segmentation technologies which have been developed for translation into English. We address this issue in section 4.1. The ARAL scores agree with our assessment that English is closer to Arabic and to Chinese than Arabic is to Chinese. As a result, we beli</context>
<context position="16391" citStr="Koehn, 2004" startWordPosition="2646" endWordPosition="2647">hinese parallel text and given the large amounts of Arabic-English and English-Chinese data, we think our results (with English bias) are still valid and interesting. That said, we leave the question of ArabicChinese optimization to future work. 4.2 Direct A-C MT System In our baseline direct A-C system, we used the Arabic and Chinese portions of our parallel corpus to train a direct phrase-based MT system. We use GIZA++ (Och and Ney, 2003) for 5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 176 word alignment, and the Pharaoh system suite to build the phrase table and decode (Koehn, 2004). The Chinese language model (LM) used 200M words from the UN corpus segmented in a manner consistent with our training. The trigram LM was built using the SRILM toolkit (Stolcke, 2002). 4.3 Sentence Pivoting MT System The sentence pivoting system (A-s-C) used English as an interface between two separate pharse-based MT systems: an Arabic-English direct system and an English-Chinese direct system. When translating Arabic to Chinese, the English top-1 output of the Arabic-English system was passed as input to the English-Chinese system. The English LM used to train the Arabic-English system is </context>
<context position="18683" citStr="Koehn, 2004" startWordPosition="3080" endWordPosition="3081">ments with different data sizes. Table 3 illustrates the training data size for each experiment. The training data is collected from the beginning of the same parallel corpus, so the larger training sets include the smaller ones. Lines Words (Arabic) S 32500 1 Million M 65000 2 Million L 130000 4 Million XL 260000 8 Million Table 3: Training Data Size We use two other data sets (1K lines each) for tuning and testing. Each sentence in these sets has only one reference. Tuning and testing data sets are the same across all experiments and systems. In all our experiments, we decode using Pharaoh (Koehn, 2004) with a distortion limit of 4 and a maximum phrase length of 7. Tuning is done for each experimental condition using Och’s Minimum Error Training (Och, 2003). Note that for each set of experiments with the same data size, we draw Chinese, Arabic and English from the same chunk of three way parallel corpus. For example, in S size experiments, the two phrase tables used to build a new table in the phrase-pivoting approach are extracted respectively from the A-E and E-C systems built in the sentence-pivoting approach with size S corpora. 5.1 Direct System Results Table 4 shows the results of the </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a Beam Search Decoder for Phrase-based Statistical Machine Translation Models. In Proceedings of AMTA’04, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>Franz Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Improving word alignment with bridge languages.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLPCoNLL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3222" citStr="Kumar et al. (2007)" startWordPosition="503" endWordPosition="506">im et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Comput</context>
</contexts>
<marker>Kumar, Och, Macherey, 2007</marker>
<rawString>Shankar Kumar, Franz Och, and Wolfgang Macherey. 2007. Improving word alignment with bridge languages. In Proceedings of EMNLPCoNLL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Morphological Analysis for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL’04,</booktitle>
<location>Boston, MA, USA.</location>
<marker>Lee, 2004</marker>
<rawString>Young-Suk Lee. 2004. Morphological Analysis for Statistical Machine Translation. In Proceedings of HLT-NAACL’04, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<pages>1--19</pages>
<contexts>
<context position="16223" citStr="Och and Ney, 2003" startWordPosition="2624" endWordPosition="2627">rabic-English and English-Chinese pipelines, but it also makes the Arabic and Chinese data potentially closer. Finally, given the expense involved in creating direct Arabic-Chinese parallel text and given the large amounts of Arabic-English and English-Chinese data, we think our results (with English bias) are still valid and interesting. That said, we leave the question of ArabicChinese optimization to future work. 4.2 Direct A-C MT System In our baseline direct A-C system, we used the Arabic and Chinese portions of our parallel corpus to train a direct phrase-based MT system. We use GIZA++ (Och and Ney, 2003) for 5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 176 word alignment, and the Pharaoh system suite to build the phrase table and decode (Koehn, 2004). The Chinese language model (LM) used 200M words from the UN corpus segmented in a manner consistent with our training. The trigram LM was built using the SRILM toolkit (Stolcke, 2002). 4.3 Sentence Pivoting MT System The sentence pivoting system (A-s-C) used English as an interface between two separate pharse-based MT systems: an Arabic-English direct system and an English-Chinese direct system. When translating Arabic to Chin</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29 (1):19–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Pro ceedings of ACL’03,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="18840" citStr="Och, 2003" startWordPosition="3107" endWordPosition="3108">parallel corpus, so the larger training sets include the smaller ones. Lines Words (Arabic) S 32500 1 Million M 65000 2 Million L 130000 4 Million XL 260000 8 Million Table 3: Training Data Size We use two other data sets (1K lines each) for tuning and testing. Each sentence in these sets has only one reference. Tuning and testing data sets are the same across all experiments and systems. In all our experiments, we decode using Pharaoh (Koehn, 2004) with a distortion limit of 4 and a maximum phrase length of 7. Tuning is done for each experimental condition using Och’s Minimum Error Training (Och, 2003). Note that for each set of experiments with the same data size, we draw Chinese, Arabic and English from the same chunk of three way parallel corpus. For example, in S size experiments, the two phrase tables used to build a new table in the phrase-pivoting approach are extracted respectively from the A-E and E-C systems built in the sentence-pivoting approach with size S corpora. 5.1 Direct System Results Table 4 shows the results of the direct translation system A-C. It also includes the result for A-E and E-C direct translation. As expected, as we double the size of the data, the BLEU score</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training for Statistical Machine Translation. In Pro ceedings of ACL’03, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fatiha Sadat</author>
<author>Nizar Habash</author>
</authors>
<title>Combination of Arabic preprocessing schemes for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of ColingACL’06.</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2433" citStr="Sadat and Habash, 2006" startWordPosition="377" endWordPosition="380">ion. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora usi</context>
<context position="14441" citStr="Sadat and Habash, 2006" startWordPosition="2332" endWordPosition="2335">r data collection is the United Nations (UN) multilingual corpus, provided by the LDC 4 (catalog no. LDC2004E12). The UN corpus has in principle parallel sentences for Arabic, English and Chinese. However, the Arabic-English 4 http://www.ldc.upenn.edu (A-E) data and Chinese-English (C-E) data sets were not in synch. The A-E data set has 3.2M lines while the C-E data set has 5.0M lines. We used the document ID provided in the data to match sentences from A-E against those in C-E to generate a three-way parallel corpus with 2.6M lines. We tokenized the Arabic data in the Arabic Treebank scheme (Sadat and Habash, 2006). Chinese was segmented into words using a segmenter developed by Howard Johnson for the Portage Chinese-English MT system.5 So a sentence consists of multiple words with spaces between them and each word is comprised of one or more characters. English was simply processed to split punctuation and “’s”. The same preprocessing was used in all systems compared. We are aware of two potentially biased aspects of our experimental setting. First, the Arabic and Chinese portions of our data collection, the UN corpus, are known to be generated from English originals. And secondly, the preprocessing te</context>
<context position="27382" citStr="Sadat and Habash (2006)" startWordPosition="4554" endWordPosition="4557">ult of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features (in particular word order). Our best result is the phrase-pivot system which scores higher than direct translation by 1.1 BLEU points. An error analysis of our system shows that we successfully handle many complex Arabic-Chinese syntactic variations although there is a large space for improvement still. In the future, we plan on exploring tighter coupling of Arabic and Chinese through comparing different methods of preprocessing Arabic for Arabic-Chinese MT, in a similar manner to Sadat and Habash (2006). We also plan to study how well these results carry on to different corpora (bilingual Arabic-English and English-Chinese) as opposed to the trilingual corpus used in this paper. We also plan to investigate whether our findings in ArabicEnglish-Chinese can be used for other different language triples. Acknowledgements We would like to thank Roland Kuhn, George Foster and Howard Johnson of the National Research Council Canada for helpful advice and discussions and for providing us with the Chinese preprocessing tools. 179 Figure 1: An example highlighting Arabic$English$Chinese syntactic diffe</context>
</contexts>
<marker>Sadat, Habash, 2006</marker>
<rawString>Fatiha Sadat and Nizar Habash. 2006. Combination of Arabic preprocessing schemes for statistical machine translation. In Proceedings of ColingACL’06. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02,</booktitle>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="19464" citStr="Papineni et al., 2002" startWordPosition="3216" endWordPosition="3219">Note that for each set of experiments with the same data size, we draw Chinese, Arabic and English from the same chunk of three way parallel corpus. For example, in S size experiments, the two phrase tables used to build a new table in the phrase-pivoting approach are extracted respectively from the A-E and E-C systems built in the sentence-pivoting approach with size S corpora. 5.1 Direct System Results Table 4 shows the results of the direct translation system A-C. It also includes the result for A-E and E-C direct translation. As expected, as we double the size of the data, the BLEU score (Papineni et al., 2002) increases. However, the rate of increase is not always consistent. In particular, the M and L conditions vary highly in A-E compared to A-C. This is odd especially given that we are comparing the same set of data from the three parallel corpora. We speculate that this may have to do with an oddity in that portion of the data set that may have a different quality than the rest. We see the effect of this drop in A-E in the next section. BLEU is measured on English case-insensitively. BLEU is measured on Chinese using segmented words not characters. 177 A-C A-E E-C S 11.17 21.89 19.29 M 13.43 23</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of ACL’02, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL’02,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2954" citStr="Schafer and Yarowsky (2002)" startWordPosition="461" endWordPosition="464">o and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on p</context>
</contexts>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>Charles Schafer &amp; David Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. In Proceedings of CoNLL’02, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simard</author>
</authors>
<title>Text translation alignment: Three languages are better than two.</title>
<date>1999</date>
<booktitle>In Pro ceedings of EMNLP VLC’99,</booktitle>
<location>College Park, MD, USA.</location>
<contexts>
<context position="3108" citStr="Simard (1999)" startWordPosition="486" endWordPosition="487">a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statis</context>
</contexts>
<marker>Simard, 1999</marker>
<rawString>Micheal. Simard. 1999. Text translation alignment: Three languages are better than two. In Pro ceedings of EMNLP VLC’99, College Park, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Nicola Ueffing</author>
<author>Pierre Isabelle</author>
<author>Roland Kuhn</author>
</authors>
<title>Rule-based translation with statistical phrase-based post-editing.</title>
<date>2007</date>
<booktitle>In Proceedings of the workshop on Statistical Machine Translation, ACL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Simard, Ueffing, Isabelle, Kuhn, 2007</marker>
<rawString>Michel Simard, Nicola Ueffing, Pierre Isabelle, and Roland Kuhn. 2007. Rule-based translation with statistical phrase-based post-editing. In Proceedings of the workshop on Statistical Machine Translation, ACL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP’02,</booktitle>
<location>Denver, CO, USA.</location>
<contexts>
<context position="16576" citStr="Stolcke, 2002" startWordPosition="2678" endWordPosition="2679">ave the question of ArabicChinese optimization to future work. 4.2 Direct A-C MT System In our baseline direct A-C system, we used the Arabic and Chinese portions of our parallel corpus to train a direct phrase-based MT system. We use GIZA++ (Och and Ney, 2003) for 5 http://iit-iti.nrc-cnrc.gc.ca/projects-projets/portage_e.html 176 word alignment, and the Pharaoh system suite to build the phrase table and decode (Koehn, 2004). The Chinese language model (LM) used 200M words from the UN corpus segmented in a manner consistent with our training. The trigram LM was built using the SRILM toolkit (Stolcke, 2002). 4.3 Sentence Pivoting MT System The sentence pivoting system (A-s-C) used English as an interface between two separate pharse-based MT systems: an Arabic-English direct system and an English-Chinese direct system. When translating Arabic to Chinese, the English top-1 output of the Arabic-English system was passed as input to the English-Chinese system. The English LM used to train the Arabic-English system is built from the counterpart of the Chinese data used to build the Chinese LM in our parallel corpus. We use 210M English words in total. 4.4 Phrase Pivoting MT System The phrase pivoting</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of ICSLP’02, Denver, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of pivot methods for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL-HLT’07,</booktitle>
<location>Rochester, NY, USA.</location>
<contexts>
<context position="3607" citStr="Utiyama and Isahara (2007)" startWordPosition="561" endWordPosition="564">ns for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Arabic-English MT by using available parallel data in other languages. Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT. Filali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 173 sentence and phrase pivoting strategies using three European languages (Spanish, French and German). Their results showed that pivoting does not work as well as direct translation. Wu and Wang (2007) focused on phrase pivoting. They proposed an interpolated scheme that employs two phrase tables: one extracted from a small amount of direct parallel data; and t</context>
<context position="17575" citStr="Utiyama and Isahara (2007)" startWordPosition="2840" endWordPosition="2843">sed to train the Arabic-English system is built from the counterpart of the Chinese data used to build the Chinese LM in our parallel corpus. We use 210M English words in total. 4.4 Phrase Pivoting MT System The phrase pivoting system (A-p-C) extracts a new Arabic to Chinese phrase table using the Arabic-English phrase table and the EnglishChinese phrase table. We consider a Chinese phrase a translation of an Arabic phrase only if some English phrase can bridge the two. We use the following formulae to compute the lexical and phrase probabilities in the new phrase table in a similar manner to Utiyama and Isahara (2007). Here, O is the lexical probability and pw is the phrase probability. O a c _ E O a e O e c &apos;( |) ( |) ( |) e O c a _ E O c e O e a &apos;( |) ( |) ( |) e p a c _ E p a e p e c w &apos;( |) w ( |) w ( |) e p c a _ E p c e p e a w &apos;( |) w ( |) w ( |) e The left hand side of the formulae represents the four required probabilities in a Pharaoh ArabicChinese phrase table. 5 Evaluation For each of the direct system, the sentencepivoting system and the phrase-pivoting system, we conduct four sets of experiments with different data sizes. Table 3 illustrates the training data size for each experiment. The tra</context>
<context position="21785" citStr="Utiyama and Isahara, 2007" startWordPosition="3607" endWordPosition="3610"> the 95% confidence level (Zhang et al., 2004). The differences between the two pivoting systems are not statistically significant. Examples from our best performing system are shown in Figure 2. A-C A-s-C A-p-C S 11.17 12.24 9.6% 13.12 17.5% M 13.43 14.10 5.0% 13.75 2.4% L 14.62 14.96 2.3% 14.97 2.4% XL 16.17 16.88 4.4% 17.29 6.9% Table 5: Word-based BLEU-4 scores. A-C is direct translation. A-s-C is indirect translation through sentence pivoting and A-p-C is indirect translation through phrase pivoting. The percentages indicate relative improvement over A-C. Our results are consistent with (Utiyama and Isahara, 2007) in that phrase-pivoting generally does better than sentence pivoting. However, we disagree with them in that, for us, direct translation is not the best system to use. We believe that this effect is caused by the combination of the very different languages we use. English is truly bridging between Arabic and Chinese in many linguistic dimensions. We think it’s English’s middle-ground-ness that makes these results possible. A-C A-s-C A-p-C BLEU-1 S 53.75 54.38 1.2% 54.64 1.7% M 56.65 57.00 0.6% 55.88 -1.4% L 58.37 57.69 -1.2% 58.79 0.7% XL 59.90 60.34 0.7% 60.28 0.6% BLEU-4 S 21.32 21.80 2.3% </context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2007. A comparison of pivot methods for phrase-based statistical machine translation. In Proceedings of NAACL-HLT’07, Rochester, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Wang</author>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2321" citStr="Wang et al., 2007" startWordPosition="357" endWordPosition="360">at using English as a pivot language for translating Arabic to Chinese actually outperforms direct translation. We believe this may be a result of English being a sort of middle ground between Arabic and Chinese in terms of different linguistic features and, in particular, word order. Section 2 describes previous work. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word align</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Chao Wang, Michael Collins, and Philipp Koehn. 2007. Chinese syntactic reordering for statistical machine translation. In Proceedings of EMNLP-CoNLL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>A Position Statement on Chinese Segmentation. Presented at the Chinese Lan guage Processing Workshop.</title>
<date>1998</date>
<note>http://www. cs.ust.hk/~dekai/papers/segmentation.html.</note>
<contexts>
<context position="6175" citStr="Wu, 1998" startWordPosition="956" endWordPosition="957">36 letters and eight optional diacritical marks. Arabic is written in a cursive mostly word-internal connected form, but words are separated by white spaces. The absence of Arabic diacritics adds a lot of ambiguity. Chinese uses a complex orthography that includes around 10,000 characters in common use. Characters convey semantic rather than phonological information. Chinese is written from left-to-right or top-down. Chinese words can be made out of one, two or more characters. However, words are written without separating spaces. Word segmentation is a major challenge for processing Chinese (Wu, 1998). English uses the Roman alphabet and its words are written with separating white spaces. English orthography is much closer to Arabic than it is to Chinese. 3.2 Morphology Arabic is a morphologically rich language with a large set of morphological features such person, number, gender, voice, aspect, mood, case, and state. Arabic features are realized using both concatenative (affixes and stems) and templatic (root and patterns) morphology with a variety of morphological, phonological and orthographic adjustments. In addition, Arabic has a set of very common clitics that are written attached t</context>
</contexts>
<marker>Wu, 1998</marker>
<rawString>Dekai Wu. 1998. A Position Statement on Chinese Segmentation. Presented at the Chinese Lan guage Processing Workshop. http://www. cs.ust.hk/~dekai/papers/segmentation.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
</authors>
<title>Pivot language aproach for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="4045" citStr="Wu and Wang (2007)" startWordPosition="620" endWordPosition="623">ilali and Bilmes (2005) improved word alignment by leveraging multilingual parallel translations. Most related to our work on pivoting are the following: Utiyama and Isahara (2007) studied 1 http://www.nist.gov/speech/tests/mt/2008/doc/ Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 173–181, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 173 sentence and phrase pivoting strategies using three European languages (Spanish, French and German). Their results showed that pivoting does not work as well as direct translation. Wu and Wang (2007) focused on phrase pivoting. They proposed an interpolated scheme that employs two phrase tables: one extracted from a small amount of direct parallel data; and the other extracted from large amounts of indirect data with a third pivoting language. They compared results for different European language as well as Chinese-Japanese translation using English as a pivoting language. Their results show that simple pivoting does not improve over direct MT; however, extending the direct MT system with phrases learned through pivoting helps. Babych et al. (2007) compared two methods for translating int</context>
</contexts>
<marker>Wu, Wang, 2007</marker>
<rawString>Hua Wu and Haifeng Wang. 2007. Pivot language aproach for phrase-based statistical machine translation. In Proceedings of ACL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>Karl-Michael Schneider</author>
<author>Steven Abney</author>
</authors>
<title>Aspect marker generation in English-to-Chinese machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="2635" citStr="Ye et al., 2007" startWordPosition="412" endWordPosition="415">ork. Section 3 discusses relevant linguistic issues of Arabic, Chinese and English. Section 4 describes our system and different pivoting techniques. And Section 5 presents our experimental results. 2 Previous Work There has been a lot of work on translation from Chinese to English (Wang et al., 2007; Crego and Mariño, 2007; Carpuat and Wu, 2007; among others) and from Arabic to English (Sadat and Habash, 2006, Al-Onaizan and Papineni, 2006; among others). There is also a fair amount of work on translation into Chinese from Japanese, Korean and English (Isahara et al., 2007; Kim et al., 2002; Ye et al., 2007; among others). In 2008, the National Institute of Standards and Technology (NIST) MT Evaluation competition introduced EnglishChinese as a new evaluation track.1 Much work has been done on exploiting multilingual corpora for MT or related tasks such as lexical induction or word alignment. Schafer and Yarowsky (2002) induced translation lexicons for languages without common parallel corpora using a bridge language that is related to the target languages. Simard (1999) described a sentence aligner that makes simultaneous decisions in a trilingual parallel text. Kumar et al. (2007) improved Ara</context>
</contexts>
<marker>Ye, Schneider, Abney, 2007</marker>
<rawString>Yang Ye, Karl-Michael Schneider, and Steven Abney. 2007. Aspect marker generation in English-to-Chinese machine translation. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ying Zhang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Interpreting Bleu/NIST scores: How much improvement do we need to have a better system?,</title>
<booktitle>In Proceedings of LREC’04,</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Zhang, Vogel, Waibel, </marker>
<rawString>Ying Zhang, Stephan Vogel and Alex Waibel, Interpreting Bleu/NIST scores: How much improvement do we need to have a better system?, In Proceedings of LREC’04, Lisbon, Portugal.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>