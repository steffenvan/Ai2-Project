<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003253">
<title confidence="0.69939">
Multilingual Revision
</title>
<author confidence="0.430935">
Charles Callaway
</author>
<affiliation confidence="0.2953045">
Istituto per la Ricerca Scientifica e Tecnologica
Istituto Trentino di Cultura, Italy (ITC-IRST)
</affiliation>
<email confidence="0.960723">
callaway@irst.itc.it
</email>
<sectionHeader confidence="0.998215" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989205882353">
Natural Language Generation has made
great strides towards multilingual gen-
eration from large-scale knowledge
sources. Meanwhile, current research in
revision has vastly improved the qual-
ity of text that NLG systems produce.
However, to-date there has been no at-
tempt at combining revision and mul-
tilingual NLG. This paper presents re-
search in multilingual revision, the last
major pipelined NLG component to be
studied from a multilingual perspective.
We describe the linguistic difficulties
in achieving multilingual revision, re-
view recent work, and present an imple-
mented framework for multilingual revi-
sion rules.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977808510638">
The quality of initial, unimproved text produced
by explanation generation systems has been no-
toriously poor (Lester and Porter, 1997). Recent
work in revision (Dalianis and Hovy, 1993; Robin,
1994; Callaway and Lester, 1997; Harvey and Car-
berry, 1998; Shaw, 1998) has shown substantial
progress towards qualitative and quantitative im-
provements in the text that explanation genera-
tors produce. By necessity, revision systems oper-
ate over deep linguistic structures rather than text
strings from template generators. Indeed, the in-
crease in variability and flexibility that deep gen-
eration systems provide is often touted as a major
advantage over simpler, more easily implemented
template generators (Reiter, 1995).
Multilinguality from deep linguistic representa-
tions (Paris et al., 1995; Stede, 1996; Bateman and
Sharoff, 1998; Scott, 1999; Kruijff et al., 2000)
is generally considered to be one of the advan-
tages that deep generation systems possess over
templates (although this depends heavily on the
definitions of deep and template methods, such as
in (Deemter et al., 1999)). By applying multilin-
gual lexica and grammars to a single initial knowl-
edge base, multilingual generators hope to lever-
age reusable components to produce texts in mul-
tiple languages with substantially less work than
implementing an equivalent number of monolin-
gual template or deep generators. But to be used
effectively and efficiently in a multilingual gener-
ation system, these reusable components must be
designed from the start for that purpose. Similarly,
one of the main motivations for multilingual revi-
sion is efficiency: A single formalism for revision
rules can greatly increase the amount of resource
sharing in a manner analogous to that of gram-
mars.
Just as in monolingual explanation generation,
unrevised multilingual text is in general quite un-
desirable. And while multilingual components
have been created for sentence planning (Bateman
and Sharoff, 1998), surface realization (Netzer and
Elhadad, 1999) and lexical choice (Stede, 1996),
no attempt has been made to combine research in
revision and multilingual NLG.
This paper presents research in multilingual re-
vision, the last major pipelined NLG component
</bodyText>
<page confidence="0.995899">
15
</page>
<bodyText confidence="0.999852545454545">
to be studied from a multilingual perspective. We
first present linguistic reasons for the difficulty
of discovering &amp;quot;revision rules&amp;quot; in both monolin-
gual and multilingual contexts. Next, we describe
recent work in revision and then analyze the el-
ements of revision rules to determine how each
element affects the revision process from both
a monolingual and multilingual perspective. Fi-
nally, we synthesize a revision rule model that per-
forms multilingual revisions under a common for-
malism in an implemented NLG system.
</bodyText>
<sectionHeader confidence="0.550198" genericHeader="method">
2 &amp;quot;Unrevising&amp;quot; a Corpus
</sectionHeader>
<bodyText confidence="0.999937298507463">
Text generation systems are notorious for produc-
ing correct but low quality text. In contrast, human
writers directly produce fluent text even in initial
drafts. Because of this, it is very difficult to find
a version of a naturally occurring text similar to
the types of protosentences produced by systems
today. (Meteer, 1990) initially explored this prob-
lem by having writers of scientific articles gen-
erate paraphrases in order to create a corpus for
studying revision rules. The lack of such corpora
is a disadvantage to implementers of revision sys-
tems because they lack the original source materi-
als with which to create revision rules that would
then allow them to achieve results comparable to
the original, polished texts.
For example, consider the four text fragments
in Figure 1, where (a) represents an excerpt from
an original passage in Spanish, (b) represents its
&amp;quot;unrevised&amp;quot; version, (c) represents the translation
of (a) into English, and (d) is the &amp;quot;unrevision&amp;quot; of
(c). While (a) and (c) are easily found in avail-
able corpora, the sentence structures in (b) and (d)
cannot be found in either existing corpora or au-
thors&apos; drafts. And yet these are precisely the types
of texts needed to discover how simple &amp;quot;protosen-
tences&amp;quot; are combined into larger clause structures.
Thus, one of the tasks that creators of revi-
sion systems must do is to collect example cor-
pora from their generation domain and &amp;quot;unrevise&amp;quot;
them to determine what types of revisions were
performed by the original authors of the domain
texts. The unrevised sentences should correspond
to the types of protosentences produced by the ini-
tial discourse and sentence planners. The result of
gathering examples from a set of corpora is a set of
revision rules applicable to that particular domain
which can then be used by a revision component
to refine and polish the final text produced by a
generation system.
In a multilingual context, this corpus analysis
must be repeated for each language, because dif-
ferent languages typically have different revision
rules (even when the content is the same, as in the
translations in Figure 1 (a) and (c), a revision sys-
tem may end up reorganizing the text in a differ-
ent manner because different languages and cul-
tures may have different modes of presentation).
Thus a system for multilingual revision must be
able to handle disparate sets of revision rules as
needed, or else resort to having multiple revision
components, with the corresponding decrease in
efficiency and increase in effort that such an archi-
tecture would bring.
A more efficient architectural approach would
be to make different multilingual revision deci-
sions for a set of languages by only replacing
sets of revision rules. To be effective, the revi-
sion module must be orchestrated in such a way
that all of the decision-making information can
be determined by the revision rules themselves.
Thus, a detailed feature analysis is necessary to
determine the structure and variability of typical
revision rules. In addition, all of the informa-
tion necessary to choose between different revi-
sion rules must be closely tied to the incoming
rhetorical structure and protosentences that com-
prise the sentence plan.
</bodyText>
<sectionHeader confidence="0.895159" genericHeader="method">
3 Aspects of Revision Operations
</sectionHeader>
<bodyText confidence="0.999932928571429">
Although much research has described the archi-
tectural and linguistic aspects of revision, rela-
tively little has been done to describe a feature-
based model of revision upon which revision deci-
sions can be based. However, most research de-
scribing implemented revision systems provides
insight into the high-level features that were found
necessary for particular projects or domains.
Dalianis&apos; work (Dalianis and Hovy, 1993) con-
centrated on the effect that a rule would have on
the text in terms of carrying it out procedurally.
His revision rules were the result of evaluating
human revisions on a set of standardized textual
propositions.
</bodyText>
<page confidence="0.995179">
16
</page>
<bodyText confidence="0.9973051">
Pase por alto el comentario. Me daba un poco de
vergiienza explicar que hacia todo esto porque
habia conocido una vez a una chica pelirroja.
Despues le dije que si, que pensaba aprender teatro.
En realidad yo aborrecia a los actores. Eran
demasiado extravertidos para mi gusto, y me
impresionaban como gente que siempre se estaba
saludando y abrazando y eran amigos de todo el
mundo. No soporto a la gente que es amiga de todo
el mundo, como los animadores de television.
</bodyText>
<listItem confidence="0.981868058823529">
(a)
(1) Pase por alto el comentario.
(2) Me daba un poco de vergiienza explicar que
hacia todo esto. ( &amp;quot;porque&amp;quot; )
(3) Habia conocido una vez a una chica pelirroja.
( &amp;quot;despues&amp;quot; )
(4) Le dije que si, que pensaba aprender teatro.
(5) En realidad, yo aborrecia a los actores.
(6) Eran demasiado extravertidos para mi gusto. (&amp;quot;y&amp;quot;)
(7) Me impresionaban como gente que siempre
se estaba saludando (&amp;quot;y&amp;quot;)
(8) Se estaba abrazando (&amp;quot;y&amp;quot;)
(9) Eran amigos de todo el mundo.
(10) No soporto a la gente (&amp;quot;que&amp;quot;)
(11) La gente es amiga de todo el mundo. (&amp;quot;como&amp;quot;)
(12) Los animadores de television [&amp;quot; son amigas...&amp;quot;]
(b)
</listItem>
<bodyText confidence="0.9991989">
I skipped over her comment. I was a bit ashamed
to explain that I had done all this because I had
once met a redheaded girl. Later I told her that
yes, I was thinking about studying theater, although
in fact, I hated actors. They were too extroverted
for my taste, and seemed like people who were
always greeting and hugging each other as if
they were friends with the whole world. I don&apos;t
put up with someone who is friends with the
whole world, like one of those television hosts.
</bodyText>
<listItem confidence="0.981720235294118">
(c)
(1) I skipped over her comment.
(2) I was a bit ashamed to explain I had done all this.
(&amp;quot;because&amp;quot;)
(3) I had once met a red-headed girl. (&amp;quot;later&amp;quot;)
(4) I told her that yes, I was thinking about studying theater.
(&amp;quot;although&amp;quot;)
(5) In fact, I hated actors.
(6) They were too extroverted for my taste. (&amp;quot;and&amp;quot;)
(7) They seemed like people who were always
greeting each other. (&amp;quot;and&amp;quot;)
(8) They were always hugging each other. (&amp;quot;as if&amp;quot;)
(9) They were friends with the whole world.
(10) I don&apos;t put up with someone. (&amp;quot;who&amp;quot;)
(11) The person is friends with the whole world. (&amp;quot;like&amp;quot;)
(12) One of those television hosts [&amp;quot;is friends with...&amp;quot;]
(d)
</listItem>
<figureCaption confidence="0.693549">
Figure 1: &amp;quot;Unrevised&amp;quot; Spanish
</figureCaption>
<listItem confidence="0.991404666666667">
• Aggregation: Operators which merge two
previously separate clauses into one.
• Ordering: Operators that reverse the external
ordering of clauses (migration) or their inter-
nal ordering (linear precedence).
• Casting: Operators that alter or enforce the
regularity of syntactic structures over multi-
ple clauses.
• Parsimony: Operators that prefer fewer over-
all words in a clause or other numeric quan-
tities such as depth of prepositional phrase or
relative clause embeddings.
</listItem>
<bodyText confidence="0.991506875">
Shaw&apos;s CASPER system of revision operators
(Shaw, 1998) focuses on the syntactic dependency
notion of hypotactic vs. paratactic operators.
CASPER functions in the domain of medical report
generation where Shaw noted that clause aggrega-
tions could frequently be classified on the basis of
dependency. In both cases, the redundant element
is deleted from one of the clauses.
</bodyText>
<listItem confidence="0.951775">
• Hypotactic: Operators which take two sen-
tences, a base and a modifier, convert the
modifier into a dependent clause, and then at-
tach it to the base sentence.
• Paratactic: Operators which attach two sen-
tences at the same dependency level, such as
with and or or coordination.
</listItem>
<bodyText confidence="0.99228825">
By far the most explicitly organized and clas-
sified set of revision operators is described in the
work on STREAK (Robin, 1994, Appendix A), a
system for writing summary descriptions of bas-
ketball games in English. Motivated by (but not
implemented using) a Tree Adjoining Grammar
approach, Robin makes the following classifica-
tions of revision operators:
</bodyText>
<listItem confidence="0.999016">
• Monotonic: Operators which leave the base
</listItem>
<page confidence="0.996014">
17
</page>
<bodyText confidence="0.9979232">
syntactic structure intact and result only in
the attachment of a new phrase or clause to
an unmodified existing structure. Examples
include Adjoin, Absorb, Conjoin, and Ap-
pend operators.
</bodyText>
<listItem confidence="0.997052333333333">
• Nonmonotonic: Operators which break up
the base syntactic structure in various ways
before attaching a new phrase or clause.
Examples include Recast, Adjunctization,
Nominalization, Demotion, and Promotion
operators.
• Side Transformations: Operators that reduce
redundant lexemes left over from previous re-
vision operations. Examples include Refer-
ence Adjustment, Argument Control, El-
lipsis, Scope Marking, Ordering Adjust-
ment, and Lexical Adjustment operators.
</listItem>
<bodyText confidence="0.9992885">
Robin lists 18 distinct types of adjoin operators
alone, organized according to the syntactic type of
the phrase to be adjoined and the syntactic type
and position of its attachment location. To illus-
trate, two of these subclasses of the adjoin opera-
tor are shown here:
</bodyText>
<listItem confidence="0.9461146">
• Adjoin Relative Clause to Bottom-Level
Nominal: Attaches a relative clause to an im-
mediately preceding noun phrase as in &amp;quot;to
power them to a win over [(the Cavs), (who
lost again)]&amp;quot;.
• Adjoin Relative Clause to Top-Level Nomi-
nal: Attaches a relative clause to a preced-
ing noun phrase which already has postmod-
ifiers as in &amp;quot;to power them to [(a win over the
Cavs), (that extended their streak)]&amp;quot;.
</listItem>
<bodyText confidence="0.995723692307692">
However, there are a number of other classifi-
cations of revision operators not covered by these
three approaches. In addition, these systems are
not multilingual in nature and their corpora analy-
ses covered only revisions in the English language.
In order to fully understand the revision process
both linguistically and computationally, as well
as to ensure that this understanding is consistent
across languages, it is important to discover and
classify as many aspects of revision operators as
possible. Some of the additional aspects we have
found in our efforts to build a multilingual revision
component are as follows:
</bodyText>
<listItem confidence="0.97875980952381">
• Rhetorical Type: Most revision systems as-
sume some underlying theory of discourse
structure, such as RST (Mann and Thomp-
son, 1987). These theories define particular
rhetorical types such as greeting or persuade
which are used by revision systems to pro-
vide additional constraints when selecting re-
vision operators. How these constraints are
affected by multilingual text is unknown.
• Perspective: While revision systems seem
identical in purpose, there are actually great
differences in what they expect to accom-
plish. For example, Dalianis and Hovy&apos;s
rules attempt to mimic human revision pro-
cesses, Robin&apos;s STREAK system attempts
to build a single sentence, Shaw&apos;s CASPER
system focuses on eliminating redundancy,
while other systems try to increase syntactic
variety.
• Syntactic structure: Most revision systems
start from sequences of protosentences and
change a subset of those protosentences into
different clauses or phrases. However, a com-
plete set of target syntactic structures (espe-
cially identifying which of those structures
overlap with the syntactic structures of other
languages) has not yet been identified.
• Attachment position: When protosentences
are converted into dependent circumstantial
clauses (e.g., when-clauses), a revision oper-
ator must choose to place it in front or at the
end of a sentence. These operators must take
into account whether a previous revision has
already occupied one of those slots as well as
whether a particular language allows a simi-
lar range of syntactic possibilities.
• Depth of representation: Robin&apos;s STREAK
system explicitly represented multiple levels
of syntax, semantics, and pragmatics. More
recent systems have shied away from this ap-
proach and favored shallower representations
to increase efficiency.
</listItem>
<page confidence="0.944238">
18
</page>
<listItem confidence="0.930037944444444">
• Scope: Revision operators can be very local
and examine only adjacent protosentences or,
at the expense of efficiency, examine proto-
sentences slightly farther away (either to ac-
tually use them in aggregating or merely for
additional context when making a more local
decision).
• New lexicalizations: Most sentence planners
do not produce many of the discourse-level
elements found in polished texts because they
are not needed when generating protosen-
tences. For instance, discourse markers (Van-
der Linden and Martin, 1995; Grote, 1998)
are frequently used to show the relationships
between individual clauses. If appropriate in-
formation were available, it would be pos-
sible for revision operators to add discourse
markers as they perform clause aggregation.
</listItem>
<bodyText confidence="0.995385333333333">
These factors are important when building a re-
vision system that is scalable in terms of size,
genre and language.
</bodyText>
<sectionHeader confidence="0.975264" genericHeader="method">
4 Motivation vs. Action
</sectionHeader>
<bodyText confidence="0.999449416666667">
Analyzing the structure of revision operators in
this manner does not imply that any particular
architecture is preferred over another. However,
much like the STRIPS architecture (Fikes and Nils-
son, 1972), our analysis of revision rules in a mul-
tilingual environment has shown that every revi-
sion operator can be broken down into two parts
describing when a rule should be fired (motivation,
expressed as triggering rules), and if it is fired,
what are the effects of that rule on the original pro-
tosentences (action, expressed as a target syntactic
modification).
</bodyText>
<listItem confidence="0.990159909090909">
• Motivations: The parts of a revision rule
which deal with whether the rule is applica-
ble and which differentiate it with respect to
other rules. Aspects which are helpful in de-
ciding applicability include rhetorical type,
perspective, syntactic structure, depth of rep-
resentation, scope, and if discourse markers
are expected to be added, those features of
the input which are salient.
• Actions: The parts of a revision rule that al-
ter either the internal syntactic structure of
</listItem>
<bodyText confidence="0.999908681818182">
clauses as they are aggregated or the rhetori-
cal relationship(s) between multiple clauses.
Aspects which are useful include monotonic-
ity, dependency, effect, perspective, syntactic
structure, and attachment position.
This division is apparent despite the language
of the text being revised. For example, because
languages have syntactic structure and at the low-
est level revisions affect that syntactic structure,1
the decision to alter that structure implies that the
revision rule knows which syntactic category it
is going to change it to. However, the particu-
lar syntactic category might be different given a
different language. Given exactly similar circum-
stances, an English revision rule might prefer to
change a protosentence into a prepositional phrase
while a Spanish revision rule might prefer a rel-
ative clause. In addition, some syntactic options
are available in certain languages but not in others
(Netzer and Elhadad, 1999).
There are frequent similarities between lan-
guages, however. For example, our corpora analy-
ses have shown that coordination with &amp;quot;and&amp;quot; usu-
ally occurs in similar situations. Also, the revi-
sion rules we have devised for English and Span-
ish in our domain almost always share identical
motivations even if they differ in their actions.
Given the overall structural similarity of revision
rules despite their differences in details, the goal
of designing a system capable of efficient multi-
lingual revision is then to devise a single architec-
tural component capable of carrying out revision
operations by swapping out sets of revision rules
rather than creating a separate revision component
for each distinct language.
In our experience, different languages have sim-
ilar sets of motivations for when to apply revision
rules and similar sets of actions that carry them
out. However, since the mapping from the set of
initial structures (which drive the analysis of the
motivation components of the revision rules) pro-
vided by the sentence planner to the set of actions
which produce the final structures is language-
specific, it is appropriate to apply a functional
</bodyText>
<footnote confidence="0.98925725">
1While revisions do ultimately alter morphological struc-
ture, they do so only indirectly. No revision rule to our knowl-
edge either considers or implements decisions based on mor-
phological information.
</footnote>
<page confidence="0.997614">
19
</page>
<figure confidence="0.9962369">
Initial
Structure
Sentence 1
Sentence 2
Preference Mapping
(per language)
11.1 Sentence 1
Prep Phr. 3
Sentence 3 Rel. Cl. 2
f (rule) : [Initial] [Final]
</figure>
<figureCaption confidence="0.999887">
Figure 2: Revision Functions
</figureCaption>
<bodyText confidence="0.999971764705882">
model. Such a model (Figure 2) provides a sep-
arate function for each language which creates a
set of revision rules by mapping from a set of mo-
tivations to a set of actions.
A multilingual revision architecture then could
have a single set of language-neutral motivation
criteria, a single set of language-neutral action ef-
fects, and a mapping function for each language
desired (Figure 3). When the system is directed
to switch from generating text for one language
to another, the revision component needs only to
switch in a new mapping function rather than us-
ing an entirely new revision component designed
solely for the new language. Another benefit is
that once sets of motivations and actions are en-
coded, it is relatively easy to adjust the effects of
the revision module for different genres and styles.
</bodyText>
<sectionHeader confidence="0.985488" genericHeader="method">
5 Implementation
</sectionHeader>
<bodyText confidence="0.999868">
We started with an existing pipelined, multi-
paragraph multilingual NLG system, STORY-
BOOK (Callaway, 2000; Callaway and Lester,
2002), that takes protosentences and revises them
into text. While the major pipelined modules (dis-
course planner, sentence planner and surface real-
izer) were already capable of multilingual genera-
tion, the revision component, REVISOR (Callaway
and Lester, 1997) only worked for English.
Our first step was to reorganize the English re-
vision component following the architecture pre-
viously described. After analyzing the existing re-
vision rules, we came up with a common set of 54
motivational triggers, 16 syntactic transformation
actions, and a mapping between them that simu-
lated the existing revision rule set. We then re-
structured the rule determination and application
mechanisms before verifying that indeed the new
</bodyText>
<figure confidence="0.9338725">
Restructurer
•If
Revised
Sentences
</figure>
<figureCaption confidence="0.999804">
Figure 3: Abstract Revision Architecture
</figureCaption>
<bodyText confidence="0.999443826086957">
revision component made substantially the same
revisions to the text as had the original revision
component.
Next, we analyzed our translated Spanish cor-
pus using the &amp;quot;unrevising&amp;quot; strategy described in
Section 2. This yielded an additional 7 motiva-
tional triggers and 2 syntactic transformation ac-
tions for the Spanish corpus that were not ac-
counted for in the original set of English revision
rules. Afterwards, we created a mapping function
from the appropriate motivational triggers found
in both the English and Spanish set to the syntactic
actions which we had found in the Spanish corpus.
For example, consider the sentences in Fig-
ure 4. REVISOR was initially capable of gener-
ating these simple protosentences in both English
and Spanish, although initially only the English
version worked well with revision, as it was keyed
to look for specific information only present in the
English output. We rewrote the English revision
rules instead to look for more generic tags from
the sentence planner indicating a particular pro-
tosentence had an intention such as IDENTITY
</bodyText>
<figure confidence="0.9963986">
Motivations
Language-
Specific
Mappings
Incoming
Unrevised
Protosentences
Iterating
Revision
Mechanism
Actions
Restructuring
Directives
Final
Structure
</figure>
<page confidence="0.907254">
20
</page>
<bodyText confidence="0.9871057">
I don&apos;t put up with a person. [+animate-relative-clause = &amp;quot;who&amp;quot;]
The person is friends with the whole world. [+comparison = &amp;quot;liken]
Television hosts are friends with the whole world.
I don&apos;t put up with a person who is friends with the whole world,
like television hosts.
No soporto a la gente. [+animate-relative-clause = &amp;quot;quen]
La gente es amiga de todo el mundo. [+comparison = &amp;quot;comon]
Los animadores del televisio&apos;n son amigas de todo el mundo.
No soporto a la gente que es amiga de todo el mundo, como los
animadores del televisio&apos;n.
</bodyText>
<figureCaption confidence="0.996672">
Figure 4: An example
</figureCaption>
<bodyText confidence="0.999924611111111">
or DESCRIPTION. We then extracted the syntac-
tic aggregation operations, such as rules for gen-
erating relative clauses, from the various revision
rules. Next, we wrote the mappings which com-
bined the two (Figure 2), and checked to ensure
that the original paragraph was regenerated. Fi-
nally, by substituting the appropriate mapping, we
were able to also generate the revised Spanish ver-
sion (Figure 4).
The result was an efficient revision system (exe-
cution time measured in tens of milliseconds) that
produced the same or very similar revised para-
graphs as the original English revision component
as well as performing appropriate revisions to the
Spanish text. This resulted in a substantial im-
provement in the amount of time required to create
a traditional, standalone revision component for
Spanish from scratch.
</bodyText>
<sectionHeader confidence="0.999488" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999853416666667">
Efficient multilingual revision is possible within
a single framework given a detailed analysis not
only of a domain and its corpus and the types of re-
vision operations conducted in each language, but
by specifying the substructures of revision rules
themselves. By isolating the differences in revi-
sion rules inherent in particular languages, we can
increase the extent of language-neutral architec-
tures and decrease the amount of work required
to implement multilinguality in formerly monolin-
gual systems.
A significant amount of the work involved in
creating a multilingual revision system lies in con-
ducting corpora analyses. One of the many prob-
lems faced by creaters of revision systems is that a
large amount of text must be examined before one
can be confident that a sufficient number of revi-
sion rules has been uncovered. And because NLG
systems to date are not capable of generating large
scale texts, it is extremely difficult to test theories
of revision rules. Having modular revision sys-
tems that can be easily altered for new languages,
styles and genres will improve the quality of texts
produced by NLG systems.
</bodyText>
<sectionHeader confidence="0.997105" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.998004">
This work was supported by the PEACH and
T1CCA projects, funded by the Autonomous
Province of Trento.
</bodyText>
<sectionHeader confidence="0.99785" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985640363636364">
J. Bateman and S. Sharoff. 1998. Multilingual gram-
mars and multilingual lexicons for multilingual text
generation. In ECAI Workshop on Multilinguality in
the Lexicon-II, pages 1-8, Brighton, UK.
Charles Callaway. 2000. Narrative Prose Genera-
tion. Ph.D. thesis, North Carolina State University,
Raleigh, NC.
Charles B. Callaway and James C. Lester. 1997. Dy-
namically improving explanations: A revision-based
approach to explanation generation. In Proceed-
ings of the Fifteenth International Joint Conference
</reference>
<page confidence="0.984028">
21
</page>
<reference confidence="0.99938955952381">
on Artificial Intelligence, pages 952-58, Nagoya,
Japan.
Charles B. Callaway and James C. Lester. 2002.
Narrative prose generation. Artificial Intelligence,
139(2):213-252, August.
Hercules Dalianis and Eduard Hovy. 1993. Aggrega-
tion in natural language generation. In Proceedings
of the Fourth European Workshop on Natural Lan-
guage Generation, Pisa, Italy.
Kees van Deemter, Emiel Krahmer, and Mariet The-
une. 1999. Plan-based vs. template-based nlg: A
false opposition? In Proceedings of the KI-99 Work-
shop Between Templates and Free Choice in Natural
Language Generation, Bonn, Germany.
R. E. Fikes and N. J. Nilsson. 1972. STRIPS: A
new approach to the application of theorem prov-
ing to problem solving. Artificial Intelligence, 2(3-
4): 189-208.
Brigitte Grote. 1998. Representing temporal discourse
markers for generation purposes. In Proceedings
of the Discourse Relations and Discourse Markers
Workshop, pages 22-28, Montréal, Canada.
Terrence Harvey and Sandra Carberry. 1998. Inte-
grating text plans for conciseness and coherence. In
Proceedings of the 36th Annual Meeting of the As-
sociation for Computational Linguistics, pages 512-
518, August.
Geert-Jan Kruijff, Elke Teich, John Bateman, Ivana
Kruijff-Korbayova, Hana Skoumalova, Serge
Sharoff, Lena Sokolova, Tony Hartley, Kamenka
Staykova, and Jill Hana. 2000. Multilinguality in
a text generation system for 3 Slavic languages. In
COLING-2000: Proceedings of the 18th Interna-
tional Conference on Computational Linguistics,
Saarbruecken, Germany.
James C. Lester and Bruce W. Porter. 1997. Devel-
oping and empirically evaluating robust explanation
generators: The KNIGHT experiments. Computa-
tional Linguistics, 23(1):65-101.
William C. Mann and Sandra A. Thompson. 1987.
Rhetorical structure theory: A theory of text
organization. Technical Report ISI/RS-87-190,
USC/Information Sciences Institute, Marina del
Rey, CA, June.
Marie W. Meteer. 1990. The Generation Gap: The
Problem of Expressibility in Text Planning. Ph.D.
thesis, University of MA, February.
Yael Dahan Netzer and Michael Elhadad. 1999. Bilin-
gual Hebrew-English generation of possessives and
partitives: Raising the input abstraction level. In
Proceedings of the 37th Meeting of the Association
for Computational Linguistics, pages 144-151, Col-
lege Park, Maryland, June.
Cecile L. Paris, Keith Vander Linden, Markus Fischer,
Anthony Hartley, Lyn Pemberton, Richard Power,
and Donia Scott. 1995. A support tool for writ-
ing multilingual instructions. In Proceedings of
the Fourteenth International Joint Conference on
Artificial Intelligence, pages 1398-1404, Montreal,
Canada.
Ehud Reiter. 1995. NLG vs. templates. In Proceed-
ings of the Fifth European Workshop on Natural
Language Generation, Leiden, The Netherlands.
Jacques Robin. 1994. Revision-Based Generation
of Natural Language Summaries Providing Histori-
cal Background. Ph.D. thesis, Columbia University,
December.
Donia R. Scott. 1999. The multilingual genera-
tion game: Authoring fluent texts in unfamiliar lan-
guages. In Proceedings of the Sixteenth Interna-
tional Joint Conference on Artificial Intelligence,
Stockholm, Sweden.
James Shaw. 1998. Clause aggregation using linguistic
knowledge. In Proceedings of the 9th International
Workshop on Natural Language Generation, pages
138-147, Niagara-on-the-Lake, Canada.
Manfred Stede. 1996. Lexical Semantics and
Knowledge Representation in Multilingual Sentence
Generation. Ph.D. thesis, University of Toronto,
Toronto, Ontario.
Keith Vander Linden and James H. Martin. 1995. Ex-
pressing rhetorical relations in instructional text: A
case study of the purpose relation. Computational
Liguistics, 21 (1): 29-57 .
</reference>
<page confidence="0.998997">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.371526">
<title confidence="0.999341">Multilingual Revision</title>
<author confidence="0.564841">Charles</author>
<affiliation confidence="0.625921">Istituto per la Ricerca Scientifica e</affiliation>
<address confidence="0.498216">Istituto Trentino di Cultura, Italy</address>
<email confidence="0.996706">callaway@irst.itc.it</email>
<abstract confidence="0.997840888888889">Natural Language Generation has made great strides towards multilingual generation from large-scale knowledge sources. Meanwhile, current research in revision has vastly improved the quality of text that NLG systems produce. However, to-date there has been no attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bateman</author>
<author>S Sharoff</author>
</authors>
<title>Multilingual grammars and multilingual lexicons for multilingual text generation.</title>
<date>1998</date>
<booktitle>In ECAI Workshop on Multilinguality in the Lexicon-II,</booktitle>
<pages>1--8</pages>
<location>Brighton, UK.</location>
<contexts>
<context position="1629" citStr="Bateman and Sharoff, 1998" startWordPosition="231" endWordPosition="234">way and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing an equivalent number of monolingual template or deep generators. But to be used effectively and efficiently in a mu</context>
</contexts>
<marker>Bateman, Sharoff, 1998</marker>
<rawString>J. Bateman and S. Sharoff. 1998. Multilingual grammars and multilingual lexicons for multilingual text generation. In ECAI Workshop on Multilinguality in the Lexicon-II, pages 1-8, Brighton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Callaway</author>
</authors>
<title>Narrative Prose Generation.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>North Carolina State University,</institution>
<location>Raleigh, NC.</location>
<contexts>
<context position="20284" citStr="Callaway, 2000" startWordPosition="3233" endWordPosition="3234">effects, and a mapping function for each language desired (Figure 3). When the system is directed to switch from generating text for one language to another, the revision component needs only to switch in a new mapping function rather than using an entirely new revision component designed solely for the new language. Another benefit is that once sets of motivations and actions are encoded, it is relatively easy to adjust the effects of the revision module for different genres and styles. 5 Implementation We started with an existing pipelined, multiparagraph multilingual NLG system, STORYBOOK (Callaway, 2000; Callaway and Lester, 2002), that takes protosentences and revises them into text. While the major pipelined modules (discourse planner, sentence planner and surface realizer) were already capable of multilingual generation, the revision component, REVISOR (Callaway and Lester, 1997) only worked for English. Our first step was to reorganize the English revision component following the architecture previously described. After analyzing the existing revision rules, we came up with a common set of 54 motivational triggers, 16 syntactic transformation actions, and a mapping between them that simu</context>
</contexts>
<marker>Callaway, 2000</marker>
<rawString>Charles Callaway. 2000. Narrative Prose Generation. Ph.D. thesis, North Carolina State University, Raleigh, NC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Dynamically improving explanations: A revision-based approach to explanation generation.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>952--58</pages>
<location>Nagoya, Japan.</location>
<contexts>
<context position="1024" citStr="Callaway and Lester, 1997" startWordPosition="143" endWordPosition="146"> to-date there has been no attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff,</context>
<context position="20569" citStr="Callaway and Lester, 1997" startWordPosition="3272" endWordPosition="3275">mponent designed solely for the new language. Another benefit is that once sets of motivations and actions are encoded, it is relatively easy to adjust the effects of the revision module for different genres and styles. 5 Implementation We started with an existing pipelined, multiparagraph multilingual NLG system, STORYBOOK (Callaway, 2000; Callaway and Lester, 2002), that takes protosentences and revises them into text. While the major pipelined modules (discourse planner, sentence planner and surface realizer) were already capable of multilingual generation, the revision component, REVISOR (Callaway and Lester, 1997) only worked for English. Our first step was to reorganize the English revision component following the architecture previously described. After analyzing the existing revision rules, we came up with a common set of 54 motivational triggers, 16 syntactic transformation actions, and a mapping between them that simulated the existing revision rule set. We then restructured the rule determination and application mechanisms before verifying that indeed the new Restructurer •If Revised Sentences Figure 3: Abstract Revision Architecture revision component made substantially the same revisions to the</context>
</contexts>
<marker>Callaway, Lester, 1997</marker>
<rawString>Charles B. Callaway and James C. Lester. 1997. Dynamically improving explanations: A revision-based approach to explanation generation. In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, pages 952-58, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative prose generation.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<pages>139--2</pages>
<contexts>
<context position="20312" citStr="Callaway and Lester, 2002" startWordPosition="3235" endWordPosition="3238">apping function for each language desired (Figure 3). When the system is directed to switch from generating text for one language to another, the revision component needs only to switch in a new mapping function rather than using an entirely new revision component designed solely for the new language. Another benefit is that once sets of motivations and actions are encoded, it is relatively easy to adjust the effects of the revision module for different genres and styles. 5 Implementation We started with an existing pipelined, multiparagraph multilingual NLG system, STORYBOOK (Callaway, 2000; Callaway and Lester, 2002), that takes protosentences and revises them into text. While the major pipelined modules (discourse planner, sentence planner and surface realizer) were already capable of multilingual generation, the revision component, REVISOR (Callaway and Lester, 1997) only worked for English. Our first step was to reorganize the English revision component following the architecture previously described. After analyzing the existing revision rules, we came up with a common set of 54 motivational triggers, 16 syntactic transformation actions, and a mapping between them that simulated the existing revision </context>
</contexts>
<marker>Callaway, Lester, 2002</marker>
<rawString>Charles B. Callaway and James C. Lester. 2002. Narrative prose generation. Artificial Intelligence, 139(2):213-252, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
<author>Eduard Hovy</author>
</authors>
<title>Aggregation in natural language generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fourth European Workshop on Natural Language Generation,</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="984" citStr="Dalianis and Hovy, 1993" startWordPosition="137" endWordPosition="140">ext that NLG systems produce. However, to-date there has been no attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al.,</context>
<context position="7220" citStr="Dalianis and Hovy, 1993" startWordPosition="1126" endWordPosition="1129">tion necessary to choose between different revision rules must be closely tied to the incoming rhetorical structure and protosentences that comprise the sentence plan. 3 Aspects of Revision Operations Although much research has described the architectural and linguistic aspects of revision, relatively little has been done to describe a featurebased model of revision upon which revision decisions can be based. However, most research describing implemented revision systems provides insight into the high-level features that were found necessary for particular projects or domains. Dalianis&apos; work (Dalianis and Hovy, 1993) concentrated on the effect that a rule would have on the text in terms of carrying it out procedurally. His revision rules were the result of evaluating human revisions on a set of standardized textual propositions. 16 Pase por alto el comentario. Me daba un poco de vergiienza explicar que hacia todo esto porque habia conocido una vez a una chica pelirroja. Despues le dije que si, que pensaba aprender teatro. En realidad yo aborrecia a los actores. Eran demasiado extravertidos para mi gusto, y me impresionaban como gente que siempre se estaba saludando y abrazando y eran amigos de todo el mun</context>
</contexts>
<marker>Dalianis, Hovy, 1993</marker>
<rawString>Hercules Dalianis and Eduard Hovy. 1993. Aggregation in natural language generation. In Proceedings of the Fourth European Workshop on Natural Language Generation, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Emiel Krahmer</author>
<author>Mariet Theune</author>
</authors>
<title>Plan-based vs. template-based nlg: A false opposition?</title>
<date>1999</date>
<booktitle>In Proceedings of the KI-99 Workshop Between Templates and Free Choice in Natural Language Generation,</booktitle>
<location>Bonn, Germany.</location>
<marker>van Deemter, Krahmer, Theune, 1999</marker>
<rawString>Kees van Deemter, Emiel Krahmer, and Mariet Theune. 1999. Plan-based vs. template-based nlg: A false opposition? In Proceedings of the KI-99 Workshop Between Templates and Free Choice in Natural Language Generation, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Fikes</author>
<author>N J Nilsson</author>
</authors>
<title>STRIPS: A new approach to the application of theorem proving to problem solving.</title>
<date>1972</date>
<journal>Artificial Intelligence,</journal>
<volume>2</volume>
<issue>3</issue>
<pages>189--208</pages>
<contexts>
<context position="16020" citStr="Fikes and Nilsson, 1972" startWordPosition="2548" endWordPosition="2552">urse markers (Vander Linden and Martin, 1995; Grote, 1998) are frequently used to show the relationships between individual clauses. If appropriate information were available, it would be possible for revision operators to add discourse markers as they perform clause aggregation. These factors are important when building a revision system that is scalable in terms of size, genre and language. 4 Motivation vs. Action Analyzing the structure of revision operators in this manner does not imply that any particular architecture is preferred over another. However, much like the STRIPS architecture (Fikes and Nilsson, 1972), our analysis of revision rules in a multilingual environment has shown that every revision operator can be broken down into two parts describing when a rule should be fired (motivation, expressed as triggering rules), and if it is fired, what are the effects of that rule on the original protosentences (action, expressed as a target syntactic modification). • Motivations: The parts of a revision rule which deal with whether the rule is applicable and which differentiate it with respect to other rules. Aspects which are helpful in deciding applicability include rhetorical type, perspective, sy</context>
</contexts>
<marker>Fikes, Nilsson, 1972</marker>
<rawString>R. E. Fikes and N. J. Nilsson. 1972. STRIPS: A new approach to the application of theorem proving to problem solving. Artificial Intelligence, 2(3-4): 189-208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
</authors>
<title>Representing temporal discourse markers for generation purposes.</title>
<date>1998</date>
<booktitle>In Proceedings of the Discourse Relations and Discourse Markers Workshop,</booktitle>
<pages>22--28</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="15454" citStr="Grote, 1998" startWordPosition="2463" endWordPosition="2464">approach and favored shallower representations to increase efficiency. 18 • Scope: Revision operators can be very local and examine only adjacent protosentences or, at the expense of efficiency, examine protosentences slightly farther away (either to actually use them in aggregating or merely for additional context when making a more local decision). • New lexicalizations: Most sentence planners do not produce many of the discourse-level elements found in polished texts because they are not needed when generating protosentences. For instance, discourse markers (Vander Linden and Martin, 1995; Grote, 1998) are frequently used to show the relationships between individual clauses. If appropriate information were available, it would be possible for revision operators to add discourse markers as they perform clause aggregation. These factors are important when building a revision system that is scalable in terms of size, genre and language. 4 Motivation vs. Action Analyzing the structure of revision operators in this manner does not imply that any particular architecture is preferred over another. However, much like the STRIPS architecture (Fikes and Nilsson, 1972), our analysis of revision rules i</context>
</contexts>
<marker>Grote, 1998</marker>
<rawString>Brigitte Grote. 1998. Representing temporal discourse markers for generation purposes. In Proceedings of the Discourse Relations and Discourse Markers Workshop, pages 22-28, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terrence Harvey</author>
<author>Sandra Carberry</author>
</authors>
<title>Integrating text plans for conciseness and coherence.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>512--518</pages>
<contexts>
<context position="1051" citStr="Harvey and Carberry, 1998" startWordPosition="147" endWordPosition="151">attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff</context>
</contexts>
<marker>Harvey, Carberry, 1998</marker>
<rawString>Terrence Harvey and Sandra Carberry. 1998. Integrating text plans for conciseness and coherence. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, pages 512-518, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan Kruijff</author>
<author>Elke Teich</author>
<author>John Bateman</author>
<author>Ivana Kruijff-Korbayova</author>
<author>Hana Skoumalova</author>
<author>Serge Sharoff</author>
<author>Lena Sokolova</author>
<author>Tony Hartley</author>
<author>Kamenka Staykova</author>
<author>Jill Hana</author>
</authors>
<title>Multilinguality in a text generation system for 3 Slavic languages. In</title>
<date>2000</date>
<booktitle>COLING-2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="1665" citStr="Kruijff et al., 2000" startWordPosition="237" endWordPosition="240">y, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing an equivalent number of monolingual template or deep generators. But to be used effectively and efficiently in a multilingual generation system, these </context>
</contexts>
<marker>Kruijff, Teich, Bateman, Kruijff-Korbayova, Skoumalova, Sharoff, Sokolova, Hartley, Staykova, Hana, 2000</marker>
<rawString>Geert-Jan Kruijff, Elke Teich, John Bateman, Ivana Kruijff-Korbayova, Hana Skoumalova, Serge Sharoff, Lena Sokolova, Tony Hartley, Kamenka Staykova, and Jill Hana. 2000. Multilinguality in a text generation system for 3 Slavic languages. In COLING-2000: Proceedings of the 18th International Conference on Computational Linguistics, Saarbruecken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James C Lester</author>
<author>Bruce W Porter</author>
</authors>
<title>Developing and empirically evaluating robust explanation generators: The KNIGHT experiments.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--1</pages>
<contexts>
<context position="934" citStr="Lester and Porter, 1997" startWordPosition="129" endWordPosition="132">ch in revision has vastly improved the quality of text that NLG systems produce. However, to-date there has been no attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality f</context>
</contexts>
<marker>Lester, Porter, 1997</marker>
<rawString>James C. Lester and Bruce W. Porter. 1997. Developing and empirically evaluating robust explanation generators: The KNIGHT experiments. Computational Linguistics, 23(1):65-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: A theory of text organization.</title>
<date>1987</date>
<tech>Technical Report ISI/RS-87-190,</tech>
<institution>USC/Information Sciences Institute,</institution>
<location>Marina del Rey, CA,</location>
<contexts>
<context position="13275" citStr="Mann and Thompson, 1987" startWordPosition="2133" endWordPosition="2137">ystems are not multilingual in nature and their corpora analyses covered only revisions in the English language. In order to fully understand the revision process both linguistically and computationally, as well as to ensure that this understanding is consistent across languages, it is important to discover and classify as many aspects of revision operators as possible. Some of the additional aspects we have found in our efforts to build a multilingual revision component are as follows: • Rhetorical Type: Most revision systems assume some underlying theory of discourse structure, such as RST (Mann and Thompson, 1987). These theories define particular rhetorical types such as greeting or persuade which are used by revision systems to provide additional constraints when selecting revision operators. How these constraints are affected by multilingual text is unknown. • Perspective: While revision systems seem identical in purpose, there are actually great differences in what they expect to accomplish. For example, Dalianis and Hovy&apos;s rules attempt to mimic human revision processes, Robin&apos;s STREAK system attempts to build a single sentence, Shaw&apos;s CASPER system focuses on eliminating redundancy, while other s</context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1987. Rhetorical structure theory: A theory of text organization. Technical Report ISI/RS-87-190, USC/Information Sciences Institute, Marina del Rey, CA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
</authors>
<title>The Generation Gap: The Problem of Expressibility in Text Planning.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>University of MA,</institution>
<contexts>
<context position="3889" citStr="Meteer, 1990" startWordPosition="586" endWordPosition="587">sion rules to determine how each element affects the revision process from both a monolingual and multilingual perspective. Finally, we synthesize a revision rule model that performs multilingual revisions under a common formalism in an implemented NLG system. 2 &amp;quot;Unrevising&amp;quot; a Corpus Text generation systems are notorious for producing correct but low quality text. In contrast, human writers directly produce fluent text even in initial drafts. Because of this, it is very difficult to find a version of a naturally occurring text similar to the types of protosentences produced by systems today. (Meteer, 1990) initially explored this problem by having writers of scientific articles generate paraphrases in order to create a corpus for studying revision rules. The lack of such corpora is a disadvantage to implementers of revision systems because they lack the original source materials with which to create revision rules that would then allow them to achieve results comparable to the original, polished texts. For example, consider the four text fragments in Figure 1, where (a) represents an excerpt from an original passage in Spanish, (b) represents its &amp;quot;unrevised&amp;quot; version, (c) represents the translat</context>
</contexts>
<marker>Meteer, 1990</marker>
<rawString>Marie W. Meteer. 1990. The Generation Gap: The Problem of Expressibility in Text Planning. Ph.D. thesis, University of MA, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Dahan Netzer</author>
<author>Michael Elhadad</author>
</authors>
<title>Bilingual Hebrew-English generation of possessives and partitives: Raising the input abstraction level.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Meeting of the Association for Computational Linguistics,</booktitle>
<pages>144--151</pages>
<location>College Park, Maryland,</location>
<contexts>
<context position="2805" citStr="Netzer and Elhadad, 1999" startWordPosition="413" endWordPosition="416">ut to be used effectively and efficiently in a multilingual generation system, these reusable components must be designed from the start for that purpose. Similarly, one of the main motivations for multilingual revision is efficiency: A single formalism for revision rules can greatly increase the amount of resource sharing in a manner analogous to that of grammars. Just as in monolingual explanation generation, unrevised multilingual text is in general quite undesirable. And while multilingual components have been created for sentence planning (Bateman and Sharoff, 1998), surface realization (Netzer and Elhadad, 1999) and lexical choice (Stede, 1996), no attempt has been made to combine research in revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component 15 to be studied from a multilingual perspective. We first present linguistic reasons for the difficulty of discovering &amp;quot;revision rules&amp;quot; in both monolingual and multilingual contexts. Next, we describe recent work in revision and then analyze the elements of revision rules to determine how each element affects the revision process from both a monolingual and multilingual perspective. Final</context>
<context position="17802" citStr="Netzer and Elhadad, 1999" startWordPosition="2829" endWordPosition="2832">nguages have syntactic structure and at the lowest level revisions affect that syntactic structure,1 the decision to alter that structure implies that the revision rule knows which syntactic category it is going to change it to. However, the particular syntactic category might be different given a different language. Given exactly similar circumstances, an English revision rule might prefer to change a protosentence into a prepositional phrase while a Spanish revision rule might prefer a relative clause. In addition, some syntactic options are available in certain languages but not in others (Netzer and Elhadad, 1999). There are frequent similarities between languages, however. For example, our corpora analyses have shown that coordination with &amp;quot;and&amp;quot; usually occurs in similar situations. Also, the revision rules we have devised for English and Spanish in our domain almost always share identical motivations even if they differ in their actions. Given the overall structural similarity of revision rules despite their differences in details, the goal of designing a system capable of efficient multilingual revision is then to devise a single architectural component capable of carrying out revision operations by</context>
</contexts>
<marker>Netzer, Elhadad, 1999</marker>
<rawString>Yael Dahan Netzer and Michael Elhadad. 1999. Bilingual Hebrew-English generation of possessives and partitives: Raising the input abstraction level. In Proceedings of the 37th Meeting of the Association for Computational Linguistics, pages 144-151, College Park, Maryland, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecile L Paris</author>
<author>Keith Vander Linden</author>
<author>Markus Fischer</author>
<author>Anthony Hartley</author>
<author>Lyn Pemberton</author>
<author>Richard Power</author>
<author>Donia Scott</author>
</authors>
<title>A support tool for writing multilingual instructions.</title>
<date>1995</date>
<booktitle>In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1398--1404</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1589" citStr="Paris et al., 1995" startWordPosition="225" endWordPosition="228">nd Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing an equivalent number of monolingual template or deep generators. But to be </context>
</contexts>
<marker>Paris, Linden, Fischer, Hartley, Pemberton, Power, Scott, 1995</marker>
<rawString>Cecile L. Paris, Keith Vander Linden, Markus Fischer, Anthony Hartley, Lyn Pemberton, Richard Power, and Donia Scott. 1995. A support tool for writing multilingual instructions. In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, pages 1398-1404, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>NLG vs. templates.</title>
<date>1995</date>
<booktitle>In Proceedings of the Fifth European Workshop on Natural Language Generation,</booktitle>
<location>Leiden, The Netherlands.</location>
<contexts>
<context position="1515" citStr="Reiter, 1995" startWordPosition="217" endWordPosition="218">y poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing a</context>
</contexts>
<marker>Reiter, 1995</marker>
<rawString>Ehud Reiter. 1995. NLG vs. templates. In Proceedings of the Fifth European Workshop on Natural Language Generation, Leiden, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University,</institution>
<contexts>
<context position="997" citStr="Robin, 1994" startWordPosition="141" endWordPosition="142">uce. However, to-date there has been no attempt at combining revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede,</context>
<context position="10919" citStr="Robin, 1994" startWordPosition="1767" endWordPosition="1768">main of medical report generation where Shaw noted that clause aggregations could frequently be classified on the basis of dependency. In both cases, the redundant element is deleted from one of the clauses. • Hypotactic: Operators which take two sentences, a base and a modifier, convert the modifier into a dependent clause, and then attach it to the base sentence. • Paratactic: Operators which attach two sentences at the same dependency level, such as with and or or coordination. By far the most explicitly organized and classified set of revision operators is described in the work on STREAK (Robin, 1994, Appendix A), a system for writing summary descriptions of basketball games in English. Motivated by (but not implemented using) a Tree Adjoining Grammar approach, Robin makes the following classifications of revision operators: • Monotonic: Operators which leave the base 17 syntactic structure intact and result only in the attachment of a new phrase or clause to an unmodified existing structure. Examples include Adjoin, Absorb, Conjoin, and Append operators. • Nonmonotonic: Operators which break up the base syntactic structure in various ways before attaching a new phrase or clause. Examples</context>
</contexts>
<marker>Robin, 1994</marker>
<rawString>Jacques Robin. 1994. Revision-Based Generation of Natural Language Summaries Providing Historical Background. Ph.D. thesis, Columbia University, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donia R Scott</author>
</authors>
<title>The multilingual generation game: Authoring fluent texts in unfamiliar languages.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Stockholm, Sweden.</location>
<contexts>
<context position="1642" citStr="Scott, 1999" startWordPosition="235" endWordPosition="236">y and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing an equivalent number of monolingual template or deep generators. But to be used effectively and efficiently in a multilingual ge</context>
</contexts>
<marker>Scott, 1999</marker>
<rawString>Donia R. Scott. 1999. The multilingual generation game: Authoring fluent texts in unfamiliar languages. In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, Stockholm, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Clause aggregation using linguistic knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation,</booktitle>
<pages>138--147</pages>
<location>Niagara-on-the-Lake, Canada.</location>
<contexts>
<context position="1064" citStr="Shaw, 1998" startWordPosition="152" endWordPosition="153">on and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component to be studied from a multilingual perspective. We describe the linguistic difficulties in achieving multilingual revision, review recent work, and present an implemented framework for multilingual revision rules. 1 Introduction The quality of initial, unimproved text produced by explanation generation systems has been notoriously poor (Lester and Porter, 1997). Recent work in revision (Dalianis and Hovy, 1993; Robin, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000</context>
<context position="10198" citStr="Shaw, 1998" startWordPosition="1647" endWordPosition="1648">those television hosts [&amp;quot;is friends with...&amp;quot;] (d) Figure 1: &amp;quot;Unrevised&amp;quot; Spanish • Aggregation: Operators which merge two previously separate clauses into one. • Ordering: Operators that reverse the external ordering of clauses (migration) or their internal ordering (linear precedence). • Casting: Operators that alter or enforce the regularity of syntactic structures over multiple clauses. • Parsimony: Operators that prefer fewer overall words in a clause or other numeric quantities such as depth of prepositional phrase or relative clause embeddings. Shaw&apos;s CASPER system of revision operators (Shaw, 1998) focuses on the syntactic dependency notion of hypotactic vs. paratactic operators. CASPER functions in the domain of medical report generation where Shaw noted that clause aggregations could frequently be classified on the basis of dependency. In both cases, the redundant element is deleted from one of the clauses. • Hypotactic: Operators which take two sentences, a base and a modifier, convert the modifier into a dependent clause, and then attach it to the base sentence. • Paratactic: Operators which attach two sentences at the same dependency level, such as with and or or coordination. By f</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. 1998. Clause aggregation using linguistic knowledge. In Proceedings of the 9th International Workshop on Natural Language Generation, pages 138-147, Niagara-on-the-Lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
</authors>
<title>Lexical Semantics and Knowledge Representation in Multilingual Sentence Generation.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Toronto,</institution>
<location>Toronto, Ontario.</location>
<contexts>
<context position="1602" citStr="Stede, 1996" startWordPosition="229" endWordPosition="230">, 1994; Callaway and Lester, 1997; Harvey and Carberry, 1998; Shaw, 1998) has shown substantial progress towards qualitative and quantitative improvements in the text that explanation generators produce. By necessity, revision systems operate over deep linguistic structures rather than text strings from template generators. Indeed, the increase in variability and flexibility that deep generation systems provide is often touted as a major advantage over simpler, more easily implemented template generators (Reiter, 1995). Multilinguality from deep linguistic representations (Paris et al., 1995; Stede, 1996; Bateman and Sharoff, 1998; Scott, 1999; Kruijff et al., 2000) is generally considered to be one of the advantages that deep generation systems possess over templates (although this depends heavily on the definitions of deep and template methods, such as in (Deemter et al., 1999)). By applying multilingual lexica and grammars to a single initial knowledge base, multilingual generators hope to leverage reusable components to produce texts in multiple languages with substantially less work than implementing an equivalent number of monolingual template or deep generators. But to be used effectiv</context>
<context position="2838" citStr="Stede, 1996" startWordPosition="420" endWordPosition="421"> multilingual generation system, these reusable components must be designed from the start for that purpose. Similarly, one of the main motivations for multilingual revision is efficiency: A single formalism for revision rules can greatly increase the amount of resource sharing in a manner analogous to that of grammars. Just as in monolingual explanation generation, unrevised multilingual text is in general quite undesirable. And while multilingual components have been created for sentence planning (Bateman and Sharoff, 1998), surface realization (Netzer and Elhadad, 1999) and lexical choice (Stede, 1996), no attempt has been made to combine research in revision and multilingual NLG. This paper presents research in multilingual revision, the last major pipelined NLG component 15 to be studied from a multilingual perspective. We first present linguistic reasons for the difficulty of discovering &amp;quot;revision rules&amp;quot; in both monolingual and multilingual contexts. Next, we describe recent work in revision and then analyze the elements of revision rules to determine how each element affects the revision process from both a monolingual and multilingual perspective. Finally, we synthesize a revision rule</context>
</contexts>
<marker>Stede, 1996</marker>
<rawString>Manfred Stede. 1996. Lexical Semantics and Knowledge Representation in Multilingual Sentence Generation. Ph.D. thesis, University of Toronto, Toronto, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Vander Linden</author>
<author>James H Martin</author>
</authors>
<title>Expressing rhetorical relations in instructional text: A case study of the purpose relation.</title>
<date>1995</date>
<journal>Computational Liguistics,</journal>
<volume>21</volume>
<issue>1</issue>
<pages>29--57</pages>
<contexts>
<context position="15440" citStr="Linden and Martin, 1995" startWordPosition="2459" endWordPosition="2462">ave shied away from this approach and favored shallower representations to increase efficiency. 18 • Scope: Revision operators can be very local and examine only adjacent protosentences or, at the expense of efficiency, examine protosentences slightly farther away (either to actually use them in aggregating or merely for additional context when making a more local decision). • New lexicalizations: Most sentence planners do not produce many of the discourse-level elements found in polished texts because they are not needed when generating protosentences. For instance, discourse markers (Vander Linden and Martin, 1995; Grote, 1998) are frequently used to show the relationships between individual clauses. If appropriate information were available, it would be possible for revision operators to add discourse markers as they perform clause aggregation. These factors are important when building a revision system that is scalable in terms of size, genre and language. 4 Motivation vs. Action Analyzing the structure of revision operators in this manner does not imply that any particular architecture is preferred over another. However, much like the STRIPS architecture (Fikes and Nilsson, 1972), our analysis of re</context>
</contexts>
<marker>Linden, Martin, 1995</marker>
<rawString>Keith Vander Linden and James H. Martin. 1995. Expressing rhetorical relations in instructional text: A case study of the purpose relation. Computational Liguistics, 21 (1): 29-57 .</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>