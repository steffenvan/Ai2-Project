<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9979545">
Manipuri-English Bidirectional Statistical Machine
Translation Systems using Morphology and Dependency Relations
</title>
<author confidence="0.986263">
Thoudam Doren Singh
</author>
<affiliation confidence="0.991304">
Department of Computer Science and
</affiliation>
<author confidence="0.36281">
Engineering
</author>
<affiliation confidence="0.709593">
Jadavpur University
</affiliation>
<email confidence="0.993977">
thoudam.doren@gmail.com
</email>
<author confidence="0.981195">
Sivaji Bandyopadhyay
</author>
<affiliation confidence="0.992033">
Department of Computer Science and
</affiliation>
<author confidence="0.361676">
Engineering
</author>
<affiliation confidence="0.709092">
Jadavpur University
</affiliation>
<email confidence="0.994799">
sivaji_cse_ju@yahoo.com
</email>
<sectionHeader confidence="0.999555" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920083333333">
Manipuri has little resource for NLP related re-
search and development activities. Manipuri is a
less privileged Tibeto-Burman language spoken
by approximately three million people mainly in
the state of Manipur in India as well as its neigh-
boring states and in the countries of Myanmar
and Bangladesh. Some of the unique features of
this language are tone, the agglutinative verb
morphology and predominance of aspect than
tense, lack of grammatical gender, number and
person. Other features are verb final word order
in a sentence i.e., Subject Object Verb (SOV)
order, extensive suffix with more limited prefixa-
tion. In Manipuri, identification of most of the
word classes and sentence types are based on the
markers. All sentences, except interrogatives end
with one of these mood markers, which may or
may not be followed by an enclitic. Basic sen-
tence types in Manipuri are determined through
illocutionary mood markers, all of which are
verbal inflectional suffixes, with the exception of
the interrogatives that end with an enclitic. Two
important problems in applying statistical ma-
chine translation (SMT) techniques to English-
Manipuri bidirectional MT systems are: (a) the
wide syntactic divergence between the language
pairs, and (b) the richer morphology and case
marking of Manipuri compared to English. The
first problem manifests itself in poor word-order
in the output translations, while the second one
leads to incorrect inflections and case marking.
The output Manipuri sentences in case of Eng-
lish-Manipuri system suffer badly when mor-
phology and case markers are incorrect in this
free word order and morphologically rich lan-
guage.
</bodyText>
<sectionHeader confidence="0.648352" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999965545454545">
The present work reports the develop-
ment of Manipuri-English bidirectional
statistical machine translation systems. In
the English-Manipuri statistical machine
translation system, the role of the suffixes
and dependency relations on the source
side and case markers on the target side
are identified as important translation
factors. A parallel corpus of 10350 sen-
tences from news domain is used for
training and the system is tested with 500
sentences. Using the proposed translation
factors, the output of the translation qual-
ity is improved as indicated by baseline
BLEU score of 13.045 and factored
BLEU score of 16.873 respectively. Si-
milarly, for the Manipuri English system,
the role of case markers and POS tags in-
formation at the source side and suffixes
and dependency relations at the target
side are identified as useful translation
factors. The case markers and suffixes
are not only responsible to determine the
word classes but also to determine the
dependency relations. Using these trans-
lation factors, the output of the transla-
tion quality is improved as indicated by
baseline BLEU score of 13.452 and fac-
tored BLEU score of 17.573 respectively.
Further, the subjective evaluation indi-
cates the improvement in the fluency and
adequacy of both the factored SMT out-
puts over the respective baseline systems.
</bodyText>
<page confidence="0.995258">
83
</page>
<note confidence="0.9816765">
Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 83–91,
COLING 2010, Beijing, August 2010.
</note>
<bodyText confidence="0.998009125">
The parallel corpora used is in news domain
which have been collected, cleaned and aligned
(Singh et al., 2010b) from the Sangai Express
newspaper website www.thesangaiexpress.com
available in both Manipuri and English. A daily
basis collection was done covering the period
from May 2008 to November 2008 since there is
no repository.
</bodyText>
<sectionHeader confidence="0.999425" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.99996138">
Koehn and Hoang (2007) developed a frame-
work for statistical translation models that tightly
integrates additional morphological, syntactic, or
semantic information. Statistical Machine Trans-
lation with scarce resources using morpho-
syntactic information is discussed in (Niepen and
Ney, 2004). It introduces sentence level restruc-
turing transformations that aim at the assimila-
tion of word order in related sentences and
exploitation of the bilingual training data by ex-
plicitly taking into account the interdependencies
of related inflected forms thereby improving the
translation quality. Popovic and Ney (2006) dis-
cussed SMT with a small amount of bilingual
training data. Case markers and morphology are
used to address the crux of fluency in the Eng-
lish-Hindi SMT system (Ramanathan et al.,
2009). Work on translating from rich to poor
morphology using factored model is reported in
(Avramidis and Koehn, 2008). In this method of
enriching input, the case agreement for nouns,
adjectives and articles are mainly defined by the
syntactic role of each phrase. Resolution of verb
conjugation is done by identifying the person of
a verb and using the linguistic information tag.
Manipuri to English Example Based Machine
Translation system is reported in (Singh and
Bandyopadhyay, 2010a) on news domain. For
this, POS tagging, morphological analysis, NER
and chunking are applied on the parallel corpus
for phrase level alignment. Chunks are aligned
using a dynamic programming “edit-distance
style” alignment algorithm. The translation
process initially looks for an exact match in the
parallel example base and returns the retrieved
target output. Otherwise, the maximal match
source sentence is identified. For word level
mismatch, the unmatched words in the input are
either translated from the lexicon or translite-
rated. Unmatched phrases are looked into the
phrase level parallel example base; the target
phrase translations are identified and then re-
combined with the retrieved output. English-
Manipuri SMT system using morpho-syntactic
and semantic information is reported in (Singh
and Bandyopadhyay, 2010c). In this system, the
role of the suffixes and dependency relations on
the source side and case markers on the target
side are identified as important translation fac-
tors.
</bodyText>
<sectionHeader confidence="0.966549" genericHeader="method">
3 Syntactic Reordering
</sectionHeader>
<bodyText confidence="0.999902666666667">
This is a preprocessing step applied to the in-
put English sentences for English-Manipuri SMT
system. The program for syntactic reordering
uses the parse trees generated by Stanford parser1
and applies a handful of reordering rules written
using perl module Parse::RecDescent. By doing
this, the SVO order of English is changed to
SOV order for Manipuri, and post modifiers are
converted to pre-modifiers. The basic difference
of Manipuri phrase order compared to English is
handled by reordering the input sentence follow-
ing the rule (Rao et al., 2000):
</bodyText>
<equation confidence="0.9289175">
SSmV VmOOmCm  C&apos;mS&apos;mS&apos;O&apos;mO&apos;V&apos;mV&apos;
where, S: Subject
O: Object
V : Verb
</equation>
<bodyText confidence="0.970898">
Cm: Clause modifier
X&apos;: Corresponding constituent in Manipuri,
where X is S, O, or V
Xm: modifier of X
There are two reasons why the syntactic reor-
dering approach improves over the baseline
phrase-based SMT system (Wang et al., 2007).
One obvious benefit is that the word order of the
transformed source sentence is much closer to
the target sentence, which reduces the reliance on
the distortion model to perform reordering during
decoding. Another potential benefit is that the
alignment between the two sides will be of high-
er quality because of fewer “distortions” between
the source and the target, so that the resulting
phrase table of the reordered system would be
better. However, a counter argument is that the
reordering is very error prone, so that the added
noise in the reordered data actually hurts the
alignments and hence the phrase tables.
</bodyText>
<footnote confidence="0.984938">
1 http://nlp.stanford.edu/software/lex-parser.shtml
</footnote>
<page confidence="0.999514">
84
</page>
<sectionHeader confidence="0.998423" genericHeader="method">
4 Morphology
</sectionHeader>
<bodyText confidence="0.9996824">
The affixes are the determining factor of the
word class in Manipuri. In this agglutinative lan-
guage the number of verbal suffixes is more than
that of nominal suffixes. Works on Manipuri
morphology are found in (Singh and Bandyo-
padhyay, 2006) and (Singh and Bandyopadhyay,
2008). In this language, a verb must minimally
consist of a verb root and an inflectional suffix.
A noun may be optionally affixed by derivational
morphemes indicating gender, number and quan-
tity. Further, a noun may be prefixed by a pro-
nominal prefix which indicates its possessor.
Words in Manipuri consist of stems or bound
roots with suffixes (from one to ten suffixes),
prefixes (only one per word) and/or enclitics.
</bodyText>
<figure confidence="0.932153857142857">
(a) ইব োমচো--qT ব োল-vk কোওই
Ibomcha-na Ball-du kao-i
Ibomcha-nom Ball-distal kick
Ibomcha kicks the ball.
(b) ব োল-vk ইব োমচো--qT কোওই
Ball-du Ibomcha-na kao-i
Ball-distal Ibomcha-nom kick
</figure>
<bodyText confidence="0.99413425">
Ibomcha kicks the ball.
The identification of subject and object in both
the sentences are done by the suffixes -qT (na) and
vk(du) as given by the examples (a) and (b). The
case markers convey the right meaning during
translation though the most acceptable order of
Manipuri sentence is SOV. In order to produce a
good translation output all the morphological
forms of a word and its translations should be
available in the training data and every word has
to appear with every possible suffixes. This will
require a large training data. By learning the gen-
eral rules of morphology, the amount of training
data could be reduced. Separating lemma and
suffix allows the system to learn more about the
different possible word formations.
</bodyText>
<table confidence="0.834724666666667">
Manipuri Gloss English Meaning
ব োম্নো Tom-na by Tom
ব োমদগী Tom-dagi from Tom
ব োমসু Tom-su Tom also
ব োমগী Tom-gi of Tom
ব োমগো Tom-ga with Tom
</table>
<tableCaption confidence="0.995761">
Table 1: Some of the inflected forms of names in
Manipuri and its corresponding English meaning
</tableCaption>
<bodyText confidence="0.965387076923077">
Table 1 gives some examples of the inflected
forms of a person name and its corresponding
English meaning. The Manipuri stemmer sepa-
rates the case markers such as –নো (-na), -দগী (-
dagi), -সু (-su), -গী (-gi), -গো (-ga) etc. from
surface forms so that “ব োম” (Tom) from Manipu-
ri side matches with “Tom” at English side help-
ing to overcome the data sparseness. Enclitics in
Manipuri fall into six categories: determiners,
case markers, the copula, mood markers, inclu-
sive / exclusive and pragmatic peak markers and
attitude markers. The role of the enclitics used
and its meaning differs based on the context.
</bodyText>
<sectionHeader confidence="0.99614" genericHeader="method">
5 Factored Model of Translation
</sectionHeader>
<bodyText confidence="0.647594444444444">
Using factored approach, a tighter integration of
linguistic information into the translation model
is done for two reasons2:
■ Translation models that operate on more
general representations, such as lemma in-
stead of surface forms of words, can draw on
richer statistics and overcome the data
sparseness problem caused by limited train-
ing data.
■ Many aspects of translation can be best ex-
plained at a morphological, syntactic or se-
mantic level. Having such information
available to the translation model allows the
direct modeling of these aspects. For in-
stance, reordering at the sentence level is
mostly driven by general syntactic principles,
local agreement constraints that show up in
morphology, etc.
</bodyText>
<subsectionHeader confidence="0.994398">
5.1 Combination of Components in Fac-
tored Model
</subsectionHeader>
<bodyText confidence="0.997375">
Factored translation model is the combination of
several components including language model,
reordering model, translation steps and genera-
tion steps in a log-linear model3:
</bodyText>
<equation confidence="0.947111">
(1)
</equation>
<bodyText confidence="0.9907365">
Z is a normalization constant that is ignored in
practice. To compute the probability of a transla-
tion e given an input sentence f, we have to eva-
luate each feature function hi. The feature weight
</bodyText>
<footnote confidence="0.999502">
2http://www.statmt.org/moses/?n=Moses.FactoredModels
3http://www.statmt.org/moses/?n=Moses.FactoredModels
</footnote>
<page confidence="0.999652">
85
</page>
<bodyText confidence="0.999957875">
λi in the log linear model is determined by using
minimum error rate training method (Och, 2003).
For a translation step component, each feature
function ht is defined over the phrase pairs (fj,ej)
given a scoring function τ:
For the generation step component, each fea-
ture function hg given a scoring function γ is de-
fined over the output words ek only:
</bodyText>
<subsectionHeader confidence="0.999724">
5.2 Stanford Dependency Parser
</subsectionHeader>
<bodyText confidence="0.99488121875">
The dependency relations used in the experiment
are generated by the Stanford dependency parser
(Marie-Catherine de Marneffe and Manning,
2008). This parser uses 55 relations to express
the dependencies among the various words in a
sentence. The dependencies are all binary rela-
tions: a grammatical relation holds between a
governor and a dependent. These relations form a
hierarchical structure with the most general rela-
tion at the root.
figure 1. Dependency relation graph of the sen-
tence “Sources said that Tom was shot by police”
generated by Stanford Parser
There are various argument relations like sub-
ject, object, objects of prepositions and clausal
complements, modifier relations like adjectival,
adverbial, participial, infinitival modifiers and
other relations like coordination, conjunct, exple-
tive and punctuation. Let us consider an example
“Sources said that Tom was shot by police”.
Stanford parser produces the dependency rela-
tions, nsubj(said, sources) and agent (shot, po-
lice) . Thus, sources|nsubj and police|agent are
the factors used. “Tom was shot by police” forms
the object of the verb “said”. The Stanford parser
represents these dependencies with the help of a
clausal complement relation which links “said”
with “shot” and uses the complementizer relation
to introduce the subordination conjunction. Fig-
ure 1 shows the dependency relation graph of the
sentence “Sources said that Tom was shot by po-
lice”.
</bodyText>
<subsectionHeader confidence="0.986811">
5.3 Factorization approach of English-
Manipuri SMT system
</subsectionHeader>
<bodyText confidence="0.93233125">
Manipuri case markers are decided by dependen-
cy relation and aspect information of English.
Figure 2 shows the translation factors used in the
translation between English and Manipuri.
</bodyText>
<listItem confidence="0.352212">
(i) Tomba drives the car.
</listItem>
<equation confidence="0.903388333333333">
ত াম্বনা কারদু ত ৌই
Tomba-na car-du thou-i
(Tomba) (the car) (drives)
</equation>
<bodyText confidence="0.797999461538461">
Tomba|empty|nsubj drive|s|empty the|empty|det
car|empty|dobj
A subject requires a case marker in a clause
with a perfective form such as –না (na). It can be
represented as,
suffix+ dependency relation 4 case marker
s|empty + empty|dobj 4 না (na)
(ii) Birds are flying.
উচেকশিং পাইশর
ucheksing payri
(birds are) (flying)
Bird|s|nsubj are|empty|aux fly|ing|empty
Thus, English-Manipuri factorization consists of
</bodyText>
<listItem confidence="0.838597">
■ a lemma to lemma translation factor [i.e.,
Bird 4 উচেক (uchek) ]
■ a suffix + dependency relation 4 suffix [i.e.,
s + nsubj 4 শিং (sing)]
■ a lemma + suffix 4 surface form generation
factor
</listItem>
<figure confidence="0.987662263157895">
[i.e., উচেক (uchek) + শিং (sing) 4 উচেকশিং
(ucheksing)]
nsubj
said
ccomp
source complm shot
agent
that
Police
nsubjpass auxpass
Tom was
86
Input Output
Word
Word
Lemma
Suffix
Dependency
Relation
</figure>
<figureCaption confidence="0.999878">
Figure 2. English to Manipuri translation factors
</figureCaption>
<subsectionHeader confidence="0.9019795">
5.4 Factorization approach of Manipuri-
English SMT system
</subsectionHeader>
<bodyText confidence="0.989143">
Manipuri case markers are responsible to identify
dependency relation and aspect information of
English. Figure 3 shows the translation factors
used in the translation between Manipuri and
English. The Manipuri- English factorization
consists of:
</bodyText>
<listItem confidence="0.9138988">
■ Translation factor: lemma to lemma
[e.g., উচেক (uchek) 4 Bird]
■ Translation factor: suffix + POS 4 depen-
dency relation + POS + suffix
[e.g., শিং (sing) + NN 4 nsubj + NN + s]
■ Generation factor: lemma + POS + depen-
dency Relation +suffix 4 surface form gen-
eration factor
[e.g., উচেক (uchek)+ NN + nsubj + শিং (sing)
4 উচেকশিং (ucheksing ]
</listItem>
<figure confidence="0.9385904">
Word
Lemma
POS
Dependen-
cy Relation
</figure>
<figureCaption confidence="0.999935">
Figure 3. The Manipuri-English translation factors
</figureCaption>
<subsectionHeader confidence="0.960518">
5.5 Syntactically enriched output
</subsectionHeader>
<bodyText confidence="0.99672675">
High-order sequence models (just like n-gram
language models over words) are used in order to
support syntactic coherence of the output (Koehn
and Hoang, 2007).
</bodyText>
<figure confidence="0.9900495">
Input Output
word
3-gram Parts-of-speech
7-gram
</figure>
<figureCaption confidence="0.991333">
Figure 4. By generating additional linguistic factors
on the output side, high-order sequence models over
these factors support syntactical coherence of the out-
put.
</figureCaption>
<bodyText confidence="0.99991425">
Adding part-of-speech factor on the output
side and exploiting them with 7-gram sequence
models (as shown in Figure 4) results in minor
improvements in BLEU score.
</bodyText>
<sectionHeader confidence="0.998562" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9965125">
A number of experiments have been carried out
using factored translation framework and incor-
porating linguistic information. The toolkits used
in the experiment are:
■ Stanford Dependency Parser4 was used to (i)
generate the dependency relations and (ii)
syntactic reordering of the input English sen-
tences using Parse::RecDescent module.
■ Moses5 toolkit (Koehn, 2007) was used for
training with GIZA++6, decoding and mini-
mum error rate training (Och, 2003) for tun-
ing.
</bodyText>
<listItem confidence="0.50936675">
■ SRILM7 toolkit (Stolcke, 2002) was used to
build language models with 10350 Manipuri
sentences for English-Manipuri system and
four and a half million English wordforms
collected from the news domain for Manipu-
ri-English system.
■ English morphological analyzer morpha 8
(Minnen et al., 2001) was used and the
</listItem>
<figure confidence="0.863192941176471">
4 http://nlp.stanford.edu/software/lex-parser.shtml
5 http://www.statmt.org/moses/
6 http://www.fjoch.com/GIZA++.html
7 http://www.speech.sri.com/projects/srilm
8
ftp://ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar.
gz
Lemma
Case
Marker
Suffix/
Case
Marker
Word
Lemma
POS
word
</figure>
<page confidence="0.996708">
87
</page>
<bodyText confidence="0.980996">
stemmer from Manipuri Morphological ana-
lyzer (Singh and Bandyopadhyay, 2006) was
used for the Manipuri side.
■ Manipuri POS tagger (Singh et. al., 2008) is
used to tag the POS (Parts of speech) factors
of the input Manipuri sentences.
</bodyText>
<sectionHeader confidence="0.998263" genericHeader="method">
7 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999467">
7.1 English-Manipuri SMT System
</subsectionHeader>
<bodyText confidence="0.9999046">
The evaluation of the machine translation sys-
tems developed in the present work is done in
two approaches using automatic scoring with
reference translation and subjective evaluation as
discussed in (Ramanathan et al., 2009).
</bodyText>
<sectionHeader confidence="0.468902" genericHeader="method">
Evaluation Metrics:
</sectionHeader>
<listItem confidence="0.975744">
■ NIST (Doddington, 2002): A high score
means a better translation by measuring the
precision of n-gram.
■ BLEU (Papineni et al, 2002): This metric
gives the precision of n-gram with respect to
the reference translation but with a brevity
penalty.
</listItem>
<table confidence="0.99749075">
No ofsentences No of words
Training 10350 296728
Development 600 16520
Test 500 15204
</table>
<tableCaption confidence="0.9776425">
Table 2. Training, development and testing corpus
statistics
</tableCaption>
<bodyText confidence="0.99462725">
Table 2 shows the corpus statistics used in the
experiment. The corpus is annotated with the
proposed factors. The following models are de-
veloped for the experiment.
</bodyText>
<sectionHeader confidence="0.552025" genericHeader="method">
Baseline:
</sectionHeader>
<bodyText confidence="0.9987365">
The model is developed using the default setting
values in MOSES.
</bodyText>
<subsectionHeader confidence="0.607552">
Lemma +Suffix:
</subsectionHeader>
<bodyText confidence="0.9998972">
It uses lemma and suffix factors on the source
side, lemma and suffix on the target side for
lemma to lemma and suffix to suffix translations
with generation step of lemma plus suffix to sur-
face form.
</bodyText>
<subsectionHeader confidence="0.633157">
Lemma + Suffix + Dependency Relation:
</subsectionHeader>
<bodyText confidence="0.986279333333333">
Lemma, suffix and dependency relations are used
on the source side. The translation steps are (a)
lemma to lemma (b) suffix + dependency rela-
tion to suffix and generation step is lemma + suf-
fix to surface form. Table 3 shows the BLEU and
NIST scores of the system using these factors.
Table 4 shows the BLEU and NIST scores of
the English-Manipuri SMT systems using lexica-
lized and syntactic reordering.
</bodyText>
<table confidence="0.9978822">
Model BLEU NIST
Baseline (surface) 13.045 4.25
Lemma + Suffix 15.237 4.79
Lemma + Suffix + De- 16.873 5.10
pendency Relation
</table>
<tableCaption confidence="0.9756725">
Table 3. Evaluation Scores of English - Manipuri
SMT System using various translation factors
</tableCaption>
<table confidence="0.999561">
Model Reordering BLEU NIST
Baseline 13.045 4.25
(surface)
Surface Lexicalized 13.501 4.32
Surface Syntactic 14.142 4.47
</table>
<tableCaption confidence="0.891831">
Table 4. Evaluation Scores of English-Manipuri SMT
system using Lexicalized and Syntactic Reordering
</tableCaption>
<bodyText confidence="0.383297">
Input/Output of English-Manipuri SMT:
</bodyText>
<listItem confidence="0.943656">
(1a) Input: Going to school is obligatory for stu-
dents.
</listItem>
<equation confidence="0.702454">
স্কুল েত্পা ছাত্রশিংগী ত ৌদ য়াদ্রবা মচ ৌশন |
</equation>
<bodyText confidence="0.590308181818182">
School chatpa shatra-sing-gi touda ya
draba mathouni.
Baseline output: স্কুল মচ ৌ েত্পা ওই ছাত্র
school mathou chatpa oy shatra
gloss : school duty going is student.
Syntactic Reorder output: ছাত্র স্কুল েত্পা ত ৌদ য়াদ্রবা
shatra school chatpa touda yadraba
gloss: Student school going compulsory.
Dependency output: ছাত্রশিং স্কুল েত্পা মচ ৌশন
shatrasing schoolda chatpa mathouni
gloss: Students going to the school is duty.
</bodyText>
<listItem confidence="0.911066">
(1b) Input: Krishna has a flute in his hand.
</listItem>
<equation confidence="0.753243">
কৃষ্ণগী খুত্তা ত ৌশদ্র অমা লল |
</equation>
<bodyText confidence="0.944263857142857">
Krishna-gi khut-ta toudri ama lei.
Syntactic Reorder output: কৃষ্ণ লল খুত্ অমা ত ৌশদ্র
Krishna lei khut ama toudri
gloss : Krishna has a hand flute
Dependency output: কৃষ্ণগী লল ত ৌশদ্র অমা খুত্তা
krishnagi lei toudri ama khutta
gloss : Krishna has a flute in his hand
</bodyText>
<page confidence="0.997429">
88
</page>
<bodyText confidence="0.9997176">
One of the main aspects required for the fluen-
cy of a sentence is agreement. Certain words
have to match in gender, case, number, person
etc. within a sentence. The rules of agreement are
language dependent and are closely linked to the
morphological structure of language. Subjective
evaluations on 100 sentences have been per-
formed for fluency and adequacy by two judges.
The fluency measures how well formed the sen-
tences are at the output and adequacy measures
the closeness of the output sentence with the ref-
erence translation. The Table 5 and Table 6 show
the adequacy and fluency scales used for evalua-
tion and Table 7 shows the scores of the evalua-
tion.
</bodyText>
<table confidence="0.724547">
Level Interpretation
4 Full meaning is conveyed
3 Most of the meaning is conveyed
2 Poor meaning is conveyed
1 No meaning is conveyed
</table>
<tableCaption confidence="0.984704">
Table 5. Adequacy scale
</tableCaption>
<table confidence="0.974974277777778">
Level Interpretation
4 Flawless with no grammatical error
3 Good output with minor errors
2 Disfluent ungrammatical with correct
phrase
1 Incomprehensible
Table 6. Fluency scale
Sentence Fluency Adequacy
length
Baseline &lt;=15 1.95 2.24
words
&gt;15 words 1.49 1.75
Reordered &lt;=15 2.58 2.75
words
&gt;15 words 1.82 1.96
Dependency &lt;=15 2.83 2.91
Relation words
&gt;15 words 1.94 2.10
</table>
<tableCaption confidence="0.9925315">
Table 7. Scale of Fluency and Adequacy on sentence
length basis of English-Manipuri SMT system
</tableCaption>
<subsectionHeader confidence="0.999321">
7.2 Manipuri-English SMT System
</subsectionHeader>
<bodyText confidence="0.993941166666667">
The system uses the corpus statistics shown in
Table 2. The corpus is annotated with the pro-
posed factors. The following models are devel-
oped for the experiment. The baseline and
lemma+suffix systems follow same factors as
English-Manipuri.
</bodyText>
<subsectionHeader confidence="0.489944">
Lemma + Suffix + POS:
</subsectionHeader>
<bodyText confidence="0.984140333333333">
Lemma, suffix and POS are used on the source
side. The translation steps are (a) lemma to
lemma (b) suffix + POS to POS + suffix + de-
pendency relation and generation step is lemma
+ suffix + POS + dependency relation to surface
form.
</bodyText>
<table confidence="0.99913125">
Model BLUE NIST
Baseline (surface) 13.452 4.31
Lemma + Suffix 16.137 4.89
Lemma + Suffix + POS 17.573 5.15
</table>
<tableCaption confidence="0.981861">
Table 8. Evaluation Scores of Manipuri-English SMT
system using various translation factors
</tableCaption>
<bodyText confidence="0.89071875">
Table 8 shows the BLEU and NIST scores of
the Manipuri-English systems using the different
factors. Table 9 shows the scores of using lexica-
lized reordering and POS language model.
</bodyText>
<table confidence="0.9991318">
Model BLUE NIST
Baseline + POS LM 14.341 4.52
Baseline + Lexicalized 13.743 4.46
Baseline + Lexicalized 14.843 4.71
+POS LM
</table>
<tableCaption confidence="0.957610333333333">
Table 9. Evaluation Scores of Manipuri-English SMT
system using Lexicalized reordering and POS Lan-
guage Model
</tableCaption>
<bodyText confidence="0.392383">
Input/Output ofManipuri-English SMT:
</bodyText>
<listItem confidence="0.908993333333333">
(2a) Input: স্কুল েত্পা ছাত্রশিংগী ত ৌদ য়াদ্রবা মচ ৌশন |
gloss: School chatpa shatra-sing-gi touda
yadraba mathouni.
</listItem>
<bodyText confidence="0.988883142857143">
Going to school is obligatory for students.
Baseline output: school going to the students
important
Lexicalized Reordered output: school going
important to the students
Lemma+Suffix+POS+lexicalized reordered
output: School going important to the students
</bodyText>
<listItem confidence="0.733926">
(2b) Input: কৃষ্ণগী খুত্তা ত ৌশদ্র অমা লল |
</listItem>
<bodyText confidence="0.9744304">
gloss: Krishna-gi khut-ta toudri ama lei.
Krishna has a flute in his hand.
Baseline output: Krishna is flute and hand
Lexicalized Reordered output: Krishna flute
has his hand
</bodyText>
<page confidence="0.999296">
89
</page>
<bodyText confidence="0.991564833333333">
Lemma+Suffix+POS+lexicalized reordered
output: Krishna has flute his hand
By considering the lemma along with suffix
and POS factors, the fluency and adequacy of the
output is better addressed as given by the sample
input and output (2a) and (2b) over the baseline
system. Using the Manipuri stemmer, the case
markers and suffixes are taken into account for
different possible word forms thereby helping to
overcome the data sparseness problem. Table 10
shows the scores of adequacy and fluency of the
evaluation.
</bodyText>
<table confidence="0.998673">
Sentence Fluency Adequacy
length
Baseline &lt;=15 1.93 2.31
words
&gt;15 words 1.51 1.76
Reordered &lt;=15 2.48 2.85
words
&gt;15 words 1.83 1.97
Lemma + &lt;=15 2.86 2.92
Suffix words
+ POS
&gt;15 words 2.01 2.11
</table>
<tableCaption confidence="0.984713">
Table 10. Scale of Fluency and Adequacy on sen-
tence length basis of Manipuri-English SMT system
</tableCaption>
<bodyText confidence="0.999913214285714">
Subjective evaluations on 100 sentences have
been performed for fluency and adequacy. In the
process of subjective evaluation, sentences were
judged on fluency, adequacy and the number of
errors in case marking/morphology. It is ob-
served that poor word-order makes the baseline
output almost incomprehensible, while lexica-
lized reordering solves the problem correctly
along with parts-of-speech language model (POS
LM). Statistical significant test is performed to
judge if a change in score that comes from a
change in the system reflects a change in overall
translation quality. It is found that all the differ-
ences are significant at the 99% level.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="method">
8 Discussion
</sectionHeader>
<bodyText confidence="0.888504777777778">
The factored approach using the proposed factors
show improved fluency and adequacy at the Ma-
nipuri output for English-Manipuri system as
shown in the Table 6. Using the Stanford gener-
ated relations shows an improvement in terms of
fluency and adequacy for shorter sentences than
the longer ones.
Input : Khamba pushed the stone with a lever.
খম্বনো জম্ফত্নো নুং অদু ইল্লম্মী |
</bodyText>
<sectionHeader confidence="0.332211" genericHeader="method">
Outputs:
</sectionHeader>
<subsectionHeader confidence="0.400919">
Syntactic Reordered: খম্ব নুং জম্ফত্ অদু ইল্লল্ল |
</subsectionHeader>
<bodyText confidence="0.902428">
Khamba nung jamfat adu illi
gloss: Khamba stone the lever push
Dependency: খম্বনো নুং অদু জম্ফত্নো ইল্লল্ল |
Khambana nung adu jamfatna illi
gloss: Khamba the stone pushed with lever
By the use of semantic relation, নো (na) is at-
tached to খম্ব (Khamba), which makes the mean-
ing খম্বনো “by Khamba” instead of just খম্ব
“Khamba”.
</bodyText>
<equation confidence="0.607059">
Input : Suddenly the woman burst into tears.
খঙব ৌদনো বমৌ অদুনো মল্লি ল্লিন্থরকই |
</equation>
<sectionHeader confidence="0.471055" genericHeader="method">
Outputs:
</sectionHeader>
<bodyText confidence="0.8917985">
Syntactic Reordered: নুিী থুনো ল্লিরোংগো কপ্পী |
Nupi thuna pirang-ga kappi
gloss: woman soon tears cry
Dependency: অথু দো নুিীদু কপ্লম্মী |
Athubada nupidu kaplammi
gloss: suddenly the woman cried
Here, in this example, the নুিী (nupi) is suf-
fixed by the দু (du), to produce নুিীদু “the wom-
an” instead of just নুিী “woman”.
The factored approach of Manipuri-English
SMT system also shows improved BLEU and
NIST scores using the proposed factors as shown
in Table 8 not only gain in fluency and adequacy
scores as shown in Table 10.
</bodyText>
<sectionHeader confidence="0.996766" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999959928571429">
A framework for Manipuri and English bidirec-
tional SMT system using factored model is expe-
rimented with a goal to improve the translation
output and reduce the amount of training data.
The output of the translation is improved by in-
corporating morphological information and se-
mantic relations by tighter integration. The
systems are evaluated using automatic scoring
techniques BLEU and NIST. The subjective
evaluation of the systems is done to find out the
fluency and adequacy. The fluency and adequacy
are also addressed better for the shorter sentences
than the longer ones using semantic relations.
The improvement is statistically significant.
</bodyText>
<page confidence="0.997084">
90
</page>
<sectionHeader confidence="0.995791" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999465989010989">
Avramidis, E. and Koehn, P. 2008. Enriching mor-
phologically poor languages for Statistical Machine
Translation, Proceedings of ACL-08: HLT
Callison-Burch, Chris., Osborne, M. and Koehn, P.
2006. Re-evaluating the Role of Bleu in Machine
Translation Research&amp;quot; In Proceedings of EACL-
2006
Doddington, G. 2002. Automatic evaluation of Ma-
chine Translation quality using n-gram co-
occurrence statistics. In Proceedings of HLT 2002,
San Diego, CA.
Koehn. P., and Hoang, H. 2007. Factored Translation
Models, In Proceedings of EMNLP-2007
Koehn, P., Hieu, H., Alexandra, B., Chris, C., Marcel-
lo, F., Nicola, B., Brooke, C., Wade, S., Christine,
M., Richard, Z., Chris, D., Ondrej, B., Alexandra,
C., Evan, H. 2007. Moses: Open Source Toolkit for
Statistical Machine Translation, Proceedings of the
ACL 2007 Demo and Poster Sessions, pages 177–
180, Prague.
Marie-Catherine de Marneffe and Manning, C. 2008.
Stanford Typed Dependency Manual
Minnen, G., Carroll, J., and Pearce, D. 2001. Applied
Morphological Processing of English, Natural
Language Engineering, 7(3), pages 207-223
Niepen, S., and Ney, H. 2004. Statistical Machine
Translation with Scarce Resources Using Morpho-
syntactic Information, Computational Linguistics,
30(2), pages 181-204
Och, F. 2003. Minimum error rate training in Statis-
tical Machine Translation , Proceedings of ACL
Papineni, K., Roukos, S., Ward, T., and Zhu, W.
2002. BLEU: a method for automatic evaluation of
machine translation. In Proceedings of 40th ACL,
Philadelphia, PA
Popovic, M., and Ney, H. 2006. Statistical Machine
Translation with a small amount of bilingual train-
ing data, 5th LREC SALTMIL Workshop on Minor-
ity Languages
Ramanathan, A., Choudhury, H., Ghosh, A., and
Bhattacharyya, P. 2009. Case markers and Mor-
phology: Addressing the crux of the fluency prob-
lem in English-Hindi SMT, Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vo-
lume 2, pages: 800-808
Rao, D., Mohanraj, K., Hegde, J., Mehta, V. and Ma-
hadane, P. 2000. A practical framework for syntac-
tic transfer of compound-complex sentences for
English-Hindi Machine Translation, Proceedings
of KBCS 2000, pages 343-354
Singh, Thoudam D., and Bandyopadhyay, S. 2006.
Word Class and Sentence Type Identification in
Manipuri Morphological Analyzer, Proceeding of
Modeling and Shallow Parsing of Indian Languag-
es(MSPIL) 2006, IIT Bombay, pages 11-17, Mum-
bai, India
Singh, Thoudam D., and Bandyopadhyay, S. 2008.
Morphology Driven Manipuri POS Tagger, In pro-
ceedings International Joint Conference on Natu-
ral Language Processing (IJCNLP-08) Workshop
on Natural Language Processing of Less Privi-
leged Languages (NLPLPL) 2008, pages 91-98,
Hyderabad, India
Singh, Thoudam D., and Bandyopadhyay, S. 2010a.
Manipuri-English Example Based Machine Trans-
lation System, International Journal of Computa-
tional Linguistics and Applications (IJCLA), ISSN
0976-0962, pages 147-158
Singh, Thoudam D., Singh, Yengkhom R. and Ban-
dyopadhyay, S., 2010b. Manipuri-English Semi
Automatic Parallel Corpora Extraction from Web,
In proceedings of 23rd International Conference
on the Computer Processing of Oriental Languag-
es (ICCPOL 2010) - New Generation in Asian In-
formation Processing , San Francisco Bay, CA,
USA, Pages 45-48
Singh, Thoudam D. and Bandyopadhyay, S., 2010c.
Statistical Machine Translation of English-
Manipuri using Morpho-Syntactic and Semantic
Information, In the proceedings of Ninth Confe-
rence of the Association for Machine Translation
in Americas (AMTA 2010), Denver, Colorado,
USA. (To appear)
Stolcke. A. 2002. SRILM - An Extensible Language
Modeling Toolkit. In Proc. Intl. Conf. Spoken Lan-
guage Processing, Denver, Colorado, September.
Wang, C., Collin, M., and Koehn, P. 2007. Chinese
syntactic reordering for statistical machine transla-
tion, Proceedings of EMNLP-CoNLL
</reference>
<page confidence="0.999166">
91
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.836720">
<title confidence="0.9992285">Manipuri-English Bidirectional Statistical Translation Systems using Morphology and Dependency Relations</title>
<author confidence="0.999637">Thoudam Doren</author>
<affiliation confidence="0.999871">Department of Computer Science Jadavpur University</affiliation>
<email confidence="0.997756">thoudam.doren@gmail.com</email>
<author confidence="0.878207">Sivaji</author>
<affiliation confidence="0.9997275">Department of Computer Science Jadavpur University</affiliation>
<email confidence="0.957322">sivaji_cse_ju@yahoo.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Avramidis</author>
<author>P Koehn</author>
</authors>
<title>Enriching morphologically poor languages for Statistical Machine Translation,</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT</booktitle>
<contexts>
<context position="4744" citStr="Avramidis and Koehn, 2008" startWordPosition="713" endWordPosition="716">04). It introduces sentence level restructuring transformations that aim at the assimilation of word order in related sentences and exploitation of the bilingual training data by explicitly taking into account the interdependencies of related inflected forms thereby improving the translation quality. Popovic and Ney (2006) discussed SMT with a small amount of bilingual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avramidis and Koehn, 2008). In this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase. Resolution of verb conjugation is done by identifying the person of a verb and using the linguistic information tag. Manipuri to English Example Based Machine Translation system is reported in (Singh and Bandyopadhyay, 2010a) on news domain. For this, POS tagging, morphological analysis, NER and chunking are applied on the parallel corpus for phrase level alignment. Chunks are aligned using a dynamic programming “edit-distance style” alignment algo</context>
</contexts>
<marker>Avramidis, Koehn, 2008</marker>
<rawString>Avramidis, E. and Koehn, P. 2008. Enriching morphologically poor languages for Statistical Machine Translation, Proceedings of ACL-08: HLT</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>Re-evaluating the Role of Bleu in Machine Translation Research&amp;quot;</title>
<date>2006</date>
<booktitle>In Proceedings of EACL2006</booktitle>
<marker>Callison-Burch, Osborne, Koehn, 2006</marker>
<rawString>Callison-Burch, Chris., Osborne, M. and Koehn, P. 2006. Re-evaluating the Role of Bleu in Machine Translation Research&amp;quot; In Proceedings of EACL2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic evaluation of Machine Translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT 2002,</booktitle>
<location>San Diego, CA.</location>
<contexts>
<context position="17391" citStr="Doddington, 2002" startWordPosition="2685" endWordPosition="2686">. gz Lemma Case Marker Suffix/ Case Marker Word Lemma POS word 87 stemmer from Manipuri Morphological analyzer (Singh and Bandyopadhyay, 2006) was used for the Manipuri side. ■ Manipuri POS tagger (Singh et. al., 2008) is used to tag the POS (Parts of speech) factors of the input Manipuri sentences. 7 Evaluation 7.1 English-Manipuri SMT System The evaluation of the machine translation systems developed in the present work is done in two approaches using automatic scoring with reference translation and subjective evaluation as discussed in (Ramanathan et al., 2009). Evaluation Metrics: ■ NIST (Doddington, 2002): A high score means a better translation by measuring the precision of n-gram. ■ BLEU (Papineni et al, 2002): This metric gives the precision of n-gram with respect to the reference translation but with a brevity penalty. No ofsentences No of words Training 10350 296728 Development 600 16520 Test 500 15204 Table 2. Training, development and testing corpus statistics Table 2 shows the corpus statistics used in the experiment. The corpus is annotated with the proposed factors. The following models are developed for the experiment. Baseline: The model is developed using the default setting value</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>Doddington, G. 2002. Automatic evaluation of Machine Translation quality using n-gram cooccurrence statistics. In Proceedings of HLT 2002, San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P</author>
<author>H Hoang</author>
</authors>
<title>Factored Translation Models,</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-2007</booktitle>
<marker>P, Hoang, 2007</marker>
<rawString>Koehn. P., and Hoang, H. 2007. Factored Translation Models, In Proceedings of EMNLP-2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hieu</author>
<author>B Alexandra</author>
<author>C Chris</author>
<author>F Marcello</author>
<author>B Nicola</author>
<author>C Brooke</author>
<author>S Wade</author>
<author>M Christine</author>
<author>Z Richard</author>
<author>D Chris</author>
<author>B Ondrej</author>
<author>C Alexandra</author>
<author>H Evan</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation,</title>
<date>2007</date>
<booktitle>Proceedings of the ACL 2007 Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague.</location>
<marker>Koehn, Hieu, Alexandra, Chris, Marcello, Nicola, Brooke, Wade, Christine, Richard, Chris, Ondrej, Alexandra, Evan, 2007</marker>
<rawString>Koehn, P., Hieu, H., Alexandra, B., Chris, C., Marcello, F., Nicola, B., Brooke, C., Wade, S., Christine, M., Richard, Z., Chris, D., Ondrej, B., Alexandra, C., Evan, H. 2007. Moses: Open Source Toolkit for Statistical Machine Translation, Proceedings of the ACL 2007 Demo and Poster Sessions, pages 177– 180, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>C Manning</author>
</authors>
<date>2008</date>
<institution>Stanford Typed Dependency Manual</institution>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Manning, C. 2008. Stanford Typed Dependency Manual</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Minnen</author>
<author>J Carroll</author>
<author>D Pearce</author>
</authors>
<date>2001</date>
<journal>Applied Morphological Processing of English, Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>207--223</pages>
<contexts>
<context position="16534" citStr="Minnen et al., 2001" startWordPosition="2572" endWordPosition="2575"> the experiment are: ■ Stanford Dependency Parser4 was used to (i) generate the dependency relations and (ii) syntactic reordering of the input English sentences using Parse::RecDescent module. ■ Moses5 toolkit (Koehn, 2007) was used for training with GIZA++6, decoding and minimum error rate training (Och, 2003) for tuning. ■ SRILM7 toolkit (Stolcke, 2002) was used to build language models with 10350 Manipuri sentences for English-Manipuri system and four and a half million English wordforms collected from the news domain for Manipuri-English system. ■ English morphological analyzer morpha 8 (Minnen et al., 2001) was used and the 4 http://nlp.stanford.edu/software/lex-parser.shtml 5 http://www.statmt.org/moses/ 6 http://www.fjoch.com/GIZA++.html 7 http://www.speech.sri.com/projects/srilm 8 ftp://ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar. gz Lemma Case Marker Suffix/ Case Marker Word Lemma POS word 87 stemmer from Manipuri Morphological analyzer (Singh and Bandyopadhyay, 2006) was used for the Manipuri side. ■ Manipuri POS tagger (Singh et. al., 2008) is used to tag the POS (Parts of speech) factors of the input Manipuri sentences. 7 Evaluation 7.1 English-Manipuri SMT System The evaluation</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Minnen, G., Carroll, J., and Pearce, D. 2001. Applied Morphological Processing of English, Natural Language Engineering, 7(3), pages 207-223</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Niepen</author>
<author>H Ney</author>
</authors>
<date>2004</date>
<booktitle>Statistical Machine Translation with Scarce Resources Using Morphosyntactic Information, Computational Linguistics,</booktitle>
<volume>30</volume>
<issue>2</issue>
<pages>181--204</pages>
<contexts>
<context position="4121" citStr="Niepen and Ney, 2004" startWordPosition="615" endWordPosition="618">sed is in news domain which have been collected, cleaned and aligned (Singh et al., 2010b) from the Sangai Express newspaper website www.thesangaiexpress.com available in both Manipuri and English. A daily basis collection was done covering the period from May 2008 to November 2008 since there is no repository. 2 Related Works Koehn and Hoang (2007) developed a framework for statistical translation models that tightly integrates additional morphological, syntactic, or semantic information. Statistical Machine Translation with scarce resources using morphosyntactic information is discussed in (Niepen and Ney, 2004). It introduces sentence level restructuring transformations that aim at the assimilation of word order in related sentences and exploitation of the bilingual training data by explicitly taking into account the interdependencies of related inflected forms thereby improving the translation quality. Popovic and Ney (2006) discussed SMT with a small amount of bilingual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avr</context>
</contexts>
<marker>Niepen, Ney, 2004</marker>
<rawString>Niepen, S., and Ney, H. 2004. Statistical Machine Translation with Scarce Resources Using Morphosyntactic Information, Computational Linguistics, 30(2), pages 181-204</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
</authors>
<title>Minimum error rate training in Statistical Machine Translation ,</title>
<date>2003</date>
<booktitle>Proceedings of ACL</booktitle>
<contexts>
<context position="11534" citStr="Och, 2003" startWordPosition="1795" endWordPosition="1796">Components in Factored Model Factored translation model is the combination of several components including language model, reordering model, translation steps and generation steps in a log-linear model3: (1) Z is a normalization constant that is ignored in practice. To compute the probability of a translation e given an input sentence f, we have to evaluate each feature function hi. The feature weight 2http://www.statmt.org/moses/?n=Moses.FactoredModels 3http://www.statmt.org/moses/?n=Moses.FactoredModels 85 λi in the log linear model is determined by using minimum error rate training method (Och, 2003). For a translation step component, each feature function ht is defined over the phrase pairs (fj,ej) given a scoring function τ: For the generation step component, each feature function hg given a scoring function γ is defined over the output words ek only: 5.2 Stanford Dependency Parser The dependency relations used in the experiment are generated by the Stanford dependency parser (Marie-Catherine de Marneffe and Manning, 2008). This parser uses 55 relations to express the dependencies among the various words in a sentence. The dependencies are all binary relations: a grammatical relation ho</context>
<context position="16227" citStr="Och, 2003" startWordPosition="2526" endWordPosition="2527">he output side and exploiting them with 7-gram sequence models (as shown in Figure 4) results in minor improvements in BLEU score. 6 Experimental Setup A number of experiments have been carried out using factored translation framework and incorporating linguistic information. The toolkits used in the experiment are: ■ Stanford Dependency Parser4 was used to (i) generate the dependency relations and (ii) syntactic reordering of the input English sentences using Parse::RecDescent module. ■ Moses5 toolkit (Koehn, 2007) was used for training with GIZA++6, decoding and minimum error rate training (Och, 2003) for tuning. ■ SRILM7 toolkit (Stolcke, 2002) was used to build language models with 10350 Manipuri sentences for English-Manipuri system and four and a half million English wordforms collected from the news domain for Manipuri-English system. ■ English morphological analyzer morpha 8 (Minnen et al., 2001) was used and the 4 http://nlp.stanford.edu/software/lex-parser.shtml 5 http://www.statmt.org/moses/ 6 http://www.fjoch.com/GIZA++.html 7 http://www.speech.sri.com/projects/srilm 8 ftp://ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar. gz Lemma Case Marker Suffix/ Case Marker Word Lemma</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. 2003. Minimum error rate training in Statistical Machine Translation , Proceedings of ACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th ACL,</booktitle>
<location>Philadelphia, PA</location>
<contexts>
<context position="17500" citStr="Papineni et al, 2002" startWordPosition="2702" endWordPosition="2705">lyzer (Singh and Bandyopadhyay, 2006) was used for the Manipuri side. ■ Manipuri POS tagger (Singh et. al., 2008) is used to tag the POS (Parts of speech) factors of the input Manipuri sentences. 7 Evaluation 7.1 English-Manipuri SMT System The evaluation of the machine translation systems developed in the present work is done in two approaches using automatic scoring with reference translation and subjective evaluation as discussed in (Ramanathan et al., 2009). Evaluation Metrics: ■ NIST (Doddington, 2002): A high score means a better translation by measuring the precision of n-gram. ■ BLEU (Papineni et al, 2002): This metric gives the precision of n-gram with respect to the reference translation but with a brevity penalty. No ofsentences No of words Training 10350 296728 Development 600 16520 Test 500 15204 Table 2. Training, development and testing corpus statistics Table 2 shows the corpus statistics used in the experiment. The corpus is annotated with the proposed factors. The following models are developed for the experiment. Baseline: The model is developed using the default setting values in MOSES. Lemma +Suffix: It uses lemma and suffix factors on the source side, lemma and suffix on the targe</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of 40th ACL, Philadelphia, PA</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popovic</author>
<author>H Ney</author>
</authors>
<title>Statistical Machine Translation with a small amount of bilingual training data,</title>
<date>2006</date>
<booktitle>5th LREC SALTMIL Workshop on Minority Languages</booktitle>
<contexts>
<context position="4442" citStr="Popovic and Ney (2006)" startWordPosition="662" endWordPosition="665">ed Works Koehn and Hoang (2007) developed a framework for statistical translation models that tightly integrates additional morphological, syntactic, or semantic information. Statistical Machine Translation with scarce resources using morphosyntactic information is discussed in (Niepen and Ney, 2004). It introduces sentence level restructuring transformations that aim at the assimilation of word order in related sentences and exploitation of the bilingual training data by explicitly taking into account the interdependencies of related inflected forms thereby improving the translation quality. Popovic and Ney (2006) discussed SMT with a small amount of bilingual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avramidis and Koehn, 2008). In this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase. Resolution of verb conjugation is done by identifying the person of a verb and using the linguistic information tag. Manipuri to English Example Based</context>
</contexts>
<marker>Popovic, Ney, 2006</marker>
<rawString>Popovic, M., and Ney, H. 2006. Statistical Machine Translation with a small amount of bilingual training data, 5th LREC SALTMIL Workshop on Minority Languages</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ramanathan</author>
<author>H Choudhury</author>
<author>A Ghosh</author>
<author>P Bhattacharyya</author>
</authors>
<title>Case markers and Morphology: Addressing the crux of the fluency problem in English-Hindi SMT,</title>
<date>2009</date>
<booktitle>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>800--808</pages>
<contexts>
<context position="4630" citStr="Ramanathan et al., 2009" startWordPosition="695" endWordPosition="698"> Machine Translation with scarce resources using morphosyntactic information is discussed in (Niepen and Ney, 2004). It introduces sentence level restructuring transformations that aim at the assimilation of word order in related sentences and exploitation of the bilingual training data by explicitly taking into account the interdependencies of related inflected forms thereby improving the translation quality. Popovic and Ney (2006) discussed SMT with a small amount of bilingual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avramidis and Koehn, 2008). In this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase. Resolution of verb conjugation is done by identifying the person of a verb and using the linguistic information tag. Manipuri to English Example Based Machine Translation system is reported in (Singh and Bandyopadhyay, 2010a) on news domain. For this, POS tagging, morphological analysis, NER and chunking are applied on the parallel corp</context>
<context position="17344" citStr="Ramanathan et al., 2009" startWordPosition="2677" endWordPosition="2680">/ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar. gz Lemma Case Marker Suffix/ Case Marker Word Lemma POS word 87 stemmer from Manipuri Morphological analyzer (Singh and Bandyopadhyay, 2006) was used for the Manipuri side. ■ Manipuri POS tagger (Singh et. al., 2008) is used to tag the POS (Parts of speech) factors of the input Manipuri sentences. 7 Evaluation 7.1 English-Manipuri SMT System The evaluation of the machine translation systems developed in the present work is done in two approaches using automatic scoring with reference translation and subjective evaluation as discussed in (Ramanathan et al., 2009). Evaluation Metrics: ■ NIST (Doddington, 2002): A high score means a better translation by measuring the precision of n-gram. ■ BLEU (Papineni et al, 2002): This metric gives the precision of n-gram with respect to the reference translation but with a brevity penalty. No ofsentences No of words Training 10350 296728 Development 600 16520 Test 500 15204 Table 2. Training, development and testing corpus statistics Table 2 shows the corpus statistics used in the experiment. The corpus is annotated with the proposed factors. The following models are developed for the experiment. Baseline: The mod</context>
</contexts>
<marker>Ramanathan, Choudhury, Ghosh, Bhattacharyya, 2009</marker>
<rawString>Ramanathan, A., Choudhury, H., Ghosh, A., and Bhattacharyya, P. 2009. Case markers and Morphology: Addressing the crux of the fluency problem in English-Hindi SMT, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages: 800-808</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rao</author>
<author>K Mohanraj</author>
<author>J Hegde</author>
<author>V Mehta</author>
<author>P Mahadane</author>
</authors>
<title>A practical framework for syntactic transfer of compound-complex sentences for English-Hindi Machine Translation,</title>
<date>2000</date>
<booktitle>Proceedings of KBCS</booktitle>
<pages>343--354</pages>
<contexts>
<context position="6692" citStr="Rao et al., 2000" startWordPosition="1012" endWordPosition="1015">ntified as important translation factors. 3 Syntactic Reordering This is a preprocessing step applied to the input English sentences for English-Manipuri SMT system. The program for syntactic reordering uses the parse trees generated by Stanford parser1 and applies a handful of reordering rules written using perl module Parse::RecDescent. By doing this, the SVO order of English is changed to SOV order for Manipuri, and post modifiers are converted to pre-modifiers. The basic difference of Manipuri phrase order compared to English is handled by reordering the input sentence following the rule (Rao et al., 2000): SSmV VmOOmCm  C&apos;mS&apos;mS&apos;O&apos;mO&apos;V&apos;mV&apos; where, S: Subject O: Object V : Verb Cm: Clause modifier X&apos;: Corresponding constituent in Manipuri, where X is S, O, or V Xm: modifier of X There are two reasons why the syntactic reordering approach improves over the baseline phrase-based SMT system (Wang et al., 2007). One obvious benefit is that the word order of the transformed source sentence is much closer to the target sentence, which reduces the reliance on the distortion model to perform reordering during decoding. Another potential benefit is that the alignment between the two sides will be of high</context>
</contexts>
<marker>Rao, Mohanraj, Hegde, Mehta, Mahadane, 2000</marker>
<rawString>Rao, D., Mohanraj, K., Hegde, J., Mehta, V. and Mahadane, P. 2000. A practical framework for syntactic transfer of compound-complex sentences for English-Hindi Machine Translation, Proceedings of KBCS 2000, pages 343-354</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thoudam D Singh</author>
<author>S Bandyopadhyay</author>
</authors>
<title>Word Class and Sentence Type Identification</title>
<date>2006</date>
<booktitle>in Manipuri Morphological Analyzer, Proceeding of Modeling and Shallow Parsing of Indian Languages(MSPIL) 2006, IIT Bombay,</booktitle>
<pages>11--17</pages>
<location>Mumbai, India</location>
<contexts>
<context position="7933" citStr="Singh and Bandyopadhyay, 2006" startWordPosition="1212" endWordPosition="1216">because of fewer “distortions” between the source and the target, so that the resulting phrase table of the reordered system would be better. However, a counter argument is that the reordering is very error prone, so that the added noise in the reordered data actually hurts the alignments and hence the phrase tables. 1 http://nlp.stanford.edu/software/lex-parser.shtml 84 4 Morphology The affixes are the determining factor of the word class in Manipuri. In this agglutinative language the number of verbal suffixes is more than that of nominal suffixes. Works on Manipuri morphology are found in (Singh and Bandyopadhyay, 2006) and (Singh and Bandyopadhyay, 2008). In this language, a verb must minimally consist of a verb root and an inflectional suffix. A noun may be optionally affixed by derivational morphemes indicating gender, number and quantity. Further, a noun may be prefixed by a pronominal prefix which indicates its possessor. Words in Manipuri consist of stems or bound roots with suffixes (from one to ten suffixes), prefixes (only one per word) and/or enclitics. (a) ইব োমচো--qT ব োল-vk কোওই Ibomcha-na Ball-du kao-i Ibomcha-nom Ball-distal kick Ibomcha kicks the ball. (b) ব োল-vk ইব োমচো--qT কোওই Ball-du Ibo</context>
<context position="16916" citStr="Singh and Bandyopadhyay, 2006" startWordPosition="2608" endWordPosition="2611">uild language models with 10350 Manipuri sentences for English-Manipuri system and four and a half million English wordforms collected from the news domain for Manipuri-English system. ■ English morphological analyzer morpha 8 (Minnen et al., 2001) was used and the 4 http://nlp.stanford.edu/software/lex-parser.shtml 5 http://www.statmt.org/moses/ 6 http://www.fjoch.com/GIZA++.html 7 http://www.speech.sri.com/projects/srilm 8 ftp://ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar. gz Lemma Case Marker Suffix/ Case Marker Word Lemma POS word 87 stemmer from Manipuri Morphological analyzer (Singh and Bandyopadhyay, 2006) was used for the Manipuri side. ■ Manipuri POS tagger (Singh et. al., 2008) is used to tag the POS (Parts of speech) factors of the input Manipuri sentences. 7 Evaluation 7.1 English-Manipuri SMT System The evaluation of the machine translation systems developed in the present work is done in two approaches using automatic scoring with reference translation and subjective evaluation as discussed in (Ramanathan et al., 2009). Evaluation Metrics: ■ NIST (Doddington, 2002): A high score means a better translation by measuring the precision of n-gram. ■ BLEU (Papineni et al, 2002): This metric gi</context>
</contexts>
<marker>Singh, Bandyopadhyay, 2006</marker>
<rawString>Singh, Thoudam D., and Bandyopadhyay, S. 2006. Word Class and Sentence Type Identification in Manipuri Morphological Analyzer, Proceeding of Modeling and Shallow Parsing of Indian Languages(MSPIL) 2006, IIT Bombay, pages 11-17, Mumbai, India</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thoudam D Singh</author>
<author>S Bandyopadhyay</author>
</authors>
<title>Morphology Driven Manipuri POS Tagger,</title>
<date>2008</date>
<booktitle>In proceedings International Joint Conference on Natural Language Processing (IJCNLP-08) Workshop on Natural Language Processing of Less Privileged Languages (NLPLPL)</booktitle>
<pages>91--98</pages>
<location>Hyderabad, India</location>
<contexts>
<context position="7969" citStr="Singh and Bandyopadhyay, 2008" startWordPosition="1218" endWordPosition="1221">en the source and the target, so that the resulting phrase table of the reordered system would be better. However, a counter argument is that the reordering is very error prone, so that the added noise in the reordered data actually hurts the alignments and hence the phrase tables. 1 http://nlp.stanford.edu/software/lex-parser.shtml 84 4 Morphology The affixes are the determining factor of the word class in Manipuri. In this agglutinative language the number of verbal suffixes is more than that of nominal suffixes. Works on Manipuri morphology are found in (Singh and Bandyopadhyay, 2006) and (Singh and Bandyopadhyay, 2008). In this language, a verb must minimally consist of a verb root and an inflectional suffix. A noun may be optionally affixed by derivational morphemes indicating gender, number and quantity. Further, a noun may be prefixed by a pronominal prefix which indicates its possessor. Words in Manipuri consist of stems or bound roots with suffixes (from one to ten suffixes), prefixes (only one per word) and/or enclitics. (a) ইব োমচো--qT ব োল-vk কোওই Ibomcha-na Ball-du kao-i Ibomcha-nom Ball-distal kick Ibomcha kicks the ball. (b) ব োল-vk ইব োমচো--qT কোওই Ball-du Ibomcha-na kao-i Ball-distal Ibomcha-no</context>
</contexts>
<marker>Singh, Bandyopadhyay, 2008</marker>
<rawString>Singh, Thoudam D., and Bandyopadhyay, S. 2008. Morphology Driven Manipuri POS Tagger, In proceedings International Joint Conference on Natural Language Processing (IJCNLP-08) Workshop on Natural Language Processing of Less Privileged Languages (NLPLPL) 2008, pages 91-98, Hyderabad, India</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thoudam D Singh</author>
<author>S Bandyopadhyay</author>
</authors>
<title>Manipuri-English Example Based Machine Translation System,</title>
<date>2010</date>
<booktitle>International Journal of Computational Linguistics and Applications (IJCLA), ISSN 0976-0962,</booktitle>
<pages>147--158</pages>
<contexts>
<context position="5115" citStr="Singh and Bandyopadhyay, 2010" startWordPosition="771" endWordPosition="774">ual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avramidis and Koehn, 2008). In this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase. Resolution of verb conjugation is done by identifying the person of a verb and using the linguistic information tag. Manipuri to English Example Based Machine Translation system is reported in (Singh and Bandyopadhyay, 2010a) on news domain. For this, POS tagging, morphological analysis, NER and chunking are applied on the parallel corpus for phrase level alignment. Chunks are aligned using a dynamic programming “edit-distance style” alignment algorithm. The translation process initially looks for an exact match in the parallel example base and returns the retrieved target output. Otherwise, the maximal match source sentence is identified. For word level mismatch, the unmatched words in the input are either translated from the lexicon or transliterated. Unmatched phrases are looked into the phrase level parallel</context>
</contexts>
<marker>Singh, Bandyopadhyay, 2010</marker>
<rawString>Singh, Thoudam D., and Bandyopadhyay, S. 2010a. Manipuri-English Example Based Machine Translation System, International Journal of Computational Linguistics and Applications (IJCLA), ISSN 0976-0962, pages 147-158</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thoudam D Singh</author>
<author>Yengkhom R Singh</author>
<author>S Bandyopadhyay</author>
</authors>
<title>Manipuri-English Semi Automatic Parallel Corpora Extraction from Web,</title>
<date>2010</date>
<booktitle>In proceedings of 23rd International Conference on the Computer Processing of Oriental Languages (ICCPOL 2010) - New Generation in Asian Information Processing ,</booktitle>
<pages>45--48</pages>
<location>San Francisco Bay, CA, USA,</location>
<contexts>
<context position="3588" citStr="Singh et al., 2010" startWordPosition="540" endWordPosition="543">ne the dependency relations. Using these translation factors, the output of the translation quality is improved as indicated by baseline BLEU score of 13.452 and factored BLEU score of 17.573 respectively. Further, the subjective evaluation indicates the improvement in the fluency and adequacy of both the factored SMT outputs over the respective baseline systems. 83 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 83–91, COLING 2010, Beijing, August 2010. The parallel corpora used is in news domain which have been collected, cleaned and aligned (Singh et al., 2010b) from the Sangai Express newspaper website www.thesangaiexpress.com available in both Manipuri and English. A daily basis collection was done covering the period from May 2008 to November 2008 since there is no repository. 2 Related Works Koehn and Hoang (2007) developed a framework for statistical translation models that tightly integrates additional morphological, syntactic, or semantic information. Statistical Machine Translation with scarce resources using morphosyntactic information is discussed in (Niepen and Ney, 2004). It introduces sentence level restructuring transformations that a</context>
</contexts>
<marker>Singh, Singh, Bandyopadhyay, 2010</marker>
<rawString>Singh, Thoudam D., Singh, Yengkhom R. and Bandyopadhyay, S., 2010b. Manipuri-English Semi Automatic Parallel Corpora Extraction from Web, In proceedings of 23rd International Conference on the Computer Processing of Oriental Languages (ICCPOL 2010) - New Generation in Asian Information Processing , San Francisco Bay, CA, USA, Pages 45-48</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thoudam D Singh</author>
<author>S Bandyopadhyay</author>
</authors>
<title>Statistical Machine Translation of EnglishManipuri using Morpho-Syntactic and Semantic Information,</title>
<date>2010</date>
<booktitle>In the proceedings of Ninth Conference of the Association for Machine Translation in Americas (AMTA 2010),</booktitle>
<location>Denver, Colorado, USA.</location>
<note>(To appear)</note>
<contexts>
<context position="5115" citStr="Singh and Bandyopadhyay, 2010" startWordPosition="771" endWordPosition="774">ual training data. Case markers and morphology are used to address the crux of fluency in the English-Hindi SMT system (Ramanathan et al., 2009). Work on translating from rich to poor morphology using factored model is reported in (Avramidis and Koehn, 2008). In this method of enriching input, the case agreement for nouns, adjectives and articles are mainly defined by the syntactic role of each phrase. Resolution of verb conjugation is done by identifying the person of a verb and using the linguistic information tag. Manipuri to English Example Based Machine Translation system is reported in (Singh and Bandyopadhyay, 2010a) on news domain. For this, POS tagging, morphological analysis, NER and chunking are applied on the parallel corpus for phrase level alignment. Chunks are aligned using a dynamic programming “edit-distance style” alignment algorithm. The translation process initially looks for an exact match in the parallel example base and returns the retrieved target output. Otherwise, the maximal match source sentence is identified. For word level mismatch, the unmatched words in the input are either translated from the lexicon or transliterated. Unmatched phrases are looked into the phrase level parallel</context>
</contexts>
<marker>Singh, Bandyopadhyay, 2010</marker>
<rawString>Singh, Thoudam D. and Bandyopadhyay, S., 2010c. Statistical Machine Translation of EnglishManipuri using Morpho-Syntactic and Semantic Information, In the proceedings of Ninth Conference of the Association for Machine Translation in Americas (AMTA 2010), Denver, Colorado, USA. (To appear)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proc. Intl. Conf. Spoken Language Processing,</booktitle>
<location>Denver, Colorado,</location>
<marker>A, 2002</marker>
<rawString>Stolcke. A. 2002. SRILM - An Extensible Language Modeling Toolkit. In Proc. Intl. Conf. Spoken Language Processing, Denver, Colorado, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>M Collin</author>
<author>P Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation,</title>
<date>2007</date>
<booktitle>Proceedings of EMNLP-CoNLL</booktitle>
<contexts>
<context position="6998" citStr="Wang et al., 2007" startWordPosition="1064" endWordPosition="1067">sing perl module Parse::RecDescent. By doing this, the SVO order of English is changed to SOV order for Manipuri, and post modifiers are converted to pre-modifiers. The basic difference of Manipuri phrase order compared to English is handled by reordering the input sentence following the rule (Rao et al., 2000): SSmV VmOOmCm  C&apos;mS&apos;mS&apos;O&apos;mO&apos;V&apos;mV&apos; where, S: Subject O: Object V : Verb Cm: Clause modifier X&apos;: Corresponding constituent in Manipuri, where X is S, O, or V Xm: modifier of X There are two reasons why the syntactic reordering approach improves over the baseline phrase-based SMT system (Wang et al., 2007). One obvious benefit is that the word order of the transformed source sentence is much closer to the target sentence, which reduces the reliance on the distortion model to perform reordering during decoding. Another potential benefit is that the alignment between the two sides will be of higher quality because of fewer “distortions” between the source and the target, so that the resulting phrase table of the reordered system would be better. However, a counter argument is that the reordering is very error prone, so that the added noise in the reordered data actually hurts the alignments and h</context>
</contexts>
<marker>Wang, Collin, Koehn, 2007</marker>
<rawString>Wang, C., Collin, M., and Koehn, P. 2007. Chinese syntactic reordering for statistical machine translation, Proceedings of EMNLP-CoNLL</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>