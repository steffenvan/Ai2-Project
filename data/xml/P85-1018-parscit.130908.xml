<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9898485">
Using Restriction to Extend Parsing Algorithms for
Complex-Feature-Based Formalisms
</title>
<author confidence="0.787685">
Stuart M. Shieber
</author>
<sectionHeader confidence="0.9581555" genericHeader="method">
Artificial Intelligence Center
SRI International
</sectionHeader>
<bodyText confidence="0.500023333333333">
and
Center for the Study of Language and Information
Stanford University
</bodyText>
<sectionHeader confidence="0.840381" genericHeader="method">
Abstract 1 Introduction
</sectionHeader>
<bodyText confidence="0.9991156">
Grammar formalisms based on the encoding of grammatical
information in complex-valued feature systems enjoy some
currency both in linguistics and natural-language-processing
research. Such formalisms can be thought of by analogy to
context-free grammars as generalizing the notion of non-
terminal symbol from a finite domain of atomic elements
to a possibly infinite domain of directed graph structures
of a certain sort. Unfortunately, in moving to an infinite
nonterniinal domain, standard methods of parsing may no
longer be applicable to the formalism. Typically, the prob-
lem manifests itself as gross inefficiency or even nontermina-
t ion of the algorithms. In this paper, we discuss a solution to
the problem of extending parsing algorithms to formalisms
with possibly infinite nonterminal domains, a solution based
on a general technique we call restriction. As a particular
example of such an extension, we present a complete, cor-
rect, terminating extension of Earley&apos;s algorithm that uses
restriction to perform top-down filtering. Our implementa-
tion of this algorithm demonstrates the drastic elimination
of chart edges that can be achieved by this technique. Fi-
nally, we describe further uses for the technique—including
parsing other grammar formalisms, including definite-clause
grammars; extending other parsing algorithms, including
LR methods and syntactic preference modeling algorithms;
and efficient indexing.
</bodyText>
<subsectionHeader confidence="0.768520666666667">
This research has been made possible in part by a gift from the Sys-
tems Development Foundation, and was also supported by the Defense
Advanced Research Projects Agency under Contract N00039-84-K-
</subsectionHeader>
<bodyText confidence="0.989332111111111">
0078 with the Naval Electronics Systems Command. The views and
conclusions contained in this document should not he interpreted as
representative of the official policies, either expressed or implied, of
the Defense Research Projects Agency or the United States govern-
ment.
The author is indebted to Fernando Pereira and Ray Perrault for their
comments on earlier drafts of this paper.
Grammar formalisms based on the encoding of grammat-
ical information in complex-valued feature systems enjoy
some currency both in linguistics and natural-language-
processing research. Such formalisms can be thought of by
analogy to context-free grammars as generalizing the no-
tion of nonterminal symbol from a finite domain of atomic
elements to a possibly infinite domain of directed graph
structures of a certain sort. Many of the surface-based
grammatical formalisms explicitly defined or presupposed
in linguistics can be characterized in this way e.g., lexi •.(1-
functional grammar (I.F(;) [51, generalized phrase st ruct
grammar (GPSG) [II, even categorial systems such as Mon-
tague grammar 181 and Ades/Steedman grammar [ I —as can
several of the grammar formalisms being used in natural-
language processing research—e.g., definite clause grammar
(DCG) [91, and PATR-II 1131.
Unfortunately, in moving to an infinite nonterminal do-
main, standard methods of parsing may no longer he ap-
plicable to the formalism. For instance, the application
of techniques for preprocessing of g,ranintars in order to
gain efficiency may fail to terminate, as in left-corner and
LR algorithms. Algorithms performing top-down prediction
(e.g. top-down backtrack parsing, Earley&apos;s algorithm) may
not terminate at parse time. Implementing backtracking
regimens—useful for instance for generating parses in some
particular order, say, in order of syntactic preference—is
in general difficult when LR-style and top-down backtrack
techniques are eliminated.
In this paper, we discuss a solution to the problem of ex-
tending parsing algorithms to formalisms with possibly infi-
nite nonterminal domains, a solution based on an operation
we call restriction. In Section 2, we summarize traditional
proposals for solutions and problems inherent in them and
propose an alternative approach to a solution using restric-
tion. In Section 3, we present some technical background
including a brief description of the PATR-II formalism—
which is used as the formalism interpreted by the pars-
ing algorithms—and a formal definition of restriction for
</bodyText>
<page confidence="0.998108">
145
</page>
<bodyText confidence="0.999126111111111">
PATR-H&apos;s nonterminal domain. In Section 4, we develop
a correct, complete and terminating extension of Earley&apos;s
algorithm for the PATR-II formalism using the restriction
notion. Readers uninterested in the technical details of the
extensions may want to skip these latter two sections, refer-
ring instead to Section 4.1 for an informal overview of the
algorithms. Finally, in Section 5, we discuss applications
of the particular algorithm and the restriction technique in
general.
</bodyText>
<sectionHeader confidence="0.6970535" genericHeader="method">
2 Traditional Solutions and an Al-
ternative Approach
</sectionHeader>
<bodyText confidence="0.9916202">
Problems with efficiently parsing formalisms based on
potentially infinite nonterminal domains have manifested
themselves in many different ways. Traditional solutions
have involved limiting in some way the class of grammars
that can be parsed.
</bodyText>
<subsectionHeader confidence="0.999388">
2.1 Limiting the formalism
</subsectionHeader>
<bodyText confidence="0.999371698412699">
The limitations can be applied to the formalism by, for in-
stance. adding a context-free &amp;quot;backbone.&amp;quot; If we require that
a context-free subgrammar be implicit in every grammar,
the subgrammar can be used for parsing and the rest of the
grammar used as a filter during or after parsing. This solu-
tion has been recommended for functional unification gram-
mars (FUG) by Martin Kay 161; its legacy can be seen in
the context-free skeleton of LFG, and the Hewlett-Packard
GPSC; system 131, and in the cat feature requirement in
PATR-Il that is described below.
However, several problems inhere in this solution of man-
dating a context-free backbone. First, the move from
context-free to complex-feature-based formalisms was mo-
tivated by the desire to structure the notion of nonterminal.
Many analyses take advantage of this by eliminating men-
tion of major category information from particular rules&apos; or
by structuring the major category itself (say into binary N
and V features plus a bar-level feature as in X-based theo-
ries). Forcing the primacy and atomicity of major category
defeats part of the purpose of structured category systems.
Second. and perhaps more critically, because only cer-
tain of the information in a rule is used to guide the parse,
say major category information, only such information can
be used to filter spurious hypotheses by top-down filtering.
Note that this problem occurs even if filtering by the rule
information is used to eliminate at the earliest possible time
constituents and partial constituents proposed during pars-
ing (as is the case in the PATR-II implementation and the
&apos;See. for instance, the coordination and copular &amp;quot;be&amp;quot; analyses from
CPSC [41, the nested VP analysis used in some PATR-Il grammars
1151, or almost all categorial analyses, in which general rules of com-
bination play the role of specific phrase-structure rules.
Earley algorithm given below; cf. the Xerox LFG system).
Thus, if information about subcategorization is left out of
the category information in the context-free skeleton, it can-
not be used to eliminate prediction edges. For example, if
we find a verb that subcategorizes for a noun phrase, but
the grammar rules allow postverbal NPs, PPs, s, VPs, and
so forth, the parser will have no way to eliminate the build-
ing of edges corresponding to these categories. Only when
such edges attempt to join with the V will the inconsistency
be found. Similarly, if information about filler-gap depen-
dencies is kept extrinsic to the category information, as in
a slash category in GPSG or an LFG annotation concern-
ing a matching constituent for a it specification, there will
be no way to keep from hypothesizing gaps at any given
vertex. This &amp;quot;gap-proliferation&amp;quot; problem has plagued many
attempts at building parsers for grammar formalisms in this
style.
In fact, by making these stringent requirements on what
information is used to guide parsing, we have to a certain
extent thrown the baby out with the bathwater. These
formalisms were intended to free us from the tyranny of
atomic nonterminal symbols, but for good performance. we
are forced toward analyses putting more and more informa-
tion in an atomic category feature. An example of this phe-
nomenon can be seen in the author&apos;s paper on LR syntactic
preference parsing 1141. Because the LALR table building
algorithm does not in general terminate for complex-feature-
based grammar formalisms, the grammar used in that paper
was a simple context-free grammar with subcategorization
and gap information placed in the atomic nonterminal sym-
bol.
</bodyText>
<subsectionHeader confidence="0.999985">
2.2 Limiting grammars and parsers
</subsectionHeader>
<bodyText confidence="0.998647222222222">
On the other hand, the grammar formalism can be left un-
changed, but particular grammars developed that happen
not to succumb to the problems inherent in the general
parsing problem for the formalism. The solution mentioned
above of placing more information in the category symbol
falls into this class. Unpublished work by Kent Wit tenburg
and by Robin Cooper has attempted to solve the gap pro-
liferation problem using special grammars.
In building a general tool for grammar testing and debug-
ging, however, we would like to commit as little as possible
to a particular grammar or style of grammar. = Furthermore,
the grammar designer should not be held down in building
an analysis by limitations of the algorithms. Thus a solution
requiring careful crafting of grammars is inadequate.
Finally, specialized parsing algorithms eau he designed
that make use of information about the part Hilar gram-
mar being parsed to eliminate spurious edges or hypothe-
ses. Rather than using a general parsing algorithm on a
</bodyText>
<footnote confidence="0.980607">
2See 1121 for further discussion of this matter.
</footnote>
<page confidence="0.998381">
146
</page>
<bodyText confidence="0.998435909090909">
limited formalism, Ford, Bresnan, and Kaplan [2] chose a
specialized algorithm working on grammars in the full LFG
formalism to model syntactic preferences. Current work at
Hewlett-Packard on parsing recent variants of GPSG seems
to take this line as well.
Again, we feel that the separation of burden is inappropri-
ate in such an attack, especially in a grammar-development
context. Coupling the grammar design and parser design
problems in this way leads to the linguistic and technolog-
ical problems becoming inherently mixed, magnifying the
difficulty of writing an adequate grammar/parser system.
</bodyText>
<subsectionHeader confidence="0.999709">
2.3 An Alternative: Using Restriction
</subsectionHeader>
<bodyText confidence="0.999884205128205">
Instead, we would like a parsing algorithm that placed no
restraints on the grammars it could handle as long as they
could be expressed within the intended formalism. Still, the
algorithm should take advantage of that part of the arbi-
trarily large amount of information in the complex-feature
structures that is significant for guiding parsing with the
particular grammar. One of the aforementioned solutions
is to require the grammar writer to put all such signifi-
cant information in a special atomic symbol—i.e., mandate
a context-free backbone. Another is to use all of the feature
structure information—but this method, as we shall see, in-
evitably leads to nonterminating algorithms.
A compromise is to parameterize the parsing algorithm
by a small amount of grammar-dependent information that
tells the algorithm which of the information in the feature
structures is significant for guiding the parse. That is, the
parameter determines how to split up the infinite nontermi-
nal domain into a finite set of equivalence classes that can be
used for parsing. By doing so, we have an optimal compro-
mise: Whatever part of the feature structure is significant
we distinguish in the equivalence classes by setting the pa-
rameter appropriately, so the information is used in parsing.
But because there are only a finite number of equivalence
classes, parsing algorithms guided in this way will terminate.
The technique we use to form equivalence classes is re-
striction, which involves taking a quotient of the domain
with respect to a restrictor. The restrictor thus serves as
the sole repository of grammar-dependent information in the
algorithm. By tuning the restrictor, the set of equivalence
classes engendered can be changed, making the algorithm
more or less efficient at guiding the parse. But independent
of the restrictor, the algorithm will be correct, since it is
still doing parsing over a finite domain of &amp;quot;nonterminals,&amp;quot;
namely, the elements of the restricted domain.
This idea can be applied to solve many of the problems en-
gendered by infinite nonterminal domains, allowing prepro-
cessing of grammars as required by LR and LC algorithms,
allowing top-down filtering or prediction as in Earley and
top-down backtrack parsing, guaranteeing termination, etc.
</bodyText>
<sectionHeader confidence="0.990064" genericHeader="method">
3 Technical Preliminaries
</sectionHeader>
<bodyText confidence="0.9994477">
Before discussing the use of restriction in parsing algorithms,
we present some technical details, including a brief introduc-
tion to the PATR-II grammar formalism, which will serve
as the grammatical formalism that the presented algorithms
will interpret. PATR-II is a simple grammar formalism that
can serve as the least common denominator of many of
the complex-feature-based and unification-based formalisms
prevalent in linguistics and computational linguistics. As
such it provides a good testbed for describing algorithms
for complex-feature-based formalisms.
</bodyText>
<subsectionHeader confidence="0.994093">
3.1 The PATR-II nonterminal domain
</subsectionHeader>
<bodyText confidence="0.994985285714286">
The PATR-II nonterminal domain is a lattice of directed,
acyclic, graph structures (dags).3 Dags can be thought of
as similar to the reentrant f-structures of LFG or functional
structures of FUG, and we will use the bracketed notation
associated with these formalisms for them. For example.
the following is a dag (D0) in this notation, with reentrancy
indicated with coindexing boxes:
</bodyText>
<equation confidence="0.9442965">
[ 6 : c]
[e: If: [g: h]
i: [ j : II ]
k: I
</equation>
<bodyText confidence="0.998643933333333">
Dags come in two varieties, complex (like the one above)
and atomic (like the dags h and c in the example). Complex
dags can be viewed as partial functions from labels to dag
values, and the notation D(l) will therefore denote the value
associated with the label / in the dag D. In the same spirit.
we can refer to the domain of a dag (dorn(D)). A dag with
an empty domain is often called an empty dag or variable.
A path in a dag is a sequence of label names (notated, e.g..
(d e I)), which can be used to pick out a particular subpart
of the dag by repeated application (in this case, the dag (g :
hi). We will extend the notation D(p) in the obvious way to
include the subdag of D picked out by a path p. We will also
occasionally use the square brackets as the Hag constructor
function, so that If : Di where D is an expression denoting
a dag will denote the dag whose f feature has value D.
</bodyText>
<subsectionHeader confidence="0.999885">
3.2 Subsumption and Unification
</subsectionHeader>
<bodyText confidence="0.7510946">
There is a natural lattice structure for dags based on
substimption—an ordering on (lags that roughly corre,pow Is
to the compatibility and relative specificity of information
3 The reader is referred to earlier works 115,101 for more detailed dis-
cussions of dag structures.
</bodyText>
<figure confidence="0.826926">
a:
d:
</figure>
<page confidence="0.97607">
147
</page>
<bodyText confidence="0.989192272727273">
contained in the dags. Intuitively viewed, a dag D subsumes
a dag D&apos; (notated DC D&apos;) if D contains a subset of the in-
formation in (i.e., is more general than) U.
Thus variables subsume all other dags, atomic or complex,
because as the trivial case, they contain no information at
all. A complex dag D subsumes a complex dag Ds if and
only if D(1) C DT) for all I E dom(D) and Ds(P) = f/(q)
for all paths p and q such that D(p) = D(q). An atomic dag
neither subsumes nor is subsumed by any different atomic
dag.
For instance, the following subsumption relations hold:
</bodyText>
<figure confidence="0.821335666666667">
a: Mib ci
(b: ell c[d.
f f
</figure>
<bodyText confidence="0.9230225">
Finally, given two dags D&apos; and D&amp;quot;, the unification of the
dags is the most general dag D such that D&apos; C D and D&amp;quot; C
D. We notate this D = D&apos; U D&amp;quot;.
The following examples illustrate the notion of unification:
</bodyText>
<figure confidence="0.7570952">
C r a: lb : cl 1
1=1 d : e
a: fl
_ [ a: : c]
[a: (b:cjiu[d: — d
</figure>
<bodyText confidence="0.890634333333333">
The unification of two dags is not always well-defined. In
the cases where no unification exists, the unification is said
to fail. For example the following pair of dags fail to unify
with each other:
[a: 1 a: (b : cl 1 „
id: al JULd: [b:dli=16. •
</bodyText>
<subsectionHeader confidence="0.9860595">
3.3 Restriction in the PATR-H nontermi-
nal domain
</subsectionHeader>
<bodyText confidence="0.99974252631579">
Now, consider the notion of restriction of a dag, using the
term almost in its technical sense of restricting the domain
of a function. By viewing dags as partial functions from la-
bels to dag values, we can envision a process of restricting
the domain of this function to a given set of labels. Extend-
ing this process recursively to every level of the (lag, we have
the concept of restriction used below. Given a finite specifi-
cation (I) (called a restrictor) of what the allowable domain
at each node of a dag is, we can define a functional, that
yields the dag restricted by the given restrictor.
Formally, we define restriction as follows. Given a relation
41 between paths and labels, and a dag D, we define Dt4)
to be the most specific dag D&apos; D such that for every path
p either De(p) is undefined, or LY(p) is atomic, or for every
1 E dom(Ds(p)), p(111. That is, every path in the restricted
dag is either undefined, atomic, or specifically allowed by the
restrictor.
The restriction process can be viewed as putting dags into
equivalence classes, each equivalence class being the largest
set of dags that all are restricted to the same dag (which we
will call its canonical member). It follows from the definition
that in general DM) C D. Finally, if we disallow infinite
relations as restrictors (i.e., restrictors must not allow values
for an infinite number of distinct paths) as we will do for the
remainder of the discussion, we are guaranteed to have only
a finite number of equivalence classes.
Actually, in the sequel we will use a particularly simple
subclass of restrictors that are generable from sets of paths.
Given a set of paths s, we can define (I) such that p43.1 if and
only if p is a prefix of some p&apos; E s. Such restrictors can be
understood as &amp;quot;throwing away&apos; all values not lying on one
of the given paths. This subclass of restrictors is sufficient
for most applications. However, the algorithms that we will
present apply to the general class as well.
Using our previous example, consider a restrictor 00 gen-
erated from the set of paths ((a b), (d e 1), (d ij f)}.
That is, p4&apos;01 for all p in the listed paths and all their pre-
fixes. Then given the previous dag Do, D0f40 is
</bodyText>
<equation confidence="0.979246666666667">
a: [6: c]
e: I []11
L1 [j:
</equation>
<bodyText confidence="0.97456075">
Restriction has thrown away all the information except the
direct values of (a b), (d e f), and (d if P. (Note however
that because the values for paths such as (d e f (j) were
thrown away, (Do(t(too)(((l e f)) is a variable.)
</bodyText>
<subsectionHeader confidence="0.991701">
3.4 PATR-H grammar rules
</subsectionHeader>
<bodyText confidence="0.9948304">
PATR-II rules describe how to combine a sequence of con-
stituents. X1 V, to form a constituent No, stating mu-
tual constraints on the dags associated with the n + 1 con-
stituents as unifications of various parts of the dags. For
instance, we might have the following rule:
</bodyText>
<equation confidence="0.8803324">
Xs Xi
(Xo rat). s
(NI rat)
(N: eat) = VP
(X, agreement) = (X2 agreement).
</equation>
<bodyText confidence="0.99911725">
By notational convention, we can eliminate unifications for
the special feature cat (the atomic major category feature)
recording this information implicitly by using it in the
&amp;quot;name&amp;quot; of the constituent, e.g.,
</bodyText>
<equation confidence="0.975231">
[ I [d : elC a
— e :
[ a : (b:c) 1U[d:
d :
</equation>
<page confidence="0.90911">
148
</page>
<figure confidence="0.4962705">
5 NP VP:
(NP agreement) = (VP agreement).
</figure>
<bodyText confidence="0.999854647058824">
If we require that this notational convention always be used
(in so doing, guaranteeing that each constituent have an
atomic major category associated with it), we have thereby
mandated a context-free backbone to the grammar, and can
then use standard context-free parsing algorithms to parse
sentences relative to grammars in this formalism. Limiting
to a context-free-based PATR-II is the solution that previous
implementations have incorporated.
Before proceeding to describe parsing such a context-free-
based PATR-II, we make one more purely notational change.
Rather than associating with each grammar rule a set of
unifications, we instead associate a dag that incorporates all
of those unifications implicitly, i.e., a rule is associated with
a dag D, such that for all unifications of the form p q in
the rule. D,(p) = D,(q). Similarly, unifications of the form
p = a where a is atomic would require that D,(p) = a. For
the rule mentioned above, such a dag would be
</bodyText>
<equation confidence="0.9900954">
X0: [ cat : ]
[ cat : NP
agreement :
cat: VP 1
agreement : j
</equation>
<bodyText confidence="0.9909193">
Thus a rule can be thought of as an ordered pair (P, D)
whore P is a production of the form Xo — • • X„ and D
is a (lag with top-level features X0, , X„ and with atomic
values for the cat feature of each of the top-level subdags.
The two notational conventions—using sets of unifications
instead of dags, and putting the cat feature information im-
plicitly in the names of the constituents—allow us to write
rules in the more compact and familiar.format above, rather
than this final cumbersome way presupposed by the algo-
rithm.
</bodyText>
<sectionHeader confidence="0.978911" genericHeader="method">
4 Using Restriction to Extend Ear-.
ley&apos;s Algorithm for PATR-II
</sectionHeader>
<bodyText confidence="0.999987333333333">
We now develop a concrete example of the use of restriction
in parsing by extending Earley&apos;s algorithm to parse gram-
mars in the PATR-II formalism just presented.
</bodyText>
<subsectionHeader confidence="0.999603">
4.1 An overview of the algorithms
</subsectionHeader>
<bodyText confidence="0.99993452173913">
Earley&apos;s algorithm L1 a bottom-up parsing algorithm that
uses top-down prediction to hypothesize the starting points
of possible constituents. Typically, the prediction step de-
termines which categories of constituent can start at a given
point in a sentence. But when most of the information is
not in an atomic category symbol, such prediction is rela-
tively useless and many types of constituents are predicted
that could never be involved in a completed parse. This
standard Earley&apos;s algorithm is presented in Section 4.2.
By extending the algorithm so that the prediction step
determines which dogs can start at a given point, we can
use the information in the features to be more precise in the
predictions and eliminate many hypotheses. However, be-
cause there are a potentially infinite number of such feature
structures, the prediction step may never terminate. This
extended Earley&apos;s algorithm is presented in Section 4.3.
We compromise by having the prediction step determine
which restricted dags can start at a given point. If the re-
strictor is chosen appropriately, this can be as constraining
as predicting on the basis of the whole feature structure, yet
prediction is guaranteed to terminate because the domain of
restricted feature structures is finite. This final extension of
Earley&apos;s algorithm is presented in Section 4.4.
</bodyText>
<subsectionHeader confidence="0.999931">
4.2 Parsing a context-free-based PATR-II
</subsectionHeader>
<bodyText confidence="0.983224833333333">
We start with the Earley algorithm for context-free-based
PATR-II on which the other algorithms are based. The al-
gorithm is described in a chart-parsing incarnation, vertices
numbered from 0 to n for an n-word sentence wi • • w„. An
item of the form [h, i, A — ct./3, DI designates an edge in the
chart from vertex h to i with dotted rule .4 — a-3 and dag
D.
The chart is initialized with an edge [0,0, X0 — .a, DI for
each rule (X0 a, D) where D((X0 eat)) = S.
For each vertex i do the following steps until no more items
can be added:
Predictor step: For each item ending at i of the formi
[h, i, X0 a.X;3, DI and each rule of the form (X0 —
-I, E) such that E((Xo cat)) = D((X; cat)), add an
edge of the form e, X0 — El if this edge is not
subsumed by another edge.
Informally, this involves predicting top-down all rules
whose left-hand-side category matches the category of
some constituent being looked for.
Completer step: For each item of the form [h, 1, .V0 —
a., DI and each item of the form [y. h, X0 — E.]
add the item 19,1, Xo Eu [X : D(X0)IJ if the
unification succeeds&apos; and this edge is not subsumed by
another edge.&apos;
</bodyText>
<subsectionHeader confidence="0.662591">
&amp;quot;Note that this unification will fail if D((X0 cat)) E((X, cat)) and
</subsectionHeader>
<bodyText confidence="0.977481">
no edge will be added, i.e., if the subphrase is not of the appropriate
category for Insertion Into the phrase being built.
&apos;One edge subsumes another edge if and only if the first three elements
of the edges are identical and the fourth element of the first edge
subsumes that of the second edge.
</bodyText>
<figure confidence="0.373276">
:
X2
</figure>
<page confidence="0.995831">
149
</page>
<bodyText confidence="0.854525230769231">
Informally, this involves forming a new partial phrase
whenever the category of a constituent needed by one
partial phrase matches the category of a completed
phrase and the dag associated with the completed phrase
can be unified in appropriately.
Scanner step: If i 0 and tv; = a, then for all items (h, i —
1, X0 a.a13, DI add the item [h, i, X0 oia.fl, Di.
Informally, this involves allowing lexical items to be in-
serted into partial phrases.
Notice that the Predictor Step in particular assumes the
availability of the cat feature for top-down prediction. Con-
sequently, this algorithm applies only to PATR-II with a
context-free base.
</bodyText>
<subsectionHeader confidence="0.999155">
4.3 Removing the Context-Free Base: An
Inadequate Extension
</subsectionHeader>
<bodyText confidence="0.984935476190476">
A first attempt at extending the algorithm to make use of
more than just a single atomic-valued cal feature (or less
if no such feature is mandated) is to change the Predictor
Step so that instead of checking the predicted rule for a left-
hand side that matches its cat feature with the predicting
subphrase, we require that the whole left-hand-side subdag
unifies with the subphrase being predicted from. Formally,
we have
Predictor step: For each item ending at i of the form
[h. i. X0 D1 and each rule of the form (X0
E). add an edge of the form 11,1, Xe — Eu (Xo
D(X1)11 if the unification succeeds and this edge is not
subsumed by another edge.
This step predicts top-down all rides whose left-hand
side matches the dag of some constituent being looked
for.
Completer step: As before.
Scanner step: As before.
However, this extension does not preserve termination.
Consider a &amp;quot;counting&apos; grammar that records in the dag the
number of terminals in the string.°
</bodyText>
<equation confidence="0.8164026">
T:
(s f) = a.
T, — 7.2 .4:
(TI n = (Td D •
1.
</equation>
<bodyText confidence="0.259539">
A -- a.
</bodyText>
<footnote confidence="0.9359485">
6Similar problems occur in natural language grammars when keeping
/Isis of, say, subcategorized constituents or gaps to be found.
</footnote>
<table confidence="0.996268727272727">
Initially, the S T rule will yield the edge
0,Xo X0: [ cat : S
Xt : cat: T
/: a
which in turn causes the Prediction step to give
yielding in turn
: Icat: T
10, 0, .X0 , : f: T :
X2 : { cat : [1: JI
f : Al
cat:
</table>
<bodyText confidence="0.331863">
and so forth ad infinitum.
</bodyText>
<subsectionHeader confidence="0.9983085">
4.4 Removing the Context-free Base: An
Adequate Extension
</subsectionHeader>
<bodyText confidence="0.971076133333333">
What is needed is a way of &apos;forgetting&apos; some of the structure
we are using for top-down prediction. But this is just what
restriction gives us, since a restricted dag always subsumes
the original, i.e., it has strictly less information. Taking
advantage of this property. we can change the Prediction
Step to restrict the top-down information before unif■ lug it
into the rule&apos;s dag.
Predictor step: For each item ending at i of the form
1h, i, X0 — D) and each rule of the form,(X0 —
E), add an edge of the form 11,1, X0 — E u
(D(X1)1`4:)1 if the unification succeeds and this edge is
not subsumed by another edge.
This step predicts top-down all rules frh,,se left-hand
side matches the restricted dag of some constituent be-
ing looked for.
</bodyText>
<table confidence="0.796932428571428">
Completer step: As before.
Scanner step: As before.
)0, 0, Xo , X0: [cat : trio Mil
: : [I:
X2: [cat : A]
f:
[ cat :
</table>
<page confidence="0.997123">
150
</page>
<bodyText confidence="0.9958975">
This algorithm on the previous grammar, using a restrictor
that allows through only the cat feature of a dag, operates as
before, but predicts the first time around the more general
edge:
</bodyText>
<table confidence="0.9855282">
[0, 0, Xo Xo [cat :
: 1:
X2: [cal :
I:
[ cat:
</table>
<bodyText confidence="0.993407916666667">
Another round of prediction yields this same edge so the
process terminates immediately. duck Because the predicted
edge is more general than (i.e., subsumes) all the infinite
number of edges it replaced that were predicted under the
nonterminating extension, it preserves completeness. On the
other hand, because the predicted edge is not more general
than the rule itself, it permits no constituents that violate
the constraints of the rule; therefore, it preserves correctness.
Finally, because restriction has a finite range, the prediction
step can only occur a finite number of times before building
an edge identical to one already built; therefore, it preserves
termination.
</bodyText>
<sectionHeader confidence="0.999587" genericHeader="evaluation">
5 Applications
</sectionHeader>
<subsectionHeader confidence="0.949578">
5.1 Some Examples of the Use of the Al-
gorithm
</subsectionHeader>
<bodyText confidence="0.998445277777778">
The algorithm just. described has been implemented and in-
corporated into the PATR-II Experimental System at. SRI
International. a grammar development and testing environ-
ment for PAT grammars written in Zetalisp for the Sym-
bolics 3Witi.
The following table gives some data suggestive of the of- -
fect of the restrictor on parsing efficiency. It shows the total
number of active and passive edges added to the chart for
five sentences of up to eleven words using four different re-
strictors. The first allowed only category information to be
useI in prediction, thus generating the same behavior as the
unextended Earley&apos;s algorithm. The second added subcate.
g,orizati(in information in addition to the category. The third
added liller-gap dependency information as well so that the
gap proliferaticm priiblem was removed. The final restrictor
added verb form information. The last cohunn shows the
percentage of edges that were eliminated by using this final
restrictor.
</bodyText>
<table confidence="0.998473857142857">
Sentence eat + subcat Prediction + form %
+ gap elim.
1 33 33 20 16 52
2 85 50 29 21 75
3 219 124 72 45 79
4 319 319 98 71 78
5 812 516 157 100 88
</table>
<bodyText confidence="0.9979219">
Several facts should be kept in mind about the data
above. First, for sentences with no Wh-movement or rel-
ative clauses, no gaps were ever predicted. In other words,
the top-down filtering is in some sense maximal with re-
spect to gap hypothesis. Second, the subcategorization in-
formation used in top-down filtering removed all hypotheses
of constituents except for those directly subcategorized for.
Finally, the grammar used contained constructs that would
cause nonterrnination in the unrestricted extension of Ear-
ley&apos;s algorithm.
</bodyText>
<subsectionHeader confidence="0.987792">
5.2 Other Applications of Restriction
</subsectionHeader>
<bodyText confidence="0.999847787878788">
This technique of restriction of complex-feature structures
into a finite set of equivalence classes can be used for a wide
variety of purposes.
First, parsing algorithms such as the above can be mod-
ified for use by grammar formalisms other than PATR-II.
In particular. defin ite-c lause grammars are amenable to this
technique, and it can be used to extend the Earley deduc-
tion of Pereira and Warren [I LI. Pereira has used a similar
technique to improve the efficiency of the RUP (bottom-
up left-corner) parser 171 for DCG. I,FC and (PSG parsers
can make rise of the top-down filtering device as Well. El&apos;C
parsers might be built that do not require a context-free
backbone.
Second, restriction ran be used to enhane4. it her parsing
algorithms. For example. the ancillary rimrt ion to compfite
1.1t closure-- which, like the Earley algorithm. either does
not use feature information, or fails to terminate—can be
modified in the same way as the Earley predictor step to ter-
minate while still using significant feature information. EA
parsing techniques can thereby 1)0 used for efficient parsing
if complex-feature-based formalisms. More speculatively.
schemes for scheduling LH parsers to yield p.irses ill pref-
erence order might be modified for complex-foal ure-kisod
formalisms, and even timed by means of the restrictor.
Finally, restriction can be used in areas of parsing other
than top-down prediction and filtering. For instance, in
many parsing schemes, edges are indexed by a category sym-
bol for efficient retrieval. In the case of Earley&apos;s algorithm.
active edges can be indexed by the category of the con-
stituent following the dot in the (lotted rule. However, this
again forces the primacy and atomicity of major category in-
formation. Once again, restriction can be used to solve the
problem. Indexing by the restriction of the dag associated
</bodyText>
<page confidence="0.995259">
151
</page>
<bodyText confidence="0.998761">
with the need pgrmits efficient retrieval that can be tuned to
the particular grammar, yet does not affect the completeness
or correctness of the algorithm. The indexing can be done
by discrimination nets, or specialized hashing functions akin
to the partial-match retrieval techniques designed for use in
Prolog implementations [161.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999152">
We have presented a general technique of restriction with
many applications in the area of manipulating complex-
feature-based grammar formalisms. As a particular exam-
ple, we presented a complete, correct, terminating exten-
sion of Earley&apos;s algorithm that uses restriction to perform
top-down filtering. Our implementation demonstrates the
drastic elimination of chart edges that can be achieved by
this technique. Finally, we described further uses for the
technique—including parsing other grammar formalisms, in-
cluding definite-clause grammars; extending other parsing
algorithms, including LR methods and syntactic preference
modeling algorithms; and efficient indexing.
We feel that the restriction technique has great potential
to make increasingly powerful grammar formalisms compu-
tationally feasible.
</bodyText>
<sectionHeader confidence="0.998982" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999933471428572">
[1] Ades, A. E. and M. J. Steedman. On the order of words.
Linguistics and Philosophy, 4(4):517-558, 1982.
[2] Ford, M.. J. Bresnan, and R. Kaplan. A competence-
based theory of syntactic closure. In J. Bresnan, editor,
The Mental Representation of Grammatical Relations,
MIT Press, Cambridge, Massachusetts, 1982.
[3] Gawron, J. M., J. King, J. Lamping, E. Loebner, E. -
A. Paulson, G. K. Pullum, I. A. Sag, and T. Wasow.
Processing English with a generalized phrase structure
grammar. In Proceedings of the 20th Annual Meet-
ing of the Association for Computational Linguistics,
pages 74-81, University of Toronto. Toronto, Ontario,
Canada, 16-18 June 1982.
[4] Gazdar, G., E. Klein, G. K. Pullum, and I. A. Sag.
Generalized Phrase Structure Grammar. Blackwell
Publishing, Oxford, England, and Harvard University
Press, Cambridge, Massachusetts, 1985.
(51 Kaplan, R. and J. Bresnan. Lexical-functional gram-
mar: a formal system for grammatical representation.
In J. Bresnan, editor, The Mental Representation of
Grammatical Relations, MIT Press, Cambridge, Mas-
sachusetts, 1983.
[61 Kay, M. An algorithm for compiling parsing tables from
a grammar. 1980. Xerox Palo Alto Research Center.
Palo Alto, California.
[7] Matsumoto, Y., H. Tanaka, H. Hirakawa. H.
and H. Yasulcawa. BUP: a bottom-up parser embed-
ded in Prolog. New Generation Computing, 1:145-158,
1983.
[81 Montague, R. The proper treatment of quantification
in ordinary English. In R. H. Thomason, editor. Formal
Philosophy, pages 188-221, Yale University Press. New
Haven, Connecticut, 1974.
[9] Pereira, F. C. N. Logic for natural language analysis.
Technical Note 275, Artificial Intelligence Center, SRI
International, Menlo Park, California, 1983.
[10] Pereira, F. C. N. and S. M. Shieber. The semantics of
grammar formalisms seen as computer languages. In
Proceedings of the Tenth International Conference on
Computational Linguistics, Stanford University, Stan-
ford, California, 2-7 July 1984.
[111 Pereira, F. C. N. and D. H. D. Warren. Parsing as
deduction. In Proceedings of the 21st Annual Meet-
ing of the Association for Computational Linguistics.
pages 137-144, Massachusetts Institute of Technology,
Cambridge, Massachusetts, 15-17 June 1983.
[121 Shieber, S. M. Criteria for designing computer facilities
for linguistic analysis. To appear in Linguistics.
[13] Shieber, S. M. The design of a computer language
for linguistic information. In Proceedings of the Tenth
International Conference on r&apos;omputational Linguis-
tics, Stanford University, Stanford, California. 2-7 July
1984.
[14] Shieber, S. M. Sentence disambiguation by a shift-
reduce parsing technique. In Proceedings of the 21st
Annual Meeting of the Association for Computational
Linguistics, pages 1 i3-118, Massachusetts Institute of
Technology, Cambridge, Massachusetts, 15-17 June
1983.
[151 Shieber, S. M., H. Uszkoreit, F. C. N. Pereira, J. J.
Robinson, and M. Tyson. The formalism and im-
plementation of PATR-I1. In Research on Interactive
Acquisition and Use of Knowledge, SRI International.
Menlo Park, California, 1983.
[161 Wise, M. J. and D. M. W. Powers. Indexing Prolog
clauses via superimposed code words and field encoded
words. In Proceedings of the 1984 International Sym-
posium on Logic Programming, pages 203-210, IEEE
Computer Society Press, Atlantic City, New Jersey, 6-9
February 1984.
</reference>
<page confidence="0.998128">
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.993396">
<title confidence="0.999863">Using Restriction to Extend Parsing Algorithms for Complex-Feature-Based Formalisms</title>
<author confidence="0.999994">Stuart M Shieber</author>
<affiliation confidence="0.9987018">Artificial Intelligence Center SRI International and Center for the Study of Language and Information Stanford University</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the order of words.</title>
<date>1982</date>
<journal>Linguistics and Philosophy,</journal>
<pages>4--4</pages>
<marker>Ades, Steedman, 1982</marker>
<rawString>[1] Ades, A. E. and M. J. Steedman. On the order of words. Linguistics and Philosophy, 4(4):517-558, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Bresnan Ford</author>
<author>R Kaplan</author>
</authors>
<title>A competencebased theory of syntactic closure.</title>
<date>1982</date>
<booktitle>The Mental Representation of Grammatical Relations,</booktitle>
<editor>In J. Bresnan, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts,</location>
<marker>Ford, Kaplan, 1982</marker>
<rawString>[2] Ford, M.. J. Bresnan, and R. Kaplan. A competencebased theory of syntactic closure. In J. Bresnan, editor, The Mental Representation of Grammatical Relations, MIT Press, Cambridge, Massachusetts, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Gawron</author>
<author>J King</author>
<author>J Lamping</author>
<author>E Loebner</author>
<author>E -A Paulson</author>
<author>G K Pullum</author>
<author>I A Sag</author>
<author>T Wasow</author>
</authors>
<title>Processing English with a generalized phrase structure grammar.</title>
<date>1982</date>
<booktitle>In Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>74--81</pages>
<institution>University of Toronto.</institution>
<location>Toronto, Ontario, Canada,</location>
<marker>Gawron, King, Lamping, Loebner, Paulson, Pullum, Sag, Wasow, 1982</marker>
<rawString>[3] Gawron, J. M., J. King, J. Lamping, E. Loebner, E. -A. Paulson, G. K. Pullum, I. A. Sag, and T. Wasow. Processing English with a generalized phrase structure grammar. In Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics, pages 74-81, University of Toronto. Toronto, Ontario, Canada, 16-18 June 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G K Pullum</author>
<author>I A Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Blackwell Publishing,</publisher>
<location>Oxford, England, and</location>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>[4] Gazdar, G., E. Klein, G. K. Pullum, and I. A. Sag. Generalized Phrase Structure Grammar. Blackwell Publishing, Oxford, England, and Harvard University Press, Cambridge, Massachusetts, 1985.</rawString>
</citation>
<citation valid="true">
<title>Lexical-functional grammar: a formal system for grammatical representation.</title>
<date>1983</date>
<booktitle>The Mental Representation of Grammatical Relations,</booktitle>
<editor>In J. Bresnan, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts,</location>
<marker>1983</marker>
<rawString>(51 Kaplan, R. and J. Bresnan. Lexical-functional grammar: a formal system for grammatical representation. In J. Bresnan, editor, The Mental Representation of Grammatical Relations, MIT Press, Cambridge, Massachusetts, 1983.</rawString>
</citation>
<citation valid="true">
<title>An algorithm for compiling parsing tables from a grammar.</title>
<date>1980</date>
<location>Palo Alto, California.</location>
<marker>1980</marker>
<rawString>[61 Kay, M. An algorithm for compiling parsing tables from a grammar. 1980. Xerox Palo Alto Research Center. Palo Alto, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H</author>
<author>H Yasulcawa</author>
</authors>
<title>BUP: a bottom-up parser embedded in Prolog.</title>
<date>1983</date>
<journal>New Generation Computing,</journal>
<pages>1--145</pages>
<marker>H, Yasulcawa, 1983</marker>
<rawString>[7] Matsumoto, Y., H. Tanaka, H. Hirakawa. H. and H. Yasulcawa. BUP: a bottom-up parser embedded in Prolog. New Generation Computing, 1:145-158, 1983.</rawString>
</citation>
<citation valid="true">
<title>The proper treatment of quantification in ordinary English. In</title>
<date>1974</date>
<pages>188--221</pages>
<editor>R. H. Thomason, editor. Formal Philosophy,</editor>
<publisher>Yale University Press.</publisher>
<location>New Haven, Connecticut,</location>
<marker>1974</marker>
<rawString>[81 Montague, R. The proper treatment of quantification in ordinary English. In R. H. Thomason, editor. Formal Philosophy, pages 188-221, Yale University Press. New Haven, Connecticut, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
</authors>
<title>Logic for natural language analysis.</title>
<date>1983</date>
<booktitle>Technical Note 275, Artificial Intelligence Center, SRI International,</booktitle>
<location>Menlo Park, California,</location>
<marker>Pereira, 1983</marker>
<rawString>[9] Pereira, F. C. N. Logic for natural language analysis. Technical Note 275, Artificial Intelligence Center, SRI International, Menlo Park, California, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
<author>S M Shieber</author>
</authors>
<title>The semantics of grammar formalisms seen as computer languages.</title>
<date>1984</date>
<booktitle>In Proceedings of the Tenth International Conference on Computational Linguistics,</booktitle>
<location>Stanford University, Stanford, California,</location>
<marker>Pereira, Shieber, 1984</marker>
<rawString>[10] Pereira, F. C. N. and S. M. Shieber. The semantics of grammar formalisms seen as computer languages. In Proceedings of the Tenth International Conference on Computational Linguistics, Stanford University, Stanford, California, 2-7 July 1984.</rawString>
</citation>
<citation valid="true">
<title>Parsing as deduction.</title>
<date>1983</date>
<booktitle>In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>137--144</pages>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, Massachusetts,</location>
<marker>1983</marker>
<rawString>[111 Pereira, F. C. N. and D. H. D. Warren. Parsing as deduction. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics. pages 137-144, Massachusetts Institute of Technology, Cambridge, Massachusetts, 15-17 June 1983.</rawString>
</citation>
<citation valid="false">
<title>Criteria for designing computer facilities for linguistic analysis.</title>
<note>To appear in Linguistics.</note>
<marker></marker>
<rawString>[121 Shieber, S. M. Criteria for designing computer facilities for linguistic analysis. To appear in Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>The design of a computer language for linguistic information.</title>
<date>1984</date>
<booktitle>In Proceedings of the Tenth International Conference on r&apos;omputational Linguistics,</booktitle>
<pages>2--7</pages>
<location>Stanford University, Stanford, California.</location>
<marker>Shieber, 1984</marker>
<rawString>[13] Shieber, S. M. The design of a computer language for linguistic information. In Proceedings of the Tenth International Conference on r&apos;omputational Linguistics, Stanford University, Stanford, California. 2-7 July 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Sentence disambiguation by a shiftreduce parsing technique.</title>
<date>1983</date>
<booktitle>In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, Massachusetts,</location>
<marker>Shieber, 1983</marker>
<rawString>[14] Shieber, S. M. Sentence disambiguation by a shiftreduce parsing technique. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, pages 1 i3-118, Massachusetts Institute of Technology, Cambridge, Massachusetts, 15-17 June 1983.</rawString>
</citation>
<citation valid="true">
<title>The formalism and implementation of PATR-I1.</title>
<date>1983</date>
<booktitle>In Research on Interactive Acquisition and Use of Knowledge, SRI International. Menlo</booktitle>
<location>Park, California,</location>
<marker>1983</marker>
<rawString>[151 Shieber, S. M., H. Uszkoreit, F. C. N. Pereira, J. J. Robinson, and M. Tyson. The formalism and implementation of PATR-I1. In Research on Interactive Acquisition and Use of Knowledge, SRI International. Menlo Park, California, 1983.</rawString>
</citation>
<citation valid="true">
<title>Indexing Prolog clauses via superimposed code words and field encoded words.</title>
<date>1984</date>
<booktitle>In Proceedings of the 1984 International Symposium on Logic Programming,</booktitle>
<pages>203--210</pages>
<publisher>IEEE Computer Society Press,</publisher>
<location>Atlantic City, New Jersey,</location>
<marker>1984</marker>
<rawString>[161 Wise, M. J. and D. M. W. Powers. Indexing Prolog clauses via superimposed code words and field encoded words. In Proceedings of the 1984 International Symposium on Logic Programming, pages 203-210, IEEE Computer Society Press, Atlantic City, New Jersey, 6-9 February 1984.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>