<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.950313">
Simultaneous Interpretation Utilizing Example-based Incremental Transfer
</title>
<author confidence="0.641861">
Hideki Mime, Hitoshi Iida and Osamu Furuse&amp;quot;
</author>
<affiliation confidence="0.323828">
ATR Interpreting Telecommunications Research Laboratories
</affiliation>
<address confidence="0.444506">
2-2 Hikaridai Seika-cho Soraku-gun Kyoto 619-0288, Japan
</address>
<email confidence="0.899299">
EMAIL: H.Mima@doc.mmu.ac.uk, iida@itl.atr.co.jp, furuse@cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.996576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999835428571429">
This paper describes a practical method of automatic simultaneous interpretation utilizing an example-based
incremental transfer mechanism. We primarily show how incremental translation is achieved in the context of
an example-based framework. We then examine the type of translation examples required for a simultaneous
interpretation to create naturally communicative dialogs. Finally, we propose a scheme for automatic
simultaneous interpretation exploiting this example-based incremental translation mechanism. Preliminary
experimentation analyzing the performance of our example-based incremental translation mechanism leads us
to believe that the proposed scheme can be utilized to achieve a practical simultaneous interpretation system.
</bodyText>
<sectionHeader confidence="0.987035" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999811">
Speech-to-speech translation necessitates quick
and perspicuous responses to natural
communication. Furthermore, since dialogues
continuously expand, it is essential to
incrementally translate inputs to avoid
interrupting the coherency of communications.
Therefore, a high degree of incrementality and
acceptability in translation such as simultaneous
interpretation is essential. To satisfy these
requirements, an incremental translation system,
which functions as a simultaneous interpreter, is
seen as an efficient solution in this field.
The main characteristic of incremental
translations is the translation process. This is
activated synchronously with the input, in
contrast with conventional sentence-by-sentence-
based translation which cannot start processing
until the end of an input (Kitano, 1994). However,
in incremental translation, we believe that the
following issues must be resolved to achieve
actual simultaneous interpretation:
</bodyText>
<listItem confidence="0.96970880952381">
• How to define Information Units (IUs)
(Halliday, 1994) to determine appropriate
components for translation — Since
differences exist among the word order of
various languages, especially between
linguistically distant languages such as English
and Japanese, appropriate transfer units,
equally effective for both the source and target
languages, have to be defined.
• How to determine plausible translation for
each IU — In terms of the information content,
the greater the number of words contained in
IUs, the less semantic ambiguity in translation,
or the later the response is obtained. Because of
time restrictions, deterministic processing by
exploiting specious measures (e.g. linguistical
or statistical plausibility) is required for each IU
translation in order to shorten the length of His.
• How to install simultaneous interpreters&apos;
know-how (i.e. empirical knowledge) — In
practical simultaneous interpretation, human
</listItem>
<bodyText confidence="0.929290111111111">
translators generally use strong sentence
planning using particular empirical know-how.
The exploitation of this kind of knowledge is
essential for achieving practical simultaneous
interpretation (Kitano, 1994).
Transfer-Driven Machine Translation (TDMT)
(Furuse, 1994a) (Mima, 1997) has been proposed,
and an efficient method of spoken dialog
translation. TDMT has the following key features:
</bodyText>
<listItem confidence="0.977383">
• Utilization of Constituent Boundary Patterns
(CB-Patterns) (Furuse, 1994b) (Furuse, 1996)
— CB-Patterns based on meaningful information
</listItem>
<bodyText confidence="0.88183275">
units are applied to parse an input incrementally
and produce translations based on the
synchronization of the source and target
language structure pairs (Abeille, 1990) (Shieber,
1990). This contrasts with the linguistic manner
of applying grammar rules.
The result of this provides for incremental
translations that can even handle lengthy input
</bodyText>
<note confidence="0.359663">
t Current affiliation: Department of Computing, Manchester Metropolitan University, Manchester M1 5GD, U.K.
</note>
<footnote confidence="0.767239">
Current affiliation: NTT Communication Science Laboratories, 2-4 Hikaridai Seika-cho Soraku-gun, Kyoto 619-
0237, Japan.
</footnote>
<page confidence="0.994999">
855
</page>
<listItem confidence="0.902684">
efficiently by splitting the input into appropriate
and meaningful chunks. In addition,
• Existence of efficient disambiguation scheme
— by dealing with best-only substructures
utilizing stored empirical translation examples
compiled from a linguistic database, the
explosion of structural ambiguities is
significantly constrained (Furuse, 1996).
</listItem>
<bodyText confidence="0.9983035">
Accordingly, TDMT has the advantage of having
both the capability to define effective IU and an
efficient deterministic processing scheme in
incremental spoken-language translation.
Additionally, in exploiting the empirical
knowledge that is required in practical
simultaneous interpretation, we can assume that
the empirical knowledge is described within the
linguistic resource of simultaneous interpretation
corpora. (Harbusch, 1992) proposed a method of
default handling in incremental generation based
on this observation.
In this paper, we describe the achievement of
practical simultaneous interpretation using a
TDMT. Furthermore, we discuss what kind of
empirical knowledge is required for realizing
efficient simultaneous interpretation, in terms of a
simultaneous translator&apos;s knowledge, as well as
proposing a method to exploit this empirical
knowledge in an example-based framework in
order to produce consistent translations.
A preliminary experiment analyzing our proposed
scheme indicates that it should be able to be used in
achieving simultaneous interpretation systems.
The next section of the paper briefly explains
incremental translation using TDMT. Section 2
discusses the type of empirical knowledge
necessary in simultaneous interpretation using
some examples. Section 3 describes our proposed
scheme for exploiting simultaneous interpretation
examples. Section 4 presents a preliminary
experiment for analyzing our proposed scheme to
confirm its feasibility. Section 5 examines some
related research in the field of incremental
translation. Finally, a summary of our approach
concludes this paper.
</bodyText>
<sectionHeader confidence="0.98684" genericHeader="method">
1 Incremental Translation Using
Transfer-Driven Machine Translation
</sectionHeader>
<subsectionHeader confidence="0.999453">
1.1 Constituent Boundary Pattern
</subsectionHeader>
<bodyText confidence="0.9995563125">
In TDMT, translation is performed by applying
stored empirical transfer knowledge, which
describes the correspondence between source
language expressions and target language
expressions at various linguistic levels. The source
and target expressions from the transfer knowledge
in TDMT are expressed as CB-Patterns, which
represent meaningful units for linguistic structure
and transfer. The efficient application of transfer
knowledge source components to an input string
plays a key role in our basic incremental
translation scheme. A pattern is defined as a
sequence that consists of variables and constituent
boundaries such as surface functional words.
The transfer knowledge is compiled from actual
translation examples in every source pattern.
</bodyText>
<subsectionHeader confidence="0.980168">
1.2 Incremental Pattern Application
</subsectionHeader>
<bodyText confidence="0.999736166666667">
The incremental application of CB-Patterns is
based on the idea of incremental chart parsing
(Furuse, 1996) (Amtrup, 1995) with notions of
linguistic levels.
The procedure for the application of CB-
Patterns is as follows:
</bodyText>
<listItem confidence="0.9193045">
(a) Determination of possible pattern applications.
(b) Translation candidate determination and
structural disambiguation of patterns by
semantic distance calculation.
</listItem>
<bodyText confidence="0.995470275862069">
Our scheme determines the best translation and
structure parallel with an input sequence and can
restrain the number of competing structures
(possible translation candidates) at the possible
utterance point in the input by performing (a) in
parallel with (b), thus reducing the translation costs
in time. The structure selected in (b) has its result
transferred with head word-information using
semantic distance calculations when combined
incrementally with other structures. The output
sentence is generated as a translation result from
the structure for the whole input, which is
composed of best-first substructures.
In order to limit the combinations of patterns
and control the appropriate timing of each partial
utterance during pattern application, we distinguish
pattern levels, and specify the linguistic sublevel
permitted for use in the assigned variables for each
linguistic level. This is because if any
combinations of patterns are permitted, it is
obvious that the possibility of combinations are
easily exploded. Table 1 shows examples of the
relationship between linguistic levels. Every CB-
pattern is categorised as one of the linguistic levels,
and a variable on a given level is instantiated by a
string on the linguistic levels in the second column
of Table 1.
For instance, in the noun phrase &amp;quot;X of r, the
variables X and Y cannot be instantiated by a
</bodyText>
<page confidence="0.99335">
856
</page>
<bodyText confidence="0.895363">
simple sentence pattern, but can be instatiated by
NP such as a noun phrase pattern or a compound
noun pattern.
Moreover, these levels give a guideline to the
timing of utterance production (i.e. the timing of
when an utterance is said). For example, each
simple sentence level pattern has utterance
markers (Table 2, where &apos;I&apos; indicates the
utterance markers) for possible insertion of an
utterance during left-to-right application of the
pattern. Thus, redundant or incomplete partial
matchings can be eliminated and an appropriate
trigger of utterance can be obtained.
(Furuse, 1996) provides further details of the
algorithm for incremental CB-Parsing.
</bodyText>
<tableCaption confidence="0.995896">
Table 1 Possible linguistic sublevels in variables
Table 2 Utterance markers
</tableCaption>
<subsectionHeader confidence="0.989096">
1.3 Disambiguation of Translation
Candidate
</subsectionHeader>
<bodyText confidence="0.9981986">
The CB-pattern &amp;quot;X no Y&amp;quot; with the particle &amp;quot;no&amp;quot; is
a frequently used expression in Japanese. We can
observe the following Japanese-to-English
transfer knowledge about &amp;quot;X no Y&amp;quot; from such
translation examples as the source-target pairs of:
</bodyText>
<construct confidence="0.796261125">
&amp;quot;hoteru jasho&amp;quot; —) &amp;quot;the address of the hotel&amp;quot;,
-eigo no paNfuretto&amp;quot; —&gt; &amp;quot;the pamphlet written in
English&amp;quot;, etc.
X no Y =&gt;
Y&apos; of X&apos; ((hoteru , jasho), ...),
&apos;hotel&apos; &apos;address&apos;
&apos;
Y&apos; written in X&apos; ((eigo, paNfuretto), ...),
</construct>
<subsectionHeader confidence="0.19398">
&apos;English&apos; pamphlee
</subsectionHeader>
<bodyText confidence="0.983411621621622">
Y&apos; for X&apos; ((asu, tenko), ...),
&apos;tomorrow&apos; &apos;weather&apos;
Within this pattern, X&apos; is the target word
corresponding to X, and a corresponding English
word is written below each Japanese word. For
example, &amp;quot;hoteru&amp;quot; means &apos;hotel&apos;, and &amp;quot;jeisho&amp;quot;
means &apos;address &apos; .
This transfer knowledge expression indicates
that the Japanese pattern &amp;quot;X no I&amp;quot; corresponds to
many possible English expressions. (hoteru,
jiisho) are sample bindings for &amp;quot;X no 1&apos;, where X
= hoteru, and Y =Asko.
TDMT makes the most of an example-based
framework, which produces an output sentence by
mimicking the closest translation example to an
input sentence. The semantic distance from the
input is calculated for all examples. Then the
example closest to the input is chosen, and the
target expression of that example is extracted.
Suppose that the input is &amp;quot;nihoNgo no
paNfuretto&amp;quot;, where nihoNgo means &apos;Japanese&apos;,
and the input is closest to (eigo, paNfuretto); &amp;quot;the
pamphlet written in Japanese&amp;quot; can be gained by
choosing Y&apos; written in X&apos; as the best target
expression.
Furthermore, ambiguity in the combination of
patterns, which have not been constrained by the
linguistic levels, is also dissolved incrementally by
using the total sum of the semantic distances of
patterns contained (Furuse, 1996).
The distance between an input and a translation
example is measured based on the semantic
distance between the words contained, and the
semantic distance between words is calculated in
terms of a thesaurus hierarchy. (Sumita, 1991)
provides further details of the semantic distance
caluculation.
</bodyText>
<sectionHeader confidence="0.730823" genericHeader="method">
2 Exploitation of a Simultaneous
Interpreter&apos;s Empirical Knowledge
</sectionHeader>
<bodyText confidence="0.996809333333333">
In practical simultaneous interpretation, human
translators generally use strong sentence planning
such as transformation between the active and the
passive voice, transformation from a lengthy
interrogative sentence to a tag question, and
topicalization transformation. Moreover, the input
is produced and modified in a step-by-step manner,
so that it can be temporarily incomplete — although
as a whole sentence it may become sufficient.
Thus, the consistency of translations has to be
adjusted appropriately when a contradiction occurs
between a previously uttered part of the translation
and the part currently being translated.
As a consequence of under specification,
simultaneous interpretation is essentially based on
</bodyText>
<table confidence="0.9811887">
Linguistic level
Simple sentence
Verb phrase (VP)
Noun phrase (NP)
compound noun (CN)
Sublevels of variables
VP, NP,
VP, NP, verb, ...
NP, CN, proper-noun, ...
CN, noun, ...
</table>
<figure confidence="0.574519583333333">
En•lish attern
By the way I X
No I X
X but I Y
X if I Y
X I where Y
Ja anese Pattern
tokorode I X&apos;
iie I X&apos;
X&apos; I shikashi Y&apos;
X&apos; I moshi Y&apos;
X&apos; I Y&apos;
</figure>
<page confidence="0.986535">
857
</page>
<bodyText confidence="0.999671333333333">
working with empirical knowledge — e.g.
simultaneous interpreters&apos; translation examples.
In this section, we first describe the kinds of
examples that are required to achieve
simultaneous interpretation using some sample
sentences.
</bodyText>
<subsectionHeader confidence="0.915421">
2.1 Empirical Knowledge
</subsectionHeader>
<listItem confidence="0.817455">
• Transformation to a tag question
</listItem>
<bodyText confidence="0.941581666666667">
Let us consider the following Japanese utterance:
(El) Nani-mo moNdai-wa ari-maseN -&lt;pause&gt;-
de-sho-ka. (what problem exist -&lt;pause&gt;- is
there)&apos;
In Japanese, an interrogative is specified at the
end of the sentence, while in English, it is
generally specified in front of the sentence. Thus,
although a translation of the whole sentence of
(El) is &apos;Is everything all right&apos;, in some cases,
&apos;Everything is all right&apos; could be uttered after the
pause in the incremental framework. In this case,
the meaning of the previously uttered part is no
longer consistent with the current translation.
However, even in this case, translation can be
continued transforming to a tag question as (E1)&apos;
by using a peculiar translation example [TE1]
without interruption by semantic inconsistency
and the insertion of a restatement.
</bodyText>
<equation confidence="0.444405333333333">
[TE1] (X de-sho-ka) -4 (X&apos;, isn&apos;t it)
(E1)&apos; Everything is alright, isn&apos;t it.({[TE1]: X&apos; =
&apos;Everything is alright&apos;))
</equation>
<listItem confidence="0.559135">
• Negative sentence
</listItem>
<bodyText confidence="0.966973423076923">
Let us consider the following utterance:
(E2) TsuiNramu-wa gozai-masu -&lt;pause&gt;- ga,
hoNjitsu-wa goriyo-ni-nare-maseN. (twin
room exist -&lt;pause&gt;- but today not-
available)
In Japanese, negation is also specified at the end
of the sentence while in English it has to be
specified in front of the finite verb. In addition, an
expression &amp;quot;X wa gozai-nzasu&amp;quot; in (E2) has
possible translations as &amp;quot;we have X— or &amp;quot;X&apos; is
available&amp;quot;. Thus, although the whole translation
should ideally read as &amp;quot;We have twin rooms, but
none are available today&amp;quot;, &amp;quot;A twin room is
available&amp;quot; might be selected as a part of the
translation in some cases. Although one solution
could be to restate previously uttered phrases such
In this paper, sample Japanese is Romanized in italic
based on the Hepburn system with the corresponding
English words following in parentheses.
as: &amp;quot;no, sorry, we do have twin rooms, but none
.....&amp;quot;, such restatements should not be used
frequently. This is because the restatements tend to
break in general, coherency of human interaction
However, in this case, translation can be
continued as (E2)&apos; by using a peculiar translation
example [TE2], with no restatement.
</bodyText>
<equation confidence="0.724963">
[TE2] (X ga, Y) —&gt; (X&apos; usually, but Y&apos;)
</equation>
<bodyText confidence="0.733844">
(E2)&apos; A twin room is available usually. but we do
not have any vacancies today. (([TE2]: X&apos;=
&apos;A twin room is available&apos;, Y&apos;=&apos;we do not
have any vacancies today&apos; ))
</bodyText>
<listItem confidence="0.612978">
• Failure of prediction
</listItem>
<bodyText confidence="0.998029888888889">
In simultaneous interpretation, elements are
usually uttered before the input consumption has
been finished. Thus, because of the uncertainty in
assumptions, a system with this facility must be
able to adjust the whole content of the translation
when it is realized that the assumption is incorrect
from information given later.
Consider the following English utterance:
(E3) That restaurant is open -&lt;pause&gt;- as only as
in the evening.
In the case of the part of the translation already
uttered, &amp;quot;sono-resutoraN-wa opuN-shite-I-masu&amp;quot;,
it should have been inserted &amp;quot;yoru nomi&amp;quot; in front
of the phrase &amp;quot;opuN-shite-1-masu&amp;quot;, when the
whole sentence is translated.
However the translation can be continued as it is
as in (E3)&apos; by using a peculiar translation example
[TE3].
</bodyText>
<equation confidence="0.9891716">
[TE3] (X as only as Y) —&gt; (X&apos; 1-masu, ga, Y&apos; nomi-
desu)
(E3)&apos; Sono-resutoraN-wa opuN-shite I-masu, ga,
yoru nomi-desu ({[TE3]: X&apos;= &apos;opuN-shite&apos; ,
Y&apos;=&apos;yoru&apos;))
</equation>
<bodyText confidence="0.999991125">
As the above example shows, simultaneous
interpretation as skilled as that performed by a
human interpreter is achievable by exploiting
peculiar translation examples - i.e. simultaneous
interpretation examples (or SI-examples, in short).
In the next section, we propose an algorithm to
handle these kinds of SI-example with the best-
first example-based incremental MT mechanism.
</bodyText>
<sectionHeader confidence="0.992743" genericHeader="method">
3 Simultaneous Interpretation Algorithm
</sectionHeader>
<bodyText confidence="0.9997852">
Although the main characteristic of example-based
translation is the use of the most similar examples
as the main knowledge source for translation, the
exploitation of SI-examples is drawn from the
following consideration:
</bodyText>
<page confidence="0.994079">
858
</page>
<listItem confidence="0.662181">
• A translation should use an example consis-
tent with previously uttered information
</listItem>
<bodyText confidence="0.856347">
Thus, the key translation process with exploiting
SI-examples consists of the following stages:
</bodyText>
<listItem confidence="0.94583525">
(1) Checking the contextual consistency between
previously uttered phrases2 and the phrase to
be uttered next.
(2) Retrieving the most plausible example
according to both the contextual sequence and
similarity.
(3) Re-translating the phrase to be uttered next by
using the example retrieved in (2)
</listItem>
<bodyText confidence="0.9999436875">
The algorithm is described as follows. In the
algorithm, the input phrase to be considered as a
combination of structures shown in Figure 1 to
facilitate understanding of the algorithm. For
example, in the case of (E3), ST, indicates &amp;quot;The
restaurant is open&amp;quot;, ST2 indicates &amp;quot;open as only
as in the evening&amp;quot;, and ST1,2 indicates the whole
phrase. In addition, trans(ST1) returns word
sequence indicating translation of ST,,, trans(ST1,
E) also returns word sequence indicating the
translation of ST, using example E, and i indicates
the current processing part. Since the algorithm
for the exploitation of SI-examples is applied only
if a previous translated phrase exists, the
proposed algorithm is executed in the case of
i&gt;=2.
</bodyText>
<sectionHeader confidence="0.944976" genericHeader="method">
Algorithm:
Start.
</sectionHeader>
<listItem confidence="0.996525333333333">
1. Retrieve the similar examples of ST, from the
total example database (normal + SI-examples)
and assign the list to the {SE} with the
appropriate semantic distance.
2. Produce trans(ST1, E), where E indicates the
most similar example listed in {SE).
3. Remove the example E from (SE).
4. If trans(ST1, E) == trans( ST1.1) +3 trans(ST1,
E)4,
</listItem>
<footnote confidence="0.694637083333333">
2 In this paper, we only state the context within a
sentence and do not refer to contexts between dialogs.
3 Indicating sequencial appending operation, which
includes removal operation of the common sub-
sequence among the last of the first item and the first
of the second item. For example, word sequences &amp;quot;A
B&amp;quot; + word sequences &amp;quot;B C&amp;quot; indicates &amp;quot;A B C&amp;quot;.
4 i.e. trans(ST1) and trans(ST1) are contextually
continuous. In this paper, we define contextually
continuous from the view point of sequences of
concrete words (phrases) contained, in terms of
combination with an example-based framework.
</footnote>
<figureCaption confidence="0.998723">
Figure 1 Notation of Substructures
</figureCaption>
<bodyText confidence="0.866714">
then, output the difference between trans(ST1,
E) and trans(ST1,), then goto End.
</bodyText>
<listItem confidence="0.597435">
5. Goto 2.
</listItem>
<subsectionHeader confidence="0.687636">
End.
</subsectionHeader>
<bodyText confidence="0.9963011875">
In the majority of conventional example-based
frameworks, only a semantic similarity is
considered in retrieving the examples to be applied.
In our scheme, on the other hand, not only
semantic similarity but also contextual consistency
with the previous translation is considered. In other
words, the key notion of the scheme is its
mechanism for selecting appropriate examples.
Hence, as the above algorithm shows, exploitation
of SI-examples can be combined smoothly with
the conventional example-based framework.
Let us explain the algorithm in terms of sentence
(E3) as an example. First, assuming that
trans(ST1) = &amp;quot;Sono-resutoraN-wa opuN-shite I -
masu&amp;quot; (the-restaurant open), the most similar
example of ST2 is normally:
</bodyText>
<equation confidence="0.802539">
[TE4] (X as only as Y) (Y&apos; nomi X&apos; I-masu)
</equation>
<bodyText confidence="0.992337166666667">
Thus, trans(ST2, TE4) can be &amp;quot;yoru nomi OpuN-
shite 1-masu&amp;quot; (evening only open) and as the
phrase &amp;quot;yoru nomi ...&amp;quot; is, in this case, not
contextually continuous, and the next example
should be extracted from the similar example list
{SE). Then, the example is [TE3J, since trans(ST2,
TE3) = &amp;quot;opuN-shite ga, yoru nomi-desu&amp;quot;,
in terms of the contextual order of the words, this
translation can be continuous. Thus, the difference
between trans(ST1) and the trans(ST2, TE3), &amp;quot;go,
yoru nomi-desu&amp;quot; can be obtained as the next
utterance.
</bodyText>
<figure confidence="0.952605727272727">
desu
The restaurant is
open
as o y as in
e evening
trans(ST1):
Sono-resutoraN-wa opuN-shite I-masu
&gt;-,
Output
trans(ST2):
dpuN-shite 1-masu,,Aga, yoru norm
</figure>
<page confidence="0.995838">
859
</page>
<sectionHeader confidence="0.983205" genericHeader="method">
4 Preliminary Experiments
</sectionHeader>
<bodyText confidence="0.983598346938775">
We conducted a preliminary experiment with
respect to (a) the quality of example-based
translation in relation to IUs (i.e., meaningful
units), and (b) the quality and speed of
incremental parsing (CB-Parsing), to confirm the
feasibility of our proposed scheme.
In the evaluation of (a), we conducted a jack-
knife experiment to measure the average success
rate of translation for the most frequently used
expressions (i.e. the most ambiguous) in Japanese,
&amp;quot;X no Y&amp;quot; and &amp;quot;X wo Y&amp;quot;. We prepared 774 and 689
examples for the expressions respectively, and
conducted the experiment in increments of 100
examples (Furuse, 1994a). The examples were
extracted by random sampling. We then evaluated
the 10 translations of corresponding expressions
in the dialog database for each case.
Figure 2 shows the average rate of the
evaluation for 10 translations.
Although the translation quality of each unit
depended on the type of expression, the graph
shows that, in general, the more examples the
system has, the better the quality5.
Conditions of our experiment and evaluation
for (b) are that the number of CB-patterns for
Japanese-English translation and English-
Japanese translation are 777 and 1241,
respectively, and the number of total examples
are 10000 and 8000, respectively. In the
evaluation, we set the system to retain only one
substructure in the semantic distance calculation
in order to confirm the feasibility of deterministic
processing at each incremental step.
CB-Parsing for 69-77 unseen dialogs (of 1,000
different unseen sentences) were manually
evaluated by assigning a grade indicating success
or failure. All of the parsing times include
accessing time for an example database (i.e.
corresponding to the whole transfer time) and
were measured on a Sparc Station 10 workstation
with 256 MB of memory.
Table 3 shows the experimental results. For
CB-Parsing accuracy, a success rate of
approximately 76 % was achieved for both
translations, rates that are fairly high for spoken-
language parsing.
5However, we also have to ascertain the practical
satiation limit, or how much the transfer knowledge
can be expanded, as a future work.
</bodyText>
<figure confidence="0.9566833">
- - - -X wo Y
X no Y
100
80
60
40
20
0
100 200 300 400 500 600 700 800
No. of Examples
</figure>
<figureCaption confidence="0.992338">
Figure 2 Quality of Example-based Transfer
</figureCaption>
<tableCaption confidence="0.960942">
Table 3 Evaluation Results
</tableCaption>
<table confidence="0.9981618">
_ J-E E-J
No. of test dialogues (sent.) 69(1225) 77 (1341)
Morphemes / sentence 9.7 7.1
CB-Parsing Accuracy 76.7 % 76.0 %
Parsing Time (average) 0.4 sec. 0.3 sec.
</table>
<bodyText confidence="0.99926823076923">
The main problem in the parsing procedure
involved an insufficient number of examples for
the CB-Pattern. However, as Figure 2 shows, an
increase in the ratio with the number of examples
could be observed with our framework. Thus,
overall accuracy and acceptability should improve
in proportion to an increase in transfer examples.
Although the speed depends on the amount of
knowledge and sentence length, the average time
was less than 0.4 seconds, which is fairly rapid.
Thus, our translation scheme can be seen as an
efficient translation mechanism in achieving a
practical simultaneous interpretation system.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="method">
5 Related Research
</sectionHeader>
<bodyText confidence="0.999397384615385">
Several schemes have been proposed with respect to
incremental translation based on the synchronization
of input and output fragments and the use of
specialized information for simultaneous
interpretation. (Kitano, 1994) proposes incremental
translation that is based on marker-passing memory-
based translation. Although the technique adopts a
cost-oriented best-first strategy to avoid the
explosion of structural ambiguity, the strategy does
not pay attention to actual aspects of the overall
meaning such as in the case when a previously made
assumption turns out to be incorrect. (Matsubara,
1997) proposed a method to handle extra-
</bodyText>
<page confidence="0.984072">
860
</page>
<bodyText confidence="0.999803909090909">
grammatical phenomena with a chart-based
incremental English-Japanese MT system based
on observations of a translation corpus. However,
this system was only capable of English to
Japanese translation. In this paper, the aspects of
flexible order, repetitions, and ellipses are only
briefly considered and necessary extensions, such
as the adjustment of consistency in related to the
whole sentence by employing simultaneous
interpreters&apos; knowledge have not been previously
investigated.
</bodyText>
<sectionHeader confidence="0.911841" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.990486782608696">
We have described a practical method of
automatic simultaneous interpretation. In the
exploitation of empirical knowledge, we
examined the kind of empirical knowledge
required to achieve efficient simultaneous
interpretation. We then have proposed a method
to exploit these empirical simultaneous translation
examples in an example-based framework to
produce a practical method of simultaneous
interpretation.
Preliminary experimentation analyzing our
proposed scheme showed that it can be utilized to
achieve a simultaneous interpretation system.
The possibility of applying this sort of
example-based framework into multilingual
translation, such as a Japanese-German pair and a
Japanese-Korean pair, has been shown in (Furuse,
1995) and (Mima, 1997). Therefore, the algorithm
can also be expected to work for not only an
English-Japanese pair but also other language
pairs.
Important areas of future research will involve
methods for:
</bodyText>
<listItem confidence="0.896164">
• Predicting the contents of the next
utterance by using dialog-specific discourse
analysis (Levin, 1995)
• Handling linguistic differences between the
source and target languages such as
</listItem>
<subsectionHeader confidence="0.427471">
subject ellipsis
</subsectionHeader>
<bodyText confidence="0.999912777777778">
We believe that some situational information,
such as the speakers-roles in the conversation
(Mima, 1997) could be potentially helpful for
both predicting the contents of the next utterance
and resolving linguistic differences. The
integration of statistical/stochastic approaches,
such as Decision-Tree Learning (Yamamoto,
1997) for the above discourse-related issues is
another area of interest for future work.
</bodyText>
<sectionHeader confidence="0.99641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999888862745098">
A. Abeille, Y. Schabes and A. K. Joshi (1990) Using
Lexicalized Tags for Machine Translation. In Proc. of
Coling&apos;90, pages 1-6.
J. W. Amtrup (1995) Chart-based Incremental Transfer
in Machine Translation. In Proc. of 6&apos; TMI. pages
188-195.
0. Furuse, E. Sumita, and H. Iida (1994a) Transfer-
Driven Machine Translation Utilizing Empirical
Knowledge (in Japanese). Trans. of Information
Processing Society of Japan. Vol. 35, No. 3, pages
414-425.
0. Furuse, and H. Iida (1994b) Constituent Boundary
Parsing for Example-Based Machine Translation. In
Proc. of Coling &apos;94, pages 105-111.
0. Furuse, J. Kawai, H. Iida, S. Akamine, and D. Kim
(1995) Multi-lingual Spoken-Language Translation
Utilizing Translation Examples. In Proc. of
NLPRS&apos;95, pages 544-549.
0. Furuse and H. Iida (1996) Incremental Translation
Utilizing Constituent Boundary patterns. In Proc. of
Coling &apos;96, pages 412-417.
K. Harbusch, G. Kikui, and A. Kilger (1994) Default
Handling in Incremental Generation. In Proc. of
Coling&apos;94. pages 356-362.
M. A. K. Halliday (1994) An Introduction to Functional
Grammar. Edward Arnold.
H. Kitano (1994) The 0 DM-DIALOG System. In
Speech-To-Speech Translation. H. Kitano. Kluwer
Academic Publishers. Pages 47-113.
L. Levin, 0. Glickman, Y. Qu, D. Gates, A. Lavie, C. P.
Rosé, C. V. Ess-Dykema and A. Waibel (1995) Using
Context in Machine Translation of Spoken Language.
In Proc. of 6&apos; TMI. pages 173-187.
S. Matsubara and Y. Inagaki (1997) Utilizing Extra-
grammatical Phenomena in Incremental English-
Japanese Machine Translation. In Proc. of 7&apos; TMI.
pages 31-38.
H. Mima, 0. Furuse, and H. Iida (1997) Improving
Performance of Transfer-Driven Machine
Translation with Extra-linguistic Information from
Context, Situation, and Environment. In Proc. of
IJCAF97. pages 983-988.
S. M. Shieber and Y. Schabes (1990) Synchronous
Tree-Adjoining Grammars. In Proc. of Coling&apos;90,
pages 253-258.
E. Sumita and H. Iida (1991) Experiments and
Prospects of Example-based Machine Translation. In
Proc. of 29&apos; ACL. pages 185-192.
K. Yamamoto, E. Sumita, 0. Furuse, and H. Iida (1997)
Ellipsis Resolution in Dialogues via Decision-Tree
Learning. In Proc. of NLPRS&apos;97. pages 423-428.
</reference>
<page confidence="0.998374">
861
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.724572">
<title confidence="0.999625">Simultaneous Interpretation Utilizing Example-based Incremental Transfer</title>
<author confidence="0.735993">Hideki Mime</author>
<author confidence="0.735993">Hitoshi Iida</author>
<author confidence="0.735993">Osamu Furuse</author>
<affiliation confidence="0.922275">ATR Interpreting Telecommunications Research Laboratories</affiliation>
<address confidence="0.98544">2-2 Hikaridai Seika-cho Soraku-gun Kyoto 619-0288, Japan</address>
<email confidence="0.995081">H.Mima@doc.mmu.ac.uk,iida@itl.atr.co.jp,furuse@cslab.kecl.ntt.co.jp</email>
<abstract confidence="0.999209125">This paper describes a practical method of automatic simultaneous interpretation utilizing an example-based incremental transfer mechanism. We primarily show how incremental translation is achieved in the context of an example-based framework. We then examine the type of translation examples required for a simultaneous interpretation to create naturally communicative dialogs. Finally, we propose a scheme for automatic simultaneous interpretation exploiting this example-based incremental translation mechanism. Preliminary experimentation analyzing the performance of our example-based incremental translation mechanism leads us to believe that the proposed scheme can be utilized to achieve a practical simultaneous interpretation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeille</author>
<author>Y Schabes</author>
<author>A K Joshi</author>
</authors>
<title>Using Lexicalized Tags for Machine Translation.</title>
<date>1990</date>
<booktitle>In Proc. of Coling&apos;90,</booktitle>
<pages>1--6</pages>
<marker>Abeille, Schabes, Joshi, 1990</marker>
<rawString>A. Abeille, Y. Schabes and A. K. Joshi (1990) Using Lexicalized Tags for Machine Translation. In Proc. of Coling&apos;90, pages 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W</author>
</authors>
<title>Amtrup</title>
<date>1995</date>
<booktitle>In Proc. of 6&apos; TMI.</booktitle>
<pages>188--195</pages>
<marker>W, 1995</marker>
<rawString>J. W. Amtrup (1995) Chart-based Incremental Transfer in Machine Translation. In Proc. of 6&apos; TMI. pages 188-195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita Furuse</author>
<author>H Iida</author>
</authors>
<title>TransferDriven Machine Translation Utilizing Empirical Knowledge (in</title>
<date>1994</date>
<journal>Japanese). Trans. of Information Processing Society of Japan.</journal>
<volume>35</volume>
<pages>414--425</pages>
<marker>Furuse, Iida, 1994</marker>
<rawString>0. Furuse, E. Sumita, and H. Iida (1994a) TransferDriven Machine Translation Utilizing Empirical Knowledge (in Japanese). Trans. of Information Processing Society of Japan. Vol. 35, No. 3, pages 414-425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Furuse</author>
<author>H Iida</author>
</authors>
<title>Constituent Boundary Parsing for Example-Based Machine Translation.</title>
<date>1994</date>
<booktitle>In Proc. of Coling &apos;94,</booktitle>
<pages>105--111</pages>
<marker>Furuse, Iida, 1994</marker>
<rawString>0. Furuse, and H. Iida (1994b) Constituent Boundary Parsing for Example-Based Machine Translation. In Proc. of Coling &apos;94, pages 105-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kawai Furuse</author>
<author>H Iida</author>
<author>S Akamine</author>
<author>D Kim</author>
</authors>
<title>Multi-lingual Spoken-Language Translation Utilizing Translation Examples.</title>
<date>1995</date>
<booktitle>In Proc. of NLPRS&apos;95,</booktitle>
<pages>544--549</pages>
<marker>Furuse, Iida, Akamine, Kim, 1995</marker>
<rawString>0. Furuse, J. Kawai, H. Iida, S. Akamine, and D. Kim (1995) Multi-lingual Spoken-Language Translation Utilizing Translation Examples. In Proc. of NLPRS&apos;95, pages 544-549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Furuse</author>
<author>H Iida</author>
</authors>
<title>Incremental Translation Utilizing Constituent Boundary patterns.</title>
<date>1996</date>
<booktitle>In Proc. of Coling &apos;96,</booktitle>
<pages>412--417</pages>
<marker>Furuse, Iida, 1996</marker>
<rawString>0. Furuse and H. Iida (1996) Incremental Translation Utilizing Constituent Boundary patterns. In Proc. of Coling &apos;96, pages 412-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Harbusch</author>
<author>G Kikui</author>
<author>A Kilger</author>
</authors>
<title>Default Handling in Incremental Generation.</title>
<date>1994</date>
<booktitle>In Proc. of Coling&apos;94.</booktitle>
<pages>356--362</pages>
<marker>Harbusch, Kikui, Kilger, 1994</marker>
<rawString>K. Harbusch, G. Kikui, and A. Kilger (1994) Default Handling in Incremental Generation. In Proc. of Coling&apos;94. pages 356-362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>An Introduction to Functional Grammar. Edward Arnold.</title>
<date>1994</date>
<contexts>
<context position="2079" citStr="Halliday, 1994" startWordPosition="253" endWordPosition="254">fy these requirements, an incremental translation system, which functions as a simultaneous interpreter, is seen as an efficient solution in this field. The main characteristic of incremental translations is the translation process. This is activated synchronously with the input, in contrast with conventional sentence-by-sentencebased translation which cannot start processing until the end of an input (Kitano, 1994). However, in incremental translation, we believe that the following issues must be resolved to achieve actual simultaneous interpretation: • How to define Information Units (IUs) (Halliday, 1994) to determine appropriate components for translation — Since differences exist among the word order of various languages, especially between linguistically distant languages such as English and Japanese, appropriate transfer units, equally effective for both the source and target languages, have to be defined. • How to determine plausible translation for each IU — In terms of the information content, the greater the number of words contained in IUs, the less semantic ambiguity in translation, or the later the response is obtained. Because of time restrictions, deterministic processing by explo</context>
</contexts>
<marker>Halliday, 1994</marker>
<rawString>M. A. K. Halliday (1994) An Introduction to Functional Grammar. Edward Arnold.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kitano</author>
</authors>
<title>The 0 DM-DIALOG System. In Speech-To-Speech Translation.</title>
<date>1994</date>
<pages>47--113</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1883" citStr="Kitano, 1994" startWordPosition="226" endWordPosition="227">puts to avoid interrupting the coherency of communications. Therefore, a high degree of incrementality and acceptability in translation such as simultaneous interpretation is essential. To satisfy these requirements, an incremental translation system, which functions as a simultaneous interpreter, is seen as an efficient solution in this field. The main characteristic of incremental translations is the translation process. This is activated synchronously with the input, in contrast with conventional sentence-by-sentencebased translation which cannot start processing until the end of an input (Kitano, 1994). However, in incremental translation, we believe that the following issues must be resolved to achieve actual simultaneous interpretation: • How to define Information Units (IUs) (Halliday, 1994) to determine appropriate components for translation — Since differences exist among the word order of various languages, especially between linguistically distant languages such as English and Japanese, appropriate transfer units, equally effective for both the source and target languages, have to be defined. • How to determine plausible translation for each IU — In terms of the information content, </context>
<context position="3166" citStr="Kitano, 1994" startWordPosition="405" endWordPosition="406">biguity in translation, or the later the response is obtained. Because of time restrictions, deterministic processing by exploiting specious measures (e.g. linguistical or statistical plausibility) is required for each IU translation in order to shorten the length of His. • How to install simultaneous interpreters&apos; know-how (i.e. empirical knowledge) — In practical simultaneous interpretation, human translators generally use strong sentence planning using particular empirical know-how. The exploitation of this kind of knowledge is essential for achieving practical simultaneous interpretation (Kitano, 1994). Transfer-Driven Machine Translation (TDMT) (Furuse, 1994a) (Mima, 1997) has been proposed, and an efficient method of spoken dialog translation. TDMT has the following key features: • Utilization of Constituent Boundary Patterns (CB-Patterns) (Furuse, 1994b) (Furuse, 1996) — CB-Patterns based on meaningful information units are applied to parse an input incrementally and produce translations based on the synchronization of the source and target language structure pairs (Abeille, 1990) (Shieber, 1990). This contrasts with the linguistic manner of applying grammar rules. The result of this pro</context>
<context position="23930" citStr="Kitano, 1994" startWordPosition="3576" endWordPosition="3577">ccuracy and acceptability should improve in proportion to an increase in transfer examples. Although the speed depends on the amount of knowledge and sentence length, the average time was less than 0.4 seconds, which is fairly rapid. Thus, our translation scheme can be seen as an efficient translation mechanism in achieving a practical simultaneous interpretation system. 5 Related Research Several schemes have been proposed with respect to incremental translation based on the synchronization of input and output fragments and the use of specialized information for simultaneous interpretation. (Kitano, 1994) proposes incremental translation that is based on marker-passing memorybased translation. Although the technique adopts a cost-oriented best-first strategy to avoid the explosion of structural ambiguity, the strategy does not pay attention to actual aspects of the overall meaning such as in the case when a previously made assumption turns out to be incorrect. (Matsubara, 1997) proposed a method to handle extra860 grammatical phenomena with a chart-based incremental English-Japanese MT system based on observations of a translation corpus. However, this system was only capable of English to Jap</context>
</contexts>
<marker>Kitano, 1994</marker>
<rawString>H. Kitano (1994) The 0 DM-DIALOG System. In Speech-To-Speech Translation. H. Kitano. Kluwer Academic Publishers. Pages 47-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qu Glickman</author>
<author>D Gates</author>
<author>A Lavie</author>
<author>C P Rosé</author>
<author>C V Ess-Dykema</author>
<author>A Waibel</author>
</authors>
<title>Using Context in Machine Translation of Spoken Language.</title>
<date>1995</date>
<booktitle>In Proc. of 6&apos; TMI.</booktitle>
<pages>173--187</pages>
<marker>Glickman, Gates, Lavie, Rosé, Ess-Dykema, Waibel, 1995</marker>
<rawString>L. Levin, 0. Glickman, Y. Qu, D. Gates, A. Lavie, C. P. Rosé, C. V. Ess-Dykema and A. Waibel (1995) Using Context in Machine Translation of Spoken Language. In Proc. of 6&apos; TMI. pages 173-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Matsubara</author>
<author>Y Inagaki</author>
</authors>
<title>Utilizing Extragrammatical Phenomena in Incremental EnglishJapanese Machine Translation.</title>
<date>1997</date>
<booktitle>In Proc. of 7&apos; TMI.</booktitle>
<pages>31--38</pages>
<marker>Matsubara, Inagaki, 1997</marker>
<rawString>S. Matsubara and Y. Inagaki (1997) Utilizing Extragrammatical Phenomena in Incremental EnglishJapanese Machine Translation. In Proc. of 7&apos; TMI. pages 31-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Furuse</author>
<author>H Iida</author>
</authors>
<title>Improving Performance of Transfer-Driven Machine Translation with Extra-linguistic Information from Context, Situation, and Environment.</title>
<date>1997</date>
<booktitle>In Proc. of IJCAF97.</booktitle>
<pages>983--988</pages>
<marker>Furuse, Iida, 1997</marker>
<rawString>H. Mima, 0. Furuse, and H. Iida (1997) Improving Performance of Transfer-Driven Machine Translation with Extra-linguistic Information from Context, Situation, and Environment. In Proc. of IJCAF97. pages 983-988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
<author>Y Schabes</author>
</authors>
<title>Synchronous Tree-Adjoining Grammars.</title>
<date>1990</date>
<booktitle>In Proc. of Coling&apos;90,</booktitle>
<pages>253--258</pages>
<marker>Shieber, Schabes, 1990</marker>
<rawString>S. M. Shieber and Y. Schabes (1990) Synchronous Tree-Adjoining Grammars. In Proc. of Coling&apos;90, pages 253-258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita</author>
<author>H Iida</author>
</authors>
<title>Experiments and Prospects of Example-based Machine Translation.</title>
<date>1991</date>
<booktitle>In Proc. of 29&apos; ACL.</booktitle>
<pages>185--192</pages>
<marker>Sumita, Iida, 1991</marker>
<rawString>E. Sumita and H. Iida (1991) Experiments and Prospects of Example-based Machine Translation. In Proc. of 29&apos; ACL. pages 185-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamamoto</author>
<author>E Sumita</author>
</authors>
<title>Ellipsis Resolution in Dialogues via Decision-Tree Learning.</title>
<date>1997</date>
<booktitle>In Proc. of NLPRS&apos;97.</booktitle>
<pages>423--428</pages>
<marker>Yamamoto, Sumita, 1997</marker>
<rawString>K. Yamamoto, E. Sumita, 0. Furuse, and H. Iida (1997) Ellipsis Resolution in Dialogues via Decision-Tree Learning. In Proc. of NLPRS&apos;97. pages 423-428.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>