<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005895">
<title confidence="0.9984355">
Improving the Recognizability of Syntactic Relations Using
Contextualized Examples
</title>
<author confidence="0.991801">
Aditi Muralidharan
</author>
<affiliation confidence="0.9969985">
Computer Science Division
University of California, Berkeley
</affiliation>
<address confidence="0.810934">
Berkeley, CA
</address>
<email confidence="0.999152">
asm@berkeley.edu
</email>
<sectionHeader confidence="0.993905" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916333333333">
A common task in qualitative data analy-
sis is to characterize the usage of a linguis-
tic entity by issuing queries over syntac-
tic relations between words. Previous in-
terfaces for searching over syntactic struc-
tures require programming-style queries.
User interface research suggests that it is
easier to recognize a pattern than to com-
pose it from scratch; therefore, interfaces
for non-experts should show previews of
syntactic relations. What these previews
should look like is an open question that
we explored with a 400-participant Me-
chanical Turk experiment. We found
that syntactic relations are recognized with
34% higher accuracy when contextual ex-
amples are shown than a baseline of nam-
ing the relations alone. This suggests
that user interfaces should display contex-
tual examples of syntactic relations to help
users choose between different relations.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998758125">
The ability to search over grammatical relation-
ships between words is useful in many non-
scientific fields. For example, a social scientist
trying to characterize different perspectives on im-
migration might ask how adjectives applying to
‘immigrant’ have changed in the last 30 years. A
scholar interested in gender might search a col-
lection to find out whether different nouns enter
into possessive relationships with ‘his’ and ‘her’
(Muralidharan and Hearst, 2013). In other fields,
grammatical queries can be used to develop pat-
terns for recognizing entities in text, such as med-
ical terms (Hirschman et al., 2005; MacLean and
Heer, 2013), and products and organizations (Cu-
lotta and McCallum, 2005), and for coding quali-
tative data such as survey results.
</bodyText>
<author confidence="0.4462">
Marti A. Hearst
</author>
<affiliation confidence="0.9062545">
School of Information
University of California, Berkeley
</affiliation>
<address confidence="0.592289">
Berkeley, CA
</address>
<email confidence="0.991251">
hearst@berkeley.edu
</email>
<bodyText confidence="0.999656780487805">
Most existing interfaces for syntactic search
(querying over grammatical and syntactic struc-
tures) require structured query syntax. For exam-
ple, the popular Stanford Parser includes Tregex,
which allows for sophisticated regular expression
search over syntactic tree structures (Levy and An-
drew, 2006). The Finite Structure Query tool for
querying syntactically annotated corpora requires
its queries to be stated in first order logic (Kepser,
2003). In the Corpus Query Language (Jakubicek
et al., 2010), a query is a pattern of attribute-
value pairs, where values can include regular ex-
pressions containing parse tree nodes and words.
Several approaches have adopted XML represen-
tations and the associated query language families
of XPATH and SPARQL. For example, LPath aug-
ments XPath with additional tree operators to give
it further expressiveness (Lai and Bird, 2010).
However, most potential users do not have pro-
gramming expertise, and are not likely to be at
ease composing rigidly-structured queries. One
survey found that even though linguists wished
to make very technical linguistic queries, 55% of
them did not know how to program (Soehn et
al., 2008). In another (Gibbs and Owens, 2012),
humanities scholars and social scientists are fre-
quently skeptical of digital tools, because they are
often difficult to use. This reduces the likelihood
that existing structured-query tools for syntactic
search will be usable by non-programmers (Ogden
and Brooks, 1983).
A related approach is the query-by-example
work seen in the past in interfaces to database sys-
tems (Androutsopoulos et al., 1995). For instance,
the Linguist’s Search Engine (Resnik et al., 2005)
uses a query-by-example strategy in which a user
types in an initial sentence in English, and the sys-
tem produces a graphical view of a parse tree as
output, which the user can alter. The user can ei-
ther click on the tree or modify the LISP expres-
sion to generalize the query. SPLICR also contains
</bodyText>
<page confidence="0.952736">
272
</page>
<bodyText confidence="0.993017431372549">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 272–277,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
a graphical tree editor tool (Rehm et al., 2009).
According to Shneiderman and Plaisant (2010),
query-by-example has largely fallen out of favor
as a user interface design approach. A downside
of QBE is that the user must manipulate an exam-
ple to arrive at the desired generalization.
More recently auto-suggest, a faster technique
that does not require the manipulation of query by
example, has become a widely-used approach in
search user interfaces with strong support in terms
of its usability (Anick and Kantamneni, 2008;
Ward et al., 2012; Jagadish et al., 2007). A list
of selectable options is shown under the search
bar, filtered to be relevant as the searcher types.
Searchers can recognize and select the option that
matches their information need, without having to
generate the query themselves.
The success of auto-suggest depends upon
showing users options they can recognize. How-
ever, we know of no prior work on how to dis-
play grammatical relations so that they can be
easily recognized. One current presentation (not
used with auto-suggest) is to name the relation
and show blanks where the words that satisfy it
would appear as in X is the subject of Y (Muralid-
haran and Hearst, 2013); we used this as the base-
line presentation in our experiments because it em-
ploys the relation definitions found in the Stan-
ford Dependency Parser’s manual (De Marneffe et
al., 2006). Following the principle of recognition
over recall, we hypothesized that showing contex-
tualized usage examples would make the relations
more recognizable.
Our results confirm that showing examples in
the form of words or phrases significantly im-
proves the accuracy with which grammatical re-
lationships are recognized over the standard base-
line of showing the relation name with blanks. Our
findings also showed that clausal relationships,
which span longer distances in sentences, bene-
fited significantly more from example phrases than
either of the other treatments.
These findings suggest that a query interface in
which a user enters a word of interest and the sys-
tem shows candidate grammatical relations aug-
mented with examples from the text will be more
successful than the baseline of simply naming the
relation and showing gaps where the participating
words appear.
</bodyText>
<sectionHeader confidence="0.971908" genericHeader="introduction">
2 Experiment
</sectionHeader>
<bodyText confidence="0.999968469387755">
We gave participants a series of identification
tasks. In each task, they were shown a list of sen-
tences containing a particular syntactic relation-
ship between highlighted words. They were asked
to identify the relationship type from a list of four
options. We presented the options in three differ-
ent ways, and compared the accuracy.
We chose Amazon’s Mechanical Turk (MTurk)
crowdsourcing platform as a source of study par-
ticipants. The wide range of backgrounds pro-
vided by MTurk is desirable because our goal is to
find a representation that is understandable to most
people, not just linguistic experts or programmers.
This platform has become widely used for both
obtaining language judgements and for usability
studies (Kittur et al., 2008; Snow et al., 2008).
Our hypothesis was:
Grammatical relations are identified
more accurately when shown with ex-
amples of contextualizing words or
phrases than without.
To test it, participants were given a series of
identification tasks. In each task, they were shown
a list of 8 sentences, each containing a particu-
lar relationship between highlighted words. They
were asked to identify the relationship from a list
of 4 choices. Additionally, one word was chosen
as a focus word that was present in all the sen-
tences, to make the relationship more recognizable
(“life” in Figure 1).
The choices were displayed in 3 different ways
(Figure 1). The baseline presentation (Figure 1a)
named the linguistic relation and showed a blank
space with a pink background for the varying word
in the relationship, the focus word highlighted in
yellow and underlined, and any necessary addi-
tional words necessary to convey the relationship
(such as “of” for the prepositional relationship
“of”, the third option).
The words presentation showed the baseline de-
sign, and in addition beneath was the word “Exam-
ples:” followed by a list of 4 example words that
could fill in the pink blank slot (Figure 1b). The
phrases presentation again showed the baseline
design, beneath which was the phrase “Patterns
like:” and a list of 4 example phrases in which
fragments of text including both the pink and the
yellow highlighted portions of the relationship ap-
peared (Figure 1c).
</bodyText>
<page confidence="0.992254">
273
</page>
<figure confidence="0.9208325">
(a) The options as they appear in the baseline condition. (b) The same options as they appear in the words condition.
(c) The same options in the phrases condition, shown as they appeared in an identification task for the relationship
</figure>
<figureCaption confidence="0.751155">
amod(life, ) (where different adjectives modify the noun ‘life’). The correct answer is ‘adjective modifier’ (4th option),
and the remaining 3 options are distractors.
Figure 1: The appearance of the choices shown in the three experiment conditions.
</figureCaption>
<bodyText confidence="0.996433529411765">
Method: We used a between-subjects design.
The task order and the choice order were not var-
ied: the only variation between participants was
the presentation of the choices. To avoid the pos-
sibility of guessing the right answer by pattern-
matching, we ensured that there was no overlap
between the list of sentences shown, and the ex-
amples shown in the choices as words or phrases.
Tasks: The tasks were generated using the
Stanford Dependency Parser (De Marneffe et al.,
2006) on the text of Moby Dick by Herman
Melville. We tested the 12 most common gram-
matical relationships in the novel in order to cover
the most content and to be able to provide as many
real examples as possible. These relationships fell
into two categories, listed below with examples.
Clausal or long-distance relations:
</bodyText>
<listItem confidence="0.84963475">
− Adverbial clause: I walk while talking
− Open clausal complement: I love to sing
− Clausal complement: he saw us leave
− Relative clause modifier: the letter I wrote
reached
Non-clausal relations:
− Subject of verb: he threw the ball
− Object of verb: he threw the ball
− Adjective modifier red ball
− Preposition (in): a hole in a bucket
− Preposition (of): the piece of cheese
− Conjunction (and) mind and body
</listItem>
<page confidence="0.95541">
274
</page>
<equation confidence="0.395017">
− Adverb modifier: we walk slowly
− Noun compound: Mr. Brown
</equation>
<bodyText confidence="0.975692">
We tested each of these 12 relations with 4 dif-
ferent focus words, 2 in each role. For example,
the Subject of Verb relation was tested in the fol-
lowing forms:
− (Ahab, ): the sentences each contained
‘Ahab’, highlighted in yellow, as the subject of
different verbs highlighted in pink.
</bodyText>
<equation confidence="0.8105038">
− (captain, )
− ( , said): the sentences each contained
the verb ‘said’, highlighted in yellow, but with
different subjects, highlighted in pink.
− ( , stood)
</equation>
<bodyText confidence="0.998747675675676">
To maximize coverage, yet keep the total task
time reasonable (average 6.8 minutes), we divided
the relations above into 4 task sets, each testing
recognition of 3 different relations. Each of rela-
tions was tested with 4 different words, making a
total of 12 tasks per participant.
Participants: 400 participants completed the
study distributed randomly over the 4 task sets and
the 3 presentations. Participants were paid 50c
(U.S.) for completing the study, with an additional
50c bonus if they correctly identified 10 or more
of the 12 relationships. They were informed of the
possibility of the bonus before starting.
To gauge their syntactic familiarity, we also
asked them to rate how familiar they were with
the terms ‘adjective’ (88% claimed they could de-
fine it), ‘infinitive’ (43%), and ‘clausal comple-
ment’ (18%). To help ensure the quality of effort,
we included a multiple-choice screening question,
“What is the third word of this sentence?” The 27
participants (out of 410) who answered incorrectly
were eliminated.
Results: The results (Figure 2) confirm our hy-
pothesis. Participants in conditions that showed
examples (phrases and words) were significantly
more accurate at identifying the relations than
participants in the baseline condition. We used
the Wilcoxson signed-rank test, an alternative to
the standard T-test that does not assume sam-
ples are normally distributed. The average suc-
cess rate in the baseline condition was 41%,
which is significantly less accurate than words:
52%, (p=0.00019, W=6136), and phrases: 55%,
(p=0.00014, W=5546.5).
Clausal relations operate over longer distances
in sentences, and so it is to be expected that show-
ing longer stretches of context would perform bet-
</bodyText>
<figure confidence="0.961174">
Average Recognition Success Rate per Relation
Baseline Phrases Words
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Overall Clausal Relations Non-Clausal Adverb Modifier
Relations
</figure>
<figureCaption confidence="0.941755666666667">
Figure 2: Recognition rates for different types of
relations under the 3 experiment conditions, with
95% confidence intervals.
</figureCaption>
<bodyText confidence="0.99983923076923">
ter in these cases; that is indeed what the re-
sults showed. Phrases significantly outperformed
words and baseline for clausal relations. The av-
erage success rate was 48% for phrases, which
is significantly more than words: 38%, (p=0.017
W=6976.5) and baseline: 24%, (p=1.9×10−9
W=4399.0), which was indistinguishable from
random guessing (25%). This is a strong improve-
ment, given that only 18% of participants reported
being able to define ‘clausal complement’.
For the non-clausal relations, there was no sig-
nificant difference between phrases and words,
although they were both overall significantly bet-
ter than the baseline (words: p=0.0063 W=6740,
phrases: p=0.023 W=6418.5). Among these rela-
tions, adverb modifiers stood out (Figure 2), be-
cause evidence suggested that words (63% suc-
cess) made the relation more recognizable than
phrases (47% success, p=0.056, W=574.0) – but
the difference was only almost significant, due to
the smaller sample size (only 96 participants en-
countered this relation). This may be because the
words are the most salient piece of information in
an adverbial relation – adverbs usually end in ‘ly’
– and in the phrases condition the additional infor-
mation distracts from recognition of this pattern.
</bodyText>
<sectionHeader confidence="0.997826" genericHeader="conclusions">
3 Conclusions
</sectionHeader>
<bodyText confidence="0.999979625">
The results imply that user interfaces for syntactic
search should show candidate relationships aug-
mented with a list of phrases in which they occur.
A list of phrases is the most recognizable presenta-
tion for clausal relationships (34% better than the
baseline), and is as good as a list of words for the
other types of relations, except adverb modifiers.
For adverb modifiers, the list of words is the most
</bodyText>
<page confidence="0.995028">
275
</page>
<bodyText confidence="0.999919962962963">
recognizable presentation. This is likely because
Enlglish adverbs usually end in ‘-ly’ are therefore
a distinctive set of words.
The list of candidates can be ordered by fre-
quency of occurrence in the collection, or by an
interestingness measure given the search word. As
the user becomes more familiar with a given re-
lation, it may be expedient to shorten the cues
shown, and then re-introduce them if a relation
has not been selected after some period of time
has elapsed. If phrases are used, there is a tradeoff
between recognizability and the space required to
display the examples of usage. However, it is im-
portant to keep in mind that because the sugges-
tions are populated with items from the collection
itself, they are informative.
The best strategy, phrases, had an overall suc-
cess rate of only 55%, although the intended user
base may have more familiarity with grammatical
relations than the participants did, and therefore
may perform better in practice. Nonetheless, there
is room for improvement in scores, and it may be
that additional visual cues, such as some kind of
bracketing, will improve results. Furthermore, the
current study did not test three-word relationships
or more complex combinations of structures, and
those may require improvements to the design.
</bodyText>
<sectionHeader confidence="0.999348" genericHeader="acknowledgments">
4 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999781333333333">
We thank Bj¨orn Hartmann for his helpful com-
ments. This work is supported by National En-
dowment for the Humanities grant HK-50011.
</bodyText>
<sectionHeader confidence="0.998584" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993456">
I Androutsopoulos, GD Ritchie, and P Thanisch. 1995.
Natural language interfaces to databases–an intro-
duction. Natural Language Engineering, 1(01):29–
81.
Peter Anick and Raj Gopal Kantamneni. 2008. A lon-
gitudinal study of real-time search assistance adop-
tion. In Proceedings of the 31st annual international
ACM SIGIR conference on Research and develop-
ment in information retrieval, pages 701–702. ACM.
Aron Culotta and Andrew McCallum. 2005. Reduc-
ing labeling effort for structured prediction tasks. In
AAAI, pages 746–751.
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In LREC, volume 6, pages 449–454.
Fred Gibbs and Trevor Owens. 2012. Building better
digital humanities tools. DH Quarterly, 6(2).
Lynette Hirschman, Alexander Yeh, Christian
Blaschke, and Alfonso Valencia. 2005. Overview
of biocreative: critical assessment of information
extraction for biology. BMC bioinformatics,
6(Suppl 1):S1.
HV Jagadish, Adriane Chapman, Aaron Elkiss,
Magesh Jayapandian, Yunyao Li, Arnab Nandi, and
Cong Yu. 2007. Making database systems usable.
In Proceedings of the 2007 ACM SIGMOD interna-
tional conference on Management of data, pages 13–
24. ACM.
Milos Jakubicek, Adam Kilgarriff, Diana McCarthy,
and Pavel Rychl`y. 2010. Fast syntactic searching in
very large corpora for many languages. In PACLIC,
volume 24, pages 741–747.
Stephan Kepser. 2003. Finite structure query: A
tool for querying syntactically annotated corpora. In
EACL, pages 179–186.
Aniket Kittur, Ed H Chi, and Bongwon Suh. 2008.
Crowdsourcing user studies with mechanical turk.
In Proceedings of the SIGCHI conference on human
factors in computing systems, pages 453–456. ACM.
Catherine Lai and Steven Bird. 2010. Querying lin-
guistic trees. Journal of Logic, Language and Infor-
mation, 19(1):53–73.
Roger Levy and Galen Andrew. 2006. Tregex and tsur-
geon: tools for querying and manipulating tree data
structures. In LREC, pages 2231–2234.
Diana Lynn MacLean and Jeffrey Heer. 2013. Iden-
tifying medical terms in patient-authored text: a
crowdsourcing-based approach. Journal of the
American Medical Informatics Association.
Aditi Muralidharan and Marti A Hearst. 2013. Sup-
porting exploratory text analysis in literature study.
Literary and Linguistic Computing, 28(2):283–295.
William C Ogden and Susan R Brooks. 1983. Query
languages for the casual user: Exploring the mid-
dle ground between formal and natural languages.
In Proceedings of the SIGCHI conference on Hu-
man Factors in Computing Systems, pages 161–165.
ACM.
Georg Rehm, Oliver Schonefeld, Andreas Witt, Erhard
Hinrichs, and Marga Reis. 2009. Sustainability of
annotated resources in linguistics: A web-platform
for exploring, querying, and distributing linguistic
corpora and other resources. Literary and Linguistic
Computing, 24(2):193–210.
Philip Resnik, Aaron Elkiss, Ellen Lau, and Heather
Taylor. 2005. The web in theoretical linguistics re-
search: Two case studies using the linguists search
engine. In Proc. 31st Mtg. Berkeley Linguistics So-
ciety, pages 265–276.
</reference>
<page confidence="0.975826">
276
</page>
<reference confidence="0.99714865">
Ben Shneiderman and Catherine Plaisant. 2010. De-
signing The User Interface: Strategies for Effective
Human-Computer Interaction, 5/e (Fifth Edition).
Addison Wesley.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and
Andrew Y Ng. 2008. Cheap and fast—but is it
good?: evaluating non-expert annotations for natu-
ral language tasks. In Proceedings of the conference
on empirical methods in natural language process-
ing, pages 254–263. Association for Computational
Linguistics.
Jan-Philipp Soehn, Heike Zinsmeister, and Georg
Rehm. 2008. Requirements of a user-friendly,
general-purpose corpus query interface. Sustain-
ability of Language Resources and Tools for Natural
Language Processing, 6:27.
David Ward, Jim Hahn, and Kirsten Feist. 2012. Au-
tocomplete as research tool: A study on providing
search suggestions. Information Technology and Li-
braries, 31(4):6–19.
</reference>
<page confidence="0.99723">
277
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.778780">
<title confidence="0.9980285">Improving the Recognizability of Syntactic Relations Contextualized Examples</title>
<author confidence="0.959155">Aditi</author>
<affiliation confidence="0.999935">Computer Science University of California,</affiliation>
<address confidence="0.820728">Berkeley,</address>
<email confidence="0.999883">asm@berkeley.edu</email>
<abstract confidence="0.999583181818182">A common task in qualitative data analysis is to characterize the usage of a linguistic entity by issuing queries over syntactic relations between words. Previous interfaces for searching over syntactic structures require programming-style queries. User interface research suggests that it is easier to recognize a pattern than to compose it from scratch; therefore, interfaces for non-experts should show previews of syntactic relations. What these previews should look like is an open question that we explored with a 400-participant Mechanical Turk experiment. We found that syntactic relations are recognized with 34% higher accuracy when contextual examples are shown than a baseline of naming the relations alone. This suggests that user interfaces should display contextual examples of syntactic relations to help users choose between different relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>GD Ritchie</author>
<author>P Thanisch</author>
</authors>
<title>Natural language interfaces to databases–an introduction.</title>
<date>1995</date>
<journal>Natural Language Engineering,</journal>
<volume>1</volume>
<issue>01</issue>
<pages>81</pages>
<contexts>
<context position="3547" citStr="Androutsopoulos et al., 1995" startWordPosition="533" endWordPosition="536">mposing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983). A related approach is the query-by-example work seen in the past in interfaces to database systems (Androutsopoulos et al., 1995). For instance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter. The user can either click on the tree or modify the LISP expression to generalize the query. SPLICR also contains 272 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 272–277, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree edi</context>
</contexts>
<marker>Androutsopoulos, Ritchie, Thanisch, 1995</marker>
<rawString>I Androutsopoulos, GD Ritchie, and P Thanisch. 1995. Natural language interfaces to databases–an introduction. Natural Language Engineering, 1(01):29– 81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Anick</author>
<author>Raj Gopal Kantamneni</author>
</authors>
<title>A longitudinal study of real-time search assistance adoption.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>701--702</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4652" citStr="Anick and Kantamneni, 2008" startWordPosition="711" endWordPosition="714">272–277, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an example to arrive at the desired generalization. More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can recognize and select the option that matches their information need, without having to generate the query themselves. The success of auto-suggest depends upon showing users options they can recognize. However, we know of no prior work on how to display grammatical relations so that they can be easily recognized. One current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satis</context>
</contexts>
<marker>Anick, Kantamneni, 2008</marker>
<rawString>Peter Anick and Raj Gopal Kantamneni. 2008. A longitudinal study of real-time search assistance adoption. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 701–702. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Reducing labeling effort for structured prediction tasks.</title>
<date>2005</date>
<booktitle>In AAAI,</booktitle>
<pages>746--751</pages>
<contexts>
<context position="1781" citStr="Culotta and McCallum, 2005" startWordPosition="264" endWordPosition="268">ul in many nonscientific fields. For example, a social scientist trying to characterize different perspectives on immigration might ask how adjectives applying to ‘immigrant’ have changed in the last 30 years. A scholar interested in gender might search a collection to find out whether different nouns enter into possessive relationships with ‘his’ and ‘her’ (Muralidharan and Hearst, 2013). In other fields, grammatical queries can be used to develop patterns for recognizing entities in text, such as medical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Culotta and McCallum, 2005), and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying syntactically annotated corpora requires its queries to be stated in first order logic (</context>
</contexts>
<marker>Culotta, McCallum, 2005</marker>
<rawString>Aron Culotta and Andrew McCallum. 2005. Reducing labeling effort for structured prediction tasks. In AAAI, pages 746–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Gibbs</author>
<author>Trevor Owens</author>
</authors>
<title>Building better digital humanities tools.</title>
<date>2012</date>
<journal>DH Quarterly,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="3144" citStr="Gibbs and Owens, 2012" startWordPosition="473" endWordPosition="476">regular expressions containing parse tree nodes and words. Several approaches have adopted XML representations and the associated query language families of XPATH and SPARQL. For example, LPath augments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010). However, most potential users do not have programming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983). A related approach is the query-by-example work seen in the past in interfaces to database systems (Androutsopoulos et al., 1995). For instance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view</context>
</contexts>
<marker>Gibbs, Owens, 2012</marker>
<rawString>Fred Gibbs and Trevor Owens. 2012. Building better digital humanities tools. DH Quarterly, 6(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Alexander Yeh</author>
<author>Christian Blaschke</author>
<author>Alfonso Valencia</author>
</authors>
<title>Overview of biocreative: critical assessment of information extraction for biology. BMC bioinformatics, 6(Suppl 1):S1.</title>
<date>2005</date>
<contexts>
<context position="1695" citStr="Hirschman et al., 2005" startWordPosition="252" endWordPosition="255">uction The ability to search over grammatical relationships between words is useful in many nonscientific fields. For example, a social scientist trying to characterize different perspectives on immigration might ask how adjectives applying to ‘immigrant’ have changed in the last 30 years. A scholar interested in gender might search a collection to find out whether different nouns enter into possessive relationships with ‘his’ and ‘her’ (Muralidharan and Hearst, 2013). In other fields, grammatical queries can be used to develop patterns for recognizing entities in text, such as medical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Culotta and McCallum, 2005), and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying sy</context>
</contexts>
<marker>Hirschman, Yeh, Blaschke, Valencia, 2005</marker>
<rawString>Lynette Hirschman, Alexander Yeh, Christian Blaschke, and Alfonso Valencia. 2005. Overview of biocreative: critical assessment of information extraction for biology. BMC bioinformatics, 6(Suppl 1):S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HV Jagadish</author>
<author>Adriane Chapman</author>
<author>Aaron Elkiss</author>
<author>Magesh Jayapandian</author>
<author>Yunyao Li</author>
<author>Arnab Nandi</author>
<author>Cong Yu</author>
</authors>
<title>Making database systems usable.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 ACM SIGMOD international conference on Management of data,</booktitle>
<pages>13--24</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4695" citStr="Jagadish et al., 2007" startWordPosition="719" endWordPosition="722">014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an example to arrive at the desired generalization. More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can recognize and select the option that matches their information need, without having to generate the query themselves. The success of auto-suggest depends upon showing users options they can recognize. However, we know of no prior work on how to display grammatical relations so that they can be easily recognized. One current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satisfy it would appear as in X is the subject o</context>
</contexts>
<marker>Jagadish, Chapman, Elkiss, Jayapandian, Li, Nandi, Yu, 2007</marker>
<rawString>HV Jagadish, Adriane Chapman, Aaron Elkiss, Magesh Jayapandian, Yunyao Li, Arnab Nandi, and Cong Yu. 2007. Making database systems usable. In Proceedings of the 2007 ACM SIGMOD international conference on Management of data, pages 13– 24. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milos Jakubicek</author>
<author>Adam Kilgarriff</author>
<author>Diana McCarthy</author>
<author>Pavel Rychl`y</author>
</authors>
<title>Fast syntactic searching in very large corpora for many languages. In PACLIC,</title>
<date>2010</date>
<volume>24</volume>
<pages>741--747</pages>
<marker>Jakubicek, Kilgarriff, McCarthy, Rychl`y, 2010</marker>
<rawString>Milos Jakubicek, Adam Kilgarriff, Diana McCarthy, and Pavel Rychl`y. 2010. Fast syntactic searching in very large corpora for many languages. In PACLIC, volume 24, pages 741–747.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Kepser</author>
</authors>
<title>Finite structure query: A tool for querying syntactically annotated corpora.</title>
<date>2003</date>
<booktitle>In EACL,</booktitle>
<pages>179--186</pages>
<contexts>
<context position="2394" citStr="Kepser, 2003" startWordPosition="354" endWordPosition="355">, and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying syntactically annotated corpora requires its queries to be stated in first order logic (Kepser, 2003). In the Corpus Query Language (Jakubicek et al., 2010), a query is a pattern of attributevalue pairs, where values can include regular expressions containing parse tree nodes and words. Several approaches have adopted XML representations and the associated query language families of XPATH and SPARQL. For example, LPath augments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010). However, most potential users do not have programming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though lingui</context>
</contexts>
<marker>Kepser, 2003</marker>
<rawString>Stephan Kepser. 2003. Finite structure query: A tool for querying syntactically annotated corpora. In EACL, pages 179–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aniket Kittur</author>
<author>Ed H Chi</author>
<author>Bongwon Suh</author>
</authors>
<title>Crowdsourcing user studies with mechanical turk.</title>
<date>2008</date>
<booktitle>In Proceedings of the SIGCHI conference on human factors in computing systems,</booktitle>
<pages>453--456</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7147" citStr="Kittur et al., 2008" startWordPosition="1115" endWordPosition="1118">r syntactic relationship between highlighted words. They were asked to identify the relationship type from a list of four options. We presented the options in three different ways, and compared the accuracy. We chose Amazon’s Mechanical Turk (MTurk) crowdsourcing platform as a source of study participants. The wide range of backgrounds provided by MTurk is desirable because our goal is to find a representation that is understandable to most people, not just linguistic experts or programmers. This platform has become widely used for both obtaining language judgements and for usability studies (Kittur et al., 2008; Snow et al., 2008). Our hypothesis was: Grammatical relations are identified more accurately when shown with examples of contextualizing words or phrases than without. To test it, participants were given a series of identification tasks. In each task, they were shown a list of 8 sentences, each containing a particular relationship between highlighted words. They were asked to identify the relationship from a list of 4 choices. Additionally, one word was chosen as a focus word that was present in all the sentences, to make the relationship more recognizable (“life” in Figure 1). The choices w</context>
</contexts>
<marker>Kittur, Chi, Suh, 2008</marker>
<rawString>Aniket Kittur, Ed H Chi, and Bongwon Suh. 2008. Crowdsourcing user studies with mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems, pages 453–456. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Lai</author>
<author>Steven Bird</author>
</authors>
<title>Querying linguistic trees.</title>
<date>2010</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="2816" citStr="Lai and Bird, 2010" startWordPosition="419" endWordPosition="422">syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying syntactically annotated corpora requires its queries to be stated in first order logic (Kepser, 2003). In the Corpus Query Language (Jakubicek et al., 2010), a query is a pattern of attributevalue pairs, where values can include regular expressions containing parse tree nodes and words. Several approaches have adopted XML representations and the associated query language families of XPATH and SPARQL. For example, LPath augments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010). However, most potential users do not have programming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983)</context>
</contexts>
<marker>Lai, Bird, 2010</marker>
<rawString>Catherine Lai and Steven Bird. 2010. Querying linguistic trees. Journal of Logic, Language and Information, 19(1):53–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Galen Andrew</author>
</authors>
<title>Tregex and tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In LREC,</booktitle>
<pages>2231--2234</pages>
<contexts>
<context position="2246" citStr="Levy and Andrew, 2006" startWordPosition="329" endWordPosition="333">gnizing entities in text, such as medical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Culotta and McCallum, 2005), and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying syntactically annotated corpora requires its queries to be stated in first order logic (Kepser, 2003). In the Corpus Query Language (Jakubicek et al., 2010), a query is a pattern of attributevalue pairs, where values can include regular expressions containing parse tree nodes and words. Several approaches have adopted XML representations and the associated query language families of XPATH and SPARQL. For example, LPath augments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010). However, most potential user</context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>Roger Levy and Galen Andrew. 2006. Tregex and tsurgeon: tools for querying and manipulating tree data structures. In LREC, pages 2231–2234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Lynn MacLean</author>
<author>Jeffrey Heer</author>
</authors>
<title>Identifying medical terms in patient-authored text: a crowdsourcing-based approach.</title>
<date>2013</date>
<journal>Journal of the American Medical Informatics Association.</journal>
<contexts>
<context position="1720" citStr="MacLean and Heer, 2013" startWordPosition="256" endWordPosition="259">arch over grammatical relationships between words is useful in many nonscientific fields. For example, a social scientist trying to characterize different perspectives on immigration might ask how adjectives applying to ‘immigrant’ have changed in the last 30 years. A scholar interested in gender might search a collection to find out whether different nouns enter into possessive relationships with ‘his’ and ‘her’ (Muralidharan and Hearst, 2013). In other fields, grammatical queries can be used to develop patterns for recognizing entities in text, such as medical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Culotta and McCallum, 2005), and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and Andrew, 2006). The Finite Structure Query tool for querying syntactically annotated cor</context>
</contexts>
<marker>MacLean, Heer, 2013</marker>
<rawString>Diana Lynn MacLean and Jeffrey Heer. 2013. Identifying medical terms in patient-authored text: a crowdsourcing-based approach. Journal of the American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aditi Muralidharan</author>
<author>Marti A Hearst</author>
</authors>
<title>Supporting exploratory text analysis in literature study.</title>
<date>2013</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>28--2</pages>
<contexts>
<context position="1545" citStr="Muralidharan and Hearst, 2013" startWordPosition="226" endWordPosition="229">alone. This suggests that user interfaces should display contextual examples of syntactic relations to help users choose between different relations. 1 Introduction The ability to search over grammatical relationships between words is useful in many nonscientific fields. For example, a social scientist trying to characterize different perspectives on immigration might ask how adjectives applying to ‘immigrant’ have changed in the last 30 years. A scholar interested in gender might search a collection to find out whether different nouns enter into possessive relationships with ‘his’ and ‘her’ (Muralidharan and Hearst, 2013). In other fields, grammatical queries can be used to develop patterns for recognizing entities in text, such as medical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Culotta and McCallum, 2005), and for coding qualitative data such as survey results. Marti A. Hearst School of Information University of California, Berkeley Berkeley, CA hearst@berkeley.edu Most existing interfaces for syntactic search (querying over grammatical and syntactic structures) require structured query syntax. For example, the popular Stanford Parser includes Tregex, which allo</context>
<context position="5330" citStr="Muralidharan and Hearst, 2013" startWordPosition="826" endWordPosition="830">ist of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can recognize and select the option that matches their information need, without having to generate the query themselves. The success of auto-suggest depends upon showing users options they can recognize. However, we know of no prior work on how to display grammatical relations so that they can be easily recognized. One current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satisfy it would appear as in X is the subject of Y (Muralidharan and Hearst, 2013); we used this as the baseline presentation in our experiments because it employs the relation definitions found in the Stanford Dependency Parser’s manual (De Marneffe et al., 2006). Following the principle of recognition over recall, we hypothesized that showing contextualized usage examples would make the relations more recognizable. Our results confirm that showing examples in the form of words or phrases significantly improves the accuracy with which grammatical relationships are recognized over the standard baseline of showing the relation name with blanks. Our findings also showed that </context>
</contexts>
<marker>Muralidharan, Hearst, 2013</marker>
<rawString>Aditi Muralidharan and Marti A Hearst. 2013. Supporting exploratory text analysis in literature study. Literary and Linguistic Computing, 28(2):283–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Ogden</author>
<author>Susan R Brooks</author>
</authors>
<title>Query languages for the casual user: Exploring the middle ground between formal and natural languages.</title>
<date>1983</date>
<booktitle>In Proceedings of the SIGCHI conference on Human Factors in Computing Systems,</booktitle>
<pages>161--165</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3416" citStr="Ogden and Brooks, 1983" startWordPosition="512" endWordPosition="515">ss (Lai and Bird, 2010). However, most potential users do not have programming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983). A related approach is the query-by-example work seen in the past in interfaces to database systems (Androutsopoulos et al., 1995). For instance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter. The user can either click on the tree or modify the LISP expression to generalize the query. SPLICR also contains 272 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Paper</context>
</contexts>
<marker>Ogden, Brooks, 1983</marker>
<rawString>William C Ogden and Susan R Brooks. 1983. Query languages for the casual user: Exploring the middle ground between formal and natural languages. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems, pages 161–165. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georg Rehm</author>
<author>Oliver Schonefeld</author>
<author>Andreas Witt</author>
<author>Erhard Hinrichs</author>
<author>Marga Reis</author>
</authors>
<title>Sustainability of annotated resources in linguistics: A web-platform for exploring, querying, and distributing linguistic corpora and other resources.</title>
<date>2009</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>24--2</pages>
<contexts>
<context position="4175" citStr="Rehm et al., 2009" startWordPosition="636" endWordPosition="639">ance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter. The user can either click on the tree or modify the LISP expression to generalize the query. SPLICR also contains 272 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 272–277, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an example to arrive at the desired generalization. More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be rel</context>
</contexts>
<marker>Rehm, Schonefeld, Witt, Hinrichs, Reis, 2009</marker>
<rawString>Georg Rehm, Oliver Schonefeld, Andreas Witt, Erhard Hinrichs, and Marga Reis. 2009. Sustainability of annotated resources in linguistics: A web-platform for exploring, querying, and distributing linguistic corpora and other resources. Literary and Linguistic Computing, 24(2):193–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Aaron Elkiss</author>
<author>Ellen Lau</author>
<author>Heather Taylor</author>
</authors>
<title>The web in theoretical linguistics research: Two case studies using the linguists search engine.</title>
<date>2005</date>
<booktitle>In Proc. 31st Mtg. Berkeley Linguistics Society,</booktitle>
<pages>265--276</pages>
<contexts>
<context position="3613" citStr="Resnik et al., 2005" startWordPosition="543" endWordPosition="546">ists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983). A related approach is the query-by-example work seen in the past in interfaces to database systems (Androutsopoulos et al., 1995). For instance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter. The user can either click on the tree or modify the LISP expression to generalize the query. SPLICR also contains 272 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 272–277, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisan</context>
</contexts>
<marker>Resnik, Elkiss, Lau, Taylor, 2005</marker>
<rawString>Philip Resnik, Aaron Elkiss, Ellen Lau, and Heather Taylor. 2005. The web in theoretical linguistics research: Two case studies using the linguists search engine. In Proc. 31st Mtg. Berkeley Linguistics Society, pages 265–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Shneiderman</author>
<author>Catherine Plaisant</author>
</authors>
<title>Designing The User Interface: Strategies for Effective Human-Computer Interaction, 5/e (Fifth Edition).</title>
<date>2010</date>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="4221" citStr="Shneiderman and Plaisant (2010)" startWordPosition="642" endWordPosition="645">e (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the system produces a graphical view of a parse tree as output, which the user can alter. The user can either click on the tree or modify the LISP expression to generalize the query. SPLICR also contains 272 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 272–277, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an example to arrive at the desired generalization. More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can rec</context>
</contexts>
<marker>Shneiderman, Plaisant, 2010</marker>
<rawString>Ben Shneiderman and Catherine Plaisant. 2010. Designing The User Interface: Strategies for Effective Human-Computer Interaction, 5/e (Fifth Edition). Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing,</booktitle>
<pages>254--263</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Y Ng. 2008. Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks. In Proceedings of the conference on empirical methods in natural language processing, pages 254–263. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan-Philipp Soehn</author>
<author>Heike Zinsmeister</author>
<author>Georg Rehm</author>
</authors>
<title>Requirements of a user-friendly, general-purpose corpus query interface.</title>
<date>2008</date>
<booktitle>Sustainability of Language Resources and Tools for Natural Language Processing,</booktitle>
<pages>6--27</pages>
<contexts>
<context position="3108" citStr="Soehn et al., 2008" startWordPosition="467" endWordPosition="470"> pairs, where values can include regular expressions containing parse tree nodes and words. Several approaches have adopted XML representations and the associated query language families of XPATH and SPARQL. For example, LPath augments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010). However, most potential users do not have programming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are frequently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983). A related approach is the query-by-example work seen in the past in interfaces to database systems (Androutsopoulos et al., 1995). For instance, the Linguist’s Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and </context>
</contexts>
<marker>Soehn, Zinsmeister, Rehm, 2008</marker>
<rawString>Jan-Philipp Soehn, Heike Zinsmeister, and Georg Rehm. 2008. Requirements of a user-friendly, general-purpose corpus query interface. Sustainability of Language Resources and Tools for Natural Language Processing, 6:27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ward</author>
<author>Jim Hahn</author>
<author>Kirsten Feist</author>
</authors>
<title>Autocomplete as research tool: A study on providing search suggestions.</title>
<date>2012</date>
<booktitle>Information Technology and Libraries,</booktitle>
<pages>31--4</pages>
<contexts>
<context position="4671" citStr="Ward et al., 2012" startWordPosition="715" endWordPosition="718">, USA, June 23-25 2014. c�2014 Association for Computational Linguistics a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an example to arrive at the desired generalization. More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can recognize and select the option that matches their information need, without having to generate the query themselves. The success of auto-suggest depends upon showing users options they can recognize. However, we know of no prior work on how to display grammatical relations so that they can be easily recognized. One current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satisfy it would appear </context>
</contexts>
<marker>Ward, Hahn, Feist, 2012</marker>
<rawString>David Ward, Jim Hahn, and Kirsten Feist. 2012. Autocomplete as research tool: A study on providing search suggestions. Information Technology and Libraries, 31(4):6–19.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>