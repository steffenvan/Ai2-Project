<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000025">
<title confidence="0.998618">
Semantic Dependency Parsing using N-best Semantic Role Sequences and
Roleset Information
</title>
<author confidence="0.990441">
Joo-Young Lee, Han-Cheol Cho, and Hae-Chang Rim
</author>
<affiliation confidence="0.978823">
Natural Language Processing Lab.
Korea University
</affiliation>
<address confidence="0.748479">
Seoul, South Korea
</address>
<email confidence="0.999338">
{jylee,hccho,rim}@nlp.korea.ac.kr
</email>
<sectionHeader confidence="0.994812" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999848470588235">
In this paper, we describe a syntactic and
semantic dependency parsing system sub-
mitted to the shared task of CoNLL 2008.
The proposed system consists of five mod-
ules: syntactic dependency parser, predi-
cate identifier, local semantic role labeler,
global role sequence candidate generator,
and role sequence selector. The syntac-
tic dependency parser is based on Malt
Parser and the sequence candidate gen-
erator is based on CKY style algorithm.
The remaining three modules are imple-
mented by using maximum entropy classi-
fiers. The proposed system achieves 76.90
of labeled F1 for the overall task, 84.82 of
labeled attachment, and 68.71 of labeled
F1 on the WSJ+Brown test set.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964142857143">
In the framework of the CoNLL08 shared task
(Surdeanu et al., 2008), a system takes POS tagged
sentences as input and produces sentences parsed
for syntactic and semantic dependencies as output.
A syntactic dependency is represented by an ID
of head word and a dependency relation between
the head word and its modifier in a sentence. A
Semantic dependency is represented by predicate
rolesets and semantic arguments for each predi-
cate.
The task combines two sub-tasks: syntactic
dependency parsing and semantic role labeling.
Among the sub-tasks, we mainly focus on the se-
mantic role labeling task. Compared to previous
</bodyText>
<note confidence="0.729423">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.991076333333333">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<note confidence="0.7769045">
CoNLL 2004 and 2005 shared tasks (Carreras and
M`arquez, 2004; Carreras and M`arquez, 2005) and
</note>
<bodyText confidence="0.9995464">
other semantic role labeling research, major dif-
ferences of our semantic role labeling task are 1)
considering nominal predicates and 2) identify-
ing roleset of predicates. Based on our observa-
tion that verbal predicate and nominal predicate
have have different characteristics, we decide to
build diffent classification modeles for each pred-
icate types. The modeles use same features but,
their statistical parameters are different. In this
paper, maximum entropy1 is used as the classifi-
cation model, but any other classification models
such as Naive Bayse, SVM, etc. also can be used.
To identify roleset, we investigate a roleset match
scoring method which evaluate how likely a roleset
is matched with the given predicate.
</bodyText>
<sectionHeader confidence="0.970561" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.9998234">
The proposed system sequentially performs syn-
tactic dependency parsing, predicate identification,
local semantic role classification, global sequence
generation, and roleset information based selec-
tion.
</bodyText>
<subsectionHeader confidence="0.996881">
2.1 Syntactic Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.9999665">
In the proposed system, Malt Parser (Nivre et
al., 2007) is adopted as the syntactic dependency
parser. Although the training and test set of
CoNLL08 use non-projective dependency gram-
mar, we decide to use projective parsing algorithm,
Nivre arc-standard, and projective/non-
projective conversion functions that Malt Parser
provides. The reason is that non-projective parsing
shows worse performance than projective parsing
with conversion in our preliminary experiment.
</bodyText>
<footnote confidence="0.99981">
1We use Zhang Le’s MaxEnt toolkit, http://homepages.
inf.ed.ac.uk/s0450736/maxent toolkit.html
</footnote>
<page confidence="0.934833">
233
</page>
<reference confidence="0.23052">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 233–237
Manchester, August 2008
</reference>
<bodyText confidence="0.999890666666667">
We projectize the non-projective training sen-
tences in the training set to generate projective sen-
tences. And then, the parser is trained with the
transformed sentences. Finally, the parsing result
is converted into non-projective structure by using
a function of Malt Parser.
Through a brief error analysis, we found that main
bottle neck for verbal predicate is auxiliary verb
be and have.
</bodyText>
<subsectionHeader confidence="0.985429">
2.3 Local Semantic Role Labeling
2.2 Predicate Identification
</subsectionHeader>
<bodyText confidence="0.999875631578947">
Unlike previous semantic role labeling task (Car-
reras and M`arquez, 2004; Carreras and M`arquez,
2005), predicates of sentences are not provided
with input in the CoNLL08. It means that a sys-
tem needs to identify which words in a sentence
are predicates.
We limit predicate candidates to the words that
exist in the frameset list of Propbank and Nom-
bank. Propbank and Nombank provide lists of
about 3,100 verbal predicates and about 4,400
nominal predicates. After dependency parsing,
words which are located in the frameset list are se-
lected as predicate candidates. The predicate iden-
tifier determines if a candidate is a predicate or not.
The identifier is implemented by using two maxi-
mum entropy models, the one is for verbal predi-
cates and the other is for nominal predicates. The
following features are used for predicate identifi-
cation:
</bodyText>
<sectionHeader confidence="0.50183" genericHeader="method">
Common Features
</sectionHeader>
<subsectionHeader confidence="0.326635">
For Predicate Identification
</subsectionHeader>
<listItem confidence="0.934563769230769">
- Lemma of Previous Word
- Lemma of Current Word
- Lemma of Next Word
- POS of Previous Word
- POS of Current Word
- POS of Next Word
- Dependency Label of Previous Word
- Dependency Label of Current Word
- Dependency Label of Next Word
Additional Features for Verbal Predicate
- Lemma + POS of Current Word
- Trigram Lemma of Previous, Current,
and Next Word
</listItem>
<sectionHeader confidence="0.650804" genericHeader="method">
Additional Features for Nominal Predicate
</sectionHeader>
<bodyText confidence="0.923664733333333">
- Lemma of Head of Current Word
- POS of Head of Current Word
- Dependency Label of Head of Current Word
Verbal predicate identifier shows 87.91 of F1 and
nominal predicate identifier shows 81.58 of F1.
Prediate identification is followed by argument la-
beling. For the given predicate, the system first
eliminates inappropriate argument candidates. The
argument identification uses different strategies for
verbs, nouns, and other predicates.
The argument classifier extracts features and la-
bels semantic roles. None is used to indicate that
a word is not a semantic argument. The classifier
also uses different maximum entropy models for
verbs, nouns, and other predicates
</bodyText>
<subsectionHeader confidence="0.818985">
2.3.1 Argument Candidate Identification
</subsectionHeader>
<bodyText confidence="0.999990454545455">
As mentioned by Pradhan et al. (2004), ar-
gument identification poses a significant bottle-
neck to improving performance of Semantic Role
Labeling system. We tried an algorithm moti-
vated from Hacioglu (2004) which defined a tree-
structured family membership of a predicate to
identify more probable argument candidates and
prune the others. However, we find that it works
for verb and other predicate type, but does not
work properly for noun predicate type. The main
reason is due to the characteristics of arguments
of noun predicates. First of all, a noun predicate
can be an argument for itself, whereas a verb pred-
icate cannot be. Secondly, dependency relation
paths from a noun predicate to its arguments are
usually shorter than a verb predicate. Although
some dependency relation paths are long, they ac-
tually involve non-informative relations like IN,
MD, or TO. Finally, major long distance relation
paths could be identified by several path patterns
acquired from the corpus.
Based on the above analysis, we specify a new
argument identification strategy for nominal pred-
icate type. The argument identifier regards a pred-
icate and its nearest neighbors - its parent and chil-
dren - as argument candidates. However, if the
POS tag of a nearest neighbor is IN, MD, or TO, it
will be ignored and the next nearest candidates will
be used. Moreover, several patterns (three consec-
utive nouns, adjective and two consecutive nouns,
two nouns combined with conjunction, and etc.)
are applied to find long distance argument candi-
dates.
</bodyText>
<page confidence="0.988566">
234
</page>
<subsectionHeader confidence="0.6026">
2.3.2 Argument Classification
</subsectionHeader>
<bodyText confidence="0.9994987">
For argument classification, various features
have been used. Primarily, we tested a set of fea-
tures suggested by Hacioglu (2004). The voice of
the predicate, left and right words, its POS tag for
a predicate, and lexical clues for adjunctive argu-
ments also have been tested. Based on the type
of predicate (i.e. verb predicate, noun predicate,
and other predicate) three classification models are
trained by using maximum entropy with the fol-
lowing same features:
</bodyText>
<subsectionHeader confidence="0.578499">
Features for Argument Classification
</subsectionHeader>
<listItem confidence="0.9497074">
- Dependen Relation Type
- Family Membership
- Position
- Lemma of Head Word
- POS of Head Word
- Path
- POS Pattern of Predicate’s Children
- Relation Pattern of Predicate’s Children
- POS Pattern of Predicate’s Siblings
- Relation Pattern of Predicate’s Siblings
- POS of candidate
- Lemma of Left Word of Candidate
- POS of Left Word of Candidate
- Lemma of Right Word of Candidate
- POS of Right Word of Candidate
</listItem>
<bodyText confidence="0.999853333333333">
The classifier produces a list of possible seman-
tic roles and its probabilities for each word in the
given sentence.
</bodyText>
<sectionHeader confidence="0.591891" genericHeader="method">
2.4 Global Semantic Role Sequence
Generation
</sectionHeader>
<bodyText confidence="0.999897473684211">
For local semantic role labeling, we assume that
semantic roles of words are independent of each
other. Toutanova et al. (2005) and Surdeanu et
al. (2007) show that global constraint and opti-
mization are important in semantic role labeling.
We use CKY-based dynamic programming strat-
egy, similar to Surdeanu et al. (2007), to verify
whether role sequences satisfy global constraint
and generate candidates of global semantic role se-
quences.
In this paper, we just use one constraint: no
duplicate arguments are allowed for verbal pred-
icates. For verbal predicates, CKY module builds
a list of all kinds of combinations of semantic roles
augmented with their probabilities. While building
the list of semantic role sequences, it removes the
sequences that violate the global constraint. The
output of CKY module is the list of semantic role
sequences satisfying the global constraint.
</bodyText>
<subsectionHeader confidence="0.891358">
2.5 Global Sequence Selection using Roleset
Information
</subsectionHeader>
<bodyText confidence="0.9999906">
Finally, we need to select the most likely semantic
role sequence. In addition, we need to identify a
roleset for a predicate. We perform these tasks by
finding a role sequence and roleset maximizing a
score on the following formula:
</bodyText>
<equation confidence="0.976618">
α · c + 0 · rf + -y · mc (1)
</equation>
<bodyText confidence="0.999948631578947">
where, c, rf, mc are role sequence score, relative
frequence of roleset, and matching score with role-
set respectively. α, 0, -y are tuning parameters of
each factor and decided empirically by using de-
velopment set. In this paper, we set α, 0, -y to 0.5,
0.3, 0.2, respectively.
The role sequence score is calculated in the
global semantic role sequence generation ex-
plained in Section 2.4. The relative frequency of a
roleset means how many times the roleset occurred
in the training set compared to the total occurrence
of the predicate. It can be easily estimated by
MLE.
The remaining problem is how to calculate the
matching score. We use maximum entropy models
as binary classifiers which output match and not-
match and use probability of match as matching
score. The features used for the roleset matching
classifiers are based on following intuitions:
</bodyText>
<listItem confidence="0.986294375">
• If core roles (e.g., A0, A2, etc) defined in
a roleset occur in a given role sequence, it
seems to be the right roleset for the role se-
quence.
• If matched core roles are close to or have de-
pendency relations with a predicate, it seems
to be the right roleset.
• If a roleset has a particle and the predicate of
</listItem>
<bodyText confidence="0.869562285714286">
a sentence also has that particle, it seems to
be the right roleset. For example, the lemma
of predicate node for the roleset cut.05
in frameset file ”cut.xml.gz” is cut back, so
the particle of cut.05 is back. If the predicate
of a sentence also has particle ’back’, it seems
to be the right roleset.
</bodyText>
<listItem confidence="0.6492955">
• If example node of a roleset in frameset file
has a functional word for certain core role that
</listItem>
<page confidence="0.996548">
235
</page>
<bodyText confidence="0.991072238095238">
also exists in a given sentence, it seems to be
the right roleset. For example, example node
is defined as follows2:
&lt;roleset id=&amp;quot;cut.09&amp;quot; ...&gt;
&lt;example&gt;
&lt;text&gt;
As the building’s new owner,
Chase will have its work cut
out for it.
&lt;/text&gt;
&lt;arg n=&amp;quot;1&amp;quot;&gt;its work&lt;/arg&gt;
&lt;rel&gt;cut out&lt;/rel&gt;
&lt;arg n=&amp;quot;2&amp;quot; f=&amp;quot;for&amp;quot;&gt;it&lt;/arg&gt;
&lt;/example&gt;
&lt;/roleset&gt;
Here, semantic role A2 has functional word
for. If a given role sequence has A2 and its
word is ’for’, than this role sequence probably
matches that roleset.
Based on these intuitions, we use following fea-
tures for roleset matching:
</bodyText>
<listItem confidence="0.949449333333333">
• Core Role Matching Count The number of
core roles exist in both roleset definition and
given role sequence
• Distance of Matched Core Role Distance
between predicate and core role which ex-
ists in both roleset and given role sequence.
We use number of word and dependency path
length as a distance
• Indication for Same Particle It becomes
yes if given predicate and roleset have same
particle. (otherwise no)
• Indication for Same Functional Word It be-
</listItem>
<bodyText confidence="0.937565">
comes yes if one of core argument is same to
the functional word of roleset. (otherwise no)
To train the roleset match classifiers, we extract
semantic role sequence and its roleset from train-
ing data as a positive example. And then, we gen-
erate negative examples by changing its roleset to
other roleset of that predicate. For example, the
above sentence in &lt;text&gt; node3 becomes a pos-
itive example for cut.09 and negative examples
for other roleset such as cut.01, cut.02, etc.
</bodyText>
<footnote confidence="0.9964916">
2Some nodes are omitted to simplify the definition of ex-
ample.
3Of cause, we assume that this sentence exist in training
corpus. So, we will extract it from corpus, not from frameset
file.
</footnote>
<table confidence="0.98707875">
WSJ+Brown WSJ Brown
LM 76.90 77.96 68.34
LA 84.82 85.69 77.83
LF 68.71 69.95 58.63
</table>
<tableCaption confidence="0.98532025">
Table 1: System performance. LM, LA, LF means
macro labeled F1 for the overall task, labeled at-
tachment for syntactic dependencies, and labeled
F1 for semantic dependencies, respectively
</tableCaption>
<table confidence="0.9806255">
Labeled Prec. Labeled Rec. Labeled F1
88.68 73.89 80.28
</table>
<tableCaption confidence="0.948319666666667">
Table 2: Performance of Local Semantic Role La-
beler n WSJ test set. Gold parsing result, correct
predicates, and correct rolesets are used.
</tableCaption>
<sectionHeader confidence="0.998629" genericHeader="method">
3 Experimental Result
</sectionHeader>
<bodyText confidence="0.999993875">
We have tested our system with the test set and
obtained official results as shown in Table 1. We
have also experimented on each module and ob-
tained promising results.
We have tried to find the upper bound of the
local semantic role labeling module. Table 2
shows the performance when gold syntactic pars-
ing result, correct predicates, and correct rolesets
are given. Comparing to phrase structure parser
based semantic role labelings such as Pradhan et
al. (2005) and Toutanova et al. (2005), our local
semantic role labeler needs to enhance the perfor-
mance. We will try to add some lexical features or
chunk features in future works.
Next, we have analyzed the effect of roleset
based selector. Table 3 shows the effect of match-
ing score and relative frequency which are the
weighted factor of selection described in section
2.5. Here, baseline means that it selects a role se-
quence which has the highest score in CKY mod-
ule and roleset is chosen randomly. The results
show that roleset matching score and relative fre-
quency of roleset are effective to choose the correct
role sequence and identify roleset.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999903571428571">
In this paper, we have described a syntactic and
semantic dependency parsing system with five dif-
ferent modules. Each module is developed with
maximum entropy classifiers based on different
predicate types. In particular, dependency relation
compression method and extracted path patterns
are used to improve the performance in the argu-
</bodyText>
<page confidence="0.993754">
236
</page>
<table confidence="0.9996204">
Prec. Rec. F1
Baseline (c) 69.34 58.42 63.41
+ mc 71.40 60.20 65.32
+ rf 75.94 63.98 69.45
+ mc, rf 76.46 64.45 69.95
</table>
<tableCaption confidence="0.99787">
Table 3: Semantic scores of global sequence selec-
</tableCaption>
<bodyText confidence="0.967451">
tion in WSJ test set. mc, rf means matching score
and relative frequency, respectively
ment candidate identification. The roleset match-
ing method is devised to select the most appropri-
ate role sequence and to identify the correct role-
set.
However, the current features for roleset match-
ing seem to be not enough and other useful features
are expected to be found in the future work. There
is also a room for improving the method to inte-
grate the role sequence score, matching score, and
the relative frequency.
</bodyText>
<sectionHeader confidence="0.998739" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999903380952381">
Joakim Nivre, Jens Nilsson, Johan Hall, Atanas
Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav
Marinov, Erwin Marsi. 2007. MaltParser: A
Language-Independent System for Data-Driven De-
pendency Parsing. Natural Language Engineering,
13(2):95–135.
Kadri Hacioglu. 2008. Semantic role labeling using
dependency trees. In COLING ’04: Proceedings of
Proceedings of the 20th international conference on
Computational Linguistics. Morristown, NJ, USA.
Kristina Toutanova, Aria Haghighi, and Christopher D.
Manning. 2005. Joint learning improves semantic
role labeling. In ACL ’05: Proceedings of the 43rd
Annual Meeting on Association for Computational
Linguistics. Morristown, NJ, USA.
Mihai Surdeanu and Richard Johansson and Adam
Meyers and Lluis M`arquez and Joakim Nivre. 2008.
The CoNLL-2008 Shared Task on Joint Parsing of
Syntactic and Semantic Dependencies. In Proceed-
ings of the 12th Conference on Computational Natu-
ral Language Learning (CoNLL-2008).
Mihai Surdeanu, Lluis M`arquez, Xavier Carreras, and
Pere Comas. 2007. Combination Strategies for Se-
mantic Role Labeling. The Journal of Artificial In-
telligence Research, 29:105–151.
Sameer Pradhan, Kadri Hacioglu, Valerie Krugler,
Wayne Ward, James H. Martin, and Daniel Jurafsky.
2005. Support Vector Learning for Semantic Argu-
ment Classification. Machine Learning. 60:11–39.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James
Martin, and Dan Jurafsky. 2004. Shallow Se-
mantic Parsing Using Support Vector Machines. In
Proceedings of the Human Language Technology
Conference/North American chapter of the Associ-
ation of Computational Linguistics (HLT/NAACL).
Boston, MA, USA.
Xavier Carreras and Lluis M`arquez. 2005. Introduc-
tion to the CoNLL-2005 Shared Task: Semantic Role
Labeling. In Proceedings of CoNLL-2005.
Xavier Carreras and Lluis M`arquez. 2004. Introduc-
tion to the CoNLL-2004 Shared Task: Semantic Role
Labeling. In Proceedings of CoNLL-2004.
</reference>
<page confidence="0.997409">
237
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.270930">
<title confidence="0.8851926">Semantic Dependency Parsing using N-best Semantic Role Sequences and Roleset Information Joo-Young Lee, Han-Cheol Cho, and Hae-Chang Natural Language Processing Korea</title>
<author confidence="0.770513">South Seoul</author>
<abstract confidence="0.935805944444444">In this paper, we describe a syntactic and semantic dependency parsing system submitted to the shared task of CoNLL 2008. The proposed system consists of five modules: syntactic dependency parser, predicate identifier, local semantic role labeler, global role sequence candidate generator, and role sequence selector. The syntactic dependency parser is based on Malt Parser and the sequence candidate generator is based on CKY style algorithm. The remaining three modules are implemented by using maximum entropy classifiers. The proposed system achieves 76.90 of labeled F1 for the overall task, 84.82 of labeled attachment, and 68.71 of labeled F1 on the WSJ+Brown test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>CoNLL</author>
</authors>
<date>2008</date>
<booktitle>Proceedings of the 12th Conference on Computational Natural Language Learning,</booktitle>
<pages>233--237</pages>
<location>Manchester,</location>
<marker>CoNLL, 2008</marker>
<rawString>CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 233–237 Manchester, August 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<marker>Nivre, Nilsson, Hall, 2007</marker>
<rawString>Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, Erwin Marsi. 2007. MaltParser: A Language-Independent System for Data-Driven Dependency Parsing. Natural Language Engineering, 13(2):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kadri Hacioglu</author>
</authors>
<title>Semantic role labeling using dependency trees.</title>
<date>2008</date>
<booktitle>In COLING ’04: Proceedings of Proceedings of the 20th international conference on Computational Linguistics.</booktitle>
<location>Morristown, NJ, USA.</location>
<marker>Hacioglu, 2008</marker>
<rawString>Kadri Hacioglu. 2008. Semantic role labeling using dependency trees. In COLING ’04: Proceedings of Proceedings of the 20th international conference on Computational Linguistics. Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint learning improves semantic role labeling.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics.</booktitle>
<location>Morristown, NJ, USA.</location>
<marker>Toutanova, Haghighi, Manning, 2005</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2005. Joint learning improves semantic role labeling. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics. Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<booktitle>The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu and Richard Johansson and Adam Meyers and Lluis M`arquez and Joakim Nivre. 2008. The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Lluis M`arquez</author>
<author>Xavier Carreras</author>
<author>Pere Comas</author>
</authors>
<title>Combination Strategies for Semantic Role Labeling.</title>
<date>2007</date>
<journal>The Journal of Artificial Intelligence Research,</journal>
<pages>29--105</pages>
<marker>Surdeanu, M`arquez, Carreras, Comas, 2007</marker>
<rawString>Mihai Surdeanu, Lluis M`arquez, Xavier Carreras, and Pere Comas. 2007. Combination Strategies for Semantic Role Labeling. The Journal of Artificial Intelligence Research, 29:105–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valerie Krugler</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support Vector Learning for Semantic Argument Classification. Machine Learning.</title>
<date>2005</date>
<pages>60--11</pages>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2005. Support Vector Learning for Semantic Argument Classification. Machine Learning. 60:11–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>Kadri Hacioglu</author>
<author>James Martin</author>
<author>Dan Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing Using Support Vector Machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference/North American chapter of the Association of Computational Linguistics (HLT/NAACL).</booktitle>
<location>Boston, MA, USA.</location>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James Martin, and Dan Jurafsky. 2004. Shallow Semantic Parsing Using Support Vector Machines. In Proceedings of the Human Language Technology Conference/North American chapter of the Association of Computational Linguistics (HLT/NAACL). Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-2005.</booktitle>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Lluis M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling. In Proceedings of CoNLL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL-2004.</booktitle>
<marker>Carreras, M`arquez, 2004</marker>
<rawString>Xavier Carreras and Lluis M`arquez. 2004. Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling. In Proceedings of CoNLL-2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>