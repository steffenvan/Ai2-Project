<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005596">
<title confidence="0.991554">
Transliteration Generation and Mining with Limited Training Resources
</title>
<author confidence="0.995526">
Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma, Aditya Bhargava,
Qing Dou, Mi-Young Kim, Grzegorz Kondrak
</author>
<affiliation confidence="0.9985325">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.921107">
Edmonton, AB, T6G 2E8, Canada
</address>
<email confidence="0.999268">
{sj,dwyer,bergsma,abhargava,qdou,miyoung2,kondrak}@cs.ualberta.ca
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916272727273">
We present DIRECTL+: an online dis-
criminative sequence prediction model
based on many-to-many alignments,
which is further augmented by the in-
corporation of joint n-gram features.
Experimental results show improvement
over the results achieved by DIRECTL in
2009. We also explore a number of diverse
resource-free and language-independent
approaches to transliteration mining,
which range from simple to sophisticated.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999257291666667">
Many out-of-vocabulary words in statistical ma-
chine translation and cross-language information
retrieval are named entities. If the languages in
question use different writing scripts, such names
must be transliterated. Transliteration can be de-
fined as the conversion of a word from one writ-
ing script to another, which is usually based on the
phonetics of the original word.
DIRECTL+ is our current approach to name
transliteration which is an extension of the DI-
RECTL system (Jiampojamarn et al., 2009). We
augmented the feature set with joint n-gram fea-
tures which allow the discriminative model to uti-
lize long dependencies of joint information of
source and target substrings (Jiampojamarn et al.,
2010). Experimental results suggest an improve-
ment over the results achieved by DIRECTL in
2009.
Transliteration mining aims at automatically
obtaining bilingual lists of names written in differ-
ent scripts. We explore a number of different ap-
proaches to transliteration mining in the context of
the NEWS 2010 Shared Task.1 The sole resource
that is provided for each language pair is a “seed”
</bodyText>
<footnote confidence="0.9365365">
1http://translit.i2r.a-star.edu.sg/
news2010
</footnote>
<bodyText confidence="0.999575888888889">
dataset that contains 1K transliteration word pairs.
The objective is then to mine transliteration pairs
from a collection of Wikipedia titles/topics that are
given in both languages.
We explore a number of diverse resource-free
and language-independent approaches to translit-
eration mining. One approach is to bootstrap the
seed data by generating pseudo-negative exam-
ples, which are combined with the positives to
form a dataset that can be used to train a clas-
sifier. We are particularly interested in achiev-
ing good performance without utilizing language-
specific resources, so that the same approach can
be applied with minimal or no modifications to an
array of diverse language pairs.
This paper is divided in two main parts that cor-
respond to the two tasks of transliteration genera-
tion and transliteration mining.
</bodyText>
<sectionHeader confidence="0.978735" genericHeader="method">
2 Transliteration generation
</sectionHeader>
<bodyText confidence="0.999982111111111">
The structure of this section is as follows. In Sec-
tion 2.1, we describe the pre-processing steps that
were applied to all datasets. Section 2.2 reviews
two methods for aligning the source and target
symbols in the training data. We provide details
on the DIRECTL+ systems in Section 2.3. In Sec-
tion 2.4, we discuss extensions of DIRECTL+ that
incorporate language-specific information. Sec-
tion 2.5 summarizes our results.
</bodyText>
<subsectionHeader confidence="0.996891">
2.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.99996">
For all generation tasks, we pre-process the pro-
vided data as follows. First, we convert all char-
acters in the source word to lower case. Then,
we remove non-alphabetic characters unless they
appear in both the source and target words. We
normalize whitespace that surrounds a comma, so
that there are no spaces before the comma and ex-
actly one space following the comma. Finally, we
separate multi-word titles into single words, using
whitespace as the separator. We assume a mono-
</bodyText>
<page confidence="0.993303">
39
</page>
<note confidence="0.9795595">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 39–47,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9986657">
tonic matching and ignore the titles that have a dif-
ferent number of words on both sides.
We observed that in the ArAe task there are
cases where an extra space is added to the target
when transliterating from Arabic names to their
English equivalents; e.g., “Al Riyad”, “El Sayed”,
etc. In order to prevent the pre-processing from
removing too many title pairs, we allow non-equal
matching if the source title is a single word.
For the English-Chinese (EnCh) task, we con-
vert the English letter “x” to “ks” to facilitate bet-
ter matching with its Chinese targets.
During testing, we pre-process test data in the
same manner, except that we do not remove non-
alphabetic characters. After the pre-processing
steps, our system proposes 10-best lists for single
word titles in the test data. For multi-word titles,
we construct 10-best lists by ranking the combina-
tion scores of single words that make up the test
titles.
</bodyText>
<subsectionHeader confidence="0.991354">
2.2 Alignment
</subsectionHeader>
<bodyText confidence="0.999943178571428">
In the transliteration tasks, training data consist
of pairs of names written in source and target
scripts without explicit character-level alignment.
In our experiments, we applied two different algo-
rithms to automatically generate alignments in the
training data. The generated alignments provide
hypotheses of substring mappings in the training
data. Given aligned training data, a transliteration
model is trained to generate names in the target
language given names in the source language.
The M2M-aligner (Jiampojamarn et al., 2007)
is based on the expectation maximization (EM)
algorithm. It allows us to create alignments be-
tween substrings of various lengths. We opti-
mized the maximum substring sizes for the source
and target based on the performance of the end
task on the development sets. We allowed empty
strings (nulls) only on the target side. We used the
M2M-aligner for all alignment tasks, except for
English-Pinyin alignment. The source code of the
M2M-aligner is publicly available.2
An alternative alignment algorithm is based on
the phonetic similarity of graphemes. The key idea
of this approach is to represent each grapheme by a
phoneme or a sequence of phonemes that is likely
to be represented by the grapheme. The sequences
of phonemes on the source side and the target
side can then be aligned on the basis of phonetic
</bodyText>
<footnote confidence="0.710989">
2http://code.google.com/p/m2m-aligner/
</footnote>
<figure confidence="0.944132333333333">
b a r c - l a y
� � � � � � � �
b a - k u r - i
</figure>
<figureCaption confidence="0.998586">
Figure 1: An alignment example.
</figureCaption>
<bodyText confidence="0.9877101">
similarity between phonemes. The main advan-
tage of the phonetic alignment is that it requires
no training data. We use the ALINE phonetic
aligner (Kondrak, 2000), which aligns two strings
of phonemes. The example in Figure 1 shows
the alignment of the word Barclay to its Katakana
transliteration ba-ku-ri. The one-to-one alignment
can then be converted to a many-to-many align-
ment by grouping the Japanese phonemes that cor-
respond to individual Katakana symbols.
</bodyText>
<subsectionHeader confidence="0.994843">
2.3 DIRECTL+
</subsectionHeader>
<bodyText confidence="0.9996015">
We refer to our present approach to transliteration
as DIRECTL+. It is an extension of our DIRECTL
system (Jiampojamarn et al., 2009). It includes ad-
ditional “joint n-gram” features that allow the dis-
criminative model to correlate longer source and
target substrings. The additional features allow
our discriminative model to train on information
that is present in generative joint n-gram models,
and additionally train on rich source-side context,
transition, and linear-chain features that have been
demonstrated to be important in the transliteration
task (Jiampojamarn et al., 2010).
Our model is based on an online discriminative
framework. At each training iteration, the model
generates an m-best list for each given source
name based on the current feature weights. The
feature weights are updated according to the gold-
standard answers and the generated m-best an-
swer lists using the Margin Infused Relaxed Algo-
rithm (MIRA) (Crammer and Singer, 2003). This
training process iterates over the training examples
until the model converges. For m-best and n-gram
parameters, we set m = 10 and n = 6 for all lan-
guage pairs. These parameters as well as others
were optimized on the development sets.
We trained our models directly on the data
that were provided by the organizers, with three
exceptions. In order to improve performance,
we gave special treatment to English-Korean
(EnKo), English-Chinese (EnCh), and English-
Hindi (EnHi). These special cases are described
in the next section.
</bodyText>
<page confidence="0.996601">
40
</page>
<subsectionHeader confidence="0.9412255">
2.4 Beyond DIRECTL+
2.4.1 Korean Jaso
</subsectionHeader>
<bodyText confidence="0.9993795">
A Korean syllable can be decomposed into two
or three components called Jaso: an initial con-
sonant, a middle vowel, and optionally a final con-
sonant. The Korean generation for EnKo involves
the following three steps: (1) English-to-Jaso gen-
eration, (2) correction of illegal Jaso sequences,
and (3) Jaso-to-Korean conversion.
In order to correct illegal Jaso sequences that
cannot be combined into Korean syllables in step
2, we consider both vowel and consonant rules.
A Korean vowel can be either a simple vowel or
a complex vowel that combines two simple vow-
els. We can use this information in order to replace
double vowels with one complex vowel. We also
use the silent consonant o (i-eung) when we need
to insert a consonant between double vowels. A
Korean vowel - (eu) is most commonly inserted
between two English consonants in transliteration.
In order to resolve three consecutive consonants, it
can be placed into the most probable position ac-
cording to the probability distribution of the train-
ing data.
</bodyText>
<subsectionHeader confidence="0.936297">
2.4.2 Japanese Katakana
</subsectionHeader>
<bodyText confidence="0.99998625">
In the Japanese Katakana generation task, we re-
place each Katakana symbol with one or two let-
ters using standard romanization tables. This has
the effect of expressing the target side in Latin let-
ters, which facilitates the alignment. DIRECTL+
is trained on the converted data to generate the tar-
get from the source. A post-processing program
then attempts to convert the generated letters back
into Katakana symbols. Sequences of letters that
cannot be converted into Katakana are removed
from the output m-best lists and replaced by lower
scoring sequences that pass the back-conversion
filter. Otherwise, there is usually a single valid
mapping because most Katakana symbols are rep-
resented by single vowels or a consonant-vowel
pair. The only apparent ambiguity involves the
letter n, which can either stand by itself or clus-
ter with the following vowel letter. We resolve the
ambiguity by always assuming the latter case un-
less the letter n occurs at the end of the word.
</bodyText>
<subsectionHeader confidence="0.708844">
2.4.3 Chinese Pinyin
</subsectionHeader>
<bodyText confidence="0.999979342857143">
Following (Jiampojamarn et al., 2009), we experi-
mented with converting the original Chinese char-
acters to Pinyin as an intermediate representation.
Pinyin is the most commonly known romanization
system for Standard Mandarin and many free tools
are available for converting Chinese characters to
Pinyin. Its alphabet contains the same 26 letters
as English. Each Chinese character can be tran-
scribed phonetically into Pinyin. A small percent-
age of Chinese characters have multiple pronunci-
ations, and are thus represented by different Pinyin
sequences. For those characters, we manually se-
lected the pronunciations that are normally used
for names. This pre-processing step significantly
reduces the size of the target symbols: from 370
distinct Chinese characters to 26 Pinyin symbols.
This allows our system to produce better align-
ments.
We developed three models: (1) trained on the
original Chinese characters, (2) trained on Pinyin,
and (3) the model that incorporates the phonetic
alignment described in Section 2.2. The combi-
nation of the predictions of the different systems
was performed using the following simple algo-
rithm (Jiampojamarn et al., 2009). First, we rank
the individual systems according to their top-1 ac-
curacy on the development set. To obtain the top-
1 prediction for each input word, we use simple
voting, with ties broken according to the ranking
of the systems. We generalize this approach to
handle n-best lists by first ordering the candidate
transliterations according to the rank assigned by
each individual system, and then similarly break-
ing ties by voting and using the ranking of the sys-
tems.
</bodyText>
<subsubsectionHeader confidence="0.615516">
2.4.4 Language identification for Hindi
</subsubsectionHeader>
<bodyText confidence="0.999984947368421">
Bhargava and Kondrak (2010) apply support vec-
tor machines (SVMs) to the task of identifying
the language of names. The intuition here is that
language information can inform transliteration.
Bhargava and Kondrak (2010) test this hypothe-
sis on the NEWS 2009 English-Hindi transliter-
ation data by training language identification on
data manually tagged as being of either Indian or
non-Indian origin. It was found that splitting the
data disjointly into two sets and training separate
transliteration models yields no performance in-
crease due to the decreased size of the data for the
models.
We adopt this approach for the NEWS 2010
task, but here we do not use disjoint splits. In-
stead, we use the SVMs to generate probabilities,
and then we apply a threshold to these probabili-
ties to generate two datasets. For example, if we
set the threshold to be 0.05, then we determine the
</bodyText>
<page confidence="0.996637">
41
</page>
<bodyText confidence="0.999950722222222">
probabilities of a given name being of Indian ori-
gin (phi) and of being of non-Indian origin (pen).
If phi &lt; 0.05 then the name is excluded from the
Indian set, and if pen &lt; 0.05 then the name is
excluded from the non-Indian set. Using the two
obtained non-disjoint sets, we then train a translit-
eration model for each set using DIRECTL+.
Since the two sets are not disjoint, we must de-
cide how to combine the two results. Given that a
name occurs in both sets, and both models provide
a ranked list of possible targets for that name, we
obtain a combined ranking using a linear combi-
nation over the mean reciprocal ranks (MRRs) of
the two lists. The weights used are phi and pen so
that the more likely a name is considered to be of
Indian origin, the more strongly the result from the
Indian set is considered relative to the result from
the non-Indian set.
</bodyText>
<subsectionHeader confidence="0.921864">
2.5 Evaluation
</subsectionHeader>
<bodyText confidence="0.999718516129032">
In the context of the NEWS 2010 Machine
Transliteration Shared Task we tested our sys-
tem on all twelve datasets: from English to Chi-
nese (EnCh), Thai (EnTh), Hindi (EnHi), Tamil
(EnTa), Bangla (EnBa), Kannada (EnKa), Ko-
rean Hangul (EnKo), Japanese Katakana (EnJa),
Japanese Kanji (JnJk); and, in the opposite di-
rection, to English from Arabic (ArAe), Chi-
nese (ChEn), and Thai (ThEn). For all datasets,
we trained transliteration models on the provided
training and development sets without additional
resources.
Table 1 shows our best results obtained on the
datasets in terms of top-1 accuracy and mean F-
score. We also include the rank in standard runs
ordered by top-1 word accuracy. The EnCh re-
sult presented in the table refers to the output of
the three-system combination, using the combi-
nation algorithm described in Section 2.4.3. The
respective results for the three component EnCh
systems were: 0.357, 0.360, and 0.363. The
EnJa result in the table refers the system described
in Section 2.4.2 that applied specific treatment
to Japanese Katakana. Based on our develop-
ment results, this specific treatment improves as
much as 2% top-1 accuracy over the language-
independent model. The EnHi system that in-
corporates language identification obtained ex-
actly the same top-1 accuracy as the language-
independent model. However, the EnKo system
with Jaso correction produced the top-1 accu-
</bodyText>
<table confidence="0.999768">
Task top-1 F-score Rank
EnCh 0.363 0.707 2
ChEn 0.137 0.740 1
EnTh 0.378 0.866 2
ThEn 0.352 0.861 2
EnHi 0.456 0.884 1
EnTa 0.390 0.891 2
EnKa 0.341 0.867 2
EnJa 0.398 0.791 1
EnKo 0.554 0.770 1
JnJk 0.126 0.426 1
ArAe 0.464 0.924 1
EnBa 0.395 0.877 2
</table>
<tableCaption confidence="0.999785">
Table 1: Transliteration generation results
</tableCaption>
<bodyText confidence="0.997007666666667">
racy of 0.554, which is a significant improvement
over 0.387 achieved by the language-independent
model.
</bodyText>
<sectionHeader confidence="0.99454" genericHeader="method">
3 Transliteration mining
</sectionHeader>
<bodyText confidence="0.999960333333333">
This section is structured as follows. In Sec-
tion 3.1, we describe the method of extracting
transliteration candidates that serves as the input
to the subsequently presented mining approaches.
Two techniques for generating negative exam-
ples are discussed in Section 3.2. Our language-
independent approaches to transliteration mining
are described in Section 3.3, and a technique for
mining English-Chinese pairs is proposed in Sec-
tion 3.4. In Section 3.5, we address the issue of
overlapping predictions. Finally, Section 3.6 and
Section 3.7 summarize our results.
</bodyText>
<subsectionHeader confidence="0.99984">
3.1 Extracting transliteration candidates
</subsectionHeader>
<bodyText confidence="0.999880375">
We cast the transliteration mining task as a bi-
nary classification problem. That is, given a word
in the source language and a word in the target
language, a classifier predicts whether or not the
pair constitutes a valid transliteration. As a pre-
processing step, we extract candidate translitera-
tions from the pairs of Wikipedia titles. Word seg-
mentation is performed based on sequences of one
or more spaces and/or punctuation symbols, which
include hyphens, underscores, brackets, and sev-
eral other non-alphanumeric characters. Apostro-
phes and single quotes are not used for segmenta-
tion (and therefore remain in a given word); how-
ever, all single quote-like characters are converted
into a generic apostrophe. Once an English ti-
tle and its target language counterpart have been
</bodyText>
<page confidence="0.99579">
42
</page>
<bodyText confidence="0.999928555555556">
segmented into words, we form the candidate set
for this title as the cross product of the two sets
of words after discarding any words that contain
fewer than two characters.
After the candidates have been extracted, indi-
vidual words are flagged for certain attributes that
may be used by our supervised learner as addi-
tional features. Alternatively, the flags may serve
as criteria for filtering the list of candidate pairs
prior to classification. We identify words that are
capitalized, consist of all lowercase (or all capital)
letters, and/or contain one or more digits. We also
attempt to encode each word in the target language
as an ASCII string, and flag that word if the opera-
tion succeeds. This can be used to filter out words
that are written in English on both the source and
target side, which are not transliterations by defi-
nition.
</bodyText>
<subsectionHeader confidence="0.998345">
3.2 Generating negative training examples
</subsectionHeader>
<bodyText confidence="0.999992387096774">
The main issue with applying a supervised learn-
ing approach to the NEWS 2010 Shared Task is
that annotated task-specific data is not available
to train the system. However, the seed pairs do
provide example transliterations, and these can be
used as positive training examples. The remaining
issue is how to select the negative examples.
We adopt two approaches for selecting nega-
tives. First, we generate all possible source-target
pairs in the seed data, and take as negatives those
pairs which are not transliterations but have a
longest common subsequence ratio (LCSR) above
0.58; this mirrors the approach used by Bergsma
and Kondrak (2007). The method assumes that
the source and target words are written in the same
script (e.g., the foreign word has been romanized).
A second possibility is to generate all seed pair-
ings as above, but then randomly select negative
examples, thus mirroring the approach in Klemen-
tiev and Roth (2006). In this case, the source and
target scripts do not need to be the same. Com-
pared with the LCSR technique, random sampling
in this manner has the potential to produce nega-
tive examples that are very “easy” (i.e., clearly not
transliterations), and which may be of limited util-
ity when training a classifier. On the other hand, at
test time, the set of candidates extracted from the
Wikipedia data will include pairs that have very
low LCSR scores; hence, it can be argued that dis-
similar pairs should also appear as negative exam-
ples in the training set.
</bodyText>
<subsectionHeader confidence="0.997696">
3.3 Language-independent approaches
</subsectionHeader>
<bodyText confidence="0.999988888888889">
In this section, we describe methods for transliter-
ation mining that can, in principle, be applied to a
wide variety of language pairs without additional
modification. For the purposes of the Shared Task,
however, we convert all source (English) words to
ASCII by removing diacritics and making appro-
priate substitutions for foreign letters. This is done
to mitigate sparsity in the relatively small seed sets
when training our classifiers.
</bodyText>
<subsectionHeader confidence="0.680324">
3.3.1 Alignment-derived romanization
</subsectionHeader>
<bodyText confidence="0.9999583125">
We developed a simple method of performing ro-
manization of foreign scripts. Initially, the seed set
of transliterations is aligned using the one-to-one
option of the M2M-aligner approach (Jiampoja-
marn et al., 2007). We allow nulls on both the
source and target sides. The resulting alignment
model contains pairs of Latin letters and foreign
script symbols (graphemes) sorted by their con-
ditional probability. Then, for each grapheme,
we select a letter (or a null symbol) that has the
highest conditional probability. The process pro-
duces an approximate romanization table that can
be obtained without any knowledge of the target
script. This method of romanization was used by
all methods described in the remainder of Sec-
tion 3.3.
</bodyText>
<subsectionHeader confidence="0.728861">
3.3.2 Normalized edit distance
</subsectionHeader>
<bodyText confidence="0.999843318181818">
Normalized edit distance (NED) is a measure of
the similarity of two strings. We define a uniform
edit cost for each of the three operations: substitu-
tion, insertion, and deletion. NED is computed by
dividing the minimum edit distance by the length
of the longer string, and subtracting the resulting
fraction from 1. Thus, the extreme values of NED
are 1 for identical strings, and 0 for strings that
have no characters in common.
Our baseline method, NED+ is simply the NED
measure augmented with filtering of the candidate
pairs described in Section 3.1. In order to address
the issue of morphological variants, we also fil-
ter out the pairs in which the English word ends
in a consonant and the foreign word ends with a
vowel. With no development set provided, we set
the similarity thresholds for individual languages
on the basis of the average word length in the seed
sets. The values were 0.38, 0.48, 0.52, and 0.58
for Hindi, Arabic, Tamil, and Russian, respec-
tively, with the last number taken from Bergsma
and Kondrak (2007).
</bodyText>
<page confidence="0.99949">
43
</page>
<subsectionHeader confidence="0.780921">
3.3.3 Alignment-based string similarity
</subsectionHeader>
<bodyText confidence="0.9999080625">
NED selects transliteration candidates when the
romanized foreign strings have high character
overlap with their English counterparts. The mea-
sure is independent of the language pair. This
is suboptimal for several reasons. First of all,
phonetically unrelated words can share many in-
cidental character matches. For example, the
French word ‘recettes’ and the English word
‘proceeds’ share the letters r,c,e,e,s as a com-
mon subsequence, but the words are phonetically
unrelated. Secondly, many reliable, recurrent,
language-specific substring matches are prevalent
in true transliterations. These pairings may or may
not involve matching characters. NED can not
learn or adapt to these language-specific patterns.
In light of these drawbacks, researchers have
proposed string similarity measures that can learn
from provided example pairs and adapt the simi-
larity function to a specific task (Ristad and Yiani-
los, 1998; Bilenko and Mooney, 2003; McCallum
et al., 2005; Klementiev and Roth, 2006).
One particularly successful approach is by
Bergsma and Kondrak (2007), who use discrim-
inative learning with an improved feature repre-
sentation. The features are substring pairs that are
consistent with a character-level alignment of the
two strings. This approach strongly improved per-
formance on cognate identification, while varia-
tions of it have also proven successful in transliter-
ation discovery (Goldwasser and Roth, 2008). We
therefore adopted this approach for the translitera-
tion mining task.
We produce negative training examples using
the LCSR threshold approach described in Sec-
tion 3.2. For features, we extract from the aligned
word pairs all substring pairs up to a maximum
length of three. We also append characters mark-
ing the beginning and end of words, as described
in Bergsma and Kondrak (2007). For our clas-
sifier, we use a Support Vector Machine (SVM)
training with the very efficient LIBLINEAR pack-
age (Fan et al., 2008). We optimize the SVM’s
regularization parameter using 10-fold cross vali-
dation on the generated training data. At test time,
we apply our classifier to all the transliteration
candidates extracted from the Wikipedia titles,
generating transliteration pairs whenever there is
a positive classification.
</bodyText>
<subsectionHeader confidence="0.941573">
3.3.4 String kernel classifier
</subsectionHeader>
<bodyText confidence="0.999968666666667">
The alignment-based classifier described in the
preceding section is limited to using substring fea-
tures that are up to (roughly) three or four letters
in length, due to the combinatorial explosion in the
number of unique features as the substring length
increases. It is natural to ask whether longer sub-
strings can be utilized to learn a more accurate pre-
dictor.
This question inspired the development of a sec-
ond SVM-based learner that uses a string kernel,
and therefore does not have to explicitly repre-
sent feature vectors. Our kernel is a standard n-
gram (or spectrum) kernel that implicitly embeds
a string in a feature space that has one co-ordinate
for each unique n-gram (see, e.g., (Shawe-Taylor
and Cristianini, 2004)). Let us denote the alphabet
over input strings as A. Given two input strings x
and x′, this kernel function computes:
</bodyText>
<equation confidence="0.7200355">
�k(x, x′) = #(s, x)#(s, x′)
s∈An
</equation>
<bodyText confidence="0.999961379310345">
where s is an n-gram and #(a, b) counts the num-
ber of times a appears as a substring of b.
An extension of the n-gram kernel that we em-
ploy here is to consider all n-grams of length
1 &lt; n &lt; k, and weight each n-gram as a func-
tion of its length. In particular, we specify a value
A and weight each n-gram by a factor of An. We
implemented this kernel in the LIBSVM software
package (Chang and Lin, 2001). Optimal values
for k, A, and the SVM’s regularization parame-
ter were estimated for each dataset using 5-fold
cross-validation. The values of (k, A) that we ul-
timately used were: EnAr (3, 0.8), EnHi (8, 0.8),
EnRu (5,1.2), and EnTa (5,1.0).
Our input string representation for a candidate
pair is formed by first aligning the source and tar-
get words using M2M-aligner (Jiampojamarn et
al., 2007). Specifically, an alignment model is
trained on the seed examples, which are subse-
quently aligned and used as positive training ex-
amples. We then generate 20K negative examples
by random sampling (cf. Section 3.2) and apply
the alignment model to this set. Not all of these
20K word pairs will necessarily be aligned; we
randomly select 10K of the successfully aligned
pairs to use as negative examples in the training
set.
Each aligned pair is converted into an “align-
ment string” by placing the letters that appear in
</bodyText>
<page confidence="0.998303">
44
</page>
<table confidence="0.838542666666667">
Word pair zubtsov 3y6uoB
Aligned pair z|u|b|t|s|o|v|3|y|6|u ||o|B|
Align’t string z3|uy|b6|tu|s |oo|vB
</table>
<tableCaption confidence="0.944908">
Table 2: An example showing how an alignment
</tableCaption>
<bodyText confidence="0.983112368421053">
string (the input representation for the string ker-
nel) is created from a word pair.
the same position in the source and target next to
one another, while retaining the separator charac-
ters (see Table 2). We also appended beginning
and end of word markers. Note that no romaniza-
tion of the target words is necessary for this pro-
cedure.
At test time, we apply the alignment model to
the candidate word pairs that have been extracted
from the train data, and retain all the successfully
aligned pairs. Here, M2M-aligner also acts as a
filter, since we cannot form alignment strings from
unaligned pairs — these yield negative predictions
by default. We also filter out pairs that met any of
the following conditions: 1) the English word con-
sists of all all capital or lowercase letters, 2) the
target word can be converted to ASCII (cf. Sec-
tion 3.1), or 3) either word contains a digit.
</bodyText>
<subsectionHeader confidence="0.853169">
3.3.5 Generation-based approach
</subsectionHeader>
<bodyText confidence="0.999818857142857">
In the mining tasks, we are interested in whether a
candidate pair (x, y) is a transliteration pair. One
approach is to determine if the generated translit-
erations of a source word y� = α(x) and a target
word x� = β(y) are similar to the given candi-
date pair. We applied DIRECTL+ to the mining
tasks by training transliteration generation models
on the provided seed data in forward and back-
ward transliteration directions, creating α(x) and
β(y) models. We now define a transliteration
score function in Eq. 1. N(x, x) is the normal-
ized edit distance between string x� and x, and w1
and w2 are combination weights to favor forward
and backward transliteration models.
</bodyText>
<equation confidence="0.999360333333333">
w1 · N(�y, y) + w2 · N(�x, x)
S(x, y) = (1)
w1 + w2
</equation>
<bodyText confidence="0.999685846153846">
A candidate pair is considered a transliteration
pair if its S(x, y) &gt; τ. Ideally, we would like
to optimize these parameters, τ, w1, w2 based on
a development set for each language pair. Unfor-
tunately, no development sets were provided for
the Shared Task. Therefore, following Bergsma
and Kondrak (2007), we adopt the threshold of
τ = 0.58. We experimented with three sets of val-
ues for w1 and w2: (1, 0), (0.5, 0.5), and (0, 1).
Our final predictions were made using w0 = 0
and w1 = 1, which appeared to produce the best
results. Thus, only the backward transliteration
model was ultimately employed.
</bodyText>
<subsectionHeader confidence="0.994939">
3.4 English-Chinese string matching
</subsectionHeader>
<bodyText confidence="0.999994976744186">
Due to the fact that names transliterated into Chi-
nese consist of multiple Chinese characters and
that the Chinese text provided in this shared task
is not segmented, we have to adopt a different ap-
proach to the English-Chinese mining task (Unlike
many other languages, there are no clear bound-
aries between Chinese words). We first train a
generation model using the seed data and then ap-
ply a greedy string matching algorithm to extract
transliteration pairs.
The generation model is built using the discrim-
inative training framework described in (Jiampoja-
marn et al., 2008). Two models are learned: one
is trained using English and Chinese characters,
while the other is trained on English and Pinyin (a
standard phonetic representation of Chinese char-
acters). In order to mine transliteration pairs from
Wikipedia titles, we first use the generation model
to produce transliterations for each English token
on the source side as both Chinese characters and
Pinyin. The generated Chinese characters are ul-
timately converted to Pinyin during string match-
ing. We also convert all the Chinese characters on
the target side to their Pinyin representations when
performing string matching.
The transliteration pairs are then mined by com-
bining two different strategies. First of all, we ob-
serve that most of the titles that contain a separa-
tion symbol “ · ” on the target side are translit-
erations. In this case, the number of tokens on
both sides is often equal. Therefore, the mining
task can be formulated as a matching problem.
We use a competitive linking approach (Melamed,
2000) to find the best match. First, we select
links between all possible pairs if similarity of
strings on both sides is above a threshold (0.6 ∗
length(Pinyin)). We then greedily extract the
pairs with highest similarity until the number of
unextracted segments on either side becomes zero.
The problem becomes harder when there is no
indication of word segmentation for Chinese. In-
stead of trying to segment the Chinese characters
first, we use an incremental string matching strat-
</bodyText>
<page confidence="0.997608">
45
</page>
<bodyText confidence="0.999922777777778">
egy. For each token on the source side, the algo-
rithm calculates its similarity with all possible n-
grams (2 &lt; n &lt; L) on the target side, where L
is the length of the Chinese title (i.e., the number
of characters). If the similarity score of n-gram
with the highest similarity surpasses a threshold
(0.5 x length(Pinyin)), the n-gram sequence is
proposed as a possible transliteration for the cur-
rent source token.
</bodyText>
<subsectionHeader confidence="0.973161">
3.5 Resolving overlapping predictions
</subsectionHeader>
<bodyText confidence="0.999955125">
Given a set of candidate word pairs that have been
extracted from a given Wikipedia title according to
the procedure described in Section 3.1, our clas-
sifiers predict a class label for each pair inde-
pendently of the others. Pairs that receive neg-
ative predictions are discarded immediately and
are never reported as mined pairs. However, it
is sometimes necessary to arbitrate between pos-
itive predictions, since it is possible for a classifier
to mark as transliterations two or more pairs that
involve the same English word or the same target
word in the title. Clearly, mining multiple overlap-
ping pairs will lower the system’s precision, since
there is (presumably) at most one correct translit-
eration in the target language version of the title
for each English word.3
Our solution is to apply a greedy algorithm that
sorts the word pair predictions for a given title
in descending order according to the scores that
were assigned by the classifier. We make one pass
through the sorted list and report a pair of words as
a mined pair unless the English word or the target
language word has already been reported (for this
particular title).4
</bodyText>
<sectionHeader confidence="0.756995" genericHeader="evaluation">
3.6 Results
</sectionHeader>
<bodyText confidence="0.999905">
In the context of the NEWS 2010 Shared Task
on Transliteration Generation we tested our sys-
tem on all five data sets: from English to Rus-
sian (EnRu), Hindi (EnHi), Tamil (EnTa), Arabic
(EnAr), and Chinese (EnCh). The EnCh set dif-
fers from the remaining sets in the lack of transpar-
ent word segmentation on the Chinese side. There
were no development sets provided for any of the
language pairs.
</bodyText>
<footnote confidence="0.996288571428571">
3On the other hand, mining all such pairs might improve
recall.
4A bug was later discovered in our implementation of this
algorithm, which had failed to add the words in a title’s first
mined pair to the “already reported” list. This sometimes
caused up to two additional mined pairs per title to be re-
ported in the prediction files that were submitted.
</footnote>
<table confidence="0.99993152631579">
Task System F P R
EnRu NED+ .875 .880 .869
BK-2007 .778 .684 .902
StringKernel* .811 .746 .889
DIRECTL+ .786 .778 .795
EnHi NED+ .907 .875 .941
BK-2007 .882 .883 .880
StringKernel .924 .954 .895
DIRECTL+ .904 .945 .866
EnTa NED+ .791 .916 .696
BK-2007 .829 .808 .852
StringKernel .914 .923 .906
DIRECTL+ .801 .919 .710
EnAr NED+ .800 .818 .783
BK-2007 .816 .834 .798
StringKernel* .827 .917 .753
DIRECTL+ .742 .861 .652
EnCh GreedyMatch .530 .698 .427
DIRECTL+ .009 .045 .005
</table>
<tableCaption confidence="0.847218">
Table 3: Transliteration mining results. An aster-
isk (*) indicates an unofficial result.
</tableCaption>
<bodyText confidence="0.9909374">
Table 3 shows the results obtained by our var-
ious systems on the final test sets, measured in
terms of F-score (F), precision (P), and recall
(R). The systems referred to as NED+, BK-2007,
StringKernel, DIRECTL+, and GreedyMatch are
described in Section 3.3.2, Section 3.3.3, Sec-
tion 3.3.4, Section 3.3.5, and Section 3.4 respec-
tively. The runs marked with an asterisk (*)
were produced after the Shared Task deadline, and
therefore are not included in the official results.
</bodyText>
<subsectionHeader confidence="0.644021">
3.7 Discussion
</subsectionHeader>
<bodyText confidence="0.9999755625">
No fixed ranking of the four approaches emerges
across the four alphabetic language pairs (all ex-
cept EnCh). However, StringKernel appears to be
the most robust, achieving the highest F-score on
three language pairs. This suggests that longer
substring features are indeed useful for classifying
candidate transliteration pairs. The simple NED+
method is a clear winner on EnRu, and obtains de-
cent scores on the remaining alphabetic language
pairs. The generation-based DIRECTL+ approach
ranks no higher than third on any language pair,
and it fails spectacularly on EnCh because of the
word segmentation ambiguity.
Finally, we observe that there are a number of
cases where the results for our discriminatively
trained classifiers, BK-2007 and StringKernel, are
</bodyText>
<page confidence="0.997192">
46
</page>
<bodyText confidence="0.999980818181818">
not significantly better than those of the simple
NED+ approach. We conjecture that automatically
generating training examples is suboptimal for this
task. A more effective strategy may be to filter all
possible word pairs in the seed data to only those
with NED above a fixed threshold. We would then
apply the same threshold to the Wikipedia candi-
dates, only passing to the classifier those pairs that
surpass the threshold. This would enable a better
match between the training and test operation of
the system.
</bodyText>
<sectionHeader confidence="0.999684" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99137775">
The results obtained in the context of the NEWS
2010 Machine Transliteration Shared Task con-
firm the effectiveness of our discriminative ap-
proaches to transliteration generation and mining.
</bodyText>
<sectionHeader confidence="0.999504" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99748875">
This research was supported by the Alberta Inge-
nuity Fund, Informatics Circle of Research Excel-
lence (iCORE), and the Natural Sciences and En-
gineering Research Council of Canada (NSERC).
</bodyText>
<sectionHeader confidence="0.99934" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999731016949153">
Shane Bergsma and Grzegorz Kondrak. 2007.
Alignment-based discriminative string similarity. In
Proc. ACL.
Aditya Bhargava and Grzegorz Kondrak. 2010. Lan-
guage identification of names with SVMs. In Proc.
NAACL-HLT.
Mikhail Bilenko and Raymond J. Mooney. 2003.
Adaptive duplicate detection using learnable string
similarity measures. In Proc. KDD.
Chih-Chung Chang and Chih-Jen Lin. 2001. LIB-
SVM: a library for support vector machines.
Software available at http://www.csie.ntu.
edu.tw/∼cjlin/libsvm.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal ofMachine Learning Research, 3:951–991.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLIN-
EAR: A library for large linear classification. JMLR,
9:1871–1874.
Dan Goldwasser and Dan Roth. 2008. Transliteration
as constrained optimization. In Proc. EMNLP.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and Hidden Markov Models to letter-to-phoneme
conversion. In Proc. HLT-NAACL.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Proc.
ACL.
Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,
Kenneth Dwyer, and Grzegorz Kondrak. 2009. Di-
recTL: a language-independent approach to translit-
eration. In NEWS ’09: Proceedings of the 2009
Named Entities Workshop: Shared Task on Translit-
eration, pages 28–31.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2010. Integrating joint n-gram features
into a discriminative training framework. In Proc.
NAACL-HLT.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proc. HLT-NAACL.
Grzegorz Kondrak. 2000. A new algorithm for the
alignment of phonetic sequences. In Proc. NAACL,
pages 288–295.
Andrew McCallum, Kedar Bellare, and Fernando
Pereira. 2005. A conditional random field for
discriminatively-trained finite-state string edit dis-
tance. In Proc. UAI.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221–249.
Eric Sven Ristad and Peter N. Yianilos. 1998. Learn-
ing string-edit distance. IEEE Trans. Pattern Analy-
sis and Machine Intelligence, 20(5).
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
</reference>
<page confidence="0.99949">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.763789">
<title confidence="0.999921">Transliteration Generation and Mining with Limited Training Resources</title>
<author confidence="0.970242">Sittichai Jiampojamarn</author>
<author confidence="0.970242">Kenneth Dwyer</author>
<author confidence="0.970242">Shane Bergsma</author>
<author confidence="0.970242">Aditya Qing Dou</author>
<author confidence="0.970242">Mi-Young Kim</author>
<author confidence="0.970242">Grzegorz</author>
<affiliation confidence="0.9979015">Department of Computing University of</affiliation>
<address confidence="0.835091">Edmonton, AB, T6G 2E8,</address>
<abstract confidence="0.997675833333333">present an online discriminative sequence prediction model based on many-to-many alignments, which is further augmented by the inof joint features. Experimental results show improvement the results achieved by in 2009. We also explore a number of diverse resource-free and language-independent approaches to transliteration mining, which range from simple to sophisticated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Alignment-based discriminative string similarity.</title>
<date>2007</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="18469" citStr="Bergsma and Kondrak (2007)" startWordPosition="2963" endWordPosition="2966"> applying a supervised learning approach to the NEWS 2010 Shared Task is that annotated task-specific data is not available to train the system. However, the seed pairs do provide example transliterations, and these can be used as positive training examples. The remaining issue is how to select the negative examples. We adopt two approaches for selecting negatives. First, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have a longest common subsequence ratio (LCSR) above 0.58; this mirrors the approach used by Bergsma and Kondrak (2007). The method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized). A second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in Klementiev and Roth (2006). In this case, the source and target scripts do not need to be the same. Compared with the LCSR technique, random sampling in this manner has the potential to produce negative examples that are very “easy” (i.e., clearly not transliterations), and which may be of limited utility when training a classifi</context>
<context position="21633" citStr="Bergsma and Kondrak (2007)" startWordPosition="3486" endWordPosition="3489">o characters in common. Our baseline method, NED+ is simply the NED measure augmented with filtering of the candidate pairs described in Section 3.1. In order to address the issue of morphological variants, we also filter out the pairs in which the English word ends in a consonant and the foreign word ends with a vowel. With no development set provided, we set the similarity thresholds for individual languages on the basis of the average word length in the seed sets. The values were 0.38, 0.48, 0.52, and 0.58 for Hindi, Arabic, Tamil, and Russian, respectively, with the last number taken from Bergsma and Kondrak (2007). 43 3.3.3 Alignment-based string similarity NED selects transliteration candidates when the romanized foreign strings have high character overlap with their English counterparts. The measure is independent of the language pair. This is suboptimal for several reasons. First of all, phonetically unrelated words can share many incidental character matches. For example, the French word ‘recettes’ and the English word ‘proceeds’ share the letters r,c,e,e,s as a common subsequence, but the words are phonetically unrelated. Secondly, many reliable, recurrent, language-specific substring matches are </context>
<context position="23489" citStr="Bergsma and Kondrak (2007)" startWordPosition="3765" endWordPosition="3768">nsistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold approach described in Section 3.2. For features, we extract from the aligned word pairs all substring pairs up to a maximum length of three. We also append characters marking the beginning and end of words, as described in Bergsma and Kondrak (2007). For our classifier, we use a Support Vector Machine (SVM) training with the very efficient LIBLINEAR package (Fan et al., 2008). We optimize the SVM’s regularization parameter using 10-fold cross validation on the generated training data. At test time, we apply our classifier to all the transliteration candidates extracted from the Wikipedia titles, generating transliteration pairs whenever there is a positive classification. 3.3.4 String kernel classifier The alignment-based classifier described in the preceding section is limited to using substring features that are up to (roughly) three o</context>
<context position="28247" citStr="Bergsma and Kondrak (2007)" startWordPosition="4584" endWordPosition="4587">sliteration directions, creating α(x) and β(y) models. We now define a transliteration score function in Eq. 1. N(x, x) is the normalized edit distance between string x� and x, and w1 and w2 are combination weights to favor forward and backward transliteration models. w1 · N(�y, y) + w2 · N(�x, x) S(x, y) = (1) w1 + w2 A candidate pair is considered a transliteration pair if its S(x, y) &gt; τ. Ideally, we would like to optimize these parameters, τ, w1, w2 based on a development set for each language pair. Unfortunately, no development sets were provided for the Shared Task. Therefore, following Bergsma and Kondrak (2007), we adopt the threshold of τ = 0.58. We experimented with three sets of values for w1 and w2: (1, 0), (0.5, 0.5), and (0, 1). Our final predictions were made using w0 = 0 and w1 = 1, which appeared to produce the best results. Thus, only the backward transliteration model was ultimately employed. 3.4 English-Chinese string matching Due to the fact that names transliterated into Chinese consist of multiple Chinese characters and that the Chinese text provided in this shared task is not segmented, we have to adopt a different approach to the English-Chinese mining task (Unlike many other langua</context>
</contexts>
<marker>Bergsma, Kondrak, 2007</marker>
<rawString>Shane Bergsma and Grzegorz Kondrak. 2007. Alignment-based discriminative string similarity. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aditya Bhargava</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Language identification of names with SVMs.</title>
<date>2010</date>
<booktitle>In Proc. NAACL-HLT.</booktitle>
<contexts>
<context position="11992" citStr="Bhargava and Kondrak (2010)" startWordPosition="1889" endWordPosition="1892">erent systems was performed using the following simple algorithm (Jiampojamarn et al., 2009). First, we rank the individual systems according to their top-1 accuracy on the development set. To obtain the top1 prediction for each input word, we use simple voting, with ties broken according to the ranking of the systems. We generalize this approach to handle n-best lists by first ordering the candidate transliterations according to the rank assigned by each individual system, and then similarly breaking ties by voting and using the ranking of the systems. 2.4.4 Language identification for Hindi Bhargava and Kondrak (2010) apply support vector machines (SVMs) to the task of identifying the language of names. The intuition here is that language information can inform transliteration. Bhargava and Kondrak (2010) test this hypothesis on the NEWS 2009 English-Hindi transliteration data by training language identification on data manually tagged as being of either Indian or non-Indian origin. It was found that splitting the data disjointly into two sets and training separate transliteration models yields no performance increase due to the decreased size of the data for the models. We adopt this approach for the NEWS</context>
</contexts>
<marker>Bhargava, Kondrak, 2010</marker>
<rawString>Aditya Bhargava and Grzegorz Kondrak. 2010. Language identification of names with SVMs. In Proc. NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bilenko</author>
<author>Raymond J Mooney</author>
</authors>
<title>Adaptive duplicate detection using learnable string similarity measures.</title>
<date>2003</date>
<booktitle>In Proc. KDD.</booktitle>
<contexts>
<context position="22622" citStr="Bilenko and Mooney, 2003" startWordPosition="3630" endWordPosition="3633">ple, the French word ‘recettes’ and the English word ‘proceeds’ share the letters r,c,e,e,s as a common subsequence, but the words are phonetically unrelated. Secondly, many reliable, recurrent, language-specific substring matches are prevalent in true transliterations. These pairings may or may not involve matching characters. NED can not learn or adapt to these language-specific patterns. In light of these drawbacks, researchers have proposed string similarity measures that can learn from provided example pairs and adapt the similarity function to a specific task (Ristad and Yianilos, 1998; Bilenko and Mooney, 2003; McCallum et al., 2005; Klementiev and Roth, 2006). One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using t</context>
</contexts>
<marker>Bilenko, Mooney, 2003</marker>
<rawString>Mikhail Bilenko and Raymond J. Mooney. 2003. Adaptive duplicate detection using learnable string similarity measures. In Proc. KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.</title>
<date>2001</date>
<note>edu.tw/∼cjlin/libsvm.</note>
<contexts>
<context position="25236" citStr="Chang and Lin, 2001" startWordPosition="4067" endWordPosition="4070">ch unique n-gram (see, e.g., (Shawe-Taylor and Cristianini, 2004)). Let us denote the alphabet over input strings as A. Given two input strings x and x′, this kernel function computes: �k(x, x′) = #(s, x)#(s, x′) s∈An where s is an n-gram and #(a, b) counts the number of times a appears as a substring of b. An extension of the n-gram kernel that we employ here is to consider all n-grams of length 1 &lt; n &lt; k, and weight each n-gram as a function of its length. In particular, we specify a value A and weight each n-gram by a factor of An. We implemented this kernel in the LIBSVM software package (Chang and Lin, 2001). Optimal values for k, A, and the SVM’s regularization parameter were estimated for each dataset using 5-fold cross-validation. The values of (k, A) that we ultimately used were: EnAr (3, 0.8), EnHi (8, 0.8), EnRu (5,1.2), and EnTa (5,1.0). Our input string representation for a candidate pair is formed by first aligning the source and target words using M2M-aligner (Jiampojamarn et al., 2007). Specifically, an alignment model is trained on the seed examples, which are subsequently aligned and used as positive training examples. We then generate 20K negative examples by random sampling (cf. Se</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu. edu.tw/∼cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="7681" citStr="Crammer and Singer, 2003" startWordPosition="1196" endWordPosition="1199"> information that is present in generative joint n-gram models, and additionally train on rich source-side context, transition, and linear-chain features that have been demonstrated to be important in the transliteration task (Jiampojamarn et al., 2010). Our model is based on an online discriminative framework. At each training iteration, the model generates an m-best list for each given source name based on the current feature weights. The feature weights are updated according to the goldstandard answers and the generated m-best answer lists using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003). This training process iterates over the training examples until the model converges. For m-best and n-gram parameters, we set m = 10 and n = 6 for all language pairs. These parameters as well as others were optimized on the development sets. We trained our models directly on the data that were provided by the organizers, with three exceptions. In order to improve performance, we gave special treatment to English-Korean (EnKo), English-Chinese (EnCh), and EnglishHindi (EnHi). These special cases are described in the next section. 40 2.4 Beyond DIRECTL+ 2.4.1 Korean Jaso A Korean syllable can </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal ofMachine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>JMLR,</journal>
<pages>9--1871</pages>
<contexts>
<context position="23618" citStr="Fan et al., 2008" startWordPosition="3788" endWordPosition="3791"> variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold approach described in Section 3.2. For features, we extract from the aligned word pairs all substring pairs up to a maximum length of three. We also append characters marking the beginning and end of words, as described in Bergsma and Kondrak (2007). For our classifier, we use a Support Vector Machine (SVM) training with the very efficient LIBLINEAR package (Fan et al., 2008). We optimize the SVM’s regularization parameter using 10-fold cross validation on the generated training data. At test time, we apply our classifier to all the transliteration candidates extracted from the Wikipedia titles, generating transliteration pairs whenever there is a positive classification. 3.3.4 String kernel classifier The alignment-based classifier described in the preceding section is limited to using substring features that are up to (roughly) three or four letters in length, due to the combinatorial explosion in the number of unique features as the substring length increases. </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. JMLR, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
</authors>
<title>Transliteration as constrained optimization.</title>
<date>2008</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="23103" citStr="Goldwasser and Roth, 2008" startWordPosition="3701" endWordPosition="3704">t can learn from provided example pairs and adapt the similarity function to a specific task (Ristad and Yianilos, 1998; Bilenko and Mooney, 2003; McCallum et al., 2005; Klementiev and Roth, 2006). One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold approach described in Section 3.2. For features, we extract from the aligned word pairs all substring pairs up to a maximum length of three. We also append characters marking the beginning and end of words, as described in Bergsma and Kondrak (2007). For our classifier, we use a Support Vector Machine (SVM) training with the very efficient LIBLINEAR package (Fan et al., 2008). We optimize the SVM’s regularization parameter using 10-fold cross validation on th</context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>Dan Goldwasser and Dan Roth. 2008. Transliteration as constrained optimization. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and Hidden Markov Models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. HLT-NAACL.</booktitle>
<contexts>
<context position="5315" citStr="Jiampojamarn et al., 2007" startWordPosition="808" endWordPosition="811">king the combination scores of single words that make up the test titles. 2.2 Alignment In the transliteration tasks, training data consist of pairs of names written in source and target scripts without explicit character-level alignment. In our experiments, we applied two different algorithms to automatically generate alignments in the training data. The generated alignments provide hypotheses of substring mappings in the training data. Given aligned training data, a transliteration model is trained to generate names in the target language given names in the source language. The M2M-aligner (Jiampojamarn et al., 2007) is based on the expectation maximization (EM) algorithm. It allows us to create alignments between substrings of various lengths. We optimized the maximum substring sizes for the source and target based on the performance of the end task on the development sets. We allowed empty strings (nulls) only on the target side. We used the M2M-aligner for all alignment tasks, except for English-Pinyin alignment. The source code of the M2M-aligner is publicly available.2 An alternative alignment algorithm is based on the phonetic similarity of graphemes. The key idea of this approach is to represent ea</context>
<context position="20048" citStr="Jiampojamarn et al., 2007" startWordPosition="3219" endWordPosition="3223">at can, in principle, be applied to a wide variety of language pairs without additional modification. For the purposes of the Shared Task, however, we convert all source (English) words to ASCII by removing diacritics and making appropriate substitutions for foreign letters. This is done to mitigate sparsity in the relatively small seed sets when training our classifiers. 3.3.1 Alignment-derived romanization We developed a simple method of performing romanization of foreign scripts. Initially, the seed set of transliterations is aligned using the one-to-one option of the M2M-aligner approach (Jiampojamarn et al., 2007). We allow nulls on both the source and target sides. The resulting alignment model contains pairs of Latin letters and foreign script symbols (graphemes) sorted by their conditional probability. Then, for each grapheme, we select a letter (or a null symbol) that has the highest conditional probability. The process produces an approximate romanization table that can be obtained without any knowledge of the target script. This method of romanization was used by all methods described in the remainder of Section 3.3. 3.3.2 Normalized edit distance Normalized edit distance (NED) is a measure of th</context>
<context position="25632" citStr="Jiampojamarn et al., 2007" startWordPosition="4133" endWordPosition="4136">of length 1 &lt; n &lt; k, and weight each n-gram as a function of its length. In particular, we specify a value A and weight each n-gram by a factor of An. We implemented this kernel in the LIBSVM software package (Chang and Lin, 2001). Optimal values for k, A, and the SVM’s regularization parameter were estimated for each dataset using 5-fold cross-validation. The values of (k, A) that we ultimately used were: EnAr (3, 0.8), EnHi (8, 0.8), EnRu (5,1.2), and EnTa (5,1.0). Our input string representation for a candidate pair is formed by first aligning the source and target words using M2M-aligner (Jiampojamarn et al., 2007). Specifically, an alignment model is trained on the seed examples, which are subsequently aligned and used as positive training examples. We then generate 20K negative examples by random sampling (cf. Section 3.2) and apply the alignment model to this set. Not all of these 20K word pairs will necessarily be aligned; we randomly select 10K of the successfully aligned pairs to use as negative examples in the training set. Each aligned pair is converted into an “alignment string” by placing the letters that appear in 44 Word pair zubtsov 3y6uoB Aligned pair z|u|b|t|s|o|v|3|y|6|u ||o|B| Align’t s</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and Hidden Markov Models to letter-to-phoneme conversion. In Proc. HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion. In</title>
<date>2008</date>
<booktitle>Proc. ACL.</booktitle>
<contexts>
<context position="29158" citStr="Jiampojamarn et al., 2008" startWordPosition="4738" endWordPosition="4742">ely employed. 3.4 English-Chinese string matching Due to the fact that names transliterated into Chinese consist of multiple Chinese characters and that the Chinese text provided in this shared task is not segmented, we have to adopt a different approach to the English-Chinese mining task (Unlike many other languages, there are no clear boundaries between Chinese words). We first train a generation model using the seed data and then apply a greedy string matching algorithm to extract transliteration pairs. The generation model is built using the discriminative training framework described in (Jiampojamarn et al., 2008). Two models are learned: one is trained using English and Chinese characters, while the other is trained on English and Pinyin (a standard phonetic representation of Chinese characters). In order to mine transliteration pairs from Wikipedia titles, we first use the generation model to produce transliterations for each English token on the source side as both Chinese characters and Pinyin. The generated Chinese characters are ultimately converted to Pinyin during string matching. We also convert all the Chinese characters on the target side to their Pinyin representations when performing strin</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Aditya Bhargava</author>
<author>Qing Dou</author>
<author>Kenneth Dwyer</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>DirecTL: a language-independent approach to transliteration.</title>
<date>2009</date>
<booktitle>In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,</booktitle>
<pages>28--31</pages>
<contexts>
<context position="1280" citStr="Jiampojamarn et al., 2009" startWordPosition="171" endWordPosition="174"> and language-independent approaches to transliteration mining, which range from simple to sophisticated. 1 Introduction Many out-of-vocabulary words in statistical machine translation and cross-language information retrieval are named entities. If the languages in question use different writing scripts, such names must be transliterated. Transliteration can be defined as the conversion of a word from one writing script to another, which is usually based on the phonetics of the original word. DIRECTL+ is our current approach to name transliteration which is an extension of the DIRECTL system (Jiampojamarn et al., 2009). We augmented the feature set with joint n-gram features which allow the discriminative model to utilize long dependencies of joint information of source and target substrings (Jiampojamarn et al., 2010). Experimental results suggest an improvement over the results achieved by DIRECTL in 2009. Transliteration mining aims at automatically obtaining bilingual lists of names written in different scripts. We explore a number of different approaches to transliteration mining in the context of the NEWS 2010 Shared Task.1 The sole resource that is provided for each language pair is a “seed” 1http://</context>
<context position="6855" citStr="Jiampojamarn et al., 2009" startWordPosition="1071" endWordPosition="1074">gnment example. similarity between phonemes. The main advantage of the phonetic alignment is that it requires no training data. We use the ALINE phonetic aligner (Kondrak, 2000), which aligns two strings of phonemes. The example in Figure 1 shows the alignment of the word Barclay to its Katakana transliteration ba-ku-ri. The one-to-one alignment can then be converted to a many-to-many alignment by grouping the Japanese phonemes that correspond to individual Katakana symbols. 2.3 DIRECTL+ We refer to our present approach to transliteration as DIRECTL+. It is an extension of our DIRECTL system (Jiampojamarn et al., 2009). It includes additional “joint n-gram” features that allow the discriminative model to correlate longer source and target substrings. The additional features allow our discriminative model to train on information that is present in generative joint n-gram models, and additionally train on rich source-side context, transition, and linear-chain features that have been demonstrated to be important in the transliteration task (Jiampojamarn et al., 2010). Our model is based on an online discriminative framework. At each training iteration, the model generates an m-best list for each given source n</context>
<context position="10334" citStr="Jiampojamarn et al., 2009" startWordPosition="1630" endWordPosition="1633">symbols. Sequences of letters that cannot be converted into Katakana are removed from the output m-best lists and replaced by lower scoring sequences that pass the back-conversion filter. Otherwise, there is usually a single valid mapping because most Katakana symbols are represented by single vowels or a consonant-vowel pair. The only apparent ambiguity involves the letter n, which can either stand by itself or cluster with the following vowel letter. We resolve the ambiguity by always assuming the latter case unless the letter n occurs at the end of the word. 2.4.3 Chinese Pinyin Following (Jiampojamarn et al., 2009), we experimented with converting the original Chinese characters to Pinyin as an intermediate representation. Pinyin is the most commonly known romanization system for Standard Mandarin and many free tools are available for converting Chinese characters to Pinyin. Its alphabet contains the same 26 letters as English. Each Chinese character can be transcribed phonetically into Pinyin. A small percentage of Chinese characters have multiple pronunciations, and are thus represented by different Pinyin sequences. For those characters, we manually selected the pronunciations that are normally used </context>
</contexts>
<marker>Jiampojamarn, Bhargava, Dou, Dwyer, Kondrak, 2009</marker>
<rawString>Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou, Kenneth Dwyer, and Grzegorz Kondrak. 2009. DirecTL: a language-independent approach to transliteration. In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration, pages 28–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Integrating joint n-gram features into a discriminative training framework.</title>
<date>2010</date>
<booktitle>In Proc. NAACL-HLT.</booktitle>
<contexts>
<context position="1484" citStr="Jiampojamarn et al., 2010" startWordPosition="203" endWordPosition="206">information retrieval are named entities. If the languages in question use different writing scripts, such names must be transliterated. Transliteration can be defined as the conversion of a word from one writing script to another, which is usually based on the phonetics of the original word. DIRECTL+ is our current approach to name transliteration which is an extension of the DIRECTL system (Jiampojamarn et al., 2009). We augmented the feature set with joint n-gram features which allow the discriminative model to utilize long dependencies of joint information of source and target substrings (Jiampojamarn et al., 2010). Experimental results suggest an improvement over the results achieved by DIRECTL in 2009. Transliteration mining aims at automatically obtaining bilingual lists of names written in different scripts. We explore a number of different approaches to transliteration mining in the context of the NEWS 2010 Shared Task.1 The sole resource that is provided for each language pair is a “seed” 1http://translit.i2r.a-star.edu.sg/ news2010 dataset that contains 1K transliteration word pairs. The objective is then to mine transliteration pairs from a collection of Wikipedia titles/topics that are given in</context>
<context position="7309" citStr="Jiampojamarn et al., 2010" startWordPosition="1136" endWordPosition="1139">ividual Katakana symbols. 2.3 DIRECTL+ We refer to our present approach to transliteration as DIRECTL+. It is an extension of our DIRECTL system (Jiampojamarn et al., 2009). It includes additional “joint n-gram” features that allow the discriminative model to correlate longer source and target substrings. The additional features allow our discriminative model to train on information that is present in generative joint n-gram models, and additionally train on rich source-side context, transition, and linear-chain features that have been demonstrated to be important in the transliteration task (Jiampojamarn et al., 2010). Our model is based on an online discriminative framework. At each training iteration, the model generates an m-best list for each given source name based on the current feature weights. The feature weights are updated according to the goldstandard answers and the generated m-best answer lists using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003). This training process iterates over the training examples until the model converges. For m-best and n-gram parameters, we set m = 10 and n = 6 for all language pairs. These parameters as well as others were optimized on the de</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2010. Integrating joint n-gram features into a discriminative training framework. In Proc. NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. HLT-NAACL.</booktitle>
<contexts>
<context position="18764" citStr="Klementiev and Roth (2006)" startWordPosition="3012" endWordPosition="3016"> the negative examples. We adopt two approaches for selecting negatives. First, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have a longest common subsequence ratio (LCSR) above 0.58; this mirrors the approach used by Bergsma and Kondrak (2007). The method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized). A second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in Klementiev and Roth (2006). In this case, the source and target scripts do not need to be the same. Compared with the LCSR technique, random sampling in this manner has the potential to produce negative examples that are very “easy” (i.e., clearly not transliterations), and which may be of limited utility when training a classifier. On the other hand, at test time, the set of candidates extracted from the Wikipedia data will include pairs that have very low LCSR scores; hence, it can be argued that dissimilar pairs should also appear as negative examples in the training set. 3.3 Language-independent approaches In this </context>
<context position="22673" citStr="Klementiev and Roth, 2006" startWordPosition="3638" endWordPosition="3641">ord ‘proceeds’ share the letters r,c,e,e,s as a common subsequence, but the words are phonetically unrelated. Secondly, many reliable, recurrent, language-specific substring matches are prevalent in true transliterations. These pairings may or may not involve matching characters. NED can not learn or adapt to these language-specific patterns. In light of these drawbacks, researchers have proposed string similarity measures that can learn from provided example pairs and adapt the similarity function to a specific task (Ristad and Yianilos, 1998; Bilenko and Mooney, 2003; McCallum et al., 2005; Klementiev and Roth, 2006). One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold approach described in Section 3.2</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Named entity transliteration and discovery from multilingual comparable corpora. In Proc. HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="6406" citStr="Kondrak, 2000" startWordPosition="1002" endWordPosition="1003">tive alignment algorithm is based on the phonetic similarity of graphemes. The key idea of this approach is to represent each grapheme by a phoneme or a sequence of phonemes that is likely to be represented by the grapheme. The sequences of phonemes on the source side and the target side can then be aligned on the basis of phonetic 2http://code.google.com/p/m2m-aligner/ b a r c - l a y � � � � � � � � b a - k u r - i Figure 1: An alignment example. similarity between phonemes. The main advantage of the phonetic alignment is that it requires no training data. We use the ALINE phonetic aligner (Kondrak, 2000), which aligns two strings of phonemes. The example in Figure 1 shows the alignment of the word Barclay to its Katakana transliteration ba-ku-ri. The one-to-one alignment can then be converted to a many-to-many alignment by grouping the Japanese phonemes that correspond to individual Katakana symbols. 2.3 DIRECTL+ We refer to our present approach to transliteration as DIRECTL+. It is an extension of our DIRECTL system (Jiampojamarn et al., 2009). It includes additional “joint n-gram” features that allow the discriminative model to correlate longer source and target substrings. The additional f</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In Proc. NAACL, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Kedar Bellare</author>
<author>Fernando Pereira</author>
</authors>
<title>A conditional random field for discriminatively-trained finite-state string edit distance.</title>
<date>2005</date>
<booktitle>In Proc. UAI.</booktitle>
<contexts>
<context position="22645" citStr="McCallum et al., 2005" startWordPosition="3634" endWordPosition="3637">ttes’ and the English word ‘proceeds’ share the letters r,c,e,e,s as a common subsequence, but the words are phonetically unrelated. Secondly, many reliable, recurrent, language-specific substring matches are prevalent in true transliterations. These pairings may or may not involve matching characters. NED can not learn or adapt to these language-specific patterns. In light of these drawbacks, researchers have proposed string similarity measures that can learn from provided example pairs and adapt the similarity function to a specific task (Ristad and Yianilos, 1998; Bilenko and Mooney, 2003; McCallum et al., 2005; Klementiev and Roth, 2006). One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold appro</context>
</contexts>
<marker>McCallum, Bellare, Pereira, 2005</marker>
<rawString>Andrew McCallum, Kedar Bellare, and Fernando Pereira. 2005. A conditional random field for discriminatively-trained finite-state string edit distance. In Proc. UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of translational equivalence among words.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="30165" citStr="Melamed, 2000" startWordPosition="4906" endWordPosition="4907">The generated Chinese characters are ultimately converted to Pinyin during string matching. We also convert all the Chinese characters on the target side to their Pinyin representations when performing string matching. The transliteration pairs are then mined by combining two different strategies. First of all, we observe that most of the titles that contain a separation symbol “ · ” on the target side are transliterations. In this case, the number of tokens on both sides is often equal. Therefore, the mining task can be formulated as a matching problem. We use a competitive linking approach (Melamed, 2000) to find the best match. First, we select links between all possible pairs if similarity of strings on both sides is above a threshold (0.6 ∗ length(Pinyin)). We then greedily extract the pairs with highest similarity until the number of unextracted segments on either side becomes zero. The problem becomes harder when there is no indication of word segmentation for Chinese. Instead of trying to segment the Chinese characters first, we use an incremental string matching strat45 egy. For each token on the source side, the algorithm calculates its similarity with all possible ngrams (2 &lt; n &lt; L) o</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>I. Dan Melamed. 2000. Models of translational equivalence among words. Computational Linguistics, 26(2):221–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Sven Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<title>Learning string-edit distance.</title>
<date>1998</date>
<journal>IEEE Trans. Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="22596" citStr="Ristad and Yianilos, 1998" startWordPosition="3625" endWordPosition="3629">character matches. For example, the French word ‘recettes’ and the English word ‘proceeds’ share the letters r,c,e,e,s as a common subsequence, but the words are phonetically unrelated. Secondly, many reliable, recurrent, language-specific substring matches are prevalent in true transliterations. These pairings may or may not involve matching characters. NED can not learn or adapt to these language-specific patterns. In light of these drawbacks, researchers have proposed string similarity measures that can learn from provided example pairs and adapt the similarity function to a specific task (Ristad and Yianilos, 1998; Bilenko and Mooney, 2003; McCallum et al., 2005; Klementiev and Roth, 2006). One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric Sven Ristad and Peter N. Yianilos. 1998. Learning string-edit distance. IEEE Trans. Pattern Analysis and Machine Intelligence, 20(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="24681" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="3955" endWordPosition="3958">g features that are up to (roughly) three or four letters in length, due to the combinatorial explosion in the number of unique features as the substring length increases. It is natural to ask whether longer substrings can be utilized to learn a more accurate predictor. This question inspired the development of a second SVM-based learner that uses a string kernel, and therefore does not have to explicitly represent feature vectors. Our kernel is a standard ngram (or spectrum) kernel that implicitly embeds a string in a feature space that has one co-ordinate for each unique n-gram (see, e.g., (Shawe-Taylor and Cristianini, 2004)). Let us denote the alphabet over input strings as A. Given two input strings x and x′, this kernel function computes: �k(x, x′) = #(s, x)#(s, x′) s∈An where s is an n-gram and #(a, b) counts the number of times a appears as a substring of b. An extension of the n-gram kernel that we employ here is to consider all n-grams of length 1 &lt; n &lt; k, and weight each n-gram as a function of its length. In particular, we specify a value A and weight each n-gram by a factor of An. We implemented this kernel in the LIBSVM software package (Chang and Lin, 2001). Optimal values for k, A, and the SVM’s regu</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>