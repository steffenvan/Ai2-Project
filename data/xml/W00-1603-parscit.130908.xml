<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.170299">
<title confidence="0.895464">
Time as a Measure of Parsing Efficiency
</title>
<author confidence="0.880224">
Robert C. Moore
</author>
<affiliation confidence="0.786665">
Microsoft Research
</affiliation>
<address confidence="0.9188535">
One Microsoft Way
Redmond, Washington 98052, USA
</address>
<email confidence="0.99865">
bobmoore@microsoft.eorn
</email>
<sectionHeader confidence="0.987601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999833388888889">
Charniak and his colleagues have proposed
implementation-independent metrics as a way
of comparing the efficiency of parsing algo-
rithms implemented on different platforms, in
different languages, and with different degrees
of &amp;quot;incidental optimization&amp;quot;. We argue that
there are easily immaginable circumstances in
which their proposed metrics would mask signif-
icant differences in efficiency; we point out that
their data do not, in fact, support the usability
of such metrics for comparing the efficiency of
different algorithms; and we analyze data for a
similar metric to try to quantify the degree of
variation one might expect between such met-
rics and actual parse time. Finally, we propose
a methodology for making cross-platform com-
parisons through the use of reference parser im-
plementations.
</bodyText>
<sectionHeader confidence="0.995599" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961037037037">
The title &amp;quot;Time as a Measure of Parsing Ef-
ficiency&amp;quot; may seem highly tautologous, since
in computer science &amp;quot;efficiency&amp;quot;, unless other-
wise qualified, is usually taken to mean speed
of execution. However, Charniak and his col-
leagues (Caraballo and Charniak, 1998; Char-
niak, Goldwater, and Johnson, 1998; Blaheta
and Charniak, 1999) have argued for another
metric edges popped off the agenda of a chart
parser as being platform independent. Now
Roark and Charniak (2000) propose a related
measure, &amp;quot;events considered&amp;quot;, that is applica-
ble to a wider range of approaches.
The present paper attempts to make the case
for going back to time as the primary mea-
sure of parsing efficiency. First, we explore
some general issues concerning the type of met-
rics proposed by Charniak and his colleagues.
Then we demonstrate using empirical data that
implementation-independent measures similar
to that proposed by Charniak can vary in how
well they correlate to execution time by as much
or more than the improvements reported by
Charniak et al. in some of their experiments.
Finally, we propose a methodology for compar-
ing parse times on different platforms, through
the use of reference parser implementations.
</bodyText>
<sectionHeader confidence="0.7120975" genericHeader="introduction">
2 Implementation-Independent
Parser Metrics
</sectionHeader>
<bodyText confidence="0.987042782608696">
As mentioned above, Charniak and his col-
leagues (Caraballo and Charniak, 1998; Char-
niak, Goldwater, and Johnson, 1998; Blaheta
and Charniak, 1999; Roark and Charniak, 2000)
have argued for implementation-independent
measures of parsing efficiency, including edges
popped off the agenda of a chart parser and,
currently, &amp;quot;events considered&amp;quot;, which is defined
by Roark and Charniak (2000) as &amp;quot;the number
of &apos;events&apos;, however they are defined for a par-
ticular parser, for which a probability must be
calculated, in order to find the parse.&amp;quot; It is ar-
gued in these papers that such metrics enable
parsing efficiency to be compared at the algo-
rithmic level without being concerned with the
degree of low-level optimization that has been
performed.
Roark and Charniak have applied the events-
considered metric both to a best-first parser
and to a word-synchronous beam-search-based
parser. These parsers differ in many respects,
but have a number of attributes in common that
bear on the current discussion:
</bodyText>
<listItem confidence="0.993683">
• They both are probabilistic, and seek to
find the parse with the highest probability
according to some model.
• They are both heuristically pruned. That
is, they do not explore all analyses that
</listItem>
<page confidence="0.997598">
23
</page>
<bodyText confidence="0.994570953846154">
have non-zero probability, nor are they
even guaranteed to explore all analyses that
might turn out to have the highest proba-
bility.
• They both prune partial analyses on the
basis of a figure of merit that can be viewed
as based on an heuristic estimate of the
expected probability that the full model
would assign to extensions of a given par-
tial analysis.
Within this framework, let us consider some
of the ways that the number of events consid-
ered could fail to correlate with parse time in an
essential way; that is, not based on what Roark
and Charniak refer to as &amp;quot;incidental optimiza-
tions&amp;quot;. First, the full probability models might
take vastly different amounts of time to com-
pute. For example, maximum-entropy, or expo-
nential, models (Berger, Della Pietra, and Dell
Pietra, 1996) are believed by some to hold the
promise of significantly higher accuracy in a va-
riety of tasks than the more conventional, sim-
pler models that Charniak and colleagues have
used. Unfortunately, maximum entropy models
are much more expensive to compute than these
simpler models, if they are normalized to pro-
duce true probability distributions.&apos; Thus if we
compared a parser that used a normalized ex-
ponential model to compute the probability of
exactly the same events that one of Roark&apos;s and
Charniak&apos;s parsers considers, we would expect
to find it much slower than theirs. This might
be a trade-off worth making, if it delivered bet-
ter parsing accuracy, but it would be ludicrous
to claim it was equally efficient, simply because
it considered no more events than Roark&apos;s and
Charniak&apos;s parsers.
Another way that the events-considered met-
ric might fail to correlate with parse time con-
cerns the figure of merit used to prune he search.
The efficacy of pruning is perhaps the most im-
portant determinant of parsing efficiency in the
types of parsers considered by Roark and Char-
niak. The better the figure of merit is as a
predictor of the probability assigned by the full
model to the best extension of a partial analy-
sis, the smaller the number of partial analyses
that need to be extended to find the best full
&apos;Note that Charniak (2000) has also explored unnor-
malized exponential models, which are fast to compute.
analysis. It is easy to imagine, however, that
some &amp;quot;better&amp;quot; figure of merit might take more
time to compute than it repays in reducing the
search space. Suppose a there is a sophisticated
figure of merit that allows reducing the number
of events considered by half over a cruder figure
of merit, but it takes so long to compute that it
increases the amount of time per event consid-
ered by a factor of ten. The events-considered
metric will rate the sophisticated figure of merit
as twice as good, even though in reality a parser
that used it would be five times slower. This is a
classic problem in heuristic search and has been
discussed extensively in the literature on com-
puter chess and automatic theorem proving.
</bodyText>
<sectionHeader confidence="0.991704" genericHeader="method">
3 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.999988735294118">
The arguments in the preceding section are in
a sense speculative, since they discuss possibil-
ities that might occur, but we have not demon-
strated that they do occur in practice. For that,
empirical evidence is required. At first blush,
Roark and Charniak might seem to have pro-
duced empirical evidence to the contrary, since
they present graphs of impressively linear rela-
tionships between events considered and time.
These linear relationships, however, are demon-
strated only with respect to one parser at a
time, where the only thing that is varied is the
degree of pruning Thus, although Roark and
Charniak argue for events-considered metric as
a way of comparing very different parsing algo-
rithms, they demonstrate only that it correlates
well with efficiency for essentially identical algo-
rithms, where only a single parameter is varied.
We have recently carried out a series of exper-
iments (Moore, 2000) comparing the efficiency
of several variants of left-corner parsing with a
number of other well-known context-free pars-
ing algorithms In contrast to the studies of
Charniak et al., these experiments looked at
non-stochastic algorithms, and the comparisons
are made on the basis of exhaustive, rather
than heuristically-pruned, parsing. Thus we
cannot directly apply either Roark and Char-
niak&apos;s events-considered metric, or the earlier
edges-popped-of-the-agenda metric, to our re-
sults. However, the total number of edges in the
chart, which we do have data on, is a very simi-
lar sort of implementation-independent metric,
and is often used informally to judge parser ef-
</bodyText>
<page confidence="0.992267">
24
</page>
<bodyText confidence="0.999952803921569">
ficiency. (Arguably, this would be the same as
the edges-popped-of-the-agenda metric, when
parser is allowed to run to exhaustion.)
To evaluate the suitability of using total
number of edges in the chart as an effi-
ciency metric, we will present a selection of
results from our CFG parsing experiments,
including edge statistics not previously pub-
lished. Results for five parsing algorithms
on three different grammars are included.
The parsing algorithms consist of two vari-
ants of left-corner parsing (LCi+BUPM and
LC2+BUPM), an Earley/Graham-Harrison-
Ruzzo parser (E/GHR), a Cocke-Kasami-
Younger parser (CKY), and a generalized LR
parser without look-ahead (GRL(0)). (The
identifiers for these parsers are the ones used in
our earlier report.) It should be mentioned that
all these parsers represent the best of several
implementations of the general approach, and
all parsers are implemented using similar tech-
niques and data structures wherever possible.
Furthermore, all algorithms are implemented in
the same language (Per15) on the same platform
(Windows 2000, 550 MHz Pentium III). Thus
we believe that the performance differences are
genuinely representative of inherent differences
in the algorithms, and not just irrelevant imple-
mentation details.
The grammars used are independently moti-
vated by analyses of natural-language corpora
or actual applications of natural language pro-
cessing. The CT grammar was compiled into
a CFG from a task-specific unification gram-
mar written for CommandTalk (Moore et al.,
1997), a spoken-language interface to a military
simulation system. The ATIS grammar was ex-
tracted from an internally generated treebank
of the DARPA ATIS3 training sentences. The
PT grammar is Charniak&apos;s PCFG grammar ex-
tracted from the Penn Treebank, with the prob-
abilities omitted. The most significant variation
among the grammars is the degree of ambiguity
of the test sets associated with each grammar.
The CT test set has 5.4 parses/sentence with
the CT grammar, the ATIS test set has 940
parses/sentence with the ATIS grammar, and
the PT test set has 7.2 x 1027 parses/sentence
with the PT grammar.
Table 1 shows the results of applying these
five parsers to the three grammars and their as-
sociated test sets. The first column gives the
average number of chart edges per sentence,
including both complete and incomplete edges
(where incomplete edges are generated). For the
GLR(0) parser, this is equivalent to the num-
ber of edges in the graph-structured stack used
by most implementations of GLR parsing. The
second column gives the average number of sec-
onds per sentence to parse exhaustively. This
includes only time to populate the chart, and
does not include time to extract parses. The fi-
nal column compares the second column to the
first, to derive an average number of millisec-
onds per chart edge. The more constant this
number is across the different parsers and gram-
mars, the better total edges in the chart will be
as a measure of parser efficiency.
If we look at the last column in detail, we see
that total number of chart edges generated does
have some crude validity as a measure of parsing
efficiency; since the majority of the test cases
fall around 0.1 milliseconds per edge. However,
the variation is fairly large. The two left-corner
parsers make a particularly interesting compar-
ison, because they differ only in a single de-
tail, and produce exactly the same edges. In
these parsers incomplete edges are subjected to
two tests before being added to the chart. The
mother of an incomplete edge has to be a possi-
ble left corner of the next daughter required by
some previous incomplete edge at the appropri-
ate position in the input; furthermore, the next
daughter of the incomplete edge being tested
has to have the next token in the input as a
possible left corner. These tests are indepen-
dent, so they can be performed in either or-
der. In LCi+BUPM the check on the mother is
performed first, and in LC2+BUPM the check
on the next daughter is performed first. These
results show that performing the check on the
mother first is 14% to 68% slower than perform-
ing the check on the next daughter first. This is
a substantial difference that cannot be detected
looking only at the edges added to the chart.
There are several places in the data where
the numbers of chart edges strongly, but incor-
rectly, predict which of two parsers should be
faster on a given grammar. For example, the
LCi+BUPM parser generates only about half
as many edges as the E/GHR parser with the
ATIS grammar, but is nevertheless 35% slower.
</bodyText>
<page confidence="0.997911">
25
</page>
<table confidence="0.9999605625">
Grammar Parser Edges/sent Sec/sent msec/edge
CT LCi+BUPM 165.3 0.0219 0.132
LC2+BUPM 165.3 0.0191 0.116
E/GHR 283.0 0.0448 0.158
CKY 1598.2 0.1540 0.096
GLR(0) 159.0 0.0214 0.135
ATIS LCi+BUPM 673.4 0.119 0.177
LC2+BUPM 673.4 0.071 0.105
E/GHR 1276.6 0.088 0.069
CKY 537.3 0.078 0.145
GLR(0) 1282.5 0.143 0.112
PT LCi+BUPM 6675.4 1.14 0.171
LC2+BUPM 6675.4 0.90 0.135
E/GHR 11143.9 0.92 0.083
CKY 5785.6 1.70 0.294
GLR(0) 51285.9 28.86 0.563
</table>
<tableCaption confidence="0.999936">
Table 1: Chart edge and time statistics for CFG parsing algorithms
</tableCaption>
<bodyText confidence="0.998033975">
It is also notable that the CKY and GLR(0)
parsers are not even self-consistent in terms of
time per edge across grammars. They take sub-
stantially more time per edge on the PT gram-
mar than on the other two.
One way to quantify the uncertainty about
the relationship between edges produced and
parse time is to use statistical analysis to es-
timate how many fewer edges one parser has to
produce to be reasonably certain that it is ac-
tually faster than another. We have performed
a crude version of such an analysis on the data
in Table 1, under the assumption that they rep-
resent a random sample of parsers and gram-
mars, suggesting the following: To be 99% cer-
tain that one parser is faster than another, it
must produce about 80% fewer edges; to be 95%
certain, it must produce about 70% fewer edges;
and to be 90% certain, it must produce about
60% fewer edges. This analysis undoubtedly
suffers from the paucity of the data, and per-
forming a wider range of experiments might well
give us tighter bounds, but it at least represents
a first cut at quantifying the variation in time-
per-edge across different parsing algorithms and
grammars. (See the Appendix for information
on how the analysis was performed.)
If we look at Charniak&apos;s latest paper re-
porting improved parser efficiency (Blaheta and
Charniak, 1999), we find a reported reduction
in edges popped off the agenda of about 60%.
We do not doubt that this result is in fact a sub-
stantial improvement over the previous method
it was compared to, but in the context of the
variation in time per edge among the parsers
presented here, we would be hard pressed to
claim this result represents a statistically sig-
nificant improvement in parsing speed, without
seeing parsing times not provided by Blaheta
and Charniak.
</bodyText>
<sectionHeader confidence="0.7651985" genericHeader="method">
4 Towards a Cross-Platform
Methodology
</sectionHeader>
<bodyText confidence="0.99256252631579">
The substantial variation in time per edge
among the parsers and grammars discussed
here strongly suggests that, in making efficiency
comparisons, actual parse times should be mea-
sured whenever that would be meaningful. For
a particular research team reporting incremen-
tal progress of a continuing research program,
this hardly seems too much to ask.
For cross-research-group comparisons the
matter is more problematical. How is one to
compare a parser written in Lisp running on an
400 MHz UltraSPARC processor to one written
in C++ running on a 750 MHz Pentium III?
The answer proposed here is to create a set of
reference parser implementations, in a variety
of languages, coupled with reference grammars
and test sets. Obviously, for different classes
of grammar unification grammars, CFGs, and
PCFGs meaningful comparisons remain diffi-
</bodyText>
<page confidence="0.989833">
26
</page>
<bodyText confidence="0.999979652173913">
cult; but for a given class, this approach should
make cross platform comparisons straightfor-
ward. For example, for CFGs, a particular
variant of CKY could be chosen, and imple-
mented as efficiently as possible in C, Lisp, Pro-
log, Perl(!), and any other language considered
relevant. The source code for implementations
would need to be provided, so that the claim
to be the best possible implementation of the
algorithm in the language could be examined,
and improvements made, without changing the
basic algorithm. Then, whenever anyone claims
to have an improved algorithm for CFG parsing,
written in any of the supported languages and
any platform that supports the language, they
could meaningfully measure how much faster
their algorithm is than CKY on the standard
grammars and test sets, by timing their parser
against the reference CKY parser for their plat-
form. Similarly, reference parser implementa-
tions could be created for PCFGs and unifica-
tion grammars to facilitate cross-research-group
studies of parser efficiency for those formalisms.
</bodyText>
<sectionHeader confidence="0.999214" genericHeader="method">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999952366666667">
Charniak and his colleagues have proposed
implementation-independent metrics as a way
of comparing the efficiency of parsing algo-
rithms implemented on different platforms, in
different languages, and with different degrees
of &amp;quot;incidental optimization&amp;quot;. We have tried to
argue that there are easily immaginable circum-
stances in which their proposed metrics would
mask significant differences in efficiency; we
have pointed out that Roark and Charniak&apos;s
data do not, in fact, support the usability of
their metric for comparing the efficiency of dif-
ferent algorithms; and we have analyzed data
for a similar metric (chart size) to try to quan-
tify the degree of variation one might expect
between such metrics and actual parse time.
Finally, we have proposed a methodology for
making cross-platform comparisons through the
use of reference parser implementations. This
methodology does not, unfortunately, address
Roark and Charniak&apos;s desire for a metric that
is insensitive different degrees of incidental op-
timization. Indeed, in our own work compar-
ing different parsing algorithms we have tried
to be scrupulous in comparing implementations
that are as similar as possible in that regard.
In effect, Charniak et al. seem to be seek met-
rics which obviate the need for controled exper-
iments, but in the end, there is no substitute for
them.
</bodyText>
<sectionHeader confidence="0.98146" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.99890505">
Berger, A., S. Della Pietra, and V. Della Pietra
(1996) &amp;quot;A Maximum Entropy Approach to
Natural Language Processing,&amp;quot; Computa-
tional Linguistics, Vol. 22, No. 1, pp. 39-71.
Blaheta, D., and E. Charniak (1999) &amp;quot;Auto-
matic Compensation for Parser Figure-of-
Merit Flaws,&amp;quot; in Proceedings of the 37th An-
nual Meeting of the Association for Compu-
tational Linguistics, College Park, Maryland,
pp. 513-518.
Caraballo, S., and E. Charniak (1998) &amp;quot;New
Figures of Merit for Best-First Probabilistic
Chart Parsing,&amp;quot; Computational Linguistics,
Vol. 24, No. 2, pp. 275-298.
Charniak, E., S. Goldwater, and M. Johnson
(1998) &amp;quot;Edge-Based Best-First Chart Pars-
ing,&amp;quot; in Proceedings of the Sixth Workshop
on Very Large Corpora, Montreal, Canada,
pp. 127-123.
Charniak, E. (2000) &amp;quot;A Maximum-Entropy-
Inspired Parser,&amp;quot; in Proceedings of the 1st
Meeting of the North American Chapter of
the Association for Computational Linguis-
tics, Seattle, Washington, pp. 132-139.
Moore, R., et al. (1997) &amp;quot;CommandTalk:
A Spoken-Language Interface for Battlefield
Simulations,&amp;quot; in Proceedings of the Fifth Con-
ference on Applied Natural Language Process-
ing, Association for Computational Linguis-
tics, Washington, DC, pp. 1-7.
Moore, R. (2000) &amp;quot;Improved Left-Corner
Chart Parsing for Large Context-Free Gram-
mars,&amp;quot; in Proceedings of the Sixth Interna-
tional Workshop on Parsing Technologies,
ACL/SIGPARSE, Trento, Italy, pp. 171-182.
Roark, B., and E. Charniak (2000) &amp;quot;Measuring
Efficiency in High-Accuracy, Broad-Coverage
Statistical Parsing,&amp;quot; in Proceedings of the
COLING 2000 Workshop on Efficiency in
Large-Scale Parsing Systems, Luxembourg.
</reference>
<page confidence="0.998363">
27
</page>
<table confidence="0.9867186">
Confidence Method 1 Method 2
Level
0.99 0.19 0.17
0.95 0.30 0.29
0.90 0.39 0.38
</table>
<tableCaption confidence="0.996887">
Table 2: Edge ratios for different significance levels
</tableCaption>
<sectionHeader confidence="0.992397" genericHeader="references">
Appendix
</sectionHeader>
<bodyText confidence="0.999964195121951">
The statistical analysis mentioned in Section 3
was performed by comparing the millisec-
onds/edge values for all pairs of parsing algo-
rithms, for each grammar and test set. Specifi-
cally, we computed the t statistic for logarithms
of ratios of milliseconds/edge values for sets of
pairs of parsers applied to the same grammar
and test set. We used logarithms of ratios rather
than the ratios themselves, on the grounds that,
a priori we would expect values of n and 1/..n to
be about equally likely for this ratio.
We computed the t statistic in two different
ways. Method 1 was simply to compute the
t statistic for the set of logarithms of ratios
of the milliseconds/edge values for all pairs of
parsing algorithms, for each grammar and test
set. This is not statistically valid, however, be-
cause the values we are computing the t statistic
for are not independent, due to re-use of mil-
liseconds/edge values in different pairwise com-
parisons. Essentially, we have manufactured 30
data points out of an original set of only 15 data
points.
In Method 2, we maintained independence by
randomly selecting pairs of parsers so that each
parser was only counted once, applied to each
grammar and test set. Since this only looks at
a subset of the possible pairwise comparisons,
we repeated this 1000 times, so that each pos-
sible pair would be selected approximately the
same number of times, and averaged the re-
sults. We then used these t statistics to compute
the ratios of edges required to be certain that
the parser producing fewer edges would actually
take less time than the other, at the 0.99, 0.95,
and 0.90 confidence levels, using a single-tailed
test (See Table 2). The two methods did not dif-
fer greatly in their results, except that Method 2
produced slightly greater uncertainty. This may
have been simply due to the smaller number of
data points used in each iteration in Method 2.
</bodyText>
<page confidence="0.998314">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.800928">
<title confidence="0.999576">Time as a Measure of Parsing Efficiency</title>
<author confidence="0.999613">C Robert</author>
<affiliation confidence="0.930229">Microsoft</affiliation>
<address confidence="0.994673">One Microsoft Way Redmond, Washington 98052, USA</address>
<email confidence="0.983214">bobmoore@microsoft.eorn</email>
<abstract confidence="0.993765789473684">Charniak and his colleagues have proposed implementation-independent metrics as a way of comparing the efficiency of parsing algorithms implemented on different platforms, in different languages, and with different degrees of &amp;quot;incidental optimization&amp;quot;. We argue that there are easily immaginable circumstances in which their proposed metrics would mask significant differences in efficiency; we point out that their data do not, in fact, support the usability of such metrics for comparing the efficiency of different algorithms; and we analyze data for a similar metric to try to quantify the degree of variation one might expect between such metrics and actual parse time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing,&amp;quot;</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>39--71</pages>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A., S. Della Pietra, and V. Della Pietra (1996) &amp;quot;A Maximum Entropy Approach to Natural Language Processing,&amp;quot; Computational Linguistics, Vol. 22, No. 1, pp. 39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blaheta</author>
<author>E Charniak</author>
</authors>
<title>Automatic Compensation for Parser Figure-ofMerit Flaws,&amp;quot;</title>
<date>1999</date>
<booktitle>in Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>513--518</pages>
<location>College Park, Maryland,</location>
<contexts>
<context position="1301" citStr="Blaheta and Charniak, 1999" startWordPosition="191" endWordPosition="194"> algorithms; and we analyze data for a similar metric to try to quantify the degree of variation one might expect between such metrics and actual parse time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations. 1 Introduction The title &amp;quot;Time as a Measure of Parsing Efficiency&amp;quot; may seem highly tautologous, since in computer science &amp;quot;efficiency&amp;quot;, unless otherwise qualified, is usually taken to mean speed of execution. However, Charniak and his colleagues (Caraballo and Charniak, 1998; Charniak, Goldwater, and Johnson, 1998; Blaheta and Charniak, 1999) have argued for another metric edges popped off the agenda of a chart parser as being platform independent. Now Roark and Charniak (2000) propose a related measure, &amp;quot;events considered&amp;quot;, that is applicable to a wider range of approaches. The present paper attempts to make the case for going back to time as the primary measure of parsing efficiency. First, we explore some general issues concerning the type of metrics proposed by Charniak and his colleagues. Then we demonstrate using empirical data that implementation-independent measures similar to that proposed by Charniak can vary in how well</context>
<context position="14332" citStr="Blaheta and Charniak, 1999" startWordPosition="2353" endWordPosition="2356">ter than another, it must produce about 80% fewer edges; to be 95% certain, it must produce about 70% fewer edges; and to be 90% certain, it must produce about 60% fewer edges. This analysis undoubtedly suffers from the paucity of the data, and performing a wider range of experiments might well give us tighter bounds, but it at least represents a first cut at quantifying the variation in timeper-edge across different parsing algorithms and grammars. (See the Appendix for information on how the analysis was performed.) If we look at Charniak&apos;s latest paper reporting improved parser efficiency (Blaheta and Charniak, 1999), we find a reported reduction in edges popped off the agenda of about 60%. We do not doubt that this result is in fact a substantial improvement over the previous method it was compared to, but in the context of the variation in time per edge among the parsers presented here, we would be hard pressed to claim this result represents a statistically significant improvement in parsing speed, without seeing parsing times not provided by Blaheta and Charniak. 4 Towards a Cross-Platform Methodology The substantial variation in time per edge among the parsers and grammars discussed here strongly sug</context>
</contexts>
<marker>Blaheta, Charniak, 1999</marker>
<rawString>Blaheta, D., and E. Charniak (1999) &amp;quot;Automatic Compensation for Parser Figure-ofMerit Flaws,&amp;quot; in Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, College Park, Maryland, pp. 513-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Caraballo</author>
<author>E Charniak</author>
</authors>
<title>New Figures of Merit for Best-First Probabilistic Chart Parsing,&amp;quot;</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<pages>275--298</pages>
<contexts>
<context position="1232" citStr="Caraballo and Charniak, 1998" startWordPosition="181" endWordPosition="184">he usability of such metrics for comparing the efficiency of different algorithms; and we analyze data for a similar metric to try to quantify the degree of variation one might expect between such metrics and actual parse time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations. 1 Introduction The title &amp;quot;Time as a Measure of Parsing Efficiency&amp;quot; may seem highly tautologous, since in computer science &amp;quot;efficiency&amp;quot;, unless otherwise qualified, is usually taken to mean speed of execution. However, Charniak and his colleagues (Caraballo and Charniak, 1998; Charniak, Goldwater, and Johnson, 1998; Blaheta and Charniak, 1999) have argued for another metric edges popped off the agenda of a chart parser as being platform independent. Now Roark and Charniak (2000) propose a related measure, &amp;quot;events considered&amp;quot;, that is applicable to a wider range of approaches. The present paper attempts to make the case for going back to time as the primary measure of parsing efficiency. First, we explore some general issues concerning the type of metrics proposed by Charniak and his colleagues. Then we demonstrate using empirical data that implementation-independe</context>
</contexts>
<marker>Caraballo, Charniak, 1998</marker>
<rawString>Caraballo, S., and E. Charniak (1998) &amp;quot;New Figures of Merit for Best-First Probabilistic Chart Parsing,&amp;quot; Computational Linguistics, Vol. 24, No. 2, pp. 275-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>S Goldwater</author>
<author>M Johnson</author>
</authors>
<title>Edge-Based Best-First Chart Parsing,&amp;quot;</title>
<date>1998</date>
<booktitle>in Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>127--123</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="1272" citStr="Charniak, Goldwater, and Johnson, 1998" startWordPosition="185" endWordPosition="190">or comparing the efficiency of different algorithms; and we analyze data for a similar metric to try to quantify the degree of variation one might expect between such metrics and actual parse time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations. 1 Introduction The title &amp;quot;Time as a Measure of Parsing Efficiency&amp;quot; may seem highly tautologous, since in computer science &amp;quot;efficiency&amp;quot;, unless otherwise qualified, is usually taken to mean speed of execution. However, Charniak and his colleagues (Caraballo and Charniak, 1998; Charniak, Goldwater, and Johnson, 1998; Blaheta and Charniak, 1999) have argued for another metric edges popped off the agenda of a chart parser as being platform independent. Now Roark and Charniak (2000) propose a related measure, &amp;quot;events considered&amp;quot;, that is applicable to a wider range of approaches. The present paper attempts to make the case for going back to time as the primary measure of parsing efficiency. First, we explore some general issues concerning the type of metrics proposed by Charniak and his colleagues. Then we demonstrate using empirical data that implementation-independent measures similar to that proposed by </context>
</contexts>
<marker>Charniak, Goldwater, Johnson, 1998</marker>
<rawString>Charniak, E., S. Goldwater, and M. Johnson (1998) &amp;quot;Edge-Based Best-First Chart Parsing,&amp;quot; in Proceedings of the Sixth Workshop on Very Large Corpora, Montreal, Canada, pp. 127-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A Maximum-EntropyInspired Parser,&amp;quot;</title>
<date>2000</date>
<booktitle>in Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>132--139</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="1439" citStr="Charniak (2000)" startWordPosition="216" endWordPosition="217">e time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations. 1 Introduction The title &amp;quot;Time as a Measure of Parsing Efficiency&amp;quot; may seem highly tautologous, since in computer science &amp;quot;efficiency&amp;quot;, unless otherwise qualified, is usually taken to mean speed of execution. However, Charniak and his colleagues (Caraballo and Charniak, 1998; Charniak, Goldwater, and Johnson, 1998; Blaheta and Charniak, 1999) have argued for another metric edges popped off the agenda of a chart parser as being platform independent. Now Roark and Charniak (2000) propose a related measure, &amp;quot;events considered&amp;quot;, that is applicable to a wider range of approaches. The present paper attempts to make the case for going back to time as the primary measure of parsing efficiency. First, we explore some general issues concerning the type of metrics proposed by Charniak and his colleagues. Then we demonstrate using empirical data that implementation-independent measures similar to that proposed by Charniak can vary in how well they correlate to execution time by as much or more than the improvements reported by Charniak et al. in some of their experiments. Final</context>
<context position="5545" citStr="Charniak (2000)" startWordPosition="896" endWordPosition="897">ecause it considered no more events than Roark&apos;s and Charniak&apos;s parsers. Another way that the events-considered metric might fail to correlate with parse time concerns the figure of merit used to prune he search. The efficacy of pruning is perhaps the most important determinant of parsing efficiency in the types of parsers considered by Roark and Charniak. The better the figure of merit is as a predictor of the probability assigned by the full model to the best extension of a partial analysis, the smaller the number of partial analyses that need to be extended to find the best full &apos;Note that Charniak (2000) has also explored unnormalized exponential models, which are fast to compute. analysis. It is easy to imagine, however, that some &amp;quot;better&amp;quot; figure of merit might take more time to compute than it repays in reducing the search space. Suppose a there is a sophisticated figure of merit that allows reducing the number of events considered by half over a cruder figure of merit, but it takes so long to compute that it increases the amount of time per event considered by a factor of ten. The events-considered metric will rate the sophisticated figure of merit as twice as good, even though in reality </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Charniak, E. (2000) &amp;quot;A Maximum-EntropyInspired Parser,&amp;quot; in Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics, Seattle, Washington, pp. 132-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
</authors>
<title>CommandTalk: A Spoken-Language Interface for Battlefield Simulations,&amp;quot;</title>
<date>1997</date>
<booktitle>in Proceedings of the Fifth Conference on Applied Natural Language Processing, Association for Computational Linguistics,</booktitle>
<pages>1--7</pages>
<location>Washington, DC,</location>
<marker>Moore, 1997</marker>
<rawString>Moore, R., et al. (1997) &amp;quot;CommandTalk: A Spoken-Language Interface for Battlefield Simulations,&amp;quot; in Proceedings of the Fifth Conference on Applied Natural Language Processing, Association for Computational Linguistics, Washington, DC, pp. 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
</authors>
<title>Improved Left-Corner Chart Parsing for Large Context-Free Grammars,&amp;quot;</title>
<date>2000</date>
<booktitle>in Proceedings of the Sixth International Workshop on Parsing Technologies, ACL/SIGPARSE,</booktitle>
<pages>171--182</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="7276" citStr="Moore, 2000" startWordPosition="1186" endWordPosition="1187">ence to the contrary, since they present graphs of impressively linear relationships between events considered and time. These linear relationships, however, are demonstrated only with respect to one parser at a time, where the only thing that is varied is the degree of pruning Thus, although Roark and Charniak argue for events-considered metric as a way of comparing very different parsing algorithms, they demonstrate only that it correlates well with efficiency for essentially identical algorithms, where only a single parameter is varied. We have recently carried out a series of experiments (Moore, 2000) comparing the efficiency of several variants of left-corner parsing with a number of other well-known context-free parsing algorithms In contrast to the studies of Charniak et al., these experiments looked at non-stochastic algorithms, and the comparisons are made on the basis of exhaustive, rather than heuristically-pruned, parsing. Thus we cannot directly apply either Roark and Charniak&apos;s events-considered metric, or the earlier edges-popped-of-the-agenda metric, to our results. However, the total number of edges in the chart, which we do have data on, is a very similar sort of implementati</context>
</contexts>
<marker>Moore, 2000</marker>
<rawString>Moore, R. (2000) &amp;quot;Improved Left-Corner Chart Parsing for Large Context-Free Grammars,&amp;quot; in Proceedings of the Sixth International Workshop on Parsing Technologies, ACL/SIGPARSE, Trento, Italy, pp. 171-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>E Charniak</author>
</authors>
<title>Measuring Efficiency in High-Accuracy, Broad-Coverage Statistical Parsing,&amp;quot;</title>
<date>2000</date>
<booktitle>in Proceedings of the COLING 2000 Workshop on Efficiency in Large-Scale Parsing Systems,</booktitle>
<location>Luxembourg.</location>
<contexts>
<context position="1439" citStr="Roark and Charniak (2000)" startWordPosition="214" endWordPosition="217">ctual parse time. Finally, we propose a methodology for making cross-platform comparisons through the use of reference parser implementations. 1 Introduction The title &amp;quot;Time as a Measure of Parsing Efficiency&amp;quot; may seem highly tautologous, since in computer science &amp;quot;efficiency&amp;quot;, unless otherwise qualified, is usually taken to mean speed of execution. However, Charniak and his colleagues (Caraballo and Charniak, 1998; Charniak, Goldwater, and Johnson, 1998; Blaheta and Charniak, 1999) have argued for another metric edges popped off the agenda of a chart parser as being platform independent. Now Roark and Charniak (2000) propose a related measure, &amp;quot;events considered&amp;quot;, that is applicable to a wider range of approaches. The present paper attempts to make the case for going back to time as the primary measure of parsing efficiency. First, we explore some general issues concerning the type of metrics proposed by Charniak and his colleagues. Then we demonstrate using empirical data that implementation-independent measures similar to that proposed by Charniak can vary in how well they correlate to execution time by as much or more than the improvements reported by Charniak et al. in some of their experiments. Final</context>
</contexts>
<marker>Roark, Charniak, 2000</marker>
<rawString>Roark, B., and E. Charniak (2000) &amp;quot;Measuring Efficiency in High-Accuracy, Broad-Coverage Statistical Parsing,&amp;quot; in Proceedings of the COLING 2000 Workshop on Efficiency in Large-Scale Parsing Systems, Luxembourg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>