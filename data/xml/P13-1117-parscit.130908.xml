<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012498">
<title confidence="0.946062">
Cross-lingual Transfer of Semantic Role Labeling Models
</title>
<author confidence="0.889818">
Mikhail Kozhevnikov and Ivan Titov
</author>
<affiliation confidence="0.855992">
Saarland University, Postfach 15 11 50
</affiliation>
<address confidence="0.73038">
66041 Saarbr¨ucken, Germany
</address>
<email confidence="0.99845">
{mkozhevn|titov}@mmci.uni-saarland.de
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999686294117647">
Semantic Role Labeling (SRL) has be-
come one of the standard tasks of natural
language processing and proven useful as
a source of information for a number of
other applications. We address the prob-
lem of transferring an SRL model from
one language to another using a shared
feature representation. This approach is
then evaluated on three language pairs,
demonstrating competitive performance as
compared to a state-of-the-art unsuper-
vised SRL system and a cross-lingual an-
notation projection baseline. We also con-
sider the contribution of different aspects
of the feature representation to the perfor-
mance of the model and discuss practical
applicability of this method.
</bodyText>
<sectionHeader confidence="0.958349" genericHeader="keywords">
1 Background and Motivation
</sectionHeader>
<bodyText confidence="0.999564696428572">
Semantic role labeling has proven useful in many
natural language processing tasks, such as ques-
tion answering (Shen and Lapata, 2007; Kaisser
and Webber, 2007), textual entailment (Sammons
et al., 2009), machine translation (Wu and Fung,
2009; Liu and Gildea, 2010; Gao and Vogel, 2011)
and dialogue systems (Basili et al., 2009; van der
Plas et al., 2009).
Multiple models have been designed to auto-
matically predict semantic roles, and a consider-
able amount of data has been annotated to train
these models, if only for a few more popular lan-
guages. As the annotation is costly, one would like
to leverage existing resources to minimize the hu-
man effort required to construct a model for a new
language.
A number of approaches to the construction of
semantic role labeling models for new languages
have been proposed. On one end of the scale is
unsupervised SRL, such as Grenager and Manning
(2006), which requires some expert knowledge,
but no labeled data. It clusters together arguments
that should bear the same semantic role, but does
not assign a particular role to each cluster. On the
other end is annotating a new dataset from scratch.
There are also intermediate options, which often
make use of similarities between languages. This
way, if an accurate model exists for one language,
it should help simplify the construction of a model
for another, related language.
The approaches in this third group often use par-
allel data to bridge the gap between languages.
Cross-lingual annotation projection systems (Pad´o
and Lapata, 2009), for example, propagate infor-
mation directly via word alignment links. How-
ever, they are very sensitive to the quality of par-
allel data, as well as the accuracy of a source-
language model on it.
An alternative approach, known as cross-lingual
model transfer, or cross-lingual model adaptation,
consists of modifying a source-language model to
make it directly applicable to a new language. This
usually involves constructing a shared feature rep-
resentation across the two languages. McDon-
ald et al. (2011) successfully apply this idea to
the transfer of dependency parsers, using part-of-
speech tags as the shared representation of words.
A later extension of T¨ackstr¨om et al. (2012) en-
riches this representation with cross-lingual word
clusters, considerably improving the performance.
In the case of SRL, a shared representation that
is purely syntactic is likely to be insufficient, since
structures with different semantics may be realized
by the same syntactic construct, for example “in
August” vs “in Britain”. However with the help of
recently introduced cross-lingual word represen-
</bodyText>
<page confidence="0.928752">
1190
</page>
<note confidence="0.913169">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1190–1200,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999859740740741">
tations, such as the cross-lingual clustering men-
tioned above or cross-lingual distributed word rep-
resentations of Klementiev et al. (2012), we may
be able to transfer models of shallow semantics in
a similar fashion.
In this work we construct a shared feature repre-
sentation for a pair of languages, employing cross-
lingual representations of syntactic and lexical in-
formation, train a semantic role labeling model on
one language and apply it to the other one. This
approach yields an SRL model for a new language
at a very low cost, effectively requiring only a
source language model and parallel data.
We evaluate on five (directed) language pairs –
EN-ZH, ZH-EN, EN-CZ, CZ-EN and EN-FR, where
EN, FR, CZ and ZH denote English, French, Czech
and Chinese, respectively. The transferred model
is compared against two baselines: an unsuper-
vised SRL system and a model trained on the out-
put of a cross-lingual annotation projection sys-
tem.
In the next section we will describe our setup,
then in section 3 present the shared feature repre-
sentation we use, discuss the evaluation data and
other technical aspects in section 4, present the
results and conclude with an overview of related
work.
</bodyText>
<sectionHeader confidence="0.997341" genericHeader="introduction">
2 Setup
</sectionHeader>
<bodyText confidence="0.999891">
The purpose of the study is not to develop a yet
another semantic role labeling system – any exist-
ing SRL system can (after some modification) be
used in this setup – but to assess the practical ap-
plicability of cross-lingual model transfer to this
problem, compare it against the alternatives and
identify its strong/weak points depending on a par-
ticular setup.
</bodyText>
<subsectionHeader confidence="0.984938">
2.1 Semantic Role Labeling Model
</subsectionHeader>
<bodyText confidence="0.998392037037037">
We consider the dependency-based version of se-
mantic role labeling as described in Hajiˇc et al.
(2009) and transfer an SRL model from one lan-
guage to another. We only consider verbal pred-
icates and ignore the predicate disambiguation
stage. We also assume that the predicate identifi-
cation information is available – in most languages
it can be obtained using a relatively simple heuris-
tic based on part-of-speech tags.
The model performs argument identification
and classification (Johansson and Nugues, 2008)
separately in a pipeline – first each candidate is
classified as being or not being a head of an argu-
ment phrase with respect to the predicate in ques-
tion and then each of the arguments is assigned a
role from a given inventory. The model is factor-
ized over arguments – the decisions regarding the
classification of different arguments are made in-
dependently of each other.
With respect to the use of syntactic annotation
we consider two options: using an existing depen-
dency parser for the target language and obtaining
one by means of cross-lingual transfer (see sec-
tion 4.2).
Following McDonald et al. (2011), we assume
that a part-of-speech tagger is available for the tar-
get language.
</bodyText>
<subsectionHeader confidence="0.980755">
2.2 SRL in the Low-resource Setting
</subsectionHeader>
<bodyText confidence="0.99996908">
Several approaches have been proposed to obtain
an SRL model for a new language with little or
no manual annotation. Unsupervised SRL mod-
els (Lang and Lapata, 2010) cluster the arguments
of predicates in a given corpus according to their
semantic roles. The performance of such models
can be impressive, especially for those languages
where semantic roles correlate strongly with syn-
tactic relation of the argument to its predicate.
However, assigning meaningful role labels to the
resulting clusters requires additional effort and the
model’s parameters generally need some adjust-
ment for every language.
If the necessary resources are already available
for a closely related language, they can be uti-
lized to facilitate the construction of a model for
the target language. This can be achieved ei-
ther by means of cross-lingual annotation projec-
tion (Yarowsky et al., 2001) or by cross-lingual
model transfer (Zeman and Resnik, 2008).
This last approach is the one we are considering
in this work, and the other two options are treated
as baselines. The unsupervised model will be fur-
ther referred to as UNSUP and the projection base-
line as PROJ.
</bodyText>
<subsectionHeader confidence="0.996236">
2.3 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.9999785">
We use the F1 measure as a metric for the argu-
ment identification stage and accuracy as an ag-
gregate measure of argument classification perfor-
mance. When comparing to the unsupervised SRL
system the clustering evaluation measures are used
instead. These are purity and collocation
</bodyText>
<page confidence="0.745072">
1191
</page>
<equation confidence="0.991405166666667">
1 �
P U = N
i
1 �
CO = N
j
</equation>
<bodyText confidence="0.999934833333333">
where Ci is the set of arguments in the i-th induced
cluster, Gj is the set of arguments in the jth gold
cluster and N is the total number of arguments.
We report the harmonic mean of the two (Lang and
Lapata, 2011) and denote it F1c to avoid confusing
it with the supervised metric.
</bodyText>
<sectionHeader confidence="0.860707" genericHeader="method">
3 Model Transfer
</sectionHeader>
<bodyText confidence="0.999899111111111">
The idea of this work is to abstract the model away
from the particular source language and apply it
to a new one. This setup requires that we use the
same feature representation for both languages, for
example part-of-speech tags and dependency rela-
tion labels should be from the same inventory.
Some features are not applicable to certain lan-
guages because the corresponding phenomena are
absent in them. For example, consider a strongly
inflected language and an analytic one. While the
latter can usually convey the information encoded
in the word form in the former one (number, gen-
der, etc.), finding a shared feature representation
for such information is non-trivial. In this study
we will confine ourselves to those features that are
applicable to all languages in question, namely:
part-of-speech tags, syntactic dependency struc-
tures and representations of the word’s identity.
</bodyText>
<subsectionHeader confidence="0.997871">
3.1 Lexical Information
</subsectionHeader>
<bodyText confidence="0.999883892857143">
We train a model on one language and apply it to a
different one. In order for this to work, the words
of the two languages have to be mapped into a
common feature space. It is also desirable that
closely related words from both languages have
similar representations in this space.
Word mapping. The first option is simply to use
the source language words as the shared represen-
tation. Here every source language word would
have itself as its representation and every target
word would map into a source word that corre-
sponds to it. In other words, we supply the model
with a gloss of the target sentence.
The mapping (bilingual dictionary) we use is
derived from a word-aligned parallel corpus, by
identifying, for each word in the target language,
the word in the source language it is most often
aligned to.
Cross-lingual clusters. There is no guarantee
that each of the words in the evaluation data is
present in our dictionary, nor that the correspond-
ing source-language word is present in the training
data, so the model would benefit from the ability
to generalize over closely related words. This can,
for example, be achieved by using cross-lingual
word clusters induced in T¨ackstr¨om et al. (2012).
We incorporate these clusters as features into our
model.
</bodyText>
<subsectionHeader confidence="0.99886">
3.2 Syntactic Information
</subsectionHeader>
<bodyText confidence="0.999865324324324">
Part-of-speech Tags. We map part-of-speech tags
into the universal tagset following Petrov et al.
(2012). This may have a negative effect on the
performance of a monolingual model, since most
part-of-speech tagsets are more fine-grained than
the universal POS tags considered here. For exam-
ple Penn Treebank inventory contains 36 tags and
the universal POS tagset – only 12. Since the finer-
grained POS tags often reflect more language-
specific phenomena, however, they would only be
useful for very closely related languages in the
cross-lingual setting.
The universal part-of-speech tags used in eval-
uation are derived from gold-standard annotation
for all languages except French, where predicted
ones had to be used instead.
Dependency Structure. Another important aspect
of syntactic information is the dependency struc-
ture. Most dependency relation inventories are
language-specific, and finding a shared representa-
tion for them is a challenging problem. One could
map dependency relations into a simplified form
that would be shared between languages, as it is
done for part-of-speech tags in Petrov et al. (2012).
The extent to which this would be useful, however,
depends on the similarity of syntactic-semantic in-
terfaces of the languages in question.
In this work we discard the dependency rela-
tion labels where the inventories do not match and
only consider the unlabeled syntactic dependency
graph. Some discrepancies, such as variations in
attachment order, may be present even there, but
this does not appear to be the case with the datasets
we use for evaluation. If a target language is poor
in resources, one can obtain a dependency parser
for the target language by means of cross-lingual
model transfer (Zeman and Resnik, 2008). We
</bodyText>
<figure confidence="0.939049">
max |Gj ∩ Ci|
j
max |Gj ∩ Ci|,
i
</figure>
<page confidence="0.985403">
1192
</page>
<bodyText confidence="0.998202666666667">
take this into account and evaluate both using the
original dependency structures and the ones ob-
tained by means of cross-lingual model transfer.
</bodyText>
<subsectionHeader confidence="0.99396">
3.3 The Model
</subsectionHeader>
<bodyText confidence="0.999991043478261">
The model we use is based on that of Bj¨orkelund
et al. (2009). It is comprised of a set of linear clas-
sifiers trained using Liblinear (Fan et al., 2008).
The feature model was modified to accommodate
the cross-lingual cluster features and the reranker
component was not used.
We do not model the interaction between differ-
ent argument roles in the same predicate. While
this has been found useful, in the cross-lingual
setup one has to be careful with the assumptions
made. For example, modeling the sequence of
roles using a Markov chain (Thompson et al.,
2003) may not work well in the present setting,
especially between distant languages, as the order
or arguments is not necessarily preserved. Most
constraints that prove useful for SRL (Chang et
al., 2007) also require customization when applied
to a new language, and some rely on language-
specific resources, such as a valency lexicon. Tak-
ing into account the interaction between different
arguments of a predicate is likely to improve the
performance of the transferred model, but this is
outside the scope of this work.
</bodyText>
<subsectionHeader confidence="0.992401">
3.4 Feature Selection
</subsectionHeader>
<bodyText confidence="0.999937">
Compatibility of feature representations is neces-
sary but not sufficient for successful model trans-
fer. We have to make sure that the features we use
are predictive of similar outcomes in the two lan-
guages as well.
Depending on the pair of languages in ques-
tion, different aspects of the feature representation
will retain or lose their predictive power. We can
be reasonably certain that the identity of an ar-
gument word is predictive of its semantic role in
any language, but it might or might not be true
of, for example, the word directly preceding the
argument word. It is therefore important to pre-
</bodyText>
<table confidence="0.9695504">
POS part-of-speech tags
Synt unlabeled dependency graph
Cls cross-lingual word clusters
Gloss glossed word forms
Deprel dependency relations
</table>
<tableCaption confidence="0.999717">
Table 1: Feature groups.
</tableCaption>
<bodyText confidence="0.999947">
vent the model from capturing overly specific as-
pects of the source language, which we do by con-
fining the model to first-order features. We also
avoid feature selection, which, performed on the
source language, is unlikely to help the model to
better generalize to the target one. The experi-
ments confirm that feature selection and the use
of second-order features degrade the performance
of the transferred model.
</bodyText>
<subsectionHeader confidence="0.989721">
3.5 Feature Groups
</subsectionHeader>
<bodyText confidence="0.9993485">
For each word, we use its part-of-speech tag,
cross-lingual cluster id, word identity (glossed,
when evaluating on the target language) and its
dependency relation to its parent. Features associ-
ated with an argument word include the attributes
of the predicate word, the argument word, its par-
ent, siblings and children, and the words directly
preceding and following it. Also included are the
sequences of part-of-speech tags and dependency
relations on the path between the predicate and the
argument.
Since we are also interested in the impact of dif-
ferent aspects of the feature representation, we di-
vide the features into groups as summarized in ta-
ble 1 and evaluate their respective contributions to
the performance of the model. If a feature group
is enabled – the model has access to the corre-
sponding source of information. For example, if
only POS group is enabled, the model relies on
the part-of-speech tags of the argument, the pred-
icate and the words to the right and left of the ar-
gument word. If Synt is enabled too, it also uses
the POS tags of the argument’s parent, children
and siblings.
Word order information constitutes an implicit
group that is always available. It includes the
Position feature, which indicates whether the
argument is located to the left or to the right of
the predicate, and allows the model to look up the
attributes of the words directly preceding and fol-
lowing the argument word. The model we com-
pare against the baselines uses all applicable fea-
ture groups (Deprel is only used in EN-CZ and
CZ-EN experiments with original syntax).
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="method">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999506">
4.1 Datasets and Preprocessing
</subsectionHeader>
<bodyText confidence="0.999499666666667">
Evaluation of the cross-lingual model transfer re-
quires a rather specific kind of dataset. Namely,
the data in both languages has to be annotated
</bodyText>
<page confidence="0.933612">
1193
</page>
<bodyText confidence="0.993921089285714">
with the same set of semantic roles following the
same (or compatible) guidelines, which is seldom
the case. We have identified three language pairs
for which such resources are available: English-
Chinese, English-Czech and English-French.
The evaluation datasets for English and Chi-
nese are those from the CoNLL Shared Task
2009 (Hajiˇc et al., 2009) (henceforth CoNLL-ST).
Their annotation in the CoNLL-ST is not identi-
cal, but the guidelines for “core” semantic roles
are similar (Kingsbury et al., 2004), so we eval-
uate only on core roles here. The data for the
second language pair is drawn from the Prague
Czech-English Dependency Treebank 2.0 (Hajiˇc
et al., 2012), which we converted to a format simi-
lar to that of CoNLL-ST1. The original annotation
uses the tectogrammatical representation (Hajiˇc,
2002) and an inventory of semantic roles (or func-
tors), most of which are interpretable across vari-
ous predicates. Also note that the syntactic anno-
tation of English and Czech in PCEDT 2.0 is quite
similar (to the extent permitted by the difference
in the structure of the two languages) and we can
use the dependency relations in our experiments.
For English-French, the English CoNLL-ST
dataset was used as a source and the model was
evaluated on the manually annotated dataset from
van der Plas et al. (2011). The latter contains one
thousand sentences from the French part of the Eu-
roparl (Koehn, 2005) corpus, annotated with se-
mantic roles following an adapted version of Prop-
Bank (Palmer et al., 2005) guidelines. The au-
thors perform annotation projection from English
to French, using a joint model of syntax and se-
mantics and employing heuristics for filtering. We
use a model trained on the output of this projec-
tion system as one of the baselines. The evalua-
tion dataset is relatively small in this case, so we
perform the transfer only one-way, from English
to French.
The part-of-speech tags in all datasets were re-
placed with the universal POS tags of Petrov et al.
(2012). For Czech, we have augmented the map-
pings to account for the tags that were not present
in the datasets from which the original mappings
were derived. Namely, tag “t” is mapped to
“VERB” and “Y” – to “PRON”.
We use parallel data to construct a bilingual
dictionary used in word mapping, as well as
in the projection baseline. For English-Czech
see http://www.ml4nlp.de/code-and-data/treex2conll
and English-French, the data is drawn from Eu-
roparl (Koehn, 2005), for English-Chinese – from
MultiUN (Eisele and Chen, 2010). The word
alignments were obtained using GIZA++ (Och
and Ney, 2003) and the intersection heuristic.
</bodyText>
<subsectionHeader confidence="0.996822">
4.2 Syntactic Transfer
</subsectionHeader>
<bodyText confidence="0.99997988">
In the low-resource setting, we cannot always
rely on the availability of an accurate dependency
parser for the target language. If one is not avail-
able, the natural solution would be to use cross-
lingual model transfer to obtain it.
Unfortunately, the models presented in the pre-
vious work, such as Zeman and Resnik (2008),
McDonald et al. (2011) and T¨ackstr¨om et al.
(2012), were not made available, so we repro-
duced the direct transfer algorithm of McDonald
et al. (2011), using Malt parser (Nivre, 2008) and
the same set of features. We did not reimple-
ment the projected transfer algorithm, however,
and used the default training procedure instead of
perceptron-based learning. The dependency struc-
ture thus obtained is, of course, only a rough ap-
proximation – even a much more sophisticated al-
gorithm may not perform well when transferring
syntax between such languages as Czech and En-
glish, given the inherent difference in their struc-
ture. The scores are shown in table 2.
We will henceforth refer to the syntactic annota-
tions that were provided with the datasets as orig-
inal, as opposed to the annotations obtained by
means of syntactic transfer.
</bodyText>
<subsectionHeader confidence="0.975383">
4.3 Baselines
</subsectionHeader>
<bodyText confidence="0.644564">
Unsupervised Baseline: We are using a version
of the unsupervised semantic role induction sys-
tem of Titov and Klementiev (2012a) adapted to
</bodyText>
<table confidence="0.999744">
Setup UAS, %
EN-ZH 35
ZH-EN 42
EN-CZ 36
CZ-EN 39
EN-FR 67
</table>
<tableCaption confidence="0.827284333333333">
Table 2: Syntactic transfer accuracy, unlabeled at-
tachment score (percent). Note that in case of
French we evaluate against the output of a super-
vised system, since manual annotation is not avail-
able for this dataset. This score does not reflect the
true performance of syntactic transfer.
</tableCaption>
<page confidence="0.989577">
1194
</page>
<bodyText confidence="0.999762476190476">
the shared feature representation considered in or-
der to make the scores comparable with those
of the transfer model and, more importantly, to
enable evaluation on transferred syntax. Note
that the original system, tailored to a more ex-
pressive language-specific syntactic representa-
tion and equipped with heuristics to identify ac-
tive/passive voice and other phenomena, achieves
higher scores than those we report here.
Projection Baseline: The projection baseline we
use for English-Czech and English-Chinese is a
straightforward one: we label the source side of a
parallel corpus using the source-language model,
then identify those verbs on the target side that are
aligned to a predicate, mark them as predicates and
propagate the argument roles in the same fashion.
A model is then trained on the resulting training
data and applied to the test set.
For English-French we instead use the output of
a fully featured projection model of van der Plas et
al. (2011), published in the CLASSiC project.
</bodyText>
<sectionHeader confidence="0.999967" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999992">
In order to ensure that the results are consistent,
the test sets, except for the French one, were par-
titioned into five equal parts (of 5 to 10 thousand
sentences each, depending on the dataset) and the
evaluation performed separately on each one. All
evaluation figures for English, Czech or Chinese
below are the average values over the five sub-
sets. In case of French, the evaluation dataset is
too small to split it further, so instead we ran the
evaluation five times on a randomly selected 80%
sample of the evaluation data and averaged over
those. In both cases the results are consistent over
the subsets, the standard deviation does not exceed
0.5% for the transfer system and projection base-
line and 1% for the unsupervised system.
</bodyText>
<subsectionHeader confidence="0.994154">
5.1 Argument Identification
</subsectionHeader>
<bodyText confidence="0.998253363636364">
We summarize the results in table 3. Argument
identification is known to rely heavily on syntac-
tic information, so it is unsurprising that it proves
inaccurate when transferred syntax is used. Our
simple projection baseline suffers from the same
problem. Even with original syntactic information
available, the performance of argument identifica-
tion is moderate. Note that the model of (van der
Plas et al., 2011), though relying on more expres-
sive syntax, only outperforms the transferred sys-
tem by 3% (Fl) on this task.
</bodyText>
<table confidence="0.999926">
Setup Syntax TRANS PROJ
EN-ZH trans 34.5 13.9
ZH-EN trans 32.6 15.6
EN-CZ trans 46.3 12.4
CZ-EN trans 42.3 22.2
EN-FR trans 61.6 43.5
EN-ZH orig 51.7 19.6
ZH-EN orig 53.2 29.7
EN-CZ orig 63.9 59.3
CZ-EN orig 67.3 60.9
EN-FR orig 71.0 51.3
</table>
<tableCaption confidence="0.991994">
Table 3: Argument identification, transferred
model vs. projection baseline, Fl.
</tableCaption>
<bodyText confidence="0.996605285714286">
Most unsupervised SRL approaches assume
that the argument identification is performed
by some external means, for example heuristi-
cally (Lang and Lapata, 2011). Such heuristics
or unsupervised approaches to argument identifi-
cation (Abend et al., 2009) can also be used in the
present setup.
</bodyText>
<subsectionHeader confidence="0.998697">
5.2 Argument Classification
</subsectionHeader>
<bodyText confidence="0.9999898">
In the following tables, TRANS column contains
the results for the transferred system, UNSUP –
for the unsupervised baseline and PROJ – for pro-
jection baseline. We highlight in bold the higher
score where the difference exceeds twice the max-
imum of the standard deviation estimates of the
two results.
Table 4 presents the unsupervised evaluation re-
sults. Note that the unsupervised model performs
as well as the transferred one or better where the
</bodyText>
<table confidence="0.999512727272727">
Setup Syntax TRANS UNSUP
EN-ZH trans 83.3 73.9
ZH-EN trans 79.2 67.6
EN-CZ trans 66.4 66.1
CZ-EN trans 68.2 68.7
EN-FR trans 74.6 65.1
EN-ZH orig 84.5 89.7
ZH-EN orig 79.2 83.0
EN-CZ orig 74.1 74.0
CZ-EN orig 74.6 76.7
EN-FR orig 73.3 72.3
</table>
<tableCaption confidence="0.992518333333333">
Table 4: Argument classification, transferred
model vs. unsupervised baseline in terms of the
clustering metric F1 (see section 2.3).
</tableCaption>
<page confidence="0.803784">
1195
</page>
<table confidence="0.999947272727273">
Setup Syntax TRANS PROJ
EN-ZH trans 70.1 69.2
ZH-EN trans 65.6 61.3
EN-CZ trans 50.1 46.3
CZ-EN trans 53.3 54.7
EN-FR trans 65.1 66.1
EN-ZH orig 71.7 69.7
ZH-EN orig 66.1 64.4
EN-CZ orig 59.0 53.2
CZ-EN orig 61.0 60.8
EN-FR orig 63.0 68.0
</table>
<tableCaption confidence="0.9902265">
Table 5: Argument classification, transferred
model vs. projection baseline, accuracy.
</tableCaption>
<bodyText confidence="0.997478166666667">
original syntactic dependencies are available. In
the more realistic scenario with transferred syn-
tax, however, the transferred model proves more
accurate.
In table 5 we compare the transferred system
with the projection baseline. It is easy to see
that the scores vary strongly depending on the lan-
guage pair, due to both the difference in the anno-
tation scheme used and the degree of relatedness
between the languages. The drop in performance
when transferring the model to another language
is large in every case, though, see table 6.
</bodyText>
<table confidence="0.998717166666667">
Setup Target Source
EN-ZH 71.7 87.1
ZH-EN 66.1 86.2
EN-CZ 59.0 80.1
CZ-EN 61.0 75.4
EN-FR 63.0 82.5
</table>
<tableCaption confidence="0.951753">
Table 6: Model accuracy on the source and target
</tableCaption>
<bodyText confidence="0.990428384615385">
language using original syntax. The source lan-
guage scores for English vary between language
pairs because of the difference in syntactic anno-
tation and role subset used.
We also include the individual F1 scores for
the top-10 most frequent labels for EN-CZ trans-
fer with original syntax in table 7. The model
provides meaningful predictions here, despite low
overall accuracy.
Most of the labels2 are self-explanatory: Pa-
tient (PAT), Actor (ACT), Time (TWHEN), Effect
(EFF), Location (LOC), Manner (MANN), Ad-
dressee (ADDR), Extent (EXT). CPHR marks the
</bodyText>
<footnote confidence="0.923663">
2http://ufal.mff.cuni.cz/∼toman/pcedt/en/functors.html
</footnote>
<table confidence="0.999431363636364">
Label Freq. F1 Re. Pr.
PAT 14707 69.4 70.0 68.7
ACT 14303 81.1 81.7 80.4
TWHEN 3631 70.6 65.1 77.0
EFF 2601 45.4 67.2 34.3
LOC 1990 41.8 35.3 51.3
MANN 1208 54.0 63.8 46.9
ADDR 1045 30.2 34.4 26.8
CPHR 791 20.4 13.1 45.0
EXT 708 42.2 40.5 44.1
DIR3 695 20.1 17.3 23.9
</table>
<tableCaption confidence="0.99228">
Table 7: EN-CZ transfer (with original syntax), F1,
</tableCaption>
<bodyText confidence="0.9165875">
recall and precision for the top-10 most frequent
roles.
nominal part of a complex predicate, as in “to have
[a plan]CPHR”, and DIR3 indicates destination.
</bodyText>
<subsectionHeader confidence="0.996766">
5.3 Additional Experiments
</subsectionHeader>
<bodyText confidence="0.99901225">
We now evaluate the contribution of different as-
pects of the feature representation to the perfor-
mance of the model. Table 8 contains the results
for English-French.
</bodyText>
<table confidence="0.996089444444444">
Features Orig Trans
POS 47.5 47.5
POS, Synt 53.0 53.1
POS, Cls 53.7 53.7
POS, Gloss 63.7 63.7
POS, Synt, Cls 55.9 56.4
POS, Synt, Gloss 65.2 66.3
POS, Cls, Gloss 61.5 61.5
POS, Synt, Cls, Gloss 63.0 65.1
</table>
<tableCaption confidence="0.991659">
Table 8: EN-FR model transfer accuracy with dif-
</tableCaption>
<bodyText confidence="0.952538066666667">
ferent feature subsets, using original and trans-
ferred syntactic information.
The fact that the model performs slightly bet-
ter with transferred syntax may be explained by
two factors. Firstly, as we already mentioned, the
original syntactic annotation is also produced au-
tomatically. Secondly, in the model transfer setup
it is more important how closely the syntactic-
semantic interface on the target side resembles that
on the source side than how well it matches the
“true” structure of the target language, and in this
respect a transferred dependency parser may have
an advantage over one trained on target-language
data.
The high impact of the Gloss features here
</bodyText>
<page confidence="0.985247">
1196
</page>
<bodyText confidence="0.999945230769231">
may be partly attributed to the fact that the map-
ping is derived from the same corpus as the eval-
uation data – Europarl (Koehn, 2005) – and partly
by the similarity between English and French in
terms of word order, usage of articles and prepo-
sitions. The moderate contribution of the cross-
lingual cluster features are likely due to the insuf-
ficient granularity of the clustering for this task.
For more distant language pairs, the contribu-
tions of individual feature groups are less inter-
pretable, so we only highlight a few observations.
First of all, both EN-CZ and CZ-EN benefit notice-
ably from the use of the original syntactic annota-
tion, including dependency relations, but not from
the transferred syntax, most likely due to the low
syntactic transfer performance. Both perform bet-
ter when lexical information is available, although
the improvement is not as significant as in the case
of French – only up to 5%.
The situation with Chinese is somewhat compli-
cated in that adding lexical information here fails
to yield an improvement in terms of the metric
considered. This is likely due to the fact that we
consider only the core roles, which can usually be
predicted with high accuracy based on syntactic
information alone.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999884064516129">
Development of robust statistical models for core
NLP tasks is a challenging problem, and adapta-
tion of existing models to new languages presents
a viable alternative to exhaustive annotation for
each language. Although the models thus obtained
are generally imperfect, they can be further refined
for a particular language and domain using tech-
niques such as active learning (Settles, 2010; Chen
et al., 2011).
Cross-lingual annotation projection (Yarowsky
et al., 2001) approaches have been applied ex-
tensively to a variety of tasks, including POS
tagging (Xi and Hwa, 2005; Das and Petrov,
2011), morphology segmentation (Snyder and
Barzilay, 2008), verb classification (Merlo et al.,
2002), mention detection (Zitouni and Florian,
2008), LFG parsing (Wr´oblewska and Frank,
2009), information extraction (Kim et al., 2010),
SRL (Pad´o and Lapata, 2009; van der Plas et al.,
2011; Annesi and Basili, 2010; Tonelli and Pi-
anta, 2008), dependency parsing (Naseem et al.,
2012; Ganchev et al., 2009; Smith and Eisner,
2009; Hwa et al., 2005) or temporal relation pre-
diction (Spreyer and Frank, 2008). Interestingly,
it has also been used to propagate morphosyntac-
tic information between old and modern versions
of the same language (Meyer, 2011).
Cross-lingual model transfer methods (McDon-
ald et al., 2011; Zeman and Resnik, 2008; Durrett
et al., 2012; Søgaard, 2011; Lopez et al., 2008)
have also been receiving much attention recently.
The basic idea behind model transfer is similar to
that of cross-lingual annotation projection, as we
can see from the way parallel data is used in, for
example, McDonald et al. (2011).
A crucial component of direct transfer ap-
proaches is the unified feature representation.
There are at least two such representations of
lexical information (Klementiev et al., 2012;
T¨ackstr¨om et al., 2012), but both work on word
level. This makes it hard to account for phenom-
ena that are expressed differently in the languages
considered, for example the syntactic function of
a certain word may be indicated by a preposi-
tion, inflection or word order, depending on the
language. Accurate representation of such infor-
mation would require an extra level of abstrac-
tion (Hajiˇc, 2002).
A side-effect of using adaptation methods is that
we are forced to use the same annotation scheme
for the task in question (SRL, in our case), which
in turn simplifies the development of cross-lingual
tools for downstream tasks. Such representations
are also likely to be useful in machine translation.
Unsupervised semantic role labeling meth-
ods (Lang and Lapata, 2010; Lang and Lapata,
2011; Titov and Klementiev, 2012a; Lorenzo and
Cerisara, 2012) also constitute an alternative to
cross-lingual model transfer.
For an overview of of semi-supervised ap-
proaches we refer the reader to Titov and Klemen-
tiev (2012b).
</bodyText>
<sectionHeader confidence="0.992493" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999867">
We have considered the cross-lingual model trans-
fer approach as applied to the task of semantic role
labeling and observed that for closely related lan-
guages it performs comparably to annotation pro-
jection approaches. It allows one to quickly con-
struct an SRL model for a new language without
manual annotation or language-specific heuristics,
provided an accurate model is available for one of
the related languages along with a certain amount
of parallel data for the two languages. While an-
</bodyText>
<page confidence="0.988223">
1197
</page>
<bodyText confidence="0.999779318181818">
notation projection approaches require sentence-
and word-aligned parallel data and crucially de-
pend on the accuracy of the syntactic parsing and
SRL on the source side of the parallel corpus,
cross-lingual model transfer can be performed us-
ing only a bilingual dictionary.
Unsupervised SRL approaches have their ad-
vantages, in particular when no annotated data is
available for any of the related languages and there
is a syntactic parser available for the target one,
but the annotation they produce is not always suf-
ficient. In applications such as Information Re-
trieval it is preferable to have precise labels, rather
than just clusters of arguments, for example.
Also note that when applying cross-lingual
model transfer in practice, one can improve upon
the performance of the simplistic model we use
for evaluation, for example by picking the features
manually, taking into account the properties of the
target language. Domain adaptation techniques
can also be employed to adjust the model to the
target language.
</bodyText>
<sectionHeader confidence="0.988907" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999802">
The authors would like to thank Alexandre Kle-
mentiev and Ryan McDonald for useful sugges-
tions and T¨ackstr¨om et al. (2012) for sharing the
cross-lingual word representations. This research
is supported by the MMCI Cluster of Excellence.
</bodyText>
<sectionHeader confidence="0.991955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996038766233766">
Omri Abend, Roi Reichart, and Ari Rappoport. 2009.
Unsupervised argument identification for semantic
role labeling. In Proceedings of the Joint Con-
ference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Nat-
ural Language Processing of the AFNLP, ACL ’09,
pages 28–36, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Paolo Annesi and Roberto Basili. 2010. Cross-lingual
alignment of FrameNet annotations through hidden
Markov models. In Proceedings of the 11th interna-
tional conference on Computational Linguistics and
Intelligent Text Processing, CICLing’10, pages 12–
25, Berlin, Heidelberg. Springer-Verlag.
Roberto Basili, Diego De Cao, Danilo Croce, Bonaven-
tura Coppola, and Alessandro Moschitti. 2009.
Cross-language frame semantics transfer in bilin-
gual corpora. In Alexander F. Gelbukh, editor, Pro-
ceedings of the 10th International Conference on
Computational Linguistics and Intelligent Text Pro-
cessing, pages 332–345.
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning (CoNLL 2009):
Shared Task, pages 43–48, Boulder, Colorado, June.
Association for Computational Linguistics.
Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007.
Guiding semi-supervision with constraint-driven
learning. In ACL.
Chenhua Chen, Alexis Palmer, and Caroline Sporleder.
2011. Enhancing active learning for semantic role
labeling via compressed dependency trees. In Pro-
ceedings of 5th International Joint Conference on
Natural Language Processing, pages 183–191, Chi-
ang Mai, Thailand, November. Asian Federation of
Natural Language Processing.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. Proceedings of the Association for
Computational Linguistics.
Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syn-
tactic transfer using a bilingual lexicon. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1–11,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.
Andreas Eisele and Yu Chen. 2010. MultiUN:
A multilingual corpus from United Nation docu-
ments. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC’10). European Language Resources Associ-
ation (ELRA).
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. Journal of
Machine Learning Research, 9:1871–1874.
Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction via
bitext projection constraints. In Proceedings of the
47th Annual Meeting of the ACL, pages 369–377,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Qin Gao and Stephan Vogel. 2011. Corpus expan-
sion for statistical machine translation with seman-
tic role label substitution rules. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 294–298, Portland, Oregon, USA.
Trond Grenager and Christopher D. Manning. 2006.
Unsupervised discovery of a statistical verb lexicon.
In Proceedings of EMNLP.
Jan Hajiˇc. 2002. Tectogrammatical representation:
Towards a minimal transfer in machine translation.
In Robert Frank, editor, Proceedings of the 6th In-
ternational Workshop on Tree Adjoining Grammars
</reference>
<page confidence="0.947709">
1198
</page>
<reference confidence="0.998995169642857">
and Related Frameworks (TAG+6), pages 216—
226, Venezia. Universita di Venezia.
Jan Haji&amp;quot;c, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan &amp;quot;St&amp;quot;ep´anek, Pavel Stra&amp;quot;n´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the
Thirteenth Conference on Computational Natural
Language Learning (CoNLL 2009): Shared Task,
pages 1–18, Boulder, Colorado.
Jan Haji&amp;quot;c, Eva Haji&amp;quot;cov´a, Jarmila Panevov´a, Petr
Sgall, Ond&amp;quot;rej Bojar, Silvie Cinkov´a, Eva Fu&amp;quot;c´ıkov´a,
Marie Mikulov´a, Petr Pajas, Jan Popelka, Ji&amp;quot;r´ı
Semeck´y, Jana &amp;quot;Sindlerov´a, Jan &amp;quot;St&amp;quot;ep´anek, Josef
Toman, Zde&amp;quot;nka Ure&amp;quot;sov´a, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y.
2012. Announcing Prague Czech-English depen-
dency treebank 2.0. In Nicoletta Calzolari (Con-
ference Chair), Khalid Choukri, Thierry Declerck,
Mehmet U&amp;quot;gur Do&amp;quot;gan, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, and Stelios Piperidis, editors, Pro-
ceedings of the Eight International Conference on
Language Resources and Evaluation (LREC’12), Is-
tanbul, Turkey, May. European Language Resources
Association (ELRA).
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel text.
Natural Language Engineering, 11(3):311–325.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based semantic role labeling of Prop-
Bank. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 69–78, Honolulu, Hawaii.
Michael Kaisser and Bonnie Webber. 2007. Question
answering based on semantic roles. In ACL Work-
shop on Deep Linguistic Processing.
Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, and
Gary Geunbae Lee. 2010. A cross-lingual an-
notation projection approach for relation detection.
In Proceedings of the 23rd International Conference
on Computational Linguistics, COLING ’10, pages
564–571, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Paul Kingsbury, Nianwen Xue, and Martha Palmer.
2004. Propbanking in parallel. In In Proceedings
of the Workshop on the Amazing Utility of Paral-
lel and Comparable Corpora, in conjunction with
LREC’04.
Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012. Inducing crosslingual distributed rep-
resentations of words. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING), Bombay, India.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Conference Pro-
ceedings: the tenth Machine Translation Summit,
pages 79–86, Phuket, Thailand. AAMT.
Joel Lang and Mirella Lapata. 2010. Unsuper-
vised induction of semantic roles. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 939–947, Los
Angeles, California, June. Association for Compu-
tational Linguistics.
Joel Lang and Mirella Lapata. 2011. Unsupervised
semantic role induction via split-merge clustering.
In Proc. of Annual Meeting of the Association for
Computational Linguistics (ACL).
Ding Liu and Daniel Gildea. 2010. Semantic role
features for machine translation. In Proceedings of
the 23rd International Conference on Computational
Linguistics (Coling 2010), Beijing, China.
Adam Lopez, Daniel Zeman, Michael Nossal, Philip
Resnik, and Rebecca Hwa. 2008. Cross-language
parser adaptation between related languages. In
IJCNLP-08 Workshop on NLP for Less Privileged
Languages, pages 35–42, Hyderabad, India, Jan-
uary.
Alejandra Lorenzo and Christophe Cerisara. 2012.
Unsupervised frame based semantic role induction:
application to French and English. In Proceedings
of the ACL 2012 Joint Workshop on Statistical Pars-
ing and Semantic Processing of Morphologically
Rich Languages, pages 30–35, Jeju, Republic of Ko-
rea, July. Association for Computational Linguistics.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 62–72, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Paola Merlo, Suzanne Stevenson, Vivian Tsang, and
Gianluca Allaria. 2002. A multi-lingual paradigm
for automatic verb classification. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL’02), pages 207–
214, Philadelphia, PA.
Roland Meyer. 2011. New wine in old wineskins?–
Tagging old Russian via annotation projection
from modern translations. Russian Linguistics,
35(2):267(15).
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective sharing for multilingual dependency
parsing. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 629–637, Jeju Island, Korea, July. Asso-
ciation for Computational Linguistics.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Comput. Linguist.,
34(4):513–553, December.
</reference>
<page confidence="0.945506">
1199
</page>
<reference confidence="0.999688819819819">
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1).
Sebastian Pad´o and Mirella Lapata. 2009. Cross-
lingual annotation projection for semantic roles.
Journal of Artificial Intelligence Research, 36:307–
340.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31:71–105.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC, May.
Mark Sammons, Vinod Vydiswaran, Tim Vieira,
Nikhil Johri, Ming wei Chang, Dan Goldwasser,
Vivek Srikumar, Gourab Kundu, Yuancheng Tu,
Kevin Small, Joshua Rule, Quang Do, and Dan
Roth. 2009. Relation alignment for textual en-
tailment recognition. In Text Analysis Conference
(TAC).
Burr Settles. 2010. Active learning literature survey.
Computer Sciences Technical Report, 1648.
Dan Shen and Mirella Lapata. 2007. Using semantic
roles to improve question answering. In EMNLP.
David A Smith and Jason Eisner. 2009. Parser adap-
tation and projection with quasi-synchronous gram-
mar features. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 822–831. Association for Com-
putational Linguistics.
Benjamin Snyder and Regina Barzilay. 2008. Cross-
lingual propagation for morphological analysis. In
Proceedings of the 23rd national conference on Ar-
tificial intelligence.
Anders Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, volume 2 of HLT ’11, pages
682–686, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Kathrin Spreyer and Anette Frank. 2008. Projection-
based acquisition of a temporal labeller. Proceed-
ings of IJCNLP 2008.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszko-
reit. 2012. Cross-lingual word clusters for direct
transfer of linguistic structure. In Proc. of the An-
nual Meeting of the North American Association
of Computational Linguistics (NAACL), pages 477–
487, Montr´eal, Canada.
Cynthia A. Thompson, Roger Levy, and Christopher D.
Manning. 2003. A generative model for seman-
tic role labeling. In Proceedings of the 14th Eu-
ropean Conference on Machine Learning, ECML
2003, pages 397–408, Dubrovnik, Croatia.
Ivan Titov and Alexandre Klementiev. 2012a. A
Bayesian approach to unsupervised semantic role in-
duction. In Proc. of European Chapter of the Asso-
ciation for Computational Linguistics (EACL).
Ivan Titov and Alexandre Klementiev. 2012b. Semi-
supervised semantic role labeling: Approaching
from an unsupervised perspective. In Proceedings
of the International Conference on Computational
Linguistics (COLING), Bombay, India, December.
Sara Tonelli and Emanuele Pianta. 2008. Frame infor-
mation transfer from English to Italian. In Proceed-
ings of LREC 2008.
Lonneke van der Plas, James Henderson, and Paola
Merlo. 2009. Domain adaptation with artificial
data for semantic parsing of speech. In Proc. 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 125–128, Boulder, Colorado.
Lonneke van der Plas, Paola Merlo, and James Hen-
derson. 2011. Scaling up automatic cross-lingual
semantic role annotation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
HLT ’11, pages 299–304, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Alina Wr´oblewska and Anette Frank. 2009. Cross-
lingual projection of LFG F-structures: Building
an F-structure bank for Polish. In Eighth Interna-
tional Workshop on Treebanks and Linguistic Theo-
ries, page 209.
Dekai Wu and Pascale Fung. 2009. Can semantic
role labeling improve SMT? In Proceedings of 13th
Annual Conference of the European Association for
Machine Translation (EAMT 2009), Barcelona.
Chenhai Xi and Rebecca Hwa. 2005. A backoff
model for bootstrapping resources for non-English
languages. In Proceedings of the conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, pages 851–858,
Stroudsburg, PA, USA.
David Yarowsky, Grace Ngai, and Ricahrd Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora. In
Proceedings of Human Language Technology Con-
ference.
Daniel Zeman and Philip Resnik. 2008. Cross-
language parser adaptation between related lan-
guages. In Proceedings of the IJCNLP-08 Workshop
on NLP for Less Privileged Languages, pages 35–
42, Hyderabad, India, January. Asian Federation of
Natural Language Processing.
Imed Zitouni and Radu Florian. 2008. Mention detec-
tion crossing the language barrier. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.
</reference>
<page confidence="0.984388">
1200
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.990374">Cross-lingual Transfer of Semantic Role Labeling Models</title>
<author confidence="0.829195">Kozhevnikov</author>
<affiliation confidence="0.953288">Saarland University, Postfach 15 11</affiliation>
<address confidence="0.847622">66041 Saarbr¨ucken,</address>
<abstract confidence="0.992307650819674">Semantic Role Labeling (SRL) has become one of the standard tasks of natural language processing and proven useful as a source of information for a number of other applications. We address the problem of transferring an SRL model from one language to another using a shared feature representation. This approach is then evaluated on three language pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages have been proposed. On one end of the scale is unsupervised SRL, such as Grenager and Manning (2006), which requires some expert knowledge, but no labeled data. It clusters together arguments that should bear the same semantic role, but does not assign a particular role to each cluster. On the other end is annotating a new dataset from scratch. There are also intermediate options, which often make use of similarities between languages. This way, if an accurate model exists for one language, it should help simplify the construction of a model for another, related language. The approaches in this third group often use parallel data to bridge the gap between languages. Cross-lingual annotation projection systems (Pad´o and Lapata, 2009), for example, propagate information directly via word alignment links. However, they are very sensitive to the quality of parallel data, as well as the accuracy of a sourcelanguage model on it. An alternative approach, known as cross-lingual model transfer, or cross-lingual model adaptation, consists of modifying a source-language model to make it directly applicable to a new language. This usually involves constructing a shared feature representation across the two languages. McDonald et al. (2011) successfully apply this idea to the transfer of dependency parsers, using part-ofspeech tags as the shared representation of words. A later extension of T¨ackstr¨om et al. (2012) enriches this representation with cross-lingual word clusters, considerably improving the performance. In the case of SRL, a shared representation that is purely syntactic is likely to be insufficient, since structures with different semantics may be realized by the same syntactic construct, for example “in August” vs “in Britain”. However with the help of introduced cross-lingual word represen- 1190 of the 51st Annual Meeting of the Association for Computational pages Bulgaria, August 4-9 2013. Association for Computational Linguistics tations, such as the cross-lingual clustering mentioned above or cross-lingual distributed word representations of Klementiev et al. (2012), we may be able to transfer models of shallow semantics in a similar fashion. In this work we construct a shared feature representation for a pair of languages, employing crosslingual representations of syntactic and lexical information, train a semantic role labeling model on one language and apply it to the other one. This approach yields an SRL model for a new language at a very low cost, effectively requiring only a source language model and parallel data. We evaluate on five (directed) language pairs – where English, French, Czech and Chinese, respectively. The transferred model is compared against two baselines: an unsupervised SRL system and a model trained on the output of a cross-lingual annotation projection system. In the next section we will describe our setup, then in section 3 present the shared feature representation we use, discuss the evaluation data and other technical aspects in section 4, present the results and conclude with an overview of related work. 2 Setup The purpose of the study is not to develop a yet another semantic role labeling system – any existing SRL system can (after some modification) be used in this setup – but to assess the practical applicability of cross-lingual model transfer to this problem, compare it against the alternatives and identify its strong/weak points depending on a particular setup. 2.1 Semantic Role Labeling Model We consider the dependency-based version of semantic role labeling as described in Hajiˇc et al. (2009) and transfer an SRL model from one language to another. We only consider verbal predicates and ignore the predicate disambiguation stage. We also assume that the predicate identification information is available – in most languages it can be obtained using a relatively simple heuristic based on part-of-speech tags. The model performs argument identification and classification (Johansson and Nugues, 2008) separately in a pipeline – first each candidate is classified as being or not being a head of an argument phrase with respect to the predicate in question and then each of the arguments is assigned a role from a given inventory. The model is factorized over arguments – the decisions regarding the classification of different arguments are made independently of each other. With respect to the use of syntactic annotation we consider two options: using an existing dependency parser for the target language and obtaining one by means of cross-lingual transfer (see section 4.2). Following McDonald et al. (2011), we assume that a part-of-speech tagger is available for the target language. 2.2 SRL in the Low-resource Setting Several approaches have been proposed to obtain an SRL model for a new language with little or no manual annotation. Unsupervised SRL models (Lang and Lapata, 2010) cluster the arguments of predicates in a given corpus according to their semantic roles. The performance of such models can be impressive, especially for those languages where semantic roles correlate strongly with syntactic relation of the argument to its predicate. However, assigning meaningful role labels to the resulting clusters requires additional effort and the model’s parameters generally need some adjustment for every language. If the necessary resources are already available for a closely related language, they can be utilized to facilitate the construction of a model for the target language. This can be achieved either by means of cross-lingual annotation projection (Yarowsky et al., 2001) or by cross-lingual model transfer (Zeman and Resnik, 2008). This last approach is the one we are considering in this work, and the other two options are treated as baselines. The unsupervised model will be furreferred to as the projection baseas 2.3 Evaluation Measures use the as a metric for the argument identification stage and accuracy as an aggregate measure of argument classification performance. When comparing to the unsupervised SRL system the clustering evaluation measures are used instead. These are purity and collocation 1191 � U i � j the set of arguments in the induced the set of arguments in the gold and the total number of arguments. We report the harmonic mean of the two (Lang and 2011) and denote it to avoid confusing it with the supervised metric. 3 Model Transfer The idea of this work is to abstract the model away from the particular source language and apply it to a new one. This setup requires that we use the same feature representation for both languages, for example part-of-speech tags and dependency relation labels should be from the same inventory. Some features are not applicable to certain languages because the corresponding phenomena are absent in them. For example, consider a strongly inflected language and an analytic one. While the latter can usually convey the information encoded in the word form in the former one (number, gender, etc.), finding a shared feature representation for such information is non-trivial. In this study we will confine ourselves to those features that are applicable to all languages in question, namely: part-of-speech tags, syntactic dependency structures and representations of the word’s identity. 3.1 Lexical Information We train a model on one language and apply it to a different one. In order for this to work, the words of the two languages have to be mapped into a common feature space. It is also desirable that closely related words from both languages have similar representations in this space. mapping. first option is simply to use the source language words as the shared representation. Here every source language word would have itself as its representation and every target word would map into a source word that corresponds to it. In other words, we supply the model with a gloss of the target sentence. The mapping (bilingual dictionary) we use is derived from a word-aligned parallel corpus, by identifying, for each word in the target language, the word in the source language it is most often aligned to. clusters. is no guarantee that each of the words in the evaluation data is present in our dictionary, nor that the corresponding source-language word is present in the training data, so the model would benefit from the ability to generalize over closely related words. This can, for example, be achieved by using cross-lingual word clusters induced in T¨ackstr¨om et al. (2012). We incorporate these clusters as features into our model. 3.2 Syntactic Information Tags. map part-of-speech tags into the universal tagset following Petrov et al. (2012). This may have a negative effect on the performance of a monolingual model, since most part-of-speech tagsets are more fine-grained than the universal POS tags considered here. For example Penn Treebank inventory contains 36 tags and the universal POS tagset – only 12. Since the finergrained POS tags often reflect more languagespecific phenomena, however, they would only be useful for very closely related languages in the cross-lingual setting. The universal part-of-speech tags used in evaluation are derived from gold-standard annotation for all languages except French, where predicted ones had to be used instead. Structure. important aspect of syntactic information is the dependency structure. Most dependency relation inventories are language-specific, and finding a shared representation for them is a challenging problem. One could map dependency relations into a simplified form that would be shared between languages, as it is done for part-of-speech tags in Petrov et al. (2012). The extent to which this would be useful, however, depends on the similarity of syntactic-semantic interfaces of the languages in question. In this work we discard the dependency relation labels where the inventories do not match and only consider the unlabeled syntactic dependency graph. Some discrepancies, such as variations in attachment order, may be present even there, but this does not appear to be the case with the datasets we use for evaluation. If a target language is poor in resources, one can obtain a dependency parser for the target language by means of cross-lingual model transfer (Zeman and Resnik, 2008). We j max i 1192 take this into account and evaluate both using the original dependency structures and the ones obtained by means of cross-lingual model transfer. 3.3 The Model The model we use is based on that of Bj¨orkelund et al. (2009). It is comprised of a set of linear classifiers trained using Liblinear (Fan et al., 2008). The feature model was modified to accommodate the cross-lingual cluster features and the reranker component was not used. We do not model the interaction between different argument roles in the same predicate. While this has been found useful, in the cross-lingual setup one has to be careful with the assumptions made. For example, modeling the sequence of roles using a Markov chain (Thompson et al., 2003) may not work well in the present setting, especially between distant languages, as the order or arguments is not necessarily preserved. Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on languagespecific resources, such as a valency lexicon. Taking into account the interaction between different arguments of a predicate is likely to improve the performance of the transferred model, but this is outside the scope of this work. 3.4 Feature Selection Compatibility of feature representations is necessary but not sufficient for successful model transfer. We have to make sure that the features we use are predictive of similar outcomes in the two languages as well. Depending on the pair of languages in question, different aspects of the feature representation will retain or lose their predictive power. We can be reasonably certain that the identity of an argument word is predictive of its semantic role in any language, but it might or might not be true of, for example, the word directly preceding the word. It is therefore important to pre- POS part-of-speech tags Synt unlabeled dependency graph Cls cross-lingual word clusters Gloss glossed word forms Deprel dependency relations Table 1: Feature groups. vent the model from capturing overly specific aspects of the source language, which we do by confining the model to first-order features. We also avoid feature selection, which, performed on the source language, is unlikely to help the model to better generalize to the target one. The experiments confirm that feature selection and the use of second-order features degrade the performance of the transferred model. 3.5 Feature Groups For each word, we use its part-of-speech tag, cross-lingual cluster id, word identity (glossed, when evaluating on the target language) and its dependency relation to its parent. Features associated with an argument word include the attributes of the predicate word, the argument word, its parent, siblings and children, and the words directly preceding and following it. Also included are the sequences of part-of-speech tags and dependency relations on the path between the predicate and the argument. Since we are also interested in the impact of different aspects of the feature representation, we divide the features into groups as summarized in table 1 and evaluate their respective contributions to the performance of the model. If a feature group is enabled – the model has access to the corresponding source of information. For example, if is enabled, the model relies on the part-of-speech tags of the argument, the predicate and the words to the right and left of the arword. If enabled too, it also uses the POS tags of the argument’s parent, children and siblings. Word order information constitutes an implicit group that is always available. It includes the which indicates whether the argument is located to the left or to the right of the predicate, and allows the model to look up the attributes of the words directly preceding and following the argument word. The model we compare against the baselines uses all applicable feagroups only used in with original syntax). 4 Evaluation 4.1 Datasets and Preprocessing Evaluation of the cross-lingual model transfer requires a rather specific kind of dataset. Namely, the data in both languages has to be annotated 1193 with the same set of semantic roles following the same (or compatible) guidelines, which is seldom the case. We have identified three language pairs for which such resources are available: English- Chinese, English-Czech and English-French. The evaluation datasets for English and Chinese are those from the CoNLL Shared Task 2009 (Hajiˇc et al., 2009) (henceforth CoNLL-ST). Their annotation in the CoNLL-ST is not identical, but the guidelines for “core” semantic roles are similar (Kingsbury et al., 2004), so we evaluate only on core roles here. The data for the second language pair is drawn from the Prague Czech-English Dependency Treebank 2.0 (Hajiˇc et al., 2012), which we converted to a format simito that of The original annotation uses the tectogrammatical representation (Hajiˇc, and an inventory of semantic roles (or funcmost of which are interpretable across various predicates. Also note that the syntactic annotation of English and Czech in PCEDT 2.0 is quite similar (to the extent permitted by the difference in the structure of the two languages) and we can use the dependency relations in our experiments. For English-French, the English CoNLL-ST dataset was used as a source and the model was evaluated on the manually annotated dataset from van der Plas et al. (2011). The latter contains one thousand sentences from the French part of the Europarl (Koehn, 2005) corpus, annotated with semantic roles following an adapted version of Prop- Bank (Palmer et al., 2005) guidelines. The authors perform annotation projection from English to French, using a joint model of syntax and semantics and employing heuristics for filtering. We use a model trained on the output of this projection system as one of the baselines. The evaluation dataset is relatively small in this case, so we perform the transfer only one-way, from English to French. The part-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the original mappings were derived. Namely, tag “t” is mapped to “VERB” and “Y” – to “PRON”. We use parallel data to construct a bilingual dictionary used in word mapping, as well as in the projection baseline. For English-Czech see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011), using Malt parser (Nivre, 2008) and the same set of features. We did not reimplement the projected transfer algorithm, however, and used the default training procedure instead of perceptron-based learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent difference in their structure. The scores are shown in table 2. We will henceforth refer to the syntactic annotathat were provided with the datasets as origas opposed to the annotations obtained by means of syntactic transfer. 4.3 Baselines Baseline: are using a version of the unsupervised semantic role induction system of Titov and Klementiev (2012a) adapted to Setup UAS, % 35 42 36 39 67 Table 2: Syntactic transfer accuracy, unlabeled attachment score (percent). Note that in case of French we evaluate against the output of a supervised system, since manual annotation is not available for this dataset. This score does not reflect the true performance of syntactic transfer. 1194 the shared feature representation considered in order to make the scores comparable with those of the transfer model and, more importantly, to enable evaluation on transferred syntax. Note that the original system, tailored to a more expressive language-specific syntactic representation and equipped with heuristics to identify active/passive voice and other phenomena, achieves higher scores than those we report here. Baseline: projection baseline we use for English-Czech and English-Chinese is a straightforward one: we label the source side of a parallel corpus using the source-language model, then identify those verbs on the target side that are aligned to a predicate, mark them as predicates and propagate the argument roles in the same fashion. A model is then trained on the resulting training data and applied to the test set. For English-French we instead use the output of a fully featured projection model of van der Plas et al. (2011), published in the CLASSiC project. 5 Results In order to ensure that the results are consistent, the test sets, except for the French one, were partitioned into five equal parts (of 5 to 10 thousand sentences each, depending on the dataset) and the evaluation performed separately on each one. All evaluation figures for English, Czech or Chinese below are the average values over the five subsets. In case of French, the evaluation dataset is too small to split it further, so instead we ran the evaluation five times on a randomly selected 80% sample of the evaluation data and averaged over those. In both cases the results are consistent over the subsets, the standard deviation does not exceed 0.5% for the transfer system and projection baseline and 1% for the unsupervised system. 5.1 Argument Identification We summarize the results in table 3. Argument identification is known to rely heavily on syntactic information, so it is unsurprising that it proves inaccurate when transferred syntax is used. Our simple projection baseline suffers from the same problem. Even with original syntactic information available, the performance of argument identification is moderate. Note that the model of (van der Plas et al., 2011), though relying on more expressive syntax, only outperforms the transferred sysby 3% on this task. Setup Syntax trans 34.5 13.9 trans 32.6 15.6 trans 46.3 12.4 trans 42.3 22.2 trans 61.6 43.5 orig 51.7 19.6 orig 53.2 29.7 orig 63.9 59.3 orig 67.3 60.9 orig 71.0 51.3 Table 3: Argument identification, transferred vs. projection baseline, Most unsupervised SRL approaches assume that the argument identification is performed by some external means, for example heuristically (Lang and Lapata, 2011). Such heuristics or unsupervised approaches to argument identification (Abend et al., 2009) can also be used in the present setup. 5.2 Argument Classification the following tables, contains results for the transferred system, the unsupervised baseline and for projection baseline. We highlight in bold the higher score where the difference exceeds twice the maximum of the standard deviation estimates of the two results. Table 4 presents the unsupervised evaluation results. Note that the unsupervised model performs as well as the transferred one or better where the Setup Syntax trans 83.3 73.9 trans 79.2 67.6 trans 66.4 66.1 trans 68.2 68.7 trans 74.6 65.1 orig 84.5 89.7 orig 79.2 83.0 orig 74.1 74.0 orig 74.6 76.7 orig 73.3 72.3 Table 4: Argument classification, transferred model vs. unsupervised baseline in terms of the metric section 2.3). 1195 Setup Syntax trans 70.1 69.2 trans 65.6 61.3 trans 50.1 46.3 trans 53.3 54.7 trans 65.1 66.1 orig 71.7 69.7 orig 66.1 64.4 orig 59.0 53.2 orig 61.0 60.8 orig 63.0 68.0 Table 5: Argument classification, transferred model vs. projection baseline, accuracy. original syntactic dependencies are available. In the more realistic scenario with transferred syntax, however, the transferred model proves more accurate. In table 5 we compare the transferred system with the projection baseline. It is easy to see that the scores vary strongly depending on the language pair, due to both the difference in the annotation scheme used and the degree of relatedness between the languages. The drop in performance when transferring the model to another language is large in every case, though, see table 6. Setup Target Source 71.7 87.1 66.1 86.2 59.0 80.1 61.0 75.4 63.0 82.5 Table 6: Model accuracy on the source and target language using original syntax. The source language scores for English vary between language pairs because of the difference in syntactic annotation and role subset used. also include the individual for top-10 most frequent labels for transfer with original syntax in table 7. The model provides meaningful predictions here, despite low overall accuracy. of the are self-explanatory: Pa-</abstract>
<email confidence="0.239538">tient(PAT),Actor(ACT),Time(TWHEN),Effect</email>
<note confidence="0.748308083333333">(EFF), Location (LOC), Manner (MANN), Addressee (ADDR), Extent (EXT). CPHR marks the Label Freq. Re. Pr. PAT 14707 69.4 70.0 68.7 ACT 14303 81.1 81.7 80.4 TWHEN 3631 70.6 65.1 77.0 EFF 2601 45.4 67.2 34.3 LOC 1990 41.8 35.3 51.3 MANN 1208 54.0 63.8 46.9 ADDR 1045 30.2 34.4 26.8 CPHR 791 20.4 13.1 45.0 EXT 708 42.2 40.5 44.1</note>
<phone confidence="0.268404">DIR3 695 20.1 17.3 23.9</phone>
<abstract confidence="0.878611328947369">7: (with original syntax), recall and precision for the top-10 most frequent roles. nominal part of a complex predicate, as in “to have and DIR3 indicates destination. 5.3 Additional Experiments We now evaluate the contribution of different aspects of the feature representation to the performance of the model. Table 8 contains the results for English-French. Features Orig Trans POS 47.5 47.5 POS, Synt 53.0 53.1 POS, Cls 53.7 53.7 POS, Gloss 63.7 63.7 POS, Synt, Cls 55.9 56.4 POS, Synt, Gloss 65.2 66.3 POS, Cls, Gloss 61.5 61.5 POS, Synt, Cls, Gloss 63.0 65.1 8: transfer accuracy with different feature subsets, using original and transferred syntactic information. The fact that the model performs slightly better with transferred syntax may be explained by two factors. Firstly, as we already mentioned, the original syntactic annotation is also produced automatically. Secondly, in the model transfer setup it is more important how closely the syntacticsemantic interface on the target side resembles that on the source side than how well it matches the “true” structure of the target language, and in this respect a transferred dependency parser may have an advantage over one trained on target-language data. high impact of the here 1196 may be partly attributed to the fact that the mapping is derived from the same corpus as the evaluation data – Europarl (Koehn, 2005) – and partly by the similarity between English and French in terms of word order, usage of articles and prepositions. The moderate contribution of the crosslingual cluster features are likely due to the insufficient granularity of the clustering for this task. For more distant language pairs, the contributions of individual feature groups are less interpretable, so we only highlight a few observations. of all, both noticeably from the use of the original syntactic annotation, including dependency relations, but not from the transferred syntax, most likely due to the low syntactic transfer performance. Both perform better when lexical information is available, although the improvement is not as significant as in the case of French – only up to 5%. The situation with Chinese is somewhat complicated in that adding lexical information here fails to yield an improvement in terms of the metric considered. This is likely due to the fact that we consider only the core roles, which can usually be predicted with high accuracy based on syntactic information alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov,</abstract>
<address confidence="0.637383777777778">2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner,</address>
<abstract confidence="0.995943675">2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed differently in the languages considered, for example the syntactic function of a certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heuristics, provided an accurate model is available for one of the related languages along with a certain amount parallel data for the two languages. While an- 1197 notation projection approaches require sentenceand word-aligned parallel data and crucially depend on the accuracy of the syntactic parsing and SRL on the source side of the parallel corpus, cross-lingual model transfer can be performed using only a bilingual dictionary. Unsupervised SRL approaches have their advantages, in particular when no annotated data is available for any of the related languages and there is a syntactic parser available for the target one, but the annotation they produce is not always sufficient. In applications such as Information Retrieval it is preferable to have precise labels, rather than just clusters of arguments, for example. Also note that when applying cross-lingual model transfer in practice, one can improve upon the performance of the simplistic model we use for evaluation, for example by picking the features manually, taking into account the properties of the target language. Domain adaptation techniques can also be employed to adjust the model to the target language. Acknowledgments The authors would like to thank Alexandre Klementiev and Ryan McDonald for useful suggestions and T¨ackstr¨om et al. (2012) for sharing the cross-lingual word representations. This research is supported by the MMCI Cluster of Excellence.</abstract>
<note confidence="0.679042">References Omri Abend, Roi Reichart, and Ari Rappoport. 2009. Unsupervised argument identification for semantic labeling. In of the Joint Conof the Annual Meeting of the ACL the International Joint Conference on Nat- Language Processing of the ACL ’09, pages 28–36, Stroudsburg, PA, USA. Association for Computational Linguistics. Paolo Annesi and Roberto Basili. 2010. Cross-lingual</note>
<abstract confidence="0.742611">alignment of FrameNet annotations through hidden models. In of the international conference on Computational Linguistics and</abstract>
<note confidence="0.950257605263158">Text CICLing’10, pages 12– 25, Berlin, Heidelberg. Springer-Verlag. Roberto Basili, Diego De Cao, Danilo Croce, Bonaventura Coppola, and Alessandro Moschitti. 2009. Cross-language frame semantics transfer in bilincorpora. In Alexander F. Gelbukh, editor, Proof the International Conference on Computational Linguistics and Intelligent Text Propages 332–345. Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): pages 43–48, Boulder, Colorado, June. Association for Computational Linguistics. Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven In Chenhua Chen, Alexis Palmer, and Caroline Sporleder. 2011. Enhancing active learning for semantic role via compressed dependency trees. In Proceedings of 5th International Joint Conference on Language pages 183–191, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing. Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based of the Association for Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntransfer using a bilingual lexicon. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Com- Natural Language pages 1–11, Jeju Island, Korea, July. Association for Computational Linguistics. Andreas Eisele and Yu Chen. 2010. MultiUN: A multilingual corpus from United Nation docu- In of the Seventh International</note>
<title confidence="0.809414">Conference on Language Resources and Evaluation European Language Resources Association (ELRA).</title>
<author confidence="0.59599">Rong-En Fan</author>
<author confidence="0.59599">Kai-Wei Chang</author>
<author confidence="0.59599">Cho-Jui Hsieh</author>
<author confidence="0.59599">Xiang-</author>
<note confidence="0.779221631578947">Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: library for large linear classification. of Learning 9:1871–1874. Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via projection constraints. In of the Annual Meeting of the pages 369–377, Stroudsburg, PA, USA. Association for Computational Linguistics. Qin Gao and Stephan Vogel. 2011. Corpus expansion for statistical machine translation with semanrole label substitution rules. In of Annual Meeting of the Association for Computational Linguistics: Human Language Technolopages 294–298, Portland, Oregon, USA. Trond Grenager and Christopher D. Manning. 2006. Unsupervised discovery of a statistical verb lexicon. of Jan Hajiˇc. 2002. Tectogrammatical representation:</note>
<title confidence="0.852087">Towards a minimal transfer in machine translation.</title>
<author confidence="0.975962">Robert Frank</author>
<author confidence="0.975962">of the In- editor</author>
<affiliation confidence="0.891682">ternational Workshop on Tree Adjoining Grammars</affiliation>
<address confidence="0.729041">1198</address>
<note confidence="0.8981505">Related Frameworks pages 216— 226, Venezia. Universita di Venezia.</note>
<author confidence="0.897259">Jan Hajic</author>
<author confidence="0.897259">Massimiliano Ciaramita</author>
<author confidence="0.897259">Richard Johans-</author>
<affiliation confidence="0.361821">son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs</affiliation>
<address confidence="0.475375">M`arquez, Adam Meyers, Joakim Nivre, Sebastian</address>
<author confidence="0.398063">Jan Step´anek Pad´o</author>
<author confidence="0.398063">Pavel Stran´ak</author>
<author confidence="0.398063">Mihai Surdeanu</author>
<note confidence="0.847866">Nianwen Xue, and Yi Zhang. 2009. The CoNLL- 2009 shared task: Syntactic and semantic dependenin multiple languages. In of the Thirteenth Conference on Computational Natural Learning (CoNLL 2009): Shared pages 1–18, Boulder, Colorado.</note>
<author confidence="0.7348425">Jan Hajic</author>
<author confidence="0.7348425">Eva Hajicov´a</author>
<author confidence="0.7348425">Jarmila Panevov´a</author>
<author confidence="0.7348425">Petr Sgall</author>
<author confidence="0.7348425">Ondrej Bojar</author>
<author confidence="0.7348425">Silvie Cinkov´a</author>
<author confidence="0.7348425">Eva Fuc´ıkov´a</author>
<author confidence="0.7348425">Marie Mikulov´a</author>
<author confidence="0.7348425">Petr Pajas</author>
<author confidence="0.7348425">Jan Popelka</author>
<author confidence="0.7348425">Jir´ı Semeck´y</author>
<author confidence="0.7348425">Jana Sindlerov´a</author>
<author confidence="0.7348425">Jan Step´anek</author>
<author confidence="0.7348425">Josef</author>
<affiliation confidence="0.458559">Toman, Zde&amp;quot;nka Ure&amp;quot;sov´a, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y.</affiliation>
<address confidence="0.457682">2012. Announcing Prague Czech-English depen-</address>
<note confidence="0.760473315789474">dency treebank 2.0. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U&amp;quot;gur Do&amp;quot;gan, Bente Maegaard, Joseph Mar- Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Resources and Evaluation Istanbul, Turkey, May. European Language Resources Association (ELRA). Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel text. Language 11(3):311–325. Richard Johansson and Pierre Nugues. 2008. Dependency-based semantic role labeling of Prop- In of the 2008 Conference on Empirical Methods in Natural Language Processpages 69–78, Honolulu, Hawaii. Michael Kaisser and Bonnie Webber. 2007. Question based on semantic roles. In Work-</note>
<title confidence="0.902951">on Deep Linguistic</title>
<author confidence="0.886691">Seokhwan Kim</author>
<author confidence="0.886691">Minwoo Jeong</author>
<author confidence="0.886691">Jonghoon Lee</author>
<abstract confidence="0.770121">Gary Geunbae Lee. 2010. A cross-lingual annotation projection approach for relation detection.</abstract>
<note confidence="0.903287">of the International Conference Computational COLING ’10, pages 564–571, Stroudsburg, PA, USA. Association for Computational Linguistics. Paul Kingsbury, Nianwen Xue, and Martha Palmer. Propbanking in parallel. In Proceedings</note>
<abstract confidence="0.659528">of the Workshop on the Amazing Utility of Parallel and Comparable Corpora, in conjunction with Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. 2012. Inducing crosslingual distributed repof words. In of the Inter-</abstract>
<affiliation confidence="0.733321">national Conference on Computational Linguistics</affiliation>
<address confidence="0.850916">Bombay, India.</address>
<author confidence="0.664148">Europarl A parallel corpus for machine translation In Pro-</author>
<note confidence="0.828957317073171">the tenth Machine Translation pages 79–86, Phuket, Thailand. AAMT. Joel Lang and Mirella Lapata. 2010. Unsuperinduction of semantic roles. In Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association Computational pages 939–947, Los Angeles, California, June. Association for Computational Linguistics. Joel Lang and Mirella Lapata. 2011. Unsupervised semantic role induction via split-merge clustering. of Annual Meeting of the Association for Linguistics Ding Liu and Daniel Gildea. 2010. Semantic role for machine translation. In of International Conference on Computational (Coling Beijing, China. Adam Lopez, Daniel Zeman, Michael Nossal, Philip Resnik, and Rebecca Hwa. 2008. Cross-language parser adaptation between related languages. In IJCNLP-08 Workshop on NLP for Less Privileged pages 35–42, Hyderabad, India, January. Alejandra Lorenzo and Christophe Cerisara. 2012. Unsupervised frame based semantic role induction: to French and English. In of the ACL 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically pages 30–35, Jeju, Republic of Korea, July. Association for Computational Linguistics. Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency In of the Conference on Em- Methods in Natural Language EMNLP ’11, pages 62–72, Stroudsburg, PA, USA. Association for Computational Linguistics. Paola Merlo, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multi-lingual paradigm automatic verb classification. In the Annual Meeting of the Association for Linguistics pages 207–</note>
<address confidence="0.558245">214, Philadelphia, PA.</address>
<author confidence="0.301274">New wine in old wineskins–</author>
<abstract confidence="0.813326">Tagging old Russian via annotation projection modern translations. 35(2):267(15). Tahira Naseem, Regina Barzilay, and Amir Globerson. 2012. Selective sharing for multilingual dependency In of the Annual Meeting of the Association for Computational Linguispages 629–637, Jeju Island, Korea, July. Association for Computational Linguistics. Joakim Nivre. 2008. Algorithms for deterministic independency parsing. 34(4):513–553, December. 1199 Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment 29(1). Sebastian Pad´o and Mirella Lapata. 2009. Crosslingual annotation projection for semantic roles. of Artificial Intelligence 36:307– 340. Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corof semantic roles. 31:71–105. Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. universal part-of-speech tagset. In of May.</abstract>
<author confidence="0.972762">Mark Sammons</author>
<author confidence="0.972762">Vinod Vydiswaran</author>
<author confidence="0.972762">Tim Vieira</author>
<author confidence="0.972762">Nikhil Johri</author>
<author confidence="0.972762">Ming wei Chang</author>
<author confidence="0.972762">Dan Goldwasser</author>
<affiliation confidence="0.614019">Vivek Srikumar, Gourab Kundu, Yuancheng Tu,</affiliation>
<address confidence="0.375444">Kevin Small, Joshua Rule, Quang Do, and Dan</address>
<note confidence="0.732944074626866">Roth. 2009. Relation alignment for textual enrecognition. In Analysis Conference Burr Settles. 2010. Active learning literature survey. Sciences Technical 1648. Dan Shen and Mirella Lapata. 2007. Using semantic to improve question answering. In David A Smith and Jason Eisner. 2009. Parser adaptation and projection with quasi-synchronous gramfeatures. In of the 2009 Conference on Empirical Methods in Natural Language pages 822–831. Association for Computational Linguistics. Benjamin Snyder and Regina Barzilay. 2008. Crosslingual propagation for morphological analysis. In Proceedings of the 23rd national conference on Ar- Anders Søgaard. 2011. Data point selection for crossadaptation of dependency parsers. In Proof the Annual Meeting of the Association for Computational Linguistics: Human Lanvolume 2 of pages 682–686, Stroudsburg, PA, USA. Association for Computational Linguistics. Kathrin Spreyer and Anette Frank. 2008. Projectionacquisition of a temporal labeller. Proceedof IJCNLP Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct of linguistic structure. In of the Annual Meeting of the North American Association Computational Linguistics pages 477– 487, Montr´eal, Canada. Cynthia A. Thompson, Roger Levy, and Christopher D. Manning. 2003. A generative model for semanrole labeling. In of the Eu- Conference on Machine ECML 2003, pages 397–408, Dubrovnik, Croatia. Ivan Titov and Alexandre Klementiev. 2012a. A Bayesian approach to unsupervised semantic role in- In of European Chapter of the Assofor Computational Linguistics Ivan Titov and Alexandre Klementiev. 2012b. Semisupervised semantic role labeling: Approaching an unsupervised perspective. In of the International Conference on Computational Bombay, India, December. Sara Tonelli and Emanuele Pianta. 2008. Frame infortransfer from English to Italian. In Proceedof LREC Lonneke van der Plas, James Henderson, and Paola Merlo. 2009. Domain adaptation with artificial for semantic parsing of speech. In 2009 Annual Conference of the North American Chapof the Association for Computational pages 125–128, Boulder, Colorado. Lonneke van der Plas, Paola Merlo, and James Henderson. 2011. Scaling up automatic cross-lingual role annotation. In of the Annual Meeting of the Association for Computa- Linguistics: Human Language HLT ’11, pages 299–304, Stroudsburg, PA, USA. Association for Computational Linguistics. Alina Wr´oblewska and Anette Frank. 2009. Crosslingual projection of LFG F-structures: Building F-structure bank for Polish. In International Workshop on Treebanks and Linguistic Theopage 209. Dekai Wu and Pascale Fung. 2009. Can semantic</note>
<title confidence="0.883283">labeling improve SMT? In of Annual Conference of the European Association for Translation (EAMT Barcelona.</title>
<author confidence="0.908562">A backoff</author>
<affiliation confidence="0.758815">model for bootstrapping resources for non-English In of the conference on Human Language Technology and Empirical Methods</affiliation>
<address confidence="0.758732">Natural Language pages 851–858, Stroudsburg, PA, USA.</address>
<note confidence="0.798066">David Yarowsky, Grace Ngai, and Ricahrd Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of Human Language Technology Con- Daniel Zeman and Philip Resnik. 2008. Crosslanguage parser adaptation between related lan- In of the IJCNLP-08 Workshop NLP for Less Privileged pages 35– 42, Hyderabad, India, January. Asian Federation of Natural Language Processing. Imed Zitouni and Radu Florian. 2008. Mention deteccrossing the language barrier. In of the Conference on Empirical Methods in Natural 1200</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Omri Abend</author>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>Unsupervised argument identification for semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, ACL ’09,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="23771" citStr="Abend et al., 2009" startWordPosition="3884" endWordPosition="3887">the transferred system by 3% (Fl) on this task. Setup Syntax TRANS PROJ EN-ZH trans 34.5 13.9 ZH-EN trans 32.6 15.6 EN-CZ trans 46.3 12.4 CZ-EN trans 42.3 22.2 EN-FR trans 61.6 43.5 EN-ZH orig 51.7 19.6 ZH-EN orig 53.2 29.7 EN-CZ orig 63.9 59.3 CZ-EN orig 67.3 60.9 EN-FR orig 71.0 51.3 Table 3: Argument identification, transferred model vs. projection baseline, Fl. Most unsupervised SRL approaches assume that the argument identification is performed by some external means, for example heuristically (Lang and Lapata, 2011). Such heuristics or unsupervised approaches to argument identification (Abend et al., 2009) can also be used in the present setup. 5.2 Argument Classification In the following tables, TRANS column contains the results for the transferred system, UNSUP – for the unsupervised baseline and PROJ – for projection baseline. We highlight in bold the higher score where the difference exceeds twice the maximum of the standard deviation estimates of the two results. Table 4 presents the unsupervised evaluation results. Note that the unsupervised model performs as well as the transferred one or better where the Setup Syntax TRANS UNSUP EN-ZH trans 83.3 73.9 ZH-EN trans 79.2 67.6 EN-CZ trans 66</context>
</contexts>
<marker>Abend, Reichart, Rappoport, 2009</marker>
<rawString>Omri Abend, Roi Reichart, and Ari Rappoport. 2009. Unsupervised argument identification for semantic role labeling. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, ACL ’09, pages 28–36, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Annesi</author>
<author>Roberto Basili</author>
</authors>
<title>Cross-lingual alignment of FrameNet annotations through hidden Markov models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th international conference on Computational Linguistics and Intelligent Text Processing, CICLing’10,</booktitle>
<pages>12--25</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="30039" citStr="Annesi and Basili, 2010" startWordPosition="4912" endWordPosition="4915">rther refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-ling</context>
</contexts>
<marker>Annesi, Basili, 2010</marker>
<rawString>Paolo Annesi and Roberto Basili. 2010. Cross-lingual alignment of FrameNet annotations through hidden Markov models. In Proceedings of the 11th international conference on Computational Linguistics and Intelligent Text Processing, CICLing’10, pages 12– 25, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Diego De Cao</author>
<author>Danilo Croce</author>
<author>Bonaventura Coppola</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Cross-language frame semantics transfer in bilingual corpora.</title>
<date>2009</date>
<booktitle>Proceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>332--345</pages>
<editor>In Alexander F. Gelbukh, editor,</editor>
<marker>Basili, De Cao, Croce, Coppola, Moschitti, 2009</marker>
<rawString>Roberto Basili, Diego De Cao, Danilo Croce, Bonaventura Coppola, and Alessandro Moschitti. 2009. Cross-language frame semantics transfer in bilingual corpora. In Alexander F. Gelbukh, editor, Proceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing, pages 332–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>43--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 43–48, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="13273" citStr="Chang et al., 2007" startWordPosition="2156" endWordPosition="2159">l., 2008). The feature model was modified to accommodate the cross-lingual cluster features and the reranker component was not used. We do not model the interaction between different argument roles in the same predicate. While this has been found useful, in the cross-lingual setup one has to be careful with the assumptions made. For example, modeling the sequence of roles using a Markov chain (Thompson et al., 2003) may not work well in the present setting, especially between distant languages, as the order or arguments is not necessarily preserved. Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on languagespecific resources, such as a valency lexicon. Taking into account the interaction between different arguments of a predicate is likely to improve the performance of the transferred model, but this is outside the scope of this work. 3.4 Feature Selection Compatibility of feature representations is necessary but not sufficient for successful model transfer. We have to make sure that the features we use are predictive of similar outcomes in the two languages as well. Depending on the pair of languages in questio</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven learning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhua Chen</author>
<author>Alexis Palmer</author>
<author>Caroline Sporleder</author>
</authors>
<title>Enhancing active learning for semantic role labeling via compressed dependency trees.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>183--191</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="29542" citStr="Chen et al., 2011" startWordPosition="4838" endWordPosition="4841"> in terms of the metric considered. This is likely due to the fact that we consider only the core roles, which can usually be predicted with high accuracy based on syntactic information alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and E</context>
</contexts>
<marker>Chen, Palmer, Sporleder, 2011</marker>
<rawString>Chenhua Chen, Alexis Palmer, and Caroline Sporleder. 2011. Enhancing active learning for semantic role labeling via compressed dependency trees. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 183–191, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29730" citStr="Das and Petrov, 2011" startWordPosition="4867" endWordPosition="4870"> alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and mode</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Syntactic transfer using a bilingual lexicon.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1--11</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="30483" citStr="Durrett et al., 2012" startWordPosition="4983" endWordPosition="4986">an, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed differently in the languag</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntactic transfer using a bilingual lexicon. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1–11, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Eisele</author>
<author>Yu Chen</author>
</authors>
<title>MultiUN: A multilingual corpus from United Nation documents.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10). European Language Resources Association (ELRA).</booktitle>
<contexts>
<context position="19107" citStr="Eisele and Chen, 2010" startWordPosition="3122" endWordPosition="3125">art-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the original mappings were derived. Namely, tag “t” is mapped to “VERB” and “Y” – to “PRON”. We use parallel data to construct a bilingual dictionary used in word mapping, as well as in the projection baseline. For English-Czech see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011),</context>
</contexts>
<marker>Eisele, Chen, 2010</marker>
<rawString>Andreas Eisele and Yu Chen. 2010. MultiUN: A multilingual corpus from United Nation documents. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10). European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="12663" citStr="Fan et al., 2008" startWordPosition="2057" endWordPosition="2060"> even there, but this does not appear to be the case with the datasets we use for evaluation. If a target language is poor in resources, one can obtain a dependency parser for the target language by means of cross-lingual model transfer (Zeman and Resnik, 2008). We max |Gj ∩ Ci| j max |Gj ∩ Ci|, i 1192 take this into account and evaluate both using the original dependency structures and the ones obtained by means of cross-lingual model transfer. 3.3 The Model The model we use is based on that of Bj¨orkelund et al. (2009). It is comprised of a set of linear classifiers trained using Liblinear (Fan et al., 2008). The feature model was modified to accommodate the cross-lingual cluster features and the reranker component was not used. We do not model the interaction between different argument roles in the same predicate. While this has been found useful, in the cross-lingual setup one has to be careful with the assumptions made. For example, modeling the sequence of roles using a Markov chain (Thompson et al., 2003) may not work well in the present setting, especially between distant languages, as the order or arguments is not necessarily preserved. Most constraints that prove useful for SRL (Chang et </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL,</booktitle>
<pages>369--377</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="30129" citStr="Ganchev et al., 2009" startWordPosition="4927" endWordPosition="4930">Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for exampl</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the 47th Annual Meeting of the ACL, pages 369–377, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Corpus expansion for statistical machine translation with semantic role label substitution rules.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>294--298</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="1192" citStr="Gao and Vogel, 2011" startWordPosition="173" endWordPosition="176">g competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages have been proposed. On one end of the scale is unsupervised SRL, such as Grenager and </context>
</contexts>
<marker>Gao, Vogel, 2011</marker>
<rawString>Qin Gao and Stephan Vogel. 2011. Corpus expansion for statistical machine translation with semantic role label substitution rules. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 294–298, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Unsupervised discovery of a statistical verb lexicon.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1806" citStr="Grenager and Manning (2006)" startWordPosition="280" endWordPosition="283"> Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages have been proposed. On one end of the scale is unsupervised SRL, such as Grenager and Manning (2006), which requires some expert knowledge, but no labeled data. It clusters together arguments that should bear the same semantic role, but does not assign a particular role to each cluster. On the other end is annotating a new dataset from scratch. There are also intermediate options, which often make use of similarities between languages. This way, if an accurate model exists for one language, it should help simplify the construction of a model for another, related language. The approaches in this third group often use parallel data to bridge the gap between languages. Cross-lingual annotation </context>
</contexts>
<marker>Grenager, Manning, 2006</marker>
<rawString>Trond Grenager and Christopher D. Manning. 2006. Unsupervised discovery of a statistical verb lexicon. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Tectogrammatical representation: Towards a minimal transfer in machine translation.</title>
<date>2002</date>
<booktitle>Proceedings of the 6th International Workshop on Tree Adjoining Grammars and Related Frameworks (TAG+6),</booktitle>
<pages>216--226</pages>
<editor>In Robert Frank, editor,</editor>
<marker>Hajiˇc, 2002</marker>
<rawString>Jan Hajiˇc. 2002. Tectogrammatical representation: Towards a minimal transfer in machine translation. In Robert Frank, editor, Proceedings of the 6th International Workshop on Tree Adjoining Grammars and Related Frameworks (TAG+6), pages 216— 226, Venezia. Universita di Venezia.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajic</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan Step´anek</author>
<author>Pavel Stran´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>1--18</pages>
<location>Boulder, Colorado.</location>
<marker>Hajic, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, Step´anek, Stran´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Haji&amp;quot;c, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan &amp;quot;St&amp;quot;ep´anek, Pavel Stra&amp;quot;n´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 1–18, Boulder, Colorado.</rawString>
</citation>
<citation valid="false">
<title>Ure&amp;quot;sov´a, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y.</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>Jan Haji&amp;quot;c, Eva Haji&amp;quot;cov´a, Jarmila Panevov´a, Petr Sgall, Ond&amp;quot;rej Bojar, Silvie Cinkov´a, Eva Fu&amp;quot;c´ıkov´a, Marie Mikulov´a, Petr Pajas, Jan Popelka, Ji&amp;quot;r´ı Semeck´y, Jana &amp;quot;Sindlerov´a, Jan &amp;quot;St&amp;quot;ep´anek, Josef Toman, Zde&amp;quot;nka</editor>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="3133" citStr="(2012)" startWordPosition="493" endWordPosition="493">r, they are very sensitive to the quality of parallel data, as well as the accuracy of a sourcelanguage model on it. An alternative approach, known as cross-lingual model transfer, or cross-lingual model adaptation, consists of modifying a source-language model to make it directly applicable to a new language. This usually involves constructing a shared feature representation across the two languages. McDonald et al. (2011) successfully apply this idea to the transfer of dependency parsers, using part-ofspeech tags as the shared representation of words. A later extension of T¨ackstr¨om et al. (2012) enriches this representation with cross-lingual word clusters, considerably improving the performance. In the case of SRL, a shared representation that is purely syntactic is likely to be insufficient, since structures with different semantics may be realized by the same syntactic construct, for example “in August” vs “in Britain”. However with the help of recently introduced cross-lingual word represen1190 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1190–1200, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics</context>
<context position="10476" citStr="(2012)" startWordPosition="1707" endWordPosition="1707">ce. The mapping (bilingual dictionary) we use is derived from a word-aligned parallel corpus, by identifying, for each word in the target language, the word in the source language it is most often aligned to. Cross-lingual clusters. There is no guarantee that each of the words in the evaluation data is present in our dictionary, nor that the corresponding source-language word is present in the training data, so the model would benefit from the ability to generalize over closely related words. This can, for example, be achieved by using cross-lingual word clusters induced in T¨ackstr¨om et al. (2012). We incorporate these clusters as features into our model. 3.2 Syntactic Information Part-of-speech Tags. We map part-of-speech tags into the universal tagset following Petrov et al. (2012). This may have a negative effect on the performance of a monolingual model, since most part-of-speech tagsets are more fine-grained than the universal POS tags considered here. For example Penn Treebank inventory contains 36 tags and the universal POS tagset – only 12. Since the finergrained POS tags often reflect more languagespecific phenomena, however, they would only be useful for very closely related </context>
<context position="18585" citStr="(2012)" startWordPosition="3042" endWordPosition="3042"> the Europarl (Koehn, 2005) corpus, annotated with semantic roles following an adapted version of PropBank (Palmer et al., 2005) guidelines. The authors perform annotation projection from English to French, using a joint model of syntax and semantics and employing heuristics for filtering. We use a model trained on the output of this projection system as one of the baselines. The evaluation dataset is relatively small in this case, so we perform the transfer only one-way, from English to French. The part-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the original mappings were derived. Namely, tag “t” is mapped to “VERB” and “Y” – to “PRON”. We use parallel data to construct a bilingual dictionary used in word mapping, as well as in the projection baseline. For English-Czech see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the i</context>
</contexts>
<marker>2012</marker>
<rawString>Jan Haji&amp;quot;c, Eva Haji&amp;quot;cov´a, Jarmila Panevov´a, Petr Sgall, Ond&amp;quot;rej Bojar, Silvie Cinkov´a, Eva Fu&amp;quot;c´ıkov´a, Marie Mikulov´a, Petr Pajas, Jan Popelka, Ji&amp;quot;r´ı Semeck´y, Jana &amp;quot;Sindlerov´a, Jan &amp;quot;St&amp;quot;ep´anek, Josef Toman, Zde&amp;quot;nka Ure&amp;quot;sov´a, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y. 2012. Announcing Prague Czech-English dependency treebank 2.0. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U&amp;quot;gur Do&amp;quot;gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel text.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="30172" citStr="Hwa et al., 2005" startWordPosition="4935" endWordPosition="4938">al annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial compon</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel text. Natural Language Engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based semantic role labeling of PropBank.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>69--78</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="5841" citStr="Johansson and Nugues, 2008" startWordPosition="921" endWordPosition="924"> alternatives and identify its strong/weak points depending on a particular setup. 2.1 Semantic Role Labeling Model We consider the dependency-based version of semantic role labeling as described in Hajiˇc et al. (2009) and transfer an SRL model from one language to another. We only consider verbal predicates and ignore the predicate disambiguation stage. We also assume that the predicate identification information is available – in most languages it can be obtained using a relatively simple heuristic based on part-of-speech tags. The model performs argument identification and classification (Johansson and Nugues, 2008) separately in a pipeline – first each candidate is classified as being or not being a head of an argument phrase with respect to the predicate in question and then each of the arguments is assigned a role from a given inventory. The model is factorized over arguments – the decisions regarding the classification of different arguments are made independently of each other. With respect to the use of syntactic annotation we consider two options: using an existing dependency parser for the target language and obtaining one by means of cross-lingual transfer (see section 4.2). Following McDonald e</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based semantic role labeling of PropBank. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 69–78, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaisser</author>
<author>Bonnie Webber</author>
</authors>
<title>Question answering based on semantic roles.</title>
<date>2007</date>
<booktitle>In ACL Workshop on Deep Linguistic Processing.</booktitle>
<contexts>
<context position="1065" citStr="Kaisser and Webber, 2007" startWordPosition="153" endWordPosition="156">one language to another using a shared feature representation. This approach is then evaluated on three language pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semanti</context>
</contexts>
<marker>Kaisser, Webber, 2007</marker>
<rawString>Michael Kaisser and Bonnie Webber. 2007. Question answering based on semantic roles. In ACL Workshop on Deep Linguistic Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seokhwan Kim</author>
<author>Minwoo Jeong</author>
<author>Jonghoon Lee</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>A cross-lingual annotation projection approach for relation detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>564--571</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29958" citStr="Kim et al., 2010" startWordPosition="4897" endWordPosition="4900">. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attentio</context>
</contexts>
<marker>Kim, Jeong, Lee, Lee, 2010</marker>
<rawString>Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, and Gary Geunbae Lee. 2010. A cross-lingual annotation projection approach for relation detection. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 564–571, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Propbanking in parallel. In</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on the Amazing Utility of Parallel and Comparable Corpora, in conjunction with LREC’04.</booktitle>
<contexts>
<context position="17099" citStr="Kingsbury et al., 2004" startWordPosition="2786" endWordPosition="2789">del transfer requires a rather specific kind of dataset. Namely, the data in both languages has to be annotated 1193 with the same set of semantic roles following the same (or compatible) guidelines, which is seldom the case. We have identified three language pairs for which such resources are available: EnglishChinese, English-Czech and English-French. The evaluation datasets for English and Chinese are those from the CoNLL Shared Task 2009 (Hajiˇc et al., 2009) (henceforth CoNLL-ST). Their annotation in the CoNLL-ST is not identical, but the guidelines for “core” semantic roles are similar (Kingsbury et al., 2004), so we evaluate only on core roles here. The data for the second language pair is drawn from the Prague Czech-English Dependency Treebank 2.0 (Hajiˇc et al., 2012), which we converted to a format similar to that of CoNLL-ST1. The original annotation uses the tectogrammatical representation (Hajiˇc, 2002) and an inventory of semantic roles (or functors), most of which are interpretable across various predicates. Also note that the syntactic annotation of English and Czech in PCEDT 2.0 is quite similar (to the extent permitted by the difference in the structure of the two languages) and we can </context>
</contexts>
<marker>Kingsbury, Xue, Palmer, 2004</marker>
<rawString>Paul Kingsbury, Nianwen Xue, and Martha Palmer. 2004. Propbanking in parallel. In In Proceedings of the Workshop on the Amazing Utility of Parallel and Comparable Corpora, in conjunction with LREC’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ivan Titov</author>
<author>Binod Bhattarai</author>
</authors>
<title>Inducing crosslingual distributed representations of words.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<location>Bombay, India.</location>
<contexts>
<context position="3873" citStr="Klementiev et al. (2012)" startWordPosition="594" endWordPosition="597">of SRL, a shared representation that is purely syntactic is likely to be insufficient, since structures with different semantics may be realized by the same syntactic construct, for example “in August” vs “in Britain”. However with the help of recently introduced cross-lingual word represen1190 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1190–1200, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics tations, such as the cross-lingual clustering mentioned above or cross-lingual distributed word representations of Klementiev et al. (2012), we may be able to transfer models of shallow semantics in a similar fashion. In this work we construct a shared feature representation for a pair of languages, employing crosslingual representations of syntactic and lexical information, train a semantic role labeling model on one language and apply it to the other one. This approach yields an SRL model for a new language at a very low cost, effectively requiring only a source language model and parallel data. We evaluate on five (directed) language pairs – EN-ZH, ZH-EN, EN-CZ, CZ-EN and EN-FR, where EN, FR, CZ and ZH denote English, French, </context>
<context position="30936" citStr="Klementiev et al., 2012" startWordPosition="5055" endWordPosition="5058">ween old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed differently in the languages considered, for example the syntactic function of a certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-</context>
</contexts>
<marker>Klementiev, Titov, Bhattarai, 2012</marker>
<rawString>Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. 2012. Inducing crosslingual distributed representations of words. In Proceedings of the International Conference on Computational Linguistics (COLING), Bombay, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Conference Proceedings: the tenth Machine Translation Summit,</booktitle>
<pages>79--86</pages>
<publisher>AAMT.</publisher>
<location>Phuket, Thailand.</location>
<contexts>
<context position="18006" citStr="Koehn, 2005" startWordPosition="2941" endWordPosition="2942">jiˇc, 2002) and an inventory of semantic roles (or functors), most of which are interpretable across various predicates. Also note that the syntactic annotation of English and Czech in PCEDT 2.0 is quite similar (to the extent permitted by the difference in the structure of the two languages) and we can use the dependency relations in our experiments. For English-French, the English CoNLL-ST dataset was used as a source and the model was evaluated on the manually annotated dataset from van der Plas et al. (2011). The latter contains one thousand sentences from the French part of the Europarl (Koehn, 2005) corpus, annotated with semantic roles following an adapted version of PropBank (Palmer et al., 2005) guidelines. The authors perform annotation projection from English to French, using a joint model of syntax and semantics and employing heuristics for filtering. We use a model trained on the output of this projection system as one of the baselines. The evaluation dataset is relatively small in this case, so we perform the transfer only one-way, from English to French. The part-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have </context>
<context position="28016" citStr="Koehn, 2005" startWordPosition="4590" endWordPosition="4591"> we already mentioned, the original syntactic annotation is also produced automatically. Secondly, in the model transfer setup it is more important how closely the syntacticsemantic interface on the target side resembles that on the source side than how well it matches the “true” structure of the target language, and in this respect a transferred dependency parser may have an advantage over one trained on target-language data. The high impact of the Gloss features here 1196 may be partly attributed to the fact that the mapping is derived from the same corpus as the evaluation data – Europarl (Koehn, 2005) – and partly by the similarity between English and French in terms of word order, usage of articles and prepositions. The moderate contribution of the crosslingual cluster features are likely due to the insufficient granularity of the clustering for this task. For more distant language pairs, the contributions of individual feature groups are less interpretable, so we only highlight a few observations. First of all, both EN-CZ and CZ-EN benefit noticeably from the use of the original syntactic annotation, including dependency relations, but not from the transferred syntax, most likely due to </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Conference Proceedings: the tenth Machine Translation Summit, pages 79–86, Phuket, Thailand. AAMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised induction of semantic roles.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>939--947</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="6732" citStr="Lang and Lapata, 2010" startWordPosition="1074" endWordPosition="1077">– the decisions regarding the classification of different arguments are made independently of each other. With respect to the use of syntactic annotation we consider two options: using an existing dependency parser for the target language and obtaining one by means of cross-lingual transfer (see section 4.2). Following McDonald et al. (2011), we assume that a part-of-speech tagger is available for the target language. 2.2 SRL in the Low-resource Setting Several approaches have been proposed to obtain an SRL model for a new language with little or no manual annotation. Unsupervised SRL models (Lang and Lapata, 2010) cluster the arguments of predicates in a given corpus according to their semantic roles. The performance of such models can be impressive, especially for those languages where semantic roles correlate strongly with syntactic relation of the argument to its predicate. However, assigning meaningful role labels to the resulting clusters requires additional effort and the model’s parameters generally need some adjustment for every language. If the necessary resources are already available for a closely related language, they can be utilized to facilitate the construction of a model for the target</context>
<context position="31712" citStr="Lang and Lapata, 2010" startWordPosition="5181" endWordPosition="5184">dered, for example the syntactic function of a certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heurist</context>
</contexts>
<marker>Lang, Lapata, 2010</marker>
<rawString>Joel Lang and Mirella Lapata. 2010. Unsupervised induction of semantic roles. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 939–947, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised semantic role induction via split-merge clustering.</title>
<date>2011</date>
<booktitle>In Proc. of Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="8268" citStr="Lang and Lapata, 2011" startWordPosition="1337" endWordPosition="1340"> be further referred to as UNSUP and the projection baseline as PROJ. 2.3 Evaluation Measures We use the F1 measure as a metric for the argument identification stage and accuracy as an aggregate measure of argument classification performance. When comparing to the unsupervised SRL system the clustering evaluation measures are used instead. These are purity and collocation 1191 1 � P U = N i 1 � CO = N j where Ci is the set of arguments in the i-th induced cluster, Gj is the set of arguments in the jth gold cluster and N is the total number of arguments. We report the harmonic mean of the two (Lang and Lapata, 2011) and denote it F1c to avoid confusing it with the supervised metric. 3 Model Transfer The idea of this work is to abstract the model away from the particular source language and apply it to a new one. This setup requires that we use the same feature representation for both languages, for example part-of-speech tags and dependency relation labels should be from the same inventory. Some features are not applicable to certain languages because the corresponding phenomena are absent in them. For example, consider a strongly inflected language and an analytic one. While the latter can usually conve</context>
<context position="23679" citStr="Lang and Lapata, 2011" startWordPosition="3871" endWordPosition="3874">del of (van der Plas et al., 2011), though relying on more expressive syntax, only outperforms the transferred system by 3% (Fl) on this task. Setup Syntax TRANS PROJ EN-ZH trans 34.5 13.9 ZH-EN trans 32.6 15.6 EN-CZ trans 46.3 12.4 CZ-EN trans 42.3 22.2 EN-FR trans 61.6 43.5 EN-ZH orig 51.7 19.6 ZH-EN orig 53.2 29.7 EN-CZ orig 63.9 59.3 CZ-EN orig 67.3 60.9 EN-FR orig 71.0 51.3 Table 3: Argument identification, transferred model vs. projection baseline, Fl. Most unsupervised SRL approaches assume that the argument identification is performed by some external means, for example heuristically (Lang and Lapata, 2011). Such heuristics or unsupervised approaches to argument identification (Abend et al., 2009) can also be used in the present setup. 5.2 Argument Classification In the following tables, TRANS column contains the results for the transferred system, UNSUP – for the unsupervised baseline and PROJ – for projection baseline. We highlight in bold the higher score where the difference exceeds twice the maximum of the standard deviation estimates of the two results. Table 4 presents the unsupervised evaluation results. Note that the unsupervised model performs as well as the transferred one or better w</context>
<context position="31735" citStr="Lang and Lapata, 2011" startWordPosition="5185" endWordPosition="5188">syntactic function of a certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heuristics, provided an accura</context>
</contexts>
<marker>Lang, Lapata, 2011</marker>
<rawString>Joel Lang and Mirella Lapata. 2011. Unsupervised semantic role induction via split-merge clustering. In Proc. of Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="1170" citStr="Liu and Gildea, 2010" startWordPosition="169" endWordPosition="172">ge pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages have been proposed. On one end of the scale is unsupervised SRL,</context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic role features for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
<author>Daniel Zeman</author>
<author>Michael Nossal</author>
<author>Philip Resnik</author>
<author>Rebecca Hwa</author>
</authors>
<title>Cross-language parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In IJCNLP-08 Workshop on NLP for Less Privileged Languages,</booktitle>
<pages>35--42</pages>
<location>Hyderabad, India,</location>
<contexts>
<context position="30519" citStr="Lopez et al., 2008" startWordPosition="4989" endWordPosition="4992">nd Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed differently in the languages considered, for example the synta</context>
</contexts>
<marker>Lopez, Zeman, Nossal, Resnik, Hwa, 2008</marker>
<rawString>Adam Lopez, Daniel Zeman, Michael Nossal, Philip Resnik, and Rebecca Hwa. 2008. Cross-language parser adaptation between related languages. In IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 35–42, Hyderabad, India, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandra Lorenzo</author>
<author>Christophe Cerisara</author>
</authors>
<title>Unsupervised frame based semantic role induction: application to French and English.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,</booktitle>
<pages>30--35</pages>
<institution>Korea, July. Association for Computational Linguistics.</institution>
<location>Jeju, Republic of</location>
<contexts>
<context position="31793" citStr="Lorenzo and Cerisara, 2012" startWordPosition="5193" endWordPosition="5196">d by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heuristics, provided an accurate model is available for one of the related languages alo</context>
</contexts>
<marker>Lorenzo, Cerisara, 2012</marker>
<rawString>Alejandra Lorenzo and Christophe Cerisara. 2012. Unsupervised frame based semantic role induction: application to French and English. In Proceedings of the ACL 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages, pages 30–35, Jeju, Republic of Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>62--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2954" citStr="McDonald et al. (2011)" startWordPosition="461" endWordPosition="465">rallel data to bridge the gap between languages. Cross-lingual annotation projection systems (Pad´o and Lapata, 2009), for example, propagate information directly via word alignment links. However, they are very sensitive to the quality of parallel data, as well as the accuracy of a sourcelanguage model on it. An alternative approach, known as cross-lingual model transfer, or cross-lingual model adaptation, consists of modifying a source-language model to make it directly applicable to a new language. This usually involves constructing a shared feature representation across the two languages. McDonald et al. (2011) successfully apply this idea to the transfer of dependency parsers, using part-ofspeech tags as the shared representation of words. A later extension of T¨ackstr¨om et al. (2012) enriches this representation with cross-lingual word clusters, considerably improving the performance. In the case of SRL, a shared representation that is purely syntactic is likely to be insufficient, since structures with different semantics may be realized by the same syntactic construct, for example “in August” vs “in Britain”. However with the help of recently introduced cross-lingual word represen1190 Proceedin</context>
<context position="6453" citStr="McDonald et al. (2011)" startWordPosition="1027" endWordPosition="1030">ues, 2008) separately in a pipeline – first each candidate is classified as being or not being a head of an argument phrase with respect to the predicate in question and then each of the arguments is assigned a role from a given inventory. The model is factorized over arguments – the decisions regarding the classification of different arguments are made independently of each other. With respect to the use of syntactic annotation we consider two options: using an existing dependency parser for the target language and obtaining one by means of cross-lingual transfer (see section 4.2). Following McDonald et al. (2011), we assume that a part-of-speech tagger is available for the target language. 2.2 SRL in the Low-resource Setting Several approaches have been proposed to obtain an SRL model for a new language with little or no manual annotation. Unsupervised SRL models (Lang and Lapata, 2010) cluster the arguments of predicates in a given corpus according to their semantic roles. The performance of such models can be impressive, especially for those languages where semantic roles correlate strongly with syntactic relation of the argument to its predicate. However, assigning meaningful role labels to the res</context>
<context position="19577" citStr="McDonald et al. (2011)" startWordPosition="3199" endWordPosition="3202">/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011), using Malt parser (Nivre, 2008) and the same set of features. We did not reimplement the projected transfer algorithm, however, and used the default training procedure instead of perceptron-based learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent difference in their structure</context>
<context position="30437" citStr="McDonald et al., 2011" startWordPosition="4974" endWordPosition="4978">l., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 62–72, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
<author>Vivian Tsang</author>
<author>Gianluca Allaria</author>
</authors>
<title>A multi-lingual paradigm for automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02),</booktitle>
<pages>207--214</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="29825" citStr="Merlo et al., 2002" startWordPosition="4879" endWordPosition="4882">ng problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald </context>
</contexts>
<marker>Merlo, Stevenson, Tsang, Allaria, 2002</marker>
<rawString>Paola Merlo, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multi-lingual paradigm for automatic verb classification. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02), pages 207– 214, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Meyer</author>
</authors>
<title>New wine in old wineskins?– Tagging old Russian via annotation projection from modern translations.</title>
<date>2011</date>
<journal>Russian Linguistics,</journal>
<volume>35</volume>
<issue>2</issue>
<contexts>
<context position="30376" citStr="Meyer, 2011" startWordPosition="4968" endWordPosition="4969">and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both wo</context>
</contexts>
<marker>Meyer, 2011</marker>
<rawString>Roland Meyer. 2011. New wine in old wineskins?– Tagging old Russian via annotation projection from modern translations. Russian Linguistics, 35(2):267(15).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
<author>Amir Globerson</author>
</authors>
<title>Selective sharing for multilingual dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>629--637</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="30107" citStr="Naseem et al., 2012" startWordPosition="4923" endWordPosition="4926"> as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data </context>
</contexts>
<marker>Naseem, Barzilay, Globerson, 2012</marker>
<rawString>Tahira Naseem, Regina Barzilay, and Amir Globerson. 2012. Selective sharing for multilingual dependency parsing. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 629–637, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="19739" citStr="Nivre, 2008" startWordPosition="3228" endWordPosition="3229">s were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011), using Malt parser (Nivre, 2008) and the same set of features. We did not reimplement the projected transfer algorithm, however, and used the default training procedure instead of perceptron-based learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent difference in their structure. The scores are shown in table 2. We will henceforth refer to the syntactic annotations that were provided with the datasets as original, as opposed to the annot</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Comput. Linguist., 34(4):513–553, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="19175" citStr="Och and Ney, 2003" startWordPosition="3133" endWordPosition="3136">tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the original mappings were derived. Namely, tag “t” is mapped to “VERB” and “Y” – to “PRON”. We use parallel data to construct a bilingual dictionary used in word mapping, as well as in the projection baseline. For English-Czech see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011), using Malt parser (Nivre, 2008) and the same set of features. We di</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Crosslingual annotation projection for semantic roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>36</volume>
<pages>340</pages>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Crosslingual annotation projection for semantic roles. Journal of Artificial Intelligence Research, 36:307– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--71</pages>
<contexts>
<context position="18107" citStr="Palmer et al., 2005" startWordPosition="2956" endWordPosition="2959"> across various predicates. Also note that the syntactic annotation of English and Czech in PCEDT 2.0 is quite similar (to the extent permitted by the difference in the structure of the two languages) and we can use the dependency relations in our experiments. For English-French, the English CoNLL-ST dataset was used as a source and the model was evaluated on the manually annotated dataset from van der Plas et al. (2011). The latter contains one thousand sentences from the French part of the Europarl (Koehn, 2005) corpus, annotated with semantic roles following an adapted version of PropBank (Palmer et al., 2005) guidelines. The authors perform annotation projection from English to French, using a joint model of syntax and semantics and employing heuristics for filtering. We use a model trained on the output of this projection system as one of the baselines. The evaluation dataset is relatively small in this case, so we perform the transfer only one-way, from English to French. The part-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the o</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31:71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC,</booktitle>
<contexts>
<context position="10666" citStr="Petrov et al. (2012)" startWordPosition="1731" endWordPosition="1734">age it is most often aligned to. Cross-lingual clusters. There is no guarantee that each of the words in the evaluation data is present in our dictionary, nor that the corresponding source-language word is present in the training data, so the model would benefit from the ability to generalize over closely related words. This can, for example, be achieved by using cross-lingual word clusters induced in T¨ackstr¨om et al. (2012). We incorporate these clusters as features into our model. 3.2 Syntactic Information Part-of-speech Tags. We map part-of-speech tags into the universal tagset following Petrov et al. (2012). This may have a negative effect on the performance of a monolingual model, since most part-of-speech tagsets are more fine-grained than the universal POS tags considered here. For example Penn Treebank inventory contains 36 tags and the universal POS tagset – only 12. Since the finergrained POS tags often reflect more languagespecific phenomena, however, they would only be useful for very closely related languages in the cross-lingual setting. The universal part-of-speech tags used in evaluation are derived from gold-standard annotation for all languages except French, where predicted ones h</context>
<context position="18585" citStr="Petrov et al. (2012)" startWordPosition="3039" endWordPosition="3042">French part of the Europarl (Koehn, 2005) corpus, annotated with semantic roles following an adapted version of PropBank (Palmer et al., 2005) guidelines. The authors perform annotation projection from English to French, using a joint model of syntax and semantics and employing heuristics for filtering. We use a model trained on the output of this projection system as one of the baselines. The evaluation dataset is relatively small in this case, so we perform the transfer only one-way, from English to French. The part-of-speech tags in all datasets were replaced with the universal POS tags of Petrov et al. (2012). For Czech, we have augmented the mappings to account for the tags that were not present in the datasets from which the original mappings were derived. Namely, tag “t” is mapped to “VERB” and “Y” – to “PRON”. We use parallel data to construct a bilingual dictionary used in word mapping, as well as in the projection baseline. For English-Czech see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the i</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of LREC, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sammons</author>
<author>Vinod Vydiswaran</author>
<author>Tim Vieira</author>
<author>Nikhil Johri</author>
</authors>
<title>Ming wei Chang, Dan Goldwasser, Vivek Srikumar, Gourab Kundu,</title>
<date>2009</date>
<booktitle>In Text Analysis Conference (TAC).</booktitle>
<location>Yuancheng Tu, Kevin Small, Joshua Rule, Quang</location>
<contexts>
<context position="1108" citStr="Sammons et al., 2009" startWordPosition="159" endWordPosition="162">representation. This approach is then evaluated on three language pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages ha</context>
</contexts>
<marker>Sammons, Vydiswaran, Vieira, Johri, 2009</marker>
<rawString>Mark Sammons, Vinod Vydiswaran, Tim Vieira, Nikhil Johri, Ming wei Chang, Dan Goldwasser, Vivek Srikumar, Gourab Kundu, Yuancheng Tu, Kevin Small, Joshua Rule, Quang Do, and Dan Roth. 2009. Relation alignment for textual entailment recognition. In Text Analysis Conference (TAC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>Active learning literature survey.</title>
<date>2010</date>
<journal>Computer Sciences</journal>
<tech>Technical Report, 1648.</tech>
<contexts>
<context position="29522" citStr="Settles, 2010" startWordPosition="4836" endWordPosition="4837"> an improvement in terms of the metric considered. This is likely due to the fact that we consider only the core roles, which can usually be predicted with high accuracy based on syntactic information alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al</context>
</contexts>
<marker>Settles, 2010</marker>
<rawString>Burr Settles. 2010. Active learning literature survey. Computer Sciences Technical Report, 1648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Mirella Lapata</author>
</authors>
<title>Using semantic roles to improve question answering.</title>
<date>2007</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1038" citStr="Shen and Lapata, 2007" startWordPosition="149" endWordPosition="152">ring an SRL model from one language to another using a shared feature representation. This approach is then evaluated on three language pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to </context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>Dan Shen and Mirella Lapata. 2007. Using semantic roles to improve question answering. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Parser adaptation and projection with quasi-synchronous grammar features.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>822--831</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30153" citStr="Smith and Eisner, 2009" startWordPosition="4931" endWordPosition="4934"> al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011</context>
</contexts>
<marker>Smith, Eisner, 2009</marker>
<rawString>David A Smith and Jason Eisner. 2009. Parser adaptation and projection with quasi-synchronous grammar features. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 822–831. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Crosslingual propagation for morphological analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the 23rd national conference on Artificial intelligence.</booktitle>
<contexts>
<context position="29783" citStr="Snyder and Barzilay, 2008" startWordPosition="4873" endWordPosition="4876">tistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross</context>
</contexts>
<marker>Snyder, Barzilay, 2008</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2008. Crosslingual propagation for morphological analysis. In Proceedings of the 23rd national conference on Artificial intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Data point selection for crosslanguage adaptation of dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<volume>2</volume>
<pages>682--686</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="30498" citStr="Søgaard, 2011" startWordPosition="4987" endWordPosition="4988"> (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed differently in the languages considered, </context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Data point selection for crosslanguage adaptation of dependency parsers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 2 of HLT ’11, pages 682–686, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Spreyer</author>
<author>Anette Frank</author>
</authors>
<title>Projectionbased acquisition of a temporal labeller.</title>
<date>2008</date>
<booktitle>Proceedings of IJCNLP</booktitle>
<contexts>
<context position="30230" citStr="Spreyer and Frank, 2008" startWordPosition="4944" endWordPosition="4947">proaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature r</context>
</contexts>
<marker>Spreyer, Frank, 2008</marker>
<rawString>Kathrin Spreyer and Anette Frank. 2008. Projectionbased acquisition of a temporal labeller. Proceedings of IJCNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL),</booktitle>
<pages>477--487</pages>
<location>Montr´eal, Canada.</location>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL), pages 477– 487, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Roger Levy</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative model for semantic role labeling.</title>
<date>2003</date>
<booktitle>In Proceedings of the 14th European Conference on Machine Learning, ECML</booktitle>
<pages>397--408</pages>
<location>Dubrovnik, Croatia.</location>
<contexts>
<context position="13073" citStr="Thompson et al., 2003" startWordPosition="2124" endWordPosition="2127">ed by means of cross-lingual model transfer. 3.3 The Model The model we use is based on that of Bj¨orkelund et al. (2009). It is comprised of a set of linear classifiers trained using Liblinear (Fan et al., 2008). The feature model was modified to accommodate the cross-lingual cluster features and the reranker component was not used. We do not model the interaction between different argument roles in the same predicate. While this has been found useful, in the cross-lingual setup one has to be careful with the assumptions made. For example, modeling the sequence of roles using a Markov chain (Thompson et al., 2003) may not work well in the present setting, especially between distant languages, as the order or arguments is not necessarily preserved. Most constraints that prove useful for SRL (Chang et al., 2007) also require customization when applied to a new language, and some rely on languagespecific resources, such as a valency lexicon. Taking into account the interaction between different arguments of a predicate is likely to improve the performance of the transferred model, but this is outside the scope of this work. 3.4 Feature Selection Compatibility of feature representations is necessary but no</context>
</contexts>
<marker>Thompson, Levy, Manning, 2003</marker>
<rawString>Cynthia A. Thompson, Roger Levy, and Christopher D. Manning. 2003. A generative model for semantic role labeling. In Proceedings of the 14th European Conference on Machine Learning, ECML 2003, pages 397–408, Dubrovnik, Croatia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A Bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>In Proc. of European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="20527" citStr="Titov and Klementiev (2012" startWordPosition="3355" endWordPosition="3358">ed learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent difference in their structure. The scores are shown in table 2. We will henceforth refer to the syntactic annotations that were provided with the datasets as original, as opposed to the annotations obtained by means of syntactic transfer. 4.3 Baselines Unsupervised Baseline: We are using a version of the unsupervised semantic role induction system of Titov and Klementiev (2012a) adapted to Setup UAS, % EN-ZH 35 ZH-EN 42 EN-CZ 36 CZ-EN 39 EN-FR 67 Table 2: Syntactic transfer accuracy, unlabeled attachment score (percent). Note that in case of French we evaluate against the output of a supervised system, since manual annotation is not available for this dataset. This score does not reflect the true performance of syntactic transfer. 1194 the shared feature representation considered in order to make the scores comparable with those of the transfer model and, more importantly, to enable evaluation on transferred syntax. Note that the original system, tailored to a more</context>
<context position="31763" citStr="Titov and Klementiev, 2012" startWordPosition="5189" endWordPosition="5192"> certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heuristics, provided an accurate model is available for on</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012a. A Bayesian approach to unsupervised semantic role induction. In Proc. of European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>Semisupervised semantic role labeling: Approaching from an unsupervised perspective.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<location>Bombay, India,</location>
<contexts>
<context position="20527" citStr="Titov and Klementiev (2012" startWordPosition="3355" endWordPosition="3358">ed learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent difference in their structure. The scores are shown in table 2. We will henceforth refer to the syntactic annotations that were provided with the datasets as original, as opposed to the annotations obtained by means of syntactic transfer. 4.3 Baselines Unsupervised Baseline: We are using a version of the unsupervised semantic role induction system of Titov and Klementiev (2012a) adapted to Setup UAS, % EN-ZH 35 ZH-EN 42 EN-CZ 36 CZ-EN 39 EN-FR 67 Table 2: Syntactic transfer accuracy, unlabeled attachment score (percent). Note that in case of French we evaluate against the output of a supervised system, since manual annotation is not available for this dataset. This score does not reflect the true performance of syntactic transfer. 1194 the shared feature representation considered in order to make the scores comparable with those of the transfer model and, more importantly, to enable evaluation on transferred syntax. Note that the original system, tailored to a more</context>
<context position="31763" citStr="Titov and Klementiev, 2012" startWordPosition="5189" endWordPosition="5192"> certain word may be indicated by a preposition, inflection or word order, depending on the language. Accurate representation of such information would require an extra level of abstraction (Hajiˇc, 2002). A side-effect of using adaptation methods is that we are forced to use the same annotation scheme for the task in question (SRL, in our case), which in turn simplifies the development of cross-lingual tools for downstream tasks. Such representations are also likely to be useful in machine translation. Unsupervised semantic role labeling methods (Lang and Lapata, 2010; Lang and Lapata, 2011; Titov and Klementiev, 2012a; Lorenzo and Cerisara, 2012) also constitute an alternative to cross-lingual model transfer. For an overview of of semi-supervised approaches we refer the reader to Titov and Klementiev (2012b). 7 Conclusion We have considered the cross-lingual model transfer approach as applied to the task of semantic role labeling and observed that for closely related languages it performs comparably to annotation projection approaches. It allows one to quickly construct an SRL model for a new language without manual annotation or language-specific heuristics, provided an accurate model is available for on</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012b. Semisupervised semantic role labeling: Approaching from an unsupervised perspective. In Proceedings of the International Conference on Computational Linguistics (COLING), Bombay, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Emanuele Pianta</author>
</authors>
<title>Frame information transfer from English to Italian.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="30066" citStr="Tonelli and Pianta, 2008" startWordPosition="4916" endWordPosition="4920">cular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, </context>
</contexts>
<marker>Tonelli, Pianta, 2008</marker>
<rawString>Sara Tonelli and Emanuele Pianta. 2008. Frame information transfer from English to Italian. In Proceedings of LREC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
</authors>
<title>Domain adaptation with artificial data for semantic parsing of speech.</title>
<date>2009</date>
<booktitle>In Proc. 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>125--128</pages>
<location>Boulder, Colorado.</location>
<marker>van der Plas, Henderson, Merlo, 2009</marker>
<rawString>Lonneke van der Plas, James Henderson, and Paola Merlo. 2009. Domain adaptation with artificial data for semantic parsing of speech. In Proc. 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 125–128, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Paola Merlo</author>
<author>James Henderson</author>
</authors>
<title>Scaling up automatic cross-lingual semantic role annotation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11,</booktitle>
<pages>299--304</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>van der Plas, Merlo, Henderson, 2011</marker>
<rawString>Lonneke van der Plas, Paola Merlo, and James Henderson. 2011. Scaling up automatic cross-lingual semantic role annotation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11, pages 299–304, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Wr´oblewska</author>
<author>Anette Frank</author>
</authors>
<title>Crosslingual projection of LFG F-structures: Building an F-structure bank for Polish.</title>
<date>2009</date>
<booktitle>In Eighth International Workshop on Treebanks and Linguistic Theories,</booktitle>
<pages>209</pages>
<marker>Wr´oblewska, Frank, 2009</marker>
<rawString>Alina Wr´oblewska and Anette Frank. 2009. Crosslingual projection of LFG F-structures: Building an F-structure bank for Polish. In Eighth International Workshop on Treebanks and Linguistic Theories, page 209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Can semantic role labeling improve SMT?</title>
<date>2009</date>
<booktitle>In Proceedings of 13th Annual Conference of the European Association for Machine Translation (EAMT 2009),</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="1148" citStr="Wu and Fung, 2009" startWordPosition="165" endWordPosition="168">ted on three language pairs, demonstrating competitive performance as compared to a state-of-the-art unsupervised SRL system and a cross-lingual annotation projection baseline. We also consider the contribution of different aspects of the feature representation to the performance of the model and discuss practical applicability of this method. 1 Background and Motivation Semantic role labeling has proven useful in many natural language processing tasks, such as question answering (Shen and Lapata, 2007; Kaisser and Webber, 2007), textual entailment (Sammons et al., 2009), machine translation (Wu and Fung, 2009; Liu and Gildea, 2010; Gao and Vogel, 2011) and dialogue systems (Basili et al., 2009; van der Plas et al., 2009). Multiple models have been designed to automatically predict semantic roles, and a considerable amount of data has been annotated to train these models, if only for a few more popular languages. As the annotation is costly, one would like to leverage existing resources to minimize the human effort required to construct a model for a new language. A number of approaches to the construction of semantic role labeling models for new languages have been proposed. On one end of the scal</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009. Can semantic role labeling improve SMT? In Proceedings of 13th Annual Conference of the European Association for Machine Translation (EAMT 2009), Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-English languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>851--858</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29707" citStr="Xi and Hwa, 2005" startWordPosition="4863" endWordPosition="4866">tactic information alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic informati</context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-English languages. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 851–858, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Ricahrd Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of Human Language Technology Conference.</booktitle>
<contexts>
<context position="7442" citStr="Yarowsky et al., 2001" startWordPosition="1184" endWordPosition="1187">. The performance of such models can be impressive, especially for those languages where semantic roles correlate strongly with syntactic relation of the argument to its predicate. However, assigning meaningful role labels to the resulting clusters requires additional effort and the model’s parameters generally need some adjustment for every language. If the necessary resources are already available for a closely related language, they can be utilized to facilitate the construction of a model for the target language. This can be achieved either by means of cross-lingual annotation projection (Yarowsky et al., 2001) or by cross-lingual model transfer (Zeman and Resnik, 2008). This last approach is the one we are considering in this work, and the other two options are treated as baselines. The unsupervised model will be further referred to as UNSUP and the projection baseline as PROJ. 2.3 Evaluation Measures We use the F1 measure as a metric for the argument identification stage and accuracy as an aggregate measure of argument classification performance. When comparing to the unsupervised SRL system the clustering evaluation measures are used instead. These are purity and collocation 1191 1 � P U = N i 1 </context>
<context position="29603" citStr="Yarowsky et al., 2001" startWordPosition="4845" endWordPosition="4848"> the fact that we consider only the core roles, which can usually be predicted with high accuracy based on syntactic information alone. 6 Related Work Development of robust statistical models for core NLP tasks is a challenging problem, and adaptation of existing models to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation predictio</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Ricahrd Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Crosslanguage parser adaptation between related languages.</title>
<date>2008</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages,</booktitle>
<pages>35--42</pages>
<location>Hyderabad, India,</location>
<contexts>
<context position="7502" citStr="Zeman and Resnik, 2008" startWordPosition="1193" endWordPosition="1196">lly for those languages where semantic roles correlate strongly with syntactic relation of the argument to its predicate. However, assigning meaningful role labels to the resulting clusters requires additional effort and the model’s parameters generally need some adjustment for every language. If the necessary resources are already available for a closely related language, they can be utilized to facilitate the construction of a model for the target language. This can be achieved either by means of cross-lingual annotation projection (Yarowsky et al., 2001) or by cross-lingual model transfer (Zeman and Resnik, 2008). This last approach is the one we are considering in this work, and the other two options are treated as baselines. The unsupervised model will be further referred to as UNSUP and the projection baseline as PROJ. 2.3 Evaluation Measures We use the F1 measure as a metric for the argument identification stage and accuracy as an aggregate measure of argument classification performance. When comparing to the unsupervised SRL system the clustering evaluation measures are used instead. These are purity and collocation 1191 1 � P U = N i 1 � CO = N j where Ci is the set of arguments in the i-th indu</context>
<context position="12307" citStr="Zeman and Resnik, 2008" startWordPosition="1989" endWordPosition="1992">e extent to which this would be useful, however, depends on the similarity of syntactic-semantic interfaces of the languages in question. In this work we discard the dependency relation labels where the inventories do not match and only consider the unlabeled syntactic dependency graph. Some discrepancies, such as variations in attachment order, may be present even there, but this does not appear to be the case with the datasets we use for evaluation. If a target language is poor in resources, one can obtain a dependency parser for the target language by means of cross-lingual model transfer (Zeman and Resnik, 2008). We max |Gj ∩ Ci| j max |Gj ∩ Ci|, i 1192 take this into account and evaluate both using the original dependency structures and the ones obtained by means of cross-lingual model transfer. 3.3 The Model The model we use is based on that of Bj¨orkelund et al. (2009). It is comprised of a set of linear classifiers trained using Liblinear (Fan et al., 2008). The feature model was modified to accommodate the cross-lingual cluster features and the reranker component was not used. We do not model the interaction between different argument roles in the same predicate. While this has been found useful</context>
<context position="19553" citStr="Zeman and Resnik (2008)" startWordPosition="3195" endWordPosition="3198"> see http://www.ml4nlp.de/code-and-data/treex2conll and English-French, the data is drawn from Europarl (Koehn, 2005), for English-Chinese – from MultiUN (Eisele and Chen, 2010). The word alignments were obtained using GIZA++ (Och and Ney, 2003) and the intersection heuristic. 4.2 Syntactic Transfer In the low-resource setting, we cannot always rely on the availability of an accurate dependency parser for the target language. If one is not available, the natural solution would be to use crosslingual model transfer to obtain it. Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al. (2011) and T¨ackstr¨om et al. (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al. (2011), using Malt parser (Nivre, 2008) and the same set of features. We did not reimplement the projected transfer algorithm, however, and used the default training procedure instead of perceptron-based learning. The dependency structure thus obtained is, of course, only a rough approximation – even a much more sophisticated algorithm may not perform well when transferring syntax between such languages as Czech and English, given the inherent diffe</context>
<context position="30461" citStr="Zeman and Resnik, 2008" startWordPosition="4979" endWordPosition="4982">ction (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett et al., 2012; Søgaard, 2011; Lopez et al., 2008) have also been receiving much attention recently. The basic idea behind model transfer is similar to that of cross-lingual annotation projection, as we can see from the way parallel data is used in, for example, McDonald et al. (2011). A crucial component of direct transfer approaches is the unified feature representation. There are at least two such representations of lexical information (Klementiev et al., 2012; T¨ackstr¨om et al., 2012), but both work on word level. This makes it hard to account for phenomena that are expressed diff</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Crosslanguage parser adaptation between related languages. In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 35– 42, Hyderabad, India, January. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Radu Florian</author>
</authors>
<title>Mention detection crossing the language barrier.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="29872" citStr="Zitouni and Florian, 2008" startWordPosition="4885" endWordPosition="4888">odels to new languages presents a viable alternative to exhaustive annotation for each language. Although the models thus obtained are generally imperfect, they can be further refined for a particular language and domain using techniques such as active learning (Settles, 2010; Chen et al., 2011). Cross-lingual annotation projection (Yarowsky et al., 2001) approaches have been applied extensively to a variety of tasks, including POS tagging (Xi and Hwa, 2005; Das and Petrov, 2011), morphology segmentation (Snyder and Barzilay, 2008), verb classification (Merlo et al., 2002), mention detection (Zitouni and Florian, 2008), LFG parsing (Wr´oblewska and Frank, 2009), information extraction (Kim et al., 2010), SRL (Pad´o and Lapata, 2009; van der Plas et al., 2011; Annesi and Basili, 2010; Tonelli and Pianta, 2008), dependency parsing (Naseem et al., 2012; Ganchev et al., 2009; Smith and Eisner, 2009; Hwa et al., 2005) or temporal relation prediction (Spreyer and Frank, 2008). Interestingly, it has also been used to propagate morphosyntactic information between old and modern versions of the same language (Meyer, 2011). Cross-lingual model transfer methods (McDonald et al., 2011; Zeman and Resnik, 2008; Durrett e</context>
</contexts>
<marker>Zitouni, Florian, 2008</marker>
<rawString>Imed Zitouni and Radu Florian. 2008. Mention detection crossing the language barrier. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>