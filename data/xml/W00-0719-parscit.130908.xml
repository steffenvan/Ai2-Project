<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015693">
<note confidence="0.818028">
In: Proceedings of CoNLL-2000 and LLL-2000, pages 99-102, Lisbon, Portugal, 2000.
</note>
<title confidence="0.9802025">
Combining Text and Heuristics for
Cost-Sensitive Spam Filtering
</title>
<note confidence="0.433013">
José M. Gomez Hidalgo Manuel Maria Lopez*
Universidad Europea-CEES, Spain Universidad de Vigo, Spain
</note>
<email confidence="0.735199">
jmgomez@dinar.esi.uem.es mjlopez@uvigo.es
</email>
<author confidence="0.794111">
Enrique Puertas Sanz
</author>
<affiliation confidence="0.496956">
Universidad Europea-CEES, Spain
</affiliation>
<email confidence="0.991755">
epsilonmail@retemail.es
</email>
<sectionHeader confidence="0.987378" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999884545454545">
Spam filtering is a text categorization task that
shows especial features that make it interest-
ing and difficult. First, the task has been per-
formed traditionally using heuristics from the
domain. Second, a cost model is required to
avoid misclassification of legitimate messages.
We present a comparative evaluation of several
machine learning algorithms applied to spam fil-
tering, considering the text of the messages and
a set of heuristics for the task. Cost-oriented
biasing and evaluation is performed.
</bodyText>
<sectionHeader confidence="0.993785" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997244173913043">
Spam, or more properly Unsolicited Commer-
cial E-mail (UCE), is an increasing threat to
the viability of Internet E-mail and a danger
to Internet commerce. UCE senders take away
resources from users and service suppliers with-
out compensation and without authorization. A
variety of counter-measures to UCE have been
proposed, from technical to regulatory (Cranor
and LaMacchia, 1998). Among the technical
ones, the use of filtering methods is popular and
effective.
UCE filtering is a text categorization task.
Text categorization (TC) is the classification of
documents with respect to a set of one or more
pre-existing categories. In the case of UCE, the
task is to classify e-mail messages or newsgroups
articles as UCE or not (that is, legitimate). The
general model of TC makes use of a set of pre-
classified documents to classify new ones, ac-
cording to the text content (i.e. words) of the
documents (Sebastiani, 1999).
Although UCE filtering seems to be a simple
instance of the more general TC task, it shows
</bodyText>
<listItem confidence="0.917141666666667">
* Partially supported by the CICYT, project no.
TEL99-0335-004-03
two special characteristics:
• First, UCE filtering has been developed us-
ing very simple heuristics for many years.
For example, one individual could manu-
ally build a filter that classifies as &amp;quot;spam&amp;quot;
messages containing the phrase &amp;quot;win big
money&amp;quot;, or with an unusual (big) number
of capital letters or non-alphanumeric char-
acters. These rules are examples of simple
but powerful heuristics that could be used
to complement a word-based automatic TC
system for UCE filtering.
• Second, all UCE filtering errors are not of
equal importance. Individuals usually pre-
fer conservative filters that tend to classify
UCE as legitimate, because missing a le-
gitimate message is more harmful than the
opposite. A cost model is imperative to
avoid the risk of missing legitimate e-mail.
</listItem>
<bodyText confidence="0.998224736842105">
Many learning algorithms have been applied
to the problem of TC (Yang, 1999), but much
less with the problem of UCE filtering in mind.
Sahami and others (1998) propose the utiliza-
tion of a Naive Bayes classifier based on the
words and a set of manually derived heuris-
tics for UCE filtering, showing that the heuris-
tics improve the effectiveness of the classifier.
Druker and others (1999) compare boosting,
Support Vector Machines, Ripper and Rocchio
classifiers for UCE filtering. Andruotsopoulos
and others (2000) present a cost-oriented eval-
uation of the Naive Bayes and k-nearest neigh-
bor (kNN) algorithms for UCE filtering. Fi-
nally, Provost (1999) compares Naive Bayes and
RIPPER for the task. These three last works
do not consider any set of heuristics for UCE
filtering. So, an extensive evaluation of learn-
ing algorithms combining words and heuristics
</bodyText>
<page confidence="0.992764">
99
</page>
<bodyText confidence="0.999966588235294">
remains to be done. Also, although the eval-
uations performed in these works have taken
into account the importance of misclassifying le-
gitimate e-mail, they have not considered that
many learning algorithms (specially those that
are error-driven) can be biased to prefer some
kind of errors to others.
In this paper, we present a comparative eval-
uation of a representative selection of Machine
Learning algorithms for UCE filtering. The al-
gorithms take advantage of two kinds of infor-
mation: the words in the messages and a set of
heuristics. Also, the algorithms are biased by
a cost weighting schema to avoid, if possible,
misclassifying legitimate e-mail. Finally, algo-
rithms are evaluated according to cost-sensitive
measures.
</bodyText>
<sectionHeader confidence="0.916036" genericHeader="method">
2 Heuristics for UCE classification
</sectionHeader>
<bodyText confidence="0.998754564102564">
Sahami and others (Sahami et al., 1998) have
proposed a set of heuristic features to comple-
ment the word Bayesian model in their work,
including: a set of around 35 hand-crafted key
phrases (like &amp;quot;free money&amp;quot;); some non text
features (like the domain of the sender, or
whether the message comes from a distribution
list or not); and features concerning the non-
alphanumeric characters in the messages.
For this work, we have focused in this last
set of features. The test collection used in
our experiments, Spambase, already contained
a set of nine heuristic features. Spambasel is
an e-mail messages collection containing 4601
messages, being 1813 (39%) marked as UCE.
The collection comes in preprocessed (not raw)
form, and its instances have been represented
as 58-dimensional vectors. The first 48 features
are words extracted from the original messages,
without stop list nor stemming, and selected as
the most unbalanced words for the UCE class.
The next 6 features are the percentage of occur-
rences of the special characters &amp;quot;;&amp;quot; , &amp;quot;(&amp;quot;, &amp;quot;[&amp;quot; , &apos;9&amp;quot;,
&amp;quot;$&amp;quot; and &amp;quot;#&amp;quot;. The following 3 features represent
different measures of occurrences of capital let-
ters in the text of the messages. Finally, the last
feature is the class label. So, features 49 to 57
represent heuristic attributes of the messages.
In our experiments, we have tested several
learning algorithms on three feature sets: only
&apos;This collection can be obtained from
http://www.ics.uci.edu/mlearn/MLRepository.html.
words, only heuristic attributes, and both. We
have divided the Spambase collection in two
parts: a 90% of the instances are used for train-
ing, and a 10% of the messages are retained for
testing. This split has been performed preserv-
ing the percentages of legitimate and UCE mes-
sages in the whole collection.
</bodyText>
<sectionHeader confidence="0.98668" genericHeader="method">
3 Cost-sensitive UCE classification
</sectionHeader>
<bodyText confidence="0.999947103448276">
According to the problem of UCE filtering, a
cost-sensitive classification is required. Each
learning algorithm can be biased to prefer some
kind of missclassification errors to others. A
popular technique for doing this is resampling
the training collection by multiplying the num-
ber of instances of the preferred class by the cost
ratio. Also, the unpreferred class can be down-
sampled by eliminating some instances. The
software package we use for our experiments ap-
plies both methods depending on the algorithm
tested.
We have tested four learning algorithms:
Naive Bayes (NB), C4.5, PART and k-nearest
neighbor (kNN), all implemented in the Weka
package (Witten and Frank, 1999). The ver-
sion of Weka used in this work is Weka 3.0.1.
The algorithms used can be biased to prefer the
mistake of classify a UCE message as not UCE
to the opposite, assigning a penalty to the sec-
ond kind of errors. Following (Androutsopou-
los et al., 2000), we have assigned 9 and 999
(9 and 999 times more important) penalties to
the missclassification of legitimate messages as
UCE. This means that every instance of a le-
gitimate message has been replaced by 9 and
999 instances of the same message respectively
for NB, C4.5 and PART. However, for kNN the
data have been downsampled.
</bodyText>
<sectionHeader confidence="0.911259" genericHeader="evaluation">
4 Evaluation and results
</sectionHeader>
<bodyText confidence="0.997637272727273">
The experiments results are summarized in the
Table 1, 2 and 3. The learning algorithms Naive
Bayes (NB), 5-Nearest Neighbor (5NN), C4.5
and PART were tested on words (-W), heuris-
tic features (-H), and both (-WH). The kNN
algorithm was tested with values of k equal to
1, 2, 5 and 8, being 5 the optimal number of
neighbors. We present the weighted accuracy
(wacc), and also the recall (rec) and precision
(pre) for the class UCE. Weighted accuracy is a
measure that weights higher the hits and misses
</bodyText>
<page confidence="0.983155">
100
</page>
<bodyText confidence="0.999963727272727">
for the preferred class. Recall and precision for
the UCE class show how effective the filter is
blocking UCE, and what is its effectiveness let-
ting legitimate messages pass the filter, respec-
tively (Androutsopoulos et al., 2000).
In Table 1, no costs were used. Tables 2 and
3 show the results of our experiments for cost
ratios of 9 and 999. For these last cases, there
were not enough training instances for the kNN
algorithm to perform classification, due to the
downsampling method applied by Weka.
</bodyText>
<sectionHeader confidence="0.964232" genericHeader="conclusions">
5 Discussion and conclusions
</sectionHeader>
<bodyText confidence="0.999916853658537">
The results of our experiments show that the
best performing algorithms are C4.5 and PART.
However, for the cost value of 999, both algo-
rithms degrade to the trivial rejector: they pre-
fer to classify every message as legitimate in or-
der to avoid highly penalized errors. With these
results, neither of these algorithms seems useful
for autonomous classification of UCE as stated
by Androutsopoulos, since this cost ratio rep-
resents a scenario in which UCE messages are
deleted without notifying the user of the UCE
filter. Nevertheless, PART-WH shows competi-
tive performance for a cost ratio of 9. Its num-
bers are comparable to those shown in a com-
mercial study by the top performing Brightmail
filtering system (Mariano, 2000), which reaches
a UCE recall of 0.73, and a precision close to
1.0, and it is manually updated.
Naive Bayes has not shown high variability
with respect to costs. This is probably due to
the sampling method, which only slightly affects
to the estimation of probabilities (done by ap-
proximation to a normal distribution). In (Sa-
hami et al., 1998; Androutsopoulos et al., 2000),
the method followed is the variation of the prob-
ability threshold, which leads to a high variation
of results. In future experiments, we plan to ap-
ply the uniform method MetaCost (Domingos,
1999) to the algorithms tested in this work, for
getting more comparable results.
With respect to the use of heuristics, we can
see that this information alone is not competi-
tive, but it can improve classification based on
words. The improvement shown in our experi-
ments is modest, due to the heuristics used. We
are not able to add other heuristics in this case
because the Spambase collection comes in a pre-
processed fashion. For future experiments, we
will use the collection from (Androutsopoulos et
al., 2000), which is in raw form. This fact will
enable us to search for more powerful heuristics.
</bodyText>
<sectionHeader confidence="0.993024" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997897888888889">
I. Androutsopoulos, G. Paliouras, V. Karkalet-
sis, G. Sakkis, C.D. Spyropoulos, and
P. Stamatopoulos. 2000. Learning to fil-
ter spam e-mail: A comparison of a naive
bayesian and a memory-based approach.
Technical Report DEMO 2000/5, Inst. of
Informatics and Telecommunications, NCSR
Demokritos, Athens, Greece.
Lorrie F. Cranor and Brian A. LaMacchia.
1998. Spam! Comm. of the ACM, 41(8).
Pedro Domingos. 1999. Metacost: A general
method for making classifiers cost-sensitive.
In Proc. of the 5th International Conference
on Knowledge Discovery and Data Mining.
Harris Drucker, Donghui Wu, and Vladimir N.
Vapnik. 1999. Support vector machines for
spam categorization. IEEE Trans. on Neural
Networks, 10(5).
Gwendolin Mariano. 2000. Study
finds filters catch only a fraction of
spam. CNET News.com. Available at
http://news.cnet.com/news/0-1005-200-
2086887.html.
Jefferson Provost. 1999. Naive-bayes
vs. rule-learning in classification of
email. Technical Report available at
http: / /www.cs.utexas.edu/users/jp/research/ ,
Dept. of Computer Sciences at the U. of
Texas at Austin.
Mehran Sahami, Susan Dumais, David Heck-
erman, and Eric Horvitz. 1998. A bayesian
approach to filtering junk e-mail. In Learn-
ing for Text Categorization: Papers from the
1998 Workshop. AAAI Tech. Rep. WS-98-05.
Fabrizio Sebastiani. 1999. A tutorial on auto-
mated text categorisation. In Proc. of the
First Argentinian Symposium on Artificial
Intelligence (ASAI-99).
Ian H. Witten and Eibe Prank. 1999. Data
Mining: Practical Machine Learning Tools
and Techniques with Java Implementations.
Morgan Kaufmann.
Yiming Yang. 1999. An evaluation of statisti-
cal approaches to text categorization. Infor-
mation Retrieval, 1(1-2).
</reference>
<page confidence="0.996329">
101
</page>
<table confidence="0.999017714285714">
classifier rec pre wacc classifier rec pre wacc
NB-W 0.97 0.74 0.85 C4.5-W 0.78 0.87 0.86
NB-H 0.31 0.80 0.69 C4.5-H 0.81 0.90 0.88
NB-WH 0.97 0.73 0.84 C4.5-WH 0.85 0.89 0.89
5NN-W 0.79 0.85 0.86 Part-W 0.81 0.87 0.87
5NN-H 0.72 0.83 0.83 Part-H 0.73 0.86 0.84
5NN-WH 0.75 0.87 0.85 Part-WH 0.89 0.91 0.92
</table>
<tableCaption confidence="0.996552">
Table 1: UCE recall, UCE precision and weighted accuracy for costs = 1.
</tableCaption>
<table confidence="0.932175142857143">
classifier rec pre wacc classifier rec pre wacc
NB-W 0.97 0.74 0.78 C4.5-W 0.55 0.96 0.95
NB-H 0.23 0.76 0.90 C4.5-H 0.41 0.96 0.95
NB-WH 0.97 0.74 0.78 C4.5-WH 0.71 0.96 0.96
5NN-W - - - Part-W 0.59 0.98 0.96
5NN-H - - - Part-H 0.23 0.93 0.93
5NN-WH - - - Part-WH 0.71 0.98 0.97
</table>
<tableCaption confidence="0.975872">
Table 2: UCE recall, UCE precision and weighted accuracy for costs = 9.
</tableCaption>
<table confidence="0.941335142857143">
classifier rec pre wacc classifier rec pre wacc
NB-W 0.18 0.79 0.96 C4.5-W 0.00 0.00 0.99
NB-H 0.23 0.76 0.90 C4.5-H 0.00 0.00 0.99
NB-WH 0.97 0.74 0.78 C4.5-WH 0.00 0.00 0.99
5NN-W - - - Part-W 0.00 0.00 0.99
5NN-H - - - Part-H 0.00 0.00 0.99
5NN-WH - - - Part-WH 0.00 0.00 0.99
</table>
<tableCaption confidence="0.996721">
Table 3: UCE recall, UCE precision and weighted accuracy for costs = 999.
</tableCaption>
<page confidence="0.997327">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.505140">
<note confidence="0.97968">of CoNLL-2000 and LLL-2000, 99-102, Lisbon, Portugal, 2000.</note>
<title confidence="0.962382">Combining Text and Heuristics Cost-Sensitive Spam Filtering</title>
<author confidence="0.981427">José M Gomez Hidalgo Manuel Maria Lopez</author>
<affiliation confidence="0.865007">Universidad Europea-CEES, Spain Universidad de Vigo, Spain</affiliation>
<title confidence="0.726755">jmgomez@dinar.esi.uem.es mjlopez@uvigo.es</title>
<author confidence="0.996543">Enrique Puertas Sanz</author>
<affiliation confidence="0.990225">Universidad Europea-CEES,</affiliation>
<email confidence="0.978157">epsilonmail@retemail.es</email>
<abstract confidence="0.988339416666667">Spam filtering is a text categorization task that shows especial features that make it interesting and difficult. First, the task has been performed traditionally using heuristics from the domain. Second, a cost model is required to avoid misclassification of legitimate messages. We present a comparative evaluation of several machine learning algorithms applied to spam filtering, considering the text of the messages and a set of heuristics for the task. Cost-oriented biasing and evaluation is performed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>G Paliouras</author>
<author>V Karkaletsis</author>
<author>G Sakkis</author>
<author>C D Spyropoulos</author>
<author>P Stamatopoulos</author>
</authors>
<title>Learning to filter spam e-mail: A comparison of a naive bayesian and a memory-based approach.</title>
<date>2000</date>
<booktitle>Inst. of Informatics and Telecommunications, NCSR Demokritos,</booktitle>
<tech>Technical Report DEMO 2000/5,</tech>
<location>Athens, Greece.</location>
<contexts>
<context position="7147" citStr="Androutsopoulos et al., 2000" startWordPosition="1128" endWordPosition="1132">ferred class by the cost ratio. Also, the unpreferred class can be downsampled by eliminating some instances. The software package we use for our experiments applies both methods depending on the algorithm tested. We have tested four learning algorithms: Naive Bayes (NB), C4.5, PART and k-nearest neighbor (kNN), all implemented in the Weka package (Witten and Frank, 1999). The version of Weka used in this work is Weka 3.0.1. The algorithms used can be biased to prefer the mistake of classify a UCE message as not UCE to the opposite, assigning a penalty to the second kind of errors. Following (Androutsopoulos et al., 2000), we have assigned 9 and 999 (9 and 999 times more important) penalties to the missclassification of legitimate messages as UCE. This means that every instance of a legitimate message has been replaced by 9 and 999 instances of the same message respectively for NB, C4.5 and PART. However, for kNN the data have been downsampled. 4 Evaluation and results The experiments results are summarized in the Table 1, 2 and 3. The learning algorithms Naive Bayes (NB), 5-Nearest Neighbor (5NN), C4.5 and PART were tested on words (-W), heuristic features (-H), and both (-WH). The kNN algorithm was tested wi</context>
<context position="9642" citStr="Androutsopoulos et al., 2000" startWordPosition="1555" endWordPosition="1558">eted without notifying the user of the UCE filter. Nevertheless, PART-WH shows competitive performance for a cost ratio of 9. Its numbers are comparable to those shown in a commercial study by the top performing Brightmail filtering system (Mariano, 2000), which reaches a UCE recall of 0.73, and a precision close to 1.0, and it is manually updated. Naive Bayes has not shown high variability with respect to costs. This is probably due to the sampling method, which only slightly affects to the estimation of probabilities (done by approximation to a normal distribution). In (Sahami et al., 1998; Androutsopoulos et al., 2000), the method followed is the variation of the probability threshold, which leads to a high variation of results. In future experiments, we plan to apply the uniform method MetaCost (Domingos, 1999) to the algorithms tested in this work, for getting more comparable results. With respect to the use of heuristics, we can see that this information alone is not competitive, but it can improve classification based on words. The improvement shown in our experiments is modest, due to the heuristics used. We are not able to add other heuristics in this case because the Spambase collection comes in a pr</context>
</contexts>
<marker>Androutsopoulos, Paliouras, Karkaletsis, Sakkis, Spyropoulos, Stamatopoulos, 2000</marker>
<rawString>I. Androutsopoulos, G. Paliouras, V. Karkaletsis, G. Sakkis, C.D. Spyropoulos, and P. Stamatopoulos. 2000. Learning to filter spam e-mail: A comparison of a naive bayesian and a memory-based approach. Technical Report DEMO 2000/5, Inst. of Informatics and Telecommunications, NCSR Demokritos, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorrie F Cranor</author>
<author>Brian A LaMacchia</author>
</authors>
<date>1998</date>
<journal>Spam! Comm. of the ACM,</journal>
<volume>41</volume>
<issue>8</issue>
<contexts>
<context position="1281" citStr="Cranor and LaMacchia, 1998" startWordPosition="177" endWordPosition="180">. We present a comparative evaluation of several machine learning algorithms applied to spam filtering, considering the text of the messages and a set of heuristics for the task. Cost-oriented biasing and evaluation is performed. 1 Introduction Spam, or more properly Unsolicited Commercial E-mail (UCE), is an increasing threat to the viability of Internet E-mail and a danger to Internet commerce. UCE senders take away resources from users and service suppliers without compensation and without authorization. A variety of counter-measures to UCE have been proposed, from technical to regulatory (Cranor and LaMacchia, 1998). Among the technical ones, the use of filtering methods is popular and effective. UCE filtering is a text categorization task. Text categorization (TC) is the classification of documents with respect to a set of one or more pre-existing categories. In the case of UCE, the task is to classify e-mail messages or newsgroups articles as UCE or not (that is, legitimate). The general model of TC makes use of a set of preclassified documents to classify new ones, according to the text content (i.e. words) of the documents (Sebastiani, 1999). Although UCE filtering seems to be a simple instance of th</context>
</contexts>
<marker>Cranor, LaMacchia, 1998</marker>
<rawString>Lorrie F. Cranor and Brian A. LaMacchia. 1998. Spam! Comm. of the ACM, 41(8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro Domingos</author>
</authors>
<title>Metacost: A general method for making classifiers cost-sensitive.</title>
<date>1999</date>
<booktitle>In Proc. of the 5th International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="9839" citStr="Domingos, 1999" startWordPosition="1590" endWordPosition="1591"> Brightmail filtering system (Mariano, 2000), which reaches a UCE recall of 0.73, and a precision close to 1.0, and it is manually updated. Naive Bayes has not shown high variability with respect to costs. This is probably due to the sampling method, which only slightly affects to the estimation of probabilities (done by approximation to a normal distribution). In (Sahami et al., 1998; Androutsopoulos et al., 2000), the method followed is the variation of the probability threshold, which leads to a high variation of results. In future experiments, we plan to apply the uniform method MetaCost (Domingos, 1999) to the algorithms tested in this work, for getting more comparable results. With respect to the use of heuristics, we can see that this information alone is not competitive, but it can improve classification based on words. The improvement shown in our experiments is modest, due to the heuristics used. We are not able to add other heuristics in this case because the Spambase collection comes in a preprocessed fashion. For future experiments, we will use the collection from (Androutsopoulos et al., 2000), which is in raw form. This fact will enable us to search for more powerful heuristics. Re</context>
</contexts>
<marker>Domingos, 1999</marker>
<rawString>Pedro Domingos. 1999. Metacost: A general method for making classifiers cost-sensitive. In Proc. of the 5th International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harris Drucker</author>
<author>Donghui Wu</author>
<author>Vladimir N Vapnik</author>
</authors>
<title>Support vector machines for spam categorization.</title>
<date>1999</date>
<journal>IEEE Trans. on Neural Networks,</journal>
<volume>10</volume>
<issue>5</issue>
<marker>Drucker, Wu, Vapnik, 1999</marker>
<rawString>Harris Drucker, Donghui Wu, and Vladimir N. Vapnik. 1999. Support vector machines for spam categorization. IEEE Trans. on Neural Networks, 10(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gwendolin Mariano</author>
</authors>
<title>Study finds filters catch only a fraction of spam.</title>
<date>2000</date>
<journal>CNET News.com. Available</journal>
<volume>at</volume>
<pages>0--1005</pages>
<contexts>
<context position="9268" citStr="Mariano, 2000" startWordPosition="1493" endWordPosition="1494">value of 999, both algorithms degrade to the trivial rejector: they prefer to classify every message as legitimate in order to avoid highly penalized errors. With these results, neither of these algorithms seems useful for autonomous classification of UCE as stated by Androutsopoulos, since this cost ratio represents a scenario in which UCE messages are deleted without notifying the user of the UCE filter. Nevertheless, PART-WH shows competitive performance for a cost ratio of 9. Its numbers are comparable to those shown in a commercial study by the top performing Brightmail filtering system (Mariano, 2000), which reaches a UCE recall of 0.73, and a precision close to 1.0, and it is manually updated. Naive Bayes has not shown high variability with respect to costs. This is probably due to the sampling method, which only slightly affects to the estimation of probabilities (done by approximation to a normal distribution). In (Sahami et al., 1998; Androutsopoulos et al., 2000), the method followed is the variation of the probability threshold, which leads to a high variation of results. In future experiments, we plan to apply the uniform method MetaCost (Domingos, 1999) to the algorithms tested in </context>
</contexts>
<marker>Mariano, 2000</marker>
<rawString>Gwendolin Mariano. 2000. Study finds filters catch only a fraction of spam. CNET News.com. Available at http://news.cnet.com/news/0-1005-200-2086887.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jefferson Provost</author>
</authors>
<title>Naive-bayes vs. rule-learning in classification of email.</title>
<date>1999</date>
<tech>Technical Report available at http: / /www.cs.utexas.edu/users/jp/research/ ,</tech>
<institution>Dept. of Computer</institution>
<contexts>
<context position="3407" citStr="Provost (1999)" startWordPosition="526" endWordPosition="527">lied to the problem of TC (Yang, 1999), but much less with the problem of UCE filtering in mind. Sahami and others (1998) propose the utilization of a Naive Bayes classifier based on the words and a set of manually derived heuristics for UCE filtering, showing that the heuristics improve the effectiveness of the classifier. Druker and others (1999) compare boosting, Support Vector Machines, Ripper and Rocchio classifiers for UCE filtering. Andruotsopoulos and others (2000) present a cost-oriented evaluation of the Naive Bayes and k-nearest neighbor (kNN) algorithms for UCE filtering. Finally, Provost (1999) compares Naive Bayes and RIPPER for the task. These three last works do not consider any set of heuristics for UCE filtering. So, an extensive evaluation of learning algorithms combining words and heuristics 99 remains to be done. Also, although the evaluations performed in these works have taken into account the importance of misclassifying legitimate e-mail, they have not considered that many learning algorithms (specially those that are error-driven) can be biased to prefer some kind of errors to others. In this paper, we present a comparative evaluation of a representative selection of Ma</context>
</contexts>
<marker>Provost, 1999</marker>
<rawString>Jefferson Provost. 1999. Naive-bayes vs. rule-learning in classification of email. Technical Report available at http: / /www.cs.utexas.edu/users/jp/research/ , Dept. of Computer Sciences at the U. of Texas at Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehran Sahami</author>
<author>Susan Dumais</author>
<author>David Heckerman</author>
<author>Eric Horvitz</author>
</authors>
<title>A bayesian approach to filtering junk e-mail.</title>
<date>1998</date>
<booktitle>In Learning for Text Categorization: Papers from the 1998 Workshop. AAAI Tech. Rep.</booktitle>
<pages>98--05</pages>
<contexts>
<context position="4425" citStr="Sahami et al., 1998" startWordPosition="686" endWordPosition="689"> learning algorithms (specially those that are error-driven) can be biased to prefer some kind of errors to others. In this paper, we present a comparative evaluation of a representative selection of Machine Learning algorithms for UCE filtering. The algorithms take advantage of two kinds of information: the words in the messages and a set of heuristics. Also, the algorithms are biased by a cost weighting schema to avoid, if possible, misclassifying legitimate e-mail. Finally, algorithms are evaluated according to cost-sensitive measures. 2 Heuristics for UCE classification Sahami and others (Sahami et al., 1998) have proposed a set of heuristic features to complement the word Bayesian model in their work, including: a set of around 35 hand-crafted key phrases (like &amp;quot;free money&amp;quot;); some non text features (like the domain of the sender, or whether the message comes from a distribution list or not); and features concerning the nonalphanumeric characters in the messages. For this work, we have focused in this last set of features. The test collection used in our experiments, Spambase, already contained a set of nine heuristic features. Spambasel is an e-mail messages collection containing 4601 messages, b</context>
<context position="9611" citStr="Sahami et al., 1998" startWordPosition="1550" endWordPosition="1554"> UCE messages are deleted without notifying the user of the UCE filter. Nevertheless, PART-WH shows competitive performance for a cost ratio of 9. Its numbers are comparable to those shown in a commercial study by the top performing Brightmail filtering system (Mariano, 2000), which reaches a UCE recall of 0.73, and a precision close to 1.0, and it is manually updated. Naive Bayes has not shown high variability with respect to costs. This is probably due to the sampling method, which only slightly affects to the estimation of probabilities (done by approximation to a normal distribution). In (Sahami et al., 1998; Androutsopoulos et al., 2000), the method followed is the variation of the probability threshold, which leads to a high variation of results. In future experiments, we plan to apply the uniform method MetaCost (Domingos, 1999) to the algorithms tested in this work, for getting more comparable results. With respect to the use of heuristics, we can see that this information alone is not competitive, but it can improve classification based on words. The improvement shown in our experiments is modest, due to the heuristics used. We are not able to add other heuristics in this case because the Sp</context>
</contexts>
<marker>Sahami, Dumais, Heckerman, Horvitz, 1998</marker>
<rawString>Mehran Sahami, Susan Dumais, David Heckerman, and Eric Horvitz. 1998. A bayesian approach to filtering junk e-mail. In Learning for Text Categorization: Papers from the 1998 Workshop. AAAI Tech. Rep. WS-98-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Sebastiani</author>
</authors>
<title>A tutorial on automated text categorisation.</title>
<date>1999</date>
<booktitle>In Proc. of the First Argentinian Symposium on Artificial Intelligence (ASAI-99).</booktitle>
<contexts>
<context position="1821" citStr="Sebastiani, 1999" startWordPosition="271" endWordPosition="272">have been proposed, from technical to regulatory (Cranor and LaMacchia, 1998). Among the technical ones, the use of filtering methods is popular and effective. UCE filtering is a text categorization task. Text categorization (TC) is the classification of documents with respect to a set of one or more pre-existing categories. In the case of UCE, the task is to classify e-mail messages or newsgroups articles as UCE or not (that is, legitimate). The general model of TC makes use of a set of preclassified documents to classify new ones, according to the text content (i.e. words) of the documents (Sebastiani, 1999). Although UCE filtering seems to be a simple instance of the more general TC task, it shows * Partially supported by the CICYT, project no. TEL99-0335-004-03 two special characteristics: • First, UCE filtering has been developed using very simple heuristics for many years. For example, one individual could manually build a filter that classifies as &amp;quot;spam&amp;quot; messages containing the phrase &amp;quot;win big money&amp;quot;, or with an unusual (big) number of capital letters or non-alphanumeric characters. These rules are examples of simple but powerful heuristics that could be used to complement a word-based autom</context>
</contexts>
<marker>Sebastiani, 1999</marker>
<rawString>Fabrizio Sebastiani. 1999. A tutorial on automated text categorisation. In Proc. of the First Argentinian Symposium on Artificial Intelligence (ASAI-99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Prank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<marker>Witten, Prank, 1999</marker>
<rawString>Ian H. Witten and Eibe Prank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
</authors>
<title>An evaluation of statistical approaches to text categorization.</title>
<date>1999</date>
<journal>Information Retrieval,</journal>
<pages>1--1</pages>
<contexts>
<context position="2831" citStr="Yang, 1999" startWordPosition="434" endWordPosition="435">money&amp;quot;, or with an unusual (big) number of capital letters or non-alphanumeric characters. These rules are examples of simple but powerful heuristics that could be used to complement a word-based automatic TC system for UCE filtering. • Second, all UCE filtering errors are not of equal importance. Individuals usually prefer conservative filters that tend to classify UCE as legitimate, because missing a legitimate message is more harmful than the opposite. A cost model is imperative to avoid the risk of missing legitimate e-mail. Many learning algorithms have been applied to the problem of TC (Yang, 1999), but much less with the problem of UCE filtering in mind. Sahami and others (1998) propose the utilization of a Naive Bayes classifier based on the words and a set of manually derived heuristics for UCE filtering, showing that the heuristics improve the effectiveness of the classifier. Druker and others (1999) compare boosting, Support Vector Machines, Ripper and Rocchio classifiers for UCE filtering. Andruotsopoulos and others (2000) present a cost-oriented evaluation of the Naive Bayes and k-nearest neighbor (kNN) algorithms for UCE filtering. Finally, Provost (1999) compares Naive Bayes an</context>
</contexts>
<marker>Yang, 1999</marker>
<rawString>Yiming Yang. 1999. An evaluation of statistical approaches to text categorization. Information Retrieval, 1(1-2).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>