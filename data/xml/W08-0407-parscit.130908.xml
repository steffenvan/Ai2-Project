<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001694">
<title confidence="0.9982025">
Experiments in discriminating phrase-based translations on the basis of
syntactic coupling features
</title>
<author confidence="0.939391">
Vassilina Nikoulina and Marc Dymetman
</author>
<affiliation confidence="0.812258">
Xerox Research Centre Europe
Grenoble, France
</affiliation>
<email confidence="0.992877">
Inikoulina,dymetmanj@xrce.xerox.com
</email>
<sectionHeader confidence="0.995562" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896388888889">
We describe experiments on discriminating
English to French phrase-based translations
through the use of syntactic “coupling” fea-
tures. Using a robust rule-based dependency
parser, we parse both the English source and
the French translation candidates from the n-
best list returned by our phrase-based system;
we compute for each candidate a number of
coupling features, that is, values that depend
on the amount of alignment between edges in
the source and target structures, and discrim-
inatively train the weights of these coupling
features. We compare different feature combi-
nations. Although the improvements in terms
of automatic measures such as Bleu and Nist
are inconclusive, an initial human assessment
of the results appears to show certain qualita-
tive improvements.
</bodyText>
<sectionHeader confidence="0.998894" genericHeader="introduction">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.987146">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.998620083333333">
When we use the phrase-based SMT system MA-
TRAX (Simard et al., 2005) to translate the sen-
tence Our declaration of rights is the first of this
millenium from English to French, the result re-
turned by the system is the erroneous translation
Notre d´eclaration des droits de la premi`ere est de
ce mill´enaire, while somewhere down the n-best list
of lesser-scored candidates we find a correct transla-
tion: Notre d´eclaration des droits est la premi`ere de
ce mill´enaire.
On closer inspection, the difference of scores be-
tween the two candidates is the following. In the
</bodyText>
<page confidence="0.978378">
55
</page>
<bodyText confidence="0.999904794117647">
second (correct) case, the phrase of rights was trans-
lated into the phrase des droits, while in the first (in-
correct) case, the phrase of was translated into the
phrase de and the phrase rights into the phrase des
droits. However, while the two bi-phrases of/de and
rights/des droits independently make perfect sense,
the sequence de des droits in French is not possi-
ble, a situation which is easily detected by a stan-
dard ngram language model; the language model has
then a tendency to try to place the (in fact superflu-
ous) de at a further place in the target (just before
la premi`ere), where it is more acceptable to it. The
overall consequence is a translation that while for-
mally possible from the viewpoint of a simple lan-
guage model, is not an adequate representation of
the meaning of the source.
Now suppose that we parse both the source and
the two candidates with a dependency parser. If we
compare the parses of the source and of the correct
translation, we find a close (in the current exam-
ple, very close) isomorphism between dependency
edges connecting pairs of aligned words (s1, s2) and
(t1, t2), where si is aligned to ti: the presence of
an edge between s1 and s2 often implies that of an
edge between t1 and t2. This is less the case if we
compare the parses of the source and of the incor-
rect translation; in this case, the word premi`ere is
now linked to droits, while the word first was linked
to millenium.
While this is of course just one example, it does
help to motivate the approach we have taken: we
compute different measures of association strength
between edges in the source and target dependency
trees, and use these measures as features for rerank-
</bodyText>
<note confidence="0.6117435">
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 55–60,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998535">
ing the n-best candidates of a baseline phrase-based
system. The hope is that by doing so, we will in-
crease the adequacy of translations, and possibly to
some extent, their fluency (at least their “seman-
tic” fluency, which is influenced by their adequacy,
as opposed to their “grammatical” fluency, which
would be better addressed by target-specific syntac-
tic features than by coupling syntactic features).
</bodyText>
<sectionHeader confidence="0.681394" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<bodyText confidence="0.999983684210526">
There is a growing body of work on the use of syntax
for improving statistical machine translation, from
approaches such as (Chiang, 2007) that use “formal
syntax”, that is syntactic structures for the source
and target that are discovered on the basis of a bilin-
gual corpus, but without resort to an externally mo-
tivated parser, to approaches such as (Yamada and
Knight, 2001) and (Marcu et al., 2006) that use an
external parser on the target only, or such as (Quirk
et al., 2005) on the source only, or such as (Cowan et
al., 2006) that use external parsers both on the source
and on the target.
Our approach is in this last category, but is distin-
guished from all the cited approaches by the fact that
it does not try to build a target structure (or string)
directly, but rather by using a baseline phrase-based
system as a generator of candidates, and then select-
ing between these candidates through a discrimina-
tive procedure. Some other researchers have taken a
similar line, for example (Hasan et al., 2006), which
only uses a parser on the target, and attempts to im-
prove the fluency of the translation produced, and es-
pecially (Och et al., 2003) that reports experiments
using a large number of syntactic features. In one
of the experiments briefly reported, a dependency
parser is used both for the source and for the tar-
get and a few features are introduced for counting
the number of edges that project from the source
to the target. This experiment, which as far as we
know was not followed up by deeper investigations,
is very similar to what we do. However we intro-
duce and compare results for a wider variety of cou-
pling features, taking into account different combi-
nations involving normalization of the counts, sym-
metrized features between the source and target, la-
belled dependencies, and also consider several ways
for computing the word alignment on the basis of
which edge couplings are determined.
</bodyText>
<sectionHeader confidence="0.750193" genericHeader="method">
2 The approach
</sectionHeader>
<subsectionHeader confidence="0.979032">
2.1 Background
</subsectionHeader>
<bodyText confidence="0.999286333333333">
Matrax. The phrase-based SMT system Matrax
(Simard et al., 2005), developed at Xerox, was
used in the experiments. Matrax is based on a
fairly standard log-linear model, but one original as-
pect of the system is the use of non-contiguous bi-
phrases. Most existing phrase-based models depend
on phrases that are sequences of contiguous words
on either the source or the target side (e.g. pren-
dre feu / catch fire). By contrast, Matrax considers
pairs of non-contiguous phrases, such as ne ... plus /
not ... anymore, where words in the source and tar-
get phrases may be separated by gaps, to be filled
at translation time by lexical material provided by
some other such pairs. One motivation behind this
approach is that, basically, the fact that the source
expression ne ... plus is a good predictor of not
... anymore does not depend on the lexical material
appearing inside the source expression, an insight
which is generally unexploitable by models based
on contiguous phrases.1
XIP. For parsing, we used the Xerox Incremen-
tal Parser XIP (Ait-Mokhtar et al., 2002), which is
a robust dependency parser developed at the Xerox
Research Centre Europe. XIP is fast (around 2000
words per second for English) and is well adapted to
a situation, like the one we have here, were we need
to parse on the order of a few hundred target candi-
dates on the fly. Also of interest to us is the fact that
XIP produces labelled dependencies, a feature that
we use in some of our experiments.
</bodyText>
<subsectionHeader confidence="0.999643">
2.2 Decoding and Training
</subsectionHeader>
<bodyText confidence="0.9999769">
Coupling features such as the ones we use require
access to the parses of candidate translations, and
these parses, at least for a parser such as XIP (and
for many similar parsers), can only be obtained once
the complete candidate translation is known. This is
why it is difficult to introduce them internally in the
Matrax stack-based decoder, which would require to
provide partial parses for prefixes of the target can-
didates and also associated heuristics to estimate the
syntactic structure of completions of these prefixes.
</bodyText>
<footnote confidence="0.983836">
1The Hiero system (Chiang, 2007) is a well-known in-
stance of a structure-oriented system that also has a notion of
gapped phrases, but contrary to Hiero, Matrax is based on non-
hierarchical phrases.
</footnote>
<page confidence="0.99727">
56
</page>
<bodyText confidence="0.999962818181818">
Instead, we resort to a standard reranking approach
in which we produce an n-best list of Matrax candi-
date translations (with n = 100 in our experiments),
and then rerank this list with a linear combination
of our parse-dependent features. In order to train
the feature weights, we use an averaged structured
perceptron approach a` la Collins, where we try to
learn weights such that the first candidate to emerge
is equal to the “oracle” candidate, that is, the candi-
date that is closest to the reference in terms of NIST
score.
</bodyText>
<subsectionHeader confidence="0.999871">
2.3 Coupling Features
</subsectionHeader>
<bodyText confidence="0.999970105263158">
Our general approach to computing coupling fea-
tures between the dependency structure of the source
and that of a candidate translation produced by Ma-
trax is the following: we start by aligning the words
between the source and the candidate translation, we
parse both sides, and we count (possibly according
to a weighting scheme) the number of configura-
tions (“rectangles”) that are of the following type:
((s1, s12, s2), (t1, t12, t2)), where s12 is an edge be-
tween s1 and s2, t12 is an edge between t1 and t2,
s1 is aligned with t1 and s2 is aligned with t2. We
implemented several variants of this basic scheme.
We start by describing different “generic” cou-
pling functions derived from the basic scheme, as-
suming that word alignments have been already de-
termined, then we describe the option of taking into
account specific dependency labels when counting
rectangles, and finally we describe two options for
computing the word alignments.
</bodyText>
<subsectionHeader confidence="0.470407">
2.3.1 Generic features
</subsectionHeader>
<bodyText confidence="0.9958388">
The first measure of coupling is based on sim-
ple, non-weighted, word alignments. Here we sim-
ply consider that a word of the source and a word
of the target are aligned or not aligned, without any
intermediary degree, and consider that a rectangle
exists on the quadruple of words s1, s2, t1, t2 iff si
is aligned to ti, s1 and s2 have a dependency link
between them (in whatever direction) and similarly
for t1 and t2. The first feature that we introduce,
Coupling-Count, is simply the count of all such rect-
angles between the source and the target.
We note that the value of this feature tends to be
correlated with the size of the source and target de-
pendency trees. We therefore introduce some nor-
malized variants of the feature:
</bodyText>
<listItem confidence="0.980659909090909">
• Coupling-Recall. We compute the number of
source edges for which there exists a projec-
tion in the target. More formally, the number of
edges between two words s1, s2 such that there
exist two words t1, t2 with si aligned to ti and
such that t1, t2 have an edge between them. We
then divide this number by the total number of
edges in the source.
• Coupling-Precision. We do the same thing this
time starting from the target.
• Coupling-F-measure. In the case of perfectly
</listItem>
<bodyText confidence="0.969066588235294">
isomorphic dependency trees (a situation that
of course rarely occurs because of the linguis-
tic divergences between languages), we would
have precision and recall both equal to 1. In or-
der to measure divergence from this ideal case,
we introduce a feature that we call Coupling-
F-measure, which is defined as the harmonic
mean of the two previous features.
One deficiency of the previous measures is that
they rely a lot on “hard” word alignments, but do not
take into account the probability of aligning a source
and a target word. We introduce another feature
Coupling-Lex that exploits lexical translation prob-
abilities: each rectangle found between the source
and target trees is weighted according to the prod-
uct of the translation probabilities associated with
(s1, t1) and (s2, t2).
</bodyText>
<subsectionHeader confidence="0.506501">
2.3.2 Label-specific features
</subsectionHeader>
<bodyText confidence="0.943534647058824">
The features previously defined do not take into
account the labels associated with edges in the de-
pendency trees. However, while rectangles of the
form ((s1, subj, s2), (t1, subj, t2)) may be rather sys-
tematic between such languages as English and
French, other rectangles may be much less so, due
on the one hand to actual linguistic divergences be-
tween the two languages, but also, as importantly
in practice, to different representational conventions
used by different grammar developers for the two
languages.2
In order to control this problem, we introduce a
collection of Label-Specific-Coupling features, each
for a specific pair of source label and target label.
2Although the XIP formalism is shared between grammar
developers of French and English, the grammars do sometimes
follow slightly different conventions.
</bodyText>
<page confidence="0.997473">
57
</page>
<bodyText confidence="0.999858375">
The values of a label-specific feature are the num-
ber of occurrences for this specific label pair. We
use only label pairs that have been observed to be
aligned in the training corpus (that is, that partici-
pate in observed rectangles). In one version of that
approach, we use all such pairs found in the corpus,
in another version only the pairs above a certain fre-
quency threshold in the corpus.
</bodyText>
<subsectionHeader confidence="0.63832">
2.3.3 Giza-based alignment
</subsectionHeader>
<bodyText confidence="0.999765333333333">
In order to compute the features described above,
a prerequisite is to be able to determine a word align-
ment between the source and a candidate transla-
tion. Our first approach is to use GIZA++ to create
these alignments, by producing for a given source
and a given candidate translation n-best alignment
lists in both directions and applying standard tech-
niques of symmetrization to produce a bidirectional
alignment.
</bodyText>
<subsectionHeader confidence="0.533253">
2.3.4 Phrase-based alignment
</subsectionHeader>
<bodyText confidence="0.999989208333333">
Another way to find word alignments is to use the
information provided by our baseline system. Since
Matrax is a phrase-based system, it has access to
the bi-phrases (aligned by definition) that are used
in order to generate a candidate translation. How-
ever note that if we use the bi-phrases directly we
are not able to establish the alignments on a word
level (since Matrax does not provide any informa-
tion about word alignments inside the bi-phrases),
but only on a phrase level, and we need to adapt the
coupling features accordingly.
To overcome this problem, we will transform the
dependencies between words into dependencies be-
tween phrases. Thus, two phrases c1, c2 will have a
dependency edge between them if there exists a de-
pendency edge between a word w1 E c1 and a word
w2 E c2. Once this transformation is done both
for the source and the target, we get dependency
graphs having phrases as nodes. We also know the
alignments between these phrases, implicit in the bi-
phrases used by Matrax. So, we can consider the
phrases as super-words, and introduce coupling fea-
tures of the same type as before, but operating on a
higher level (super-words) this time.
</bodyText>
<sectionHeader confidence="0.998951" genericHeader="evaluation">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.988098">
3.1 Description
</subsectionHeader>
<bodyText confidence="0.987516076923077">
For all our experiments we use the training, develop-
ment and test sets provided for the English-French
News Commentary corpus in WMT-08. The num-
ber of sentences in these sets are respectively 55039,
1057 and 1064, and the average sentence length is 21
words (English) and 24.5 words (French).
We take Matrax as the baseline system. With this
system we generate 100-best lists of candidate trans-
lations for all source sentences of the test set, we
rerank these candidates using our features, and we
output the top candidate. We present our results in
Table 1, distinguished according to the actual com-
bination of features used in each experiment.
</bodyText>
<listItem confidence="0.976351821428571">
• The Baseline entry in the table corresponds to
Matrax results on the test set, without the use
of any of the coupling features.
• We distinguish two sub-tables, according to
whether Giza-based alignments or phrase-
based alignments were used.
• The Generic keyword corresponds to the cou-
pling features introduced in section 2.3.1, based
on rectangle counts, independent of the labels
of the edges.
• The Matrax keyword corresponds to using Ma-
trax “internal” features as reranking features,
along with the coupling features. These Ma-
trax features are pretty standard phrase-based
features, apart from some features dealing ex-
plicitly with gapped phrases, and are described
in detail in (Simard et al., 2005).
• The Labels and Frequent Labels keywords cor-
responds to using label-specific features. In
the first case (Labels) we extracted all of the
aligned label pairs (label pair associated with a
coupling rectangle) found in a training set of
1000 source sentences along with their 100-
best Matrax translations (this set was chosen
to be different from the development set in or-
der to avoid overfitting effects when rerank-
ing on the development set); we then obtained
2053 features of this kind. In the second case
</listItem>
<page confidence="0.994061">
58
</page>
<table confidence="0.998310285714285">
NIST BLEU - + Diff
Baseline 6.4093 0.2034 0 0 0
Giza-based alignments
Generic 6.3383 0.2043 15 17 2
Generic, Matrax 6.3782 0.2083 4 18 14
Labels 6.3483 0.1963 12 18 6
Labels, Generic 6.3514 0.2010 3 18 15
Labels, Generic, Matrax 6.4016 0.2075 3 20 17
Frequent Labels 6.3815 0.2054 7 11 4
Frequent Labels, Generic 6.3826 0.2044 6 18 12
Frequent Labels, Generic, Matrax 6.4177 0.2100 2 16 14
Phrase-based alignments
Generic 6.2869 0.1964 12 14 2
Generic, Matrax 6.3972 0.2031 4 11 7
Labels 6.3677 0.1995 16 15 -1
Labels, Generic 6.3567 0.1977 8 15 7
Labels, Generic, Matrax 6.4269 0.2049 4 17 13
Frequent Labels 6.3701 0.1998 3 15 12
Frequent Labels, Generic 6.3846 0.2013 7 16 9
Frequent Labels, Generic, Matrax 6.4160 0.2049 4 16 12
Giza Generic, Phrase Generic, Giza Labels, Matrax 6.4351 0.2060 7 22 15
</table>
<tableCaption confidence="0.999913">
Table 1: Reranking results.
</tableCaption>
<bodyText confidence="0.997062666666667">
(Frequent Labels), we only kept the most fre-
quently observed among these label pairs, re-
taining only 137 such features.
</bodyText>
<listItem confidence="0.711748428571429">
• When several keywords appear on a line, we
used the union of the corresponding features,
and in the last line of the table, we show a
combination involving at the same time some
features computed on the basis of Giza-based
alignments and of phrase-based alignments.
• Along with the NIST and BLEU scores of each
</listItem>
<bodyText confidence="0.991069363636364">
combination3, we also conducted an informal
manual assessment of the quality of the results
relative to the Matrax baseline. We took a ran-
dom sample of 100 source sentences from the
test set and for each sentence, assessed whether
the first candidate produced by reranking was
better, worse, or indistinguishable in terms of
quality relative to the baseline translation. We
report the number of improvements (+) and de-
teriorations (-) among these 100 samples as
well as their difference.
</bodyText>
<footnote confidence="0.6824785">
3These scores were computed on the basis of only one ref-
erence.
</footnote>
<subsectionHeader confidence="0.997632">
3.2 Discussion of the results
</subsectionHeader>
<bodyText confidence="0.99996335">
While the overall results in terms of Bleu and Nist
do not show major improvements relative to the
baseline, there are several interesting observations to
make. First of all, if we focus on feature combina-
tions in which Matrax features are included (shown
in italics in the table), we see that there is a gen-
eral tendency for the results, both in terms of auto-
matic and human evaluations, to be better than for
the same combination without the Matrax features;
the explanation seems to be that if we do not use the
Matrax features during reranking, but consider the
100 candidates in the n-best list to be equally valu-
able from the viewpoint of Matrax features, we lose
essential information that cannot be recovered sim-
ply by appeal to the syntactic coupling features.4
If we now concentrate on the lines which do in-
clude Matrax features and compare their results with
the baseline, we see a trend for these results to be
better than the baseline, both in terms of automatic
measures as (more strongly) in terms of human eval-
</bodyText>
<footnote confidence="0.9984735">
4This is not very surprising and probably on the basis of this
observation it would be useful in further experiments to intro-
duce as an additional feature the log-linear score given by the
Matrax baseline.
</footnote>
<page confidence="0.998885">
59
</page>
<bodyText confidence="0.999939444444444">
uation. Taken individually, perhaps the improve-
ments are not very clear, but collectively, a trend
does seem to appear in favor of syntactic coupling
features generally, although we have not conducted
formal statistical tests to validate this impression. A
more detailed comparison between individual lines,
inside the class of combinations that include Matrax
features, appears however difficult to make on the
basis of the current experiments.
</bodyText>
<sectionHeader confidence="0.989781" genericHeader="conclusions">
4 Conclusion and Perspectives
</sectionHeader>
<bodyText confidence="0.993026333333333">
Although there is some consensus that the future
of statistical machine translation lies in the use of
structural information, it is generally admitted that
it is currently difficult to significantly improve over
phrase-base systems in this way, at least in terms of
automatic evaluation measures. Our results do not
contradict that impression, although they are more
encouraging in terms of preliminary human asses-
ments than in terms of the automatic measures.
The reranking approach to using syntactic fea-
tures on top of a phrase-based system is attractive
because on the one hand it is easier to implement
than a full new syntax-aware decoder, and on the
other hand it guarantees at least as good perfor-
mance as the baseline phrase-based system, if some
precautions are taken. On the other hand, its main
limitations concern the size of the n-best list of can-
didates that is realistic in terms of decoding time.5
At least two approaches seem promising in order to
alleviate this problem: (1) find a way to capitalize
on the factorization of translation candidates in the
internal lattice used by the phrase-based decoder, in
order to produce factorized parses that would permit
comparison between more candidates than can be
seen through a final n-best list; (2) allow the reranker
to perform local transformations of the n-best candi-
dates, in the spirit of (Langlais et al., 2007), in order
to be able to explore a larger space of promising can-
didates than is provided by the static list.
Another interesting direction would be to learn
the feature weights by reranking towards another
type of oracle than the one we used, which is de-
fined as the closest candidate in the list in terms of
NIST score relative to the reference; instead it might
5It should be noted however that we could increase this size
from 100 to 1000 without incurring too much penalty, given the
speed of the XIP parser we use.
be worthwhile to use as an oracle the candidate in
the list which receives the best human assessment
in terms of fluency and adequacy, giving a better
chance to the syntactic features to show their worth;
but this would probably also require that these sys-
tems be mostly evaluated in terms of human assess-
ment, a trend which is more and more noticeable in
the SMT community.
</bodyText>
<sectionHeader confidence="0.999172" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999874595238096">
Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond shallowness: incre-
mental deep parsing. Natural Language Engineering,
8(3):121–144.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
Brooke Cowan, Ivona Kucerova, and Michael Collins.
2006. A discriminative model for tree-to-tree trans-
lation. In Proceedings EMNLP.
Saˇsa Hasan, Oliver Bender, and Hermann Ney. 2006.
Reranking translation hypotheses using structural
properties. In Proceedings of the EACL Workshop on
Learning Structured Information in Natural Language
Applications.
Philippe Langlais, Alexandre Patry, and Fabrizio Gotti.
2007. A greedy decoder for phrase-based statistical
machine translation. In Proceedings of the 11th Inter-
national Conference on Theoretical and Methodolog-
ical Issues in Machine Translation, pages 104–113,
Skvde, Sweden, Sept.
D. Marcu, W. Wang, A. Echihabi, and K. Knight.
2006. SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases. In Proceedings
EMNLP, pages 44–52.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syn-
tax for statistical machine translation: Final report of
john hopkins 2003 summer workshop. Technical re-
port, John Hopkins University.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In ACL05.
Michel Simard, Nicola Cancedda, Bruno Cavestro,
Marc Dymetman, ´Eric Gaussier, Cyril Goutte,
Kenji Yamada, Philippe Langlais, and Arne Mauser.
2005. Translating with non-contiguous phrases. In
HLT/EMNLP.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proceedings ACL,
pages 531–538.
</reference>
<page confidence="0.998411">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.503677">
<title confidence="0.9863795">Experiments in discriminating phrase-based translations on the basis syntactic coupling features</title>
<author confidence="0.980848">Vassilina Nikoulina</author>
<author confidence="0.980848">Marc</author>
<affiliation confidence="0.998856">Xerox Research Centre</affiliation>
<address confidence="0.544416">Grenoble,</address>
<email confidence="0.994112">Inikoulina,dymetmanj@xrce.xerox.com</email>
<abstract confidence="0.998228789473684">We describe experiments on discriminating English to French phrase-based translations through the use of syntactic “coupling” features. Using a robust rule-based dependency parser, we parse both the English source and the French translation candidates from the nbest list returned by our phrase-based system; we compute for each candidate a number of coupling features, that is, values that depend on the amount of alignment between edges in the source and target structures, and discriminatively train the weights of these coupling features. We compare different feature combinations. Although the improvements in terms of automatic measures such as Bleu and Nist are inconclusive, an initial human assessment of the results appears to show certain qualitative improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah A¨ıt-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>Robustness beyond shallowness: incremental deep parsing.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>3</issue>
<marker>A¨ıt-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude Roux. 2002. Robustness beyond shallowness: incremental deep parsing. Natural Language Engineering, 8(3):121–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="4059" citStr="Chiang, 2007" startWordPosition="662" endWordPosition="663">. c�2008 Association for Computational Linguistics ing the n-best candidates of a baseline phrase-based system. The hope is that by doing so, we will increase the adequacy of translations, and possibly to some extent, their fluency (at least their “semantic” fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a targe</context>
<context position="7937" citStr="Chiang, 2007" startWordPosition="1330" endWordPosition="1331">some of our experiments. 2.2 Decoding and Training Coupling features such as the ones we use require access to the parses of candidate translations, and these parses, at least for a parser such as XIP (and for many similar parsers), can only be obtained once the complete candidate translation is known. This is why it is difficult to introduce them internally in the Matrax stack-based decoder, which would require to provide partial parses for prefixes of the target candidates and also associated heuristics to estimate the syntactic structure of completions of these prefixes. 1The Hiero system (Chiang, 2007) is a well-known instance of a structure-oriented system that also has a notion of gapped phrases, but contrary to Hiero, Matrax is based on nonhierarchical phrases. 56 Instead, we resort to a standard reranking approach in which we produce an n-best list of Matrax candidate translations (with n = 100 in our experiments), and then rerank this list with a linear combination of our parse-dependent features. In order to train the feature weights, we use an averaged structured perceptron approach a` la Collins, where we try to learn weights such that the first candidate to emerge is equal to the “</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brooke Cowan</author>
<author>Ivona Kucerova</author>
<author>Michael Collins</author>
</authors>
<title>A discriminative model for tree-to-tree translation.</title>
<date>2006</date>
<booktitle>In Proceedings EMNLP.</booktitle>
<contexts>
<context position="4455" citStr="Cowan et al., 2006" startWordPosition="733" endWordPosition="736">t-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve the fluency of the translation produced, and especial</context>
</contexts>
<marker>Cowan, Kucerova, Collins, 2006</marker>
<rawString>Brooke Cowan, Ivona Kucerova, and Michael Collins. 2006. A discriminative model for tree-to-tree translation. In Proceedings EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇsa Hasan</author>
<author>Oliver Bender</author>
<author>Hermann Ney</author>
</authors>
<title>Reranking translation hypotheses using structural properties.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL Workshop on Learning Structured Information in Natural Language Applications.</booktitle>
<contexts>
<context position="4936" citStr="Hasan et al., 2006" startWordPosition="816" endWordPosition="819"> 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve the fluency of the translation produced, and especially (Och et al., 2003) that reports experiments using a large number of syntactic features. In one of the experiments briefly reported, a dependency parser is used both for the source and for the target and a few features are introduced for counting the number of edges that project from the source to the target. This experiment, which as far as we know was not followed up by deeper investigations, is very similar to what we do. However we introduce and compare results for a wid</context>
</contexts>
<marker>Hasan, Bender, Ney, 2006</marker>
<rawString>Saˇsa Hasan, Oliver Bender, and Hermann Ney. 2006. Reranking translation hypotheses using structural properties. In Proceedings of the EACL Workshop on Learning Structured Information in Natural Language Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>Alexandre Patry</author>
<author>Fabrizio Gotti</author>
</authors>
<title>A greedy decoder for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>104--113</pages>
<location>Skvde, Sweden,</location>
<contexts>
<context position="21358" citStr="Langlais et al., 2007" startWordPosition="3588" endWordPosition="3591">utions are taken. On the other hand, its main limitations concern the size of the n-best list of candidates that is realistic in terms of decoding time.5 At least two approaches seem promising in order to alleviate this problem: (1) find a way to capitalize on the factorization of translation candidates in the internal lattice used by the phrase-based decoder, in order to produce factorized parses that would permit comparison between more candidates than can be seen through a final n-best list; (2) allow the reranker to perform local transformations of the n-best candidates, in the spirit of (Langlais et al., 2007), in order to be able to explore a larger space of promising candidates than is provided by the static list. Another interesting direction would be to learn the feature weights by reranking towards another type of oracle than the one we used, which is defined as the closest candidate in the list in terms of NIST score relative to the reference; instead it might 5It should be noted however that we could increase this size from 100 to 1000 without incurring too much penalty, given the speed of the XIP parser we use. be worthwhile to use as an oracle the candidate in the list which receives the b</context>
</contexts>
<marker>Langlais, Patry, Gotti, 2007</marker>
<rawString>Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–113, Skvde, Sweden, Sept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>W Wang</author>
<author>A Echihabi</author>
<author>K Knight</author>
</authors>
<title>SPMT: Statistical Machine Translation with Syntactified Target Language Phrases.</title>
<date>2006</date>
<booktitle>In Proceedings EMNLP,</booktitle>
<pages>44--52</pages>
<contexts>
<context position="4323" citStr="Marcu et al., 2006" startWordPosition="706" endWordPosition="709"> fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan </context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>D. Marcu, W. Wang, A. Echihabi, and K. Knight. 2006. SPMT: Statistical Machine Translation with Syntactified Target Language Phrases. In Proceedings EMNLP, pages 44–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
</authors>
<title>Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar,</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>John Hopkins University.</institution>
<location>Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen</location>
<marker>Och, Gildea, 2003</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syntax for statistical machine translation: Final report of john hopkins 2003 summer workshop. Technical report, John Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In ACL05.</booktitle>
<contexts>
<context position="4403" citStr="Quirk et al., 2005" startWordPosition="722" endWordPosition="725">l” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar line, for example (Hasan et al., 2006), which only uses a parser on the target, and attempts to improve t</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In ACL05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Nicola Cancedda</author>
<author>Bruno Cavestro</author>
<author>Marc Dymetman</author>
</authors>
<title>Eric Gaussier, Cyril Goutte,</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<location>Kenji Yamada, Philippe Langlais, and</location>
<contexts>
<context position="1103" citStr="Simard et al., 2005" startWordPosition="156" endWordPosition="159">om the nbest list returned by our phrase-based system; we compute for each candidate a number of coupling features, that is, values that depend on the amount of alignment between edges in the source and target structures, and discriminatively train the weights of these coupling features. We compare different feature combinations. Although the improvements in terms of automatic measures such as Bleu and Nist are inconclusive, an initial human assessment of the results appears to show certain qualitative improvements. 1 Introduction 1.1 Motivation When we use the phrase-based SMT system MATRAX (Simard et al., 2005) to translate the sentence Our declaration of rights is the first of this millenium from English to French, the result returned by the system is the erroneous translation Notre d´eclaration des droits de la premi`ere est de ce mill´enaire, while somewhere down the n-best list of lesser-scored candidates we find a correct translation: Notre d´eclaration des droits est la premi`ere de ce mill´enaire. On closer inspection, the difference of scores between the two candidates is the following. In the 55 second (correct) case, the phrase of rights was translated into the phrase des droits, while in </context>
<context position="5937" citStr="Simard et al., 2005" startWordPosition="986" endWordPosition="989"> edges that project from the source to the target. This experiment, which as far as we know was not followed up by deeper investigations, is very similar to what we do. However we introduce and compare results for a wider variety of coupling features, taking into account different combinations involving normalization of the counts, symmetrized features between the source and target, labelled dependencies, and also consider several ways for computing the word alignment on the basis of which edge couplings are determined. 2 The approach 2.1 Background Matrax. The phrase-based SMT system Matrax (Simard et al., 2005), developed at Xerox, was used in the experiments. Matrax is based on a fairly standard log-linear model, but one original aspect of the system is the use of non-contiguous biphrases. Most existing phrase-based models depend on phrases that are sequences of contiguous words on either the source or the target side (e.g. prendre feu / catch fire). By contrast, Matrax considers pairs of non-contiguous phrases, such as ne ... plus / not ... anymore, where words in the source and target phrases may be separated by gaps, to be filled at translation time by lexical material provided by some other suc</context>
<context position="15900" citStr="Simard et al., 2005" startWordPosition="2668" endWordPosition="2671">ut the use of any of the coupling features. • We distinguish two sub-tables, according to whether Giza-based alignments or phrasebased alignments were used. • The Generic keyword corresponds to the coupling features introduced in section 2.3.1, based on rectangle counts, independent of the labels of the edges. • The Matrax keyword corresponds to using Matrax “internal” features as reranking features, along with the coupling features. These Matrax features are pretty standard phrase-based features, apart from some features dealing explicitly with gapped phrases, and are described in detail in (Simard et al., 2005). • The Labels and Frequent Labels keywords corresponds to using label-specific features. In the first case (Labels) we extracted all of the aligned label pairs (label pair associated with a coupling rectangle) found in a training set of 1000 source sentences along with their 100- best Matrax translations (this set was chosen to be different from the development set in order to avoid overfitting effects when reranking on the development set); we then obtained 2053 features of this kind. In the second case 58 NIST BLEU - + Diff Baseline 6.4093 0.2034 0 0 0 Giza-based alignments Generic 6.3383 0</context>
</contexts>
<marker>Simard, Cancedda, Cavestro, Dymetman, 2005</marker>
<rawString>Michel Simard, Nicola Cancedda, Bruno Cavestro, Marc Dymetman, ´Eric Gaussier, Cyril Goutte, Kenji Yamada, Philippe Langlais, and Arne Mauser. 2005. Translating with non-contiguous phrases. In HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings ACL,</booktitle>
<pages>531--538</pages>
<contexts>
<context position="4298" citStr="Yamada and Knight, 2001" startWordPosition="701" endWordPosition="704">ncy (at least their “semantic” fluency, which is influenced by their adequacy, as opposed to their “grammatical” fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features). 1.2 Related Work There is a growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (Chiang, 2007) that use “formal syntax”, that is syntactic structures for the source and target that are discovered on the basis of a bilingual corpus, but without resort to an externally motivated parser, to approaches such as (Yamada and Knight, 2001) and (Marcu et al., 2006) that use an external parser on the target only, or such as (Quirk et al., 2005) on the source only, or such as (Cowan et al., 2006) that use external parsers both on the source and on the target. Our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build a target structure (or string) directly, but rather by using a baseline phrase-based system as a generator of candidates, and then selecting between these candidates through a discriminative procedure. Some other researchers have taken a similar </context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings ACL, pages 531–538.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>