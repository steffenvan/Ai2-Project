<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001036">
<title confidence="0.967735">
Smoothing a Lexicon-based POS Tagger for Arabic and Hebrew
</title>
<author confidence="0.972943">
Saib Mansour Khalil Sima&apos;an Yoad Winter
</author>
<affiliation confidence="0.953859">
Computer Science, Technion ILLC Computer Science, Technion
</affiliation>
<address confidence="0.63605175">
Haifa, 32000, Israel Universiteit van Amsterdam Haifa, 32000, Israel
Amsterdam, The Netherlands and Netherlands Institute for Ad-
vanced Study
Wassenaar, The Netherlands
</address>
<email confidence="0.989193">
saib@cs.technion.ac.il simaan@science.uva.nl winter@cs.technion.ac.il
</email>
<sectionHeader confidence="0.995412" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924634375">
We propose an enhanced Part-of-Speech
(POS) tagger of Semitic languages that
treats Modern Standard Arabic (hence-
forth Arabic) and Modern Hebrew
(henceforth Hebrew) using the same
probabilistic model and architectural set-
ting. We start out by porting an existing
Hidden Markov Model POS tagger for
Hebrew to Arabic by exchanging a mor-
phological analyzer for Hebrew with
Buckwalter&apos;s (2002) morphological ana-
lyzer for Arabic. This gives state-of-the-
art accuracy (96.12%), comparable to Ha-
bash and Rambow’s (2005) analyzer-
based POS tagger on the same Arabic
datasets. However, further improvement
of such analyzer-based tagging methods is
hindered by the incomplete coverage of
standard morphological analyzer (Bar
Haim et al., 2005). To overcome this cov-
erage problem we supplement the output
of Buckwalter&apos;s analyzer with syntheti-
cally constructed analyses that are pro-
posed by a model which uses character
information (Diab et al., 2004) in a way
that is similar to Nakagawa&apos;s (2004) sys-
tem for Chinese and Japanese. A version
of this extended model that (unlike Naka-
gawa) incorporates synthetically con-
structed analyses also for known words
achieves 96.28% accuracy on the standard
Arabic test set.
</bodyText>
<sectionHeader confidence="0.999251" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99980165625">
Part-of-Speech tagging for Semitic languages has
been an active topic of research in recent years.
(Diab et al., 2004; Habash and Rambow, 2005;
Bar-Haim et al., 2005) are some examples for this
line of work on Modern Standard Arabic and Mod-
ern Hebrew. POS tagging systems aim at classify-
ing input sequences of lexemes by assigning each
such sequence a corresponding sequence of most
probable POS tags. It is often assumed that for
each input lexeme there is a set of a priori possible
POS tag categories, or a probability function over
them, and the tagger has to choose from this lim-
ited set of candidate categories. We henceforth use
the term lexicon to refer to the set of lexemes in a
language and the mapping that assigns each of
them candidate POS tags, possibly with additional
probabilities.
Two ways to obtain a lexicon can be distin-
guished in recent works on POS tagging in Semitic
languages. Data-driven approaches like (Diab et al.
2004) employ the lexicon only implicitly when
extracting features on possible POS tags from an-
notated corpora that are used for training the POS
tagger. Lexicon-based approaches (Habash and
Rambow, 2005; Bar-Haim et al., 2005) use a lexi-
con that is extracted from a manually constructed
morphological analyzer (Buckwalter 2002 and
Segal 2001 respectively).
In this paper we show that although lexicon-
based taggers for Arabic and Hebrew may initially
outperform data-driven taggers, they do not ex-
haust the advantages of data-driven approaches.
</bodyText>
<page confidence="0.994764">
97
</page>
<note confidence="0.308122">
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97–103,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.996892738461539">
Consequently, we propose a hybrid model of data-
driven methods and lexicon-based methods, and
show its advantages over both models, in a way
that is reminiscent of Nakagawa&apos;s (2004) results
for Chinese and Japanese.
As a first step, we develop a Part-of-Speech tag-
ger that treats Arabic and Hebrew using the same
probabilistic model and architectural setting. We
start out from MorphTagger, a lexicon-based tag-
ger for Hebrew developed by Bar-Haim et al.
(2005), which uses standard Hidden Markov
Model techniques. We port the existing
MorphTagger implementation to Arabic by ex-
changing Segal&apos;s (2001) morphological analyzer
with Buckwalter&apos;s (2002) morphological analyzer,
and then training the tagger on the Arabic Tree-
bank (Maamouri et al., 2001). Remarkably, this
gives state-of-the-art accuracy (96.12%) on the
same Arabic datasets as Habash and Rambow
(2005). To the best of our knowledge, this is the
first time the same POS tagging architecture is
used both for Arabic and Hebrew texts with com-
parable accuracy.
Despite the initial advantages of this setting, our
empirical study shows that in both languages, fur-
ther improvement in accuracy is hindered by the
incompleteness of the morphological analyzer. By
&amp;quot;incompleteness&amp;quot; we refer not only to the well-
studied problem of unknown words (out-of-
vocabulary). Our results show that for both Arabic
and Hebrew, a more serious problem involves
words for which the analyzer provides a set of
analyses that does not contain the correct one. We
find out that this is the case for 3% of the words in
the development set. This obviously sets an upper
bound on tagger accuracy using methods that are
purely based on a manually constructed lexicon.
We refer to this problem as the &amp;quot;incomplete lexi-
con&amp;quot; problem.
We focus on devising a solution to the incom-
plete lexicon problem by smoothing. We supple-
ment the output of Buckwalter&apos;s analyzer with
synthetically constructed analyses that are pro-
posed by a model which uses character information
(Diab et al., 2004) in a way that is similar to Naka-
gawa&apos;s (2004) system for Japanese. Unlike Naka-
gawa&apos;s method, however, our smoothing method
incorporates synthetically constructed analyses
also for known words, though only when all avail-
able taggings of the sentence have low probabili-
ties according to our model. A version of this
extended model achieves a modest improvement
(96.28%) in accuracy over the baseline on the
standard Arabic test set.
This paper is structured as follows. In section 2
we start with a brief discussion of previous work.
Section 3 describes our adaptation of Bar Haim et
al.’s POS tagging system to Arabic. In section 4
we show that an architecture like Bar Haim et al.’s,
which relies on a morphological analyzer, is likely
to suffer from coverage problems under any con-
figuration where it is used as a stand-alone. In sec-
tion 5 we present our new architecture and the
method of combining the models. Section 6 con-
cludes.
</bodyText>
<sectionHeader confidence="0.958568" genericHeader="method">
2 Relation to Previous Works
</sectionHeader>
<bodyText confidence="0.999911235294118">
Quite a few works have dealt with extending a
given POS tagger, mainly by smoothing it using
extra-information about untreated words. For ex-
ample, (Church, 1988) uses the simple heuristic of
predicting proper nouns from capitalization. This
method is not applicable to Arabic and Hebrew,
which lack typographical marking of proper nouns.
More advanced methods like those described by
Weischedel et al. (1993) incorporate the treatment
of unknown words within the probability model.
Weischedel et al. use derivational and inflectional
endings to infer POS tags of unknown words. Na-
kagawa (2004) addresses the problem of unknown
words for Japanese and Chinese, and uses a hybrid
method of word-level and character-level informa-
tion. In his model, Nakagawa uses character in-
formation (only) when handling unknown words,
claiming that in word-level methods information
about known words helps to achieve higher accu-
racy compared to character-level models. On the
other hand, when it comes to unknown words, Na-
kagawa uses a character-level method, which is
hypothesized to be more robust in such cases than
word-level methods.
Virtually all works that dealt with coverage
problems of POS taggers have concentrated on the
problem of “unknown” words – words that have no
analysis in the initial tagging system. However, in
the context of analyzer-based tagging systems, we
also have to deal with the problem of “known”
words that miss the correct analysis in the morpho-
logical analyzer. In the Arabic and Hebrew data-
sets we have examined, this problem is more
severe than the unknown words problem. Unlike
</bodyText>
<page confidence="0.995026">
98
</page>
<bodyText confidence="0.999934">
previous works, we propose to smooth the word-
segment driven model also for “known” words. To
avoid overgeneration, this is done only when all
taggings of the sentence have low probability.
</bodyText>
<sectionHeader confidence="0.879476" genericHeader="method">
3 Adapting a Hebrew POS-tagger to
Arabic
</sectionHeader>
<bodyText confidence="0.9691937">
Bar Haim et al.&apos;s (2005) POS tagging system,
MorphTagger, was developed initially for Hebrew.
Our work is mainly developed for Arabic and
tested over Arabic data. Due to the similarity in the
morphological processes in Hebrew and Arabic
and the generality of Bar Haim et al.&apos;s architecture,
the adaptation process was fairly simple. However,
as far as we know this is the first implementation
of a unified model for Arabic and Hebrew that
achieves state-of-the-art accuracy. MorphTagger
requires two components: a morphological ana-
lyzer to produce a set of analyses for every lexeme,
and a POS tagged corpus for acquiring an HMM
disambiguator. The HMM disambiguator assigns a
probability to every pair xxxx, where
w1 n , t 1 nw1n = w1...w is a sentence and t1 n = t1...t a corre-
n n
sponding sequence of POS tags hypothesized by
the analyzer. This probability is approximated in a
standard HMM fashion:
</bodyText>
<equation confidence="0.993301">
n
P(wn1, ti) = P(ti )P(wn1  |ti)= flP(ti  |ti−1 , ti−2 Awi  |0
)
1
</equation>
<bodyText confidence="0.994013962962963">
For an input sentence n
w1 , the pair xxxx with
w 1 n , t 1 n
the highest probability is selected. The language
(P(ti  |ti−1, ti−2)) and lexical (P(wi  |ti)) models&apos;
parameters are estimated from the tagged corpus
by Maximum-Likelihood Estimator (MLE) fol-
lowed by Katz backoff smoothing for the language
model and Add-A, smoothing for the lexical model,
where a small A,=1 count is given to analyzes pro-
vided by the analyzer but not found in the training
corpus. Furthermore, MorphTagger employs an
array of other smoothing techniques explained in
Bar Haim et al. (2005).
Our implementation of MorphTagger for Arabic
was developed using Buckwalter’s (2002) Mor-
phological Analyzer v1.0 (BMA1.0), and the Ara-
bic Treebank part 1 v2.0 (ATB1), Part 2 v2.0
(ATB2) and Part 3 v1.0 (ATB3). The ATB was
chosen not only because of its size and comprehen-
siveness, but also because Buckwalter’s analyzer
was developed in accordance with the ATB, which
makes the task of combining information from
both sources easier. In all our experiments we use a
tag-set of 24 tags which was mapped from the
original tag-set (191 tags in ATB1) using the map-
ping script of the ATB distribution.
To check the ambiguity level and the difficulty
of the task at hand, we ran BMA1.0 over a testing
set extracted from ATB1. The average number of
analyses per word is 1.83, and the average number
of segmentations per word is 1.2, however, the task
of disambiguating Arabic is still not easy, as 46%
of the data is ambiguous. Those results are compa-
rable to the results of Bar Haim et al. for Hebrew,
according to which the average number of analyses
per word is 2.17 with 1.25 segmentations on aver-
age per word, and 54% of the words are ambigu-
ous.
The performance of MorphTagger over Arabic
was measured using the same test settings of Diab
et al. (2004). Habash and Rambow (2005) use a
different test setting drawn from ATB1. Although
we could not reproduce the exact setting of Habash
and Rambow, comparison to their reported accu-
racy is still quite telling due to the similarity of the
data. The comparison between the accuracy of the
three systems is summarized in Table 1. The re-
sults in this table were obtained using the correct
(“gold”) segmentation and applying the standard F-
measure for POS tagging accuracy. The result of
Diab et al. was reproduced on their setting, and the
result of Habash and Rambow is as reported in
their paper.
</bodyText>
<table confidence="0.99554575">
System Tagging accuracy
MorphTagger 96.12
Diab et al. 95.81
Habash and Rambow 97.5
</table>
<tableCaption confidence="0.998351">
Table 1 - Comparison between systems over ATB1
</tableCaption>
<bodyText confidence="0.9824">
The result achieved by MorphTagger slightly
exceeds Diab et al.’s result (on the same test set-
ting) and is slightly inferior to Habash and Ram-
bow’s reported result. Overall, it is an encouraging
result that the MorphTagger system that was de-
veloped for Hebrew could be easily ported to Ara-
bic and yield state-of-the-art results.
In Table 2, we present the accuracies achieved
for MorphTagger on a cross validated, 10-fold test,
including the standard deviation results in paren-
theses. The results are reported both for gold-
segmentation (GS) and without GS.
i
</bodyText>
<page confidence="0.979458">
99
</page>
<table confidence="0.999618">
Test setting Accuracy per word (%) Fβ=1 per Word -segment (%)
Segmentation Tagging Segmentation Tagging
GS 100 94.89 100 95.436
(0.62) (0.53)
without GS 99.015 (0.24) 94.374 98.854 (0.28) 94.727
(0.64) (0.56)
</table>
<tableCaption confidence="0.995629">
Table 2 - MorphTagger performance cross validated
</tableCaption>
<bodyText confidence="0.999973739130435">
Note that by tagging accuracy per word we
mean the percentage of words correctly segmented
and tagged. The tagging F-measure is calculated in
the standard way, counting the correctly tagged
word-segments and dividing it by the number of
&amp;quot;gold&amp;quot; word-segments for recall, and further by the
number of outputted word-segments for precision.
Analyzing the POS tagging errors of MorphTag-
ger, we found that about 2.8% of the words in
ATB1 were not correctly analyzed by the morpho-
logical analyzer. Such “incomplete lexicon” prob-
lems inevitably lead to tagging errors in
MorphTagger’s architecture. This problem is more
serious still on data taken from ATB2 and ATB3,
where respectively 4.5% and 5.3% of the data led
to “incomplete lexicon” problems. We conclude
that a morphological analyzer can be used to im-
prove upon Diab et al.’s results, as done in Habash
and Rambow and in our straightforward applica-
tion of MorphTagger to Arabic. However, this
method still suffers from considerable coverage
problems, which are discussed in the following
section.
</bodyText>
<sectionHeader confidence="0.82054" genericHeader="method">
4 Coverage of Morphological Analysis
</sectionHeader>
<subsectionHeader confidence="0.67915">
for Arabic
</subsectionHeader>
<bodyText confidence="0.999891181818182">
In order to analyze the coverage problem, we
tested the coverage of BMA1.0 over parts of the
ATB which were composed from articles taken on
different periods of times. The results are summa-
rized in Table 3. The schema of the table includes,
for each part of the ATB: (i) the number of tokens
that include at least one Arabic character (hence-
forth “Arabic words”1); (ii) Out-of-Vocabulary
(OOV) words, unanalyzed by BMA1.0; (iii) the
percentage of proper nouns (NNP) out of the OOV
words; (iv) the number of “no correct” words –
</bodyText>
<footnote confidence="0.8540185">
1 This definition of Arabic words is taken from Buckwalter&apos;s
analyzer.
</footnote>
<bodyText confidence="0.999947421052632">
words for which BMA1.0 found at least one solu-
tion but the correct analysis according to the ATB
was not among them; and (v,vi,vii) the number of
proper nouns (NNP), nouns (NN) and adjectives
(JJ) from &amp;quot;no correct&amp;quot;. A problem that is unique to
the ATB is that some words in the corpus were not
manually annotated and were given the NO_FUNC
tag. Those words are counted as Arabic words, but
are ignored in the rest of the statistics of Table 3.
The noticeable difference in OOV words be-
tween ATB1 and ATB2/ATB3 is expected, be-
cause the lexicon of BMA1.0 was developed using
information extracted from ATB1. ATB2 and
ATB3, which were developed after BMA1.0 was
released (using a more advanced version of Buck-
walter&apos;s analyzer), show a different picture. In
those two parts the OOV problem is not too hard: a
heuristic that would assign NNP to each OOV
word would be sufficient in most of the cases.
However, the “No Correct” problem is more diffi-
cult: NNPs account for 5% in ATB2 and 18% in
ATB3 of these words, which are mostly dominated
by missing adjectives and missing nouns (54%
jointly in ATB2 and 37% jointly in ATB3).
Taken together, the OOV problem and the “No
Correct” problem mean that more than 5% of the
words in ATB2 and ATB3 cannot be tagged cor-
rectly using BMA1.0 unless further data are added
to those provided by the morphological analyzer. A
similar coverage result was reached for Hebrew by
Bar Haim et al., using a morphological analyzer for
Hebrew (Segal, 2001). Bar Haim et al. report that
for about 4% of the Hebrew words in their corpus,
the correct analysis was missing. From these data
we conclude that on top of systems like the ones
proposed by Bar Haim et al. and Habash and Ram-
bow, we need to enhance the morphological
analyzer using additional analyses.
</bodyText>
<page confidence="0.755472">
100
</page>
<table confidence="0.999603625">
ATB Arabic OOV NNP of No Correct NNP of No NN of No JJ of No
part words OOV Correct Correct Correct
1 123798 126 21 3369 0 517 980
(0.11%) (16.67%) (2.82%) (15.35%) (29.09%)
2 125729 958 497 5663 282 1254 1818
(0.77%) (51.88%) (4.53%) (4.98%) (22.14%) (32.1%)
3 293026 6405 5241 15484 2864 2238 3494
(2.2%) (81.83%) (5.32%) (18.5%) (14.45%) (22.57%)
</table>
<tableCaption confidence="0.992285">
Table 3 - Coverage of Buckwalter&apos;s Analyzer
</tableCaption>
<sectionHeader confidence="0.592717" genericHeader="method">
5 Smoothing Using a Data-driven Charac-
ter-based Model
</sectionHeader>
<bodyText confidence="0.999960184210527">
So far we have shown that POS tagging models
that use a morphological analyzer achieve high
accuracy but suffer from coverage problems that
can not be solved by a simple heuristic. On the
other hand, models that use character-based infor-
mation are likely to make relatively good predic-
tions for words that are out of the vocabulary of the
morphological analyzer. We hypothesize that this
may be especially true for Semitic languages, due
to their rich and systematic pattern (template) para-
digms. Such patterns add constant characters to
root characters, and features of substrings of words
may therefore help in predicting POS tags from
those patterns.
Our baseline models for the experiments are
MorphTagger with a NNP heuristic (MorphTag-
ger+NNP) and ArabicSVM (Diab et al.&apos;s system).
As we have already reported in section 3,
MorphTagger+NNP achieved 96.12% tagging ac-
curacy and ArabicSVM achieved 95.87% over the
same testing data used by Diab et al. One simple
hybrid model would be adding the analyses pro-
duced by the SVM to the morphological analyzer
analyses and disambiguate these analyses using
MorphTagger&apos;s HMM. This system has improved
accuracy – it achieved accuracy of 96.18%, higher
than both of the base models.
The problem with such model is over-generation
of the SVM: when checked over ATB1 and ATB2,
40% of the new analyses introduced by the SVM
are correct analyses, and 60% are wrong. To avoid
this problem, we suggest conditioning the addition
of SVM analyses on the sentence&apos;s tagging prob-
ability calculated by the HMM model. This is justi-
fied due to the fact that there is correlation between
the probability of the tagging of a sentence given
by a language model and the accuracy of the tag-
ging. The relation is shown in Figure 1.
</bodyText>
<figure confidence="0.8894245">
-800 -700 -600 -500 -400 -300 -200 -100 0
normalized log(P(s))
</figure>
<figureCaption confidence="0.998462">
Figure 1 Probability VS Accuracy
</figureCaption>
<bodyText confidence="0.9933385">
Figure 1 shows the relation between the accu-
racy of the tagging and the normalized logarithmic
probability of the tagging. We normalize the prob-
ability of the tagging by the sentence length as
longer sentences usually have lower probabilities.
Following the previous conclusions, we propose
a hybrid model which adds the analyses of the
SVM only in cases where the tagging probability
by the basic MorphTagger system is lower than an
empirically calculated threshold. If the HMM is
confident about the tagging it produces, the prob-
ability of the tagging will be high enough to pass
the threshold, and then the tagging will be output-
ted without adding the SVM analyses which might
add noise to the morphological analyzer output. A
general algorithm is shown in Figure 2.
</bodyText>
<figure confidence="0.953229857142857">
80
100
95
accuracy
90
85
75
</figure>
<page confidence="0.985294">
101
</page>
<bodyText confidence="0.951317">
Given a sentence s, perform the following steps:
</bodyText>
<listItem confidence="0.880296">
1. Produce analyses for each word in s using the morphological analyzer
combined with the corpus analyses.
2. Calculate lexical and contextual probabilities using available annotated
corpora (using Maximum Likelihood Estimation).
3. Run Viterbi&apos;s Algorithm for HMM disambiguation, and calculate a rank
of the tagging which is composed from the probability given by the
model and the length of the sentence.
4. If [rank&gt;threshold] output tagging.
4&apos;. [Otherwise] run the character based model over the sentence and add the
new analyses generated.
5&apos;. Combine the analyses generated by the morphological analyzer and the
character-based model, update the lexical probabilities and rerun the
model.
</listItem>
<figureCaption confidence="0.933962">
Figure 2 - Enhanced Tagging Algorithm
</figureCaption>
<bodyText confidence="0.999991407407407">
Note that in the algorithm, a new (word, tag)
pair introduced by the morphological analyzer or
by the character model does not appear in the
tagged corpus, therefore a small count λ=1 is given
in such cases. This method can be improved fur-
ther, especially for the analyses produced by the
data-driven character-based method.
The accuracy we obtained using this system was
96.28% which shows slight improvement over the
previous simple hybrid system. Examining the er-
rors in the simple hybrid method and the condi-
tioned method, we see that the improvement is not
smooth: the conditioned model includes errors
which did not exist in the simple model. These er-
rors occur when correct analyses of the character-
based model were discarded. In general, however,
the conditioned method chooses more correct
analyses. It should be noted that adding the charac-
ter-based model analyses boosted the coverage
from 97% to 98%, but the accuracy did not im-
prove to the same level. The main cause for this is
the weak relation between the probability of a sen-
tence and the accuracy. As it is difficult to model
this relation, we believe that more time should be
invested to improve the HMM probabilities espe-
cially for the character model analyses, which can
boost the chances of choosing good analyses.
</bodyText>
<sectionHeader confidence="0.998968" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999748447368421">
This paper demonstrates that it is possible to suc-
cessfully port a POS tagger originally built for He-
brew to Arabic using a morphological analyzer and
a tagged corpus. The POS tagger (called
MorphTagger) achieves state-of-the-art results
both on Hebrew and Arabic. Despite this positive
result we find that further improvement of accu-
racy is hindered by the coverage of the morpho-
logical analyzer. Contrary to earlier work on POS
tagging, the problem turns out not so much in un-
known (OOV) lexemes as much as in known lex-
emes for which the correct tag is missing. We
showed empirical evidence that this problem arises
for the available treebanks and morphological ana-
lyzers for both Arabic and Hebrew. We propose an
approach that smoothes a given lexical model (ob-
tained from a morphological analyzer and an anno-
tated corpus) by adding synthetically constructed
analyses, obtained from a POS tagger that com-
bines character-level information. Unlike earlier
work, we apply this smoothing only when the
probabilistic model assigns probabilities lower
than a threshold to all possible POS taggings of the
input sentence. This way we obtain moderate im-
provement in Arabic POS tagging.
The problem of missing lexeme-POS pairs in
POS taggers for Semitic languages is more severe
than in languages like English. We conjecture that
this is because of the more complex morphology of
Semitic languages.
In future work it might be worthwhile to con-
sider morphological processes that are more com-
plex than the standard affixation
(suffixing/prefixing) processes in order to general-
ize better over cases in the training data. Such a
generalization may provide better coverage of lex-
eme-POS pairs and would increase the upper
bound on accuracy.
</bodyText>
<page confidence="0.998457">
102
</page>
<sectionHeader confidence="0.995865" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881358490566">
Roy Bar Haim, Khalil Sima’an and Yoad Winter. 2005.
Choosing an Optimal Architecture for Segmentation
and POS-Tagging of Modern Hebrew. ACL Work-
shop on Computational Approaches to Semitic Lan-
guages. A revised and extended version to appear in
Journal of Natural Language Engineering.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: a case
study in part of speech tagging. In Computational
Linguistics 21, pages 543-565.
Tim Buckwalter. 2002. Arabic Morphological Analyzer
Version 1.0. Linguistic Data Consortium, University
of Pennsylvania.
Kenneth W. Church. 1988. A stochastic parts program
and noun phrase parser for unrestricted text. Pro-
ceedings of the second conference on Applied natural
language processing, Pages 136-143.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.
Automatic Tagging of Arabic Text: From Raw Text to
Base Phras e Chunks. In HLT-NAACL: Short Pa-
pers, pages 149-152.
Nizar Habash and Owen Rambow. 2005. Arabic To-
kenization, Part-of-Speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In
Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics, pages 573-
580, Ann Arbor.
Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-
sama Emam, and Hany Hassan. 2003. Language
model based Arabic word segmentation. In ACL,
pages 399-406.
Mohamed Maamouri and Ann Bies. 2004. Developing
an Arabic treebank: Methods, guidelines, proce-
dures, and tools. In Proceedings of the Workshop on
Computational Approaches to Arabic Script-based
Languages (COLING), Geneva.
Christopher D. Manning and Hinrich Schütze. 1999.
Foundations of Statistical Natural Language Proc-
essing. The MIT press, Cambridge, Massachusetts.
Tetsuji Nakagawa. 2004. Chinese and Japanese word
segmentation using word-level and character-level
information. In Proceedings of the 20th International
Conference on Computational Linguistics, pages
466-472, Geneva.
Erel Segal. 2001. Hebrew morphological analyzer for
Hebrew undotted texts. Master&apos;s thesis, Computer
Science Department, Technion, Haifa, Israel.
Ralph Weischedel, Marie Meteer, Richard Schwartz,
Lance Ramshaw and Jeff Palmucci. 1993. Coping
with Ambiguity and Unknown Words through Prob-
abilistic Models. Computational Linguistics (Special
issue on using large corpora: II) volume 19, pages
361-382.
</reference>
<page confidence="0.999297">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.526595">
<title confidence="0.999879">Smoothing a Lexicon-based POS Tagger for Arabic and Hebrew</title>
<author confidence="0.996407">Saib Mansour Khalil Sima&apos;an Yoad Winter</author>
<affiliation confidence="0.988012">Computer Science, Technion ILLC Computer Science, Technion</affiliation>
<address confidence="0.99448">Haifa, 32000, Israel Universiteit van Amsterdam Haifa, 32000, Israel</address>
<affiliation confidence="0.661541">The Netherlands and Netherlands Institute for Advanced Study</affiliation>
<address confidence="0.854088">Wassenaar, The Netherlands</address>
<email confidence="0.979623">saib@cs.technion.ac.ilsimaan@science.uva.nlwinter@cs.technion.ac.il</email>
<abstract confidence="0.998640484848485">We propose an enhanced Part-of-Speech (POS) tagger of Semitic languages that treats Modern Standard Arabic (henceand Modern Hebrew using the same probabilistic model and architectural setting. We start out by porting an existing Hidden Markov Model POS tagger for Hebrew to Arabic by exchanging a morphological analyzer for Hebrew with Buckwalter&apos;s (2002) morphological analyzer for Arabic. This gives state-of-theart accuracy (96.12%), comparable to Habash and Rambow’s (2005) analyzerbased POS tagger on the same Arabic datasets. However, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (Bar Haim et al., 2005). To overcome this coverage problem we supplement the output of Buckwalter&apos;s analyzer with synthetically constructed analyses that are proposed by a model which uses character information (Diab et al., 2004) in a way that is similar to Nakagawa&apos;s (2004) system for Chinese and Japanese. A version of this extended model that (unlike Nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard Arabic test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar Haim</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Choosing an Optimal Architecture for Segmentation and POS-Tagging of Modern Hebrew.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering.</journal>
<booktitle>ACL Workshop on Computational Approaches to Semitic</booktitle>
<marker>Haim, Sima’an, Winter, 2005</marker>
<rawString>Roy Bar Haim, Khalil Sima’an and Yoad Winter. 2005. Choosing an Optimal Architecture for Segmentation and POS-Tagging of Modern Hebrew. ACL Workshop on Computational Approaches to Semitic Languages. A revised and extended version to appear in Journal of Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging.</title>
<date>1995</date>
<booktitle>In Computational Linguistics 21,</booktitle>
<pages>543--565</pages>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging. In Computational Linguistics 21, pages 543-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium,</title>
<date>2002</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="2891" citStr="Buckwalter 2002" startWordPosition="446" endWordPosition="447"> refer to the set of lexemes in a language and the mapping that assigns each of them candidate POS tags, possibly with additional probabilities. Two ways to obtain a lexicon can be distinguished in recent works on POS tagging in Semitic languages. Data-driven approaches like (Diab et al. 2004) employ the lexicon only implicitly when extracting features on possible POS tags from annotated corpora that are used for training the POS tagger. Lexicon-based approaches (Habash and Rambow, 2005; Bar-Haim et al., 2005) use a lexicon that is extracted from a manually constructed morphological analyzer (Buckwalter 2002 and Segal 2001 respectively). In this paper we show that although lexiconbased taggers for Arabic and Hebrew may initially outperform data-driven taggers, they do not exhaust the advantages of data-driven approaches. 97 Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97–103, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Consequently, we propose a hybrid model of datadriven methods and lexicon-based methods, and show its advantages over both models, in a way that is reminiscent of Nakagawa&apos;s (2004) results for Chinese and Japanese. A</context>
</contexts>
<marker>Buckwalter, 2002</marker>
<rawString>Tim Buckwalter. 2002. Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>Proceedings of the second conference on Applied natural language processing,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="6408" citStr="Church, 1988" startWordPosition="1015" endWordPosition="1016">on of previous work. Section 3 describes our adaptation of Bar Haim et al.’s POS tagging system to Arabic. In section 4 we show that an architecture like Bar Haim et al.’s, which relies on a morphological analyzer, is likely to suffer from coverage problems under any configuration where it is used as a stand-alone. In section 5 we present our new architecture and the method of combining the models. Section 6 concludes. 2 Relation to Previous Works Quite a few works have dealt with extending a given POS tagger, mainly by smoothing it using extra-information about untreated words. For example, (Church, 1988) uses the simple heuristic of predicting proper nouns from capitalization. This method is not applicable to Arabic and Hebrew, which lack typographical marking of proper nouns. More advanced methods like those described by Weischedel et al. (1993) incorporate the treatment of unknown words within the probability model. Weischedel et al. use derivational and inflectional endings to infer POS tags of unknown words. Nakagawa (2004) addresses the problem of unknown words for Japanese and Chinese, and uses a hybrid method of word-level and character-level information. In his model, Nakagawa uses ch</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Kenneth W. Church. 1988. A stochastic parts program and noun phrase parser for unrestricted text. Proceedings of the second conference on Applied natural language processing, Pages 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Tagging of Arabic Text: From Raw Text to Base Phras e Chunks. In HLT-NAACL: Short Papers,</title>
<date>2004</date>
<pages>149--152</pages>
<contexts>
<context position="1343" citStr="Diab et al., 2004" startWordPosition="186" endWordPosition="189">changing a morphological analyzer for Hebrew with Buckwalter&apos;s (2002) morphological analyzer for Arabic. This gives state-of-theart accuracy (96.12%), comparable to Habash and Rambow’s (2005) analyzerbased POS tagger on the same Arabic datasets. However, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (Bar Haim et al., 2005). To overcome this coverage problem we supplement the output of Buckwalter&apos;s analyzer with synthetically constructed analyses that are proposed by a model which uses character information (Diab et al., 2004) in a way that is similar to Nakagawa&apos;s (2004) system for Chinese and Japanese. A version of this extended model that (unlike Nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard Arabic test set. 1 Introduction Part-of-Speech tagging for Semitic languages has been an active topic of research in recent years. (Diab et al., 2004; Habash and Rambow, 2005; Bar-Haim et al., 2005) are some examples for this line of work on Modern Standard Arabic and Modern Hebrew. POS tagging systems aim at classifying input sequences of lexemes by a</context>
<context position="2570" citStr="Diab et al. 2004" startWordPosition="395" endWordPosition="398">ach such sequence a corresponding sequence of most probable POS tags. It is often assumed that for each input lexeme there is a set of a priori possible POS tag categories, or a probability function over them, and the tagger has to choose from this limited set of candidate categories. We henceforth use the term lexicon to refer to the set of lexemes in a language and the mapping that assigns each of them candidate POS tags, possibly with additional probabilities. Two ways to obtain a lexicon can be distinguished in recent works on POS tagging in Semitic languages. Data-driven approaches like (Diab et al. 2004) employ the lexicon only implicitly when extracting features on possible POS tags from annotated corpora that are used for training the POS tagger. Lexicon-based approaches (Habash and Rambow, 2005; Bar-Haim et al., 2005) use a lexicon that is extracted from a manually constructed morphological analyzer (Buckwalter 2002 and Segal 2001 respectively). In this paper we show that although lexiconbased taggers for Arabic and Hebrew may initially outperform data-driven taggers, they do not exhaust the advantages of data-driven approaches. 97 Proceedings of the 5th Workshop on Important Unresolved Ma</context>
<context position="5283" citStr="Diab et al., 2004" startWordPosition="823" endWordPosition="826">volves words for which the analyzer provides a set of analyses that does not contain the correct one. We find out that this is the case for 3% of the words in the development set. This obviously sets an upper bound on tagger accuracy using methods that are purely based on a manually constructed lexicon. We refer to this problem as the &amp;quot;incomplete lexicon&amp;quot; problem. We focus on devising a solution to the incomplete lexicon problem by smoothing. We supplement the output of Buckwalter&apos;s analyzer with synthetically constructed analyses that are proposed by a model which uses character information (Diab et al., 2004) in a way that is similar to Nakagawa&apos;s (2004) system for Japanese. Unlike Nakagawa&apos;s method, however, our smoothing method incorporates synthetically constructed analyses also for known words, though only when all available taggings of the sentence have low probabilities according to our model. A version of this extended model achieves a modest improvement (96.28%) in accuracy over the baseline on the standard Arabic test set. This paper is structured as follows. In section 2 we start with a brief discussion of previous work. Section 3 describes our adaptation of Bar Haim et al.’s POS tagging</context>
<context position="10865" citStr="Diab et al. (2004)" startWordPosition="1765" endWordPosition="1768">e difficulty of the task at hand, we ran BMA1.0 over a testing set extracted from ATB1. The average number of analyses per word is 1.83, and the average number of segmentations per word is 1.2, however, the task of disambiguating Arabic is still not easy, as 46% of the data is ambiguous. Those results are comparable to the results of Bar Haim et al. for Hebrew, according to which the average number of analyses per word is 2.17 with 1.25 segmentations on average per word, and 54% of the words are ambiguous. The performance of MorphTagger over Arabic was measured using the same test settings of Diab et al. (2004). Habash and Rambow (2005) use a different test setting drawn from ATB1. Although we could not reproduce the exact setting of Habash and Rambow, comparison to their reported accuracy is still quite telling due to the similarity of the data. The comparison between the accuracy of the three systems is summarized in Table 1. The results in this table were obtained using the correct (“gold”) segmentation and applying the standard Fmeasure for POS tagging accuracy. The result of Diab et al. was reproduced on their setting, and the result of Habash and Rambow is as reported in their paper. System Ta</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic Tagging of Arabic Text: From Raw Text to Base Phras e Chunks. In HLT-NAACL: Short Papers, pages 149-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>573--580</pages>
<location>Ann Arbor.</location>
<contexts>
<context position="1763" citStr="Habash and Rambow, 2005" startWordPosition="254" endWordPosition="257"> overcome this coverage problem we supplement the output of Buckwalter&apos;s analyzer with synthetically constructed analyses that are proposed by a model which uses character information (Diab et al., 2004) in a way that is similar to Nakagawa&apos;s (2004) system for Chinese and Japanese. A version of this extended model that (unlike Nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard Arabic test set. 1 Introduction Part-of-Speech tagging for Semitic languages has been an active topic of research in recent years. (Diab et al., 2004; Habash and Rambow, 2005; Bar-Haim et al., 2005) are some examples for this line of work on Modern Standard Arabic and Modern Hebrew. POS tagging systems aim at classifying input sequences of lexemes by assigning each such sequence a corresponding sequence of most probable POS tags. It is often assumed that for each input lexeme there is a set of a priori possible POS tag categories, or a probability function over them, and the tagger has to choose from this limited set of candidate categories. We henceforth use the term lexicon to refer to the set of lexemes in a language and the mapping that assigns each of them ca</context>
<context position="4137" citStr="Habash and Rambow (2005)" startWordPosition="630" endWordPosition="633">elop a Part-of-Speech tagger that treats Arabic and Hebrew using the same probabilistic model and architectural setting. We start out from MorphTagger, a lexicon-based tagger for Hebrew developed by Bar-Haim et al. (2005), which uses standard Hidden Markov Model techniques. We port the existing MorphTagger implementation to Arabic by exchanging Segal&apos;s (2001) morphological analyzer with Buckwalter&apos;s (2002) morphological analyzer, and then training the tagger on the Arabic Treebank (Maamouri et al., 2001). Remarkably, this gives state-of-the-art accuracy (96.12%) on the same Arabic datasets as Habash and Rambow (2005). To the best of our knowledge, this is the first time the same POS tagging architecture is used both for Arabic and Hebrew texts with comparable accuracy. Despite the initial advantages of this setting, our empirical study shows that in both languages, further improvement in accuracy is hindered by the incompleteness of the morphological analyzer. By &amp;quot;incompleteness&amp;quot; we refer not only to the wellstudied problem of unknown words (out-ofvocabulary). Our results show that for both Arabic and Hebrew, a more serious problem involves words for which the analyzer provides a set of analyses that does</context>
<context position="10891" citStr="Habash and Rambow (2005)" startWordPosition="1769" endWordPosition="1772">task at hand, we ran BMA1.0 over a testing set extracted from ATB1. The average number of analyses per word is 1.83, and the average number of segmentations per word is 1.2, however, the task of disambiguating Arabic is still not easy, as 46% of the data is ambiguous. Those results are comparable to the results of Bar Haim et al. for Hebrew, according to which the average number of analyses per word is 2.17 with 1.25 segmentations on average per word, and 54% of the words are ambiguous. The performance of MorphTagger over Arabic was measured using the same test settings of Diab et al. (2004). Habash and Rambow (2005) use a different test setting drawn from ATB1. Although we could not reproduce the exact setting of Habash and Rambow, comparison to their reported accuracy is still quite telling due to the similarity of the data. The comparison between the accuracy of the three systems is summarized in Table 1. The results in this table were obtained using the correct (“gold”) segmentation and applying the standard Fmeasure for POS tagging accuracy. The result of Diab et al. was reproduced on their setting, and the result of Habash and Rambow is as reported in their paper. System Tagging accuracy MorphTagger</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 573-580, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>399--406</pages>
<marker>Lee, 2003</marker>
<rawString>Young-Suk Lee, Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan. 2003. Language model based Arabic word segmentation. In ACL, pages 399-406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
</authors>
<title>Developing an Arabic treebank: Methods, guidelines, procedures, and tools.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages (COLING),</booktitle>
<location>Geneva.</location>
<marker>Maamouri, Bies, 2004</marker>
<rawString>Mohamed Maamouri and Ann Bies. 2004. Developing an Arabic treebank: Methods, guidelines, procedures, and tools. In Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages (COLING), Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing. The MIT press,</booktitle>
<location>Cambridge, Massachusetts.</location>
<marker>Manning, Schütze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 1999. Foundations of Statistical Natural Language Processing. The MIT press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
</authors>
<title>Chinese and Japanese word segmentation using word-level and character-level information.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>466--472</pages>
<location>Geneva.</location>
<contexts>
<context position="6840" citStr="Nakagawa (2004)" startWordPosition="1079" endWordPosition="1081">ion to Previous Works Quite a few works have dealt with extending a given POS tagger, mainly by smoothing it using extra-information about untreated words. For example, (Church, 1988) uses the simple heuristic of predicting proper nouns from capitalization. This method is not applicable to Arabic and Hebrew, which lack typographical marking of proper nouns. More advanced methods like those described by Weischedel et al. (1993) incorporate the treatment of unknown words within the probability model. Weischedel et al. use derivational and inflectional endings to infer POS tags of unknown words. Nakagawa (2004) addresses the problem of unknown words for Japanese and Chinese, and uses a hybrid method of word-level and character-level information. In his model, Nakagawa uses character information (only) when handling unknown words, claiming that in word-level methods information about known words helps to achieve higher accuracy compared to character-level models. On the other hand, when it comes to unknown words, Nakagawa uses a character-level method, which is hypothesized to be more robust in such cases than word-level methods. Virtually all works that dealt with coverage problems of POS taggers ha</context>
</contexts>
<marker>Nakagawa, 2004</marker>
<rawString>Tetsuji Nakagawa. 2004. Chinese and Japanese word segmentation using word-level and character-level information. In Proceedings of the 20th International Conference on Computational Linguistics, pages 466-472, Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erel Segal</author>
</authors>
<title>Hebrew morphological analyzer for Hebrew undotted texts.</title>
<date>2001</date>
<tech>Master&apos;s thesis,</tech>
<institution>Computer Science Department,</institution>
<location>Technion, Haifa,</location>
<contexts>
<context position="2906" citStr="Segal 2001" startWordPosition="449" endWordPosition="450"> lexemes in a language and the mapping that assigns each of them candidate POS tags, possibly with additional probabilities. Two ways to obtain a lexicon can be distinguished in recent works on POS tagging in Semitic languages. Data-driven approaches like (Diab et al. 2004) employ the lexicon only implicitly when extracting features on possible POS tags from annotated corpora that are used for training the POS tagger. Lexicon-based approaches (Habash and Rambow, 2005; Bar-Haim et al., 2005) use a lexicon that is extracted from a manually constructed morphological analyzer (Buckwalter 2002 and Segal 2001 respectively). In this paper we show that although lexiconbased taggers for Arabic and Hebrew may initially outperform data-driven taggers, they do not exhaust the advantages of data-driven approaches. 97 Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97–103, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Consequently, we propose a hybrid model of datadriven methods and lexicon-based methods, and show its advantages over both models, in a way that is reminiscent of Nakagawa&apos;s (2004) results for Chinese and Japanese. As a first step,</context>
<context position="15584" citStr="Segal, 2001" startWordPosition="2562" endWordPosition="2563">cient in most of the cases. However, the “No Correct” problem is more difficult: NNPs account for 5% in ATB2 and 18% in ATB3 of these words, which are mostly dominated by missing adjectives and missing nouns (54% jointly in ATB2 and 37% jointly in ATB3). Taken together, the OOV problem and the “No Correct” problem mean that more than 5% of the words in ATB2 and ATB3 cannot be tagged correctly using BMA1.0 unless further data are added to those provided by the morphological analyzer. A similar coverage result was reached for Hebrew by Bar Haim et al., using a morphological analyzer for Hebrew (Segal, 2001). Bar Haim et al. report that for about 4% of the Hebrew words in their corpus, the correct analysis was missing. From these data we conclude that on top of systems like the ones proposed by Bar Haim et al. and Habash and Rambow, we need to enhance the morphological analyzer using additional analyses. 100 ATB Arabic OOV NNP of No Correct NNP of No NN of No JJ of No part words OOV Correct Correct Correct 1 123798 126 21 3369 0 517 980 (0.11%) (16.67%) (2.82%) (15.35%) (29.09%) 2 125729 958 497 5663 282 1254 1818 (0.77%) (51.88%) (4.53%) (4.98%) (22.14%) (32.1%) 3 293026 6405 5241 15484 2864 223</context>
</contexts>
<marker>Segal, 2001</marker>
<rawString>Erel Segal. 2001. Hebrew morphological analyzer for Hebrew undotted texts. Master&apos;s thesis, Computer Science Department, Technion, Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Lance Ramshaw</author>
<author>Jeff Palmucci</author>
</authors>
<title>Coping with Ambiguity and Unknown Words through Probabilistic Models. Computational Linguistics (Special issue on using large corpora:</title>
<date>1993</date>
<journal>II</journal>
<volume>19</volume>
<pages>361--382</pages>
<contexts>
<context position="6655" citStr="Weischedel et al. (1993)" startWordPosition="1050" endWordPosition="1053">rom coverage problems under any configuration where it is used as a stand-alone. In section 5 we present our new architecture and the method of combining the models. Section 6 concludes. 2 Relation to Previous Works Quite a few works have dealt with extending a given POS tagger, mainly by smoothing it using extra-information about untreated words. For example, (Church, 1988) uses the simple heuristic of predicting proper nouns from capitalization. This method is not applicable to Arabic and Hebrew, which lack typographical marking of proper nouns. More advanced methods like those described by Weischedel et al. (1993) incorporate the treatment of unknown words within the probability model. Weischedel et al. use derivational and inflectional endings to infer POS tags of unknown words. Nakagawa (2004) addresses the problem of unknown words for Japanese and Chinese, and uses a hybrid method of word-level and character-level information. In his model, Nakagawa uses character information (only) when handling unknown words, claiming that in word-level methods information about known words helps to achieve higher accuracy compared to character-level models. On the other hand, when it comes to unknown words, Nakag</context>
</contexts>
<marker>Weischedel, Meteer, Schwartz, Ramshaw, Palmucci, 1993</marker>
<rawString>Ralph Weischedel, Marie Meteer, Richard Schwartz, Lance Ramshaw and Jeff Palmucci. 1993. Coping with Ambiguity and Unknown Words through Probabilistic Models. Computational Linguistics (Special issue on using large corpora: II) volume 19, pages 361-382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>