<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.995168">
Whitepaper of NEWS 2010 Shared Task on
Transliteration Mining
</title>
<author confidence="0.859526">
A Kumaran Mitesh M. Khapra Haizhou Li
</author>
<affiliation confidence="0.9681845">
Microsoft Research India Indian Institute of Technology-Bombay Institute for Infocomm
Bangalore, India Mumbai, India Research, Singapore
</affiliation>
<sectionHeader confidence="0.989091" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99683065">
Transliteration is generally defined as phonetic
translation of names across languages. Ma-
chine Transliteration is a critical technology in
many domains, such as machine translation,
cross-language information retriev-
al/extraction, etc. Recent research has shown
that high quality machine transliteration sys-
tems may be developed in a language-neutral
manner, using a reasonably sized good quality
corpus (~15-25K parallel names) between a
given pair of languages. In this shared task,
we focus on acquisition of such good quality
names corpora in many languages, thus com-
plementing the machine transliteration shared
task that is concurrently conducted in the same
NEWS 2010 workshop. Specifically, this task
focuses on mining the Wikipedia paired enti-
ties data (aka, inter-wiki-links) to produce
high-quality transliteration data that may be
used for transliteration tasks.
</bodyText>
<sectionHeader confidence="0.988342" genericHeader="keywords">
1 Task Description
</sectionHeader>
<bodyText confidence="0.99995495">
The task is to develop a system for mining single
word transliteration pairs from the standard Wi-
kipedia paired topics (aka, Wikipedia Inter-
Language Links, or WIL1) in one or more of the
specified language pairs. The WIL’s link articles
on the same topic in multiple languages, and are
traditionally used as a parallel language resource
for many NLP applications, such as Machine
Translation, Crosslingual Search, etc. Specific
WIL’s of interest for our task are those that con-
tain proper names – either wholly or partly –
which can yield rich transliteration data.
Each WIL consists of a topic in the source and
the language pair, and the task is to identify parts
of the topic (in the respective language titles) that
are transliterations of each other. A seed data set
(of about 1K transliteration pairs) would be pro-
vided for each language pair, and are the only
resource to be used for developing a mining sys-
tem. The participants are expected to produce a
</bodyText>
<page confidence="0.191246">
1 Wikipedia’s Interlanguage Links:
</page>
<bodyText confidence="0.9648396">
http://en.wikipedia.org/wiki/Help:Interlanguage_links.
paired list of source-target single word named
entities, for every WIL provided. At the evalua-
tion time, a random subset of WIL’s (about 1K
WIL’s) in each language pair that are hand la-
beled would be used to test the results produced
by the participants.
Participants may use only the 1K seed data
provided by the organizers to produce “standard”
results; this restriction is imposed to provide a
meaningful way of comparing the effective me-
thods and approaches. However, “non-standard”
runs would be permitted where participants may
use more seed data or any language-specific re-
source available to them.
</bodyText>
<sectionHeader confidence="0.8185155" genericHeader="introduction">
2 Important Dates
SHARED TASK SCHEDULES
</sectionHeader>
<table confidence="0.986098428571428">
Registration Opens 1-Feb-2010
Registration Closes 13-Mar-2010
Training Data Release 26 -Feb-2010
Test Data Release 13-Mar-2010
Results Submission Due 20-Mar-2010
Evaluation Results An-
nouncement 27-Mar-2010
Short Papers Due 5-Apr-2010
Workshop Paper Sub-
mission Closes 5-Apr-2010
Workshop &amp; Task Pa-
pers Acceptance 6-May-2010
CRC Due 15-May-2010
Workshop Date 16-Jul-2010
</table>
<sectionHeader confidence="0.980431" genericHeader="method">
3 Participation
</sectionHeader>
<listItem confidence="0.995054125">
1. Registration (1 Feb 2010)
a. Prospective participants are to register to
the NEWS-2010 Workshop homepage, for
this specific task.
2. Training Data Release (26 Feb 2010)
a. Registered participants are to obtain seed
and Wikipedia data from the Shared Task
organizers.
</listItem>
<page confidence="0.955309">
29
</page>
<note confidence="0.6059145">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 29–38,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.919255237288136">
3. Evaluation Script (1 March 2010)
a. A sample submission and an evaluation
script will be released in due course.
b. The participants must make sure that their
output is produced in a way that the evalua-
tion script may run and produce the ex-
pected output.
c. The same script (with held out test data and
the user outputs) would be used for final
evaluation.
4. Testing data (13 March 2010)
a. The test data would be a held out data of
approximately 1K “gold-standard” mined
data.
b. The submissions (up to 10) would be tested
against the test data, and the results pub-
lished.
5. Results (27 March 2010)
a. On the results announcement date, the
evaluation results would be published on
the Workshop website.
b. Note that only the scores (in respective me-
trics) of the participating systems on each
language pairs would be published, but no
explicit ranking of the participating sys-
tems.
c. Note that this is a shared evaluation task
and not a competition; the results are meant
to be used to evaluate systems on common
data set with common metrics, and not to
rank the participating systems. While the
participants can cite the performance of
their systems (scores on metrics) from the
workshop report, they should not use any
ranking information in their publications.
d. Further, all participants should agree not to
reveal identities of other participants in any
of their publications unless you get permis-
sion from the other respective participants.
If the participants want to remain anonym-
ous in published results, they should inform
the organizers at the time of registration.
Note that the results of their systems would
still be published, but with the participant
identities masked. As a result, in this case,
your organization name will still appear in
the web site as one of participants, but it is
not linked explicitly with your results.
6. Short Papers on Task (5 April 2010)
a. Each submitting site is required to submit a
4-page system paper (short paper) for its
submissions, including their approach, data
used and the results.
b. All system short papers will be included in
the proceedings. Selected short papers will
be presented in the NEWS 2010 workshop.
Acceptance of the system short-papers
would be announced together with that of
other papers.
</listItem>
<sectionHeader confidence="0.981042" genericHeader="method">
4 Languages Involved
</sectionHeader>
<bodyText confidence="0.993810666666667">
The task involves transliteration mining in the
language pairs summarized in the following ta-
ble.
</bodyText>
<table confidence="0.972307428571429">
Source Lan- Target Lan- Track ID
guage guage
English Chinese WM-EnCn
English Hindi WM-EnHi
English Tamil WM-EnTa
English Russian WM-EnRu
English Arabic WM-EnAr
</table>
<tableCaption confidence="0.999054">
Table 1: Language Pairs in the shared task
</tableCaption>
<sectionHeader confidence="0.934771" genericHeader="method">
5 Data Sets for the Task
</sectionHeader>
<bodyText confidence="0.9903125">
The following datasets are used for each lan-
guage pair, for this task.
</bodyText>
<table confidence="0.999346642857143">
Training Data Size Remarks
Seed Data (Pa- —1K Paired names be-
rallel) tween source and
target languages.
To-be-mined Vari- Paired named entities
Wikipedia Inter- able between source and
Wiki-Link Data target languages ob-
(Noisy) tained directly from
Wikipedia
Test Data —1K This is a subset of
Wikipedia Inter-
Wiki-Link data,
which will be hand
labeled.
</table>
<tableCaption confidence="0.987212">
Table 2: Datasets for the shared task
</tableCaption>
<bodyText confidence="0.999061714285714">
The first two sets would be provided by the or-
ganizers to the participants, and the third will be
used for evaluation.
To-Mine-Data WIL data: All WIL’s from an
appropriate download from Wikipedia would be
provided. The WIL data might look like the
samples shown in Tables 3 and 4, with the sin-
</bodyText>
<page confidence="0.990237">
30
</page>
<bodyText confidence="0.985483666666667">
gle-word transliterations highlighted. Note that
there could be 0, 1 or more single-word translite-
rations from each WIL.
</bodyText>
<table confidence="0.999233777777778">
# English Wikipedia Hindi Wikipedia
Title Title
1 Indian National Congress भारतीय राष्ट्रीय काांग्रेस
2 University of Oxford ऑक्सफ़र्ड
विश्वविद्यालय
3 Indian Institute of Science भारतीय विज्ञान
सांस्थान
4 Jawaharlal Nehru Univer-जिाहरलाल नेहरू
sity विश्वविद्यालय
</table>
<tableCaption confidence="0.8150015">
Table 3: Sample English-Hindi Wikipedia title
pairs
</tableCaption>
<table confidence="0.998275">
# English Wikipedia Russian Wikipedia
Title Title
1 Mikhail Gorbachev Горбачёв, Михаил
Сергеевич
2 George Washington Вашингтон, Джордж
3 Treaty of Versailles Версальский договор
4 French Republic Франция
</table>
<tableCaption confidence="0.998218">
Table 4: Sample English-Russian Wikipedia title
</tableCaption>
<bodyText confidence="0.97961675">
pairs
Seed transliteration data: In addition we pro-
vide approximately 1K parallel names in each
language pair as seed data to develop any metho-
dology to identify transliterations. For standard
run results, only this seed data could be used,
though for non-standard runs, more data or other
linguistics resources may be used.
</bodyText>
<table confidence="0.9914328">
English Names Hindi Names
Village विलॆज
Linden वलन्र्न
Market माकेट
Mysore मैसूर
</table>
<tableCaption confidence="0.942937">
Table 5: Sample English-Hindi seed data
</tableCaption>
<table confidence="0.8989682">
English Names Russian Names
Gregory Григорий
Hudson Гудзон
Victor Виктор
baranowski барановский
</table>
<tableCaption confidence="0.988364">
Table 6: Sample English-Russian seed data
</tableCaption>
<bodyText confidence="0.9981399375">
Test set: We plan to randomly select ~1000 wi-
kipedia links (from the large noisy Inter-wiki-
links) as test-set, and manually extract the single
word transliteration pairs associated with each of
these WILs. Please note that a given WIL can
provide 0, 1 or more single-word transliteration
pairs. To keep the task simple, we consider as
correct transliterations only those that are clear
transliterations word-per-word (morphological
variations one or both sides are not considered
transliterations) These 1K test set will be a subset
of Wikipedia data provided to the user. The gold
dataset might look like the following (assuming
the items 1, 2, 3 and 4 in Tables 3 and 4 were
among the randomly selected WIL’s from To-
Mine-Data).
</bodyText>
<table confidence="0.984657166666667">
WIL# English Names Hindi Names
1 Congress काांग्रेस
2 Oxford ऑक्सफ़र्ड
3 &lt;Null&gt; &lt;Null&gt;
4 Jawaharlal जिाहरलाल
4 Nehru नेहरू
</table>
<tableCaption confidence="0.8657905">
Table 7: Sample English-Hindi transliteration
pairs mined from Wikipedia title pairs
</tableCaption>
<table confidence="0.996163857142857">
WIL# English Names Russian Names
1 Mikhail Михаил
1 Gorbachev Горбачёв
2 George Джордж
2 Washington Вашингтон
3 Versailles Версальский
4 &lt;Null&gt; &lt;Null&gt;
</table>
<tableCaption confidence="0.993005">
Table 8: Sample English-Russian translitera-
tion pairs mined from Wikipedia title pairs
</tableCaption>
<bodyText confidence="0.9932813">
Evaluation: The participants are expected to
mine such single-word transliteration data for
every specific WIL, though the evaluation would
be done only against the randomly selected,
hand-labeled test set. At evaluation time, the
task organizers check every WIL in test set from
among the user-provided results, to evaluate the
quality of the submission on the 3 metrics de-
scribed later.
Additional information on data use:
</bodyText>
<listItem confidence="0.995658333333333">
1. Seed data may have ownership and appropri-
ate licenses may need to be procured for use.
2. To-be-mined Wikipedia data is extracted
from Wikipedia (in Jan/Feb 2010), and dis-
tributed as-is. No assurances that they are
correct, complete or consistent.
</listItem>
<page confidence="0.999722">
31
</page>
<figureCaption confidence="0.999099">
Figure 1: Overview of the mining task and evaluation
</figureCaption>
<listItem confidence="0.935574730769231">
3. The hand-labeled test set is created by
NEWS shared task organizers, and will be
used for computing the metrics for a given
submission.
4. We expect that the participants to use only
the seed data (parallel names) provided by
the Shared Task for a standard run to ensure
a fair evaluation and a meaningful compari-
son between the effectiveness of approaches
taken by various systems. At least one such
run (using only the data provided by the
shared task) is mandatory for all participants
for a given task that they participate in.
5. If more data (either parallel names data or
monolingual data), or any language-specific
modules were used, then all such runs using
extra data or resources must be marked as
“Non-standard”. For such non-standard
runs, it is required to disclose the size and
characteristics of the data or the nature of
languages resources used, in their paper.
6. A participant may submit a maximum of 10
runs for a given language pair (including one
or more “standard” run). There could be
more standard runs, without exceeding 10
(including the non-standard runs).
</listItem>
<sectionHeader confidence="0.996111" genericHeader="method">
6 Paper Format
</sectionHeader>
<bodyText confidence="0.998945">
All paper submissions to NEWS 2010 should
follow the ACL 2010 paper submission policy
(http://acl2010.org/papers.html), including paper
format, blind review policy and title and author
format convention. Shared task system short pa-
pers are also in two-column format without ex-
ceeding four (4) pages plus any extra page for
references. However, there is no need for double-
blind requirements, as the users may refer to
their runs and metrics in the published results.
</bodyText>
<sectionHeader confidence="0.997049" genericHeader="method">
7 Evaluation Metrics
</sectionHeader>
<bodyText confidence="0.999849">
We plan to measure the quality of the mining
task using the following measures:
</bodyText>
<listItem confidence="0.998037333333333">
1. PrecisionCorrectTransliterations (PTrans)
2. RecallCorrectTransliteration (RTrans)
3. F-ScoreCorrectTransliteration (FTrans).
</listItem>
<bodyText confidence="0.993150785714286">
Please refer to the following figures for the ex-
planations:
A = True Positives (TP) = Pairs that were identi-
fied as &amp;quot;Correct Transliterations&amp;quot; by the partici-
pant and were indeed &amp;quot;Correct Transliterations&amp;quot;
as per the gold standard
B = False Positives (FP) = Pairs that were identi-
fied as &amp;quot;Correct Transliterations&amp;quot; by the partici-
pant but they were &amp;quot;Incorrect Transliterations&amp;quot; as
per the gold standard.
C = False Negatives (FN) = Pairs that were iden-
tified as &amp;quot;Incorrect Transliterations&amp;quot; by the par-
ticipant but were actually &amp;quot;Correct Translitera-
tions&amp;quot; as per the gold standard.
</bodyText>
<page confidence="0.998174">
32
</page>
<bodyText confidence="0.994572">
D = True Negatives (TN) = Pairs that were iden-
tified as &amp;quot;Incorrect Transliterations&amp;quot; by the par-
ticipant and were indeed &amp;quot;Incorrect Translitera-
tions&amp;quot; as per the gold standard.
</bodyText>
<figure confidence="0.983322633333333">
8 Contact Us
If you have any questions about this share task
and the database, please contact one of the orga-
nizers below:
1. RecallCorrectTransliteration (RTrans)
The recall is going to be computed using the
sample as follows:
TP A A
RTrans = TP+FN = A + C = T
2. PrecisionCorrectTransliteration (PTrans)
The precision is going to be computed using the
sample as follows:
TP A
PTrans = TP+FP =
A+ B
3. F-Score (F) 2 * PTrans * RTrans
F=
PTrans + RTrans
Dr. A. Kumaran
Microsoft Research India
Bangalore 560080 INDIA
a.kumaran@microsoft.com
Mitesh Khapra
Indian Institute of Technology-Bombay
Mumbai, INDIA
MKhapra@cse.iitb.ac.in.
Dr Haizhou Li
Institute for Infocomm Research
Singapore, SINGAPORE 138632
hli@i2r.a-star.edu.sg.
</figure>
<page confidence="0.995066">
33
</page>
<sectionHeader confidence="0.837972" genericHeader="method">
Appendix A: Seed Parallel Names Data
</sectionHeader>
<listItem confidence="0.998991375">
• File Naming Conventions:
o NEWS09_Seed_XXYY_1K.xml,
■ XX: Source Language
■ YY: Target Language
■ 1K: number of parallel names
• File Formats:
o All data would be made available in XML formats (Appendix A).
• Data Encoding Formats:
</listItem>
<bodyText confidence="0.5401915">
o The data would be in Unicode, in UTF-8 encoding. The results are expected to be
submitted in UTF-8 format only, and in the XML format specified.
</bodyText>
<figure confidence="0.93606037037037">
File: NEWS2009_Seed_EnHi_1000.xml
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;SeedCorpus
CorpusID = &amp;quot;NEWS2009-Seed-EnHi-1K&amp;quot;
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
CorpusType = &amp;quot;Seed&amp;quot;
CorpusSize = &amp;quot;1000&amp;quot;
CorpusFormat = &amp;quot;UTF8&amp;quot;&gt;
&lt;Name ID=”1”&gt;
&lt;SourceName&gt;eeeeee1&lt;/SourceName&gt;
&lt;TargetName ID=&amp;quot;1&amp;quot;&gt;hhhhhh1_1&lt;/TargetName&gt;
&lt;TargetName ID=&amp;quot;2&amp;quot;&gt;hhhhhh1_2&lt;/TargetName&gt;
...
&lt;TargetName ID=&amp;quot;n&amp;quot;&gt;hhhhhh1_n&lt;/TargetName&gt;
&lt;/Name&gt;
&lt;Name ID=”2”&gt;
&lt;SourceName&gt;eeeeee2&lt;/SourceName&gt;
&lt;TargetName ID=&amp;quot;1&amp;quot;&gt;hhhhhh2_1&lt;/TargetName&gt;
&lt;TargetName ID=&amp;quot;2&amp;quot;&gt;hhhhhh2_2&lt;/TargetName&gt;
...
&lt;TargetName ID=&amp;quot;m&amp;quot;&gt;hhhhhh2_m&lt;/TargetName&gt;
&lt;/Name&gt;
...
&lt;!-- rest of the names to follow --&gt;
...
&lt;/SeedCorpus&gt;
</figure>
<sectionHeader confidence="0.627588" genericHeader="method">
Appendix B: Wikipedia InterwikiLinks Data
</sectionHeader>
<listItem confidence="0.999320625">
• File Naming Conventions:
o NEWS09_Wiki_XXYY_nnnn.xml,
■ XX: Source Language
■ YY: Target Language
■ nnnn: size of paired entities culled from Wikipedia (“25K”, “10000”, etc.)
• File Formats:
o All data would be made available in XML formats (Appendix A).
• Data Encoding Formats:
</listItem>
<bodyText confidence="0.54042">
o The data would be in Unicode, in UTF-8 encoding. The results are expected to be
submitted in UTF-8 format only, and in the XML format specified.
</bodyText>
<page confidence="0.994223">
34
</page>
<figure confidence="0.909035904761905">
File: NEWS2009_Wiki_EnHi_10K.xml
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;WikipediaCorpus
CorpusID = &amp;quot;NEWS2009-Wiki-EnHi-10K&amp;quot;
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
CorpusType = &amp;quot;Wiki&amp;quot;
CorpusSize = &amp;quot;10000&amp;quot;
CorpusFormat = &amp;quot;UTF8&amp;quot;&gt;
&lt;Title ID=”1”&gt;
&lt;SourceEntity&gt;e1 e2 ... en&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;h1 h2 ... hm&lt;/TargetEntity&gt;
&lt;/Title&gt;
&lt;Title ID=”2”&gt;
&lt;SourceEntity&gt;e1 e2 ... ei&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;h1 h2 ... hj&lt;/TargetEntity&gt;
&lt;/Title&gt;
...
&lt;!-- rest of the titles to follow --&gt;
...
&lt;/ WikipediaCorpus&gt;
</figure>
<sectionHeader confidence="0.44654" genericHeader="method">
Appendix C: Results Submission - Format
</sectionHeader>
<listItem confidence="0.936941076923077">
• File Naming Conventions:
o NEWS09_ Result _XXYY_gggg nn_description.xml
■ XX: Source
■ YY: Target
■ gggg: Group ID
■ nn: run ID.
■ description: Description of the run
• File Formats:
o All results would be submitted in XML formats (Appendix B).
• Data Encoding Formats:
o The data would be in Unicode, in UTF-8 encoding. The results are expected to be
submitted in UTF-8 format only.
Example: NEWS2009_EnHi_TUniv_01_HMMBased.xml
</listItem>
<equation confidence="0.696193125">
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;WikipediaMiningTaskResults
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
GroupID = &amp;quot;Trans University&amp;quot;
RunID = &amp;quot;1&amp;quot;
RunType = &amp;quot;Standard&amp;quot;
Comments = &amp;quot;SVD Run with params: alpha=xxx beta=yyy&amp;quot;&gt;
</equation>
<figure confidence="0.980782916666667">
&lt;Title ID=&amp;quot;1&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;e1&lt;/SourceName&gt;
&lt;TargetName&gt;h1&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;MinedPair ID=&amp;quot;2&amp;quot;&gt;
&lt;SourceName&gt;e2&lt;/SourceName&gt;
&lt;TargetName&gt;h2&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;!—followed by other pairs mined from this title--&gt;
&lt;/Title&gt;
&lt;Title ID=&amp;quot;2&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;e1&lt;/SourceName&gt;
&lt;TargetName&gt;h1&lt;/TargetName&gt;
&lt;/MinedPair&gt;
35
&lt;MinedPair ID=&amp;quot;2&amp;quot;&gt;
&lt;SourceName&gt;e2&lt;/SourceName&gt;
&lt;TargetName&gt;h2&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;!—followed by other pairs mined from this title--&gt;
&lt;/Title&gt;
...
&lt;!-- All titles in the culled data to follow --&gt;
...
&lt;/WikipediaMiningTaskResults&gt;
Appendix D: Sample Eng-Hindi Interwikilink Data
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;WikipediaCorpus CorpusID = &amp;quot;NEWS2009-Wiki-EnHi-Sample&amp;quot;
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
CorpusType = &amp;quot;Wiki&amp;quot; CorpusSize = &amp;quot;3&amp;quot;
CorpusFormat = &amp;quot;UTF8&amp;quot;&gt;
&lt;Title ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceEntity&gt;Indian National Congress&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;भारतीय राष्ट्रीय काांग्रेस&lt;/TargetEntity&gt;
&lt;/Title&gt;
&lt;!-- {Congress, काांग्रेस} should be identified by the paricipants--&gt;
&lt;Title ID=&amp;quot;2&amp;quot;&gt;
&lt;SourceEntity&gt;University of Oxford&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;ऑक्सफ़र्ड विश्वविद्याऱय&lt;/TargetEntity&gt;
&lt;/Title&gt;
&lt;!-- {Oxford, ऑक्सफ़र्ड} should be identified by the paricipants--&gt;
&lt;Title ID=&amp;quot;3&amp;quot;&gt;
&lt;SourceEntity&gt;Jawaharlal Nehru University&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;जिाहरऱाऱ नेहरू विश्वविद्याऱय&lt;/TargetEntity&gt;
&lt;/Title&gt;
&lt;!-- {Jawaharlal, जिाहरऱाऱ} and {Nehru, नेहरू} should be
identified by the paricipants--&gt;
&lt;Title ID=&amp;quot;4&amp;quot;&gt;
&lt;SourceEntity&gt;Indian Institute Of Science&lt;/SourceEntity&gt;
&lt;TargetEntity&gt;भारतीय विज्ञान सांस्थान&lt;/TargetEntity&gt;
&lt;/Title&gt;
&lt;!--There are no transliteration pairs here --&gt;
&lt;/WikipediaCorpus&gt;
Appendix E: Eng-Hindi Gold Mined Data (wrt the above WIL Data)
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;WikipediaMiningTaskResults
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
GroupID = &amp;quot;Gold-Standard&amp;quot;
RunID = &amp;quot;&amp;quot;
RunType = &amp;quot;&amp;quot;
Comments = &amp;quot;&amp;quot;&gt;
&lt;Title ID=&amp;quot;1&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Congress&lt;/SourceName&gt;
&lt;TargetName&gt; काांग्रेस&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;/Title&gt;
&lt;Title ID=&amp;quot;2&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
36
&lt;SourceName&gt;Oxford&lt;/SourceName&gt;
&lt;TargetName&gt; ऑक्सफ़र्ड&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;/Title&gt;
&lt;Title ID=&amp;quot;3&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Jawaharlal&lt;/SourceName&gt;
&lt;TargetName&gt; जिाहरऱाऱ&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;MinedPair ID=&amp;quot;2&amp;quot;&gt;
&lt;SourceName&gt;Nehru&lt;/SourceName&gt;
&lt;TargetName&gt; नेहरू&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;/Title&gt;
&lt;Title ID=&amp;quot;4&amp;quot;&gt;
&lt;/Title&gt;
&lt;/WikipediaMiningTaskResults&gt;
Appendix F: English-Hindi Sample Submission and Evaluation
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;WikipediaMiningTaskResults
SourceLang = &amp;quot;English&amp;quot;
TargetLang = &amp;quot;Hindi&amp;quot;
GroupID = &amp;quot;Gold-Standard&amp;quot;
RunID = &amp;quot;&amp;quot;
RunType = &amp;quot;&amp;quot;
&lt;Title ID=&amp;quot;1&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Congress&lt;/SourceName&gt;
&lt;TargetName&gt; काांग्रेस&lt;/TargetName&gt;
&lt;/MinedPair&gt;
The participant mined all correct transliteration pairs
&lt;/Title&gt;
&lt;Title ID=&amp;quot;2&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Oxford&lt;/SourceName&gt;
&lt;TargetName&gt; ऑक्सफ़र्ड&lt;/TargetName&gt;
&lt;/MinedPair&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;University&lt;/SourceName&gt;
&lt;TargetName&gt;विश्वविद्याऱय&lt;/TargetName&gt;
&lt;/MinedPair&gt;
The participant mined an incorrect transliteration pair {University,विश्वविद्याऱय}
&lt;/Title&gt;
&lt;Title ID=&amp;quot;3&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Jawaharlal&lt;/SourceName&gt;
&lt;TargetName&gt; जिाहरऱाऱ&lt;/TargetName&gt;
&lt;/MinedPair&gt;
The participant missed the correct transliteration pair {Nehru, नेहरू}
&lt;/Title&gt;
&lt;Title ID=&amp;quot;4&amp;quot;&gt;
&lt;MinedPair ID=&amp;quot;1&amp;quot;&gt;
&lt;SourceName&gt;Indian&lt;/SourceName&gt;
&lt;TargetName&gt;भारतीय&lt;/TargetName&gt;
&lt;/MinedPair&gt;
The participant mined an incorrect transliteration pair {Indian, भारतीय}
&lt;/Title&gt;
&lt;/WikipediaMiningTaskResults&gt;
</figure>
<page confidence="0.896485">
37
</page>
<sectionHeader confidence="0.307024" genericHeader="method">
Sample Evaluation
</sectionHeader>
<equation confidence="0.83738125">
T = |{(Congress, काांग्रेस), (Oxford, ऑक्सफ़र्ड), (Jawaharlal, जिाहरलाल),(Nehru, नेहरू)}  |= 4
A = TP =  |{(Congress, काांग्रेस), (Oxford, ऑक्सफ़र्ड), (Jawaharlal, जिाहरलाल)} |= 3
B = FP = |{(Indian, भारतीय), (University, विश्वविद्यालय) } |= 2
C = FN = |{(Nehru, नेहरू)} |= 1
</equation>
<figure confidence="0.694873666666667">
TP A A 3
4 = 0.75
RT,a=
ns
TP + FN = A + C = T
TP = A = 3 _
PT,ans = TP+FP A+B 5 - 0.60
F = 2 * PT,ans * RT,ans
PT,ans + RT,ans
2 * 0.6 * 0.75 = 0.67
=
0.6 + 0.75
</figure>
<page confidence="0.983759">
38
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.970035">Whitepaper of NEWS 2010 Shared Task Transliteration Mining</title>
<author confidence="0.870799">A Kumaran Mitesh M Khapra Haizhou Li</author>
<affiliation confidence="0.99303">Microsoft Research India Indian Institute of Technology-Bombay Institute for Infocomm</affiliation>
<address confidence="0.974324">Bangalore, India Mumbai, India Research, Singapore</address>
<abstract confidence="0.999175649122807">Transliteration is generally defined as phonetic translation of names across languages. Machine Transliteration is a critical technology in many domains, such as machine translation, information al/extraction, etc. Recent research has shown that high quality machine transliteration systems may be developed in a language-neutral manner, using a reasonably sized good quality corpus (~15-25K parallel names) between a given pair of languages. In this shared task, we focus on acquisition of such good quality names corpora in many languages, thus complementing the machine transliteration shared task that is concurrently conducted in the same NEWS 2010 workshop. Specifically, this task focuses on mining the Wikipedia paired entities data (aka, inter-wiki-links) to produce high-quality transliteration data that may be used for transliteration tasks. 1 Task Description The task is to develop a system for mining single word transliteration pairs from the standard Wikipedia paired topics (aka, Wikipedia Inter- Links, or in one or more of the language pairs. WIL’s link articles on the same topic in multiple languages, and are traditionally used as a parallel language resource for many NLP applications, such as Machine Translation, Crosslingual Search, etc. Specific of interest for our task are those that proper names wholly or partly which can yield rich transliteration data. Each WIL consists of a topic in the source and the language pair, and the task is to identify parts of the topic (in the respective language titles) that are transliterations of each other. A seed data set (of about 1K transliteration pairs) would be provided for each language pair, and are the only resource to be used for developing a mining system. The participants are expected to produce a 1Interlanguage Links: paired list of source-target single word named entities, for every WIL provided. At the evaluatime, a subset of WIL’s (about 1K in each language pair that are labeled would be used to test the results produced by the participants. Participants may use only the 1K seed data by the organizers to produce results; this restriction is imposed to provide a meaningful way of comparing the effective meand approaches. However, runs would be permitted where participants may use more seed data or any language-specific resource available to them.</abstract>
<title confidence="0.656007416666667">2 Important Dates SHARED TASK SCHEDULES Opens Registration Closes 13-Mar-2010 Data Release 26 Test Data Release 13-Mar-2010 Results Submission Due 20-Mar-2010 Results Announcement 27-Mar-2010 Papers Paper Sub- Closes</title>
<author confidence="0.292333">Task Pa-</author>
<note confidence="0.399965">Acceptance Due Workshop Date 16-Jul-2010 3 Participation 1. Registration (1 Feb 2010)</note>
<abstract confidence="0.994503424657534">a. Prospective participants are to register to the NEWS-2010 Workshop homepage, for this specific task. 2. Training Data Release (26 Feb 2010) a. Registered participants are to obtain seed and Wikipedia data from the Shared Task organizers. 29 of the 2010 Named Entities Workshop, ACL pages Sweden, 16 July 2010. Association for Computational Linguistics 3. Evaluation Script (1 March 2010) a. A sample submission and an evaluation script will be released in due course. b. The participants must make sure that their output is produced in a way that the evaluation script may run and produce the expected output. c. The same script (with held out test data and the user outputs) would be used for final evaluation. 4. Testing data (13 March 2010) a. The test data would be a held out data of 1K mined data. b. The submissions (up to 10) would be tested against the test data, and the results published. 5. Results (27 March 2010) a. On the results announcement date, the evaluation results would be published on the Workshop website. b. Note that only the scores (in respective metrics) of the participating systems on each language pairs would be published, but no explicit ranking of the participating systems. c. Note that this is a shared evaluation task and not a competition; the results are meant to be used to evaluate systems on common data set with common metrics, and not to rank the participating systems. While the participants can cite the performance of their systems (scores on metrics) from the workshop report, they should not use any ranking information in their publications. d. Further, all participants should agree not to reveal identities of other participants in any of their publications unless you get permission from the other respective participants. If the participants want to remain anonymous in published results, they should inform the organizers at the time of registration. Note that the results of their systems would still be published, but with the participant identities masked. As a result, in this case, your organization name will still appear in the web site as one of participants, but it is not linked explicitly with your results. 6. Short Papers on Task (5 April 2010) a. Each submitting site is required to submit a 4-page system paper (short paper) for its submissions, including their approach, data used and the results. b. All system short papers will be included in the proceedings. Selected short papers will be presented in the NEWS 2010 workshop. Acceptance of the system short-papers would be announced together with that of other papers. 4 Languages Involved The task involves transliteration mining in the language pairs summarized in the following table.</abstract>
<title confidence="0.641315333333333">Source Target Track ID guage guage English Chinese WM-EnCn</title>
<author confidence="0.82799725">English Hindi WM-EnHi English Tamil WM-EnTa English Russian WM-EnRu English Arabic WM-EnAr</author>
<abstract confidence="0.961280273972603">1: Pairs in the shared task 5 Data Sets for the Task The following datasets are used for each language pair, for this task. Training Data Size Remarks Seed Data (Parallel) —1K names tween source target languages. To-be-mined Wikipedia Inter- Wiki-Link Data (Noisy) Variable Paired named entities between source and target languages ob-tained directly from Wikipedia Test Data —1K This is a subset of Wikipedia Inter-Wiki-Link data, which will be hand labeled. 2: for the shared task The first two sets would be provided by the organizers to the participants, and the third will be used for evaluation. WIL WIL’s from an appropriate download from Wikipedia would be provided. The WIL data might look like the shown in Tables 3 and 4, with the sin- 30 gle-word transliterations highlighted. Note that there could be 0, 1 or more single-word transliterations from each WIL. Title Title 1 Indian National Congress भारतीय राष्ट्रीय काांग्रेस 2 University of Oxford ऑक्सफ़र्ड विश्वविद्यालय 3 Indian Institute of Science भारतीय विज्ञान सांस्थान 4 Nehru नेहरू sity विश्वविद्यालय 3: English-Hindi Wikipedia title pairs Title 1 Mikhail Gorbachev Сергеевич 2 George Washington 3 Treaty of Versailles Версальский договор 4 French Republic Франция 4: English-Russian Wikipedia title pairs transliteration data: addition we provide approximately 1K parallel names in each language pair as seed data to develop any methodology to identify transliterations. For standard run results, only this seed data could be used, though for non-standard runs, more data or other linguistics resources may be used. English Names Hindi Names Village विलॆज Linden वलन्र्न Market माकेट Mysore मैसूर 5: English-Hindi seed data English Names Russian Names Gregory Григорий Hudson Гудзон Victor Виктор baranowski барановский 6: English-Russian seed data set: plan to randomly select ~1000 wikipedia links (from the large noisy Inter-wikilinks) as test-set, and manually extract the single word transliteration pairs associated with each of these WILs. Please note that a given WIL can provide 0, 1 or more single-word transliteration pairs. To keep the task simple, we consider as correct transliterations only those that are clear transliterations word-per-word (morphological variations one or both sides are not considered transliterations) These 1K test set will be a subset of Wikipedia data provided to the user. The gold dataset might look like the following (assuming the items 1, 2, 3 and 4 in Tables 3 and 4 were the randomly selected WIL’s To-</abstract>
<note confidence="0.7648035">Mine-Data). WIL# English Names Hindi Names 1 Congress काांग्रेस 2 Oxford ऑक्सफ़र्ड 3 &lt;Null&gt; &lt;Null&gt; 4 Jawaharlal जिाहरलाल</note>
<abstract confidence="0.968142514285714">4 Nehru नेहरू 7: English-Hindi transliteration pairs mined from Wikipedia title pairs WIL# English Names Russian Names 1 Mikhail Михаил 1 Gorbachev Горбачёв 2 George Джордж 2 Washington Вашингтон 3 Versailles Версальский 4 &lt;Null&gt; &lt;Null&gt; 8: English-Russian transliteration pairs mined from Wikipedia title pairs participants are expected to mine such single-word transliteration data for every specific WIL, though the evaluation would be done only against the randomly selected, hand-labeled test set. At evaluation time, the task organizers check every WIL in test set from among the user-provided results, to evaluate the quality of the submission on the 3 metrics described later. Additional information on data use: 1. Seed data may have ownership and appropriate licenses may need to be procured for use. 2. To-be-mined Wikipedia data is extracted from Wikipedia (in Jan/Feb 2010), and distributed as-is. No assurances that they are correct, complete or consistent. 31 1: of the mining task and evaluation 3. The hand-labeled test set is created by NEWS shared task organizers, and will be used for computing the metrics for a given submission. 4. We expect that the participants to use only the seed data (parallel names) provided by the Shared Task for a standard run to ensure a fair evaluation and a meaningful comparison between the effectiveness of approaches taken by various systems. At least one such run (using only the data provided by the shared task) is mandatory for all participants for a given task that they participate in. 5. If more data (either parallel names data or monolingual data), or any language-specific modules were used, then all such runs using extra data or resources must be marked as For such runs, it is required to disclose the size and characteristics of the data or the nature of languages resources used, in their paper. 6. A participant may submit a maximum of 10 runs for a given language pair (including one or more “standard” run). There could be more standard runs, without exceeding 10 (including the non-standard runs). 6 Paper Format All paper submissions to NEWS 2010 should follow the ACL 2010 paper submission policy including paper format, blind review policy and title and author format convention. Shared task system short papers are also in two-column format without exceeding four (4) pages plus any extra page for references. However, there is no need for doubleblind requirements, as the users may refer to their runs and metrics in the published results. 7 Evaluation Metrics We plan to measure the quality of the mining task using the following measures: 1. 2. 3. Please refer to the following figures for the explanations: A = True Positives (TP) = Pairs that were identified as &amp;quot;Correct Transliterations&amp;quot; by the participant and were indeed &amp;quot;Correct Transliterations&amp;quot; as per the gold standard B = False Positives (FP) = Pairs that were identified as &amp;quot;Correct Transliterations&amp;quot; by the participant but they were &amp;quot;Incorrect Transliterations&amp;quot; as per the gold standard. C = False Negatives (FN) = Pairs that were identified as &amp;quot;Incorrect Transliterations&amp;quot; by the participant but were actually &amp;quot;Correct Transliterations&amp;quot; as per the gold standard. 32 D = True Negatives (TN) = Pairs that were identified as &amp;quot;Incorrect Transliterations&amp;quot; by the participant and were indeed &amp;quot;Incorrect Transliterations&amp;quot; as per the gold standard. 8 Contact Us If you have any questions about this share task and the database, please contact one of the organizers below: 1. The recall is going to be computed using the sample as follows: TP A A 2. The precision is going to be computed using the sample as follows: TP A 3. F-Score (F)</abstract>
<author confidence="0.962083">A Kumaran</author>
<affiliation confidence="0.999864">Microsoft Research India</affiliation>
<address confidence="0.986773">Bangalore 560080 INDIA</address>
<email confidence="0.999612">a.kumaran@microsoft.com</email>
<author confidence="0.985519">Mitesh Khapra</author>
<affiliation confidence="0.999618">Indian Institute of Technology-Bombay</affiliation>
<address confidence="0.99407">Mumbai, INDIA</address>
<email confidence="0.957689">MKhapra@cse.iitb.ac.in.</email>
<affiliation confidence="0.7716025">Dr Haizhou Li Institute for Infocomm Research</affiliation>
<address confidence="0.926277">Singapore, SINGAPORE 138632</address>
<note confidence="0.909291882352941">hli@i2r.a-star.edu.sg. 33 Appendix A: Seed Parallel Names Data • File Naming Conventions: o NEWS09_Seed_XXYY_1K.xml, ■ XX: Source Language ■ YY: Target Language ■ 1K: number of parallel names • File Formats: o All data would be made available in XML formats (Appendix A). • Data Encoding Formats: o The data would be in Unicode, in UTF-8 encoding. The results are expected to be submitted in UTF-8 format only, and in the XML format specified. File: NEWS2009_Seed_EnHi_1000.xml &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt; &lt;SeedCorpus CorpusID = &amp;quot;NEWS2009-Seed-EnHi-1K&amp;quot;</note>
<title confidence="0.620100333333333">SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; CorpusType = &amp;quot;Seed&amp;quot;</title>
<note confidence="0.950909388888889">CorpusSize = &amp;quot;1000&amp;quot; CorpusFormat = &amp;quot;UTF8&amp;quot;&gt; &lt;Name ID=”1”&gt; &lt;SourceName&gt;eeeeee1&lt;/SourceName&gt; &lt;TargetName ID=&amp;quot;1&amp;quot;&gt;hhhhhh1_1&lt;/TargetName&gt; &lt;TargetName ID=&amp;quot;2&amp;quot;&gt;hhhhhh1_2&lt;/TargetName&gt; ... &lt;TargetName ID=&amp;quot;n&amp;quot;&gt;hhhhhh1_n&lt;/TargetName&gt; &lt;/Name&gt; &lt;Name ID=”2”&gt; &lt;SourceName&gt;eeeeee2&lt;/SourceName&gt; &lt;TargetName ID=&amp;quot;1&amp;quot;&gt;hhhhhh2_1&lt;/TargetName&gt; &lt;TargetName ID=&amp;quot;2&amp;quot;&gt;hhhhhh2_2&lt;/TargetName&gt; ... &lt;TargetName ID=&amp;quot;m&amp;quot;&gt;hhhhhh2_m&lt;/TargetName&gt; &lt;/Name&gt; ... &lt;!-rest of the names to follow --&gt; ... &lt;/SeedCorpus&gt; Appendix B: Wikipedia InterwikiLinks Data • File Naming Conventions: o NEWS09_Wiki_XXYY_nnnn.xml, ■ XX: Source Language ■ YY: Target Language ■ nnnn: size of paired entities culled from Wikipedia (“25K”, “10000”, etc.) • File Formats: o All data would be made available in XML formats (Appendix A). • Data Encoding Formats: o The data would be in Unicode, in UTF-8 encoding. The results are expected to be submitted in UTF-8 format only, and in the XML format specified. 34 File: NEWS2009_Wiki_EnHi_10K.xml &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt; &lt;WikipediaCorpus CorpusID = &amp;quot;NEWS2009-Wiki-EnHi-10K&amp;quot;</note>
<title confidence="0.691275333333333">SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; CorpusType = &amp;quot;Wiki&amp;quot;</title>
<note confidence="0.790982838709678">CorpusSize = &amp;quot;10000&amp;quot; CorpusFormat = &amp;quot;UTF8&amp;quot;&gt; &lt;Title ID=”1”&gt; &lt;SourceEntity&gt;e1 e2 ... en&lt;/SourceEntity&gt; h2 ... &lt;/Title&gt; &lt;Title ID=”2”&gt; &lt;SourceEntity&gt;e1 e2 ... ei&lt;/SourceEntity&gt; &lt;TargetEntity&gt;h1 h2 ... hj&lt;/TargetEntity&gt; &lt;/Title&gt; ... &lt;!-rest of the titles to follow --&gt; ... &lt;/ WikipediaCorpus&gt; Appendix C: Results Submission - Format • File Naming Conventions: o NEWS09_ Result _XXYY_gggg nn_description.xml ■ XX: Source ■ YY: Target ■ gggg: Group ID ■ nn: run ID. ■ description: Description of the run • File Formats: o All results would be submitted in XML formats (Appendix B). • Data Encoding Formats: o The data would be in Unicode, in UTF-8 encoding. The results are expected to be submitted in UTF-8 format only. Example: NEWS2009_EnHi_TUniv_01_HMMBased.xml &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt; &lt;WikipediaMiningTaskResults SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; GroupID = &amp;quot;Trans University&amp;quot; RunID = &amp;quot;1&amp;quot; RunType = &amp;quot;Standard&amp;quot; Comments = &amp;quot;SVD Run with params: alpha=xxx beta=yyy&amp;quot;&gt; &lt;Title ID=&amp;quot;1&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;e1&lt;/SourceName&gt; &lt;TargetName&gt;h1&lt;/TargetName&gt; &lt;/MinedPair&gt; &lt;MinedPair ID=&amp;quot;2&amp;quot;&gt; &lt;SourceName&gt;e2&lt;/SourceName&gt; &lt;TargetName&gt;h2&lt;/TargetName&gt; &lt;/MinedPair&gt; by other pairs mined from this title--&gt; &lt;/Title&gt; &lt;Title ID=&amp;quot;2&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;e1&lt;/SourceName&gt; &lt;TargetName&gt;h1&lt;/TargetName&gt; &lt;/MinedPair&gt; 35 &lt;MinedPair ID=&amp;quot;2&amp;quot;&gt; &lt;SourceName&gt;e2&lt;/SourceName&gt; &lt;TargetName&gt;h2&lt;/TargetName&gt; &lt;/MinedPair&gt; by other pairs mined from this title--&gt; &lt;/Title&gt; ... &lt;!-- All titles in the culled data to follow --&gt; ... &lt;/WikipediaMiningTaskResults&gt; Appendix D: Sample Eng-Hindi Interwikilink Data &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt; &lt;WikipediaCorpus CorpusID = &amp;quot;NEWS2009-Wiki-EnHi-Sample&amp;quot; SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; CorpusType = &amp;quot;Wiki&amp;quot; CorpusSize = &amp;quot;3&amp;quot; CorpusFormat = &amp;quot;UTF8&amp;quot;&gt; &lt;Title ID=&amp;quot;1&amp;quot;&gt; &lt;SourceEntity&gt;Indian National Congress&lt;/SourceEntity&gt; राष्ट्रीय &lt;/Title&gt; {Congress, should be identified by the paricipants--&gt; &lt;Title ID=&amp;quot;2&amp;quot;&gt; &lt;SourceEntity&gt;University of Oxford&lt;/SourceEntity&gt; &lt;/Title&gt; {Oxford, should be identified by the paricipants--&gt; &lt;Title ID=&amp;quot;3&amp;quot;&gt; &lt;SourceEntity&gt;Jawaharlal Nehru University&lt;/SourceEntity&gt; नेहरू &lt;/Title&gt; {Jawaharlal, and {Nehru, should be identified by the paricipants--&gt; &lt;Title ID=&amp;quot;4&amp;quot;&gt; &lt;SourceEntity&gt;Indian Institute Of Science&lt;/SourceEntity&gt; विज्ञान &lt;/Title&gt; &lt;!--There are no transliteration pairs here --&gt; &lt;/WikipediaCorpus&gt; Appendix E: Eng-Hindi Gold Mined Data (wrt the above WIL Data) &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;</note>
<title confidence="0.873713428571429">lt;WikipediaMiningTaskResults SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; GroupID = &amp;quot;Gold-Standard&amp;quot; RunID = &amp;quot;&amp;quot; RunType = &amp;quot;&amp;quot; Comments = &amp;quot;&amp;quot;&gt;</title>
<note confidence="0.96974225">lt;Title ID=&amp;quot;1&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Congress&lt;/SourceName&gt; &lt;/MinedPair&gt; &lt;/Title&gt; &lt;Title ID=&amp;quot;2&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; 36 &lt;SourceName&gt;Oxford&lt;/SourceName&gt; &lt;/MinedPair&gt; &lt;/Title&gt; &lt;Title ID=&amp;quot;3&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Jawaharlal&lt;/SourceName&gt; &lt;/MinedPair&gt; &lt;MinedPair ID=&amp;quot;2&amp;quot;&gt; &lt;SourceName&gt;Nehru&lt;/SourceName&gt; &lt;/MinedPair&gt; &lt;/Title&gt; &lt;Title ID=&amp;quot;4&amp;quot;&gt; &lt;/Title&gt; &lt;/WikipediaMiningTaskResults&gt; Appendix F: English-Hindi Sample Submission and Evaluation &lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;</note>
<title confidence="0.850553666666667">lt;WikipediaMiningTaskResults SourceLang = &amp;quot;English&amp;quot; TargetLang = &amp;quot;Hindi&amp;quot; GroupID = &amp;quot;Gold-Standard&amp;quot; RunID = &amp;quot;&amp;quot; RunType = &amp;quot;&amp;quot;</title>
<note confidence="0.93615275">lt;Title ID=&amp;quot;1&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Congress&lt;/SourceName&gt; &lt;/MinedPair&gt; The participant mined all correct transliteration pairs &lt;/Title&gt; &lt;Title ID=&amp;quot;2&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Oxford&lt;/SourceName&gt; &lt;/MinedPair&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;University&lt;/SourceName&gt; &lt;/MinedPair&gt; participant mined an incorrect transliteration pair &lt;/Title&gt; &lt;Title ID=&amp;quot;3&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Jawaharlal&lt;/SourceName&gt; &lt;/MinedPair&gt; participant missed the correct transliteration pair {Nehru, &lt;/Title&gt; &lt;Title ID=&amp;quot;4&amp;quot;&gt; &lt;MinedPair ID=&amp;quot;1&amp;quot;&gt; &lt;SourceName&gt;Indian&lt;/SourceName&gt; &lt;/MinedPair&gt; participant mined an incorrect transliteration pair {Indian, &lt;/Title&gt; &lt;/WikipediaMiningTaskResults&gt; 37 Sample Evaluation = (Oxford, (Jawaharlal, 4 = TP = (Oxford, (Jawaharlal, = 3</note>
<abstract confidence="0.8515616">FP = 2 = FN = TP A A 3 4 = 0.75 ns TP= A= 2 = 0.67 = 0.6 + 0.75</abstract>
<intro confidence="0.671668">38</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>