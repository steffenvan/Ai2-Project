<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008974">
<title confidence="0.997019">
V3: Unsupervised Generation of Domain Aspect Terms for
Aspect Based Sentiment Analysis
</title>
<note confidence="0.640184">
Aitor Garcia-Pablos,
Montse Cuadros, Se´an Gaines
Vicomtech-IK4 research centre
Mikeletegi 57, San Sebastian, Spain
</note>
<email confidence="0.98855">
{agarciap,mcuadros}@vicomtech.org
</email>
<author confidence="0.900697">
German Rigau
</author>
<affiliation confidence="0.8342415">
IXA Group
Euskal Herriko Unibertsitatea,
</affiliation>
<address confidence="0.962012">
San Sebastian, Spain
</address>
<email confidence="0.998565">
german.rigau@ehu.es
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985111111111">
This paper presents V3, an unsupervised
system for aspect-based Sentiment Analy-
sis when evaluated on the SemEval 2014
Task 4. V3 focuses on generating a list
of aspect terms for a new domain using a
collection of raw texts from the domain.
We also implement a very basic approach
to classify the aspect terms into categories
and assign polarities to them.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956652173913">
The automatic analysis of opinions, within the
framework of opinion mining or sentiment anal-
ysis, has gained a huge importance during the last
decade due to the amount of review web sites,
blogs and social networks producing everyday a
massive amount of new content (Pang and Lee,
2008; Liu, 2012; Zhang and Liu, 2014). This con-
tent usually contains opinions about different enti-
ties, products or services. Trying to cope with this
large amounts of textual data is unfeasible with-
out the help of automatic Opinion Mining tools
which try to detect, identify, classify, aggregate
and summarize the opinions expressed about dif-
ferent topics (Hu and Liu, 2004) (Popescu and Et-
zioni, 2005) (Wu et al., 2009) (Zhang et al., 2010).
In this framework, aspect based opinion mining
systems aim to detect the sentiment at “aspect”
level (i.e. the precise feature being opinionated in
a clause or sentence).
In this paper we describe our system presented
in the SemEval 2014 task 41 Aspect Based Senti-
ment Analysis (Pontiki et al., 2014), which focuses
on detecting opinionated aspect terms (e.g. wine
</bodyText>
<footnote confidence="0.9842615">
This work is licensed under a Creative Commons Attribution
4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http:
//creativecommons.org/licenses/by/4.0/
1http://alt.qcri.org/semeval2014/
task4/
</footnote>
<bodyText confidence="0.995132956521739">
list and menu in restaurant domain, and hard disk
and battery life in laptop domain), their categories
and polarities in customer review sentences.
The task provides two training datasets, one of
restaurant reviews and other of laptop reviews.
The restaurant review dataset consists of over
3,000 English sentences from restaurant reviews
borrowed from (Ganu et al., 2009). The laptop
review dataset consists of over 3,000 English sen-
tences extracted from customer reviews. The task
is divided in four different subtasks: subtask 1 as-
pect term extraction, subtask 2 aspect term polar-
ity detection, subtask 3 aspect category detection,
subtask 4 aspect category polarity detection. Our
system mainly focused on subtask 1, but we have
also participated in the other subtasks.
The paper is organized as follows: section 2
presents our approach, section 3 details the im-
provement methods used for the aspects term se-
lection and section 4 focus on category and polar-
ity tagging. Finally section 5 presents the results
obtained and section 6 draws the conclusions and
future work.
</bodyText>
<sectionHeader confidence="0.919408" genericHeader="method">
2 Our approach
</sectionHeader>
<bodyText confidence="0.999256375">
We have adapted the double-propagation tech-
nique described in (Qiu et al., 2009; Qiu et al.,
2011). This method consists of using a minimal
seed list of aspect terms and opinion words and
propagate them through an unlabelled domain-
related corpus using a set of propagation rules.
The goal is to obtain an extended aspect term and
opinion word lists. (Qiu et al., 2009) define opin-
ion words as words that convey some positive or
negative sentiment polarities. They only extract
nouns as aspect terms and adjectives as opinion
words, and we assume the same restriction.
The propagation rules have the form of depen-
dency relations and some part-of-speech restric-
tions. Some rules extract new aspect terms, and
others extract new opinion words. Table 1 shows
</bodyText>
<page confidence="0.987091">
833
</page>
<note confidence="0.7303595">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 833–837,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999934387096774">
the rules used in our approach, similar to those de-
tailed in (Qiu et al., 2011) with some modifica-
tions. In this table, T stands for aspect term (i.e.
a word already in the aspect terms set) and O for
opinion word (i.e. a word already in the opinion
words set). W means any word. The dependency
types used are amod, dobj, subj and conj, which
stand for adjectival modifier, direct object, subject
and conjunction respectively. Additional restric-
tions on the Part-Of-Speech (POS) of the words
present in the rule are shown in the third column
of the table. The last column indicates to which
set (aspect terms or opinion words) the new word
is added.
To obtain the dependency trees and word lem-
mas and POS tags, we use the Stanford NLP tools2
(De Marneffe et al., 2006). Our initial seed words
are just the adjectives good and bad, which are
added to the initial opinion words set. The ini-
tial aspect terms set starts empty. Each sentence
in the dataset is analysed to obtain its dependency
tree and the rules are checked sequentially. If rule
is triggered, then the word indicated by that rule
is added to the corresponding set (aspect terms
or opinion words, depending on the rule). These
new words can be then used to trigger the propa-
gation rules later. After the last sentence the pro-
cess starts from the beginning to check the rules
with the newly added words. The process stops
when no more words have been added during a
full dataset iteration.
</bodyText>
<sectionHeader confidence="0.929388" genericHeader="method">
3 Selecting aspect term candidates
</sectionHeader>
<bodyText confidence="0.999906142857143">
The double-propagation process populates both
sets of domain aspect terms and domain opinion
words, but we focus our attention in the aspect
terms set. Due to the nature of the process it tends
to generate hundreds of different potential aspect
terms, many of them being incorrect. We apply
some additional processes to improve the list.
</bodyText>
<subsectionHeader confidence="0.999926">
3.1 Ranking the aspect terms
</subsectionHeader>
<bodyText confidence="0.999592285714286">
One way to reduce the undesired terms is to rank
them, pushing the incorrect aspect terms to the
bottom of the list and using only a certain subset
of top ranked terms. In order to rank this list we
have modelled the double-propagation process as
a undirected graph population process. Each new
aspect term or opinion word discovered by apply-
</bodyText>
<footnote confidence="0.5382115">
2http://nlp.stanford.edu/software/
lex-parser.shtml
</footnote>
<bodyText confidence="0.999956210526316">
ing a propagation rule is added as a vertex to the
graph. The rule used to extract the new word is
added as an edge to the graph, connecting the orig-
inal word and the newly discovered word.
We have applied the well-known PageRank al-
gorithm (Brin and Page, 1998) to score the vertices
of the graph. To calculate the PageRank scores
we have used the JUNG framework3 (OMadad-
hain et al., 2005), a set of Java libraries to work
with graphs. The value of the alpha parameter that
represents the probability of a random jump to any
node of the graph has been left at 0.15 (in the lit-
erature it is recommended an alpha value between
0.1 and 0.2). The aspect terms are then ordered us-
ing their associated score, being the most relevant
aspect term, the one with the highest score. Then
the list can be trimmed to a certain amount of top
ranked terms, trying to balance the precision and
recall of the resulting list.
</bodyText>
<subsectionHeader confidence="0.999898">
3.2 Filtering undesired words
</subsectionHeader>
<bodyText confidence="0.999909214285714">
The double-propagation method always intro-
duces many undesired words. Some of these un-
desired words appear very frequently and are com-
bined with a large number of words. So, they tend
to also appear in high positions in the ranking.
Many of these words are easy to identify, and they
are not likely to be useful aspect terms in any do-
main. Examples of these words are: nothing, ev-
erything, thing, anyone, someone, somebody, etc.
In this work we use a domain agnostic stop word
list to deal with this kind of words. The authors
of the original double-propagation approach use
some clause and frequency based heuristics that
we do not employ here.
</bodyText>
<subsectionHeader confidence="0.999525">
3.3 Detecting multiword terms
</subsectionHeader>
<bodyText confidence="0.999672416666667">
Many aspect terms are not just single words, but
compounds and multiword terms (e.g. wine list,
hard disk drive, battery life, etc.). In the origi-
nal double-propagation paper, the authors consider
adjacent nouns to a given aspect term as multiword
terms and perform an a posteriori pruning based
on the frequency of the combination. We have
tried to add multiword terms without increasing
the amount of noise in the resulting list. One of the
approaches included in the system exploits Word-
Net 4 (Fellbaum, 1999), and the following simple
rules:
</bodyText>
<footnote confidence="0.9999335">
3http://jung.sourceforge.net
4http://wordnet.princeton.edu/
</footnote>
<page confidence="0.983257">
834
</page>
<table confidence="0.999870333333333">
Rule Observations Constraints Action
R11 O → amod→W W is a noun W→T
R12 O→dobj→W1 ←subj←W2 W2 is a noun W2→T
R21 T ← amod ← W W is an adjective W→O
R22 T → subj → W1 ← dobj ← W2 W2 is an adjective W2→ O
R31 T → conj → W W is a noun W → T
R32 T → subj → W1 ← dobj ← W2 W2 is a noun W → T
R41 O → conj → W W is an adjective W→ O
R42 O → Dep1 → W1 ← Dep2 ← W2 Dep1==Dep2, W2 is an adjective W2→ O
</table>
<tableCaption confidence="0.999726">
Table 1: Propagation rules.
</tableCaption>
<listItem confidence="0.912467285714286">
• If word N and word N+1 are nouns, and the
combination is an entry in WordNet (or in
Wikipedia, see below). E.g.: battery life
• If word N is an adjective and word N+1 is
a noun, and the combination is an entry in
WordNet. E.g.: hot dog, happy hour
• If word Nis an adjective, word N+1 is a noun,
</listItem>
<bodyText confidence="0.9429">
and word n is a relational adjective in Word-
Net (lexical file 01). E.g.: Thai food
In order to improve the coverage of the Word-
Net approach, we also check if a combination of
two consecutive nouns appears as a Wikipedia ar-
ticle title. Wikipedia articles refer to real word
concepts and entities, so if a combination of words
is a title of a Wikipedia article it is very likely
that this word combination is also meaningful (e.g.
DVD player, USB port, goat cheese, pepperoni
pizza). We limit the lookup in Wikipedia titles just
to combination of nouns to avoid the inclusion of
incorrect aspect terms.
</bodyText>
<sectionHeader confidence="0.828532" genericHeader="method">
4 Assigning categories and polarities
</sectionHeader>
<bodyText confidence="0.99998094">
Despite we have focused our attention on acquir-
ing aspect terms from a domain, we have also par-
ticipated in the rest of subtasks: grouping aspect
terms into a fixed set of categories, and assigning
polarities to both aspect terms and categories.
To group the aspect terms into categories, we
have employed WordNet similarities. The idea
is to compare the detected aspect terms against a
term or group of terms representative of the tar-
get categories. In this case the categories (only
for restaurants) were food, service, price, ambi-
ence and anecdotes/miscellaneous.
Initially, the representative word for each cate-
gory (except for the anecdotes/miscellaneous) was
the name of the category itself. We use the similar-
ity measure described by (Wu and Palmer, 1994).
Detected aspect terms are compared to the set of
representative words on each category, and they
are assigned to the category with a higher similar-
ity result. For example using this approach, the
similarity between food and cheese is 0.8, while
similarity between service and cheese is 0.25, and
between price and cheese is 0.266. Thus, in this
case cheese is assigned to the category food.
If the similarity does not surpass a given min-
imum threshold (manually set to 0.7), the current
aspect term is not assigned to the category to avoid
assigning a wrong category just because the other
were even less similar. After classifying the as-
pect terms of a given sentence into categories, we
assign those categories to the sentence. If no cat-
egory has been assigned, then we use the anec-
dotes/miscellaneous category as the default one.
This approach is quite naive and it has many
limitations. It works quite well for the category
food, classifying ingredients and meals, but it fails
when the category or the aspect terms are more
vague or abstract. In addition, we do not perform
any kind of word sense disambiguation or sense
pruning, which probably would discard unrelated
senses.
For detecting the polarity we have used the
SentiWords (Guerini et al., 2013; Warriner et al.,
2013) as a polarity lexicon. Using direct depen-
dency relations between aspect terms and polarity
bearing words we assign the polarity value from
the lexicon to the aspect term. We make a simple
count of the polarities of the aspect terms classi-
fied under a certain category to assign the polarity
of that category in a particular sentence.
</bodyText>
<sectionHeader confidence="0.999241" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999662">
The run submitted to the SemEval task 4 compe-
tition was based on 25k unlabelled sentences ex-
tracted from domain related reviews (for restau-
rants and laptops) obtained by scraping different
websites. We used these unlabelled sentences to
execute our unsupervised system to generate and
</bodyText>
<page confidence="0.995889">
835
</page>
<table confidence="0.999308">
Restaur. aspect terms Precision Recall F-score
SemEval Baseline 0.525 0.427 0.471
V3 (S) 0.656 0.562 0.605
V3 (W) 0.571 0.641 0.604
V3 (W+S) 0.575 0.645 0.608
</table>
<tableCaption confidence="0.990433">
Table 2: Results on the restaurant review test set.
</tableCaption>
<table confidence="0.9998664">
Laptops aspect terms Precision Recall F-score
SemEval Baseline 0.443 0.298 0.356
V3 (S) 0.265 0.276 0.271
V3 (W) 0.321 0.425 0.366
V3 (W+S) 0.279 0.444 0.343
</table>
<tableCaption confidence="0.999964">
Table 3: Results on the laptop review test set.
</tableCaption>
<bodyText confidence="0.999863387096774">
rank the aspect term lists. Then we used those
aspect term lists to annotate the sentences using
a simple lemma matching approach between the
words. The generated aspect term lists were lim-
ited to the first ranked 550 items after some initial
experiments with the SemEval training sets.
The SemEval test datasets (restaurants and lap-
tops) contain about 800 sentences each. The
restaurant dataset contains 1,134 labelled gold as-
pect term spans, and the laptop dataset contains
634 labelled gold aspect term spans. We compare
the results against the SemEval baseline which is
calculated using the scripts provided by the Se-
mEval organizers. This baseline splits the dataset
into train and test subsets, and uses all the labelled
aspect terms in the train subset to build a dictio-
nary of aspect terms. Then it simply uses that dic-
tionary to label the test subset for evaluation.
Tables 2 and 3 show the performance of our sys-
tem with respect to the baselines in both datasets.
”V3 (S)” stands for our system only using the Se-
mEval test data (as our approach is unsupervised
it learns from the available texts for the task). (W)
refers to the results using our own dataset scraped
from the Web. Finally (W+S) refers to the results
using both SemEval and our Web dataset mixed
together. The best results are highlighted in bold.
For subtask 1, although our system outperforms
the baseline in terms of F-score in both datasets, in
the competition our system obtained quite modest
results ranking 24th and 26th out of 29 participants
</bodyText>
<table confidence="0.990836">
Restaur. categories Precision Recall F-score
SemEval Baseline 0.671 0.602 0.638
V3 0.638 0.569 0.602
</table>
<tableCaption confidence="0.998015">
Table 4: Results on restaurant category detection
using the test set.
</tableCaption>
<table confidence="0.999791">
Polarity detection accuracy Baseline V3
Restaur. aspect terms 0.642 0.597
Restaur. categories 0.656 0.472
Laptop aspect terms 0.510 0.538
</table>
<tableCaption confidence="0.8584105">
Table 5: Results for the polarity classification sub-
tasks (subtasks 2 and 4).
</tableCaption>
<bodyText confidence="0.998112611111111">
for restaurants and laptops respectively.
One of the most important source of errors are
the multiword aspect term detection. In the Se-
mEval datasets, about the 25% of the gold aspect
terms are multiword terms. In both datasets we
find a large number of names of recipes and meals,
composed by two, three or even more words,
which cannot appear in our aspect term lists be-
cause we limit the multiword length up to two
words.
As mentioned in the introduction our approach
focuses mainly in the aspects so the approach for
detecting categories and polarities needs more at-
tention. Table 4 presents our results on category
detection and table 5 our results on polarities. The
results are quite poor so we do not comment on
them here. We will address these subtasks in fu-
ture work.
</bodyText>
<sectionHeader confidence="0.997374" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9996493125">
In this paper we propose a simple and unsuper-
vised system able to bootstrap and rank a list
of domain aspect terms from a set of unlabelled
domain texts. We use a double-propagation ap-
proach, and we model the obtained terms and their
relations as a graph. Then, we apply the PageRank
algorithm to score the obtained terms. Despite the
modest results, our unsupervised system for de-
tecting aspect terms performs better than the su-
pervised baseline. In our future work we will try
to improve the way we deal with multiword terms
to reduce the amount of incorrect aspect terms and
generate a better ranking. We also plan to try
different methods for the category grouping, and
explore knowledge-based word sense disambigua-
tion methods for improving the current system.
</bodyText>
<sectionHeader confidence="0.997762" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.991044666666667">
This work has been partially funded by SKaTer
(TIN2012-38584-C06-02) and OpeNER (FP7-
ICT-2011-SME- DCL-296451).
</bodyText>
<page confidence="0.997732">
836
</page>
<sectionHeader confidence="0.996308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999634942857143">
Sergey Brin and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual web search engine.
Computer networks and ISDN systems, 30(1):107–
117.
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.
Christiane Fellbaum. 1999. WordNet. Wiley Online
Library.
Gayatree Ganu, N Elhadad, and A Marian. 2009. Be-
yond the Stars: Improving Rating Predictions using
Review Text Content. WebDB, (WebDB):1–6.
Marco Guerini, Lorenzo Gatti, and Marco Turchi.
2013. Sentiment analysis: How to derive prior
polarities from sentiwordnet. arXiv preprint
arXiv:1309.5843.
Minqing Hu and Bing Liu. 2004. Mining opinion fea-
tures in customer reviews. AAAI.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Joshua OMadadhain, Danyel Fisher, Padhraic Smyth,
Scott White, and Yan-Biao Boey. 2005. Analysis
and visualization of network data using jung. Jour-
nal of Statistical Software, 10(2):1–35.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect based sentiment analysis. Proceedings of
the International Workshop on Semantic Evaluation
(SemEval).
AM Popescu and Oren Etzioni. 2005. Extracting prod-
uct features and opinions from reviews. Natural lan-
guage processing and text mining, (October):339–
346.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding Domain Sentiment Lexicon
through Double Propagation. IJCAI.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extrac-
tion through double propagation. Computational
linguistics, (July 2010).
Amy Beth Warriner, Victor Kuperman, and Marc Brys-
baert. 2013. Norms of valence, arousal, and dom-
inance for 13,915 english lemmas. Behavior re-
search methods, 45(4):1191–1207.
Zhibiao Wu and Martha Palmer. 1994. Verbs seman-
tics and lexical selection. In Proceedings of the 32nd
annual meeting on Association for Computational
Linguistics, pages 133–138. Association for Com-
putational Linguistics.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In Proceedings of the 2009 Conference on Em-
pirical Methods in Natural Language Processing:
Volume 3-Volume 3, pages 1533–1541. Association
for Computational Linguistics.
Lei Zhang and Bing Liu. 2014. Aspect and Entity
Extraction for Opinion Mining. Data Mining and
Knowledge Discovery for Big Data.
L Zhang, Bing Liu, SH Lim, and E O’Brien-Strain.
2010. Extracting and ranking product features in
opinion documents. Proceedings of the 23rd Inter-
national Conference on Computational Linguistics,
(August):1462–1470.
</reference>
<page confidence="0.997849">
837
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.093137">
<title confidence="0.902367">V3: Unsupervised Generation of Domain Aspect Terms Aspect Based Sentiment Analysis Aitor</title>
<author confidence="0.746985">Montse Cuadros</author>
<author confidence="0.746985">Se´an</author>
<note confidence="0.648188">Vicomtech-IK4 research Mikeletegi 57, San Sebastian,</note>
<author confidence="0.55288">German</author>
<affiliation confidence="0.678273666666667">IXA Euskal Herriko San Sebastian,</affiliation>
<email confidence="0.995271">german.rigau@ehu.es</email>
<abstract confidence="0.9986861">This paper presents V3, an unsupervised system for aspect-based Sentiment Analysis when evaluated on the SemEval 2014 Task 4. V3 focuses on generating a list of aspect terms for a new domain using a collection of raw texts from the domain. We also implement a very basic approach to classify the aspect terms into categories and assign polarities to them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual web search engine.</title>
<date>1998</date>
<journal>Computer networks and ISDN systems,</journal>
<volume>30</volume>
<issue>1</issue>
<pages>117</pages>
<contexts>
<context position="6551" citStr="Brin and Page, 1998" startWordPosition="1062" endWordPosition="1065">ms is to rank them, pushing the incorrect aspect terms to the bottom of the list and using only a certain subset of top ranked terms. In order to rank this list we have modelled the double-propagation process as a undirected graph population process. Each new aspect term or opinion word discovered by apply2http://nlp.stanford.edu/software/ lex-parser.shtml ing a propagation rule is added as a vertex to the graph. The rule used to extract the new word is added as an edge to the graph, connecting the original word and the newly discovered word. We have applied the well-known PageRank algorithm (Brin and Page, 1998) to score the vertices of the graph. To calculate the PageRank scores we have used the JUNG framework3 (OMadadhain et al., 2005), a set of Java libraries to work with graphs. The value of the alpha parameter that represents the probability of a random jump to any node of the graph has been left at 0.15 (in the literature it is recommended an alpha value between 0.1 and 0.2). The aspect terms are then ordered using their associated score, being the most relevant aspect term, the one with the highest score. Then the list can be trimmed to a certain amount of top ranked terms, trying to balance t</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems, 30(1):107– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<date>1999</date>
<publisher>WordNet. Wiley Online Library.</publisher>
<contexts>
<context position="8416" citStr="Fellbaum, 1999" startWordPosition="1389" endWordPosition="1390">e some clause and frequency based heuristics that we do not employ here. 3.3 Detecting multiword terms Many aspect terms are not just single words, but compounds and multiword terms (e.g. wine list, hard disk drive, battery life, etc.). In the original double-propagation paper, the authors consider adjacent nouns to a given aspect term as multiword terms and perform an a posteriori pruning based on the frequency of the combination. We have tried to add multiword terms without increasing the amount of noise in the resulting list. One of the approaches included in the system exploits WordNet 4 (Fellbaum, 1999), and the following simple rules: 3http://jung.sourceforge.net 4http://wordnet.princeton.edu/ 834 Rule Observations Constraints Action R11 O → amod→W W is a noun W→T R12 O→dobj→W1 ←subj←W2 W2 is a noun W2→T R21 T ← amod ← W W is an adjective W→O R22 T → subj → W1 ← dobj ← W2 W2 is an adjective W2→ O R31 T → conj → W W is a noun W → T R32 T → subj → W1 ← dobj ← W2 W2 is a noun W → T R41 O → conj → W W is an adjective W→ O R42 O → Dep1 → W1 ← Dep2 ← W2 Dep1==Dep2, W2 is an adjective W2→ O Table 1: Propagation rules. • If word N and word N+1 are nouns, and the combination is an entry in WordNet (</context>
</contexts>
<marker>Fellbaum, 1999</marker>
<rawString>Christiane Fellbaum. 1999. WordNet. Wiley Online Library.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>N Elhadad</author>
<author>A Marian</author>
</authors>
<title>Beyond the Stars: Improving Rating Predictions using Review Text Content.</title>
<date>2009</date>
<location>WebDB, (WebDB):1–6.</location>
<contexts>
<context position="2428" citStr="Ganu et al., 2009" startWordPosition="363" endWordPosition="366">k is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ 1http://alt.qcri.org/semeval2014/ task4/ list and menu in restaurant domain, and hard disk and battery life in laptop domain), their categories and polarities in customer review sentences. The task provides two training datasets, one of restaurant reviews and other of laptop reviews. The restaurant review dataset consists of over 3,000 English sentences from restaurant reviews borrowed from (Ganu et al., 2009). The laptop review dataset consists of over 3,000 English sentences extracted from customer reviews. The task is divided in four different subtasks: subtask 1 aspect term extraction, subtask 2 aspect term polarity detection, subtask 3 aspect category detection, subtask 4 aspect category polarity detection. Our system mainly focused on subtask 1, but we have also participated in the other subtasks. The paper is organized as follows: section 2 presents our approach, section 3 details the improvement methods used for the aspects term selection and section 4 focus on category and polarity tagging</context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, N Elhadad, and A Marian. 2009. Beyond the Stars: Improving Rating Predictions using Review Text Content. WebDB, (WebDB):1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Guerini</author>
<author>Lorenzo Gatti</author>
<author>Marco Turchi</author>
</authors>
<title>Sentiment analysis: How to derive prior polarities from sentiwordnet. arXiv preprint arXiv:1309.5843.</title>
<date>2013</date>
<contexts>
<context position="11895" citStr="Guerini et al., 2013" startWordPosition="2015" endWordPosition="2018">pect terms of a given sentence into categories, we assign those categories to the sentence. If no category has been assigned, then we use the anecdotes/miscellaneous category as the default one. This approach is quite naive and it has many limitations. It works quite well for the category food, classifying ingredients and meals, but it fails when the category or the aspect terms are more vague or abstract. In addition, we do not perform any kind of word sense disambiguation or sense pruning, which probably would discard unrelated senses. For detecting the polarity we have used the SentiWords (Guerini et al., 2013; Warriner et al., 2013) as a polarity lexicon. Using direct dependency relations between aspect terms and polarity bearing words we assign the polarity value from the lexicon to the aspect term. We make a simple count of the polarities of the aspect terms classified under a certain category to assign the polarity of that category in a particular sentence. 5 Evaluation The run submitted to the SemEval task 4 competition was based on 25k unlabelled sentences extracted from domain related reviews (for restaurants and laptops) obtained by scraping different websites. We used these unlabelled sent</context>
</contexts>
<marker>Guerini, Gatti, Turchi, 2013</marker>
<rawString>Marco Guerini, Lorenzo Gatti, and Marco Turchi. 2013. Sentiment analysis: How to derive prior polarities from sentiwordnet. arXiv preprint arXiv:1309.5843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinion features in customer reviews.</title>
<date>2004</date>
<publisher>AAAI.</publisher>
<contexts>
<context position="1368" citStr="Hu and Liu, 2004" startWordPosition="206" endWordPosition="209">hin the framework of opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). In this paper we describe our system presented in the SemEval 2014 task 41 Aspect Based Sentiment Analysis (Pontiki et al., 2014), which focuses on detecting opinionated aspect terms (e.g. wine This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining opinion features in customer reviews. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1008" citStr="Liu, 2012" startWordPosition="150" endWordPosition="151">based Sentiment Analysis when evaluated on the SemEval 2014 Task 4. V3 focuses on generating a list of aspect terms for a new domain using a collection of raw texts from the domain. We also implement a very basic approach to classify the aspect terms into categories and assign polarities to them. 1 Introduction The automatic analysis of opinions, within the framework of opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua OMadadhain</author>
<author>Danyel Fisher</author>
<author>Padhraic Smyth</author>
<author>Scott White</author>
<author>Yan-Biao Boey</author>
</authors>
<title>Analysis and visualization of network data using jung.</title>
<date>2005</date>
<journal>Journal of Statistical Software,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="6679" citStr="OMadadhain et al., 2005" startWordPosition="1084" endWordPosition="1088">ed terms. In order to rank this list we have modelled the double-propagation process as a undirected graph population process. Each new aspect term or opinion word discovered by apply2http://nlp.stanford.edu/software/ lex-parser.shtml ing a propagation rule is added as a vertex to the graph. The rule used to extract the new word is added as an edge to the graph, connecting the original word and the newly discovered word. We have applied the well-known PageRank algorithm (Brin and Page, 1998) to score the vertices of the graph. To calculate the PageRank scores we have used the JUNG framework3 (OMadadhain et al., 2005), a set of Java libraries to work with graphs. The value of the alpha parameter that represents the probability of a random jump to any node of the graph has been left at 0.15 (in the literature it is recommended an alpha value between 0.1 and 0.2). The aspect terms are then ordered using their associated score, being the most relevant aspect term, the one with the highest score. Then the list can be trimmed to a certain amount of top ranked terms, trying to balance the precision and recall of the resulting list. 3.2 Filtering undesired words The double-propagation method always introduces man</context>
</contexts>
<marker>OMadadhain, Fisher, Smyth, White, Boey, 2005</marker>
<rawString>Joshua OMadadhain, Danyel Fisher, Padhraic Smyth, Scott White, and Yan-Biao Boey. 2005. Analysis and visualization of network data using jung. Journal of Statistical Software, 10(2):1–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="997" citStr="Pang and Lee, 2008" startWordPosition="146" endWordPosition="149">d system for aspect-based Sentiment Analysis when evaluated on the SemEval 2014 Task 4. V3 focuses on generating a list of aspect terms for a new domain using a collection of raw texts from the domain. We also implement a very basic approach to classify the aspect terms into categories and assign polarities to them. 1 Introduction The automatic analysis of opinions, within the framework of opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Harris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Semeval-2014 task 4: Aspect based sentiment analysis.</title>
<date>2014</date>
<booktitle>Proceedings of the International Workshop on Semantic Evaluation (SemEval).</booktitle>
<contexts>
<context position="1737" citStr="Pontiki et al., 2014" startWordPosition="269" endWordPosition="272">s. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). In this paper we describe our system presented in the SemEval 2014 task 41 Aspect Based Sentiment Analysis (Pontiki et al., 2014), which focuses on detecting opinionated aspect terms (e.g. wine This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ 1http://alt.qcri.org/semeval2014/ task4/ list and menu in restaurant domain, and hard disk and battery life in laptop domain), their categories and polarities in customer review sentences. The task provides two training datasets, one of restaurant reviews and other of laptop reviews. The restaurant review dataset consist</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. Semeval-2014 task 4: Aspect based sentiment analysis. Proceedings of the International Workshop on Semantic Evaluation (SemEval).</rawString>
</citation>
<citation valid="true">
<authors>
<author>AM Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews. Natural language processing and text mining,</title>
<date>2005</date>
<contexts>
<context position="1396" citStr="Popescu and Etzioni, 2005" startWordPosition="210" endWordPosition="214">f opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). In this paper we describe our system presented in the SemEval 2014 task 41 Aspect Based Sentiment Analysis (Pontiki et al., 2014), which focuses on detecting opinionated aspect terms (e.g. wine This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.or</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>AM Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. Natural language processing and text mining, (October):339– 346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding Domain Sentiment Lexicon through Double Propagation.</title>
<date>2009</date>
<publisher>IJCAI.</publisher>
<contexts>
<context position="3225" citStr="Qiu et al., 2009" startWordPosition="493" endWordPosition="496">n, subtask 2 aspect term polarity detection, subtask 3 aspect category detection, subtask 4 aspect category polarity detection. Our system mainly focused on subtask 1, but we have also participated in the other subtasks. The paper is organized as follows: section 2 presents our approach, section 3 details the improvement methods used for the aspects term selection and section 4 focus on category and polarity tagging. Finally section 5 presents the results obtained and section 6 draws the conclusions and future work. 2 Our approach We have adapted the double-propagation technique described in (Qiu et al., 2009; Qiu et al., 2011). This method consists of using a minimal seed list of aspect terms and opinion words and propagate them through an unlabelled domainrelated corpus using a set of propagation rules. The goal is to obtain an extended aspect term and opinion word lists. (Qiu et al., 2009) define opinion words as words that convey some positive or negative sentiment polarities. They only extract nouns as aspect terms and adjectives as opinion words, and we assume the same restriction. The propagation rules have the form of dependency relations and some part-of-speech restrictions. Some rules ex</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding Domain Sentiment Lexicon through Double Propagation. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation. Computational linguistics,</title>
<date>2011</date>
<contexts>
<context position="3244" citStr="Qiu et al., 2011" startWordPosition="497" endWordPosition="500">t term polarity detection, subtask 3 aspect category detection, subtask 4 aspect category polarity detection. Our system mainly focused on subtask 1, but we have also participated in the other subtasks. The paper is organized as follows: section 2 presents our approach, section 3 details the improvement methods used for the aspects term selection and section 4 focus on category and polarity tagging. Finally section 5 presents the results obtained and section 6 draws the conclusions and future work. 2 Our approach We have adapted the double-propagation technique described in (Qiu et al., 2009; Qiu et al., 2011). This method consists of using a minimal seed list of aspect terms and opinion words and propagate them through an unlabelled domainrelated corpus using a set of propagation rules. The goal is to obtain an extended aspect term and opinion word lists. (Qiu et al., 2009) define opinion words as words that convey some positive or negative sentiment polarities. They only extract nouns as aspect terms and adjectives as opinion words, and we assume the same restriction. The propagation rules have the form of dependency relations and some part-of-speech restrictions. Some rules extract new aspect te</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational linguistics, (July 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Beth Warriner</author>
<author>Victor Kuperman</author>
<author>Marc Brysbaert</author>
</authors>
<title>Norms of valence, arousal, and dominance for 13,915 english lemmas. Behavior research methods,</title>
<date>2013</date>
<pages>45--4</pages>
<contexts>
<context position="11919" citStr="Warriner et al., 2013" startWordPosition="2019" endWordPosition="2022">sentence into categories, we assign those categories to the sentence. If no category has been assigned, then we use the anecdotes/miscellaneous category as the default one. This approach is quite naive and it has many limitations. It works quite well for the category food, classifying ingredients and meals, but it fails when the category or the aspect terms are more vague or abstract. In addition, we do not perform any kind of word sense disambiguation or sense pruning, which probably would discard unrelated senses. For detecting the polarity we have used the SentiWords (Guerini et al., 2013; Warriner et al., 2013) as a polarity lexicon. Using direct dependency relations between aspect terms and polarity bearing words we assign the polarity value from the lexicon to the aspect term. We make a simple count of the polarities of the aspect terms classified under a certain category to assign the polarity of that category in a particular sentence. 5 Evaluation The run submitted to the SemEval task 4 competition was based on 25k unlabelled sentences extracted from domain related reviews (for restaurants and laptops) obtained by scraping different websites. We used these unlabelled sentences to execute our uns</context>
</contexts>
<marker>Warriner, Kuperman, Brysbaert, 2013</marker>
<rawString>Amy Beth Warriner, Victor Kuperman, and Marc Brysbaert. 2013. Norms of valence, arousal, and dominance for 13,915 english lemmas. Behavior research methods, 45(4):1191–1207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10635" citStr="Wu and Palmer, 1994" startWordPosition="1802" endWordPosition="1805">ect terms into a fixed set of categories, and assigning polarities to both aspect terms and categories. To group the aspect terms into categories, we have employed WordNet similarities. The idea is to compare the detected aspect terms against a term or group of terms representative of the target categories. In this case the categories (only for restaurants) were food, service, price, ambience and anecdotes/miscellaneous. Initially, the representative word for each category (except for the anecdotes/miscellaneous) was the name of the category itself. We use the similarity measure described by (Wu and Palmer, 1994). Detected aspect terms are compared to the set of representative words on each category, and they are assigned to the category with a higher similarity result. For example using this approach, the similarity between food and cheese is 0.8, while similarity between service and cheese is 0.25, and between price and cheese is 0.266. Thus, in this case cheese is assigned to the category food. If the similarity does not surpass a given minimum threshold (manually set to 0.7), the current aspect term is not assigned to the category to avoid assigning a wrong category just because the other were eve</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pages 133–138. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>3</volume>
<pages>1533--1541</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1414" citStr="Wu et al., 2009" startWordPosition="215" endWordPosition="218">t analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). In this paper we describe our system presented in the SemEval 2014 task 41 Aspect Based Sentiment Analysis (Pontiki et al., 2014), which focuses on detecting opinionated aspect terms (e.g. wine This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3-Volume 3, pages 1533–1541. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
</authors>
<title>Aspect and Entity Extraction for Opinion Mining. Data Mining and Knowledge Discovery for Big Data.</title>
<date>2014</date>
<contexts>
<context position="1030" citStr="Zhang and Liu, 2014" startWordPosition="152" endWordPosition="155">ment Analysis when evaluated on the SemEval 2014 Task 4. V3 focuses on generating a list of aspect terms for a new domain using a collection of raw texts from the domain. We also implement a very basic approach to classify the aspect terms into categories and assign polarities to them. 1 Introduction The automatic analysis of opinions, within the framework of opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content (Pang and Lee, 2008; Liu, 2012; Zhang and Liu, 2014). This content usually contains opinions about different entities, products or services. Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics (Hu and Liu, 2004) (Popescu and Etzioni, 2005) (Wu et al., 2009) (Zhang et al., 2010). In this framework, aspect based opinion mining systems aim to detect the sentiment at “aspect” level (i.e. the precise feature being opinionated in a clause or sentence). In this paper we descr</context>
</contexts>
<marker>Zhang, Liu, 2014</marker>
<rawString>Lei Zhang and Bing Liu. 2014. Aspect and Entity Extraction for Opinion Mining. Data Mining and Knowledge Discovery for Big Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zhang</author>
<author>Bing Liu</author>
<author>SH Lim</author>
<author>E O’Brien-Strain</author>
</authors>
<title>Extracting and ranking product features in opinion documents.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics, (August):1462–1470.</booktitle>
<marker>Zhang, Liu, Lim, O’Brien-Strain, 2010</marker>
<rawString>L Zhang, Bing Liu, SH Lim, and E O’Brien-Strain. 2010. Extracting and ranking product features in opinion documents. Proceedings of the 23rd International Conference on Computational Linguistics, (August):1462–1470.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>