<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001853">
<note confidence="0.634488333333333">
THE LOGICAL ANALYSIS OF LEXICAL AMBIGUITY
David Stallard,
BBN Laboratories Inc.
10 Moulton St.,
Cambridge, Mass.
02238
</note>
<sectionHeader confidence="0.980617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99843675">
Theories of semantic interpretation which wish to
capture as many generalizations as possible must
face up to the manifoldly ambiguous and contextually
dependent nature of word meaning) In this paper I
present a two-level scheme of semantic interpretation
in which the first level deals with the semantic con-
sequences of -syntactic structure and the second with
the choice of word meaning. On the first level the
meanings of ambiguous words, pronominal
references, nominal compounds and metonomies are
not treated as fixed, but are instead represented by
free variables which range over predicates and func-
tions. The context-dependence of lexical meaning is
dealt with by the second level, a constraint propaga-
tion process which attempts to assign values to these
variables on the basis of the logical coherence of the
overall result. In so doing it makes use of a set of
polysemy operators which map between lexical
senses, thus making a potentially indefinite number of
related senses available.
</bodyText>
<sectionHeader confidence="0.999395" genericHeader="keywords">
1 INTRODUCTION: LEXICAL
ASSOCIATION IN A COMPOSITIONAL
SEMANTICS
</sectionHeader>
<bodyText confidence="0.992227929577465">
A tenet now held with some force among formal
semanticists is that the meaning of a complex natural-
language expression should be a function of just two
things: the meanings of the parts of the expression
and the syntactic rule used to form the expression out
of those parts. Systems such as Montague Grammar
[9] give phrases like &amp;quot;former senator&amp;quot; compositional
treatments by first translating them to an expression
of intensional logic, and then giving this expression a
model-theoretic interpretation in the usual way. The
practical relevance of this goal to work in natural lan-
guage processing is clear: for any application domain,
maximum coverage could be obtained from the same
domain-independent set of rules, needing only to add
the relevant entries, with their primitive associations of
meaning, to the lexicon.
&apos;The work presented here was supported under DARPA contract
*N00014-85-C-0016. The views and conclusions contained in this
document are those of the author and should not be interpreted as
necessarily representing the official policies, either expressed or
implied, of the Defense Advanced Research Projects Agency or the
United States Government.
An obvious technical issue for this program is
raised by the phenomenon of lexical ambiguity. This
problem is not one that has been particularly ad-
dressed in the Montague Grammar literature. The
most obvious approach is simply to make alternative
lexical senses separate entries in the lexicon, and to
allow these disambiguated lexical items to give rise to
separate syntactic and semantic analyses. The com-
putationally unattractive consequences of this are
quite clear: the same work must be done over again
for each variant.
An alternative class of proposals defers the lexical
part of the analysis until the rest is done. Hobbs
[5] has presented the most detailed general treatment
of this type to date. This treatment simply associates
each ambiguous lexical item with the logical disjunc-
tion of its separate senses. Standard reasoning tech-
niques (such as theorem proving) can then be ap-
plied. The problem with this approach is that it is
simply not correct. This may be most straightfor-
wardly seen in yes/no questions that contain an am-
biguity. For example, suppose the the ambiguous
verb &amp;quot;have&amp;quot; is to be treated as the disjunction of the
predicates POSSESS, PART-OF, etc. Then the
answer to the question &amp;quot;Does the butcher have
kidneys?&amp;quot; must always come out &amp;quot;yes&amp;quot;, because the
second alternative is (assumably) true regardless.
This method goes wrong because the issue in resolv-
ing ambiguity is determining which possibility was in-
tended, not which possibility is true.
A more correct approach is due to Landsbergen
and Scha [8] and implemented in the PHLIOA1 sys-
tem. There, the result of semantic interpretation is an
expression of an ambiguous logical language called
EFL (for English-oriented Formal Language). During
semantic interpretation each lexeme is assigned to
one (possibly ambiguous) descriptive constant of that
language, which is later mapped, via local translation
rules, to one or more expressions of an unambiguous
logical language called WML (for World Model
Language). The result is a set of complete WML
translations of the entire EFL expression, from which
sortally anomalous alternatives are subsequently
eliminated.
The PHLIOA1 system, while handling homonymy
acceptably, does not address the problem of
polysemy - the presence of an indefinite number of
related senses for a single word. Consider the
polysemous lexeme &amp;quot;mouth&amp;quot;, which is used differently
</bodyText>
<page confidence="0.998099">
179
</page>
<bodyText confidence="0.99894195">
in the phrases &amp;quot;mouth of a person&amp;quot;, &amp;quot;mouth of a
bottle&amp;quot;, &amp;quot;mouth of a river&amp;quot;, and &amp;quot;mouth of a cave&amp;quot;.
Surely the same logical relationship is not involved in
each of these cases. Generalizing the meaning of the
word will not help either, for if we tried to re-define
&amp;quot;mouth&amp;quot; to mean just any aperture, we would lose our
ability to refer to human &amp;quot;mouths&amp;quot; independently of
other parts of the body. Enumerating these separate
senses with separate translation rules does not look
like a very promising approach either, since it is not at
all clear that the list above could not be continued
indefinitely. The problem with such an approach to
meaning seems to be that it is too discrete: in linguis-
tic terms, it does not &amp;quot;capture a generalization&amp;quot;.
This paper presents a method of dealing with lex-
ical meanings which does seek to capture the
generalizations implicit in polysemy. The complexes
of meanings associated with polysemous lexical items
are generated, structured and extended by a kind of
&amp;quot;grammar&amp;quot; of word meaning: a set of operators which
take descriptive constants of a meaning represen-
tation language onto other descriptive constants or
expressions of that language. These operations in-
clude not only metaphorical and metonymic extension
of the word sense, but &amp;quot;broadening&amp;quot;, which allows a
word to refer to a wider class of items than before;
&amp;quot;exclusion&amp;quot;, which removes from the denotation of a
word the members of a particular subset thereof;
&amp;quot;narrowing&amp;quot;, which narrows the denotation down to a
particular subset. Each word is assumed to have a
core sense (or in the case that it is homonymous,
several core senses) from which extended senses
can be derived by recursive application of the
operators.
Related to the issue of lexical ambiguity, if tradi-
tionally studied apart from it. are the problems raised
by nominal compounds and metonymies. Here the
problem is determining the binary relation which has
been &amp;quot;elided&amp;quot; from the utterance. This could in prin-
ciple be any relation; a translation rule approach can-
not help here. Novel metaphorical uses of a word,
such as the substitution of an individual for a whole
class, will also escape such an approach. The point
about all three of these phenomena is that they es-
sentially create new lexical senses. The productive-
ness of this process suggests that the established
senses of polysemous lexemes may be generated in
the same way.
A key innovation of this work is to treat every non-
logical word as being potentially ambiguous. Thus
semantic interpretation initially assigns to each such
lexical item not an ambiguous constant, but a free
variable capable of ranging over the appropriate type
of a higher-order intensional logic (4]. These free vari-
ables are restricted to range not over an explicitly
enumerated set of logical expressions, but over a
potentially infinite set of them which is recursively
enumerable by the polysemy operators. Obviously,
the core sense itself (and other established senses)
are not excluded as candidates. A separate con-
straint propagation stage then assigns appropriate
descriptive constant values to these variables based
on the sortal coherence of the whole expression.
This two-stage method of semantic interpretation
will be seen to have an advantage over one not dis-
cussed so far: a single stage method which not does
not allot a separate role to lexical semantics or pay
close attention to compositionality, but rather seeks to
interpret distinct patterns like &amp;quot;mouth of a cave&amp;quot; as a
whole. Besides suffering from the same lack of
generality criticised above this latter method en-
counters difficulty when an ambiguous word-form and
a pronoun or trace are combined together. A second
constraint propagation stage enables the dependence
of word meaning on context - specifically, on the
meanings of other words and the referents of
anaphors and deixis in the utterance - to be captured.
The computational effect is that search can be cut
down in a space that is essentially a cartesian product
over the ambiguous elements of an utterance.
</bodyText>
<sectionHeader confidence="0.998723" genericHeader="method">
2 THE NOTION OF A &amp;quot;LOGICAL
VOCABULARY&amp;quot;
</sectionHeader>
<bodyText confidence="0.999787657142857">
Lexical association cannot be considered apart
from a notion of &amp;quot;logical&amp;quot; or &amp;quot;conceptual&amp;quot; vocabulary -
the set of descriptive constants of a logical language
which are available for making such associations.
This notion may be identified with the &amp;quot;domain model&amp;quot;
or &amp;quot;conceptual model&amp;quot; of such systems as PHLIOA1
(11], TEAM (3] and IRUS [1]. Logical vocabularies, or
&amp;quot;domains&amp;quot;, are what the polysemy operators work
with. The present section lays down the represen-
tational structure which the next, dealing with the
polysemy operators themselves, will make use of.
Let a &amp;quot;domain&amp;quot; be defined as a set of descriptive
constants and axioms involving them, subject to three
conditions: (1) The descriptive constants are such that
a specification of each of their extensions gives a
&amp;quot;state of the world&amp;quot; relevant to the domain (2) The
axioms are such that they constrain which states of
the world are possible or allowable (3) The axioms do
not define the constants with the biconditional, but
with one-way implication only, thus leaving the con-
stants primitive. If complete definitions of constants
via lambda-abstraction is allowed it is only as a tech-
nical convienence; these are to be regarded as
&amp;quot;extra&amp;quot;.
The latter condition (3) captures the important fact
that domains are not definable in terms of other
domains. Thus expressions cast in logical vocabulary
DA cannot be directly used to refer to states of affairs,
etc. expressible only in terms of logical vocabulary
Da. This has an impact for natural language question
answering systems in which DA is the notions of or-
dinary language and DB the logical vocabulary of
some technical domain. In this case, only lexical
items specially invented for the technical domain
(such as &amp;quot;JP-5&amp;quot;, a particular kind of military jet fuel)
</bodyText>
<page confidence="0.982968">
180
</page>
<bodyText confidence="0.999577757142857">
have an unproblematic lexical association in terms of
Da. Obviously not all the words a user employs will
have this characteristic, nor will all the constants of
the technical domain be lexicalizable in this way. In
other cases the notions of DA will have to be mapped
to those of Da, in some way that is not yet specified.
A common occurrence is for lexical items avail-
able in regular English to be employed to bridge the
gap, in such a way as to multiply their effective am-
biguity. Consider a question seeking to find ships with
a certain offensive capability: &amp;quot;What ships carry Har-
poon missiles?&amp;quot;. On a literal interpretation of the word
&amp;quot;carry&amp;quot; the predication of the sentence is satisfied
whether the ships &amp;quot;carry&amp;quot; the missiles as weaponry or
as incidental cargo, yet of these only the first alter-
native is the desired one. If the query were instead
&amp;quot;What ships carry oranges?&amp;quot; the second alternative is
the preferable one. The resultant &amp;quot;splitting&amp;quot; of lexical
senses can be regarded as a form of ambiguity
generated by the contact between logical domains.
Other kinds of mapping between notions of dif-
ferent domains are more complex, not taking place
along the lines of greater or lesser specificity, but in-
volving instead another kind of mapping that is really
tantamount to metaphor. A phrase like &amp;quot;in Marketing&amp;quot;,
for example, is not locative in the literal sense of loca-
tion in space but rather makes use of a metaphor
having to do with this notion. Here the initial domain
is that of space and spatial inclusion, while the final
one is that of, say, fields of employment or expertise.
The formal representation of metaphor used in
this work is that of Indurkhya [7]. Indurkhya identifies
a metaphor with the formal notion of a &amp;quot;T-MAP&amp;quot;: a pair
&lt;F,S&gt; where F is a function mapping descriptive con-
stants from one domain to another and S is a set of
sentences which are expected to carry over from the
first domain to the second. A metaphor is &amp;quot;coherent&amp;quot;
if the transferred sentences S are logically consistent
with the axioms of the target domain, &amp;quot;strongly
coherent&amp;quot; if they already lie in the deductive closure of
those axioms.
Depending on the formal language used to
represent the statements S. one may encounter com-
putational difficulties (i.e. decidability) with this
program. One way around this is not to use predicate
calculus (as Indurkhya does) but a language that is
more restrictive than predicate calculus. For the price
of surrending complete expressive power one gains
the advantage of deductive tractability.
One system which may be used for this purpose is
the NIKL (10] system, in which only a few types of
axioms can be encoded. A descriptive constant
subsumes another of the same complex type if its
extension is always a superset of the other. Two
constants are disjoint if their extensions are always
disjoint. (Note that respective subsumees of the two
constants &amp;quot;inherit&amp;quot; this disjointness.) Relations of
more than one argument have sortal (one-place
predicate) restrictions on their argument, thus stipulat-
ing that the extension of the relation will always be a
subset of the cartesian product of the extensions of
the sorts. Finally, a one-place predicate P restricts a
binary relation R to be 0 if the image under R of each
member of P&apos;s extension is a member of the exten-
sion of the second one-place predicate 0. In what
follows I will treat this operation as restricting the form
that the extension of the relation R may take on, so
that the placing of constraint P on the first argument
results in a propagation of the constraint Q on the
second argument.
</bodyText>
<sectionHeader confidence="0.999919" genericHeader="method">
3 THE LEXICAL CONSTRAINT MODULE
</sectionHeader>
<subsectionHeader confidence="0.990835">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.999919515151515">
In this section I present a solution to the multiple
problems of ambiguity posed by a natural utterance.
Added to the architecture of semantic interpreter, dis-
course model, lexicon and domain model is a new
component - the lexical constraint module. It accepts
from the semantic interpreter a logical form containing
free variables of higher-order and constructs from it a
constraint graph structure in which such variables are
connected in accordance with the syntactic structure
of the expression. This structure is then used in a
constraint-propagation process that attempts to as-
sign descriptive constant values to the expressions.
The lexicon in this scheme stores for each non-logical
word an extendable polysemic complex (or com-
plexes, in the case of homonymy) of logical associa-
tions. I shall describe assumptions about the seman-
tic rule set-up as I go along.
In making these assignments, the module applies
a &amp;quot;maxim of coherence&amp;quot;. That is, we assume that the
user will not deliberately speak nonsense to us, use
terms redundantly. or make use of elaborate means to
refer to the null set. A coherent outcome is one where
the descriptive constants being applied to the same
terms (bound variables and individual constants) are
not sortally disjoint. This may not always be achiev-
able with the core sense of words. When it is not, a
set of &amp;quot;polysemy operators&amp;quot; is invoked to re-interpret a
lexical assignment in such a way as to make sense of
the expression.
I will first consider an example where no such
re-interpretation is required. For the utterance &amp;quot;John
has a car&amp;quot;, the following logical form is given as input
to the constraint module:
</bodyText>
<equation confidence="0.419471">
(3 x (car x) &amp; (have John x) )
</equation>
<bodyText confidence="0.997932833333333">
The underlined symbols are the free variables. Sup-
pose the main verb &amp;quot;have&amp;quot; to be homonymous be-
tween the various predicates PART-OF, OWN,
AFFLICTED-WITH. The last of these is eliminable
because the argument sorts it requires and the the
sorts given to it do not agree: physical objects and
</bodyText>
<page confidence="0.993706">
181
</page>
<bodyText confidence="0.999896333333333">
diseases are disjoint sets. Such surface inspection of
argument sorts is not the only source of constraint,
however. For some relations a particular constraint
on the first argument causes a constraint on its
second argument. Thus, the alternative PART-OF is
eliminable because the parts of an organism must
themselves be organic material, something clearly
disjoint with artifacts like cars. The constraint graph is
now satisfied, and we are left with:
</bodyText>
<sectionHeader confidence="0.908082" genericHeader="method">
(3 z (CAR X) &amp; (OWNS JOHN z))
</sectionHeader>
<subsectionHeader confidence="0.99992">
3.2 The polysemy operators
</subsectionHeader>
<bodyText confidence="0.999989">
We now proceed to overconstrained cases in
which potential assignments are in conflict, and re-
interpretation by the polysemy operators is required.
For the first pair of such operators, generalization and
exclusion, we will make use of the Montague Gram-
mar notion of universal sublimation [2]. A universal
sublimation of a concept A is just the set of properties
which are true of all A&apos;s members, or:
</bodyText>
<equation confidence="0.567635">
(XP (V X A(X) -&gt; PVC)))
</equation>
<bodyText confidence="0.97282337037037">
Generalization and exclusion operate upon lexical
senses by modifying their universal sublimations and
looking for the alternative meaning (if any) of the word
that most closely corresponds to this new set.
As an example of generalization, consider the
phrase &amp;quot;plastic silverware&amp;quot;. While in literal terms this
is oxymoronic, one often sees it used to refer to plas-
tic eating utensils, and in situations where only these
items are available, the word &amp;quot;silverware&amp;quot; alone may
be used to denote them. Obviously for such speakers
the class EATING-UTENSIL is available as an ex-
tended and generalized sense of &amp;quot;silverware&amp;quot;. The
initial representation would be:
(XX (and (plastic z)
(silverware x)))
A portion of the sublimation of the concept SILVER-
WARE is the set (MADE-OF-SILVER, EATING-
UTENSIL). Of these, it is the first property that is
disjoint with PLASTIC and a new sublimation is con-
structed which excludes it. In the partial represen-
tation above, this new sublimation is just the class
EATING-UTENSIL itself.
Exclusion takes a lexical sense onto one from
which particular sub-senses have been explicitly ex-
cluded. Consider the sentence -The Thresher is not a
ship, it&apos;s a submarine&amp;quot;, or, to be free about its logical
form:
</bodyText>
<sectionHeader confidence="0.9582" genericHeader="method">
(CONTRAST (ship Thresher)
</sectionHeader>
<subsectionHeader confidence="0.86128">
(submarine Thresher))
</subsectionHeader>
<bodyText confidence="0.999953317073171">
If we assign the core meanings to these words this is
nonsensical, since SUBMARINEs are, by definition,
SHIPs as well. The expression coheres if whatever is
assigned to ship excludes SUBMARINE. We form a
partial sublimation (SHIP,-SUBMARINE), and find
corresponding to it the alternative sense of &amp;quot;ship&amp;quot;,
SURFACE-SHIP.
A surprising number of words have such alter-
native exclusionary senses, among them &amp;quot;axe&amp;quot;, where
HATCHET is excluded; &amp;quot;animal&amp;quot;, where HUMAN is
excluded; and &amp;quot;blue&amp;quot;, where TURQUOISE (and other
off-color shades) is excluded. The phenomenon
seems to be that a specialized term for some distin-
guished subset of a concept comes to be the
preferred term for members of that subset. The all-
embracing word can still be used, but it comes to
have a sense which is contrastive with these distin-
guished subsets. From the impression made by a
Venn diagram of the set and its excluded subsets we
might call this &amp;quot;cut-out&amp;quot; polysemy.
One wonders if certain phenomena which have
been described as ill-formedness might not in fact be
instances of this sort of polysemy. Goodman, for in-
stance, uses the actual word pair &amp;quot;blue&amp;quot; - &amp;quot;turquoise&amp;quot;
as an example of
&amp;quot;miscommunication&amp;quot;cite(Goodman85). What seems
more plausible however, is that the speaker describ-
ing a turquoise object as &amp;quot;blue&amp;quot; is not really misspeak-
ing, but is rather using the word &amp;quot;blue&amp;quot; in the more
inclusive sense which embraces all shades of the
color.
Metonymic extension re-interprets a predicate by
interposing an arbitrary, sortally compatible relation
between an argument place of the predicate and the
actual argument. An example can be seen in the
command &amp;quot;Highlight C3 tracks&amp;quot;, where &amp;quot;C3&amp;quot; is a
predication made of ships and &amp;quot;tracks&amp;quot; are trajectories
of ship positions, traced out on a screen. Obviously,
on literal interpretation, this utterance does not
cohere, since physical objects (ships) and graphical
objects (tracks) are disjoint. We have:
</bodyText>
<sectionHeader confidence="0.425318" genericHeader="method">
(HIGHLIGHT ^(XX (c3 X) &amp; (track X)))
</sectionHeader>
<bodyText confidence="0.999949857142857">
The categories SHIP and TRACK have too many
clashing properties for generalization or exclusion to
prevail. Instead, the two clashing elements are recon-
ciled by finding a function or relation reaching be-
tween SHIPs and TRACKs (or subsuming categories)
and metonymically extending one of the items with it.
The extended meaning of &amp;quot;C3&amp;quot; can be expressed by:
</bodyText>
<equation confidence="0.856061666666667">
(XX (3 Y (and (SHIP Y)
(SHIP-TRACR Y X)
(C3 Y)))
</equation>
<bodyText confidence="0.999982">
In any usage of the metonomy operation there is a
choice about which of two clashing elements to ex-
tend. In this case it would also have been possible to
have metonymically extended &amp;quot;track&amp;quot; instead of &amp;quot;C3&amp;quot;
in this example. The resultant expression would then
be a set of ships instead of tracks - clearly not what is
wanted here. It would moreover not be an im-
mediately coherent one itself. since &amp;quot;highlighting&amp;quot; can
only be done on graphical objects. More importantly,
it would seem to be that metonomies are less likely to
</bodyText>
<page confidence="0.995811">
182
</page>
<bodyText confidence="0.995878543478261">
shift the head noun meaning, since this changes the
sortal category of what is being referred to and
operated upon by the utterance. This seems to be
particularly strong when the head noun&apos;s meaning has
an underlying functional role, as does &amp;quot;track&amp;quot; in this
case.
Note that many words which at first appear to
have unitary senses are actually better described in
terms of metonymic complexes. Thus, &amp;quot;window&amp;quot; can
be used to refer to its constituent pane of glass, its
sash, or the opening around it. Similar examples can
be seen in light&amp;quot;, which can be used to refer to the
actual electromagnetic radiation or the device for
producing it, and &amp;quot;bank&amp;quot; (in the fiscal sense), which
can be used to refer to the building or the financial
institution itself.
Metaphorical extension operates not by shifting an
argument place of a predicate, but by shifting the
predicate itself. Capturing the generality in the mean-
ing of &amp;quot;mouth&amp;quot; in the example of section 1 involves
capturing a class of metaphors involving that concept.
Classes of metaphors are described by the notion of a
parameterized T-MAP, in which the mapping function
F and set of sentences S are not completely specified,
but may instead have missing elements which must
be solved for. Let &amp;quot;mouth of the cave&amp;quot; be given by:
(mouth (iota x (cave x) ) )
The functional constant MOUTH is restricted to
operate on individuals of the class ANIMAL, so the
above is incoherent on literal interpretation. A
metaphorical re-interpretation must select certain con-
stants for the mapping function F and certain facts S
which carry over to the new domain. Two such facts
are:
SUBSUMES(ENCLOSES-SPACE,ANIMAL)
SUBSUMES(OPENING,MOUTH)
In this use of the word &amp;quot;mouth&amp;quot; it is operating on in-
dividuals of the class CAVE instead of ANIMAL. One
element of the mapping function F is thus the pair
(ANIMAL,CAVE). In order to determine the relation-
ship that the word &amp;quot;mouth&amp;quot; really means in the ex-
ample we must solve for a function variable P which
MOUTH is mapped to. This function must be sortally
coherent with CAVE; it is the righthand member of the
second ordered pair of the mapping function F.
The sentences to be transferred are:
</bodyText>
<sectionHeader confidence="0.992771" genericHeader="method">
SUBSUMES (ENCLOSES-SPACE, CAVE)
SUBSUMES (OPENING-Os&apos;,?)
</sectionHeader>
<bodyText confidence="0.999468833333333">
Of these, the first is not only not inconsistent, but true.
One descriptive constant of the geological domain
which is obviously not incoherent with CAVE is the
function CAVE-ENTRANCE. If this function is used in
place of P the second sentence is satisfied as well.
An important metric of metaphorical plausibility is
how much structure in S is transferred from source to
target domain versus how many descriptive constants
are mapped via the function F. In the present example
the ratio is one. Clearly if this ratio is high the
metaphor is stronger and more plausible; if it is low
the metaphor is less so.
</bodyText>
<subsectionHeader confidence="0.997609">
3.3 Nominal Compounds
</subsectionHeader>
<bodyText confidence="0.999990055555556">
Nominal compounds are treated by assuming that
the semantic rules formulate their interpretation with a
free binary predicate variable standing in for the rela-
tion which must be determined to complete the inter-
pretation of the compound. Interpreting the nominal
compound thus becomes solving for this predicate
variable. This variable is initially unconstrained ex-
cept by the sorts of the noun meanings it connects.
A problem with some nominal compounds is that
they seem to violate the restrictions imposed by their
component parts. For example, a &amp;quot;staple gun&amp;quot; is not
a weapon at all, and would thus on some treatments
have to be treated either idiomatically or as a com-
pletely incoherent expression. With the approach
presented here, however, the polysemy operators can
be invoked to find a re-interpretation of the words for
which a solution does exist. The word &amp;quot;gun&amp;quot; can be
re-interpreted to discard the clashing property of
shooting bullets only, and to denote in this case the
wider class of devices that eject objects of whatever
type.
An important point about nominal compounds is
that they cannot be treated extensionally. A soup pot
is still such whether it currently contains something
different from soup, or indeed whether it contains any-
thing at all. Clearly, the relation to be solved for in a
nominal compound may in general be a non-
extensional one between kinds. Such a relation may
in turn have a meaning postulate which dictates which
actual entities (such as the actual soup) may be re-
lated at which indices of time. This phenomenon
would seem to pose a problem for Hobbs and Martin
[6], who view as a sub-problem resolving the refer-
ence of the lube oil&amp;quot; in the compound &amp;quot;tube oil alarm&amp;quot;.
One can imagine a lube oil alarm&amp;quot; which only sounds
when all the lube oil is gone.
</bodyText>
<subsectionHeader confidence="0.991686">
3.4 Effect on Anaphora Resolution
</subsectionHeader>
<bodyText confidence="0.9998384">
Even after syntactic and pragmatic considerations
have been taken into account, the decision on the
correct referents for anaphora cannot take place in-
dependently of considerations of word meaning
choice. Consider the following two sentences:
</bodyText>
<listItem confidence="0.836263">
(1) The table is in that building
(2) It is a bank.
</listItem>
<bodyText confidence="0.999576">
The proper referent of &amp;quot;it&amp;quot; in (2) is constrained by the
predication made by the ambiguous lexical item
&amp;quot;bank&amp;quot;, namely that it either be a RIVER-BANK or a
BANK-BUILDING. Neither is sortally coherent with
TABLE, the referent described by &amp;quot;the table&amp;quot; is elimin-
</bodyText>
<page confidence="0.997301">
183
</page>
<bodyText confidence="0.9999235">
able. The only thing left is the individual described by
&amp;quot;that building&amp;quot; and since BUILDING, being an AR-
TIFACT, is disjoint with RIVER-BANK, the proper
sense of &amp;quot;bank&amp;quot; is BANK-BUILDING and the referent
of &amp;quot;it&amp;quot; is &amp;quot;that building&amp;quot;.
exclusion operator) that an alternative sense of &amp;quot;lion&amp;quot;
means a male lion only. One should not presume,
however, that the discovery of new lexical senses will
occur on a constant basis. The last heuristic above is
therefore an important one.
</bodyText>
<subsectionHeader confidence="0.943472">
3.5 Algorithm and Heuristics
</subsectionHeader>
<bodyText confidence="0.999992652173913">
The algorithm used by the lexical constraint
module is a search loop consisting of just three parts -
tentative assignment, constraint propagation and
re-interpretation. On the first iteration tentative as-
signment constrains each word-variable with its core
logical sense, or the set of its core senses if it is
homonymous. These serve as entry points to the
polysemy complexes. Variables associated with
anaphors are initially constrained by whatever prag-
matic and syntactic (such as C-command) considera-
tions are seen to apply. The variables associated with
nominal compounds are initially left unconstrained.
Thereafter, constraint propagation may end up in
one of three states: satisfaction, in which case the
module returns a single logical expression;
underconstraint, in which case there is an ambiguity
with which the user must be presented; overconstraint
in which case re-interpretation is invoked to search for
an interpretation which coheres.
The most important issue in performing re-
interpretation is controlling the process that the sys-
tem does not &amp;quot;hallucinate&amp;quot; arbitrary meanings into an
expression. The control heuristics include:
</bodyText>
<listItem confidence="0.971580666666667">
1. consider overconstrained variables for
re-interpretation first
2. prefer generalizations and exclusions
which modify a small number of
properties
3. prefer metaphorical extensions with a
high ratio of plausibility (as in Sec 3.2)
and minimize the number of
&amp;quot;augmentations&amp;quot; and &amp;quot;positings&amp;quot; [7]
4. avoid multiple re-interpretations of the
same item
5. prefer re-interpretations to already es-
</listItem>
<bodyText confidence="0.991514692307692">
tablished polysemous senses instead of
creating new ones
In Hobbs&apos; work [61 control turns on a notion of a &amp;quot;cost-
function&amp;quot; associated with the lengths of proofs. The
notion of &amp;quot;minimality&amp;quot; in that work has some similarity
to the heuristics above, which seek to avoid arbitrary
re-interpretations of lexical meanings by prefering
conservative re-interpretations and discouraging mul-
tiple ones.
The creation by the polysemy operators of new
sense for a word can effectively be regarded as a kind
of &amp;quot;learning&amp;quot;. Thus, given the sentence &amp;quot;That&apos;s not a
lion, that&apos;s a lioness&amp;quot; the system could deduce (via the
</bodyText>
<sectionHeader confidence="0.999985" genericHeader="conclusions">
4 CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.99998252631579">
This component will be implemented in a future
version of BBN&apos;s JANUS natural language under-
standing system. Included in this system will be a
unification parser with a large grammar and a new
and improved semantic interpreter.
I have tried to show how a compositional seman-
tics need not be incompatible with a context-
dependent notion of word meaning by making a divi-
sion of labor between the rule-to-rule translation of
syntactic structure and the complex semantics of lex-
ical items. I shall even go so far as to say that such a
division of labor is neccesary for the compositional
program to succeed. A component which takes into
account the creativity of lexical meanings and which
utilizes knowledge representation and limited in-
ference not only gives word meaning its proper place
in a modular system but also has the potential of ex-
tending coverage and flexibility beyond what is cur-
rently available in natural language systems.
</bodyText>
<sectionHeader confidence="0.995881" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999276">
I would like to thank Remko Scha for his many
useful comments on this work. I would also like to
thank Erhard Hinrichs and Bob lngria for their com-
ments and encouragement, and Jessica Handler for
valuable linguistic data.
</bodyText>
<sectionHeader confidence="0.999228" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996938166666667">
[1] Bates, Madeleine and Bobrow, Robert J.
A Transportable Natural Language Interface
for Information Retrieval.
In Proceedings of the 6th Annual International
ACM SIGIR Conference. ACM Special In-
terest Group on Information Retrieval and
American Society for Information Science,
Washington, D.C., June, 1983.
(21 David R. Dowty, Robert E. Wall, and Stanley
Peters.
Introduction to Montague Grammar.
D. Reidel Publishing Company, 1981.
Barbara Grosz, Douglas E. Appelt, Paul Mar-
tin, and Fernando Pereira.
TEAM: An Experiment in the Design of Trans-
portable Natural-Language Interfaces.
Technical Report 356, SRI International,
Menlo Park, CA, August, 1985.
</reference>
<page confidence="0.987296">
184
</page>
<reference confidence="0.999702644444445">
[4] Hinrichs, Erhard W.
A Revised Syntax and Semantics of a Seman-
tic Interpretation Language.
1986.
[5] Hobbs, Jerry R.
Overview of the TACITUS Project.
In Proceedings of the DARPA 1986 Strategic
Computing Natural Language Workshop,
pages 19-25. The Defense Advanced .
Research Projects Agency, May, 1986.
[6] Jerry R. Hobbs and Paul Martin.
Local Pragmatics.
In Proceedings, IJCAI-87. International Joint
Conferences on Artificial Intelligence, Inc.,
August, 1987.
To appear.
[7] Indurkhya, Bipin.
Constrained Semantic Transference: A Formal
Theory of Metaphors.
Technical Report 85/008, Boston University,
1985.
[9] Landsbergen, S.P.J. and Scha, R.J.H.
Formal Languages for Semantic Represen-
tation.
In Allen and Petofi (editors), Aspects of
Automatized Text Processing: Papers in
Textlinguistics. Hamburg:Buske, 1979.
[9] Montague, R.
The Proper Treatment of Quantification in Or-
dinary English.
In J. Hintakka, J.Moravcsik and P.Suppes
(editors), Approaches to Natural Lan-
guage. Proceedings of the 1970 Stanford
Workship on Grammar and Semantics,
pages 221-242. Dordrecht: D.Reidel,
1973.
[10] Moser, Margaret.
An Overview of NIKL.
Technical Report Section of BBN Report No.
5421, Bolt Beranek and Newman Inc.,
1983.
[11] &amp;ha., Remko J.H.
Logical Foundations for Question-Answering.
Phillips Research Laboratories, Eindhoven,
The Netherlands, 1983.
</reference>
<page confidence="0.998848">
185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.833887">
<title confidence="0.99909">THE LOGICAL ANALYSIS OF LEXICAL AMBIGUITY</title>
<author confidence="0.999964">David Stallard</author>
<affiliation confidence="0.994956">Inc.</affiliation>
<address confidence="0.947511">10 Moulton St., Cambridge, Mass. 02238</address>
<abstract confidence="0.999663">Theories of semantic interpretation which wish to capture as many generalizations as possible must face up to the manifoldly ambiguous and contextually dependent nature of word meaning) In this paper I present a two-level scheme of semantic interpretation in which the first level deals with the semantic consequences of -syntactic structure and the second with the choice of word meaning. On the first level the meanings of ambiguous words, pronominal references, nominal compounds and metonomies are not treated as fixed, but are instead represented by free variables which range over predicates and functions. The context-dependence of lexical meaning is dealt with by the second level, a constraint propagation process which attempts to assign values to these variables on the basis of the logical coherence of the overall result. In so doing it makes use of a set of polysemy operators which map between lexical senses, thus making a potentially indefinite number of related senses available.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Madeleine Bates</author>
<author>Robert J Bobrow</author>
</authors>
<marker>Bates, Bobrow, </marker>
<rawString>[1] Bates, Madeleine and Bobrow, Robert J.</rawString>
</citation>
<citation valid="false">
<title>A Transportable Natural Language Interface for Information Retrieval.</title>
<marker></marker>
<rawString>A Transportable Natural Language Interface for Information Retrieval.</rawString>
</citation>
<citation valid="true">
<date>1983</date>
<booktitle>In Proceedings of the 6th Annual International ACM SIGIR Conference. ACM Special Interest Group on Information Retrieval and American Society for Information Science,</booktitle>
<location>Washington, D.C.,</location>
<marker>1983</marker>
<rawString>In Proceedings of the 6th Annual International ACM SIGIR Conference. ACM Special Interest Group on Information Retrieval and American Society for Information Science, Washington, D.C., June, 1983.</rawString>
</citation>
<citation valid="false">
<marker></marker>
<rawString>(21 David R. Dowty, Robert E. Wall, and Stanley Peters.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
</authors>
<date>1981</date>
<publisher>Reidel Publishing Company,</publisher>
<marker>D, 1981</marker>
<rawString>Introduction to Montague Grammar. D. Reidel Publishing Company, 1981.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Barbara Grosz</author>
<author>Douglas E Appelt</author>
<author>Paul Martin</author>
<author>Fernando Pereira</author>
</authors>
<marker>Grosz, Appelt, Martin, Pereira, </marker>
<rawString>Barbara Grosz, Douglas E. Appelt, Paul Martin, and Fernando Pereira.</rawString>
</citation>
<citation valid="false">
<title>TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces.</title>
<marker></marker>
<rawString>TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces.</rawString>
</citation>
<citation valid="false">
<tech>Technical Report 356,</tech>
<publisher>SRI International,</publisher>
<marker></marker>
<rawString>Technical Report 356, SRI International,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Menlo Park</author>
<author>August CA</author>
</authors>
<date>1985</date>
<note>[4] Hinrichs, Erhard W.</note>
<marker>Park, CA, 1985</marker>
<rawString>Menlo Park, CA, August, 1985. [4] Hinrichs, Erhard W.</rawString>
</citation>
<citation valid="true">
<title>A Revised Syntax and Semantics of a Semantic Interpretation Language.</title>
<date>1986</date>
<marker>1986</marker>
<rawString>A Revised Syntax and Semantics of a Semantic Interpretation Language. 1986.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<journal>Overview of the TACITUS Project.</journal>
<marker>Hobbs, </marker>
<rawString>[5] Hobbs, Jerry R. Overview of the TACITUS Project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Paul Martin</author>
</authors>
<title>Strategic Computing Natural Language Workshop,</title>
<date>1986</date>
<booktitle>In Proceedings of the DARPA</booktitle>
<pages>pages</pages>
<note>[6]</note>
<marker>Hobbs, Martin, 1986</marker>
<rawString>In Proceedings of the DARPA 1986 Strategic Computing Natural Language Workshop, pages 19-25. The Defense Advanced . Research Projects Agency, May, 1986. [6] Jerry R. Hobbs and Paul Martin. Local Pragmatics.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>In Proceedings, IJCAI-87. International Joint Conferences on Artificial Intelligence, Inc.,</booktitle>
<marker>1987</marker>
<rawString>In Proceedings, IJCAI-87. International Joint Conferences on Artificial Intelligence, Inc., August, 1987.</rawString>
</citation>
<citation valid="false">
<note>To appear. [7] Indurkhya, Bipin.</note>
<marker></marker>
<rawString>To appear. [7] Indurkhya, Bipin.</rawString>
</citation>
<citation valid="false">
<title>Constrained Semantic Transference: A Formal Theory of Metaphors.</title>
<marker></marker>
<rawString>Constrained Semantic Transference: A Formal Theory of Metaphors.</rawString>
</citation>
<citation valid="true">
<date>1985</date>
<booktitle>[9] Landsbergen, S.P.J. and Scha, R.J.H.</booktitle>
<tech>Technical Report 85/008,</tech>
<institution>Boston University,</institution>
<marker>1985</marker>
<rawString>Technical Report 85/008, Boston University, 1985. [9] Landsbergen, S.P.J. and Scha, R.J.H.</rawString>
</citation>
<citation valid="false">
<title>Formal Languages for Semantic Representation.</title>
<marker></marker>
<rawString>Formal Languages for Semantic Representation.</rawString>
</citation>
<citation valid="true">
<title>[9]</title>
<date>1979</date>
<booktitle>Aspects of Automatized Text Processing: Papers in Textlinguistics. Hamburg:Buske,</booktitle>
<editor>In Allen and Petofi (editors),</editor>
<location>Montague, R.</location>
<marker>1979</marker>
<rawString>In Allen and Petofi (editors), Aspects of Automatized Text Processing: Papers in Textlinguistics. Hamburg:Buske, 1979. [9] Montague, R.</rawString>
</citation>
<citation valid="false">
<title>The Proper Treatment of Quantification in Ordinary English.</title>
<marker></marker>
<rawString>The Proper Treatment of Quantification in Ordinary English.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In J Hintakka</author>
</authors>
<title>J.Moravcsik and P.Suppes (editors), Approaches to Natural Language.</title>
<date>1973</date>
<booktitle>Proceedings of the 1970 Stanford Workship on Grammar and Semantics,</booktitle>
<pages>221--242</pages>
<location>Dordrecht: D.Reidel,</location>
<marker>Hintakka, 1973</marker>
<rawString>In J. Hintakka, J.Moravcsik and P.Suppes (editors), Approaches to Natural Language. Proceedings of the 1970 Stanford Workship on Grammar and Semantics, pages 221-242. Dordrecht: D.Reidel, 1973.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Margaret Moser</author>
</authors>
<title>An Overview of NIKL.</title>
<marker>Moser, </marker>
<rawString>[10] Moser, Margaret. An Overview of NIKL.</rawString>
</citation>
<citation valid="false">
<date>1983</date>
<tech>Technical Report Section of BBN Report No. 5421,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<marker>1983</marker>
<rawString>Technical Report Section of BBN Report No. 5421, Bolt Beranek and Newman Inc., 1983.</rawString>
</citation>
<citation valid="false">
<authors>
<author>&amp;ha</author>
</authors>
<title>Remko J.H. Logical Foundations for Question-Answering.</title>
<marker>&amp;ha, </marker>
<rawString>[11] &amp;ha., Remko J.H. Logical Foundations for Question-Answering.</rawString>
</citation>
<citation valid="false">
<date>1983</date>
<institution>Phillips Research Laboratories,</institution>
<location>Eindhoven, The Netherlands,</location>
<marker>1983</marker>
<rawString>Phillips Research Laboratories, Eindhoven, The Netherlands, 1983.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>