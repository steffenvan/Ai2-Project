<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004679">
<title confidence="0.998879">
A Computational Approach to Automatic Prediction of Drunk-Texting
</title>
<author confidence="0.9119395">
Aditya Joshi1,2,3 Abhijit Mishra1 Balamurali AR4
Pushpak Bhattacharyya1 Mark James Carman2
</author>
<affiliation confidence="0.9717695">
1IIT Bombay, India, 2Monash University, Australia
3IITB-Monash Research Academy, India 4Aix-Marseille University, France
</affiliation>
<email confidence="0.966259">
{adityaj, abhijitmishra, pb}@cse.iitb.ac.in
balamurali.ar@lif.univ-mrs.fr,mark.carman@monash.edu
</email>
<sectionHeader confidence="0.993849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999852153846154">
Alcohol abuse may lead to unsociable
behavior such as crime, drunk driving,
or privacy leaks. We introduce auto-
matic drunk-texting prediction as the task
of identifying whether a text was writ-
ten when under the influence of alcohol.
We experiment with tweets labeled using
hashtags as distant supervision. Our clas-
sifiers use a set of N-gram and stylistic fea-
tures to detect drunk tweets. Our observa-
tions present the first quantitative evidence
that text contains signals that can be ex-
ploited to detect drunk-texting.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999424652173913">
The ubiquity of communication devices has made
social media highly accessible. The content on
these media reflects a user’s day-to-day activities.
This includes content created under the influence
of alcohol. In popular culture, this has been re-
ferred to as ‘drunk-texting’1. In this paper, we in-
troduce automatic ‘drunk-texting prediction’ as a
computational task. Given a tweet, the goal is to
automatically identify if it was written by a drunk
user. We refer to tweets written under the influ-
ence of alcohol as ‘drunk tweets’, and the opposite
as ‘sober tweets’.
A key challenge is to obtain an annotated
dataset. We use hashtag-based supervision so that
the authors of the tweets mention if they were
drunk at the time of posting a tweet. We create
three datasets by using different strategies that are
related to the use of hashtags. We then present
SVM-based classifiers that use N-gram and stylis-
tic features such as capitalisation, spelling errors,
etc. Through our experiments, we make subtle
points related to: (a) the performance of our fea-
tures, (b) how our approach compares against
</bodyText>
<footnote confidence="0.814535">
1Source: http://www.urbandictionary.com
</footnote>
<bodyText confidence="0.998748">
human ability to detect drunk-texting, (c) most
discriminative stylistic features, and (d) an error
analysis that points to future work. To the best of
our knowledge, this is a first study that shows the
feasibility of text-based analysis for drunk-texting
prediction.
</bodyText>
<sectionHeader confidence="0.99327" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.998919033333333">
Past studies show the relation between alcohol
abuse and unsociable behaviour such as aggres-
sion (Bushman and Cooper, 1990), crime (Carpen-
ter, 2007), suicide attempts (Merrill et al., 1992),
drunk driving (Loomis and West, 1958), and risky
sexual behaviour (Bryan et al., 2005). Merrill et
al. (1992) state that “those responsible for assess-
ing cases of attempted suicide should be adept at
detecting alcohol misuse”. Thus, a drunk-texting
prediction system can be used to identify individ-
uals susceptible to these behaviours, or for inves-
tigative purposes after an incident.
Drunk-texting may also cause regret. Mail
Goggles2 prompts a user to solve math questions
before sending an email on weekend evenings.
Some Android applications3 avoid drunk-texting
by blocking outgoing texts at the click of a button.
However, to the best of our knowledge, these tools
require a user command to begin blocking. An on-
going text-based analysis will be more helpful, es-
pecially since it offers a more natural setting by
monitoring stream of social media text and not ex-
plicitly seeking user input. Thus, automatic drunk-
texting prediction will improve systems aimed to
avoid regrettable drunk-texting. To the best of
our knowledge, ours is the first study that does a
quantitative analysis, in terms of prediction of the
drunk state by using textual clues.
Several studies have studied linguistic traits
associated with emotion expression and mental
</bodyText>
<footnote confidence="0.998223">
2http://gmailblog.blogspot.in/2008/10/new-in-labs-stop-
sending-mail-you-later.html
3https://play.google.com/store/apps/details?id=com.oopsapp
</footnote>
<page confidence="0.726807">
604
</page>
<bodyText confidence="0.788934125">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 604–608,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
health issues, suicidal nature, criminal status, etc.
(Pennebaker, 1993; Pennebaker, 1997). NLP tech-
niques have been used in the past to address so-
cial safety and mental health issues (Resnik et al.,
2013).
</bodyText>
<sectionHeader confidence="0.966172" genericHeader="method">
3 Definition and Challenges
</sectionHeader>
<bodyText confidence="0.997915833333333">
Drunk-texting prediction is the task of classifying
a text as drunk or sober. For example, a tweet
‘Feeling buzzed. Can’t remember how the evening
went’ must be predicted as ‘drunk’, whereas, ‘Re-
turned from work late today, the traffic was bad’
must be predicted as ‘sober’. The challenges are:
</bodyText>
<listItem confidence="0.998043523809524">
1. More than topic categorisation: Drunk-
texting prediction is similar to topic cate-
gorisation (that is, classification of docu-
ments into a set of categories such as ‘news’,
‘sports’, etc.). However, Borrill et al. (1987)
show that alcohol abusers have more pro-
nounced emotions, specifically, anger. In this
respect, drunk-texting prediction lies at the
confluence of topic categorisation and emo-
tion classification.
2. Identification of labeled examples: It is dif-
ficult to obtain a set of sober tweets. The
ideal label can be possibly given only by the
author. For example, whether a tweet such
as ‘I am feeling lonely tonight’ is a drunk
tweet is ambiguous. This is similar to sar-
casm expressed as an exaggeration (for ex-
ample, ‘This is the best film ever!), where the
context beyond the text needs to be consid-
ered.
3. Precision/Recall trade-off: The goal that a
</listItem>
<bodyText confidence="0.906266111111111">
drunk-texting prediction system must chase
depends on the application. An application
that identifies potential crimes must work
with high precision, since the target popula-
tion to be monitored will be large. On the
other hand, when being used to avoid regret-
table drunk-texting, a prediction system must
produce high recall in order to ensure that a
drunk message does not pass through.
</bodyText>
<sectionHeader confidence="0.99615" genericHeader="method">
4 Dataset Creation
</sectionHeader>
<bodyText confidence="0.999909538461538">
We use hashtag-based supervision to create our
datasets, similar to tasks like emotion classifica-
tion (Purver and Battersby, 2012). The tweets are
downloaded using Twitter API (https://dev.
twitter.com/). We remove non-Unicode
characters, and eliminate tweets that contain hy-
perlinks4 and also tweets that are shorter than 6
words in length. Finally, hashtags used to indi-
cate drunk or sober tweets are removed so that
they provide labels, but do not act as features. The
dataset is available on request. As a result, we cre-
ate three datasets, each using a different strategy
for sober tweets, as follows:
</bodyText>
<figureCaption confidence="0.981853">
Figure 1: Word cloud for drunk tweets
</figureCaption>
<listItem confidence="0.997523">
1. Dataset 1 (2435 drunk, 762 sober): We col-
lect tweets that are marked as drunk and
sober, using hashtags. Tweets containing
hashtags #drunk, #drank and #imdrunk are
considered to be drunk tweets, while those
with #notdrunk, #imnotdrunk and #sober are
considered to be sober tweets.
2. Dataset 2 (2435 drunk, 5644 sober): The
drunk tweets are downloaded using drunk
hashtags, as above. The list of users who cre-
ated these tweets is extracted. For the nega-
tive class, we download tweets by these users,
which do not contain the hashtags that corre-
spond to drunk tweets.
3. Dataset H (193 drunk, 317 sober): A sepa-
</listItem>
<bodyText confidence="0.9701882">
rate dataset is created where drunk tweets are
downloaded using drunk hashtags, as above.
The set of sober tweets is collected using both
the approaches above. The resultant is the
held-out test set Dataset-H that contains no
tweets in common with Datasets 1 and 2.
The drunk tweets for Datasets 1 and 2 are
the same. Figure 1 shows a word-cloud for
these drunk tweets (with stop words and forms
of the word ‘drunk’ removed), created using
</bodyText>
<footnote confidence="0.99891">
4This is a rigid criterion, but we observe that tweets with
hyperlinks are likely to be promotional in nature.
</footnote>
<page confidence="0.982766">
605
</page>
<table confidence="0.9997871875">
Feature Description
N-gram Features
Unigram &amp; Bigram (Presence) Boolean features indicating unigrams and bigrams
Unigram &amp; Bigram (Count) Real-valued features indicating unigrams and bigrams
Stylistic Features
LDA unigrams (Presence/Count) Boolean &amp; real-valued features indicating unigrams from LDA
POS Ratio Ratios of nouns, adjectives, adverbs in the tweet
#Named Entity Mentions Number of named entity mentions
#Discourse Connectors Number of discourse connectors
Spelling errors Boolean feature indicating presence of spelling mistakes
Repeated characters Boolean feature indicating whether a character is repeated three
Capitalisation times consecutively
Length Number of capital letters in the tweet
Emoticon (Presence/Count) Number of words
Sentiment Ratio Boolean &amp; real-valued features indicating unigrams
Positive and negative word ratios
</table>
<tableCaption confidence="0.999889">
Table 1: Our Feature Set for Drunk-texting Prediction
</tableCaption>
<bodyText confidence="0.9988415">
WordItOut5. The size of a word indicates its fre-
quency. In addition to topical words such as ‘bar’,
‘bottle’ and ‘wine’, the word-cloud shows senti-
ment words such as ‘love’ or ‘damn’, along with
profane words.
Heuristics other than these hashtags could have
been used for dataset creation. For example,
timestamps were a good option to account for time
at which a tweet was posted. However, this could
not be used because user’s local times was not
available, since very few users had geolocation en-
abled.
</bodyText>
<sectionHeader confidence="0.996202" genericHeader="method">
5 Feature Design
</sectionHeader>
<bodyText confidence="0.99993">
The complete set of features is shown in Table 1.
There are two sets of features: (a) N-gram fea-
tures, and (b) Stylistic features. We use unigrams
and bigrams as N-gram features- considering both
presence and count.
Table 1 shows the complete set of stylistic fea-
tures of our prediction system. POS ratios are a set
of features that record the proportion of each POS
tag in the dataset (for example, the proportion of
nouns/adjectives, etc.). The POS tags and named
entity mentions are obtained from NLTK (Bird,
2006). Discourse connectors are identified based
on a manually created list. Spelling errors are
identified using a spell checker by Aby (2014).
The repeated characters feature captures a situ-
ation in which a word contains a letter that is
repeated three or more times, as in the case of
</bodyText>
<footnote confidence="0.933533">
5www.worditout.com
</footnote>
<bodyText confidence="0.9999295">
happpy. Since drunk-texting is often associated
with emotional expression, we also incorporate a
set of sentiment-based features. These features in-
clude: count/presence of emoticons and sentiment
ratio. Sentiment ratio is the proportion of posi-
tive and negative words in the tweet. To deter-
mine positive and negative words, we use the sen-
timent lexicon in Wilson et al. (2005). To identify
a more refined set of words that correspond to the
two classes, we also estimated 20 topics for the
dataset by estimating an LDA model (Blei et al.,
2003). We then consider top 10 words per topic,
for both classes. This results in 400 LDA-specific
unigrams that are then used as features.
</bodyText>
<table confidence="0.9985239">
A NP PP NR PR
(%) (%) (%) (%) (%)
Dataset 1
N-gram 85.5 72.8 88.8 63.4 92.5
Stylistic 75.6 32.5 76.2 3.2 98.6
All 85.4 71.9 89.1 64.6 91.9
Dataset 2
N-gram 77.9 82.3 65.5 87.2 56.5
Stylistic 70.3 70.8 56.7 97.9 6.01
All 78.1 82.6 65.3 86.9 57.5
</table>
<tableCaption confidence="0.9310335">
Table 2: Performance of our features on Datasets
1 and 2
</tableCaption>
<page confidence="0.999073">
606
</page>
<sectionHeader confidence="0.998017" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9986671">
Using the two sets of features, we train SVM clas-
sifiers (Chang and Lin, 2011)6. We show the
five-fold cross-validation performance of our fea-
tures on Datasets 1 and 2, in Section 6.1, and on
Dataset H in Section 6.2. Section 6.3 presents an
error analysis. Accuracy, positive/negative preci-
sion and positive/negative recall are shown as A,
PP/NP and PR/NR respectively. ‘Drunk’ forms
the positive class, while ‘Sober’ forms the nega-
tive class.
</bodyText>
<table confidence="0.954229333333333">
Top features
# Dataset 1 Dataset 2
1 POS NOUN Spelling error
2 Capitalization LDA drinking
3 Spelling error POS NOUN
4 POS PREPOSITION Length
5 Length LDA tonight
6 LDA Llife Sentiment Ratio
7 POS VERB Char repeat
8 LDA today LDA today
9 POS ADV LDA drunken
10 Sentiment Ratio LDA lmao
</table>
<tableCaption confidence="0.991783">
Table 3: Top stylistic features for Datasets 1 and 2
obtained using Chi-squared test-based ranking
</tableCaption>
<subsectionHeader confidence="0.899734">
6.1 Performance for Datasets 1 and 2
</subsectionHeader>
<bodyText confidence="0.999934470588235">
Table 2 shows the performance for five-fold cross-
validation for Datasets 1 and 2. In case of Dataset
1, we observe that N-gram features achieve an ac-
curacy of 85.5%. We see that our stylistic features
alone exhibit degraded performance, with an ac-
curacy of 75.6%, in the case of Dataset 1. Ta-
ble 3 shows top stylistic features, when trained
on the two datasets. Spelling errors, POS ratios
for nouns (POS NOUN)7, length and sentiment
ratios appear in both lists, in addition to LDA-
based unigrams. However, negative recall reduces
to a mere 3.2%. This degradation implies that
our features capture a subset of drunk tweets and
that there are properties of drunk tweets that may
be more subtle. When both N-gram and stylis-
tic features are used, there is negligible improve-
ment. The accuracy for Dataset 2 increases from
</bodyText>
<footnote confidence="0.9912016">
6We also repeated all experiments for Naive Bayes. They
do not perform as well as SVM, and have poor recall.
7POS ratios for nouns, adjectives and adverbs were nearly
similar in drunk and sober tweets - with the maximum differ-
ence being 0.03%
</footnote>
<bodyText confidence="0.985717">
77.9% to 78.1%. Precision/Recall metrics do not
change significantly either. The best accuracy of
our classifier is 78.1% for all features, and 75.6%
for stylistic features. This shows that text-based
clues can indeed be used for drunk-texting predic-
tion.
</bodyText>
<table confidence="0.9989365">
A1 A2 A3
A1 - 0.42 0.36
A2 0.42 - 0.30
A3 0.36 0.30 -
</table>
<tableCaption confidence="0.941968">
Table 4: Cohen’s Kappa for three annotators (A1-
A3)
</tableCaption>
<table confidence="0.999651571428571">
A NP PP NR PR
(%) (%) (%) (%) (%)
Annotators 68.8 71.7 61.7 83.9 43.5
Training Our classifiers
Dataset
Dataset 1 47.3 70 40 26 81
Dataset 2 64 70 53 72 50
</table>
<tableCaption confidence="0.957104">
Table 5: Performance of human evaluators and our
classifiers (trained on all features), for Dataset-H
as the test set
</tableCaption>
<subsectionHeader confidence="0.990597">
6.2 Performance for Held-out Dataset H
</subsectionHeader>
<bodyText confidence="0.99679475">
Using held-out dataset H, we evaluate how our
system performs in comparison to humans. Three
annotators, A1-A3, mark each tweet in the Dataset
H as drunk or sober. Table 4 shows a moderate
agreement between our annotators (for example,
it is 0.42 for A1 and A2). Table 5 compares our
classifier with humans. Our human annotators per-
form the task with an average accuracy of 68.8%,
while our classifier (with all features) trained on
Dataset 2 reaches 64%. The classifier trained on
Dataset 2 is better than which is trained on Dataset
1.
</bodyText>
<subsectionHeader confidence="0.901998">
6.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.890089125">
Some categories of errors that occur are:
1. Incorrect hashtag supervision: The tweet
‘Can’t believe I lost my bag last night, lit-
erally had everything in! Thanks god the
bar man found it’ was marked with‘#Drunk’.
However, this tweet is not likely to be a drunk
tweet, but describes a drunk episode in retro-
spective. Our classifier predicts it as sober.
</bodyText>
<page confidence="0.994332">
607
</page>
<bodyText confidence="0.995005714285714">
2. Seemingly sober tweets: Human annotators
as well as our classifier could not identify
whether ‘Will you take her on a date? But
really she does like you’ was drunk, although
the author of the tweet had marked it so.
This example also highlights the difficulty of
drunk-texting prediction.
</bodyText>
<listItem confidence="0.5496755">
3. Pragmatic difficulty: The tweet ‘National
dress of Ireland is one’s one vomit.. my fam-
</listItem>
<bodyText confidence="0.978755">
ily is lovely’ was correctly identified by our
human annotators as a drunk tweet. This
tweet contains an element of humour and
topic change, but our classifier could not cap-
ture it.
</bodyText>
<sectionHeader confidence="0.996206" genericHeader="conclusions">
7 Conclusion &amp; Future Work
</sectionHeader>
<bodyText confidence="0.999966791666667">
In this paper, we introduce automatic drunk-
texting prediction as the task of predicting a tweet
as drunk or sober. First, we justify the need for
drunk-texting prediction as means of identifying
risky social behavior arising out of alcohol abuse,
and the need to build tools that avoid privacy leaks
due to drunk-texting. We then highlight the chal-
lenges of drunk-texting prediction: one of the
challenges is selection of negative examples (sober
tweets). Using hashtag-based supervision, we cre-
ate three datasets annotated with drunk or sober
labels. We then present SVM-based classifiers
which use two sets of features: N-gram and stylis-
tic features. Our drunk prediction system obtains
a best accuracy of 78.1%. We observe that our
stylistic features add negligible value to N-gram
features. We use our heldout dataset to compare
how our system performs against human annota-
tors. While human annotators achieve an accuracy
of 68.8%, our system reaches reasonably close and
performs with a best accuracy of 64%.
Our analysis of the task and experimental find-
ings make a case for drunk-texting prediction as a
useful and feasible NLP application.
</bodyText>
<sectionHeader confidence="0.998811" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999632766666667">
Aby. 2014. Aby word processing website, January.
Steven Bird. 2006. Nltk: the natural language toolkit.
In Proceedings of the COLING/ACL on Interactive
presentation sessions, pages 69–72. Association for
Computational Linguistics.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. the Journal of ma-
chine Learning research, 3:993–1022.
Josephine A Borrill, Bernard K Rosen, and Angela B
Summerfield. 1987. The influence of alcohol on
judgement of facial expressions of emotion. British
Journal of Medical Psychology.
Angela Bryan, Courtney A Rocheleau, Reuben N Rob-
bins, and Kent E Hutchinson. 2005. Condom use
among high-risk adolescents: testing the influence
of alcohol use on the relationship of cognitive corre-
lates of behavior. Health Psychology, 24(2):133.
Brad J Bushman and Harris M Cooper. 1990. Effects
of alcohol on human aggression: An intergrative re-
search review. Psychological bulletin, 107(3):341.
Christopher Carpenter. 2007. Heavy alcohol use and
crime: Evidence from underage drunk-driving laws.
Journal of Law and Economics, 50(3):539–557.
Chih-Chung Chang and Chih-Jen Lin. 2011. Lib-
svm: a library for support vector machines. ACM
Transactions on Intelligent Systems and Technology
(TIST), 2(3):27.
Ted A Loomis and TC West. 1958. The influence of al-
cohol on automobile driving ability: An experimen-
tal study for the evaluation of certain medicologi-
cal aspects. Quarterly journal of studies on alcohol,
19(1):30–46.
John Merrill, GABRIELLE MILKER, John Owens,
and Allister Vale. 1992. Alcohol and attempted sui-
cide. British journal of addiction, 87(1):83–89.
James W Pennebaker. 1993. Putting stress into words:
Health, linguistic, and therapeutic implications. Be-
haviour research and therapy, 31(6):539–548.
James W Pennebaker. 1997. Writing about emotional
experiences as a therapeutic process. Psychological
science, 8(3):162–166.
Matthew Purver and Stuart Battersby. 2012. Experi-
menting with distant supervision for emotion classi-
fication. In Proceedings of the 13th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 482–491. Association
for Computational Linguistics.
Philip Resnik, Anderson Garron, and Rebecca Resnik.
2013. Using topic modeling to improve prediction
of neuroticism and depression. In Proceedings of
the 2013 Conference on Empirical Methods in Nat-
ural, pages 1348–1353. Association for Computa-
tional Linguistics.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the con-
ference on human language technology and empiri-
cal methods in natural language processing, pages
347–354. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.997229">
608
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.340320">
<title confidence="0.8176295">Computational Approach to Automatic Prediction of Abhijit Balamurali</title>
<author confidence="0.999804">Mark James</author>
<affiliation confidence="0.9983525">Bombay, India, University, Research Academy, India University,</affiliation>
<email confidence="0.8153825">abhijitmishra,balamurali.ar@lif.univ-mrs.fr,mark.carman@monash.edu</email>
<abstract confidence="0.987512571428571">Alcohol abuse may lead to unsociable behavior such as crime, drunk driving, or privacy leaks. We introduce automatic drunk-texting prediction as the task of identifying whether a text was written when under the influence of alcohol. We experiment with tweets labeled using hashtags as distant supervision. Our classifiers use a set of N-gram and stylistic features to detect drunk tweets. Our observations present the first quantitative evidence that text contains signals that can be exploited to detect drunk-texting.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aby</author>
</authors>
<title>Aby word processing website,</title>
<date>2014</date>
<contexts>
<context position="9895" citStr="Aby (2014)" startWordPosition="1530" endWordPosition="1531">e 1. There are two sets of features: (a) N-gram features, and (b) Stylistic features. We use unigrams and bigrams as N-gram features- considering both presence and count. Table 1 shows the complete set of stylistic features of our prediction system. POS ratios are a set of features that record the proportion of each POS tag in the dataset (for example, the proportion of nouns/adjectives, etc.). The POS tags and named entity mentions are obtained from NLTK (Bird, 2006). Discourse connectors are identified based on a manually created list. Spelling errors are identified using a spell checker by Aby (2014). The repeated characters feature captures a situation in which a word contains a letter that is repeated three or more times, as in the case of 5www.worditout.com happpy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features include: count/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of positive and negative words in the tweet. To determine positive and negative words, we use the sentiment lexicon in Wilson et al. (2005). To identify a more refined set of words that correspond to</context>
</contexts>
<marker>Aby, 2014</marker>
<rawString>Aby. 2014. Aby word processing website, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
</authors>
<title>Nltk: the natural language toolkit.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions,</booktitle>
<pages>69--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9757" citStr="Bird, 2006" startWordPosition="1509" endWordPosition="1510">local times was not available, since very few users had geolocation enabled. 5 Feature Design The complete set of features is shown in Table 1. There are two sets of features: (a) N-gram features, and (b) Stylistic features. We use unigrams and bigrams as N-gram features- considering both presence and count. Table 1 shows the complete set of stylistic features of our prediction system. POS ratios are a set of features that record the proportion of each POS tag in the dataset (for example, the proportion of nouns/adjectives, etc.). The POS tags and named entity mentions are obtained from NLTK (Bird, 2006). Discourse connectors are identified based on a manually created list. Spelling errors are identified using a spell checker by Aby (2014). The repeated characters feature captures a situation in which a word contains a letter that is repeated three or more times, as in the case of 5www.worditout.com happpy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features include: count/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of positive and negative words in the tweet. To determine pos</context>
</contexts>
<marker>Bird, 2006</marker>
<rawString>Steven Bird. 2006. Nltk: the natural language toolkit. In Proceedings of the COLING/ACL on Interactive presentation sessions, pages 69–72. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="10603" citStr="Blei et al., 2003" startWordPosition="1646" endWordPosition="1649">hat is repeated three or more times, as in the case of 5www.worditout.com happpy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features include: count/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of positive and negative words in the tweet. To determine positive and negative words, we use the sentiment lexicon in Wilson et al. (2005). To identify a more refined set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003). We then consider top 10 words per topic, for both classes. This results in 400 LDA-specific unigrams that are then used as features. A NP PP NR PR (%) (%) (%) (%) (%) Dataset 1 N-gram 85.5 72.8 88.8 63.4 92.5 Stylistic 75.6 32.5 76.2 3.2 98.6 All 85.4 71.9 89.1 64.6 91.9 Dataset 2 N-gram 77.9 82.3 65.5 87.2 56.5 Stylistic 70.3 70.8 56.7 97.9 6.01 All 78.1 82.6 65.3 86.9 57.5 Table 2: Performance of our features on Datasets 1 and 2 606 6 Evaluation Using the two sets of features, we train SVM classifiers (Chang and Lin, 2011)6. We show the five-fold cross-validation performance of our feature</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josephine A Borrill</author>
<author>Bernard K Rosen</author>
<author>Angela B Summerfield</author>
</authors>
<title>The influence of alcohol on judgement of facial expressions of emotion.</title>
<date>1987</date>
<journal>British Journal of Medical Psychology.</journal>
<contexts>
<context position="4948" citStr="Borrill et al. (1987)" startWordPosition="730" endWordPosition="733">past to address social safety and mental health issues (Resnik et al., 2013). 3 Definition and Challenges Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet ‘Feeling buzzed. Can’t remember how the evening went’ must be predicted as ‘drunk’, whereas, ‘Returned from work late today, the traffic was bad’ must be predicted as ‘sober’. The challenges are: 1. More than topic categorisation: Drunktexting prediction is similar to topic categorisation (that is, classification of documents into a set of categories such as ‘news’, ‘sports’, etc.). However, Borrill et al. (1987) show that alcohol abusers have more pronounced emotions, specifically, anger. In this respect, drunk-texting prediction lies at the confluence of topic categorisation and emotion classification. 2. Identification of labeled examples: It is difficult to obtain a set of sober tweets. The ideal label can be possibly given only by the author. For example, whether a tweet such as ‘I am feeling lonely tonight’ is a drunk tweet is ambiguous. This is similar to sarcasm expressed as an exaggeration (for example, ‘This is the best film ever!), where the context beyond the text needs to be considered. 3</context>
</contexts>
<marker>Borrill, Rosen, Summerfield, 1987</marker>
<rawString>Josephine A Borrill, Bernard K Rosen, and Angela B Summerfield. 1987. The influence of alcohol on judgement of facial expressions of emotion. British Journal of Medical Psychology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Bryan</author>
<author>Courtney A Rocheleau</author>
<author>Reuben N Robbins</author>
<author>Kent E Hutchinson</author>
</authors>
<title>Condom use among high-risk adolescents: testing the influence of alcohol use on the relationship of cognitive correlates of behavior.</title>
<date>2005</date>
<journal>Health Psychology,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="2615" citStr="Bryan et al., 2005" startWordPosition="386" endWordPosition="389">ch compares against 1Source: http://www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that “those responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse”. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at the click of a button. However, to the best of our knowledge, these tools require a user </context>
</contexts>
<marker>Bryan, Rocheleau, Robbins, Hutchinson, 2005</marker>
<rawString>Angela Bryan, Courtney A Rocheleau, Reuben N Robbins, and Kent E Hutchinson. 2005. Condom use among high-risk adolescents: testing the influence of alcohol use on the relationship of cognitive correlates of behavior. Health Psychology, 24(2):133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brad J Bushman</author>
<author>Harris M Cooper</author>
</authors>
<title>Effects of alcohol on human aggression: An intergrative research review.</title>
<date>1990</date>
<journal>Psychological bulletin,</journal>
<volume>107</volume>
<issue>3</issue>
<contexts>
<context position="2461" citStr="Bushman and Cooper, 1990" startWordPosition="362" endWordPosition="365">such as capitalisation, spelling errors, etc. Through our experiments, we make subtle points related to: (a) the performance of our features, (b) how our approach compares against 1Source: http://www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that “those responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse”. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android</context>
</contexts>
<marker>Bushman, Cooper, 1990</marker>
<rawString>Brad J Bushman and Harris M Cooper. 1990. Effects of alcohol on human aggression: An intergrative research review. Psychological bulletin, 107(3):341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Carpenter</author>
</authors>
<title>Heavy alcohol use and crime: Evidence from underage drunk-driving laws.</title>
<date>2007</date>
<journal>Journal of Law and Economics,</journal>
<volume>50</volume>
<issue>3</issue>
<contexts>
<context position="2486" citStr="Carpenter, 2007" startWordPosition="367" endWordPosition="369">rrors, etc. Through our experiments, we make subtle points related to: (a) the performance of our features, (b) how our approach compares against 1Source: http://www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that “those responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse”. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drun</context>
</contexts>
<marker>Carpenter, 2007</marker>
<rawString>Christopher Carpenter. 2007. Heavy alcohol use and crime: Evidence from underage drunk-driving laws. Journal of Law and Economics, 50(3):539–557.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Libsvm: a library for support vector machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<contexts>
<context position="11135" citStr="Chang and Lin, 2011" startWordPosition="1748" endWordPosition="1751"> also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003). We then consider top 10 words per topic, for both classes. This results in 400 LDA-specific unigrams that are then used as features. A NP PP NR PR (%) (%) (%) (%) (%) Dataset 1 N-gram 85.5 72.8 88.8 63.4 92.5 Stylistic 75.6 32.5 76.2 3.2 98.6 All 85.4 71.9 89.1 64.6 91.9 Dataset 2 N-gram 77.9 82.3 65.5 87.2 56.5 Stylistic 70.3 70.8 56.7 97.9 6.01 All 78.1 82.6 65.3 86.9 57.5 Table 2: Performance of our features on Datasets 1 and 2 606 6 Evaluation Using the two sets of features, we train SVM classifiers (Chang and Lin, 2011)6. We show the five-fold cross-validation performance of our features on Datasets 1 and 2, in Section 6.1, and on Dataset H in Section 6.2. Section 6.3 presents an error analysis. Accuracy, positive/negative precision and positive/negative recall are shown as A, PP/NP and PR/NR respectively. ‘Drunk’ forms the positive class, while ‘Sober’ forms the negative class. Top features # Dataset 1 Dataset 2 1 POS NOUN Spelling error 2 Capitalization LDA drinking 3 Spelling error POS NOUN 4 POS PREPOSITION Length 5 Length LDA tonight 6 LDA Llife Sentiment Ratio 7 POS VERB Char repeat 8 LDA today LDA tod</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted A Loomis</author>
<author>TC West</author>
</authors>
<title>The influence of alcohol on automobile driving ability: An experimental study for the evaluation of certain medicological aspects. Quarterly journal of studies on alcohol,</title>
<date>1958</date>
<contexts>
<context position="2566" citStr="Loomis and West, 1958" startWordPosition="378" endWordPosition="381"> the performance of our features, (b) how our approach compares against 1Source: http://www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that “those responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse”. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at the click of a button. However, to the b</context>
</contexts>
<marker>Loomis, West, 1958</marker>
<rawString>Ted A Loomis and TC West. 1958. The influence of alcohol on automobile driving ability: An experimental study for the evaluation of certain medicological aspects. Quarterly journal of studies on alcohol, 19(1):30–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Merrill</author>
<author>GABRIELLE MILKER</author>
<author>John Owens</author>
<author>Allister Vale</author>
</authors>
<title>Alcohol and attempted suicide. British journal of addiction,</title>
<date>1992</date>
<pages>87--1</pages>
<contexts>
<context position="2527" citStr="Merrill et al., 1992" startWordPosition="372" endWordPosition="375"> we make subtle points related to: (a) the performance of our features, (b) how our approach compares against 1Source: http://www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that “those responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse”. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at t</context>
</contexts>
<marker>Merrill, MILKER, Owens, Vale, 1992</marker>
<rawString>John Merrill, GABRIELLE MILKER, John Owens, and Allister Vale. 1992. Alcohol and attempted suicide. British journal of addiction, 87(1):83–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
</authors>
<title>Putting stress into words: Health, linguistic, and therapeutic implications. Behaviour research and therapy,</title>
<date>1993</date>
<pages>31--6</pages>
<contexts>
<context position="4269" citStr="Pennebaker, 1993" startWordPosition="620" endWordPosition="621"> state by using textual clues. Several studies have studied linguistic traits associated with emotion expression and mental 2http://gmailblog.blogspot.in/2008/10/new-in-labs-stopsending-mail-you-later.html 3https://play.google.com/store/apps/details?id=com.oopsapp 604 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 604–608, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics health issues, suicidal nature, criminal status, etc. (Pennebaker, 1993; Pennebaker, 1997). NLP techniques have been used in the past to address social safety and mental health issues (Resnik et al., 2013). 3 Definition and Challenges Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet ‘Feeling buzzed. Can’t remember how the evening went’ must be predicted as ‘drunk’, whereas, ‘Returned from work late today, the traffic was bad’ must be predicted as ‘sober’. The challenges are: 1. More than topic categorisation: Drunktexting prediction is similar to topic categorisation (that is, classification of documents into a se</context>
</contexts>
<marker>Pennebaker, 1993</marker>
<rawString>James W Pennebaker. 1993. Putting stress into words: Health, linguistic, and therapeutic implications. Behaviour research and therapy, 31(6):539–548.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
</authors>
<title>Writing about emotional experiences as a therapeutic process.</title>
<date>1997</date>
<journal>Psychological science,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="4288" citStr="Pennebaker, 1997" startWordPosition="622" endWordPosition="623">xtual clues. Several studies have studied linguistic traits associated with emotion expression and mental 2http://gmailblog.blogspot.in/2008/10/new-in-labs-stopsending-mail-you-later.html 3https://play.google.com/store/apps/details?id=com.oopsapp 604 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 604–608, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics health issues, suicidal nature, criminal status, etc. (Pennebaker, 1993; Pennebaker, 1997). NLP techniques have been used in the past to address social safety and mental health issues (Resnik et al., 2013). 3 Definition and Challenges Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet ‘Feeling buzzed. Can’t remember how the evening went’ must be predicted as ‘drunk’, whereas, ‘Returned from work late today, the traffic was bad’ must be predicted as ‘sober’. The challenges are: 1. More than topic categorisation: Drunktexting prediction is similar to topic categorisation (that is, classification of documents into a set of categories suc</context>
</contexts>
<marker>Pennebaker, 1997</marker>
<rawString>James W Pennebaker. 1997. Writing about emotional experiences as a therapeutic process. Psychological science, 8(3):162–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>Stuart Battersby</author>
</authors>
<title>Experimenting with distant supervision for emotion classification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>482--491</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6131" citStr="Purver and Battersby, 2012" startWordPosition="923" endWordPosition="926">xt beyond the text needs to be considered. 3. Precision/Recall trade-off: The goal that a drunk-texting prediction system must chase depends on the application. An application that identifies potential crimes must work with high precision, since the target population to be monitored will be large. On the other hand, when being used to avoid regrettable drunk-texting, a prediction system must produce high recall in order to ensure that a drunk message does not pass through. 4 Dataset Creation We use hashtag-based supervision to create our datasets, similar to tasks like emotion classification (Purver and Battersby, 2012). The tweets are downloaded using Twitter API (https://dev. twitter.com/). We remove non-Unicode characters, and eliminate tweets that contain hyperlinks4 and also tweets that are shorter than 6 words in length. Finally, hashtags used to indicate drunk or sober tweets are removed so that they provide labels, but do not act as features. The dataset is available on request. As a result, we create three datasets, each using a different strategy for sober tweets, as follows: Figure 1: Word cloud for drunk tweets 1. Dataset 1 (2435 drunk, 762 sober): We collect tweets that are marked as drunk and s</context>
</contexts>
<marker>Purver, Battersby, 2012</marker>
<rawString>Matthew Purver and Stuart Battersby. 2012. Experimenting with distant supervision for emotion classification. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 482–491. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Anderson Garron</author>
<author>Rebecca Resnik</author>
</authors>
<title>Using topic modeling to improve prediction of neuroticism and depression.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural,</booktitle>
<pages>1348--1353</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4403" citStr="Resnik et al., 2013" startWordPosition="642" endWordPosition="645">//gmailblog.blogspot.in/2008/10/new-in-labs-stopsending-mail-you-later.html 3https://play.google.com/store/apps/details?id=com.oopsapp 604 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 604–608, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics health issues, suicidal nature, criminal status, etc. (Pennebaker, 1993; Pennebaker, 1997). NLP techniques have been used in the past to address social safety and mental health issues (Resnik et al., 2013). 3 Definition and Challenges Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet ‘Feeling buzzed. Can’t remember how the evening went’ must be predicted as ‘drunk’, whereas, ‘Returned from work late today, the traffic was bad’ must be predicted as ‘sober’. The challenges are: 1. More than topic categorisation: Drunktexting prediction is similar to topic categorisation (that is, classification of documents into a set of categories such as ‘news’, ‘sports’, etc.). However, Borrill et al. (1987) show that alcohol abusers have more pronounced emotion</context>
</contexts>
<marker>Resnik, Garron, Resnik, 2013</marker>
<rawString>Philip Resnik, Anderson Garron, and Rebecca Resnik. 2013. Using topic modeling to improve prediction of neuroticism and depression. In Proceedings of the 2013 Conference on Empirical Methods in Natural, pages 1348–1353. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on human language technology and empirical methods in natural language processing,</booktitle>
<pages>347--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10435" citStr="Wilson et al. (2005)" startWordPosition="1615" endWordPosition="1618">created list. Spelling errors are identified using a spell checker by Aby (2014). The repeated characters feature captures a situation in which a word contains a letter that is repeated three or more times, as in the case of 5www.worditout.com happpy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features include: count/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of positive and negative words in the tweet. To determine positive and negative words, we use the sentiment lexicon in Wilson et al. (2005). To identify a more refined set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003). We then consider top 10 words per topic, for both classes. This results in 400 LDA-specific unigrams that are then used as features. A NP PP NR PR (%) (%) (%) (%) (%) Dataset 1 N-gram 85.5 72.8 88.8 63.4 92.5 Stylistic 75.6 32.5 76.2 3.2 98.6 All 85.4 71.9 89.1 64.6 91.9 Dataset 2 N-gram 77.9 82.3 65.5 87.2 56.5 Stylistic 70.3 70.8 56.7 97.9 6.01 All 78.1 82.6 65.3 86.9 57.5 Table 2: Performance of our features on Datasets 1 a</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the conference on human language technology and empirical methods in natural language processing, pages 347–354. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>