<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000178">
<title confidence="0.998344">
Syntactic Patterns versus Word Alignment: Extracting Opinion Targets
from Online Reviews
</title>
<author confidence="0.999534">
Kang Liu, Liheng Xu and Jun Zhao
</author>
<affiliation confidence="0.9940665">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
</affiliation>
<email confidence="0.997266">
{kliu, lhxu, jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.993897" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972407407407">
Mining opinion targets is a fundamen-
tal and important task for opinion min-
ing from online reviews. To this end,
there are usually two kinds of methods:
syntax based and alignment based meth-
ods. Syntax based methods usually ex-
ploited syntactic patterns to extract opin-
ion targets, which were however prone to
suffer from parsing errors when dealing
with online informal texts. In contrast,
alignment based methods used word align-
ment model to fulfill this task, which could
avoid parsing errors without using pars-
ing. However, there is no research fo-
cusing on which kind of method is more
better when given a certain amount of re-
views. To fill this gap, this paper empiri-
cally studies how the performance of these
two kinds of methods vary when chang-
ing the size, domain and language of the
corpus. We further combine syntactic pat-
terns with alignment model by using a par-
tially supervised framework and investi-
gate whether this combination is useful or
not. In our experiments, we verify that
our combination is effective on the corpus
with small and medium size.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988480769231">
With the rapid development of Web 2.0, huge
amount of user reviews are springing up on the
Web. Mining opinions from these reviews be-
come more and more urgent since that customers
expect to obtain fine-grained information of prod-
ucts and manufacturers need to obtain immediate
feedbacks from customers. In opinion mining, ex-
tracting opinion targets is a basic subtask. It is
to extract a list of the objects which users express
their opinions on and can provide the prior infor-
mation of targets for opinion mining. So this task
has attracted many attentions. To extract opin-
ion targets, pervious approaches usually relied on
opinion words which are the words used to ex-
press the opinions (Hu and Liu, 2004a; Popescu
and Etzioni, 2005; Liu et al., 2005; Wang and
Wang, 2008; Qiu et al., 2011; Liu et al., 2012). In-
tuitively, opinion words often appear around and
modify opinion targets, and there are opinion re-
lations and associations between them. If we have
known some words to be opinion words, the words
which those opinion words modify will have high
probability to be opinion targets.
Therefore, identifying the aforementioned opin-
ion relations between words is important for ex-
tracting opinion targets from reviews. To fulfill
this aim, previous methods exploited the words
co-occurrence information to indicate them (Hu
and Liu, 2004a; Hu and Liu, 2004b). Obviously,
these methods cannot obtain precise extraction be-
cause of the diverse expressions by reviewers, like
long-span modified relations between words, etc.
To handle this problem, several methods exploited
syntactic information, where several heuristic pat-
terns based on syntactic parsing were designed
(Popescu and Etzioni, 2005; Qiu et al., 2009; Qiu
et al., 2011). However, the sentences in online
reviews usually have informal writing styles in-
cluding grammar mistakes, typos, improper punc-
tuation etc., which make parsing prone to gener-
ate mistakes. As a result, the syntax-based meth-
ods which heavily depended on the parsing per-
formance would suffer from parsing errors (Zhang
et al., 2010). To improve the extraction perfor-
mance, we can only employ some exquisite high-
precision patterns. But this strategy is likely to
miss many opinion targets and has lower recall
with the increase of corpus size. To resolve these
problems, Liu et al. (2012) formulated identifying
opinion relations between words as an monolin-
gual alignment process. A word can find its cor-
responding modifiers by using a word alignment
</bodyText>
<page confidence="0.949441">
1754
</page>
<note confidence="0.959385">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1754–1763,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999624">
Figure 1: Mining Opinion Relations between Words using Partially Supervised Alignment Model
</figureCaption>
<bodyText confidence="0.999956688311689">
model (WAM). Without using syntactic parsing,
the noises from parsing errors can be effectively
avoided. Nevertheless, we notice that the align-
ment model is a statistical model which needs suf-
ficient data to estimate parameters. When the data
is insufficient, it would suffer from data sparseness
and may make the performance decline.
Thus, from the above analysis, we can observe
that the size of the corpus has impacts on these
two kinds of methods, which arises some impor-
tant questions: how can we make selection be-
tween syntax based methods and alignment based
method for opinion target extraction when given
a certain amount of reviews? And which kind of
methods can obtain better extraction performance
with the variation of the size of the dataset? Al-
though (Liu et al., 2012) had proved the effective-
ness of WAM, they mainly performed experiments
on the dataset with medium size. We are still curi-
ous about that when the size of dataset is larger
or smaller, can we obtain the same conclusion?
To our best knowledge, these problems have not
been studied before. Moreover, opinions may be
expressed in different ways with the variation of
the domain and language of the corpus. When the
domain or language of the corpus is changed, what
conclusions can we obtain? To answer these ques-
tions, in this paper, we adopt a unified framework
to extract opinion targets from reviews, in the key
component of which we vary the methods between
syntactic patterns and alignment model. Then we
run the whole framework on the corpus with dif-
ferent size (from #500 to #1, 000, 000), domain
(three domains) and language (Chinese and En-
glish) to empirically assess the performance varia-
tions and discuss which method is more effective.
Furthermore, this paper naturally addresses an-
other question: is it useful for opinion targets ex-
traction when we combine syntactic patterns and
word alignment model into a unified model? To
this end, we employ a partially supervised align-
ment model (PSWAM) like (Gao et al., 2010; Liu
et al., 2013). Based on the exquisitely designed
high-precision syntactic patterns, we can obtain
some precisely modified relations between words
in sentences, which provide a portion of links of
the full alignments. Then, these partial alignment
links can be regarded as the constrains for a stan-
dard unsupervised word alignment model. And
each target candidate would find its modifier un-
der the partial supervision. In this way, the er-
rors generated in standard unsupervised WAM can
be corrected. For example in Figure 1, “kindly”
and “courteous” are incorrectly regarded as the
modifiers for “foods” if the WAM is performed
in an whole unsupervised framework. However,
by using some high-precision syntactic patterns,
we can assert “courteous” should be aligned to
“services”, and “delicious” should be aligned to
“foods”. Through combination under partial su-
pervision, we can see “kindly” and “courteous”
are correctly linked to “services”. Thus, it’s rea-
sonable to expect to yield better performance than
traditional methods. As mentioned in (Liu et al.,
2013), using PSWAM can not only inherit the
advantages of WAM: effectively avoiding noises
from syntactic parsing errors when dealing with
informal texts, but also can improve the mining
performance by using partial supervision. How-
ever, is this kind of combination always useful for
opinion target extraction? To access this problem,
we also make comparison between PSWAM based
method and the aforementioned methods in the
same corpora with different size, language and do-
main. The experimental results show the combina-
tion by using PSWAM can be effective on dataset
with small and medium size.
</bodyText>
<page confidence="0.993025">
1755
</page>
<sectionHeader confidence="0.999658" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999988273684211">
Opinion target extraction isn’t a new task for opin-
ion mining. There are much work focusing on
this task, such as (Hu and Liu, 2004b; Ding et al.,
2008; Li et al., 2010; Popescu and Etzioni, 2005;
Wu et al., 2009). Totally, previous studies can be
divided into two main categories: supervised and
unsupervised methods.
In supervised approaches, the opinion target ex-
traction task was usually regarded as a sequence
labeling problem (Jin and Huang, 2009; Li et al.,
2010; Ma and Wan, 2010; Wu et al., 2009; Zhang
et al., 2009). It’s not only to extract a lexicon or list
of opinion targets, but also to find out each opin-
ion target mentions in reviews. Thus, the contex-
tual words are usually selected as the features to
indicate opinion targets in sentences. And classi-
cal sequence labeling models are used to train the
extractor, such as CRFs (Li et al., 2010), HMM
(Jin and Huang, 2009) etc.. Jin et al. (2009) pro-
posed a lexicalized HMM model to perform opin-
ion mining. Both Li et al. (2010) and Ma et al.
(2010) used CRFs model to extract opinion tar-
gets in reviews. Specially, Li et al. proposed a
Skip-Tree CRF model for opinion target extrac-
tion, which exploited three structures including
linear-chain structure, syntactic structure, and con-
junction structure. However, the main limitation
of these supervised methods is the need of labeled
training data. If the labeled training data is insuf-
ficient, the trained model would have unsatisfied
extraction performance. Labeling sufficient train-
ing data is time and labor consuming. And for dif-
ferent domains, we need label data independently,
which is obviously impracticable.
Thus, many researches focused on unsupervised
methods, which are mainly to extract a list of opin-
ion targets from reviews. Similar to ours, most ap-
proaches regarded opinion words as the indicator
for opinion targets. (Hu and Liu, 2004a) regarded
the nearest adjective to an noun/noun phrase as
its modifier. Then it exploited an association
rule mining algorithm to mine the associations be-
tween them. Finally, the frequent explicit prod-
uct features can be extracted in a bootstrapping
process by further combining item’s frequency in
dataset. Only using nearest neighbor rule to mine
the modifier for each candidate cannot obtain pre-
cise results. Thus, (Popescu and Etzioni, 2005)
used syntax information to extract opinion targets,
which designed some syntactic patterns to capture
the modified relations between words. The experi-
mental results showed that their method had better
performance than (Hu and Liu, 2004a). Moreover,
(Qiu et al., 2011) proposed a Double Propagation
method to expand sentiment words and opinion
targets iteratively, where they also exploited syn-
tactic relations between words. Specially, (Qiu
et al., 2011) didn’t only design syntactic patterns
for capturing modified relations, but also designed
patterns for capturing relations among opinion tar-
gets and relations among opinion words. How-
ever, the main limitation of Qiu’s method is that
the patterns based on dependency parsing tree may
miss many targets for the large corpora. There-
fore, Zhang et al. (2010) extended Qiu’s method.
Besides the patterns used in Qiu’s method, they
adopted some other special designed patterns to
increase recall. In addition they used the HITS
(Kleinberg, 1999) algorithm to compute opinion
target confidences to improve the precision. (Liu
et al., 2012) formulated identifying opinion re-
lations between words as an alignment process.
They used a completely unsupervised WAM to
capture opinion relations in sentences. Then the
opinion targets were extracted in a standard ran-
dom walk framework where two factors were con-
sidered: opinion relevance and target importance.
Their experimental results have shown that WAM
was more effective than traditional syntax-based
methods for this task. (Liu et al., 2013) extend
Liu’s method, which is similar to our method and
also used a partially supervised alignment model
to extract opinion targets from reviews. We notice
these two methods ((Liu et al., 2012) and (Liu et
al., 2013)) only performed experiments on the cor-
pora with a medium size. Although both of them
proved that WAM model is better than the meth-
ods based on syntactic patterns, they didn’t dis-
cuss the performance variation when dealing with
the corpora with different sizes, especially when
the size of the corpus is less than 1,000 and more
than 10,000. Based on their conclusions, we still
don’t know which kind of methods should be se-
lected for opinion target extraction when given a
certain amount of reviews.
</bodyText>
<sectionHeader confidence="0.990596" genericHeader="method">
3 Opinion Target Extraction
Methodology
</sectionHeader>
<bodyText confidence="0.998403333333333">
To extract opinion targets from reviews, we adopt
the framework proposed by (Liu et al., 2012),
which is a graph-based extraction framework and
</bodyText>
<page confidence="0.951346">
1756
</page>
<bodyText confidence="0.986528">
has two main components as follows.
</bodyText>
<listItem confidence="0.73788545">
1) The first component is to capture opinion
relations in sentences and estimate associations
between opinion target candidates and potential
opinion words. In this paper, we assume opinion
targets to be nouns or noun phrases, and opinion
words may be adjectives or verbs, which are usu-
ally adopted by (Hu and Liu, 2004a; Qiu et al.,
2011; Wang and Wang, 2008; Liu et al., 2012).
And a potential opinion relation is comprised of
an opinion target candidate and its corresponding
modified word.
2) The second component is to estimate the
confidence of each candidate. The candidates with
higher confidence scores than a threshold will be
extracted as opinion targets. In this procedure, we
formulate the associations between opinion target
candidates and potential opinion words in a bipar-
tite graph. A random walk based algorithm is em-
ployed on this graph to estimate the confidence of
each target candidate.
</listItem>
<bodyText confidence="0.999806833333333">
In this paper, we fix the method in the sec-
ond component and vary the algorithms in the
first component. In the first component, we re-
spectively use syntactic patterns and unsupervised
word alignment model (WAM) to capture opinion
relations. In addition, we employ a partially super-
vised word alignment model (PSWAM) to incor-
porate syntactic information into WAM. In exper-
iments, we run the whole framework on the differ-
ent corpora to discuss which method is more effec-
tive. In the following subsections, we will present
them in detail.
</bodyText>
<sectionHeader confidence="0.579624666666667" genericHeader="method">
3.1 The First Component: Capturing
Opinion Relations and Estimating
Associations between Words
</sectionHeader>
<subsectionHeader confidence="0.916485">
3.1.1 Syntactic Patterns
</subsectionHeader>
<bodyText confidence="0.998153916666667">
To capture opinion relations in sentences by using
syntactic patterns, we employ the manual designed
syntactic patterns proposed by (Qiu et al., 2011).
Similar to Qiu, only the syntactic patterns based
on the direct dependency are employed to guar-
antee the extraction qualities. The direct depen-
dency has two types. The first type indicates that
one word depends on the other word without any
additional words in their dependency path. The
second type denotes that two words both depend
on a third word directly. Specifically, we employ
Minipar1 to parse sentences. To further make syn-
</bodyText>
<footnote confidence="0.878134">
1http://webdocs.cs.ualberta.ca/lindek/minipar.htm
</footnote>
<bodyText confidence="0.999740642857143">
tactic patterns precisely, we only use a few depen-
dency relation labels outputted by Minipar, such
as mod, pnmod, subj, desc etc. To make a clear
explanation, we give out some syntactic pattern
examples in Table 1. In these patterns, OC is a
potential opinion word which is an adjective or a
verb. TC is an opinion target candidate which is
a noun or noun phrase. The item on the arrows
means the dependency relation type. The item in
parenthesis denotes the part-of-speech of the other
word. In these examples, the first three patterns
are based on the first direct dependency type and
the last two patterns are based on the second direct
dependency type.
</bodyText>
<table confidence="0.9991442">
Pattern#1: &lt;OC&gt; mod
−−−→&lt;TC&gt;
Example: This phone has an amazing design
Pattern#2: &lt;TC&gt; obj
−−→&lt;OC&gt;
Example: I like this phone very much
Pattern#3: &lt;OC&gt;pnmod
−−−−→&lt;TC&gt;
Example: the buttons easier to use
−−−→(NN) subj
Pattern#4: &lt;OC&gt; mod ←−−−&lt;TC&gt;
Example: IPhone is a revolutionary smart phone
−−−→(VBE) subj
Pattern#5: &lt;OC&gt; pred ←−−−&lt;TC&gt;
Example: The quality of LCD is good
</table>
<tableCaption confidence="0.9696025">
Table 1: Some Examples of Used Syntactic Pat-
terns
</tableCaption>
<subsectionHeader confidence="0.514265">
3.1.2 Unsupervised Word Alignment Model
</subsectionHeader>
<bodyText confidence="0.999943888888889">
In this subsection, we present our method for cap-
turing opinion relations using unsupervised word
alignment model. Similar to (Liu et al., 2012),
every sentence in reviews is replicated to gener-
ate a parallel sentence pair, and the word align-
ment algorithm is applied to the monolingual sce-
nario to align a noun/noun phase with its modi-
fiers. We select IBM-3 model (Brown et al., 1993)
as the alignment model. Formally, given a sen-
</bodyText>
<equation confidence="0.827384">
tence S = {w1, w2, ..., wn}, we have
t(wj|waj)d(j|aj,N) (1)
</equation>
<bodyText confidence="0.994874714285714">
where t(wj|waj) models the co-occurrence infor-
mation of two words in dataset. d(j|aj, n) mod-
els word position information, which describes the
probability of a word in position aj aligned with a
word in position j. And n(φi|wi) describes the
ability of a word for modifying (being modified
by) several words. φi denotes the number of words
</bodyText>
<equation confidence="0.95727175">
Pibm3(A|S)
N N
a n(φi|wi) H
i=1 j=1
</equation>
<page confidence="0.864385">
1757
</page>
<bodyText confidence="0.9819355625">
that are aligned with wi. In our experiments, we
set Oi = 2.
Since we only have interests on capturing opin-
ion relations between words, we only pay at-
tentions on the alignments between opinion tar-
get candidates (nouns/noun phrases) and potential
opinion words (adjectives/verbs). If we directly
use the alignment model, a noun (noun phrase)
may align with other unrelated words, like prepo-
sitions or conjunctions and so on. Thus, we set
constrains on the model: 1) Alignment links must
be assigned among nouns/noun phrases, adjec-
tives/verbs and null words. Aligning to null words
means that this word has no modifier or modifies
nothing; 2) Other unrelated words can only align
with themselves.
</bodyText>
<subsectionHeader confidence="0.76015">
3.1.3 Combining Syntax-based Method with
Alignment-based Method
</subsectionHeader>
<bodyText confidence="0.99641037704918">
In this subsection, we try to combine syntactic in-
formation with word alignment model. As men-
tioned in the first section, we adopt a partially
supervised alignment model to make this com-
bination. Here, the opinion relations obtained
through the high-precision syntactic patterns (Sec-
tion 3.1.1) are regarded as the ground truth and
can only provide a part of full alignments in sen-
tences. They are treated as the constrains for the
word alignment model. Given some partial align-
ment links Aˆ = {(k, ak)|k E [1, n], ak E [1, n]},
the optimal word alignment A* = {(i, ai)|i E
[1, n], ai E [1, n]} can be obtained as A* =
argmax P(A|5, ˆA), where (i, ai) means that a
A
noun (noun phrase) at position i is aligned with
its modifier at position ai.
Since the labeled data provided by syntactic pat-
terns is not a full alignment, we adopt a EM-based
algorithm, named as constrained hill-climbing al-
gorithm(Gao et al., 2010), to estimate the parame-
ters in the model. In the training process, the con-
strained hill-climbing algorithm can ensure that
the final model is marginalized on the partial align-
ment links. Particularly, in the E step, their method
aims to find out the alignments which are consis-
tent to the alignment links provided by syntactic
patterns, where there are main two steps involved.
1) Optimize towards the constraints. This step
aims to generate an initial alignments for align-
ment model (IBM-3 model in our method), which
can be close to the constraints. First, a simple
alignment model (IBM-1, IBM-2, HMM etc.) is
trained. Then, the evidence being inconsistent
to the partial alignment links will be got rid of
by using the move operator operator mi,j which
changes aj = i and the swap operator sj1,j2 which
exchanges aj1 and aj2. The alignment is updated
iteratively until no additional inconsistent links
can be removed.
2) Towards the optimal alignment under the
constraints. This step aims to optimize towards
the optimal alignment under the constraints which
starts from the aforementioned initial alignments.
Gao et.al. (2010) set the corresponding cost value
of the invalid move or swap operation in M and
5 to be negative, where M and 5 are respec-
tively called Moving Matrix and Swapping Ma-
trix, which record all possible move and swap
costs between two different alignments. In this
way, the invalid operators will never be picked
which can guarantee that the final alignment links
to have high probability to be consistent with the
partial alignment links provided by high-precision
syntactic patterns.
Then in M-step, evidences from the neighbor of
final alignments are collected so that we can pro-
duce the estimation of parameters for the next iter-
ation. In the process, those statistics which come
from inconsistent alignment links aren’t be picked
up. Thus, we have
</bodyText>
<equation confidence="0.992778">
P (wi|wai, ˆA)
r λ, otherwise
t =P(wi|wai) + λ, inconsistent with Aˆ
</equation>
<bodyText confidence="0.965300166666667">
(2)
where λ means that we make soft constraints on
the alignment model. As a result, we expect some
errors generated through high-precision patterns
(Section 3.1.1) may be revised in the alignment
process.
</bodyText>
<subsectionHeader confidence="0.999651">
3.2 Estimating Associations between Words
</subsectionHeader>
<bodyText confidence="0.990037769230769">
After capturing opinion relations in sentences, we
can obtain a lot of word pairs, each of which is
comprised of an opinion target candidate and its
corresponding modified word. Then the condi-
tional probabilities between potential opinion tar-
get wt and potential opinion word wo can be es-
timated by using maximum likelihood estimation.
Thus, we have P(wt|wo) = Count(wt,wo)
Count(wo) , where
Count(·) means the item’s frequency informa-
tion. P(wt|wo) means the conditional probabili-
ties between two words. At the same time, we can
obtain conditional probability P(wo|wt). Then,
</bodyText>
<page confidence="0.98302">
1758
</page>
<bodyText confidence="0.992323">
similar to (Liu et al., 2012), the association be-
tween an opinion target candidate and its modifier
is estimated as follows. Association(wt, wo) =
(α × P(wt|wo) + (1 − α) × P(wo|wt))−1, where
α is the harmonic factor. We set α = 0.5 in our
experiments.
</bodyText>
<subsectionHeader confidence="0.9966545">
3.3 The Second Component: Estimating
Candidate Confidence
</subsectionHeader>
<bodyText confidence="0.999794608695653">
In the second component, we adopt a graph-based
algorithm used in (Liu et al., 2012) to compute
the confidence of each opinion target candidate,
and the candidates with higher confidence than the
threshold will be extracted as the opinion targets.
Here, opinion words are regarded as the impor-
tant indicators. We assume that two target candi-
dates are likely to belong to the similar category, if
they are modified by similar opinion words. Thus,
we can propagate the opinion target confidences
through opinion words.
To model the mined associations between
words, a bipartite graph is constructed, which
is defined as a weighted undirected graph G =
(V, E, W). It contains two kinds of vertex: opin-
ion target candidates and potential opinion words,
respectively denoted as vt ∈ V and vo ∈ V .
As shown in Figure 2, the white vertices repre-
sent opinion target candidates and the gray ver-
tices represent potential opinion words. An edge
evt,vo ∈ E between vertices represents that there is
an opinion relation, and the weight w on the edge
represents the association between two words.
</bodyText>
<figureCaption confidence="0.959806">
Figure 2: Modeling Opinion Relations between
Words in a Bipartite Graph
</figureCaption>
<bodyText confidence="0.9997914">
To estimate the confidence of each opinion tar-
get candidate, we employ a random walk algo-
rithm on our graph, which iteratively computes
the weighted average of opinion target confidences
from neighboring vertices. Thus we have
</bodyText>
<equation confidence="0.987822">
Ci+1 = (1 − β) × M × MT × Ci + β × I (3)
</equation>
<bodyText confidence="0.968369">
where Ci+1 and Ci respectively represent the
opinion target confidence vector in the (i + 1)th
and ith iteration. M is the matrix of word asso-
ciations, where Mi,j denotes the association be-
tween the opinion target candidate i and the po-
tential opinion word j. And I is defined as the
prior confidence of each candidate for opinion tar-
get. Similar to (Liu et al., 2012), we set each item
in Iv = tf(v)idf(v) , where t vis the term fre-
Ev tf(v)idf(v) f (vis
quency of v in the corpus, and df(v) is computed
by using the Google n-gram corpus2. β ∈ [0, 1]
represents the impact of candidate prior knowl-
edge on the final estimation results. In experi-
ments, we set β = 0.4. The algorithm run un-
til convergence which is achieved when the confi-
dence on each node ceases to change in a tolerance
value.
</bodyText>
<sectionHeader confidence="0.999908" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995257">
4.1 Datasets and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.944626722222222">
In this section, to answer the questions men-
tioned in the first section, we collect a large
collection named as LARGE, which includes re-
views from three different domains and differ-
ent languages. This collection was also used
in (Liu et al., 2012). In the experiments, re-
views are first segmented into sentences accord-
ing to punctuation. The detailed statistical in-
formation of the used collection is shown in Ta-
ble 2, where Restaurant is crawled from the Chi-
nese Web site: www.dianping.com. The Hotel and
MP3 are used in (Wang et al., 2011), which are re-
spectively crawled from www.tripadvisor.com and
www.amazon.com. For each dataset, we perform
random sampling to generate testing set with dif-
ferent sizes, where we use sampled subsets with
#sentences = 5 × 102, 103, 5 × 103, 104, 5 ×
104, 105 and 106 sentences respectively. Each
</bodyText>
<table confidence="0.99984125">
Domain Language Sentence Reviews
Restaurant Chinese 1,683,129 395,124
Hotel English 1,855,351 185,829
MP3 English 289,931 30,837
</table>
<tableCaption confidence="0.998788">
Table 2: Experimental Dataset
</tableCaption>
<footnote confidence="0.827736833333333">
sentence is tokenized, part-of-speech tagged by
using Stanford NLP tool3, and parsed by using
Minipar toolkit. And the method of (Zhu et al.,
2009) is used to identify noun phrases.
2http://books.google.com/ngrams/datasets
3http://nlp.stanford.edu/software/tagger.shtml
</footnote>
<page confidence="0.996415">
1759
</page>
<bodyText confidence="0.999975">
We select precision and recall as the metrics.
Specifically, to obtain the ground truth, we man-
ually label all opinion targets for each subset. In
this process, three annotators are involved. First,
every noun/noun phrase and its contexts in review
sentences are extracted. Then two annotators were
required to judge whether every noun/noun phrase
is opinion target or not. If a conflict happens, a
third annotator will make judgment for final re-
sults. The average inter-agreements is 0.74. We
also perform a significant test, i.e., a t-test with a
default significant level of 0.05.
</bodyText>
<subsectionHeader confidence="0.831592">
4.2 Compared Methods
</subsectionHeader>
<bodyText confidence="0.9985565">
We select three methods for comparison as fol-
lows.
</bodyText>
<listItem confidence="0.98345475">
• Syntax: It uses syntactic patterns mentioned
in Section 3.1.1 in the first component to
capture opinion relations in reviews. Then
the associations between words are estimated
and the graph based algorithm proposed in
the second component (Section 3.3) is per-
formed to extract opinion targets.
• WAM: It is similar to Syntax, where the only
difference is that WAM uses unsupervised
WAM (Section 3.1.2) to capture opinion re-
lations.
• PSWAM is similar to Syntax and WAM,
</listItem>
<bodyText confidence="0.995284">
where the difference is that PSWAM uses the
method mentioned in Section 3.1.3 to capture
opinion relations, which incorporates syntac-
tic information into word alignment model by
using partially supervised framework.
The experimental results on different domains are
respectively shown in Figure 3, 4 and 5.
</bodyText>
<subsectionHeader confidence="0.9975135">
4.3 Syntax based Methods vs. Alignment
based Methods
</subsectionHeader>
<bodyText confidence="0.994882">
Comparing Syntax with WAM and PSWAM, we
can obtain the following observations:
</bodyText>
<figureCaption confidence="0.999626">
Figure 3: Experimental results on Restaurant
Figure 4: Experimental results on Hotel
Figure 5: Experimental results on MP3
</figureCaption>
<listItem confidence="0.953427454545455">
1) When the size of the corpus is small, Syntax
has better precision than alignment based meth-
ods (WAM and PSWAM). We believe the reason
is that the high-precision syntactic patterns em-
ployed in Syntax can effectively capture opinion
relations in a small amount of texts. In contrast,
the methods based on word alignment model may
suffer from data sparseness for parameter estima-
tion, so the precision is lower.
2) However, when the size of the corpus in-
creases, the precision of Syntax decreases, even
</listItem>
<bodyText confidence="0.963826708333333">
worse than alignment based methods. We believe
it’s because more noises were introduced from
parsing errors with the increase of the size of the
corpus, which will have more negative impacts on
extraction results. In contrast, for estimating the
parameters of alignment based methods, the data
is more sufficient, so the precision is better com-
pared with syntax based method.
3) We also observe that recall of Syntax is
worse than other two methods. It’s because the
human expressions of opinions are diverse and the
manual designed syntactic patterns are limited to
capture all opinion relations in sentences, which
may miss an amount of correct opinion targets.
4) It’s interesting that the performance gap be-
tween these three methods is smaller with the in-
crease of the size of the corpus (more than 50,000).
We guess the reason is that when the data is suffi-
cient enough, we can obtain sufficient statistics for
each opinion target. In such situation, the graph-
based ranking algorithm in the second component
will be apt to be affected by the frequency infor-
mation, so the final performance could not be sen-
sitive to the performance of opinion relations iden-
</bodyText>
<page confidence="0.974501">
1760
</page>
<bodyText confidence="0.999951826086957">
tification in the first component. Thus, in this situ-
ation, we can get conclusion that there is no obvi-
ously difference on performance between syntax-
based approach and alignment-based approach.
5) From the results on dataset with different lan-
guages and different domains, we can obtain the
similar observations. It indicates that choosing ei-
ther syntactic patterns or word alignment model
for extracting opinion targets can take a few con-
sideration on the language and domain of the cor-
pus.
Thus, based on the above observations, we can
draw the following conclusions: making chooses
between different methods is only related to the
size of the corpus. The method based on syn-
tactic patterns is more suitable for small cor-
pus (#sentences &lt; 5 x 103 shown in our
experiments). And word alignment model is
more suitable for medium corpus (5 x 103 &lt;
#sentences &lt; 5 x 104). Moreover, when the
size of the corpus is big enough, the performance
of two kinds of methods tend to become the same
(#sentences &gt; 105 shown in our experiments).
</bodyText>
<subsectionHeader confidence="0.958217">
4.4 Is It Useful Combining Syntactic Patterns
with Word Alignment Model
</subsectionHeader>
<bodyText confidence="0.997977641025641">
In this subsection, we try to see whether combin-
ing syntactic information with alignment model by
using PSWAM is effective or not for opinion tar-
get extraction. From the results in Figure 3, 4 and
5, we can see that PSWAM has the similar recall
compared with WAM in all datasets. PSWAM
outperforms WAM on precision in all dataset. But
the precision gap between PSWAM and WAM
decreases when the size of the corpus increases.
When the size is larger than 5 x 104, the perfor-
mance of these two methods is almost the same.
We guess the reason is that more noises from pars-
ing errors will be introduced by syntactic patterns
with the increase of the size of corpus , which have
negative impacts on alignment performance. At
the same time, as mentioned above, a great deal of
reviews will bring sufficient statistics for estimat-
ing parameters in alignment model, so the roles
of partial supervision from syntactic information
will be covered by frequency information used in
our graph based ranking algorithm.
Compared with State-of-the-art Methods.
However, it’s not say that this combination is
not useful. From the results, we still see that
PSWAM outperforms WAM in all datasets on
precision when size of corpus is smaller than
5 x 104. To further prove the effectiveness of
our combination, we compare PSWAM with some
state-of-the-art methods, including Hu (Hu and
Liu, 2004a), which extracted frequent opinion tar-
get words based on association mining rules, DP
(Qiu et al., 2011), which extracted opinion tar-
gets through syntactic patterns, and LIU (Liu et
al., 2012), which fulfilled this task by using un-
supervised WAM. The parameter settings in these
baselines are the same as the settings in the orig-
inal papers. Because of the space limitation, we
only show the results on Restaurant and Hotel, as
shown in Figure 6 and 7.
</bodyText>
<figureCaption confidence="0.99544475">
Figure 6: Compared with the State-of-the-art
Methods on Restaurant
Figure 7: Compared with the State-of-the-art
Methods on Hotel
</figureCaption>
<bodyText confidence="0.994230944444444">
From the experimental results, we can obtain
the following observations. PSWAM outperforms
other methods in most datasets. This indicates
that our method based on PSWAM is effective
for opinion target extraction. Especially compared
PSWAM with LIU, both of which are based on
word alignment model, we can see PSWAM iden-
tifies opinion relations by performing WAM under
partial supervision, which can effectively improve
the precision when dealing with small and medium
corpus. However, these improvements are limited
when the size of the corpus increases, which has
the similar observations obtained above.
The Impact of Syntactic Information on
Word Alignment Model. Although we have
prove the effectiveness of PSWAM in the corpus
with small and medium size, we are still curious
about how the performance varies when we incor-
</bodyText>
<page confidence="0.967986">
1761
</page>
<bodyText confidence="0.9581024">
porate different amount of syntactic information
into WAM. In this experiment, we rank the used
syntactic patterns mentioned in Section 3.1.1 ac-
cording to the quantities of the extracted alignment
links by these patterns. Then, to capture opin-
ion relations, we respectively use top N syntactic
patterns according to frequency mentioned above
to generate partial alignment links for PSWAM in
section 3.1.3. We respectively define N=[1,7]. The
larger is N , the more syntactic information is in-
</bodyText>
<figureCaption confidence="0.8665684">
corporated. Because of the space limitation, only
the average performance of all dataset is shown in
Figure 8.
Figure 8: The Impacts of Different Syntactic In-
formation on Word Alignment Model
</figureCaption>
<bodyText confidence="0.999774">
In Figure 8, we can observe that the syntactic in-
formation mainly have effect on precision. When
the size of the corpus is small, the opinion rela-
tions mined by high-precision syntactic patterns
are usually correct, so incorporating more syntac-
tic information can improve the precision of word
alignment model more. However, when the size of
the corpus increases, incorporating more syntactic
information has little impact on precision.
</bodyText>
<sectionHeader confidence="0.998745" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999986444444445">
This paper discusses the performance variation of
syntax based methods and alignment based meth-
ods on opinion target extraction task for the dataset
with different sizes, different languages and dif-
ferent domains. Through experimental results, we
can see that choosing which method is not related
with corpus domain and language, but strongly
associated with the size of the corpus . We can
conclude that syntax-based method is likely to be
more effective when the size of the corpus is small,
and alignment-based methods are more useful for
the medium size corpus. We further verify that in-
corporating syntactic information into word align-
ment model by using PSWAM is effective when
dealing with the corpora with small or medium
size. When the size of the corpus is larger and
larger, the performance gap between syntax based,
WAM and PSWAM will decrease.
In future work, we will extract opinion targets
based on not only opinion relations. Other seman-
tic relations, such as the topical associations be-
tween opinion targets (or opinion words) should
also be employed. We believe that considering
multiple semantic associations will help to im-
prove the performance. In this way, how to model
heterogenous relations in a unified model for opin-
ion targets extraction is worthy to be studied.
</bodyText>
<sectionHeader confidence="0.959581" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.997913333333333">
This work was supported by the National Natu-
ral Science Foundation of China (No. 61070106,
No. 61272332 and No. 61202329), the Na-
tional High Technology Development 863 Pro-
gram of China (No. 2012AA011102), the Na-
tional Basic Research Program of China (No.
2012CB316300), Tsinghua National Laboratory
for Information Science and Technology (TNList)
Cross-discipline Foundation and the Opening
Project of Beijing Key Laboratory of Inter-
net Culture and Digital Dissemination Research
(ICDD201201).
</bodyText>
<sectionHeader confidence="0.999183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999181733333333">
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: pa-
rameter estimation. Comput. Linguist., 19(2):263–
311, June.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In Proceedings of the Conference on Web Search and
Web Data Mining (WSDM).
Qin Gao, Nguyen Bach, and Stephan Vogel. 2010. A
semi-supervised word alignment algorithm with par-
tial manual alignments. In Proceedings of the Joint
Fifth Workshop on Statistical Machine Translation
and MetricsMATR, pages 1–10, Uppsala, Sweden,
July. Association for Computational Linguistics.
</reference>
<page confidence="0.856509">
1762
</page>
<reference confidence="0.999837626506024">
Mingqin Hu and Bing Liu. 2004a. Mining opinion fea-
tures in customer reviews. In Proceedings of Con-
ference on Artificial Intelligence (AAAI).
Minqing Hu and Bing Liu. 2004b. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.
Wei Jin and Hay Ho Huang. 2009. A novel lexical-
ized hmm-based learning framework for web opin-
ion mining. In Proceedings of International Confer-
ence on Machine Learning (ICML).
Jon M. Kleinberg. 1999. Authoritative sources in a
hyperlinked environment. J. ACM, 46(5):604–632,
September.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Yingju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-aware review mining and summarization.
In Chu-Ren Huang and Dan Jurafsky, editors, COL-
ING, pages 653–661. Tsinghua University Press.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In Allan Ellis and Tatsuya Hagino,
editors, WWW, pages 342–351. ACM.
Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opin-
ion target extraction using word-based translation
model. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 1346–1356, Jeju Island, Korea,
July. Association for Computational Linguistics.
Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013.
Opinion target extraction using partially supervised
word alignment model.
Tengfei Ma and Xiaojun Wan. 2010. Opinion tar-
get extraction in chinese news comments. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 782–790. Chinese Information Pro-
cessing Society of China.
Ana-Maria Popescu and Oren Etzioni. 2005. Ex-
tracting product features and opinions from reviews.
In Proceedings of the conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, HLT ’05, pages 339–346,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Che. 2009.
Expanding domain sentiment lexicon through dou-
ble propagation.
Guang Qiu, Bing Liu 0001, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extraction
through double propagation. Computational Lin-
guistics, 37(1):9–27.
Bo Wang and Houfeng Wang. 2008. Bootstrapping
both product features and opinion words from chi-
nese customer reviews with cross-inducing.
Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011.
Latent aspect rating analysis without aspect key-
word supervision. In Chid Apt, Joydeep Ghosh,
and Padhraic Smyth, editors, KDD, pages 618–626.
ACM.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In EMNLP, pages 1533–1541. ACL.
Qi Zhang, Yuanbin Wu, Tao Li, Mitsunori Ogihara,
Joseph Johnson, and Xuanjing Huang. 2009. Min-
ing product reviews based on shallow dependency
parsing. In Proceedings of the 32nd international
ACM SIGIR conference on Research and develop-
ment in information retrieval, SIGIR ’09, pages
726–727, New York, NY, USA. ACM.
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O’Brien-Strain. 2010. Extracting and ranking
product features in opinion documents. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 1462–1470. Chinese Information
Processing Society of China.
Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and
Muhua Zhu. 2009. Multi-aspect opinion polling
from textual reviews. In David Wai-Lok Cheung,
Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and
Jimmy J. Lin, editors, CIKM, pages 1799–1802.
ACM.
</reference>
<page confidence="0.916602">
1763
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886026">
<title confidence="0.995049">Syntactic Patterns versus Word Alignment: Extracting Opinion from Online Reviews</title>
<author confidence="0.994026">Kang Liu</author>
<author confidence="0.994026">Liheng Xu</author>
<author confidence="0.994026">Jun</author>
<affiliation confidence="0.9787755">National Laboratory of Pattern Institute of Automation, Chinese Academy of</affiliation>
<email confidence="0.942837">lhxu,</email>
<abstract confidence="0.999690357142857">Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empirically studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>311</pages>
<contexts>
<context position="16302" citStr="Brown et al., 1993" startWordPosition="2625" endWordPosition="2628">C&gt; mod ←−−−&lt;TC&gt; Example: IPhone is a revolutionary smart phone −−−→(VBE) subj Pattern#5: &lt;OC&gt; pred ←−−−&lt;TC&gt; Example: The quality of LCD is good Table 1: Some Examples of Used Syntactic Patterns 3.1.2 Unsupervised Word Alignment Model In this subsection, we present our method for capturing opinion relations using unsupervised word alignment model. Similar to (Liu et al., 2012), every sentence in reviews is replicated to generate a parallel sentence pair, and the word alignment algorithm is applied to the monolingual scenario to align a noun/noun phase with its modifiers. We select IBM-3 model (Brown et al., 1993) as the alignment model. Formally, given a sentence S = {w1, w2, ..., wn}, we have t(wj|waj)d(j|aj,N) (1) where t(wj|waj) models the co-occurrence information of two words in dataset. d(j|aj, n) models word position information, which describes the probability of a word in position aj aligned with a word in position j. And n(φi|wi) describes the ability of a word for modifying (being modified by) several words. φi denotes the number of words Pibm3(A|S) N N a n(φi|wi) H i=1 j=1 1757 that are aligned with wi. In our experiments, we set Oi = 2. Since we only have interests on capturing opinion re</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Comput. Linguist., 19(2):263– 311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Web Search and Web Data Mining (WSDM).</booktitle>
<contexts>
<context position="7950" citStr="Ding et al., 2008" startWordPosition="1279" endWordPosition="1282">xts, but also can improve the mining performance by using partial supervision. However, is this kind of combination always useful for opinion target extraction? To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sent</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the Conference on Web Search and Web Data Mining (WSDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Nguyen Bach</author>
<author>Stephan Vogel</author>
</authors>
<title>A semi-supervised word alignment algorithm with partial manual alignments.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="6117" citStr="Gao et al., 2010" startWordPosition="988" endWordPosition="991">ey component of which we vary the methods between syntactic patterns and alignment model. Then we run the whole framework on the corpus with different size (from #500 to #1, 000, 000), domain (three domains) and language (Chinese and English) to empirically assess the performance variations and discuss which method is more effective. Furthermore, this paper naturally addresses another question: is it useful for opinion targets extraction when we combine syntactic patterns and word alignment model into a unified model? To this end, we employ a partially supervised alignment model (PSWAM) like (Gao et al., 2010; Liu et al., 2013). Based on the exquisitely designed high-precision syntactic patterns, we can obtain some precisely modified relations between words in sentences, which provide a portion of links of the full alignments. Then, these partial alignment links can be regarded as the constrains for a standard unsupervised word alignment model. And each target candidate would find its modifier under the partial supervision. In this way, the errors generated in standard unsupervised WAM can be corrected. For example in Figure 1, “kindly” and “courteous” are incorrectly regarded as the modifiers for</context>
<context position="18465" citStr="Gao et al., 2010" startWordPosition="2995" endWordPosition="2999">egarded as the ground truth and can only provide a part of full alignments in sentences. They are treated as the constrains for the word alignment model. Given some partial alignment links Aˆ = {(k, ak)|k E [1, n], ak E [1, n]}, the optimal word alignment A* = {(i, ai)|i E [1, n], ai E [1, n]} can be obtained as A* = argmax P(A|5, ˆA), where (i, ai) means that a A noun (noun phrase) at position i is aligned with its modifier at position ai. Since the labeled data provided by syntactic patterns is not a full alignment, we adopt a EM-based algorithm, named as constrained hill-climbing algorithm(Gao et al., 2010), to estimate the parameters in the model. In the training process, the constrained hill-climbing algorithm can ensure that the final model is marginalized on the partial alignment links. Particularly, in the E step, their method aims to find out the alignments which are consistent to the alignment links provided by syntactic patterns, where there are main two steps involved. 1) Optimize towards the constraints. This step aims to generate an initial alignments for alignment model (IBM-3 model in our method), which can be close to the constraints. First, a simple alignment model (IBM-1, IBM-2, </context>
</contexts>
<marker>Gao, Bach, Vogel, 2010</marker>
<rawString>Qin Gao, Nguyen Bach, and Stephan Vogel. 2010. A semi-supervised word alignment algorithm with partial manual alignments. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 1–10, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingqin Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinion features in customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="2045" citStr="Hu and Liu, 2004" startWordPosition="334" endWordPosition="337">e Web. Mining opinions from these reviews become more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence informatio</context>
<context position="7930" citStr="Hu and Liu, 2004" startWordPosition="1275" endWordPosition="1278">ng with informal texts, but also can improve the mining performance by using partial supervision. However, is this kind of combination always useful for opinion target extraction? To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opi</context>
<context position="9665" citStr="Hu and Liu, 2004" startWordPosition="1564" endWordPosition="1567">nction structure. However, the main limitation of these supervised methods is the need of labeled training data. If the labeled training data is insufficient, the trained model would have unsatisfied extraction performance. Labeling sufficient training data is time and labor consuming. And for different domains, we need label data independently, which is obviously impracticable. Thus, many researches focused on unsupervised methods, which are mainly to extract a list of opinion targets from reviews. Similar to ours, most approaches regarded opinion words as the indicator for opinion targets. (Hu and Liu, 2004a) regarded the nearest adjective to an noun/noun phrase as its modifier. Then it exploited an association rule mining algorithm to mine the associations between them. Finally, the frequent explicit product features can be extracted in a bootstrapping process by further combining item’s frequency in dataset. Only using nearest neighbor rule to mine the modifier for each candidate cannot obtain precise results. Thus, (Popescu and Etzioni, 2005) used syntax information to extract opinion targets, which designed some syntactic patterns to capture the modified relations between words. The experime</context>
<context position="12915" citStr="Hu and Liu, 2004" startWordPosition="2077" endWordPosition="2080">d for opinion target extraction when given a certain amount of reviews. 3 Opinion Target Extraction Methodology To extract opinion targets from reviews, we adopt the framework proposed by (Liu et al., 2012), which is a graph-based extraction framework and 1756 has two main components as follows. 1) The first component is to capture opinion relations in sentences and estimate associations between opinion target candidates and potential opinion words. In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). And a potential opinion relation is comprised of an opinion target candidate and its corresponding modified word. 2) The second component is to estimate the confidence of each candidate. The candidates with higher confidence scores than a threshold will be extracted as opinion targets. In this procedure, we formulate the associations between opinion target candidates and potential opinion words in a bipartite graph. A random walk based algorithm is employed on this graph to estimate the confidence of each target candidate. In this pa</context>
<context position="30927" citStr="Hu and Liu, 2004" startWordPosition="5070" endWordPosition="5073">reat deal of reviews will bring sufficient statistics for estimating parameters in alignment model, so the roles of partial supervision from syntactic information will be covered by frequency information used in our graph based ranking algorithm. Compared with State-of-the-art Methods. However, it’s not say that this combination is not useful. From the results, we still see that PSWAM outperforms WAM in all datasets on precision when size of corpus is smaller than 5 x 104. To further prove the effectiveness of our combination, we compare PSWAM with some state-of-the-art methods, including Hu (Hu and Liu, 2004a), which extracted frequent opinion target words based on association mining rules, DP (Qiu et al., 2011), which extracted opinion targets through syntactic patterns, and LIU (Liu et al., 2012), which fulfilled this task by using unsupervised WAM. The parameter settings in these baselines are the same as the settings in the original papers. Because of the space limitation, we only show the results on Restaurant and Hotel, as shown in Figure 6 and 7. Figure 6: Compared with the State-of-the-art Methods on Restaurant Figure 7: Compared with the State-of-the-art Methods on Hotel From the experim</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Mingqin Hu and Bing Liu. 2004a. Mining opinion features in customer reviews. In Proceedings of Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2045" citStr="Hu and Liu, 2004" startWordPosition="334" endWordPosition="337">e Web. Mining opinions from these reviews become more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence informatio</context>
<context position="7930" citStr="Hu and Liu, 2004" startWordPosition="1275" endWordPosition="1278">ng with informal texts, but also can improve the mining performance by using partial supervision. However, is this kind of combination always useful for opinion target extraction? To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opi</context>
<context position="9665" citStr="Hu and Liu, 2004" startWordPosition="1564" endWordPosition="1567">nction structure. However, the main limitation of these supervised methods is the need of labeled training data. If the labeled training data is insufficient, the trained model would have unsatisfied extraction performance. Labeling sufficient training data is time and labor consuming. And for different domains, we need label data independently, which is obviously impracticable. Thus, many researches focused on unsupervised methods, which are mainly to extract a list of opinion targets from reviews. Similar to ours, most approaches regarded opinion words as the indicator for opinion targets. (Hu and Liu, 2004a) regarded the nearest adjective to an noun/noun phrase as its modifier. Then it exploited an association rule mining algorithm to mine the associations between them. Finally, the frequent explicit product features can be extracted in a bootstrapping process by further combining item’s frequency in dataset. Only using nearest neighbor rule to mine the modifier for each candidate cannot obtain precise results. Thus, (Popescu and Etzioni, 2005) used syntax information to extract opinion targets, which designed some syntactic patterns to capture the modified relations between words. The experime</context>
<context position="12915" citStr="Hu and Liu, 2004" startWordPosition="2077" endWordPosition="2080">d for opinion target extraction when given a certain amount of reviews. 3 Opinion Target Extraction Methodology To extract opinion targets from reviews, we adopt the framework proposed by (Liu et al., 2012), which is a graph-based extraction framework and 1756 has two main components as follows. 1) The first component is to capture opinion relations in sentences and estimate associations between opinion target candidates and potential opinion words. In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). And a potential opinion relation is comprised of an opinion target candidate and its corresponding modified word. 2) The second component is to estimate the confidence of each candidate. The candidates with higher confidence scores than a threshold will be extracted as opinion targets. In this procedure, we formulate the associations between opinion target candidates and potential opinion words in a bipartite graph. A random walk based algorithm is employed on this graph to estimate the confidence of each target candidate. In this pa</context>
<context position="30927" citStr="Hu and Liu, 2004" startWordPosition="5070" endWordPosition="5073">reat deal of reviews will bring sufficient statistics for estimating parameters in alignment model, so the roles of partial supervision from syntactic information will be covered by frequency information used in our graph based ranking algorithm. Compared with State-of-the-art Methods. However, it’s not say that this combination is not useful. From the results, we still see that PSWAM outperforms WAM in all datasets on precision when size of corpus is smaller than 5 x 104. To further prove the effectiveness of our combination, we compare PSWAM with some state-of-the-art methods, including Hu (Hu and Liu, 2004a), which extracted frequent opinion target words based on association mining rules, DP (Qiu et al., 2011), which extracted opinion targets through syntactic patterns, and LIU (Liu et al., 2012), which fulfilled this task by using unsupervised WAM. The parameter settings in these baselines are the same as the settings in the original papers. Because of the space limitation, we only show the results on Restaurant and Hotel, as shown in Figure 6 and 7. Figure 6: Compared with the State-of-the-art Methods on Restaurant Figure 7: Compared with the State-of-the-art Methods on Hotel From the experim</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004b. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hay Ho Huang</author>
</authors>
<title>A novel lexicalized hmm-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="8251" citStr="Jin and Huang, 2009" startWordPosition="1326" endWordPosition="1329">nt size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. And classical sequence labeling models are used to train the extractor, such as CRFs (Li et al., 2010), HMM (Jin and Huang, 2009) etc.. Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Both Li et al. (2010) and Ma et al. (2010) used CRFs model to extract opinion ta</context>
</contexts>
<marker>Jin, Huang, 2009</marker>
<rawString>Wei Jin and Hay Ho Huang. 2009. A novel lexicalized hmm-based learning framework for web opinion mining. In Proceedings of International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>J. ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="11107" citStr="Kleinberg, 1999" startWordPosition="1786" endWordPosition="1787">o exploited syntactic relations between words. Specially, (Qiu et al., 2011) didn’t only design syntactic patterns for capturing modified relations, but also designed patterns for capturing relations among opinion targets and relations among opinion words. However, the main limitation of Qiu’s method is that the patterns based on dependency parsing tree may miss many targets for the large corpora. Therefore, Zhang et al. (2010) extended Qiu’s method. Besides the patterns used in Qiu’s method, they adopted some other special designed patterns to increase recall. In addition they used the HITS (Kleinberg, 1999) algorithm to compute opinion target confidences to improve the precision. (Liu et al., 2012) formulated identifying opinion relations between words as an alignment process. They used a completely unsupervised WAM to capture opinion relations in sentences. Then the opinion targets were extracted in a standard random walk framework where two factors were considered: opinion relevance and target importance. Their experimental results have shown that WAM was more effective than traditional syntax-based methods for this task. (Liu et al., 2013) extend Liu’s method, which is similar to our method a</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. J. ACM, 46(5):604–632, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
</authors>
<title>Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu.</title>
<date>2010</date>
<booktitle>In Chu-Ren Huang and</booktitle>
<pages>653--661</pages>
<editor>Dan Jurafsky, editors, COLING,</editor>
<publisher>Tsinghua University Press.</publisher>
<marker>Li, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware review mining and summarization. In Chu-Ren Huang and Dan Jurafsky, editors, COLING, pages 653–661. Tsinghua University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web.</title>
<date>2005</date>
<pages>342--351</pages>
<editor>In Allan Ellis and Tatsuya Hagino, editors, WWW,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="2091" citStr="Liu et al., 2005" startWordPosition="342" endWordPosition="345">me more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and Liu, 2004a; Hu and </context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In Allan Ellis and Tatsuya Hagino, editors, WWW, pages 342–351. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using word-based translation model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1346--1356</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="2149" citStr="Liu et al., 2012" startWordPosition="354" endWordPosition="357">tain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and Liu, 2004a; Hu and Liu, 2004b). Obviously, these methods cannot obtain precis</context>
<context position="3660" citStr="Liu et al. (2012)" startWordPosition="589" endWordPosition="592"> et al., 2009; Qiu et al., 2011). However, the sentences in online reviews usually have informal writing styles including grammar mistakes, typos, improper punctuation etc., which make parsing prone to generate mistakes. As a result, the syntax-based methods which heavily depended on the parsing performance would suffer from parsing errors (Zhang et al., 2010). To improve the extraction performance, we can only employ some exquisite highprecision patterns. But this strategy is likely to miss many opinion targets and has lower recall with the increase of corpus size. To resolve these problems, Liu et al. (2012) formulated identifying opinion relations between words as an monolingual alignment process. A word can find its corresponding modifiers by using a word alignment 1754 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1754–1763, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 1: Mining Opinion Relations between Words using Partially Supervised Alignment Model model (WAM). Without using syntactic parsing, the noises from parsing errors can be effectively avoided. Nevertheless, we notice that the alignment mod</context>
<context position="4893" citStr="Liu et al., 2012" startWordPosition="781" endWordPosition="784">cal model which needs sufficient data to estimate parameters. When the data is insufficient, it would suffer from data sparseness and may make the performance decline. Thus, from the above analysis, we can observe that the size of the corpus has impacts on these two kinds of methods, which arises some important questions: how can we make selection between syntax based methods and alignment based method for opinion target extraction when given a certain amount of reviews? And which kind of methods can obtain better extraction performance with the variation of the size of the dataset? Although (Liu et al., 2012) had proved the effectiveness of WAM, they mainly performed experiments on the dataset with medium size. We are still curious about that when the size of dataset is larger or smaller, can we obtain the same conclusion? To our best knowledge, these problems have not been studied before. Moreover, opinions may be expressed in different ways with the variation of the domain and language of the corpus. When the domain or language of the corpus is changed, what conclusions can we obtain? To answer these questions, in this paper, we adopt a unified framework to extract opinion targets from reviews, </context>
<context position="11200" citStr="Liu et al., 2012" startWordPosition="1798" endWordPosition="1801">ign syntactic patterns for capturing modified relations, but also designed patterns for capturing relations among opinion targets and relations among opinion words. However, the main limitation of Qiu’s method is that the patterns based on dependency parsing tree may miss many targets for the large corpora. Therefore, Zhang et al. (2010) extended Qiu’s method. Besides the patterns used in Qiu’s method, they adopted some other special designed patterns to increase recall. In addition they used the HITS (Kleinberg, 1999) algorithm to compute opinion target confidences to improve the precision. (Liu et al., 2012) formulated identifying opinion relations between words as an alignment process. They used a completely unsupervised WAM to capture opinion relations in sentences. Then the opinion targets were extracted in a standard random walk framework where two factors were considered: opinion relevance and target importance. Their experimental results have shown that WAM was more effective than traditional syntax-based methods for this task. (Liu et al., 2013) extend Liu’s method, which is similar to our method and also used a partially supervised alignment model to extract opinion targets from reviews. </context>
<context position="12505" citStr="Liu et al., 2012" startWordPosition="2010" endWordPosition="2013">xperiments on the corpora with a medium size. Although both of them proved that WAM model is better than the methods based on syntactic patterns, they didn’t discuss the performance variation when dealing with the corpora with different sizes, especially when the size of the corpus is less than 1,000 and more than 10,000. Based on their conclusions, we still don’t know which kind of methods should be selected for opinion target extraction when given a certain amount of reviews. 3 Opinion Target Extraction Methodology To extract opinion targets from reviews, we adopt the framework proposed by (Liu et al., 2012), which is a graph-based extraction framework and 1756 has two main components as follows. 1) The first component is to capture opinion relations in sentences and estimate associations between opinion target candidates and potential opinion words. In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). And a potential opinion relation is comprised of an opinion target candidate and its corresponding modified word. 2) The second c</context>
<context position="16061" citStr="Liu et al., 2012" startWordPosition="2582" endWordPosition="2585">ncy type. Pattern#1: &lt;OC&gt; mod −−−→&lt;TC&gt; Example: This phone has an amazing design Pattern#2: &lt;TC&gt; obj −−→&lt;OC&gt; Example: I like this phone very much Pattern#3: &lt;OC&gt;pnmod −−−−→&lt;TC&gt; Example: the buttons easier to use −−−→(NN) subj Pattern#4: &lt;OC&gt; mod ←−−−&lt;TC&gt; Example: IPhone is a revolutionary smart phone −−−→(VBE) subj Pattern#5: &lt;OC&gt; pred ←−−−&lt;TC&gt; Example: The quality of LCD is good Table 1: Some Examples of Used Syntactic Patterns 3.1.2 Unsupervised Word Alignment Model In this subsection, we present our method for capturing opinion relations using unsupervised word alignment model. Similar to (Liu et al., 2012), every sentence in reviews is replicated to generate a parallel sentence pair, and the word alignment algorithm is applied to the monolingual scenario to align a noun/noun phase with its modifiers. We select IBM-3 model (Brown et al., 1993) as the alignment model. Formally, given a sentence S = {w1, w2, ..., wn}, we have t(wj|waj)d(j|aj,N) (1) where t(wj|waj) models the co-occurrence information of two words in dataset. d(j|aj, n) models word position information, which describes the probability of a word in position aj aligned with a word in position j. And n(φi|wi) describes the ability of </context>
<context position="21272" citStr="Liu et al., 2012" startWordPosition="3452" endWordPosition="3455">Words After capturing opinion relations in sentences, we can obtain a lot of word pairs, each of which is comprised of an opinion target candidate and its corresponding modified word. Then the conditional probabilities between potential opinion target wt and potential opinion word wo can be estimated by using maximum likelihood estimation. Thus, we have P(wt|wo) = Count(wt,wo) Count(wo) , where Count(·) means the item’s frequency information. P(wt|wo) means the conditional probabilities between two words. At the same time, we can obtain conditional probability P(wo|wt). Then, 1758 similar to (Liu et al., 2012), the association between an opinion target candidate and its modifier is estimated as follows. Association(wt, wo) = (α × P(wt|wo) + (1 − α) × P(wo|wt))−1, where α is the harmonic factor. We set α = 0.5 in our experiments. 3.3 The Second Component: Estimating Candidate Confidence In the second component, we adopt a graph-based algorithm used in (Liu et al., 2012) to compute the confidence of each opinion target candidate, and the candidates with higher confidence than the threshold will be extracted as the opinion targets. Here, opinion words are regarded as the important indicators. We assum</context>
<context position="23346" citStr="Liu et al., 2012" startWordPosition="3813" endWordPosition="3816">fidence of each opinion target candidate, we employ a random walk algorithm on our graph, which iteratively computes the weighted average of opinion target confidences from neighboring vertices. Thus we have Ci+1 = (1 − β) × M × MT × Ci + β × I (3) where Ci+1 and Ci respectively represent the opinion target confidence vector in the (i + 1)th and ith iteration. M is the matrix of word associations, where Mi,j denotes the association between the opinion target candidate i and the potential opinion word j. And I is defined as the prior confidence of each candidate for opinion target. Similar to (Liu et al., 2012), we set each item in Iv = tf(v)idf(v) , where t vis the term freEv tf(v)idf(v) f (vis quency of v in the corpus, and df(v) is computed by using the Google n-gram corpus2. β ∈ [0, 1] represents the impact of candidate prior knowledge on the final estimation results. In experiments, we set β = 0.4. The algorithm run until convergence which is achieved when the confidence on each node ceases to change in a tolerance value. 4 Experiments 4.1 Datasets and Evaluation Metrics In this section, to answer the questions mentioned in the first section, we collect a large collection named as LARGE, which </context>
<context position="31121" citStr="Liu et al., 2012" startWordPosition="5101" endWordPosition="5104">nformation used in our graph based ranking algorithm. Compared with State-of-the-art Methods. However, it’s not say that this combination is not useful. From the results, we still see that PSWAM outperforms WAM in all datasets on precision when size of corpus is smaller than 5 x 104. To further prove the effectiveness of our combination, we compare PSWAM with some state-of-the-art methods, including Hu (Hu and Liu, 2004a), which extracted frequent opinion target words based on association mining rules, DP (Qiu et al., 2011), which extracted opinion targets through syntactic patterns, and LIU (Liu et al., 2012), which fulfilled this task by using unsupervised WAM. The parameter settings in these baselines are the same as the settings in the original papers. Because of the space limitation, we only show the results on Restaurant and Hotel, as shown in Figure 6 and 7. Figure 6: Compared with the State-of-the-art Methods on Restaurant Figure 7: Compared with the State-of-the-art Methods on Hotel From the experimental results, we can obtain the following observations. PSWAM outperforms other methods in most datasets. This indicates that our method based on PSWAM is effective for opinion target extractio</context>
</contexts>
<marker>Liu, Xu, Zhao, 2012</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opinion target extraction using word-based translation model. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1346–1356, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Yang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using partially supervised word alignment model.</title>
<date>2013</date>
<contexts>
<context position="6136" citStr="Liu et al., 2013" startWordPosition="992" endWordPosition="995">ich we vary the methods between syntactic patterns and alignment model. Then we run the whole framework on the corpus with different size (from #500 to #1, 000, 000), domain (three domains) and language (Chinese and English) to empirically assess the performance variations and discuss which method is more effective. Furthermore, this paper naturally addresses another question: is it useful for opinion targets extraction when we combine syntactic patterns and word alignment model into a unified model? To this end, we employ a partially supervised alignment model (PSWAM) like (Gao et al., 2010; Liu et al., 2013). Based on the exquisitely designed high-precision syntactic patterns, we can obtain some precisely modified relations between words in sentences, which provide a portion of links of the full alignments. Then, these partial alignment links can be regarded as the constrains for a standard unsupervised word alignment model. And each target candidate would find its modifier under the partial supervision. In this way, the errors generated in standard unsupervised WAM can be corrected. For example in Figure 1, “kindly” and “courteous” are incorrectly regarded as the modifiers for “foods” if the WAM</context>
<context position="11653" citStr="Liu et al., 2013" startWordPosition="1866" endWordPosition="1869">ns to increase recall. In addition they used the HITS (Kleinberg, 1999) algorithm to compute opinion target confidences to improve the precision. (Liu et al., 2012) formulated identifying opinion relations between words as an alignment process. They used a completely unsupervised WAM to capture opinion relations in sentences. Then the opinion targets were extracted in a standard random walk framework where two factors were considered: opinion relevance and target importance. Their experimental results have shown that WAM was more effective than traditional syntax-based methods for this task. (Liu et al., 2013) extend Liu’s method, which is similar to our method and also used a partially supervised alignment model to extract opinion targets from reviews. We notice these two methods ((Liu et al., 2012) and (Liu et al., 2013)) only performed experiments on the corpora with a medium size. Although both of them proved that WAM model is better than the methods based on syntactic patterns, they didn’t discuss the performance variation when dealing with the corpora with different sizes, especially when the size of the corpus is less than 1,000 and more than 10,000. Based on their conclusions, we still don’</context>
</contexts>
<marker>Liu, Xu, Liu, Zhao, 2013</marker>
<rawString>Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013. Opinion target extraction using partially supervised word alignment model.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tengfei Ma</author>
<author>Xiaojun Wan</author>
</authors>
<title>Opinion target extraction in chinese news comments.</title>
<date>2010</date>
<booktitle>In ChuRen Huang and</booktitle>
<pages>782--790</pages>
<editor>Dan Jurafsky, editors, COLING (Posters),</editor>
<contexts>
<context position="8286" citStr="Ma and Wan, 2010" startWordPosition="1334" endWordPosition="1337">rimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. And classical sequence labeling models are used to train the extractor, such as CRFs (Li et al., 2010), HMM (Jin and Huang, 2009) etc.. Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Both Li et al. (2010) and Ma et al. (2010) used CRFs model to extract opinion targets in reviews. Specially, Li et </context>
</contexts>
<marker>Ma, Wan, 2010</marker>
<rawString>Tengfei Ma and Xiaojun Wan. 2010. Opinion target extraction in chinese news comments. In ChuRen Huang and Dan Jurafsky, editors, COLING (Posters), pages 782–790. Chinese Information Processing Society of China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>339--346</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2073" citStr="Popescu and Etzioni, 2005" startWordPosition="338" endWordPosition="341">ons from these reviews become more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and L</context>
<context position="7994" citStr="Popescu and Etzioni, 2005" startWordPosition="1287" endWordPosition="1290"> performance by using partial supervision. However, is this kind of combination always useful for opinion target extraction? To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. And classical sequence labeling model</context>
<context position="10112" citStr="Popescu and Etzioni, 2005" startWordPosition="1633" endWordPosition="1636">which are mainly to extract a list of opinion targets from reviews. Similar to ours, most approaches regarded opinion words as the indicator for opinion targets. (Hu and Liu, 2004a) regarded the nearest adjective to an noun/noun phrase as its modifier. Then it exploited an association rule mining algorithm to mine the associations between them. Finally, the frequent explicit product features can be extracted in a bootstrapping process by further combining item’s frequency in dataset. Only using nearest neighbor rule to mine the modifier for each candidate cannot obtain precise results. Thus, (Popescu and Etzioni, 2005) used syntax information to extract opinion targets, which designed some syntactic patterns to capture the modified relations between words. The experimental results showed that their method had better performance than (Hu and Liu, 2004a). Moreover, (Qiu et al., 2011) proposed a Double Propagation method to expand sentiment words and opinion targets iteratively, where they also exploited syntactic relations between words. Specially, (Qiu et al., 2011) didn’t only design syntactic patterns for capturing modified relations, but also designed patterns for capturing relations among opinion targets</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 339–346, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Che</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<contexts>
<context position="3056" citStr="Qiu et al., 2009" startWordPosition="490" endWordPosition="493">, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and Liu, 2004a; Hu and Liu, 2004b). Obviously, these methods cannot obtain precise extraction because of the diverse expressions by reviewers, like long-span modified relations between words, etc. To handle this problem, several methods exploited syntactic information, where several heuristic patterns based on syntactic parsing were designed (Popescu and Etzioni, 2005; Qiu et al., 2009; Qiu et al., 2011). However, the sentences in online reviews usually have informal writing styles including grammar mistakes, typos, improper punctuation etc., which make parsing prone to generate mistakes. As a result, the syntax-based methods which heavily depended on the parsing performance would suffer from parsing errors (Zhang et al., 2010). To improve the extraction performance, we can only employ some exquisite highprecision patterns. But this strategy is likely to miss many opinion targets and has lower recall with the increase of corpus size. To resolve these problems, Liu et al. (2</context>
</contexts>
<marker>Qiu, Liu, Bu, Che, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Che. 2009. Expanding domain sentiment lexicon through double propagation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu 0001, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational Linguistics, 37(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Wang</author>
<author>Houfeng Wang</author>
</authors>
<title>Bootstrapping both product features and opinion words from chinese customer reviews with cross-inducing.</title>
<date>2008</date>
<contexts>
<context position="2112" citStr="Wang and Wang, 2008" startWordPosition="346" endWordPosition="349">rgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. In opinion mining, extracting opinion targets is a basic subtask. It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. So this task has attracted many attentions. To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011; Liu et al., 2012). Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and Liu, 2004a; Hu and Liu, 2004b). Obviousl</context>
<context position="12955" citStr="Wang and Wang, 2008" startWordPosition="2085" endWordPosition="2088">given a certain amount of reviews. 3 Opinion Target Extraction Methodology To extract opinion targets from reviews, we adopt the framework proposed by (Liu et al., 2012), which is a graph-based extraction framework and 1756 has two main components as follows. 1) The first component is to capture opinion relations in sentences and estimate associations between opinion target candidates and potential opinion words. In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). And a potential opinion relation is comprised of an opinion target candidate and its corresponding modified word. 2) The second component is to estimate the confidence of each candidate. The candidates with higher confidence scores than a threshold will be extracted as opinion targets. In this procedure, we formulate the associations between opinion target candidates and potential opinion words in a bipartite graph. A random walk based algorithm is employed on this graph to estimate the confidence of each target candidate. In this paper, we fix the method in the second com</context>
</contexts>
<marker>Wang, Wang, 2008</marker>
<rawString>Bo Wang and Houfeng Wang. 2008. Bootstrapping both product features and opinion words from chinese customer reviews with cross-inducing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Latent aspect rating analysis without aspect keyword supervision.</title>
<date>2011</date>
<pages>618--626</pages>
<editor>In Chid Apt, Joydeep Ghosh, and Padhraic Smyth, editors, KDD,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="24362" citStr="Wang et al., 2011" startWordPosition="3997" endWordPosition="4000">ange in a tolerance value. 4 Experiments 4.1 Datasets and Evaluation Metrics In this section, to answer the questions mentioned in the first section, we collect a large collection named as LARGE, which includes reviews from three different domains and different languages. This collection was also used in (Liu et al., 2012). In the experiments, reviews are first segmented into sentences according to punctuation. The detailed statistical information of the used collection is shown in Table 2, where Restaurant is crawled from the Chinese Web site: www.dianping.com. The Hotel and MP3 are used in (Wang et al., 2011), which are respectively crawled from www.tripadvisor.com and www.amazon.com. For each dataset, we perform random sampling to generate testing set with different sizes, where we use sampled subsets with #sentences = 5 × 102, 103, 5 × 103, 104, 5 × 104, 105 and 106 sentences respectively. Each Domain Language Sentence Reviews Restaurant Chinese 1,683,129 395,124 Hotel English 1,855,351 185,829 MP3 English 289,931 30,837 Table 2: Experimental Dataset sentence is tokenized, part-of-speech tagged by using Stanford NLP tool3, and parsed by using Minipar toolkit. And the method of (Zhu et al., 2009)</context>
</contexts>
<marker>Wang, Lu, Zhai, 2011</marker>
<rawString>Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Chid Apt, Joydeep Ghosh, and Padhraic Smyth, editors, KDD, pages 618–626. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining. In</title>
<date>2009</date>
<booktitle>EMNLP,</booktitle>
<pages>1533--1541</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="8012" citStr="Wu et al., 2009" startWordPosition="1291" endWordPosition="1294">al supervision. However, is this kind of combination always useful for opinion target extraction? To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. And classical sequence labeling models are used to trai</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In EMNLP, pages 1533–1541. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Zhang</author>
<author>Yuanbin Wu</author>
<author>Tao Li</author>
<author>Mitsunori Ogihara</author>
<author>Joseph Johnson</author>
<author>Xuanjing Huang</author>
</authors>
<title>Mining product reviews based on shallow dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09,</booktitle>
<pages>726--727</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8324" citStr="Zhang et al., 2009" startWordPosition="1342" endWordPosition="1345">on by using PSWAM can be effective on dataset with small and medium size. 1755 2 Related Work Opinion target extraction isn’t a new task for opinion mining. There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al., 2008; Li et al., 2010; Popescu and Etzioni, 2005; Wu et al., 2009). Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al., 2010; Ma and Wan, 2010; Wu et al., 2009; Zhang et al., 2009). It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. And classical sequence labeling models are used to train the extractor, such as CRFs (Li et al., 2010), HMM (Jin and Huang, 2009) etc.. Jin et al. (2009) proposed a lexicalized HMM model to perform opinion mining. Both Li et al. (2010) and Ma et al. (2010) used CRFs model to extract opinion targets in reviews. Specially, Li et al. proposed a Skip-Tree CRF model for</context>
</contexts>
<marker>Zhang, Wu, Li, Ogihara, Johnson, Huang, 2009</marker>
<rawString>Qi Zhang, Yuanbin Wu, Tao Li, Mitsunori Ogihara, Joseph Johnson, and Xuanjing Huang. 2009. Mining product reviews based on shallow dependency parsing. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09, pages 726–727, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
</authors>
<title>Suk Hwan Lim, and Eamonn O’Brien-Strain.</title>
<date>2010</date>
<booktitle>In ChuRen Huang</booktitle>
<pages>1462--1470</pages>
<editor>and Dan Jurafsky, editors, COLING (Posters),</editor>
<marker>Zhang, Liu, 2010</marker>
<rawString>Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O’Brien-Strain. 2010. Extracting and ranking product features in opinion documents. In ChuRen Huang and Dan Jurafsky, editors, COLING (Posters), pages 1462–1470. Chinese Information Processing Society of China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingbo Zhu</author>
<author>Huizhen Wang</author>
<author>Benjamin K Tsou</author>
<author>Muhua Zhu</author>
</authors>
<title>Multi-aspect opinion polling from textual reviews. In</title>
<date>2009</date>
<pages>1799--1802</pages>
<editor>David Wai-Lok Cheung, Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and Jimmy J. Lin, editors, CIKM,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="24962" citStr="Zhu et al., 2009" startWordPosition="4090" endWordPosition="4093">ang et al., 2011), which are respectively crawled from www.tripadvisor.com and www.amazon.com. For each dataset, we perform random sampling to generate testing set with different sizes, where we use sampled subsets with #sentences = 5 × 102, 103, 5 × 103, 104, 5 × 104, 105 and 106 sentences respectively. Each Domain Language Sentence Reviews Restaurant Chinese 1,683,129 395,124 Hotel English 1,855,351 185,829 MP3 English 289,931 30,837 Table 2: Experimental Dataset sentence is tokenized, part-of-speech tagged by using Stanford NLP tool3, and parsed by using Minipar toolkit. And the method of (Zhu et al., 2009) is used to identify noun phrases. 2http://books.google.com/ngrams/datasets 3http://nlp.stanford.edu/software/tagger.shtml 1759 We select precision and recall as the metrics. Specifically, to obtain the ground truth, we manually label all opinion targets for each subset. In this process, three annotators are involved. First, every noun/noun phrase and its contexts in review sentences are extracted. Then two annotators were required to judge whether every noun/noun phrase is opinion target or not. If a conflict happens, a third annotator will make judgment for final results. The average inter-a</context>
</contexts>
<marker>Zhu, Wang, Tsou, Zhu, 2009</marker>
<rawString>Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and Muhua Zhu. 2009. Multi-aspect opinion polling from textual reviews. In David Wai-Lok Cheung, Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and Jimmy J. Lin, editors, CIKM, pages 1799–1802. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>