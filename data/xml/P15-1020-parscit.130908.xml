<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000099">
<title confidence="0.9991145">
Syntax-based Simultaneous Translation
through Prediction of Unseen Syntactic Constituents
</title>
<author confidence="0.995353">
Yusuke Oda Graham Neubig Sakriani Sakti Tomoki Toda Satoshi Nakamura
</author>
<affiliation confidence="0.939966">
Graduate School of Information Science
Nara Institute of Science and Technology
Takayamacho, Ikoma, Nara 630-0192, Japan
</affiliation>
<email confidence="0.933326">
{oda.yusuke.on9, neubig, ssakti, tomoki, s-nakamura}@is.naist.jp
</email>
<sectionHeader confidence="0.996541" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999963045454546">
Simultaneous translation is a method to
reduce the latency of communication
through machine translation (MT) by di-
viding the input into short segments be-
fore performing translation. However,
short segments pose problems for syntax-
based translation methods, as it is diffi-
cult to generate accurate parse trees for
sub-sentential segments. In this paper,
we perform the first experiments applying
syntax-based SMT to simultaneous trans-
lation, and propose two methods to pre-
vent degradations in accuracy: a method to
predict unseen syntactic constituents that
help generate complete parse trees, and a
method that waits for more input when the
current utterance is not enough to gener-
ate a fluent translation. Experiments on
English-Japanese translation show that the
proposed methods allow for improvements
in accuracy, particularly with regards to
word order of the target sentences.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.978292232558139">
Speech translation is an application of machine
translation (MT) that converts utterances from the
speaker’s language into the listener’s language.
One of the most identifying features of speech
translation is the fact that it must be performed
in real time while the speaker is speaking, and
thus it is necessary to split a constant stream
of words into translatable segments before start-
ing the translation process. Traditionally, speech
translation assumes that each segment corresponds
to a sentence, and thus performs sentence bound-
ary detection before translation (Matusov et al.,
2006). However, full sentences can be long, par-
ticularly in formal speech such as lectures, and
if translation does not start until explicit ends of
Figure 1: Simultaneous translation where the
source sentence is segmented after “I think” and
translated according to (a) the standard method,
(b) Grissom II et al. (2014)’s method of final verb
prediction, and (c) our method of predicting syn-
tactic constituents.
sentences, listeners may be forced to wait a con-
siderable time until receiving the result of trans-
lation. For example, when the speaker continues
to talk for 10 seconds, listeners must wait at least
10 seconds to obtain the result of translation. This
is the major factor limiting simultaneity in tradi-
tional speech translation systems.
Simultaneous translation (Section 2) avoids this
problem by starting to translate before observing
the whole sentence, as shown in Figure 1 (a).
However, as translation starts before the whole
sentence is observed, translation units are often
not syntactically or semantically complete, and the
performance may suffer accordingly. The dele-
terious effect of this missing information is less
worrying in largely monotonic language pairs (e.g.
English-French), but cannot be discounted in syn-
tactically distant language pairs (e.g. English-
Japanese) that often require long-distance reorder-
ing beyond translation units.
One way to avoid this problem of missing infor-
mation is to explicitly predict information needed
</bodyText>
<page confidence="0.970648">
198
</page>
<note confidence="0.988787">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 198–207,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999602">
Figure 2: Process of English-Japanese simultaneous translation with sentence segmentation.
</figureCaption>
<bodyText confidence="0.999977446428572">
to translate the content accurately. An ambitious
first step in this direction was recently proposed
by Grissom II et al. (2014), who describe a method
that predicts sentence-final verbs using reinforce-
ment learning (e.g. Figure 1 (b)). This approach
has the potential to greatly decrease the delay
in translation from verb-final languages to verb-
initial languages (such as German-English), but is
also limited to only this particular case.
In this paper, we propose a more general
method that focuses on a different variety of in-
formation: unseen syntactic constituents. This
method is motivated by our desire to apply trans-
lation models that use source-side parsing, such
as tree-to-string (T2S) translation (Huang et al.,
2006) or syntactic pre-ordering (Xia and McCord,
2004), which have been shown to greatly improve
translation accuracy over syntactically divergent
language pairs. However, conventional methods
for parsing are not directly applicable to the par-
tial sentences that arise in simultaneous MT. The
reason for this, as explained in detail in Section
3, is that parsing methods generally assume that
they are given input that forms a complete syntac-
tic phrase. Looking at the example in Figure 1,
after the speaker has spoken the words “I think”
we have a partial sentence that will only be com-
plete once we observe the following SBAR. Our
method attempts to predict exactly this informa-
tion, as shown in Figure 1 (c), guessing the re-
maining syntactic constituents that will allow us
to acquire a proper parse tree.
Specifically the method consists of two parts:
First, we propose a method that trains a statisti-
cal model to predict future syntactic constituents
based on features of the input segment (Section 4).
Second, we demonstrate how to apply this syntac-
tic prediction to MT, including the proposal of a
heuristic method that examines whether a future
constituent has the potential to cause a reordering
problem during translation, and wait for more in-
put in these cases (Section 5).
Based on the proposed method, we perform ex-
periments in simultaneous translation of English-
Japanese talks (Section 6). As this is the first work
applying T2S translation to simultaneous MT, we
first compare T2S to more traditional phrase-based
techniques. We find that T2S translation is effec-
tive with longer segments, but drops off quickly
with shorter segments, justifying the need for tech-
niques to handle translation when full context is
not available. We then compare the proposed
method of predicting syntactic constituents, and
find that it improves translation results, particu-
larly with respect to word ordering in the output
sentences.
</bodyText>
<sectionHeader confidence="0.962058" genericHeader="introduction">
2 Simultaneous Translation
</sectionHeader>
<bodyText confidence="0.9997866">
In simultaneous translation, we assume that we are
given an incoming stream of words f, which we
are expected to translate. As the f is long, we
would like to begin translating before we reach the
end of the stream. Previous methods to do so can
generally be categorized into incremental decod-
ing methods, and sentence segmentation methods.
In incremental decoding, each incoming word is
fed into the decoder one-by-one, and the decoder
updates the search graph with the new words and
decides whether it should begin translation. Incre-
mental decoding methods have been proposed for
phrase-based (Sankaran et al., 2010; Yarmoham-
madi et al., 2013; Finch et al., 2014) and hierar-
chical phrase-based (Siahbani et al., 2014) SMT
</bodyText>
<page confidence="0.998248">
199
</page>
<bodyText confidence="0.999964378378378">
models.1 Incremental decoding has the advantage
of using information about the decoding graph in
the choice of translation timing, but also requires
significant changes to the internal workings of the
decoder, precluding the use of standard decoding
tools or techniques.
Sentence segmentation methods (Figure 2)
provide a simpler alternative by first divid-
ing f into subsequences of 1 or more words
[f(1), ... , f(N)]. These segments are then trans-
lated with a traditional decoder into output se-
quences [e(1), ... , e(N)], which each are output as
soon as translation finishes. Many methods have
been proposed to perform segmentation, includ-
ing the use of prosodic boundaries (F¨ugen et al.,
2007; Bangalore et al., 2012), predicting punc-
tuation marks (Rangarajan Sridhar et al., 2013),
reordering probabilities of phrases (Fujita et al.,
2013), or models to explicitly optimize translation
accuracy (Oda et al., 2014). Previous work often
assumes that f is a single sentence, and focus on
sub-sentential segmentation, an approach we fol-
low in this work.
Sentence segmentation methods have the obvi-
ous advantage of allowing for translation as soon
as a segment is decided. However, the use of the
shorter segments also makes it necessary to trans-
late while part of the utterance is still unknown. As
a result, segmenting sentences more aggressively
often results in a decrease translation accuracy.
This is a problem in phrase-based MT, the frame-
work used in the majority of previous research on
simultaneous translation. However, it is an even
larger problem when performing translation that
relies on parsing the input sentence. We describe
the problems caused by parsing a segment f(�),
and solutions, in the following section.
</bodyText>
<sectionHeader confidence="0.847062" genericHeader="method">
3 Parsing Incomplete Sentences
</sectionHeader>
<subsectionHeader confidence="0.996586">
3.1 Difficulties in Incomplete Parsing
</subsectionHeader>
<bodyText confidence="0.9999895">
In standard phrase structure parsing, the parser as-
sumes that each input string is a complete sen-
tence, or at least a complete phrase. For example,
Figure 3 (a) shows the phrase structure of the com-
plete sentence “this is a pen.” However, in the case
of simultaneous translation, each translation unit
</bodyText>
<footnote confidence="0.9643774">
1There is also one previous rule-based system that uses
syntax in incremental translation, but it is language specific
and limited domain (Ryu et al., 2006), and thus difficult to
compare with our SMT-based system. It also does not predict
unseen constituents, relying only on the observed segment.
</footnote>
<figureCaption confidence="0.9797185">
Figure 3: Phrase structures with surrounding syn-
tactic constituents.
</figureCaption>
<bodyText confidence="0.999925541666666">
is not necessarily segmented in a way that guar-
antees that the translation unit is a complete sen-
tence, so each translation unit should be treated
not as a whole, but as a part of a spoken sentence.
As a result, the parser input may be an incomplete
sequence of words (e.g. “this is,” “is a”), and a
standard parser will generate an incorrect parse as
shown in Figures 3(b) and 3(c).
The proposed method solves this problem by
supplementing unseen syntactic constituents be-
fore and after the translation unit. For example,
considering parse trees for the complete sentence
in Figure 3(a), we see that a noun phrase (NP) can
be placed after the translation unit “this is.” If we
append the syntactic constituent NP as a “black
box” before parsing, we can create a syntactically
desirable parse tree as shown in Figure 3(d1) We
also can construct another tree as shown in Fig-
ure 3(d2) by appending two constituents DT and
NN . For the other example “is a,” we can create
the parse tree in Figure 3(e1) by appending NP
before the unit and NN after the unit, or can cre-
ate the tree in Figure 3(e2) by appending only NN
after the unit.
</bodyText>
<subsectionHeader confidence="0.999923">
3.2 Formulation of Incomplete Parsing
</subsectionHeader>
<bodyText confidence="0.999889">
A typical model for phrase structure parsing is the
probabilistic context-free grammar (PCFG). Pars-
ing is performed by finding the parse tree T that
</bodyText>
<page confidence="0.961399">
200
</page>
<bodyText confidence="0.998404">
maximizes the PCFG probability given a sequence
of words w ≡ [w1, w2, · · · , w,,,] as shown by Eq.
(2):
</bodyText>
<equation confidence="0.999108625">
T* ≡ arg max Pr(T |w) (1)
T
≃ arg max [
T
∑ log Pr(X → [Y, · · ·]) +
(X→[Y,···])ET
∑ log Pr(X → wz) ], (2)
(X→wi)ET
</equation>
<bodyText confidence="0.984426318181818">
where Pr(X → [Y, · · ·]) represents the genera-
tive probabilities of the sequence of constituents
[Y, · · ·] given a parent constituent X, and Pr(X →
wz) represents the generative probabilities of each
word wz (1 ≤ i ≤ n) given a parent constituent
X.
To consider parsing of incomplete sentences
with appended syntactic constituents, We define
L ≡ [L|L|, · · · , L2, L1] as the sequence of pre-
ceding syntactic constituents of the translation unit
and R ≡ [R1, R2, · · · , R|R|] as the sequence of
following syntactic constituents of the translation
unit. For the example Figure 3(d1), we assume
that L = [ ] and R = [ NP ].
We assume that both sequences of syntactic
constituents L and R are predicted based on the
sequence of words w before the main parsing step.
Thus, the whole process of parsing incomplete
sentences can be described as the combination of
predicting both sequences of syntactic constituents
represented by Eq. (3) and (4) and parsing with
predicted syntactic constituents represented by Eq.
</bodyText>
<equation confidence="0.981258857142857">
(5):
L* ≡ arg max Pr(L|w),
L
R* ≡ arg max Pr(R|w),
R
T* ≡ arg max Pr(T|L*, w, R*).
T
</equation>
<bodyText confidence="0.99997525">
Algorithmically, parsing with predicted syntac-
tic constituents can be achieved by simply treating
each syntactic constituent as another word in the
input sequence and using a standard parsing algo-
rithm such as the CKY algorithm. In this process,
the only difference between syntactic constituents
and normal words is the probability, which we de-
fine as follows:
</bodyText>
<equation confidence="0.9431365">
Pr(X → Y 1, ifY=X ) ≡6
{ 0, otherwise. ( )
</equation>
<bodyText confidence="0.999894214285714">
It should be noted that here L refers to syntac-
tic constituents that have already been seen in the
past. Thus, it is theoretically possible to store past
parse trees as history and generate L based on this
history, or condition Eq. 3 based on this infor-
mation. However, deciding which part of trees to
use as L is not trivial, and applying this approach
requires that we predict L and R using different
methods. Thus, in this study, we use the same
method to predict both sequences of constituents
for simplicity.
In the next section, we describe the actual
method used to create a predictive model for these
strings of syntactic constituents.
</bodyText>
<sectionHeader confidence="0.986501" genericHeader="method">
4 Predicting Syntactic Constituents
</sectionHeader>
<bodyText confidence="0.999943">
In order to define which syntactic constituents
should be predicted by our model, we assume that
each final parse tree generated by w, L and R
must satisfy the following conditions:
</bodyText>
<listItem confidence="0.980697111111111">
1. The parse tree generated by w, L and R must
be “complete.” Defining this formally, this
means that the root node of the parse tree for
the segment must correspond to a node in the
parse tree for the original complete sentence.
2. Each parse tree contains only L, w and R as
terminal symbols.
3. The number of nodes is the minimum neces-
sary to satisfy these conditions.
</listItem>
<bodyText confidence="0.998845">
As shown in the Figure 3, there is ambiguity re-
garding syntactic constituents to be predicted (e.g.
we can choose either [ NP ] or [ DT , NN ] as R
for w = [ “this”, “is” ]). These conditions avoid
ambiguity of which syntactic constituents should
predicted for partial sentences in the training data.
Looking at the example, Figures 3(d1) and 3(e1)
satisfy these conditions, but 3(d2) and 3(e2) do
not.
Figure 4 shows the statistics of the lengths of
L and R sequences extracted according to these
criteria for all substrings of the WSJ datasets 2 to
23 of the Penn Treebank (Marcus et al., 1993), a
standard training set for English syntactic parsers.
From the figure we can see that lengths of up to 2
constituents cover the majority of cases for both L
and R, but a significant number of cases require
longer strings. Thus methods that predict a fixed
number of constituents are not appropriate here. In
Algorithm 1, we show the method we propose to
</bodyText>
<page confidence="0.99605">
201
</page>
<figureCaption confidence="0.993659">
Figure 4: Statistics of numbers of syntactic con-
stituents to be predicted.
</figureCaption>
<bodyText confidence="0.979785774193548">
predict R for constituent sequences of an arbitrary
length. Here * represents the concatenation of
two sequences.
First, our method forcibly parses the input se-
quence w and retrieves a potentially incorrect
parse tree T′, which is used to calculate features
for the prediction model. The next syntactic con-
stituent R+ is then predicted using features ex-
tracted from w, T′, and the predicted sequence
history R*. This prediction is repeated recurrently
until the end-of-sentence symbol (“nil” in Algo-
rithm 1) is predicted as the next symbol.
In this study, we use a multi-label classifier
based on linear SVMs (Fan et al., 2008) to predict
new syntactic constituents with features shown
in Table 1. We treat the input sequence w and
predicted syntactic constituents R* as a concate-
nated sequence w * R*. For example, if we have
w = [ this, is, a ] and R* = [ NN ], then the
word features “3 rightmost 1-grams” will take the
values “is,” “a,” and NN . Tags of semi-terminal
nodes in T′ are used as part-of-speech (POS) tags
for corresponding words and the POS of each pre-
dicted syntactic constituent is simply its tag. “nil”
is used when some information is not available.
For example, if we have w = [ this, is ] and
R* = [ ] then “3 rightmost 1-grams” will take the
values “nil,” “this,” and “is.” Algorithm 1 and Ta-
ble 1 shows the method used to predict R* but L*
can be predicted by performing the prediction pro-
cess in the reverse order.
</bodyText>
<sectionHeader confidence="0.998017" genericHeader="method">
5 Tree-to-string SMT with Syntactic
Constituents
</sectionHeader>
<bodyText confidence="0.9979164">
Once we have created a tree from the sequence
L* * w * R* by performing PCFG parsing with
predicted syntactic constituents according to Eqs.
(2), (5), and (6), the next step is to use this tree in
translation. In this section, we focus specifically
</bodyText>
<equation confidence="0.890331083333333">
Algorithm 1 Prediction algorithm for following
constituents R*
T′ ← arg max Pr(T |w)
T
R* ← [ ]
loop
R+ ← arg max Pr(R|T′, R*)
R
if R+ = nil then
return R*
end if
R* ← R* *[R+]
</equation>
<tableCaption confidence="0.786263">
end loop
Table 1: Features used in predicting syntactic con-
stituents.
</tableCaption>
<table confidence="0.9963117">
Type Feature
Words 3 leftmost 1,2-grams in w * R*
3 rightmost 1,2-grams in w * R*
Left/rightmost pair in w * R*
POS Same as “Words”
Parse Tag of the root node
Tags of children of the root node
Pairs of root and children nodes
Length |w|
|R*|
</table>
<bodyText confidence="0.9993285">
on T2S translation, which we use in our experi-
ments, but it is likely that similar methods are ap-
plicable to other uses of source-side syntax such
as pre-ordering as well.
It should be noted that using these trees in T2S
translation models is not trivial because each esti-
mated syntactic constituent should be treated as an
aggregated entity representing all possibilities of
subtrees rooted in such a constituent. Specifically,
there are two problems: the possibility of reorder-
ing an as-of-yet unseen syntactic constituent into
the middle of the translated sentence, and the cal-
culation of language model probabilities consider-
ing syntactic constituent tags.
With regards to the first problem of reordering,
consider the example of English-Japanese transla-
tion in Figure 5(b), where a syntactic constituent
PP is placed at the end of the English sequence
(R*), but the corresponding entity in the Japanese
translation result should be placed in the middle of
the sentence. In this case, if we attempt to translate
immediately, we will have to omit the as-of-yet
unknown PP from our translation and translate it
later, resulting in an unnatural word ordering in the
</bodyText>
<page confidence="0.997659">
202
</page>
<figureCaption confidence="0.997145">
Figure 5: Waiting for the next translation unit.
</figureCaption>
<bodyText confidence="0.99013825">
target sentence.2
Thus, if any of the syntactic constituents in R
are placed anywhere other than the end of the
translation result, we can assume that this is a hint
that the current segmentation boundary is not ap-
propriate. Based on this intuition, we propose a
heuristic method that ignores segmentation bound-
aries that result in a translation of this type, and in-
stead wait for the next translation unit, helping to
avoid problems due to inappropriate segmentation
boundaries. Algorithm 2 formally describes this
waiting method.
The second problem of language model proba-
bilities arises because we are attempting to gener-
ate a string of words, some of which are not actual
words but tags representing syntactic constituents.
Creating a language model that contains probabil-
ities for these tags in the appropriate places is not
trivial, so for simplicity, we simply assume that ev-
ery syntactic constituent tag is an unknown word,
and that the output of translation consists of both
translated normal words and non-translated tags as
shown in Figure 5. We relegate a more complete
handling of these tags to future work.
</bodyText>
<footnote confidence="0.9936466">
2It is also potentially possible to create a predictive model
for the actual content of the PP as done for sentence-final
verbs by Grissom II et al. (2014), but the space of potential
prepositional phrases is huge, and we leave this non-trivial
task for future work.
</footnote>
<equation confidence="0.883002588235294">
Algorithm 2 Waiting algorithm for T2S SMT
w ← [ ]
loop
w ← w * NextSegment()
L* ← arg max Pr(L|w)
L
R* ← arg max Pr(R|w)
R
T* ← arg max Pr(T|L*, w, R*)
T
e* ← arg max
e
if elements of R* are rightmost in e* then
Output(e*)
w ← [ ]
end if
end loop
</equation>
<sectionHeader confidence="0.998365" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999556">
6.1 Experiment Settings
</subsectionHeader>
<bodyText confidence="0.9999745">
We perform 2 types of experiments to evaluate the
effectiveness of the proposed methods.
</bodyText>
<subsectionHeader confidence="0.962662">
6.1.1 Predicting Syntactic Constituents
</subsectionHeader>
<bodyText confidence="0.999954153846154">
In the first experiment, we evaluate prediction ac-
curacies of unseen syntactic constituents L and R.
To do so, we train a predictive model as described
in Section 4 using an English treebank and evalu-
ate its performance. To create training and testing
data, we extract all substrings w s.t. |w |≥ 2 in
the Penn Treebank and calculate the correspond-
ing syntactic constituents L and R by according
to the original trees and substring w. We use the
90% of the extracted data for training a classifier
and the remaining 10% for testing estimation re-
call, precision and F-measure. We use the Ckylark
parser(Oda et al., 2015) to generate T′ from w.
</bodyText>
<subsectionHeader confidence="0.733139">
6.1.2 Simultaneous Translation
</subsectionHeader>
<bodyText confidence="0.999668833333333">
Next, we evaluate the performance of T2S si-
multaneous translation adopting the two proposed
methods. We use data of TED talks from the
English-Japanese section of WIT3 (Cettolo et al.,
2012), and also append dictionary entries and ex-
amples in Eijiro3 to the training data to increase
the vocabulary of the translation model. The total
number of sentences/entries is 2.49M (WIT3, Ei-
jiro), 998 (WIT3), and 468 (WIT3) sentences for
training, development, and testing respectively.
We use the Stanford Tokenizer4 for English
tokenization, KyTea (Neubig et al., 2011) for
</bodyText>
<footnote confidence="0.994372">
3http://eijiro.jp/
4http://nlp.stanford.edu/software/tokenizer.shtml
</footnote>
<figure confidence="0.9564805">
(a) (b)
Pr(e|T*)
</figure>
<page confidence="0.998349">
203
</page>
<bodyText confidence="0.997852545454545">
Japanese tokenization, GIZA++ (Och and Ney,
2003) to construct word alignment, and KenLM
(Heafield et al., 2013) to generate a 5-gram target
language model. We use the Ckylark parser, which
we modified to implement the parsing method of
Section 3.2, to generate T* from L*, w and R*.
We use Travatar (Neubig, 2013) to train the T2S
translation model used in the proposed method,
and also Moses (Koehn et al., 2007) to train
phrase-based translation models that serve as a
baseline. Each translation model is tuned us-
ing MERT (Och, 2003) to maximize BLEU (Pa-
pineni et al., 2002). We evaluate translation ac-
curacies by BLEU and also RIBES (Isozaki et
al., 2010), a reordering-focused metric which has
achieved high correlation with human evaluation
on English-Japanese translation tasks.
We perform tests using two different sentence
segmentation methods. The first is n-words seg-
mentation (Rangarajan Sridhar et al., 2013), a sim-
ple heuristic that simply segments the input ev-
ery n words. This method disregards syntactic
and semantic units in the original sentence, al-
lowing us to evaluate the robustness of translation
against poor segmentation boundaries. The second
method is the state-of-the-art segmentation strat-
egy proposed by Oda et al. (2014), which finds
segmentation boundaries that optimize the accu-
racy of the translation output. We use BLEU+1
(Lin and Och, 2004) as the objective of this seg-
mentation strategy.
We evaluate the following baseline and pro-
posed methods:
PBMT is a baseline using phrase-based SMT.
T2S uses T2S SMT with parse trees generated
from only w.
T2S-Tag further predicts unseen syntactic con-
stituents according to Section 4. Before eval-
uation, all constituent tags are simply deleted
from the output.
T2S-Wait uses T2S-Tag and adds the waiting
strategy described in Section 5.
We also show PBMT-Sent and T2S-Sent which
are full sentence-based PBMT and T2S systems.
</bodyText>
<subsectionHeader confidence="0.9136595">
6.2 Results
6.2.1 Predicting Syntactic Constituents
</subsectionHeader>
<bodyText confidence="0.785578">
Table 2 shows the recall, precision, and F-measure
of the estimated L and R sequences. The table
</bodyText>
<tableCaption confidence="0.9326735">
Table 2: Performance of syntactic constituent pre-
diction.
</tableCaption>
<table confidence="0.9856256">
Target P % R % F %
L (ordered) 31.93 7.27 11.85
(unordered) 51.21 11.66 19.00
R (ordered) 51.12 33.78 40.68
(unordered) 52.77 34.87 42.00
</table>
<bodyText confidence="0.99703547826087">
shows results of two evaluation settings, where
the order of generated constituents is considered
or not.
We can see that in each case recall is lower than
the corresponding precision and the performance
of L differs between ordered and unordered re-
sults. These trends result from the fact that the
model generates fewer constituents than exist in
the test data. However, this trend is not entirely un-
expected because it is not possible to completely
accurately guess syntactic constituents from every
substring w. For example, parts of the sentence
“in the next 18 minutes” can generate the sequence
“in the next CD NN ” and “ IN DT JJ 18 min-
utes,” but the constituents CD in the former case
and DT and JJ in the latter case are not neces-
sary in all situations. In contrast, NN and IN
will probably be inserted most cases. As a result,
the appearance of such ambiguous constituents in
the training data is less consistent than that of nec-
essary syntactic constituents, and thus the predic-
tion model avoids generating such ambiguous con-
stituents.
</bodyText>
<subsectionHeader confidence="0.585492">
6.2.2 Simultaneous Translation
</subsectionHeader>
<bodyText confidence="0.9999">
Next, we evaluate the translation results achieved
by the proposed method. Figures 6 and 7 show the
relationship between the mean number of words in
the translation segments and translation accuracy
of BLEU and RIBES respectively. Each horizon-
tal axis of these graphs indicates the mean number
of words in translation units that are used to gen-
erate the actual translation output, and these can
be assumed to be proportional to the mean waiting
time for listeners. In cases except T2S-Wait, these
values are equal to the mean length of translation
unit generated by the segmentation strategies, and
in the case of T2S-Wait, this value shows the length
of the translation units concatenated by the waiting
strategy. First looking at the full sentence results
(rightmost points in each graph), we can see that
T2S greatly outperforms PBMT on full sentences,
</bodyText>
<page confidence="0.993678">
204
</page>
<figure confidence="0.973743">
(a) n-words segmentation (b) optimized segmentation
</figure>
<figureCaption confidence="0.990722">
Figure 6: Mean #words and BLEU scores of each method.
</figureCaption>
<figure confidence="0.927207">
(a) n-words segmentation (b) optimized segmentation
</figure>
<figureCaption confidence="0.999973">
Figure 7: Mean #words and RIBES scores of each method.
</figureCaption>
<bodyText confidence="0.999866552631579">
underlining the importance of considering syntax
for this language pair.
Turning to simultaneous translation, we first
consider the case of n-words segmentation, which
will demonstrate robustness of each method to
poorly formed translation segments. When we
compare PBMT and T2S, we can see that T2S is
superior for longer segments, but on shorter seg-
ments performance is greatly reduced, dropping
below that of PBMT in BLEU at an average of 6
words, and RIBES at an average of 4 words. This
trend is reasonable, considering that shorter trans-
lation units will result in syntactically inconsistent
units and thus incorrect parse trees. Next look-
ing at the results for T2S-Tag, we can see that in
the case of the n-words segmentation, it is able
to maintain the same translation performance of
PBMT, even at the shorter settings. Furthermore,
T2S-Wait also maintains the same performance
of T2S-Tag in BLEU and achieves much higher
performance than any of the other methods in
RIBES, particularly with regards to shorter trans-
lation units. This result shows that the method of
waiting for more input in the face of potential re-
ordering problems is highly effective in maintain-
ing the correct ordering of the output.
In the case of the optimized segmentation,
all three T2S methods maintain approximately
the same performance, consistently outperforming
PBMT in RIBES, and crossing in BLEU around 5-
6 words. From this, we can hypothesize that the
optimized segmentation strategy learns features
that maintain some syntactic consistency, which
plays a similar role to the proposed method. How-
ever, RIBES scores for T2S-Wait is still generally
higher than the other methods, demonstrating that
waiting maintains its reordering advantage even in
the optimized segmentation case.
</bodyText>
<sectionHeader confidence="0.997076" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999930714285714">
In this paper, we proposed the first method to
apply SMT using source syntax to simultaneous
translation. Especially, we proposed methods to
maintain the syntactic consistency of translation
units by predicting unseen syntactic constituents,
and waiting until more input is available when it is
necessary to achieve good translation results. Ex-
</bodyText>
<page confidence="0.995334">
205
</page>
<bodyText confidence="0.999933388888889">
periments on an English-Japanese TED talk trans-
lation task demonstrate that our methods are more
robust to short, inconsistent translation segments.
As future work, we are planning to devise
more sophisticated methods for language model-
ing using constituent tags, and ways to incorpo-
rate previously translated segments into the esti-
mation process for left-hand constituents. Next,
our method to predict additional constituents does
not target the grammatically correct translation
units for which L = [ ] and R = [ ], although
there is still room for improvement in this assump-
tion. In addition, we hope to expand the meth-
ods proposed here to a more incremental setting,
where both parsing and decoding are performed
incrementally, and the information from these pro-
cesses can be reflected in the decision of segmen-
tation boundaries.
</bodyText>
<sectionHeader confidence="0.984114" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.833269">
Part of this work was supported by JSPS KAK-
ENHI Grant Number 24240032, and Grant-in-Aid
for JSPS Fellows Grant Number 15J10649.
</bodyText>
<sectionHeader confidence="0.998571" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999620532467533">
Srinivas Bangalore, Vivek Kumar Rangarajan Srid-
har, Prakash Kolan, Ladan Golipour, and Aura
Jimenez. 2012. Real-time incremental speech-to-
speech translation of dialogs. In Proc. NAACL.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT3: Web inventory of transcribed
and translated talks. In Proc. EAMT.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. The Journal
of Machine Learning Research.
Andrew Finch, Xiaolin Wang, and Eiichiro Sumita.
2014. An exploration of segmentation strategies in
stream decoding. In Proc. IWSLT.
Christian F¨ugen, Alex Waibel, and Muntsin Kolss.
2007. Simultaneous translation of lectures and
speeches. Machine Translation, 21.
Tomoki Fujita, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013. Sim-
ple, lexicalized choice of translation timing for si-
multaneous speech translation. In Proc. Interspeech.
Alvin Grissom II, He He, Jordan Boyd-Graber, John
Morgan, and Hal Daum´e III. 2014. Dont until the
final verb wait: Reinforcement learning for simulta-
neous machine translation. In Proc. EMNLP.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modified
Kneser-Ney language model estimation. In Proc.
ACL.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. AMTA.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010. Automatic
evaluation of translation quality for distant language
pairs. In Proc. EMNLP.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ACL.
Chin-Yew Lin and Franz Josef Och. 2004. ORANGE:
a method for evaluating automatic evaluation met-
rics for machine translation. In Proc. COLING.
Mitchell P Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The Penn treebank. Com-
putational linguistics, 19(2).
Evgeny Matusov, Arne Mauser, and Hermann Ney.
2006. Automatic sentence segmentation and punc-
tuation prediction for spoken language translation.
In Proc. IWSLT.
Graham Neubig, Yosuke Nakata, and Shinsuke Mori.
2011. Pointwise prediction for robust, adaptable
japanese morphological analysis. In Proc. ACL-
HLT.
Graham Neubig. 2013. Travatar: A forest-to-string
machine translation engine based on tree transduc-
ers. In Proc. ACL.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational linguistics.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. ACL.
Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki
Toda, and Satoshi Nakamura. 2014. Optimiz-
ing segmentation strategies for simultaneous speech
translation. In Proc. ACL.
Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki
Toda, and Satoshi Nakamura. 2015. Ckylark: A
more robust PCFG-LA parser. In Proc. NAACL-
HLT.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic eval-
uation of machine translation. In Proc. ACL.
</reference>
<page confidence="0.981346">
206
</page>
<reference confidence="0.999615434782609">
Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas
Bangalore, Andrej Ljolje, and Rathinavelu Chengal-
varayan. 2013. Segmentation strategies for stream-
ing speech translation. In Proc. NAACL-HLT.
Koichiro Ryu, Shigeki Matsubara, and Yasuyoshi In-
agaki. 2006. Simultaneous english-japanese spo-
ken language translation based on incremental de-
pendency parsing and transfer. In Proc. COLING.
Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar.
2010. Incremental decoding for phrase-based statis-
tical machine translation. In Proc. WMT.
Maryam Siahbani, Ramtin Mehdizadeh Seraj,
Baskaran Sankaran, and Anoop Sarkar. 2014.
Incremental translation using hierarchical phrase-
based translation system. In Proc. SLT.
Fei Xia and Michael McCord. 2004. Improving
a statistical MT system with automatically learned
rewrite patterns. In Proc. COLING.
Mahsa Yarmohammadi, Vivek Kumar Rangara-
jan Sridhar, Srinivas Bangalore, and Baskaran
Sankaran. 2013. Incremental segmentation and
decoding strategies for simultaneous translation. In
Proc. IJCNLP.
</reference>
<page confidence="0.998015">
207
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.804804">
<title confidence="0.9977295">Syntax-based Simultaneous through Prediction of Unseen Syntactic Constituents</title>
<author confidence="0.990643">Yusuke Oda Graham Neubig Sakriani Sakti Tomoki Toda Satoshi</author>
<affiliation confidence="0.999582">Graduate School of Information Nara Institute of Science and</affiliation>
<address confidence="0.870092">Takayamacho, Ikoma, Nara 630-0192,</address>
<email confidence="0.916741">neubig,ssakti,tomoki,</email>
<abstract confidence="0.999461086956522">Simultaneous translation is a method to reduce the latency of communication through machine translation (MT) by dividing the input into short segments before performing translation. However, short segments pose problems for syntaxbased translation methods, as it is difficult to generate accurate parse trees for sub-sentential segments. In this paper, we perform the first experiments applying syntax-based SMT to simultaneous translation, and propose two methods to prevent degradations in accuracy: a method to predict unseen syntactic constituents that help generate complete parse trees, and a method that waits for more input when the current utterance is not enough to generate a fluent translation. Experiments on English-Japanese translation show that the proposed methods allow for improvements in accuracy, particularly with regards to word order of the target sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
</authors>
<title>Vivek Kumar Rangarajan Sridhar, Prakash Kolan,</title>
<date>2012</date>
<booktitle>In Proc. NAACL.</booktitle>
<location>Ladan</location>
<marker>Bangalore, 2012</marker>
<rawString>Srinivas Bangalore, Vivek Kumar Rangarajan Sridhar, Prakash Kolan, Ladan Golipour, and Aura Jimenez. 2012. Real-time incremental speech-tospeech translation of dialogs. In Proc. NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Christian Girardi</author>
<author>Marcello Federico</author>
</authors>
<title>WIT3: Web inventory of transcribed and translated talks.</title>
<date>2012</date>
<booktitle>In Proc. EAMT.</booktitle>
<contexts>
<context position="20965" citStr="Cettolo et al., 2012" startWordPosition="3500" endWordPosition="3503"> testing data, we extract all substrings w s.t. |w |≥ 2 in the Penn Treebank and calculate the corresponding syntactic constituents L and R by according to the original trees and substring w. We use the 90% of the extracted data for training a classifier and the remaining 10% for testing estimation recall, precision and F-measure. We use the Ckylark parser(Oda et al., 2015) to generate T′ from w. 6.1.2 Simultaneous Translation Next, we evaluate the performance of T2S simultaneous translation adopting the two proposed methods. We use data of TED talks from the English-Japanese section of WIT3 (Cettolo et al., 2012), and also append dictionary entries and examples in Eijiro3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram</context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012. WIT3: Web inventory of transcribed and translated talks. In Proc. EAMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research.</journal>
<contexts>
<context position="15478" citStr="Fan et al., 2008" startWordPosition="2535" endWordPosition="2538">for constituent sequences of an arbitrary length. Here * represents the concatenation of two sequences. First, our method forcibly parses the input sequence w and retrieves a potentially incorrect parse tree T′, which is used to calculate features for the prediction model. The next syntactic constituent R+ is then predicted using features extracted from w, T′, and the predicted sequence history R*. This prediction is repeated recurrently until the end-of-sentence symbol (“nil” in Algorithm 1) is predicted as the next symbol. In this study, we use a multi-label classifier based on linear SVMs (Fan et al., 2008) to predict new syntactic constituents with features shown in Table 1. We treat the input sequence w and predicted syntactic constituents R* as a concatenated sequence w * R*. For example, if we have w = [ this, is, a ] and R* = [ NN ], then the word features “3 rightmost 1-grams” will take the values “is,” “a,” and NN . Tags of semi-terminal nodes in T′ are used as part-of-speech (POS) tags for corresponding words and the POS of each predicted syntactic constituent is simply its tag. “nil” is used when some information is not available. For example, if we have w = [ this, is ] and R* = [ ] th</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. The Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Xiaolin Wang</author>
<author>Eiichiro Sumita</author>
</authors>
<title>An exploration of segmentation strategies in stream decoding.</title>
<date>2014</date>
<booktitle>In Proc. IWSLT.</booktitle>
<contexts>
<context position="7007" citStr="Finch et al., 2014" startWordPosition="1068" endWordPosition="1071"> are given an incoming stream of words f, which we are expected to translate. As the f is long, we would like to begin translating before we reach the end of the stream. Previous methods to do so can generally be categorized into incremental decoding methods, and sentence segmentation methods. In incremental decoding, each incoming word is fed into the decoder one-by-one, and the decoder updates the search graph with the new words and decides whether it should begin translation. Incremental decoding methods have been proposed for phrase-based (Sankaran et al., 2010; Yarmohammadi et al., 2013; Finch et al., 2014) and hierarchical phrase-based (Siahbani et al., 2014) SMT 199 models.1 Incremental decoding has the advantage of using information about the decoding graph in the choice of translation timing, but also requires significant changes to the internal workings of the decoder, precluding the use of standard decoding tools or techniques. Sentence segmentation methods (Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into output sequences [e(1), ... , e(N)], which each are</context>
</contexts>
<marker>Finch, Wang, Sumita, 2014</marker>
<rawString>Andrew Finch, Xiaolin Wang, and Eiichiro Sumita. 2014. An exploration of segmentation strategies in stream decoding. In Proc. IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian F¨ugen</author>
<author>Alex Waibel</author>
<author>Muntsin Kolss</author>
</authors>
<title>Simultaneous translation of lectures and speeches.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<marker>F¨ugen, Waibel, Kolss, 2007</marker>
<rawString>Christian F¨ugen, Alex Waibel, and Muntsin Kolss. 2007. Simultaneous translation of lectures and speeches. Machine Translation, 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoki Fujita</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Simple, lexicalized choice of translation timing for simultaneous speech translation.</title>
<date>2013</date>
<booktitle>In Proc. Interspeech.</booktitle>
<contexts>
<context position="7914" citStr="Fujita et al., 2013" startWordPosition="1210" endWordPosition="1213"> use of standard decoding tools or techniques. Sentence segmentation methods (Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into output sequences [e(1), ... , e(N)], which each are output as soon as translation finishes. Many methods have been proposed to perform segmentation, including the use of prosodic boundaries (F¨ugen et al., 2007; Bangalore et al., 2012), predicting punctuation marks (Rangarajan Sridhar et al., 2013), reordering probabilities of phrases (Fujita et al., 2013), or models to explicitly optimize translation accuracy (Oda et al., 2014). Previous work often assumes that f is a single sentence, and focus on sub-sentential segmentation, an approach we follow in this work. Sentence segmentation methods have the obvious advantage of allowing for translation as soon as a segment is decided. However, the use of the shorter segments also makes it necessary to translate while part of the utterance is still unknown. As a result, segmenting sentences more aggressively often results in a decrease translation accuracy. This is a problem in phrase-based MT, the fra</context>
</contexts>
<marker>Fujita, Neubig, Sakti, Toda, Nakamura, 2013</marker>
<rawString>Tomoki Fujita, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2013. Simple, lexicalized choice of translation timing for simultaneous speech translation. In Proc. Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvin Grissom He He</author>
<author>Jordan Boyd-Graber</author>
<author>John Morgan</author>
<author>Hal Daum´e</author>
</authors>
<title>Dont until the final verb wait: Reinforcement learning for simultaneous machine translation.</title>
<date>2014</date>
<booktitle>In Proc. EMNLP.</booktitle>
<marker>He, Boyd-Graber, Morgan, Daum´e, 2014</marker>
<rawString>Alvin Grissom II, He He, Jordan Boyd-Graber, John Morgan, and Hal Daum´e III. 2014. Dont until the final verb wait: Reinforcement learning for simultaneous machine translation. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Ivan Pouzyrevsky</author>
<author>Jonathan H Clark</author>
<author>Philipp Koehn</author>
</authors>
<title>Scalable modified Kneser-Ney language model estimation. In</title>
<date>2013</date>
<booktitle>Proc. ACL.</booktitle>
<contexts>
<context position="21544" citStr="Heafield et al., 2013" startWordPosition="3581" endWordPosition="3584">nese section of WIT3 (Cettolo et al., 2012), and also append dictionary entries and examples in Eijiro3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high</context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable modified Kneser-Ney language model estimation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proc. AMTA.</booktitle>
<contexts>
<context position="4388" citStr="Huang et al., 2006" startWordPosition="644" endWordPosition="647"> II et al. (2014), who describe a method that predicts sentence-final verbs using reinforcement learning (e.g. Figure 1 (b)). This approach has the potential to greatly decrease the delay in translation from verb-final languages to verbinitial languages (such as German-English), but is also limited to only this particular case. In this paper, we propose a more general method that focuses on a different variety of information: unseen syntactic constituents. This method is motivated by our desire to apply translation models that use source-side parsing, such as tree-to-string (T2S) translation (Huang et al., 2006) or syntactic pre-ordering (Xia and McCord, 2004), which have been shown to greatly improve translation accuracy over syntactically divergent language pairs. However, conventional methods for parsing are not directly applicable to the partial sentences that arise in simultaneous MT. The reason for this, as explained in detail in Section 3, is that parsing methods generally assume that they are given input that forms a complete syntactic phrase. Looking at the example in Figure 1, after the speaker has spoken the words “I think” we have a partial sentence that will only be complete once we obse</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proc. AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
</authors>
<title>Automatic evaluation of translation quality for distant language pairs.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="22091" citStr="Isozaki et al., 2010" startWordPosition="3677" endWordPosition="3680"> Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method is the state-of-the-art segmentation strategy proposed by Oda et al. (2014), which </context>
</contexts>
<marker>Isozaki, Hirao, Duh, Sudoh, Tsukada, 2010</marker>
<rawString>Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010. Automatic evaluation of translation quality for distant language pairs. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation. In</title>
<date>2007</date>
<booktitle>Proc. ACL.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="21846" citStr="Koehn et al., 2007" startWordPosition="3635" endWordPosition="3638">and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syn</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Franz Josef Och</author>
</authors>
<title>ORANGE: a method for evaluating automatic evaluation metrics for machine translation. In</title>
<date>2004</date>
<booktitle>Proc. COLING.</booktitle>
<contexts>
<context position="22808" citStr="Lin and Och, 2004" startWordPosition="3784" endWordPosition="3787">Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method is the state-of-the-art segmentation strategy proposed by Oda et al. (2014), which finds segmentation boundaries that optimize the accuracy of the translation output. We use BLEU+1 (Lin and Och, 2004) as the objective of this segmentation strategy. We evaluate the following baseline and proposed methods: PBMT is a baseline using phrase-based SMT. T2S uses T2S SMT with parse trees generated from only w. T2S-Tag further predicts unseen syntactic constituents according to Section 4. Before evaluation, all constituent tags are simply deleted from the output. T2S-Wait uses T2S-Tag and adds the waiting strategy described in Section 5. We also show PBMT-Sent and T2S-Sent which are full sentence-based PBMT and T2S systems. 6.2 Results 6.2.1 Predicting Syntactic Constituents Table 2 shows the recal</context>
</contexts>
<marker>Lin, Och, 2004</marker>
<rawString>Chin-Yew Lin and Franz Josef Och. 2004. ORANGE: a method for evaluating automatic evaluation metrics for machine translation. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: The Penn treebank.</title>
<date>1993</date>
<journal>Computational linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="14415" citStr="Marcus et al., 1993" startWordPosition="2356" endWordPosition="2359">tisfy these conditions. As shown in the Figure 3, there is ambiguity regarding syntactic constituents to be predicted (e.g. we can choose either [ NP ] or [ DT , NN ] as R for w = [ “this”, “is” ]). These conditions avoid ambiguity of which syntactic constituents should predicted for partial sentences in the training data. Looking at the example, Figures 3(d1) and 3(e1) satisfy these conditions, but 3(d2) and 3(e2) do not. Figure 4 shows the statistics of the lengths of L and R sequences extracted according to these criteria for all substrings of the WSJ datasets 2 to 23 of the Penn Treebank (Marcus et al., 1993), a standard training set for English syntactic parsers. From the figure we can see that lengths of up to 2 constituents cover the majority of cases for both L and R, but a significant number of cases require longer strings. Thus methods that predict a fixed number of constituents are not appropriate here. In Algorithm 1, we show the method we propose to 201 Figure 4: Statistics of numbers of syntactic constituents to be predicted. predict R for constituent sequences of an arbitrary length. Here * represents the concatenation of two sequences. First, our method forcibly parses the input sequen</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: The Penn treebank. Computational linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Automatic sentence segmentation and punctuation prediction for spoken language translation.</title>
<date>2006</date>
<booktitle>In Proc. IWSLT.</booktitle>
<contexts>
<context position="1844" citStr="Matusov et al., 2006" startWordPosition="262" endWordPosition="265">et sentences. 1 Introduction Speech translation is an application of machine translation (MT) that converts utterances from the speaker’s language into the listener’s language. One of the most identifying features of speech translation is the fact that it must be performed in real time while the speaker is speaking, and thus it is necessary to split a constant stream of words into translatable segments before starting the translation process. Traditionally, speech translation assumes that each segment corresponds to a sentence, and thus performs sentence boundary detection before translation (Matusov et al., 2006). However, full sentences can be long, particularly in formal speech such as lectures, and if translation does not start until explicit ends of Figure 1: Simultaneous translation where the source sentence is segmented after “I think” and translated according to (a) the standard method, (b) Grissom II et al. (2014)’s method of final verb prediction, and (c) our method of predicting syntactic constituents. sentences, listeners may be forced to wait a considerable time until receiving the result of translation. For example, when the speaker continues to talk for 10 seconds, listeners must wait at</context>
</contexts>
<marker>Matusov, Mauser, Ney, 2006</marker>
<rawString>Evgeny Matusov, Arne Mauser, and Hermann Ney. 2006. Automatic sentence segmentation and punctuation prediction for spoken language translation. In Proc. IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Yosuke Nakata</author>
<author>Shinsuke Mori</author>
</authors>
<title>Pointwise prediction for robust, adaptable japanese morphological analysis.</title>
<date>2011</date>
<booktitle>In Proc. ACLHLT.</booktitle>
<contexts>
<context position="21337" citStr="Neubig et al., 2011" startWordPosition="3557" endWordPosition="3560">15) to generate T′ from w. 6.1.2 Simultaneous Translation Next, we evaluate the performance of T2S simultaneous translation adopting the two proposed methods. We use data of TED talks from the English-Japanese section of WIT3 (Cettolo et al., 2012), and also append dictionary entries and examples in Eijiro3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model </context>
</contexts>
<marker>Neubig, Nakata, Mori, 2011</marker>
<rawString>Graham Neubig, Yosuke Nakata, and Shinsuke Mori. 2011. Pointwise prediction for robust, adaptable japanese morphological analysis. In Proc. ACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
</authors>
<title>Travatar: A forest-to-string machine translation engine based on tree transducers.</title>
<date>2013</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="21746" citStr="Neubig, 2013" startWordPosition="3619" endWordPosition="3620">ries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al.</context>
</contexts>
<marker>Neubig, 2013</marker>
<rawString>Graham Neubig. 2013. Travatar: A forest-to-string machine translation engine based on tree transducers. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models. Computational linguistics.</title>
<date>2003</date>
<contexts>
<context position="21481" citStr="Och and Ney, 2003" startWordPosition="3571" endWordPosition="3574">sed methods. We use data of TED talks from the English-Japanese section of WIT3 (Cettolo et al., 2012), and also append dictionary entries and examples in Eijiro3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neubig et al., 2011) for 3http://eijiro.jp/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="21968" citStr="Och, 2003" startWordPosition="3657" endWordPosition="3658">p/ 4http://nlp.stanford.edu/software/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor seg</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Oda</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Optimizing segmentation strategies for simultaneous speech translation.</title>
<date>2014</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="7988" citStr="Oda et al., 2014" startWordPosition="1221" endWordPosition="1224">(Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into output sequences [e(1), ... , e(N)], which each are output as soon as translation finishes. Many methods have been proposed to perform segmentation, including the use of prosodic boundaries (F¨ugen et al., 2007; Bangalore et al., 2012), predicting punctuation marks (Rangarajan Sridhar et al., 2013), reordering probabilities of phrases (Fujita et al., 2013), or models to explicitly optimize translation accuracy (Oda et al., 2014). Previous work often assumes that f is a single sentence, and focus on sub-sentential segmentation, an approach we follow in this work. Sentence segmentation methods have the obvious advantage of allowing for translation as soon as a segment is decided. However, the use of the shorter segments also makes it necessary to translate while part of the utterance is still unknown. As a result, segmenting sentences more aggressively often results in a decrease translation accuracy. This is a problem in phrase-based MT, the framework used in the majority of previous research on simultaneous translati</context>
<context position="22683" citStr="Oda et al. (2014)" startWordPosition="3764" endWordPosition="3767">ES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method is the state-of-the-art segmentation strategy proposed by Oda et al. (2014), which finds segmentation boundaries that optimize the accuracy of the translation output. We use BLEU+1 (Lin and Och, 2004) as the objective of this segmentation strategy. We evaluate the following baseline and proposed methods: PBMT is a baseline using phrase-based SMT. T2S uses T2S SMT with parse trees generated from only w. T2S-Tag further predicts unseen syntactic constituents according to Section 4. Before evaluation, all constituent tags are simply deleted from the output. T2S-Wait uses T2S-Tag and adds the waiting strategy described in Section 5. We also show PBMT-Sent and T2S-Sent wh</context>
</contexts>
<marker>Oda, Neubig, Sakti, Toda, Nakamura, 2014</marker>
<rawString>Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2014. Optimizing segmentation strategies for simultaneous speech translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Oda</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Ckylark: A more robust PCFG-LA parser.</title>
<date>2015</date>
<booktitle>In Proc. NAACLHLT.</booktitle>
<contexts>
<context position="20720" citStr="Oda et al., 2015" startWordPosition="3461" endWordPosition="3464"> the first experiment, we evaluate prediction accuracies of unseen syntactic constituents L and R. To do so, we train a predictive model as described in Section 4 using an English treebank and evaluate its performance. To create training and testing data, we extract all substrings w s.t. |w |≥ 2 in the Penn Treebank and calculate the corresponding syntactic constituents L and R by according to the original trees and substring w. We use the 90% of the extracted data for training a classifier and the remaining 10% for testing estimation recall, precision and F-measure. We use the Ckylark parser(Oda et al., 2015) to generate T′ from w. 6.1.2 Simultaneous Translation Next, we evaluate the performance of T2S simultaneous translation adopting the two proposed methods. We use data of TED talks from the English-Japanese section of WIT3 (Cettolo et al., 2012), and also append dictionary entries and examples in Eijiro3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Eijiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively. We use the Stanford Tokenizer4 for English tokenization, KyTea (Neu</context>
</contexts>
<marker>Oda, Neubig, Sakti, Toda, Nakamura, 2015</marker>
<rawString>Yusuke Oda, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2015. Ckylark: A more robust PCFG-LA parser. In Proc. NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="22009" citStr="Papineni et al., 2002" startWordPosition="3662" endWordPosition="3666">oftware/tokenizer.shtml (a) (b) Pr(e|T*) 203 Japanese tokenization, GIZA++ (Och and Ney, 2003) to construct word alignment, and KenLM (Heafield et al., 2013) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T* from L*, w and R*. We use Travatar (Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method i</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Kumar Rangarajan Sridhar</author>
<author>John Chen</author>
<author>Srinivas Bangalore</author>
<author>Andrej Ljolje</author>
<author>Rathinavelu Chengalvarayan</author>
</authors>
<title>Segmentation strategies for streaming speech translation.</title>
<date>2013</date>
<booktitle>In Proc. NAACL-HLT.</booktitle>
<contexts>
<context position="7855" citStr="Sridhar et al., 2013" startWordPosition="1202" endWordPosition="1205">nges to the internal workings of the decoder, precluding the use of standard decoding tools or techniques. Sentence segmentation methods (Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into output sequences [e(1), ... , e(N)], which each are output as soon as translation finishes. Many methods have been proposed to perform segmentation, including the use of prosodic boundaries (F¨ugen et al., 2007; Bangalore et al., 2012), predicting punctuation marks (Rangarajan Sridhar et al., 2013), reordering probabilities of phrases (Fujita et al., 2013), or models to explicitly optimize translation accuracy (Oda et al., 2014). Previous work often assumes that f is a single sentence, and focus on sub-sentential segmentation, an approach we follow in this work. Sentence segmentation methods have the obvious advantage of allowing for translation as soon as a segment is decided. However, the use of the shorter segments also makes it necessary to translate while part of the utterance is still unknown. As a result, segmenting sentences more aggressively often results in a decrease translat</context>
<context position="22353" citStr="Sridhar et al., 2013" startWordPosition="3712" endWordPosition="3715">(Neubig, 2013) to train the T2S translation model used in the proposed method, and also Moses (Koehn et al., 2007) to train phrase-based translation models that serve as a baseline. Each translation model is tuned using MERT (Och, 2003) to maximize BLEU (Papineni et al., 2002). We evaluate translation accuracies by BLEU and also RIBES (Isozaki et al., 2010), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks. We perform tests using two different sentence segmentation methods. The first is n-words segmentation (Rangarajan Sridhar et al., 2013), a simple heuristic that simply segments the input every n words. This method disregards syntactic and semantic units in the original sentence, allowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method is the state-of-the-art segmentation strategy proposed by Oda et al. (2014), which finds segmentation boundaries that optimize the accuracy of the translation output. We use BLEU+1 (Lin and Och, 2004) as the objective of this segmentation strategy. We evaluate the following baseline and proposed methods: PBMT is a baseline using phrase-based S</context>
</contexts>
<marker>Sridhar, Chen, Bangalore, Ljolje, Chengalvarayan, 2013</marker>
<rawString>Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas Bangalore, Andrej Ljolje, and Rathinavelu Chengalvarayan. 2013. Segmentation strategies for streaming speech translation. In Proc. NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koichiro Ryu</author>
<author>Shigeki Matsubara</author>
<author>Yasuyoshi Inagaki</author>
</authors>
<title>Simultaneous english-japanese spoken language translation based on incremental dependency parsing and transfer.</title>
<date>2006</date>
<booktitle>In Proc. COLING.</booktitle>
<contexts>
<context position="9329" citStr="Ryu et al., 2006" startWordPosition="1438" endWordPosition="1441"> the problems caused by parsing a segment f(�), and solutions, in the following section. 3 Parsing Incomplete Sentences 3.1 Difficulties in Incomplete Parsing In standard phrase structure parsing, the parser assumes that each input string is a complete sentence, or at least a complete phrase. For example, Figure 3 (a) shows the phrase structure of the complete sentence “this is a pen.” However, in the case of simultaneous translation, each translation unit 1There is also one previous rule-based system that uses syntax in incremental translation, but it is language specific and limited domain (Ryu et al., 2006), and thus difficult to compare with our SMT-based system. It also does not predict unseen constituents, relying only on the observed segment. Figure 3: Phrase structures with surrounding syntactic constituents. is not necessarily segmented in a way that guarantees that the translation unit is a complete sentence, so each translation unit should be treated not as a whole, but as a part of a spoken sentence. As a result, the parser input may be an incomplete sequence of words (e.g. “this is,” “is a”), and a standard parser will generate an incorrect parse as shown in Figures 3(b) and 3(c). The </context>
</contexts>
<marker>Ryu, Matsubara, Inagaki, 2006</marker>
<rawString>Koichiro Ryu, Shigeki Matsubara, and Yasuyoshi Inagaki. 2006. Simultaneous english-japanese spoken language translation based on incremental dependency parsing and transfer. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baskaran Sankaran</author>
<author>Ajeet Grewal</author>
<author>Anoop Sarkar</author>
</authors>
<title>Incremental decoding for phrase-based statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proc. WMT.</booktitle>
<contexts>
<context position="6959" citStr="Sankaran et al., 2010" startWordPosition="1059" endWordPosition="1062">ion In simultaneous translation, we assume that we are given an incoming stream of words f, which we are expected to translate. As the f is long, we would like to begin translating before we reach the end of the stream. Previous methods to do so can generally be categorized into incremental decoding methods, and sentence segmentation methods. In incremental decoding, each incoming word is fed into the decoder one-by-one, and the decoder updates the search graph with the new words and decides whether it should begin translation. Incremental decoding methods have been proposed for phrase-based (Sankaran et al., 2010; Yarmohammadi et al., 2013; Finch et al., 2014) and hierarchical phrase-based (Siahbani et al., 2014) SMT 199 models.1 Incremental decoding has the advantage of using information about the decoding graph in the choice of translation timing, but also requires significant changes to the internal workings of the decoder, precluding the use of standard decoding tools or techniques. Sentence segmentation methods (Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into out</context>
</contexts>
<marker>Sankaran, Grewal, Sarkar, 2010</marker>
<rawString>Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar. 2010. Incremental decoding for phrase-based statistical machine translation. In Proc. WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryam Siahbani</author>
<author>Ramtin Mehdizadeh Seraj</author>
<author>Baskaran Sankaran</author>
<author>Anoop Sarkar</author>
</authors>
<title>Incremental translation using hierarchical phrasebased translation system.</title>
<date>2014</date>
<booktitle>In Proc. SLT.</booktitle>
<contexts>
<context position="7061" citStr="Siahbani et al., 2014" startWordPosition="1076" endWordPosition="1079">are expected to translate. As the f is long, we would like to begin translating before we reach the end of the stream. Previous methods to do so can generally be categorized into incremental decoding methods, and sentence segmentation methods. In incremental decoding, each incoming word is fed into the decoder one-by-one, and the decoder updates the search graph with the new words and decides whether it should begin translation. Incremental decoding methods have been proposed for phrase-based (Sankaran et al., 2010; Yarmohammadi et al., 2013; Finch et al., 2014) and hierarchical phrase-based (Siahbani et al., 2014) SMT 199 models.1 Incremental decoding has the advantage of using information about the decoding graph in the choice of translation timing, but also requires significant changes to the internal workings of the decoder, precluding the use of standard decoding tools or techniques. Sentence segmentation methods (Figure 2) provide a simpler alternative by first dividing f into subsequences of 1 or more words [f(1), ... , f(N)]. These segments are then translated with a traditional decoder into output sequences [e(1), ... , e(N)], which each are output as soon as translation finishes. Many methods </context>
</contexts>
<marker>Siahbani, Seraj, Sankaran, Sarkar, 2014</marker>
<rawString>Maryam Siahbani, Ramtin Mehdizadeh Seraj, Baskaran Sankaran, and Anoop Sarkar. 2014. Incremental translation using hierarchical phrasebased translation system. In Proc. SLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proc. COLING.</booktitle>
<contexts>
<context position="4437" citStr="Xia and McCord, 2004" startWordPosition="651" endWordPosition="654">redicts sentence-final verbs using reinforcement learning (e.g. Figure 1 (b)). This approach has the potential to greatly decrease the delay in translation from verb-final languages to verbinitial languages (such as German-English), but is also limited to only this particular case. In this paper, we propose a more general method that focuses on a different variety of information: unseen syntactic constituents. This method is motivated by our desire to apply translation models that use source-side parsing, such as tree-to-string (T2S) translation (Huang et al., 2006) or syntactic pre-ordering (Xia and McCord, 2004), which have been shown to greatly improve translation accuracy over syntactically divergent language pairs. However, conventional methods for parsing are not directly applicable to the partial sentences that arise in simultaneous MT. The reason for this, as explained in detail in Section 3, is that parsing methods generally assume that they are given input that forms a complete syntactic phrase. Looking at the example in Figure 1, after the speaker has spoken the words “I think” we have a partial sentence that will only be complete once we observe the following SBAR. Our method attempts to pr</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahsa Yarmohammadi</author>
</authors>
<title>Vivek Kumar Rangarajan Sridhar, Srinivas Bangalore, and Baskaran Sankaran.</title>
<date>2013</date>
<booktitle>Proc. IJCNLP.</booktitle>
<marker>Yarmohammadi, 2013</marker>
<rawString>Mahsa Yarmohammadi, Vivek Kumar Rangarajan Sridhar, Srinivas Bangalore, and Baskaran Sankaran. 2013. Incremental segmentation and decoding strategies for simultaneous translation. In Proc. IJCNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>