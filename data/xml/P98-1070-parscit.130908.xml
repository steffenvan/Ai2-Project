<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.99508">
Splitting Long or III-formed Input
for Robust Spoken-language Translation
</title>
<author confidence="0.414141">
Osamu FURUSEt, Setsuo YAMADA, Kazuhide YAMAMOTO
</author>
<affiliation confidence="0.342313">
ATR Interpreting Telecommunications Research Laboratories
</affiliation>
<address confidence="0.552957">
2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan
</address>
<email confidence="0.636796">
furuseOcslab.kecl.ntt.co.jp, {syamada, yamamoto}Oitl.atr.co.jp
</email>
<sectionHeader confidence="0.9927" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999981222222222">
This paper proposes an input-splitting method
for translating spoken-language which includes
many long or ill-formed expressions. The pro-
posed method splits input into well-balanced
translation units based on a semantic distance
calculation. The splitting is performed dur-
ing left-to-right parsing, and does not degrade
translation efficiency. The complete translation
result is formed by concatenating the partial
translation results of each split unit. The pro-
posed method can be incorporated into frame-
works like TDMT, which utilize left-to-right
parsing and a score for a substructure. Experi-
mental results show that the proposed method
gives TDMT the following advantages: (1) elim-
ination of null outputs, (2) splitting of utter-
ances into sentences, and (3) robust translation
of erroneous speech recognition results.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.981339672131148">
A spoken-language translation system requires
the ability to treat long or ill-formed input. An
utterance as input of a spoken-language trans-
lation system, is not always one well-formed
sentence. Also, when treating an utterance in
speech translation, the speech recognition result
which is the input of the translation component,
might be corrupted even though the input utter-
ance is well-formed. Such a misrecognized result
can cause a parsing failure, and consequently, no
translation output would be produced. Further-
more, we cannot expect that a speech recogni-
tion result includes punctuation marks such as
a comma or a period between words, which are
useful information for parsing. 1
As a solution for treating long input, long-
sentence splitting techniques, such as that of
t Current affiliation is NTT Communication Science
Laboratories.
&apos;Punctuation marks are not used in translation input
in this paper.
Kim (1994), have been proposed. These tech-
niques, however, use many splitting rules writ-
ten manually and do not treat ill-formed in-
put. Wakita (1997) proposed a robust transla-
tion method which locally extracts only reliable
parts, i.e., those within the semantic distance
threshold and over some word length. This
technique, however, does not split input into
units globally, or sometimes does not output
any translation result.
This paper proposes an input-splitting
method for robust spoken-language translation.
The proposed method splits input into well-
balanced translation units based on a seman-
tic distance calculation. The complete trans-
lation result is formed by concatenating the
partial translation results of each split unit.
The proposed method can be incorporated into
frameworks that utilize left-to-right parsing and
a score for a substructure, In fact, it has
been added to Transfer-Driven Machine Trans-
lation (TDMT), which was proposed for efficient
and robust spoken-language translation (Fu-
ruse, 1994; Furuse, 1996). The splitting is per-
formed during TDMT&apos;s left-to-right chart pars-
ing strategy, and does not degrade translation
efficiency. The proposed method gives TDMT
the following advantages: (1) elimination of null
outputs, (2) splitting of utterances into sen-
tences, and (3) robust translation of erroneous
speech recognition results.
In the subsequent sections, we will first out-
line the translation strategy of TDMT. Then,
we will explain the framework of our split-
ting method in Japanese-to-English (JE) and
English-to-Japanese (EJ) translation. Next, by
comparing the TDMT system&apos;s performance be-
tween two sets of translations with and with-
out using the proposed method, we will demon-
strate the usefulness of our method.
</bodyText>
<page confidence="0.999137">
421
</page>
<sectionHeader confidence="0.9118" genericHeader="method">
2 Translation strategy of TDMT
</sectionHeader>
<subsectionHeader confidence="0.986702">
2.1 Transfer knowledge
</subsectionHeader>
<bodyText confidence="0.99998323076923">
TDMT produces a translation result by mim-
icking the example judged most semantically
similar to the input string, based on the idea
of Example-Based MT. Since it is difficult to
store enough example sentences to translate ev-
ery input, TDMT performs the translation by
combining the examples of the partial expres-
sions, which are represented by transfer knowl-
edge patterns. Transfer knowledge in TDMT is
compiled from translation examples. The fol-
lowing EJ transfer knowledge expression indi-
cates that the English pattern &amp;quot;X at Y&amp;quot; corre-
sponds to several possible Japanese expressions:
</bodyText>
<equation confidence="0.998038">
X at Y =&gt; Y de X&apos; ((present, con ference)..),
Y ni ((stay, hotel)..),
Y wo Xt ((look, it)..)
</equation>
<bodyText confidence="0.999917057142857">
The first possible translation pattern is &amp;quot;Y1 de
&amp;quot;, with example set ((present,conference)..).
We will see that this pattern is likely to be se-
lected to the extent that the input variable bind-
ings are semantically similar to the sample bind-
ings, where X =&amp;quot;present&amp;quot; and Y =&amp;quot;conference&amp;quot;.
X&apos; is the transfer result of X.
The source expression of the transfer knowl-
edge is expressed by a constituent boundary
pattern, which is defined as a sequence that
consists of variables and symbols representing
constituent boundaries (Furuse, 1994). A vari-
able corresponds to some linguistic constituent.
A constituent boundary is expressed by either
a functional word or a part-of-speech bigram
marker. In the case that there is no func-
tional surface word that divides the expression
into two constituents, a part-of-speech bigram
is employed as a boundary marker, which is ex-
pressed by hyphenating the parts-of-speech of a
left-constituent&apos;s last word and that of a right-
constituent&apos;s first word.
For instance, the expression &amp;quot;go to Kyoto&amp;quot; is
divided into two constituents, &amp;quot;go&amp;quot; and &amp;quot;Kyoto&amp;quot;.
The preposition &amp;quot;to&amp;quot; can be identified as a con-
stituent boundary. Therefore, in parsing &amp;quot;go to
Kyoto&amp;quot;, we use the pattern &amp;quot;X to Y&amp;quot;.
The expression &amp;quot;I go&amp;quot; can be divided into
two constituents &amp;quot;/&amp;quot; and &amp;quot;go&amp;quot;, which are a pro-
noun and a verb, respectively. Since there is
no functional surface word between the two
constituents, pronoun-verb can be inserted as a
boundary marker into &amp;quot;I go&amp;quot;, giving &amp;quot;I pronoun-
verb go&amp;quot;, which will now match the general
transfer knowledge pattern &amp;quot;X pronoun-verb Y&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.999602">
2.2 Left-to-right parsing
</subsectionHeader>
<bodyText confidence="0.999328153846154">
In TDMT, possible source language structures
are derived by applying the constituent bound-
ary patterns of transfer knowledge source parts
to an input string in a left-to-right fashion (Fu-
ruse, 1996), based on a chart parsing method.
An input string is parsed by combining active
and passive arcs shifting the processed string
left-to-right. In order to limit the combina-
tions of patterns during pattern application,
each pattern is assigned its linguistic level, and
for each linguistic level, we specify the linguistic
sublevels permitted to be used in the assigned
variables.
</bodyText>
<figure confidence="0.6362912">
Y X pronoun-verb Y
1 1
I go
(c) &amp;quot;ft
X pronoun-verb Y
1 1
X to Y
1 I
go Kyoto
•fr
</figure>
<figureCaption confidence="0.998734">
Figure 1: Substructures for &amp;quot;I go to Kyoto&amp;quot;
</figureCaption>
<bodyText confidence="0.98056416">
Figure 1 shows the substructures for each pas-
sive arc and each active arc in &amp;quot;I go to Kyoto&amp;quot;.
A processed string is indicated by &amp;quot;.11.&amp;quot;. A pas-
sive arc is created from a content word shown in
(a), or from a combination of patterns for which
all of the variables are instantiated, like (c), (e),
and (f). An active arc, which corresponds to an
incomplete substructure, is created from a com-
bination of patterns some of which have unin-
stantiated variables as right-hand neighbors to
the processed string, like (b) and (d).
If the processed string creates a passive arc for
a substring and the passive arc satisfies the left-
most part of an uninstantiated variable in the
pattern of active arcs for the left-neighboring
substring, the variable is instantiated with the
passive arc. Suppose that the processed string
is &amp;quot;Kyoto&amp;quot; in &amp;quot;I go to Kyoto&amp;quot;. The passive arc
(e) is created, and it instantiates Y of the ac-
tive arc (b). Thus, by combining (b) and (e),
the structure of &amp;quot;I go to Kyoto&amp;quot; is composed like
(f). If a passive arc is generated in such op-
eration, the creation of a new arc by variable
instantiation is repeated. If a new arc can no
longer be created, the processed string is shifted
</bodyText>
<figure confidence="0.9916965">
X pronoun-verb
ft 11.
(a) (b)
X to Y X to Y
1 t. 1 I
go go Kyoto
(d) 1.
(e)
</figure>
<page confidence="0.994898">
422
</page>
<bodyText confidence="0.998292333333333">
to the right-neighboring string. If the whole in-
put string can be covered with a passive arc, the
parsing will succeed.
</bodyText>
<subsectionHeader confidence="0.995526">
2.3 Disambiguation
</subsectionHeader>
<bodyText confidence="0.999977882352941">
The left-to-right parsing determines the best
structure and best transferred result locally by
performing structural disambiguation using se-
mantic distance calculations, in parallel with
the derivation of possible structures (Furuse,
1996). The best structure is determined when
a relative passive arc is created. Only the
best substructure is retained and combined with
other arcs. The best structure is selected by
computing the total sum of all the possible
combinations of the partial semantic distance
values. The structure with the smallest to-
tal distance is chosen as the best structure.
The semantic distance is calculated according
to the relationship of the positions of the words&apos;
semantic attributes in the thesaurus (Sumita,
1992).
</bodyText>
<sectionHeader confidence="0.864507" genericHeader="method">
3 Splitting strategy
</sectionHeader>
<bodyText confidence="0.999966428571429">
If the parsing of long or ill-formed input is only
undertaken by the application of stored pat-
terns, it often fails and generates no results.
Our strategy to parse such input, is to split the
input into units each of which can be parsed and
translated, and is explained as items (A)—(F) in
this section.
</bodyText>
<subsectionHeader confidence="0.9838895">
3.1 Concatenation of neighboring
substructures
</subsectionHeader>
<bodyText confidence="0.999882">
The splitting is performed during left-to-right
parsing as follows:
</bodyText>
<listItem confidence="0.7850995">
(A) Neighboring passive arcs can create a
larger passive arc by concatenating them.
(B) A passive arc which concatenates neigh-
boring passive arcs can be further concate-
nated with the right-neighboring passive
arc.
</listItem>
<bodyText confidence="0.984362846153846">
These items enable two neighboring substruc-
tures to compose a structure even if there is no
stored pattern which combines them. Figure 2
shows structure composition from neighboring
substructures based on these items. a, 0, and
7 are structures of neighboring substrings. The
triangles express substructures composed only
from stored patterns. The boxes express sub-
structures produced by concatenating neighbor-
ing substructures. S is composed from its neigh-
boring substructures, i.e., a and 0. In addition,
c is composed from its neighboring substruc-
tures, i.e., S and 7.
</bodyText>
<figureCaption confidence="0.995161">
Figure 2: Structure from split substructures
</figureCaption>
<bodyText confidence="0.972750333333333">
Items (A) and (B) enable such a colloquial
utterance as (1) to compose a structure by split-
ting, as shown in Figure 3.
</bodyText>
<figure confidence="0.615037">
(1) &amp;quot;Certainly sir for how many people please&amp;quot;
</figure>
<figureCaption confidence="0.998755">
Figure 3: Structure for (1)
</figureCaption>
<subsectionHeader confidence="0.8001565">
3.2 Splitting input into well-formed
parts and ill-formed parts
</subsectionHeader>
<bodyText confidence="0.992437111111111">
Item (C) splits input into well-formed parts and
ill-formed parts, and enables parsing in such
cases where the input is ill-formed or the trans-
lation rules are insufficient. The well-formed
parts can be applied patterns or they can con-
sist of one content word. The ill-formed parts,
which consist of one functional word or one
part-of-speech bigram marker, are split from the
well-formed parts.
</bodyText>
<listItem confidence="0.996722571428571">
(C) In addition to content words, boundary
markers, namely, any functional words
and inserted part-of-speech bigram mark-
ers, also create a passive arc and compose
a substructure.
(2) &amp;quot;They also have tennis courts too plus a disco&amp;quot;
(3) &amp;quot;Four please two children two adults&amp;quot;
</listItem>
<bodyText confidence="0.619214333333333">
Suppose that the substrings of utterance (2),
&amp;quot;they also have tennis courts too&amp;quot; and &amp;quot;a disco&amp;quot;,
can create a passive arc, and that the system has
not yet learned a pattern to which preposition
&amp;quot;plus&amp;quot; is relevant, such as &amp;quot;X plus r or &amp;quot;plus
X&amp;quot;.
Also, suppose that the substrings of utterance
(3), &amp;quot;four please&amp;quot; and &amp;quot;two children two adults&amp;quot;,
can create a passive arc, that part-of-speech
</bodyText>
<page confidence="0.997382">
423
</page>
<bodyText confidence="0.998882285714286">
bigram marker &amp;quot;adverb-numeral&amp;quot; is inserted be-
tween these substrings, and that the system
does not know pattern &amp;quot;X adverb-numeral Y&amp;quot; to
combine a sentence for X and a noun phrase for
Y.
By item (C), utterances (2) and (3) can be
parsed in these situations as shown in Figure 4.
</bodyText>
<figureCaption confidence="0.99495">
Figure 4: Structures for (2) and (3)
</figureCaption>
<subsectionHeader confidence="0.999625">
3.3 Structure preference
</subsectionHeader>
<bodyText confidence="0.996844586206897">
Although the splitting strategy improves ro-
bustness of the parsing, heavy dependence on
the splitting strategy should be avoided. Since
a global structure has more syntactic and se-
mantic relations than a set of fragmental ex-
pressions, in general, the translation of a global
expression tends to be better than the transla-
tion of a set of fragmental expressions. Accord-
ingly, the splitting strategy should be used as a
backup function.
Figure 5 shows three possible structures for
&amp;quot;go to Kyoto&amp;quot;. (a) is a structure relevant to pat-
tern &amp;quot;X to Y&amp;quot; at the verb phrase level. In (b),
the input string is split into two substrings, &amp;quot;go&amp;quot;
and &amp;quot;to Kyoto&amp;quot;. In (c), the input string is split
into three substrings, &amp;quot;go&amp;quot;, &amp;quot;to&amp;quot;, and &amp;quot;Kyoto&amp;quot;.
The digit described at the vertex of a triangle
is the sum of distance values for that strucure.
Among these three, (a), which does not use
splitting, is the best structure. Item (D) is regu-
lated to give low priority to structures including
split substructures.
(D) When a structure is composed by splitting,
a large distance value is assigned.
In the TDMT system, the distance value in
each variable varies from 0 to 1. We experimen-
tally assigned the distance value of 5.00 to one
application of splitting, and 0.00 to the struc-
ture including only one word or one part-of-
</bodyText>
<figure confidence="0.99911725">
0.00 0.00 0.00
5.00 to 5.00
9 Kyoto
(c)
</figure>
<figureCaption confidence="0.999954">
Figure 5: Structures for &amp;quot;go to Kyoto&amp;quot;
</figureCaption>
<bodyText confidence="0.9998447">
speech bigram marker. 2
Suppose that substructures in Figure 5 are
assigned the following distance values. The to-
tal distance value of (a) is 0.33. The splitting
is applied to (b) and (c), once and twice, re-
spectively. Therefore, the total distance value
of (b) is 0.00+0.33+5.00x 1=5.33, and that of (c)
is 0.00+0.00+0.00+5.00x 2=10.00. (a) is selected
as the best structure because it gives the small-
est total distance value.
</bodyText>
<subsectionHeader confidence="0.994076">
3.4 Translation output
</subsectionHeader>
<bodyText confidence="0.976204954545455">
The results gained from a structure correspond-
ing to a passive arc can be transferred and a
partial translation result can then be generated.
The translation result of a split structure is
formed as follows:
(E) The complete translation result is formed
by concatenating the partial translation re-
sults of each split unit.
A punctuation mark such as &amp;quot;,&amp;quot; can be in-
serted between partial translation results to
make the complete translation result clear, al-
though we cannot expect punctuation in an in-
put utterance. The EJ translation result of ut-
terance (1) is as follows:
certainly sir I for how many people please
hai nan-nmn desuka
Strings such as functional words and part-of-
speech bigram markers have no target expres-
sion, and are transferred as follows:
&apos;These values are tentatively assigned through com-
paring the splitting performance for some values, and are
effective only for the present TDMT system.
</bodyText>
<figure confidence="0.877958">
(b)
</figure>
<page confidence="0.998532">
424
</page>
<tableCaption confidence="0.999813">
Table 1: Effect of splitting on translation performance
</tableCaption>
<table confidence="0.998987666666667">
output rate (%) parsing success rate (%) output understandability (%)
w/o splitting w/ splitting w/o w/ w/o w/
3 E 95.8 100 75.5 76.7 71.8 75.9
EJ 94.2 100 75.0 76.0 81.0 84.0
JK 83.4 100 68.3 71.2 80.4 94.5
KJ 66.7 100 54.1 56.4 64.1 90.5
</table>
<figureCaption confidence="0.485978333333333">
(F) A string which does not have a target ex-
pression, is transferred to a string as
which means an incomprehensible part.
The EJ translation results of utterances (2)
and (3) are as follows. &amp;quot;i&amp;quot; denotes a splitting
position.
</figureCaption>
<figure confidence="0.377899666666667">
they also have tennis courts too I plus la disco
4 4
douyouni tenisu-kooto ga macs ari-masu, , disuko
</figure>
<bodyText confidence="0.8216255">
four pleaseladverb-numeral &apos;two children two adults
yon o-negai-shi masu , ,kodomo futari otona futari
</bodyText>
<sectionHeader confidence="0.895668" genericHeader="method">
4 Effect of splitting
</sectionHeader>
<bodyText confidence="0.999975866666667">
The splitting strategy based on items (A)—(F)
in Section 3 can be introduced to frameworks
such as TDMT, which utilize left-to-right pars-
ing and a score for a substructure. We discuss
the effect of splitting by showing experimental
results of the TDMT system&apos;s JE, EJ, Japanese-
to-Korean (JK), and Korean-to-Japanese (KJ)
translations. 3 The TDMT system, whose
domain is travel conversations, presently can
treat multi-lingual translation. The present vo-
cabulary size is about 13,000 words in JE and
JK, about 7,000 words in EJ, and about 4,000
words in KJ. The number of training sentences
is about 2,900 in JE and EJ, about 1,400 in JK,
and about 600 in KJ.
</bodyText>
<subsectionHeader confidence="0.99376">
4.1 Null-output elimination
</subsectionHeader>
<bodyText confidence="0.996814486486487">
It is crucial for a machine translation system to
output some result even though the input is in-
formed or the translation rules are insufficient.
Items (C) and (D) in Section 3, split input into
well-formed parts and ill-formed parts so that
well-formed parts can cover the input as widely
as possible. Since a content word and a pattern
&apos;In the experimental results referred to later in this
section, the input does not consist of strings but of cor-
rect morpheme sequences. This enables us to focus on
the evaluation of our splitting method by excluding cases
where the morphological analysis fails.
can be assigned some transferred results, some
translation result can be produced if the input
has at least one well-formed part.
Table 1 shows how the splitting improves the
translation performance of TDMT. More than
1,000 sentences, i.e., new data for the system,
were tested in each kind of translation. There
was no null output, and a 100 % output rate
in every translation. So, by using the splitting
method, the TDMT can eliminate null output
unless the morphological analysis gives no re-
sult or the input includes no content word. The
splitting also improves the parsing success rate
and the understandability of the output in every
translation.
The output rates of the JK and KJ transla-
tions were small without splitting because the
amount of sample sentences is less than that for
the JE and EJ translations. However, the split-
ting compensated for the shortage of sample
sentences and raised the output rate to 100 %.
Since Japanese and Korean are linguistically
close, the splitting method increases the under-
standable results for JK and KJ translations
more than for JE and EJ translations.
</bodyText>
<subsectionHeader confidence="0.99924">
4.2 Utterance splitting into sentences
</subsectionHeader>
<bodyText confidence="0.999902">
In order to gain a good translation result for
an utterance including more than one sentence,
the utterance should be split into proper sen-
tences. The distance calculation mechanism
alms to split an utterance into sentences cor-
rectly.
</bodyText>
<footnote confidence="0.6239645">
(4) &amp;quot;Yes that will be fine at five o&apos;clock we will re-
move the bed&amp;quot;
</footnote>
<bodyText confidence="0.999754111111111">
For instance, splitting is necessary to trans-
late utterance (4), which includes more than one
sentence. The candidates for (4)&apos;s structure are
shown in Figure 6. The total distance value
of (a) is 0.00+1.11+5.00x1=6.11, that of (b) is
0.00+0.00+1.11+5.00x2=11.11, and that of (c) is
0.83+0.00+0.42+5.00x2=11.25. As (a) has the
smallest total distance, it is chosen as the best
structure, and this agrees with our intuition.
</bodyText>
<page confidence="0.99699">
425
</page>
<figure confidence="0.63688675">
.83 5.00 A0.00 5.00 0&apos;42
s that wil p nom: l- e wi
ne at five o&apos;c/oc pronoun ove the ,
(e)
</figure>
<figureCaption confidence="0.997805">
Figure 6: Structures for (4)
</figureCaption>
<bodyText confidence="0.999838181818182">
We have checked the accuracy of utterance
splitting by using 277 Japanese utterances and
368 English utterances, all of which included
more than one sentence. Table 2 shows the suc-
cess rates for splitting the utterances into sen-
tences. Although TDMT can also use the pat-
tern &amp;quot;X boundary Y&amp;quot; in which X and Y are at
the sentence level to split the utterances, the
proposed splitting method increases the success
rates for splitting the utterances in both lan-
guages.
</bodyText>
<tableCaption confidence="0.989979">
Table 2: Success rates for splitting utterances
</tableCaption>
<table confidence="0.959316">
w/o splitting w/ splitting
Japanese 75.8 83.8
English 59.2 69.3
</table>
<subsectionHeader confidence="0.997425">
4.3 Translation after speech recognition
</subsectionHeader>
<bodyText confidence="0.999967222222222">
Speech recognition sometimes produces inaccu-
rate results from an actual utterance, and erro-
neous parts often provide ill-formed translation
inputs. However, our splitting method can also
produce some translation results from such mis-
recognized inputs and improve the understand-
ability of the resulting speech-translation.
Table 3 shows an example of a JE translation
of a recognition result including a substitution
error. The underlined words are misrecognized
parts. &amp;quot;youi(preparation)&amp;quot; in the utterance is re-
placed with &amp;quot;yori(postposition)&amp;quot;.
Table 4 shows an example of a JE translation
of a recognition result including an insertion er-
ror. &amp;quot;wo&amp;quot; has been inserted into the utterance
after speech recognition. The translation of the
speech recognition result, is the same as that
of the utterance except for the addition of &amp;quot;..&amp;quot;;
&amp;quot;..&amp;quot; is the translation result for &amp;quot;wo&amp;quot;, which is
a postposition mainly signing an object.
Table 5 shows an example of the EJ trans-
lation of a recognition result including a dele-
tion error. &amp;quot;&apos;s&amp;quot; in the utterance is deleted after
speech recognition. In the translation of this
result, &amp;quot;..&amp;quot; appears instead of &amp;quot;wa&amp;quot;, which is
a postposition signing topic. &amp;quot;..&amp;quot; is the trans-
lation for marker &amp;quot;pronoun-adverb&amp;quot;, which has
been inserted between &amp;quot;that&amp;quot; and &amp;quot;all&amp;quot;. The
recognition result is split into three parts &amp;quot;yes
that&amp;quot;, &amp;quot;pronoun-adverb&amp;quot;, and &amp;quot;all correct&amp;quot;. Al-
though the translations in Tables 3, 4, and
5 might be slightly degraded by the splitting,
the meaning of each utterance can be commu-
nicated with these translations.
We have experimented the effect of split-
ting on JE speech translation using 47 erro-
neous recognition results of Japanese utter-
ances. These utterances have been used as ex-
ample utterances by the TDMT system. There-
fore, for utterances correctly recognized, the
translations of the recognition results should
succeed. The erroneous recognition results were
collected from an experimental base using the
method of Shimizu (1996).
Table 6 shows the numbers of sentences at
each level based on the extent that the mean-
ing of an utterance can be understood from the
translation result. Without the splitting, only
19.1% of the erroneous recognition results are
wholly or partially understandable. The split-
ting method increases this rate to 57.4%. Fail-
ures in spite of the splitting are mainly caused
by the misrecognition of key parts such as pred-
icates.
</bodyText>
<tableCaption confidence="0.973109">
Table 6: Translation after erroneous recognition
</tableCaption>
<table confidence="0.700735857142857">
w/o splitting w/ splitting
wholly understandable 6 (12.8%) 15 (31.9%)
partially 3 (6.3%) 12 (25.5%)
understandable
misunderstood, or 6 (12.8%) 20 (42.6%)
never understandable
null output 32 (68.1%) 0 (0.0%)
</table>
<subsectionHeader confidence="0.992013">
4.4 Translation time
</subsectionHeader>
<bodyText confidence="0.989429">
Since our splitting method is performed under
left-to-right parsing, translation efficiency is not
</bodyText>
<page confidence="0.997171">
426
</page>
<table confidence="0.9364162">
•
translation input TDMT system&apos;s translation result
utterance Chousyoku no go youi wa deki masu ga We can prepare breakfast.
recognition result -FR Breakfast .. .. .. .. we can do.
Chousyoku no gowa deki masu ga
</table>
<tableCaption confidence="0.992891">
Table 4: Insertion error in JE translation
</tableCaption>
<table confidence="0.772249285714286">
•
translation input TDMT system&apos;s translation result
utterance Yes that &apos;s all correct Hai sore wa mattaku tadashii desu.
recognition result Yes that all correct Hai sore .. mattaku tadashii desu.
translation input TDMT system&apos;s translation result
utterance
recognition result
</table>
<bodyText confidence="0.9927972">
Soreto yoyaku ga hitsu you desu ka
Soreto wo yoyaku ga hitsu you desu ka
And is a reservation necessary?
And .. is a reservation necessary?
a serious problem. We have compared EJ trans-
lation times in the TDMT system for two cases.
One was without the splitting method, and the
other was with it. Table 7 shows the translation
time of English sentences with an average in-
put length of 7.1 words, and English utterances
consisting of more than one sentence with an
average input length of 11.4 words. The trans-
lation times of the TDMT system written in
LISP, were measured using a Sparc10 worksta-
tion.
</bodyText>
<tableCaption confidence="0.933312">
Table 7 Translation time of E
</tableCaption>
<bodyText confidence="0.992506571428571">
input w/o splitting w/ splitting
sentence 0.35sec 0.36sec
utterance 0.60sec 0.61sec
The time difference between the two situa-
tions is small. This shows that the translation
efficiency of TDMT is maintained even if the
splitting method is introduced to TDMT.
</bodyText>
<sectionHeader confidence="0.990501" genericHeader="conclusions">
5 Concluding remarks
</sectionHeader>
<bodyText confidence="0.999954">
We have proposed an input-splitting method
for translating spoken-language which includes
many long or ill-formed expressions. Experi-
mental results have shown that the proposed
method improves TDMT&apos;s performance with-
out degrading the translation efficiency. The
proposed method is applicable to not only
TDMT but also other frameworks that uti-
lize left-to-right parsing and a score for a
substructure. One important future research
goal is the achievement of a simultaneous in-
terpretation mechanism for application to a
practical spoken-language translation system.
The left-to-right mechanism should be main-
tained for that purpose. Our splitting method
meets this requirement, and can be applied to
multi-lingual translation because of its universal
framework.
</bodyText>
<sectionHeader confidence="0.999676" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999650612903226">
0. Furuse and H. lida. 1994. Constituent
Boundary Parsing for Example-Based Ma-
chine Translation. In Proc. of Coling &apos;94,
pages 105-111.
0. Furuse and H. lida. 1996. Incremental
Translation Utilizing Constituent Boundary
Patterns. In Proc. of Coling &apos;96, pages 412-
417.
Y.B. Kim and T. Ehara. 1994. An Auto-
matic Sentence Breaking and Subject Supple-
ment Method for J/E Machine Translation
(in Japanese). In Transactions of Informa-
tion Processing Society of Japan, Vol. 35, No.
6, pages 1018-1028.
T. Shimizu, H. Yamamoto, H. Masataki,
S. Matsunaga, and Y. Sagisaka. 1996. Spon-
taneous Dialogue Speech Recognition us-
ing Cross-word Context Constrained Word
Graphs. In Proc. of ICA SSP &apos;96, pages 145-
148.
E. Sumita and H. lida. 1992. Example-Based
Transfer of Japanese Adnominal Particles
into English. IEICE Transactions on Infor-
mation and Systems, E75-D, No. 4, pages
585-594.
Y. Wakita, J. Kawai, and H. lida. 1997. Cor-
rect parts extraction from speech recognition
results using semantic distance calculation,
and its application to speech translation. In
Proc. of A CL/EACL Workshop on Spoken
Language Translation, pages 24-31.
</reference>
<page confidence="0.998546">
427
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.927276">
<title confidence="0.9995315">Splitting Long or III-formed Input for Robust Spoken-language Translation</title>
<author confidence="0.945133">Osamu FURUSEt</author>
<author confidence="0.945133">Setsuo YAMADA</author>
<author confidence="0.945133">Kazuhide YAMAMOTO</author>
<affiliation confidence="0.992063">ATR Interpreting Telecommunications Research Laboratories</affiliation>
<address confidence="0.991835">2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan</address>
<email confidence="0.995659">furuseOcslab.kecl.ntt.co.jp,{syamada,yamamoto}Oitl.atr.co.jp</email>
<abstract confidence="0.999621526315789">This paper proposes an input-splitting method for translating spoken-language which includes many long or ill-formed expressions. The proposed method splits input into well-balanced translation units based on a semantic distance calculation. The splitting is performed during left-to-right parsing, and does not degrade translation efficiency. The complete translation result is formed by concatenating the partial translation results of each split unit. The proposed method can be incorporated into frameworks like TDMT, which utilize left-to-right parsing and a score for a substructure. Experimental results show that the proposed method gives TDMT the following advantages: (1) elimination of null outputs, (2) splitting of utterances into sentences, and (3) robust translation of erroneous speech recognition results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Furuse</author>
<author>H lida</author>
</authors>
<title>Constituent Boundary Parsing for Example-Based Machine Translation.</title>
<date>1994</date>
<booktitle>In Proc. of Coling &apos;94,</booktitle>
<pages>105--111</pages>
<marker>Furuse, lida, 1994</marker>
<rawString>0. Furuse and H. lida. 1994. Constituent Boundary Parsing for Example-Based Machine Translation. In Proc. of Coling &apos;94, pages 105-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Furuse</author>
<author>H lida</author>
</authors>
<title>Incremental Translation Utilizing Constituent Boundary Patterns.</title>
<date>1996</date>
<booktitle>In Proc. of Coling &apos;96,</booktitle>
<pages>412--417</pages>
<marker>Furuse, lida, 1996</marker>
<rawString>0. Furuse and H. lida. 1996. Incremental Translation Utilizing Constituent Boundary Patterns. In Proc. of Coling &apos;96, pages 412-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y B Kim</author>
<author>T Ehara</author>
</authors>
<title>An Automatic Sentence Breaking and Subject Supplement Method for J/E Machine Translation (in Japanese).</title>
<date>1994</date>
<journal>In Transactions of Information Processing Society of Japan,</journal>
<volume>35</volume>
<pages>1018--1028</pages>
<marker>Kim, Ehara, 1994</marker>
<rawString>Y.B. Kim and T. Ehara. 1994. An Automatic Sentence Breaking and Subject Supplement Method for J/E Machine Translation (in Japanese). In Transactions of Information Processing Society of Japan, Vol. 35, No. 6, pages 1018-1028.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Shimizu</author>
<author>H Yamamoto</author>
<author>H Masataki</author>
<author>S Matsunaga</author>
<author>Y Sagisaka</author>
</authors>
<title>Spontaneous Dialogue Speech Recognition using Cross-word Context Constrained Word Graphs.</title>
<date>1996</date>
<booktitle>In Proc. of ICA SSP &apos;96,</booktitle>
<pages>145--148</pages>
<marker>Shimizu, Yamamoto, Masataki, Matsunaga, Sagisaka, 1996</marker>
<rawString>T. Shimizu, H. Yamamoto, H. Masataki, S. Matsunaga, and Y. Sagisaka. 1996. Spontaneous Dialogue Speech Recognition using Cross-word Context Constrained Word Graphs. In Proc. of ICA SSP &apos;96, pages 145-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita</author>
<author>H lida</author>
</authors>
<title>Example-Based Transfer of Japanese Adnominal Particles into English.</title>
<date>1992</date>
<journal>IEICE Transactions on Information and Systems,</journal>
<volume>75</volume>
<pages>585--594</pages>
<marker>Sumita, lida, 1992</marker>
<rawString>E. Sumita and H. lida. 1992. Example-Based Transfer of Japanese Adnominal Particles into English. IEICE Transactions on Information and Systems, E75-D, No. 4, pages 585-594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wakita</author>
<author>J Kawai</author>
<author>H lida</author>
</authors>
<title>Correct parts extraction from speech recognition results using semantic distance calculation, and its application to speech translation.</title>
<date>1997</date>
<booktitle>In Proc. of A CL/EACL Workshop on Spoken Language Translation,</booktitle>
<pages>24--31</pages>
<marker>Wakita, Kawai, lida, 1997</marker>
<rawString>Y. Wakita, J. Kawai, and H. lida. 1997. Correct parts extraction from speech recognition results using semantic distance calculation, and its application to speech translation. In Proc. of A CL/EACL Workshop on Spoken Language Translation, pages 24-31.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>