<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001583">
<title confidence="0.982429">
Towards Ontological Question Answering
</title>
<author confidence="0.993022">
Remi Zajac
</author>
<affiliation confidence="0.981721">
Computing Research Laboratory, New Mexico State University
</affiliation>
<email confidence="0.699133">
zajacOcrl.nmsu.edu
</email>
<sectionHeader confidence="0.959281" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998569">
This paper presents an ontology-based semantic
framework to question answering. Both ques-
tion and source text are parsed into underspec-
ified semantic expressions where names of se-
mantic atoms and predicates are defined in an
interlingual ontology. Answer retrieval is done
using subsumption and unification, and queries
are expanded incrementally using ontological
rules. Ranking of answers is achieved by using
graded unification.
</bodyText>
<sectionHeader confidence="0.997973" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.99421">
1.1 Overview of the approach
</subsectionHeader>
<bodyText confidence="0.999970212765958">
This paper presents a lexical semantic frame-
work to question answering, where an interlin-
gual ontology, e.g. (Mahesh and Nirenburg,
1995; Mahesh, 1996; Raskin &amp; Nirenburg), pro-
vides the atoms and predicates used in the se-
mantic expression associated to questions and
texts. The semantic dictionaries and the ontol-
ogy are the sources of ontological rules which
are used to expand the query (the semantic
expression associated to the natural language
question). The use of a formal ontology pro-
vides a natural path towards knowledge-base
and database question answering as well as
domain-driven question-answering. This ap-
proach provides a common framework for both
cross-language question answering and mixed
text/database access.
Both question and source text are parsed
into a variant of Minimal Recursion Semantics
(Copestake et als. 95; Copestake et als. 99).
Underspecified semantic expressions ( USEs) are
associated to sentences or sentence fragments
by a robust unification-based parser. When the
parser does not produce a complete parse for a
sentence, the USE of the sentence is the con-
junction of USEs of parsed sentence fragments.
For the purpose of QA, USEs are conjoined at
the paragraph level.
In the semantic dictionary, words are given
(partial) semantic descriptions. In these de-
scriptions, concepts, roles and attributes, are
defined in an interlingual ontology (Mahesh
and Nirenburg, 1995; Mahesh, 1996; Raskin &amp;
Nirenburg). Concepts, roles and attributes par-
ticipate in their own type inheritance hierarchy.
Concepts are given definitions (as USEs), and
roles and attributes participating in the defini-
tion are given default types and default values.
Answer retrieval is done using unification on
USEs and matching answers are ranked by com-
puting the relevance of the answer to the ques-
tion. If no answer can be found using uni-
fication, the query is expanded incrementally
until an answer can be found. Query ex-
pansion uses ontological rules expressing syn-
onymic, antonymic and meronymic relations be-
tween concepts.
</bodyText>
<sectionHeader confidence="0.986943" genericHeader="introduction">
1.2 Related work
</sectionHeader>
<bodyText confidence="0.999676016949153">
Question-answering using &amp;quot;flat logical forms&amp;quot;
has been used in the ExtrAns system (Molla et
als. 00) for Unix man pages, following (Hobbs
86) for logical forms. In this system, con-
cepts are simply words and only a few domain-
dependent rules seem to be added to the sys-
tem to perform inference during the answer ex-
traction process. The rules seem to be limited
to hyperonymic relations (for example: &amp;quot;cp is-a
command&amp;quot;).
In the Falcon system (Harabagiu et als. 00),
both questions and answers are translated into
logical forms, also following Hobbs. This sys-
tem uses uses unification to retrieve poten-
tial answers. Semantic relations provided by
WordNet are used to derive so-called &amp;quot;key-
word alternations&amp;quot; (inventor/invented/invent,
killer/assassin, people/population). Hyper-
onymic relations extracted from WordNet are
used to derive axioms for the abductive prover:
prefer is like better (Hobbs et als. 93).
The Qanda system (Breck et als. 99) com-
bines IR and knowledge-representation tech-
niques in a similar way: both texts containing
potential answers and questions are parsed into
a logical form, and the question&apos;s logical form
is matched against the text&apos;s logical forms. The
logical form atoms are concepts, although the
KR framework is not described in the paper
(the description of the KR-based approach in
this paper is rather short, and no reference for
this framework is provided).
A somewhat related approach is described in
(Keselj 01). The author uses an HPSG gram-
mar to parse questions and potential answer
texts into a semantic representation, and an-
swers are extracted by matching the semantic
representation of the question and the potential
answers. This system does not seem to use any
knowledge-based representation.
Also relevant is the work done in the
knowledge-base community for accessing knowl-
edge bases using natural language queries. This
line of research has a long history, going back
perhaps to the Lunar system (Woods 77). More
recent relevant work include question answering
using Quasi-Logical Forms (Gamback &amp; Ljung
92) where QLFs queries are translated into SQL
queries for a relational database. The system
described in (Clark et als. 99) assumes that the
knowledge is stored in a knowledge base and
structured as an ontology of the domain. In
this system, the user builds interactively a KB
query, the system matches the query against a
list of query types which are themselves asso-
ciated to answer schemata. The KB inference
capabilities are used in building an answer from
answer schemata (a conceptual graph), from
which a natural language text is generated.
</bodyText>
<sectionHeader confidence="0.568749" genericHeader="method">
2 Underspecified semantic parsing
</sectionHeader>
<subsectionHeader confidence="0.798549">
2.1 Underspecified semantic
expressions
</subsectionHeader>
<bodyText confidence="0.9982218">
The semantic description of a word in the se-
mantic lexicon is a partial underspecified se-
mantic expression (USE). For example, the se-
mantics of the verb run is simply specified as
run(e)1 and almost all associated relations and
properties are inherited from the super-type of
run which is ground-contact-motion. The
expanded semantic description includes the con-
junction of predicates run(e) agent(e,a) in-
strument(e,i), etc. In the semantic dictio-
nary, the verb run and the nouns run and run-
ning share the same core semantic expression (a
run(e) event). This captures all morphosyntac-
tic variations used to refer to the same event.
Events such as run(e) are 1-place predicates
where the argument is an index on the referred
event.2 Instead of having a positional argument
notation as in (Copestake et als. 99), partici-
pants in a relation are described using relational
predicates such as agent (e,a), theme(e,t), etc.
where the first argument is linked to the event,
and the second argument is the referent of the
agent, theme, etc. This allows to represent in
a flexible way expressions where not all partici-
pants are realized in the linguistic expression.
Objects are unary predicates where the argu-
ment indexes the referent3. For example, the
word weapon is defined as weapon(x). Objects
do not have associated relational predicates as
events do, but they may have attributes that
describe properties of the object, such as size,
shape, etc. These attributes are encoded us-
ing 2-place predicates such as size(x,y) where
the second argument is an atomic value (num-
ber, symbol, string). Nouns derived from verbs
include an inverse relation to the event. For
example, the noun investor is an investor con-
cept which participates in an investment event
described by the following expression:
investor(i) agent(e,i) invest(e)
This allows for example to capture
derivational lexical relations such as in-
vest/investor/investment.
Properties (realized as lexically adjectives
and adverbs) are also unary predicates where
</bodyText>
<footnote confidence="0.7535944">
1For the sake of simplicity, we ignore in this paper
scopal information: the handle and scopal arguments of
the predicate. See (Copestake et als. 99) for details.
2A better representation would use 2 arguments, one
for the process of the event (which can be modified by
time, tense, aspect properties and adverbial expressions),
and the second argument for the concept, which can be
modified by adjectival expressions (case of light verbs for
example). See e.g. (Riehemann 97).
3Ignoring again scopal information.
</footnote>
<bodyText confidence="0.99998356">
the argument indexes the referent of the modi-
fied event or object.4
Parsing natural language expressions as un-
derspecified semantic expressions of this kind
gives a fairly a representation of language ex-
pression which abstract away from a large va-
riety of idiosyncratic morpho-syntactic forms.
At the morpho-lexical level (dictionary), a con-
cept represent a whole family of derived lexical
elements. For example, verbs and their nom-
inalizations are mapped to the same concept
(to run/a run/running), and semantically re-
lated adjectives and adverbs are also mapped
to the same concept (rapid/rapidly). At the
morpho-syntactic level (parsing), the seman-
tic representation is invariant across a large
set of syntactic forms: passive/active, topical-
ized/unmarked, and various forms of subordina-
tion and coordination. A good overview of the
paraphrasing power of this kind of semantic ex-
pressions can be found in (Mel&apos;euk 88; Mel&apos;euk
&amp; Polguere 91) for example. The exact coverage
of the morpho-syntactic variants depends there-
fore on (1) the semantic dictionary and (2) the
coverage of the parser.
</bodyText>
<subsectionHeader confidence="0.97811">
2.2 Robust semantic parsing
</subsectionHeader>
<bodyText confidence="0.979458829268293">
Underspecified semantic expressions are asso-
ciated to sentences or sentence fragments by
a robust unification-based parser. When the
parser does not produce a complete parse for
a sentence, but only a sequence of fragments
(NPs, VPs, clauses, etc.), a post-processor col-
lects fragment USEs for each phrase and asso-
ciate the conjunction of fragment USEs to the
sentence. Therefore, the semantics associated
to a sentence which has not been fully parsed
provides partial information with respect to the
semantics that would be built for a complete
parse. The partial semantic expression will
contain all semantic predicates introduced by
lexical elements and phrasals in all fragments.
However, it will lack some equalities between
variables of predicates when these predicates be-
long to fragments not connected by the parser.
Additionally, scope will also be unspecified in
these cases.
For the purpose of QA, USEs are conjoined at
4Representation of adverbial modifiers of adjectives
or adverbs use the handle variable, which is not men-
tioned in this paper.
the paragraph level. At this level, a co-reference
resolution engine, if available, might introduce
additional (co-reference) constraints.
For example, a full parse of Leonov, the first
man to walk in space produces a semantic ex-
pression such as:
name(y,&amp;quot;Leonov&amp;quot; ) first(y) man(y)
walk(w) agent (w, y) location(w,/)
space(/)
If however the parser does not produces a full
parse but only a sequence of clausal and phrasal
chunks (e.g., Leonov / the first man / to walk
in space), the partial semantic expression simply
looses some of the co-references:
name(x,&amp;quot;Leonov&amp;quot; ) first (y) man(y)
walk(w) agent(w,z) location(w,l)
space(/)
</bodyText>
<sectionHeader confidence="0.970806" genericHeader="method">
3 Retrieving answers
</sectionHeader>
<bodyText confidence="0.999896583333333">
Answer retrieval is done first using the sub-
sumption test: a potential answer is any frag-
ment/sentence/paragraph which USE is sub-
sumed by the query USE.5 If no answer can be
found, unification is used instead and results are
ranked by computing the relevance of the an-
swer to the question. If no answer can be found
using unification, the query is expanded incre-
mentally until an answer can be found. Query
expansion uses ontological rules expressing syn-
onymic, antonymic and meronymic relations be-
tween concepts6.
</bodyText>
<subsectionHeader confidence="0.989144">
3.1 Subsumption
</subsectionHeader>
<bodyText confidence="0.9996606">
The subsumption test checks that all predicates
in the question use subsume some predicates
in the potential answer use. Predicate sub-
sumption holds if the question predicate is equal
or more general (higher in the type hierarchy)
than the answer predicate. In addition, vari-
able bindings present in the question should also
hold in the answer. An other definition of sub-
sumption is that the unifier of the question and
the answer is equivalent to the answer itself.
</bodyText>
<footnote confidence="0.869947833333333">
5We can assume that relevant text passages have been
retrieved using an IR engine so that we do not need to
parse a whole collection.
6Hyponymy and hyperonymy are built in the type hi-
erarchy and are therefore used directly by the subsump-
tion and the unification algorithms.
</footnote>
<listItem confidence="0.99627175">
• Question: What is a meerkat?
• Answer: Photo, The meerkat, a type of
mongoose, thrives in its Coachella Valley
haven.
</listItem>
<bodyText confidence="0.76277175">
Using the appropriate question/answer type
categorization, the parser will produce the fol-
lowing USE for the question, where z is the dis-
tinguished variable:
</bodyText>
<equation confidence="0.957542571428571">
y / meerkat(x) typeof(x,y)
The USE for the answer will include:
photo(p) meerkat(m) typeof(m,c)
mongoose(c) thrive(e) agent(e,m)
location(e,/) possessor(m,/)
haven(/) name(/,&amp;quot; Coachella Val-
ley&amp;quot;)
</equation>
<bodyText confidence="0.959320444444445">
In this case, the semantics of the question
subsumes the semantics of the sentence and a
simple subsumption test will retrieve the text
containing the answer. Unification will provide
the variable bindings { y = ni, z = c}, and
the extraction of the sub-expression including
the distinguished variable provides the seman-
tic fragment corresponding to the answer:
mongoose(m,c)
</bodyText>
<subsectionHeader confidence="0.972565">
3.2 Unification
</subsectionHeader>
<bodyText confidence="0.967715333333333">
When no answer can be found using subsump-
tion, unification is used instead. The unified
USE contains predicates of both question and
answer. If two predicates have the same name
or have a common subtype, they are unified;
the unification of two predicates may introduce
additional variable bindings. If the two expres-
sions do not have any unifiable predicates, the
unification of the two expressions fails.
</bodyText>
<listItem confidence="0.9981815">
• Question: Who was the first Russian as-
tronaut to walk in space?
• Answer: The broad-shouldered but
paunchy Leonov, who in 1965 became
the first man to walk in space, signed
autographs.
</listItem>
<bodyText confidence="0.968183">
The USE of the question contains:
</bodyText>
<equation confidence="0.868285666666667">
x / person(x) first(x) russian(x) as-
tronaut(x) walk(w) agent(w,x) lo-
cation(w,$) space(s)
</equation>
<bodyText confidence="0.718696">
and the USE of the answer contains:
name(y,&amp;quot;Leonov&amp;quot; ) location( e,d)
</bodyText>
<equation confidence="0.8651945">
date(d,1965) first(y) man(y)
walk(w) agent(w,y) location(w,/)
space(/) sign(s) agent (s, y)
theme(s,z) autograph(z)
</equation>
<bodyText confidence="0.99210925">
In this case, the question does not subsumes
the answer since it contains predicates which
are not in the answer (russian, astronaut).
However, the two expressions share the follow-
ing predicates: first, walk, agent, location
and space. In addition, the question predicate
person unifies with man, which is a subtype of
person in the semantic type hierarchy. These
unifications also bind the variables appearing in
the predicates. Therefore, the unification suc-
ceeds and the text is a potential answer.
The unified comon sub-expression is:
man(x) first (x) walk(w) agent(w,x)
location(w,$) space(s)
If the text was only partially analyzed, some
co-references would be missing. A subsump-
tion test would fails because of missing predi-
cates in the text, but also because of missing
co-references. The use of unification however
re-introduces the missing co-references, produc-
ing the same unified common sub-expression as
above.
Valid answers. In the general case, several
answers could be found by unification since the
presence of one unifiable predicate in the an-
swer and in the text is enough to make the two
expressions unifiable. However, this does not
guaranty that the text contains the answer. To
make sure that the text actually answers the
question, we require that the distinguished vari-
able in the question be bound to a variable in
the answer. This is indeed the case in this exam-
ple through for example the unification of per-
son(x) and man(y). This unification adds the
constraint x = y and which therefore enables to
recover the information name(x,&amp;quot;Leonov&amp;quot;). If
the distinguished variable has no binding in the
answer, it is not a valid answer (the text simply
shares some semantic elements with the ques-
tion without addressing the topic of the ques-
tion itself).
Note that, unlike subsumption, typed unifica-
tion may succeed when an element in the query
is more specific than some matching element in
the text. Type unification provides a built-in
relaxation method (the use an hyponym of the
question element) for matching questions and
answers. As we may prefer specific answers to
more generic ones, the unification algorithm can
keep track of specificity information by comput-
ing a distance between the unifier and the initial
query.
</bodyText>
<subsectionHeader confidence="0.976955">
3.3 Graded Unification
</subsectionHeader>
<bodyText confidence="0.997576285714286">
Even if we restrict potential answers to the one
containing a binding for distinguished variables,
it is possible to retrieve more than one answer.
To select an appropriate answer in the set of
all answers, we compute the similarity between
questions and answers by recording how many
predicates get unified. In the example, we have:
</bodyText>
<listItem confidence="0.99793875">
• 6 question predicates unify out of a total of
8, and 2 do not unify;
• 5 answer predicates unify out of a total of
12, and 7 do not unify.
</listItem>
<bodyText confidence="0.999992636363636">
We can therefore attribute a score to the uni-
fication such as the average percentage of uni-
fied predicates in both question and answer,
58% in this case, as suggested in (Molla 01).
However, this symmetric scoring does not re-
flect the fact that, intuitively, the answer is a
much better match than the score would in-
dicate. A score that uses a measure of sub-
sumption instead seems more appropriate. We
therefore compute the ratio of unified question
predicate (number of unified question predicate
divided by the total number of question predi-
cates). This number is a measure of relevant in-
formation found in the answer. In the example,
the retrieved answer answers 75% of the ques-
tion. To this ratio, we add the number of co-
references in the unified sub-expression which
also hold in the answer text divided by the num-
ber of co-references in the query.
We also compute the ratio of non-unified an-
swer predicates (number of non-unified answer
predicates divided by the total number of an-
swer predicates). This number measures the
proportion of irrelevant information in the an-
swer (58% in the example). As for answer
relevance, we add the number of missing co-
references in the answer divided by the number
of co-references in the answer.
We then rank answers first by the proportion
of relevant information, and for answers con-
taining the same amount of relevant informa-
tion, by their proportion of irrelevant informa-
tion (to favor shorter answers).
</bodyText>
<subsectionHeader confidence="0.97803">
3.4 Incremental query reformulation
</subsectionHeader>
<bodyText confidence="0.999945185185185">
Using unification and a semantic type hierar-
chy will not solve problems when synonymous
expressions are used: synonymous expressions
traverse the ontology sideways and not along
hyponymy-hyperonymy links. When unification
fails, the query needs to be expanded to include
synonymous expressions and other types of se-
mantic variations. This is done by rewriting the
semantics of the question using ontological in-
ference rules.
An ontological inference rule is used to
rewrite part of the question&apos;s use: the left-hand
side of a rule is unified with the the use and the
match is replaced with the right-hand side. The
reformulated expression is then used to attempt
to retrieve an answer. If no answer is found, the
process is repeated iteratively. If the rules are
not recursive, the reformulation process termi-
nates and therefore the answer extraction pro-
cess terminates too.
The incremental process of query reformu-
lation using a breath-first strategy will find
an answer which is semantically closest to the
question by minimizing the number of semantic
transformations of the question, a process which
is somewhat analogous to abduction (Hobbs et
als. 93).
</bodyText>
<subsectionHeader confidence="0.547886">
Synonymy
</subsectionHeader>
<bodyText confidence="0.999985833333333">
The ontology represents a language-
independent categorization of the word,
but in many cases, synonymies do not carry
across languages. Therefore, synonymic rela-
tions are expressed as lexical relations within
the dictionary of the language, and not in the
ontology. We generate ontological synonymy
rules directly from lexical synonymy relations.
Whenever a synonymy relation holds between
2 words in the dictionary, we generate an onto-
logical rule between the semantic expressions
of these two words. If for example killer is a
synonym of assassin in English, the semantic
representation might or might not be the
same. If they are the same, no rule need to
be generated (case of true synonymy). If,
however, the semantic expressions are different,
we produce a rewrite rule:
</bodyText>
<equation confidence="0.722826">
Sem(killer) Sem(assassin)
</equation>
<bodyText confidence="0.99584">
The same method can be adapted for
antonymic relations by introducing a negation
predicate in the right-hand side.
Meronymy
Part/whole relations (part-of, subset, member
of a collection, etc.) are defined in the ontology
and can be used to generate ontological rules
for some kinds of metonymies. The concept is
replaced by the concept pointed by the part-of
relation concept (the inverse is also possible).
For example, expressions such as:
</bodyText>
<equation confidence="0.818533">
X(x) partof(x,y) Y(y)
</equation>
<bodyText confidence="0.984777481481481">
where partof can be any meronymic relation,
produce rules like
X(x)—Y(y)
Y(y)—X(x)
Type relaxation
If rules for relations such as synonymy and
meronymy fail to produce an answer, it is pos-
sible to relax the question. A relaxed question
is generated by substituting the super-type of
a predicate for the predicate itself. In such a
case, unification can occur with siblings of the
original predicate, going sideways in the type
hierarchy.
Summary
Textual variants of a natural language expres-
sion that can be dealt with this approach in-
clude (near-)synonymic lexical variations, and
a subset of metonymies (part as whole, far-
synonymy). The exact coverage of the textual
variants that can be handle will depend on the
particular ontology that is the source of the
rules. An interesting related problem would be
the processing of a larger class of metaphoric
expressions that share the same core meaning
and that are not covered by ontological rules
(Martin 90). This would require to add specific
metaphor rules to the system.
</bodyText>
<sectionHeader confidence="0.995962" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999952447368421">
We outlined an interlingual framework to ques-
tion answering based on underspecified seman-
tics and interlingual ontology. The use of a
logico-semantic framework allows to extract se-
mantically relevant answers and to justify these
answers. Associated to an ontology, the infer-
ence mechanism is extended to use ontologi-
cal knowledge. For open-text question answer-
ing, any language ontology could be used as
the source of ontological rules: Sensus (Knight
Luk 94), Mikrokosmos (Mahesh and Niren-
burg, 1995; Mahesh, 1996; Raskin &amp; Niren-
burg), Wordnet (Fellbaum et als. 91) although
the quality of the end results will obviously de-
pend on the coverage and the quality of the on-
tology.
It could also be possible to use a domain-
specific ontology for question answering on re-
stricted technical domains. A domain-specific
ontology could then be used to interface to a
knowledge-base, opening the way for mixed text
and database question answering systems on
open-domain as well as on specific domains.
The use of separate semantic lexicon and
interlingual ontology enables the development
of cross-language question answering systems,
as demonstrated for example by the Spanish-
English Crest system at CRL.7
The use of semantic expressions allows to
abstract away from a large range of morpho-
syntactic paraphrases of the same semantic ex-
pression. In addition, the use of ontological
rules allows to abstract away from lexical, tex-
tual and stylistic variants of the same semantic
expression. The exact span of theses variants
remains to be determined. This paper presents
a work in progress, and no evaluation results are
available at the time of writing.
</bodyText>
<sectionHeader confidence="0.998212" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996799883720931">
Breck, Eric, John Burger, David House, Marc
Light, Inderjeet Mani. 1999. &amp;quot;Question an-
swering from large document collections&amp;quot;.
AAAI Fall Symposium on Question Answer-
ing Systems.
7http://crl.nmsu.edu/research/projects/crest
Clark, Peter, John Thompson &amp; Bruce
Porter. 1999. &amp;quot;A knowledge-based approach
to question-answering&amp;quot;. AAAI-99 Fall Sym-
posium on Question Answering Systems.
Copestake, A, D. Flickinger, R. Malouf, S.
Riehemann, I. Sag. 1995. &amp;quot;Translation using
Minimal Recursion Semantics&amp;quot;. TMI-95.
Copestake, A, D. Flickinger, I. Sag.
1999. &amp;quot;Minimal Recursion Seman-
tics: an Introduction&amp;quot;. ms. (see
http: //www-csli. stanf ord. edu/ aac)
Gamback, Bjorn &amp; Stefan Ljung. 1992. &amp;quot;Ques-
tion answering in the Swedish Core Lan-
guage Engine. SICS Research Report R92:14,
Swedish Institute of Computer Science,
Stockholm, Sweden.
C. Fellbaum, D. Gross, G. Miller. 1991. &amp;quot;Word-
net&apos;: a lexical database organized on psy-
chlinguistic principles&amp;quot;. Lexical Acquisition:
Exploiting On-Line Resources to Build a Lex-
icon. Lawrence Erlbaum Associates.
Harabagiu, Sanda, Dan Moldovan, Marius
Pasca, Rada Mihalcea, Mihai Surdeanu, Raz-
van Bunescu, Roxana Girju, Vasile Rus &amp;
Paul Morarescu. &amp;quot;FALCON: boosting knowl-
edge for answer engines&amp;quot;. TREC-9.
Hobbs, Jerry. 1986. &amp;quot;Overview of the TACITUS
project&amp;quot;. Computational Linguistics 12(3).
Hobbs, Jerry, Mark Stickel, Doug Appelt, Paul
Martin. 1986. &amp;quot;Interpretation as Abduction.
Artificial Intelligence 63, pp69-142.
Keselj, Vlado. 2001. &amp;quot;Question Answering us-
ing Unification-based Grammar&amp;quot;. 14th Cana-
dian Conference on Artificial Intelligence,
AF2001, Ottawa, Canada, June 2001. (To ap-
pear).
Knight, K. and S. Luk. 1994. &amp;quot;Building a Large-
Scale Knowledge Base for Machine Transla-
tion&amp;quot;. Proceedings of the American Associa-
tion of Artificial Intelligence AAAI-94. Seat-
tle, WA.
Kavi Mahesh. 1996. Ontology Development for
Machine Translation: Ideology and Methodol-
ogy. Memorandum in Computer and Cogni-
tive Science, MCCS-96-292, Computing Re-
search Laboratory, New- Mexico State Uni-
versity, Las Cruces, NM.
Mahesh, K. and S. Nirenburg. 1995a. &amp;quot;A Situ-
ated Ontology for Practical NLP&amp;quot;. Proceed-
ings of the Workshop on Basic Ontological
Issues in Knowledge Sharing, International
Joint Conference on Artificial Intelligence,
Montreal, Canada.
James Martin. 1990. A computational model of
metaphor interpretation. Academic Press.
Igor Mel&apos;euk. 1988. Dependancy Syntax: Theory
and Practice. State University of New York
Press, Albany.
Igor Mel&apos;euk &amp; Alain Polguere. 1991. &amp;quot;Aspects
of the Implementation of the Meaning-Text
Model for English Generation&amp;quot;. In I. Lan-
cashire (ed.) Research in Humanities Com-
puting 1. Clarenton press, London. pp204-
215.
Molla, Diego, Gerold Schneider, Rold Schwitter
&amp; Michael Hess. 2000. &amp;quot;Answer extraction us-
ing a dependency grammar in ExtrAns&amp;quot;. TAL
41(1), pp127-156.
Molla, Diego. 2001. &amp;quot;Towards incremental se-
mantic annotation&amp;quot;. Proc. of the MMA-2001
Conference, Tokyo.
Raskin, V. and S. Nirenburg. 1996. &amp;quot;Ten
Choices for Lexical Semantics&amp;quot;. NMSU CRL
Technical Report MCCS-96-304.
Riehemann, Susanne. 1997 &amp;quot;Idiomatic construc-
tion in HPSG&amp;quot;. ms., Stanford University.
Woods, W.A. 1997. &amp;quot;Lunar rock in natural En-
glish: explorations in natural language ques-
tion answering&amp;quot;. In A. Zampolli (ed.) Linguis-
tic Structure Processing, North Holland.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.924769">
<title confidence="0.999766">Towards Ontological Question Answering</title>
<author confidence="0.989298">Remi Zajac</author>
<affiliation confidence="0.975482">Computing Research Laboratory, New Mexico State</affiliation>
<email confidence="0.999465">zajacOcrl.nmsu.edu</email>
<abstract confidence="0.995779727272727">This paper presents an ontology-based semantic framework to question answering. Both question and source text are parsed into underspecified semantic expressions where names of semantic atoms and predicates are defined in an interlingual ontology. Answer retrieval is done using subsumption and unification, and queries are expanded incrementally using ontological rules. Ranking of answers is achieved by using graded unification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Breck</author>
<author>John Burger</author>
<author>David House</author>
<author>Marc Light</author>
<author>Inderjeet Mani</author>
</authors>
<title>Question answering from large document collections&amp;quot;. AAAI Fall Symposium on Question Answering Systems.</title>
<date>1999</date>
<marker>Breck, Burger, House, Light, Mani, 1999</marker>
<rawString>Breck, Eric, John Burger, David House, Marc Light, Inderjeet Mani. 1999. &amp;quot;Question answering from large document collections&amp;quot;. AAAI Fall Symposium on Question Answering Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>John Thompson</author>
<author>Bruce Porter</author>
</authors>
<title>A knowledge-based approach to question-answering&amp;quot;. AAAI-99 Fall Symposium on Question Answering Systems.</title>
<date>1999</date>
<marker>Clark, Thompson, Porter, 1999</marker>
<rawString>Clark, Peter, John Thompson &amp; Bruce Porter. 1999. &amp;quot;A knowledge-based approach to question-answering&amp;quot;. AAAI-99 Fall Symposium on Question Answering Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>R Malouf</author>
<author>S Riehemann</author>
<author>I Sag</author>
</authors>
<title>Translation using Minimal Recursion Semantics&amp;quot;.</title>
<date>1995</date>
<tech>TMI-95.</tech>
<marker>Copestake, Flickinger, Malouf, Riehemann, Sag, 1995</marker>
<rawString>Copestake, A, D. Flickinger, R. Malouf, S. Riehemann, I. Sag. 1995. &amp;quot;Translation using Minimal Recursion Semantics&amp;quot;. TMI-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>I Sag</author>
</authors>
<title>Minimal Recursion Semantics: an Introduction&amp;quot;. ms. (see http: //www-csli. stanf ord.</title>
<date>1999</date>
<note>edu/ aac</note>
<marker>Copestake, Flickinger, Sag, 1999</marker>
<rawString>Copestake, A, D. Flickinger, I. Sag. 1999. &amp;quot;Minimal Recursion Semantics: an Introduction&amp;quot;. ms. (see http: //www-csli. stanf ord. edu/ aac)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bjorn Gamback</author>
<author>Stefan Ljung</author>
</authors>
<title>Question answering in the Swedish Core Language Engine.</title>
<date>1992</date>
<tech>SICS Research Report R92:14,</tech>
<institution>Swedish Institute of Computer Science, Stockholm, Sweden.</institution>
<marker>Gamback, Ljung, 1992</marker>
<rawString>Gamback, Bjorn &amp; Stefan Ljung. 1992. &amp;quot;Question answering in the Swedish Core Language Engine. SICS Research Report R92:14, Swedish Institute of Computer Science, Stockholm, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>G Miller</author>
</authors>
<title>Wordnet&apos;: a lexical database organized on psychlinguistic principles&amp;quot;. Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. Lawrence Erlbaum Associates.</title>
<date>1991</date>
<marker>Fellbaum, Gross, Miller, 1991</marker>
<rawString>C. Fellbaum, D. Gross, G. Miller. 1991. &amp;quot;Wordnet&apos;: a lexical database organized on psychlinguistic principles&amp;quot;. Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sanda Harabagiu</author>
<author>Dan Moldovan</author>
<author>Marius Pasca</author>
<author>Rada Mihalcea</author>
</authors>
<title>Mihai Surdeanu, Razvan Bunescu, Roxana Girju, Vasile Rus &amp; Paul Morarescu. &amp;quot;FALCON: boosting knowledge for answer engines&amp;quot;.</title>
<pages>9</pages>
<marker>Harabagiu, Moldovan, Pasca, Mihalcea, </marker>
<rawString>Harabagiu, Sanda, Dan Moldovan, Marius Pasca, Rada Mihalcea, Mihai Surdeanu, Razvan Bunescu, Roxana Girju, Vasile Rus &amp; Paul Morarescu. &amp;quot;FALCON: boosting knowledge for answer engines&amp;quot;. TREC-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Overview of the TACITUS project&amp;quot;.</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<volume>12</volume>
<issue>3</issue>
<marker>Hobbs, 1986</marker>
<rawString>Hobbs, Jerry. 1986. &amp;quot;Overview of the TACITUS project&amp;quot;. Computational Linguistics 12(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
<author>Mark Stickel</author>
<author>Doug Appelt</author>
<author>Paul Martin</author>
</authors>
<title>Interpretation as Abduction.</title>
<date>1986</date>
<journal>Artificial Intelligence</journal>
<volume>63</volume>
<pages>69--142</pages>
<marker>Hobbs, Stickel, Appelt, Martin, 1986</marker>
<rawString>Hobbs, Jerry, Mark Stickel, Doug Appelt, Paul Martin. 1986. &amp;quot;Interpretation as Abduction. Artificial Intelligence 63, pp69-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vlado Keselj</author>
</authors>
<title>Question Answering using Unification-based Grammar&amp;quot;.</title>
<date>2001</date>
<booktitle>14th Canadian Conference on Artificial Intelligence, AF2001,</booktitle>
<location>Ottawa, Canada,</location>
<note>(To appear).</note>
<marker>Keselj, 2001</marker>
<rawString>Keselj, Vlado. 2001. &amp;quot;Question Answering using Unification-based Grammar&amp;quot;. 14th Canadian Conference on Artificial Intelligence, AF2001, Ottawa, Canada, June 2001. (To appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>S Luk</author>
</authors>
<title>Building a LargeScale Knowledge Base for Machine Translation&amp;quot;.</title>
<date>1994</date>
<booktitle>Proceedings of the American Association of Artificial Intelligence AAAI-94.</booktitle>
<location>Seattle, WA.</location>
<marker>Knight, Luk, 1994</marker>
<rawString>Knight, K. and S. Luk. 1994. &amp;quot;Building a LargeScale Knowledge Base for Machine Translation&amp;quot;. Proceedings of the American Association of Artificial Intelligence AAAI-94. Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kavi Mahesh</author>
</authors>
<title>Ontology Development for Machine Translation: Ideology and Methodology.</title>
<date>1996</date>
<booktitle>Memorandum in Computer and Cognitive Science,</booktitle>
<pages>96--292</pages>
<institution>Computing Research Laboratory, New- Mexico State University,</institution>
<location>Las Cruces, NM.</location>
<contexts>
<context position="763" citStr="Mahesh, 1996" startWordPosition="105" endWordPosition="106">sents an ontology-based semantic framework to question answering. Both question and source text are parsed into underspecified semantic expressions where names of semantic atoms and predicates are defined in an interlingual ontology. Answer retrieval is done using subsumption and unification, and queries are expanded incrementally using ontological rules. Ranking of answers is achieved by using graded unification. 1 Introduction 1.1 Overview of the approach This paper presents a lexical semantic framework to question answering, where an interlingual ontology, e.g. (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg), provides the atoms and predicates used in the semantic expression associated to questions and texts. The semantic dictionaries and the ontology are the sources of ontological rules which are used to expand the query (the semantic expression associated to the natural language question). The use of a formal ontology provides a natural path towards knowledge-base and database question answering as well as domain-driven question-answering. This approach provides a common framework for both cross-language question answering and mixed text/database access. Both question and so</context>
<context position="2034" citStr="Mahesh, 1996" startWordPosition="300" endWordPosition="301">mantics (Copestake et als. 95; Copestake et als. 99). Underspecified semantic expressions ( USEs) are associated to sentences or sentence fragments by a robust unification-based parser. When the parser does not produce a complete parse for a sentence, the USE of the sentence is the conjunction of USEs of parsed sentence fragments. For the purpose of QA, USEs are conjoined at the paragraph level. In the semantic dictionary, words are given (partial) semantic descriptions. In these descriptions, concepts, roles and attributes, are defined in an interlingual ontology (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg). Concepts, roles and attributes participate in their own type inheritance hierarchy. Concepts are given definitions (as USEs), and roles and attributes participating in the definition are given default types and default values. Answer retrieval is done using unification on USEs and matching answers are ranked by computing the relevance of the answer to the question. If no answer can be found using unification, the query is expanded incrementally until an answer can be found. Query expansion uses ontological rules expressing synonymic, antonymic and meronymic relations bet</context>
<context position="21955" citStr="Mahesh, 1996" startWordPosition="3483" endWordPosition="3484"> rules (Martin 90). This would require to add specific metaphor rules to the system. 4 Conclusion We outlined an interlingual framework to question answering based on underspecified semantics and interlingual ontology. The use of a logico-semantic framework allows to extract semantically relevant answers and to justify these answers. Associated to an ontology, the inference mechanism is extended to use ontological knowledge. For open-text question answering, any language ontology could be used as the source of ontological rules: Sensus (Knight Luk 94), Mikrokosmos (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg), Wordnet (Fellbaum et als. 91) although the quality of the end results will obviously depend on the coverage and the quality of the ontology. It could also be possible to use a domainspecific ontology for question answering on restricted technical domains. A domain-specific ontology could then be used to interface to a knowledge-base, opening the way for mixed text and database question answering systems on open-domain as well as on specific domains. The use of separate semantic lexicon and interlingual ontology enables the development of cross-language question answering</context>
</contexts>
<marker>Mahesh, 1996</marker>
<rawString>Kavi Mahesh. 1996. Ontology Development for Machine Translation: Ideology and Methodology. Memorandum in Computer and Cognitive Science, MCCS-96-292, Computing Research Laboratory, New- Mexico State University, Las Cruces, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Mahesh</author>
<author>S Nirenburg</author>
</authors>
<title>A Situated Ontology for Practical NLP&amp;quot;.</title>
<date>1995</date>
<booktitle>Proceedings of the Workshop on Basic Ontological Issues in Knowledge Sharing, International Joint Conference on Artificial Intelligence,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="749" citStr="Mahesh and Nirenburg, 1995" startWordPosition="101" endWordPosition="104">.edu Abstract This paper presents an ontology-based semantic framework to question answering. Both question and source text are parsed into underspecified semantic expressions where names of semantic atoms and predicates are defined in an interlingual ontology. Answer retrieval is done using subsumption and unification, and queries are expanded incrementally using ontological rules. Ranking of answers is achieved by using graded unification. 1 Introduction 1.1 Overview of the approach This paper presents a lexical semantic framework to question answering, where an interlingual ontology, e.g. (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg), provides the atoms and predicates used in the semantic expression associated to questions and texts. The semantic dictionaries and the ontology are the sources of ontological rules which are used to expand the query (the semantic expression associated to the natural language question). The use of a formal ontology provides a natural path towards knowledge-base and database question answering as well as domain-driven question-answering. This approach provides a common framework for both cross-language question answering and mixed text/database access. Both q</context>
<context position="2020" citStr="Mahesh and Nirenburg, 1995" startWordPosition="296" endWordPosition="299">iant of Minimal Recursion Semantics (Copestake et als. 95; Copestake et als. 99). Underspecified semantic expressions ( USEs) are associated to sentences or sentence fragments by a robust unification-based parser. When the parser does not produce a complete parse for a sentence, the USE of the sentence is the conjunction of USEs of parsed sentence fragments. For the purpose of QA, USEs are conjoined at the paragraph level. In the semantic dictionary, words are given (partial) semantic descriptions. In these descriptions, concepts, roles and attributes, are defined in an interlingual ontology (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg). Concepts, roles and attributes participate in their own type inheritance hierarchy. Concepts are given definitions (as USEs), and roles and attributes participating in the definition are given default types and default values. Answer retrieval is done using unification on USEs and matching answers are ranked by computing the relevance of the answer to the question. If no answer can be found using unification, the query is expanded incrementally until an answer can be found. Query expansion uses ontological rules expressing synonymic, antonymic and meronymic</context>
<context position="21941" citStr="Mahesh and Nirenburg, 1995" startWordPosition="3478" endWordPosition="3482">e not covered by ontological rules (Martin 90). This would require to add specific metaphor rules to the system. 4 Conclusion We outlined an interlingual framework to question answering based on underspecified semantics and interlingual ontology. The use of a logico-semantic framework allows to extract semantically relevant answers and to justify these answers. Associated to an ontology, the inference mechanism is extended to use ontological knowledge. For open-text question answering, any language ontology could be used as the source of ontological rules: Sensus (Knight Luk 94), Mikrokosmos (Mahesh and Nirenburg, 1995; Mahesh, 1996; Raskin &amp; Nirenburg), Wordnet (Fellbaum et als. 91) although the quality of the end results will obviously depend on the coverage and the quality of the ontology. It could also be possible to use a domainspecific ontology for question answering on restricted technical domains. A domain-specific ontology could then be used to interface to a knowledge-base, opening the way for mixed text and database question answering systems on open-domain as well as on specific domains. The use of separate semantic lexicon and interlingual ontology enables the development of cross-language ques</context>
</contexts>
<marker>Mahesh, Nirenburg, 1995</marker>
<rawString>Mahesh, K. and S. Nirenburg. 1995a. &amp;quot;A Situated Ontology for Practical NLP&amp;quot;. Proceedings of the Workshop on Basic Ontological Issues in Knowledge Sharing, International Joint Conference on Artificial Intelligence, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A computational model of metaphor interpretation.</title>
<date>1990</date>
<publisher>Academic Press.</publisher>
<marker>Martin, 1990</marker>
<rawString>James Martin. 1990. A computational model of metaphor interpretation. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel&apos;euk</author>
</authors>
<title>Dependancy Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>Albany.</location>
<marker>Mel&apos;euk, 1988</marker>
<rawString>Igor Mel&apos;euk. 1988. Dependancy Syntax: Theory and Practice. State University of New York Press, Albany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel&apos;euk</author>
<author>Alain Polguere</author>
</authors>
<title>Aspects of the Implementation of the Meaning-Text Model for English Generation&amp;quot;.</title>
<date>1991</date>
<booktitle>Research in Humanities Computing 1. Clarenton press, London.</booktitle>
<pages>204--215</pages>
<editor>In I. Lancashire (ed.)</editor>
<marker>Mel&apos;euk, Polguere, 1991</marker>
<rawString>Igor Mel&apos;euk &amp; Alain Polguere. 1991. &amp;quot;Aspects of the Implementation of the Meaning-Text Model for English Generation&amp;quot;. In I. Lancashire (ed.) Research in Humanities Computing 1. Clarenton press, London. pp204-215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Molla</author>
<author>Gerold Schneider</author>
<author>Rold Schwitter</author>
<author>Michael Hess</author>
</authors>
<title>Answer extraction using a dependency grammar in ExtrAns&amp;quot;.</title>
<date>2000</date>
<journal>TAL</journal>
<volume>41</volume>
<issue>1</issue>
<pages>127--156</pages>
<marker>Molla, Schneider, Schwitter, Hess, 2000</marker>
<rawString>Molla, Diego, Gerold Schneider, Rold Schwitter &amp; Michael Hess. 2000. &amp;quot;Answer extraction using a dependency grammar in ExtrAns&amp;quot;. TAL 41(1), pp127-156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Molla</author>
</authors>
<title>Towards incremental semantic annotation&amp;quot;.</title>
<date>2001</date>
<booktitle>Proc. of the MMA-2001 Conference,</booktitle>
<location>Tokyo.</location>
<marker>Molla, 2001</marker>
<rawString>Molla, Diego. 2001. &amp;quot;Towards incremental semantic annotation&amp;quot;. Proc. of the MMA-2001 Conference, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>S Nirenburg</author>
</authors>
<title>Ten Choices for Lexical Semantics&amp;quot;.</title>
<date>1996</date>
<tech>NMSU CRL Technical Report MCCS-96-304.</tech>
<marker>Raskin, Nirenburg, 1996</marker>
<rawString>Raskin, V. and S. Nirenburg. 1996. &amp;quot;Ten Choices for Lexical Semantics&amp;quot;. NMSU CRL Technical Report MCCS-96-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susanne Riehemann</author>
</authors>
<title>Idiomatic construction in HPSG&amp;quot;. ms.,</title>
<date>1997</date>
<institution>Stanford University.</institution>
<marker>Riehemann, 1997</marker>
<rawString>Riehemann, Susanne. 1997 &amp;quot;Idiomatic construction in HPSG&amp;quot;. ms., Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Lunar rock in natural English: explorations in natural language question answering&amp;quot;.</title>
<date>1997</date>
<booktitle>Linguistic Structure Processing,</booktitle>
<editor>In A. Zampolli (ed.)</editor>
<location>North Holland.</location>
<marker>Woods, 1997</marker>
<rawString>Woods, W.A. 1997. &amp;quot;Lunar rock in natural English: explorations in natural language question answering&amp;quot;. In A. Zampolli (ed.) Linguistic Structure Processing, North Holland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>