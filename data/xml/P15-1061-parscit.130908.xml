<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000060">
<title confidence="0.959531">
Classifying Relations by Ranking with Convolutional Neural Networks
</title>
<note confidence="0.48792975">
Cicero Nogueira dos Santos
IBM Research
138/146 Av. Pasteur
Rio de Janeiro, RJ, Brazil
</note>
<email confidence="0.995055">
cicerons@br.ibm.com
</email>
<author confidence="0.96553">
Bing Xiang
</author>
<affiliation confidence="0.585954666666667">
IBM Watson
1101 Kitchawan
Yorktown Heights, NY, USA
</affiliation>
<email confidence="0.993358">
bingxia@us.ibm.com
</email>
<author confidence="0.91157">
Bowen Zhou
</author>
<affiliation confidence="0.560692333333333">
IBM Watson
1101 Kitchawan
Yorktown Heights, NY, USA
</affiliation>
<email confidence="0.997248">
zhou@us.ibm.com
</email>
<sectionHeader confidence="0.993862" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999955259259259">
Relation classification is an important se-
mantic processing task for which state-of-
the-art systems still rely on costly hand-
crafted features. In this work we tackle the
relation classification task using a convo-
lutional neural network that performs clas-
sification by ranking (CR-CNN). We pro-
pose a new pairwise ranking loss function
that makes it easy to reduce the impact
of artificial classes. We perform experi-
ments using the the SemEval-2010 Task
8 dataset, which is designed for the task
of classifying the relationship between two
nominals marked in a sentence. Using CR-
CNN, we outperform the state-of-the-art
for this dataset and achieve a F1 of 84.1
without using any costly handcrafted fea-
tures. Additionally, our experimental re-
sults show that: (1) our approach is more
effective than CNN followed by a soft-
max classifier; (2) omitting the representa-
tion of the artificial class Other improves
both precision and recall; and (3) using
only word embeddings as input features is
enough to achieve state-of-the-art results if
we consider only the text between the two
target nominals.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999722294117647">
Relation classification is an important Natural
Language Processing (NLP) task which is nor-
mally used as an intermediate step in many com-
plex NLP applications such as question-answering
and automatic knowledge base construction. Since
the last decade there has been increasing interest
in applying machine learning approaches to this
task (Zhang, 2004; Qian et al., 2009; Rink and
Harabagiu, 2010). One reason is the availability
of benchmark datasets such as the SemEval-2010
task 8 dataset (Hendrickx et al., 2010), which en-
codes the task of classifying the relationship be-
tween two nominals marked in a sentence. The
following sentence contains an example of the
Component-Whole relation between the nominals
“introduction” and “book”.
The [introduction],, in the [book],, is a
summary of what is in the text.
Some recent work on relation classification has
focused on the use of deep neural networks with
the aim of reducing the number of handcrafted fea-
tures (Socher et al., 2012; Zeng et al., 2014; Yu et
al., 2014). However, in order to achieve state-of-
the-art results these approaches still use some fea-
tures derived from lexical resources such as Word-
Net or NLP tools such as dependency parsers and
named entity recognizers (NER).
In this work, we propose a new convolutional
neural network (CNN), which we name Classifi-
cation by Ranking CNN (CR-CNN), to tackle the
relation classification task. The proposed network
learns a distributed vector representation for each
relation class. Given an input text segment, the
network uses a convolutional layer to produce a
distributed vector representation of the text and
compares it to the class representations in order
to produce a score for each class. We propose a
new pairwise ranking loss function that makes it
easy to reduce the impact of artificial classes. We
perform an extensive number of experiments using
the the SemEval-2010 Task 8 dataset. Using CR-
CNN, and without the need for any costly hand-
crafted feature, we outperform the state-of-the-art
for this dataset. Our experimental results are ev-
idence that: (1) CR-CNN is more effective than
CNN followed by a softmax classifier; (2) omit-
ting the representation of the artificial class Other
improves both precision and recall; and (3) using
only word embeddings as input features is enough
to achieve state-of-the-art results if we consider
only the text between the two target nominals.
</bodyText>
<page confidence="0.981558">
626
</page>
<note confidence="0.978266666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 626–634,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.995343875">
The remainder of the paper is structured as fol-
lows. Section 2 details the proposed neural net-
work. In Section 3, we present details about the
setup of experimental evaluation, and then de-
scribe the results in Section 4. In Section 5, we
discuss previous work in deep neural networks
for relation classification and for other NLP tasks.
Section 6 presents our conclusions.
</bodyText>
<sectionHeader confidence="0.980527" genericHeader="method">
2 The Proposed Neural Network
</sectionHeader>
<bodyText confidence="0.999902153846154">
Given a sentence x and two target nouns, CR-CNN
computes a score for each relation class c ∈ C.
For each class c ∈ C, the network learns a dis-
tributed vector representation which is encoded as
a column in the class embedding matrix Wclasses.
As detailed in Figure 1, the only input for the net-
work is the tokenized text string of the sentence. In
the first step, CR-CNN transforms words into real-
valued feature vectors. Next, a convolutional layer
is used to construct a distributed vector represen-
tations of the sentence, rx. Finally, CR-CNN com-
putes a score for each relation class c ∈ C by per-
forming adot product between rx and W
</bodyText>
<subsectionHeader confidence="0.996097">
2.1 Word Embeddings
</subsectionHeader>
<bodyText confidence="0.999860857142857">
The first layer of the network transforms words
into representations that capture syntactic and
semantic information about the words. Given
a sentence x consisting of N words x =
{w1, w2, ..., wN}, every word wn is converted into
a real-valued vector rw-. Therefore, the input to
the next layer is a sequence of real-valued vectors
</bodyText>
<equation confidence="0.911998">
f wl w2 wN l
embx = jr 1l, r , ..., r f
</equation>
<bodyText confidence="0.998851666666667">
Word representations are encoded by column
vectors in an embedding matrix Wwrd ∈ Rd&apos;×|V |,
where V is a fixed-sized vocabulary. Each column
</bodyText>
<subsectionHeader confidence="0.822795">
Wwrd i∈ Rd
</subsectionHeader>
<bodyText confidence="0.990557666666667">
of the i-th word in the vocabulary. We transform a
word w into its word embedding rw by using the
matrix-vector product:
</bodyText>
<equation confidence="0.701727">
rw = Wwrdvw
</equation>
<bodyText confidence="0.9977862">
where vw is a vector of size |V  |which has value
1 at index w and zero in all other positions. The
matrix Wwrd is a parameter to be learned, and the
size of the word embedding dw is a hyperparame-
ter to be chosen by the user.
</bodyText>
<subsectionHeader confidence="0.995318">
2.2 Word Position Embeddings
</subsectionHeader>
<bodyText confidence="0.958342185185185">
In the task of relation classification, information
that is needed to determine the class of a relation
Figure 1: CR-CNN: a Neural Network for classi-
fying by ranking.
between two target nouns normally comes from
words which are close to the target nouns. Zeng
et al. (2014) propose the use of word position em-
beddings (position features) which help the CNN
by keeping track of how close words are to the tar-
get nouns. These features are similar to the posi-
tion features proposed by Collobert et al. (2011)
for the Semantic Role Labeling task.
In this work we also experiment with the word
position embeddings (WPE) proposed by Zeng et
al. (2014). The WPE is derived from the relative
distances of the current word to the target noun1
and noun2. For instance, in the sentence shown in
Figure 1, the relative distances of left to car and
plant are -1 and 2, respectively. As in (Collobert
et al., 2011), each relative distance is mapped to
a vector of dimension dwpe, which is initialized
with random numbers. dwpe is a hyperparameter
of the network. Given the vectors wp1 and wp2 for
the word w with respect to the targets noun1 and
noun2, the position embedding of w is given by
classes.
corresponds to the word embedding
</bodyText>
<page confidence="0.997303">
627
</page>
<bodyText confidence="0.9993015">
the concatenation of these two vectors, wpew =
[wp1, wp2].
In the experiments where word position
embeddings are used, the word embed-
ding and the word position embedding of
each word are concatenated to form the
input for the convolutional layer, embx =
{[rw1, wpew1], [rw2, wpew2], ..., [rwN , wpewN ]}.
</bodyText>
<subsectionHeader confidence="0.999701">
2.3 Sentence Representation
</subsectionHeader>
<bodyText confidence="0.999815416666667">
The next step in the NN consists in creating the
distributed vector representation rx for the input
sentence x. The main challenges in this step are
the sentence size variability and the fact that im-
portant information can appear at any position in
the sentence. In recent work, convolutional ap-
proaches have been used to tackle these issues
when creating representations for text segments
of different sizes (Zeng et al., 2014; Hu et al.,
2014; dos Santos and Gatti, 2014) and character-
level representations of words of different sizes
(dos Santos and Zadrozny, 2014). Here, we use
a convolutional layer to compute distributed vec-
tor representations of the sentence. The convo-
lutional layer first produces local features around
each word in the sentence. Then, it combines these
local features using a max operation to create a
fixed-sized vector for the input sentence.
Given a sentence x, the convolutional layer ap-
plies a matrix-vector operation to each window
of size k of successive windows in embx =
{rw1, rw2, ..., rwN}. Let us define the vector zn E
Rdwk as the concatenation of a sequence of k word
embeddings, centralized in the n-th word:
</bodyText>
<equation confidence="0.875641">
zn = (rwn−(k−1)/2, ..., rwn+(k−1)/2)T
</equation>
<bodyText confidence="0.981247227272727">
In order to overcome the issue of referencing
words with indices outside of the sentence bound-
aries, we augment the sentence with a special
padding token replicated k −1
2 times at the be-
ginning and the end.
The convolutional layer computes the j-th ele-
ment of the vector rx E Rdc as follows:
[rx]j = 1max [f (W1zn + b1)] j
where W1 E Rdc×dwk is the weight matrix of the
convolutional layer and f is the hyperbolic tangent
function. The same matrix is used to extract local
features around each word window of the given
sentence. The fixed-sized distributed vector rep-
resentation for the sentence is obtained by using
the max over all word windows. Matrix W1 and
vector b1 are parameters to be learned. The num-
ber of convolutional units dc, and the size of the
word context window k are hyperparameters to be
chosen by the user. It is important to note that dc
corresponds to the size of the sentence representa-
tion.
</bodyText>
<subsectionHeader confidence="0.999754">
2.4 Class embeddings and Scoring
</subsectionHeader>
<bodyText confidence="0.99996125">
Given the distributed vector representation of the
input sentence x, the network with parameter set
θ computes the score for a class label c E C by
using the dot product
</bodyText>
<equation confidence="0.588773">
sθ(x)c = rTx[Wclasses] c
</equation>
<bodyText confidence="0.974373153846154">
where Wclasses is an embedding matrix whose
columns encode the distributed vector representa-
tions of the different class labels, and [Wclasses]c
is the column vector that contains the embedding
of the class c. Note that the number of dimensions
in each class embedding must be equal to the size
of the sentence representation, which is defined by
dc. The embedding matrix Wclasses is a parame-
ter to be learned by the network. It is initialized
by randomly sampling each value from an uniform
� 6
distribution: U (−r, r), where r =
JCJ + dc.
</bodyText>
<subsectionHeader confidence="0.992729">
2.5 Training Procedure
</subsectionHeader>
<bodyText confidence="0.9974549">
Our network is trained by minimizing a pairwise
ranking loss function over the training set D. The
input for each training round is a sentence x and
two different class labels y+ E C and c− E C,
where y+ is a correct class label for x and c− is
not. Let sθ(x)y+ and sθ(x)c− be respectively the
scores for class labels y+ and c− generated by the
network with parameter set θ. We propose a new
logistic loss function over these scores in order to
train CR-CNN:
</bodyText>
<equation confidence="0.9979485">
L = log(1 + exp(γ(m+ − sθ(x)y+)) (1)
+ log(1 + exp(γ(m− + sθ(x)c−))
</equation>
<bodyText confidence="0.999357666666667">
where m+ and m− are margins and γ is a scal-
ing factor that magnifies the difference between
the score and the margin and helps to penalize
more on the prediction errors. The first term in
the right side of Equation 1 decreases as the score
sθ(x)y+ increases. The second term in the right
</bodyText>
<page confidence="0.994116">
628
</page>
<bodyText confidence="0.999958785714286">
side decreases as the score se(x)c− decreases.
Training CR-CNN by minimizing the loss func-
tion in Equation 1 has the effect of training to give
scores greater than m+ for the correct class and
(negative) scores smaller than −m− for incorrect
classes. In our experiments we set ry to 2, m+ to
2.5 and m− to 0.5. We use L2 regularization by
adding the term Q11θ112 to Equation 1. In our ex-
periments we set Q to 0.001. We use stochastic
gradient descent (SGD) to minimize the loss func-
tion with respect to θ.
Like some other ranking approaches that only
update two classes/examples at every training
round (Weston et al., 2011; Gao et al., 2014), we
can efficiently train the network for tasks which
have a very large number of classes. This is an
advantage over softmax classifiers.
On the other hand, sampling informative nega-
tive classes/examples can have a significant impact
in the effectiveness of the learned model. In the
case of our loss function, more informative nega-
tive classes are the ones with a score larger than
−m−. The number of classes in the relation clas-
sification dataset that we use in our experiments is
small. Therefore, in our experiments, given a sen-
tence x with class label y+, the incorrect class c−
that we choose to perform a SGD step is the one
with the highest score among all incorrect classes
</bodyText>
<equation confidence="0.762784">
c− = arg max se(x)c.
c ∈ C; c6=y+
</equation>
<bodyText confidence="0.999893545454545">
For tasks where the number of classes is large,
we can fix a number of negative classes to be con-
sidered at each example and select the one with
the largest score to perform a gradient step. This
approach is similar to the one used by Weston et
al. (2014) to select negative examples.
We use the backpropagation algorithm to com-
pute gradients of the network. In our experi-
ments, we implement the CR-CNN architecture
and the backpropagation algorithm using Theano
(Bergstra et al., 2010).
</bodyText>
<subsectionHeader confidence="0.993818">
2.6 Special Treatment of Artificial Classes
</subsectionHeader>
<bodyText confidence="0.999973827586207">
In this work, we consider a class as artificial if it is
used to group items that do not belong to any of the
actual classes. An example of artificial class is the
class Other in the SemEval 2010 relation classifi-
cation task. In this task, the artificial class Other
is used to indicate that the relation between two
nominals does not belong to any of the nine rela-
tion classes of interest. Therefore, the class Other
is very noisy since it groups many different types
of relations that may not have much in common.
An important characteristic of CR-CNN is that
it makes it easy to reduce the effect of artificial
classes by omitting their embeddings. If the em-
bedding of a class label c is omitted, it means that
the embedding matrix Wclasses does not contain
a column vector for c. One of the main benefits
from this strategy is that the learning process fo-
cuses on the “natural” classes only. Since the em-
bedding of the artificial class is omitted, it will not
influence the prediction step, i.e., CR-CNN does
not produce a score for the artificial class.
In our experiments with the SemEval-2010 rela-
tion classification task, when training with a sen-
tence x whose class label y = Other, the first
term in the right side of Equation 1 is set to
zero. During prediction time, a relation is clas-
sified as Other only if all actual classes have neg-
ative scores. Otherwise, it is classified with the
class which has the largest score.
</bodyText>
<sectionHeader confidence="0.99984" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.998907">
3.1 Dataset and Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.988599642857143">
We use the SemEval-2010 Task 8 dataset to per-
form our experiments. This dataset contains
10,717 examples annotated with 9 different rela-
tion types and an artificial relation Other, which
is used to indicate that the relation in the exam-
ple does not belong to any of the nine main rela-
tion types. The nine relations are Cause-Effect,
Component-Whole, Content-Container, Entity-
Destination, Entity-Origin, Instrument-Agency,
Member-Collection, Message-Topic and Product-
Producer. Each example contains a sentence
marked with two nominals e1 and e2, and the
task consists of predicting the relation between
the two nominals taking into consideration the di-
rectionality. That means that the relation Cause-
Effect(e1,e2) is different from the relation Cause-
Effect(e2,e1), as shown in the examples below.
More information about this dataset can be found
in (Hendrickx et al., 2010).
The [war]„ resulted in other collateral imperial
[conquests],, as well. ⇒ Cause-Effect(e1,e2)
The [burst],, has been caused by water hammer
[pressure],2. ⇒ Cause-Effect(e2,e1)
The SemEval-2010 Task 8 dataset is already
partitioned into 8,000 training instances and 2,717
test instances. We score our systems by using the
SemEval-2010 Task 8 official scorer, which com-
putes the macro-averaged F1-scores for the nine
</bodyText>
<page confidence="0.99635">
629
</page>
<bodyText confidence="0.9802995">
actual relations (excluding Other) and takes the di-
rectionality into consideration.
</bodyText>
<subsectionHeader confidence="0.999223">
3.2 Word Embeddings Initialization
</subsectionHeader>
<bodyText confidence="0.999321210526316">
The word embeddings used in our experiments are
initialized by means of unsupervised pre-training.
We perform pre-training using the skip-gram NN
architecture (Mikolov et al., 2013) available in
the word2vec tool. We use the December 2013
snapshot of the English Wikipedia corpus to train
word embeddings with word2vec. We prepro-
cess the Wikipedia text using the steps described
in (dos Santos and Gatti, 2014): (1) removal of
paragraphs that are not in English; (2) substitu-
tion of non-western characters for a special char-
acter; (3) tokenization of the text using the to-
kenizer available with the Stanford POS Tagger
(Toutanova et al., 2003); (4) removal of sentences
that are less than 20 characters long (including
white spaces) or have less than 5 tokens. (5) lower-
case all words and substitute each numerical digit
by a 0. The resulting clean corpus contains about
1.75 billion tokens.
</bodyText>
<subsectionHeader confidence="0.987033">
3.3 Neural Network Hyper-parameter
</subsectionHeader>
<bodyText confidence="0.9999399">
We use 4-fold cross-validation to tune the neu-
ral network hyperparameters. Learning rates in
the range of 0.03 and 0.01 give relatively simi-
lar results. Best results are achieved using be-
tween 10 and 15 training epochs, depending on
the CR-CNN configuration. In Table 1, we show
the selected hyperparameter values. Additionally,
we use a learning rate schedule that decreases the
learning rate A according to the training epoch t.
The learning rate for epoch t, At, is computed us-
</bodyText>
<equation confidence="0.549625333333333">
A
ing the equation: At = .
t
</equation>
<table confidence="0.999662">
Parameter Parameter Name Value
dw Word Emb. size 400
dwpe Word Pos. Emb. size 70
dc Convolutinal Units 1000
k Context Window size 3
A Initial Learning Rate 0.025
</table>
<tableCaption confidence="0.998476">
Table 1: CR-CNN Hyperparameters
</tableCaption>
<sectionHeader confidence="0.997886" genericHeader="method">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.9957405">
4.1 Word Position Embeddings and Input
Text Span
</subsectionHeader>
<bodyText confidence="0.997433567567568">
In the experiments discussed in this section we as-
sess the impact of using word position embeddings
(WPE) and also propose a simpler alternative ap-
proach that is almost as effective as WPEs. The
main idea behind the use of WPEs in relation clas-
sification task is to give some hint to the convo-
lutional layer of how close a word is to the target
nouns, based on the assumption that closer words
have more impact than distant words.
Here we hypothesize that most of the informa-
tion needed to classify the relation appear between
the two target nouns. Based on this hypothesis,
we perform an experiment where the input for the
convolutional layer consists of the word embed-
dings of the word sequence {we, −1, ..., we, + 1}
where e1 and e2 correspond to the positions of the
first and the second target nouns, respectively.
In Table 2 we compare the results of different
CR-CNN configurations. The first column indi-
cates whether the full sentence was used (Yes) or
whether the text span between the target nouns
was used (No). The second column informs if
the WPEs were used or not. It is clear that the
use of WPEs is essential when the full sentence is
used, since F1 jumps from 74.3 to 84.1. This ef-
fect of WPEs is reported by (Zeng et al., 2014). On
the other hand, when using only the text span be-
tween the target nouns, the impact of WPE is much
smaller. With this strategy, we achieve a F1 of 82.8
using only word embeddings as input, which is a
result as good as the previous state-of-the-art F1 of
83.0 reported in (Yu et al., 2014) for the SemEval-
2010 Task 8 dataset. This experimental result also
suggests that, in this task, the CNN works better
for short texts.
All experiments reported in the next sections
use CR-CNN with full sentence and WPEs.
</bodyText>
<table confidence="0.999395166666667">
Full Word Prec. Rec. F1
Sentence Position
Yes Yes 83.7 84.7 84.1
No Yes 83.3 83.9 83.5
No No 83.4 82.3 82.8
Yes No 78.1 71.5 74.3
</table>
<tableCaption confidence="0.9875895">
Table 2: Comparison of different CR-CNN con-
figurations.
</tableCaption>
<page confidence="0.995977">
630
</page>
<subsectionHeader confidence="0.878611">
4.2 Impact of Omitting the Embedding of the
artificial class Other
</subsectionHeader>
<bodyText confidence="0.999775647058824">
In this experiment we assess the impact of omit-
ting the embedding of the class Other. As we
mentioned above, this class is very noisy since it
groups many different infrequent relation types.
Its embedding is difficult to define and therefore
brings noise into the classification process of the
natural classes. In Table 3 we present the results
comparing the use and omission of embedding
for the class Other. The two first lines of results
present the official F1, which does not take into
account the results for the class Other. We can see
that by omitting the embedding of the class Other
both precision and recall for the other classes im-
prove, which results in an increase of 1.4 in the
F1. These results suggest that the strategy we use
in CR-CNN to avoid the noise of artificial classes
is effective.
</bodyText>
<table confidence="0.998803666666667">
Use embedding Class Prec. Rec. F1
of class Other
No All 83.7 84.7 84.1
Yes All 81.3 84.3 82.7
No Other 52.0 48.7 50.3
Yes Other 60.1 48.7 53.8
</table>
<tableCaption confidence="0.980531">
Table 3: Impact of not using an embedding for the
artificial class Other.
</tableCaption>
<bodyText confidence="0.999499916666667">
In the two last lines of Table 3 we present the
results for the class Other. We can note that
while the recall for the cases classified as Other
remains 48.7, the precision significantly decreases
from 60.1 to 52.0 when the embedding of the class
Other is not used. That means that more cases
from natural classes (all) are now been classified
as Other. However, as both the precision and the
recall of the natural classes increase, the cases that
are now classified as Other must be cases that are
also wrongly classified when the embedding of the
class Other is used.
</bodyText>
<subsectionHeader confidence="0.984852">
4.3 CR-CNN versus CNN+Softmax
</subsectionHeader>
<bodyText confidence="0.999824214285714">
In this section we report experimental results com-
paring CR-CNN with CNN+Softmax. In order
to do a fair comparison, we’ve implemented a
CNN+Softmax and trained it with the same data,
word embeddings and WPEs used in CR-CNN.
Concretely, our CNN+Softmax consists in getting
the output of the convolutional layer, which is the
vector r,, in Figure 1, and giving it as input for
a softmax classifier. We tune the parameters of
CNN+Softmax by using a 4-fold cross-validation
with the training set. Compared to the hyperpa-
rameter values for CR-CNN presented in Table 1,
the only difference for CNN+Softmax is the num-
ber of convolutional units d&apos;, which is set to 400.
In Table 4 we compare the results of CR-
CNN and CNN+Softmax. CR-CNN outperforms
CNN+Softmax in both precision and recall, and
improves the F1 by 1.6. The third line in Ta-
ble 4 shows the result reported by Zeng et al.
(2014) when only word embeddings and WPEs
are used as input to the network (similar to our
CNN+Softmax). We believe that the word embed-
dings employed by them is the main reason their
result is much worse than that of CNN+Softmax.
We use word embeddings of size 400 while they
use word embeddings of size 50, which were
trained using much less unlabeled data than we
did.
</bodyText>
<table confidence="0.9996044">
Neural Net. Prec. Rec. F1
CR-CNN 83.7 84.7 84.1
CNN+SoftMax 82.1 83.1 82.5
CNN+SoftMax - - 78.9
(Zeng et al., 2014)
</table>
<tableCaption confidence="0.988215">
Table 4: Comparison of results of CR-CNN and
CNN+Softmax.
</tableCaption>
<subsectionHeader confidence="0.999575">
4.4 Comparison with the State-of-the-art
</subsectionHeader>
<bodyText confidence="0.9999001">
In Table 5 we compare CR-CNN results with
results recently published for the SemEval-2010
Task 8 dataset. Rink and Harabagiu (2010) present
a support vector machine (SVM) classifier that is
fed with a rich (traditional) feature set. It ob-
tains an F1 of 82.2, which was the best result
at SemEval-2010 Task 8. Socher et al. (2012)
present results for a recursive neural network
(RNN) that employs a matrix-vector representa-
tion to every node in a parse tree in order to com-
pose the distributed vector representation for the
complete sentence. Their method is named the
matrix-vector recursive neural network (MVRNN)
and achieves a F1 of 82.4 when POS, NER and
WordNet features are used. In (Zeng et al., 2014),
the authors present results for a CNN+Softmax
classifier which employs lexical and sentence-
level features. Their classifier achieves a F1 of
82.7 when adding a handcrafted feature based on
the WordNet. Yu et al. (2014) present the Factor-
</bodyText>
<page confidence="0.997212">
631
</page>
<bodyText confidence="0.99991985">
based Compositional Embedding Model (FCM),
which achieves a F1 of 83.0 by deriving sentence-
level and substructure embeddings from word em-
beddings utilizing dependency trees and named
entities.
As we can see in the last line of Table 5, CR-
CNN using the full sentence, word embeddings
and WPEs outperforms all previous reported re-
sults and reaches a new state-of-the-art F1 of 84.1.
This is a remarkable result since we do not use
any complicated features that depend on external
lexical resources such as WordNet and NLP tools
such as named entity recognizers (NERs) and de-
pendency parsers.
We can see in Table 5 that CR-CNN1 also
achieves the best result among the systems that
use word embeddings as the only input features.
The closest result (80.6), which is produced by the
FCM system of Yu et al. (2014), is 2.2 F1 points
behind CR-CNN result (82.8).
</bodyText>
<subsectionHeader confidence="0.9829195">
4.5 Most Representative Trigrams for each
Relation
</subsectionHeader>
<bodyText confidence="0.999990961538461">
In Table 6, for each relation type we present the
five trigrams in the test set which contributed the
most for scoring correctly classified examples.
Remember that in CR-CNN, given a sentence x
the score for the class c is computed by sθ(x)c =
rXT[Wclasses]c. In order to compute the most rep-
resentative trigram of a sentence x, we trace back
each position in rx to find the trigram responsible
for it. For each trigram t, we compute its particular
contribution for the score by summing the terms
in score that use positions in rx that trace back to
t. The most representative trigram in x is the one
with the largest contribution to the improvement of
the score. In order to create the results presented
in Table 6, we rank the trigrams which were se-
lected as the most representative of any sentence
in decreasing order of contribution value. If a tri-
gram appears as the largest contributor for more
than one sentence, its contribuition value becomes
the sum of its contribution for each sentence.
We can see in Table 6 that for most classes, the
trigrams that contributed the most to increase the
score are indeed very informative regarding the re-
lation type. As expected, different trigrams play
an important role depending on the direction of
the relation. For instance, the most informative tri-
</bodyText>
<footnote confidence="0.8612965">
1This is the result using only the text span between the
target nouns.
</footnote>
<bodyText confidence="0.999571166666667">
gram for Entity-Origin(e1,e2) is “away from the”,
while reverse direction of the relation, Entity-
Origin(e2,e1) or Origin-Entity, has “the source
of” as the most informative trigram. These re-
sults are a step towards the extraction of meaning-
ful knowledge from models produced by CNNs.
</bodyText>
<sectionHeader confidence="0.999615" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999466627906977">
Over the years, various approaches have been
proposed for relation classification (Zhang, 2004;
Qian et al., 2009; Hendrickx et al., 2010; Rink and
Harabagiu, 2010). Most of them treat it as a multi-
class classification problem and apply a variety of
machine learning techniques to the task in order to
achieve a high accuracy.
Recently, deep learning (Bengio, 2009) has be-
come an attractive area for multiple applications,
including computer vision, speech recognition and
natural language processing. Among the different
deep learning strategies, convolutional neural net-
works have been successfully applied to different
NLP task such as part-of-speech tagging (dos San-
tos and Zadrozny, 2014), sentiment analysis (Kim,
2014; dos Santos and Gatti, 2014), question classi-
fication (Kalchbrenner et al., 2014), semantic role
labeling (Collobert et al., 2011), hashtag predic-
tion (Weston et al., 2014), sentence completion
and response matching (Hu et al., 2014).
Some recent work on deep learning for relation
classification include Socher et al. (2012), Zeng
et al. (2014) and Yu et al. (2014). In (Socher et
al., 2012), the authors tackle relation classification
using a recursive neural network (RNN) that as-
signs a matrix-vector representation to every node
in a parse tree. The representation for the com-
plete sentence is computed bottom-up by recur-
sively combining the words according to the syn-
tactic structure of the parse tree Their method is
named the matrix-vector recursive neural network
(MVRNN).
Zeng et al. (2014) propose an approach for re-
lation classification where sentence-level features
are learned through a CNN, which has word em-
bedding and position features as its input. In par-
allel, lexical features are extracted according to
given nouns. Then sentence-level and lexical fea-
tures are concatenated into a single vector and
fed into a softmax classifier for prediction. This
approach achieves state-of-the-art performance on
the SemEval-2010 Task 8 dataset.
Yu et al. (2014) propose a Factor-based Com-
</bodyText>
<page confidence="0.992689">
632
</page>
<table confidence="0.9997222">
Classifier Feature Set F1
SVM POS, prefixes, morphological, WordNet, dependency parse, 82.2
(Rink and Harabagiu, 2010) Levin classes, ProBank, FrameNet, NomLex-Plus,
Google n-gram, paraphrases, TextRunner
RNN word embeddings 74.8
(Socher et al., 2012) word embeddings, POS, NER, WordNet 77.6
MVRNN word embeddings 79.1
(Socher et al., 2012) word embeddings, POS, NER, WordNet 82.4
word embeddings 69.7
CNN+Softmax word embeddings, word position embeddings, 82.7
(Zeng et al., 2014) word pair, words around word pair, WordNet
FCM word embeddings 80.6
(Yu et al., 2014) word embeddings, dependency parse, NER 83.0
CR-CNN word embeddings 82.8
word embeddings, word position embeddings 84.1
</table>
<tableCaption confidence="0.999788">
Table 5: Comparison with results published in the literature.
</tableCaption>
<bodyText confidence="0.94614565">
Relation (e1,e2) (e2,e1)
Cause-Effect e1 resulted in, e1 caused a, had caused e2 caused by, was caused by, are
the, poverty cause e2, caused a e2 caused by, been caused by, e2 from e1
Component-Whole e1 of the, of the e2, part of the, e2 ’s e1, with its e1, e2 has a,
in the e2, e1 on the e2 comprises the, e2 with e1
Content-Container was in a, was hidden in, were in a, e2 full of, e2 with e1, e2 was full,
was inside a, was contained in e2 contained a, e2 with cold
Entity-Destination e1 into the, e1 into a, e1 to the, -
was put inside, imported into the
Entity-Origin away from the, derived from a, had the source of, e2 grape e1,
left the, derived from an, e1 from the e2 butter e1
Instrument-Agency are used by, e1 for e2, is used by, with a e1, by using e1, e2 finds a,
trade for e2, with the e2 e2 with a, e2 , who
Member-Collection of the e2, in the e2, of this e2, e2 of e1, of wild e1, of elven e1,
the political e2, e1 collected in e2 of different, of 0000 e1
Message-Topic e1 is the, e1 asserts the, e1 that the, described in the, discussed in the,
on the e2, e1 inform about featured in numerous, discussed
in cabinet, documented in two,
Product-Producer e1 by the, by a e2, of the e2, e2 of the, e2 has constructed, e2 ’s e1,
by the e2, from the e2 e2 came up, e2 who created
</bodyText>
<tableCaption confidence="0.811074">
Table 6: List of most representative trigrams for each relation type.
</tableCaption>
<bodyText confidence="0.9995965625">
positional Embedding Model (FCM) by deriving
sentence-level and substructure embeddings from
word embeddings, utilizing dependency trees and
named entities. It achieves slightly higher accu-
racy on the same dataset than (Zeng et al., 2014),
but only when syntactic information is used.
There are two main differences between the ap-
proach proposed in this paper and the ones pro-
posed in (Socher et al., 2012; Zeng et al., 2014; Yu
et al., 2014): (1) CR-CNN uses a pair-wise rank-
ing method, while other approaches apply multi-
class classification by using the softmax function
on the top of the CNN/RNN; and (2) CR-CNN
employs an effective method to deal with artificial
classes by omitting their embeddings, while other
approaches treat all classes equally.
</bodyText>
<sectionHeader confidence="0.999357" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999915588235294">
In this work we tackle the relation classification
task using a CNN that performs classification by
ranking. The main contributions of this work are:
(1) the definition of a new state-of-the-art for the
SemEval-2010 Task 8 dataset without using any
costly handcrafted features; (2) the proposal of a
new CNN for classification that uses class embed-
dings and a new rank loss function; (3) an effective
method to deal with artificial classes by omitting
their embeddings in CR-CNN; (4) the demonstra-
tion that using only the text between target nomi-
nals is almost as effective as using WPEs; and (5)
a method to extract from the CR-CNN model the
most representative contexts of each relation type.
Although we apply CR-CNN to relation classifica-
tion, this method can be used for any classification
task.
</bodyText>
<page confidence="0.998992">
633
</page>
<sectionHeader confidence="0.998332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999953333333333">
The authors would like to thank Nina Wacholder
for her valuable suggestions to improve the final
version of the paper.
</bodyText>
<sectionHeader confidence="0.996441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999860155339806">
Yoshua Bengio. 2009. Learning deep architectures
for ai. Foundations and Trends Machine Learning,
2(1):1–127.
James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien,
Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and
Yoshua Bengio. 2010. Theano: a CPU and GPU
math expression compiler. In Proceedings of the
Python for Scientific Computing Conference.
R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. 2011. Natural lan-
guage processing (almost) from scratch. Journal of
Machine Learning Research, 12:2493–2537.
C´ıcero Nogueira dos Santos and Ma´ıra Gatti. 2014.
Deep convolutional neural networks for sentiment
analysis of short texts. In Proceedings of the 25th In-
ternational Conference on Computational Linguis-
tics (COLING), Dublin, Ireland.
C´ıcero Nogueira dos Santos and Bianca Zadrozny.
2014. Learning character-level representations for
part-of-speech tagging. In Proceedings of the
31st International Conference on Machine Learning
(ICML), JMLR: W&amp;CP volume 32, Beijing, China.
Jianfeng Gao, Patrick Pantel, Michael Gamon, Xi-
aodong He, and Li Deng. 2014. Modeling interest-
ingness with deep neural networks. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP).
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid ´O. S´eaghdha, Sebastian
Pad´o, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2010. Semeval-2010 task 8:
Multi-way classification of semantic relations be-
tween pairs of nominals. In Proceedings of the
5th International Workshop on Semantic Evaluation,
pages 33–38.
Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai
Chen. 2014. Convolutional neural network archi-
tectures for matching natural language sentences. In
Proceedings of the Conference on Neural Informa-
tion Processing Systems, pages 2042–2050.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural netork for mod-
elling sentences. In Proceedings of the 52th Annual
Meeting of the Association for Computational Lin-
guistics, pages 655–665, Baltimore, Maryland.
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods for Natural Lan-
guage Processing, pages 1746–1751, Doha, Qatar.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In In Proceedings of Work-
shop at ICLR.
Longhua Qian, Guodong Zhou, Fang Kong, and
Qiaoming Zhu. 2009. Semi-supervised learning for
semantic relation classification using stratified sam-
pling strategy. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 1437–1445.
Bryan Rink and Sanda Harabagiu. 2010. Utd: Clas-
sifying semantic relations by combining lexical and
semantic resources. In Proceedings of International
Workshop on Semantic Evaluation, pages 256–259.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic com-
positionality through recursive matrix-vector spaces.
In Proceedings of the Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
1201–1211.
Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology, pages
173–180.
Jason Weston, Samy Bengio, and Nicolas Usunier.
2011. Wsabie: Scaling up to large vocabulary image
annotation. In Proceedings of the Twenty-Second
International Joint Conference on Artificial Intelli-
gence, pages 2764–2770.
Jason Weston, Sumit Chopra, and Keith Adams. 2014.
#tagspace: Semantic embeddings from hashtags. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1822–1827.
Mo Yu, Matthew Gormley, and Mark Dredze. 2014.
Factor-based compositional embedding models. In
Proceedings of the 2nd Workshop on Learning Se-
mantics, Montreal, Canada.
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
the 25th International Conference on Computational
Linguistics (COLING), pages 2335–2344, Dublin,
Ireland.
Zhu Zhang. 2004. Weakly-supervised relation classifi-
cation for information extraction. In Proceedings of
the ACM International Conference on Information
and Knowledge Management, pages 581–588, New
York, NY, USA.
</reference>
<page confidence="0.99862">
634
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.126998">
<title confidence="0.999501">Classifying Relations by Ranking with Convolutional Neural Networks</title>
<author confidence="0.983242">Cicero Nogueira dos</author>
<affiliation confidence="0.98569">IBM</affiliation>
<address confidence="0.845988">138/146 Av.</address>
<author confidence="0.484385">Rio de_Janeiro</author>
<author confidence="0.484385">RJ</author>
<email confidence="0.998423">cicerons@br.ibm.com</email>
<author confidence="0.988428">Bing</author>
<affiliation confidence="0.987729">IBM</affiliation>
<address confidence="0.854395">1101</address>
<affiliation confidence="0.701915">Yorktown Heights, NY,</affiliation>
<email confidence="0.997747">bingxia@us.ibm.com</email>
<author confidence="0.922923">Bowen</author>
<affiliation confidence="0.959389">IBM</affiliation>
<address confidence="0.836369">1101</address>
<affiliation confidence="0.716934">Yorktown Heights, NY,</affiliation>
<email confidence="0.999488">zhou@us.ibm.com</email>
<abstract confidence="0.999416178571429">Relation classification is an important semantic processing task for which state-ofthe-art systems still rely on costly handcrafted features. In this work we tackle the relation classification task using a convolutional neural network that performs classification by ranking (CR-CNN). We propose a new pairwise ranking loss function that makes it easy to reduce the impact of artificial classes. We perform experiments using the the SemEval-2010 Task 8 dataset, which is designed for the task of classifying the relationship between two nominals marked in a sentence. Using CR- CNN, we outperform the state-of-the-art for this dataset and achieve a F1 of 84.1 without using any costly handcrafted features. Additionally, our experimental results show that: (1) our approach is more effective than CNN followed by a softmax classifier; (2) omitting the representaof the artificial class both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
</authors>
<title>Learning deep architectures for ai.</title>
<date>2009</date>
<booktitle>Foundations and Trends Machine Learning,</booktitle>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="26859" citStr="Bengio, 2009" startWordPosition="4596" endWordPosition="4597">hile reverse direction of the relation, EntityOrigin(e2,e1) or Origin-Entity, has “the source of” as the most informative trigram. These results are a step towards the extraction of meaningful knowledge from models produced by CNNs. 5 Related Work Over the years, various approaches have been proposed for relation classification (Zhang, 2004; Qian et al., 2009; Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some </context>
</contexts>
<marker>Bengio, 2009</marker>
<rawString>Yoshua Bengio. 2009. Learning deep architectures for ai. Foundations and Trends Machine Learning, 2(1):1–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Bergstra</author>
<author>Olivier Breuleux</author>
<author>Fr´ed´eric Bastien</author>
<author>Pascal Lamblin</author>
<author>Razvan Pascanu</author>
<author>Guillaume Desjardins</author>
<author>Joseph Turian</author>
<author>David Warde-Farley</author>
<author>Yoshua Bengio</author>
</authors>
<title>Theano: a CPU and GPU math expression compiler.</title>
<date>2010</date>
<booktitle>In Proceedings of the Python for Scientific Computing Conference.</booktitle>
<contexts>
<context position="13214" citStr="Bergstra et al., 2010" startWordPosition="2262" endWordPosition="2265">c− that we choose to perform a SGD step is the one with the highest score among all incorrect classes c− = arg max se(x)c. c ∈ C; c6=y+ For tasks where the number of classes is large, we can fix a number of negative classes to be considered at each example and select the one with the largest score to perform a gradient step. This approach is similar to the one used by Weston et al. (2014) to select negative examples. We use the backpropagation algorithm to compute gradients of the network. In our experiments, we implement the CR-CNN architecture and the backpropagation algorithm using Theano (Bergstra et al., 2010). 2.6 Special Treatment of Artificial Classes In this work, we consider a class as artificial if it is used to group items that do not belong to any of the actual classes. An example of artificial class is the class Other in the SemEval 2010 relation classification task. In this task, the artificial class Other is used to indicate that the relation between two nominals does not belong to any of the nine relation classes of interest. Therefore, the class Other is very noisy since it groups many different types of relations that may not have much in common. An important characteristic of CR-CNN </context>
</contexts>
<marker>Bergstra, Breuleux, Bastien, Lamblin, Pascanu, Desjardins, Turian, Warde-Farley, Bengio, 2010</marker>
<rawString>James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. 2010. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>J Weston</author>
<author>L Bottou</author>
<author>M Karlen</author>
<author>K Kavukcuoglu</author>
<author>P Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="6597" citStr="Collobert et al. (2011)" startWordPosition="1090" endWordPosition="1093">ned, and the size of the word embedding dw is a hyperparameter to be chosen by the user. 2.2 Word Position Embeddings In the task of relation classification, information that is needed to determine the class of a relation Figure 1: CR-CNN: a Neural Network for classifying by ranking. between two target nouns normally comes from words which are close to the target nouns. Zeng et al. (2014) propose the use of word position embeddings (position features) which help the CNN by keeping track of how close words are to the target nouns. These features are similar to the position features proposed by Collobert et al. (2011) for the Semantic Role Labeling task. In this work we also experiment with the word position embeddings (WPE) proposed by Zeng et al. (2014). The WPE is derived from the relative distances of the current word to the target noun1 and noun2. For instance, in the sentence shown in Figure 1, the relative distances of left to car and plant are -1 and 2, respectively. As in (Collobert et al., 2011), each relative distance is mapped to a vector of dimension dwpe, which is initialized with random numbers. dwpe is a hyperparameter of the network. Given the vectors wp1 and wp2 for the word w with respec</context>
<context position="27349" citStr="Collobert et al., 2011" startWordPosition="4663" endWordPosition="4666">pply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named </context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´ıcero Nogueira dos Santos</author>
<author>Ma´ıra Gatti</author>
</authors>
<title>Deep convolutional neural networks for sentiment analysis of short texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="8124" citStr="Santos and Gatti, 2014" startWordPosition="1353" endWordPosition="1356">are concatenated to form the input for the convolutional layer, embx = {[rw1, wpew1], [rw2, wpew2], ..., [rwN , wpewN ]}. 2.3 Sentence Representation The next step in the NN consists in creating the distributed vector representation rx for the input sentence x. The main challenges in this step are the sentence size variability and the fact that important information can appear at any position in the sentence. In recent work, convolutional approaches have been used to tackle these issues when creating representations for text segments of different sizes (Zeng et al., 2014; Hu et al., 2014; dos Santos and Gatti, 2014) and characterlevel representations of words of different sizes (dos Santos and Zadrozny, 2014). Here, we use a convolutional layer to compute distributed vector representations of the sentence. The convolutional layer first produces local features around each word in the sentence. Then, it combines these local features using a max operation to create a fixed-sized vector for the input sentence. Given a sentence x, the convolutional layer applies a matrix-vector operation to each window of size k of successive windows in embx = {rw1, rw2, ..., rwN}. Let us define the vector zn E Rdwk as the co</context>
<context position="16570" citStr="Santos and Gatti, 2014" startWordPosition="2807" endWordPosition="2810">val-2010 Task 8 official scorer, which computes the macro-averaged F1-scores for the nine 629 actual relations (excluding Other) and takes the directionality into consideration. 3.2 Word Embeddings Initialization The word embeddings used in our experiments are initialized by means of unsupervised pre-training. We perform pre-training using the skip-gram NN architecture (Mikolov et al., 2013) available in the word2vec tool. We use the December 2013 snapshot of the English Wikipedia corpus to train word embeddings with word2vec. We preprocess the Wikipedia text using the steps described in (dos Santos and Gatti, 2014): (1) removal of paragraphs that are not in English; (2) substitution of non-western characters for a special character; (3) tokenization of the text using the tokenizer available with the Stanford POS Tagger (Toutanova et al., 2003); (4) removal of sentences that are less than 20 characters long (including white spaces) or have less than 5 tokens. (5) lowercase all words and substitute each numerical digit by a 0. The resulting clean corpus contains about 1.75 billion tokens. 3.3 Neural Network Hyper-parameter We use 4-fold cross-validation to tune the neural network hyperparameters. Learning</context>
<context position="27247" citStr="Santos and Gatti, 2014" startWordPosition="4649" endWordPosition="4652">., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursi</context>
</contexts>
<marker>Santos, Gatti, 2014</marker>
<rawString>C´ıcero Nogueira dos Santos and Ma´ıra Gatti. 2014. Deep convolutional neural networks for sentiment analysis of short texts. In Proceedings of the 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´ıcero Nogueira dos Santos</author>
<author>Bianca Zadrozny</author>
</authors>
<title>Learning character-level representations for part-of-speech tagging.</title>
<date>2014</date>
<booktitle>In Proceedings of the 31st International Conference on Machine Learning (ICML), JMLR: W&amp;CP</booktitle>
<volume>32</volume>
<location>Beijing, China.</location>
<contexts>
<context position="8219" citStr="Santos and Zadrozny, 2014" startWordPosition="1367" endWordPosition="1370">wpew2], ..., [rwN , wpewN ]}. 2.3 Sentence Representation The next step in the NN consists in creating the distributed vector representation rx for the input sentence x. The main challenges in this step are the sentence size variability and the fact that important information can appear at any position in the sentence. In recent work, convolutional approaches have been used to tackle these issues when creating representations for text segments of different sizes (Zeng et al., 2014; Hu et al., 2014; dos Santos and Gatti, 2014) and characterlevel representations of words of different sizes (dos Santos and Zadrozny, 2014). Here, we use a convolutional layer to compute distributed vector representations of the sentence. The convolutional layer first produces local features around each word in the sentence. Then, it combines these local features using a max operation to create a fixed-sized vector for the input sentence. Given a sentence x, the convolutional layer applies a matrix-vector operation to each window of size k of successive windows in embx = {rw1, rw2, ..., rwN}. Let us define the vector zn E Rdwk as the concatenation of a sequence of k word embeddings, centralized in the n-th word: zn = (rwn−(k−1)/2</context>
<context position="27187" citStr="Santos and Zadrozny, 2014" startWordPosition="4639" endWordPosition="4643">classification (Zhang, 2004; Qian et al., 2009; Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representatio</context>
</contexts>
<marker>Santos, Zadrozny, 2014</marker>
<rawString>C´ıcero Nogueira dos Santos and Bianca Zadrozny. 2014. Learning character-level representations for part-of-speech tagging. In Proceedings of the 31st International Conference on Machine Learning (ICML), JMLR: W&amp;CP volume 32, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Patrick Pantel</author>
<author>Michael Gamon</author>
<author>Xiaodong He</author>
<author>Li Deng</author>
</authors>
<title>Modeling interestingness with deep neural networks.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="12010" citStr="Gao et al., 2014" startWordPosition="2049" endWordPosition="2052">re se(x)c− decreases. Training CR-CNN by minimizing the loss function in Equation 1 has the effect of training to give scores greater than m+ for the correct class and (negative) scores smaller than −m− for incorrect classes. In our experiments we set ry to 2, m+ to 2.5 and m− to 0.5. We use L2 regularization by adding the term Q11θ112 to Equation 1. In our experiments we set Q to 0.001. We use stochastic gradient descent (SGD) to minimize the loss function with respect to θ. Like some other ranking approaches that only update two classes/examples at every training round (Weston et al., 2011; Gao et al., 2014), we can efficiently train the network for tasks which have a very large number of classes. This is an advantage over softmax classifiers. On the other hand, sampling informative negative classes/examples can have a significant impact in the effectiveness of the learned model. In the case of our loss function, more informative negative classes are the ones with a score larger than −m−. The number of classes in the relation classification dataset that we use in our experiments is small. Therefore, in our experiments, given a sentence x with class label y+, the incorrect class c− that we choose </context>
</contexts>
<marker>Gao, Pantel, Gamon, He, Deng, 2014</marker>
<rawString>Jianfeng Gao, Patrick Pantel, Michael Gamon, Xiaodong He, and Li Deng. 2014. Modeling interestingness with deep neural networks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iris Hendrickx</author>
<author>Su Nam Kim</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Diarmuid ´O S´eaghdha</author>
<author>Sebastian Pad´o</author>
<author>Marco Pennacchiotti</author>
<author>Lorenza Romano</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>33--38</pages>
<marker>Hendrickx, Kim, Kozareva, Nakov, S´eaghdha, Pad´o, Pennacchiotti, Romano, Szpakowicz, 2010</marker>
<rawString>Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid ´O. S´eaghdha, Sebastian Pad´o, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2010. Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 33–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baotian Hu</author>
<author>Zhengdong Lu</author>
<author>Hang Li</author>
<author>Qingcai Chen</author>
</authors>
<title>Convolutional neural network architectures for matching natural language sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Neural Information Processing Systems,</booktitle>
<pages>2042--2050</pages>
<contexts>
<context position="8095" citStr="Hu et al., 2014" startWordPosition="1348" endWordPosition="1351">bedding of each word are concatenated to form the input for the convolutional layer, embx = {[rw1, wpew1], [rw2, wpew2], ..., [rwN , wpewN ]}. 2.3 Sentence Representation The next step in the NN consists in creating the distributed vector representation rx for the input sentence x. The main challenges in this step are the sentence size variability and the fact that important information can appear at any position in the sentence. In recent work, convolutional approaches have been used to tackle these issues when creating representations for text segments of different sizes (Zeng et al., 2014; Hu et al., 2014; dos Santos and Gatti, 2014) and characterlevel representations of words of different sizes (dos Santos and Zadrozny, 2014). Here, we use a convolutional layer to compute distributed vector representations of the sentence. The convolutional layer first produces local features around each word in the sentence. Then, it combines these local features using a max operation to create a fixed-sized vector for the input sentence. Given a sentence x, the convolutional layer applies a matrix-vector operation to each window of size k of successive windows in embx = {rw1, rw2, ..., rwN}. Let us define t</context>
<context position="27452" citStr="Hu et al., 2014" startWordPosition="4679" endWordPosition="4682">learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named the matrix-vector recursive neural network (MVRNN). Zeng et al. (2014) propose an approach for relation</context>
</contexts>
<marker>Hu, Lu, Li, Chen, 2014</marker>
<rawString>Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. In Proceedings of the Conference on Neural Information Processing Systems, pages 2042–2050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural netork for modelling sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>655--665</pages>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="27300" citStr="Kalchbrenner et al., 2014" startWordPosition="4656" endWordPosition="4659">reat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic s</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural netork for modelling sentences. In Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics, pages 655–665, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods for Natural Language Processing,</booktitle>
<pages>1746--1751</pages>
<location>Doha, Qatar.</location>
<contexts>
<context position="27218" citStr="Kim, 2014" startWordPosition="4646" endWordPosition="4647">Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is </context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods for Natural Language Processing, pages 1746–1751, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<booktitle>In In Proceedings of Workshop at ICLR.</booktitle>
<contexts>
<context position="16341" citStr="Mikolov et al., 2013" startWordPosition="2769" endWordPosition="2772">[burst],, has been caused by water hammer [pressure],2. ⇒ Cause-Effect(e2,e1) The SemEval-2010 Task 8 dataset is already partitioned into 8,000 training instances and 2,717 test instances. We score our systems by using the SemEval-2010 Task 8 official scorer, which computes the macro-averaged F1-scores for the nine 629 actual relations (excluding Other) and takes the directionality into consideration. 3.2 Word Embeddings Initialization The word embeddings used in our experiments are initialized by means of unsupervised pre-training. We perform pre-training using the skip-gram NN architecture (Mikolov et al., 2013) available in the word2vec tool. We use the December 2013 snapshot of the English Wikipedia corpus to train word embeddings with word2vec. We preprocess the Wikipedia text using the steps described in (dos Santos and Gatti, 2014): (1) removal of paragraphs that are not in English; (2) substitution of non-western characters for a special character; (3) tokenization of the text using the tokenizer available with the Stanford POS Tagger (Toutanova et al., 2003); (4) removal of sentences that are less than 20 characters long (including white spaces) or have less than 5 tokens. (5) lowercase all wo</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In In Proceedings of Workshop at ICLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longhua Qian</author>
<author>Guodong Zhou</author>
<author>Fang Kong</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Semi-supervised learning for semantic relation classification using stratified sampling strategy.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1437--1445</pages>
<contexts>
<context position="1822" citStr="Qian et al., 2009" startWordPosition="276" endWordPosition="279">tion of the artificial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals. 1 Introduction Relation classification is an important Natural Language Processing (NLP) task which is normally used as an intermediate step in many complex NLP applications such as question-answering and automatic knowledge base construction. Since the last decade there has been increasing interest in applying machine learning approaches to this task (Zhang, 2004; Qian et al., 2009; Rink and Harabagiu, 2010). One reason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcrafted features (Soche</context>
<context position="26607" citStr="Qian et al., 2009" startWordPosition="4552" endWordPosition="4555">expected, different trigrams play an important role depending on the direction of the relation. For instance, the most informative tri1This is the result using only the text span between the target nouns. gram for Entity-Origin(e1,e2) is “away from the”, while reverse direction of the relation, EntityOrigin(e2,e1) or Origin-Entity, has “the source of” as the most informative trigram. These results are a step towards the extraction of meaningful knowledge from models produced by CNNs. 5 Related Work Over the years, various approaches have been proposed for relation classification (Zhang, 2004; Qian et al., 2009; Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis</context>
</contexts>
<marker>Qian, Zhou, Kong, Zhu, 2009</marker>
<rawString>Longhua Qian, Guodong Zhou, Fang Kong, and Qiaoming Zhu. 2009. Semi-supervised learning for semantic relation classification using stratified sampling strategy. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1437–1445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Rink</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Utd: Classifying semantic relations by combining lexical and semantic resources.</title>
<date>2010</date>
<booktitle>In Proceedings of International Workshop on Semantic Evaluation,</booktitle>
<pages>256--259</pages>
<contexts>
<context position="1849" citStr="Rink and Harabagiu, 2010" startWordPosition="280" endWordPosition="283">ial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals. 1 Introduction Relation classification is an important Natural Language Processing (NLP) task which is normally used as an intermediate step in many complex NLP applications such as question-answering and automatic knowledge base construction. Since the last decade there has been increasing interest in applying machine learning approaches to this task (Zhang, 2004; Qian et al., 2009; Rink and Harabagiu, 2010). One reason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcrafted features (Socher et al., 2012; Zeng et al.</context>
<context position="23098" citStr="Rink and Harabagiu (2010)" startWordPosition="3957" endWordPosition="3960">NN+Softmax). We believe that the word embeddings employed by them is the main reason their result is much worse than that of CNN+Softmax. We use word embeddings of size 400 while they use word embeddings of size 50, which were trained using much less unlabeled data than we did. Neural Net. Prec. Rec. F1 CR-CNN 83.7 84.7 84.1 CNN+SoftMax 82.1 83.1 82.5 CNN+SoftMax - - 78.9 (Zeng et al., 2014) Table 4: Comparison of results of CR-CNN and CNN+Softmax. 4.4 Comparison with the State-of-the-art In Table 5 we compare CR-CNN results with results recently published for the SemEval-2010 Task 8 dataset. Rink and Harabagiu (2010) present a support vector machine (SVM) classifier that is fed with a rich (traditional) feature set. It obtains an F1 of 82.2, which was the best result at SemEval-2010 Task 8. Socher et al. (2012) present results for a recursive neural network (RNN) that employs a matrix-vector representation to every node in a parse tree in order to compose the distributed vector representation for the complete sentence. Their method is named the matrix-vector recursive neural network (MVRNN) and achieves a F1 of 82.4 when POS, NER and WordNet features are used. In (Zeng et al., 2014), the authors present r</context>
<context position="26658" citStr="Rink and Harabagiu, 2010" startWordPosition="4560" endWordPosition="4563">ant role depending on the direction of the relation. For instance, the most informative tri1This is the result using only the text span between the target nouns. gram for Entity-Origin(e1,e2) is “away from the”, while reverse direction of the relation, EntityOrigin(e2,e1) or Origin-Entity, has “the source of” as the most informative trigram. These results are a step towards the extraction of meaningful knowledge from models produced by CNNs. 5 Related Work Over the years, various approaches have been proposed for relation classification (Zhang, 2004; Qian et al., 2009; Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question </context>
<context position="28638" citStr="Rink and Harabagiu, 2010" startWordPosition="4864" endWordPosition="4867">(2014) propose an approach for relation classification where sentence-level features are learned through a CNN, which has word embedding and position features as its input. In parallel, lexical features are extracted according to given nouns. Then sentence-level and lexical features are concatenated into a single vector and fed into a softmax classifier for prediction. This approach achieves state-of-the-art performance on the SemEval-2010 Task 8 dataset. Yu et al. (2014) propose a Factor-based Com632 Classifier Feature Set F1 SVM POS, prefixes, morphological, WordNet, dependency parse, 82.2 (Rink and Harabagiu, 2010) Levin classes, ProBank, FrameNet, NomLex-Plus, Google n-gram, paraphrases, TextRunner RNN word embeddings 74.8 (Socher et al., 2012) word embeddings, POS, NER, WordNet 77.6 MVRNN word embeddings 79.1 (Socher et al., 2012) word embeddings, POS, NER, WordNet 82.4 word embeddings 69.7 CNN+Softmax word embeddings, word position embeddings, 82.7 (Zeng et al., 2014) word pair, words around word pair, WordNet FCM word embeddings 80.6 (Yu et al., 2014) word embeddings, dependency parse, NER 83.0 CR-CNN word embeddings 82.8 word embeddings, word position embeddings 84.1 Table 5: Comparison with result</context>
</contexts>
<marker>Rink, Harabagiu, 2010</marker>
<rawString>Bryan Rink and Sanda Harabagiu. 2010. Utd: Classifying semantic relations by combining lexical and semantic resources. In Proceedings of International Workshop on Semantic Evaluation, pages 256–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="2436" citStr="Socher et al., 2012" startWordPosition="376" endWordPosition="379"> 2009; Rink and Harabagiu, 2010). One reason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcrafted features (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014). However, in order to achieve state-ofthe-art results these approaches still use some features derived from lexical resources such as WordNet or NLP tools such as dependency parsers and named entity recognizers (NER). In this work, we propose a new convolutional neural network (CNN), which we name Classification by Ranking CNN (CR-CNN), to tackle the relation classification task. The proposed network learns a distributed vector representation for each relation class. Given an input text segment, the network uses a convolutional layer to produce a distribut</context>
<context position="23296" citStr="Socher et al. (2012)" startWordPosition="3993" endWordPosition="3996"> of size 50, which were trained using much less unlabeled data than we did. Neural Net. Prec. Rec. F1 CR-CNN 83.7 84.7 84.1 CNN+SoftMax 82.1 83.1 82.5 CNN+SoftMax - - 78.9 (Zeng et al., 2014) Table 4: Comparison of results of CR-CNN and CNN+Softmax. 4.4 Comparison with the State-of-the-art In Table 5 we compare CR-CNN results with results recently published for the SemEval-2010 Task 8 dataset. Rink and Harabagiu (2010) present a support vector machine (SVM) classifier that is fed with a rich (traditional) feature set. It obtains an F1 of 82.2, which was the best result at SemEval-2010 Task 8. Socher et al. (2012) present results for a recursive neural network (RNN) that employs a matrix-vector representation to every node in a parse tree in order to compose the distributed vector representation for the complete sentence. Their method is named the matrix-vector recursive neural network (MVRNN) and achieves a F1 of 82.4 when POS, NER and WordNet features are used. In (Zeng et al., 2014), the authors present results for a CNN+Softmax classifier which employs lexical and sentencelevel features. Their classifier achieves a F1 of 82.7 when adding a handcrafted feature based on the WordNet. Yu et al. (2014) </context>
<context position="27544" citStr="Socher et al. (2012)" startWordPosition="4693" endWordPosition="4696">ng computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named the matrix-vector recursive neural network (MVRNN). Zeng et al. (2014) propose an approach for relation classification where sentence-level features are learned through a CNN, which has word embe</context>
<context position="28771" citStr="Socher et al., 2012" startWordPosition="4881" endWordPosition="4884">nd position features as its input. In parallel, lexical features are extracted according to given nouns. Then sentence-level and lexical features are concatenated into a single vector and fed into a softmax classifier for prediction. This approach achieves state-of-the-art performance on the SemEval-2010 Task 8 dataset. Yu et al. (2014) propose a Factor-based Com632 Classifier Feature Set F1 SVM POS, prefixes, morphological, WordNet, dependency parse, 82.2 (Rink and Harabagiu, 2010) Levin classes, ProBank, FrameNet, NomLex-Plus, Google n-gram, paraphrases, TextRunner RNN word embeddings 74.8 (Socher et al., 2012) word embeddings, POS, NER, WordNet 77.6 MVRNN word embeddings 79.1 (Socher et al., 2012) word embeddings, POS, NER, WordNet 82.4 word embeddings 69.7 CNN+Softmax word embeddings, word position embeddings, 82.7 (Zeng et al., 2014) word pair, words around word pair, WordNet FCM word embeddings 80.6 (Yu et al., 2014) word embeddings, dependency parse, NER 83.0 CR-CNN word embeddings 82.8 word embeddings, word position embeddings 84.1 Table 5: Comparison with results published in the literature. Relation (e1,e2) (e2,e1) Cause-Effect e1 resulted in, e1 caused a, had caused e2 caused by, was caused</context>
<context position="31036" citStr="Socher et al., 2012" startWordPosition="5292" endWordPosition="5295">two, Product-Producer e1 by the, by a e2, of the e2, e2 of the, e2 has constructed, e2 ’s e1, by the e2, from the e2 e2 came up, e2 who created Table 6: List of most representative trigrams for each relation type. positional Embedding Model (FCM) by deriving sentence-level and substructure embeddings from word embeddings, utilizing dependency trees and named entities. It achieves slightly higher accuracy on the same dataset than (Zeng et al., 2014), but only when syntactic information is used. There are two main differences between the approach proposed in this paper and the ones proposed in (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014): (1) CR-CNN uses a pair-wise ranking method, while other approaches apply multiclass classification by using the softmax function on the top of the CNN/RNN; and (2) CR-CNN employs an effective method to deal with artificial classes by omitting their embeddings, while other approaches treat all classes equally. 6 Conclusion In this work we tackle the relation classification task using a CNN that performs classification by ranking. The main contributions of this work are: (1) the definition of a new state-of-the-art for the SemEval-2010 Task 8 dataset withou</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="16803" citStr="Toutanova et al., 2003" startWordPosition="2846" endWordPosition="2849">used in our experiments are initialized by means of unsupervised pre-training. We perform pre-training using the skip-gram NN architecture (Mikolov et al., 2013) available in the word2vec tool. We use the December 2013 snapshot of the English Wikipedia corpus to train word embeddings with word2vec. We preprocess the Wikipedia text using the steps described in (dos Santos and Gatti, 2014): (1) removal of paragraphs that are not in English; (2) substitution of non-western characters for a special character; (3) tokenization of the text using the tokenizer available with the Stanford POS Tagger (Toutanova et al., 2003); (4) removal of sentences that are less than 20 characters long (including white spaces) or have less than 5 tokens. (5) lowercase all words and substitute each numerical digit by a 0. The resulting clean corpus contains about 1.75 billion tokens. 3.3 Neural Network Hyper-parameter We use 4-fold cross-validation to tune the neural network hyperparameters. Learning rates in the range of 0.03 and 0.01 give relatively similar results. Best results are achieved using between 10 and 15 training epochs, depending on the CR-CNN configuration. In Table 1, we show the selected hyperparameter values. A</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Samy Bengio</author>
<author>Nicolas Usunier</author>
</authors>
<title>Wsabie: Scaling up to large vocabulary image annotation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2764--2770</pages>
<contexts>
<context position="11991" citStr="Weston et al., 2011" startWordPosition="2045" endWordPosition="2048"> decreases as the score se(x)c− decreases. Training CR-CNN by minimizing the loss function in Equation 1 has the effect of training to give scores greater than m+ for the correct class and (negative) scores smaller than −m− for incorrect classes. In our experiments we set ry to 2, m+ to 2.5 and m− to 0.5. We use L2 regularization by adding the term Q11θ112 to Equation 1. In our experiments we set Q to 0.001. We use stochastic gradient descent (SGD) to minimize the loss function with respect to θ. Like some other ranking approaches that only update two classes/examples at every training round (Weston et al., 2011; Gao et al., 2014), we can efficiently train the network for tasks which have a very large number of classes. This is an advantage over softmax classifiers. On the other hand, sampling informative negative classes/examples can have a significant impact in the effectiveness of the learned model. In the case of our loss function, more informative negative classes are the ones with a score larger than −m−. The number of classes in the relation classification dataset that we use in our experiments is small. Therefore, in our experiments, given a sentence x with class label y+, the incorrect class</context>
</contexts>
<marker>Weston, Bengio, Usunier, 2011</marker>
<rawString>Jason Weston, Samy Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to large vocabulary image annotation. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, pages 2764–2770.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Sumit Chopra</author>
<author>Keith Adams</author>
</authors>
<title>tagspace: Semantic embeddings from hashtags.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1822--1827</pages>
<contexts>
<context position="12983" citStr="Weston et al. (2014)" startWordPosition="2227" endWordPosition="2230"> ones with a score larger than −m−. The number of classes in the relation classification dataset that we use in our experiments is small. Therefore, in our experiments, given a sentence x with class label y+, the incorrect class c− that we choose to perform a SGD step is the one with the highest score among all incorrect classes c− = arg max se(x)c. c ∈ C; c6=y+ For tasks where the number of classes is large, we can fix a number of negative classes to be considered at each example and select the one with the largest score to perform a gradient step. This approach is similar to the one used by Weston et al. (2014) to select negative examples. We use the backpropagation algorithm to compute gradients of the network. In our experiments, we implement the CR-CNN architecture and the backpropagation algorithm using Theano (Bergstra et al., 2010). 2.6 Special Treatment of Artificial Classes In this work, we consider a class as artificial if it is used to group items that do not belong to any of the actual classes. An example of artificial class is the class Other in the SemEval 2010 relation classification task. In this task, the artificial class Other is used to indicate that the relation between two nomina</context>
<context position="27391" citStr="Weston et al., 2014" startWordPosition="4670" endWordPosition="4673"> to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named the matrix-vector recursive neural network</context>
</contexts>
<marker>Weston, Chopra, Adams, 2014</marker>
<rawString>Jason Weston, Sumit Chopra, and Keith Adams. 2014. #tagspace: Semantic embeddings from hashtags. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1822–1827.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mo Yu</author>
<author>Matthew Gormley</author>
<author>Mark Dredze</author>
</authors>
<title>Factor-based compositional embedding models.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2nd Workshop on Learning Semantics,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="2473" citStr="Yu et al., 2014" startWordPosition="384" endWordPosition="387">ason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcrafted features (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014). However, in order to achieve state-ofthe-art results these approaches still use some features derived from lexical resources such as WordNet or NLP tools such as dependency parsers and named entity recognizers (NER). In this work, we propose a new convolutional neural network (CNN), which we name Classification by Ranking CNN (CR-CNN), to tackle the relation classification task. The proposed network learns a distributed vector representation for each relation class. Given an input text segment, the network uses a convolutional layer to produce a distributed vector representation of the text </context>
<context position="19399" citStr="Yu et al., 2014" startWordPosition="3308" endWordPosition="3311">her the full sentence was used (Yes) or whether the text span between the target nouns was used (No). The second column informs if the WPEs were used or not. It is clear that the use of WPEs is essential when the full sentence is used, since F1 jumps from 74.3 to 84.1. This effect of WPEs is reported by (Zeng et al., 2014). On the other hand, when using only the text span between the target nouns, the impact of WPE is much smaller. With this strategy, we achieve a F1 of 82.8 using only word embeddings as input, which is a result as good as the previous state-of-the-art F1 of 83.0 reported in (Yu et al., 2014) for the SemEval2010 Task 8 dataset. This experimental result also suggests that, in this task, the CNN works better for short texts. All experiments reported in the next sections use CR-CNN with full sentence and WPEs. Full Word Prec. Rec. F1 Sentence Position Yes Yes 83.7 84.7 84.1 No Yes 83.3 83.9 83.5 No No 83.4 82.3 82.8 Yes No 78.1 71.5 74.3 Table 2: Comparison of different CR-CNN configurations. 630 4.2 Impact of Omitting the Embedding of the artificial class Other In this experiment we assess the impact of omitting the embedding of the class Other. As we mentioned above, this class is </context>
<context position="23895" citStr="Yu et al. (2014)" startWordPosition="4091" endWordPosition="4094">her et al. (2012) present results for a recursive neural network (RNN) that employs a matrix-vector representation to every node in a parse tree in order to compose the distributed vector representation for the complete sentence. Their method is named the matrix-vector recursive neural network (MVRNN) and achieves a F1 of 82.4 when POS, NER and WordNet features are used. In (Zeng et al., 2014), the authors present results for a CNN+Softmax classifier which employs lexical and sentencelevel features. Their classifier achieves a F1 of 82.7 when adding a handcrafted feature based on the WordNet. Yu et al. (2014) present the Factor631 based Compositional Embedding Model (FCM), which achieves a F1 of 83.0 by deriving sentencelevel and substructure embeddings from word embeddings utilizing dependency trees and named entities. As we can see in the last line of Table 5, CRCNN using the full sentence, word embeddings and WPEs outperforms all previous reported results and reaches a new state-of-the-art F1 of 84.1. This is a remarkable result since we do not use any complicated features that depend on external lexical resources such as WordNet and NLP tools such as named entity recognizers (NERs) and depende</context>
<context position="27585" citStr="Yu et al. (2014)" startWordPosition="4702" endWordPosition="4705">tural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named the matrix-vector recursive neural network (MVRNN). Zeng et al. (2014) propose an approach for relation classification where sentence-level features are learned through a CNN, which has word embedding and position features as its input.</context>
<context position="29087" citStr="Yu et al., 2014" startWordPosition="4930" endWordPosition="4933">. Yu et al. (2014) propose a Factor-based Com632 Classifier Feature Set F1 SVM POS, prefixes, morphological, WordNet, dependency parse, 82.2 (Rink and Harabagiu, 2010) Levin classes, ProBank, FrameNet, NomLex-Plus, Google n-gram, paraphrases, TextRunner RNN word embeddings 74.8 (Socher et al., 2012) word embeddings, POS, NER, WordNet 77.6 MVRNN word embeddings 79.1 (Socher et al., 2012) word embeddings, POS, NER, WordNet 82.4 word embeddings 69.7 CNN+Softmax word embeddings, word position embeddings, 82.7 (Zeng et al., 2014) word pair, words around word pair, WordNet FCM word embeddings 80.6 (Yu et al., 2014) word embeddings, dependency parse, NER 83.0 CR-CNN word embeddings 82.8 word embeddings, word position embeddings 84.1 Table 5: Comparison with results published in the literature. Relation (e1,e2) (e2,e1) Cause-Effect e1 resulted in, e1 caused a, had caused e2 caused by, was caused by, are the, poverty cause e2, caused a e2 caused by, been caused by, e2 from e1 Component-Whole e1 of the, of the e2, part of the, e2 ’s e1, with its e1, e2 has a, in the e2, e1 on the e2 comprises the, e2 with e1 Content-Container was in a, was hidden in, were in a, e2 full of, e2 with e1, e2 was full, was insid</context>
<context position="31073" citStr="Yu et al., 2014" startWordPosition="5300" endWordPosition="5303">, of the e2, e2 of the, e2 has constructed, e2 ’s e1, by the e2, from the e2 e2 came up, e2 who created Table 6: List of most representative trigrams for each relation type. positional Embedding Model (FCM) by deriving sentence-level and substructure embeddings from word embeddings, utilizing dependency trees and named entities. It achieves slightly higher accuracy on the same dataset than (Zeng et al., 2014), but only when syntactic information is used. There are two main differences between the approach proposed in this paper and the ones proposed in (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014): (1) CR-CNN uses a pair-wise ranking method, while other approaches apply multiclass classification by using the softmax function on the top of the CNN/RNN; and (2) CR-CNN employs an effective method to deal with artificial classes by omitting their embeddings, while other approaches treat all classes equally. 6 Conclusion In this work we tackle the relation classification task using a CNN that performs classification by ranking. The main contributions of this work are: (1) the definition of a new state-of-the-art for the SemEval-2010 Task 8 dataset without using any costly handcrafted featur</context>
</contexts>
<marker>Yu, Gormley, Dredze, 2014</marker>
<rawString>Mo Yu, Matthew Gormley, and Mark Dredze. 2014. Factor-based compositional embedding models. In Proceedings of the 2nd Workshop on Learning Semantics, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daojian Zeng</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Guangyou Zhou</author>
<author>Jun Zhao</author>
</authors>
<title>Relation classification via convolutional deep neural network.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>2335--2344</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2455" citStr="Zeng et al., 2014" startWordPosition="380" endWordPosition="383">agiu, 2010). One reason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcrafted features (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014). However, in order to achieve state-ofthe-art results these approaches still use some features derived from lexical resources such as WordNet or NLP tools such as dependency parsers and named entity recognizers (NER). In this work, we propose a new convolutional neural network (CNN), which we name Classification by Ranking CNN (CR-CNN), to tackle the relation classification task. The proposed network learns a distributed vector representation for each relation class. Given an input text segment, the network uses a convolutional layer to produce a distributed vector represent</context>
<context position="6365" citStr="Zeng et al. (2014)" startWordPosition="1048" endWordPosition="1051">nsform a word w into its word embedding rw by using the matrix-vector product: rw = Wwrdvw where vw is a vector of size |V |which has value 1 at index w and zero in all other positions. The matrix Wwrd is a parameter to be learned, and the size of the word embedding dw is a hyperparameter to be chosen by the user. 2.2 Word Position Embeddings In the task of relation classification, information that is needed to determine the class of a relation Figure 1: CR-CNN: a Neural Network for classifying by ranking. between two target nouns normally comes from words which are close to the target nouns. Zeng et al. (2014) propose the use of word position embeddings (position features) which help the CNN by keeping track of how close words are to the target nouns. These features are similar to the position features proposed by Collobert et al. (2011) for the Semantic Role Labeling task. In this work we also experiment with the word position embeddings (WPE) proposed by Zeng et al. (2014). The WPE is derived from the relative distances of the current word to the target noun1 and noun2. For instance, in the sentence shown in Figure 1, the relative distances of left to car and plant are -1 and 2, respectively. As </context>
<context position="8078" citStr="Zeng et al., 2014" startWordPosition="1344" endWordPosition="1347">he word position embedding of each word are concatenated to form the input for the convolutional layer, embx = {[rw1, wpew1], [rw2, wpew2], ..., [rwN , wpewN ]}. 2.3 Sentence Representation The next step in the NN consists in creating the distributed vector representation rx for the input sentence x. The main challenges in this step are the sentence size variability and the fact that important information can appear at any position in the sentence. In recent work, convolutional approaches have been used to tackle these issues when creating representations for text segments of different sizes (Zeng et al., 2014; Hu et al., 2014; dos Santos and Gatti, 2014) and characterlevel representations of words of different sizes (dos Santos and Zadrozny, 2014). Here, we use a convolutional layer to compute distributed vector representations of the sentence. The convolutional layer first produces local features around each word in the sentence. Then, it combines these local features using a max operation to create a fixed-sized vector for the input sentence. Given a sentence x, the convolutional layer applies a matrix-vector operation to each window of size k of successive windows in embx = {rw1, rw2, ..., rwN}</context>
<context position="19107" citStr="Zeng et al., 2014" startWordPosition="3252" endWordPosition="3255">volutional layer consists of the word embeddings of the word sequence {we, −1, ..., we, + 1} where e1 and e2 correspond to the positions of the first and the second target nouns, respectively. In Table 2 we compare the results of different CR-CNN configurations. The first column indicates whether the full sentence was used (Yes) or whether the text span between the target nouns was used (No). The second column informs if the WPEs were used or not. It is clear that the use of WPEs is essential when the full sentence is used, since F1 jumps from 74.3 to 84.1. This effect of WPEs is reported by (Zeng et al., 2014). On the other hand, when using only the text span between the target nouns, the impact of WPE is much smaller. With this strategy, we achieve a F1 of 82.8 using only word embeddings as input, which is a result as good as the previous state-of-the-art F1 of 83.0 reported in (Yu et al., 2014) for the SemEval2010 Task 8 dataset. This experimental result also suggests that, in this task, the CNN works better for short texts. All experiments reported in the next sections use CR-CNN with full sentence and WPEs. Full Word Prec. Rec. F1 Sentence Position Yes Yes 83.7 84.7 84.1 No Yes 83.3 83.9 83.5 N</context>
<context position="22387" citStr="Zeng et al. (2014)" startWordPosition="3835" endWordPosition="3838">tting the output of the convolutional layer, which is the vector r,, in Figure 1, and giving it as input for a softmax classifier. We tune the parameters of CNN+Softmax by using a 4-fold cross-validation with the training set. Compared to the hyperparameter values for CR-CNN presented in Table 1, the only difference for CNN+Softmax is the number of convolutional units d&apos;, which is set to 400. In Table 4 we compare the results of CRCNN and CNN+Softmax. CR-CNN outperforms CNN+Softmax in both precision and recall, and improves the F1 by 1.6. The third line in Table 4 shows the result reported by Zeng et al. (2014) when only word embeddings and WPEs are used as input to the network (similar to our CNN+Softmax). We believe that the word embeddings employed by them is the main reason their result is much worse than that of CNN+Softmax. We use word embeddings of size 400 while they use word embeddings of size 50, which were trained using much less unlabeled data than we did. Neural Net. Prec. Rec. F1 CR-CNN 83.7 84.7 84.1 CNN+SoftMax 82.1 83.1 82.5 CNN+SoftMax - - 78.9 (Zeng et al., 2014) Table 4: Comparison of results of CR-CNN and CNN+Softmax. 4.4 Comparison with the State-of-the-art In Table 5 we compar</context>
<context position="23675" citStr="Zeng et al., 2014" startWordPosition="4056" endWordPosition="4059">Task 8 dataset. Rink and Harabagiu (2010) present a support vector machine (SVM) classifier that is fed with a rich (traditional) feature set. It obtains an F1 of 82.2, which was the best result at SemEval-2010 Task 8. Socher et al. (2012) present results for a recursive neural network (RNN) that employs a matrix-vector representation to every node in a parse tree in order to compose the distributed vector representation for the complete sentence. Their method is named the matrix-vector recursive neural network (MVRNN) and achieves a F1 of 82.4 when POS, NER and WordNet features are used. In (Zeng et al., 2014), the authors present results for a CNN+Softmax classifier which employs lexical and sentencelevel features. Their classifier achieves a F1 of 82.7 when adding a handcrafted feature based on the WordNet. Yu et al. (2014) present the Factor631 based Compositional Embedding Model (FCM), which achieves a F1 of 83.0 by deriving sentencelevel and substructure embeddings from word embeddings utilizing dependency trees and named entities. As we can see in the last line of Table 5, CRCNN using the full sentence, word embeddings and WPEs outperforms all previous reported results and reaches a new state</context>
<context position="27564" citStr="Zeng et al. (2014)" startWordPosition="4697" endWordPosition="4700">eech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014), sentiment analysis (Kim, 2014; dos Santos and Gatti, 2014), question classification (Kalchbrenner et al., 2014), semantic role labeling (Collobert et al., 2011), hashtag prediction (Weston et al., 2014), sentence completion and response matching (Hu et al., 2014). Some recent work on deep learning for relation classification include Socher et al. (2012), Zeng et al. (2014) and Yu et al. (2014). In (Socher et al., 2012), the authors tackle relation classification using a recursive neural network (RNN) that assigns a matrix-vector representation to every node in a parse tree. The representation for the complete sentence is computed bottom-up by recursively combining the words according to the syntactic structure of the parse tree Their method is named the matrix-vector recursive neural network (MVRNN). Zeng et al. (2014) propose an approach for relation classification where sentence-level features are learned through a CNN, which has word embedding and position f</context>
<context position="29001" citStr="Zeng et al., 2014" startWordPosition="4915" endWordPosition="4918">. This approach achieves state-of-the-art performance on the SemEval-2010 Task 8 dataset. Yu et al. (2014) propose a Factor-based Com632 Classifier Feature Set F1 SVM POS, prefixes, morphological, WordNet, dependency parse, 82.2 (Rink and Harabagiu, 2010) Levin classes, ProBank, FrameNet, NomLex-Plus, Google n-gram, paraphrases, TextRunner RNN word embeddings 74.8 (Socher et al., 2012) word embeddings, POS, NER, WordNet 77.6 MVRNN word embeddings 79.1 (Socher et al., 2012) word embeddings, POS, NER, WordNet 82.4 word embeddings 69.7 CNN+Softmax word embeddings, word position embeddings, 82.7 (Zeng et al., 2014) word pair, words around word pair, WordNet FCM word embeddings 80.6 (Yu et al., 2014) word embeddings, dependency parse, NER 83.0 CR-CNN word embeddings 82.8 word embeddings, word position embeddings 84.1 Table 5: Comparison with results published in the literature. Relation (e1,e2) (e2,e1) Cause-Effect e1 resulted in, e1 caused a, had caused e2 caused by, was caused by, are the, poverty cause e2, caused a e2 caused by, been caused by, e2 from e1 Component-Whole e1 of the, of the e2, part of the, e2 ’s e1, with its e1, e2 has a, in the e2, e1 on the e2 comprises the, e2 with e1 Content-Contai</context>
<context position="30869" citStr="Zeng et al., 2014" startWordPosition="5262" endWordPosition="5265">opic e1 is the, e1 asserts the, e1 that the, described in the, discussed in the, on the e2, e1 inform about featured in numerous, discussed in cabinet, documented in two, Product-Producer e1 by the, by a e2, of the e2, e2 of the, e2 has constructed, e2 ’s e1, by the e2, from the e2 e2 came up, e2 who created Table 6: List of most representative trigrams for each relation type. positional Embedding Model (FCM) by deriving sentence-level and substructure embeddings from word embeddings, utilizing dependency trees and named entities. It achieves slightly higher accuracy on the same dataset than (Zeng et al., 2014), but only when syntactic information is used. There are two main differences between the approach proposed in this paper and the ones proposed in (Socher et al., 2012; Zeng et al., 2014; Yu et al., 2014): (1) CR-CNN uses a pair-wise ranking method, while other approaches apply multiclass classification by using the softmax function on the top of the CNN/RNN; and (2) CR-CNN employs an effective method to deal with artificial classes by omitting their embeddings, while other approaches treat all classes equally. 6 Conclusion In this work we tackle the relation classification task using a CNN th</context>
</contexts>
<marker>Zeng, Liu, Lai, Zhou, Zhao, 2014</marker>
<rawString>Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolutional deep neural network. In Proceedings of the 25th International Conference on Computational Linguistics (COLING), pages 2335–2344, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Zhang</author>
</authors>
<title>Weakly-supervised relation classification for information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>581--588</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="1803" citStr="Zhang, 2004" startWordPosition="274" endWordPosition="275">he representation of the artificial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals. 1 Introduction Relation classification is an important Natural Language Processing (NLP) task which is normally used as an intermediate step in many complex NLP applications such as question-answering and automatic knowledge base construction. Since the last decade there has been increasing interest in applying machine learning approaches to this task (Zhang, 2004; Qian et al., 2009; Rink and Harabagiu, 2010). One reason is the availability of benchmark datasets such as the SemEval-2010 task 8 dataset (Hendrickx et al., 2010), which encodes the task of classifying the relationship between two nominals marked in a sentence. The following sentence contains an example of the Component-Whole relation between the nominals “introduction” and “book”. The [introduction],, in the [book],, is a summary of what is in the text. Some recent work on relation classification has focused on the use of deep neural networks with the aim of reducing the number of handcraf</context>
<context position="26588" citStr="Zhang, 2004" startWordPosition="4550" endWordPosition="4551">ion type. As expected, different trigrams play an important role depending on the direction of the relation. For instance, the most informative tri1This is the result using only the text span between the target nouns. gram for Entity-Origin(e1,e2) is “away from the”, while reverse direction of the relation, EntityOrigin(e2,e1) or Origin-Entity, has “the source of” as the most informative trigram. These results are a step towards the extraction of meaningful knowledge from models produced by CNNs. 5 Related Work Over the years, various approaches have been proposed for relation classification (Zhang, 2004; Qian et al., 2009; Hendrickx et al., 2010; Rink and Harabagiu, 2010). Most of them treat it as a multiclass classification problem and apply a variety of machine learning techniques to the task in order to achieve a high accuracy. Recently, deep learning (Bengio, 2009) has become an attractive area for multiple applications, including computer vision, speech recognition and natural language processing. Among the different deep learning strategies, convolutional neural networks have been successfully applied to different NLP task such as part-of-speech tagging (dos Santos and Zadrozny, 2014),</context>
</contexts>
<marker>Zhang, 2004</marker>
<rawString>Zhu Zhang. 2004. Weakly-supervised relation classification for information extraction. In Proceedings of the ACM International Conference on Information and Knowledge Management, pages 581–588, New York, NY, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>