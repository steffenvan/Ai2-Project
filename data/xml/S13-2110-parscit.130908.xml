<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9932785">
UWM-TRIADS: Classifying Drug-Drug Interactions with Two-Stage
SVM and Post-Processing
</title>
<author confidence="0.996967">
Majid Rastegar-Mojarad Richard D. Boyce Rashmi Prasad
</author>
<affiliation confidence="0.999914">
University of Wisconsin-Milwaukee University of Pittsburgh University of Wisconsin-Milwaukee
</affiliation>
<address confidence="0.522588">
Milwaukee, WI, USA Pittsburgh, PA, USA Milwaukee, WI, USA
</address>
<email confidence="0.996774">
Rastega3@uwm.edu rdb20@pitt.edu prasadr@uwm.edu
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999635555555555">
We describe our system for the DDIExtraction-2013
shared task of classifying Drug-Drug interactions
(DDIs) given labeled drug mentions. The challenge
called for a five-way classification of all drug pairs in
each sentence: a drug pair is either non-interacting, or
interacting as one of four types. Our approach begins
with the use of a two-stage weighted SVM classifier
to handle the highly unbalanced class distribution: the
first stage for a binary classification of drug pairs as
interacting or non-interacting, and the second stage for
further classification of interacting pairs from the first
stage into one of the four interacting types. Our SVM
features exploit stemmed words, lemmas, bigrams,
part of speech tags, verb lists, and similarity measures,
among others. For each stage, we also developed a set
of post-processing rules based on observations in the
training data. Our best system achieved 0.472 F-
measure.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999024358490566">
Potential drug-drug interactions (DDIs), defined
as the co-prescription of two drugs that are
known to interact, are a significant source of pre-
ventable drug-related harm (i.e., adverse drug
events, or ADEs) (Nebeker et al., 2004). Gurwitz
et al, in their cohort study of ADEs among older
Americans receiving ambulatory care, found that
13.3% of preventable errors leading to an ADE
involved the co-prescription of drugs for which a
“...well established, clinically important interac-
tion” was known (Gurwitz et al., 2003). Nearly
7% (23/338) of the ADEs experienced by resi-
dents of two academic nursing homes over a
nine-month period were attributable to DDIs
(Gurwitz et al., 2005). Sixteen cohort and case-
control studies reported an elevated risk of hospi-
talization in patients who were exposed to DDIs
(Hines et al., 2011).
Failure to properly manage a DDI is a medical
error, and the Institute of Medicine has noted that
a lack of drug knowledge is one of the most fre-
quent proximal causes of such errors (Committee
on Identifying and Preventing Medication Errors,
2007). Indeed, health care providers often have
inadequate knowledge of what drug interactions
can occur, of patient specific factors that can in-
crease the risk of harm from an interaction, and
how to properly manage an interaction when pa-
tient exposure cannot be avoided (Chen et al.,
2005; Hines et al., 2012).
Unfortunately, there is no single complete and
authoritative source of DDI knowledge (Hines et
al., 2012). Rather, there are multiple sources,
each tasked with extracting, evaluating, and stay-
ing up-to-date with pertinent DDIs reported in
the literature, and drug product labeling (Boyce
et al., 2012). The dynamic nature of drug
knowledge, combined with the enormity of the
biomedical literature, makes this task extremely
challenging. Hence, natural language processing
methods for identifying and extracting DDIs are
receiving increased attention.
In 2011, the first shared task challenge for DDI
extraction, DDIExtraction-2011 (Segura-Bedmar
et al., 2011), invited participants to develop au-
tomatic methods to extract DDIs. The task fo-
cused on the identification of all possible pairs of
interacting drugs, without specifying anything
further about the interactions. By contrast, the
DDIExtraction-2013 (Segura-Bedmar et al.,
2013) shared task emphasized the importance of
recognizing what is being asserted about the in-
teraction. Accordingly, the challenge called for a
</bodyText>
<page confidence="0.955224">
667
</page>
<bodyText confidence="0.6152635">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 667–674, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
five-way classification of sentences for each
drug-pair:
</bodyText>
<listItem confidence="0.9762412">
• Advice: the sentence notes a recommendation
or advice related to the concomitant use of
the two drugs (e.g., “... UROXATRAL
should NOT be used in combination with
other alpha-blockers.”);
• Effect: the sentence states the effect of the
drug interaction, including pharmacodynamic
effect or mechanism of interaction (e.g.,
“Quinolones may enhance the effects of the
oral anticoagulant, warfarin, ...”);
• Mechanism: the sentence describes a phar-
macokinetic mechanism (e.g., “Grepafloxa-
cin is a competitive inhibitor of the
metabolism of theophylline.”).
• Int: the sentence mentions a drug interaction
but doesn’t provide any additional infor-
mation (e.g., “The interaction of omeprazole
and ketoconazole has been established.”).
• None: the sentence does not show an interac-
tion between the two drugs;
</listItem>
<bodyText confidence="0.99993725">
To focus on, and separately evaluate, different
aspects of the problem, the 2013 shared task was
divided into two subtasks. One task focused on
the recognition and classification of drug names,
while the other focused on the identification and
classification of DDIs, with the drug names pro-
vided from the gold standard. In this paper, we
describe our approach for handling the second
task, namely, DDI identification and classifica-
tion of all possible pairs of drugs in the provided
corpus. Our approach combined machine-
learning methods with the use of rules for post-
processing. A key feature of our machine-
learning approach is that it is specifically de-
signed to handle the highly unbalanced class dis-
tribution via the use of a two-stage weighted
SVM classifier. In addition to a variety of fea-
tures exploited for the classifier, we also devel-
oped a set of post-processing rules, with a
different set of rules applied after each stage of
SVM classification. Finally, our approach is also
aimed towards exploring the efficacy of methods
that do not need to rely on syntactic-parse based
features.
The paper is organized as follows. In the next
section, we describe the training and test data set
used in the challenge. In section 3, we describe
our method, the classifiers used at each stage,
their features, and post processing. In section 4,
we present the evaluation and results. We con-
clude in Section 5 with discussion and future
work.
</bodyText>
<sectionHeader confidence="0.988844" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.9948675">
The DDIExtraction-2013 challenge provided a
DDI corpus for development, containing 142
Medline abstracts on the subject of drug-drug
interactions, and 572 documents describing drug-
drug interactions from the DrugBank database.
The corpus includes 6976 sentences that were
annotated with four types of pharmacological
entities and four types of DDIs. The DDIs types
are: advice, effect, mechanism, and int.1 Table 1
shows the number of instances for each type. Ex-
amples can be seen in Section 1. The test set in-
cludes 33 Medline abstracts and 158 DrugBank
documents containing 1299 sentences and 5519
drug pairs.
</bodyText>
<table confidence="0.997717428571429">
Type Number
Positive Advice 827
Effect 1700
Mechanism 1322
Int 188
Negative None (non-interacting drugs) 23772
Total 27809
</table>
<tableCaption confidence="0.999834">
Table 1: Number of instances in each class
</tableCaption>
<sectionHeader confidence="0.997518" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.9996027">
Classification of each drug pair in a sentence in-
volved distinguishing between 5 classes, advice,
effect, mechanism, int and none. As described in
Section 2 (see Table 1), a major challenge in this
task is posed by the unbalanced distribution of
the classes. First, considering just the positive vs.
negative classes, just 16.9% (4037/23772) of
drug pairs are in the positive class, which include
interacting drug pairs (labeled as advice, effect,
mechanism and int). Furthermore, the four types
</bodyText>
<footnote confidence="0.985449">
1 http://www.cs.york.ac.uk/semeval-
2013/task9/data/uploads/task-9.2-ddi-extraction.pdf
</footnote>
<page confidence="0.995112">
668
</page>
<bodyText confidence="0.999975857142857">
within the positive class are also unbalanced,
with the int type constituting only 4.6%
(188/4037) of the instances. A classifier trained
on this data will, therefore, be biased towards the
majority class(es). We employed a two-stage
classification approach to cope with this problem,
as described below.
</bodyText>
<subsectionHeader confidence="0.997098">
3.1 Two-stage classification
</subsectionHeader>
<bodyText confidence="0.998219509803922">
Figure 1 shows the architecture of the system. In
the first stage, we trained a binary classifier to
classify drug pairs into positive and negative
classes. Then, in the second stage, we considered
only instances that were classified as positive by
the first classifier, and classified them into ad-
vice, effect, mechanism, and int classes, using a
multi-class classifier. A two-stage classifier of-
fers a distinct advantage over a one-stage classi-
fier for the DDI data set, which is highly skewed
towards one class, but particularly because this
majority class is also clearly semantically distinct
from the other positive classes (see Table 1).
By reframing part of this problem as a binary
classification task, we can exploit binary clas-
sification techniques and allow the classifier
to be particularly attentive to features distin-
guishing positive and negative drug pairs,
while at the same time avoiding the bias
against each of the non-majority classes. Our
experiments with the training set confirm this
idea.
Despite the above advantage of a two-stage
SVM, however, the unbalanced class problem
still remains, especially for training at the
first stage, where we have 20854 negative
instances and 4026 positives instances. In the
second stage, the data is somewhat unbal-
anced as well, with 20.5% as advice, 42.2%
as effect, 32.6% as mechanism, and only 4.7%
as int. To handle this problem further, we ex-
plored different approaches and algorithms,
including SMOTE (Chawla et al. 2002) and
other resampling algorithms. Our best results
over the training data were obtained with
Support Vector Machine (SVM) with differ-
ent class weights. We used LibSVM (Chang
and Lin, 2011) and set class weights for each
stage using results of cross-validation over
the training data (see Table 3 for class
weights).
As we wanted to pass the positively classified
instances from the first stage to the second stage
classifier, we favored the positive class in the
first stage. This resulted in a relatively high num-
ber of false positives for the positive instances,
which we attempted to reduce with a set of post-
processing rules before sending them to the se-
cond stage classifier. A different set of post-
processing rules were also developed to apply on
the output of the second stage classifier.
</bodyText>
<subsectionHeader confidence="0.999555">
3.2 Pre-processing
</subsectionHeader>
<bodyText confidence="0.907051333333333">
Before classification, all sentence instances in the
training and test set were pre-processed for the
following:
</bodyText>
<listItem confidence="0.97744425">
• All letters were changed to lower case.
• All drug names were normalized by replacing
them with one of two strings; one used for
drug mentions that were candidates for clas-
</listItem>
<figure confidence="0.522271625">
Sentence with more
than two drugs
Lemmatizer Stop Words list
Pre-Processing POS tagger
Stemmer One/more instances
First Stage Binary Classifier
(Weighted-SVM)
Instances classi- Instances positive classi-
fied as negative fied as
Post-Processing
Classified as Classified as
negative positive
Second Stage Multi-Class
Classifier (Weighted-SVM)
Post-Processing
Final Classification
</figure>
<figureCaption confidence="0.998279">
Figure 1: The Architecture of the system
</figureCaption>
<page confidence="0.983645">
669
</page>
<bodyText confidence="0.999312">
sification in the instance, and the other used
for all other drug mentions.
</bodyText>
<listItem confidence="0.998186466666667">
• All numbers were normalized by replacing
them with the same string.
• Stop words and punctuation were removed.
We used different stop word lists for differ-
ent systems that were submitted to the chal-
lenge.
• Part of speech (POS) tags were obtained with
the Stanford NLP tool (Toutanova et al,
2003).
• Words were stemmed with the Porter Stem-
mer (Porter, 1980).
• Words were lemmatized with the dragon tool
(Zhou et al, 2007).
• Synsets for words were obtained using
WordNet (Fellbaum, 1998).
</listItem>
<subsectionHeader confidence="0.871858">
3.3 Features
</subsectionHeader>
<bodyText confidence="0.998433909090909">
Since each sentence can have more than two drug
mentions, we generated an instance of the sen-
tence for each drug pair. We used different com-
binations of various features for the three
different systems submitted to the challenge
(Section 3.4.3). The following describes all the
features separated into two categories: features
per sentence and features per drug-pair instances.
Features per sentence: These are sentence-level
features that have the same values across all in-
stances of a sentence.
</bodyText>
<listItem confidence="0.981300882352941">
1- Words: This is a binary feature for all words
that appeared more than once in the corpus,
indicating the presence or absence of each
such word in the sentence. We considered
stemmed words as well as lemmatized words.
2- Word bigrams: This is a binary feature for all
word bigrams that appeared more than once
in the corpus, indicating the presence or ab-
sence of each such bigram in the sentence
3- Number of words: This feature represents the
total number of words in the sentence
4- Number of drug mentions: This feature repre-
sents the total number of drug mentions in
the sentence.
5- Cosine similarity between centroid vector of
each class and the instance: Inspired by the
vector space Information Retrieval approach,
</listItem>
<bodyText confidence="0.948336428571429">
we added new features to represent the co-
sine similarity between a sentence and the
centroid of normalized vectors for sentences
assigned the class X. Cosine similarity is cal-
culated based on modified tf*idf. We com-
puted modified tf*idf for a word w in class
C, based on the following formula:
</bodyText>
<equation confidence="0.985781">
(TF * IDF)w,C = log(count(w,C)+1)*
log(total # Inst / (#inst _ contains _ w +1))
</equation>
<bodyText confidence="0.99938705">
TF is the logarithm of the number of times the
word occurs in all sentences assigned to the class.
IDF is 1.0 divided by the logarithm of number of
instances in the class divided by the number of
times the word occurs across all classes. To cal-
culate the centroid vector for class C, a vector is
created for each sentence in class C by giving
each word in the sentence a modified TF*IDF
weight. The centroid vector for class C is the
mean of all vectors of sentences in class C. The
Cosine similarity between a given instance and
the centroid vector of each class is then used a
feature.
Features per instance (for each drug-pair): In
contrast to sentence-level features, these features
may have different values across the different
drug-pair instances. In each instance, we distin-
guished the two main drugs of interest for the
instance from all other additional drugs men-
tioned in the instance.
</bodyText>
<listItem confidence="0.456601">
1- Number of words between two main drugs:
This represents the total number of words be-
tween the two main drugs.
2- Number of drugs between two main drugs:
</listItem>
<bodyText confidence="0.933347928571428">
This represents the total number of additional
drugs appearing between the two main drugs.
3- Number of verbs: We used the number of
verbs in the instance as a feature, but relative
to their sentential position. In particular, we
split each instance into three sections: (i) be-
fore the first main drug, (ii) between the two
main drugs, and (iii) after the second main
drug. Then, we counted the number of verbs
in each section, and used them as three dif-
ferent features.
4- Number of verbs using class-specific verb
lists: For each class, we extracted two lists of
verbs. The first list contains verbs that ap-
</bodyText>
<page confidence="0.990436">
670
</page>
<bodyText confidence="0.908278">
peared in just that class but not in the others.
Thus, the set of verbs extracted for each class
are unique and different from the verbs asso-
ciated with other classes. The second list in-
cludes all verbs that appeared in that class
and their synonyms, extracted from Word-
Net. Then, for each of the three sentence sec-
tions, as described above, we created two
features to represent the number of verbs
from each of these lists that appeared in the
section. (An alternative way to represent this
feature would be to weight the verbs accord-
ing to their relative frequencies in the differ-
ent classes.)
5- POS of words between two main drugs: This
is a binary feature for word POS tags ob-
tained from POS tagging, and indicates the
presence or absence of each POS between the
two main drugs.
</bodyText>
<subsectionHeader confidence="0.994892">
3.4 Post processing
</subsectionHeader>
<bodyText confidence="0.9999462">
As described in Section 3.1, we developed a set
of post-processing rules for each stage of the
classifier. Here, we describe these rules, devel-
oped on the basis of observations in the training
data.
</bodyText>
<subsectionHeader confidence="0.749673">
3.4.1 Post processing after the first stage
</subsectionHeader>
<bodyText confidence="0.99986">
Post-processing rules for the first stage were de-
signed to reduce the number of false positives for
the positive class, since the weight assignment in
this stage favors this class. We provide examples
for each rule:
</bodyText>
<listItem confidence="0.652211111111111">
• The instance is classified as negative if both
drug mentions have the same name, since a
drug cannot interact with itself.
“In controlled clinical trials of AUGMENTIN XR,
22 patients received concomitant allopurinol and
AUGMENTIN XR.”
• The instance is classified as negative if one
of the drugs is a plural form of the other one,
since, as above, they refer to the same drug.
</listItem>
<construct confidence="0.79991025">
“Oral Anticoagulants: Interaction studies with
warfarin failed to identify any clinically im-
portant effect on the serum concentrations of the
anticoagulant or on its anticoagulant effect.”
</construct>
<bodyText confidence="0.5815235">
• The instance is classified as negative if one
of the drug mentions refers to a drug class
name of the other, since we don’t expect a
drug to interact with its class. Drug class
names were obtained from a classification
provided by the FDA.2 In the example below,
“MAOI” is the drug class name for “isocar-
boxazid”.
</bodyText>
<construct confidence="0.5365965">
“You cannot take mazindol if you have taken a
monoamine oxidase inhibitor (MAOI) such as
isocarboxazid (Marplan), tranylcypromine (Par-
nate), or phenelzine (Nardil) in the last 14 days.”
</construct>
<bodyText confidence="0.835893931034483">
• The instance is classified as negative if “,” or
“, and” appears between the two main drug
mentions, and is accompanied by an addi-
tional drug mention. This rules identifies
contexts where drugs are mentioned as a set,
in interaction with a different drug. The fol-
lowing sentences show “glyburide”, “tolbut-
amide” and “glipzide” as part of a set of
drugs in interaction with the additional drug
“DIFLUCAN”.
“DIFLUCAN reduces the metabolism of tolbut-
amide, glyburide, and glipizide and increases the
plasma concentration of these agents.”
“DIFLUCAN reduces the metabolism of tolbut-
amide, glyburide, and glipizide and increases the
plasma concentration of these agents.”
• The sentence is classified as negative if “,”
and additional drugs appear between the
main drug mentions. Like the previous rule,
this again recognizes drugs mentioned as a
set but identifies non-adjacent mentions. For
example, the following sentence doesn’t ex-
press any interaction between “tolbutamide”
and “glipizide”, and the rule recognizes them
as part of a set mention even though they are
non-adjacent.
“DIFLUCAN reduces the metabolism of tolbut-
amide, glyburide, and glipizide and increases the
plasma concentration of these agents.”
</bodyText>
<footnote confidence="0.9962175">
2http://www.fda.gov/ForIndustry/DataStandards/StructuredP
roductLabeling/ucm162549.htm
</footnote>
<page confidence="0.998084">
671
</page>
<bodyText confidence="0.922843">
• The instance is classified as negative if “or”
appears between the two main drug mentions
and the sentence contains additional drug
mentions. The presence of additional drug
mentions in the sentence is required here
since such conjoined pairs can interact with
each other when they occur alone.
</bodyText>
<figureCaption confidence="0.412677">
“Concurrent ingestion of antacid (20 mL of ant-
acid containing aluminum hydroxide, magnesium
hydroxide, and simethicone) did not significantly
affect the exposure of oxybutynin or desethyloxy-
butynin.”
</figureCaption>
<subsectionHeader confidence="0.805327">
3.4.2 Post processing after the second stage
</subsectionHeader>
<bodyText confidence="0.969956095238095">
Post-processing after the second classifier identi-
fies sentences like the following:
“Coadministration of alosetron and strong CYP3A4
inhibitors, such as clarithromycin, teli thromycin,
protease inhibitors, voriconazole, and itraconazole
has not been evaluated but should be undertaken with
caution because of similar potential drug interac-
tions.”
Examples like these illustrate that if drugs are
mentioned as a set, then all drugs in the set must
have the same interaction type with a drug men-
tioned outside the set. Thus, in the example, the
interaction of each of “clarithromycin”, “teli-
thromycin”, “protease inhibitors”, “voricona-
zole”, and “itraconazole” with “alosetron”
should be classified in the same way. We used
several syntactic and lexical cues to identify set
mentions of drugs. Then, since the SVM classi-
fier can make different decisions for each such
pair (e.g., it may assign one label to the interac-
tion of “clarithromycin” with “alosetron” and
</bodyText>
<table confidence="0.999147636363636">
System Metric Drug- Medline All
Bank
System 1 Prec 0.44 0.21 0.43
Rec 0.49 0.23 0.47
F 0.46 0.22 0.45
System 2 Prec 0.49 0.30 0.47
Rec 0.49 0.41 0.47
F 0.49 0.35 0.47
System 3 Prec 0.42 0.26 0.40
Rec 0.51 0.47 0.50
F 0.46 0.33 0.44
</table>
<tableCaption confidence="0.9966975">
Table 2. Results of each system. The three systems are
described in Section 3.4.3.
</tableCaption>
<bodyText confidence="0.999980266666667">
another label to the interaction of “telithromycin”
with “alosetron”), we applied uniform labeling
for the interaction of all such pairs. The majority
label was used as the common label. Ties were
not encountered in this data, although a solution
would have to be devised otherwise.
An important consideration for this rule is that it
uses both positively and negatively labeled in-
stances. The former are taken from the result of
the second stage classifier, and the latter from the
negative instances of the first stage classifier and
the negative instances of the first post-processor.
These varied inputs to the rule are illustrated by
the three ingoing arrows into the second post-
processor in Figure 1.
</bodyText>
<subsectionHeader confidence="0.86115">
3.4.3 Submitted Systems
</subsectionHeader>
<bodyText confidence="0.993868083333333">
We used the Weka (Hall et al. 2009) tool for all
experiments and submitted three systems (Sys-
tem1, System 2, and System 3 in Table 2) to the
challenge. All systems used the same two-stage
approach and SVM classification (LibSVM), but
differed in the use of some of the features (Sec-
tion 3.3) and in the weights assignment (Table 3).
We used linear kernel and the cost (C) was 1.2
and gamma was 0.5. In System 1, we used
stemmed words (instead of lemmatized words)
and a stop word list of 165 words. In System 2,
we used stemmed words again, but a different
</bodyText>
<table confidence="0.999736578947369">
System Stage Class Weight
System 1 First Positive 6.5
Stage Negative 1.0
Second Advice 800.0
Stage Effect 600.0
Int 3200.0
Mechanism 500.0
System 2 First Positive 2.5
Stage Negative 1.0
Second Advice 800.0
Stage Effect 600.0
Int 3200.0
Mechanism 500.0
System 3 First Positive 6.5
Stage Negative 1.0
Second Advice 80.0
Stage Effect 60.0
Int 320.0
Mechanism 50.0
</table>
<tableCaption confidence="0.999937">
Table 3: Class weight assignments in different systems
</tableCaption>
<page confidence="0.99765">
672
</page>
<bodyText confidence="0.999881">
stop word list of 263 words. Finally, in System 3,
we used lemmatized words and the same stop
word list of 263 words as in System 2. Weights
assignment was different across all systems, as
shown in Table 3.
</bodyText>
<sectionHeader confidence="0.99985" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999908538461538">
Table 2 shows the evaluation results of our sys-
tem over the test set. Our best results are
achieved with System 2, in which we used
stemmed words and our 263 stop word list, in
addition to the other features described in Section
3.3. Both the stop word list and the use of
stemmed vs. lemmatized words can be seen to
affect the performance. Clearly, a larger stop
word list is more useful, since both System 2 and
System 3 show an improvement over System 1.
On the other hand, the use of lemmas (used in
System 3) seems to be detrimental, compared
with stemmed words.
</bodyText>
<sectionHeader confidence="0.991218" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999990912280702">
To the best of our knowledge, this is the first
study to explore the value of a two-stage SVM
classification process for performing the complex
task of identifying sentences describing DDIs,
and making the important distinction between
statements providing advice, mechanism and ef-
fect, or declaring a pharmacokinetic and pharma-
codynamic DDI: critical distinctions in the fields
of pharmacology and pharmacy. We find that the
use of a two-stage classifier to handle the prob-
lem of an unbalanced class distribution for the
task of identifying and classifying DDIs is feasi-
ble but requires further development.
It’s valuable to consider these results within the
context of previous efforts for extracting DDIs.
Ten research papers were presented at the 2011
SemEval Conference (Segura-Bedmar et al,
2011) which used a smaller DDI corpus (Medline
abstracts were not included) and a simpler classi-
fication task (Segura-Bedmar et al, 2010). The
best performing system in this challenge utilized
an ensemble learning approach (Thomas et al,
2011) and produced an F-measure of 0.657. The
second best performing method utilized compo-
site kernels, a method that combines feature-
based and kernel-based methods, and was found
to perform with an F-measure of 0.64 (Chow-
dhury et al, 2011). Other NLP research has fo-
cused exclusively on extracting pharmacokinetic
DDIs from either Medline (e.g., Airola et al,
2008) or drug product labeling (e.g., Boyce et al,
2012).
Due to time constraints, we couldn’t test other
classifiers such as Naïve Bayes, JRip and Ran-
domforest in our approach. Future work will test
if SVM is the best choice for the first stage bina-
ry classifier. It is possible that libShortText (Yu
et al, 2013) works better than LibSVM because
this task is for sentence classification. We also
plan to explore if Naïve Bayes, JRip, or Random-
forest could work better than SVM for the second
stage multi-class classifier.
Since only three systems were permitted to the
challenge, and since the labeled test data was not
available until the time of writing, we did not
have the opportunity to test the impact of all the
features that we considered, or of the post-
processing rules. This will be explored in future
work.
We also plan to explore some variations to our
approach. For example, we will try to incorporate
some of the rules, especially those in the first
post-processor, as features in our system. Finally,
although we did utilize some semantic infor-
mation from WordNet for this work, we would
like to explore additional rich features, drawing
on syntax, semantics and discourse.
</bodyText>
<sectionHeader confidence="0.992758" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.682782066666667">
Airola A., S. Pyysalo, J. Bjšrne, T. Pahikkala, F.
Ginter and T. Salakoski. 2008. All-paths graph ker-
nel for protein-protein interaction extraction with
evaluation of cross-corpus learning. BMC Bioin-
formatics 9. Suppl 11 (2008): S2
Boyce R. D., C. Collins, M. Clayton, J. Kloke and J.
R. Horn. 2012. Inhibitory metabolic drug interac-
tions with newer psychotropic drugs: inclusion in
package inserts and influences of concurrence in
drug interaction screening software. The Annals of
Pharmacotherapy 46.10 (2012): 1287-1298
Boyce R. D., G. Gardner and H. Harkema. 2012. Us-
ing Natural Language Processing to Extract Drug-
Drug Interaction Information from Package Inserts.
Proceedings of the 2012 Workshop on BioNLP.
</reference>
<page confidence="0.997144">
673
</page>
<reference confidence="0.999503440860215">
Chang C. and C. Lin. 2011. LIBSVM: a library for
support vector machines. ACM Transactions on In-
telligent Systems and Technology. 2(3): 27.
Chawla N. V., K. W. Boyer, L. O. Hall and W. P.
Kegelmeyer. 2002. SMOTE: Synthetic Minority
Over-sampling Technique. Journal of Artificial In-
telligence Research 16: 321-357.
Chen Y. F., A. J. Avery, K. E. Neil, C. Johnson, M. E.
Dewey and I. H. Stockley. 2005. Incidence and
possible causes of prescribing potentially hazard-
ous/contraindicated drug combinations in general
practice. Drug Safety, 28(1): 67-80.
Chowdhury F. M., A. B. Abacha, A. Lavelli and P.
Zweigenbaum. 2011. Two Different Machine
Learning Techniques for Drug-Drug Interaction
Extraction. Proceedings of the 1st Challenge Task
on Drug-Drug Interaction Extraction (DDIExtrac-
tion-2011), 19–26.
Committee on Identifying and Preventing Medication
Errors, Aspden P, Wolcott J, Bootman JL, and
Cronenwett LR. 2007. Preventing Medication Er-
rors: Quality Chasm Series. Washington, D.C. The
National Academies Press.
Fellbaum C. 1998. WordNet: An Electronic Lexical
Database. Cambridge, MA: MIT Press.
Gurwitz J. H., T. S. Field, L. R. Harrold, J. Roth-
schild, K. Debellis, A. C. Seger, C. Cadoret, L. S.
Fish, L. Garber, M. Kelleher and D. W. Bates.
2003. Incidence and preventability of adverse drug
events among older persons in the ambulatory set-
ting. Journal of the American Medical Association,
289(9): 1107-1116.
Gurwitz J. H., T. S. Field, J. Judge, P. Rochon, L. R.
Harrold, C. Cadoret, M. Lee, K. White, J. LaPrino,
J. Erramuspe-Mainard, M. DeFlorio, L. Gavendo, J.
Auger and D. W. Bates. 2005. The incidence of ad-
verse drug events in two large academic long-term
care facilities. The American Journal of Medicine,
118(3): 251-258.
Hall M., E. Frank, G. Holmes, B. Pfahringer, P.
Reutemann and I. Witten. 2009. The WEKA Data
Mining Software: An Update. SIGKDD Explora-
tions, Volume 11, Issue 1.
Hines L. E., and J. E. Murphy. 2011. Potentially harm-
ful drug-drug interactions in the elderly: a review.
The American Journal of Geriatric Pharmacother-
apy, 9(6): 364-377.
Hines L. E., D. C. Malone and J. E. Murphy. 2012.
Recommendations for Generating, Evaluating, and
Implementing Drug-Drug Interaction Evidence.
Pharmacotherapy: The Journal of Human Pharma-
cology and Drug Therapy, 32(4): 304-313.
Nebeker J. R., P. Barach and M. H. Samore. 2004.
Clarifying Adverse Drug Events: A Clinician’s
Guide to Terminology, Documentation, and Re-
porting. Annals of Internal Medicine, 140(10): 795-
801.
Porter M. F. 1980. An algorithm for suffix stripping.
Program, 14(3): 130-137.
Segura-Bedmar I., P. Martinez and C. Pablo-Sanchez.
2010. Extracting drug-drug interactions from bio-
medical texts. BMC Bioinformatics 11, Suppl 5, P9.
Segura-Bedmar I., P. Martinez and D. S‡nchez-
Cisneros. 2011. The 1st DDIExtraction-2011 chal-
lenge task: Extraction of Drug-Drug Interactions
from biomedical texts. Proceedings of the 1st Chal-
lenge Task on Drug-Drug Interaction Extraction
(DDIExtraction-2011).
Segura-Bedmar I., P. Mart’nez and M. Herrero-Zazo.
2013. SemEval-2013 Task 9: Extraction of Drug-
Drug Interactions from Biomedical Texts. Proceed-
ings of the 7th International Workshop on Semantic
Evaluation (SemEval 2013).
Thomas P., M. Neves, I. Solt, D. Tikk and U. Leser.
2011. Relation Extraction for Drug-Drug Interac-
tions using Ensemble Learning. Proceedings of the
1st Challenge Task on Drug-Drug Interaction Ex-
traction (DDIExtraction-2011).
Toutanova K., D. Klein, C. Manning and Y. Sing-
er. 2003. Feature-Rich Part-of-Speech Tagging
with a Cyclic Dependency Network.
In Proceedings of HLT-NAACL, 173-180.
Yu H., C. Ho, Y. Juan and C. Lin. 2013. LibShortText:
A Library for Short-text Classification and Analy-
sis. Technical Report.
http://www.csie.ntu.edu.tw/~cjlin/ pa-
pers/libshorttext.pdf.
Zhou X., X. Zhang and X. Hu. 2007. Dragon Toolkit:
Incorporating Auto-learned Semantic Knowledge
into Large-Scale Text Retrieval and Mining.
In Proceedings of the 19th IEEE International Con-
ference on Tools with Artificial Intelligence
(ICTAI), 197-201.
</reference>
<page confidence="0.998821">
674
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.785388">
<title confidence="0.9986885">UWM-TRIADS: Classifying Drug-Drug Interactions with Two-Stage SVM and Post-Processing</title>
<author confidence="0.997629">Majid Rastegar-Mojarad Richard D Boyce Rashmi Prasad</author>
<affiliation confidence="0.999868">University of Wisconsin-Milwaukee University of Pittsburgh University of Wisconsin-Milwaukee</affiliation>
<address confidence="0.984305">Milwaukee, WI, USA Pittsburgh, PA, USA Milwaukee, WI, USA</address>
<email confidence="0.979581">Rastega3@uwm.edurdb20@pitt.eduprasadr@uwm.edu</email>
<abstract confidence="0.990133157894737">We describe our system for the DDIExtraction-2013 shared task of classifying Drug-Drug interactions (DDIs) given labeled drug mentions. The challenge called for a five-way classification of all drug pairs in each sentence: a drug pair is either non-interacting, or interacting as one of four types. Our approach begins with the use of a two-stage weighted SVM classifier to handle the highly unbalanced class distribution: the first stage for a binary classification of drug pairs as interacting or non-interacting, and the second stage for further classification of interacting pairs from the first stage into one of the four interacting types. Our SVM features exploit stemmed words, lemmas, bigrams, part of speech tags, verb lists, and similarity measures, among others. For each stage, we also developed a set of post-processing rules based on observations in the training data. Our best system achieved 0.472 Fmeasure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Airola</author>
<author>S Pyysalo</author>
<author>J Bjšrne</author>
<author>T Pahikkala</author>
<author>F Ginter</author>
<author>T Salakoski</author>
</authors>
<title>All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning.</title>
<date>2008</date>
<journal>BMC Bioinformatics 9. Suppl</journal>
<volume>11</volume>
<pages>2</pages>
<contexts>
<context position="24254" citStr="Airola et al, 2008" startWordPosition="3895" endWordPosition="3898">-Bedmar et al, 2011) which used a smaller DDI corpus (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stage binary classifier. It is possible that libShortText (Yu et al, 2013) works better than LibSVM because this task is for sentence classification. We also plan to explore if Naïve Bayes, JRip, or Randomforest could work better than SVM for the second stage multi-class classifier. Since only three systems were permitted to the challenge, and since the labeled t</context>
</contexts>
<marker>Airola, Pyysalo, Bjšrne, Pahikkala, Ginter, Salakoski, 2008</marker>
<rawString>Airola A., S. Pyysalo, J. Bjšrne, T. Pahikkala, F. Ginter and T. Salakoski. 2008. All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning. BMC Bioinformatics 9. Suppl 11 (2008): S2</rawString>
</citation>
<citation valid="true">
<authors>
<author>R D Boyce</author>
<author>C Collins</author>
<author>M Clayton</author>
<author>J Kloke</author>
<author>J R Horn</author>
</authors>
<title>Inhibitory metabolic drug interactions with newer psychotropic drugs: inclusion in package inserts and influences of concurrence in drug interaction screening software. The Annals of Pharmacotherapy 46.10</title>
<date>2012</date>
<pages>1287--1298</pages>
<contexts>
<context position="2971" citStr="Boyce et al., 2012" startWordPosition="449" endWordPosition="452">ors, 2007). Indeed, health care providers often have inadequate knowledge of what drug interactions can occur, of patient specific factors that can increase the risk of harm from an interaction, and how to properly manage an interaction when patient exposure cannot be avoided (Chen et al., 2005; Hines et al., 2012). Unfortunately, there is no single complete and authoritative source of DDI knowledge (Hines et al., 2012). Rather, there are multiple sources, each tasked with extracting, evaluating, and staying up-to-date with pertinent DDIs reported in the literature, and drug product labeling (Boyce et al., 2012). The dynamic nature of drug knowledge, combined with the enormity of the biomedical literature, makes this task extremely challenging. Hence, natural language processing methods for identifying and extracting DDIs are receiving increased attention. In 2011, the first shared task challenge for DDI extraction, DDIExtraction-2011 (Segura-Bedmar et al., 2011), invited participants to develop automatic methods to extract DDIs. The task focused on the identification of all possible pairs of interacting drugs, without specifying anything further about the interactions. By contrast, the DDIExtraction</context>
<context position="24305" citStr="Boyce et al, 2012" startWordPosition="3904" endWordPosition="3907"> (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stage binary classifier. It is possible that libShortText (Yu et al, 2013) works better than LibSVM because this task is for sentence classification. We also plan to explore if Naïve Bayes, JRip, or Randomforest could work better than SVM for the second stage multi-class classifier. Since only three systems were permitted to the challenge, and since the labeled test data was not available until the time of writin</context>
</contexts>
<marker>Boyce, Collins, Clayton, Kloke, Horn, 2012</marker>
<rawString>Boyce R. D., C. Collins, M. Clayton, J. Kloke and J. R. Horn. 2012. Inhibitory metabolic drug interactions with newer psychotropic drugs: inclusion in package inserts and influences of concurrence in drug interaction screening software. The Annals of Pharmacotherapy 46.10 (2012): 1287-1298</rawString>
</citation>
<citation valid="true">
<authors>
<author>R D Boyce</author>
<author>G Gardner</author>
<author>H Harkema</author>
</authors>
<title>Using Natural Language Processing to Extract DrugDrug Interaction Information from Package Inserts.</title>
<date>2012</date>
<booktitle>Proceedings of the 2012 Workshop on BioNLP.</booktitle>
<contexts>
<context position="2971" citStr="Boyce et al., 2012" startWordPosition="449" endWordPosition="452">ors, 2007). Indeed, health care providers often have inadequate knowledge of what drug interactions can occur, of patient specific factors that can increase the risk of harm from an interaction, and how to properly manage an interaction when patient exposure cannot be avoided (Chen et al., 2005; Hines et al., 2012). Unfortunately, there is no single complete and authoritative source of DDI knowledge (Hines et al., 2012). Rather, there are multiple sources, each tasked with extracting, evaluating, and staying up-to-date with pertinent DDIs reported in the literature, and drug product labeling (Boyce et al., 2012). The dynamic nature of drug knowledge, combined with the enormity of the biomedical literature, makes this task extremely challenging. Hence, natural language processing methods for identifying and extracting DDIs are receiving increased attention. In 2011, the first shared task challenge for DDI extraction, DDIExtraction-2011 (Segura-Bedmar et al., 2011), invited participants to develop automatic methods to extract DDIs. The task focused on the identification of all possible pairs of interacting drugs, without specifying anything further about the interactions. By contrast, the DDIExtraction</context>
<context position="24305" citStr="Boyce et al, 2012" startWordPosition="3904" endWordPosition="3907"> (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stage binary classifier. It is possible that libShortText (Yu et al, 2013) works better than LibSVM because this task is for sentence classification. We also plan to explore if Naïve Bayes, JRip, or Randomforest could work better than SVM for the second stage multi-class classifier. Since only three systems were permitted to the challenge, and since the labeled test data was not available until the time of writin</context>
</contexts>
<marker>Boyce, Gardner, Harkema, 2012</marker>
<rawString>Boyce R. D., G. Gardner and H. Harkema. 2012. Using Natural Language Processing to Extract DrugDrug Interaction Information from Package Inserts. Proceedings of the 2012 Workshop on BioNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chang</author>
<author>C Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology.</journal>
<volume>2</volume>
<issue>3</issue>
<pages>27</pages>
<contexts>
<context position="9693" citStr="Chang and Lin, 2011" startWordPosition="1482" endWordPosition="1485"> SVM, however, the unbalanced class problem still remains, especially for training at the first stage, where we have 20854 negative instances and 4026 positives instances. In the second stage, the data is somewhat unbalanced as well, with 20.5% as advice, 42.2% as effect, 32.6% as mechanism, and only 4.7% as int. To handle this problem further, we explored different approaches and algorithms, including SMOTE (Chawla et al. 2002) and other resampling algorithms. Our best results over the training data were obtained with Support Vector Machine (SVM) with different class weights. We used LibSVM (Chang and Lin, 2011) and set class weights for each stage using results of cross-validation over the training data (see Table 3 for class weights). As we wanted to pass the positively classified instances from the first stage to the second stage classifier, we favored the positive class in the first stage. This resulted in a relatively high number of false positives for the positive instances, which we attempted to reduce with a set of postprocessing rules before sending them to the second stage classifier. A different set of postprocessing rules were also developed to apply on the output of the second stage clas</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chang C. and C. Lin. 2011. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology. 2(3): 27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N V Chawla</author>
<author>K W Boyer</author>
<author>L O Hall</author>
<author>W P Kegelmeyer</author>
</authors>
<title>SMOTE: Synthetic Minority Over-sampling Technique.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research</journal>
<volume>16</volume>
<pages>321--357</pages>
<contexts>
<context position="9505" citStr="Chawla et al. 2002" startWordPosition="1452" endWordPosition="1455">irs, while at the same time avoiding the bias against each of the non-majority classes. Our experiments with the training set confirm this idea. Despite the above advantage of a two-stage SVM, however, the unbalanced class problem still remains, especially for training at the first stage, where we have 20854 negative instances and 4026 positives instances. In the second stage, the data is somewhat unbalanced as well, with 20.5% as advice, 42.2% as effect, 32.6% as mechanism, and only 4.7% as int. To handle this problem further, we explored different approaches and algorithms, including SMOTE (Chawla et al. 2002) and other resampling algorithms. Our best results over the training data were obtained with Support Vector Machine (SVM) with different class weights. We used LibSVM (Chang and Lin, 2011) and set class weights for each stage using results of cross-validation over the training data (see Table 3 for class weights). As we wanted to pass the positively classified instances from the first stage to the second stage classifier, we favored the positive class in the first stage. This resulted in a relatively high number of false positives for the positive instances, which we attempted to reduce with a</context>
</contexts>
<marker>Chawla, Boyer, Hall, Kegelmeyer, 2002</marker>
<rawString>Chawla N. V., K. W. Boyer, L. O. Hall and W. P. Kegelmeyer. 2002. SMOTE: Synthetic Minority Over-sampling Technique. Journal of Artificial Intelligence Research 16: 321-357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y F Chen</author>
<author>A J Avery</author>
<author>K E Neil</author>
<author>C Johnson</author>
<author>M E Dewey</author>
<author>I H Stockley</author>
</authors>
<title>Incidence and possible causes of prescribing potentially hazardous/contraindicated drug combinations in general practice.</title>
<date>2005</date>
<journal>Drug Safety,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>67--80</pages>
<contexts>
<context position="2647" citStr="Chen et al., 2005" startWordPosition="400" endWordPosition="403">d risk of hospitalization in patients who were exposed to DDIs (Hines et al., 2011). Failure to properly manage a DDI is a medical error, and the Institute of Medicine has noted that a lack of drug knowledge is one of the most frequent proximal causes of such errors (Committee on Identifying and Preventing Medication Errors, 2007). Indeed, health care providers often have inadequate knowledge of what drug interactions can occur, of patient specific factors that can increase the risk of harm from an interaction, and how to properly manage an interaction when patient exposure cannot be avoided (Chen et al., 2005; Hines et al., 2012). Unfortunately, there is no single complete and authoritative source of DDI knowledge (Hines et al., 2012). Rather, there are multiple sources, each tasked with extracting, evaluating, and staying up-to-date with pertinent DDIs reported in the literature, and drug product labeling (Boyce et al., 2012). The dynamic nature of drug knowledge, combined with the enormity of the biomedical literature, makes this task extremely challenging. Hence, natural language processing methods for identifying and extracting DDIs are receiving increased attention. In 2011, the first shared </context>
</contexts>
<marker>Chen, Avery, Neil, Johnson, Dewey, Stockley, 2005</marker>
<rawString>Chen Y. F., A. J. Avery, K. E. Neil, C. Johnson, M. E. Dewey and I. H. Stockley. 2005. Incidence and possible causes of prescribing potentially hazardous/contraindicated drug combinations in general practice. Drug Safety, 28(1): 67-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Chowdhury</author>
<author>A B Abacha</author>
<author>A Lavelli</author>
<author>P Zweigenbaum</author>
</authors>
<title>Two Different Machine Learning Techniques for Drug-Drug Interaction Extraction.</title>
<date>2011</date>
<booktitle>Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011),</booktitle>
<contexts>
<context position="24128" citStr="Chowdhury et al, 2011" startWordPosition="3875" endWordPosition="3879">in the context of previous efforts for extracting DDIs. Ten research papers were presented at the 2011 SemEval Conference (Segura-Bedmar et al, 2011) which used a smaller DDI corpus (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stage binary classifier. It is possible that libShortText (Yu et al, 2013) works better than LibSVM because this task is for sentence classification. We also plan to explore if Naïve Bayes, JRip, or Randomforest could work better than SVM </context>
</contexts>
<marker>Chowdhury, Abacha, Lavelli, Zweigenbaum, 2011</marker>
<rawString>Chowdhury F. M., A. B. Abacha, A. Lavelli and P. Zweigenbaum. 2011. Two Different Machine Learning Techniques for Drug-Drug Interaction Extraction. Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011), 19–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Wolcott</author>
<author>Bootman JL</author>
<author>Cronenwett LR</author>
</authors>
<title>Committee on Identifying and Preventing Medication Errors, Aspden</title>
<date>2007</date>
<publisher>The National Academies Press.</publisher>
<location>Washington, D.C.</location>
<marker>Wolcott, JL, LR, 2007</marker>
<rawString>Committee on Identifying and Preventing Medication Errors, Aspden P, Wolcott J, Bootman JL, and Cronenwett LR. 2007. Preventing Medication Errors: Quality Chasm Series. Washington, D.C. The National Academies Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="11596" citStr="Fellbaum, 1998" startWordPosition="1791" endWordPosition="1792">on Figure 1: The Architecture of the system 669 sification in the instance, and the other used for all other drug mentions. • All numbers were normalized by replacing them with the same string. • Stop words and punctuation were removed. We used different stop word lists for different systems that were submitted to the challenge. • Part of speech (POS) tags were obtained with the Stanford NLP tool (Toutanova et al, 2003). • Words were stemmed with the Porter Stemmer (Porter, 1980). • Words were lemmatized with the dragon tool (Zhou et al, 2007). • Synsets for words were obtained using WordNet (Fellbaum, 1998). 3.3 Features Since each sentence can have more than two drug mentions, we generated an instance of the sentence for each drug pair. We used different combinations of various features for the three different systems submitted to the challenge (Section 3.4.3). The following describes all the features separated into two categories: features per sentence and features per drug-pair instances. Features per sentence: These are sentence-level features that have the same values across all instances of a sentence. 1- Words: This is a binary feature for all words that appeared more than once in the cor</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum C. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Gurwitz</author>
<author>T S Field</author>
<author>L R Harrold</author>
<author>J Rothschild</author>
<author>K Debellis</author>
<author>A C Seger</author>
<author>C Cadoret</author>
<author>L S Fish</author>
<author>L Garber</author>
<author>M Kelleher</author>
<author>D W Bates</author>
</authors>
<title>Incidence and preventability of adverse drug events among older persons in the ambulatory setting.</title>
<date>2003</date>
<journal>Journal of the American Medical Association,</journal>
<volume>289</volume>
<issue>9</issue>
<pages>1107--1116</pages>
<contexts>
<context position="1809" citStr="Gurwitz et al., 2003" startWordPosition="259" endWordPosition="262">based on observations in the training data. Our best system achieved 0.472 Fmeasure. 1 Introduction Potential drug-drug interactions (DDIs), defined as the co-prescription of two drugs that are known to interact, are a significant source of preventable drug-related harm (i.e., adverse drug events, or ADEs) (Nebeker et al., 2004). Gurwitz et al, in their cohort study of ADEs among older Americans receiving ambulatory care, found that 13.3% of preventable errors leading to an ADE involved the co-prescription of drugs for which a “...well established, clinically important interaction” was known (Gurwitz et al., 2003). Nearly 7% (23/338) of the ADEs experienced by residents of two academic nursing homes over a nine-month period were attributable to DDIs (Gurwitz et al., 2005). Sixteen cohort and casecontrol studies reported an elevated risk of hospitalization in patients who were exposed to DDIs (Hines et al., 2011). Failure to properly manage a DDI is a medical error, and the Institute of Medicine has noted that a lack of drug knowledge is one of the most frequent proximal causes of such errors (Committee on Identifying and Preventing Medication Errors, 2007). Indeed, health care providers often have inad</context>
</contexts>
<marker>Gurwitz, Field, Harrold, Rothschild, Debellis, Seger, Cadoret, Fish, Garber, Kelleher, Bates, 2003</marker>
<rawString>Gurwitz J. H., T. S. Field, L. R. Harrold, J. Rothschild, K. Debellis, A. C. Seger, C. Cadoret, L. S. Fish, L. Garber, M. Kelleher and D. W. Bates. 2003. Incidence and preventability of adverse drug events among older persons in the ambulatory setting. Journal of the American Medical Association, 289(9): 1107-1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Gurwitz</author>
<author>T S Field</author>
<author>J Judge</author>
<author>P Rochon</author>
<author>L R Harrold</author>
<author>C Cadoret</author>
<author>M Lee</author>
<author>K White</author>
<author>J LaPrino</author>
<author>J Erramuspe-Mainard</author>
<author>M DeFlorio</author>
<author>L Gavendo</author>
<author>J Auger</author>
<author>D W Bates</author>
</authors>
<title>The incidence of adverse drug events in two large academic long-term care facilities.</title>
<date>2005</date>
<journal>The American Journal of Medicine,</journal>
<volume>118</volume>
<issue>3</issue>
<pages>251--258</pages>
<contexts>
<context position="1970" citStr="Gurwitz et al., 2005" startWordPosition="286" endWordPosition="289">escription of two drugs that are known to interact, are a significant source of preventable drug-related harm (i.e., adverse drug events, or ADEs) (Nebeker et al., 2004). Gurwitz et al, in their cohort study of ADEs among older Americans receiving ambulatory care, found that 13.3% of preventable errors leading to an ADE involved the co-prescription of drugs for which a “...well established, clinically important interaction” was known (Gurwitz et al., 2003). Nearly 7% (23/338) of the ADEs experienced by residents of two academic nursing homes over a nine-month period were attributable to DDIs (Gurwitz et al., 2005). Sixteen cohort and casecontrol studies reported an elevated risk of hospitalization in patients who were exposed to DDIs (Hines et al., 2011). Failure to properly manage a DDI is a medical error, and the Institute of Medicine has noted that a lack of drug knowledge is one of the most frequent proximal causes of such errors (Committee on Identifying and Preventing Medication Errors, 2007). Indeed, health care providers often have inadequate knowledge of what drug interactions can occur, of patient specific factors that can increase the risk of harm from an interaction, and how to properly man</context>
</contexts>
<marker>Gurwitz, Field, Judge, Rochon, Harrold, Cadoret, Lee, White, LaPrino, Erramuspe-Mainard, DeFlorio, Gavendo, Auger, Bates, 2005</marker>
<rawString>Gurwitz J. H., T. S. Field, J. Judge, P. Rochon, L. R. Harrold, C. Cadoret, M. Lee, K. White, J. LaPrino, J. Erramuspe-Mainard, M. DeFlorio, L. Gavendo, J. Auger and D. W. Bates. 2005. The incidence of adverse drug events in two large academic long-term care facilities. The American Journal of Medicine, 118(3): 251-258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hall</author>
<author>E Frank</author>
<author>G Holmes</author>
<author>B Pfahringer</author>
<author>P Reutemann</author>
<author>I Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<contexts>
<context position="21097" citStr="Hall et al. 2009" startWordPosition="3361" endWordPosition="3364">y label was used as the common label. Ties were not encountered in this data, although a solution would have to be devised otherwise. An important consideration for this rule is that it uses both positively and negatively labeled instances. The former are taken from the result of the second stage classifier, and the latter from the negative instances of the first stage classifier and the negative instances of the first post-processor. These varied inputs to the rule are illustrated by the three ingoing arrows into the second postprocessor in Figure 1. 3.4.3 Submitted Systems We used the Weka (Hall et al. 2009) tool for all experiments and submitted three systems (System1, System 2, and System 3 in Table 2) to the challenge. All systems used the same two-stage approach and SVM classification (LibSVM), but differed in the use of some of the features (Section 3.3) and in the weights assignment (Table 3). We used linear kernel and the cost (C) was 1.2 and gamma was 0.5. In System 1, we used stemmed words (instead of lemmatized words) and a stop word list of 165 words. In System 2, we used stemmed words again, but a different System Stage Class Weight System 1 First Positive 6.5 Stage Negative 1.0 Secon</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Hall M., E. Frank, G. Holmes, B. Pfahringer, P. Reutemann and I. Witten. 2009. The WEKA Data Mining Software: An Update. SIGKDD Explorations, Volume 11, Issue 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L E Hines</author>
<author>J E Murphy</author>
</authors>
<title>Potentially harmful drug-drug interactions in the elderly: a review.</title>
<date>2011</date>
<journal>The American Journal of Geriatric Pharmacotherapy,</journal>
<volume>9</volume>
<issue>6</issue>
<pages>364--377</pages>
<marker>Hines, Murphy, 2011</marker>
<rawString>Hines L. E., and J. E. Murphy. 2011. Potentially harmful drug-drug interactions in the elderly: a review. The American Journal of Geriatric Pharmacotherapy, 9(6): 364-377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L E Hines</author>
<author>D C Malone</author>
<author>J E Murphy</author>
</authors>
<title>Recommendations for Generating, Evaluating, and Implementing Drug-Drug Interaction Evidence. Pharmacotherapy:</title>
<date>2012</date>
<journal>The Journal of Human Pharmacology and Drug Therapy,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>304--313</pages>
<contexts>
<context position="2668" citStr="Hines et al., 2012" startWordPosition="404" endWordPosition="407">zation in patients who were exposed to DDIs (Hines et al., 2011). Failure to properly manage a DDI is a medical error, and the Institute of Medicine has noted that a lack of drug knowledge is one of the most frequent proximal causes of such errors (Committee on Identifying and Preventing Medication Errors, 2007). Indeed, health care providers often have inadequate knowledge of what drug interactions can occur, of patient specific factors that can increase the risk of harm from an interaction, and how to properly manage an interaction when patient exposure cannot be avoided (Chen et al., 2005; Hines et al., 2012). Unfortunately, there is no single complete and authoritative source of DDI knowledge (Hines et al., 2012). Rather, there are multiple sources, each tasked with extracting, evaluating, and staying up-to-date with pertinent DDIs reported in the literature, and drug product labeling (Boyce et al., 2012). The dynamic nature of drug knowledge, combined with the enormity of the biomedical literature, makes this task extremely challenging. Hence, natural language processing methods for identifying and extracting DDIs are receiving increased attention. In 2011, the first shared task challenge for DD</context>
</contexts>
<marker>Hines, Malone, Murphy, 2012</marker>
<rawString>Hines L. E., D. C. Malone and J. E. Murphy. 2012. Recommendations for Generating, Evaluating, and Implementing Drug-Drug Interaction Evidence. Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy, 32(4): 304-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Nebeker</author>
<author>P Barach</author>
<author>M H Samore</author>
</authors>
<title>Clarifying Adverse Drug Events: A Clinician’s Guide to Terminology, Documentation, and Reporting.</title>
<date>2004</date>
<journal>Annals of Internal Medicine,</journal>
<volume>140</volume>
<issue>10</issue>
<pages>795--801</pages>
<contexts>
<context position="1518" citStr="Nebeker et al., 2004" startWordPosition="214" endWordPosition="217">classification of interacting pairs from the first stage into one of the four interacting types. Our SVM features exploit stemmed words, lemmas, bigrams, part of speech tags, verb lists, and similarity measures, among others. For each stage, we also developed a set of post-processing rules based on observations in the training data. Our best system achieved 0.472 Fmeasure. 1 Introduction Potential drug-drug interactions (DDIs), defined as the co-prescription of two drugs that are known to interact, are a significant source of preventable drug-related harm (i.e., adverse drug events, or ADEs) (Nebeker et al., 2004). Gurwitz et al, in their cohort study of ADEs among older Americans receiving ambulatory care, found that 13.3% of preventable errors leading to an ADE involved the co-prescription of drugs for which a “...well established, clinically important interaction” was known (Gurwitz et al., 2003). Nearly 7% (23/338) of the ADEs experienced by residents of two academic nursing homes over a nine-month period were attributable to DDIs (Gurwitz et al., 2005). Sixteen cohort and casecontrol studies reported an elevated risk of hospitalization in patients who were exposed to DDIs (Hines et al., 2011). Fai</context>
</contexts>
<marker>Nebeker, Barach, Samore, 2004</marker>
<rawString>Nebeker J. R., P. Barach and M. H. Samore. 2004. Clarifying Adverse Drug Events: A Clinician’s Guide to Terminology, Documentation, and Reporting. Annals of Internal Medicine, 140(10): 795-801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<pages>130--137</pages>
<contexts>
<context position="11465" citStr="Porter, 1980" startWordPosition="1769" endWordPosition="1770">assified as Classified as negative positive Second Stage Multi-Class Classifier (Weighted-SVM) Post-Processing Final Classification Figure 1: The Architecture of the system 669 sification in the instance, and the other used for all other drug mentions. • All numbers were normalized by replacing them with the same string. • Stop words and punctuation were removed. We used different stop word lists for different systems that were submitted to the challenge. • Part of speech (POS) tags were obtained with the Stanford NLP tool (Toutanova et al, 2003). • Words were stemmed with the Porter Stemmer (Porter, 1980). • Words were lemmatized with the dragon tool (Zhou et al, 2007). • Synsets for words were obtained using WordNet (Fellbaum, 1998). 3.3 Features Since each sentence can have more than two drug mentions, we generated an instance of the sentence for each drug pair. We used different combinations of various features for the three different systems submitted to the challenge (Section 3.4.3). The following describes all the features separated into two categories: features per sentence and features per drug-pair instances. Features per sentence: These are sentence-level features that have the same </context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Porter M. F. 1980. An algorithm for suffix stripping. Program, 14(3): 130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Martinez</author>
<author>C Pablo-Sanchez</author>
</authors>
<title>Extracting drug-drug interactions from biomedical texts.</title>
<date>2010</date>
<journal>BMC Bioinformatics</journal>
<volume>11</volume>
<pages>9</pages>
<contexts>
<context position="23787" citStr="Segura-Bedmar et al, 2010" startWordPosition="3821" endWordPosition="3824">cokinetic and pharmacodynamic DDI: critical distinctions in the fields of pharmacology and pharmacy. We find that the use of a two-stage classifier to handle the problem of an unbalanced class distribution for the task of identifying and classifying DDIs is feasible but requires further development. It’s valuable to consider these results within the context of previous efforts for extracting DDIs. Ten research papers were presented at the 2011 SemEval Conference (Segura-Bedmar et al, 2011) which used a smaller DDI corpus (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes,</context>
</contexts>
<marker>Segura-Bedmar, Martinez, Pablo-Sanchez, 2010</marker>
<rawString>Segura-Bedmar I., P. Martinez and C. Pablo-Sanchez. 2010. Extracting drug-drug interactions from biomedical texts. BMC Bioinformatics 11, Suppl 5, P9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Martinez</author>
<author>D S‡nchezCisneros</author>
</authors>
<title>The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug Interactions from biomedical texts.</title>
<date>2011</date>
<booktitle>Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011).</booktitle>
<marker>Segura-Bedmar, Martinez, S‡nchezCisneros, 2011</marker>
<rawString>Segura-Bedmar I., P. Martinez and D. S‡nchezCisneros. 2011. The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug Interactions from biomedical texts. Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Mart’nez</author>
<author>M Herrero-Zazo</author>
</authors>
<date>2013</date>
<booktitle>SemEval-2013 Task 9: Extraction of DrugDrug Interactions from Biomedical Texts. Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Segura-Bedmar, Mart’nez, Herrero-Zazo, 2013</marker>
<rawString>Segura-Bedmar I., P. Mart’nez and M. Herrero-Zazo. 2013. SemEval-2013 Task 9: Extraction of DrugDrug Interactions from Biomedical Texts. Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Thomas</author>
<author>M Neves</author>
<author>I Solt</author>
<author>D Tikk</author>
<author>U Leser</author>
</authors>
<title>Relation Extraction for Drug-Drug Interactions using Ensemble Learning.</title>
<date>2011</date>
<booktitle>Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011).</booktitle>
<contexts>
<context position="23893" citStr="Thomas et al, 2011" startWordPosition="3837" endWordPosition="3840"> the use of a two-stage classifier to handle the problem of an unbalanced class distribution for the task of identifying and classifying DDIs is feasible but requires further development. It’s valuable to consider these results within the context of previous efforts for extracting DDIs. Ten research papers were presented at the 2011 SemEval Conference (Segura-Bedmar et al, 2011) which used a smaller DDI corpus (Medline abstracts were not included) and a simpler classification task (Segura-Bedmar et al, 2010). The best performing system in this challenge utilized an ensemble learning approach (Thomas et al, 2011) and produced an F-measure of 0.657. The second best performing method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stag</context>
</contexts>
<marker>Thomas, Neves, Solt, Tikk, Leser, 2011</marker>
<rawString>Thomas P., M. Neves, I. Solt, D. Tikk and U. Leser. 2011. Relation Extraction for Drug-Drug Interactions using Ensemble Learning. Proceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction (DDIExtraction-2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="11404" citStr="Toutanova et al, 2003" startWordPosition="1756" endWordPosition="1759">- Instances positive classified as negative fied as Post-Processing Classified as Classified as negative positive Second Stage Multi-Class Classifier (Weighted-SVM) Post-Processing Final Classification Figure 1: The Architecture of the system 669 sification in the instance, and the other used for all other drug mentions. • All numbers were normalized by replacing them with the same string. • Stop words and punctuation were removed. We used different stop word lists for different systems that were submitted to the challenge. • Part of speech (POS) tags were obtained with the Stanford NLP tool (Toutanova et al, 2003). • Words were stemmed with the Porter Stemmer (Porter, 1980). • Words were lemmatized with the dragon tool (Zhou et al, 2007). • Synsets for words were obtained using WordNet (Fellbaum, 1998). 3.3 Features Since each sentence can have more than two drug mentions, we generated an instance of the sentence for each drug pair. We used different combinations of various features for the three different systems submitted to the challenge (Section 3.4.3). The following describes all the features separated into two categories: features per sentence and features per drug-pair instances. Features per se</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Toutanova K., D. Klein, C. Manning and Y. Singer. 2003. Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network. In Proceedings of HLT-NAACL, 173-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yu</author>
<author>C Ho</author>
<author>Y Juan</author>
<author>C Lin</author>
</authors>
<title>LibShortText: A Library for Short-text Classification and Analysis.</title>
<date>2013</date>
<tech>Technical Report.</tech>
<contexts>
<context position="24563" citStr="Yu et al, 2013" startWordPosition="3950" endWordPosition="3953">rforming method utilized composite kernels, a method that combines featurebased and kernel-based methods, and was found to perform with an F-measure of 0.64 (Chowdhury et al, 2011). Other NLP research has focused exclusively on extracting pharmacokinetic DDIs from either Medline (e.g., Airola et al, 2008) or drug product labeling (e.g., Boyce et al, 2012). Due to time constraints, we couldn’t test other classifiers such as Naïve Bayes, JRip and Randomforest in our approach. Future work will test if SVM is the best choice for the first stage binary classifier. It is possible that libShortText (Yu et al, 2013) works better than LibSVM because this task is for sentence classification. We also plan to explore if Naïve Bayes, JRip, or Randomforest could work better than SVM for the second stage multi-class classifier. Since only three systems were permitted to the challenge, and since the labeled test data was not available until the time of writing, we did not have the opportunity to test the impact of all the features that we considered, or of the postprocessing rules. This will be explored in future work. We also plan to explore some variations to our approach. For example, we will try to incorpora</context>
</contexts>
<marker>Yu, Ho, Juan, Lin, 2013</marker>
<rawString>Yu H., C. Ho, Y. Juan and C. Lin. 2013. LibShortText: A Library for Short-text Classification and Analysis. Technical Report.</rawString>
</citation>
<citation valid="false">
<note>http://www.csie.ntu.edu.tw/~cjlin/ papers/libshorttext.pdf.</note>
<marker></marker>
<rawString>http://www.csie.ntu.edu.tw/~cjlin/ papers/libshorttext.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhou</author>
<author>X Zhang</author>
<author>X Hu</author>
</authors>
<title>Dragon Toolkit: Incorporating Auto-learned Semantic Knowledge into Large-Scale Text Retrieval and Mining.</title>
<date>2007</date>
<booktitle>In Proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence (ICTAI),</booktitle>
<pages>197--201</pages>
<contexts>
<context position="11530" citStr="Zhou et al, 2007" startWordPosition="1779" endWordPosition="1782">i-Class Classifier (Weighted-SVM) Post-Processing Final Classification Figure 1: The Architecture of the system 669 sification in the instance, and the other used for all other drug mentions. • All numbers were normalized by replacing them with the same string. • Stop words and punctuation were removed. We used different stop word lists for different systems that were submitted to the challenge. • Part of speech (POS) tags were obtained with the Stanford NLP tool (Toutanova et al, 2003). • Words were stemmed with the Porter Stemmer (Porter, 1980). • Words were lemmatized with the dragon tool (Zhou et al, 2007). • Synsets for words were obtained using WordNet (Fellbaum, 1998). 3.3 Features Since each sentence can have more than two drug mentions, we generated an instance of the sentence for each drug pair. We used different combinations of various features for the three different systems submitted to the challenge (Section 3.4.3). The following describes all the features separated into two categories: features per sentence and features per drug-pair instances. Features per sentence: These are sentence-level features that have the same values across all instances of a sentence. 1- Words: This is a bi</context>
</contexts>
<marker>Zhou, Zhang, Hu, 2007</marker>
<rawString>Zhou X., X. Zhang and X. Hu. 2007. Dragon Toolkit: Incorporating Auto-learned Semantic Knowledge into Large-Scale Text Retrieval and Mining. In Proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence (ICTAI), 197-201.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>