<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.940339">
VERBOCEAN: Mining the Web for Fine-Grained Semantic Verb Relations
</title>
<author confidence="0.995902">
Timothy Chklovski and Patrick Pantel
</author>
<affiliation confidence="0.997577">
Information Sciences Institute
University of Southern California
</affiliation>
<address confidence="0.795573">
4676 Admiralty Way
Marina del Rey, CA 90292
</address>
<email confidence="0.989722">
Itimc, pantel}@isi.edu
</email>
<sectionHeader confidence="0.992339" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993725571428571">
Broad-coverage repositories of semantic relations
between verbs could benefit many NLP tasks. We
present a semi-automatic method for extracting
fine-grained semantic relations between verbs. We
detect similarity, strength, antonymy, enablement,
and temporal happens-before relations between
pairs of strongly associated verbs using lexico-
syntactic patterns over the Web. On a set of 29,165
strongly associated verb pairs, our extraction algo-
rithm yielded 65.5% accuracy. Analysis of
error types shows that on the relation strength we
achieved 75% accuracy. We provide the
resource, called VERBOCEAN, for download at
http://semantics.isi.edu/ocean/.
</bodyText>
<sectionHeader confidence="0.998492" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951108695652">
Many NLP tasks, such as question answering,
summarization, and machine translation could
benefit from broad-coverage semantic resources
such as WordNet (Miller 1990) and EVCA (Eng-
lish Verb Classes and Alternations) (Levin 1993).
These extremely useful resources have very high
precision entries but have important limitations
when used in real-world NLP tasks due to their
limited coverage and prescriptive nature (i.e. they
do not include semantic relations that are plausible
but not guaranteed). For example, it may be valu-
able to know that if someone has bought an item,
they may sell it at a later time. WordNet does not
include the relation &amp;quot;X buys Y&amp;quot; happens-before &amp;quot;X
sells Y&amp;quot; since it is possible to sell something with-
out having bought it (e.g. having manufactured or
stolen it).
Verbs are the primary vehicle for describing
events and expressing relations between entities.
Hence, verb semantics could help in many natural
language processing (NLP) tasks that deal with
events or relations between entities. For tasks
which require canonicalization of natural language
statements or derivation of plausible inferences
from such statements, a particularly valuable re-
source is one which (i) relates verbs to one another
and (ii) provides broad coverage of the verbs in the
target language.
In this paper, we present an algorithm that semi-
automatically discovers fine-grained verb seman-
tics by querying the Web using simple lexico-
syntactic patterns. The verb relations we discover
are similarity, strength, antonymy, enablement, and
temporal relations. Identifying these relations over
29,165 verb pairs results in a broad-coverage re-
source we call VERBOCEAN. Our approach extends
previously formulated ones that use surface pat-
terns as indicators of semantic relations between
nouns (Hearst 1992; Etzioni 2003; Ravichandran
and Hovy 2002). We extend these approaches in
two ways: (i) our patterns indicate verb conjuga-
tion to increase their expressiveness and specificity
and (ii) we use a measure similar to mutual infor-
mation to account for both the frequency of the
verbs whose semantic relations are being discov-
ered as well as for the frequency of the pattern.
</bodyText>
<sectionHeader confidence="0.998743" genericHeader="introduction">
2 Relevant Work
</sectionHeader>
<bodyText confidence="0.999863">
In this section, we describe application domains
that can benefit from a resource of verb semantics.
We then introduce some existing resources and
describe previous attempts at mining semantics
from text.
</bodyText>
<subsectionHeader confidence="0.937647">
2.1 Applications
</subsectionHeader>
<bodyText confidence="0.999903421052632">
Question answering is often approached by can-
onicalizing the question text and the answer text
into logical forms. This approach is taken, inter
alia, by a top-performing system (Moldovan et al.
2002). In discussing future work on the system&apos;s
logical form matching component, Rus (2002 p.
143) points to incorporating entailment and causa-
tion verb relations to improve the matcher&apos;s per-
formance. In other work, Webber et al. (2002)
have argued that successful question answering
depends on lexical reasoning, and that lexical rea-
soning in turn requires fine-grained verb semantics
in addition to troponymy (is-a relations between
verbs) and antonymy.
In multi-document summarization, knowing verb
similarities is useful for sentence compression and
for determining sentences that have the same
meaning (Lin 1997). Knowing that a particular
action happens before another or is enabled by
</bodyText>
<figureCaption confidence="0.994657">
Figure 1. Fellbaum&apos;s (1998) entailment hierarchy.
</figureCaption>
<bodyText confidence="0.9999076">
another is also useful to determine the order of the
events (Barzilay et al. 2002). For example, to order
summary sentences properly, it may be useful to
know that selling something can be preceded by
either buying, manufacturing, or stealing it. Fur-
thermore, knowing that a particular verb has a
meaning stronger than another (e.g. rape vs. abuse
and renovate vs. upgrade) can help a system pick
the most general sentence.
In lexical selection of verbs in machine transla-
tion and in work on document classification, prac-
titioners have argued for approaches that depend
on wide-coverage resources indicating verb simi-
larity and membership of a verb in a certain class.
In work on translating verbs with many counter-
parts in the target language, Palmer and Wu (1995)
discuss inherent limitations of approaches which
do not examine a verb&apos;s class membership, and put
forth an approach based on verb similarity. In
document classification, Klavans and Kan (1998)
demonstrate that document type is correlated with
the presence of many verbs of a certain EVCA
class (Levin 1993). In discussing future work, Kla-
vans and Kan point to extending coverage of the
manually constructed EVCA resource as a way of
improving the performance of the system. A wide-
coverage repository of verb relations including
verbs linked by the similarity relation will provide
a way to automatically extend the existing verb
classes to cover more of the English lexicon.
</bodyText>
<subsectionHeader confidence="0.999658">
2.2 Existing resources
</subsectionHeader>
<bodyText confidence="0.999859761904762">
Some existing broad-coverage resources on
verbs have focused on organizing verbs into
classes or annotating their frames or thematic roles.
EVCA (English Verb Classes and Alternations)
(Levin 1993) organizes verbs by similarity and
participation / nonparticipation in alternation pat-
terns. It contains 3200 verbs classified into 191
classes. Additional manually constructed resources
include PropBank (Kingsbury et al. 2002), Frame-
Net (Baker et al. 1998), VerbNet (Kipper et al.
2000), and the resource on verb selectional restric-
tions developed by Gomez (2001).
Our approach differs from the above in its focus.
We relate verbs to each other rather than organize
them into classes or identify their frames or the-
matic roles. WordNet does provide relations be-
tween verbs, but at a coarser level. We provide
finer-grained relations such as strength, enable-
ment and temporal information. Also, in contrast
with WordNet, we cover more than the prescriptive
cases.
</bodyText>
<subsectionHeader confidence="0.99985">
2.3 Mining semantics from text
</subsectionHeader>
<bodyText confidence="0.999970071428571">
Previous web mining work has rarely addressed
extracting many different semantic relations from
Web-sized corpus. Most work on extracting se-
mantic information from large corpora has largely
focused on the extraction of is-a relations between
nouns. Hearst (1992) was the first followed by
recent larger-scale and more fully automated ef-
forts (Pantel and Ravichandran 2004; Etzioni et al.
2004; Ravichandran and Hovy 2002). Recently,
Moldovan et al. (2004) present a learning algo-
rithm to detect 35 fine-grained noun phrase rela-
tions.
Turney (2001) studied word relatedness and
synonym extraction, while Lin et al. (2003) present
an algorithm that queries the Web using lexical
patterns for distinguishing noun synonymy and
antonymy. Our approach addresses verbs and pro-
vides for a richer and finer-grained set of seman-
tics. Reliability of estimating bigram counts on the
web via search engines has been investigated by
Keller and Lapata (2003).
Semantic networks have also been extracted
from dictionaries and other machine-readable re-
sources. MindNet (Richardson et al. 1998) extracts
a collection of triples of the type &amp;quot;ducks have
wings&amp;quot; and &amp;quot;duck capable-of flying&amp;quot;. This re-
source, however, does not relate verbs to each
other or provide verb semantics.
</bodyText>
<sectionHeader confidence="0.979492" genericHeader="method">
3 Semantic relations among verbs
</sectionHeader>
<bodyText confidence="0.999976761904762">
In this section, we introduce and motivate the
specific relations that we extract. Whilst the natural
language literature is rich in theories of semantics
(Barwise and Perry 1985; Schank and Abelson
1977), large-coverage manually created semantic
resources typically only organize verbs into a flat
or shallow hierarchy of classes (such as those de-
scribed in Section 2.2). WordNet identifies synon-
ymy, antonymy, troponymy, and cause. As sum-
marized in Figure 1, Fellbaum (1998) discusses a
finer-grained analysis of entailment, while the
WordNet database does not distinguish between,
e.g., backward presupposition (forget :: know,
where know must have happened before forget)
from proper temporal inclusion (walk :: step). In
formulating our set of relations, we have relied on
the finer-grained analysis, explicitly breaking out
the temporal precedence between entities.
In selecting the relations to identify, we aimed at
both covering the relations described in WordNet
and covering the relations present in our collection
</bodyText>
<figure confidence="0.993910384615385">
Entailment
+Temporal Inclusion -Temporal Inclusion
+Troponymy
(coextensiveness)
march-walk
-Troponymy
(proper inclusion)
walk-step
Backward
Presupposition
forget-know
Cause
show-see
</figure>
<bodyText confidence="0.998102368421052">
of strongly associated verb pairs. We relied on the
strongly associated verb pairs, described in Section
4.4, for computational efficiency. The relations we
identify were experimentally found to cover 99 out
of 100 randomly selected verb pairs.
Our algorithm identifies six semantic relations
between verbs. These are summarized in Table 1
along with their closest corresponding WordNet
category and the symmetry of the relation (whether
VI rel V2 is equivalent to V2 rel VI).
Similarity. As Fellbaum (1998) and the tradition
of organizing verbs into similarity classes indicate,
verbs do not neatly fit into a unified is-a (tro-
ponymy) hierarchy. Rather, verbs are often similar
or related. Similarity between action verbs, for
example, can arise when they differ in connota-
tions about manner or degree of action. Examples
extracted by our system include maximize :: en-
hance, produce :: create, reduce :: restrict.
Strength. When two verbs are similar, one may
denote a more intense, thorough, comprehensive or
absolute action. In the case of change-of-state
verbs, one may denote a more complete change.
We identify this as the strength relation. Sample
verb pairs extracted by our system, in the order
weak to strong, are: taint :: poison, permit :: au-
thorize, surprise :: startle, startle :: shock. Some
instances of strength sometimes map to WordNet&apos;s
troponymy relation.
Strength, a subclass of similarity, has not been
identified in broad-coverage networks of verbs, but
may be of particular use in natural language gen-
eration and summarization applications.
Antonymy. Also known as semantic opposition,
antonymy between verbs has several distinct sub-
types. As discussed by Fellbaum (1998), it can
arise from switching thematic roles associated with
the verb (as in buy :: sell, lend :: borrow). There is
also antonymy between stative verbs (live :: die,
differ :: equal) and antonymy between sibling
verbs which share a parent (walk :: run) or an en-
tailed verb (fail :: succeed both entail try).
Antonymy also systematically interacts with the
happens-before relation in the case of restitutive
opposition (Cruse 1986). This subtype is exempli-
fied by damage :: repair, wrap :: unwrap. In terms
of the relations we recognize, it can be stated that
restitutive-opposition(V1, V2) = happens-
before(V1, V2), and antonym(V1, V2). Examples of
antonymy extracted by our system include: assem-
ble :: dismantle; ban :: allow; regard :: condemn,
roast :: fry.
Enablement. This relation holds between two
verbs V1 and V2 when the pair can be glossed as V1
is accomplished by V2. Enablement is classified as
a type of causal relation by Barker and Szpakowicz
(1995). Examples of enablement extracted by our
</bodyText>
<tableCaption confidence="0.980343666666667">
Table 1. Semantic relations identified in VERBOCEAN. Sib-
lings in the WordNet column refers to terms with the same
troponymic parent, e.g. swim and fly.
</tableCaption>
<figure confidence="0.779932153846154">
Alignment with
Symmetric
WordNet
similarity transform :: integrate synonyms or Y
siblings
synonyms or
strength wound :: kill N
siblings
antonymy open :: close antonymy Y
enablement fight :: win cause N
happens- buy :: sell; cause
before marry :: divorce entailment, no N
temporal inclusion
</figure>
<bodyText confidence="0.970157727272727">
system include: assess :: review and accomplish ::
complete.
Happens-before. This relation indicates that the
two verbs refer to two temporally disjoint intervals
or instances. WordNet&apos;s cause relation, between a
causative and a resultative verb (as in buy :: own),
would be tagged as instances of happens-before by
our system. Examples of the happens-before rela-
tion identified by our system include marry :: di-
vorce, detain :: prosecute, enroll :: graduate,
schedule :: reschedule, tie :: untie.
</bodyText>
<sectionHeader confidence="0.994875" genericHeader="method">
4 Approach
</sectionHeader>
<bodyText confidence="0.999957421052632">
We discover the semantic relations described
above by querying the Web with Google for
lexico-syntactic patterns indicative of each rela-
tion. Our approach has two stages. First, we iden-
tify pairs of highly associated verbs co-occurring
on the Web with sufficient frequency using previ-
ous work by Lin and Pantel (2001), as described in
Section 4.4. Next, for each verb pair, we tested
lexico-syntactic patterns, calculating a score for
each possible semantic relation as described in
Section 4.2. Finally, as described in Section 4.3,
we compare the strengths of the individual seman-
tic relations and, preferring the most specific and
then strongest relations, output a consistent set as
the final output. As a guide to consistency, we use
a simple theory of semantics indicating which se-
mantic relations are subtypes of other ones, and
which are compatible and which are mutually ex-
clusive.
</bodyText>
<subsectionHeader confidence="0.992366">
4.1 Lexico-syntactic patterns
</subsectionHeader>
<bodyText confidence="0.989679125">
The lexico-syntactic patterns were manually se-
lected by examining pairs of verbs in known se-
mantic relations. They were refined to decrease
capturing wrong parts of speech or incorrect se-
mantic relations. We used 50 verb pairs and the
overall process took about 25 hours.
We use a total of 35 patterns, which are listed in
Table 2 along with the estimated frequency of hits.
</bodyText>
<note confidence="0.319921">
SEMANTIC EXAMPLE
RELATION
</note>
<tableCaption confidence="0.9313756">
Table 2. Semantic relations and the 35 surface patterns used
to identify them. Total number of patterns for that relation is
shown in parentheses. In patterns, &amp;quot;*&amp;quot; matches any single
word. Punctuation does not count as words by the search
engine used (Google).
</tableCaption>
<figure confidence="0.827717545454545">
SEMANTIC Surface Hitsest for
RELATION Patterns patterns
narrow
similarity (2)* X ie Y 219,480
Xed ie Yed
broad
similarity (2)* Xed and Yed
to X and Y 154,518,326
X even Y
Xed even Yed
X and even Y
</figure>
<figureCaption confidence="0.619093">
strength (8) Xed and even Yed
</figureCaption>
<bodyText confidence="0.8872575">
Y or at least X 1,016,905
Yed or at least Xed
not only Xed but Yed
not just Xed but Yed
</bodyText>
<equation confidence="0.811422">
Sp(V, V2) _ P(p) x P(V) x P(V2 )
</equation>
<bodyText confidence="0.966841928571428">
The probabilities in the denominator are difficult
to calculate directly from search engine results. For
a given lexico-syntactic pattern, we need to esti-
mate the frequency of the pattern instantiated with
appropriately conjugated verbs. For verbs, we need
to estimate the frequency of the verbs, but avoid
counting other parts-of-speech (e.g. chair as a
noun or painted as an adjective). Another issue is
that some relations are symmetric (similarity and
antonymy), while others are not (strength, enable-
ment, happens-before). For symmetric relations
only, the verbs can fill the lexico-syntactic pattern
in either order. To address these issues, we esti-
mate Sp(V1,V2) using:
</bodyText>
<equation confidence="0.833881">
hits ( , , )
V p V
1 2
P V p V
( , , )
1 2
SP(Y,V2) hitseJp) x hits(&amp;quot;to V1&amp;quot;)x C x hits(&amp;quot;to V2&amp;quot;)x
N N N
for asymmetric relations and
N
C v
Xed * by Ying the
Xed * by Ying or
to X * by Ying the
to X * by Ying or
enablement (4)
2,348,392
either X or Y
either Xs or Ys
either Xed or Yed
antonymy (7) either Xing or Ying 18,040,916
whether to X or Y
Xed * but Yed
to X * but Y
</equation>
<figureCaption confidence="0.794531454545455">
to X and then Y
to X * and then Y
Xed and then Yed
Xed * and then Yed
happens-before
(12) to X and later Y
Xed and later Yed 8,288,871
to X and subsequently Y
Xed and subsequently Yed
to X and eventually Y
Xed and eventually Yed
</figureCaption>
<bodyText confidence="0.9817511">
*narrow- and broad- similarity overlap in their coverage
and are treated as a single category, similarity, when
postprocessed. Narrow similarity tests for rare patterns
and hitsest for it had to be approximated rather than
estimated from the smaller corpus.
Note that our patterns specify the tense of the verbs
they accept. When instantiating these patterns, we
conjugate as needed. For example, &amp;quot;both Xed and
Yed&amp;quot; instantiates on sing and dance as &amp;quot;both sung
and danced&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.963809">
4.2 Testing for a semantic relation
</subsectionHeader>
<bodyText confidence="0.999961571428571">
In this section, we describe how the presence of
a semantic relation is detected. We test the rela-
tions with patterns exemplified in Table 2. We
adopt an approach inspired by mutual information
to measure the strength of association, denoted
Sp(V1, V2), between three entities: a verb pair V1
and V2 and a lexico-syntactic pattern p:
</bodyText>
<equation confidence="0.989724333333333">
hits V p V
( , , )
2 1
� N N
P 2* (p) x hits(&amp;quot;to Y&amp;quot;) x Cv x hits(&amp;quot;to V2&amp;quot;) x C
st
hits
N N N
&gt; C1
</equation>
<bodyText confidence="0.822460714285714">
As a result of tuning the system on a tuning set of
50 verb pairs,
= 8.5.
Additional test for asymmetric relations. For
the asymmetric relations, we require not only that
exceed a certain threshold, but that
there be strong asymmetry
</bodyText>
<equation confidence="0.900281666666667">
Sp(V1,V2)
C1
(V1,V2)
</equation>
<bodyText confidence="0.979553">
of the relation:
for symmetric relations.
Here, hits(S) denotes the number of documents
containing the string S, as returned by Google. N is
the number of words indexed by the search engine
</bodyText>
<equation confidence="0.9175715">
(N
7.2 x 1011),
</equation>
<bodyText confidence="0.9637146">
is a correction factor to obtain
the frequency of the verb V in all tenses from the
frequency of the pattern &amp;quot;to V&amp;quot;. Based on several
verbs, we have estimated
= 8.5. Because pattern
counts, when instantiated with verbs, could not be
estimated directly, we have computed the frequen-
cies of the patterns in
tagged
word corpus and used it to estimate the ex-
pected number of hits
for each pattern.
We estimated the
a similar method.
We say that the semantic relation
</bodyText>
<figure confidence="0.855557785714286">
indicated by
lexico-syntactic pattern
≈
Cv
Cv
a part-of-speech
500M
hitsest(p)
N with
Sp
p is present between V1
and V2 if
SP
From the tuning set, C2 = 5.
</figure>
<subsectionHeader confidence="0.988209">
4.3 Pruning identified semantic relations
</subsectionHeader>
<bodyText confidence="0.8645625">
Given a pair of semantic relations from the set
we identify, one of three cases can arise: (i) one
</bodyText>
<equation confidence="0.980360692307692">
Sp(V1,V2) _ hits(V1,p,V2) &gt; C2
S V V h
( , ) its V p V
( , ,
p 2 1 2 1
)
hits (V 1 , ,
p V2
)
�
S V V
( , )
1 2
</equation>
<bodyText confidence="0.99985828125">
relation is more specific (strength is more specific
than similarity, enablement is more specific than
happens-before), (ii) the relations are compatible
(antonymy and happens-before), where presence of
one does not imply or rule out presence of the
other, and (iii) the relations are incompatible (simi-
larity and antonymy).
It is not uncommon for our algorithm to identify
presence of several relations, with different
strengths. To produce the most likely output, we
use semantics of compatibility of the relations to
output the most likely one(s). The rules are as
follows:
If the frequency was too low (less than 10 on the
pattern &amp;quot;X * Y&amp;quot; OR &amp;quot;Y * X&amp;quot; OR &amp;quot;X * * Y&amp;quot; OR &amp;quot;Y
* * X&amp;quot;), output that the statements are unrelated
and stop.
If happens-before is detected, output presence of
happens-before (additional relation may still be
output, if detected).
If happens-before is not detected, ignore detec-
tion of enablement (because enablement is more
specific than happens-before, but is sometimes
falsely detected in the absence of happens-before).
If strength is detected, score of similarity is ig-
nored (because strength is more specific than simi-
larity).
Of the relations strength, similarity, opposition
and enablement which were detected (and not ig-
nored), output the one with highest Sp.
If nothing has been output to this point, output
unrelated.
</bodyText>
<subsectionHeader confidence="0.997953">
4.4 Extracting highly associated verb pairs
</subsectionHeader>
<bodyText confidence="0.998978575757576">
To exhaustively test the more than 64 million
unordered verb pairs for WordNet&apos;s more than
11,000 verbs would be computationally intractable.
Instead, we use a set of highly associated verb
pairs output by a paraphrasing algorithm called
DIRT (Lin and Pantel 2001). Since we are able to
test up to 4000 verb pairs per day on a single ma-
chine (we issue at most 40 queries per test and
each query takes approximately 0.5 seconds), we
are able to test several dozen associated verbs for
each verb in WordNet in a matter of weeks.
Lin and Pantel (2001) describe an algorithm
called DIRT (Discovery of Inference Rules from
Text) that automatically learns paraphrase expres-
sions from text. It is a generalization of previous
algorithms that use the distributional hypothesis
(Harris 1985) for finding similar words. Instead of
applying the hypothesis to words, Lin and Pantel
applied it to paths in dependency trees. Essen-
tially, if two paths tend to link the same sets of
words, they hypothesized that the meanings of the
corresponding paths are similar. It is from paths of
the form subject-verb-object that we extract our set
of associated verb pairs. Hence, this paper is con-
cerned only with relations between transitive
verbs.
A path, extracted from a parse tree, is an expres-
sion that represents a binary relation between two
nouns. A set of paraphrases was generated for each
pair of associated paths. For example, using a
1.5GB newspaper corpus, here are the 20 most
associated paths to &amp;quot;X solves Y&amp;quot; generated by
DIRT:
</bodyText>
<construct confidence="0.544301909090909">
Y is solved by X, X resolves Y, X finds
a solution to Y, X tries to solve Y, X
deals with Y, Y is resolved by X, X ad-
dresses Y, X seeks a solution to Y, X
does something about Y, X solution to
Y, Y is resolved in X, Y is solved
through X, X rectifies Y, X copes with
Y, X overcomes Y, X eases Y, X tackles
Y, X alleviates Y, X corrects Y, X is a
solution to Y, X makes Y worse, X irons
out Y
</construct>
<bodyText confidence="0.999578166666667">
This list of associated paths looks tantalizingly
close to the kind of axioms that would prove useful
in an inference system. However, DIRT only out-
puts pairs of paths that have some semantic rela-
tion. We used these as our set to extract finer-
grained relations.
</bodyText>
<sectionHeader confidence="0.996636" genericHeader="method">
5 Experimental results
</sectionHeader>
<bodyText confidence="0.9991965">
In this section, we empirically evaluate the accu-
racy of VERBOCEAN1.
</bodyText>
<subsectionHeader confidence="0.989358">
5.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999234111111111">
We studied 29,165 pairs of verbs. Applying
DIRT to a 1.5GB newspaper corpus2, we extracted
4000 paths that consisted of single verbs in the
relation subject-verb-object (i.e. paths of the form
&amp;quot;X verb Y&amp;quot;) whose verbs occurred in at least 150
documents on the Web. For example, from the 20
most associated paths to &amp;quot;X solves Y&amp;quot; shown in
Section 4.4, the following verb pairs were ex-
tracted:
</bodyText>
<figureCaption confidence="0.994146">
solves :: resolves
solves :: addresses
solves :: rectifies
solves :: overcomes
solves :: eases
solves :: tackles
solves :: corrects
</figureCaption>
<subsectionHeader confidence="0.998674">
5.2 Accuracy
</subsectionHeader>
<bodyText confidence="0.99594825">
We classified each verb pair according to the
semantic relations described in Section 2. If the
system does not identify any semantic relation for
a verb pair, then the system tags the pair as having
</bodyText>
<footnote confidence="0.9883114">
1 VERBOCEAN is available for download at
http://semantics.isi.edu/ocean/.
2 The 1.5GB corpus consists of San Jose Mercury,
Wall Street Journal and AP Newswire articles from the
TREC-9 collection.
</footnote>
<tableCaption confidence="0.989477">
Table 3. Five randomly selected pairs along with the system tag (in bold) and the judges&apos; responses.
</tableCaption>
<table confidence="0.37823985">
PAIRS WITH SYSTEM TAG (IN BOLD) CORRECT PREFERRED SEMANTIC RELATION
JUDGE 1 JUDGE 2 JUDGE 1 JUDGE 2
happens-before/ is stronger
than
Yes Yes
Yes Yes
Yes Yes
Yes No
No No
is similar to is similar to
has no relation with has no relation with
happens-before / is
stronger than
has no relation with can result in
has no relation with has no relation with
X absolve Y is similar to X vindicate Y
X bottom Y has no relation with X abate Y
X outrage Y happens-after / is stronger than X shock Y
X pool Y has no relation with X increase Y
X insure Y is similar to X expedite Y
</table>
<tableCaption confidence="0.996533">
Table 4. Accuracy of system-discovered relations.
</tableCaption>
<table confidence="0.9990175">
Tags ACCURACY Baseline
Correct Preferred Tags Correct
Correct
Judge 1 66% 54% 24%
Judge 2 65% 52% 20%
Average 65.5% 53% 22%
</table>
<bodyText confidence="0.999947361111111">
no relation. To evaluate the accuracy of the sys-
tem, we randomly sampled 100 of these verb pairs,
and presented the classifications to two human
judges. The adjudicators were asked to judge
whether or not the system classification was ac-
ceptable (i.e. whether or not the relations output by
the system were correct). Since the semantic rela-
tions are not disjoint (e.g. mop is both stronger
than and similar to sweep), multiple relations may
be appropriately acceptable for a given verb pair.
The judges were also asked to identify their pre-
ferred semantic relations (i.e. those relations which
seem most plausible). Table 3 shows five randomly
selected pairs along with the judges&apos; responses.
The Appendix shows sample relationships discov-
ered by the system.
Table 4 shows the accuracy of the system. The
baseline system consists of labeling each pair with
the most common semantic relation, similarity,
which occurs 33 times. The Tags Correct column
represents the percentage of verb pairs whose sys-
tem output relations were deemed correct. The
Preferred Tags Correct column gives the percent-
age of verb pairs whose system output relations
matched exactly the human&apos;s preferred relations.
The Kappa statistic (Siegel and Castellan 1988) for
the task of judging system tags as correct and in-
correct is κ = 0.78 whereas the task of identifying
the preferred semantic relation has κ = 0.72. For
the latter task, the two judges agreed on 73 of the
100 semantic relations. 73% gives an idea of an
upper bound for humans on this task. On these 73
relations, the system achieved a higher accuracy of
70.0%. The system is allowed to output the hap-
pens-before relation in combination with other
relations. On the 17 happens-before relations out-
</bodyText>
<tableCaption confidence="0.999248">
Table 5. Accuracy of each semantic relation.
</tableCaption>
<table confidence="0.999222">
SEMANTIC SYSTEM Tags Preferred Tags
RELATION TAGS Correct Correct
similarity 41 63.4% 40.2%
strength 14 75.0% 75.0%
antonymy 8 50.0% 43.8%
enablement 2 100% 100%
no relation 35 72.9% 72.9%
happens before 17 67.6% 55.9%
</table>
<bodyText confidence="0.9995688">
put by the system, 67.6% were judged correct.
Ignoring the happens-before relations, we achieved
a Tags Correct precision of 68%.
Table 5 shows the accuracy of the system on
each of the relations. The stronger-than relation is
a subset of the similarity relation. Considering a
coarser extraction where stronger-than relations
are merged with similarity, the task of judging
system tags and the task of identifying the pre-
ferred semantic relation both jump to 68.2% accu-
racy. Also, the overall accuracy of the system
climbs to 68.5%.
As described in Section 2, WordNet contains
verb semantic relations. A significant percentage
of our discovered relations are not covered by
WordNet&apos;s coarser classifications. Of the 40 verb
pairs whose system relation was tagged as correct
by both judges in our accuracy experiments and
whose tag was not `no relation&apos;, only 22.5% of
them existed in a WordNet relation.
</bodyText>
<subsectionHeader confidence="0.856095">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999981428571428">
The experience of extracting these semantic rela-
tions has clarified certain important challenges.
While relying on a search engine allows us to
query a corpus of nearly a trillion words, some
issues arise: (i) the number of instances has to be
approximated by the number of hits (documents);
(ii) the number of hits for the same query may
fluctuate over time; and (iii) some needed counts
are not directly available. We addressed the latter
issue by approximating these counts using a
smaller corpus.
We do not detect entailment with lexico-
syntactic patterns. In fact, we propose that whether
the entailment relation holds between V1 and V2
depends on the absence of another verb V1&apos; in the
same relationship with V2. For example, given the
relation marry happens-before divorce, we can
conclude that divorce entails marry. But, given the
relation buy happens-before sell, we cannot con-
clude entailment since manufacture can also hap-
pen before sell. This also applies to the enablement
and strength relations.
Corpus-based methods, including ours, hold the
promise of wide coverage but are weak on dis-
criminating senses. While we hope that applica-
tions will benefit from this resource as is, an inter-
esting next step would be to augment it with sense
information.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="method">
6 Future work
</sectionHeader>
<bodyText confidence="0.999981085714286">
There are several ways to improve the accuracy
of the current algorithm and to detect relations
between low frequency verb pairs. One avenue
would be to automatically learn or manually craft
more patterns and to extend the pattern vocabulary
(when developing the system, we have noticed that
different registers and verb types require different
patterns). Another possibility would be to use
more relaxed patterns when the part of speech
confusion is not likely (e.g. &amp;quot;eat&amp;quot; is a common
verb which does not have a noun sense, and pat-
terns need not protect against noun senses when
testing such verbs).
Our approach can potentially be extended to
multiword paths. DIRT actually provides two
orders of magnitude more relations than the 29,165
single verb relations (subject-verb-object) we ex-
tracted. On the same 1GB corpus described in Sec-
tion 5.1, DIRT extracted over 200K paths and 6M
unique paraphrases. These provide an opportunity
to create a much larger corpus of semantic rela-
tions, or to construct smaller, in-depth resources
for selected subdomains. For example, we could
extract that take a trip to is similar to travel to, and
that board a plane happens before deplane.
If the entire database is viewed as a graph, we
currently leverage and enforce only local consis-
tency. It would be useful to enforce global consis-
tency, e.g. V1 stronger-than V2, and V2 stronger-
than V3 indicates that V1 stronger-than V3, which
may be leveraged to identify additional relations or
inconsistent relations (e.g. V3 stronger-than V1).
Finally, as discussed in Section 5.3, entailment
relations may be derivable by processing the com-
plete graph of the identified semantic relation.
</bodyText>
<sectionHeader confidence="0.998831" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999981777777778">
We have demonstrated that certain fine-grained
semantic relations between verbs are present on the
Web, and are extractable with a simple pattern-
based approach. In addition to discovering rela-
tions identified in WordNet, such as opposition and
enablement, we obtain strong results on strength
relations (for which no wide-coverage resource is
available). On a set of 29,165 associated verb
pairs, experimental results show an accuracy of
65.5% in assigning similarity, strength, antonymy,
enablement, and happens-before.
Further work may refine extraction methods and
further process the mined semantics to derive other
relations such as entailment.
We hope to open the way to inferring implied,
but not stated assertions and to benefit applications
such as question answering, information retrieval,
and summarization.
</bodyText>
<sectionHeader confidence="0.998369" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999978">
The authors wish to thank the reviewers for their
helpful comments and Google Inc. for supporting
high volume querying of their index. This research
was partly supported by NSF grant #EIA-0205111.
</bodyText>
<sectionHeader confidence="0.998441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.945266933333333">
Baker, C.; Fillmore, C.; and Lowe, J. 1998. The
Berkeley FrameNet project. In Proceedings of
COLING-ACL. Montreal, Canada.
Barker, K.; and Szpakowicz, S. 1995. Interactive
Semantic Analysis of Clause-Level
Relationships. In Proceedings of PACLING `95.
Brisbane.
Barwise, J. and Perry, J. 1985. Semantic innocence
and uncompromising situations. In: Martinich,
A. P. (ed.) The Philosophy of Language. New
York: Oxford University Press. pp. 401413.
Barzilay, R.; Elhadad, N.; and McKeown, K. 2002.
Inferring strategies for sentence ordering in
multidocument summarization. JAIR, 17:3555.
Cruse, D. 1992 Antonymy Revisited: Some
Thoughts on the Relationship between Words
and Concepts, in A. Lehrer and E.V. Kittay
(eds.), Frames, Fields, and Contrasts, Hillsdale,
NJ, Lawrence Erlbaum associates, pp. 289-306.
Etzioni, O.; Cafarella, M.; Downey, D.; Kok, S.;
Popescu, A.; Shaked, T.; Soderland, S.; Weld,
D.; and Yates, A. 2004. Web-scale information
extraction in KnowItAll. To appear in WWW-
2004.
Appendix. Sample relations extracted by our system.
SEMANTIC EXAMPLES
RELATION
maximize :: enhance
similarity produce :: create
reduce :: restrict
permit :: authorize
strength surprise :: startle
startle :: shock
SEMANTIC EXAMPLES
RELATION
assess :: review
enablement accomplish :: complete
double-click :: click
assemble :: dismantle
antonymy regard :: condemn
roast :: fry
SEMANTIC EXAMPLES
detain :: prosecute
enroll :: graduate
schedule :: reschedule
</reference>
<figure confidence="0.929422666666667">
RELATION
happens
before
</figure>
<reference confidence="0.999637095238095">
Fellbaum, C. 1998. Semantic network of English
verbs. In Fellbaum, (ed). WordNet: An
Electronic Lexical Database, MIT Press.
Gomez, F. 2001. An Algorithm for Aspects of
Semantic Interpretation Using an Enhanced
WordNet. In NAACL-2001, CMU, Pittsburgh.
Harris, Z. 1985. Distributional Structure. In: Katz,
J. J. (ed.), The Philosophy of Linguistics. New
York: Oxford University Press. pp. 2647.
Hearst, M. 1992. Automatic acquisition of
hyponyms from large text corpora. In COLING-
92. pp. 539545. Nantes, France.
Keller, F.and Lapata, M. 2003. Using the Web to
Obtain Frequencies for Unseen Bigrams.
Computational Linguistics 29:3.
Kingsbury, P; Palmer, M.; and Marcus, M. 2002.
Adding semantic annotation to the Penn
TreeBank. In Proceedings of HLT-2002. San
Diego, California.
Kipper, K.; Dang, H.; and Palmer, M. 2000. Class-
based construction of a verb lexicon. In Pro-
ceedings of AAAI-2000. Austin, TX.
Klavans, J. and Kan, M. 1998. Document classi-
fication: Role of verb in document analysis. In
Proceedings COLING-ACL &apos;98. Montreal,
Canada.
Levin, B. 1993. English Verb Classes and
Alternations: A Preliminary Investigation.
University of Chicago Press, Chicago, IL.
Lin, C-Y. 1997. Robust Automated Topic
Identification. Ph.D. Thesis. University of
Southern California.
Lin, D. and Pantel, P. 2001. Discovery of inference
rules for question answering. Natural Language
Engineering, 7(4):343-360.
Lin, D.; Zhao, S.; Qin, L.; and Zhou, M. 2003.
Identifying synonyms among distributionally
similar words. In Proceedings of IJCAI-03.
pp.1492-1493. Acapulco, Mexico.
Miller, G. 1990. WordNet: An online lexical
database. International Journal of Lexicography,
3(4).
Moldovan, D.; Badulescu, A.; Tatu, M.; Antohe,
D.; and Girju, R. 2004. Models for the semantic
classification of noun phrases. To appear in
Proceedings of HLT/NAACL-2004 Workshop on
Computational Lexical Semantics.
Moldovan, D.; Harabagiu, S.; Girju, R.;
Morarescu, P.; Lacatusu, F.; Novischi, A.;
Badulescu, A.; and Bolohan, O. 2002. LCC tools
for question answering. In Notebook of the
Eleventh Text REtrieval Conference (TREC-
2002). pp. 144154.
Palmer, M., Wu, Z. 1995. Verb Semantics for
English-Chinese Translation Machine
Translation, 9(4).
Pantel, P. and Ravichandran, D. 2004.
Automatically labeling semantic classes. To
appear in Proceedings of HLT/NAACL-2004.
Boston, MA.
Ravichandran, D. and Hovy, E., 2002. Learning
surface text patterns for a question answering
system. In Proceedings of ACL-02.
Philadelphia, PA.
Richardson, S.; Dolan, W.; and Vanderwende, L.
1998. MindNet: acquiring and structuring
semantic information from text. In Proceedings
of COLING &apos;98.
Rus, V. 2002. Logic Forms for WordNet Glosses.
Ph.D. Thesis. Southern Methodist University.
Schank, R. and Abelson, R. 1977. Scripts, Plans,
Goals and Understanding: An Inquiry into
Human Knowledge Structures. Lawrence
Erlbaum Associates.
Siegel, S. and Castellan Jr., N. 1988.
Nonparametric Statistics for the Behavioral
Sciences. McGraw-Hill.
Turney, P. 2001. Mining the Web for synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings
ECML-2001. Freiburg, Germany.
Webber, B.; Gardent, C.; and Bos, J. 2002.
Position statement: Inference in question
answering. In Proceedings of LREC-2002. Las
Palmas, Spain.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.264030">
<title confidence="0.999737">Mining the Web for Fine-Grained Semantic Verb Relations</title>
<author confidence="0.948619">Chklovski</author>
<affiliation confidence="0.9985855">Information Sciences University of Southern</affiliation>
<address confidence="0.986616">4676 Admiralty</address>
<author confidence="0.635515">Marina del Rey</author>
<author confidence="0.635515">CA</author>
<email confidence="0.986192">Itimc,pantel}@isi.edu</email>
<abstract confidence="0.954676071428571">Broad-coverage repositories of semantic relations between verbs could benefit many NLP tasks. We present a semi-automatic method for extracting fine-grained semantic relations between verbs. We detect similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web. On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy. Analysis of types shows that on the relation achieved 75% accuracy. We provide the called for download at</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>C Fillmore</author>
<author>J Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL.</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="6180" citStr="Baker et al. 1998" startWordPosition="933" endWordPosition="936">linked by the similarity relation will provide a way to automatically extend the existing verb classes to cover more of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles. EVCA (English Verb Classes and Alternations) (Levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns. It contains 3200 verbs classified into 191 classes. Additional manually constructed resources include PropBank (Kingsbury et al. 2002), FrameNet (Baker et al. 1998), VerbNet (Kipper et al. 2000), and the resource on verb selectional restrictions developed by Gomez (2001). Our approach differs from the above in its focus. We relate verbs to each other rather than organize them into classes or identify their frames or thematic roles. WordNet does provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Baker, C.; Fillmore, C.; and Lowe, J. 1998. The Berkeley FrameNet project. In Proceedings of COLING-ACL. Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Barker</author>
<author>S Szpakowicz</author>
</authors>
<title>Interactive Semantic Analysis of Clause-Level Relationships.</title>
<date>1995</date>
<booktitle>In Proceedings of PACLING `95.</booktitle>
<location>Brisbane.</location>
<contexts>
<context position="11875" citStr="Barker and Szpakowicz (1995)" startWordPosition="1812" endWordPosition="1815">y interacts with the happens-before relation in the case of restitutive opposition (Cruse 1986). This subtype is exemplified by damage :: repair, wrap :: unwrap. In terms of the relations we recognize, it can be stated that restitutive-opposition(V1, V2) = happensbefore(V1, V2), and antonym(V1, V2). Examples of antonymy extracted by our system include: assemble :: dismantle; ban :: allow; regard :: condemn, roast :: fry. Enablement. This relation holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2. Enablement is classified as a type of causal relation by Barker and Szpakowicz (1995). Examples of enablement extracted by our Table 1. Semantic relations identified in VERBOCEAN. Siblings in the WordNet column refers to terms with the same troponymic parent, e.g. swim and fly. Alignment with Symmetric WordNet similarity transform :: integrate synonyms or Y siblings synonyms or strength wound :: kill N siblings antonymy open :: close antonymy Y enablement fight :: win cause N happens- buy :: sell; cause before marry :: divorce entailment, no N temporal inclusion system include: assess :: review and accomplish :: complete. Happens-before. This relation indicates that the two ve</context>
</contexts>
<marker>Barker, Szpakowicz, 1995</marker>
<rawString>Barker, K.; and Szpakowicz, S. 1995. Interactive Semantic Analysis of Clause-Level Relationships. In Proceedings of PACLING `95. Brisbane.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Barwise</author>
<author>J Perry</author>
</authors>
<title>Semantic innocence and uncompromising situations.</title>
<date>1985</date>
<booktitle>The Philosophy of Language.</booktitle>
<pages>401--413</pages>
<editor>In: Martinich, A. P. (ed.)</editor>
<publisher>University Press.</publisher>
<location>New York: Oxford</location>
<contexts>
<context position="8187" citStr="Barwise and Perry 1985" startWordPosition="1246" endWordPosition="1249">ng bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Richardson et al. 1998) extracts a collection of triples of the type &amp;quot;ducks have wings&amp;quot; and &amp;quot;duck capable-of flying&amp;quot;. This resource, however, does not relate verbs to each other or provide verb semantics. 3 Semantic relations among verbs In this section, we introduce and motivate the specific relations that we extract. Whilst the natural language literature is rich in theories of semantics (Barwise and Perry 1985; Schank and Abelson 1977), large-coverage manually created semantic resources typically only organize verbs into a flat or shallow hierarchy of classes (such as those described in Section 2.2). WordNet identifies synonymy, antonymy, troponymy, and cause. As summarized in Figure 1, Fellbaum (1998) discusses a finer-grained analysis of entailment, while the WordNet database does not distinguish between, e.g., backward presupposition (forget :: know, where know must have happened before forget) from proper temporal inclusion (walk :: step). In formulating our set of relations, we have relied on </context>
</contexts>
<marker>Barwise, Perry, 1985</marker>
<rawString>Barwise, J. and Perry, J. 1985. Semantic innocence and uncompromising situations. In: Martinich, A. P. (ed.) The Philosophy of Language. New York: Oxford University Press. pp. 401413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>N Elhadad</author>
<author>K McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument summarization.</title>
<date>2002</date>
<journal>JAIR,</journal>
<pages>17--35</pages>
<contexts>
<context position="4343" citStr="Barzilay et al. 2002" startWordPosition="646" endWordPosition="649"> other work, Webber et al. (2002) have argued that successful question answering depends on lexical reasoning, and that lexical reasoning in turn requires fine-grained verb semantics in addition to troponymy (is-a relations between verbs) and antonymy. In multi-document summarization, knowing verb similarities is useful for sentence compression and for determining sentences that have the same meaning (Lin 1997). Knowing that a particular action happens before another or is enabled by Figure 1. Fellbaum&apos;s (1998) entailment hierarchy. another is also useful to determine the order of the events (Barzilay et al. 2002). For example, to order summary sentences properly, it may be useful to know that selling something can be preceded by either buying, manufacturing, or stealing it. Furthermore, knowing that a particular verb has a meaning stronger than another (e.g. rape vs. abuse and renovate vs. upgrade) can help a system pick the most general sentence. In lexical selection of verbs in machine translation and in work on document classification, practitioners have argued for approaches that depend on wide-coverage resources indicating verb similarity and membership of a verb in a certain class. In work on tr</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Barzilay, R.; Elhadad, N.; and McKeown, K. 2002. Inferring strategies for sentence ordering in multidocument summarization. JAIR, 17:3555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>Antonymy Revisited: Some Thoughts on the Relationship between Words and Concepts,</title>
<date>1992</date>
<pages>289--306</pages>
<editor>in A. Lehrer and E.V. Kittay (eds.), Frames, Fields, and Contrasts, Hillsdale, NJ, Lawrence Erlbaum associates,</editor>
<marker>Cruse, 1992</marker>
<rawString>Cruse, D. 1992 Antonymy Revisited: Some Thoughts on the Relationship between Words and Concepts, in A. Lehrer and E.V. Kittay (eds.), Frames, Fields, and Contrasts, Hillsdale, NJ, Lawrence Erlbaum associates, pp. 289-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>D Downey</author>
<author>S Kok</author>
<author>A Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D Weld</author>
<author>A Yates</author>
</authors>
<title>Web-scale information extraction in KnowItAll.</title>
<date>2004</date>
<note>To appear in WWW2004.</note>
<contexts>
<context position="7110" citStr="Etzioni et al. 2004" startWordPosition="1079" endWordPosition="1082">verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Kok, Popescu, Shaked, Soderland, Weld, Yates, 2004</marker>
<rawString>Etzioni, O.; Cafarella, M.; Downey, D.; Kok, S.; Popescu, A.; Shaked, T.; Soderland, S.; Weld, D.; and Yates, A. 2004. Web-scale information extraction in KnowItAll. To appear in WWW2004.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Appendix</author>
</authors>
<title>Sample relations extracted by our system.</title>
<journal>SEMANTIC EXAMPLES RELATION</journal>
<marker>Appendix, </marker>
<rawString>Appendix. Sample relations extracted by our system. SEMANTIC EXAMPLES RELATION</rawString>
</citation>
<citation valid="false">
<authors>
<author>maximize</author>
</authors>
<title>enhance similarity produce :: create reduce :: restrict permit :: authorize strength surprise :: startle startle :: shock SEMANTIC EXAMPLES RELATION assess :: review enablement accomplish :: complete double-click :: click assemble :: dismantle antonymy regard :: condemn roast :: fry SEMANTIC EXAMPLES detain :: prosecute enroll :: graduate schedule :: reschedule</title>
<marker>maximize, </marker>
<rawString>maximize :: enhance similarity produce :: create reduce :: restrict permit :: authorize strength surprise :: startle startle :: shock SEMANTIC EXAMPLES RELATION assess :: review enablement accomplish :: complete double-click :: click assemble :: dismantle antonymy regard :: condemn roast :: fry SEMANTIC EXAMPLES detain :: prosecute enroll :: graduate schedule :: reschedule</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>Semantic network of English verbs.</title>
<date>1998</date>
<booktitle>In Fellbaum, (ed). WordNet: An Electronic Lexical Database,</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8485" citStr="Fellbaum (1998)" startWordPosition="1293" endWordPosition="1294">apable-of flying&amp;quot;. This resource, however, does not relate verbs to each other or provide verb semantics. 3 Semantic relations among verbs In this section, we introduce and motivate the specific relations that we extract. Whilst the natural language literature is rich in theories of semantics (Barwise and Perry 1985; Schank and Abelson 1977), large-coverage manually created semantic resources typically only organize verbs into a flat or shallow hierarchy of classes (such as those described in Section 2.2). WordNet identifies synonymy, antonymy, troponymy, and cause. As summarized in Figure 1, Fellbaum (1998) discusses a finer-grained analysis of entailment, while the WordNet database does not distinguish between, e.g., backward presupposition (forget :: know, where know must have happened before forget) from proper temporal inclusion (walk :: step). In formulating our set of relations, we have relied on the finer-grained analysis, explicitly breaking out the temporal precedence between entities. In selecting the relations to identify, we aimed at both covering the relations described in WordNet and covering the relations present in our collection Entailment +Temporal Inclusion -Temporal Inclusion</context>
<context position="9724" citStr="Fellbaum (1998)" startWordPosition="1467" endWordPosition="1468">ness) march-walk -Troponymy (proper inclusion) walk-step Backward Presupposition forget-know Cause show-see of strongly associated verb pairs. We relied on the strongly associated verb pairs, described in Section 4.4, for computational efficiency. The relations we identify were experimentally found to cover 99 out of 100 randomly selected verb pairs. Our algorithm identifies six semantic relations between verbs. These are summarized in Table 1 along with their closest corresponding WordNet category and the symmetry of the relation (whether VI rel V2 is equivalent to V2 rel VI). Similarity. As Fellbaum (1998) and the tradition of organizing verbs into similarity classes indicate, verbs do not neatly fit into a unified is-a (troponymy) hierarchy. Rather, verbs are often similar or related. Similarity between action verbs, for example, can arise when they differ in connotations about manner or degree of action. Examples extracted by our system include maximize :: enhance, produce :: create, reduce :: restrict. Strength. When two verbs are similar, one may denote a more intense, thorough, comprehensive or absolute action. In the case of change-of-state verbs, one may denote a more complete change. We</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. 1998. Semantic network of English verbs. In Fellbaum, (ed). WordNet: An Electronic Lexical Database, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Gomez</author>
</authors>
<title>An Algorithm for Aspects of Semantic Interpretation Using an Enhanced WordNet.</title>
<date>2001</date>
<booktitle>In NAACL-2001, CMU,</booktitle>
<location>Pittsburgh.</location>
<contexts>
<context position="6287" citStr="Gomez (2001)" startWordPosition="952" endWordPosition="953">ore of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles. EVCA (English Verb Classes and Alternations) (Levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns. It contains 3200 verbs classified into 191 classes. Additional manually constructed resources include PropBank (Kingsbury et al. 2002), FrameNet (Baker et al. 1998), VerbNet (Kipper et al. 2000), and the resource on verb selectional restrictions developed by Gomez (2001). Our approach differs from the above in its focus. We relate verbs to each other rather than organize them into classes or identify their frames or thematic roles. WordNet does provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large</context>
</contexts>
<marker>Gomez, 2001</marker>
<rawString>Gomez, F. 2001. An Algorithm for Aspects of Semantic Interpretation Using an Enhanced WordNet. In NAACL-2001, CMU, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>Distributional Structure. In:</title>
<date>1985</date>
<booktitle>The Philosophy of Linguistics.</booktitle>
<pages>26--47</pages>
<editor>Katz, J. J. (ed.),</editor>
<publisher>University Press.</publisher>
<location>New York: Oxford</location>
<contexts>
<context position="20528" citStr="Harris 1985" startWordPosition="3334" endWordPosition="3335">hly associated verb pairs output by a paraphrasing algorithm called DIRT (Lin and Pantel 2001). Since we are able to test up to 4000 verb pairs per day on a single machine (we issue at most 40 queries per test and each query takes approximately 0.5 seconds), we are able to test several dozen associated verbs for each verb in WordNet in a matter of weeks. Lin and Pantel (2001) describe an algorithm called DIRT (Discovery of Inference Rules from Text) that automatically learns paraphrase expressions from text. It is a generalization of previous algorithms that use the distributional hypothesis (Harris 1985) for finding similar words. Instead of applying the hypothesis to words, Lin and Pantel applied it to paths in dependency trees. Essentially, if two paths tend to link the same sets of words, they hypothesized that the meanings of the corresponding paths are similar. It is from paths of the form subject-verb-object that we extract our set of associated verb pairs. Hence, this paper is concerned only with relations between transitive verbs. A path, extracted from a parse tree, is an expression that represents a binary relation between two nouns. A set of paraphrases was generated for each pair </context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Harris, Z. 1985. Distributional Structure. In: Katz, J. J. (ed.), The Philosophy of Linguistics. New York: Oxford University Press. pp. 2647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In COLING92.</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="2714" citStr="Hearst 1992" startWordPosition="395" endWordPosition="396">ch (i) relates verbs to one another and (ii) provides broad coverage of the verbs in the target language. In this paper, we present an algorithm that semiautomatically discovers fine-grained verb semantics by querying the Web using simple lexicosyntactic patterns. The verb relations we discover are similarity, strength, antonymy, enablement, and temporal relations. Identifying these relations over 29,165 verb pairs results in a broad-coverage resource we call VERBOCEAN. Our approach extends previously formulated ones that use surface patterns as indicators of semantic relations between nouns (Hearst 1992; Etzioni 2003; Ravichandran and Hovy 2002). We extend these approaches in two ways: (i) our patterns indicate verb conjugation to increase their expressiveness and specificity and (ii) we use a measure similar to mutual information to account for both the frequency of the verbs whose semantic relations are being discovered as well as for the frequency of the pattern. 2 Relevant Work In this section, we describe application domains that can benefit from a resource of verb semantics. We then introduce some existing resources and describe previous attempts at mining semantics from text. 2.1 Appl</context>
<context position="6980" citStr="Hearst (1992)" startWordPosition="1060" endWordPosition="1061">r rather than organize them into classes or identify their frames or thematic roles. WordNet does provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram count</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M. 1992. Automatic acquisition of hyponyms from large text corpora. In COLING92. pp. 539545. Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F and Lapata Keller</author>
<author>M</author>
</authors>
<title>Using the Web to Obtain Frequencies for Unseen Bigrams.</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<marker>Keller, M, 2003</marker>
<rawString>Keller, F.and Lapata, M. 2003. Using the Web to Obtain Frequencies for Unseen Bigrams. Computational Linguistics 29:3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
<author>M Marcus</author>
</authors>
<title>Adding semantic annotation to the Penn TreeBank.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT-2002.</booktitle>
<location>San Diego, California.</location>
<contexts>
<context position="6150" citStr="Kingsbury et al. 2002" startWordPosition="927" endWordPosition="930">of verb relations including verbs linked by the similarity relation will provide a way to automatically extend the existing verb classes to cover more of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles. EVCA (English Verb Classes and Alternations) (Levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns. It contains 3200 verbs classified into 191 classes. Additional manually constructed resources include PropBank (Kingsbury et al. 2002), FrameNet (Baker et al. 1998), VerbNet (Kipper et al. 2000), and the resource on verb selectional restrictions developed by Gomez (2001). Our approach differs from the above in its focus. We relate verbs to each other rather than organize them into classes or identify their frames or thematic roles. WordNet does provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rar</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>Kingsbury, P; Palmer, M.; and Marcus, M. 2002. Adding semantic annotation to the Penn TreeBank. In Proceedings of HLT-2002. San Diego, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kipper</author>
<author>H Dang</author>
<author>M Palmer</author>
</authors>
<title>Classbased construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI-2000.</booktitle>
<location>Austin, TX.</location>
<contexts>
<context position="6210" citStr="Kipper et al. 2000" startWordPosition="938" endWordPosition="941">tion will provide a way to automatically extend the existing verb classes to cover more of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles. EVCA (English Verb Classes and Alternations) (Levin 1993) organizes verbs by similarity and participation / nonparticipation in alternation patterns. It contains 3200 verbs classified into 191 classes. Additional manually constructed resources include PropBank (Kingsbury et al. 2002), FrameNet (Baker et al. 1998), VerbNet (Kipper et al. 2000), and the resource on verb selectional restrictions developed by Gomez (2001). Our approach differs from the above in its focus. We relate verbs to each other rather than organize them into classes or identify their frames or thematic roles. WordNet does provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations f</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Kipper, K.; Dang, H.; and Palmer, M. 2000. Classbased construction of a verb lexicon. In Proceedings of AAAI-2000. Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Klavans</author>
<author>M Kan</author>
</authors>
<title>Document classification: Role of verb in document analysis.</title>
<date>1998</date>
<booktitle>In Proceedings COLING-ACL &apos;98.</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="5220" citStr="Klavans and Kan (1998)" startWordPosition="787" endWordPosition="790"> vs. abuse and renovate vs. upgrade) can help a system pick the most general sentence. In lexical selection of verbs in machine translation and in work on document classification, practitioners have argued for approaches that depend on wide-coverage resources indicating verb similarity and membership of a verb in a certain class. In work on translating verbs with many counterparts in the target language, Palmer and Wu (1995) discuss inherent limitations of approaches which do not examine a verb&apos;s class membership, and put forth an approach based on verb similarity. In document classification, Klavans and Kan (1998) demonstrate that document type is correlated with the presence of many verbs of a certain EVCA class (Levin 1993). In discussing future work, Klavans and Kan point to extending coverage of the manually constructed EVCA resource as a way of improving the performance of the system. A widecoverage repository of verb relations including verbs linked by the similarity relation will provide a way to automatically extend the existing verb classes to cover more of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes </context>
</contexts>
<marker>Klavans, Kan, 1998</marker>
<rawString>Klavans, J. and Kan, M. 1998. Document classification: Role of verb in document analysis. In Proceedings COLING-ACL &apos;98. Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="1136" citStr="Levin 1993" startWordPosition="151" endWordPosition="152">ns between pairs of strongly associated verbs using lexicosyntactic patterns over the Web. On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy. Analysis of error types shows that on the relation strength we achieved 75% accuracy. We provide the resource, called VERBOCEAN, for download at http://semantics.isi.edu/ocean/. 1 Introduction Many NLP tasks, such as question answering, summarization, and machine translation could benefit from broad-coverage semantic resources such as WordNet (Miller 1990) and EVCA (English Verb Classes and Alternations) (Levin 1993). These extremely useful resources have very high precision entries but have important limitations when used in real-world NLP tasks due to their limited coverage and prescriptive nature (i.e. they do not include semantic relations that are plausible but not guaranteed). For example, it may be valuable to know that if someone has bought an item, they may sell it at a later time. WordNet does not include the relation &amp;quot;X buys Y&amp;quot; happens-before &amp;quot;X sells Y&amp;quot; since it is possible to sell something without having bought it (e.g. having manufactured or stolen it). Verbs are the primary vehicle for des</context>
<context position="5334" citStr="Levin 1993" startWordPosition="808" endWordPosition="809">ne translation and in work on document classification, practitioners have argued for approaches that depend on wide-coverage resources indicating verb similarity and membership of a verb in a certain class. In work on translating verbs with many counterparts in the target language, Palmer and Wu (1995) discuss inherent limitations of approaches which do not examine a verb&apos;s class membership, and put forth an approach based on verb similarity. In document classification, Klavans and Kan (1998) demonstrate that document type is correlated with the presence of many verbs of a certain EVCA class (Levin 1993). In discussing future work, Klavans and Kan point to extending coverage of the manually constructed EVCA resource as a way of improving the performance of the system. A widecoverage repository of verb relations including verbs linked by the similarity relation will provide a way to automatically extend the existing verb classes to cover more of the English lexicon. 2.2 Existing resources Some existing broad-coverage resources on verbs have focused on organizing verbs into classes or annotating their frames or thematic roles. EVCA (English Verb Classes and Alternations) (Levin 1993) organizes </context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, B. 1993. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Lin</author>
</authors>
<title>Robust Automated Topic Identification.</title>
<date>1997</date>
<tech>Ph.D. Thesis.</tech>
<institution>University of Southern California.</institution>
<contexts>
<context position="4136" citStr="Lin 1997" startWordPosition="615" endWordPosition="616"> discussing future work on the system&apos;s logical form matching component, Rus (2002 p. 143) points to incorporating entailment and causation verb relations to improve the matcher&apos;s performance. In other work, Webber et al. (2002) have argued that successful question answering depends on lexical reasoning, and that lexical reasoning in turn requires fine-grained verb semantics in addition to troponymy (is-a relations between verbs) and antonymy. In multi-document summarization, knowing verb similarities is useful for sentence compression and for determining sentences that have the same meaning (Lin 1997). Knowing that a particular action happens before another or is enabled by Figure 1. Fellbaum&apos;s (1998) entailment hierarchy. another is also useful to determine the order of the events (Barzilay et al. 2002). For example, to order summary sentences properly, it may be useful to know that selling something can be preceded by either buying, manufacturing, or stealing it. Furthermore, knowing that a particular verb has a meaning stronger than another (e.g. rape vs. abuse and renovate vs. upgrade) can help a system pick the most general sentence. In lexical selection of verbs in machine translatio</context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>Lin, C-Y. 1997. Robust Automated Topic Identification. Ph.D. Thesis. University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<pages>7--4</pages>
<contexts>
<context position="13185" citStr="Lin and Pantel (2001)" startWordPosition="2019" endWordPosition="2022">tween a causative and a resultative verb (as in buy :: own), would be tagged as instances of happens-before by our system. Examples of the happens-before relation identified by our system include marry :: divorce, detain :: prosecute, enroll :: graduate, schedule :: reschedule, tie :: untie. 4 Approach We discover the semantic relations described above by querying the Web with Google for lexico-syntactic patterns indicative of each relation. Our approach has two stages. First, we identify pairs of highly associated verbs co-occurring on the Web with sufficient frequency using previous work by Lin and Pantel (2001), as described in Section 4.4. Next, for each verb pair, we tested lexico-syntactic patterns, calculating a score for each possible semantic relation as described in Section 4.2. Finally, as described in Section 4.3, we compare the strengths of the individual semantic relations and, preferring the most specific and then strongest relations, output a consistent set as the final output. As a guide to consistency, we use a simple theory of semantics indicating which semantic relations are subtypes of other ones, and which are compatible and which are mutually exclusive. 4.1 Lexico-syntactic patte</context>
<context position="20010" citStr="Lin and Pantel 2001" startWordPosition="3243" endWordPosition="3246">fore). If strength is detected, score of similarity is ignored (because strength is more specific than similarity). Of the relations strength, similarity, opposition and enablement which were detected (and not ignored), output the one with highest Sp. If nothing has been output to this point, output unrelated. 4.4 Extracting highly associated verb pairs To exhaustively test the more than 64 million unordered verb pairs for WordNet&apos;s more than 11,000 verbs would be computationally intractable. Instead, we use a set of highly associated verb pairs output by a paraphrasing algorithm called DIRT (Lin and Pantel 2001). Since we are able to test up to 4000 verb pairs per day on a single machine (we issue at most 40 queries per test and each query takes approximately 0.5 seconds), we are able to test several dozen associated verbs for each verb in WordNet in a matter of weeks. Lin and Pantel (2001) describe an algorithm called DIRT (Discovery of Inference Rules from Text) that automatically learns paraphrase expressions from text. It is a generalization of previous algorithms that use the distributional hypothesis (Harris 1985) for finding similar words. Instead of applying the hypothesis to words, Lin and P</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Lin, D. and Pantel, P. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>S Zhao</author>
<author>L Qin</author>
<author>M Zhou</author>
</authors>
<title>Identifying synonyms among distributionally similar words.</title>
<date>2003</date>
<booktitle>In Proceedings of IJCAI-03.</booktitle>
<pages>1492--1493</pages>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="7338" citStr="Lin et al. (2003)" startWordPosition="1114" endWordPosition="1117">vious web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Richardson et al. 1998) extracts a collection of triples of the type &amp;quot;ducks have wings&amp;quot; and &amp;quot;duck capable-of flying&amp;quot;. This resource, however, does not relate verbs to </context>
</contexts>
<marker>Lin, Zhao, Qin, Zhou, 2003</marker>
<rawString>Lin, D.; Zhao, S.; Qin, L.; and Zhou, M. 2003. Identifying synonyms among distributionally similar words. In Proceedings of IJCAI-03. pp.1492-1493. Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>WordNet: An online lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="1074" citStr="Miller 1990" startWordPosition="141" endWordPosition="142">ngth, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web. On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy. Analysis of error types shows that on the relation strength we achieved 75% accuracy. We provide the resource, called VERBOCEAN, for download at http://semantics.isi.edu/ocean/. 1 Introduction Many NLP tasks, such as question answering, summarization, and machine translation could benefit from broad-coverage semantic resources such as WordNet (Miller 1990) and EVCA (English Verb Classes and Alternations) (Levin 1993). These extremely useful resources have very high precision entries but have important limitations when used in real-world NLP tasks due to their limited coverage and prescriptive nature (i.e. they do not include semantic relations that are plausible but not guaranteed). For example, it may be valuable to know that if someone has bought an item, they may sell it at a later time. WordNet does not include the relation &amp;quot;X buys Y&amp;quot; happens-before &amp;quot;X sells Y&amp;quot; since it is possible to sell something without having bought it (e.g. having man</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Miller, G. 1990. WordNet: An online lexical database. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>A Badulescu</author>
<author>M Tatu</author>
<author>D Antohe</author>
<author>R Girju</author>
</authors>
<title>Models for the semantic classification of noun phrases.</title>
<date>2004</date>
<booktitle>Proceedings of HLT/NAACL-2004 Workshop on Computational Lexical Semantics.</booktitle>
<note>To appear in</note>
<contexts>
<context position="7173" citStr="Moldovan et al. (2004)" startWordPosition="1088" endWordPosition="1091">tions such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Ri</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Girju, 2004</marker>
<rawString>Moldovan, D.; Badulescu, A.; Tatu, M.; Antohe, D.; and Girju, R. 2004. Models for the semantic classification of noun phrases. To appear in Proceedings of HLT/NAACL-2004 Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>S Harabagiu</author>
<author>R Girju</author>
<author>P Morarescu</author>
<author>F Lacatusu</author>
<author>A Novischi</author>
<author>A Badulescu</author>
<author>O Bolohan</author>
</authors>
<title>LCC tools for question answering.</title>
<date>2002</date>
<booktitle>In Notebook of the Eleventh Text REtrieval Conference (TREC2002).</booktitle>
<pages>144--154</pages>
<contexts>
<context position="3523" citStr="Moldovan et al. 2002" startWordPosition="523" endWordPosition="526"> use a measure similar to mutual information to account for both the frequency of the verbs whose semantic relations are being discovered as well as for the frequency of the pattern. 2 Relevant Work In this section, we describe application domains that can benefit from a resource of verb semantics. We then introduce some existing resources and describe previous attempts at mining semantics from text. 2.1 Applications Question answering is often approached by canonicalizing the question text and the answer text into logical forms. This approach is taken, inter alia, by a top-performing system (Moldovan et al. 2002). In discussing future work on the system&apos;s logical form matching component, Rus (2002 p. 143) points to incorporating entailment and causation verb relations to improve the matcher&apos;s performance. In other work, Webber et al. (2002) have argued that successful question answering depends on lexical reasoning, and that lexical reasoning in turn requires fine-grained verb semantics in addition to troponymy (is-a relations between verbs) and antonymy. In multi-document summarization, knowing verb similarities is useful for sentence compression and for determining sentences that have the same meani</context>
</contexts>
<marker>Moldovan, Harabagiu, Girju, Morarescu, Lacatusu, Novischi, Badulescu, Bolohan, 2002</marker>
<rawString>Moldovan, D.; Harabagiu, S.; Girju, R.; Morarescu, P.; Lacatusu, F.; Novischi, A.; Badulescu, A.; and Bolohan, O. 2002. LCC tools for question answering. In Notebook of the Eleventh Text REtrieval Conference (TREC2002). pp. 144154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>Z Wu</author>
</authors>
<title>Verb Semantics for English-Chinese Translation Machine Translation,</title>
<date>1995</date>
<contexts>
<context position="5026" citStr="Palmer and Wu (1995)" startWordPosition="758" endWordPosition="761">seful to know that selling something can be preceded by either buying, manufacturing, or stealing it. Furthermore, knowing that a particular verb has a meaning stronger than another (e.g. rape vs. abuse and renovate vs. upgrade) can help a system pick the most general sentence. In lexical selection of verbs in machine translation and in work on document classification, practitioners have argued for approaches that depend on wide-coverage resources indicating verb similarity and membership of a verb in a certain class. In work on translating verbs with many counterparts in the target language, Palmer and Wu (1995) discuss inherent limitations of approaches which do not examine a verb&apos;s class membership, and put forth an approach based on verb similarity. In document classification, Klavans and Kan (1998) demonstrate that document type is correlated with the presence of many verbs of a certain EVCA class (Levin 1993). In discussing future work, Klavans and Kan point to extending coverage of the manually constructed EVCA resource as a way of improving the performance of the system. A widecoverage repository of verb relations including verbs linked by the similarity relation will provide a way to automati</context>
</contexts>
<marker>Palmer, Wu, 1995</marker>
<rawString>Palmer, M., Wu, Z. 1995. Verb Semantics for English-Chinese Translation Machine Translation, 9(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
</authors>
<title>Automatically labeling semantic classes. To appear in</title>
<date>2004</date>
<booktitle>Proceedings of HLT/NAACL-2004.</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="7089" citStr="Pantel and Ravichandran 2004" startWordPosition="1075" endWordPosition="1078">oes provide relations between verbs, but at a coarser level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have als</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>Pantel, P. and Ravichandran, D. 2004. Automatically labeling semantic classes. To appear in Proceedings of HLT/NAACL-2004. Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ravichandran</author>
<author>E Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-02.</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2757" citStr="Ravichandran and Hovy 2002" startWordPosition="399" endWordPosition="402"> another and (ii) provides broad coverage of the verbs in the target language. In this paper, we present an algorithm that semiautomatically discovers fine-grained verb semantics by querying the Web using simple lexicosyntactic patterns. The verb relations we discover are similarity, strength, antonymy, enablement, and temporal relations. Identifying these relations over 29,165 verb pairs results in a broad-coverage resource we call VERBOCEAN. Our approach extends previously formulated ones that use surface patterns as indicators of semantic relations between nouns (Hearst 1992; Etzioni 2003; Ravichandran and Hovy 2002). We extend these approaches in two ways: (i) our patterns indicate verb conjugation to increase their expressiveness and specificity and (ii) we use a measure similar to mutual information to account for both the frequency of the verbs whose semantic relations are being discovered as well as for the frequency of the pattern. 2 Relevant Work In this section, we describe application domains that can benefit from a resource of verb semantics. We then introduce some existing resources and describe previous attempts at mining semantics from text. 2.1 Applications Question answering is often approa</context>
<context position="7139" citStr="Ravichandran and Hovy 2002" startWordPosition="1083" endWordPosition="1086">er level. We provide finer-grained relations such as strength, enablement and temporal information. Also, in contrast with WordNet, we cover more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machi</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Ravichandran, D. and Hovy, E., 2002. Learning surface text patterns for a question answering system. In Proceedings of ACL-02. Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Richardson</author>
<author>W Dolan</author>
<author>L Vanderwende</author>
</authors>
<title>MindNet: acquiring and structuring semantic information from text.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING &apos;98.</booktitle>
<contexts>
<context position="7794" citStr="Richardson et al. 1998" startWordPosition="1183" endWordPosition="1186">4) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Richardson et al. 1998) extracts a collection of triples of the type &amp;quot;ducks have wings&amp;quot; and &amp;quot;duck capable-of flying&amp;quot;. This resource, however, does not relate verbs to each other or provide verb semantics. 3 Semantic relations among verbs In this section, we introduce and motivate the specific relations that we extract. Whilst the natural language literature is rich in theories of semantics (Barwise and Perry 1985; Schank and Abelson 1977), large-coverage manually created semantic resources typically only organize verbs into a flat or shallow hierarchy of classes (such as those described in Section 2.2). WordNet iden</context>
</contexts>
<marker>Richardson, Dolan, Vanderwende, 1998</marker>
<rawString>Richardson, S.; Dolan, W.; and Vanderwende, L. 1998. MindNet: acquiring and structuring semantic information from text. In Proceedings of COLING &apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
</authors>
<title>Logic Forms for WordNet Glosses.</title>
<date>2002</date>
<tech>Ph.D. Thesis.</tech>
<institution>Southern Methodist University.</institution>
<contexts>
<context position="3609" citStr="Rus (2002" startWordPosition="538" endWordPosition="539">semantic relations are being discovered as well as for the frequency of the pattern. 2 Relevant Work In this section, we describe application domains that can benefit from a resource of verb semantics. We then introduce some existing resources and describe previous attempts at mining semantics from text. 2.1 Applications Question answering is often approached by canonicalizing the question text and the answer text into logical forms. This approach is taken, inter alia, by a top-performing system (Moldovan et al. 2002). In discussing future work on the system&apos;s logical form matching component, Rus (2002 p. 143) points to incorporating entailment and causation verb relations to improve the matcher&apos;s performance. In other work, Webber et al. (2002) have argued that successful question answering depends on lexical reasoning, and that lexical reasoning in turn requires fine-grained verb semantics in addition to troponymy (is-a relations between verbs) and antonymy. In multi-document summarization, knowing verb similarities is useful for sentence compression and for determining sentences that have the same meaning (Lin 1997). Knowing that a particular action happens before another or is enabled b</context>
</contexts>
<marker>Rus, 2002</marker>
<rawString>Rus, V. 2002. Logic Forms for WordNet Glosses. Ph.D. Thesis. Southern Methodist University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>R Abelson</author>
</authors>
<title>Scripts, Plans, Goals and Understanding: An Inquiry into Human Knowledge Structures. Lawrence Erlbaum Associates.</title>
<date>1977</date>
<contexts>
<context position="8213" citStr="Schank and Abelson 1977" startWordPosition="1250" endWordPosition="1253">web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Richardson et al. 1998) extracts a collection of triples of the type &amp;quot;ducks have wings&amp;quot; and &amp;quot;duck capable-of flying&amp;quot;. This resource, however, does not relate verbs to each other or provide verb semantics. 3 Semantic relations among verbs In this section, we introduce and motivate the specific relations that we extract. Whilst the natural language literature is rich in theories of semantics (Barwise and Perry 1985; Schank and Abelson 1977), large-coverage manually created semantic resources typically only organize verbs into a flat or shallow hierarchy of classes (such as those described in Section 2.2). WordNet identifies synonymy, antonymy, troponymy, and cause. As summarized in Figure 1, Fellbaum (1998) discusses a finer-grained analysis of entailment, while the WordNet database does not distinguish between, e.g., backward presupposition (forget :: know, where know must have happened before forget) from proper temporal inclusion (walk :: step). In formulating our set of relations, we have relied on the finer-grained analysis</context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Schank, R. and Abelson, R. 1977. Scripts, Plans, Goals and Understanding: An Inquiry into Human Knowledge Structures. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>Castellan Jr</author>
<author>N</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGraw-Hill.</publisher>
<marker>Siegel, Jr, N, 1988</marker>
<rawString>Siegel, S. and Castellan Jr., N. 1988. Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Mining the Web for synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>In Proceedings ECML-2001.</booktitle>
<location>Freiburg, Germany.</location>
<contexts>
<context position="7265" citStr="Turney (2001)" startWordPosition="1105" endWordPosition="1106"> more than the prescriptive cases. 2.3 Mining semantics from text Previous web mining work has rarely addressed extracting many different semantic relations from Web-sized corpus. Most work on extracting semantic information from large corpora has largely focused on the extraction of is-a relations between nouns. Hearst (1992) was the first followed by recent larger-scale and more fully automated efforts (Pantel and Ravichandran 2004; Etzioni et al. 2004; Ravichandran and Hovy 2002). Recently, Moldovan et al. (2004) present a learning algorithm to detect 35 fine-grained noun phrase relations. Turney (2001) studied word relatedness and synonym extraction, while Lin et al. (2003) present an algorithm that queries the Web using lexical patterns for distinguishing noun synonymy and antonymy. Our approach addresses verbs and provides for a richer and finer-grained set of semantics. Reliability of estimating bigram counts on the web via search engines has been investigated by Keller and Lapata (2003). Semantic networks have also been extracted from dictionaries and other machine-readable resources. MindNet (Richardson et al. 1998) extracts a collection of triples of the type &amp;quot;ducks have wings&amp;quot; and &amp;quot;d</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Turney, P. 2001. Mining the Web for synonyms: PMI-IR versus LSA on TOEFL. In Proceedings ECML-2001. Freiburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>C Gardent</author>
<author>J Bos</author>
</authors>
<title>Position statement: Inference in question answering.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC-2002. Las</booktitle>
<location>Palmas,</location>
<contexts>
<context position="3755" citStr="Webber et al. (2002)" startWordPosition="560" endWordPosition="563">cation domains that can benefit from a resource of verb semantics. We then introduce some existing resources and describe previous attempts at mining semantics from text. 2.1 Applications Question answering is often approached by canonicalizing the question text and the answer text into logical forms. This approach is taken, inter alia, by a top-performing system (Moldovan et al. 2002). In discussing future work on the system&apos;s logical form matching component, Rus (2002 p. 143) points to incorporating entailment and causation verb relations to improve the matcher&apos;s performance. In other work, Webber et al. (2002) have argued that successful question answering depends on lexical reasoning, and that lexical reasoning in turn requires fine-grained verb semantics in addition to troponymy (is-a relations between verbs) and antonymy. In multi-document summarization, knowing verb similarities is useful for sentence compression and for determining sentences that have the same meaning (Lin 1997). Knowing that a particular action happens before another or is enabled by Figure 1. Fellbaum&apos;s (1998) entailment hierarchy. another is also useful to determine the order of the events (Barzilay et al. 2002). For exampl</context>
</contexts>
<marker>Webber, Gardent, Bos, 2002</marker>
<rawString>Webber, B.; Gardent, C.; and Bos, J. 2002. Position statement: Inference in question answering. In Proceedings of LREC-2002. Las Palmas, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>