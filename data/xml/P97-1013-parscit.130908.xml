<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000027">
<title confidence="0.997747">
The Rhetorical Parsing of Natural Language Texts
</title>
<author confidence="0.998645">
Daniel Marcu
</author>
<affiliation confidence="0.883592666666667">
Department of Computer Science
University of Toronto
Toronto, Ontario
</affiliation>
<address confidence="0.931175">
Canada M5S 3G4
</address>
<email confidence="0.974889">
marcuelcs.toronto.edu
</email>
<sectionHeader confidence="0.997012" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999984111111111">
We derive the rhetorical structures of texts
by means of two new, surface-form-based
algorithms: one that identifies discourse
usages of cue phrases and breaks sen-
tences into clauses, and one that produces
valid rhetorical structure trees for unre-
stricted natural language texts. The algo-
rithms use information that was derived
from a corpus analysis of cue phrases.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955696969697">
Researchers of natural language have repeatedly ac-
knowledged that texts are not just a sequence of words
nor even a sequence of clauses and sentences. However,
despite the impressive number of discourse-related theo-
ries that have been proposed so far, there have emerged
no algorithms capable of deriving the discourse struc-
ture of an unrestricted text. On one hand, efforts such
as those described by Asher (1993), Lascarides, Asher,
and Oberlander (1992), Kamp and Reyle (1993), Grover
et al. (1994), and PrUst, Scha, and van den Berg (1994)
take the position that discourse structures can be built
only in conjunction with fully specified clause and sen-
tence structures. And Hobbs&apos;s theory (1990) assumes
that sophisticated knowledge bases and inference mech-
anisms are needed for determining the relations between
discourse units. Despite the formal elegance of these
approaches, they are very domain dependent and, there-
fore, unable to handle more than a few restricted exam-
ples. On the other hand, although the theories described
by Grosz and Sidner (1986), Polanyi (1988), and Mann
and Thompson (1988) are successfully applied manually,
they are too informal to support an automatic approach
to discourse analysis.
In contrast with this previous work, the rhetorical
parser that we present builds discourse trees for unre-
stricted texts. We first discuss the key concepts on which
our approach relies (section 2) and the corpus analysis
(section 3) that provides the empirical data for our rhetor-
ical parsing algorithm. We discuss then an algorithm that
recognizes discourse usages of cue phrases and that de-
termines clause boundaries within sentences. Lastly, we
present the rhetorical parser and an example of its opera-
tion (section 4).
</bodyText>
<sectionHeader confidence="0.998931" genericHeader="introduction">
2 Foundation
</sectionHeader>
<bodyText confidence="0.999958025641026">
The mathematical foundations of the rhetorical parsing
algorithm rely on a first-order formalization of valid text
structures (Marcu, 1997). The assumptions of the for-
malization are the following. 1. The elementary units
of complex text structures are non-overlapping spans of
text. 2. Rhetorical, coherence, and cohesive relations
hold between textual units of various sizes. 3. Rela-
tions can be partitioned into two classes: paratactic and
hypotactic. Paratactic relations are those that hold be-
tween spans of equal importance. Hypotactic relations
are those that hold between a span that is essential for the
writer&apos;s purpose, i.e., a nucleus, and a span that increases
the understanding of the nucleus but is not essential for
the writer&apos;s purpose, i.e., a satellite. 4. The abstract
structure of most texts is a binary, tree-like structure. 5.
If a relation holds between two textual spans of the tree
structure of a text, that relation also holds between the
most important units of the constituent subspans. The
most important units of a textual span are determined re-
cursively: they correspond to the most important units
of the immediate subspans when the relation that holds
between these subspans is paratactic, and to the most im-
portant units of the nucleus subspan when the relation
that holds between the immediate subspans is hypotactic.
In our previous work (Marcu, 1996), we presented a
complete axiomatization of these principles in the con-
text of Rhetorical Structure Theory (Mann and Thomp-
son, 1988) and we described an algorithm that, starting
from the set of textual units that make up a text and
the set of elementary rhetorical relations that hold be-
tween these units, can derive all the valid discourse trees
of that text. Consequently, if one is to build discourse
trees for unrestricted texts, the problems that remain to
be solved are the automatic determination of the tex-
tual units and the rhetorical relations that hold between
them. In this paper, we show how one can find and ex-
ploit approximate solutions for both of these problems
by capitalizing on the occurrences of certain lexicogram-
matical constructs. Such constructs can include tense
</bodyText>
<page confidence="0.984542">
96
</page>
<bodyText confidence="0.998889941176471">
and aspect (Moens and Steedman, 1988; Webber, 1988;
Lascarides and Asher, 1993), certain patterns of pronom-
inalization and anaphoric usages (Sidner, 1981; Grosz
and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and
Weinstein, 1995), it-clefts (Delin and Oberlander, 1992),
and discourse markers or cue phrases (Ballard, Conrad,
and Longacre, 1971; Halliday and Hasan, 1976; Van
Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986;
Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders,
Spooren, and Noordman, 1992; Hirschberg and Litman,
1993; Knott, 1995; Fraser, 1996; Moser and Moore,
1997). In the work described here, we investigate how far
we can get by focusing our attention only on discourse
markers and lexicogrammatical constructs that can be
detected by a shallow analysis of natural language texts.
The intuition behind our choice relies on the following
facts:
</bodyText>
<listItem confidence="0.965351894736842">
• Psycholinguistic and other empirical
research (Kintsch, 1977; Schiffrin, 1987; Segal,
Duchan, and Scott, 1991; Cahn, 1992; Sanders,
Spooren, and Noordman, 1992; Hirschberg and
Litman, 1993: Knott, 1995; Costermans and
Fayol, 1997) has shown that discourse markers
are consistently used by human subjects both as
cohesive ties between adjacent clauses and as
&amp;quot;macroconnectors&amp;quot; between larger textual units.
Therefore, we can use them as rhetorical indica-
tors at any of the following levels: clause, sen-
tence, paragraph, and text.
• The number of discourse markers in a typical
text — approximately one marker for every two
clauses (Redeker, 1990) — is sufficiently large to
enable the derivation of rich rhetorical structures
for texts.
• Discourse markers are used in a manner that is
consistent with the semantics and pragmatics of
</listItem>
<bodyText confidence="0.987354611940299">
the discourse segments that they relate. In other
words, we assume that the texts that we pro-
cess are well-formed from a discourse perspec-
tive, much as researchers in sentence parsing as-
sume that they are well-formed from a syntactic
perspective. As a consequence, we assume that
one can bootstrap the full syntactic, semantic, and
pragmatic analysis of the clauses that make up
a text and still end up with a reliable discourse
structure for that text.
Given the above discussion, the immediate objection
that one can raise is that discourse markers are doubly
ambiguous: in some cases, their use is only sentential,
i.e., they make a semantic contribution to the interpre-
tation of a clause; and even in the cases where markers
have a discourse usage, they are ambiguous with respect
to the rhetorical relations that they mark and the sizes of
the textual spans that they connect. We address now each
of these objections in turn.
Sentential and discourse usages of cue phrases.
Empirical studies on the disambiguation of cue
phrases (Hirschberg and Litman, 1993) have shown that
just by considering the orthographic environment in
which a discourse marker occurs, one can distinguish
between sentential and discourse usages in about 80% of
cases. We have taken Hirschberg and Litman&apos;s research
one step further and designed a comprehensive corpus
analysis that enabled us to improve their results and cov-
erage. The method, procedure, and results of our corpus
analysis are discussed in section 3.
Discourse markers are ambiguous with respect to the
rhetorical relations that they mark and the sizes of the
units that they connect. When we began this research,
no empirical data supported the extent to which this am-
biguity characterizes natural language texts. To better
understand this problem, the corpus analysis described in
section 3 was designed so as to also provide information
about the types of rhetorical relations, rhetorical statuses
(nucleus or satellite), and sizes of textual spans that each
marker can indicate. We knew from the beginning that it
would be impossible to predict exactly the types of rela-
tions and the sizes of the spans that a given cue marks.
However, given that the structure that we are trying to
build is highly constrained, such a prediction proved to
be unnecessary: the overall constraints on the structure of
discourse that we enumerated in the beginning of this sec-
tion cancel out most of the configurations of elementary
constraints that do not yield correct discourse trees.
Consider, for example, the following text:
(1) [Although discourse markers are ambiguous,&apos;]
[one can use them to build discourse trees for
unrestricted texts:2] [this will lead to many new
applications in natural language processing.3]
For the sake of the argument, assume that we are able to
break text (1) into textual units as labelled above and
that we are interested now in finding rhetorical rela-
tions between these units. Assume now that we can
infer that Although marks a CONCESSIVE relation be-
tween satellite 1 and nucleus either 2 or 3, and the colon,
an ELABORATION between satellite 3 and nucleus either
1 or 2. If we use the convention that hypotactic rela-
tions are represented as first-order predicates having the
form rhet_rel(NAME, satellite, nucleus) and that paratac-
tic relations are represented as predicates having the form
rhet_rel(NAmE, nucleus&apos;, nucleus2), a correct representa-
tion for text (1) is then the set of two disjunctions given
in (2):
</bodyText>
<equation confidence="0.712893">
rhet_re/(CONCESSION, 1,2) V
</equation>
<bodyText confidence="0.9246376">
(2) rhet_re/(coNcEssioN, 1,3)
rhet _rel(ELABORATION , 3, 1) V
rhet_re/(ELABORATION, 3,2)
Despite the ambiguity of the relations, the over-
all rhetorical structure constraints will associate only
one discourse tree with text (1), namely the tree
given in figure 1: any discourse tree configura-
tion that uses relations rhet_re/(coNCESSioN, 1,3) and
rhet_re/(ELABoRATIoN , 3, 1) will be ruled out. For ex-
ample, relation rhet_re/(ELABoRATIoN, 3, 1) will be ruled
</bodyText>
<page confidence="0.996529">
97
</page>
<figure confidence="0.939147">
1 2
</figure>
<figureCaption confidence="0.999963">
Figure 1: The discourse tree of text (1).
</figureCaption>
<bodyText confidence="0.999774833333333">
out because unit 1 is not an important unit for span [1,2]
and, as mentioned at the beginning of this section, a
rhetorical relation that holds between two spans of a valid
text structure must also hold between their most impor-
tant units: the important unit of span [1,2] is unit 2, i.e.,
the nucleus of the relation r het fel(cONCESSION , 1,2).
</bodyText>
<sectionHeader confidence="0.99793" genericHeader="method">
3 A corpus analysis of discourse markers
</sectionHeader>
<subsectionHeader confidence="0.999819">
3.1 Materials
</subsectionHeader>
<bodyText confidence="0.999978852941176">
We used previous work on cue phrases (Halliday and
Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992;
Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996)
to create an initial set of more than 450 potential dis-
course markers. For each potential discourse marker, we
then used an automatic procedure that extracted from the
Brown corpus a set of text fragments. Each text fragment
contained a &amp;quot;window&amp;quot; of approximately 200 words and
an emphasized occurrence of a marker. On average, we
randomly selected approximately 19 text fragments per
marker, having few texts for the markers that do not occur
very often in the corpus and up to 60 text fragments for
markers such as and, which we considered to be highly
ambiguous. Overall, we randomly selected more than
7900 texts.
All the text fragments associated with a potential cue
phrase were paired with a set of slots in which an ana-
lyst described the following. 1. The orthographic en-
vironment that characterizes the usage of the potential
discourse marker. This included occurrences of periods,
commas, colons, semicolons, etc. 2. The type of usage:
Sentential, Discourse, or Both. 3. The position of the
marker in the textual unit to which it belonged: Begin-
ning,Medial, or End. 4. The right boundary of the textual
unit associated with the marker. 5. The relative position
of the textual unit that the unit containing the marker was
connected to: Before or After. 6. The rhetorical relations
that the cue phrase signaled. 7. The textual types of the
units connected by the discourse marker: from Clause
to Multiple_Paragraph. 8. The rhetorical status of each
textual unit involved in the relation: Nucleus or Satel-
lite. The algorithms described in this paper rely on the
results derived from the analysis of 1600 of the 7900 text
fragments.
</bodyText>
<subsectionHeader confidence="0.995461">
3.2 Procedure
</subsectionHeader>
<bodyText confidence="0.994322111111111">
After the slots for each text fragment were filled, the
results were automatically exported into a relational
database. The database was then examined semi-
automatically with the purpose of deriving procedures
that a shallow analyzer could use to identify discourse
usages of cue phrases, break sentences into clauses, and
hypothesize rhetorical relations between textual units.
For each discourse usage of a cue phrase, we derived
the following:
</bodyText>
<listItem confidence="0.934690466666666">
• A regular expression that contains an unambigu-
ous cue phrase instantiation and its orthographic
environment. A cue phrase is assigned a regu-
lar expression if, in the corpus, it has a discourse
usage in most of its occurrences and if a shallow
analyzer can detect it and the boundaries of the
textual units that it connects. For example, the
regular expression &amp;quot;[,] although&amp;quot; identifies such
a discourse usage.
• A procedure that can be used by a shallow ana-
lyzer to determine the boundaries of the textual
unit to which the cue phrase belongs. For exam-
ple, the procedure associated with &amp;quot;[,] although&amp;quot;
instructs the analyzer that the textual unit that
pertains to this cue phrase starts at the marker and
ends at the end of the sentence or at a position to
be determined by the procedure associated with
the subsequent discourse marker that occurs in
that sentence.
• A procedure that can be used by a shallow ana-
lyzer to hypothesize the sizes of the textual units
that the cue phrase relates and the rhetorical re-
lations that may hold between these units. For
example, the procedure associated with &amp;quot;[,] al-
though&amp;quot; will hypothesize that there exists a CON-
CESSION between the clause to which it belongs
and the clause(s) that went before in the same
sentence. For most markers this procedure makes
disjunctive hypotheses of the kind shown in (2)
above.
</listItem>
<sectionHeader confidence="0.873162" genericHeader="method">
33 Results
</sectionHeader>
<bodyText confidence="0.9709655">
At the time of writing, we have identified 1253 occur-
rences of cue phrases that exhibit discourse usages and
associated with each of them procedures that instruct
a shallow analyzer how the surrounding text should be
broken into textual units. This information is used by an
algorithm that concurrently identifies discourse usages of
cue phrases and determines the clauses that a text is made
of. The algorithm examines a text sentence by sentence
and determines a set of potential discourse markers that
occur in each sentence. It then applies left to right the
procedures that are associated with each potential marker.
These procedures have the following possible effects:
• They can cause an immediate breaking of the cur-
rent sentence into clauses. For example, when
an 1,1 although&amp;quot; marker is found, a new clause,
whose right boundary is just before the occur-
rence of the marker, is created. The algorithm is
then recursively applied on the text that is found
</bodyText>
<figure confidence="0.738957333333333">
LABORAT1ON
1-2
CONCESSI i N 3
</figure>
<page confidence="0.995437">
98
</page>
<table confidence="0.7074815">
Text No. of discourse No. of discourse No. of discourse Recall Precision
markers identified markers identified markers identified
manually by the algorithm correctly
by the algorithm
. 174 169 150 86.2% 88.8%
63 55 49 77.8% 89.1%
38 24 23 63.2% 95.6%
Total 275 248 222 80.8% 89.5%
</table>
<tableCaption confidence="0.999476">
Table 1: Evaluation of the marker identification procedure.
</tableCaption>
<table confidence="0.978810125">
Text No. of No. of clause No. of clause No. of clause Recall Precision
sentences boundaries identified boundaries identified boundaries identified
manually by the algorithm correctly
by the algorithm
242 428 416 371 86.7% 89.2%
80 151 123 113 74.8% 91.8%
19 61 37 36 59.0% 97.3%
Total 341 640 576 520 81.3% 90.3%
</table>
<tableCaption confidence="0.998691">
Table 2: Evaluation of the clause boundary identification procedure.
</tableCaption>
<listItem confidence="0.965594142857143">
between the occurrence of&amp;quot;[,] although&amp;quot; and the
end of the sentence.
• They can cause the setting of a flag. For example,
when an &amp;quot;Although&amp;quot; marker is found, a flag is
set to instruct the analyzer to break the current
sentence at the first occurrence of a comma.
• They can cause a cue phrase to be identified as
</listItem>
<bodyText confidence="0.931738285714286">
having a discourse usage. For example, when the
cue phrase &amp;quot;Although&amp;quot; is identified, it is also as-
signed a discourse usage. The decision of whether
a cue phrase is considered to have a discourse us-
age is sometimes based on the context in which
that phrase occurs, i.e., it depends on the occur-
rence of other cue phrases. For example, an &amp;quot;and&amp;quot;
will not be assigned a discourse usage in most of
the cases; however, when it occurs in conjunction
with &amp;quot;although&amp;quot;, i.e., &amp;quot;and although&amp;quot;, it will be
assigned such a role.
The most important criterion for using a cue phrase in
the marker identification procedure is that the cue phrase
(together with its orthographic neighborhood) is used as
a discourse marker in at least 90% of the examples that
were extracted from the corpus. The enforcement of
this criterion reduces on one hand the recall of the dis-
course markers that can be detected, but on the other
hand, increases significantly the precision. We chose this
deliberately because, during the corpus analysis, we no-
ticed that most of the markers that connect large textual
units can be identified by a shallow analyzer. In fact,
the discourse marker that is responsible for most of our
algorithm recall failures is and. Since a shallow analyzer
cannot identify with sufficient precision whether an oc-
currence of and has a discourse or a sentential usage, most
of its occurrences are therefore ignored. It is true that,
in this way, the discourse structures that we build lose
some potential finer granularity, but fortunately, from a
rhetorical analysis perspective, the loss has insignificant
global repercussions: the vast majority of the relations
that we miss due to recall failures of and are JOINT and
SEQUENCE relations that hold between adjacent clauses.
Evaluation. To evaluate our algorithm, we randomly
selected three texts, each belonging to a different genre:
</bodyText>
<listItem confidence="0.9989775">
1. an expository text of 5036 words from Scientific
American;
2. a magazine article of 1588 words from Time;
3. a narration of 583 words from the Brown Corpus.
</listItem>
<bodyText confidence="0.99986580952381">
Three independent judges, graduate students in computa-
tional linguistics, broke the texts into clauses. The judges
were given no instructions about the criteria that they had
to apply in order to determine the clause boundaries;
rather, they were supposed to rely on their intuition and
preferred definition of clause. The locations in texts that
were labelled as clause boundaries by at least two of the
three judges were considered to be &amp;quot;valid clause bound-
aries&amp;quot;. We used the valid clause boundaries assigned by
judges as indicators of discourse usages of cue phrases
and we determined manually the cue phrases that sig-
nalled a discourse relation. For example, if an &amp;quot;and&amp;quot; was
used in a sentence and if the judges agreed that a clause
boundary existed just before the &amp;quot;and&amp;quot;, we assigned that
&amp;quot;and&amp;quot; a discourse usage. Otherwise, we assigned it a
sentential usage. Hence, we manually determined all
discourse usages of cue phrases and all discourse bound-
aries between elementary units.
We then applied our marker and clause identification
algorithm on the same texts. Our algorithm found 80.8%
of the discourse markers with a precision of 89.5% (see
</bodyText>
<page confidence="0.990694">
99
</page>
<bodyText confidence="0.569148">
INPUT: a text T.
</bodyText>
<listItem confidence="0.998554875">
1. Determine the set D of all discourse markers and
the set UT of elementary textual units in T.
2. Hypothesize a set of relations R between the
elements of Ur.
3. Use a constraint satisfaction procedure to determine
all the discourse trees of T.
4. Assign a weight to each of the discourse trees and
determine the tree(s) with maximal weight.
</listItem>
<figureCaption confidence="0.997392">
Figure 2: Outline of the rhetorical parsing algorithm
</figureCaption>
<bodyText confidence="0.9979034">
table 1), a result that outperforms Hirschberg and Lit-
man&apos;s (1993). The same algorithm identified correctly
81.3% of the clause boundaries, with a precision of 90.3%
(see table 2). We are not aware of any surface-form-based
algorithms that achieve similar results.
</bodyText>
<sectionHeader confidence="0.961227" genericHeader="method">
4 Building up discourse trees
</sectionHeader>
<subsectionHeader confidence="0.990841">
4.1 The rhetorical parsing algorithm
</subsectionHeader>
<bodyText confidence="0.999979538461538">
The rhetorical parsing algorithm is outlined in figure 2.
In the first step, the marker and clause identification algo-
rithm is applied. Once the textual units are determined,
the rhetorical parser uses the procedures derived from
the corpus analysis to hypothesize rhetorical relations
between the textual units. A constraint-satisfaction pro-
cedure similar to that described in (Marcu, 1996) then de-
termines all the valid discourse trees (see (Marcu, 1997)
for details). The rhetorical parsing algorithm has been
fully implemented in C++.
Discourse is ambiguous the same way sentences are:
more than one discourse structure is usually produced for
a text. In our experiments, we noticed, at least for En-
glish, that the &amp;quot;best&amp;quot; discourse trees are usually those that
are skewed to the right. We believe that the explanation
of this observation is that text processing is, essentially,
a left-to-right process. Usually, people write texts so that
the most important ideas go first, both at the paragraph
and at the text level.&apos; The more text writers add, the more
they elaborate on the text that went before: as a conse-
quence, incremental discourse building consists mostly
of expansion of the right branches. In order to deal with
the ambiguity of discourse, the rhetorical parser com-
putes a weight for each valid discourse tree and retains
only those that are maximal. The weight function reflects
how skewed to the right a tree is.
</bodyText>
<subsectionHeader confidence="0.996728">
4.2 The rhetorical parser in operation
</subsectionHeader>
<bodyText confidence="0.994379674418605">
Consider the following text from the November 1996
issue of Scientific American (3). The words in italics
denote the discourse markers, the square brackets denote
&apos;In fact, journalists are trained to employ this &amp;quot;pyramid&amp;quot;
approach to writing consciously (Cumming and McKercher,
1994).
the boundaries of elementary textual units, and the curly
brackets denote the boundaries of parenthetical textual
units that were determined by the rhetorical parser (see
Marcu (1997) for details); the numbers associated with
the square brackets are identification labels.
[With its distant orbit { — 50 percent far-
ther from the sun than Earth —} and slim at-
mospheric blanket,&apos;] [Mars experiences frigid
weather conditions.2] [Surface temperatures typ-
ically average about —60 degrees Celsius (-76
degrees Fahrenheit) at the equator and can dip
to —123 degrees C near the poles.3] [Only the
midday sun at tropical latitudes is warm enough
to thaw ice on occasion,/ [but any liquid wa-
ter formed in this way would evaporate al-
most instantly5] [because of the low atmospheric
pressure.6]
[Although the atmosphere holds a small
amount of water, and water-ice clouds sometimes
develop,7] [most Martian weather involves blow-
ing dust or carbon dioxide.8] [Each win ter,for ex-
ample, a blizzard of frozen carbon dioxide rages
over one pole, and a few meters of this dry-
ice snow accumulate as previously frozen carbon
dioxide evaporates from the opposite polar cap.9]
[Yet even on the summer pole, (where the sun re-
mains in the sky all day long, } temperatures never
warm enough to melt frozen water.m]
Since parenthetical information is related only to the el-
ementary unit that it belongs to, we do not assign it an
elementary textual unit status. Such an assignment will
only create problems at the formal level as well, because
then discourse structures can no longer be represented as
binary trees.
On the basis of the data derived from the corpus anal-
ysis, the algorithm hypothesizes the following set of re-
lations between the textual units:
</bodyText>
<equation confidence="0.95819">
rhet_re/(JusTIFicArioN, 1,2) V
rhet_rel(coNDmoN, 1,2)
r het _rel(ELABoRATioN , 3, [1,2]) v
rhet_re/(ELABoRATioN , [3,6], [1,2])
rhet_re/(ELABoRATioN, [4,6], 3) v
rher_re/(ELABoRA&apos;noN, [4,6], [1,3])
rhet_re/(coNTRAsT, 4,5)
rhet_re/(EVIDENcE, 6,5)
rhet _re/(ELABORAT1ON, [7,10], [1,6])
rhet_rel(coNcEssIoN, 7,8)
rhet_re/(EXAMPLE, 9, [7,8]) V
rhet_re/(EXAMPLE, [9,10], [7,8])
rhet_rd(ANTITHESIS, 9, 10) v
rhet_re/(ANTITHESIS , [7,9], 10)
</equation>
<bodyText confidence="0.999906142857143">
The algorithm then determines all the valid discourse
trees that can be built for elementary units 1 to 10, given
the constraints in (4). In this case, the algorithm con-
structs 8 different trees. The trees are ordered according
to their weights. The &amp;quot;best&amp;quot; tree for text (3) has weight
3 and is fully represented in figure 3. The PostScript file
corresponding to figure 3 was automatically generated by
</bodyText>
<page confidence="0.8246">
100
</page>
<table confidence="0.630841454545454">
Weight= 3
Elaboration
Elaboration Is ; Exemplification •
; • (, for example) ;
.... r • &amp;quot; .
.... .. .
Anethests •
(Yet)
lustification,Condition
(With)
Elaboration • Concession
</table>
<figure confidence="0.937813307692307">
• . . . .* (Although)
With itodislant
orbit and slim
atmospheric
blanker,
(I)
.50 percent
farther from the
sun than Earth.
Surface
temperatures
typically average
about -60 degrees
Celsius (-76
degrees Fahrenheit)
at the equator and
can dip to -123
degrees C near the
poles.
(3)
Contrast.
• (, but )
\-
/ 1
1
1
</figure>
<tableCaption confidence="0.972483105263158">
Although the
atmosphere holds a
small amount of
water, and
water-ice clouds
sometimes develop,
(2)
Each Mater, for
example, a blizzard
of frozen carbon
dioxide rages over
one pole, and a few
Melon of this
dry-ice snow
accumulate as
previously frozen
carbon dioxide
evaporates from the
opposite polar cap.
</tableCaption>
<figure confidence="0.956950882352941">
(9)
most Martian
weather involves
blowing dust or
carbon dioxide.
(8)
Yet even on the
summer pole temperatures never 1
warms enough to =it
frozen MON.
(10)
Mars experiences i
Iligid weather
condition. 1
(2) 1
where the sun
remains in the sky
all day long,
Only the midday sun Evidence
at tropical ( because )
latitudes is warm
enough to thaw ice
on ocatsion,
(4)
but any liquid
water formed in
this way would
evaporate almost
instantly
(5)
because of the low
atmospheric
Kamm.
(6)
</figure>
<figureCaption confidence="0.999994">
Figure 3: The discourse tree of maximal weight that can be associated with text (3).
</figureCaption>
<bodyText confidence="0.9995946">
a back-end algorithm that uses &amp;quot;dot&amp;quot;, a preprocessor for
drawing directed graphs. The convention that we use is
that nuclei are surrounded by solid boxes and satellites
by dotted boxes; the links between a node and the subor-
dinate nucleus or nuclei are represented by solid arrows,
and the links between a node and the subordinate satel-
lites by dotted lines. The occurrences of parenthetical
information are marked in the text by a —P— and a unique
subordinate satellite that contains the parenthetical infor-
mation.
</bodyText>
<subsectionHeader confidence="0.706715">
43 Discussion and evaluation
</subsectionHeader>
<bodyText confidence="0.9997898">
We believe that there are two ways to evaluate the cor-
rectness of the discourse trees that an automatic process
builds. One way is to compare the automatically derived
trees with trees that have been built manually. Another
way is to evaluate the impact that the discourse trees that
we derive automatically have on the accuracy of other
natural language processing tasks, such as anaphora res-
olution, intention recognition, or text summarization. In
this paper, we describe evaluations that follow both these
avenues.
Unfortunately, the linguistic community has not yet
built a corpus of discourse trees against which our rhetor-
ical parser can be evaluated with the effectiveness that
traditional parsers are. To circumvent this problem, two
analysts manually built the discourse trees for five texts
that ranged from 161 to 725 words. Although there were
some differences with respect to the names of the rela-
tions that the analysts used, the agreement with respect to
the status assigned to various units (nuclei and satellites)
and the overall shapes of the trees was significant.
In order to measure this agreement we associated an
importance score to each textual unit in a tree and com-
puted the Spearman correlation coefficients between the
importance scores derived from the discourse trees built
by each analyst.2 The Spearman correlation coefficient
</bodyText>
<figure confidence="0.648656">
•
. ....
</figure>
<footnote confidence="0.9844115">
2The Spearman rank correlation coefficient is an alternative
to the usual correlation coefficient. It is based on the ranks of
the data, and not on the data itself, and so is resistant to outliers.
The null hypothesis tested by Spearman is that two variables
</footnote>
<page confidence="0.998077">
101
</page>
<bodyText confidence="0.999970493333334">
between the ranks assigned for each textual unit on the
bases of the discourse trees built by the two analysts was
very high: 0.798, at p &lt; 0.0001 level of significance. The
differences between the two analysts came mainly from
their interpretations of two of the texts: the discourse
trees of one analyst mirrored the paragraph structure of
the texts, while the discourse trees of the other mirrored
a logical organization of the text, which that analyst be-
lieved to be important.
The Spearman correlation coefficients with respect to
the importance of textual units between the discourse
trees built by our program and those built by each analyst
were 0.480, p &lt; 0.0001 and 0.449, p &lt; 0.0001. These
lower correlation values were due to the differences in
the overall shape of the trees and to the fact that the
granularity of the discourse trees built by the program
was not as fine as that of the trees built by the analysts.
Besides directly comparing the trees built by the pro-
gram with those built by analysts, we also evaluated the
impact that our trees could have on the task of sum-
marizing text. A summarization program that uses the
rhetorical parser described here recalled 66% of the sen-
tences considered important by 13 judges in the same five
texts, with a precision of 68%. In contrast, a random pro-
cedure recalled, on average, only 38.4% of the sentences
considered important by the judges, with a precision of
38.4%. And the Microsoft Office 97 summarizer recalled
41% of the important sentences with a precision of 39%.
We discuss at length the experiments from which the data
presented above was derived in (Marcu, 1997).
The rhetorical parser presented in this paper uses only
the structural constraints that were enumerated in sec-
tion 2. Co-relational constraints, focus, theme, anaphoric
links, and other syntactic, semantic, and pragmatic fac-
tors do not yet play a role in our system, but we neverthe-
less expect them to reduce the number of valid discourse
trees that can be associated with a text. We also ex-
pect that other robust methods for determining coherence
relations between textual units, such as those described
by Harabagiu and Moldovan (1995), will improve the
accuracy of the routines that hypothesize the rhetorical
relations that hold between adjacent units.
We are not aware of the existence of any other rhetor-
ical parser for English. However, Sumita et al. (1992)
report on a discourse analyzer for Japanese. Even if one
ignores some computational &amp;quot;bonuses&amp;quot; that can be eas-
ily exploited by a Japanese discourse analyzer (such as
co-reference and topic identification), there are still some
key differences between Sumita&apos;s work and ours. Partic-
ularly important is the fact that the theoretical foundations
of Sumita et al.&apos;s analyzer do not seem to be able to ac-
commodate the ambiguity of discourse markers: in their
are independent of each other, against the alternative hypothesis
that the rank of a variable is correlated with the rank of another
variable. The value of the statistic ranges from —1, indicating
that high ranks of one variable occur with low ranks of the
other variable, through 0, indicating no correlation between the
variables, to +1, indicating that high ranks of one variable occur
with high ranks of the other variable.
system, discourse markers are considered unambiguous
with respect to the relations that they signal. In contrast,
our system uses a mathematical model in which this am-
biguity is acknowledged and appropriately treated. Also,
the discourse trees that we build are very constrained
structures (see section 2): as a consequence, we do not
overgenerate invalid trees as Sumita et al. do. Further-
more, we use only surface-based methods for determin-
ing the markers and textual units and use clauses as the
minimal units of the discourse trees. In contrast, Sumita
et al. use deep syntactic and semantic processing tech-
niques for determining the markers and the textual units
and use sentences as minimal units in the discourse struc-
tures that they build. A detailed comparison of our work
with Sumita et al.&apos;s and others&apos; work is given in (Marcu,
1997).
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9996254375">
We introduced the notion of rhetorical parsing, i.e., the
process through which natural language texts are au-
tomatically mapped into discourse trees. In order to
make rhetorical parsing work, we improved previous al-
gorithms for cue phrase disambiguation, and proposed
new algorithms for determining the elementary textual
units and for computing the valid discourse trees of a
text. The solution that we described is both general and
robust.
Acknowledgements. This research would have not
been possible without the help of Graeme Hirst; there
are no right words to thank him for it. I am grateful
to Melanie Baljko, Phil Edmonds, and Steve Green for
their help with the corpus analysis. This research was
supported by the Natural Sciences and Engineering Re-
search Council of Canada
</bodyText>
<sectionHeader confidence="0.997935" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985404736842105">
Asher, Nicholas. 1993. Reference to Abstract Objects in
Discourse. Kluwer Academic Publishers, Dordrecht.
Ballard, D. Lee, Robert Conrad, and Robert E. Longacre.
1971. The deep and surface grammar of interclausal
relations. Foundations of language, 4:70-118.
Cahn, Janet. 1992. An investigation into the correlation
of cue phrases, unfilled pauses and the structuring of
spoken discourse. In Proceedings of the IRCS Work-
shop on Prosody in Natural Speech, pages 19-30.
Cohen, Robin. 1987. Analyzing the structure of argu-
mentative discourse. Computational Linguistics,13(1-
2): 11-24, January-June.
Costermans, Jean and Michel Fayol. 1997. Processing
Interclausal Relationships. Studies in the Production
and Comprehension of Text. Lawrence Erlbaum Asso-
ciates, Publishers.
Cumming, Carmen and Catherine McKercher. 1994.
The Canadian Reporter: News writing and reporting.
Hartcourt Brace.
</reference>
<page confidence="0.978067">
102
</page>
<reference confidence="0.999402970873787">
Delin, Judy L. and Jon Oberlander. 1992. Aspect-
switching and subordination: the role of it-clefts in dis-
course. In Proceedings of the Fourteenth International
Conference on Computational Linguistics (COLING-
92), pages 281-287, Nantes, France, August 23-28.
Fraser, Bruce. 1996. Pragmatic markers. Pragmatics,
6(2):167-190.
Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein.
1995. Centering: A framework for modeling the local
coherence of discourse. Computational Linguistics,
21(2):203-226, June.
Grosz, Barbara J. and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Compu-
tational Linguistics, 12(3):175-204, July-September.
Grover, Claire, Chris Brew, Suresh Manandhar, and Marc
Moens. 1994. Priority union and generalization in dis-
course grammars. In Proceedings of the 32nd Annual
Meeting of the Association for ComputationalLinguis-
tics (ACL-94), pages 17-24, Las Cruces, June 27-30.
Halliday, Michael A.K. and Rugaiya Hasan. 1976. Co-
hesion in English. Longman.
Harabagiu, Sanda M. and Dan I. Moldovan. 1995. A
marker-propagation algorithm for text coherence. In
Working Notes of the Workshop on Parallel Process-
ing in Artificial Intelligence, pages 76-86, Montreal,
Canada, August.
Hirschberg, Julia and Diane Litman. 1993. Empirical
studies on the disambiguation of cue phrases. Compu-
tational Linguistics, 19(3):501-530.
Hobbs, Jerry R. 1990. Literature and Cognition. CSLI
Lecture Notes Number 21.
Kamp, Hand and Uwe Reyle. 1993. From Discourse
to Logic: Introduction to ModelTheoretic Semantics
of Natural Language, Formal Logic and Discourse
Representation Theory. Kluwer Academic Publishers,
London, Boston, Dordrecht. Studies in Linguistics and
Philosophy, Volume 42.
Kintsch, Walter. 1977. On comprehending stories. In
Marcel Just and Patricia Carpenter, editors, Cognitive
processes in comprehension. Erlbaum, Hillsdale, New
Jersey.
Knott, Alistair. 1995. A Data-Driven Methodology for
Motivating a Set of Coherence Relations. Ph.D. thesis,
University of Edinburgh.
Lascarides, Alex and Nicholas Asher. 1993. Temporal
interpretation, discourse relations, and common sense
entailment. Linguistics and Philosophy, 16(5):437-
493.
Lascarides, Alex, Nicholas Asher, and Jon Oberlander.
1992. Inferring discourse relations in context. In Pro-
ceedings of the 30th Annual Meeting of the Association
for Computational Linguistics (ACL-92), pages 1-8.
Longacre, Robert E. 1983. The Grammar of Discourse.
Plenum Press, New York.
Mann, William C. and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243-281.
Marcu, Daniel. 1996. Building up rhetorical structure
trees. In Proceedings of the Thirteenth National Con-
ference on Artificial Intelligence (AAAI-96), volume 2,
pages 1069-1074, Portland, Oregon, August 4-8,.
Marcu, Daniel. 1997. The rhetorical parsing, sum-
marization, and generation of natural language texts.
Ph.D. thesis, Department of Computer Science, Uni-
versity of Toronto, Forthcoming.
Martin, James R. 1992. English Text. System and Struc-
ture. John Benjamin Publishing Company, Philadel-
phia/Amsterdam.
Moens, Marc and Mark Steedman. 1988. Temporal on-
tology and temporal reference. Computational Lin-
guistics, 14(2):15-28.
Moser, Megan and Johanna D. Moore. 1997. On the
correlation of cues with discourse structure: Results
from a corpus study. Submitted for publication.
Polanyi, Livia. 1988. A formal model of the structure of
discourse. Journal of Pragmatics, 12:601-638.
Priist, H., R. Scha, and M. van den Berg. 1994. Discourse
grammar and verb phrase anaphora. Linguistics and
Philosophy, 17(3):261-327, June.
Redeker, Gisela. 1990. Ideational and pragmatic markers
of discourse structure. Journal of Pragmatics, 14:367-
381.
Sanders, Ted J.M., Wilbert P.M. Spooren, and Leo G.M.
Noordman. 1992. Toward a taxonomy of coherence
relations. Discourse Processes, 15:1-35.
Schiffrin, Deborah. 1987. Discourse Markers. Cam-
bridge University Press.
Segal, Erwin M., Judith F. Duchan, and Paula J. Scott.
1991. The role of interclausal connectives in narrative
structuring: Evidence from adults&apos; interpretations of
simple stories. Discourse Processes, 14:27-54.
Sidner, Candace L. 1981. Focusing for interpretation of
pronouns. Computational Linguistics, 7(4):217-231,
October-December.
Sumita, K., K. Ono, T. Chino, T. Ukita, and S. Amano.
1992. A discourse structure analyzer for Japanese text.
In Proceedings of the International Conference on
Fifth Generation Computer Systems, volume 2, pages
1133-1140.
Van Dijk, Teun A. 1979. Pragmatic connectives. Journal
of Pragmatics, 3:447-456.
Webber, Bonnie L. 1988. Tense as discourse anaphor.
Computational Linguistics, 14(2):61-72, June.
</reference>
<page confidence="0.999299">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.903604">
<title confidence="0.999965">The Rhetorical Parsing of Natural Language Texts</title>
<author confidence="0.999883">Daniel Marcu</author>
<affiliation confidence="0.999972">Department of Computer Science University of Toronto</affiliation>
<address confidence="0.956855">Toronto, Ontario Canada M5S 3G4</address>
<email confidence="0.998979">marcuelcs.toronto.edu</email>
<abstract confidence="0.9989165">We derive the rhetorical structures of texts by means of two new, surface-form-based algorithms: one that identifies discourse usages of cue phrases and breaks sentences into clauses, and one that produces valid rhetorical structure trees for unrestricted natural language texts. The algorithms use information that was derived from a corpus analysis of cue phrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
</authors>
<title>Reference to Abstract Objects in Discourse.</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="974" citStr="Asher (1993)" startWordPosition="147" endWordPosition="148">and one that produces valid rhetorical structure trees for unrestricted natural language texts. The algorithms use information that was derived from a corpus analysis of cue phrases. 1 Introduction Researchers of natural language have repeatedly acknowledged that texts are not just a sequence of words nor even a sequence of clauses and sentences. However, despite the impressive number of discourse-related theories that have been proposed so far, there have emerged no algorithms capable of deriving the discourse structure of an unrestricted text. On one hand, efforts such as those described by Asher (1993), Lascarides, Asher, and Oberlander (1992), Kamp and Reyle (1993), Grover et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although th</context>
<context position="4575" citStr="Asher, 1993" startWordPosition="721" endWordPosition="722">rical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our atten</context>
</contexts>
<marker>Asher, 1993</marker>
<rawString>Asher, Nicholas. 1993. Reference to Abstract Objects in Discourse. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lee Ballard</author>
<author>Robert Conrad</author>
<author>Robert E Longacre</author>
</authors>
<title>The deep and surface grammar of interclausal relations. Foundations of language,</title>
<date>1971</date>
<pages>4--70</pages>
<contexts>
<context position="4845" citStr="Ballard, Conrad, and Longacre, 1971" startWordPosition="757" endWordPosition="761"> the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin</context>
</contexts>
<marker>Ballard, Conrad, Longacre, 1971</marker>
<rawString>Ballard, D. Lee, Robert Conrad, and Robert E. Longacre. 1971. The deep and surface grammar of interclausal relations. Foundations of language, 4:70-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Cahn</author>
</authors>
<title>An investigation into the correlation of cue phrases, unfilled pauses and the structuring of spoken discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the IRCS Workshop on Prosody in Natural Speech,</booktitle>
<pages>pages</pages>
<contexts>
<context position="5495" citStr="Cahn, 1992" startWordPosition="858" endWordPosition="859">79; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as &amp;quot;macroconnectors&amp;quot; between larger textual units. Therefore, we can use them as rhetorical indicators at any of the following levels: clause, sentence, paragraph, and text. • The number of discourse markers in a typical text — approximately one marker for every two clauses (Redeker, 1990) — is sufficiently large to enable the derivation of rich rhetorical structu</context>
</contexts>
<marker>Cahn, 1992</marker>
<rawString>Cahn, Janet. 1992. An investigation into the correlation of cue phrases, unfilled pauses and the structuring of spoken discourse. In Proceedings of the IRCS Workshop on Prosody in Natural Speech, pages 19-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cohen</author>
</authors>
<title>Analyzing the structure of argumentative discourse.</title>
<date>1987</date>
<journal>Computational Linguistics,13(1-2):</journal>
<pages>11--24</pages>
<contexts>
<context position="4957" citStr="Cohen, 1987" startWordPosition="777" endWordPosition="778">solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman,</context>
</contexts>
<marker>Cohen, 1987</marker>
<rawString>Cohen, Robin. 1987. Analyzing the structure of argumentative discourse. Computational Linguistics,13(1-2): 11-24, January-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Costermans</author>
<author>Michel Fayol</author>
</authors>
<date>1997</date>
<booktitle>Processing Interclausal Relationships. Studies in the Production and Comprehension of Text. Lawrence Erlbaum Associates,</booktitle>
<publisher>Publishers.</publisher>
<contexts>
<context position="5604" citStr="Costermans and Fayol, 1997" startWordPosition="871" endWordPosition="874">ders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as &amp;quot;macroconnectors&amp;quot; between larger textual units. Therefore, we can use them as rhetorical indicators at any of the following levels: clause, sentence, paragraph, and text. • The number of discourse markers in a typical text — approximately one marker for every two clauses (Redeker, 1990) — is sufficiently large to enable the derivation of rich rhetorical structures for texts. • Discourse markers are used in a manner that is consistent with the semantics and pragmatics </context>
</contexts>
<marker>Costermans, Fayol, 1997</marker>
<rawString>Costermans, Jean and Michel Fayol. 1997. Processing Interclausal Relationships. Studies in the Production and Comprehension of Text. Lawrence Erlbaum Associates, Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Cumming</author>
<author>Catherine McKercher</author>
</authors>
<title>The Canadian Reporter: News writing and reporting. Hartcourt Brace.</title>
<date>1994</date>
<contexts>
<context position="21976" citStr="Cumming and McKercher, 1994" startWordPosition="3574" endWordPosition="3577">cremental discourse building consists mostly of expansion of the right branches. In order to deal with the ambiguity of discourse, the rhetorical parser computes a weight for each valid discourse tree and retains only those that are maximal. The weight function reflects how skewed to the right a tree is. 4.2 The rhetorical parser in operation Consider the following text from the November 1996 issue of Scientific American (3). The words in italics denote the discourse markers, the square brackets denote &apos;In fact, journalists are trained to employ this &amp;quot;pyramid&amp;quot; approach to writing consciously (Cumming and McKercher, 1994). the boundaries of elementary textual units, and the curly brackets denote the boundaries of parenthetical textual units that were determined by the rhetorical parser (see Marcu (1997) for details); the numbers associated with the square brackets are identification labels. [With its distant orbit { — 50 percent farther from the sun than Earth —} and slim atmospheric blanket,&apos;] [Mars experiences frigid weather conditions.2] [Surface temperatures typically average about —60 degrees Celsius (-76 degrees Fahrenheit) at the equator and can dip to —123 degrees C near the poles.3] [Only the midday s</context>
</contexts>
<marker>Cumming, McKercher, 1994</marker>
<rawString>Cumming, Carmen and Catherine McKercher. 1994. The Canadian Reporter: News writing and reporting. Hartcourt Brace.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judy L Delin</author>
<author>Jon Oberlander</author>
</authors>
<title>Aspectswitching and subordination: the role of it-clefts in discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING92),</booktitle>
<pages>281--287</pages>
<location>Nantes, France,</location>
<contexts>
<context position="4770" citStr="Delin and Oberlander, 1992" startWordPosition="747" endWordPosition="750">roblems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts</context>
</contexts>
<marker>Delin, Oberlander, 1992</marker>
<rawString>Delin, Judy L. and Jon Oberlander. 1992. Aspectswitching and subordination: the role of it-clefts in discourse. In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING92), pages 281-287, Nantes, France, August 23-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Fraser</author>
</authors>
<title>Pragmatic markers.</title>
<date>1996</date>
<journal>Pragmatics,</journal>
<pages>6--2</pages>
<contexts>
<context position="5066" citStr="Fraser, 1996" startWordPosition="792" endWordPosition="793">cts. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by hum</context>
<context position="10788" citStr="Fraser, 1996" startWordPosition="1718" endWordPosition="1719">ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for markers such as and, which we considered to be highly ambiguous. Overall, we randomly selected more</context>
</contexts>
<marker>Fraser, 1996</marker>
<rawString>Fraser, Bruce. 1996. Pragmatic markers. Pragmatics, 6(2):167-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<contexts>
<context position="4729" citStr="Grosz, Joshi, and Weinstein, 1995" startWordPosition="741" endWordPosition="745">d discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203-226, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="1621" citStr="Grosz and Sidner (1986)" startWordPosition="246" endWordPosition="249"> Oberlander (1992), Kamp and Reyle (1993), Grover et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although the theories described by Grosz and Sidner (1986), Polanyi (1988), and Mann and Thompson (1988) are successfully applied manually, they are too informal to support an automatic approach to discourse analysis. In contrast with this previous work, the rhetorical parser that we present builds discourse trees for unrestricted texts. We first discuss the key concepts on which our approach relies (section 2) and the corpus analysis (section 3) that provides the empirical data for our rhetorical parsing algorithm. We discuss then an algorithm that recognizes discourse usages of cue phrases and that determines clause boundaries within sentences. Las</context>
<context position="4673" citStr="Grosz and Sidner, 1986" startWordPosition="733" endWordPosition="736">of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow </context>
<context position="10717" citStr="Grosz and Sidner, 1986" startWordPosition="1706" endWordPosition="1709">1) will be ruled out. For example, relation rhet_re/(ELABoRATIoN, 3, 1) will be ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for markers such as and, which w</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara J. and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204, July-September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Chris Brew</author>
<author>Suresh Manandhar</author>
<author>Marc Moens</author>
</authors>
<title>Priority union and generalization in discourse grammars.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for ComputationalLinguistics (ACL-94),</booktitle>
<pages>17--24</pages>
<location>Las Cruces,</location>
<contexts>
<context position="1061" citStr="Grover et al. (1994)" startWordPosition="158" endWordPosition="161"> language texts. The algorithms use information that was derived from a corpus analysis of cue phrases. 1 Introduction Researchers of natural language have repeatedly acknowledged that texts are not just a sequence of words nor even a sequence of clauses and sentences. However, despite the impressive number of discourse-related theories that have been proposed so far, there have emerged no algorithms capable of deriving the discourse structure of an unrestricted text. On one hand, efforts such as those described by Asher (1993), Lascarides, Asher, and Oberlander (1992), Kamp and Reyle (1993), Grover et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although the theories described by Grosz and Sidner (1986), Polanyi (1988), and Mann and Thompson </context>
</contexts>
<marker>Grover, Brew, Manandhar, Moens, 1994</marker>
<rawString>Grover, Claire, Chris Brew, Suresh Manandhar, and Marc Moens. 1994. Priority union and generalization in discourse grammars. In Proceedings of the 32nd Annual Meeting of the Association for ComputationalLinguistics (ACL-94), pages 17-24, Las Cruces, June 27-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>Rugaiya Hasan</author>
</authors>
<date>1976</date>
<note>Cohesion in English. Longman.</note>
<contexts>
<context position="4871" citStr="Halliday and Hasan, 1976" startWordPosition="762" endWordPosition="765"> relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and</context>
<context position="10693" citStr="Halliday and Hasan, 1976" startWordPosition="1702" endWordPosition="1705">rhet_re/(ELABoRATIoN , 3, 1) will be ruled out. For example, relation rhet_re/(ELABoRATIoN, 3, 1) will be ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for mark</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Halliday, Michael A.K. and Rugaiya Hasan. 1976. Cohesion in English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Dan I Moldovan</author>
</authors>
<title>A marker-propagation algorithm for text coherence.</title>
<date>1995</date>
<booktitle>In Working Notes of the Workshop on Parallel Processing in Artificial Intelligence,</booktitle>
<pages>76--86</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="30268" citStr="Harabagiu and Moldovan (1995)" startWordPosition="4938" endWordPosition="4941">at length the experiments from which the data presented above was derived in (Marcu, 1997). The rhetorical parser presented in this paper uses only the structural constraints that were enumerated in section 2. Co-relational constraints, focus, theme, anaphoric links, and other syntactic, semantic, and pragmatic factors do not yet play a role in our system, but we nevertheless expect them to reduce the number of valid discourse trees that can be associated with a text. We also expect that other robust methods for determining coherence relations between textual units, such as those described by Harabagiu and Moldovan (1995), will improve the accuracy of the routines that hypothesize the rhetorical relations that hold between adjacent units. We are not aware of the existence of any other rhetorical parser for English. However, Sumita et al. (1992) report on a discourse analyzer for Japanese. Even if one ignores some computational &amp;quot;bonuses&amp;quot; that can be easily exploited by a Japanese discourse analyzer (such as co-reference and topic identification), there are still some key differences between Sumita&apos;s work and ours. Particularly important is the fact that the theoretical foundations of Sumita et al.&apos;s analyzer do</context>
</contexts>
<marker>Harabagiu, Moldovan, 1995</marker>
<rawString>Harabagiu, Sanda M. and Dan I. Moldovan. 1995. A marker-propagation algorithm for text coherence. In Working Notes of the Workshop on Parallel Processing in Artificial Intelligence, pages 76-86, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Diane Litman</author>
</authors>
<title>Empirical studies on the disambiguation of cue phrases.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--3</pages>
<contexts>
<context position="5039" citStr="Hirschberg and Litman, 1993" startWordPosition="786" endWordPosition="789">ences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers a</context>
<context position="7270" citStr="Hirschberg and Litman, 1993" startWordPosition="1145" endWordPosition="1148">ure for that text. Given the above discussion, the immediate objection that one can raise is that discourse markers are doubly ambiguous: in some cases, their use is only sentential, i.e., they make a semantic contribution to the interpretation of a clause; and even in the cases where markers have a discourse usage, they are ambiguous with respect to the rhetorical relations that they mark and the sizes of the textual spans that they connect. We address now each of these objections in turn. Sentential and discourse usages of cue phrases. Empirical studies on the disambiguation of cue phrases (Hirschberg and Litman, 1993) have shown that just by considering the orthographic environment in which a discourse marker occurs, one can distinguish between sentential and discourse usages in about 80% of cases. We have taken Hirschberg and Litman&apos;s research one step further and designed a comprehensive corpus analysis that enabled us to improve their results and coverage. The method, procedure, and results of our corpus analysis are discussed in section 3. Discourse markers are ambiguous with respect to the rhetorical relations that they mark and the sizes of the units that they connect. When we began this research, no</context>
<context position="10760" citStr="Hirschberg and Litman, 1993" startWordPosition="1712" endWordPosition="1715">ation rhet_re/(ELABoRATIoN, 3, 1) will be ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for markers such as and, which we considered to be highly ambiguous. Overal</context>
</contexts>
<marker>Hirschberg, Litman, 1993</marker>
<rawString>Hirschberg, Julia and Diane Litman. 1993. Empirical studies on the disambiguation of cue phrases. Computational Linguistics, 19(3):501-530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Literature and Cognition.</title>
<date>1990</date>
<journal>CSLI Lecture Notes Number</journal>
<volume>21</volume>
<marker>Hobbs, 1990</marker>
<rawString>Hobbs, Jerry R. 1990. Literature and Cognition. CSLI Lecture Notes Number 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hand Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic: Introduction to ModelTheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
<date>1993</date>
<booktitle>Studies in Linguistics and Philosophy, Volume</booktitle>
<volume>42</volume>
<publisher>Kluwer Academic Publishers,</publisher>
<location>London, Boston, Dordrecht.</location>
<contexts>
<context position="1039" citStr="Kamp and Reyle (1993)" startWordPosition="154" endWordPosition="157">or unrestricted natural language texts. The algorithms use information that was derived from a corpus analysis of cue phrases. 1 Introduction Researchers of natural language have repeatedly acknowledged that texts are not just a sequence of words nor even a sequence of clauses and sentences. However, despite the impressive number of discourse-related theories that have been proposed so far, there have emerged no algorithms capable of deriving the discourse structure of an unrestricted text. On one hand, efforts such as those described by Asher (1993), Lascarides, Asher, and Oberlander (1992), Kamp and Reyle (1993), Grover et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although the theories described by Grosz and Sidner (1986), Polanyi (1988), </context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, Hand and Uwe Reyle. 1993. From Discourse to Logic: Introduction to ModelTheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer Academic Publishers, London, Boston, Dordrecht. Studies in Linguistics and Philosophy, Volume 42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
</authors>
<title>On comprehending stories.</title>
<date>1977</date>
<booktitle>Cognitive processes in comprehension. Erlbaum,</booktitle>
<editor>In Marcel Just and Patricia Carpenter, editors,</editor>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="5434" citStr="Kintsch, 1977" startWordPosition="849" endWordPosition="850">nrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as &amp;quot;macroconnectors&amp;quot; between larger textual units. Therefore, we can use them as rhetorical indicators at any of the following levels: clause, sentence, paragraph, and text. • The number of discourse markers in a typical text — approximately one marker for every two clauses (Redeker, 1990) — is sufficien</context>
</contexts>
<marker>Kintsch, 1977</marker>
<rawString>Kintsch, Walter. 1977. On comprehending stories. In Marcel Just and Patricia Carpenter, editors, Cognitive processes in comprehension. Erlbaum, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
</authors>
<title>A Data-Driven Methodology for Motivating a Set of Coherence Relations.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="5052" citStr="Knott, 1995" startWordPosition="790" endWordPosition="791">tical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistent</context>
<context position="10773" citStr="Knott, 1995" startWordPosition="1716" endWordPosition="1717">, 1) will be ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for markers such as and, which we considered to be highly ambiguous. Overall, we randoml</context>
</contexts>
<marker>Knott, 1995</marker>
<rawString>Knott, Alistair. 1995. A Data-Driven Methodology for Motivating a Set of Coherence Relations. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Lascarides</author>
<author>Nicholas Asher</author>
</authors>
<title>Temporal interpretation, discourse relations, and common sense entailment. Linguistics and Philosophy,</title>
<date>1993</date>
<pages>16--5</pages>
<contexts>
<context position="4575" citStr="Lascarides and Asher, 1993" startWordPosition="719" endWordPosition="722">lementary rhetorical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our atten</context>
</contexts>
<marker>Lascarides, Asher, 1993</marker>
<rawString>Lascarides, Alex and Nicholas Asher. 1993. Temporal interpretation, discourse relations, and common sense entailment. Linguistics and Philosophy, 16(5):437-493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Lascarides</author>
<author>Nicholas Asher</author>
<author>Jon Oberlander</author>
</authors>
<title>Inferring discourse relations in context.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92),</booktitle>
<pages>1--8</pages>
<marker>Lascarides, Asher, Oberlander, 1992</marker>
<rawString>Lascarides, Alex, Nicholas Asher, and Jon Oberlander. 1992. Inferring discourse relations in context. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92), pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Longacre</author>
</authors>
<title>The Grammar of Discourse.</title>
<date>1983</date>
<publisher>Plenum Press,</publisher>
<location>New York.</location>
<contexts>
<context position="4903" citStr="Longacre, 1983" startWordPosition="769" endWordPosition="770"> paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sander</context>
</contexts>
<marker>Longacre, 1983</marker>
<rawString>Longacre, Robert E. 1983. The Grammar of Discourse. Plenum Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text,</tech>
<pages>8--3</pages>
<contexts>
<context position="1667" citStr="Mann and Thompson (1988)" startWordPosition="253" endWordPosition="256">over et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although the theories described by Grosz and Sidner (1986), Polanyi (1988), and Mann and Thompson (1988) are successfully applied manually, they are too informal to support an automatic approach to discourse analysis. In contrast with this previous work, the rhetorical parser that we present builds discourse trees for unrestricted texts. We first discuss the key concepts on which our approach relies (section 2) and the corpus analysis (section 3) that provides the empirical data for our rhetorical parsing algorithm. We discuss then an algorithm that recognizes discourse usages of cue phrases and that determines clause boundaries within sentences. Lastly, we present the rhetorical parser and an e</context>
<context position="3836" citStr="Mann and Thompson, 1988" startWordPosition="595" endWordPosition="599">of the tree structure of a text, that relation also holds between the most important units of the constituent subspans. The most important units of a textual span are determined recursively: they correspond to the most important units of the immediate subspans when the relation that holds between these subspans is paratactic, and to the most important units of the nucleus subspan when the relation that holds between the immediate subspans is hypotactic. In our previous work (Marcu, 1996), we presented a complete axiomatization of these principles in the context of Rhetorical Structure Theory (Mann and Thompson, 1988) and we described an algorithm that, starting from the set of textual units that make up a text and the set of elementary rhetorical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicog</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann, William C. and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Building up rhetorical structure trees.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96),</booktitle>
<volume>2</volume>
<pages>1069--1074</pages>
<location>Portland, Oregon,</location>
<contexts>
<context position="3704" citStr="Marcu, 1996" startWordPosition="577" endWordPosition="578">The abstract structure of most texts is a binary, tree-like structure. 5. If a relation holds between two textual spans of the tree structure of a text, that relation also holds between the most important units of the constituent subspans. The most important units of a textual span are determined recursively: they correspond to the most important units of the immediate subspans when the relation that holds between these subspans is paratactic, and to the most important units of the nucleus subspan when the relation that holds between the immediate subspans is hypotactic. In our previous work (Marcu, 1996), we presented a complete axiomatization of these principles in the context of Rhetorical Structure Theory (Mann and Thompson, 1988) and we described an algorithm that, starting from the set of textual units that make up a text and the set of elementary rhetorical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show</context>
<context position="20613" citStr="Marcu, 1996" startWordPosition="3354" endWordPosition="3355">3% of the clause boundaries, with a precision of 90.3% (see table 2). We are not aware of any surface-form-based algorithms that achieve similar results. 4 Building up discourse trees 4.1 The rhetorical parsing algorithm The rhetorical parsing algorithm is outlined in figure 2. In the first step, the marker and clause identification algorithm is applied. Once the textual units are determined, the rhetorical parser uses the procedures derived from the corpus analysis to hypothesize rhetorical relations between the textual units. A constraint-satisfaction procedure similar to that described in (Marcu, 1996) then determines all the valid discourse trees (see (Marcu, 1997) for details). The rhetorical parsing algorithm has been fully implemented in C++. Discourse is ambiguous the same way sentences are: more than one discourse structure is usually produced for a text. In our experiments, we noticed, at least for English, that the &amp;quot;best&amp;quot; discourse trees are usually those that are skewed to the right. We believe that the explanation of this observation is that text processing is, essentially, a left-to-right process. Usually, people write texts so that the most important ideas go first, both at the </context>
</contexts>
<marker>Marcu, 1996</marker>
<rawString>Marcu, Daniel. 1996. Building up rhetorical structure trees. In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), volume 2, pages 1069-1074, Portland, Oregon, August 4-8,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The rhetorical parsing, summarization, and generation of natural language texts.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, University of Toronto, Forthcoming.</institution>
<contexts>
<context position="2456" citStr="Marcu, 1997" startWordPosition="376" endWordPosition="377"> we present builds discourse trees for unrestricted texts. We first discuss the key concepts on which our approach relies (section 2) and the corpus analysis (section 3) that provides the empirical data for our rhetorical parsing algorithm. We discuss then an algorithm that recognizes discourse usages of cue phrases and that determines clause boundaries within sentences. Lastly, we present the rhetorical parser and an example of its operation (section 4). 2 Foundation The mathematical foundations of the rhetorical parsing algorithm rely on a first-order formalization of valid text structures (Marcu, 1997). The assumptions of the formalization are the following. 1. The elementary units of complex text structures are non-overlapping spans of text. 2. Rhetorical, coherence, and cohesive relations hold between textual units of various sizes. 3. Relations can be partitioned into two classes: paratactic and hypotactic. Paratactic relations are those that hold between spans of equal importance. Hypotactic relations are those that hold between a span that is essential for the writer&apos;s purpose, i.e., a nucleus, and a span that increases the understanding of the nucleus but is not essential for the writ</context>
<context position="20678" citStr="Marcu, 1997" startWordPosition="3365" endWordPosition="3366"> 2). We are not aware of any surface-form-based algorithms that achieve similar results. 4 Building up discourse trees 4.1 The rhetorical parsing algorithm The rhetorical parsing algorithm is outlined in figure 2. In the first step, the marker and clause identification algorithm is applied. Once the textual units are determined, the rhetorical parser uses the procedures derived from the corpus analysis to hypothesize rhetorical relations between the textual units. A constraint-satisfaction procedure similar to that described in (Marcu, 1996) then determines all the valid discourse trees (see (Marcu, 1997) for details). The rhetorical parsing algorithm has been fully implemented in C++. Discourse is ambiguous the same way sentences are: more than one discourse structure is usually produced for a text. In our experiments, we noticed, at least for English, that the &amp;quot;best&amp;quot; discourse trees are usually those that are skewed to the right. We believe that the explanation of this observation is that text processing is, essentially, a left-to-right process. Usually, people write texts so that the most important ideas go first, both at the paragraph and at the text level.&apos; The more text writers add, the </context>
<context position="22161" citStr="Marcu (1997)" startWordPosition="3603" endWordPosition="3604">and retains only those that are maximal. The weight function reflects how skewed to the right a tree is. 4.2 The rhetorical parser in operation Consider the following text from the November 1996 issue of Scientific American (3). The words in italics denote the discourse markers, the square brackets denote &apos;In fact, journalists are trained to employ this &amp;quot;pyramid&amp;quot; approach to writing consciously (Cumming and McKercher, 1994). the boundaries of elementary textual units, and the curly brackets denote the boundaries of parenthetical textual units that were determined by the rhetorical parser (see Marcu (1997) for details); the numbers associated with the square brackets are identification labels. [With its distant orbit { — 50 percent farther from the sun than Earth —} and slim atmospheric blanket,&apos;] [Mars experiences frigid weather conditions.2] [Surface temperatures typically average about —60 degrees Celsius (-76 degrees Fahrenheit) at the equator and can dip to —123 degrees C near the poles.3] [Only the midday sun at tropical latitudes is warm enough to thaw ice on occasion,/ [but any liquid water formed in this way would evaporate almost instantly5] [because of the low atmospheric pressure.6]</context>
<context position="29729" citStr="Marcu, 1997" startWordPosition="4853" endWordPosition="4854">aluated the impact that our trees could have on the task of summarizing text. A summarization program that uses the rhetorical parser described here recalled 66% of the sentences considered important by 13 judges in the same five texts, with a precision of 68%. In contrast, a random procedure recalled, on average, only 38.4% of the sentences considered important by the judges, with a precision of 38.4%. And the Microsoft Office 97 summarizer recalled 41% of the important sentences with a precision of 39%. We discuss at length the experiments from which the data presented above was derived in (Marcu, 1997). The rhetorical parser presented in this paper uses only the structural constraints that were enumerated in section 2. Co-relational constraints, focus, theme, anaphoric links, and other syntactic, semantic, and pragmatic factors do not yet play a role in our system, but we nevertheless expect them to reduce the number of valid discourse trees that can be associated with a text. We also expect that other robust methods for determining coherence relations between textual units, such as those described by Harabagiu and Moldovan (1995), will improve the accuracy of the routines that hypothesize </context>
<context position="32222" citStr="Marcu, 1997" startWordPosition="5260" endWordPosition="5261">urse trees that we build are very constrained structures (see section 2): as a consequence, we do not overgenerate invalid trees as Sumita et al. do. Furthermore, we use only surface-based methods for determining the markers and textual units and use clauses as the minimal units of the discourse trees. In contrast, Sumita et al. use deep syntactic and semantic processing techniques for determining the markers and the textual units and use sentences as minimal units in the discourse structures that they build. A detailed comparison of our work with Sumita et al.&apos;s and others&apos; work is given in (Marcu, 1997). 5 Conclusion We introduced the notion of rhetorical parsing, i.e., the process through which natural language texts are automatically mapped into discourse trees. In order to make rhetorical parsing work, we improved previous algorithms for cue phrase disambiguation, and proposed new algorithms for determining the elementary textual units and for computing the valid discourse trees of a text. The solution that we described is both general and robust. Acknowledgements. This research would have not been possible without the help of Graeme Hirst; there are no right words to thank him for it. I </context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Marcu, Daniel. 1997. The rhetorical parsing, summarization, and generation of natural language texts. Ph.D. thesis, Department of Computer Science, University of Toronto, Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Martin</author>
</authors>
<title>English Text. System and Structure.</title>
<date>1992</date>
<publisher>John Benjamin Publishing Company, Philadelphia/Amsterdam.</publisher>
<contexts>
<context position="10731" citStr="Martin, 1992" startWordPosition="1710" endWordPosition="1711">r example, relation rhet_re/(ELABoRATIoN, 3, 1) will be ruled 97 1 2 Figure 1: The discourse tree of text (1). out because unit 1 is not an important unit for span [1,2] and, as mentioned at the beginning of this section, a rhetorical relation that holds between two spans of a valid text structure must also hold between their most important units: the important unit of span [1,2] is unit 2, i.e., the nucleus of the relation r het fel(cONCESSION , 1,2). 3 A corpus analysis of discourse markers 3.1 Materials We used previous work on cue phrases (Halliday and Hasan, 1976; Grosz and Sidner, 1986; Martin, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996) to create an initial set of more than 450 potential discourse markers. For each potential discourse marker, we then used an automatic procedure that extracted from the Brown corpus a set of text fragments. Each text fragment contained a &amp;quot;window&amp;quot; of approximately 200 words and an emphasized occurrence of a marker. On average, we randomly selected approximately 19 text fragments per marker, having few texts for the markers that do not occur very often in the corpus and up to 60 text fragments for markers such as and, which we considered t</context>
</contexts>
<marker>Martin, 1992</marker>
<rawString>Martin, James R. 1992. English Text. System and Structure. John Benjamin Publishing Company, Philadelphia/Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
<author>Mark Steedman</author>
</authors>
<title>Temporal ontology and temporal reference.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<contexts>
<context position="4532" citStr="Moens and Steedman, 1988" startWordPosition="713" endWordPosition="716">its that make up a text and the set of elementary rhetorical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investiga</context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>Moens, Marc and Mark Steedman. 1988. Temporal ontology and temporal reference. Computational Linguistics, 14(2):15-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megan Moser</author>
<author>Johanna D Moore</author>
</authors>
<title>On the correlation of cues with discourse structure: Results from a corpus study.</title>
<date>1997</date>
<note>Submitted for publication.</note>
<contexts>
<context position="5090" citStr="Moser and Moore, 1997" startWordPosition="794" endWordPosition="797">tructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by human subjects both as cohe</context>
</contexts>
<marker>Moser, Moore, 1997</marker>
<rawString>Moser, Megan and Johanna D. Moore. 1997. On the correlation of cues with discourse structure: Results from a corpus study. Submitted for publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
</authors>
<title>A formal model of the structure of discourse.</title>
<date>1988</date>
<journal>Journal of Pragmatics,</journal>
<pages>12--601</pages>
<contexts>
<context position="1637" citStr="Polanyi (1988)" startWordPosition="250" endWordPosition="251">and Reyle (1993), Grover et al. (1994), and PrUst, Scha, and van den Berg (1994) take the position that discourse structures can be built only in conjunction with fully specified clause and sentence structures. And Hobbs&apos;s theory (1990) assumes that sophisticated knowledge bases and inference mechanisms are needed for determining the relations between discourse units. Despite the formal elegance of these approaches, they are very domain dependent and, therefore, unable to handle more than a few restricted examples. On the other hand, although the theories described by Grosz and Sidner (1986), Polanyi (1988), and Mann and Thompson (1988) are successfully applied manually, they are too informal to support an automatic approach to discourse analysis. In contrast with this previous work, the rhetorical parser that we present builds discourse trees for unrestricted texts. We first discuss the key concepts on which our approach relies (section 2) and the corpus analysis (section 3) that provides the empirical data for our rhetorical parsing algorithm. We discuss then an algorithm that recognizes discourse usages of cue phrases and that determines clause boundaries within sentences. Lastly, we present </context>
</contexts>
<marker>Polanyi, 1988</marker>
<rawString>Polanyi, Livia. 1988. A formal model of the structure of discourse. Journal of Pragmatics, 12:601-638.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Priist</author>
<author>R Scha</author>
<author>M van den Berg</author>
</authors>
<title>Discourse grammar and verb phrase anaphora. Linguistics and Philosophy,</title>
<date>1994</date>
<pages>17--3</pages>
<marker>Priist, Scha, van den Berg, 1994</marker>
<rawString>Priist, H., R. Scha, and M. van den Berg. 1994. Discourse grammar and verb phrase anaphora. Linguistics and Philosophy, 17(3):261-327, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gisela Redeker</author>
</authors>
<title>Ideational and pragmatic markers of discourse structure.</title>
<date>1990</date>
<journal>Journal of Pragmatics,</journal>
<pages>14--367</pages>
<contexts>
<context position="4972" citStr="Redeker, 1990" startWordPosition="779" endWordPosition="780"> both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1</context>
</contexts>
<marker>Redeker, 1990</marker>
<rawString>Redeker, Gisela. 1990. Ideational and pragmatic markers of discourse structure. Journal of Pragmatics, 14:367-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted J M Sanders</author>
<author>Wilbert P M Spooren</author>
<author>Leo G M Noordman</author>
</authors>
<title>Toward a taxonomy of coherence relations.</title>
<date>1992</date>
<booktitle>Discourse Processes,</booktitle>
<pages>15--1</pages>
<contexts>
<context position="5010" citStr="Sanders, Spooren, and Noordman, 1992" startWordPosition="781" endWordPosition="785">problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has s</context>
</contexts>
<marker>Sanders, Spooren, Noordman, 1992</marker>
<rawString>Sanders, Ted J.M., Wilbert P.M. Spooren, and Leo G.M. Noordman. 1992. Toward a taxonomy of coherence relations. Discourse Processes, 15:1-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deborah Schiffrin</author>
</authors>
<title>Discourse Markers.</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4944" citStr="Schiffrin, 1987" startWordPosition="775" endWordPosition="776">loit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschber</context>
</contexts>
<marker>Schiffrin, 1987</marker>
<rawString>Schiffrin, Deborah. 1987. Discourse Markers. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin M Segal</author>
<author>Judith F Duchan</author>
<author>Paula J Scott</author>
</authors>
<title>The role of interclausal connectives in narrative structuring: Evidence from adults&apos; interpretations of simple stories.</title>
<date>1991</date>
<booktitle>Discourse Processes,</booktitle>
<pages>14--27</pages>
<contexts>
<context position="5483" citStr="Segal, Duchan, and Scott, 1991" startWordPosition="853" endWordPosition="857">ay and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural language texts. The intuition behind our choice relies on the following facts: • Psycholinguistic and other empirical research (Kintsch, 1977; Schiffrin, 1987; Segal, Duchan, and Scott, 1991; Cahn, 1992; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993: Knott, 1995; Costermans and Fayol, 1997) has shown that discourse markers are consistently used by human subjects both as cohesive ties between adjacent clauses and as &amp;quot;macroconnectors&amp;quot; between larger textual units. Therefore, we can use them as rhetorical indicators at any of the following levels: clause, sentence, paragraph, and text. • The number of discourse markers in a typical text — approximately one marker for every two clauses (Redeker, 1990) — is sufficiently large to enable the derivation of rich rhetor</context>
</contexts>
<marker>Segal, Duchan, Scott, 1991</marker>
<rawString>Segal, Erwin M., Judith F. Duchan, and Paula J. Scott. 1991. The role of interclausal connectives in narrative structuring: Evidence from adults&apos; interpretations of simple stories. Discourse Processes, 14:27-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Focusing for interpretation of pronouns.</title>
<date>1981</date>
<journal>Computational Linguistics,</journal>
<pages>7--4</pages>
<contexts>
<context position="4649" citStr="Sidner, 1981" startWordPosition="731" endWordPosition="732">scourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can b</context>
</contexts>
<marker>Sidner, 1981</marker>
<rawString>Sidner, Candace L. 1981. Focusing for interpretation of pronouns. Computational Linguistics, 7(4):217-231, October-December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sumita</author>
<author>K Ono</author>
<author>T Chino</author>
<author>T Ukita</author>
<author>S Amano</author>
</authors>
<title>A discourse structure analyzer for Japanese text.</title>
<date>1992</date>
<booktitle>In Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<volume>2</volume>
<pages>1133--1140</pages>
<contexts>
<context position="4694" citStr="Sumita et al., 1992" startWordPosition="737" endWordPosition="740">ly, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we can get by focusing our attention only on discourse markers and lexicogrammatical constructs that can be detected by a shallow analysis of natural l</context>
<context position="30495" citStr="Sumita et al. (1992)" startWordPosition="4975" endWordPosition="4978"> focus, theme, anaphoric links, and other syntactic, semantic, and pragmatic factors do not yet play a role in our system, but we nevertheless expect them to reduce the number of valid discourse trees that can be associated with a text. We also expect that other robust methods for determining coherence relations between textual units, such as those described by Harabagiu and Moldovan (1995), will improve the accuracy of the routines that hypothesize the rhetorical relations that hold between adjacent units. We are not aware of the existence of any other rhetorical parser for English. However, Sumita et al. (1992) report on a discourse analyzer for Japanese. Even if one ignores some computational &amp;quot;bonuses&amp;quot; that can be easily exploited by a Japanese discourse analyzer (such as co-reference and topic identification), there are still some key differences between Sumita&apos;s work and ours. Particularly important is the fact that the theoretical foundations of Sumita et al.&apos;s analyzer do not seem to be able to accommodate the ambiguity of discourse markers: in their are independent of each other, against the alternative hypothesis that the rank of a variable is correlated with the rank of another variable. The</context>
</contexts>
<marker>Sumita, Ono, Chino, Ukita, Amano, 1992</marker>
<rawString>Sumita, K., K. Ono, T. Chino, T. Ukita, and S. Amano. 1992. A discourse structure analyzer for Japanese text. In Proceedings of the International Conference on Fifth Generation Computer Systems, volume 2, pages 1133-1140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teun A Van Dijk</author>
</authors>
<title>Pragmatic connectives.</title>
<date>1979</date>
<journal>Journal of Pragmatics,</journal>
<pages>3--447</pages>
<marker>Van Dijk, 1979</marker>
<rawString>Van Dijk, Teun A. 1979. Pragmatic connectives. Journal of Pragmatics, 3:447-456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie L Webber</author>
</authors>
<title>Tense as discourse anaphor.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<contexts>
<context position="4546" citStr="Webber, 1988" startWordPosition="717" endWordPosition="718">d the set of elementary rhetorical relations that hold between these units, can derive all the valid discourse trees of that text. Consequently, if one is to build discourse trees for unrestricted texts, the problems that remain to be solved are the automatic determination of the textual units and the rhetorical relations that hold between them. In this paper, we show how one can find and exploit approximate solutions for both of these problems by capitalizing on the occurrences of certain lexicogrammatical constructs. Such constructs can include tense 96 and aspect (Moens and Steedman, 1988; Webber, 1988; Lascarides and Asher, 1993), certain patterns of pronominalization and anaphoric usages (Sidner, 1981; Grosz and Sidner, 1986; Sumita et al., 1992; Grosz, Joshi, and Weinstein, 1995), it-clefts (Delin and Oberlander, 1992), and discourse markers or cue phrases (Ballard, Conrad, and Longacre, 1971; Halliday and Hasan, 1976; Van Dijk, 1979; Longacre, 1983; Grosz and Sidner, 1986; Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders, Spooren, and Noordman, 1992; Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996; Moser and Moore, 1997). In the work described here, we investigate how far we </context>
</contexts>
<marker>Webber, 1988</marker>
<rawString>Webber, Bonnie L. 1988. Tense as discourse anaphor. Computational Linguistics, 14(2):61-72, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>