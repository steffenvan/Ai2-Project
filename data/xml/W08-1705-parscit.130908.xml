<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.98794">
Speeding up LFG Parsing Using C-Structure Pruning
</title>
<author confidence="0.988143">
Aoife Cahill$ John T. Maxwell III† Paul Meurer§ Christian Rohrer$ Victoria Ros´en¶
</author>
<affiliation confidence="0.81623325">
$IMS, University of Stuttgart, Germany, {cahillae, rohrer}@ims.uni-stuttgart.de
†Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304, maxwell@parc.com
§Unifob Aksis, Bergen, Norway, paul.meurer@aksis.uib.no
¶Unifob Aksis and University of Bergen, Norway, victoria@uib.no
</affiliation>
<sectionHeader confidence="0.991125" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999451153846154">
In this paper we present a method for
greatly reducing parse times in LFG pars-
ing, while at the same time maintaining
parse accuracy. We evaluate the method-
ology on data from English, German and
Norwegian and show that the same pat-
terns hold across languages. We achieve
a speedup of 67% on the English data and
49% on the German data. On a small
amount of data for Norwegian, we achieve
a speedup of 40%, although with more
training data we expect this figure to in-
crease.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999890277777778">
Efficient parsing of large amounts of natural lan-
guage is extremely important for any real-world
application. The XLE Parsing System is a large-
scale, hand-crafted, deep, unification-based sys-
tem that processes raw text and produces both
constituent structures (phrase structure trees) and
feature structures (dependency attribute-value ma-
trices). A typical breakdown of parsing time
of XLE components with the English grammar
is Morphology (1.6%), Chart (5.8%) and Unifier
(92.6%). It is clear that the major bottleneck in
processing is in unification. Cahill et al. (2007)
carried out a preliminary experiment to test the
theory that if fewer c-structures were passed to
the unifier, overall parsing times would improve,
while the accuracy of parsing would remain sta-
ble. Their experiments used state-of-the-art prob-
abilistic treebank-based parsers to automatically
</bodyText>
<note confidence="0.723278">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.967329333333333">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999133807692308">
mark certain constituents on the input sentences,
limiting the number of c-structures the XLE pars-
ing system would build. They achieved an 18%
speedup in parse times, while maintaining the ac-
curacy of the output f-structures. The experiments
presented in Cahill et al. (2007) used the XLE sys-
tem as a black box and did not make any changes to
it. However, the results were encouraging enough
for a c-structure pruning mechanism to be fully in-
tegrated into the XLE system.
The paper is structured as follows: we present
the pruning model that has been integrated into the
XLE system (Section 2), and how it can be ap-
plied successfully to more than one language. We
present experiments for English (Section 3), Ger-
man (Section 4) and Norwegian (Section 5) show-
ing that for both German and English, a significant
improvement in speed is achieved, while the qual-
ity of the f-structures remains stable. For Norwe-
gian a speedup is also achieved, but more training
data is required to sustain the accuracy of the f-
structures. In Section 7 we present an error anal-
ysis on the German data. We then relate the work
presented in this paper to similar efficient parsing
strategies (Section 8) before concluding in Section
9.
</bodyText>
<sectionHeader confidence="0.9050685" genericHeader="introduction">
2 XLE and the C-Structure Pruning
Mechanism
</sectionHeader>
<bodyText confidence="0.997960888888889">
The XLE system is designed to deal with large
amounts of data in a robust manner. There are
several mechanisms which facilitate this, including
fragmenting and skimming. Fragmenting is called
when the grammar is unable to provide a complete
parse for the input sentence, and a fragment anal-
ysis of largest possible chunks is built. Skimming
is called when too much time or memory has been
used by XLE. Any constituents that have not been
</bodyText>
<page confidence="0.990318">
33
</page>
<note confidence="0.849109">
Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 33–40
Manchester, August 2008
</note>
<bodyText confidence="0.999960470588235">
fully processed are “skimmed”, which means that
the amount of work carried out in processing the
constituent is limited. This guarantees that XLE
will finish processing the sentence in polynomial
time.
XLE uses a chart-based mechanism for build-
ing parses, and has been complemented with a c-
structure pruning mechanism to speed up parsing
time. During pruning, subtrees at a particular cell
in the chart are pruned if their probabilities are not
higher than a certain threshold. The chart pruner
uses a simple stochastic CFG model. The proba-
bility of a tree is the product of the probabilities
of each of the rules used to form the tree, includ-
ing the rules that lead to lexical items (such as N
→ dog). The probability of a rule is basically the
number of times that that particular form of the
rule occurs in the training data divided by the num-
ber of times the rule’s category occurs in the train-
ing data, plus a smoothing term. This is similar
to the pruning described in Charniak and Johnson
(2005) where edges in a coarse-grained parse for-
est are pruned to allow full evaluation with fine-
grained categories.
The pruner prunes at the level of individual con-
stituents in the chart. It calculates the probabil-
ities of each of the subtrees of a constituent and
compares them. The probability of each subtree
is compared with the best subtree probability for
that constituent. If a subtree’s probability is lower
than the best probability by a given factor, then the
subtree is pruned. In practice, the threshold is the
natural logarithm of the factor used. So a value of
5 means that a subtree will be pruned if its prob-
ability is about a factor of 150 less than the best
probability.
If two different subtrees have different num-
bers of morphemes under them, then the proba-
bility model is biased towards the subtree that has
fewer morphemes (since there are fewer probabil-
ities multiplied together). XLE counteracts this by
normalizing the probabilities based on the differ-
ence in length.
To illustrate how this works, we give the follow-
ing example. The string Fruitflies like bananas has
two different analyses. Figures 1 and 2 give their
analyses along with hypothetical probabilities for
each rule.
These two analyses come together at the S con-
stituent that spans the whole sentence. The proba-
bility of the first analysis is 8.4375E-14. The prob-
</bodyText>
<figure confidence="0.962097">
S
V
like N
bananas
NP VP 0.5000
N N 0.1500
Fruit 0.0010
flies 0.0015
V NP 0.2000
like 0.0050
N 0.5000
bananas 0.0015
8.4375E-14
</figure>
<figureCaption confidence="0.9849515">
Figure 1: Analysis (1) for the string Fruitflies like
bananas with hypothetical probabilities
</figureCaption>
<figure confidence="0.9712046">
bananas
S NP VP 0.5000
NP N 0.5000
N Fruit 0.0010
V flies 0.0025
VP V PP 0.1000
P like 0.0500
PP P NP 0.9000
NP bananas 0.0015
4.21875E-12
</figure>
<figureCaption confidence="0.965205">
Figure 2: Analysis (2) for the string Fruitflies like
bananas with hypothetical probabilities
</figureCaption>
<bodyText confidence="0.999747666666667">
ability of the second analysis is 4.21875E-12. This
means that the probability of the second analysis
is 50 times higher than the probability of the first
analysis. If the threshold is less than the natural
logarithm of 50 (about 3.9), then the subtree of the
first analysis will be pruned from the S constituent.
</bodyText>
<sectionHeader confidence="0.994579" genericHeader="method">
3 Experiments on English
</sectionHeader>
<bodyText confidence="0.999396428571429">
We carried out a number of parsing experiments to
test the effect of c-structure pruning, both in terms
of time and accuracy. We trained the c-structure
pruning algorithm on the standard sections of Penn
Treebank Wall Street Journal Text (Marcus et al.,
1994). The training data consists of the original
WSJ strings, marked up with some of the Penn
</bodyText>
<figure confidence="0.995494407407408">
like
N
S
NP
N
Fruit
V
flies
VP
P
NP
PP
NP
VP
N
Fruit
flies
N
NP
S
NP
N
N
VP
V
NP
N
</figure>
<page confidence="0.994151">
34
</page>
<bodyText confidence="0.999966285714286">
Treebank constituent information. We marked up
NPs and SBARs as well as adjective and verbal
POS categories. This is meant to guide the train-
ing process, so that it does learn from parses that
are not compatible with the original treebank anal-
ysis. We evaluated against the PARC 700 Depen-
dency Bank (King et al., 2003), splitting it into 140
sentences as development data and the remaining
unseen 560 for final testing (as in Kaplan et al.
(2004)). We experimented with different values
of the pruning cutoff on the development set; the
results are given in Table 1.
The results show that the lower the cutoff value,
the quicker the sentences can be parsed. Using
a cutoff of 4, the development sentences can be
parsed in 100 CPU seconds, while with a cutoff
of 10, the same experiment takes 182 seconds.
With no cutoff, the experiment takes 288 CPU sec-
onds. However, this increase in speed comes at a
price. The number of fragment parses increases,
i.e. there are more sentences that fail to be analyzed
with a complete spanning parse. With no pruning,
the number of fragment parses is 23, while with
the most aggressive pruning factor of 4, there are
39 fragment parses. There are also many more
skimmed sentences with no c-structure pruning,
which impacts negatively on the results. The ora-
cle f-score with no pruning is 83.07, but with prun-
ing (at all thresholds) the oracle f-score is higher.
This is due to less skimming when pruning is acti-
vated, since the more subtrees that are pruned, the
less likely the XLE system is to run over the time
or memory limits needed to trigger skimming.
Having established that a cutoff of 5 performs
best on the development data, we carried out the
final evaluation on the 560-sentence test set using
this cutoff. The results are given in Table 2. There
is a 67% speedup in parsing the 560 sentences, and
the most probable f-score increases significantly
from 79.93 to 82.83. The oracle f-score also in-
creases, while there is a decrease in the random f-
score. This shows that we are throwing away good
solutions during pruning, but that overall the re-
sults improve. Part of this again is due to the fact
that with no pruning, skimming is triggered much
more often. With a pruning factor of 5, there are
no skimmed sentences. There is also one sentence
that timed out with no pruning, which also lowers
the most probable and oracle f-scores.
</bodyText>
<table confidence="0.9995965">
Pruning Level None 5
Total Time 1204 392
Most Probable F-Score 79.93 82.83
Oracle F-Score 84.75 87.79
Random F-Score 75.47 74.31
# Fragment Parses 96 91
# Time Outs 1 0
# Skimmed Sents 33 0
</table>
<tableCaption confidence="0.998244">
Table 2: Results of c-structure pruning experi-
ments on English test data
</tableCaption>
<sectionHeader confidence="0.966936" genericHeader="method">
4 Experiments on German
</sectionHeader>
<bodyText confidence="0.999995176470588">
We carried out a similar set of experiments on
German data to test whether the methodology de-
scribed above ported to a language other than En-
glish. In the case of German, the typical time of
XLE components is: Morphology (22.5%), Chart
(3.5%) and Unifier (74%). As training data we
used the TIGER corpus (Brants et al., 2002). Set-
ting aside 2000 sentences for development and
testing, we used the remaining 48,474 sentences as
training data. In order to create the partially brack-
eted input required for training, we converted the
original TIGER graphs into Penn-style trees with
empty nodes and retained bracketed constituents of
the type NP, S, PN and AP. The training data was
parsed by the German ParGram LFG (Rohrer and
Forst, 2006). This resulted in 25,677 full parses,
21,279 fragmented parses and 1,518 parse fail-
ures.1 There are 52,959 features in the final prun-
ing model.
To establish the optimal pruning settings for
German, we split the 2,000 saved sentences into
371 development sentences and 1495 test sen-
tences for final evaluation. We evaluated against
the TiGer Dependency Bank (Forst et al., 2004)
(TiGerDB), a dependency-based gold standard for
German parsers that encodes grammatical rela-
tions similar to, though more fine-grained than,
the ones in the TIGER Treebank as well as mor-
phosyntactic features. We experimented with the
same pruning levels as in the English experiments.
The results are given in Table 3.
The results on the development set show a sim-
ilar trend to the English results. A cutoff of 4 re-
sults in the fastest system, however at the expense
</bodyText>
<footnote confidence="0.995604333333333">
1The reason there are more fragment parses than, for ex-
ample, the results reported in Rohrer and Forst (2006) is that
the bracketed input constrains the parser to only return parses
compatible with the bracketed input. If there is no solution
compatible with the brackets, then a fragment parse is re-
turned.
</footnote>
<page confidence="0.986354">
35
</page>
<table confidence="0.999936">
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 83.07 84.50 85.47 85.75 85.57 85.57 85.02 84.10
Time (CPU seconds) 288 100 109 123 132 151 156 182
# Time Outs 0 0 0 0 0 0 0
# Fragments 23 39 36 31 29 27 27 24
# Skimmed Sents 8 0 0 1 1 1 1 3
</table>
<tableCaption confidence="0.99689">
Table 1: Results of c-structure pruning experiments on English development data
</tableCaption>
<table confidence="0.9999692">
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 83.69 83.45 84.02 82.86 82.82 82.95 83.03 82.81
Time (CPU seconds) 1313 331 465 871 962 1151 1168 1163
# Time Outs 6 0 0 5 5 5 5 6
# Fragments 65 104 93 81 74 73 73 68
</table>
<tableCaption confidence="0.99646">
Table 3: Results of c-structure pruning experiments on German development data
</tableCaption>
<table confidence="0.999963571428571">
Pruning Level None 5
Total Time 3300 1655
Most Probable F-Score 82.63 82.73
Oracle F-Score 84.96 84.79
Random F-Score 73.58 73.72
# Fragment Parses 324 381
# Time Outs 2 2
</table>
<tableCaption confidence="0.9892995">
Table 4: Results of c-structure pruning experi-
ments on German test data
</tableCaption>
<bodyText confidence="0.999085533333333">
of accuracy. A cutoff of 5 seems to provide the
best tradeoff between time and accuracy. Again,
most of the gain in oracle f-score is due to fewer
timeouts, rather than improved f-structures. In the
German development set, a cutoff of 5 leads to a
speedup of over 64% and a small increase in or-
acle f-score of 0.33 points. Therefore, for the fi-
nal evaluation on the unseen test-set, we choose a
cutoff of 5. The results are given in Table 4. We
achieve a speedup of 49% and a non-significant in-
crease in most probable f-score of 0.094. The time
spent by the system on morphology is much higher
for German than for English. If we only take the
unification stage of the process into account, the
German experiments show a speedup of 65.5%.
</bodyText>
<sectionHeader confidence="0.994573" genericHeader="method">
5 Experiments on Norwegian
</sectionHeader>
<bodyText confidence="0.999704488888889">
As there is no treebank currently available for Nor-
wegian, we were unable to train the c-structure
pruning mechanism for Norwegian in the same
way as was done for English and German. There
is, however, some LFG-parsed data that has been
completely disambiguated using the techniques
described in Ros´en et al. (2006). In total there
are 937 sentences from various text genres includ-
ing Norwegian hiking guides, Sophie’s World and
the Norwegian Wikipedia. We also use this dis-
ambiguated data as a gold standard for evaluation.
The typical time of XLE components with the Nor-
wegian grammar is: Morphology (1.6%), Chart
(11.2%) and Unifier (87.2%).
From the disambiguated text, we can automati-
cally extract partially bracketed sentences as input
to the c-structure pruning training method. We can
also extract sentences for training that are partially
disambiguated, but these cannot be used as part of
the test data. To do this, we extract the bracketed
string for each solution. If all the solutions pro-
duce the same bracketed string, then this is added
to the training data. This results in an average of
4556 features. As the data set is small, we do not
split it into development, training and test sections
as was done for English and German. Instead we
carry out a 10-fold cross validation over the entire
set. The results for each pruning level are given in
Table 5.
The results in Table 5 show that the pattern that
held for English and German does not quite hold
for Norwegian. While, as expected, the time taken
to parse the test set is greatly reduced when using
c-structure pruning, there is also a negative impact
on the quality of the f-structures. One reason for
this is that there are now sentences that could pre-
viously be parsed, and that now no longer can be
parsed, even with a fragment grammar.2 With c-
structure pruning, the number of fragment parses
increases for all thresholds, apart from 10. It is
also difficult to compare the Norwegian experi-
ment to the English and German, since the gold
standard is constrained to only consist of sentences
that can be parsed by the grammar. Theoretically
the oracle f-score for the experiment with no prun-
</bodyText>
<footnote confidence="0.882809">
2With an extended fragment grammar, this would not hap-
pen.
</footnote>
<page confidence="0.996077">
36
</page>
<table confidence="0.999883166666667">
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 98.76 94.45 95.60 96.40 96.90 97.52 98.00 98.33
Time (CPU seconds) 218.8 106.2 107.4 109.3 112 116.2 124 130.7
# Time Outs 0 0 0 0 0 0 0 0
# Parse Failures 0.2 5.7 3.9 2 3.2 4.2 4.6 4.2
# Fragments 1.3 7.7 6.5 4.7 2.8 1.8 1.5 1.2
</table>
<tableCaption confidence="0.999402">
Table 5: Results of c-structure pruning 10-fold cross validation experiments on Norwegian data
</tableCaption>
<figureCaption confidence="0.977585">
Figure 3: The lower-bound results for each of the
10 cross validation runs across the thresholds
</figureCaption>
<bodyText confidence="0.999841307692308">
ing should be 100. The slight drop is due to a
slightly different morphological analyzer used in
the final experiments that treats compound nouns
differently. A threshold of 10 gives the best results,
with a speedup of 40% and a drop in f-score of 0.43
points. It is difficult to choose the “best” thresh-
old, as the amount of training data is probably not
enough to get an accurate picture of the data. For
example, Figure 3 shows the lower-bound results
for each of the 10 runs. It is difficult to see a clear
pattern for all the runs, indicating that the amount
of training data is probably not enough for a reli-
able experiment.
</bodyText>
<sectionHeader confidence="0.913057" genericHeader="method">
6 Size of Training Data Corpus
</sectionHeader>
<bodyText confidence="0.999982157894737">
The size of the Norwegian training corpus is con-
siderably smaller than the training corpora for En-
glish or German, so the question remains how
much training data we need in order for the c-
structure pruning to deliver reliable results. In or-
der to establish a rough estimate for the size of
training corpus required, we carried out an experi-
ment on the German TIGER training corpus.
We randomly divided the TIGER training cor-
pus into sets of 500 sentences. We plot the learn-
ing curve of the c-structure pruning mechanism in
Figure 4, examining the effect of increasing the
size of the training corpus on the oracle f-score on
the development set of 371 sentences. The curve
shows that, for the German data, the highest oracle
f-score of 84.98 was achieved with a training cor-
pus of 32,000 sentences. Although the curve fluc-
tuates, the general trend is that the more training
data, the better the oracle f-score.3
</bodyText>
<sectionHeader confidence="0.998605" genericHeader="method">
7 Error Analysis
</sectionHeader>
<bodyText confidence="0.99911975">
Given that we are removing some subtrees during
parsing, it can sometimes happen that the desired
analysis gets pruned. We will take German as an
example, and look at some of these cases.
</bodyText>
<subsectionHeader confidence="0.8567665">
7.1 Separable particles vs pronominal
adverbs
</subsectionHeader>
<bodyText confidence="0.999965263157895">
The word dagegen (“against it”) can be a separable
prefix (VPART) or a pronominal adverb (PADV).
The verb protestieren (“to protest”) does not take
dagegen as separable prefix. The verb stimmen
(“to agree”) however does. If we parse the sen-
tence in (1) with the verb protestieren and activate
pruning, we do not get a complete parse. If we
parse the same sentence with stimmen as in (2) we
do get a complete parse. If we replace dagegen
by daf¨ur, which in the current version of the Ger-
man LFG can only be a pronominal adverb, the
sentence in (3) gets a parse. We also notice that
if we parse a sentence, as in (4), where dagegen
occurs in a position where our grammar does not
allow separable prefixes to occur, we get a com-
plete parse for the sentence. These examples show
that the pruning mechanism has learned to prune
the separable prefix reading of words that can be
both separable prefixes and pronominal adverbs.
</bodyText>
<table confidence="0.683654333333333">
(1) Sie protestieren dagegen.
they protest against-it
‘They protest against it.’
(2) Sie stimmen dagegen.
they vote against-it
‘They vote against it.’
</table>
<footnote confidence="0.506931714285714">
3Unexpectedly, the curve begins to decline after 32,000
sentences. However, the differences in f-score are not statis-
tically significant (using the approximate randomization test).
Running the same experiment with a different random seed
results in a similarly shaped graph, but any decline in f-score
when training on more data was not statistically significant at
the 99% level.
</footnote>
<page confidence="0.392818">
95
</page>
<figure confidence="0.983241888888889">
90
85
80
75
70
65
60
55
None 4 5 6 7 8 9 10
</figure>
<page confidence="0.556409">
37
</page>
<figure confidence="0.998468785714286">
F-Score
84.9
84.8
84.7
84.6
84.5
84.4
84.3
84.2
84.1
85
84
32000, 84.97698
Number of Training Sentences
</figure>
<figureCaption confidence="0.999807">
Figure 4: The effect of increasing the size of the training data on the oracle f-score
</figureCaption>
<bodyText confidence="0.640336666666667">
(3) Er protestiert daf¨ur. (6) Das Morden will nicht enden.
he protests for-it the murdering wants not end
‘He protests in favour of it.’ ‘The murdering does not want to end.’
(4) Dagegen protestiert er. (7) Das Arbeiten endet.
against-it protests he the working ends
‘Against it, he protests.’
</bodyText>
<subsectionHeader confidence="0.995263">
7.2 Derived nominal vs non-derived nominal
</subsectionHeader>
<bodyText confidence="0.98098475">
The word Morden can be the dative plural of the
noun Mord (“murder”) or the nominalized form of
the verb morden (“to murder”). With c-structure
pruning activated (at level 5), the nominalized
reading, as in (6), gets pruned, whereas the dative
plural reading is not (5). At pruning level 6, both
readings are assigned a full parse. We see simi-
lar pruning of nominalized readings as in (7). If
we look in more detail at the raw counts for re-
lated subtrees gathered from the training data, we
see that the common noun reading for Morden oc-
curs 156 times, while the nominalized reading only
occurs three times. With more training data, the c-
structure pruning mechanism could possibly learn
when to prune correctly in such cases.
‘The operation ends.’
</bodyText>
<subsectionHeader confidence="0.8837885">
7.3 Personal pronouns which also function as
determiners
</subsectionHeader>
<bodyText confidence="0.999694777777778">
There are a number of words in German that can
function both as personal pronouns and determin-
ers. If we take, for example, the word ihr, which
can mean “her”, “their”, “to-her”, “you-pl” etc.,
the reading as a determiner gets pruned as well as
some occurrences as a pronoun. In example (8),
we get a complete parse for the sentence with the
dative pronoun reading of ihr. However, in ex-
ample (9), the determiner reading is pruned and
we fail to get a complete parse. In example (10),
we also fail to get a complete parse, but in exam-
ple (11), we do get a complete parse. There is a
parameter we can set that sets a confidence value
in certain tags. So, for example, we set the con-
fidence value of INFL-F BASE[det] (the tag given
to the determiner reading of personal pronouns) to
be 0.5, which says that we are 50% confident that
the tag INFL-F BASE[det] is correct. This results in
</bodyText>
<listItem confidence="0.500664">
(5) Er
</listItem>
<bodyText confidence="0.684482833333333">
he
redet
speaks
von Morden.
of murders
‘He speaks of murders.’
</bodyText>
<page confidence="0.998233">
38
</page>
<bodyText confidence="0.926889">
examples 8, 9 and 11 receiving a complete parse,
with the pruning threshold set to 5.
</bodyText>
<figure confidence="0.436895666666667">
(8) Er
he
‘He gives it to her.’
(9) Ihr
her/their
‘Her/Their car drives.
</figure>
<bodyText confidence="0.9996475">
pruning. We automatically extracted a specialized
corpus of 31,845 sentences from the Huge Ger-
man Corpus. This corpus is a collection of 200
million words of newspaper and other text. The
sentences we extracted all contained examples of
proper noun coordination and had been automati-
cally chunked. Training on this sub-corpus as well
as the original TIGER training data did have the
desired effect of now parsing example (13) with
c-structure pruning activated.
</bodyText>
<figure confidence="0.972550125">
es
it
ihr.
her
gibt
gives
Auto
car
f¨ahrt.
drives
(10) Ihr
you(pl)
kommt.
come
8 Related Work
‘You come.’
</figure>
<bodyText confidence="0.530094">
(11) Er vertraut ihr.
he trusts her
‘He trusts her.’
</bodyText>
<subsectionHeader confidence="0.996866">
7.4 Coordination of Proper Nouns
</subsectionHeader>
<bodyText confidence="0.999647933333333">
Training the German c-structure pruning mecha-
nism on the TIGER treebank resulted in a pecu-
liar phenomenon when parsing coordinated proper
nouns. If we parse four coordinated proper nouns
with c-structure pruning activated as in (12), we
get a complete parse. However, as soon as we add
a fifth proper noun as in (13), we get a fragment
parse. This is only the case with proper nouns,
since the sentence in (14) which coordinates com-
mon nouns gets a complete parse. Interestingly, if
we coordinate n proper nouns plus one common
noun, we also get a complete parse. The reason for
this is that proper noun coordination is less com-
mon than common noun coordination in our train-
ing set.
</bodyText>
<reference confidence="0.976561230769231">
(12) Hans, Fritz, Emil und Maria singen.
‘Hans, Fritz, Emil and Maria sing.’
(13) Hans, Fritz, Emil, Walter und Maria sin-
gen.
‘Hans, Fritz, Emil, Walter and Maria sing.’
(14) Hunde, Katzen, Esel, Pferde und Affen
kommen.
‘Dogs, cats, donkeys, horses and apes
come.’
(15) Hans, Fritz, Emil, Walter, Maria und
Kinder singen.
‘Hans, Fritz, Emil, Walter, Maria and chil-
dren sing.’
</reference>
<bodyText confidence="0.99990865">
We ran a further experiment to test what effect
adding targeted training data had on c-structure
Ninomiya et al. (2005) investigate beam threshold-
ing based on the local width to improve the speed
of a probabilistic HPSG parser. In each cell of a
CYK chart, the method keeps only a portion of the
edges which have higher figure of merits compared
to the other edges in the same cell. In particular,
each cell keeps the edges whose figure of merit is
greater than αmax - δ, where αmax is the high-
est figure of merit among the edges in the chart.
The term “beam thresholding” is a little confusing,
since a beam search is not necessary – instead, the
CYK chart is pruned directly. For this reason, we
prefer the term “chart pruning” instead.
Clark and Curran (2007) describe the use of
a supertagger with a CCG parser. A supertag-
ger is like a tagger but with subcategorization in-
formation included. Chart pruners and supertag-
gers are conceptually complementary, since chart
pruners prune edges with the same span and the
same category, whereas supertaggers prune (lexi-
cal) edges with the same span and different cate-
gories. Ninomiya et al. (2005) showed that com-
bining a chunk parser with beam thresholding pro-
duced better results than either technique alone. So
adding a supertagger should improve the results
described in this paper.
Zhang et al. (2007) describe a technique to
selectively unpack an HPSG parse forest to ap-
ply maximum entropy features and get the n-best
parses. XLE already does something similar when
it applies maximum entropy features to get the
n-best feature structures after having obtained a
packed representation of all of the valid feature
structures. The current paper shows that pruning
the c-structure chart before doing (packed) unifica-
tion speeds up the process of getting a packed rep-
resentation of all the valid feature structures (ex-
cept the ones that may have been pruned).
</bodyText>
<page confidence="0.999125">
39
</page>
<sectionHeader confidence="0.997658" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999838307692308">
In this paper we have presented a c-structure prun-
ing mechanism which has been integrated into the
XLE LFG parsing system. By pruning the number
of c-structures built in the chart, the next stage of
processing, the unifier, has considerably less work
to do. This results in a speedup of 67% for En-
glish, 49% for German and 40% for Norwegian.
The amount of training data for Norwegian was
much less than that for English or German, there-
fore further work is required to fully investigate
the effect of c-structure pruning. However, the re-
sults, even from the small training data, were en-
couraging and show the same general patterns as
English and German. We showed that for the Ger-
man training data, 32,000 sentences was the opti-
mal number in order to achieve the highest oracle
f-score. There remains some work to be done in
tuning the parameters for the c-structure pruning,
as our error analysis shows. Of course, with sta-
tistical methods one can never be guaranteed that
the correct parse will be produced; however we can
adjust the parameters to account for known prob-
lems. We have shown that the c-structure pruning
mechanism described is an efficient way of reduc-
ing parse times, while maintaining the accuracy of
the overall system.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999861666666667">
The work presented in this paper was supported
by the COINS project as part of the linguistic
Collaborative Research Centre (SFB 732) at the
University of Stuttgart and by the Norwegian Re-
search Council through the LOGON and TREPIL
projects.
</bodyText>
<sectionHeader confidence="0.999275" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999813014705882">
Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
Treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories, Sozopol, Bulgaria.
Cahill, Aoife, Tracy Holloway King, and John T.
Maxwell III. 2007. Pruning the Search Space of
a Hand-Crafted Parsing System with a Probabilistic
Parser. In ACL 2007 Workshop on Deep Linguistic
Processing, pages 65–72, Prague, Czech Republic,
June. Association for Computational Linguistics.
Charniak, Eugene and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL’05), pages 173–180, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Clark, Stephen and James R. Curran. 2007. Wide-
Coverage Efficient Statistical Parsing with CCG and
Log-Linear Models. Computational Linguistics,
33(4):493–552.
Forst, Martin, N´uria Bertomeu, Berthold Crysmann,
Frederik Fouvry, Silvia Hansen-Schirra, and Valia
Kordoni. 2004. Towards a dependency-based gold
standard for German parsers – The TiGer Depen-
dency Bank. In Proceedings of the COLING Work-
shop on Linguistically Interpreted Corpora (LINC
’04), Geneva, Switzerland.
Kaplan, Ronald M., John T. Maxwell, Tracy H. King,
and Richard Crouch. 2004. Integrating Finite-state
Technology with Deep LFG Grammars. In Pro-
ceedings of the ESSLLI 2004 Workshop on Combin-
ing Shallow and Deep Processing for NLP, Nancy,
France.
King, Tracy Holloway, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ronald M. Kaplan. 2003. The
PARC 700 Dependency Bank. In Proceedings of the
EACL Workshop on Linguistically Interpreted Cor-
pora (LINC ’03), Budapest, Hungary.
Marcus, Mitchell P., Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a Large Annotated
Corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313–330.
Ninomiya, Takashi, Yoshimasa Tsuruoka, Yusuke
Miyao, and Jun’ichi Tsujii. 2005. Efficacy of Beam
Thresholding, Unification Filtering and Hybrid Pars-
ing in Probabilistic HPSG Parsing. In Proceed-
ings of the Ninth International Workshop on Pars-
ing Technology, pages 103–114, Vancouver, British
Columbia, October. Association for Computational
Linguistics.
Rohrer, Christian and Martin Forst. 2006. Improving
Coverage and Parsing Quality of a Large-scale LFG
for German. In Proceedings of the Language Re-
sources and Evaluation Conference (LREC-2006),
Genoa, Italy.
Ros´en, Victoria, Paul Meurer, and Koenraad de Smedt.
2006. Towards a Toolkit Linking Treebanking and
Grammar Development. In Hajic, Jan and Joakim
Nivre, editors, Proceedings of the Fifth Workshop
on Treebanks and Linguistic Theories, pages 55–66,
December.
Zhang, Yi, Stephan Oepen, and John Carroll. 2007.
Efficiency in Unification-Based N-Best Parsing. In
Proceedings of the Tenth International Conference
on Parsing Technologies, pages 48–59, Prague,
Czech Republic, June. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.998635">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.385822">
<title confidence="0.999941">Speeding up LFG Parsing Using C-Structure Pruning</title>
<author confidence="0.999538">T Maxwell</author>
<affiliation confidence="0.9999">University of Stuttgart, Germany,</affiliation>
<address confidence="0.774641333333333">Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304, Aksis, Bergen, Norway, Aksis and University of Bergen, Norway,</address>
<abstract confidence="0.990868285714286">In this paper we present a method for greatly reducing parse times in LFG parsing, while at the same time maintaining parse accuracy. We evaluate the methodology on data from English, German and Norwegian and show that the same patterns hold across languages. We achieve a speedup of 67% on the English data and 49% on the German data. On a small amount of data for Norwegian, we achieve a speedup of 40%, although with more training data we expect this figure to increase.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Fritz Hans</author>
</authors>
<title>Emil und Maria singen.</title>
<location>Hans, Fritz, Emil and Maria sing.’</location>
<marker>Hans, </marker>
<rawString>(12) Hans, Fritz, Emil und Maria singen. ‘Hans, Fritz, Emil and Maria sing.’</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fritz Hans</author>
</authors>
<location>Emil, Walter und Maria singen.</location>
<marker>Hans, </marker>
<rawString>(13) Hans, Fritz, Emil, Walter und Maria singen.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fritz ‘Hans</author>
<author>Emil</author>
</authors>
<institution>Walter and Maria sing.’</institution>
<marker>‘Hans, Emil, </marker>
<rawString>‘Hans, Fritz, Emil, Walter and Maria sing.’</rawString>
</citation>
<citation valid="false">
<authors>
<author>Katzen Hunde</author>
</authors>
<title>Esel, Pferde und Affen kommen.</title>
<marker>Hunde, </marker>
<rawString>(14) Hunde, Katzen, Esel, Pferde und Affen kommen.</rawString>
</citation>
<citation valid="false">
<authors>
<author>cats ‘Dogs</author>
</authors>
<title>donkeys, horses and apes come.’</title>
<marker>‘Dogs, </marker>
<rawString>‘Dogs, cats, donkeys, horses and apes come.’</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fritz Hans</author>
</authors>
<location>Emil, Walter, Maria und Kinder singen.</location>
<marker>Hans, </marker>
<rawString>(15) Hans, Fritz, Emil, Walter, Maria und Kinder singen.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fritz ‘Hans</author>
</authors>
<location>Emil, Walter, Maria</location>
<note>and children sing.’</note>
<marker>‘Hans, </marker>
<rawString>‘Hans, Fritz, Emil, Walter, Maria and children sing.’</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER Treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="10354" citStr="Brants et al., 2002" startWordPosition="1751" endWordPosition="1754">scores. Pruning Level None 5 Total Time 1204 392 Most Probable F-Score 79.93 82.83 Oracle F-Score 84.75 87.79 Random F-Score 75.47 74.31 # Fragment Parses 96 91 # Time Outs 1 0 # Skimmed Sents 33 0 Table 2: Results of c-structure pruning experiments on English test data 4 Experiments on German We carried out a similar set of experiments on German data to test whether the methodology described above ported to a language other than English. In the case of German, the typical time of XLE components is: Morphology (22.5%), Chart (3.5%) and Unifier (74%). As training data we used the TIGER corpus (Brants et al., 2002). Setting aside 2000 sentences for development and testing, we used the remaining 48,474 sentences as training data. In order to create the partially bracketed input required for training, we converted the original TIGER graphs into Penn-style trees with empty nodes and retained bracketed constituents of the type NP, S, PN and AP. The training data was parsed by the German ParGram LFG (Rohrer and Forst, 2006). This resulted in 25,677 full parses, 21,279 fragmented parses and 1,518 parse failures.1 There are 52,959 features in the final pruning model. To establish the optimal pruning settings f</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER Treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Tracy Holloway King</author>
<author>John T Maxwell</author>
</authors>
<title>Pruning the Search Space of a Hand-Crafted Parsing System with a Probabilistic Parser.</title>
<date>2007</date>
<booktitle>In ACL 2007 Workshop on Deep Linguistic Processing,</booktitle>
<pages>65--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1493" citStr="Cahill et al. (2007)" startWordPosition="224" endWordPosition="227">expect this figure to increase. 1 Introduction Efficient parsing of large amounts of natural language is extremely important for any real-world application. The XLE Parsing System is a largescale, hand-crafted, deep, unification-based system that processes raw text and produces both constituent structures (phrase structure trees) and feature structures (dependency attribute-value matrices). A typical breakdown of parsing time of XLE components with the English grammar is Morphology (1.6%), Chart (5.8%) and Unifier (92.6%). It is clear that the major bottleneck in processing is in unification. Cahill et al. (2007) carried out a preliminary experiment to test the theory that if fewer c-structures were passed to the unifier, overall parsing times would improve, while the accuracy of parsing would remain stable. Their experiments used state-of-the-art probabilistic treebank-based parsers to automatically © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. mark certain constituents on the input sentences, limiting the number of c-structures the XLE parsing system would build. They a</context>
</contexts>
<marker>Cahill, King, Maxwell, 2007</marker>
<rawString>Cahill, Aoife, Tracy Holloway King, and John T. Maxwell III. 2007. Pruning the Search Space of a Hand-Crafted Parsing System with a Probabilistic Parser. In ACL 2007 Workshop on Deep Linguistic Processing, pages 65–72, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4784" citStr="Charniak and Johnson (2005)" startWordPosition="769" endWordPosition="772">articular cell in the chart are pruned if their probabilities are not higher than a certain threshold. The chart pruner uses a simple stochastic CFG model. The probability of a tree is the product of the probabilities of each of the rules used to form the tree, including the rules that lead to lexical items (such as N → dog). The probability of a rule is basically the number of times that that particular form of the rule occurs in the training data divided by the number of times the rule’s category occurs in the training data, plus a smoothing term. This is similar to the pruning described in Charniak and Johnson (2005) where edges in a coarse-grained parse forest are pruned to allow full evaluation with finegrained categories. The pruner prunes at the level of individual constituents in the chart. It calculates the probabilities of each of the subtrees of a constituent and compares them. The probability of each subtree is compared with the best subtree probability for that constituent. If a subtree’s probability is lower than the best probability by a given factor, then the subtree is pruned. In practice, the threshold is the natural logarithm of the factor used. So a value of 5 means that a subtree will be</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Charniak, Eugene and Mark Johnson. 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 173–180, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, Stephen and James R. Curran. 2007. WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Forst</author>
<author>N´uria Bertomeu</author>
<author>Berthold Crysmann</author>
<author>Frederik Fouvry</author>
<author>Silvia Hansen-Schirra</author>
<author>Valia Kordoni</author>
</authors>
<title>Towards a dependency-based gold standard for German parsers – The TiGer Dependency Bank.</title>
<date>2004</date>
<booktitle>In Proceedings of the COLING Workshop on Linguistically Interpreted Corpora (LINC ’04),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="11144" citStr="Forst et al., 2004" startWordPosition="1880" endWordPosition="1883">red for training, we converted the original TIGER graphs into Penn-style trees with empty nodes and retained bracketed constituents of the type NP, S, PN and AP. The training data was parsed by the German ParGram LFG (Rohrer and Forst, 2006). This resulted in 25,677 full parses, 21,279 fragmented parses and 1,518 parse failures.1 There are 52,959 features in the final pruning model. To establish the optimal pruning settings for German, we split the 2,000 saved sentences into 371 development sentences and 1495 test sentences for final evaluation. We evaluated against the TiGer Dependency Bank (Forst et al., 2004) (TiGerDB), a dependency-based gold standard for German parsers that encodes grammatical relations similar to, though more fine-grained than, the ones in the TIGER Treebank as well as morphosyntactic features. We experimented with the same pruning levels as in the English experiments. The results are given in Table 3. The results on the development set show a similar trend to the English results. A cutoff of 4 results in the fastest system, however at the expense 1The reason there are more fragment parses than, for example, the results reported in Rohrer and Forst (2006) is that the bracketed </context>
</contexts>
<marker>Forst, Bertomeu, Crysmann, Fouvry, Hansen-Schirra, Kordoni, 2004</marker>
<rawString>Forst, Martin, N´uria Bertomeu, Berthold Crysmann, Frederik Fouvry, Silvia Hansen-Schirra, and Valia Kordoni. 2004. Towards a dependency-based gold standard for German parsers – The TiGer Dependency Bank. In Proceedings of the COLING Workshop on Linguistically Interpreted Corpora (LINC ’04), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>John T Maxwell</author>
<author>Tracy H King</author>
<author>Richard Crouch</author>
</authors>
<title>Integrating Finite-state Technology with Deep LFG Grammars.</title>
<date>2004</date>
<booktitle>In Proceedings of the ESSLLI 2004 Workshop on Combining Shallow and Deep Processing for NLP,</booktitle>
<location>Nancy, France.</location>
<contexts>
<context position="7806" citStr="Kaplan et al. (2004)" startWordPosition="1300" endWordPosition="1303">The training data consists of the original WSJ strings, marked up with some of the Penn like N S NP N Fruit V flies VP P NP PP NP VP N Fruit flies N NP S NP N N VP V NP N 34 Treebank constituent information. We marked up NPs and SBARs as well as adjective and verbal POS categories. This is meant to guide the training process, so that it does learn from parses that are not compatible with the original treebank analysis. We evaluated against the PARC 700 Dependency Bank (King et al., 2003), splitting it into 140 sentences as development data and the remaining unseen 560 for final testing (as in Kaplan et al. (2004)). We experimented with different values of the pruning cutoff on the development set; the results are given in Table 1. The results show that the lower the cutoff value, the quicker the sentences can be parsed. Using a cutoff of 4, the development sentences can be parsed in 100 CPU seconds, while with a cutoff of 10, the same experiment takes 182 seconds. With no cutoff, the experiment takes 288 CPU seconds. However, this increase in speed comes at a price. The number of fragment parses increases, i.e. there are more sentences that fail to be analyzed with a complete spanning parse. With no p</context>
</contexts>
<marker>Kaplan, Maxwell, King, Crouch, 2004</marker>
<rawString>Kaplan, Ronald M., John T. Maxwell, Tracy H. King, and Richard Crouch. 2004. Integrating Finite-state Technology with Deep LFG Grammars. In Proceedings of the ESSLLI 2004 Workshop on Combining Shallow and Deep Processing for NLP, Nancy, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy Holloway King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The PARC 700 Dependency Bank.</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL Workshop on Linguistically Interpreted Corpora (LINC ’03),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="7678" citStr="King et al., 2003" startWordPosition="1278" endWordPosition="1281">d the c-structure pruning algorithm on the standard sections of Penn Treebank Wall Street Journal Text (Marcus et al., 1994). The training data consists of the original WSJ strings, marked up with some of the Penn like N S NP N Fruit V flies VP P NP PP NP VP N Fruit flies N NP S NP N N VP V NP N 34 Treebank constituent information. We marked up NPs and SBARs as well as adjective and verbal POS categories. This is meant to guide the training process, so that it does learn from parses that are not compatible with the original treebank analysis. We evaluated against the PARC 700 Dependency Bank (King et al., 2003), splitting it into 140 sentences as development data and the remaining unseen 560 for final testing (as in Kaplan et al. (2004)). We experimented with different values of the pruning cutoff on the development set; the results are given in Table 1. The results show that the lower the cutoff value, the quicker the sentences can be parsed. Using a cutoff of 4, the development sentences can be parsed in 100 CPU seconds, while with a cutoff of 10, the same experiment takes 182 seconds. With no cutoff, the experiment takes 288 CPU seconds. However, this increase in speed comes at a price. The numbe</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>King, Tracy Holloway, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald M. Kaplan. 2003. The PARC 700 Dependency Bank. In Proceedings of the EACL Workshop on Linguistically Interpreted Corpora (LINC ’03), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1994</date>
<contexts>
<context position="7184" citStr="Marcus et al., 1994" startWordPosition="1178" endWordPosition="1181">hetical probabilities ability of the second analysis is 4.21875E-12. This means that the probability of the second analysis is 50 times higher than the probability of the first analysis. If the threshold is less than the natural logarithm of 50 (about 3.9), then the subtree of the first analysis will be pruned from the S constituent. 3 Experiments on English We carried out a number of parsing experiments to test the effect of c-structure pruning, both in terms of time and accuracy. We trained the c-structure pruning algorithm on the standard sections of Penn Treebank Wall Street Journal Text (Marcus et al., 1994). The training data consists of the original WSJ strings, marked up with some of the Penn like N S NP N Fruit V flies VP P NP PP NP VP N Fruit flies N NP S NP N N VP V NP N 34 Treebank constituent information. We marked up NPs and SBARs as well as adjective and verbal POS categories. This is meant to guide the training process, so that it does learn from parses that are not compatible with the original treebank analysis. We evaluated against the PARC 700 Dependency Bank (King et al., 2003), splitting it into 140 sentences as development data and the remaining unseen 560 for final testing (as i</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Ninomiya</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Efficacy of Beam Thresholding, Unification Filtering and Hybrid Parsing in Probabilistic HPSG Parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth International Workshop on Parsing Technology,</booktitle>
<pages>103--114</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia,</location>
<marker>Ninomiya, Tsuruoka, Miyao, Tsujii, 2005</marker>
<rawString>Ninomiya, Takashi, Yoshimasa Tsuruoka, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Efficacy of Beam Thresholding, Unification Filtering and Hybrid Parsing in Probabilistic HPSG Parsing. In Proceedings of the Ninth International Workshop on Parsing Technology, pages 103–114, Vancouver, British Columbia, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Rohrer</author>
<author>Martin Forst</author>
</authors>
<title>Improving Coverage and Parsing Quality of a Large-scale LFG for German.</title>
<date>2006</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC-2006),</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="10766" citStr="Rohrer and Forst, 2006" startWordPosition="1819" endWordPosition="1822">to a language other than English. In the case of German, the typical time of XLE components is: Morphology (22.5%), Chart (3.5%) and Unifier (74%). As training data we used the TIGER corpus (Brants et al., 2002). Setting aside 2000 sentences for development and testing, we used the remaining 48,474 sentences as training data. In order to create the partially bracketed input required for training, we converted the original TIGER graphs into Penn-style trees with empty nodes and retained bracketed constituents of the type NP, S, PN and AP. The training data was parsed by the German ParGram LFG (Rohrer and Forst, 2006). This resulted in 25,677 full parses, 21,279 fragmented parses and 1,518 parse failures.1 There are 52,959 features in the final pruning model. To establish the optimal pruning settings for German, we split the 2,000 saved sentences into 371 development sentences and 1495 test sentences for final evaluation. We evaluated against the TiGer Dependency Bank (Forst et al., 2004) (TiGerDB), a dependency-based gold standard for German parsers that encodes grammatical relations similar to, though more fine-grained than, the ones in the TIGER Treebank as well as morphosyntactic features. We experimen</context>
</contexts>
<marker>Rohrer, Forst, 2006</marker>
<rawString>Rohrer, Christian and Martin Forst. 2006. Improving Coverage and Parsing Quality of a Large-scale LFG for German. In Proceedings of the Language Resources and Evaluation Conference (LREC-2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Ros´en</author>
<author>Paul Meurer</author>
<author>Koenraad de Smedt</author>
</authors>
<title>Towards a Toolkit Linking Treebanking and Grammar Development.</title>
<date>2006</date>
<booktitle>Proceedings of the Fifth Workshop on Treebanks and Linguistic Theories,</booktitle>
<pages>55--66</pages>
<editor>In Hajic, Jan and Joakim Nivre, editors,</editor>
<marker>Ros´en, Meurer, de Smedt, 2006</marker>
<rawString>Ros´en, Victoria, Paul Meurer, and Koenraad de Smedt. 2006. Towards a Toolkit Linking Treebanking and Grammar Development. In Hajic, Jan and Joakim Nivre, editors, Proceedings of the Fifth Workshop on Treebanks and Linguistic Theories, pages 55–66, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Stephan Oepen</author>
<author>John Carroll</author>
</authors>
<title>Efficiency in Unification-Based N-Best Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the Tenth International Conference on Parsing Technologies,</booktitle>
<pages>48--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Zhang, Oepen, Carroll, 2007</marker>
<rawString>Zhang, Yi, Stephan Oepen, and John Carroll. 2007. Efficiency in Unification-Based N-Best Parsing. In Proceedings of the Tenth International Conference on Parsing Technologies, pages 48–59, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>