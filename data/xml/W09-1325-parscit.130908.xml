<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.242671">
<title confidence="0.981332">
Semantic Annotation of Papers: Interface &amp; Enrichment Tool (SAPIENT)
</title>
<author confidence="0.999327">
Maria Liakata†, Claire Q††, Larisa N. Soldatova†††
</author>
<affiliation confidence="0.9991245">
Department of Computer Science
University of Wales, Aberystwyth
</affiliation>
<address confidence="0.904826">
SY23 3DB UK
</address>
<email confidence="0.994818">
†mal@aber.ac.uk, ††ceq08@aber.ac.uk, †††lss@aber.ac.uk
</email>
<sectionHeader confidence="0.998647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995584647058824">
In this paper we introduce a web application
(SAPIENT) for sentence based annotation of
full papers with semantic information. SAPI-
ENT enables experts to annotate scientific pa-
pers sentence by sentence and also to link re-
lated sentences together, thus forming spans
of interesting regions, which can facilitate text
mining applications. As part of the system,
we developed an XML-aware sentence split-
ter (SSSplit) which preserves XML markup
and identifies sentences through the addition
of in-line markup. SAPIENT has been used
in a systematic study for the annotation of
scientific papers with concepts representing
the Core Information about Scientific Papers
(CISP) to create a corpus of 225 annotated pa-
pers.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999000769230769">
Given the rapid growth in the quantity of scientific
literature, particularly in the Biosciences, there is
an increasing need to work with full papers rather
than abstracts, both to identify their key contribu-
tions and to provide some automated assistance to
researchers (Karamanis et al., 2008; Medlock and
Briscoe, 2007). Initiatives like OTMI1, which aim
to make full papers available to researchers for text
mining purposes is further evidence that relying
solely on abstracts presents important limitations for
such tasks. A recent study on whether information
retrieval from full text is more effective than search-
ing abstracts alone (Lin Jimmy, 2009) showed that
</bodyText>
<footnote confidence="0.959632">
1http://opentextmining.org/wiki/Main Page
</footnote>
<bodyText confidence="0.99968396875">
the former is indeed the case. Their experimental re-
sults suggested that span-level analysis is a promis-
ing strategy for taking advantage of the full papers,
where spans are defined as paragraphs of text as-
sessed by humans and deemed to be relevant to one
of 36 pre-defined topics. Therefore, when working
with full papers, it is important to be able to iden-
tify and annotate spans of text. In previous research,
sentence based annotation has been used to identify
text regions with scientific content of interest to the
user (Wilbur et al., 2006; Shatkay et al., 2008) or
zones of different rhetorical status (AZ) (Teufel and
Moens, 2002). Sentences are the structural units of
paragraphs and can be more flexible than paragraphs
for text mining purposes other than information re-
trieval.
Current general purpose systems for linguistic an-
notation such as Callisto2 allow the creation of a
simple annotation schema that is a tag set augmented
with simple (e.g. string) attributes for each tag.
Knowtator (Ogren, 2006) is a plug-in of the knowl-
edge representation tool Prot´eg´e3, which works as
a general purpose text annotation tool and has the
advantage that it can work with complex ontology-
derived schemas. However, these systems are not
particularly suited to sentence by sentence annota-
tion of full papers, as one would need to highlight
entire sentences manually. Also these systems work
mainly with plain text, so they do not necessarily
interpret the structural information already available
in the paper, which can be crucial to annotation deci-
sions for the type of high level annotation mentioned
</bodyText>
<footnote confidence="0.999755">
2http://callisto.mitre.org/manual/use.html
3http://protege.stanford.edu/
</footnote>
<page confidence="0.962998">
193
</page>
<note confidence="0.9065665">
Proceedings of the Workshop on BioNLP, pages 193–200,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999955181818182">
above. The OSCAR3 (Corbett et al., 2007) tool for
the recognition and annotation of chemical named
entities fully displays underlying paper information
in XML but is not suited to sentence by sentence an-
notation.
To address the above issues, we present a sys-
tem (SAPIENT) for sentence by sentence annota-
tion of scientific papers which supports ontology-
motivated concepts representing the core informa-
tion about scientific papers (CISP) (Soldatova and
Liakata, 2007). An important aspect of the system is
that although annotation is sentence based, the sys-
tem caters for identifiers, which link together sen-
tences pertaining to the same concept. This way
spans of interest or key regions are formed. SAPI-
ENT also incorporates OSCAR3 capability for the
automatic recognition of chemical named entities
and runs within a browser, which makes it platform
independent. SAPIENT takes as input full scien-
tific papers in XML, splits them into individual sen-
tences, displays them and allows the user to anno-
tate each sentence with one of 11 CISP concepts as
well as link the sentence to other sentences refer-
ring to the same instance of the concept selected.
The system is especially suitable for so called multi-
dimensional annotation (Shatkay et al., 2008) or
ontology-motivated annotation, where a label origi-
nates from a class with properties. SAPIENT is cur-
rently being employed by 16 Chemistry experts to
develop a corpus of scientific papers (ART Corpus)
annotated with Core Information about Scientific
Papers (CISP) covering topics in Physical Chemistry
and Biochemistry.
</bodyText>
<sectionHeader confidence="0.992471" genericHeader="method">
2 SAPIENT System Description
</sectionHeader>
<bodyText confidence="0.99960585">
We chose to implement SAPIENT as a web appli-
cation, so as to make it platform independent and
easier to incorporate as part of an online workflow.
We have used state of the art web technologies to
develop SAPIENT, namely Java, Javascript (with
Asynchronous JavaScript and XML (AJAX) func-
tionality), XSLT, CSS and XML. The system has a
client-server architecture (see Figure 1), with pa-
pers being uploaded and stored on the server but
functionality for annotation contained in Javascript,
which runs client-side in the browser. This is in-
spired by but in contrast with OSCAR3 (Corbett
et al., 2007), which also allows manual annota-
tion alongside the automated annotation of chemical
named entities, but where each minor edit is saved
to the server, writing to a file. We chose to make
more of the functionality client-side in order to re-
duce the number of server requests, which could be-
come problematic if the system became widely dis-
tributed.
</bodyText>
<figureCaption confidence="0.999764">
Figure 1: Architecture of the SAPIENT System
</figureCaption>
<bodyText confidence="0.995531173913044">
SAPIENT has been designed to take as input full
papers in XML, conforming to the SciXML schema
(Rupp et al., 2006)(see Section 3).
To view or annotate a paper, a user must first up-
load it. The index page of SAPIENT shows a list
of papers already uploaded (available as links) and
an interface for uploading more papers (See Figure
2). Once the user selects a link to a paper, the pa-
per is split into sentences using the XML-aware sen-
tence splitter SSSplit which we have developed (See
section 4) and is included in the server-side Java.
The resultant XML file is stored alongside the origi-
nal upload. Sentence splitting involves detecting the
boundaries of sentences and, in this context, mark-
ing the latter by inline &lt;s&gt;&lt;/s&gt; tags added to the
original XML. The &lt;s&gt;&lt;/s&gt; tags contain an id at-
tribute enumerating the sentence.
After sentence splitting, the new XML file
containing sentence boundaries marked by &lt;s
id=#NUM&gt;&lt; /s&gt; tags is parsed by XSLT into
HTML, so that it displays in the browser. In the
HTML interface dynamically generated in this way,
Javascript annotation drop-downs are available for
</bodyText>
<figure confidence="0.999322419354839">
SAPIENT Architecture
User Input Browser
Paper in
.xml
Javascript based
annotation with
CISP
Page for paper
upload &amp;
links to uploaded
papers
Paper displayed
in dynamic html
response
Click on paper
Click on Save
Processing
with .xsl
XML Http
request
Annotations saved
In mode2.xml
OSCAR annotations
1) Paper is split
into sentences
with SSSplit
2) Paper saved
as mode2.xml
Paper saved
as source.xml
Server
</figure>
<page confidence="0.762625">
194
</page>
<figureCaption confidence="0.999489">
Figure 2: Index page of the SAPIENT System
</figureCaption>
<bodyText confidence="0.999966574468085">
each sentence. The user can perform annotations
by selecting items from the drop-downs and all the
corresponding annotation information is stored in
Javascript until a request to save is made by the user.
The Javascript drop-downs allow annotation at
two levels (Figure 3), enabling a sentence to have a
semantic label (type) with properties (subtypes) and
an identifier (conceptID).
In the current implementation of SAPIENT, The
type drop-down value corresponds to the selection
of one out of 11 general scientific concepts (Li-
akata and Soldatova, 2008), namely (‘Background’,
‘Conclusion’, ‘Experiment’, ‘Goal of the Investi-
gation’, ‘Hypothesis’,‘Method’, ‘Model’, ‘Motiva-
tion’, ‘Object of the Investigation’, ‘Observation’,
‘Result’). These labels originate from a set of
meta-data (The Core Information about Scientific
Concepts (CISP) (Soldatova and Liakata, 2007)
which were constructed using an ontology method-
ology, based on an ontology of experiments EXPO
(Soldatova and King, 2006). Because these labels
map to ontology classes, they can also have prop-
erties. For example, ‘Method’ has the property
‘New’/‘Old’,‘Advantage’/‘Disadvantage’. These
properties are dependent on the type selected and
are expressed in terms of the subtype drop-down.
The third drop-down, concept ID allows a user to
provide a concept identifier. The latter is an entity
formed by the name of a concept and a number (e.g.
“Res2”). Concept identifiers uniquely identify an in-
stance of a concept (e.g. the second Result), but not
a sentence. That is, concept identifiers designate and
link together instances of the same semantic con-
cept, spread across different sentences, which can
be in different parts of the paper. For example, the
second result (“Res2”) can be referred to by 1 sen-
tence in the abstract, 5 sentences in the Discussion
and 2 sentences in the Conclusion sections.
The distinction between sentence identifiers and
concept identifiers is an important characteristic of
the system. It means that the system does not neces-
sarily assume a ‘1-1’ correspondence between a sen-
tence and a concept, but rather that concepts can be
represented by spans of often disjoint text. There-
fore, SAPIENT indirectly allows the annotation of
discourse segments beyond the sentence level and
also keeps track of co-referring sentences.
</bodyText>
<subsectionHeader confidence="0.948344">
2.1 SAPIENT Usability
</subsectionHeader>
<bodyText confidence="0.999983125">
Even though SAPIENT has been primarily designed
to work with CISP concepts, it can be used to an-
notate papers according to any sentence based anno-
tation scheme. Changes required can be easily per-
formed by modifying the XSL sheet which dynami-
cally generates HTML from XML and organises the
structure of drop-down menus. Automated noun-
phrase based annotation from existing ontologies
is available to SAPIENT users through OSCAR3
(Corbett et al., 2007), since SAPIENT incorporates
OSCAR3 functionality for chemical named entity
recognition. The latter is implemented as a link
which when selected calls the OSCAR3 workflow
(integrated in the system) to automatically recognise
chemical named entities (NEs) (See Figure 5).
When all annotations (both sentence based and
chemical NEs) are saved to the server, a new ver-
sion of the XML file is produced, which contains
in-line annotation for sentences as well as extra in-
line annotation for the semantic concepts and NEs
embedded within &lt;s&gt;&lt;/s&gt; tags. These annotation
tags are compliant with the SciXML schema (Rupp
et al., 2006) and in the case of sentence-based anno-
tations are of the form:
</bodyText>
<equation confidence="0.87134775">
&lt;annotationART atype=‘‘GSC”type=#TYPE
conceptID=#CONCEPTID
novelty=‘‘Yes/No”advantage=‘‘Yes/No”
&lt;/annotationART&gt;
</equation>
<bodyText confidence="0.998069">
(See Figure 4). The attribute type, stands for the
CISP concept selected for the sentence in question.
The conceptID attribute is an enumerator of the par-
ticular concept, which the sentence refers to. For
</bodyText>
<page confidence="0.995808">
195
</page>
<bodyText confidence="0.999952821428571">
example, two different sentences will have differ-
ent sentence ids but if they refer to the same con-
cept (e.g. the same “Conclusion”) , they will be
assigned the same concept ID (e.g. “Con3”). The
attributes novelty and advantage, are properties of
the concepts assigned to a sentence and depend
on the concept selection. They take boolean val-
ues or the dummy value “None” if the properties
are not defined for a particular concept. For ex-
ample, these attributes are relevant when the con-
cept selected is a ‘Method’, in which case the
method can be “New/Old” and/or have an “Advan-
tage/Disadvantage”. The novelty and advantage at-
tributes co-exist in the annotation (as can be seen in
Figure 4) but they are not set by the system at the
same time. For instance, if a sentence refers to a new
method, it will be given the type ‘Method’ and the
subtype “New”; this sets the novelty attribute in the
underlying XML to “Yes” and leaves the advantage
attribute set to the default “None”. The sentence will
also be given a conceptID, e.g. “Met1”. If another
sentence refers to an advantage of this method, then
the new sentence will be assigned the type ‘Method’,
the subtype “Advantage” (which sets the underlying
advantage attribute to “Yes”) and the same concep-
tID “Met1”. The novelty attribute value is then in-
herited from the novelty attribute value of the first
coreferring sentence, which in this case is “New”.
</bodyText>
<sectionHeader confidence="0.989441" genericHeader="method">
3 Input: Paper in XML
</sectionHeader>
<bodyText confidence="0.9997092">
SAPIENT currently accepts as input papers in XML,
especially ones compliant with the SciXML schema
(Rupp et al., 2006). SciXML is ideally suited for
this purpose as it was developed for representing the
logical structure of scientific research papers. Tags
used in the schema serve the purpose of paper iden-
tification (e.g. &lt;TITLE&gt;,&lt;AUTHOR&gt;), defining
sections of the paper (e.g. &lt;DIV&gt;,&lt;HEADER&gt;),
text sections with specific function and formatting
(e.g. &lt;ABSTRACT&gt;, &lt;EQUATION&gt;), paragraph
tags &lt;P&gt;, references, tables, figures and footnotes,
lists, bibliography. SAPIENT operates only on the
&lt;TITLE&gt;, &lt;ABSTRACT&gt; ,&lt;BODY&gt; and &lt;P&gt;
tags, leaving out any list elements following the
body, such as acknowledgements, figures or refer-
ences at the end of the paper. This is because we
make the assumption that only the abstract and the
body contain sentences with semantic content of any
importance to the research carried out in the paper.
This would have been different if SAPIENT anno-
tated figures as well, but such provision is not cur-
rently made. Tags such as &lt;REF&gt;, citations in the
text, are included within the sentence boundaries.
Even though SAPIENT was developed with the
SciXML schema in mind, it will work with any
well formed XML document that has &lt;PAPER&gt;
as the root node and which also contains an
&lt;ABSTRACT&gt; and &lt;BODY&gt; node. Therefore, it
is relatively easy to adapt SAPIENT to other XML
schemas.
</bodyText>
<sectionHeader confidence="0.991349" genericHeader="method">
4 SSSplit: Sapient Sentence Splitting
</sectionHeader>
<subsectionHeader confidence="0.989679">
4.1 Sentence Matching
</subsectionHeader>
<bodyText confidence="0.999954965517241">
The reason for developing our own sentence split-
ter was that sentence splitters widely available could
not handle XML properly. The XML markup con-
tains useful information about the document struc-
ture and formatting in the form of inline tags,
which is important for determining the logical struc-
ture of the paper. The latter is worth preserv-
ing for our purposes, since it can influence the
annotation of individual sentences. XML markup
(e.g. &lt;ABSTRACT&gt;,&lt;REF&gt;,&lt;EQUATION&gt;)
needs to be combined carefully with tags designat-
ing sentence boundaries (&lt;s&gt;&lt;/s&gt;), so that the
resulting document is in well formed XML. Cur-
rent sentence splitters ignore XML markup, which
means that any document formatting/information
would have to be removed in order to use them.
RASP (Briscoe et al., 2006), the sentence splitter
used in the Sciborg project4 at the University of
Cambridge, can deal with XML but has to be com-
piled for different operating systems, which would
result in compromising the platform independence
of SAPIENT. A recent MPhil thesis (Owusu, 2008)
has also developed an XML-aware sentence splitter
but the code is in Microsoft C#.Net and therefore not
platform independent.
We have written the XML-aware sentence split-
ter SSSplit in the platform-independent Java lan-
guage (version 1.6), based on and extending open
source Perl code5 for handling plain text. In or-
</bodyText>
<footnote confidence="0.9999615">
4http://www.cl.cam.ac.uk/research/nl/sciborg/www/
5http://search.cpan.org/ tgrose/HTML-Summary-0.017/
</footnote>
<page confidence="0.997473">
196
</page>
<figureCaption confidence="0.999983666666667">
Figure 3: Example of SAPIENT annotation through selection from drop-down menu.
Figure 4: Behind the scenes: Example XML fragment of a paper annotated using SAPIENT.
Figure 5: Incorporation of OSCAR3 annotations in SAPIENT, after selecting the link “Auto Annotate”
</figureCaption>
<page confidence="0.992603">
197
</page>
<bodyText confidence="0.999820142857143">
der to make our sentence splitter XML aware, we
translated the Perl regular expression rules into Java
and modifed them to make them compatible with the
SciXML(Rupp et al., 2006) schema. We then fur-
ther improved the rules, by training on a set of 14
papers in SciXML. This involved displaying the pa-
pers, checking whether the XML was well formed
and making corrections accordingly. We would ob-
serve cases of oversplit and undersplit sentences and
amend the rules while keeping them as general as
possible. The rules in SSSplit were evaluated by
comparing the system output against a gold standard
of 41 papers, where sentence boundaries had been
provided by human experts (See section 4.2). The
sentence splitter is integrated within the SAPIENT
system but is also available as a separate package
(“SSSplit”). This should enable any future work to
easily incorporate or extend it. It is currently trained
for splitting papers in SciXML, but can be easily
ported to any other kind of XML, as discussed in
section 3.
</bodyText>
<subsectionHeader confidence="0.998503">
4.2 SSSplit Evaluation
</subsectionHeader>
<bodyText confidence="0.99983584">
SAPIENT and SSSplit have been have been em-
ployed by more than 20 different users to success-
fully display 270 full papers. For a more accurate
evaluation of the quality of the sentences produced
by SSSplit, we used a Perl script which compared
the sentence boundaries (start and end) generated
by SSSplit, to sentence tags in a set of 41 papers
(SciXML files) annotated manually by human ex-
perts. If both the start and end of a sentence matched
up in the generated and manual versions, we consid-
ered this a true positive result. In the case where a
sentence did not match in the two versions, we first
searched for a matching end in our generated set of
sentences and then in the hand annotated version. If
the ‘true’ end of the sentence (as defined by the man-
ual annotation) was found in later sentences in the
SSSplit version, this meant that the system had split
a sentence too early, or “oversplit”. This we consid-
ered to be a false positive, since we had detected a
sentence boundary where in reality there was none.
This would result in the following sentence being
matched at the end only, which also counts as a false
positive. In the case where the end of the SSSplit
sentence was found in a later sentence, within the
set of ‘true’ sentences, it meant that our sentence
</bodyText>
<table confidence="0.9970935">
RASP Owusu SSSplit
Precision 0.994 0.996 0.964
Recall 0.983 0.990 0.994
F-measure 0.988 0.992 0.978
</table>
<tableCaption confidence="0.9874505">
Table 1: Comparison of sentence splitters in RASP,
Owusu and SSSplit.
</tableCaption>
<bodyText confidence="0.997165128205128">
spanned too wide, or that the system had “under-
split”. These cases we considered to be false nega-
tives, as we had failed to detect a sentence boundary
where there was one.
Our training consisted of 14 papers in the fields of
physical chemistry and biochemistry. A different set
of 41 papers distinct from the training set but from
the same thematic domain was used as a test set. Out
of these 41 papers, 36 feature as a test set (with n-
fold validation) also for the sentence splitters RASP
(Briscoe et al., 2006) and the XML-aware sentence
splitter developed by (Owusu, 2008). The results for
all three systems, obtained as medians of Precision,
Recall and F-measure for the 36 papers are shown in
Table 1.
Precision is the proportion of true positives over
all end and start tags returned, giving a measure of
the number of boundaries identified correctly. Re-
call is the proportion of true positives over all the
relevant start and end tags in the hand-annotated pa-
pers, giving a measure of the number of boundaries
actually found. F-Measure combines Precision and
Recall to give a more balanced view on the system
performance.
In comparison with RASP and the XML-Aware
splitter of (Owusu, 2008), SSSplit performed well,
though it did not outperform these systems. Their
highest result for precision was 0.996 (vs 0.964 for
SSSplit) and for recall 0.990 (vs 0.994 for SSSplit).
We can explain their higher results somewhat by
their use of n-fold cross-validation on 36 out of the
same 41 papers that we used, which can allow in-
formation from the test set to leak into the training
data. We did not perform n-fold cross-validation, as
this would have involved going through each of the
papers and removing any potential influence on our
regular expression rules of the sentences included
within, which is a non-trivial process. Our test data
was completely unseen, which meant that our eval-
</bodyText>
<page confidence="0.992644">
198
</page>
<table confidence="0.999618">
Training Testing
(1979 sentences) (5002 sentences)
Precision 0.961 0.964
Recall 0.995 0.994
F-measure 0.96875 0.978
</table>
<tableCaption confidence="0.9735805">
Table 2: Comparison of SSSplit on the training and test-
ing papers. The training set consisted of 14 papers (1979
sentences) and the testing set of 41 papers (5002 sen-
tences).
</tableCaption>
<bodyText confidence="0.999435947368421">
uation is stricter, avoiding any influence from the
training data.
In addition to the comparison between SSSplit
and the other two XML-aware sentence splitters, we
also performed a comparison between our training
and testing sets, depicted in Table 2.
As can be seen in Table 2, recall was only slightly
better on the training set than the test set, but preci-
sion was worse on the training set, presumably be-
cause of lack of attention being paid to the oversplit-
ting in a particular paper (“b103844n”). This shows
that we have not overfitted to the training set in de-
veloping our splitter. Our recall is particularly high,
indicating that our splitter makes very few false neg-
ative errors. We can attribute many of the false pos-
itive errors to our somewhat small set of abbrevi-
ations considered, resulting in oversplit sentences.
We would like to incorporate a more sophisticated
approach to abbreviations in the future.
</bodyText>
<sectionHeader confidence="0.998334" genericHeader="method">
5 Performing CISP Annotations
</sectionHeader>
<bodyText confidence="0.999964741935484">
Within the context of the ART project (Soldatova et
al., 2007), SAPIENT has been used by 16 Chem-
istry experts to annotate 265 papers from RSC Pub-
lishing journals, covering topics in Physical Chem-
istry and Biochemistry. Experts have been anno-
tating the papers sentence by sentence, assigning
each sentence one of 11 core scientific concepts and
linking together sentences across a paper which re-
fer to the same instance of a concept. The aim
is to create a corpus of annotated papers (ART-
corpus) with regions of scientific interest identified
by CISP concepts (“Result”,“Conclusion”, “Obser-
vation”,“Method” and so on).
A preliminary evaluation of the experts’ agree-
ment on the ART Corpus, based on a sample of
41 papers, annotated by the 16 experts in non-
overlapping groups of 3, shows significant agree-
ment between annotators, given the difficulty of
the task (an average kappa co-efficient of 0.55 per
group). The details of this work are beyond the
scope of the current paper, but the preliminary re-
sults underline the usability of both the CISP meta-
data and SAPIENT. In the future, we plan to further
evaluate the ART Corpus by incorporating existing
machine learning algorithms into SAPIENT and au-
tomating the generation of CISP meta-data. This
would make SAPIENT a very useful tool and would
indeed add a lot more value to the meta-data, since
training and paying annotators is a costly process
and manually annotating papers is incredibly time
consuming.
</bodyText>
<sectionHeader confidence="0.998837" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99978475">
We have presented SAPIENT, a web-based tool for
the annotation of full papers, sentence by sentence,
with semantic information. We have also discussed
how these annotations result in the indirect defini-
tion of regions of interest within the paper. The sys-
tem has been already tested in a systematic study
and has been employed for the creation of a corpus
of papers annotated with CISP concepts (ART Cor-
pus). In the future we plan to extend SAPIENT so
that the system can itself suggest annotation labels
to users. We also plan to target the needs of partic-
ular users such as authors of papers, reviewers and
editors.
SAPIENT, SSSplit and their documenta-
tion are both available for download from
http://www.aber.ac.uk/compsci/Research/bio/art/sapient/.
</bodyText>
<sectionHeader confidence="0.998966" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99792">
We would like to thank Peter Corbett, Amanda
Clare, Jem Rowland and Andrew Sparkes for
reading and commenting on earlier versions
of this paper. We would also like to thank
the anonymous reviewers for their useful com-
ments. This work was part of the ART Project
(http://www.aber.ac.uk/compsci/Research/bio/art/),
funded by the U.K. Higher Education Joint
Information Services Committee (JISC).
</bodyText>
<page confidence="0.998528">
199
</page>
<sectionHeader confidence="0.998347" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999941733333334">
E. Briscoe, J. Carroll and R. Watson 2006. The Sec-
ond Release of the RASP System. Proceedings of the
COLING/ACL 2006 Interactive Presentation Sessions,
Sydney, Australia.
P. Corbett, P. Batchelor and S. Teufel. 2007. Annotation
of Chemical Named Entities. Proc. BioNLP.
Nikiforos Karamanis, Ruth Seal, Ian Lewin, Peter Mc-
Quilton, Andreas Vlachos, Caroline Gasperin, Rachel
Drysdale and Ted Briscoe. 2008. Natural Language
Processing in aid of FlyBase curators. BMC Bioinfor-
matics, 9:193.
Maria Liakata and Larisa N. Soldatova. 2008. Guide-
lines for the annotation of General Scientific Concepts
JISC Project Report, http://ie-repository.jisc.ac.uk/.
Jimmy Lin 2009. Is Searching Full Text More Effec-
tive Than Searching Abstracts? BMC Bioinformatics,
10:46.
Ben Medlock and Ted Briscoe. 2007. Weakly supervised
learning for hedge classification in scientific literature.
45th Annual Meeting of the Association for Compu-
tational Linguistics, 23-30 Jun 2007, Prague, Czech
Republic.
P. Ogren. 2006. Knowtator: a Prot´eg´e plug-in for an-
notated corpus construction. Proceedings of the 2006
Conference of the North American Chapter of the As-
sociation For Computational Linguistics on Human
Language Technology: Companion Volume: Demon-
strations, New York Press, New York, June 04 - 09,
2006.
Lawrence Owusu. 2008. XML-Aware Sentence Splitter.
MPhil thesis, Cambridge, UK.
CJ Rupp, Ann Copestake, Simone Teufel and Ben Wal-
dron. 2006. Flexible Interfaces in the Application of
Language Technology to an eScience Corpus. Pro-
ceedings of the UK e-Science Programme All Hands
Meeting 2006 (AHM2006), Nottingham, UK
Hagit Shatkay, Fengxia Pan, Andrey Rzhetsky and W.
John Wilbur. 2008. Multi-dimensional classification
of biomedical text: Toward automated, practical pro-
vision of high-utility text to diverse users. Bioinfor-
matics, 24(18):2086–2093.
Larisa N. Soldatova and Maria Liakata. 2007. An ontol-
ogy methodology and CISP - the proposed Core Infor-
mation about Scientific Papers. JISC Project Report,
http://ie-repository.jisc.ac.uk/137/.
L. Soldatova, C. Batchelor, M. Liakata, H. Fielding, S.
Lewis and R. King 2007. ART: An ontology based
tool for the translation of papers into Semantic Web
format. Proceedings of the SIG/ISMB07 ontology
workshop., p.33–36.
Larisa N. Soldatova and Ross D. King. 2006. An On-
tology of Scientific Experiments. Journal of the Royal
Society Interface, 3:795–803.
S. Teufel and M. Moens. 2002. Summarizing Scientific
Articles – Experiments with Relevance and Rhetorical
Status. Computational Linguistics, 28(4). (preprint)
W. Wilbur, A. Rzhetsky and H. Shatkay. 2006. New Di-
rections in Biomedical Text Annotations: Deifinitions,
Guidelines and Corpus Construction. BMC Bioinfor-
matics, 7:356.
</reference>
<page confidence="0.996622">
200
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.699232">
<title confidence="0.998227">Semantic Annotation of Papers: Interface &amp; Enrichment Tool (SAPIENT)</title>
<author confidence="0.997488">Claire Larisa N</author>
<affiliation confidence="0.999975">Department of Computer University of Wales,</affiliation>
<address confidence="0.847116">SY23 3DB</address>
<abstract confidence="0.9819755">In this paper we introduce a web application (SAPIENT) for sentence based annotation of full papers with semantic information. SAPI- ENT enables experts to annotate scientific papers sentence by sentence and also to link related sentences together, thus forming spans of interesting regions, which can facilitate text mining applications. As part of the system, we developed an XML-aware sentence splitter (SSSplit) which preserves XML markup and identifies sentences through the addition of in-line markup. SAPIENT has been used in a systematic study for the annotation of scientific papers with concepts representing the Core Information about Scientific Papers (CISP) to create a corpus of 225 annotated papers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<date>2006</date>
<booktitle>The Second Release of the RASP System. Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="15143" citStr="Briscoe et al., 2006" startWordPosition="2393" endWordPosition="2396">ormation about the document structure and formatting in the form of inline tags, which is important for determining the logical structure of the paper. The latter is worth preserving for our purposes, since it can influence the annotation of individual sentences. XML markup (e.g. &lt;ABSTRACT&gt;,&lt;REF&gt;,&lt;EQUATION&gt;) needs to be combined carefully with tags designating sentence boundaries (&lt;s&gt;&lt;/s&gt;), so that the resulting document is in well formed XML. Current sentence splitters ignore XML markup, which means that any document formatting/information would have to be removed in order to use them. RASP (Briscoe et al., 2006), the sentence splitter used in the Sciborg project4 at the University of Cambridge, can deal with XML but has to be compiled for different operating systems, which would result in compromising the platform independence of SAPIENT. A recent MPhil thesis (Owusu, 2008) has also developed an XML-aware sentence splitter but the code is in Microsoft C#.Net and therefore not platform independent. We have written the XML-aware sentence splitter SSSplit in the platform-independent Java language (version 1.6), based on and extending open source Perl code5 for handling plain text. In or4http://www.cl.ca</context>
<context position="19099" citStr="Briscoe et al., 2006" startWordPosition="3056" endWordPosition="3059">.990 0.994 F-measure 0.988 0.992 0.978 Table 1: Comparison of sentence splitters in RASP, Owusu and SSSplit. spanned too wide, or that the system had “undersplit”. These cases we considered to be false negatives, as we had failed to detect a sentence boundary where there was one. Our training consisted of 14 papers in the fields of physical chemistry and biochemistry. A different set of 41 papers distinct from the training set but from the same thematic domain was used as a test set. Out of these 41 papers, 36 feature as a test set (with nfold validation) also for the sentence splitters RASP (Briscoe et al., 2006) and the XML-aware sentence splitter developed by (Owusu, 2008). The results for all three systems, obtained as medians of Precision, Recall and F-measure for the 36 papers are shown in Table 1. Precision is the proportion of true positives over all end and start tags returned, giving a measure of the number of boundaries identified correctly. Recall is the proportion of true positives over all the relevant start and end tags in the hand-annotated papers, giving a measure of the number of boundaries actually found. F-Measure combines Precision and Recall to give a more balanced view on the sys</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>E. Briscoe, J. Carroll and R. Watson 2006. The Second Release of the RASP System. Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Corbett</author>
<author>P Batchelor</author>
<author>S Teufel</author>
</authors>
<title>Annotation of Chemical Named Entities.</title>
<date>2007</date>
<booktitle>Proc. BioNLP.</booktitle>
<contexts>
<context position="3558" citStr="Corbett et al., 2007" startWordPosition="534" endWordPosition="537"> not particularly suited to sentence by sentence annotation of full papers, as one would need to highlight entire sentences manually. Also these systems work mainly with plain text, so they do not necessarily interpret the structural information already available in the paper, which can be crucial to annotation decisions for the type of high level annotation mentioned 2http://callisto.mitre.org/manual/use.html 3http://protege.stanford.edu/ 193 Proceedings of the Workshop on BioNLP, pages 193–200, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics above. The OSCAR3 (Corbett et al., 2007) tool for the recognition and annotation of chemical named entities fully displays underlying paper information in XML but is not suited to sentence by sentence annotation. To address the above issues, we present a system (SAPIENT) for sentence by sentence annotation of scientific papers which supports ontologymotivated concepts representing the core information about scientific papers (CISP) (Soldatova and Liakata, 2007). An important aspect of the system is that although annotation is sentence based, the system caters for identifiers, which link together sentences pertaining to the same conc</context>
<context position="5715" citStr="Corbett et al., 2007" startWordPosition="880" endWordPosition="883">IENT System Description We chose to implement SAPIENT as a web application, so as to make it platform independent and easier to incorporate as part of an online workflow. We have used state of the art web technologies to develop SAPIENT, namely Java, Javascript (with Asynchronous JavaScript and XML (AJAX) functionality), XSLT, CSS and XML. The system has a client-server architecture (see Figure 1), with papers being uploaded and stored on the server but functionality for annotation contained in Javascript, which runs client-side in the browser. This is inspired by but in contrast with OSCAR3 (Corbett et al., 2007), which also allows manual annotation alongside the automated annotation of chemical named entities, but where each minor edit is saved to the server, writing to a file. We chose to make more of the functionality client-side in order to reduce the number of server requests, which could become problematic if the system became widely distributed. Figure 1: Architecture of the SAPIENT System SAPIENT has been designed to take as input full papers in XML, conforming to the SciXML schema (Rupp et al., 2006)(see Section 3). To view or annotate a paper, a user must first upload it. The index page of S</context>
<context position="10452" citStr="Corbett et al., 2007" startWordPosition="1638" endWordPosition="1641">. Therefore, SAPIENT indirectly allows the annotation of discourse segments beyond the sentence level and also keeps track of co-referring sentences. 2.1 SAPIENT Usability Even though SAPIENT has been primarily designed to work with CISP concepts, it can be used to annotate papers according to any sentence based annotation scheme. Changes required can be easily performed by modifying the XSL sheet which dynamically generates HTML from XML and organises the structure of drop-down menus. Automated nounphrase based annotation from existing ontologies is available to SAPIENT users through OSCAR3 (Corbett et al., 2007), since SAPIENT incorporates OSCAR3 functionality for chemical named entity recognition. The latter is implemented as a link which when selected calls the OSCAR3 workflow (integrated in the system) to automatically recognise chemical named entities (NEs) (See Figure 5). When all annotations (both sentence based and chemical NEs) are saved to the server, a new version of the XML file is produced, which contains in-line annotation for sentences as well as extra inline annotation for the semantic concepts and NEs embedded within &lt;s&gt;&lt;/s&gt; tags. These annotation tags are compliant with the SciXML sc</context>
</contexts>
<marker>Corbett, Batchelor, Teufel, 2007</marker>
<rawString>P. Corbett, P. Batchelor and S. Teufel. 2007. Annotation of Chemical Named Entities. Proc. BioNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
<author>Ruth Seal</author>
<author>Ian Lewin</author>
<author>Peter McQuilton</author>
<author>Andreas Vlachos</author>
<author>Caroline Gasperin</author>
<author>Rachel Drysdale</author>
<author>Ted Briscoe</author>
</authors>
<title>Natural Language Processing in aid of FlyBase curators.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<pages>9--193</pages>
<contexts>
<context position="1282" citStr="Karamanis et al., 2008" startWordPosition="185" endWordPosition="188">ter (SSSplit) which preserves XML markup and identifies sentences through the addition of in-line markup. SAPIENT has been used in a systematic study for the annotation of scientific papers with concepts representing the Core Information about Scientific Papers (CISP) to create a corpus of 225 annotated papers. 1 Introduction Given the rapid growth in the quantity of scientific literature, particularly in the Biosciences, there is an increasing need to work with full papers rather than abstracts, both to identify their key contributions and to provide some automated assistance to researchers (Karamanis et al., 2008; Medlock and Briscoe, 2007). Initiatives like OTMI1, which aim to make full papers available to researchers for text mining purposes is further evidence that relying solely on abstracts presents important limitations for such tasks. A recent study on whether information retrieval from full text is more effective than searching abstracts alone (Lin Jimmy, 2009) showed that 1http://opentextmining.org/wiki/Main Page the former is indeed the case. Their experimental results suggested that span-level analysis is a promising strategy for taking advantage of the full papers, where spans are defined </context>
</contexts>
<marker>Karamanis, Seal, Lewin, McQuilton, Vlachos, Gasperin, Drysdale, Briscoe, 2008</marker>
<rawString>Nikiforos Karamanis, Ruth Seal, Ian Lewin, Peter McQuilton, Andreas Vlachos, Caroline Gasperin, Rachel Drysdale and Ted Briscoe. 2008. Natural Language Processing in aid of FlyBase curators. BMC Bioinformatics, 9:193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Liakata</author>
<author>Larisa N Soldatova</author>
</authors>
<title>Guidelines for the annotation of General Scientific Concepts</title>
<date>2008</date>
<tech>JISC Project Report, http://ie-repository.jisc.ac.uk/.</tech>
<contexts>
<context position="8217" citStr="Liakata and Soldatova, 2008" startWordPosition="1293" endWordPosition="1297">saved as source.xml Server 194 Figure 2: Index page of the SAPIENT System each sentence. The user can perform annotations by selecting items from the drop-downs and all the corresponding annotation information is stored in Javascript until a request to save is made by the user. The Javascript drop-downs allow annotation at two levels (Figure 3), enabling a sentence to have a semantic label (type) with properties (subtypes) and an identifier (conceptID). In the current implementation of SAPIENT, The type drop-down value corresponds to the selection of one out of 11 general scientific concepts (Liakata and Soldatova, 2008), namely (‘Background’, ‘Conclusion’, ‘Experiment’, ‘Goal of the Investigation’, ‘Hypothesis’,‘Method’, ‘Model’, ‘Motivation’, ‘Object of the Investigation’, ‘Observation’, ‘Result’). These labels originate from a set of meta-data (The Core Information about Scientific Concepts (CISP) (Soldatova and Liakata, 2007) which were constructed using an ontology methodology, based on an ontology of experiments EXPO (Soldatova and King, 2006). Because these labels map to ontology classes, they can also have properties. For example, ‘Method’ has the property ‘New’/‘Old’,‘Advantage’/‘Disadvantage’. These</context>
</contexts>
<marker>Liakata, Soldatova, 2008</marker>
<rawString>Maria Liakata and Larisa N. Soldatova. 2008. Guidelines for the annotation of General Scientific Concepts JISC Project Report, http://ie-repository.jisc.ac.uk/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jimmy Lin</author>
</authors>
<title>Is Searching Full Text More Effective Than Searching Abstracts?</title>
<date>2009</date>
<journal>BMC Bioinformatics,</journal>
<pages>10--46</pages>
<marker>Lin, 2009</marker>
<rawString>Jimmy Lin 2009. Is Searching Full Text More Effective Than Searching Abstracts? BMC Bioinformatics, 10:46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2007</date>
<booktitle>45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>23--30</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1310" citStr="Medlock and Briscoe, 2007" startWordPosition="189" endWordPosition="192">erves XML markup and identifies sentences through the addition of in-line markup. SAPIENT has been used in a systematic study for the annotation of scientific papers with concepts representing the Core Information about Scientific Papers (CISP) to create a corpus of 225 annotated papers. 1 Introduction Given the rapid growth in the quantity of scientific literature, particularly in the Biosciences, there is an increasing need to work with full papers rather than abstracts, both to identify their key contributions and to provide some automated assistance to researchers (Karamanis et al., 2008; Medlock and Briscoe, 2007). Initiatives like OTMI1, which aim to make full papers available to researchers for text mining purposes is further evidence that relying solely on abstracts presents important limitations for such tasks. A recent study on whether information retrieval from full text is more effective than searching abstracts alone (Lin Jimmy, 2009) showed that 1http://opentextmining.org/wiki/Main Page the former is indeed the case. Their experimental results suggested that span-level analysis is a promising strategy for taking advantage of the full papers, where spans are defined as paragraphs of text assess</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>Ben Medlock and Ted Briscoe. 2007. Weakly supervised learning for hedge classification in scientific literature. 45th Annual Meeting of the Association for Computational Linguistics, 23-30 Jun 2007, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ogren</author>
</authors>
<title>Knowtator: a Prot´eg´e plug-in for annotated corpus construction.</title>
<date>2006</date>
<booktitle>Proceedings of the 2006 Conference of the North American Chapter of the Association For Computational Linguistics on Human Language Technology: Companion Volume: Demonstrations,</booktitle>
<publisher>Press,</publisher>
<location>New York</location>
<contexts>
<context position="2717" citStr="Ogren, 2006" startWordPosition="414" endWordPosition="415">search, sentence based annotation has been used to identify text regions with scientific content of interest to the user (Wilbur et al., 2006; Shatkay et al., 2008) or zones of different rhetorical status (AZ) (Teufel and Moens, 2002). Sentences are the structural units of paragraphs and can be more flexible than paragraphs for text mining purposes other than information retrieval. Current general purpose systems for linguistic annotation such as Callisto2 allow the creation of a simple annotation schema that is a tag set augmented with simple (e.g. string) attributes for each tag. Knowtator (Ogren, 2006) is a plug-in of the knowledge representation tool Prot´eg´e3, which works as a general purpose text annotation tool and has the advantage that it can work with complex ontologyderived schemas. However, these systems are not particularly suited to sentence by sentence annotation of full papers, as one would need to highlight entire sentences manually. Also these systems work mainly with plain text, so they do not necessarily interpret the structural information already available in the paper, which can be crucial to annotation decisions for the type of high level annotation mentioned 2http://c</context>
</contexts>
<marker>Ogren, 2006</marker>
<rawString>P. Ogren. 2006. Knowtator: a Prot´eg´e plug-in for annotated corpus construction. Proceedings of the 2006 Conference of the North American Chapter of the Association For Computational Linguistics on Human Language Technology: Companion Volume: Demonstrations, New York Press, New York, June 04 - 09, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Owusu</author>
</authors>
<title>XML-Aware Sentence Splitter. MPhil thesis,</title>
<date>2008</date>
<location>Cambridge, UK.</location>
<contexts>
<context position="15410" citStr="Owusu, 2008" startWordPosition="2438" endWordPosition="2439">e.g. &lt;ABSTRACT&gt;,&lt;REF&gt;,&lt;EQUATION&gt;) needs to be combined carefully with tags designating sentence boundaries (&lt;s&gt;&lt;/s&gt;), so that the resulting document is in well formed XML. Current sentence splitters ignore XML markup, which means that any document formatting/information would have to be removed in order to use them. RASP (Briscoe et al., 2006), the sentence splitter used in the Sciborg project4 at the University of Cambridge, can deal with XML but has to be compiled for different operating systems, which would result in compromising the platform independence of SAPIENT. A recent MPhil thesis (Owusu, 2008) has also developed an XML-aware sentence splitter but the code is in Microsoft C#.Net and therefore not platform independent. We have written the XML-aware sentence splitter SSSplit in the platform-independent Java language (version 1.6), based on and extending open source Perl code5 for handling plain text. In or4http://www.cl.cam.ac.uk/research/nl/sciborg/www/ 5http://search.cpan.org/ tgrose/HTML-Summary-0.017/ 196 Figure 3: Example of SAPIENT annotation through selection from drop-down menu. Figure 4: Behind the scenes: Example XML fragment of a paper annotated using SAPIENT. Figure 5: Inc</context>
<context position="19162" citStr="Owusu, 2008" startWordPosition="3067" endWordPosition="3068">plitters in RASP, Owusu and SSSplit. spanned too wide, or that the system had “undersplit”. These cases we considered to be false negatives, as we had failed to detect a sentence boundary where there was one. Our training consisted of 14 papers in the fields of physical chemistry and biochemistry. A different set of 41 papers distinct from the training set but from the same thematic domain was used as a test set. Out of these 41 papers, 36 feature as a test set (with nfold validation) also for the sentence splitters RASP (Briscoe et al., 2006) and the XML-aware sentence splitter developed by (Owusu, 2008). The results for all three systems, obtained as medians of Precision, Recall and F-measure for the 36 papers are shown in Table 1. Precision is the proportion of true positives over all end and start tags returned, giving a measure of the number of boundaries identified correctly. Recall is the proportion of true positives over all the relevant start and end tags in the hand-annotated papers, giving a measure of the number of boundaries actually found. F-Measure combines Precision and Recall to give a more balanced view on the system performance. In comparison with RASP and the XML-Aware spli</context>
</contexts>
<marker>Owusu, 2008</marker>
<rawString>Lawrence Owusu. 2008. XML-Aware Sentence Splitter. MPhil thesis, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CJ Rupp</author>
<author>Ann Copestake</author>
<author>Simone Teufel</author>
<author>Ben Waldron</author>
</authors>
<title>Flexible Interfaces in the Application of Language Technology to an eScience Corpus.</title>
<date>2006</date>
<booktitle>Proceedings of the UK e-Science Programme All Hands Meeting</booktitle>
<location>Nottingham, UK</location>
<contexts>
<context position="6221" citStr="Rupp et al., 2006" startWordPosition="967" endWordPosition="970">t, which runs client-side in the browser. This is inspired by but in contrast with OSCAR3 (Corbett et al., 2007), which also allows manual annotation alongside the automated annotation of chemical named entities, but where each minor edit is saved to the server, writing to a file. We chose to make more of the functionality client-side in order to reduce the number of server requests, which could become problematic if the system became widely distributed. Figure 1: Architecture of the SAPIENT System SAPIENT has been designed to take as input full papers in XML, conforming to the SciXML schema (Rupp et al., 2006)(see Section 3). To view or annotate a paper, a user must first upload it. The index page of SAPIENT shows a list of papers already uploaded (available as links) and an interface for uploading more papers (See Figure 2). Once the user selects a link to a paper, the paper is split into sentences using the XML-aware sentence splitter SSSplit which we have developed (See section 4) and is included in the server-side Java. The resultant XML file is stored alongside the original upload. Sentence splitting involves detecting the boundaries of sentences and, in this context, marking the latter by inl</context>
<context position="11076" citStr="Rupp et al., 2006" startWordPosition="1736" endWordPosition="1739">e SAPIENT incorporates OSCAR3 functionality for chemical named entity recognition. The latter is implemented as a link which when selected calls the OSCAR3 workflow (integrated in the system) to automatically recognise chemical named entities (NEs) (See Figure 5). When all annotations (both sentence based and chemical NEs) are saved to the server, a new version of the XML file is produced, which contains in-line annotation for sentences as well as extra inline annotation for the semantic concepts and NEs embedded within &lt;s&gt;&lt;/s&gt; tags. These annotation tags are compliant with the SciXML schema (Rupp et al., 2006) and in the case of sentence-based annotations are of the form: &lt;annotationART atype=‘‘GSC”type=#TYPE conceptID=#CONCEPTID novelty=‘‘Yes/No”advantage=‘‘Yes/No” &lt;/annotationART&gt; (See Figure 4). The attribute type, stands for the CISP concept selected for the sentence in question. The conceptID attribute is an enumerator of the particular concept, which the sentence refers to. For 195 example, two different sentences will have different sentence ids but if they refer to the same concept (e.g. the same “Conclusion”) , they will be assigned the same concept ID (e.g. “Con3”). The attributes novelty</context>
<context position="13012" citStr="Rupp et al., 2006" startWordPosition="2056" endWordPosition="2059"> advantage attribute set to the default “None”. The sentence will also be given a conceptID, e.g. “Met1”. If another sentence refers to an advantage of this method, then the new sentence will be assigned the type ‘Method’, the subtype “Advantage” (which sets the underlying advantage attribute to “Yes”) and the same conceptID “Met1”. The novelty attribute value is then inherited from the novelty attribute value of the first coreferring sentence, which in this case is “New”. 3 Input: Paper in XML SAPIENT currently accepts as input papers in XML, especially ones compliant with the SciXML schema (Rupp et al., 2006). SciXML is ideally suited for this purpose as it was developed for representing the logical structure of scientific research papers. Tags used in the schema serve the purpose of paper identification (e.g. &lt;TITLE&gt;,&lt;AUTHOR&gt;), defining sections of the paper (e.g. &lt;DIV&gt;,&lt;HEADER&gt;), text sections with specific function and formatting (e.g. &lt;ABSTRACT&gt;, &lt;EQUATION&gt;), paragraph tags &lt;P&gt;, references, tables, figures and footnotes, lists, bibliography. SAPIENT operates only on the &lt;TITLE&gt;, &lt;ABSTRACT&gt; ,&lt;BODY&gt; and &lt;P&gt; tags, leaving out any list elements following the body, such as acknowledgements, figures</context>
<context position="16278" citStr="Rupp et al., 2006" startWordPosition="2560" endWordPosition="2563">nd extending open source Perl code5 for handling plain text. In or4http://www.cl.cam.ac.uk/research/nl/sciborg/www/ 5http://search.cpan.org/ tgrose/HTML-Summary-0.017/ 196 Figure 3: Example of SAPIENT annotation through selection from drop-down menu. Figure 4: Behind the scenes: Example XML fragment of a paper annotated using SAPIENT. Figure 5: Incorporation of OSCAR3 annotations in SAPIENT, after selecting the link “Auto Annotate” 197 der to make our sentence splitter XML aware, we translated the Perl regular expression rules into Java and modifed them to make them compatible with the SciXML(Rupp et al., 2006) schema. We then further improved the rules, by training on a set of 14 papers in SciXML. This involved displaying the papers, checking whether the XML was well formed and making corrections accordingly. We would observe cases of oversplit and undersplit sentences and amend the rules while keeping them as general as possible. The rules in SSSplit were evaluated by comparing the system output against a gold standard of 41 papers, where sentence boundaries had been provided by human experts (See section 4.2). The sentence splitter is integrated within the SAPIENT system but is also available as </context>
</contexts>
<marker>Rupp, Copestake, Teufel, Waldron, 2006</marker>
<rawString>CJ Rupp, Ann Copestake, Simone Teufel and Ben Waldron. 2006. Flexible Interfaces in the Application of Language Technology to an eScience Corpus. Proceedings of the UK e-Science Programme All Hands Meeting 2006 (AHM2006), Nottingham, UK</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagit Shatkay</author>
<author>Fengxia Pan</author>
<author>Andrey Rzhetsky</author>
<author>W John Wilbur</author>
</authors>
<title>Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>18</issue>
<contexts>
<context position="2269" citStr="Shatkay et al., 2008" startWordPosition="342" endWordPosition="345">owed that 1http://opentextmining.org/wiki/Main Page the former is indeed the case. Their experimental results suggested that span-level analysis is a promising strategy for taking advantage of the full papers, where spans are defined as paragraphs of text assessed by humans and deemed to be relevant to one of 36 pre-defined topics. Therefore, when working with full papers, it is important to be able to identify and annotate spans of text. In previous research, sentence based annotation has been used to identify text regions with scientific content of interest to the user (Wilbur et al., 2006; Shatkay et al., 2008) or zones of different rhetorical status (AZ) (Teufel and Moens, 2002). Sentences are the structural units of paragraphs and can be more flexible than paragraphs for text mining purposes other than information retrieval. Current general purpose systems for linguistic annotation such as Callisto2 allow the creation of a simple annotation schema that is a tag set augmented with simple (e.g. string) attributes for each tag. Knowtator (Ogren, 2006) is a plug-in of the knowledge representation tool Prot´eg´e3, which works as a general purpose text annotation tool and has the advantage that it can w</context>
<context position="4766" citStr="Shatkay et al., 2008" startWordPosition="729" endWordPosition="732">the same concept. This way spans of interest or key regions are formed. SAPIENT also incorporates OSCAR3 capability for the automatic recognition of chemical named entities and runs within a browser, which makes it platform independent. SAPIENT takes as input full scientific papers in XML, splits them into individual sentences, displays them and allows the user to annotate each sentence with one of 11 CISP concepts as well as link the sentence to other sentences referring to the same instance of the concept selected. The system is especially suitable for so called multidimensional annotation (Shatkay et al., 2008) or ontology-motivated annotation, where a label originates from a class with properties. SAPIENT is currently being employed by 16 Chemistry experts to develop a corpus of scientific papers (ART Corpus) annotated with Core Information about Scientific Papers (CISP) covering topics in Physical Chemistry and Biochemistry. 2 SAPIENT System Description We chose to implement SAPIENT as a web application, so as to make it platform independent and easier to incorporate as part of an online workflow. We have used state of the art web technologies to develop SAPIENT, namely Java, Javascript (with Asyn</context>
</contexts>
<marker>Shatkay, Pan, Rzhetsky, Wilbur, 2008</marker>
<rawString>Hagit Shatkay, Fengxia Pan, Andrey Rzhetsky and W. John Wilbur. 2008. Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users. Bioinformatics, 24(18):2086–2093.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larisa N Soldatova</author>
<author>Maria Liakata</author>
</authors>
<title>An ontology methodology and CISP - the proposed Core Information about Scientific Papers.</title>
<date>2007</date>
<tech>JISC Project Report, http://ie-repository.jisc.ac.uk/137/.</tech>
<contexts>
<context position="3983" citStr="Soldatova and Liakata, 2007" startWordPosition="599" endWordPosition="602">p://protege.stanford.edu/ 193 Proceedings of the Workshop on BioNLP, pages 193–200, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics above. The OSCAR3 (Corbett et al., 2007) tool for the recognition and annotation of chemical named entities fully displays underlying paper information in XML but is not suited to sentence by sentence annotation. To address the above issues, we present a system (SAPIENT) for sentence by sentence annotation of scientific papers which supports ontologymotivated concepts representing the core information about scientific papers (CISP) (Soldatova and Liakata, 2007). An important aspect of the system is that although annotation is sentence based, the system caters for identifiers, which link together sentences pertaining to the same concept. This way spans of interest or key regions are formed. SAPIENT also incorporates OSCAR3 capability for the automatic recognition of chemical named entities and runs within a browser, which makes it platform independent. SAPIENT takes as input full scientific papers in XML, splits them into individual sentences, displays them and allows the user to annotate each sentence with one of 11 CISP concepts as well as link the</context>
<context position="8532" citStr="Soldatova and Liakata, 2007" startWordPosition="1332" endWordPosition="1335">tation at two levels (Figure 3), enabling a sentence to have a semantic label (type) with properties (subtypes) and an identifier (conceptID). In the current implementation of SAPIENT, The type drop-down value corresponds to the selection of one out of 11 general scientific concepts (Liakata and Soldatova, 2008), namely (‘Background’, ‘Conclusion’, ‘Experiment’, ‘Goal of the Investigation’, ‘Hypothesis’,‘Method’, ‘Model’, ‘Motivation’, ‘Object of the Investigation’, ‘Observation’, ‘Result’). These labels originate from a set of meta-data (The Core Information about Scientific Concepts (CISP) (Soldatova and Liakata, 2007) which were constructed using an ontology methodology, based on an ontology of experiments EXPO (Soldatova and King, 2006). Because these labels map to ontology classes, they can also have properties. For example, ‘Method’ has the property ‘New’/‘Old’,‘Advantage’/‘Disadvantage’. These properties are dependent on the type selected and are expressed in terms of the subtype drop-down. The third drop-down, concept ID allows a user to provide a concept identifier. The latter is an entity formed by the name of a concept and a number (e.g. “Res2”). Concept identifiers uniquely identify an instance of</context>
</contexts>
<marker>Soldatova, Liakata, 2007</marker>
<rawString>Larisa N. Soldatova and Maria Liakata. 2007. An ontology methodology and CISP - the proposed Core Information about Scientific Papers. JISC Project Report, http://ie-repository.jisc.ac.uk/137/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Soldatova</author>
<author>C Batchelor</author>
<author>M Liakata</author>
<author>H Fielding</author>
<author>S Lewis</author>
<author>R King</author>
</authors>
<title>ART: An ontology based tool for the translation of papers into Semantic Web format.</title>
<date>2007</date>
<booktitle>Proceedings of the SIG/ISMB07 ontology workshop.,</booktitle>
<pages>33--36</pages>
<contexts>
<context position="21785" citStr="Soldatova et al., 2007" startWordPosition="3502" endWordPosition="3505">set, presumably because of lack of attention being paid to the oversplitting in a particular paper (“b103844n”). This shows that we have not overfitted to the training set in developing our splitter. Our recall is particularly high, indicating that our splitter makes very few false negative errors. We can attribute many of the false positive errors to our somewhat small set of abbreviations considered, resulting in oversplit sentences. We would like to incorporate a more sophisticated approach to abbreviations in the future. 5 Performing CISP Annotations Within the context of the ART project (Soldatova et al., 2007), SAPIENT has been used by 16 Chemistry experts to annotate 265 papers from RSC Publishing journals, covering topics in Physical Chemistry and Biochemistry. Experts have been annotating the papers sentence by sentence, assigning each sentence one of 11 core scientific concepts and linking together sentences across a paper which refer to the same instance of a concept. The aim is to create a corpus of annotated papers (ARTcorpus) with regions of scientific interest identified by CISP concepts (“Result”,“Conclusion”, “Observation”,“Method” and so on). A preliminary evaluation of the experts’ agr</context>
</contexts>
<marker>Soldatova, Batchelor, Liakata, Fielding, Lewis, King, 2007</marker>
<rawString>L. Soldatova, C. Batchelor, M. Liakata, H. Fielding, S. Lewis and R. King 2007. ART: An ontology based tool for the translation of papers into Semantic Web format. Proceedings of the SIG/ISMB07 ontology workshop., p.33–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larisa N Soldatova</author>
<author>Ross D King</author>
</authors>
<title>An Ontology of Scientific Experiments.</title>
<date>2006</date>
<journal>Journal of the Royal Society Interface,</journal>
<pages>3--795</pages>
<contexts>
<context position="8654" citStr="Soldatova and King, 2006" startWordPosition="1351" endWordPosition="1354">fier (conceptID). In the current implementation of SAPIENT, The type drop-down value corresponds to the selection of one out of 11 general scientific concepts (Liakata and Soldatova, 2008), namely (‘Background’, ‘Conclusion’, ‘Experiment’, ‘Goal of the Investigation’, ‘Hypothesis’,‘Method’, ‘Model’, ‘Motivation’, ‘Object of the Investigation’, ‘Observation’, ‘Result’). These labels originate from a set of meta-data (The Core Information about Scientific Concepts (CISP) (Soldatova and Liakata, 2007) which were constructed using an ontology methodology, based on an ontology of experiments EXPO (Soldatova and King, 2006). Because these labels map to ontology classes, they can also have properties. For example, ‘Method’ has the property ‘New’/‘Old’,‘Advantage’/‘Disadvantage’. These properties are dependent on the type selected and are expressed in terms of the subtype drop-down. The third drop-down, concept ID allows a user to provide a concept identifier. The latter is an entity formed by the name of a concept and a number (e.g. “Res2”). Concept identifiers uniquely identify an instance of a concept (e.g. the second Result), but not a sentence. That is, concept identifiers designate and link together instance</context>
</contexts>
<marker>Soldatova, King, 2006</marker>
<rawString>Larisa N. Soldatova and Ross D. King. 2006. An Ontology of Scientific Experiments. Journal of the Royal Society Interface, 3:795–803.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
<author>M Moens</author>
</authors>
<date>2002</date>
<booktitle>Summarizing Scientific Articles – Experiments with Relevance and Rhetorical Status. Computational Linguistics,</booktitle>
<volume>28</volume>
<issue>4</issue>
<pages>(preprint)</pages>
<contexts>
<context position="2339" citStr="Teufel and Moens, 2002" startWordPosition="353" endWordPosition="356">deed the case. Their experimental results suggested that span-level analysis is a promising strategy for taking advantage of the full papers, where spans are defined as paragraphs of text assessed by humans and deemed to be relevant to one of 36 pre-defined topics. Therefore, when working with full papers, it is important to be able to identify and annotate spans of text. In previous research, sentence based annotation has been used to identify text regions with scientific content of interest to the user (Wilbur et al., 2006; Shatkay et al., 2008) or zones of different rhetorical status (AZ) (Teufel and Moens, 2002). Sentences are the structural units of paragraphs and can be more flexible than paragraphs for text mining purposes other than information retrieval. Current general purpose systems for linguistic annotation such as Callisto2 allow the creation of a simple annotation schema that is a tag set augmented with simple (e.g. string) attributes for each tag. Knowtator (Ogren, 2006) is a plug-in of the knowledge representation tool Prot´eg´e3, which works as a general purpose text annotation tool and has the advantage that it can work with complex ontologyderived schemas. However, these systems are n</context>
</contexts>
<marker>Teufel, Moens, 2002</marker>
<rawString>S. Teufel and M. Moens. 2002. Summarizing Scientific Articles – Experiments with Relevance and Rhetorical Status. Computational Linguistics, 28(4). (preprint)</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wilbur</author>
<author>A Rzhetsky</author>
<author>H Shatkay</author>
</authors>
<date>2006</date>
<booktitle>New Directions in Biomedical Text Annotations: Deifinitions, Guidelines and Corpus Construction. BMC Bioinformatics,</booktitle>
<pages>7--356</pages>
<contexts>
<context position="2246" citStr="Wilbur et al., 2006" startWordPosition="338" endWordPosition="341"> (Lin Jimmy, 2009) showed that 1http://opentextmining.org/wiki/Main Page the former is indeed the case. Their experimental results suggested that span-level analysis is a promising strategy for taking advantage of the full papers, where spans are defined as paragraphs of text assessed by humans and deemed to be relevant to one of 36 pre-defined topics. Therefore, when working with full papers, it is important to be able to identify and annotate spans of text. In previous research, sentence based annotation has been used to identify text regions with scientific content of interest to the user (Wilbur et al., 2006; Shatkay et al., 2008) or zones of different rhetorical status (AZ) (Teufel and Moens, 2002). Sentences are the structural units of paragraphs and can be more flexible than paragraphs for text mining purposes other than information retrieval. Current general purpose systems for linguistic annotation such as Callisto2 allow the creation of a simple annotation schema that is a tag set augmented with simple (e.g. string) attributes for each tag. Knowtator (Ogren, 2006) is a plug-in of the knowledge representation tool Prot´eg´e3, which works as a general purpose text annotation tool and has the </context>
</contexts>
<marker>Wilbur, Rzhetsky, Shatkay, 2006</marker>
<rawString>W. Wilbur, A. Rzhetsky and H. Shatkay. 2006. New Directions in Biomedical Text Annotations: Deifinitions, Guidelines and Corpus Construction. BMC Bioinformatics, 7:356.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>