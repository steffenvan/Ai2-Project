<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013537">
<title confidence="0.994907">
Dependency-based Pre-ordering for Chinese-English Machine Translation
</title>
<author confidence="0.972279">
Jingsheng Cai†* Masao Utiyama$ Eiichiro Sumita$ Yujie Zhang††School of Computer and Information Technology, Beijing Jiaotong University
</author>
<affiliation confidence="0.955726">
$National Institute of Information and Communications Technology
</affiliation>
<email confidence="0.929626333333333">
joycetsai99@gmail.com
{mutiyama, eiichiro.sumita}@nict.go.jp
yjzhang@bjtu.edu.cn
</email>
<sectionHeader confidence="0.993698" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999890285714286">
In statistical machine translation (SMT),
syntax-based pre-ordering of the source
language is an effective method for deal-
ing with language pairs where there are
great differences in their respective word
orders. This paper introduces a novel
pre-ordering approach based on depen-
dency parsing for Chinese-English SMT.
We present a set of dependency-based pre-
ordering rules which improved the BLEU
score by 1.61 on the NIST 2006 evalua-
tion data. We also investigate the accuracy
of the rule set by conducting human eval-
uations.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997092500000001">
SMT systems have difficulties translating between
distant language pairs such as Chinese and En-
glish. The reason for this is that there are great
differences in their word orders. Reordering there-
fore becomes a key issue in SMT systems between
distant language pairs.
Previous work has shown that the approaches
tackling the problem by introducing a pre-ordering
procedure into phrase-based SMT (PBSMT) were
effective. These pre-ordering approaches first
parse the source language sentences to create parse
trees. Then, syntactic reordering rules are ap-
plied to these parse trees with the goal of re-
ordering the source language sentences into the
word order of the target language. Syntax-based
pre-ordering by employing constituent parsing
have demonstrated effectiveness in many language
pairs, such as English-French (Xia and McCord,
2004), German-English (Collins et al., 2005),
Chinese-English (Wang et al., 2007; Zhang et al.,
2008), and English-Japanese (Lee et al., 2010).
∗ This work was done when the first author was on an
internship in NICT.
As a kind of constituent structure, HPSG (Pol-
lard and Sag, 1994) parsing-based pre-ordering
showed improvements in SVO-SOV translations,
such as English-Japanese (Isozaki et al., 2010; Wu
et al., 2011) and Chinese-Japanese (Han et al.,
2012). Since dependency parsing is more concise
than constituent parsing in describing sentences,
some research has used dependency parsing in
pre-ordering approaches for language pairs such
as Arabic-English (Habash, 2007), and English-
SOV languages (Xu et al., 2009; Katz-Brown et
al., 2011). The pre-ordering rules can be made
manually (Collins et al., 2005; Wang et al., 2007;
Han et al., 2012) or extracted automatically from
a parallel corpus (Xia and McCord, 2004; Habash,
2007; Zhang et al., 2007; Wu et al., 2011).
The purpose of this paper is to introduce a novel
dependency-based pre-ordering approach through
creating a pre-ordering rule set and applying it to
the Chinese-English PBSMT system. Experiment
results showed that our pre-ordering rule set im-
proved the BLEU score on the NIST 2006 evalua-
tion data by 1.61. Moreover, this rule set substan-
tially decreased the total times of rule application
about 60%, compared with a constituent-based ap-
proach (Wang et al., 2007). We also conducted hu-
man evaluations in order to assess its accuracy. To
our knowledge, our manually created pre-ordering
rule set is the first Chinese-English dependency-
based pre-ordering rule set.
The most similar work to this paper is that of
Wang et al. (2007). They created a set of pre-
ordering rules for constituent parsers for Chinese-
English PBSMT. In contrast, we propose a set of
pre-ordering rules for dependency parsers. We
argue that even though the rules by Wang et al.
(2007) exist, it is almost impossible to automati-
cally convert their rules into rules that are appli-
cable to dependency parsers. In fact, we aban-
doned our initial attempts to automatically convert
their rules into rules for dependency parsers, and
</bodyText>
<page confidence="0.987353">
155
</page>
<bodyText confidence="0.351144">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 155–160,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<figure confidence="0.999489">
(a) A constituent parse tree
(b) Stanford typed dependency parse tree
</figure>
<figureCaption confidence="0.924887333333333">
Figure 1: A constituent parse tree and its cor-
responding Stanford typed dependency parse tree
for the same Chinese sentence.
</figureCaption>
<bodyText confidence="0.999798416666667">
spent more than two months discovering the rules
introduced in this paper. By applying our rules
and Wang et al.’s rules, one can use both depen-
dency and constituency parsers for pre-ordering in
Chinese-English PBSMT.
This is especially important on the point of the
system combination of PBSMT systems, because
the diversity of outputs from machine translation
systems is important for system combination (Cer
et al., 2013). By using both our rules and Wang et
al.’s rules, one can obtain diverse machine trans-
lation results because the pre-ordering results of
these two rule sets are generally different.
Another similar work is that of (Xu et al., 2009).
They created a pre-ordering rule set for depen-
dency parsers from English to several SOV lan-
guages. In contrast, our rule set is for Chinese-
English PBSMT. That is, the direction of transla-
tion is opposite. Because there are a lot of lan-
guage specific decisions that reflect specific as-
pects of the source language and the language pair
combination, our rule set provides a valuable re-
source for pre-ordering in Chinese-English PB-
SMT.
</bodyText>
<sectionHeader confidence="0.9201665" genericHeader="method">
2 Dependency-based Pre-ordering Rule
Set
</sectionHeader>
<bodyText confidence="0.909057153846154">
Figure 1 shows a constituent parse tree and its
Stanford typed dependency parse tree for the same
Figure 2: An example of a preposition phrase with
a plmod structure. The phrase translates into “in
front of the US embassy”.
Chinese sentence. As shown in the figure, the
number of nodes in the dependency parse tree
(i.e. 9) is much fewer than that in its correspond-
ing constituent parse tree (i.e. 17). Because de-
pendency parse trees are generally more concise
than the constituent ones, they can conduct long-
distance reorderings in a finer way. Thus, we at-
tempted to conduct pre-ordering based on depen-
dency parsing. There are two widely-used de-
pendency systems – Stanford typed dependencies
and CoNLL typed dependencies. For Chinese,
there are 45 types of grammatical relations for
Stanford typed dependencies (Chang et al., 2009)
and 25 for CoNLL typed dependencies. As we
thought that Stanford typed dependencies could
describe language phenomena more meticulously
owing to more types of grammatical relations, we
preferred to use it for searching candidate pre-
ordering rules.
We designed two types of formats in our
dependency-based pre-ordering rules. They are:
</bodyText>
<equation confidence="0.7030835">
Type-1: x : y
Type-2: x - y
</equation>
<bodyText confidence="0.999912875">
Here, both x and y are dependency relations
(e.g., plmod or lobj in Figure 2). We define the
dependency structure of a dependency relation as
the structure containing the dependent word (e.g.,
the word directly indicated by plmod, or “orf” in
Figure 2) and the whole subtree under the depen-
dency relation (all of the words that directly or
indirectly depend on the dependent word, or the
words under “orf” in Figure 2). Further, we define
X and Y as the corresponding dependency struc-
tures of the dependency relations x and y, respec-
tively. We define X\Y as structure X except Y. For
example, in Figure 2, let x and y denote plmod and
lobj dependency relations, then X represents “orf”
and all words under “orf”, Y represents “)CItM”
and all words under “)CIPM”, and X\Y represents
</bodyText>
<page confidence="0.99738">
156
</page>
<figureCaption confidence="0.994430666666667">
Figure 3: An example of rcmod structure within
an nsubj structure. The phrase translates into “a
senior official close to Sharon said”.
Figure 4: An example of rcmod structure with a
preposition modifier. The phrase translates into “a
press conference held in Kabul”.
</figureCaption>
<bodyText confidence="0.999581142857143">
“M”. For Type-1, Y is a sub-structure of X. The
rule repositions X\Y to the position before Y. For
Type-2, X and Y are ordered sibling structures un-
der a same parent node. The rule repositions X to
the position after Y.
We obtained rules as the following steps:
1 Search the Chinese dependency parse trees
in the corpus and rank all of the structures
matching the two types of rules respectively
according to their frequencies. Note that
while calculating the frequencies of Type-
1 structures, we dismissed the structures in
which X occurred before Y originally.
2 Filtration. 1) Filter out the structures which
occurred less than 5,000 times. 2) Filter
out the structures from which it was almost
impossible to derive candidate pre-ordering
rules because x or y was an “irrespective” de-
pendency relation, for example, root, conj, cc
and so on.
3 Investigate the remaining structures. For each
kind of structure, we selected some of the
sample dependency parse trees that contained
it, tried to restructure the parse trees accord-
ing to the matched rule and judged the re-
ordered Chinese phrases. If the reordering
produced a Chinese phrase that had a closer
word order to that of the English one, this
structure would be a candidate pre-ordering
rule.
4 Conduct primary experiments which used the
same training set and development set as the
experiments described in Section 3. In the
primary experiments, we tested the effective-
ness of the candidate rules and filtered the
ones that did not work based on the BLEU
scores on the development set.
As a result, we obtained eight pre-ordering rules
in total, which can be divided into three depen-
dency relation categories. They are: plmod (lo-
calizer modifier of a preposition), rcmod (relative
clause modifier) and prep (preposition modifer).
Each of these categories are discussed in detail be-
low.
plmod Figure 2 shows an example of a preposi-
tional phrase with a plmod structure, which trans-
lates literally into “in the US embassy front”. In
Chinese, the dependent word of a plmod relation
(e.g., “M” in Figure 2) occurs in the last position
of the prepositional phrase. However, in English,
this kind of word (e.g., “front” in the caption of
Figure 2) always occur directly after prepositions,
which is to say, in the second position in a preposi-
tional phrase. Therefore, we applied a rule plmod
: lobj (localizer object) to reposition the depen-
dent word of the plmod relation (e.g., “M” in Fig-
ure 2) to the position before the lobj structure (e.g.,
“XD4 -kJPM” in Figure 2). In this case, it also
comes directly after the preposition. Similarly, we
created a rule plmod : lccomp (clausal comple-
ment of a localizer).
rcmod Figure 3 shows an example of an rcmod
structure under an nsubj (nominal subject) struc-
ture. Here “mw” means “measure word”. As
shown in the figure, relative clause modifiers in
Chinese (e.g., “ �!_ Y_ft �” in Figure 3) oc-
curs before the noun being modified, which is in
contrast to English (e.g., “close to Sharon” in the
caption of Figure 3), where they come after. Thus,
we introduced a series of rules NOUN : rcmod
to restructure rcmod structures so that the noun
is moved to the head. In this example, with the
application of an nsubj : rcmod rule, the phrase
can be translated into “a senior official close to
Sharon say”, which has a word order very close
to English. Since a noun can be nsubj, dobj (di-
rect object), pobj (prepositional object) and lobj
</bodyText>
<page confidence="0.988407">
157
</page>
<table confidence="0.9996234">
Type System Parser BLEU Counts #Sent.
- No pre-ordering - 29.96 - -
Constituent WR07 Berkeley 31.45 2,561,937 852,052
Dependency OUR DEP 1 Berkeley Const. 31.54 978,013 556,752
OUR DEP 2 Mate 31.57 947,441 547,084
</table>
<tableCaption confidence="0.964915">
Table 1: The comparison of four systems, including the performance (BLEU) on the test set, the total
count of each rule set and the number of sentences they were applied to on the training set.
</tableCaption>
<figureCaption confidence="0.991443">
Figure 5: An example of verb phrase with a
preposition modifier. The phrase translates into
“Musharraf told reporters here”.
</figureCaption>
<bodyText confidence="0.999691333333333">
in Stanford typed dependencies, we created four
rules from the NOUN pattern. Note that for some
preposition modifiers, we needed a rule rcmod :
prep to conduct the same work. For instance, the
Chinese phrase in Figure 4 can be translated into
“hold in Kabul press conference” with the appli-
cation of this rule.
prep Within verb phrases, the positions of prep
structures are quite different between Chinese and
English. Figure 5 shows an example of a verb
phrase with a preposition modifier (prep), which
literally translates into “Musharraf at this place tell
reporter”. Recognizing that prep structures occur
before the verb in Chinese (e.g., “;(E !t �,ft” in Fig-
ure 5) but after the verb in English (usually in the
last position of a verb phrase, e.g., “here” in the
caption of Figure 5), we applied a rule prep - dobj
to reposition prep structures after their sibling dobj
structures.
In summary, the dependency-based pre-
ordering rule set has eight rules: plmod : lobj,
plmod : lccomp, nsubj : rcmod, dobj : rcmod,
pobj : rcmod, lobj : rcmod, rcmod : prep, and
prep - dobj.
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999980204545455">
We used the MOSES PBSMT system (Koehn et
al., 2007) in our experiments. The training data,
which included those data used in Wang et al.
(2007), contained 1 million pairs of sentences ex-
tracted from the Linguistic Data Consortium’s par-
allel news corpora. Our development set was
the official NIST MT evaluation data from 2002
to 2005, consisting of 4476 Chinese-English sen-
tences pairs. Our test set was the NIST 2006 MT
evaluation data, consisting of 1664 sentence pairs.
We employed the Stanford Segmenter1 to segment
all of the data sets. For evaluation, we used BLEU
scores (Papineni et al., 2002).
We implemented the constituent-based pre-
ordering rule set in Wang et al. (2007) for compar-
ison, which is called WR07 below. The Berkeley
Parser (Petrov et al., 2006) was employed for pars-
ing the Chinese sentences. For training the Berke-
ley Parser, we used Chinese Treebank (CTB) 7.0.
We conducted our dependency-based pre-
ordering experiments on the Berkeley Parser and
the Mate Parser (Bohnet, 2010), which were
shown to be the two best parsers for Stanford
typed dependencies (Che et al., 2012). First, we
converted the constituent parse trees in the re-
sults of the Berkeley Parser into dependency parse
trees by employing a tool in the Stanford Parser
(Klein and Manning, 2003). For the Mate Parser,
POS tagged inputs are required both in training
and in inference. Thus, we then extracted the
POS information from the results of the Berke-
ley Parser and used these as the pre-specified POS
tags for the Mate Parser. Finally, we applied our
dependency-based pre-ordering rule set to the de-
pendency parse trees created from the converted
Berkeley Parser and the Mate Parser, respectively.
Table 1 presents a comparison of the system
without pre-ordering, the constituent system us-
ing WR07 and two dependency systems employ-
ing the converted Berkeley Parser and the Mate
Parser, respectively. It shows the BLEU scores on
the test set and the statistics of pre-ordering on the
training set, which includes the total count of each
rule set and the number of sentences they were ap-
</bodyText>
<footnote confidence="0.983788">
1http://nlp.stanford.edu/software/segmenter.shtml
</footnote>
<page confidence="0.98797">
158
</page>
<table confidence="0.9992456">
Category Count Correct Incorrect Accuracy
plmod 42 26 16 61.9%
rcmod 89 49 40 55.1%
prep 54 36 18 66.7%
All 185 111 74 60.0%
</table>
<tableCaption confidence="0.942084">
Table 2: Accuracy of the dependency-based pre-ordering rules on a set of 200 sentences randomly se-
lected from the development set.
</tableCaption>
<bodyText confidence="0.999289387755102">
plied to. Both of our dependency systems outper-
formed WR07 slightly but were not significant at
p = 0.05. However, both of them substantially de-
creased the total times about 60% (or 1,600,000)
for pre-ordering rule applications on the training
set, compared with WR07. In our opinion, the rea-
son for the great decrease was that the dependency
parse trees were more concise than the constituent
parse trees in describing sentences and they could
also describe the reordering at the sentence level in
a finer way. In contrast, the constituent parse trees
were more redundant and they needed more nodes
to conduct long-distance reordering. In this case,
the affect of the performance of the constituent
parsers on pre-ordering is larger than that of the
dependency ones so that the constituent parsers are
likely to bring about more incorrect pre-orderings.
Similar to Wang et al. (2007), we carried out
human evaluations to assess the accuracy of our
dependency-based pre-ordering rules by employ-
ing the system “OUR DEP 2” in Table 1. The
evaluation set contained 200 sentences randomly
selected from the development set. Among them,
107 sentences contained at least one rule and the
rules were applied 185 times totally. Since the
accuracy check for dependency parse trees took
great deal of time, we did not try to select er-
ror free (100% accurately parsed) sentences. A
bilingual speaker of Chinese and English looked
at an original Chinese phrase and the pre-ordered
one with their corresponding English phrase and
judged whether the pre-ordering obtained a Chi-
nese phrase that had a closer word order to the En-
glish one. Table 2 shows the accuracies of three
categories of our dependency-based pre-ordering
rules. The overall accuracy of this rule set is
60.0%, which is almost at the same level as the
WR07 rule set (62.1%), according to the similar
evaluation (200 sentences and one annotator) con-
ducted in Wang et al. (2007). Notice that some
of the incorrect pre-orderings may be caused by
erroneous parsing as also suggested by Wang et
al. (2007). Through human evaluations, we found
that 19 out of the total 74 incorrect pre-orderings
resulted from errors in parsing. Among them, 13
incorrect pre-orderings applied the rules of the rc-
mod category. The analysis suggests that we need
to introduce constraints on the rule application of
this category in the future.
</bodyText>
<sectionHeader confidence="0.997746" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999962388888889">
In this paper, we introduced a novel pre-ordering
approach based on dependency parsing for a
Chinese-English PBSMT system. The results
showed that our approach achieved a BLEU score
gain of 1.61. Moreover, our dependency-based
pre-ordering rule set substantially decreased the
time for applying pre-ordering rules about 60%
compared with WR07, on the training set of 1M
sentences pairs. The overall accuracy of our rule
set is 60.0%, which is almost at the same level as
the WR07 rule set. These results indicated that
dependency parsing is more effective for conduct-
ing pre-ordering for Chinese-English PBSMT. Al-
though our work focused on Chinese, the ideas can
also be applied to other languages.
In the future, we attempt to create more efficient
pre-ordering rules by exploiting the rich informa-
tion in dependency structures.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99989875">
We thank the anonymous reviewers for their valu-
able comments and suggestions. This work is sup-
ported in part by the International Science &amp; Tech-
nology Cooperation Program of China (Grant No.
2014DFA11350) and Key Lab of Intelligent In-
formation Processing of Chinese Academy of Sci-
ences (CAS), Institute of Computing Technology,
CAS, Beijing 100190, China.
</bodyText>
<sectionHeader confidence="0.990196" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.561771">
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
</reference>
<page confidence="0.995678">
159
</page>
<reference confidence="0.997480861111111">
ings of the 23rd International Conference on Com-
putational Linguistics (COLING 2010).
Daniel Cer, Christopher D. Manning, and Dan Juraf-
sky. 2013. Positive Diversity Tuning for Machine
Translation System Combination. In Proceedings of
the Eighth Workshop on Statistical Machine Trans-
lation (WMT 2013).
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative
reordering with Chinese grammatical relations fea-
tures. In Proceedings of the HLT-NAACL Workshop
on Syntax and Structure in Statistical Translation,
pages 51-59.
Wanxiang Che, Valentin Spitkovsky, and Ting Liu.
2012. A comparison of Chinese parsers for Stan-
ford dependencies. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics, pages 11-16.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Lin-
guistics, pages 531-540.
Dan Han, Katsuhito Sudoh, Xianchao Wu, Kevin Duh,
Hajime Tsukada, and Masaaki Nagata. 2012. Head
Finalization reordering for Chinese-to-Japanese ma-
chine translation. In Proceedings of SSST-6, Sixth
Workshop on Syntax, Semantics and Structure in
Statistical Translation, pages 57-66.
Nizar Habash. 2007. Syntactic preprocessing for sta-
tistical machine translation. In Proceedings of the
11th Machine Translation Summit (MT-Summit).
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and
Kevin Duh. 2010. Head Finalization: A simple re-
ordering rule for SOV languages. In Proceedings
of the Joint Fifth Workshop on Statistical Machine
Translation and MetricsMATR, pages 250-257.
Jason Katz-Brown, Slav Petrov, Ryan McDonald,
Franz J. Och, David Talbot, Hiroshi Ichikawa,
Masakazu Seno, and Hideto Kazawa. 2011. Train-
ing a parser for machine translation reordering. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 183-
192.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics, pages 423-430.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster
Sessions, pages 177-180.
Young-Suk Lee, Bing Zhao, and Xiaoqian Luo.
2010. Constituent reordering and syntax models for
English-to-Japanese statistical machine translation.
In Proceedings of the 23rd International of Confer-
ence on Computational Linguistics, pages 626-634.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311-318.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 433-440.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. University of Chicago
Press.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, pages 737-745.
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. 2011. Extracting
preordering rules from predicate-argument struc-
tures. In Proceedings of 5th International Joint Con-
ference on Natural Language Processing, pages 29-
37.
Fei Xia and Michael McCord. 2004. Improving
a statistical MT system with automatically learned
rewrite patterns. In Proceedings of Coling 2004,
pages 508-514.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz J.
Och. 2009. Using a dependency parser to improve
SMT for subject-object-verb languages. In Proceed-
ings of HLT-NAACL, pages 245-253.
Jiajun Zhang, Chengqing Zong, and Shoushan Li.
2008. Sentence type based reordering model for sta-
tistical machine translation. In Proceedings of the
22nd International Conference on Computational
Linguistics, pages 1089-1096.
Yuqi Zhang, Richard Zens, and Hermann Ney. 2011.
Chunk-level reordering of source language sen-
tences with automatically learned rules for statisti-
cal machine translation. In HLT-NAACL Workshop
on Syntax and Structure in Statistical Translation,
pages 1-8.
</reference>
<page confidence="0.99743">
160
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.348067">
<title confidence="0.774744">Dependency-based Pre-ordering for Chinese-English Machine Translation Masao of Computer and Information Technology, Beijing Jiaotong Institute of Information and Communications</title>
<email confidence="0.685137">yjzhang@bjtu.edu.cn</email>
<abstract confidence="0.991992533333333">In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT. We present a set of dependency-based preordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data. We also investigate the accuracy of the rule set by conducting human evaluations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="13763" citStr="Bohnet, 2010" startWordPosition="2250" endWordPosition="2251">r test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering rule set in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Parser (Petrov et al., 2006) was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0. We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al., 2012). First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser (Klein and Manning, 2003). For the Mate Parser, POS tagged inputs are required both in training and in inference. Thus, we then extracted the POS information from the results of the Berkeley Parser and used these as the pre-specified POS tags for the Mate Parser. Finally, we applied our dependency-based pre-ordering rule set to the dependency </context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
<author>Dan Jurafsky</author>
</authors>
<title>Positive Diversity Tuning for Machine Translation System Combination.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation (WMT</booktitle>
<contexts>
<context position="4745" citStr="Cer et al., 2013" startWordPosition="715" endWordPosition="718">) A constituent parse tree (b) Stanford typed dependency parse tree Figure 1: A constituent parse tree and its corresponding Stanford typed dependency parse tree for the same Chinese sentence. spent more than two months discovering the rules introduced in this paper. By applying our rules and Wang et al.’s rules, one can use both dependency and constituency parsers for pre-ordering in Chinese-English PBSMT. This is especially important on the point of the system combination of PBSMT systems, because the diversity of outputs from machine translation systems is important for system combination (Cer et al., 2013). By using both our rules and Wang et al.’s rules, one can obtain diverse machine translation results because the pre-ordering results of these two rule sets are generally different. Another similar work is that of (Xu et al., 2009). They created a pre-ordering rule set for dependency parsers from English to several SOV languages. In contrast, our rule set is for ChineseEnglish PBSMT. That is, the direction of translation is opposite. Because there are a lot of language specific decisions that reflect specific aspects of the source language and the language pair combination, our rule set provi</context>
</contexts>
<marker>Cer, Manning, Jurafsky, 2013</marker>
<rawString>Daniel Cer, Christopher D. Manning, and Dan Jurafsky. 2013. Positive Diversity Tuning for Machine Translation System Combination. In Proceedings of the Eighth Workshop on Statistical Machine Translation (WMT 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Huihsin Tseng</author>
<author>Dan Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Discriminative reordering with Chinese grammatical relations features.</title>
<date>2009</date>
<booktitle>In Proceedings of the HLT-NAACL Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>51--59</pages>
<contexts>
<context position="6285" citStr="Chang et al., 2009" startWordPosition="972" endWordPosition="975"> embassy”. Chinese sentence. As shown in the figure, the number of nodes in the dependency parse tree (i.e. 9) is much fewer than that in its corresponding constituent parse tree (i.e. 17). Because dependency parse trees are generally more concise than the constituent ones, they can conduct longdistance reorderings in a finer way. Thus, we attempted to conduct pre-ordering based on dependency parsing. There are two widely-used dependency systems – Stanford typed dependencies and CoNLL typed dependencies. For Chinese, there are 45 types of grammatical relations for Stanford typed dependencies (Chang et al., 2009) and 25 for CoNLL typed dependencies. As we thought that Stanford typed dependencies could describe language phenomena more meticulously owing to more types of grammatical relations, we preferred to use it for searching candidate preordering rules. We designed two types of formats in our dependency-based pre-ordering rules. They are: Type-1: x : y Type-2: x - y Here, both x and y are dependency relations (e.g., plmod or lobj in Figure 2). We define the dependency structure of a dependency relation as the structure containing the dependent word (e.g., the word directly indicated by plmod, or “o</context>
</contexts>
<marker>Chang, Tseng, Jurafsky, Manning, 2009</marker>
<rawString>Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christopher D. Manning. 2009. Discriminative reordering with Chinese grammatical relations features. In Proceedings of the HLT-NAACL Workshop on Syntax and Structure in Statistical Translation, pages 51-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Valentin Spitkovsky</author>
<author>Ting Liu</author>
</authors>
<title>A comparison of Chinese parsers for Stanford dependencies.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>11--16</pages>
<contexts>
<context position="13859" citStr="Che et al., 2012" startWordPosition="2265" endWordPosition="2268">yed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering rule set in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Parser (Petrov et al., 2006) was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0. We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al., 2012). First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser (Klein and Manning, 2003). For the Mate Parser, POS tagged inputs are required both in training and in inference. Thus, we then extracted the POS information from the results of the Berkeley Parser and used these as the pre-specified POS tags for the Mate Parser. Finally, we applied our dependency-based pre-ordering rule set to the dependency parse trees created from the converted Berkeley Parser and the Mate Parser, respectively. Table </context>
</contexts>
<marker>Che, Spitkovsky, Liu, 2012</marker>
<rawString>Wanxiang Che, Valentin Spitkovsky, and Ting Liu. 2012. A comparison of Chinese parsers for Stanford dependencies. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 11-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>531--540</pages>
<contexts>
<context position="1784" citStr="Collins et al., 2005" startWordPosition="246" endWordPosition="249"> pairs. Previous work has shown that the approaches tackling the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such </context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kucerova. 2005. Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 531-540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Han</author>
<author>Katsuhito Sudoh</author>
<author>Xianchao Wu</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Head Finalization reordering for Chinese-to-Japanese machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>57--66</pages>
<contexts>
<context position="2198" citStr="Han et al., 2012" startWordPosition="312" endWordPosition="315">ge. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce a novel dependency-based pre-ordering ap</context>
</contexts>
<marker>Han, Sudoh, Wu, Duh, Tsukada, Nagata, 2012</marker>
<rawString>Dan Han, Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. 2012. Head Finalization reordering for Chinese-to-Japanese machine translation. In Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 57-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Syntactic preprocessing for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Machine Translation Summit (MT-Summit).</booktitle>
<contexts>
<context position="2416" citStr="Habash, 2007" startWordPosition="343" endWordPosition="344">Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system. Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by </context>
</contexts>
<marker>Habash, 2007</marker>
<rawString>Nizar Habash. 2007. Syntactic preprocessing for statistical machine translation. In Proceedings of the 11th Machine Translation Summit (MT-Summit).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Kevin Duh</author>
</authors>
<title>Head Finalization: A simple reordering rule for SOV languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>250--257</pages>
<contexts>
<context position="2140" citStr="Isozaki et al., 2010" startWordPosition="302" endWordPosition="305">e language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this pape</context>
</contexts>
<marker>Isozaki, Sudoh, Tsukada, Duh, 2010</marker>
<rawString>Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and Kevin Duh. 2010. Head Finalization: A simple reordering rule for SOV languages. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 250-257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Katz-Brown</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Franz J Och</author>
<author>David Talbot</author>
<author>Hiroshi Ichikawa</author>
<author>Masakazu Seno</author>
<author>Hideto Kazawa</author>
</authors>
<title>Training a parser for machine translation reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>183--192</pages>
<contexts>
<context position="2485" citStr="Katz-Brown et al., 2011" startWordPosition="353" endWordPosition="356">se (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system. Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61. Moreover, this rule set substantially decreased the total times</context>
</contexts>
<marker>Katz-Brown, Petrov, McDonald, Och, Talbot, Ichikawa, Seno, Kazawa, 2011</marker>
<rawString>Jason Katz-Brown, Slav Petrov, Ryan McDonald, Franz J. Och, David Talbot, Hiroshi Ichikawa, Masakazu Seno, and Hideto Kazawa. 2011. Training a parser for machine translation reordering. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 183-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="14043" citStr="Klein and Manning, 2003" startWordPosition="2296" endWordPosition="2299">et in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Parser (Petrov et al., 2006) was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0. We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al., 2012). First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser (Klein and Manning, 2003). For the Mate Parser, POS tagged inputs are required both in training and in inference. Thus, we then extracted the POS information from the results of the Berkeley Parser and used these as the pre-specified POS tags for the Mate Parser. Finally, we applied our dependency-based pre-ordering rule set to the dependency parse trees created from the converted Berkeley Parser and the Mate Parser, respectively. Table 1 presents a comparison of the system without pre-ordering, the constituent system using WR07 and two dependency systems employing the converted Berkeley Parser and the Mate Parser, re</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 423-430.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="12812" citStr="Koehn et al., 2007" startWordPosition="2092" endWordPosition="2095">s into “Musharraf at this place tell reporter”. Recognizing that prep structures occur before the verb in Chinese (e.g., “;(E !t �,ft” in Figure 5) but after the verb in English (usually in the last position of a verb phrase, e.g., “here” in the caption of Figure 5), we applied a rule prep - dobj to reposition prep structures after their sibling dobj structures. In summary, the dependency-based preordering rule set has eight rules: plmod : lobj, plmod : lccomp, nsubj : rcmod, dobj : rcmod, pobj : rcmod, lobj : rcmod, rcmod : prep, and prep - dobj. 3 Experiments We used the MOSES PBSMT system (Koehn et al., 2007) in our experiments. The training data, which included those data used in Wang et al. (2007), contained 1 million pairs of sentences extracted from the Linguistic Data Consortium’s parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs. Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Bing Zhao</author>
<author>Xiaoqian Luo</author>
</authors>
<title>Constituent reordering and syntax models for English-to-Japanese statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International of Conference on Computational Linguistics,</booktitle>
<pages>626--634</pages>
<contexts>
<context position="1882" citStr="Lee et al., 2010" startWordPosition="261" endWordPosition="264"> procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 20</context>
</contexts>
<marker>Lee, Zhao, Luo, 2010</marker>
<rawString>Young-Suk Lee, Bing Zhao, and Xiaoqian Luo. 2010. Constituent reordering and syntax models for English-to-Japanese statistical machine translation. In Proceedings of the 23rd International of Conference on Computational Linguistics, pages 626-634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="13362" citStr="Papineni et al., 2002" startWordPosition="2183" endWordPosition="2186"> dobj. 3 Experiments We used the MOSES PBSMT system (Koehn et al., 2007) in our experiments. The training data, which included those data used in Wang et al. (2007), contained 1 million pairs of sentences extracted from the Linguistic Data Consortium’s parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs. Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering rule set in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Parser (Petrov et al., 2006) was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0. We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al., 2012). First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="13529" citStr="Petrov et al., 2006" startWordPosition="2211" endWordPosition="2214">tained 1 million pairs of sentences extracted from the Linguistic Data Consortium’s parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs. Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering rule set in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Parser (Petrov et al., 2006) was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0. We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser (Bohnet, 2010), which were shown to be the two best parsers for Stanford typed dependencies (Che et al., 2012). First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser (Klein and Manning, 2003). For the Mate Parser, POS tagged inputs are required both in training and in inferenc</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433-440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2021" citStr="Pollard and Sag, 1994" startWordPosition="287" endWordPosition="291">eate parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically fro</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Wang</author>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>737--745</pages>
<contexts>
<context position="1820" citStr="Wang et al., 2007" startWordPosition="251" endWordPosition="254"> approaches tackling the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), an</context>
<context position="3179" citStr="Wang et al., 2007" startWordPosition="467" endWordPosition="470"> al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system. Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61. Moreover, this rule set substantially decreased the total times of rule application about 60%, compared with a constituent-based approach (Wang et al., 2007). We also conducted human evaluations in order to assess its accuracy. To our knowledge, our manually created pre-ordering rule set is the first Chinese-English dependencybased pre-ordering rule set. The most similar work to this paper is that of Wang et al. (2007). They created a set of preordering rules for constituent parsers for ChineseEnglish PBSMT. In contrast, we propose a set of pre-ordering rules for dependency parsers. We argue that even though the rules by Wang et al. (2007) exist, it is almost impossible to automatically convert their rules into rules that are applicable to depende</context>
<context position="12904" citStr="Wang et al. (2007)" startWordPosition="2108" endWordPosition="2111"> the verb in Chinese (e.g., “;(E !t �,ft” in Figure 5) but after the verb in English (usually in the last position of a verb phrase, e.g., “here” in the caption of Figure 5), we applied a rule prep - dobj to reposition prep structures after their sibling dobj structures. In summary, the dependency-based preordering rule set has eight rules: plmod : lobj, plmod : lccomp, nsubj : rcmod, dobj : rcmod, pobj : rcmod, lobj : rcmod, rcmod : prep, and prep - dobj. 3 Experiments We used the MOSES PBSMT system (Koehn et al., 2007) in our experiments. The training data, which included those data used in Wang et al. (2007), contained 1 million pairs of sentences extracted from the Linguistic Data Consortium’s parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs. Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter1 to segment all of the data sets. For evaluation, we used BLEU scores (Papineni et al., 2002). We implemented the constituent-based preordering rule set in Wang et al. (2007) for comparison, which is called WR07 below. The Berkeley Par</context>
<context position="16034" citStr="Wang et al. (2007)" startWordPosition="2622" endWordPosition="2625">7. In our opinion, the reason for the great decrease was that the dependency parse trees were more concise than the constituent parse trees in describing sentences and they could also describe the reordering at the sentence level in a finer way. In contrast, the constituent parse trees were more redundant and they needed more nodes to conduct long-distance reordering. In this case, the affect of the performance of the constituent parsers on pre-ordering is larger than that of the dependency ones so that the constituent parsers are likely to bring about more incorrect pre-orderings. Similar to Wang et al. (2007), we carried out human evaluations to assess the accuracy of our dependency-based pre-ordering rules by employing the system “OUR DEP 2” in Table 1. The evaluation set contained 200 sentences randomly selected from the development set. Among them, 107 sentences contained at least one rule and the rules were applied 185 times totally. Since the accuracy check for dependency parse trees took great deal of time, we did not try to select error free (100% accurately parsed) sentences. A bilingual speaker of Chinese and English looked at an original Chinese phrase and the pre-ordered one with their </context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Chao Wang, Michael Collins, and Philipp Koehn. 2007. Chinese syntactic reordering for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 737-745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianchao Wu</author>
<author>Katsuhito Sudoh</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Extracting preordering rules from predicate-argument structures.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>29--37</pages>
<contexts>
<context position="2158" citStr="Wu et al., 2011" startWordPosition="306" endWordPosition="309">nto the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce </context>
</contexts>
<marker>Wu, Sudoh, Duh, Tsukada, Nagata, 2011</marker>
<rawString>Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. 2011. Extracting preordering rules from predicate-argument structures. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 29-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>508--514</pages>
<contexts>
<context position="1745" citStr="Xia and McCord, 2004" startWordPosition="241" endWordPosition="244">in SMT systems between distant language pairs. Previous work has shown that the approaches tackling the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-order</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of Coling 2004, pages 508-514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Xu</author>
<author>Jaeho Kang</author>
<author>Michael Ringgaard</author>
<author>Franz J Och</author>
</authors>
<title>Using a dependency parser to improve SMT for subject-object-verb languages.</title>
<date>2009</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>245--253</pages>
<contexts>
<context position="2459" citStr="Xu et al., 2009" startWordPosition="349" endWordPosition="352">nd English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV languages (Xu et al., 2009; Katz-Brown et al., 2011). The pre-ordering rules can be made manually (Collins et al., 2005; Wang et al., 2007; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011). The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system. Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61. Moreover, this rule set substantially</context>
<context position="4977" citStr="Xu et al., 2009" startWordPosition="755" endWordPosition="758">he rules introduced in this paper. By applying our rules and Wang et al.’s rules, one can use both dependency and constituency parsers for pre-ordering in Chinese-English PBSMT. This is especially important on the point of the system combination of PBSMT systems, because the diversity of outputs from machine translation systems is important for system combination (Cer et al., 2013). By using both our rules and Wang et al.’s rules, one can obtain diverse machine translation results because the pre-ordering results of these two rule sets are generally different. Another similar work is that of (Xu et al., 2009). They created a pre-ordering rule set for dependency parsers from English to several SOV languages. In contrast, our rule set is for ChineseEnglish PBSMT. That is, the direction of translation is opposite. Because there are a lot of language specific decisions that reflect specific aspects of the source language and the language pair combination, our rule set provides a valuable resource for pre-ordering in Chinese-English PBSMT. 2 Dependency-based Pre-ordering Rule Set Figure 1 shows a constituent parse tree and its Stanford typed dependency parse tree for the same Figure 2: An example of a </context>
</contexts>
<marker>Xu, Kang, Ringgaard, Och, 2009</marker>
<rawString>Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz J. Och. 2009. Using a dependency parser to improve SMT for subject-object-verb languages. In Proceedings of HLT-NAACL, pages 245-253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Zhang</author>
<author>Chengqing Zong</author>
<author>Shoushan Li</author>
</authors>
<title>Sentence type based reordering model for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>1089--1096</pages>
<contexts>
<context position="1841" citStr="Zhang et al., 2008" startWordPosition="255" endWordPosition="258">g the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004), German-English (Collins et al., 2005), Chinese-English (Wang et al., 2007; Zhang et al., 2008), and English-Japanese (Lee et al., 2010). ∗ This work was done when the first author was on an internship in NICT. As a kind of constituent structure, HPSG (Pollard and Sag, 1994) parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese (Isozaki et al., 2010; Wu et al., 2011) and Chinese-Japanese (Han et al., 2012). Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007), and EnglishSOV language</context>
</contexts>
<marker>Zhang, Zong, Li, 2008</marker>
<rawString>Jiajun Zhang, Chengqing Zong, and Shoushan Li. 2008. Sentence type based reordering model for statistical machine translation. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 1089-1096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuqi Zhang</author>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Chunk-level reordering of source language sentences with automatically learned rules for statistical machine translation.</title>
<date>2011</date>
<booktitle>In HLT-NAACL Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>1--8</pages>
<marker>Zhang, Zens, Ney, 2011</marker>
<rawString>Yuqi Zhang, Richard Zens, and Hermann Ney. 2011. Chunk-level reordering of source language sentences with automatically learned rules for statistical machine translation. In HLT-NAACL Workshop on Syntax and Structure in Statistical Translation, pages 1-8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>