<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000596">
<note confidence="0.725999">
ACL-08: HLT
</note>
<title confidence="0.9700885">
Workshop on
Mobile Language
Processing
Proceedings of the Workshop
</title>
<author confidence="0.941823">
June 20, 2008
</author>
<affiliation confidence="0.94582">
The Ohio State University
Columbus, Ohio, USA
</affiliation>
<note confidence="0.621546">
Production and Manufacturing by
Omnipress Inc.
2600 Anderson Street
Madison, WI 53707
USA
c�2008 The Association for Computational Linguistics
Order copies of this and other ACL proceedings from:
Association for Computational Linguistics (ACL)
209 N. Eighth Street
Stroudsburg, PA 18360
USA
Tel: +1-570-476-8006
Fax: +1-570-476-0860
</note>
<email confidence="0.788303">
acl@aclweb.org
</email>
<sectionHeader confidence="0.684494" genericHeader="abstract">
ISBN 978-1-932432-13-8
</sectionHeader>
<page confidence="0.733403">
ii
</page>
<sectionHeader confidence="0.903172" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.996220775862069">
Mobile devices such as ultra-mobile PCs, personal digital assistants, and smart phones have many
unique characteristics that make them both highly desirable as well as difficult to use. On the positive
side, they are small, convenient, personalizable, and provide an anytime-anywhere communication
capability. On the other hand, they have limited input and output capabilities, limited bandwidth,
limited memory, and restricted processing power.
In anticipation of new and exciting applications for natural and spoken language processing on mobile
devices, this workshop provided a forum for discussing some of the challenges that are unique to this
domain. For instance, mobile devices are beginning to integrate sensors (most commonly for location
detection through GPS, Global Positioning Systems) that can be exploited by context/location aware
NLP systems. Another interesting research direction is the use of information from multiple devices
for “distributed” language modeling and inference. To give some concrete examples, knowing the type
of web queries made from nearby devices or from a specific location or ’context’ can be combined
for various applications and could potentially improve information retrieval results. Learned language
models could be transferred from device to device, propagating and updating the language models
continuously and in a decentralized manner.
Processing and memory limitations faced by the execution of NLP and speech recognition software
on small devices need to be addressed. Several papers addressed this issue. In “Information
extraction using finite state automata and syllable n-grams” Seon et al. proposed a modified HMM
for information extraction in a mobile environment. This kind of model has the advantage of being
compact. Huggins-Daines et al. proposed a simple entropy-based technique to improve the scalability
of acoustic models in embedded systems; they showed a significant speed-up in recognition with
a negligible increase in word error rate (“Mixture Pruning and Roughening for Scalable Acoustic
Models.”) Ganchev and Dredze in “Small Statistical Models by Random Feature Mixing” showed
how it is possible to do efficient NLP learning by reducing the number of parameters on resource
constrained devices with little loss in performance; and “A Wearable Headset Speech-to-Speech
Translation System” by Krstovski et al. shrunk a speech translation system to fit into a wearable
speech-to-speech translation system.
Some applications and practical considerations may require a client/server or distributed architecture:
what are the implications for language processing systems in using such architectures? Homola (“A
Distributed Database for Mobile NLP Applications”) proposed a distributed database for lexical
transfer in machine translation. The database contains data shared among multiple devices and
automatically synchronizes them.
The limitation of the input and output channels necessitates typing on increasingly smaller keyboards
which can be quite difficult, and similarly reading on small displays is challenging. Speech interfaces
for dictation or for understanding navigation commands and/or language models for typing suggestions
would enhance the input channel, while NLP systems for text classification, summarization and
iii
information extraction would be helpful for the output channel. Speech and multimodal interfaces,
language generation and dialog systems would provide a natural way to interact with mobile devices. A
multimodal dialogue system for interacting with a home entertainment center via a mobile device was
proposed by Gruenstein et al. in “A Multimodal Home entertainment Interface via a Mobile Device.”
Furthermore, the growing market of cell phones in developing regions can be used for delivering
applications in the areas of health, education and economic growth to rural communities. Some of
the challenges in this area are the limited literacy, the many languages and dialects spoken and the
networking infrastructure.
For the health domain, Nikolova and Ma in their paper “Assistive Mobile Communication Support”
discussed the role of mobile technologies in a system for communication support for people with
speech and language disabilities.
We believe that the issues raised by the papers in this Workshop represent just the tip of the iceberg,
and we hope that by raising awareness of these issues, more research will be aimed at mobile language
processing. The ACL 2008 Workshop on Mobile Language Processing took place on June 20 in
Columbus, Ohio following ACL-08: HLT with an invited talk by Dr. Lisa Stifelman, Principal User
Experience Manager at Tellme/Microsoft, seven oral paper presentations, a poster and a demo session
and a panel discussion.
We thank the members of the Program Committee for their diligent and insightful reviews, as well as
our illustrious Panel Session members.
Barbara Rosario and Tim Paek
Co-Organizers
</bodyText>
<page confidence="0.61">
iv
</page>
<table confidence="0.959784958333333">
Organizers:
Barbara Rosario, Intel Research
Tim Paek, Microsoft Research
Program Committee:
Alex Acero, Microsoft Research
Alan Black, CMU
Dilek Hakkani Tur, ICSI
Marti Hearst, iSchool, UC Berkeley
Michael Johnston, AT&amp;T
Maryam Kamvar, Google and Columbia University
Kevin Knight, USC/Information Sciences Institute
Julian Kupiec, Google
Dekang Lin, University of Alberta, Canada
Maryam Mahdaviani, University of British Columbia, Canada
Wolfgang Minker, University of Ulm, Germany
Noah Smith, CMU
Bo Thiesson, Microsoft Research
Gokhan Tur , SRI
Fuliang Weng, Bosch
Thomas Zheng , Tsinghua University
Geoffrey Zweig, Microsoft Research
Invited Speaker:
Lisa Stifelman, Principal User Experience Manager at Tellme/Microsoft.
v
</table>
<tableCaption confidence="0.96999">
Table of Contents
</tableCaption>
<figure confidence="0.894470944444445">
A Multimodal Home Entertainment Interface via a Mobile Device
Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee Hetherington,
Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu 1
A Wearable Headset Speech-to-Speech Translation System
Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem and Premkumar
Natarajan 10
Information extraction using finite state automata and syllable n-grams in a mobile environment
Choong-Nyoung Seon, Harksoo Kim and Jungyun Seo 13
Small Statistical Models by Random Feature Mixing
Kuzman Ganchev and Mark Dredze 19
Mixture Pruning and Roughening for Scalable Acoustic Models
David Huggins-Daines and Alexander I. Rudnicky 21
Assistive Mobile Communication Support
Sonya Nikolova and Xiaojuan Ma 25
A Distributed Database for Mobile NLP Applications
Petr Homola 27
vii
Workshop Program
</figure>
<note confidence="0.543904">
Friday, June 20, 2008
</note>
<reference confidence="0.956774076923077">
8:45–9:00 Opening Remarks
9:00–10:00 Invited Talk by Dr. Lisa Stifelman, Principal User Experience Manager at
Tellme/Microsoft. Say it and See it! Applying User-Centered Design to Mobile
and Multimodal Search.
10:00–10:30 A Multimodal Home Entertainment Interface via a Mobile Device
Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee
Hetherington, Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu
10:30–11:00 Break
11:00–11:25 A Wearable Headset Speech-to-Speech Translation System
Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem
and Premkumar Natarajan
11:25–11:50 Information extraction using finite state automata and syllable n-grams in a mobile
environment
Choong-Nyoung Seon, Harksoo Kim and Jungyun Seo
11:50–12:15 Small Statistical Models by Random Feature Mixing
Kuzman Ganchev and Mark Dredze
12:15–1:15 Lunch
1:15–1:40 Mixture Pruning and Roughening for Scalable Acoustic Models
David Huggins-Daines and Alexander I. Rudnicky
1:40–2:05 Assistive Mobile Communication Support
Sonya Nikolova and Xiaojuan Ma
2:05–2:30 A Distributed Database for Mobile NLP Applications
Petr Homola
2:30–3:30 Demos and Posters
3:30–4:00 Break
4:00–5:00 Panel Session
</reference>
<page confidence="0.808561">
ix
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.014138">
<note confidence="0.656288">ACL-08: HLT Workshop on</note>
<title confidence="0.722864">Mobile Language Processing</title>
<note confidence="0.904079">Proceedings of the Workshop</note>
<date confidence="0.982938">June 20, 2008</date>
<affiliation confidence="0.682446">The Ohio State</affiliation>
<address confidence="0.997041">Columbus, Ohio, USA</address>
<author confidence="0.684048">Production</author>
<author confidence="0.684048">Manufacturing by</author>
<affiliation confidence="0.994596">Omnipress Inc.</affiliation>
<address confidence="0.994518333333333">2600 Anderson Street Madison, WI 53707 USA</address>
<title confidence="0.535685">The Association for Computational Linguistics</title>
<author confidence="0.427293">Order copies of this</author>
<author confidence="0.427293">other ACL proceedings from</author>
<affiliation confidence="0.817318">Association for Computational Linguistics (ACL)</affiliation>
<address confidence="0.998977333333333">209 N. Eighth Street Stroudsburg, PA 18360 USA</address>
<phone confidence="0.9993445">Tel: +1-570-476-8006 Fax: +1-570-476-0860</phone>
<email confidence="0.943608">acl@aclweb.org</email>
<phone confidence="0.380326">ISBN 978-1-932432-13-8</phone>
<intro confidence="0.655113">ii</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>8:45–9:00 Opening Remarks 9:00–10:00 Invited Talk by Dr. Lisa Stifelman, Principal User Experience Manager at Tellme/Microsoft. Say it and See it! Applying User-Centered Design to Mobile and Multimodal Search.</title>
<marker></marker>
<rawString>8:45–9:00 Opening Remarks 9:00–10:00 Invited Talk by Dr. Lisa Stifelman, Principal User Experience Manager at Tellme/Microsoft. Say it and See it! Applying User-Centered Design to Mobile and Multimodal Search.</rawString>
</citation>
<citation valid="false">
<title>10:00–10:30 A Multimodal Home Entertainment Interface via a Mobile Device Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee Hetherington, Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu 10:30–11:00 Break 11:00–11:25 A Wearable Headset Speech-to-Speech Translation System Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem and Premkumar Natarajan</title>
<marker></marker>
<rawString>10:00–10:30 A Multimodal Home Entertainment Interface via a Mobile Device Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee Hetherington, Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu 10:30–11:00 Break 11:00–11:25 A Wearable Headset Speech-to-Speech Translation System Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem and Premkumar Natarajan</rawString>
</citation>
<citation valid="false">
<title>11:25–11:50 Information extraction using finite state automata and syllable n-grams in a mobile environment</title>
<marker></marker>
<rawString>11:25–11:50 Information extraction using finite state automata and syllable n-grams in a mobile environment</rawString>
</citation>
<citation valid="false">
<authors>
<author>Choong-Nyoung Seon</author>
</authors>
<title>Harksoo Kim and Jungyun Seo 11:50–12:15 Small Statistical Models by Random Feature Mixing Kuzman Ganchev and Mark Dredze 12:15–1:15 Lunch 1:15–1:40 Mixture Pruning and Roughening for Scalable Acoustic Models David Huggins-Daines and Alexander I.</title>
<booktitle>Rudnicky 1:40–2:05 Assistive Mobile Communication Support Sonya Nikolova and Xiaojuan Ma 2:05–2:30 A Distributed Database for Mobile NLP Applications Petr Homola 2:30–3:30 Demos and Posters 3:30–4:00 Break 4:00–5:00 Panel Session</booktitle>
<marker>Seon, </marker>
<rawString>Choong-Nyoung Seon, Harksoo Kim and Jungyun Seo 11:50–12:15 Small Statistical Models by Random Feature Mixing Kuzman Ganchev and Mark Dredze 12:15–1:15 Lunch 1:15–1:40 Mixture Pruning and Roughening for Scalable Acoustic Models David Huggins-Daines and Alexander I. Rudnicky 1:40–2:05 Assistive Mobile Communication Support Sonya Nikolova and Xiaojuan Ma 2:05–2:30 A Distributed Database for Mobile NLP Applications Petr Homola 2:30–3:30 Demos and Posters 3:30–4:00 Break 4:00–5:00 Panel Session</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>