<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000062">
<sectionHeader confidence="0.7397395" genericHeader="method">
UNDERSTANDING SCENE DESCRIPTIONS
AS EVENT SIMULATIONS1
</sectionHeader>
<author confidence="0.504568">
David L. Waltz
</author>
<affiliation confidence="0.719928">
University of Illinois at Urbana-Champaign
</affiliation>
<bodyText confidence="0.999576083333333">
The language of scene descriptions2 must allow a
hearer to build structures of schemas similar (to some
level of detail) to those the speaker has built via
perceptual processes. The understanding process in
general requires a hearer to create and run &amp;quot;event
simulations&amp;quot; to check the consistency and plausibility
of a &amp;quot;picture&amp;quot; constructed from a speaker&apos;s description.
A speaker must also run similar event simulations on his
own descriptions in order to be able to judge when the
hearer has been given sufficient information to
construct an appropriate &amp;quot;picture&amp;quot;, and to be able to
respond appropriately to the hearer&apos;s questions about or
responses to the scene description.
In this paper I explore some simple scene,
description examples in which a hearer must make
judgements involving reasoning about scenes, space,
common-sense physics, cause-effect relationships, etc.
While I propose some mechanisms for dealing with such
scene descriptions, my primary concern at this time is
to flesh out our understanding of just what the
mechanisms must accomplish: what information will be
available to them and what information must be found or
generated to account for the inferences we know are
actually made.
</bodyText>
<sectionHeader confidence="0.727178" genericHeader="method">
1. SHE PROBLEM AREA
</sectionHeader>
<bodyText confidence="0.998876112903226">
An entity (human or computer) that could be said to
fulls, understand scene descriptions would have to have a
broad range of abilities. For example, it would have to
be able to make predictions about likely futures; to
judge certain scene descriptions to be implausible or
impossible; to point to items in a scene, given a
description of the scene; and to say whether or not a
scene description corresponded to a , given scene
experienced through other sensory modes. In general,
then, the entity would have to have a sensory system
that it could use to generate scene representations to
be compared with scene representations it had generated
on the basis of natural language input.
In this paper I concentrate on 1) the problems of
making appropriate predictions and inferences about
described scenes, and 2) the problem of judging when
scene descriptions are physically implausible or
impossible.
I do not consider directly problems that would
require a vision system, problems such as deciding
whether a linguistic scene description is appropriate
for a perceived scene, or generating linguistic scene
descriptions from visual input, or learning scene
description language through experience.
I also do not consider speech act aspects of scene
descriptions in much detail here. I believe that the
principles of speech acts transcend topics of language;
I am not convinced that the study of scene descriptions
would lead to major insights into speech acts that
couldn&apos;t be as well gained through the study of language
in other domains.
This work was supported in part oy the Office of Naval
Research under Contract ONR-N00014-75-C-0612 with the
University of Illinois, and was supported in part by the
Advanced Research Projects Agency of the Department of
Defense and monitored by ONR under Contract No.
N00014-77-C-0378 with Bolt Beranek and Newman Inc.
2The term &amp;quot;scene&amp;quot; is intended to coyer both static
scenes and dynamic scenes (or events) that are bounded
in space and time.
3In general I believe that many of the event simulation
procedures ought to involve kinesthetic and tactile
information. I by no means intend the simulations to be
only visual, although we have explored the Al aspects of
vision far more than those of any other senses.
I do believe, however, that the study of scene
descriptions has a considerable bearing on other areas
of language analysis, including syntax, semantics, and
pragmatics. For example, consider the following
sentences:
on the hill with my own eyes.
on the hill with a telescope.
on the hill with a red ski mask.
The well-known sentence 32 is truly ambiguous, but Si
and S3, while likely to be treated as syntactically
similar to 32 by current parsers, are each relatively
unambiguous; I would like to be able to explain how a
system can choose the appropriate parsings in these
cases, as well as how a sequence of sentences can add
constraints to a single scene-centered representation,
and aid in disambiguation. For example, if given the
pair of sentences:
</bodyText>
<equation confidence="0.952656">
(32) I saw the man on the hill with a telescope.
(S4) I cleaned the lens to get a better view of him.
</equation>
<bodyText confidence="0.910642090909091">
a language understanding system should be able to select
the appropriate reading of 32.
I would also like to explore mechanisms that would
be appropriate for judging that
(35) My dachshund bit our mailman on the ear.
requires an explanation (dachshunds could not jump high
enough to reach a mailman&apos;s ear, and there is no way to
choose between possible scenarios which would get the
dachsund high enough or the mailman low enough for the
biting to take place). The mechanisms must also be able
to judge that the sentences:
</bodyText>
<listItem confidence="0.986039">
(S6) My doberman bit our mailman on the ear.
(37) My dachshund bit our gardener on the ear.
(38) My dachshund bit our mailman on the leg.
</listItem>
<bodyText confidence="0.994672793103448">
do rat. require explanations.
A few words about the importance of explanation are
in order here. If a program could judge correctly which
scene descriptions were plausible and which were nor..,
but could not explain way it made the judgements it did,
I think I would feel profoundly dissatisfied with and
suspicious of the program as a model of language
comprehension. A program ought to consider the &amp;quot;right
options&amp;quot; and decide among them for the &amp;quot;right reasons%
if it is to be taken seriously as a model of cognition.&apos;
I will argue that scene descriptions are often most
naturally represented by structures which are, at least
in part, only awkwardly viewed as propositional; such
representations include coordinate systems,
trajectories, and event-simulating mechanisms, i.e.
procedures which set up models of objects, interactions,
and constraints, &amp;quot;set them in motion&amp;quot;, and &amp;quot;watch what
happens&amp;quot;. I suggest that event simulations are
supported by mechanisms that model common-sense physics
and human behavior
I will also argue that there is no way to put limits
on the degree of detail which may have to be considered
in constructing event simulations; virtually any feature
of an object can in the right circumstances become
centrally important.
An explanation need not be in natural language; for
example, I probably could be convinced via traces of a
program&apos;s operation that it had been concerned with the
right issues in judging scene plausibility.
</bodyText>
<figure confidence="0.851619666666667">
(Si) I saw the man
(32) I saw the man
(33) I saw the man
</figure>
<page confidence="0.986103">
7
</page>
<listItem confidence="0.7015734">
2.
progress, as in:
(S9) The pencil is on the desk.
(S10) A helicopter is flying overhead.
($11) My dachshund was biting the mailman.
</listItem>
<bodyText confidence="0.979214315789474">
Sequences of sentences can also be used to specify a
single static scene description, a process I will refer
to as &amp;quot;detail addition&amp;quot;. As an example of detail
addition, consider the following sequence of sentences
(taken from Waltz &amp; Boggess (1)):
(S12) A goldfish is in a fish bowl.
($13) The fish bowl is on a stand.
(S14)The stand is on a desk.
(S15) The desk is in a room.
A program written by Boggess (2] is able to build a
representation of these sentences by assigning to each
object mentioned a size, position, and orientation in a
coordinate system, as illustrated in figure 1. I will
refer to such representations as &amp;quot;spatial analog models&amp;quot;
(in (1] they were called &amp;quot;visual analog models&amp;quot;).
Objects In Boggess&apos;s program are defined by giving
values for their typical values of size, weight,
orientation, surfaces capable of supporting other
objects, as well as other properties such as &amp;quot;hollow&amp;quot; or
&amp;quot;solid&amp;quot;, and so on.
Fizure 1 A &amp;quot;visual analog model&amp;quot; of S12-515.
Dynamic scene descriptions can use detail addition
also, but more commonly they use either the mechanisms
of &amp;quot;successive refinement&amp;quot; [3] or &amp;quot;temporal addition&amp;quot;.
&amp;quot;Temporal addition&amp;quot; refers to the process of describing
events through a series of time-ordered static scene
descriptions, as in:
($16) Our mailman fell while running from our
dachshund.
(Si?) The dachshund bit the mailman on the ear.
&amp;quot;Successive refinement&amp;quot; refers to a process where an
introductory sentence sets up a more or less
prototypical event which is then modified by succeeding
sentences, e.g. by listing exceptions to one&apos;s ordinary
expectations of the prototype, or by providing specific
values for optional items in he prototype, or by
similar means. The following sentences provide an
example of &amp;quot;successive refinement&amp;quot;:
</bodyText>
<listItem confidence="0.934979416666667">
($18) A car hit a boy near our house.
($19) The car was speeding eastward on Main Street At
the time.
(S20) The boy, who was riding a bicycle, was knocked
to tht 1round.
3. THE GOALS OF A SCENE UNDERSTANDING SYSTEM
What should a scene description understanding system
to do with a linguistic scene description? Basically 1)
verify plausibility, 2) make inferences and predictions,
3) act if action is called for, and 4) remember whatever
is important. For the time being, I am only considering
1) and 2) in detail. In order to carry out 1) and 2), I
</listItem>
<bodyText confidence="0.999849118644068">
would like my system to turn scene descriptions (static
or dynamic) into a time sequence of &amp;quot;expanded spatial
analog models&amp;quot;, where each expanded spatial analog model
represents either 1) a set of spatial relationships (as
in S12-S15), or 2) spatial relationships plus models of
actions in progress, chosen from a fairly large set of
primitive actions (see below), or 3) prototypical
actions that can stand for sequences of primitive
actions. These prototypical actions would have to be
fitted into the current context, and modified according
to the dictates of the objects and modifiers that were
supplied in the scene description.
The action prototype would have associated selection
restrictions for objects; if the objects in the scene
description matched the selection restrictions, then
there would be no need to expand the prototype into
primitives, and the &amp;quot;before&amp;quot; and &amp;quot;after&amp;quot; scenes (similar
to pre- and post-conditions) of the action prototype
could be used safely.
If the selection restrictions were violated by
objects in the scene, or if modifiers were present, or
if the context did not match the preconditions, then it
would have to be possible to adapt the action prototype
&amp;quot;appropriately&amp;quot;. It would also have to be possible to
reason about the action without actually running the
event simulation sequence underlying it in its entirety;
sections that would have to be modified, plus before and
after models, might be the only portions of the
simulation actually run. The rest of the prototype could
be treated as a kind of &amp;quot;black box&amp;quot; with known
input-output characteristics.
I have not yet found a principled way to enumerate
the primitives mentioned above, but I believe that there
should be many of them, and that they should not
necessarily be non-overlapping; what is most Important
is that they should have precise representations in
spatial analog models, and be capable of being used to
generate plausible candidates for succeding spatial
analog models. Some examples of primitives I have looked
at and expect to include are: break-object-into-parts,
mechanically-join-parts, hit, touch, support, translate,
fall.
As an example of the expansion of a non-primitive
action into primitive actions, consider &amp;quot;bite x y&amp;quot;; its
steps are: 1)(set-up] Instantiate x as a &amp;quot;biting-thing&amp;quot;
-- defaults = mouth, teeth, jaws of an an/mate entity;
2) instantiate y as &amp;quot;thing-bitten&amp;quot;; 3)(before] x is open
and does not touch y and x partially surrounds y (i.e. y
is not totally inside x); 4) x is closing on y;
5)[action] x is touching y, preferably in two places on
opposite sides of y and x continues to close; 6) x
deforms y; 7)Lafter] x is moving away from y, and no
longer touches y.
Finally, lest it should not be clear from the
sketchiness of the comments above, I am by no means
satisfied yet with these ideas as an explanation of
scene description understanding, althougn I am confident
that this research is headed in the right general
direztion.
</bodyText>
<sectionHeader confidence="0.989659" genericHeader="method">
4. ILAUSIBIL/TY JUDGEMENT
</sectionHeader>
<bodyText confidence="0.999630954545454">
The basic argument I am advancing in this paper is
this: it is essential in understanding scene
descriptions to set up and run event simulations for the
scenes; we judge the plausibility (or possibility),
meaningfulness, and completeness of a description on the
basis of our experience in attempting to set up and run
the simulation. By studying cases where we judge
descriptions to be implausible we can gain insight into
just what is done routinely during the understanding of
scene descriptions, since these cases correspond to
failures in setting up or running event simulations.
By &amp;quot;instantiate an X&amp;quot; I mean assign X a physical place,
posture, orientation, etc. or. retrieve a pointer to sulh
an instantiation, if it is a familiar one. Th s
&amp;quot;instantiate a baby&amp;quot; would retrieve a pointer, whereas
&amp;quot;instantiate a two-neaded dog&amp;quot; would probably have to
attempt to generate one on the spot. Note that this
process may itself fail, i.e. that an entity may not be
able to &amp;quot;imagine&amp;quot; such an object.
ap,n:i::::n:ound it useful to distinguish between static
and dynamic scene descriptions. static scene
express spatial relations or actions in
</bodyText>
<page confidence="0.989558">
8
</page>
<bodyText confidence="0.999974">
As the examples below illustrate, sometimes an event
simulation simply cannot be set up because information
is missing, or several possible &amp;quot;pictures&amp;quot; are equally
plausible, or the objects and actions being described
cannot be fitted together for a variety of reasons, or
the results of running the simulation do not match our
knowledge of the world or the following portions of the
scene description, and so on. It is also important to
emphacize that our ultimate interest is in being able to
succeed in setting up and running event simulations;
therefore I have for the most part chosen ambiguous
examples where at least one event simulation succeeds.
</bodyText>
<listItem confidence="0.460562666666667">
4.1 TRANSLATING AN OLD EXAMPLE INTO NEW MECHANISMS
Consider Bar-Hillel&apos;s famous sentence
(310) The box is in the pen.
</listItem>
<bodyText confidence="0.996083619047619">
Plausibility judgement is necessary to choose the
appropriate reading, i.e. that &amp;quot;pen&amp;quot; . playpen. Minor
extensions to Boggess&apos;s program could allow it to choose
&apos; the appropriate referent for pen. Pent (the writing
implement) would be defined as having a relatively fixed
size (subject to being overridden by modifiers, as in
&amp;quot;tiny pen&amp;quot; or &amp;quot;twelve inch pen&amp;quot;), but the size of 22112.
(the enclosure) would be allowed to vary over a range of
values (as would the size of box). The program could
attempt to model the sentence by instantiating standard
(default-sized) models of box, pen1, and pen2, and
attempting to assign the objects to positions in a
coordinate system such that the box would be ja pent or
pen2. Pent could not take part in such a spatial analog
model both because of pent&apos;s rigid size, and the extreme
shrinkage that would be required of box (outside box&apos;s
allowed range) to make it smaller than the pen1, and
also because penl is not a container (i.e. hollow
object). Pen2 and box prototypes could be fitted
together without problems, and could thus be chosen as
the most appropriate interpretation.
</bodyText>
<subsectionHeader confidence="0.79195">
4.2 A SIMPLE EVENT SIMULATION
</subsectionHeader>
<bodyText confidence="0.9998682">
Extending Boggess&apos;s program to deal with most of the
other examples given in this paper so far would be
harder, although I believe that S1-S4 could be handled
without too much difficulty. Let us look at 52 and S4 in
more detail:
</bodyText>
<equation confidence="0.486174">
(52) I saw the man on the hill with a telescope.
(S4) I cleaned the lens to get a better view of him.
</equation>
<bodyText confidence="0.999849928571429">
After being told 52, a system would either pick one
of the possible interpretations as most plausible, or it
might be unable to choose between competing
interpretations, and keep them both. When it is told
S4, the system must first discover that &amp;quot;the lens&amp;quot; is
part of the telescope. Having done this, $4
unambiguously forces the placement of the speaker to be
close enough to the telescope to touch it. This is
because all common interpretations of clean require the
agent to be close to the object. At least two possible
interpretations still remain: 1) the speaker is distant
from the man on the hill, and is using the telescope to
view the man; or 2) the speaker, telescope, and man on
the hill are all close together. The phrase &amp;quot;to get a
better view of him&amp;quot; refers to the actions of the speaker
in viewing the man, and thus makes interpretation 1)
much more likely, but 2) is still conceivable. The
reasoning necessary to choose 1) as most plausible is
rather subtle, involving the idea that telescopes are
usually used to look at distant objects.
In any case, the proposed mechanisms should allow a
system to discard an interpretatiion of S2 and 54 where
the man on the hill had a telescope and was distant from
the speaker.
A central figure in the machine translation effort of
the late 50&apos;s and early 60&apos;s, Bar-Hillel cited this
sentence in explaining why machine translation was
impossible. He subsequently quit the field.
</bodyText>
<listItem confidence="0.787895">
4.3 SIMULATING AN IMPLAUSIBLE EVENT
Let us also look again at S5:
($5) My dachshund bit our mailman on the ear.
</listItem>
<bodyText confidence="0.95966575">
and be more specific about what an event simulation
should involve in this rather complex case. The event
simulation set up procedures I envision would.execute
the following steps:
</bodyText>
<listItem confidence="0.9314885">
1) instantiate a standard mailman and dachshund in
default positions (e.g. both standing on level ground
outdoors on a residential street with no special props
other than the mailman&apos;s uniform and mailbag);
2) analyze the preconditions for &amp;quot;bite&amp;quot; to find that
they require the dog&apos;s mouth to surround the mailman&apos;s
ear;
3) see whether the dachshund&apos;s mouth can reach the
mailman&apos;s ear directly (no);
4) see whether the dog can stretch high enough to reach
(no; this test would require an articulated model of
the dog&apos;s skeleton or a prototypical representation of a
dog on its hind legs.);
5) see whether a dachshund could jump high enough (no;
this step is decidedly non-trivial to implement! );
6) see whether the mailman ordinarily gets into any
positions where the dog could reach his ear (no);
7) conclude that the mailman could not be bitten as
stated unless default sizes or movement ranges are
relaxed in some way. Since there is no clearly preferred
way to relax the defaults, more information is necessary
to make this an &amp;quot;unambiguous&amp;quot; description.
</listItem>
<bodyText confidence="0.986096829268293">
I have quoted &amp;quot;unambiguous&amp;quot; because the sentence 35
is not ambiguous in any ordinary sense, lexically or
structurally. What It ambiguous are the conditions and
actions which could have led up to S5. Strangely
enough, the ordinary actions of mailmen (checked in step
6) seem relevant to the judgement of plausibility in
this sentence. As evidence for this analysis, note that
the substitution of &amp;quot;gardener&amp;quot; for &amp;quot;mailman&amp;quot; turns (S5)
into a sentence that can be simulated without problems.
I think that it is significant that such peripheral
factors can be influential in judging, the plausibility
of an event. At the same time, I am aware that the
effect in this case is rather weak, that people can
accept this sentence without noting any strangeness, so
I do not want to draw conclusions that are too strong.
4.4 MAKING INFERENCES ABOUT SCENES
Consider the following passage:
(P1) You are at one end of a vast hall stretching
forward out of sight to the west. There are openings
to either side. Nearby, a wide stone staircase leads
downward. The hall is filled with wisps of white mist
swaying to and fro almost as if alive. A cold wind
blows up the staircase. There is a passage at the top
of the dome behind you. Rough stone steps lead up the
dome.
Given this passage (taken from the computer game
&amp;quot;Adventure&amp;quot;) one can infer that it is possible to move
to the west, north, south, or east (up the rough stone
steps). Note that this information is buried in the
description; in order to infer this information, it
would be useful to construct a spatial analog model,
lAlthough one could do it by simply including in the
definition of a dog information about how high a dog can
jump, e.g. no higher than twice the dog&apos;s length.
However I consider this something of a &amp;quot;hack&amp;quot;, because
it ignores some other problems, for example the timing
problem a dog would face in biting a small target like a
person&apos;s ear at the apex of its highest jump. I would
prefer a solution that could, if necessary, perform an
event simulation for step 5), rather than trust canned
data.
</bodyText>
<page confidence="0.995307">
9
</page>
<bodyText confidence="0.996813947368421">
with &amp;quot;you&amp;quot; facing west, and the scene features placed
appropriately. In playing Adventure, it is also
necessary to remember salient features of the scenes
described so that one can recognize the same room later,
given a passage such ELS:
(P2) You&apos;re in hall of mists. Rough stone steps lead
up the dome. There is a threatening little dwarf in
the room with you.
Adventure can only accept a very limited class of
commands from a player at any given point in the game.
It is only possible to play the game because one can
make reasonable inferences about what actions are
possible at a given point, i.e. take an object, move in
some direction, throw a knife, open a door, etc. While
I am not quite sure what make of my observations about
this example, I think that games such as Adventure are
potentially valuable tools for gathering information
about the kinds of spatial and other inferences people
make about scene descriptions.
</bodyText>
<subsectionHeader confidence="0.964073">
4.5 MIRACLES AND WORLD RECORDS
</subsectionHeader>
<bodyText confidence="0.914666454545454">
With some sentences there may be no plausible
interpretation at all. In many of the examples which
follow, it Seems unlikely that we actually generate (at
least consciously) an event simulation. Rather it seems
that we have some shortcuts for recognizing that certain
events would have to be termed &amp;quot;miraculous&amp;quot; or difficult
to believe.
(522) My car goes 2000 miles on a tank of gas.
(S23) Mary caught the bullet between her teeth.
(524) The child fell from the 10th story window to the
street below, but wasn&apos;t hurt.
</bodyText>
<listItem confidence="0.9825685">
(S25) We took the refrigerator home in the trunk of
our VW Beetle.
(S26) She had given birth to 25 children by the age of
30.
</listItem>
<bodyText confidence="0.946752941176471">
(S27) The robin picked up the book and flew away with
it.
(S28) The child chewed up and swallowed the pair of
scissors.
The Guinness Book of World Records LS full of
examples that defy event simulation. How one is able to
judge the plausibility of these (and how we might get a
system to do so) remains something of a mystery to me.
The problem of recognizing obviously implausible
events rapidly is an important one to consider for
dealing with pronouns. Often we choose the appropriate
referent for a pronoun because only one of the possible
referents could be part of a plausible event if
substituted for the pronoun. For example, &amp;quot;it&amp;quot; must
refer to &amp;quot;milk&amp;quot;, not &amp;quot;baby&amp;quot;, in S29:
(529) I didn&apos;t want the baby to get sick from drinking
the milk, so I boiled it.
</bodyText>
<sectionHeader confidence="0.995903" genericHeader="method">
5. THE_ROLE OF EVENT SIMULAT7QH IN A FULI. THEORY OF
LANGUAGF
</sectionHeader>
<bodyText confidence="0.999546363636364">
I suggested in section 3 that a scene description
understanding system would have to 1) verify the
plausibility of a described scene, 2) make inferences or
predictions about the scene, 3) act if action is called
for, and 4) remember whatever is Important. As pointed
out in section 4.5, event simulations may not even be
need for all cases of plausibility judgement.
Furthermore, scene descriptions constitute only one of
many possible topics of language. Nonetheless, I feel
that the study of event simulation is extremely
important.
</bodyText>
<subsectionHeader confidence="0.97438">
5.1 WHY ARE SIMPLE PHYSICAL SCENES WORTH CONSIDERING?
</subsectionHeader>
<bodyText confidence="0.9628976">
For a number of reasons, methodological as well as
theoretical, I believe that it is not only worthwhile,
but also important to begin the study of scene
descriptions with the world of simple physical objects,
events, and physical behaviors with simple goals.
1) Methodologically it is necessary to pick an area of
concentration which is restricted in some way. The world
of simple physical objects and events is one of the
simplest worlds that links language and sensory
descriptions.
2) As argued in the work of Piaget (5], it seems likely
that we come to comprehend the world by first mastering
the sensory/motor world, and then by adapting and
building on our schemata from the sensory/motor world to
understand progressively more abstract worlds. In the
area of language Jackendoff (6) offers parallel
arguments. Thus the world of simple physical oojects and
behaviors has a privileged positions in the development
of cognition and language.
3) Few words in English are reserved for describing the
abstract world only. Most abstract words also have a
physical meaning. In some cases the physical meanings
may provide important metaphors for understanding the
abstract world, while in other cases the same mechanisms
that are used in the interpretation of the physical
world may be shared with mechanisms that interpret the
abstract world.
4) I would like the representations I develop for
linguistic scene descriptions to be compatible with
representations I can Imagine generating with a vision
system. Thus this work does have an indirect bearing on
vision research: my representations characterize and put
constraints on the types and forms of information I
think a vision system ought to be able to supply.
5) Even in the physical domain, we must come to grips
with some processes that resemble those involved in the
generation and understanding of metaphor: matching,
adaptation of schemata, modification of stereotypical
items to match actual items, and the interpretation of
items from different perspectives.
</bodyText>
<subsectionHeader confidence="0.93468">
5.2 SCENE DESCRIPTIONS AND A THEORY OF ACTION
</subsectionHeader>
<bodyText confidence="0.999381057142857">
I take it as evident that every scene description,
indeed every utterance, is associated with some purpose
or goal of a speaker. The speaker&apos;s purpose affects the
organization and order of the speaker&apos;s presentation,
the items included and the items omitted, as well as
word choice and stress. Any two witnesses of the same
event will in general give accounts of it that differ on
every level, especially if one or both witnesses were
participants or has some special Interest in the cause
or outcome of the event.
For now I have ignored all these factors of scene
description understanding; I have not attempted an
account of the deciphering of a speaker&apos;s goals or
biases from a given scene description. I have instead
considered only the propositional content of scene
description utterances, in particular the issue of
whether or not a given scene description could plausibly
correspond to a real scene. Until we can give an account
of the judgement of plausibility of description
meanings, we cannot even say how we recognize blatant
lies; from this perspective, understanding jam someone
might lie or mislead, i.e. understanding the intended
effect of an utterance, is a secondary issue.
There seems to me to be a clear need for a &amp;quot;theory
of human action&amp;quot;, both for purposes of event simulation
and, more importantly, to provide a better overall
framework for Al research than we currently have. While
no one to my knowledge still accepts as plausible the
&amp;quot;big switch&amp;quot; theory of intelligent action (7), most Al
work seems to proceed on the &amp;quot;big switch&amp;quot; assumptions
that it is valid to study intelligent behavior in
isolated domains, and that there is no compelling reason
at this point to worry about whether (let alone AoJeL) the
pieces developed in isolation will ultimately fit
together.
</bodyText>
<subsectionHeader confidence="0.874623">
5.3 ARE THERE MANY WAYS TO SKIN k CAT?
</subsectionHeader>
<bodyText confidence="0.9407375">
Spatial analog models are certainly not the only
possible representation for scene descriptions, but they
are convenient and natural in many ways. Among their
advantages are: 1) computational adequacy for
</bodyText>
<page confidence="0.994522">
10
</page>
<bodyText confidence="0.999972461538462">
representing the locations and motions of objects; 2)
the ability to implicitly represent relationships
between objects, and to allow easy derivation of these
relationships; 3) ease of interaction with a vision
system, and ultimately appropriateness for allowing a
mobile entity to navigate and locate objects. The main
problem with these representations is that scene
descriptions are usually underspecified, so that there
is a range of possible locations for each object. It
thus becomes risky to trust implicit relationships
between objects. Event stereotypes are probably
important because they specify compactly all the
important relationships between objects.
</bodyText>
<sectionHeader confidence="0.739024" genericHeader="conclusions">
5.4 RELATED WORK
</sectionHeader>
<bodyText confidence="0.99615428125">
A number of papers related the the topics treated
here have appeared in recent years. Many are listed in
[8] which also provides some ideas on the generation of
scene descriptions. This work has been pervasively
influenced by the ideas of Bill Woods on &amp;quot;procedural
semantics&amp;quot;, especially as presented in [91.
Representations for large-scale space (paths, maps,
etc.) were treated in Kuipers&apos; thesis [10]. Novak [11]
wrote a program that generated and used diagrams for
understanding physics problems. Simmons [12] wrote
programs that understood simple scene descriptions
involving several known objects. Inferences about the
causes and effects of actions and events have been
considered by Schank and Abelson[13] and Rieger[14].
Johnson-Laird(15) has investigated problems in
understanding scenes with spatial locative prepositions,
as has Herskovits(16]. Recent work by Forbus(17] has
developed a very interesting paradigm for qualitative
reasoning in physics, built on work by deKleer[18,19],
and related to work by Hayes(20,21]. My comments on
pronoun resolution are in the same spirit as Hobbs(22],
although Hobbs&apos;s &amp;quot;predicate interpretation&amp;quot; is quite
different from my &amp;quot;analog spatial models&amp;quot;. Ideas on the
adaptation of prototypes for the representation of 3-D
shape were explored in Waltz (23]. A effort toward
qualitative mechanics is described in Bundy [24]. Also
relevant is the work on mental imagery of Kosslyn &amp;
Shwartz(25] and Hinton(26].
I would like to acknowledge especially the helpful
comments of Ken Forbus, and also the help I have
received from Bill Woods, Candy Sidner, Jeff Gibbons,
Rusty Bobrow, David Israel, and Brad Goodman.
</bodyText>
<sectionHeader confidence="0.992625" genericHeader="references">
6. REFERENCES
</sectionHeader>
<reference confidence="0.999945125">
[1] Waltz, D.L. and Boggess, L.C. Visual Analog
representations for natural language understanding.
Proc. of IJCAT-74, Tokyo, Japan, Aug. 1979.
[2] Boggess, L.C. Computational interpretation of
English spatial prepositions. Unpublished Ph.D.
dissertation, Computer Science Dept., University of
Illinois, Urbana, 1978.
[3] Chafe, W.L. The flow of thought and the flow of
language. In T.Givon (ed.) Discourse and Syntax
Academic Press, New York, 1979.
[4] Bar-Hillel, Y. 1.aauagaAnclJ.nf.2mar,=.
Addison-Wesley, New York, 1964.
[5] Piaget, J. Six Psychological Studies Vintage Books,
New York, 1967.
[6] Jackendoff, R. Toward an explanatory semantic
representation. finguiltir Inauirv L, 1, 89-150, 1975.
[7] Minsky, M. and Papert, S. Artificial Intelligence,
Project MAC report, 1971.
[8] Waltz, D.L. Generating and understanding scene
descriptions. In Joshi, Sag, and Webber (eds.) Flaments
of Discourse Understanding Cambridege University Press,
to appear. Also Working paper 24, Coordinated Science
Lab, Univ. of Illinois, Urbana Feb. 1980.
[9] Woods, W.A. Procedural semantics as a theory of
meaning In Joshi, Sag, and Webber (eds.) Fiements of
nigoolirge Underqtanding. Cambridge University Press, to
appear.
[10] Kuipers, B.J. Representing knowledge of large-scale
space. Tech. Rpt. AI-TR-418, MIT Al Lab, Cambridge, MA,
1977.
[11] Novak, G.S. Computer understanding of physics
problems stated in natural language. Tech. Rpt. NL-30,
Dept. of Computer Science, University of Texas, Austin,
1976.
[12] Simmons, R.F. The CLOWNS microworld. In Schank and
Nash-Webber (eds.) Theoretical Issues in Natural
Language Processing, ACL, Arlington, VA, 1975.
[13] Schank, R.C. and Abelson, R. Scripts. Plans.
Goals. and Understanding. Lawrence Erlbaum Associates,
Hillsdale, NJ, 1977.
[14] Rieger, C. The commonsense algorithm as a basis for
computer models of human memory, inference, belief and
contextual language comprehension. In Schank and
Nash-Webber (eds.) Theoretical Issues La Natural
Language Processing, ACL, Arlington, VA, 1975.
[15] Johnson-Laird, P.N. Mental models in cognitive
science. Cognitive Scienre 4, 1, 71-115, Jan.-Mar.
1980.
[16] Herskovitz, A. On the spatial uses of prepositions.
In this proceedings.
[17] Forbus, K.D. A study of qualitative and geometric
knowledge in reasoning about motion. MS thesis, MIT Al
Lab, Cambridge, MA, Feb. 1980.
[18) de Kleer, J. Multiple representations of knowledge
in a mechanics problem-solver. Frac- 5th Intl. Joint
Cont. on Artificial Intelligenne, MIT, Cambridge, MA,
1977, 299-304.
[19] de Kleer, J. The origin and resolution of
ambiguities in causal arguments. Proc. IJCAT-74, Tokyo,
Japan, 1979, 197-203.
[20] Hayes, P.J. The naive physics manifesto.
Unpublished paper, May 1978.
(21] Hayes, P.J. Naive physics 1: Ontology for liquids.
Unpublished paper, Aug. 1978.
[22] Hobbs, J.R. Pronoun resolution. Research report,
Dept. of Computer Sciences, City College, City
University of New York, c.1976.
(23] Waltz, D.L. Relating images, concepts, and words.
Proc. of the NSF Workshop on the Representation of 1-0
Obiects, University of Pennsylvania, Philadelphia, 1979.
Also available as Working Paper 23, Coordinated Science
Lab, University of Illinois, Urbana, Feb. 1980.
[24] Bundy, A. Will it reach the top? Prediction in the
mechanics world. Artificial Intelligence 10, 2, April
1978.
[25] Kosslyn, S.M. &amp; Shwartz, S.P. A simulation of
visual imagery. Cognitive Science 1, 3, July 1977.
[26] Hinton, G. Some demonstrations of the effects of
structural descriptions in mental imagery. Cognitive
Salezue_1, 3, July-Sept. 1979.
</reference>
<page confidence="0.999486">
11
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.010659">
<title confidence="0.992849">UNDERSTANDING SCENE DESCRIPTIONS EVENT</title>
<author confidence="0.999992">David L Waltz</author>
<affiliation confidence="0.987434">University of Illinois at Urbana-Champaign</affiliation>
<abstract confidence="0.998021071428571">language of scene must allow a hearer to build structures of schemas similar (to some level of detail) to those the speaker has built via perceptual processes. The understanding process in requires a hearer to create and run simulations&amp;quot; to check the consistency and plausibility of a &amp;quot;picture&amp;quot; constructed from a speaker&apos;s description. A speaker must also run similar event simulations on his own descriptions in order to be able to judge when the hearer has been given sufficient information to construct an appropriate &amp;quot;picture&amp;quot;, and to be able to respond appropriately to the hearer&apos;s questions about or responses to the scene description. In this paper I explore some simple scene, description examples in which a hearer must make judgements involving reasoning about scenes, space, common-sense physics, cause-effect relationships, etc. While I propose some mechanisms for dealing with such scene descriptions, my primary concern at this time is to flesh out our understanding of just what the mechanisms must accomplish: what information will be available to them and what information must be found or generated to account for the inferences we know are actually made. PROBLEM AREA An entity (human or computer) that could be said to understand scene descriptions would have to have a broad range of abilities. For example, it would have to be able to make predictions about likely futures; to judge certain scene descriptions to be implausible or impossible; to point to items in a scene, given a description of the scene; and to say whether or not a scene description corresponded to a , given scene experienced through other sensory modes. In general, then, the entity would have to have a sensory system that it could use to generate scene representations to be compared with scene representations it had generated on the basis of natural language input. In this paper I concentrate on 1) the problems of making appropriate predictions and inferences about described scenes, and 2) the problem of judging when scene descriptions are physically implausible or impossible. I do not consider directly problems that would require a vision system, problems such as deciding whether a linguistic scene description is appropriate for a perceived scene, or generating linguistic scene descriptions from visual input, or learning scene description language through experience. I also do not consider speech act aspects of scene descriptions in much detail here. I believe that the principles of speech acts transcend topics of language; I am not convinced that the study of scene descriptions would lead to major insights into speech acts that couldn&apos;t be as well gained through the study of language in other domains.</abstract>
<note confidence="0.995163166666667">This work was supported in part oy the Office of Naval Research under Contract ONR-N00014-75-C-0612 with the University of Illinois, and was supported in part by the Advanced Research Projects Agency of the Department of Defense and monitored by ONR under Contract No. N00014-77-C-0378 with Bolt Beranek and Newman Inc.</note>
<abstract confidence="0.99014048">term &amp;quot;scene&amp;quot; to coyer both static scenes and dynamic scenes (or events) that are bounded in space and time. general I believe that many of the event simulation procedures ought to involve kinesthetic and tactile information. I by no means intend the simulations to be only visual, although we have explored the Al aspects of vision far more than those of any other senses. I do believe, however, that the study of scene descriptions has a considerable bearing on other areas of language analysis, including syntax, semantics, and pragmatics. For example, consider the following sentences: on the hill with my own eyes. on the hill with a telescope. on the hill with a red ski mask. The well-known sentence 32 is truly ambiguous, but Si and S3, while likely to be treated as syntactically similar to 32 by current parsers, are each relatively unambiguous; I would like to be able to explain how a system can choose the appropriate parsings in these cases, as well as how a sequence of sentences can add constraints to a single scene-centered representation, and aid in disambiguation. For example, if given the pair of sentences: (32) I saw the man on the hill with a telescope. (S4) I cleaned the lens to get a better view of him. a language understanding system should be able to select the appropriate reading of 32. I would also like to explore mechanisms that would be appropriate for judging that (35) My dachshund bit our mailman on the ear. requires an explanation (dachshunds could not jump high enough to reach a mailman&apos;s ear, and there is no way to choose between possible scenarios which would get the dachsund high enough or the mailman low enough for the biting to take place). The mechanisms must also be able to judge that the sentences: (S6) My doberman bit our mailman on the ear. (37) My dachshund bit our gardener on the ear. (38) My dachshund bit our mailman on the leg. do rat. require explanations. A few words about the importance of explanation are in order here. If a program could judge correctly which scene descriptions were plausible and which were nor.., but could not explain way it made the judgements it did, I think I would feel profoundly dissatisfied with and suspicious of the program as a model of language comprehension. A program ought to consider the &amp;quot;right options&amp;quot; and decide among them for the &amp;quot;right reasons% if it is to be taken seriously as a model of cognition.&apos; I will argue that scene descriptions are often most naturally represented by structures which are, at least in part, only awkwardly viewed as propositional; such representations include coordinate systems, trajectories, and event-simulating mechanisms, i.e. procedures which set up models of objects, interactions, and constraints, &amp;quot;set them in motion&amp;quot;, and &amp;quot;watch what happens&amp;quot;. I suggest that event simulations are supported by mechanisms that model common-sense physics and human behavior I will also argue that there is no way to put limits on the degree of detail which may have to be considered event simulations; virtually any feature of an object can in the right circumstances become centrally important. An explanation need not be in natural language; for example, I probably could be convinced via traces of a program&apos;s operation that it had been concerned with the right issues in judging scene plausibility. (Si) I saw the man (32) I saw the man (33) I saw the man 7 2. progress, as in: The pencil the desk. (S10) A helicopter is flying overhead. ($11) My dachshund was biting the mailman. Sequences of sentences can also be used to specify a single static scene description, a process I will refer to as &amp;quot;detail addition&amp;quot;. As an example of detail addition, consider the following sequence of sentences from Waltz &amp; Boggess (S12) A goldfish is in a fish bowl. ($13) The fish bowl is on a stand. (S14)The stand is on a desk. (S15) The desk is in a room. program written by Boggess (2] to build a representation of these sentences by assigning to each object mentioned a size, position, and orientation in a coordinate system, as illustrated in figure 1. I will refer to such representations as &amp;quot;spatial analog models&amp;quot; (in (1] they were called &amp;quot;visual analog models&amp;quot;). Objects In Boggess&apos;s program are defined by giving values for their typical values of size, weight, orientation, surfaces capable of supporting other objects, as well as other properties such as &amp;quot;hollow&amp;quot; or &amp;quot;solid&amp;quot;, and so on. 1A &amp;quot;visual analog model&amp;quot; of S12-515. Dynamic scene descriptions can use detail addition also, but more commonly they use either the mechanisms of &amp;quot;successive refinement&amp;quot; [3] or &amp;quot;temporal addition&amp;quot;. &amp;quot;Temporal addition&amp;quot; refers to the process of describing events through a series of time-ordered static scene descriptions, as in: ($16) Our mailman fell while running from our dachshund. (Si?) The dachshund bit the mailman on the ear. &amp;quot;Successive refinement&amp;quot; refers to a process where an introductory sentence sets up a more or less prototypical event which is then modified by succeeding sentences, e.g. by listing exceptions to one&apos;s ordinary of the prototype, or specific values for optional items in he prototype, or by similar means. The following sentences provide an example of &amp;quot;successive refinement&amp;quot;: ($18) A car hit a boy near our house. ($19) The car was speeding eastward on Main Street At the time. (S20) The boy, who was riding a bicycle, was knocked to tht 1round. GOALS OF A UNDERSTANDING SYSTEM What should a scene description understanding system to do with a linguistic scene description? Basically 1) verify plausibility, 2) make inferences and predictions, 3) act if action is called for, and 4) remember whatever is important. For the time being, I am only considering 1) and 2) in detail. In order to carry out 1) and 2), I would like my system to turn scene descriptions (static or dynamic) into a time sequence of &amp;quot;expanded spatial analog models&amp;quot;, where each expanded spatial analog model represents either 1) a set of spatial relationships (as in S12-S15), or 2) spatial relationships plus models of actions in progress, chosen from a fairly large set of actions or 3) prototypical actions that can stand for sequences of primitive actions. These prototypical actions would have to be fitted into the current context, and modified according to the dictates of the objects and modifiers that were supplied in the scene description. The action prototype would have associated selection restrictions for objects; if the objects in the scene description matched the selection restrictions, then there would be no need to expand the prototype into primitives, and the &amp;quot;before&amp;quot; and &amp;quot;after&amp;quot; scenes (similar to preand post-conditions) of the action prototype could be used safely. If the selection restrictions were violated by scene, or if modifiers were present, or if the context did not match the preconditions, then it would have to be possible to adapt the action prototype &amp;quot;appropriately&amp;quot;. It would also have to be possible to reason about the action without actually running the event simulation sequence underlying it in its entirety; sections that would have to be modified, plus before and after models, might be the only portions of the simulation actually run. The rest of the prototype could be treated as a kind of &amp;quot;black box&amp;quot; with known input-output characteristics. I have not yet found a principled way to enumerate the primitives mentioned above, but I believe that there should be many of them, and that they should not necessarily be non-overlapping; what is most Important they should have precise representations in spatial analog models, and be capable of being used to generate plausible candidates for succeding spatial analog models. Some examples of primitives I have looked at and expect to include are: break-object-into-parts, mechanically-join-parts, hit, touch, support, translate, fall. example of the expansion of a non-primitive action into primitive actions, consider &amp;quot;bite x y&amp;quot;; its steps are: 1)(set-up] Instantiate x as a &amp;quot;biting-thing&amp;quot; -defaults = mouth, teeth, jaws of an an/mate entity; 2) instantiate y as &amp;quot;thing-bitten&amp;quot;; 3)(before] x is open and does not touch y and x partially surrounds y (i.e. y is not totally inside x); 4) x is closing on y; 5)[action] x is touching y, preferably in two places on sides of y and x continues to close; x x moving away from y, and no longer touches y. Finally, lest it should not be clear from the sketchiness of the comments above, I am by no means satisfied yet with these ideas as an explanation of scene description understanding, althougn I am confident that this research is headed in the right general direztion. JUDGEMENT The basic argument I am advancing in this paper is this: it is essential in understanding scene descriptions to set up and run event simulations for the scenes; we judge the plausibility (or possibility), meaningfulness, and completeness of a description on the basis of our experience in attempting to set up and run the simulation. By studying cases where we judge descriptions to be implausible we can gain insight into just what is done routinely during the understanding of scene descriptions, since these cases correspond to failures in setting up or running event simulations. By &amp;quot;instantiate an X&amp;quot; I mean assign X a physical place, posture, orientation, etc. or. retrieve a pointer to sulh an instantiation, if it is a familiar one. Th s &amp;quot;instantiate a baby&amp;quot; would retrieve a pointer, whereas &amp;quot;instantiate a two-neaded dog&amp;quot; would probably have to attempt to generate one on the spot. Note that this process may itself fail, i.e. that an entity may not be able to &amp;quot;imagine&amp;quot; such an object. it useful to distinguish between static dynamic scene descriptions. scene express spatial relations or actions in 8 As the examples below illustrate, sometimes an event simulation simply cannot be set up because information is missing, or several possible &amp;quot;pictures&amp;quot; are equally plausible, or the objects and actions being described cannot be fitted together for a variety of reasons, or the results of running the simulation do not match our knowledge of the world or the following portions of the scene description, and so on. It is also important to emphacize that our ultimate interest is in being able to succeedin setting up and running event simulations; therefore I have for the most part chosen ambiguous examples where at least one event simulation succeeds. 4.1 TRANSLATING AN OLD EXAMPLE INTO NEW MECHANISMS Consider Bar-Hillel&apos;s famous sentence (310) The box is in the pen. Plausibility judgement is necessary to choose the appropriate reading, i.e. that &amp;quot;pen&amp;quot; . playpen. Minor extensions to Boggess&apos;s program could allow it to choose the appropriate referent for pen. Pent(the writing implement) would be defined as having a relatively fixed size (subject to being overridden by modifiers, as in pen&amp;quot; or &amp;quot;twelve inch pen&amp;quot;), but the size of (the enclosure) would be allowed to vary over a range of values (as would the size of box). The program could attempt to model the sentence by instantiating standard (default-sized) models of box, pen1, and pen2, and attempting to assign the objects to positions in a system such that the box would be or pen2. Pent could not take part in such a spatial analog model both because of pent&apos;s rigid size, and the extreme shrinkage that would be required of box (outside box&apos;s allowed range) to make it smaller than the pen1, and also because penl is not a container (i.e. hollow object). Pen2 and box prototypes could be fitted together without problems, and could thus be chosen as the most appropriate interpretation. 4.2 A SIMPLE EVENT SIMULATION Extending Boggess&apos;s program to deal with most of the other examples given in this paper so far would be harder, although I believe that S1-S4 could be handled without too much difficulty. Let us look at 52 and S4 in more detail: (52) I saw the man on the hill with a telescope. (S4) I cleaned the lens to get a better view of him. After being told 52, a system would either pick one of the possible interpretations as most plausible, or it might be unable to choose between competing interpretations, and keep them both. When it is told S4, the system must first discover that &amp;quot;the lens&amp;quot; is part of the telescope. Having done this, $4 unambiguously forces the placement of the speaker to be close enough to the telescope to touch it. This is all common interpretations of cleanrequire the agent to be close to the object. At least two possible still remain: 1) the speaker from the man on the hill, and is using the telescope to view the man; or 2) the speaker, telescope, and man on the hill are all close together. The phrase &amp;quot;to get a better view of him&amp;quot; refers to the actions of the speaker in viewing the man, and thus makes interpretation 1) much more likely, but 2) is still conceivable. The reasoning necessary to choose 1) as most plausible is rather subtle, involving the idea that telescopes are usually used to look at distant objects. In any case, the proposed mechanisms should allow a system to discard an interpretatiion of S2 and 54 where the man on the hill had a telescope and was distant from the speaker. A central figure in the machine translation effort of the late 50&apos;s and early 60&apos;s, Bar-Hillel cited this sentence in explaining why machine translation was impossible. He subsequently quit the field. 4.3 SIMULATING AN IMPLAUSIBLE EVENT Let us also look again at S5: ($5) My dachshund bit our mailman on the ear. and be more specific about what an event simulation should involve in this rather complex case. The event simulation set up procedures I envision would.execute the following steps: 1) instantiate a standard mailman and dachshund in default positions (e.g. both standing on level ground outdoors on a residential street with no special props other than the mailman&apos;s uniform and mailbag); 2) analyze the preconditions for &amp;quot;bite&amp;quot; to find that they require the dog&apos;s mouth to surround the mailman&apos;s ear; 3) see whether the dachshund&apos;s mouth can reach the mailman&apos;s ear directly (no); 4) see whether the dog can stretch high enough to reach (no; this test would require an articulated model of the dog&apos;s skeleton or a prototypical representation of a dog on its hind legs.); 5) see whether a dachshund could jump high enough (no; this step is decidedly non-trivial to implement! ); 6) see whether the mailman ordinarily gets into any positions where the dog could reach his ear (no); conclude that the mailman could not as stated unless default sizes or movement ranges are relaxed in some way. Since there is no clearly preferred way to relax the defaults, more information is necessary to make this an &amp;quot;unambiguous&amp;quot; description. I have quoted &amp;quot;unambiguous&amp;quot; because the sentence 35 is not ambiguous in any ordinary sense, lexically or structurally. What It ambiguous are the conditions and actions which could have led up to S5. Strangely enough, the ordinary actions of mailmen (checked in step 6) seem relevant to the judgement of plausibility in this sentence. As evidence for this analysis, note that substitution of &amp;quot;gardener&amp;quot; turns (S5) into a sentence that can be simulated without problems. I think that it is significant that such peripheral factors can be influential in judging, the plausibility of an event. At the same time, I am aware that the effect in this case is rather weak, that people can accept this sentence without noting any strangeness, so do not want to that are too strong. 4.4 MAKING INFERENCES ABOUT SCENES Consider the following passage: (P1) You are at one end of a vast hall stretching forward out of sight to the west. There are openings to either side. Nearby, a wide stone staircase leads downward. The hall is filled with wisps of white mist swaying to and fro almost as if alive. A cold wind blows up the staircase. There is a passage at the top of the dome behind you. Rough stone steps lead up the dome. Given this passage (taken from the computer game &amp;quot;Adventure&amp;quot;) one can infer that it is possible to move to the west, north, south, or east (up the rough stone steps). Note that this information is buried in the description; in order to infer this information, it would be useful to construct a spatial analog model, one could do it by simply including in the definition of a dog information about how high a dog can jump, e.g. no higher than twice the dog&apos;s length. However I consider this something of a &amp;quot;hack&amp;quot;, because it ignores some other problems, for example the timing problem a dog would face in biting a small target like a person&apos;s ear at the apex of its highest jump. I would prefer a solution that could, if necessary, perform an event simulation for step 5), rather than trust canned data. 9 with &amp;quot;you&amp;quot; facing west, and the scene features placed appropriately. In playing Adventure, it is also necessary to remember salient features of the scenes described so that one can recognize the same room later, a passage such in hall of mists. Rough stone steps lead up the dome. There is a threatening little dwarf in the room with you. Adventure can only accept a very limited class of commands from a player at any given point in the game. It is only possible to play the game because one can make reasonable inferences about what actions are possible at a given point, i.e. take an object, move in some direction, throw a knife, open a door, etc. While I am not quite sure what make of my observations about this example, I think that games such as Adventure are potentially valuable tools for gathering information about the kinds of spatial and other inferences people make about scene descriptions. 4.5 MIRACLES AND WORLD RECORDS With some sentences there may be no plausible at all. In many of the examples follow, it Seems unlikely that we actually generate (at least consciously) an event simulation. Rather it seems that we have some shortcuts for recognizing that certain events would have to be termed &amp;quot;miraculous&amp;quot; or difficult to believe. car goes 2000 miles on a tank of gas. (S23) Mary caught the bullet between her teeth. (524) The child fell from the 10th story window to the street below, but wasn&apos;t hurt. (S25) We took the refrigerator home in the trunk of our VW Beetle. (S26) She had given birth to 25 children by the age of 30. (S27) The robin picked up the book and flew away with it. (S28) The child chewed up and swallowed the pair of scissors. Guinness Book of World Records of examples that defy event simulation. How one is able to judge the plausibility of these (and how we might get a to do so) remains something mystery to me. The problem of recognizing obviously implausible events rapidly is an important one to consider for dealing with pronouns. Often we choose the appropriate referent for a pronoun because only one of the possible referents could be part of a plausible event if substituted for the pronoun. For example, &amp;quot;it&amp;quot; must refer to &amp;quot;milk&amp;quot;, not &amp;quot;baby&amp;quot;, in S29: (529) I didn&apos;t want the baby to get sick from drinking the milk, so I boiled it. OF EVENT SIMULAT7QH IN A FULI. THEORY OF LANGUAGF suggested in section a scene description understanding system would have to 1) verify the plausibility of a described scene, 2) make inferences or predictions about the scene, 3) act if action is called for, and 4) remember whatever is Important. As pointed out in section 4.5, event simulations may not even be need for all cases of plausibility judgement. Furthermore, scene descriptions constitute only one of many possible topics of language. Nonetheless, I feel that the study of event simulation is extremely important. 5.1 WHY ARE SIMPLE PHYSICAL SCENES WORTH CONSIDERING? For a number of reasons, methodological as well as theoretical, I believe that it is not only worthwhile, but also important to begin the study of scene descriptions with the world of simple physical objects, events, and physical behaviors with simple goals. 1) Methodologically it is necessary to pick an area of concentration which is restricted in some way. The world of simple physical objects and events is one of the simplest worlds that links language and sensory descriptions. 2) As argued in the work of Piaget (5], it seems likely that we come to comprehend the world by first mastering the sensory/motor world, and then by adapting and building on our schemata from the sensory/motor world to understand progressively more abstract worlds. In the area of language Jackendoff (6) offers parallel arguments. Thus the world of simple physical oojects and behaviors has a privileged positions in the development of cognition and language. 3) Few words in English are reserved for describing the abstract world only. Most abstract words also have a physical meaning. In some cases the physical meanings may provide important metaphors for understanding the world, while cases the same mechanisms that are used in the interpretation of the physical world may be shared with mechanisms that interpret the abstract world. 4) I would like the representations I develop for scene descriptions to with representations I can Imagine generating with a vision system. Thus this work does have an indirect bearing on vision research: my representations characterize and put constraints on the types and forms of information I a ought to be able to supply. 5) Even in the physical domain, we must come to grips with some processes that resemble those involved in the generation and understanding of metaphor: matching, adaptation of schemata, modification of stereotypical items to match actual items, and the interpretation of items from different perspectives. 5.2 SCENE DESCRIPTIONS AND A THEORY OF ACTION I take it as evident that every scene description, indeed every utterance, is associated with some purpose or goal of a speaker. The speaker&apos;s purpose affects the organization and order of the speaker&apos;s presentation, the items included and the items omitted, as well as word choice and stress. Any two witnesses of the same event will in general give accounts of it that differ on every level, especially if one or both witnesses were participants or has some special Interest in the cause or outcome of the event. For now I have ignored all these factors of scene description understanding; I have not attempted an account of the deciphering of a speaker&apos;s goals or biases from a given scene description. I have instead considered only the propositional content of scene description utterances, in particular the issue of or not scene description could plausibly correspond to a real scene. Until we can give an account of the judgement of plausibility of description meanings, we cannot even say how we recognize blatant from this perspective, understanding might lie or mislead, i.e. understanding the intended effect of an utterance, is a secondary issue. There seems to me to be a clear need for a &amp;quot;theory of human action&amp;quot;, both for purposes of event simulation and, more importantly, to provide a better overall framework for Al research than we currently have. While no one to my knowledge still accepts as plausible the &amp;quot;big switch&amp;quot; theory of intelligent action (7), most Al work seems to proceed on the &amp;quot;big switch&amp;quot; assumptions that it is valid to study intelligent behavior in isolated domains, and that there is no compelling reason at this point to worry about whether (let alone AoJeL) the pieces developed in isolation will ultimately fit together. THERE MANY WAYS TO SKIN k CAT? analog models are the only representation for scene they are convenient and natural in many ways. Among their are: 1) computational adequacy representing the locations and motions of objects; 2) the ability to implicitly represent relationships between objects, and to allow easy derivation of these relationships; 3) ease of interaction with a vision system, and ultimately appropriateness for allowing a mobile entity to navigate and locate objects. The main problem with these representations is that scene descriptions are usually underspecified, so that there is a range of possible locations for each object. It thus becomes risky to trust implicit relationships between objects. Event stereotypes are probably important because they specify compactly all the important relationships between objects. 5.4 RELATED WORK A number of papers related the the topics treated here have appeared in recent years. Many are listed in [8] which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work by Hayes(20,21]. My comments on pronoun resolution are in the same spirit as Hobbs(22], although Hobbs&apos;s &amp;quot;predicate interpretation&amp;quot; is quite different from my &amp;quot;analog spatial models&amp;quot;. Ideas on the adaptation of prototypes for the representation of 3-D shape were explored in Waltz (23]. A effort toward qualitative mechanics is described in Bundy [24]. Also relevant is the work on mental imagery of Kosslyn &amp; Shwartz(25] and Hinton(26]. I would like to acknowledge especially the helpful comments of Ken Forbus, and also the help I have received from Bill Woods, Candy Sidner, Jeff Gibbons, Rusty Bobrow, David Israel, and Brad Goodman. [1] Waltz, D.L. and Boggess, L.C. Visual Analog representations for natural language understanding.</abstract>
<note confidence="0.951043101265823">of IJCAT-74,Tokyo, Japan, Aug. 1979. [2] Boggess, L.C. Computational interpretation of English spatial prepositions. Unpublished Ph.D. dissertation, Computer Science Dept., University of Illinois, Urbana, 1978. [3] Chafe, W.L. The flow of thought and the flow of In T.Givon (ed.) and Syntax Academic Press, New York, 1979. [4] Bar-Hillel, Y. 1.aauagaAnclJ.nf.2mar,=. Addison-Wesley, New York, 1964. Piaget, J. Psychological StudiesVintage Books, New York, 1967. [6] Jackendoff, R. Toward an explanatory semantic InauirvL, 1, 89-150, 1975. [7] Minsky, M. and Papert, S. Artificial Intelligence, Project MAC report, 1971. [8] Waltz, D.L. Generating and understanding scene In Joshi, Sag, and Webber (eds.) Discourse UnderstandingCambridege University Press, to appear. Also Working paper 24, Coordinated Science Lab, Univ. of Illinois, Urbana Feb. 1980. [9] Woods, W.A. Procedural semantics as a theory of In Joshi, Sag, and Webber (eds.) Underqtanding.Cambridge University Press, to appear. [10] Kuipers, B.J. Representing knowledge of large-scale space. Tech. Rpt. AI-TR-418, MIT Al Lab, Cambridge, MA, 1977. [11] Novak, G.S. Computer understanding of physics problems stated in natural language. Tech. Rpt. NL-30, Dept. of Computer Science, University of Texas, Austin, 1976. [12] Simmons, R.F. The CLOWNS microworld. In Schank and (eds.) Issues in Natural Processing,ACL, Arlington, VA, 1975. Schank, R.C. and Abelson, R. Plans. and Understanding.Lawrence Erlbaum Associates, Hillsdale, NJ, 1977. [14] Rieger, C. The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension. In Schank and (eds.) Issues La Natural Processing,ACL, Arlington, VA, 1975. [15] Johnson-Laird, P.N. Mental models in cognitive Scienre 4,1, 71-115, Jan.-Mar. 1980. [16] Herskovitz, A. On the spatial uses of prepositions. In this proceedings. [17] Forbus, K.D. A study of qualitative and geometric knowledge in reasoning about motion. MS thesis, MIT Al Lab, Cambridge, MA, Feb. 1980. [18) de Kleer, J. Multiple representations of knowledge a mechanics problem-solver. 5th Intl. Joint on Artificial Intelligenne,MIT, Cambridge, MA, 1977, 299-304. [19] de Kleer, J. The origin and resolution of in causal arguments. IJCAT-74,Tokyo, Japan, 1979, 197-203. [20] Hayes, P.J. The naive physics manifesto. Unpublished paper, May 1978. (21] Hayes, P.J. Naive physics 1: Ontology for liquids. Unpublished paper, Aug. 1978. [22] Hobbs, J.R. Pronoun resolution. Research report, Dept. of Computer Sciences, City College, City University of New York, c.1976. (23] Waltz, D.L. Relating images, concepts, and words. of on the Representation of 1-0 Obiects,University of Pennsylvania, Philadelphia, 1979. Also available as Working Paper 23, Coordinated Science Lab, University of Illinois, Urbana, Feb. 1980. [24] Bundy, A. Will it reach the top? Prediction in the world. Intelligence 10,2, April 1978. Kosslyn, S.M. &amp; Shwartz, simulation of imagery. Science 1,3, July 1977. [26] Hinton, G. Some demonstrations of the effects of descriptions in mental imagery. Salezue_1, 3, July-Sept. 1979. 11</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D L Waltz</author>
<author>L C Boggess</author>
</authors>
<title>Visual Analog representations for natural language understanding.</title>
<date>1979</date>
<booktitle>Proc. of IJCAT-74,</booktitle>
<location>Tokyo, Japan,</location>
<marker>[1]</marker>
<rawString>Waltz, D.L. and Boggess, L.C. Visual Analog representations for natural language understanding. Proc. of IJCAT-74, Tokyo, Japan, Aug. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L C Boggess</author>
</authors>
<title>Computational interpretation of English spatial prepositions.</title>
<date>1978</date>
<institution>Computer Science Dept., University of Illinois,</institution>
<location>Urbana,</location>
<note>Unpublished Ph.D. dissertation,</note>
<marker>[2]</marker>
<rawString>Boggess, L.C. Computational interpretation of English spatial prepositions. Unpublished Ph.D. dissertation, Computer Science Dept., University of Illinois, Urbana, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W L Chafe</author>
</authors>
<title>The flow of thought and the flow of language. In</title>
<date>1979</date>
<booktitle>Discourse and Syntax</booktitle>
<editor>T.Givon (ed.)</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="7872" citStr="[3]" startWordPosition="1299" endWordPosition="1299">e, position, and orientation in a coordinate system, as illustrated in figure 1. I will refer to such representations as &amp;quot;spatial analog models&amp;quot; (in (1] they were called &amp;quot;visual analog models&amp;quot;). Objects In Boggess&apos;s program are defined by giving values for their typical values of size, weight, orientation, surfaces capable of supporting other objects, as well as other properties such as &amp;quot;hollow&amp;quot; or &amp;quot;solid&amp;quot;, and so on. Fizure 1 A &amp;quot;visual analog model&amp;quot; of S12-515. Dynamic scene descriptions can use detail addition also, but more commonly they use either the mechanisms of &amp;quot;successive refinement&amp;quot; [3] or &amp;quot;temporal addition&amp;quot;. &amp;quot;Temporal addition&amp;quot; refers to the process of describing events through a series of time-ordered static scene descriptions, as in: ($16) Our mailman fell while running from our dachshund. (Si?) The dachshund bit the mailman on the ear. &amp;quot;Successive refinement&amp;quot; refers to a process where an introductory sentence sets up a more or less prototypical event which is then modified by succeeding sentences, e.g. by listing exceptions to one&apos;s ordinary expectations of the prototype, or by providing specific values for optional items in he prototype, or by similar means. The follow</context>
</contexts>
<marker>[3]</marker>
<rawString>Chafe, W.L. The flow of thought and the flow of language. In T.Givon (ed.) Discourse and Syntax Academic Press, New York, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
</authors>
<date></date>
<publisher>Addison-Wesley,</publisher>
<location>New York,</location>
<marker>[4]</marker>
<rawString>Bar-Hillel, Y. 1.aauagaAnclJ.nf.2mar,=. Addison-Wesley, New York, 1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piaget</author>
</authors>
<title>Six Psychological Studies Vintage Books,</title>
<date>1967</date>
<location>New York,</location>
<marker>[5]</marker>
<rawString>Piaget, J. Six Psychological Studies Vintage Books, New York, 1967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jackendoff</author>
</authors>
<title>Toward an explanatory semantic representation.</title>
<date>1975</date>
<journal>finguiltir Inauirv L,</journal>
<volume>1</volume>
<pages>89--150</pages>
<marker>[6]</marker>
<rawString>Jackendoff, R. Toward an explanatory semantic representation. finguiltir Inauirv L, 1, 89-150, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
<author>S Papert</author>
</authors>
<date>1971</date>
<booktitle>Artificial Intelligence, Project MAC report,</booktitle>
<marker>[7]</marker>
<rawString>Minsky, M. and Papert, S. Artificial Intelligence, Project MAC report, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Waltz</author>
</authors>
<title>Generating and understanding scene descriptions.</title>
<date>1980</date>
<booktitle>Flaments of Discourse Understanding</booktitle>
<editor>In Joshi, Sag, and Webber (eds.)</editor>
<publisher>Cambridege University Press,</publisher>
<institution>Coordinated Science Lab, Univ. of Illinois,</institution>
<location>Urbana</location>
<note>to appear. Also Working paper 24,</note>
<contexts>
<context position="28237" citStr="[8]" startWordPosition="4710" endWordPosition="4710">eraction with a vision system, and ultimately appropriateness for allowing a mobile entity to navigate and locate objects. The main problem with these representations is that scene descriptions are usually underspecified, so that there is a range of possible locations for each object. It thus becomes risky to trust implicit relationships between objects. Event stereotypes are probably important because they specify compactly all the important relationships between objects. 5.4 RELATED WORK A number of papers related the the topics treated here have appeared in recent years. Many are listed in [8] which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson</context>
</contexts>
<marker>[8]</marker>
<rawString>Waltz, D.L. Generating and understanding scene descriptions. In Joshi, Sag, and Webber (eds.) Flaments of Discourse Understanding Cambridege University Press, to appear. Also Working paper 24, Coordinated Science Lab, Univ. of Illinois, Urbana Feb. 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W A Woods</author>
</authors>
<title>Procedural semantics as a theory of meaning</title>
<editor>In Joshi, Sag, and Webber (eds.)</editor>
<publisher>Cambridge University Press,</publisher>
<note>to appear.</note>
<marker>[9]</marker>
<rawString>Woods, W.A. Procedural semantics as a theory of meaning In Joshi, Sag, and Webber (eds.) Fiements of nigoolirge Underqtanding. Cambridge University Press, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Kuipers</author>
</authors>
<title>Representing knowledge of large-scale space.</title>
<date>1977</date>
<tech>Tech. Rpt. AI-TR-418,</tech>
<institution>MIT Al Lab,</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="28532" citStr="[10]" startWordPosition="4754" endWordPosition="4754">becomes risky to trust implicit relationships between objects. Event stereotypes are probably important because they specify compactly all the important relationships between objects. 5.4 RELATED WORK A number of papers related the the topics treated here have appeared in recent years. Many are listed in [8] which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and rela</context>
</contexts>
<marker>[10]</marker>
<rawString>Kuipers, B.J. Representing knowledge of large-scale space. Tech. Rpt. AI-TR-418, MIT Al Lab, Cambridge, MA, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Novak</author>
</authors>
<title>Computer understanding of physics problems stated in natural language.</title>
<date>1976</date>
<tech>Tech. Rpt. NL-30,</tech>
<institution>Dept. of Computer Science, University of Texas,</institution>
<location>Austin,</location>
<contexts>
<context position="28544" citStr="[11]" startWordPosition="4756" endWordPosition="4756">y to trust implicit relationships between objects. Event stereotypes are probably important because they specify compactly all the important relationships between objects. 5.4 RELATED WORK A number of papers related the the topics treated here have appeared in recent years. Many are listed in [8] which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work </context>
</contexts>
<marker>[11]</marker>
<rawString>Novak, G.S. Computer understanding of physics problems stated in natural language. Tech. Rpt. NL-30, Dept. of Computer Science, University of Texas, Austin, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
</authors>
<title>The CLOWNS microworld.</title>
<date>1975</date>
<booktitle>In Schank and Nash-Webber (eds.) Theoretical Issues in Natural Language Processing, ACL,</booktitle>
<location>Arlington, VA,</location>
<contexts>
<context position="28642" citStr="[12]" startWordPosition="4770" endWordPosition="4770">e they specify compactly all the important relationships between objects. 5.4 RELATED WORK A number of papers related the the topics treated here have appeared in recent years. Many are listed in [8] which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work by Hayes(20,21]. My comments on pronoun resolution are in the same spirit as Hobbs(22], although H</context>
</contexts>
<marker>[12]</marker>
<rawString>Simmons, R.F. The CLOWNS microworld. In Schank and Nash-Webber (eds.) Theoretical Issues in Natural Language Processing, ACL, Arlington, VA, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Plans</author>
</authors>
<title>Goals. and Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hillsdale, NJ,</location>
<contexts>
<context position="28841" citStr="[13]" startWordPosition="4798" endWordPosition="4798"> which also provides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work by Hayes(20,21]. My comments on pronoun resolution are in the same spirit as Hobbs(22], although Hobbs&apos;s &amp;quot;predicate interpretation&amp;quot; is quite different from my &amp;quot;analog spatial models&amp;quot;. Ideas on the adaptation of prototypes for the representation of 3-D shape were explored in Waltz (23]. A effort t</context>
</contexts>
<marker>[13]</marker>
<rawString>Schank, R.C. and Abelson, R. Scripts. Plans. Goals. and Understanding. Lawrence Erlbaum Associates, Hillsdale, NJ, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
</authors>
<title>The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension.</title>
<date>1975</date>
<booktitle>In Schank and Nash-Webber (eds.) Theoretical Issues La Natural Language Processing, ACL,</booktitle>
<location>Arlington, VA,</location>
<contexts>
<context position="28856" citStr="[14]" startWordPosition="4800" endWordPosition="4800">vides some ideas on the generation of scene descriptions. This work has been pervasively influenced by the ideas of Bill Woods on &amp;quot;procedural semantics&amp;quot;, especially as presented in [91. Representations for large-scale space (paths, maps, etc.) were treated in Kuipers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work by Hayes(20,21]. My comments on pronoun resolution are in the same spirit as Hobbs(22], although Hobbs&apos;s &amp;quot;predicate interpretation&amp;quot; is quite different from my &amp;quot;analog spatial models&amp;quot;. Ideas on the adaptation of prototypes for the representation of 3-D shape were explored in Waltz (23]. A effort toward qualitati</context>
</contexts>
<marker>[14]</marker>
<rawString>Rieger, C. The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension. In Schank and Nash-Webber (eds.) Theoretical Issues La Natural Language Processing, ACL, Arlington, VA, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P N Johnson-Laird</author>
</authors>
<title>Mental models in cognitive science.</title>
<date>1980</date>
<journal>Cognitive Scienre</journal>
<volume>4</volume>
<pages>71--115</pages>
<marker>[15]</marker>
<rawString>Johnson-Laird, P.N. Mental models in cognitive science. Cognitive Scienre 4, 1, 71-115, Jan.-Mar. 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Herskovitz</author>
</authors>
<title>On the spatial uses of prepositions. In this proceedings.</title>
<marker>[16]</marker>
<rawString>Herskovitz, A. On the spatial uses of prepositions. In this proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K D Forbus</author>
</authors>
<title>A study of qualitative and geometric knowledge in reasoning about motion. MS thesis,</title>
<date>1980</date>
<booktitle>Frac- 5th Intl. Joint Cont. on Artificial Intelligenne, MIT,</booktitle>
<pages>299--304</pages>
<institution>MIT Al Lab,</institution>
<location>Cambridge, MA,</location>
<marker>[17]</marker>
<rawString>Forbus, K.D. A study of qualitative and geometric knowledge in reasoning about motion. MS thesis, MIT Al Lab, Cambridge, MA, Feb. 1980. [18) de Kleer, J. Multiple representations of knowledge in a mechanics problem-solver. Frac- 5th Intl. Joint Cont. on Artificial Intelligenne, MIT, Cambridge, MA, 1977, 299-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J de Kleer</author>
</authors>
<title>The origin and resolution of ambiguities in causal arguments.</title>
<date>1979</date>
<booktitle>Proc. IJCAT-74,</booktitle>
<pages>197--203</pages>
<location>Tokyo, Japan,</location>
<contexts>
<context position="29122" citStr="[18,19]" startWordPosition="4834" endWordPosition="4834">pers&apos; thesis [10]. Novak [11] wrote a program that generated and used diagrams for understanding physics problems. Simmons [12] wrote programs that understood simple scene descriptions involving several known objects. Inferences about the causes and effects of actions and events have been considered by Schank and Abelson[13] and Rieger[14]. Johnson-Laird(15) has investigated problems in understanding scenes with spatial locative prepositions, as has Herskovits(16]. Recent work by Forbus(17] has developed a very interesting paradigm for qualitative reasoning in physics, built on work by deKleer[18,19], and related to work by Hayes(20,21]. My comments on pronoun resolution are in the same spirit as Hobbs(22], although Hobbs&apos;s &amp;quot;predicate interpretation&amp;quot; is quite different from my &amp;quot;analog spatial models&amp;quot;. Ideas on the adaptation of prototypes for the representation of 3-D shape were explored in Waltz (23]. A effort toward qualitative mechanics is described in Bundy [24]. Also relevant is the work on mental imagery of Kosslyn &amp; Shwartz(25] and Hinton(26]. I would like to acknowledge especially the helpful comments of Ken Forbus, and also the help I have received from Bill Woods, Candy Sidner, </context>
</contexts>
<marker>[19]</marker>
<rawString>de Kleer, J. The origin and resolution of ambiguities in causal arguments. Proc. IJCAT-74, Tokyo, Japan, 1979, 197-203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
</authors>
<title>The naive physics manifesto. Unpublished paper,</title>
<date>1978</date>
<marker>[20]</marker>
<rawString>Hayes, P.J. The naive physics manifesto. Unpublished paper, May 1978. (21] Hayes, P.J. Naive physics 1: Ontology for liquids. Unpublished paper, Aug. 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Pronoun resolution. Research report,</title>
<date>1976</date>
<booktitle>Proc. of the NSF Workshop on the Representation of</booktitle>
<pages>1--0</pages>
<institution>Dept. of Computer Sciences, City College, City University of</institution>
<location>New York,</location>
<marker>[22]</marker>
<rawString>Hobbs, J.R. Pronoun resolution. Research report, Dept. of Computer Sciences, City College, City University of New York, c.1976. (23] Waltz, D.L. Relating images, concepts, and words. Proc. of the NSF Workshop on the Representation of 1-0 Obiects, University of Pennsylvania, Philadelphia, 1979. Also available as Working Paper 23, Coordinated Science Lab, University of Illinois, Urbana, Feb. 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bundy</author>
</authors>
<title>Will it reach the top? Prediction in the mechanics world.</title>
<date>1978</date>
<journal>Artificial Intelligence</journal>
<volume>10</volume>
<marker>[24]</marker>
<rawString>Bundy, A. Will it reach the top? Prediction in the mechanics world. Artificial Intelligence 10, 2, April 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Kosslyn</author>
<author>S P Shwartz</author>
</authors>
<title>A simulation of visual imagery.</title>
<date>1977</date>
<journal>Cognitive Science</journal>
<volume>1</volume>
<marker>[25]</marker>
<rawString>Kosslyn, S.M. &amp; Shwartz, S.P. A simulation of visual imagery. Cognitive Science 1, 3, July 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hinton</author>
</authors>
<title>Some demonstrations of the effects of structural descriptions in mental imagery.</title>
<date>1979</date>
<booktitle>Cognitive Salezue_1,</booktitle>
<location>3, July-Sept.</location>
<marker>[26]</marker>
<rawString>Hinton, G. Some demonstrations of the effects of structural descriptions in mental imagery. Cognitive Salezue_1, 3, July-Sept. 1979.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>