<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002195">
<title confidence="0.991305">
Harnessing Context Incongruity for Sarcasm Detection
</title>
<author confidence="0.971427">
Aditya Joshi&apos;,2,3 Vinita Sharma&apos; Pushpak Bhattacharyya&apos;
</author>
<affiliation confidence="0.906829">
&apos;IIT Bombay, India, 2Monash University, Australia
3IITB-Monash Research Academy, India
</affiliation>
<email confidence="0.991638">
aadi.cse@iitb.ac.in, pb@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.993747" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999833785714286">
The relationship between context incon-
gruity and sarcasm has been studied in lin-
guistics. We present a computational sys-
tem that harnesses context incongruity as a
basis for sarcasm detection. Our statistical
sarcasm classifiers incorporate two kinds
of incongruity features: explicit and im-
plicit. We show the benefit of our incon-
gruity features for two text forms - tweets
and discussion forum posts. Our system
also outperforms two past works (with F-
score improvement of 10-20%). We also
show how our features can capture inter-
sentential incongruity.
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999829727272727">
Sarcasm is defined as ‘a cutting, often ironic re-
mark intended to express contempt or ridicule’1.
Sarcasm detection is the task of predicting a text
as sarcastic or non-sarcastic. The past work in sar-
casm detection involves rule-based and statistical
approaches using: (a) unigrams and pragmatic fea-
tures (such as emoticons, etc.) (Gonzalez-Ibanez
et al., 2011; Carvalho et al., 2009; Barbieri et al.,
2014), (b) extraction of common patterns, such
as hashtag-based sentiment (Maynard and Green-
wood, 2014; Liebrecht et al., 2013), a positive verb
being followed by a negative situation (Riloff et
al., 2013), or discriminative n-grams (Tsur et al.,
2010a; Davidov et al., 2010).
Thus, the past work detects sarcasm with spe-
cific indicators. However, we believe that it is time
that sarcasm detection is based on well-studied lin-
guistic theories. In this paper, we use one such lin-
guistic theory: context incongruity. Although the
past work exploits incongruity, it does so piece-
meal; we take a more well-rounded view of in-
congruity and place it center-stage for our work.
</bodyText>
<note confidence="0.499823">
1Source: The Free Dictionary
</note>
<bodyText confidence="0.999566666666667">
The features of our sarcasm detection system are
based on two kinds of incongruity: ‘explicit’ and
‘implicit’. The contribution of this paper is:
</bodyText>
<listItem confidence="0.8636521875">
• We present a sarcasm detection system that is
grounded on a linguistic theory, the theory of
context incongruity in our case. Sarcasm de-
tection research can push the frontiers by tak-
ing help of well-studied linguistic theories.
• Our sarcasm detection system outperforms
two state-of-art sarcasm detection sys-
tems (Riloff et al., 2013; Maynard and
Greenwood, 2014). Our system shows an
improvement for short ‘tweets’ as well as
long ‘discussion forum posts’.
• We introduce inter-sentential incongruity for
sarcasm detection, that expands context of a
discussion forum post by including the previ-
ous post (also known as the ‘elicitor’ post) in
the discussion thread.
</listItem>
<bodyText confidence="0.999579416666667">
Rest of the paper is organized as follows. We first
discuss related work in Section 2. We introduce
context incongruity in Section 3. Feature design
for explicit incongruity is presented in Section 3.1,
and that for implicit incongruity is in Section 3.2.
We then describe the architecture of our sarcasm
detection system in Section 4 and our experimen-
tal setup in Section 5. Quantitative evaluation is
in Section 6. Inter-sentential sarcasm detection is
in Section 7. Section 8 presents the error analysis.
Section 9 concludes the paper and points to future
directions.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999914428571429">
Sarcasm/irony as a linguistic phenomenon has
been extensively studied. According to Wilson
(2006), sarcasm arises from situational disparity.
The relationship between context incongruity and
sarcasm processing (by humans) has been studied
in Ivanko and Pexman (2003). Several properties
of sarcasm have also been investigated. Campbell
</bodyText>
<page confidence="0.894186">
757
</page>
<bodyText confidence="0.97193262">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 757–762,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
and Katz (2012) state that sarcasm occurs along
different dimensions, namely, failed expectation,
pragmatic insincerity, negative tension, presence
of a victim and along stylistic components such as
emotion words. Eisterhold et al. (2006) observe
that sarcasm can be identified based on the state-
ment preceding and following the sarcastic state-
ment. This is particularly true in cases where the
incongruity is not expressed within the sarcastic
text itself.
Computational detection of sarcasm is a rela-
tively recent area of research. Initial work on
sarcasm detection investigates the role of lexi-
cal and pragmatic features. Tepperman et al.
(2006) present sarcasm recognition in speech us-
ing prosodic, spectral (average pitch, pitch slope,
etc.) and contextual cues (laughter or response
to questions). Carvalho et al. (2009) use sim-
ple linguistic features like interjection, changed
names, etc. for irony detection. Davidov et al.
(2010) train a sarcasm classifier with syntactic
and pattern-based features. Gonzalez-Ibanez et al.
(2011) study the role of unigrams and emoticons
in sarcasm detection. Liebrecht et al. (2013) use
a dataset of Dutch tweets that contain sarcasm-
related hashtags and implement a classifier to pre-
dict sarcasm. A recent work by ?) takes the output
of sarcasm detection as an input to sentiment clas-
sification. They present a rule-based system that
uses the pattern: if the sentiment of a tokenized
hashtag does not agree with sentiment in rest of the
tweet, the tweet is sarcastic, in addition to other
rules.
Our approach is architecturally similar to Tsur
et al. (2010b) who use a semi-supervised pattern
acquisition followed by classification. Our feature
engineering is based on Riloff et al. (2013) and
Ramteke et al. (2013). Riloff et al. (2013) state
that sarcasm is a contrast between positive senti-
ment word and a negative situation. They imple-
ment a rule-based system that uses phrases of pos-
itive verb phrases and negative situations extracted
from a corpus of sarcastic tweets. Ramteke et al.
(2013) present a novel approach to detect thwart-
ing: the phenomenon where sentiment in major
portions of text is reversed by sentiment in smaller,
conclusive portions.
</bodyText>
<sectionHeader confidence="0.984277" genericHeader="method">
3 Context Incongruity
</sectionHeader>
<bodyText confidence="0.999893">
Incongruity is defined as ‘the state of being not
in agreement, as with principles’1. Context incon-
gruity is a necessary condition for sarcasm (Camp-
bell and Katz, 2012). Ivanko and Pexman (2003)
state that the sarcasm processing time (time taken
by humans to understand sarcasm) depends on the
degree of context incongruity between the state-
ment and the context.
Deriving from this idea, we consider two cases
of incongruity in sarcasm that are analogous to two
degrees of incongruity. We call them explicit in-
congruity and implicit incongruity, where im-
plicit incongruity demands a higher processing
time. It must be noted that our system only han-
dles incongruity between the text and common
world knowledge (i.e., the knowledge that ‘being
stranded’ is an undesirable situation, and hence,
‘Being stranded in traffic is the best way to start
my week’ is a sarcastic statement). This leaves out
an example like ‘Wow! You are so punctual’ which
may be sarcastic depending on situational context.
</bodyText>
<subsectionHeader confidence="0.995093">
3.1 Explicit incongruity
</subsectionHeader>
<bodyText confidence="0.999910166666667">
Explicit incongruity is overtly expressed through
sentiment words of both polarities (as in the case
of ‘I love being ignored’ where there is a positive
word ‘love’ and a negative word ‘ignored’). The
converse is not true as in the case of ‘The movie
starts slow but the climax is great’.
</bodyText>
<subsectionHeader confidence="0.999208">
3.2 Implicit Incongruity
</subsectionHeader>
<bodyText confidence="0.999969222222222">
An implicit incongruity is covertly expressed
through phrases of implied sentiment, as op-
posed to opposing polar words. Consider
the example “I love this paper so much that
I made a doggy bag out of it”. There is no explicit
incongruity here: the only polar word is ‘love’.
However, the clause ‘I made a doggy bag out of it’
has an implied sentiment that is incongruous with
the polar word ‘love’.
</bodyText>
<subsectionHeader confidence="0.999835">
3.3 Estimating prevalence
</subsectionHeader>
<bodyText confidence="0.999991375">
We conduct a naive, automatic evaluation on a
dataset of 18,141 sarcastic tweets. As a crude
estimate, we consider an explicit incongruity as
presence of positive and negative words. Around
11% sarcastic tweets have at least one explicit in-
congruity. We also manually evaluate 50 sarcas-
tic tweets and observe that 10 have explicit incon-
gruity, while others have implicit incongruity.
</bodyText>
<sectionHeader confidence="0.991176" genericHeader="method">
4 Architecture
</sectionHeader>
<bodyText confidence="0.998129">
Our system for sarcasm detection augments the
feature vector of a tweet with features based on the
</bodyText>
<page confidence="0.989323">
758
</page>
<bodyText confidence="0.999966357142857">
two types of incongruity. Specifically, we use four
kinds of features: (a) Lexical, (b) Pragmatic, (c)
Implicit congruity, and (d) Explicit incongruity
features. Lexical features are unigrams obtained
using feature selection techniques such as χ2 Test
and Categorical Proportional Difference. Prag-
matic features include emoticons, laughter expres-
sions, punctuation marks and capital words as
given by Carvalho et al. (2009). In addition to
the two, our system incorporates two kinds of in-
congruity features, as discussed next. The explicit
incongruity features are numeric, qualitative fea-
tures, while implicit incongruity features are re-
lated to implicit phrases.
</bodyText>
<subsectionHeader confidence="0.909109">
4.1 Feature Design: Explicit Incongruity
</subsectionHeader>
<bodyText confidence="0.9998935">
An explicit incongruity giving rise to sarcasm
bears resemblance to thwarted expectations (an-
other commonly known challenge to sentiment
analysis). Consider this example: ‘I love the
</bodyText>
<subsubsectionHeader confidence="0.630409">
color. The features are interesting. But a
</subsubsectionHeader>
<bodyText confidence="0.999966888888889">
bad battery life ruins it’. The positive expectation
in the first two sentences is thwarted by the last
sentence. A similar incongruity is observed in
the sarcastic ‘My tooth hurts! Yay!’. The nega-
tive word ‘hurts’ is incongruous with the positive
‘Yay!’. Hence, our explicit incongruity features
are a relevant subset of features from a past sys-
tem to detect thwarting by Ramteke et al. (2013).
These features are:
</bodyText>
<listItem confidence="0.989486">
• Number of sentiment incongruities: The
number of times a positive word is followed
by a negative word, and vice versa
• Largest positive/negative subsequence: The
length of the longest series of contiguous pos-
itive/negative words
• Number of positive and negative words
• Lexical Polarity: The polarity based purely
on the basis of lexical features, as determined
by Lingpipe SA system (Alias-i, 2008). Note
that the ‘native polarity’ need not be correct.
However, a tweet that is strongly positive on
the surface is more likely to be sarcastic than
a tweet that seems to be negative. This is
because sarcasm, by definition, tends to be
caustic/hurtful. This also helps against hum-
ble bragging. (as in case of the tweet ‘so i
have to be up at 5am to autograph 7,000 pics
of myself? Sounds like just about the worst
Wednesday morning I could ever imagine’).
</listItem>
<subsectionHeader confidence="0.936272">
4.2 Feature Design: Implicit Incongruity
</subsectionHeader>
<bodyText confidence="0.999925">
We use phrases with implicit sentiment as the
implicit incongruity features. These phrases are
sentiment-bearing verb and noun phrases, the lat-
ter being situations with implied sentiment (e.g.
‘getting late for work’). For this, we modify
the algorithm given in Riloff et al. (2013) in two
ways: (a) they extract only positive verbs and neg-
ative noun situation phrases. We generalize it to
both polarities, (b) they remove subsumed phrases
(i.e. ‘being ignored’ subsumes ‘being ignored by
a friend’) while we retain both phrases. The ben-
efit of (a) and (b) above was experimentally vali-
dated, but is not included in this paper due to lim-
ited space.
While they use rule-based algorithms that em-
ploy these extracted phrases to detect sarcasm, we
include them as implicit incongruity features, in
addition to other features. It is possible that the set
of extracted situation phrases may contain some
phrases without implicit sentiment. We hope that
the limited size of the tweet guards against such
false positives being too many in number. We add
phrases in the two sets as count-based implicit in-
congruity features.
</bodyText>
<sectionHeader confidence="0.998884" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.959489533333333">
We use three datasets to evaluate our system:
1. Tweet-A (5208 tweets, 4170 sarcastic):
We download tweets with hashtags #sar-
casm and #sarcastic as sarcastic tweets
and #notsarcasm and #notsarcastic as non-
sarcastic, using the Twitter API (https://
dev.twitter.com/). A similar hashtag-
based approach to create a sarcasm-annotated
dataset was employed in Gonzalez-Ibanez et
al. (2011). As an additional quality check, a
rough glance through the tweets is done, and
the ones found to be wrong are removed. The
hashtags mentioned above are removed from
the text so that they act as labels but not as
features.
</bodyText>
<listItem confidence="0.878189875">
2. Tweet-B (2278 tweets, 506 sarcastic): This
dataset was manually labeled for Riloff et al.
(2013). Some tweets were unavailable, due
to deletion or privacy settings.
3. Discussion-A (1502 discussion forum
posts, 752 sarcastic): This dataset is created
from the Internet Argument Corpus (Walker
et al., 2012) that contains manual annota-
</listItem>
<page confidence="0.994932">
759
</page>
<table confidence="0.999788294117647">
Lexical
Unigrams Unigrams in the training corpus
Pragmatic
Capitalization Numeric feature indicating presence of capital letters
Emoticons &amp; laughter ex- Numeric feature indicating presence of emoticons and ‘lol’s
pressions Numeric feature indicating presence of punctuation marks
Punctuation marks
Implicit Incongruity
Implicit Sentiment Boolean feature indicating phrases extracted from the implicit phrase
Phrases extraction step
Explicit Incongruity
#Explicit incongruity Number of times a word is followed by a word of opposite polarity
Largest positive /negative Length of largest series of words with polarity unchanged
subsequence Number of positive words
#Positive words Number of negative words
#Negative words Polarity of a tweet based on words present
Lexical Polarity
</table>
<tableCaption confidence="0.999391">
Table 1: Features of our sarcasm detection system
</tableCaption>
<bodyText confidence="0.997052666666667">
tions for sarcasm. We randomly select 752
sarcastic and 752 non-sarcastic discussion
forum posts.
To extract the implicit incongruity features, we run
the iterative algorithm described in Section 4.2,
on a dataset of 4000 tweets (50% sarcastic) (also
created using hashtag-based supervision). The al-
gorithm results in a total of 79 verb phrases and
202 noun phrases. We train our classifiers for dif-
ferent feature combinations, using LibSVM with
RBF kernel (Chang and Lin, 2011), and report av-
erage 5-fold cross-validation values.
</bodyText>
<table confidence="0.999863888888889">
Features P R F
Original Algorithm by Riloff et al. (2013)
Ordered 0.774 0.098 0.173
Unordered 0.799 0.337 0.474
Our system
Lexical (Baseline) 0.820 0.867 0.842
Lexical+Implicit 0.822 0.887 0.853
Lexical+Explicit 0.807 0.985 0.8871
All features 0.814 0.976 0.8876
</table>
<tableCaption confidence="0.982362">
Table 2: Comparative results for Tweet-A using
rule-based algorithm and statistical classifiers us-
ing our feature combinations
</tableCaption>
<sectionHeader confidence="0.987034" genericHeader="method">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.86651">
Table 2 shows the performance of our classifiers
in terms of Precision (P), Recall (R) and F-score
</bodyText>
<table confidence="0.9997692">
Features P R F
Lexical (Baseline) 0.645 0.508 0.568
Lexical+Explicit 0.698 0.391 0.488
Lexical+Implicit 0.513 0.762 0.581
All features 0.489 0.924 0.640
</table>
<tableCaption confidence="0.972536">
Table 3: Comparative results for Discussion-A us-
ing our feature combinations
</tableCaption>
<bodyText confidence="0.998022333333334">
(F), for Tweet-A. The table first reports values
from a re-implementation of Riloff et al. (2013)’s
two rule-based algorithms: the ordered version
predicts a tweet as sarcastic if it has a positive
verb phrase followed by a negative situation/noun
phrase, while the unordered does so if the two are
present in any order. We see that all statistical
classifiers surpass the rule-based algorithms. The
best F-score obtained is 0.8876 when all four kinds
of features are used. This is an improvement of
about 5% over the baseline, and 40% over the al-
gorithm by Riloff et al. (2013). Table 3 shows
that even in the case of the Discussion-A dataset,
our features result in an improved performance.
The F-score increases from 0.568 to 0.640, an im-
provement of about 8% in case of discussion fo-
rum posts, when all features are used.
To confirm that we indeed do better, we com-
pare our system, with their reported values. This
is necessary for several reasons. For example,
we reimplement their algorithm but do not have
</bodyText>
<page confidence="0.986392">
760
</page>
<table confidence="0.999801428571429">
Approach P R F
Riloff et al. (2013) 0.62 0.44 0.51
(best reported)
Maynard and Green- 0.46 0.38 0.41
wood (2014)
Our system (all fea- 0.77 0.51 0.61
tures)
</table>
<tableCaption confidence="0.994933">
Table 4: Comparison of our system with two past
works, for Tweet-B
</tableCaption>
<bodyText confidence="0.993966142857143">
access to their exact extracted phrases. Table 4
shows that we achieve a 10% higher F-score
than the best reported F-score of Riloff et al.
(2013). This value is also 20% higher than our
re-implementation of Maynard and Greenwood
(2014) that uses their hashtag retokenizer and rule-
based algorithm.
</bodyText>
<sectionHeader confidence="0.9828955" genericHeader="method">
7 Incorporating inter-sentential
incongruity
</sectionHeader>
<bodyText confidence="0.999987695652174">
Our system performs worse for Discussion-A
than Tweet-A/B possibly because of incongruity
outside the text. Because of the thread struc-
ture of discussion forums, sarcasm in a ‘target
post’ can be identified using the post preceding
it (called ‘elicitor post’), similar to human con-
versation (Eisterhold et al., 2006). For example,
‘Wow, you are smart!’ may or may not be sarcas-
tic. If a sarcasm classifier incorporates informa-
tion from the elicitor post ‘I could not finish my as-
signment’, a correct prediction is possible. Hence,
we now explore how our incongruity-based fea-
tures can help to capture ‘inter-sentential incon-
gruity’. We compute the five explicit incongruity
features for a concatenated version of target post
and elicitor post (elicitor posts are available for
IAC corpus, the source of Discussion-A). The pre-
cision rises to 0.705 but the recall falls to 0.274. A
possible reason is that only 15% posts have elicitor
posts, making the inter-sentential features sparse.
That notwithstanding, our observation shows
that using the inter-sentential context is an in-
teresting direction for sarcasm detection.
</bodyText>
<sectionHeader confidence="0.999438" genericHeader="method">
8 Error Analysis
</sectionHeader>
<bodyText confidence="0.910893260869565">
Some common errors made by our system are:
1. Subjective polarity: The tweet ‘Yay for 3
hour Chem labs’ is tagged by the author as
sarcastic, which may not be common percep-
tion.
2. No incongruity within text: As stated in
Section 2, our system does not detect sar-
casm where incongruity is expressed outside
the text. About 10% misclassified examples
that we analyzed, contained such an incon-
gruity.
3. Incongruity due to numbers: Our system
could not detect incongruity arising due to
numbers as in ‘Going in to work for 2 hours
was totally worth the 35 minute drive.’.
4. Dataset granularity: Some discussion
forum posts are marked as sarcastic,
but contain non-sarcastic portions, lead-
ing to irrelevant features. For example,
‘How special, now all you have to do is prove
that a glob of cells has rights. I happen to
believe that a person’s life and the right to
life begins at conception’.
</bodyText>
<listItem confidence="0.8900215">
5. Politeness: In some cases, implicit incon-
gruity was less evident because of politeness,
as in, ‘Post all your inside jokes on facebook,
I really want to hear about them’.
</listItem>
<sectionHeader confidence="0.87476" genericHeader="conclusions">
9 Conclusion &amp; Future Work
</sectionHeader>
<bodyText confidence="0.99978544">
Our paper uses the linguistic relationship between
context incongruity and sarcasm as a basis for sar-
casm detection. Our sarcasm classifier uses four
kinds of features: lexical, pragmatic, explicit in-
congruity, and implicit incongruity features. We
evaluate our system on two text forms: tweets and
discussion forum posts. We observe an improve-
ment of 40% over a reported rule-based algo-
rithm, and 5% over the statistical classifier base-
line that uses unigrams, in case of tweets. The cor-
responding improvement in case of discussion fo-
rum posts is 8%. Our system also outperforms
two past works (Riloff et al., 2013; Maynard and
Greenwood, 2014) with 10-20% improvement in
F-score. Finally, to improve the performance for
discussion forum posts, we introduce a novel ap-
proach to use elicitor posts for sarcasm detection.
We observe an improvement of 21.6% in preci-
sion, when our incongruity features are used to
capture inter-sentential incongruity.
Our error analysis points to potential future
work such as: (a) role of numbers for sarcasm, and
(b) situations with subjective sentiment. We are
currently exploring a more robust incorporation of
inter-sentential incongruity for sarcasm detection.
</bodyText>
<page confidence="0.995593">
761
</page>
<sectionHeader confidence="0.98579" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999407444444444">
Alias-i. 2008. Lingpipe natural language toolkit.
Francesco Barbieri, Horacio Saggion, and Francesco
Ronzano. 2014. Modelling sarcasm in twitter, a
novel approach. ACL 2014, page 50.
John D Campbell and Albert N Katz. 2012. Are there
necessary conditions for inducing a sense of sarcas-
tic irony? Discourse Processes, 49(6):459–480.
Paula Carvalho, Lu´ıs Sarmento, M´ario J Silva, and
Eug´enio de Oliveira. 2009. Clues for detect-
ing irony in user-generated contents: oh...!! it’s
so easy;-). In Proceedings of the 1st international
CIKM workshop on Topic-sentiment analysis for
mass opinion, pages 53–56. ACM.
Chih-Chung Chang and Chih-Jen Lin. 2011. Lib-
svm: a library for support vector machines. ACM
Transactions on Intelligent Systems and Technology
(TIST), 2(3):27.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Semi-supervised recognition of sarcastic sentences
in twitter and amazon. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning, pages 107–116. Association for
Computational Linguistics.
Jodi Eisterhold, Salvatore Attardo, and Diana Boxer.
2006. Reactions to irony in discourse: Evidence for
the least disruption principle. Journal of Pragmat-
ics, 38(8):1239–1256.
Roberto Gonzalez-Ibanez, Smaranda Muresan, and
Nina Wacholder. 2011. Identifying sarcasm in twit-
ter: a closer look. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies: short
papers-Volume 2, pages 581–586. Association for
Computational Linguistics.
Stacey L Ivanko and Penny M Pexman. 2003. Context
incongruity and irony processing. Discourse Pro-
cesses, 35(3):241–279.
CC Liebrecht, FA Kunneman, and APJ van den Bosch.
2013. The perfect solution for detecting sarcasm in
tweets# not.
Diana Maynard and Mark A Greenwood. 2014. Who
cares about sarcastic tweets? investigating the im-
pact of sarcasm on sentiment analysis. In Proceed-
ings of LREC.
Ankit Ramteke, Pushpak Bhattacharyya, Akshat Malu,
and J Saketha Nath. 2013. Detecting turnarounds
in sentiment analysis: Thwarting. In Proceedings of
ACL.
Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-
dra De Silva, Nathan Gilbert, and Ruihong Huang.
2013. Sarcasm as contrast between a positive senti-
ment and negative situation. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, pages 704–714. Association
for Computational Linguistics.
Joseph Tepperman, David R Traum, and Shrikanth
Narayanan. 2006. yeah right: sarcasm recognition
for spoken dialogue systems. In INTERSPEECH.
Oren Tsur, Dmitry Davidov, and Ari Rappoport.
2010a. Icwsm-a great catchy name: Semi-
supervised recognition of sarcastic sentences in on-
line product reviews. In ICWSM.
Oren Tsur, Dmitry Davidov, and Ari Rappoport.
2010b. Icwsm-a great catchy name: Semi-
supervised recognition of sarcastic sentences in on-
line product reviews. In ICWSM.
Marilyn A Walker, Jean E Fox Tree, Pranav Anand,
Rob Abbott, and Joseph King. 2012. A corpus for
research on deliberation and debate. In LREC, pages
812–817.
Deirdre Wilson. 2006. The pragmatics of verbal irony:
Echo or pretence? Lingua, 116(10):1722–1743.
</reference>
<page confidence="0.996647">
762
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.603243">
<title confidence="0.994421">Harnessing Context Incongruity for Sarcasm Detection</title>
<author confidence="0.811833">Vinita</author>
<affiliation confidence="0.976026">Bombay, India, University, Research Academy,</affiliation>
<email confidence="0.883128">aadi.cse@iitb.ac.in,pb@cse.iitb.ac.in</email>
<abstract confidence="0.991848666666667">The relationship between context incongruity and sarcasm has been studied in linguistics. We present a computational system that harnesses context incongruity as a basis for sarcasm detection. Our statistical sarcasm classifiers incorporate two kinds of incongruity features: explicit and implicit. We show the benefit of our incongruity features for two text forms tweets and discussion forum posts. Our system also outperforms two past works (with Fscore improvement of 10-20%). We also show how our features can capture intersentential incongruity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alias-i</author>
</authors>
<title>Lingpipe natural language toolkit.</title>
<date>2008</date>
<contexts>
<context position="10168" citStr="Alias-i, 2008" startWordPosition="1583" endWordPosition="1584">d ‘hurts’ is incongruous with the positive ‘Yay!’. Hence, our explicit incongruity features are a relevant subset of features from a past system to detect thwarting by Ramteke et al. (2013). These features are: • Number of sentiment incongruities: The number of times a positive word is followed by a negative word, and vice versa • Largest positive/negative subsequence: The length of the longest series of contiguous positive/negative words • Number of positive and negative words • Lexical Polarity: The polarity based purely on the basis of lexical features, as determined by Lingpipe SA system (Alias-i, 2008). Note that the ‘native polarity’ need not be correct. However, a tweet that is strongly positive on the surface is more likely to be sarcastic than a tweet that seems to be negative. This is because sarcasm, by definition, tends to be caustic/hurtful. This also helps against humble bragging. (as in case of the tweet ‘so i have to be up at 5am to autograph 7,000 pics of myself? Sounds like just about the worst Wednesday morning I could ever imagine’). 4.2 Feature Design: Implicit Incongruity We use phrases with implicit sentiment as the implicit incongruity features. These phrases are sentimen</context>
</contexts>
<marker>Alias-i, 2008</marker>
<rawString>Alias-i. 2008. Lingpipe natural language toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesco Barbieri</author>
<author>Horacio Saggion</author>
<author>Francesco Ronzano</author>
</authors>
<title>Modelling sarcasm in twitter, a novel approach. ACL</title>
<date>2014</date>
<pages>50</pages>
<contexts>
<context position="1220" citStr="Barbieri et al., 2014" startWordPosition="174" endWordPosition="177"> text forms - tweets and discussion forum posts. Our system also outperforms two past works (with Fscore improvement of 10-20%). We also show how our features can capture intersentential incongruity. 1 Introduction Sarcasm is defined as ‘a cutting, often ironic remark intended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity, it does so piecemeal; we take a more well-rou</context>
</contexts>
<marker>Barbieri, Saggion, Ronzano, 2014</marker>
<rawString>Francesco Barbieri, Horacio Saggion, and Francesco Ronzano. 2014. Modelling sarcasm in twitter, a novel approach. ACL 2014, page 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Campbell</author>
<author>Albert N Katz</author>
</authors>
<title>Are there necessary conditions for inducing a sense of sarcastic irony?</title>
<date>2012</date>
<booktitle>Discourse Processes,</booktitle>
<volume>49</volume>
<issue>6</issue>
<contexts>
<context position="6324" citStr="Campbell and Katz, 2012" startWordPosition="967" endWordPosition="971">t al. (2013) state that sarcasm is a contrast between positive sentiment word and a negative situation. They implement a rule-based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets. Ramteke et al. (2013) present a novel approach to detect thwarting: the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portions. 3 Context Incongruity Incongruity is defined as ‘the state of being not in agreement, as with principles’1. Context incongruity is a necessary condition for sarcasm (Campbell and Katz, 2012). Ivanko and Pexman (2003) state that the sarcasm processing time (time taken by humans to understand sarcasm) depends on the degree of context incongruity between the statement and the context. Deriving from this idea, we consider two cases of incongruity in sarcasm that are analogous to two degrees of incongruity. We call them explicit incongruity and implicit incongruity, where implicit incongruity demands a higher processing time. It must be noted that our system only handles incongruity between the text and common world knowledge (i.e., the knowledge that ‘being stranded’ is an undesirabl</context>
</contexts>
<marker>Campbell, Katz, 2012</marker>
<rawString>John D Campbell and Albert N Katz. 2012. Are there necessary conditions for inducing a sense of sarcastic irony? Discourse Processes, 49(6):459–480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula Carvalho</author>
<author>Lu´ıs Sarmento</author>
<author>M´ario J Silva</author>
<author>Eug´enio de Oliveira</author>
</authors>
<title>Clues for detecting irony in user-generated contents: oh...!! it’s so easy;-).</title>
<date>2009</date>
<booktitle>In Proceedings of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion,</booktitle>
<pages>53--56</pages>
<publisher>ACM.</publisher>
<marker>Carvalho, Sarmento, Silva, de Oliveira, 2009</marker>
<rawString>Paula Carvalho, Lu´ıs Sarmento, M´ario J Silva, and Eug´enio de Oliveira. 2009. Clues for detecting irony in user-generated contents: oh...!! it’s so easy;-). In Proceedings of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion, pages 53–56. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Libsvm: a library for support vector machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<contexts>
<context position="14058" citStr="Chang and Lin, 2011" startWordPosition="2192" endWordPosition="2195"> negative words #Negative words Polarity of a tweet based on words present Lexical Polarity Table 1: Features of our sarcasm detection system tions for sarcasm. We randomly select 752 sarcastic and 752 non-sarcastic discussion forum posts. To extract the implicit incongruity features, we run the iterative algorithm described in Section 4.2, on a dataset of 4000 tweets (50% sarcastic) (also created using hashtag-based supervision). The algorithm results in a total of 79 verb phrases and 202 noun phrases. We train our classifiers for different feature combinations, using LibSVM with RBF kernel (Chang and Lin, 2011), and report average 5-fold cross-validation values. Features P R F Original Algorithm by Riloff et al. (2013) Ordered 0.774 0.098 0.173 Unordered 0.799 0.337 0.474 Our system Lexical (Baseline) 0.820 0.867 0.842 Lexical+Implicit 0.822 0.887 0.853 Lexical+Explicit 0.807 0.985 0.8871 All features 0.814 0.976 0.8876 Table 2: Comparative results for Tweet-A using rule-based algorithm and statistical classifiers using our feature combinations 6 Evaluation Table 2 shows the performance of our classifiers in terms of Precision (P), Recall (R) and F-score Features P R F Lexical (Baseline) 0.645 0.508</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Semi-supervised recognition of sarcastic sentences in twitter and amazon.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>107--116</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1490" citStr="Davidov et al., 2010" startWordPosition="216" endWordPosition="219">tended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity, it does so piecemeal; we take a more well-rounded view of incongruity and place it center-stage for our work. 1Source: The Free Dictionary The features of our sarcasm detection system are based on two kinds of incongruity: ‘explicit’ and ‘implicit’. The contribution of this paper is: • We present a sarcasm detecti</context>
<context position="4870" citStr="Davidov et al. (2010)" startWordPosition="732" endWordPosition="735">lowing the sarcastic statement. This is particularly true in cases where the incongruity is not expressed within the sarcastic text itself. Computational detection of sarcasm is a relatively recent area of research. Initial work on sarcasm detection investigates the role of lexical and pragmatic features. Tepperman et al. (2006) present sarcasm recognition in speech using prosodic, spectral (average pitch, pitch slope, etc.) and contextual cues (laughter or response to questions). Carvalho et al. (2009) use simple linguistic features like interjection, changed names, etc. for irony detection. Davidov et al. (2010) train a sarcasm classifier with syntactic and pattern-based features. Gonzalez-Ibanez et al. (2011) study the role of unigrams and emoticons in sarcasm detection. Liebrecht et al. (2013) use a dataset of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recent work by ?) takes the output of sarcasm detection as an input to sentiment classification. They present a rule-based system that uses the pattern: if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules.</context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Semi-supervised recognition of sarcastic sentences in twitter and amazon. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 107–116. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jodi Eisterhold</author>
<author>Salvatore Attardo</author>
<author>Diana Boxer</author>
</authors>
<title>Reactions to irony in discourse: Evidence for the least disruption principle.</title>
<date>2006</date>
<journal>Journal of Pragmatics,</journal>
<volume>38</volume>
<issue>8</issue>
<contexts>
<context position="4169" citStr="Eisterhold et al. (2006)" startWordPosition="624" endWordPosition="627"> studied in Ivanko and Pexman (2003). Several properties of sarcasm have also been investigated. Campbell 757 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 757–762, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and Katz (2012) state that sarcasm occurs along different dimensions, namely, failed expectation, pragmatic insincerity, negative tension, presence of a victim and along stylistic components such as emotion words. Eisterhold et al. (2006) observe that sarcasm can be identified based on the statement preceding and following the sarcastic statement. This is particularly true in cases where the incongruity is not expressed within the sarcastic text itself. Computational detection of sarcasm is a relatively recent area of research. Initial work on sarcasm detection investigates the role of lexical and pragmatic features. Tepperman et al. (2006) present sarcasm recognition in speech using prosodic, spectral (average pitch, pitch slope, etc.) and contextual cues (laughter or response to questions). Carvalho et al. (2009) use simple </context>
<context position="16742" citStr="Eisterhold et al., 2006" startWordPosition="2625" endWordPosition="2628">ases. Table 4 shows that we achieve a 10% higher F-score than the best reported F-score of Riloff et al. (2013). This value is also 20% higher than our re-implementation of Maynard and Greenwood (2014) that uses their hashtag retokenizer and rulebased algorithm. 7 Incorporating inter-sentential incongruity Our system performs worse for Discussion-A than Tweet-A/B possibly because of incongruity outside the text. Because of the thread structure of discussion forums, sarcasm in a ‘target post’ can be identified using the post preceding it (called ‘elicitor post’), similar to human conversation (Eisterhold et al., 2006). For example, ‘Wow, you are smart!’ may or may not be sarcastic. If a sarcasm classifier incorporates information from the elicitor post ‘I could not finish my assignment’, a correct prediction is possible. Hence, we now explore how our incongruity-based features can help to capture ‘inter-sentential incongruity’. We compute the five explicit incongruity features for a concatenated version of target post and elicitor post (elicitor posts are available for IAC corpus, the source of Discussion-A). The precision rises to 0.705 but the recall falls to 0.274. A possible reason is that only 15% pos</context>
</contexts>
<marker>Eisterhold, Attardo, Boxer, 2006</marker>
<rawString>Jodi Eisterhold, Salvatore Attardo, and Diana Boxer. 2006. Reactions to irony in discourse: Evidence for the least disruption principle. Journal of Pragmatics, 38(8):1239–1256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Gonzalez-Ibanez</author>
<author>Smaranda Muresan</author>
<author>Nina Wacholder</author>
</authors>
<title>Identifying sarcasm in twitter: a closer look.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2,</booktitle>
<pages>581--586</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1173" citStr="Gonzalez-Ibanez et al., 2011" startWordPosition="166" endWordPosition="169"> show the benefit of our incongruity features for two text forms - tweets and discussion forum posts. Our system also outperforms two past works (with Fscore improvement of 10-20%). We also show how our features can capture intersentential incongruity. 1 Introduction Sarcasm is defined as ‘a cutting, often ironic remark intended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity</context>
<context position="4970" citStr="Gonzalez-Ibanez et al. (2011)" startWordPosition="745" endWordPosition="748">not expressed within the sarcastic text itself. Computational detection of sarcasm is a relatively recent area of research. Initial work on sarcasm detection investigates the role of lexical and pragmatic features. Tepperman et al. (2006) present sarcasm recognition in speech using prosodic, spectral (average pitch, pitch slope, etc.) and contextual cues (laughter or response to questions). Carvalho et al. (2009) use simple linguistic features like interjection, changed names, etc. for irony detection. Davidov et al. (2010) train a sarcasm classifier with syntactic and pattern-based features. Gonzalez-Ibanez et al. (2011) study the role of unigrams and emoticons in sarcasm detection. Liebrecht et al. (2013) use a dataset of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recent work by ?) takes the output of sarcasm detection as an input to sentiment classification. They present a rule-based system that uses the pattern: if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules. Our approach is architecturally similar to Tsur et al. (2010b) who use a semi-supervised pattern ac</context>
<context position="12184" citStr="Gonzalez-Ibanez et al. (2011)" startWordPosition="1910" endWordPosition="1913">in some phrases without implicit sentiment. We hope that the limited size of the tweet guards against such false positives being too many in number. We add phrases in the two sets as count-based implicit incongruity features. 5 Experimental Setup We use three datasets to evaluate our system: 1. Tweet-A (5208 tweets, 4170 sarcastic): We download tweets with hashtags #sarcasm and #sarcastic as sarcastic tweets and #notsarcasm and #notsarcastic as nonsarcastic, using the Twitter API (https:// dev.twitter.com/). A similar hashtagbased approach to create a sarcasm-annotated dataset was employed in Gonzalez-Ibanez et al. (2011). As an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. The hashtags mentioned above are removed from the text so that they act as labels but not as features. 2. Tweet-B (2278 tweets, 506 sarcastic): This dataset was manually labeled for Riloff et al. (2013). Some tweets were unavailable, due to deletion or privacy settings. 3. Discussion-A (1502 discussion forum posts, 752 sarcastic): This dataset is created from the Internet Argument Corpus (Walker et al., 2012) that contains manual annota759 Lexical Unigrams Unigrams in the tr</context>
</contexts>
<marker>Gonzalez-Ibanez, Muresan, Wacholder, 2011</marker>
<rawString>Roberto Gonzalez-Ibanez, Smaranda Muresan, and Nina Wacholder. 2011. Identifying sarcasm in twitter: a closer look. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 581–586. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stacey L Ivanko</author>
<author>Penny M Pexman</author>
</authors>
<title>Context incongruity and irony processing.</title>
<date>2003</date>
<booktitle>Discourse Processes,</booktitle>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="3581" citStr="Ivanko and Pexman (2003)" startWordPosition="545" endWordPosition="548">ongruity is in Section 3.2. We then describe the architecture of our sarcasm detection system in Section 4 and our experimental setup in Section 5. Quantitative evaluation is in Section 6. Inter-sentential sarcasm detection is in Section 7. Section 8 presents the error analysis. Section 9 concludes the paper and points to future directions. 2 Related Work Sarcasm/irony as a linguistic phenomenon has been extensively studied. According to Wilson (2006), sarcasm arises from situational disparity. The relationship between context incongruity and sarcasm processing (by humans) has been studied in Ivanko and Pexman (2003). Several properties of sarcasm have also been investigated. Campbell 757 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 757–762, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and Katz (2012) state that sarcasm occurs along different dimensions, namely, failed expectation, pragmatic insincerity, negative tension, presence of a victim and along stylistic components such as emotion words. Eisterhold et al. (2006) observe tha</context>
<context position="6350" citStr="Ivanko and Pexman (2003)" startWordPosition="972" endWordPosition="975">rcasm is a contrast between positive sentiment word and a negative situation. They implement a rule-based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets. Ramteke et al. (2013) present a novel approach to detect thwarting: the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portions. 3 Context Incongruity Incongruity is defined as ‘the state of being not in agreement, as with principles’1. Context incongruity is a necessary condition for sarcasm (Campbell and Katz, 2012). Ivanko and Pexman (2003) state that the sarcasm processing time (time taken by humans to understand sarcasm) depends on the degree of context incongruity between the statement and the context. Deriving from this idea, we consider two cases of incongruity in sarcasm that are analogous to two degrees of incongruity. We call them explicit incongruity and implicit incongruity, where implicit incongruity demands a higher processing time. It must be noted that our system only handles incongruity between the text and common world knowledge (i.e., the knowledge that ‘being stranded’ is an undesirable situation, and hence, ‘B</context>
</contexts>
<marker>Ivanko, Pexman, 2003</marker>
<rawString>Stacey L Ivanko and Penny M Pexman. 2003. Context incongruity and irony processing. Discourse Processes, 35(3):241–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CC Liebrecht</author>
<author>FA Kunneman</author>
<author>APJ van den Bosch</author>
</authors>
<title>The perfect solution for detecting sarcasm in tweets# not.</title>
<date>2013</date>
<marker>Liebrecht, Kunneman, van den Bosch, 2013</marker>
<rawString>CC Liebrecht, FA Kunneman, and APJ van den Bosch. 2013. The perfect solution for detecting sarcasm in tweets# not.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Maynard</author>
<author>Mark A Greenwood</author>
</authors>
<title>Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="1317" citStr="Maynard and Greenwood, 2014" startWordPosition="187" endWordPosition="191">(with Fscore improvement of 10-20%). We also show how our features can capture intersentential incongruity. 1 Introduction Sarcasm is defined as ‘a cutting, often ironic remark intended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity, it does so piecemeal; we take a more well-rounded view of incongruity and place it center-stage for our work. 1Source: The Free Dictionary The</context>
<context position="16319" citStr="Maynard and Greenwood (2014)" startWordPosition="2563" endWordPosition="2566">eed do better, we compare our system, with their reported values. This is necessary for several reasons. For example, we reimplement their algorithm but do not have 760 Approach P R F Riloff et al. (2013) 0.62 0.44 0.51 (best reported) Maynard and Green- 0.46 0.38 0.41 wood (2014) Our system (all fea- 0.77 0.51 0.61 tures) Table 4: Comparison of our system with two past works, for Tweet-B access to their exact extracted phrases. Table 4 shows that we achieve a 10% higher F-score than the best reported F-score of Riloff et al. (2013). This value is also 20% higher than our re-implementation of Maynard and Greenwood (2014) that uses their hashtag retokenizer and rulebased algorithm. 7 Incorporating inter-sentential incongruity Our system performs worse for Discussion-A than Tweet-A/B possibly because of incongruity outside the text. Because of the thread structure of discussion forums, sarcasm in a ‘target post’ can be identified using the post preceding it (called ‘elicitor post’), similar to human conversation (Eisterhold et al., 2006). For example, ‘Wow, you are smart!’ may or may not be sarcastic. If a sarcasm classifier incorporates information from the elicitor post ‘I could not finish my assignment’, a c</context>
</contexts>
<marker>Maynard, Greenwood, 2014</marker>
<rawString>Diana Maynard and Mark A Greenwood. 2014. Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ankit Ramteke</author>
<author>Pushpak Bhattacharyya</author>
<author>Akshat Malu</author>
<author>J Saketha Nath</author>
</authors>
<title>Detecting turnarounds in sentiment analysis: Thwarting.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5690" citStr="Ramteke et al. (2013)" startWordPosition="865" endWordPosition="868">et of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recent work by ?) takes the output of sarcasm detection as an input to sentiment classification. They present a rule-based system that uses the pattern: if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules. Our approach is architecturally similar to Tsur et al. (2010b) who use a semi-supervised pattern acquisition followed by classification. Our feature engineering is based on Riloff et al. (2013) and Ramteke et al. (2013). Riloff et al. (2013) state that sarcasm is a contrast between positive sentiment word and a negative situation. They implement a rule-based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets. Ramteke et al. (2013) present a novel approach to detect thwarting: the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portions. 3 Context Incongruity Incongruity is defined as ‘the state of being not in agreement, as with principles’1. Context incongruity is a necessary condition for</context>
<context position="9743" citStr="Ramteke et al. (2013)" startWordPosition="1514" endWordPosition="1517"> An explicit incongruity giving rise to sarcasm bears resemblance to thwarted expectations (another commonly known challenge to sentiment analysis). Consider this example: ‘I love the color. The features are interesting. But a bad battery life ruins it’. The positive expectation in the first two sentences is thwarted by the last sentence. A similar incongruity is observed in the sarcastic ‘My tooth hurts! Yay!’. The negative word ‘hurts’ is incongruous with the positive ‘Yay!’. Hence, our explicit incongruity features are a relevant subset of features from a past system to detect thwarting by Ramteke et al. (2013). These features are: • Number of sentiment incongruities: The number of times a positive word is followed by a negative word, and vice versa • Largest positive/negative subsequence: The length of the longest series of contiguous positive/negative words • Number of positive and negative words • Lexical Polarity: The polarity based purely on the basis of lexical features, as determined by Lingpipe SA system (Alias-i, 2008). Note that the ‘native polarity’ need not be correct. However, a tweet that is strongly positive on the surface is more likely to be sarcastic than a tweet that seems to be n</context>
</contexts>
<marker>Ramteke, Bhattacharyya, Malu, Nath, 2013</marker>
<rawString>Ankit Ramteke, Pushpak Bhattacharyya, Akshat Malu, and J Saketha Nath. 2013. Detecting turnarounds in sentiment analysis: Thwarting. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Ashequl Qadir</author>
<author>Prafulla Surve</author>
<author>Lalindra De Silva</author>
<author>Nathan Gilbert</author>
<author>Ruihong Huang</author>
</authors>
<title>Sarcasm as contrast between a positive sentiment and negative situation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>704--714</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Riloff, Qadir, Surve, De Silva, Gilbert, Huang, 2013</marker>
<rawString>Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Ruihong Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 704–714. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Tepperman</author>
<author>David R Traum</author>
<author>Shrikanth Narayanan</author>
</authors>
<title>yeah right: sarcasm recognition for spoken dialogue systems.</title>
<date>2006</date>
<booktitle>In INTERSPEECH.</booktitle>
<contexts>
<context position="4579" citStr="Tepperman et al. (2006)" startWordPosition="689" endWordPosition="692">t sarcasm occurs along different dimensions, namely, failed expectation, pragmatic insincerity, negative tension, presence of a victim and along stylistic components such as emotion words. Eisterhold et al. (2006) observe that sarcasm can be identified based on the statement preceding and following the sarcastic statement. This is particularly true in cases where the incongruity is not expressed within the sarcastic text itself. Computational detection of sarcasm is a relatively recent area of research. Initial work on sarcasm detection investigates the role of lexical and pragmatic features. Tepperman et al. (2006) present sarcasm recognition in speech using prosodic, spectral (average pitch, pitch slope, etc.) and contextual cues (laughter or response to questions). Carvalho et al. (2009) use simple linguistic features like interjection, changed names, etc. for irony detection. Davidov et al. (2010) train a sarcasm classifier with syntactic and pattern-based features. Gonzalez-Ibanez et al. (2011) study the role of unigrams and emoticons in sarcasm detection. Liebrecht et al. (2013) use a dataset of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recen</context>
</contexts>
<marker>Tepperman, Traum, Narayanan, 2006</marker>
<rawString>Joseph Tepperman, David R Traum, and Shrikanth Narayanan. 2006. yeah right: sarcasm recognition for spoken dialogue systems. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Tsur</author>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Icwsm-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews.</title>
<date>2010</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1466" citStr="Tsur et al., 2010" startWordPosition="212" endWordPosition="215">ten ironic remark intended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity, it does so piecemeal; we take a more well-rounded view of incongruity and place it center-stage for our work. 1Source: The Free Dictionary The features of our sarcasm detection system are based on two kinds of incongruity: ‘explicit’ and ‘implicit’. The contribution of this paper is: • We p</context>
<context position="5531" citStr="Tsur et al. (2010" startWordPosition="841" endWordPosition="844">nd pattern-based features. Gonzalez-Ibanez et al. (2011) study the role of unigrams and emoticons in sarcasm detection. Liebrecht et al. (2013) use a dataset of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recent work by ?) takes the output of sarcasm detection as an input to sentiment classification. They present a rule-based system that uses the pattern: if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules. Our approach is architecturally similar to Tsur et al. (2010b) who use a semi-supervised pattern acquisition followed by classification. Our feature engineering is based on Riloff et al. (2013) and Ramteke et al. (2013). Riloff et al. (2013) state that sarcasm is a contrast between positive sentiment word and a negative situation. They implement a rule-based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets. Ramteke et al. (2013) present a novel approach to detect thwarting: the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portion</context>
</contexts>
<marker>Tsur, Davidov, Rappoport, 2010</marker>
<rawString>Oren Tsur, Dmitry Davidov, and Ari Rappoport. 2010a. Icwsm-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Tsur</author>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Icwsm-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews.</title>
<date>2010</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1466" citStr="Tsur et al., 2010" startWordPosition="212" endWordPosition="215">ten ironic remark intended to express contempt or ridicule’1. Sarcasm detection is the task of predicting a text as sarcastic or non-sarcastic. The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014), (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013), a positive verb being followed by a negative situation (Riloff et al., 2013), or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010). Thus, the past work detects sarcasm with specific indicators. However, we believe that it is time that sarcasm detection is based on well-studied linguistic theories. In this paper, we use one such linguistic theory: context incongruity. Although the past work exploits incongruity, it does so piecemeal; we take a more well-rounded view of incongruity and place it center-stage for our work. 1Source: The Free Dictionary The features of our sarcasm detection system are based on two kinds of incongruity: ‘explicit’ and ‘implicit’. The contribution of this paper is: • We p</context>
<context position="5531" citStr="Tsur et al. (2010" startWordPosition="841" endWordPosition="844">nd pattern-based features. Gonzalez-Ibanez et al. (2011) study the role of unigrams and emoticons in sarcasm detection. Liebrecht et al. (2013) use a dataset of Dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm. A recent work by ?) takes the output of sarcasm detection as an input to sentiment classification. They present a rule-based system that uses the pattern: if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules. Our approach is architecturally similar to Tsur et al. (2010b) who use a semi-supervised pattern acquisition followed by classification. Our feature engineering is based on Riloff et al. (2013) and Ramteke et al. (2013). Riloff et al. (2013) state that sarcasm is a contrast between positive sentiment word and a negative situation. They implement a rule-based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets. Ramteke et al. (2013) present a novel approach to detect thwarting: the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portion</context>
</contexts>
<marker>Tsur, Davidov, Rappoport, 2010</marker>
<rawString>Oren Tsur, Dmitry Davidov, and Ari Rappoport. 2010b. Icwsm-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Jean E Fox Tree</author>
<author>Pranav Anand</author>
<author>Rob Abbott</author>
<author>Joseph King</author>
</authors>
<title>A corpus for research on deliberation and debate.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>812--817</pages>
<contexts>
<context position="12717" citStr="Walker et al., 2012" startWordPosition="1998" endWordPosition="2001">ach to create a sarcasm-annotated dataset was employed in Gonzalez-Ibanez et al. (2011). As an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. The hashtags mentioned above are removed from the text so that they act as labels but not as features. 2. Tweet-B (2278 tweets, 506 sarcastic): This dataset was manually labeled for Riloff et al. (2013). Some tweets were unavailable, due to deletion or privacy settings. 3. Discussion-A (1502 discussion forum posts, 752 sarcastic): This dataset is created from the Internet Argument Corpus (Walker et al., 2012) that contains manual annota759 Lexical Unigrams Unigrams in the training corpus Pragmatic Capitalization Numeric feature indicating presence of capital letters Emoticons &amp; laughter ex- Numeric feature indicating presence of emoticons and ‘lol’s pressions Numeric feature indicating presence of punctuation marks Punctuation marks Implicit Incongruity Implicit Sentiment Boolean feature indicating phrases extracted from the implicit phrase Phrases extraction step Explicit Incongruity #Explicit incongruity Number of times a word is followed by a word of opposite polarity Largest positive /negative</context>
</contexts>
<marker>Walker, Tree, Anand, Abbott, King, 2012</marker>
<rawString>Marilyn A Walker, Jean E Fox Tree, Pranav Anand, Rob Abbott, and Joseph King. 2012. A corpus for research on deliberation and debate. In LREC, pages 812–817.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deirdre Wilson</author>
</authors>
<title>The pragmatics of verbal irony: Echo or pretence?</title>
<date>2006</date>
<journal>Lingua,</journal>
<volume>116</volume>
<issue>10</issue>
<contexts>
<context position="3412" citStr="Wilson (2006)" startWordPosition="524" endWordPosition="525">rk in Section 2. We introduce context incongruity in Section 3. Feature design for explicit incongruity is presented in Section 3.1, and that for implicit incongruity is in Section 3.2. We then describe the architecture of our sarcasm detection system in Section 4 and our experimental setup in Section 5. Quantitative evaluation is in Section 6. Inter-sentential sarcasm detection is in Section 7. Section 8 presents the error analysis. Section 9 concludes the paper and points to future directions. 2 Related Work Sarcasm/irony as a linguistic phenomenon has been extensively studied. According to Wilson (2006), sarcasm arises from situational disparity. The relationship between context incongruity and sarcasm processing (by humans) has been studied in Ivanko and Pexman (2003). Several properties of sarcasm have also been investigated. Campbell 757 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 757–762, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and Katz (2012) state that sarcasm occurs along different dimensions, namely, fai</context>
</contexts>
<marker>Wilson, 2006</marker>
<rawString>Deirdre Wilson. 2006. The pragmatics of verbal irony: Echo or pretence? Lingua, 116(10):1722–1743.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>