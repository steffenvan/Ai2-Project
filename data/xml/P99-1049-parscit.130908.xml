<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.998438">
An Efficient Statistical Speech Act Type Tagging System for
Speech Translation Systems
</title>
<author confidence="0.760906">
Hideki Tanaka and Akio Yokoo
</author>
<affiliation confidence="0.682721">
ATR Interpreting Telecommunications Research Laboratories
</affiliation>
<address confidence="0.93862">
2-2, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan
</address>
<email confidence="0.95343">
ftanakahlayokoolOitl.atr.co.jp
</email>
<sectionHeader confidence="0.993488" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999131875">
This paper describes a new efficient speech
act type tagging system. This system cov-
ers the tasks of (1) segmenting a turn into
the optimal number of speech act units
(SA units), and (2) assigning a speech act
type tag (SA tag) to each SA unit. Our
method is based on a theoretically clear
statistical model that integrates linguistic,
acoustic and situational information. We
report tagging experiments on Japanese
and English dialogue corpora manually la-
beled with SA tags. We then discuss the
performance difference between the two
languages. We also report on some trans-
lation experiments on positive response
expressions using SA tags.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969290322581">
This paper describes a statistical speech act type
tagging system that utilizes linguistic, acoustic and
situational features. This work can be viewed as a
study on automatic &amp;quot;Discourse Tagging&amp;quot; whose ob-
jective is to assign tags to discourse units in texts or
dialogues. Discourse tagging is studied mainly from
two different viewpoints, i.e., linguistic and engineer-
ing viewpoints. The work described here belongs to
the latter group. More specifically, we are interested
in automatically recognizing the speech act types of
utterances and in applying them to speech transla-
tion systems.
Several studies on discourse tagging to date have
been motivated by engineering applications. The
early studies by Nagata and Morimoto (1994) and
Reithinger and Maier (1995) showed the possibility
of predicting dialogue act tags for next utterances
with statistical methods. These studies, however,
presupposed properly segmented utterances, which
is not a realistic assumption. In contrast to this
assumption, automatic utterance segmentation (or
discourse segmentation) is desired here.
Discourse segmentation in linguistics, whether
manual or automatic, has also received keen atten-
tion because such segmentation provides the founda-
tion of higher discourse structures (Grosz and Sid-
ner, 1986).
Discourse segmentation has also received keen at-
tention from the engineering side because the nat-
ural language processing systems that follow the
speech recognition system are designed to accept lin-
guistically meaningful units (Stolcke and Shriberg,
1996). There has been a lot of research following
this line such as (Stolcke and Shriberg, 1996) (Cet-
tolo and Falavigna, 1998), to only mention a few.
We can take advantage of these studies as a pre—
process for tagging. In this paper, however, we pro-
pose a statistical tagging system that optimally per-
forms segmentation and tagging at the same time.
Previous studies like (Litman and Passonneau, 1995)
have pointed out that the use of a multiple informa-
tion source can contribute to better segmentation
and tagging, and so our statistical model integrates
linguistic, acoustic and situational information.
The problem can be formalized as a search prob-
lem on a word graph, which can be efficiently han-
dled by an extended dynamic programming algo-
rithm. Actually, we can efficiently find the optimal
solution without limiting the search space at all.
The results of our tagging experiments involving
both Japanese and English corpora indicated a high
performance for Japanese but a considerably lower
performance for the English corpora. This work
also reports on the use of speech act type tags for
translating Japanese and English positive response
expressions. Positive responses quite often appear
in task—oriented dialogues like those in our tasks.
They are often highly ambiguous and problematic
in speech translation. We will show that these ex-
pressions can be effectively translated with the help
of dialogue information, which we call speech act
type tags.
</bodyText>
<sectionHeader confidence="0.993416" genericHeader="introduction">
2 The Problems
</sectionHeader>
<bodyText confidence="0.999279333333333">
In this section, we briefly explain our speech act type
tags and the tagged data and then formally define
the tagging problem.
</bodyText>
<page confidence="0.995269">
381
</page>
<subsectionHeader confidence="0.600574">
2.1 Data and Tags
</subsectionHeader>
<bodyText confidence="0.975711469387755">
The data used in this study is a collection of tran-
scribed dialogues on a travel arrangement task be-
tween Japanese and English speakers mediated by
interpreters (Morimoto et al., 1994). The tran-
scriptions were separated by language, i.e., En-
glish and Japanese, and the resultant two corpora
share the same content. Both transcriptions went
through morphological analysis, which was manually
checked. The transcriptions have clear turn bound-
aries (TB&apos;s).
Some of the Japanese and English dialogue files
were manually segmented into speech act units (SA
units) and assigned with speech act type tags (SA
tags). The SA tags represent a speaker&apos;s intention
in an utterance, and is more or less similar to the
traditional illocutionary force type (Searle, 1969).
The SA tags for the Japanese language were based
on the set proposed by Seligman et al. (1994) and
had 29 types. The English SA tags were based on
the Japanese tags, but we redesigned and reduced
the size to 17 types. We believed that an excessively
detailed tag classification would decrease the inter-
coder reliability and so pruned some detailed tags.&apos;
The following lines show an example of the English
tagged dialogues. Two turns uttered by a hotel clerk
and a customer were segmented into SA units and
assigned with SA tags.
&lt;clerk&apos;s turn&gt;
Hello, (expressive)
New York City Hotel, (inform)
may I help you? (offer)
&lt;customer(interpreter) &apos;s turn&gt;
Hello, (expressive)
my name is Hiroko Tanaka (inform)
and I would like to make a reservation for
a room at your hotel. (desire)
The tagging work to the dialogue was conducted
by experts who studied the tagging manual before-
hand. The manual described the tag definitions
and turn segmentation strategies and gave examples.
The work involved three experts for the Japanese
corpus and two experts for the English corpus.2
The result was checked and corrected by one ex-
pert for each language. Therefore, since the work
was done by one expert, the inter-coder tagging in-
stability was suppressed to a minimum. As the re-
sult of the tagging, we obtained 95 common dialogue
files with SA tags for Japanese and English and used
them in our experiments.
</bodyText>
<footnote confidence="0.9965075">
1 Japanese tags, for example, had four tags mainly
used for dialogue endings: thank, offer-follow-up, good-
wishes, and farewell, most of which were reduced to ex-
pressive in English.
2They did not listen to the recorded sounds in either
case.
</footnote>
<subsectionHeader confidence="0.981109">
2.2 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.9997575">
Our tagging system assumes an input of a word se-
quence for a dialogue produced by a speech recog-
nition system. The word sequence is accompanied
with clear turn boundaries. Here, the words do not
contain any punctuation marks. The word sequence
can be viewed as a sequence of quadruples:
</bodyText>
<listItem confidence="0.835762">
• • (wi-1,/i-i,ai--1,si-i),(tvi,Ii,ahsi)• • •
</listItem>
<bodyText confidence="0.992959285714285">
where wi represents a surface wordform, and each
vector represents the following additional informa-
tion for wi.
canonical form and part of speech of
wi (linguistic feature)
ai: pause duration measured milliseconds
after wi (acoustic feature)
si: speaker&apos;s identification for wi such as
clerk or customer (situational feature)
Therefore, an utterance like Hello I am John Phillips
and ... uttered by a customer is viewed as a sequence
like
(Hello, (hello, INTER), 100, customer),
(1,(i, PRON),O, customer)), (am, (be,
BE), 0, customer) ....
From here, we will denote a word sequence as W =
wi,w2, wi, ,wn for simplicity. However, note
that W is a sequence of quadruples as described
above.
The task of speech act type tagging in this pa-
per covers two tasks: (1) segmentation of a word
sequence into the optimal number of SA units, and
(2) assignment of an SA tag to each SA unit. Here,
the input is a word sequence with clear TB&apos;s, and
our tagger takes each turn as a process unit. 3
In this paper, an SA unit is denoted as u and the
sequence is denoted as U. An SA tag is denoted as
t and the sequence is denoted as T. x: represents
a sequence of x starting from s to e. Therefore, PI
represents a tag sequence from 1 to j.
The task is now formally addressed as follows:
find the best SA unit sequence U and tag sequence
T for each turn when a word sequence W with clear
TB&apos;s is given. We will treat this problem with the
statistical model described in the next section.
</bodyText>
<sectionHeader confidence="0.999194" genericHeader="method">
3 Statistical Model
</sectionHeader>
<bodyText confidence="0.999861">
The problem addressed in Section 2 can be formal-
ized as a search problem in a word graph that holds
all possible combinations of SA units in a turn. We
take a probabilistic approach to this problem, which
formalizes it as finding a path (i.7, i&apos;) in the word
graph that maximizes the probability P(U,T IW).
</bodyText>
<footnote confidence="0.955267">
&apos;Although we do not explicitly represent TB&apos;s in a
word sequence in the following discussions, one might
assume virtual TB markers like © in the word sequence.
</footnote>
<page confidence="0.998151">
382
</page>
<bodyText confidence="0.9965476">
This is formally represented in equation (1). This
probability is naturally decomposed into the prod-
uct of two terms as in equation (3). The first prob-
ability in equation (3) represents an arbitrary word
sequence constituting one SA unit uj , given hi (the
history of SA units and. tags from the beginning of
a dialogue, hi = tii-1) and input W. The sec-
ond probability represents the current SA unit ui
bearing a particular SA tag ti, given uj, hi, and
W.
</bodyText>
<equation confidence="0.944838285714286">
argmax P(U, T 1W), (1)
U,T
argmax H p(,,t; I hi, w), (2)
U,T j =1
argmax 11 p(i; h3, W)
U,T j.i
x P(ti 1 uj , hi ,W).
</equation>
<bodyText confidence="0.999994272727273">
We call the first term &amp;quot;unit existence probability&amp;quot;
PE and the second term &amp;quot;tagging probability&amp;quot; PT.
Figure 1 shows a simplified image of the probability
calculation in a word graph, where we have finished
processing the word sequence of wis-1.
Now, we estimate the probability for the word se-
quence ws8+P-1 constituting an SA unit uj and hav-
ing a particular SA tag tj. Because of the problem of
sparse data, these probabilities are hard to directly
estimate from the training corpus. We will use the
following approximation techniques.
</bodyText>
<subsectionHeader confidence="0.993029">
3.1 Unit Existence Probability
</subsectionHeader>
<bodyText confidence="0.9991826">
The probability of unit existence PE is actually
equivalent to the probability that the word sequence
w3, , w7,_1 exists as one SA unit given hi and
W (Fig. 1).
We then approximate PE by
</bodyText>
<equation confidence="0.9912056">
PE P(B„,,_i,„. = 11 hi ,W)
= 1 I hi, W)
s+p-2
x H P(Bwm,„,m+, = 0 I hj, W), (4)
771=S
</equation>
<bodyText confidence="0.989723">
where the random variable B.,„„„,..„, takes the bi-
nary values 1 and 0. A value of 1 corresponds to the
existence of an SA unit boundary between wx and
wx+1, and a value of 0 to the non—existence of an SA
unit boundary. PE is approximated by the product
of two types of probabilities: for a word sequence
break at both ends of an SA unit and for a non—
break inside the unit. Notice that the probabilities
of the former type adjust an unfairly high probabil-
ity estimation for an SA unit that is made from a
short word sequence.
The estimation of PE is now reduced to that of
P(B„,„+, I hi ,W). This probability is estimated
by a probabilistic decision tree and we have
</bodyText>
<equation confidence="0.921277">
P(B„,,r,„„+1 I h2,W) P(B„.,tur+, I (DE(h),W)),
</equation>
<bodyText confidence="0.99998895">
where &apos;TE is a decision tree that categorizes ii,, W
into equivalent classes (Jelinek, 1997). We modi-
fied C4.5 (Quinlan, 1993) style algorithm to produce
probability and used it for this purpose. The deci-
sion tree is known to be effective for the data sparse-
ness problem and can take different types of parame-
ters such as discrete and continuous values, which is
useful since our word sequence contains both types
of features.
Through preliminary experiments, we found that
hi (the past history of tagging results) was not useful
and discarded it. We also found that the probability
was well estimated by the information available in a
short range of r around wr, which is stored in W.
Actually, the attributes used to develop the tree were
in W&apos; = 4+41: surface wordforms for
parts of speech for wf+,..44, and the pause duration
between wx and wx+1. The word range r was set
from 1 to 3 as we will report in sub—section 5.3.
As a result, we obtained the final form of PE as
</bodyText>
<equation confidence="0.9874508">
PE P(B„,,_1011, = 11 (1)E(W1))
x = 1 I 4:1)E(Wi))
s+p-2
X H P(B„„,,„m+, = 0 I (1)E(W1))(5)
771=3
</equation>
<subsectionHeader confidence="0.98946">
3.2 Tagging Probability
</subsectionHeader>
<bodyText confidence="0.9999875">
The tagging probability PT was estimated by the
following formula utilizing a decision tree (I)T. Two
functions named f and g were also utilized to extract
information from the word sequence in ui
</bodyText>
<equation confidence="0.582793">
PT P(ii I(DT(Auj), ,ti_m)) (6)
</equation>
<bodyText confidence="0.999992833333333">
As this formula indicates, we only used information
available with the ui and m histories of SA tags in
hi. The function f(uj) outputs the speaker&apos;s identi-
fication of uj. The function g(u2) extracts cue words
for the SA tags from uj using a cue word list. The
cue word list was extracted from a training corpus
that was manually labeled with the SA tags. For
each SA tag, the 10 most dependent words were ex-
tracted with a x2—test. After converting these into
canonical forms, they were conjoined.
To develop a statistical decision tree, we used an
input table whose attributes consisted of a cue word
list, a speaker&apos;s identification, and in previous tags.
The value for each cue word was a binary value,
where 1 was set when the utterance uj contained
the word, or otherwise 0. The effect of f(u), g(ui),
and length in for the tagging performance will be
reported in sub—section 5.3.
</bodyText>
<sectionHeader confidence="0.972507" genericHeader="method">
4 Search Method
</sectionHeader>
<bodyText confidence="0.99778">
A search in a word graph was conducted using the
extended dynamic programming technique proposed
</bodyText>
<figure confidence="0.796059625">
(3)
383
turn boundary current process front
hi history
-1111
ui_i, tj_/ ui,
CD - - - - - 0-CD Ca - - - - CD CD- - - -
WI ws-/ W. ws+] ws+p-1 ws+p wn
</figure>
<figureCaption confidence="0.922555">
W word sequence for a dialogue
Figure 1: Probability calculation.
</figureCaption>
<bodyText confidence="0.999809523809524">
by Nagata (1994). This algorithm was originally de-
veloped for a statistical Japanese morphological an-
alyzer whose tasks are to determine boundaries in an
input character sequence having no separators and
to give an appropriate part of speech tag to each
word, i.e., a character sequence unit. This algorithm
can handle arbitrary lengths of histories of pos tags
and words and efficiently produce n—best results.
We can see a high similarity between our task and
Japanese morphological analysis. Our task requires
the segmentation of a word sequence instead of a
character sequence and the assignment of an SA tag
instead of a pos tag.
The main difference is that a word dictionary is
available with a morphological analyzer. Thanks to
its dictionary, a morphological analyzer can assume
possible morpheme boundaries. Our tagger, on
the other hand, has to assume that any word se-
quence in a turn can constitute an SA unit in the
search. This difference, however, does not require
any essential change in the search algorithm.
</bodyText>
<sectionHeader confidence="0.990657" genericHeader="method">
5 Tagging Experiments
</sectionHeader>
<subsectionHeader confidence="0.981696">
5.1 Data Profile
</subsectionHeader>
<bodyText confidence="0.936711176470588">
We have conducted several tagging experiments on
both the Japanese and English corpora described in
sub—section 2.1. Table 1 shows a summary of the
95 files used in the experiments. In the experiments
described below, we used morpheme sequences for
input instead of word sequences and showed the cor-
responding counts.
The average number of SA units per turn was
2.68 for Japanese and 2.31 for English. The aver-
age number of boundary candidates per turn was
18 for Japanese and 12.7 for English. The number
of tag types, the average number of SA units, and
the average number of SA boundary candidates in-
dicated that the Japanese data were more difficult
to process.
4Also, the probability for the existence of a word can
be directly estimated from the corpus.
</bodyText>
<tableCaption confidence="0.999671">
Table 1: Counts in both corpora.
</tableCaption>
<table confidence="0.931788333333333">
Japanese English
2,020 2,020
5,416 4,675
38,418 27,639
30 33
29 17
</table>
<subsectionHeader confidence="0.852494">
5.2 Evaluation Methods
</subsectionHeader>
<bodyText confidence="0.999895307692308">
We used &amp;quot;labeled bracket matching&amp;quot; for evalua-
tion (Nagata, 1994). The result of tagging can be
viewed as a set of labeled brackets, where brack-
ets correspond to turn segmentation and their labels
correspond to SA tags. With this in mind, the eval-
uation was done in the following way. We counted
the number of brackets in the correct answer, de-
noted as R (reference). We also counted the num-
ber of brackets in the tagger&apos;s output, denoted as
S (system). Then the number of matching brackets
was counted and denoted as M (match). Thus, we
could define the precision rate with MIS and the
recall rate with MIR.
The matching was judged in two ways. One was
&amp;quot;segmentation match&amp;quot;: the positions of both start-
ing and ending brackets (boundaries) were equal.
The other was &amp;quot;segmentation+tagging match&amp;quot;: the
tags of both brackets were equal in addition to the
segmentation match.
The proposed evaluation simultaneously con-
firmed both the starting and ending positions of an
SA unit and was more severe than methods that only
evaluate one side of the boundary of an SA unit.
Notice that the precision and recall for the segmen-
tation+tagging match is bounded by those of the
segmentation match.
</bodyText>
<subsectionHeader confidence="0.998645">
5.3 Tagging Results
</subsectionHeader>
<bodyText confidence="0.999473">
The total tagging performance is affected by the two
probability terms PE and PT both of which contain
the parameters in Table 2. To find the best param-
</bodyText>
<figure confidence="0.983514">
Counts
Turn
SA unit
Morpheme
POS types
SA tag type
</figure>
<page confidence="0.991839">
384
</page>
<tableCaption confidence="0.999424">
Table 2: Parameters in probability terms. Table 4: T-scores for segmentation accuracies.
</tableCaption>
<table confidence="0.998976">
Recall Precision
A B C A B C
B 2.84 - - B 1.25 - -
C 2.71 0.12 - C 0.83 0.44 -
D 2.57 0.28 0.17 D 0.74 0.39 0.01
PE PT
r +1 f (ui): speaker of ui
r: word range cue words in ui
previous SA tags
</table>
<tableCaption confidence="0.999987">
Table 3: Average accuracy for segmentation match.
Table 5: Average accuracy for seg.d-tag. match.
</tableCaption>
<table confidence="0.793795">
Parameter Recall rate % Precision rate %
72.25 72.70
74.91 75.35
74.83 75.29
74.50 74.96
Parameter Recall rate % Precision rate %
A 89.50 91.99
91.89 92.92
92.00 92.57
92.20 92.58
</table>
<bodyText confidence="0.994656636363636">
eter set and see the effect of each parameter, we
conducted the following two types of experiments.
I Change the parameters for PE with fixed pa-
rameters for PT
The effect of the parameters in PE was mea-
sured by the segmentation match.
II Change the parameters for PT with fixed pa-
rameters for PE
The effect of the parameters in PT was mea-
sured by the segmentation+tagging match.
Now, we report the details with the Japanese set.
</bodyText>
<subsubsectionHeader confidence="0.453896">
5.3.1 Effects of PE with Japanese Data
</subsubsectionHeader>
<bodyText confidence="0.960546909090909">
We fixed the parameters for PT as f(u), g(uj),
i.e., a speaker&apos;s identification, cue words in the
current SA unit, and the SA tag of the previous SA
unit. The unit existence probability was estimated
using the following parameters.
(A): Surface wordforms and pos&apos;s of wf +1, i.e., word
range r = 1
(B): Surface wordforms and pos&apos;s of wf+?, i.e., word
range r = 2
(C): (A) with a pause duration between wx, wx+1
(D): (B) with a pause duration between wx, wx4.1
Under the above conditions, we conducted 10-fold
cross-validation tests and measured the average re-
call and precision rates in the segmentation match,
which are listed in Table 3.
We then conducted t-tests among these average
scores. Table 4 shows the 1-scores between different
parameter conditions. In the following discussions,
we will use the following 1-scores: ta=0 025(18) =
2.10 and ta.o 05(18) = 1.73.
We can note the following features from Tables 3
and 4.
</bodyText>
<listItem confidence="0.840866">
• recall rate
</listItem>
<bodyText confidence="0.9739354">
(B), (C), and (D) showed statistically signif-
icant (two-sided significance level of 5%, i.e.,
t &gt; 2.10) improvement from (A). (D) did not
show significant improvement from either (B)
nor (C).
</bodyText>
<listItem confidence="0.81095">
• precision rate
</listItem>
<bodyText confidence="0.92605775">
Although (B) and (C) did not improve from
(A) with a high statistical significance, we can
observe the tendency of improvement. (D) did
not show a significant difference from (B) or
(C).
We can, therefore, say that (B) and (C) showed
equally significant improvement from (A): expansion
of the word range r from 1 to 2 and using pause infor-
mation with word range 1. The combination of word
range 2 and pause (D), however, did not show any
significant differences from (B) or (C). We believe
that the combination resulted in data sparseness.
</bodyText>
<subsubsectionHeader confidence="0.713728">
5.3.2 Effects of PT with Japanese Data
</subsubsectionHeader>
<bodyText confidence="0.945020166666667">
For the Type II experiments, we set the parame-
ters for PE as condition (C): surface wordforms and
pos&apos;s of w,x+1 and a pause duration between wx and
wx+1. Then, PT was estimated using the following
parameters.
(E): Cue words in utterance uj, i.e., g(u3)
</bodyText>
<equation confidence="0.862663333333333">
(F): (E) with tj_i
(G): (E) with ti_j and 13_2
(H): (E) with ti_i and a speaker&apos;s identification
</equation>
<bodyText confidence="0.995403833333333">
The recall and precision rates for the segmenta-
tion+tagging match were evaluated in the same way
as in the previous experiments. The results are
shown in Table 5. The 1-scores among these param-
eter setting are shown in Table 6. We can observe
the following features.
</bodyText>
<listItem confidence="0.763464333333333">
• recall rate
(F) and (G) showed an improvement from (E)
with a two-sided significance level of 10% (1&gt;
</listItem>
<page confidence="0.99916">
385
</page>
<tableCaption confidence="0.829534">
Table 6: T-scores for seg.+tag. accuracies.
</tableCaption>
<table confidence="0.9974954">
Recall Precision
E F G E F G
F 1.87 - - F 1.97 - -
G 1.78 0.05 - G 1.90 0.04 -
H 1.50 0.26 0.21 II 1.60 0.28 0.24
</table>
<bodyText confidence="0.849624368421053">
1.73). However, (G) and (H) did not show sig-
nificant improvements from (F).
• precision rate
Same as recall rate.
Here, we can say that i2 together with the cue
words (F) played the dominant role in the SA tag
assignment, and the further addition of history ti -2
(G) or the speaker&apos;s identification 100 (H) did not
result in significant improvements.
5.3.3 Summary of Japanese Tagging
Experiments
As a concise summary, the best recall and preci-
sion rates for the segmentation match were obtained
with conditions (B) and (C): approximately 92%
and 93%, respectively. The best recall and preci-
sion rates for the segmentation+tagging match were
74.91% and 75.35 %, respectively (Table 5 (F)). We
consider these figures quite satisfactory considering
the severeness of our evaluation scheme.
</bodyText>
<subsubsectionHeader confidence="0.791018">
5.3.4 English Tagging Experiment
</subsubsectionHeader>
<bodyText confidence="0.9999935">
We will briefly discuss the experiments with En-
glish data. The English corpus experiments were
similar to the Japanese ones. For the SA unit seg-
mentation, we changed the word range r from 1 to
3 while fixing the parameters for PT to (H), where
we obtained the best results with word range r = 2,
i.e., (B). The recall rate was 71.92% and the preci-
sion rate was 78.10%. 5
We conducted the exact same tagging experi-
ments as the Japanese ones by fixing the parame-
ter for PE to (B). Experiments with condition (H)
showed the best score: the recall rate was 53.17%
and the precision rate was 57.75%. We obtained
lower performance than that for Japanese. This was
somewhat surprising since we thought English would
be easier to process. The lower performance in seg-
mentation affected the total tagging performance.
We will further discuss the difference in section 7.
</bodyText>
<sectionHeader confidence="0.961589" genericHeader="method">
6 Application of SA tags to speech
translation
</sectionHeader>
<bodyText confidence="0.996710818181818">
In this section, we will briefly discuss an application
of SA tags to a machine translation task. This is one
&apos;Experiments with pause information were not
conducted.
of the motivations of the automatic tagging research
described in the previous sections. We actually dealt
with the translation problem of positive responses
appearing in both Japanese and English dialogues.
Japanese positive responses like Hai
and Soudesuka, and the English ones like Yes and
I see appear quite often in our corpus. Since our di-
alogues were collected from the travel arrangement
domain, which can basically be viewed as a sequence
of a pair of questions and answers, they naturally
contain many of these expressions.
These expressions are highly ambiguous in word-
sense. For example, Hai can mean Yes (accept), Uh
huh (acknowledgment), hello (greeting) and so on.
Incorrect translation of the expression could confuse
the dialogue participants. These expressions, how-
ever, are short and do not contain enough clues for
proper translation in themselves, so some other con-
textual information is inevitably required.
We assume that SA tags can provide such neces-
sary information since we can distinguish the trans-
lations by the SA tags in the parentheses in the
above examples.
We conducted a series of experiments to verify
if positive responses can be properly translated us-
ing SA tags with other situational information. We
assumed that SA tags are properly given to these ex-
pressions and used the manually tagged corpus de-
scribed in Table 1 for the experiments.
We collected Japanese positive responses from the
SA units in the corpus. After assigning an En-
glish translation to each expression, we categorized
these expressions into several representative forms.
For example, the surface Japanese expression Fe,
Kekkou desu was categorized under the representa-
tive form Kekkou.
We also made such data for English positive re-
sponses. The size of the Japanese and English data
in representative forms (equivalent to SA unit) is
shown in Table 7. Notice that 1,968 out of 5,416
Japanese SA units are positive responses and 1,037
out of 4,675 English SA units are positive responses.
The Japanese data contained 16 types of English
translations and the English data contained 12 types
of Japanese translations in total.
We examined the effects of all possible combi-
nations of the following four features on transla-
tion accuracy. We trained decision trees with the
C4.5 (Quinlan, 1993) type algorithm while using
these features (in all possible combinations) as at-
tributes.
</bodyText>
<listItem confidence="0.9888548">
(I) Representative form of the positive response
(J) SA tag for the positive response
(K) SA tag for the SA unit previous to the positive
response
(L) Speaker (Hotel/Clerk)
</listItem>
<page confidence="0.997163">
386
</page>
<tableCaption confidence="0.911368">
Table 7: Representation forms and the counts. Table 9: Best performance for each number of fea-
</tableCaption>
<table confidence="0.993888733333333">
tures.
Japanese freq. English freq.
Kekkou 69 I understand 6
Soudesu ka 192 Great 5
Hai 930 Okay 240
Soudesu 120 I see 136
Mochiron 7 All right 136
Soudesu ne 16 Very well 13
Shouchi 30 Certainly 27
Wakari— Yes 359
mashita 304 Fine 52
Kashikomari— Right 10
mashita 300 Sure 44
Very good 9
Total 1,968 Total 1,037
</table>
<tableCaption confidence="0.999125">
Table 8: Accuracies with one feature.
</tableCaption>
<table confidence="0.7275854">
Feature J to E (%) E to J (%)
54.83 46.96
51.73 34.33
73.02 55.35
40.09 37.80
</table>
<bodyText confidence="0.959750958333333">
We will show some of the results. Table 8 shows
the accuracy when using one feature as the attribute.
We can naturally assume that the use of feature (I)
gives the baseline accuracy.
The result gives us a strange impression in that
the SA tags for the previous SA units (K) were far
more effective than the SA tags for the positive re-
sponses themselves (J). This phenomenon can be
explained by the variety of tag types given to the
utterances. A positive response expressions of the
same representative form have at most a few SA tag
types, say two, whereas the previous SA units can
have many SA tag types. If a positive response ex-
pression possesses five translations, they cannot be
translated with two SA tags.
Table 9 shows the best feature combinations at
each number of features from 1 to 4. The best fea-
ture combinations were exactly the same for both
translation directions, Japanese to English and vice
versa. The percentages are the average accuracy ob-
tained by the 10—fold cross—validation, and the t—
score in each row indicates the effect of adding one
feature from the upper row. We again admit a
score that that is greater than 2.01 as significant (two—
sided significance level of 5 %).
The accuracy for Japanese translation was sat-
urated with the two features (K) and (I). Further
addition of any feature did not show any significant
improvement. The SA tag for the positive responses
did not work.
The accuracy for English translation was satu-
Features J to E (%) E to J (%)
73.02 55.35
K,I 88.51 15.42 60.66 3.10
K,I,L 88.92 0.51 65.58 2.49
K,I,L,J 88.21 0.75 66.74 0.55
rated with the three features (K), (I), and (L). The
speaker&apos;s identification proved to be effective, unlike
Japanese. This is due to the necessity of controlling
politeness in Japanese translations according to the
speaker. The SA tag for the positive responses did
not work either.
These results suggest that the SA tag informa-
tion for the previous SA unit and the speaker&apos;s in-
formation should be kept in addition to representa-
tive forms when we implement the positive response
translation system together with the SA tagging sys-
tem.
</bodyText>
<sectionHeader confidence="0.998222" genericHeader="method">
7 Related Works and Discussions
</sectionHeader>
<bodyText confidence="0.9999825625">
We discuss the tagging work in this section. In sub—
section 5.3, we showed that Japanese segmentation
into SA units was quite successful only with lexical
information, but English segmentation was not that
successful.
Although we do not know of any experiments di-
rectly comparable to ours, a recent work reported
by Cettolo and Falavigna (1998) seems to be sim-
ilar. In that paper, they worked on finding se-
mantic boundaries in Italian dialogues with the
&amp;quot;appointment scheduling task.&amp;quot; Their semantic
boundary nearly corresponds to our SA unit bound-
ary. Cettolo and Falavigna (1998) reported recall
and precision rates of 62.8% and 71.8%, respec-
tively, which were obtained with insertion and dele-
tion of boundary markers. These scores are clearly
lower than our results with a Japanese segmentation
match.
Although we should not jump to a generalization,
we are tempted to say the Japanese dialogues are
easier to segment than western languages. With this
in mind, we would like to discuss our study.
First of all, was the manual segmentation quality
the same for both corpora? As we explained in sub—
section 2.1, both corpora were tagged by experts,
and the entire result was checked by one of them
for each language. Therefore, we believe that there
was not such a significant gap in quality that could
explain the segmentation performance.
Secondly, which lexical information yielded such
a performance gap? We investigated the effects of
part—of—speech and morphemes in the segmentation
</bodyText>
<page confidence="0.993796">
387
</page>
<bodyText confidence="0.999830722222222">
of both languages. We conducted the same 10—fold
cross—validation tests as in sub—section 5.3 and ob-
tained 82.29% (recall) and 86.16% (precision) for
Japanese under condition (B&apos;), which used only pos&apos;s
in 4+12 for the PE calculation. English, in con-
trast, marked rates of 65.63% (recall) and 73.35%
(precision) under the same condition. These results
indicated the outstanding effectiveness of Japanese
pos&apos;s in segmentation. Actually, we could see some
pos&apos;s such as &amp;quot;ending particle (shu-jyoshi)&amp;quot; which
clearly indicate sentence endings and we considered
that they played important roles in the segmenta-
tion. English, on the other hand, did not seem to
have such strong segment indicating pos&apos;s. Although
lexical information is important in English segmen-
tation (Stolcke and Shriberg, 1996), what other in-
formation can help improve such segmentation?
Hirschberg and Nakatani (1996) showed that
prosodic information helps human discourse segmen-
tation. Litman and Passonneau (1995) addressed
the usefulness of a &amp;quot;multiple knowledge source&amp;quot;
in human and automatic discourse segmentation.
Venditti and Swerts (1996) stated that the into-
national features for many Indo—European lan-
guages help cue the structure of spoken dis-
course. Cettolo and Falavigna (1998) reported im-
provements in Italian semantic boundary detection
with acoustic information. All of these works indi-
cate that the use of acoustic or prosodic information
is useful, so this is surely one of our future directions.
The use of higher syntactical information is also
one of our directions. The SA unit should be a mean-
ingful syntactic unit, although its degree of meaning-
fulness may be less than that in written texts. The
goodness of this aspect can be easily incorporated in
our probability term PE.
</bodyText>
<sectionHeader confidence="0.999497" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.99299695">
We have described a new efficient statistical speech
act type tagging system based on a statistical model
used in Japanese morphological analyzers. This sys-
tem integrates linguistic, acoustic, and situational
features and efficiently performs optimal segmenta-
tion of a turn and tagging. From several tagging
experiments, we showed that the system segmented
turns and assigned speech act type tags at high ac-
curacy rates when using Japanese data. Compara-
tively lower performance was obtained using English
data, and we discussed the performance difference.
We also examined the effect of parameters in the sta-
tistical models on tagging performance. We finally
showed that the SA tags in this paper are useful in
translating positive responses that often appear in
task—oriented dialogues such as those in ours.
Acknowledgment
The authors would like to thank Mr. Yasuo
Tanida for the excellent programming works and Dr.
Seiichi Yamamoto for stimulus discussions.
</bodyText>
<sectionHeader confidence="0.996816" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997732254901961">
M. Cettolo and D. Falavigna. 1998. Automatic de-
tection of semantic boundaries based on acoustic
and lexical knowledge. In ICSLP &apos;98, volume 4,
pages 1551-1554.
B. J. Grosz and C. L. Sidner. 1986. Atten-
tion, intentions and the structure of discourse.
Computational Linguistics, 12(3): 175-204, July—
September.
J. Hirschberg and C. H. Nakatani. 1996. A prosodic
analysis of discourse segments in direction—giving
monologues. In 34th Annual Meeting of the Asso-
ciation for the Computational Linguistics, pages
286-293.
F. Jelinek, 1997. Statistical Methods for Speech
Recognition, chapter 10. The MIT Press.
D. J. Litman and R. J. Passonneau. 1995. Com-
bining multiple knowledge sourses for discourse
segmentation. In 33rd Annual Meeting of the As-
sociation for the Computational Linguistics, pages
108-115.
T. Morimoto, N. Uratani, T. Takezawa, 0. Furuse,
Y. Sobashima, H. Iida, A. Nakamura, Y. Sagisaka,
N. Higuchi, and Y. Yamazaki. 1994. A speech and
language database for speech translation research.
In ICSLP &apos;9.4, pages 1791-1794.
M. Nagata and T. Morimoto. 1994. An information-
theoretic model of discourse for next utterance
type prediction. Transactions of Information
Processing Society of Japan, 35(6):1050-1061.
M. Nagata. 1994. A stochastic Japanese morpholog-
ical analyzer using a forward—DP and backward—
A* N—best search algorithm. In Proceedings of
Coling94, pages 201-207.
J. R. Quinlan. 1993. C.4.5: Programs for Machine
Learning. Morgan Kaufmann.
N. Reithinger and E. Maier. 1995. Utilizing statisti-
cal dialogue act processing in verbmobil. In 33rd
Annual Meeting of the Associations for Computa-
tional Linguistics, pages 116-121.
J. R. Searle. 1969. Speech Ads. Cambridge Univer-
sity Press.
M. Seligman, L. Fais, and M. Tomokiyo. 1994.
A bilingual set of communicative act labels for
spontaneous dialogues. Technical Report TR—IT-
0081, ATR—ITL.
A. Stolcke and E. Shriberg. 1996. Automatic lin-
guistic segmentation of conversational speech. In
ICSLP &apos;96, volume 2, pages 1005-1008.
J. Venditti and M. Swerts. 1996. Intonational cues
to discourse structure in Japanese. In ICSLP &apos;96,
volume 2, pages 725-728.
</reference>
<page confidence="0.998229">
388
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.951017">
<title confidence="0.999627">An Efficient Statistical Speech Act Type Tagging System for Speech Translation Systems</title>
<author confidence="0.979014">Hideki Tanaka</author>
<author confidence="0.979014">Akio Yokoo</author>
<affiliation confidence="0.998081">ATR Interpreting Telecommunications Research Laboratories</affiliation>
<address confidence="0.994741">2-2, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan</address>
<email confidence="0.984416">ftanakahlayokoolOitl.atr.co.jp</email>
<abstract confidence="0.999555647058824">This paper describes a new efficient speech act type tagging system. This system covers the tasks of (1) segmenting a turn into the optimal number of speech act units (SA units), and (2) assigning a speech act type tag (SA tag) to each SA unit. Our method is based on a theoretically clear statistical model that integrates linguistic, acoustic and situational information. We report tagging experiments on Japanese and English dialogue corpora manually labeled with SA tags. We then discuss the performance difference between the two languages. We also report on some translation experiments on positive response expressions using SA tags.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Cettolo</author>
<author>D Falavigna</author>
</authors>
<title>Automatic detection of semantic boundaries based on acoustic and lexical knowledge.</title>
<date>1998</date>
<booktitle>In ICSLP &apos;98,</booktitle>
<volume>4</volume>
<pages>1551--1554</pages>
<contexts>
<context position="2594" citStr="Cettolo and Falavigna, 1998" startWordPosition="377" endWordPosition="381">or discourse segmentation) is desired here. Discourse segmentation in linguistics, whether manual or automatic, has also received keen attention because such segmentation provides the foundation of higher discourse structures (Grosz and Sidner, 1986). Discourse segmentation has also received keen attention from the engineering side because the natural language processing systems that follow the speech recognition system are designed to accept linguistically meaningful units (Stolcke and Shriberg, 1996). There has been a lot of research following this line such as (Stolcke and Shriberg, 1996) (Cettolo and Falavigna, 1998), to only mention a few. We can take advantage of these studies as a pre— process for tagging. In this paper, however, we propose a statistical tagging system that optimally performs segmentation and tagging at the same time. Previous studies like (Litman and Passonneau, 1995) have pointed out that the use of a multiple information source can contribute to better segmentation and tagging, and so our statistical model integrates linguistic, acoustic and situational information. The problem can be formalized as a search problem on a word graph, which can be efficiently handled by an extended dyn</context>
<context position="27963" citStr="Cettolo and Falavigna (1998)" startWordPosition="4772" endWordPosition="4775">hese results suggest that the SA tag information for the previous SA unit and the speaker&apos;s information should be kept in addition to representative forms when we implement the positive response translation system together with the SA tagging system. 7 Related Works and Discussions We discuss the tagging work in this section. In sub— section 5.3, we showed that Japanese segmentation into SA units was quite successful only with lexical information, but English segmentation was not that successful. Although we do not know of any experiments directly comparable to ours, a recent work reported by Cettolo and Falavigna (1998) seems to be similar. In that paper, they worked on finding semantic boundaries in Italian dialogues with the &amp;quot;appointment scheduling task.&amp;quot; Their semantic boundary nearly corresponds to our SA unit boundary. Cettolo and Falavigna (1998) reported recall and precision rates of 62.8% and 71.8%, respectively, which were obtained with insertion and deletion of boundary markers. These scores are clearly lower than our results with a Japanese segmentation match. Although we should not jump to a generalization, we are tempted to say the Japanese dialogues are easier to segment than western languages.</context>
<context position="30372" citStr="Cettolo and Falavigna (1998)" startWordPosition="5145" endWordPosition="5148">her hand, did not seem to have such strong segment indicating pos&apos;s. Although lexical information is important in English segmentation (Stolcke and Shriberg, 1996), what other information can help improve such segmentation? Hirschberg and Nakatani (1996) showed that prosodic information helps human discourse segmentation. Litman and Passonneau (1995) addressed the usefulness of a &amp;quot;multiple knowledge source&amp;quot; in human and automatic discourse segmentation. Venditti and Swerts (1996) stated that the intonational features for many Indo—European languages help cue the structure of spoken discourse. Cettolo and Falavigna (1998) reported improvements in Italian semantic boundary detection with acoustic information. All of these works indicate that the use of acoustic or prosodic information is useful, so this is surely one of our future directions. The use of higher syntactical information is also one of our directions. The SA unit should be a meaningful syntactic unit, although its degree of meaningfulness may be less than that in written texts. The goodness of this aspect can be easily incorporated in our probability term PE. 8 Conclusions We have described a new efficient statistical speech act type tagging system</context>
</contexts>
<marker>Cettolo, Falavigna, 1998</marker>
<rawString>M. Cettolo and D. Falavigna. 1998. Automatic detection of semantic boundaries based on acoustic and lexical knowledge. In ICSLP &apos;98, volume 4, pages 1551-1554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<pages>175--204</pages>
<contexts>
<context position="2216" citStr="Grosz and Sidner, 1986" startWordPosition="319" endWordPosition="323">neering applications. The early studies by Nagata and Morimoto (1994) and Reithinger and Maier (1995) showed the possibility of predicting dialogue act tags for next utterances with statistical methods. These studies, however, presupposed properly segmented utterances, which is not a realistic assumption. In contrast to this assumption, automatic utterance segmentation (or discourse segmentation) is desired here. Discourse segmentation in linguistics, whether manual or automatic, has also received keen attention because such segmentation provides the foundation of higher discourse structures (Grosz and Sidner, 1986). Discourse segmentation has also received keen attention from the engineering side because the natural language processing systems that follow the speech recognition system are designed to accept linguistically meaningful units (Stolcke and Shriberg, 1996). There has been a lot of research following this line such as (Stolcke and Shriberg, 1996) (Cettolo and Falavigna, 1998), to only mention a few. We can take advantage of these studies as a pre— process for tagging. In this paper, however, we propose a statistical tagging system that optimally performs segmentation and tagging at the same ti</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. J. Grosz and C. L. Sidner. 1986. Attention, intentions and the structure of discourse. Computational Linguistics, 12(3): 175-204, July— September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>C H Nakatani</author>
</authors>
<title>A prosodic analysis of discourse segments in direction—giving monologues.</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for the Computational Linguistics,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="29998" citStr="Hirschberg and Nakatani (1996)" startWordPosition="5091" endWordPosition="5094">t, marked rates of 65.63% (recall) and 73.35% (precision) under the same condition. These results indicated the outstanding effectiveness of Japanese pos&apos;s in segmentation. Actually, we could see some pos&apos;s such as &amp;quot;ending particle (shu-jyoshi)&amp;quot; which clearly indicate sentence endings and we considered that they played important roles in the segmentation. English, on the other hand, did not seem to have such strong segment indicating pos&apos;s. Although lexical information is important in English segmentation (Stolcke and Shriberg, 1996), what other information can help improve such segmentation? Hirschberg and Nakatani (1996) showed that prosodic information helps human discourse segmentation. Litman and Passonneau (1995) addressed the usefulness of a &amp;quot;multiple knowledge source&amp;quot; in human and automatic discourse segmentation. Venditti and Swerts (1996) stated that the intonational features for many Indo—European languages help cue the structure of spoken discourse. Cettolo and Falavigna (1998) reported improvements in Italian semantic boundary detection with acoustic information. All of these works indicate that the use of acoustic or prosodic information is useful, so this is surely one of our future directions. T</context>
</contexts>
<marker>Hirschberg, Nakatani, 1996</marker>
<rawString>J. Hirschberg and C. H. Nakatani. 1996. A prosodic analysis of discourse segments in direction—giving monologues. In 34th Annual Meeting of the Association for the Computational Linguistics, pages 286-293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Statistical Methods for Speech Recognition, chapter 10.</title>
<date>1997</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="11032" citStr="Jelinek, 1997" startWordPosition="1844" endWordPosition="1845">e of an SA unit boundary. PE is approximated by the product of two types of probabilities: for a word sequence break at both ends of an SA unit and for a non— break inside the unit. Notice that the probabilities of the former type adjust an unfairly high probability estimation for an SA unit that is made from a short word sequence. The estimation of PE is now reduced to that of P(B„,„+, I hi ,W). This probability is estimated by a probabilistic decision tree and we have P(B„,,r,„„+1 I h2,W) P(B„.,tur+, I (DE(h),W)), where &apos;TE is a decision tree that categorizes ii,, W into equivalent classes (Jelinek, 1997). We modified C4.5 (Quinlan, 1993) style algorithm to produce probability and used it for this purpose. The decision tree is known to be effective for the data sparseness problem and can take different types of parameters such as discrete and continuous values, which is useful since our word sequence contains both types of features. Through preliminary experiments, we found that hi (the past history of tagging results) was not useful and discarded it. We also found that the probability was well estimated by the information available in a short range of r around wr, which is stored in W. Actual</context>
</contexts>
<marker>Jelinek, 1997</marker>
<rawString>F. Jelinek, 1997. Statistical Methods for Speech Recognition, chapter 10. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Litman</author>
<author>R J Passonneau</author>
</authors>
<title>Combining multiple knowledge sourses for discourse segmentation.</title>
<date>1995</date>
<booktitle>In 33rd Annual Meeting of the Association for the Computational Linguistics,</booktitle>
<pages>108--115</pages>
<contexts>
<context position="2871" citStr="Litman and Passonneau, 1995" startWordPosition="425" endWordPosition="428">s also received keen attention from the engineering side because the natural language processing systems that follow the speech recognition system are designed to accept linguistically meaningful units (Stolcke and Shriberg, 1996). There has been a lot of research following this line such as (Stolcke and Shriberg, 1996) (Cettolo and Falavigna, 1998), to only mention a few. We can take advantage of these studies as a pre— process for tagging. In this paper, however, we propose a statistical tagging system that optimally performs segmentation and tagging at the same time. Previous studies like (Litman and Passonneau, 1995) have pointed out that the use of a multiple information source can contribute to better segmentation and tagging, and so our statistical model integrates linguistic, acoustic and situational information. The problem can be formalized as a search problem on a word graph, which can be efficiently handled by an extended dynamic programming algorithm. Actually, we can efficiently find the optimal solution without limiting the search space at all. The results of our tagging experiments involving both Japanese and English corpora indicated a high performance for Japanese but a considerably lower pe</context>
<context position="30096" citStr="Litman and Passonneau (1995)" startWordPosition="5104" endWordPosition="5107">dicated the outstanding effectiveness of Japanese pos&apos;s in segmentation. Actually, we could see some pos&apos;s such as &amp;quot;ending particle (shu-jyoshi)&amp;quot; which clearly indicate sentence endings and we considered that they played important roles in the segmentation. English, on the other hand, did not seem to have such strong segment indicating pos&apos;s. Although lexical information is important in English segmentation (Stolcke and Shriberg, 1996), what other information can help improve such segmentation? Hirschberg and Nakatani (1996) showed that prosodic information helps human discourse segmentation. Litman and Passonneau (1995) addressed the usefulness of a &amp;quot;multiple knowledge source&amp;quot; in human and automatic discourse segmentation. Venditti and Swerts (1996) stated that the intonational features for many Indo—European languages help cue the structure of spoken discourse. Cettolo and Falavigna (1998) reported improvements in Italian semantic boundary detection with acoustic information. All of these works indicate that the use of acoustic or prosodic information is useful, so this is surely one of our future directions. The use of higher syntactical information is also one of our directions. The SA unit should be a me</context>
</contexts>
<marker>Litman, Passonneau, 1995</marker>
<rawString>D. J. Litman and R. J. Passonneau. 1995. Combining multiple knowledge sourses for discourse segmentation. In 33rd Annual Meeting of the Association for the Computational Linguistics, pages 108-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Sobashima Furuse</author>
<author>H Iida</author>
<author>A Nakamura</author>
<author>Y Sagisaka</author>
<author>N Higuchi</author>
<author>Y Yamazaki</author>
</authors>
<title>A speech and language database for speech translation research.</title>
<date>1994</date>
<booktitle>In ICSLP &apos;9.4,</booktitle>
<pages>1791--1794</pages>
<marker>Furuse, Iida, Nakamura, Sagisaka, Higuchi, Yamazaki, 1994</marker>
<rawString>T. Morimoto, N. Uratani, T. Takezawa, 0. Furuse, Y. Sobashima, H. Iida, A. Nakamura, Y. Sagisaka, N. Higuchi, and Y. Yamazaki. 1994. A speech and language database for speech translation research. In ICSLP &apos;9.4, pages 1791-1794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
<author>T Morimoto</author>
</authors>
<title>An informationtheoretic model of discourse for next utterance type prediction.</title>
<date>1994</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<pages>35--6</pages>
<contexts>
<context position="1662" citStr="Nagata and Morimoto (1994)" startWordPosition="244" endWordPosition="247"> situational features. This work can be viewed as a study on automatic &amp;quot;Discourse Tagging&amp;quot; whose objective is to assign tags to discourse units in texts or dialogues. Discourse tagging is studied mainly from two different viewpoints, i.e., linguistic and engineering viewpoints. The work described here belongs to the latter group. More specifically, we are interested in automatically recognizing the speech act types of utterances and in applying them to speech translation systems. Several studies on discourse tagging to date have been motivated by engineering applications. The early studies by Nagata and Morimoto (1994) and Reithinger and Maier (1995) showed the possibility of predicting dialogue act tags for next utterances with statistical methods. These studies, however, presupposed properly segmented utterances, which is not a realistic assumption. In contrast to this assumption, automatic utterance segmentation (or discourse segmentation) is desired here. Discourse segmentation in linguistics, whether manual or automatic, has also received keen attention because such segmentation provides the foundation of higher discourse structures (Grosz and Sidner, 1986). Discourse segmentation has also received kee</context>
</contexts>
<marker>Nagata, Morimoto, 1994</marker>
<rawString>M. Nagata and T. Morimoto. 1994. An informationtheoretic model of discourse for next utterance type prediction. Transactions of Information Processing Society of Japan, 35(6):1050-1061.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
</authors>
<title>A stochastic Japanese morphological analyzer using a forward—DP and backward— A* N—best search algorithm.</title>
<date>1994</date>
<booktitle>In Proceedings of Coling94,</booktitle>
<pages>201--207</pages>
<contexts>
<context position="13493" citStr="Nagata (1994)" startWordPosition="2289" endWordPosition="2290">&apos;s identification, and in previous tags. The value for each cue word was a binary value, where 1 was set when the utterance uj contained the word, or otherwise 0. The effect of f(u), g(ui), and length in for the tagging performance will be reported in sub—section 5.3. 4 Search Method A search in a word graph was conducted using the extended dynamic programming technique proposed (3) 383 turn boundary current process front hi history -1111 ui_i, tj_/ ui, CD - - - - - 0-CD Ca - - - - CD CD- - - - WI ws-/ W. ws+] ws+p-1 ws+p wn W word sequence for a dialogue Figure 1: Probability calculation. by Nagata (1994). This algorithm was originally developed for a statistical Japanese morphological analyzer whose tasks are to determine boundaries in an input character sequence having no separators and to give an appropriate part of speech tag to each word, i.e., a character sequence unit. This algorithm can handle arbitrary lengths of histories of pos tags and words and efficiently produce n—best results. We can see a high similarity between our task and Japanese morphological analysis. Our task requires the segmentation of a word sequence instead of a character sequence and the assignment of an SA tag ins</context>
<context position="15488" citStr="Nagata, 1994" startWordPosition="2621" endWordPosition="2622">er of SA units per turn was 2.68 for Japanese and 2.31 for English. The average number of boundary candidates per turn was 18 for Japanese and 12.7 for English. The number of tag types, the average number of SA units, and the average number of SA boundary candidates indicated that the Japanese data were more difficult to process. 4Also, the probability for the existence of a word can be directly estimated from the corpus. Table 1: Counts in both corpora. Japanese English 2,020 2,020 5,416 4,675 38,418 27,639 30 33 29 17 5.2 Evaluation Methods We used &amp;quot;labeled bracket matching&amp;quot; for evaluation (Nagata, 1994). The result of tagging can be viewed as a set of labeled brackets, where brackets correspond to turn segmentation and their labels correspond to SA tags. With this in mind, the evaluation was done in the following way. We counted the number of brackets in the correct answer, denoted as R (reference). We also counted the number of brackets in the tagger&apos;s output, denoted as S (system). Then the number of matching brackets was counted and denoted as M (match). Thus, we could define the precision rate with MIS and the recall rate with MIR. The matching was judged in two ways. One was &amp;quot;segmentati</context>
</contexts>
<marker>Nagata, 1994</marker>
<rawString>M. Nagata. 1994. A stochastic Japanese morphological analyzer using a forward—DP and backward— A* N—best search algorithm. In Proceedings of Coling94, pages 201-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C.4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="11066" citStr="Quinlan, 1993" startWordPosition="1850" endWordPosition="1851">proximated by the product of two types of probabilities: for a word sequence break at both ends of an SA unit and for a non— break inside the unit. Notice that the probabilities of the former type adjust an unfairly high probability estimation for an SA unit that is made from a short word sequence. The estimation of PE is now reduced to that of P(B„,„+, I hi ,W). This probability is estimated by a probabilistic decision tree and we have P(B„,,r,„„+1 I h2,W) P(B„.,tur+, I (DE(h),W)), where &apos;TE is a decision tree that categorizes ii,, W into equivalent classes (Jelinek, 1997). We modified C4.5 (Quinlan, 1993) style algorithm to produce probability and used it for this purpose. The decision tree is known to be effective for the data sparseness problem and can take different types of parameters such as discrete and continuous values, which is useful since our word sequence contains both types of features. Through preliminary experiments, we found that hi (the past history of tagging results) was not useful and discarded it. We also found that the probability was well estimated by the information available in a short range of r around wr, which is stored in W. Actually, the attributes used to develop</context>
<context position="24671" citStr="Quinlan, 1993" startWordPosition="4201" endWordPosition="4202">orm Kekkou. We also made such data for English positive responses. The size of the Japanese and English data in representative forms (equivalent to SA unit) is shown in Table 7. Notice that 1,968 out of 5,416 Japanese SA units are positive responses and 1,037 out of 4,675 English SA units are positive responses. The Japanese data contained 16 types of English translations and the English data contained 12 types of Japanese translations in total. We examined the effects of all possible combinations of the following four features on translation accuracy. We trained decision trees with the C4.5 (Quinlan, 1993) type algorithm while using these features (in all possible combinations) as attributes. (I) Representative form of the positive response (J) SA tag for the positive response (K) SA tag for the SA unit previous to the positive response (L) Speaker (Hotel/Clerk) 386 Table 7: Representation forms and the counts. Table 9: Best performance for each number of features. Japanese freq. English freq. Kekkou 69 I understand 6 Soudesu ka 192 Great 5 Hai 930 Okay 240 Soudesu 120 I see 136 Mochiron 7 All right 136 Soudesu ne 16 Very well 13 Shouchi 30 Certainly 27 Wakari— Yes 359 mashita 304 Fine 52 Kashi</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>J. R. Quinlan. 1993. C.4.5: Programs for Machine Learning. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
<author>E Maier</author>
</authors>
<title>Utilizing statistical dialogue act processing in verbmobil.</title>
<date>1995</date>
<booktitle>In 33rd Annual Meeting of the Associations for Computational Linguistics,</booktitle>
<pages>116--121</pages>
<contexts>
<context position="1694" citStr="Reithinger and Maier (1995)" startWordPosition="249" endWordPosition="252">k can be viewed as a study on automatic &amp;quot;Discourse Tagging&amp;quot; whose objective is to assign tags to discourse units in texts or dialogues. Discourse tagging is studied mainly from two different viewpoints, i.e., linguistic and engineering viewpoints. The work described here belongs to the latter group. More specifically, we are interested in automatically recognizing the speech act types of utterances and in applying them to speech translation systems. Several studies on discourse tagging to date have been motivated by engineering applications. The early studies by Nagata and Morimoto (1994) and Reithinger and Maier (1995) showed the possibility of predicting dialogue act tags for next utterances with statistical methods. These studies, however, presupposed properly segmented utterances, which is not a realistic assumption. In contrast to this assumption, automatic utterance segmentation (or discourse segmentation) is desired here. Discourse segmentation in linguistics, whether manual or automatic, has also received keen attention because such segmentation provides the foundation of higher discourse structures (Grosz and Sidner, 1986). Discourse segmentation has also received keen attention from the engineering</context>
</contexts>
<marker>Reithinger, Maier, 1995</marker>
<rawString>N. Reithinger and E. Maier. 1995. Utilizing statistical dialogue act processing in verbmobil. In 33rd Annual Meeting of the Associations for Computational Linguistics, pages 116-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>Speech Ads.</title>
<date>1969</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4854" citStr="Searle, 1969" startWordPosition="743" endWordPosition="744">d by interpreters (Morimoto et al., 1994). The transcriptions were separated by language, i.e., English and Japanese, and the resultant two corpora share the same content. Both transcriptions went through morphological analysis, which was manually checked. The transcriptions have clear turn boundaries (TB&apos;s). Some of the Japanese and English dialogue files were manually segmented into speech act units (SA units) and assigned with speech act type tags (SA tags). The SA tags represent a speaker&apos;s intention in an utterance, and is more or less similar to the traditional illocutionary force type (Searle, 1969). The SA tags for the Japanese language were based on the set proposed by Seligman et al. (1994) and had 29 types. The English SA tags were based on the Japanese tags, but we redesigned and reduced the size to 17 types. We believed that an excessively detailed tag classification would decrease the intercoder reliability and so pruned some detailed tags.&apos; The following lines show an example of the English tagged dialogues. Two turns uttered by a hotel clerk and a customer were segmented into SA units and assigned with SA tags. &lt;clerk&apos;s turn&gt; Hello, (expressive) New York City Hotel, (inform) may</context>
</contexts>
<marker>Searle, 1969</marker>
<rawString>J. R. Searle. 1969. Speech Ads. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Seligman</author>
<author>L Fais</author>
<author>M Tomokiyo</author>
</authors>
<title>A bilingual set of communicative act labels for spontaneous dialogues.</title>
<date>1994</date>
<tech>Technical Report TR—IT0081, ATR—ITL.</tech>
<contexts>
<context position="4950" citStr="Seligman et al. (1994)" startWordPosition="759" endWordPosition="762">e, i.e., English and Japanese, and the resultant two corpora share the same content. Both transcriptions went through morphological analysis, which was manually checked. The transcriptions have clear turn boundaries (TB&apos;s). Some of the Japanese and English dialogue files were manually segmented into speech act units (SA units) and assigned with speech act type tags (SA tags). The SA tags represent a speaker&apos;s intention in an utterance, and is more or less similar to the traditional illocutionary force type (Searle, 1969). The SA tags for the Japanese language were based on the set proposed by Seligman et al. (1994) and had 29 types. The English SA tags were based on the Japanese tags, but we redesigned and reduced the size to 17 types. We believed that an excessively detailed tag classification would decrease the intercoder reliability and so pruned some detailed tags.&apos; The following lines show an example of the English tagged dialogues. Two turns uttered by a hotel clerk and a customer were segmented into SA units and assigned with SA tags. &lt;clerk&apos;s turn&gt; Hello, (expressive) New York City Hotel, (inform) may I help you? (offer) &lt;customer(interpreter) &apos;s turn&gt; Hello, (expressive) my name is Hiroko Tanak</context>
</contexts>
<marker>Seligman, Fais, Tomokiyo, 1994</marker>
<rawString>M. Seligman, L. Fais, and M. Tomokiyo. 1994. A bilingual set of communicative act labels for spontaneous dialogues. Technical Report TR—IT0081, ATR—ITL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>E Shriberg</author>
</authors>
<title>Automatic linguistic segmentation of conversational speech.</title>
<date>1996</date>
<booktitle>In ICSLP &apos;96,</booktitle>
<volume>2</volume>
<pages>1005--1008</pages>
<contexts>
<context position="2473" citStr="Stolcke and Shriberg, 1996" startWordPosition="357" endWordPosition="360">nted utterances, which is not a realistic assumption. In contrast to this assumption, automatic utterance segmentation (or discourse segmentation) is desired here. Discourse segmentation in linguistics, whether manual or automatic, has also received keen attention because such segmentation provides the foundation of higher discourse structures (Grosz and Sidner, 1986). Discourse segmentation has also received keen attention from the engineering side because the natural language processing systems that follow the speech recognition system are designed to accept linguistically meaningful units (Stolcke and Shriberg, 1996). There has been a lot of research following this line such as (Stolcke and Shriberg, 1996) (Cettolo and Falavigna, 1998), to only mention a few. We can take advantage of these studies as a pre— process for tagging. In this paper, however, we propose a statistical tagging system that optimally performs segmentation and tagging at the same time. Previous studies like (Litman and Passonneau, 1995) have pointed out that the use of a multiple information source can contribute to better segmentation and tagging, and so our statistical model integrates linguistic, acoustic and situational informatio</context>
<context position="29907" citStr="Stolcke and Shriberg, 1996" startWordPosition="5078" endWordPosition="5081">ondition (B&apos;), which used only pos&apos;s in 4+12 for the PE calculation. English, in contrast, marked rates of 65.63% (recall) and 73.35% (precision) under the same condition. These results indicated the outstanding effectiveness of Japanese pos&apos;s in segmentation. Actually, we could see some pos&apos;s such as &amp;quot;ending particle (shu-jyoshi)&amp;quot; which clearly indicate sentence endings and we considered that they played important roles in the segmentation. English, on the other hand, did not seem to have such strong segment indicating pos&apos;s. Although lexical information is important in English segmentation (Stolcke and Shriberg, 1996), what other information can help improve such segmentation? Hirschberg and Nakatani (1996) showed that prosodic information helps human discourse segmentation. Litman and Passonneau (1995) addressed the usefulness of a &amp;quot;multiple knowledge source&amp;quot; in human and automatic discourse segmentation. Venditti and Swerts (1996) stated that the intonational features for many Indo—European languages help cue the structure of spoken discourse. Cettolo and Falavigna (1998) reported improvements in Italian semantic boundary detection with acoustic information. All of these works indicate that the use of ac</context>
</contexts>
<marker>Stolcke, Shriberg, 1996</marker>
<rawString>A. Stolcke and E. Shriberg. 1996. Automatic linguistic segmentation of conversational speech. In ICSLP &apos;96, volume 2, pages 1005-1008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Venditti</author>
<author>M Swerts</author>
</authors>
<title>Intonational cues to discourse structure in Japanese.</title>
<date>1996</date>
<booktitle>In ICSLP &apos;96,</booktitle>
<volume>2</volume>
<pages>725--728</pages>
<contexts>
<context position="30228" citStr="Venditti and Swerts (1996)" startWordPosition="5122" endWordPosition="5125">hu-jyoshi)&amp;quot; which clearly indicate sentence endings and we considered that they played important roles in the segmentation. English, on the other hand, did not seem to have such strong segment indicating pos&apos;s. Although lexical information is important in English segmentation (Stolcke and Shriberg, 1996), what other information can help improve such segmentation? Hirschberg and Nakatani (1996) showed that prosodic information helps human discourse segmentation. Litman and Passonneau (1995) addressed the usefulness of a &amp;quot;multiple knowledge source&amp;quot; in human and automatic discourse segmentation. Venditti and Swerts (1996) stated that the intonational features for many Indo—European languages help cue the structure of spoken discourse. Cettolo and Falavigna (1998) reported improvements in Italian semantic boundary detection with acoustic information. All of these works indicate that the use of acoustic or prosodic information is useful, so this is surely one of our future directions. The use of higher syntactical information is also one of our directions. The SA unit should be a meaningful syntactic unit, although its degree of meaningfulness may be less than that in written texts. The goodness of this aspect c</context>
</contexts>
<marker>Venditti, Swerts, 1996</marker>
<rawString>J. Venditti and M. Swerts. 1996. Intonational cues to discourse structure in Japanese. In ICSLP &apos;96, volume 2, pages 725-728.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>