<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.168861">
<title confidence="0.945052">
COLEUR and COLSLM: A WSD approach to Multilingual Lexical
Substitution, Tasks 2 and 3 SemEval 2010
</title>
<author confidence="0.996899">
Weiwei Guo and Mona Diab
</author>
<affiliation confidence="0.996435">
Center for Computational Learning Systems
Columbia University
</affiliation>
<email confidence="0.991835">
{weiwei,mdiab}@ccls.columbia.edu
</email>
<bodyText confidence="0.999859414634146">
ambiguous words in one language probably trans-
late to different lexical items in another language.
Hence, our approach relies on two crucial compo-
nents: a WSD module for the source language (our
target test words, in our case these are the English
target test words) and an automatic word align-
ment module to discover the target word sense cor-
respondences with the foreign words in a second
language. Our approach to both tasks is unsuper-
vised since we don’t have real training data anno-
tated with the target words and their corresponding
translations into l2 at the onset of the problem.
Accordingly, at training time, we rely on auto-
matically tagging large amounts of English data
(target word instances) with their relevant senses
and finding their l2 correspondences based on au-
tomatically induced word alignments. Each of
these English sense and l2 correspondence pairs
has an associated translation probability value de-
pending on frequency of co-occurrence. This in-
formation is aggregated in a look-up table over
the entire training set. An entry in the table
would have a target word sense type paired with all
the observed translation correspondences l2 word
types. Each of the l2 word types has a probabil-
ity of translation that is calculated as a normal-
ized weighted average of all the instances of this
l2 word type with the English sense aggregated
across the whole parallel corpus. This process re-
sults in an English word sense translation table
(WSTT). The word senses are derived from Word-
Net (Fellbaum, 1998). We expand the English
word sense entry correspondences by adding the
translations of the members of target word sense
synonym set as listed in WordNet.
For alignment, we specifically use the GIZA++
software for inducing word alignments across the
parallel corpora (Och &amp; Ney, 2003). We apply
GIZA++ to the parallel corpus in both directions
English to l2 and l2 to English then take only the
intersection of the two alignment sets, hence fo-
</bodyText>
<page confidence="0.956857">
129
</page>
<bodyText confidence="0.967732833333333">
Abstract
In this paper, we present a word sense
disambiguation (WSD) based system for
multilingual lexical substitution. Our
method depends on having a WSD system
for English and an automatic word align-
ment method. Crucially the approach re-
lies on having parallel corpora. For Task
2 (Sinha et al., 2009) we apply a super-
vised WSD system to derive the English
word senses. For Task 3 (Lefever &amp; Hoste,
2009), we apply an unsupervised approach
to the training and test data. Both of our
systems that participated in Task 2 achieve
a decent ranking among the participating
systems. For Task 3 we achieve the highest
ranking on several of the language pairs:
French, German and Italian.
</bodyText>
<sectionHeader confidence="0.965853" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999884857142857">
In this paper, we present our system that was ap-
plied to the cross lingual substitution for two tasks
in SEMEVAL 2010, Tasks 2 and 3. We adopt
the same approach for both tasks with some dif-
ferences in the basic set-up. Our basic approach
relies on applying a word sense disambiguation
(WSD) system to the English data that comes from
a parallel corpus for English and a language of
relevance to the task, language 2 (l2). Then we
automatically induce the English word sense cor-
respondences to l2. Accordingly, for a given test
target word, we return its equivalent l2 words as-
suming that we are able to disambiguate the target
word in context.
</bodyText>
<page confidence="0.738679">
2 Our Detailed Approach
</page>
<bodyText confidence="0.99750195">
We approach the problem of multilingual lexical
substitution from a WSD perspective. We adopt
the hypothesis that the different word senses of
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 129–133,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
cusing more on precision of alignment rather than
recall.
For each language in Task 3 and Task 2, we
use TreeTagger1 to do the preprocessing for all
languages. The preprocessing includes segmenta-
tion, POS tagging and lemmatization. Since Tree-
Tagger is independent of languages, our system
does not rely on anything that is language spe-
cific; our system can be easily applied to other
languages. We run GIZA++ on the parallel cor-
pus, and obtain the intersection of the alignments
in both directions. Meanwhile, every time a target
English word appears in a sentence, we apply our
WSD system on it, using the sentence as context.
From this information, we build a WSST from
the English sense(s) to their corresponding foreign
words. Moreover, we use WordNet as a means of
augmenting the translation correspondences. We
expand the word sense to its synset from WordNet
adding the l2 words that corresponded to all the
member senses in the synset yielding more trans-
lation variability.
At test time, given a test data target word, we
apply the same WSD system that is applied to the
training corpus to create the WSTT. Once the tar-
get word instance is disambiguated in context, we
look up the corresponding entry in the WSTT and
return the ranked list of l2 correspondences. We
present results for best and for oot which vary only
in the cut off threshold. In the BEST condition we
return the highest ranked candidate, in the oot con-
dition we return the top 10 (where available).2
Given the above mentioned pipeline, Tasks 2
and 3 are very similar. Their main difference lies
in the underlying WSD system applied.
</bodyText>
<sectionHeader confidence="0.999753" genericHeader="keywords">
3 Task 2
</sectionHeader>
<subsectionHeader confidence="0.99995">
3.1 System Details
</subsectionHeader>
<bodyText confidence="0.9999018">
We use a relatively simple monolingual supervised
WSD system to create the sense tags on the En-
glish data. We use the SemCor word sense anno-
tated corpus. SemCor is a subset of the Brown
Corpus. For each of our target English words
found disambiguated in the SemCor corpus, we
create a sense profile for each of its senses. A
sense profile is a vector of all the content words
that occur in the context of this sense in the Sem-
Cor corpus. The dimensions of the vector are word
</bodyText>
<footnote confidence="0.986782666666667">
1 http://www. ims.uni-stuttgart. de/proj ekte/corplex/TreeTagg
2Some of the target word senses had less than 10 l2 word
correspondences.
</footnote>
<table confidence="0.98444725">
Corpus best oot
P R P R
T2-COLSLM 27.59 25.99 46.61 43.91
T2-COLEUR 19.47 18.15 44.77 41.72
</table>
<tableCaption confidence="0.9920115">
Table 1: Precision and Recall results per corpus on
Task 2 test set
</tableCaption>
<bodyText confidence="0.9999412">
types, as in a bag of words model, and the vec-
tor entries are the co-occurrence frequency of the
word sense and the word type. At test time, given
a a target English word, we create a bag of word
types contextual vector for each instance of the
word using the surrounding context. We compare
the created test vector to the SemCor vectors and
choose the highest most similar sense and use that
for sense disambiguation. In case of ties, we return
more than one sense tag.
</bodyText>
<subsectionHeader confidence="0.998162">
3.2 Data
</subsectionHeader>
<bodyText confidence="0.999957333333333">
We use both naturally occurring parallel data and
machine translation data. The data for our first
Task 2 submission, T2-COLEUR, comprises nat-
urally occurring parallel data, namely, the Span-
ish English portion of the EuroParl data provided
by Task 3 organizers. For the machine transla-
tion data, we use translations of the source En-
glish data pertaining to the following corpora:
the Brown corpus, WSJ, SensEval1, SensEval2
datasets as translated by two machine translation
systems: Global Link (GL), Systran (SYS) (Guo
&amp; Diab, 2010). We refer to the translated corpus
as the SALAAM corpus. The intuition for creating
SALAAM (an artificial parallel corpus) is to create
a balanced translation corpus that is less domain
and genre skewed than the EuroParl data. This lat-
ter corpus results in our 2nd system for this task
T2-COLSLM.
</bodyText>
<subsectionHeader confidence="0.841207">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.99944175">
Table 1 presents our overall results as evaluated by
the organizers.
It is clear that the T2-COLSLM outperforms
T2-COLEUR.
</bodyText>
<sectionHeader confidence="0.999658" genericHeader="introduction">
4 Task 3
</sectionHeader>
<subsectionHeader confidence="0.999168">
4.1 System Details
</subsectionHeader>
<bodyText confidence="0.99860575">
Contrary to Task 2, we apply a context based un-
r/ supervised WSD module to the English side of the
parallel data. Our unsupervised WSD method, as
described in (Guo &amp; Diab, 2009), is a graph based
</bodyText>
<page confidence="0.972141">
130
</page>
<bodyText confidence="0.998893">
unsupervised WSD method. Given a sequence of
words W = {w1, w2...wn}, each word wi with
several senses {si1, si2...sim}. A graph G = (V,E)
is defined such that there exists a vertex v for each
sense. Two senses of two different words may be
connected by an edge e, depending on their dis-
tance. That two senses are connected suggests
they should have influence on each other, accord-
ingly a maximum allowable distance is set. They
explore 4 different graph based algorithms.We fo-
cus on the In-Degree graph based algorithm.
The In-Degree algorithm presents the problem
as a weighted graph with senses as nodes and sim-
ilarity between senses as weights on edges. The
In-Degree of a vertex refers to the number of
edges incident on that vertex. In the weighted
graph, the In-Degree for each vertex is calcu-
lated by summing the weights on the edges that are
incident on it. After all the In-Degree values
for each sense are computed, the sense with max-
imum value is chosen as the final sense for that
word. In our implementation of the In-Degree
algorithm, we use the JCN similarity measure for
both Noun-Noun and Verb-Verb similarity calcu-
lation.
</bodyText>
<subsectionHeader confidence="0.980285">
4.2 Data
</subsectionHeader>
<bodyText confidence="0.99999625">
We use the training data from EuroParl provided
by the task organizers for the 5 different language
pairs. We participate in all the language competi-
tions. We refer to our system as T3-COLEUR.
</bodyText>
<subsectionHeader confidence="0.881494">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.9906265">
Table 2 shows our system results on Task 3, spec-
ified by languages.
</bodyText>
<subsectionHeader confidence="0.998427">
4.4 Error Analysis and Discussion
</subsectionHeader>
<bodyText confidence="0.999985444444444">
As shown in Table 2, our system T3-COLEUR
ranks the highest for the French, German and Ital-
ian language tasks on both best and oot. However
the overall F-measures are very low. Our system
ranks last for Dutch among 3 systems and it is
middle of the pack for the Spanish language task.
In general we note that the results for oot are nat-
urally higher than for BEST since by design it is a
more relaxed measure.
</bodyText>
<sectionHeader confidence="0.999886" genericHeader="related work">
5 Related works
</sectionHeader>
<bodyText confidence="0.999916388888889">
Our work mainly investigates the influence of
WSD on providing machine translation candi-
dates. Carpuat &amp; Wu (2007) and Chan et al.(2007)
show WSD improves MT. However, in (Carpuat
&amp; Wu, 2007) classical WSD is missing by ignor-
ing predefined senses. They treat translation can-
didates as sense labels, then find linguistic fea-
tures in the English side, and cast the disambigua-
tion process as a classification problem. Of rele-
vance also to our work is that related to the task
of English monolingual lexical substitution. For
example some of the approaches that participated
in the SemEval 2007 excercise include the follow-
ing. Yuret (2007) used a statistical language model
based on a large corpus to assign likelihoods to
each candidate substitutes for a target word in a
sentence. Martinez et al. (2007) uses WordNet to
find candidate substitutes, produce word sequence
including substitutes. They rank the substitutes by
ranking the word sequence including that substi-
tutes using web queries. In (Giuliano C. et al.,
2007), they extract synonyms from dictionaries.
They have 2 ways of ranking of the synonyms:
by similarity metric based on LSA and by occur-
rence in a large 5-gram web corpus. Dahl et al.
(2007) also extract synonyms from dictionaries.
They present two systems. The first one scores
substitutes based on how frequently the local con-
text match the target word. The second one in-
corporates cosine similarity. Finally, Hassan et al.
(2007) extract candidates from several linguistic
resources, and combine many techniques and ev-
idences to compute the scores such as machine
translation, most common sense, language model
and so on to pick the most suitable lexical substi-
tution candidates.
</bodyText>
<sectionHeader confidence="0.992749" genericHeader="conclusions">
6 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.9980786875">
In this paper we presented a word sense disam-
biguation based system for multilingual lexical
substitution. The approach relies on having a
WSD system for English and an automatic word
alignment method. Crucially the approach relies
on having parallel corpora. For Task 2 we apply
a supervised WSD system to derive the English
word senses. For Task 3, we apply an unsuper-
vised approach to the training and test data. Both
of our systems that participated in Task 2 achieve
a decent ranking among the participating systems.
For Task 3 we achieve the highest ranking on sev-
eral of the language pairs: French, German and
Italian.
In the future, we would like to investigate the
usage of the Spanish and Italian WordNets for the
</bodyText>
<page confidence="0.992111">
131
</page>
<table confidence="0.998789714285714">
Language best oot
P R rank P R rank
Dutch 10.71 10.56 3/3 21.47 21.27 3/3
Spanish 19.78 19.59 3/7 35.84 35.46 5/7
French 21.96 21.73 1/7 49.44 48.96 1/5
German 13.79 13.63 1/3 33.21 32.82 1/3
Italian 15.55 15.4 1/3 40.7 40.34 1/3
</table>
<tableCaption confidence="0.999767">
Table 2: Results of T3-COLEUR per language on Task 3 Test set
</tableCaption>
<bodyText confidence="0.9927">
task. We would like to also expand our exami-
nation to other sources of bilingual data such as
comparable corpora. Finally, we would like to in-
vestigate using unsupervised clustering of senses
(Word Sense Induction) methods in lieu of the
WSD approaches that rely on WordNet.
</bodyText>
<sectionHeader confidence="0.995993" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986850131578947">
CARPUAT M. &amp; WU D. (2007). Improving statis-
tical machine translation using word sense disam-
biguation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), p. 61–72, Prague,
Czech Republic: Association for Computational
Linguistics.
CHAN Y. S., NG H. T. &amp; CHIANG D. (2007). Word
sense disambiguation improves statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
p. 33–40, Prague, Czech Republic: Association for
Computational Linguistics.
DAHL G., FRASSICA A. &amp; WICENTOWSKI R. (2007).
SW-AG: Local Context Matching for English Lexi-
cal Substitution. In Proceedings of the 4th workshop
on Semantic Evaluations (SemEval-2007), Prague,
Czech Republic.
FELLBAUM C. (1998). ”wordnet: An electronic lexical
database”. MIT Press.
GIULIANO C., GLIOZZO A. &amp; STRAPPARAVA C
(2007). FBK-irst: Lexical Substitution Task Ex-
ploiting Domain and Syntagmatic Coherence. In
Proceedings of the 4th workshop on Semantic Eval-
uations (SemEval-2007), Prague, Czech Republic.
GUO W. &amp; DIAB M. (2009). ”Improvements to mono-
lingual English word sense disambiguation”. In
ACL Workshop on Semantics Evaluations.
GUO W. &amp; DIAB M. (2010). ”Combining orthogonal
monolingual and multilingual sources of evidence
for All Words WSD”. In ACL 2010.
HASSAN S., CSOMAI A., BANEA C., SINHA R. &amp;
MIHALCEA R. (2007). UNT: SubFinder: Combin-
ing Knowledge Sources for Automatic Lexical Sub-
stitution. In Proceedings of the 4th workshop on Se-
mantic Evaluations (SemEval-2007), Prague, Czech
Republic.
IDE N. &amp; V RONIS J. (1998). Word sense disambigua-
tion: The state of the art. In Computational Linguis-
tics, p. 1–40.
JIANG J. &amp; CONRATH. D. (1997). Semantic similar-
ity based on corpus statistics and lexical taxonomy.
In Proceedings of the International Conference on
Research in Computational Linguistics, Taiwan.
LEACOCK C. &amp; CHODOROW M. (1998). Combining
local context and wordnet sense similarity for word
sense identification. In WordNet, An Electronic Lex-
ical Database: The MIT Press.
LEFEVER C. &amp; HOSTE V. (2009). SemEval-2010
Task 3: Cross-lingual Word Sense Disambiguation.
In Proceedings of the NAACL HLT Workshop on Se-
mantic Evaluations: Recent Achievements and Fu-
ture Directions, Boulder, Colorado.
LESK M. (1986). Automatic sense disambiguation us-
ing machine readable dictionaries: How to tell a pine
cone from an ice cream cone. In In Proceedings of
the SIGDOC Conference, Toronto.
MARTINEZ D., KIM S. &amp; BALDWIN T. (2007).
MELB-MKB: Lexical Substitution system based
on Relatives in Context In Proceedings of the
4th workshop on Semantic Evaluations (SemEval-
2007), Prague, Czech Republic.
M. PALMER, C. FELLBAUM S. C. L. D. &amp; DANG
H. (2001). English tasks: all-words and verb lex-
ical sample. In In Proceedings of ACL/SIGLEX
Senseval-2, Toulouse, France.
MIHALCEA R. (2005). Unsupervised large-vocabulary
word sense disambiguation with graph-based algo-
rithms for sequence data labeling. In Proceedings
of Human Language Technology Conference and
Conference on Empirical Methods in Natural Lan-
guage Processing, p. 411–418, Vancouver, British
Columbia, Canada: Association for Computational
Linguistics.
MILLER G. A. (1990). Wordnet: a lexical database for
132 english. In Communications of the ACM, p. 39–41.
NAVIGLI R. (2009). Word sense disambiguation: a
survey. In ACM Computing Surveys, p. 1–69: ACM
Press.
OCH F. J. &amp; NEY H. (2003). A systematic compari-
son of various statistical alignment models. Compu-
tational Linguistics, 29(1), 19–51.
PEDERSEN B. &amp; PATWARDHAN (2005). Maximizing
semantic relatedness to perform word sense disam-
biguation. In University of Minnesota Supercomput-
ing Institute Research Report UMSI 2005/25, Min-
nesotta.
PRADHAN S., LOPER E., DLIGACH D. &amp; PALMER
M. (2007). Semeval-2007 task-17: English lexi-
cal sample, srl and all words. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), p. 87–92, Prague, Czech Re-
public: Association for Computational Linguistics.
SINHA R. &amp; MIHALCEA R. (2007). Unsupervised
graph-based word sense disambiguation using mea-
sures of word semantic similarity. In Proceedings
of the IEEE International Conference on Semantic
Computing (ICSC 2007), Irvine, CA.
SINHA R., MCCARTHY D. &amp; MIHALCEA R. (2009).
SemEval-2010 Task 2: Cross-Lingual Lexical Sub-
stitution. In Proceedings of the NAACL HLT Work-
shop on Semantic Evaluations: Recent Achieve-
ments and Future Directions, Irvine, CA.
SNYDER B. &amp; PALMER M. (2004). The english all-
words task. In R. MIHALCEA &amp; P. EDMONDS,
Eds., Senseval-3: Third International Workshop on
the Evaluation of Systems for the Semantic Analysis
of Text, p. 41–43, Barcelona, Spain: Association for
Computational Linguistics.
YURET D. (2007). KU: Word sense disambiguation
by substitution. In Proceedings of the 4th workshop
on Semantic Evaluations (SemEval-2007), Prague,
Czech Republic.
</reference>
<page confidence="0.999148">
133
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.092824">
<title confidence="0.639024">COLEUR and COLSLM: A WSD approach to Multilingual Lexical Substitution, Tasks 2 and 3 SemEval 2010</title>
<author confidence="0.995608">Weiwei Guo</author>
<author confidence="0.995608">Mona Diab</author>
<affiliation confidence="0.999865">Center for Computational Learning Systems Columbia University</affiliation>
<abstract confidence="0.999627542857143">ambiguous words in one language probably translate to different lexical items in another language. Hence, our approach relies on two crucial components: a WSD module for the source language (our target test words, in our case these are the English target test words) and an automatic word alignment module to discover the target word sense correspondences with the foreign words in a second language. Our approach to both tasks is unsupervised since we don’t have real training data annotated with the target words and their corresponding translations into l2 at the onset of the problem. Accordingly, at training time, we rely on automatically tagging large amounts of English data (target word instances) with their relevant senses and finding their l2 correspondences based on automatically induced word alignments. Each of these English sense and l2 correspondence pairs has an associated translation probability value depending on frequency of co-occurrence. This information is aggregated in a look-up table over the entire training set. An entry in the table would have a target word sense type paired with all the observed translation correspondences l2 word types. Each of the l2 word types has a probability of translation that is calculated as a normalized weighted average of all the instances of this l2 word type with the English sense aggregated across the whole parallel corpus. This process results in an English word sense translation table (WSTT). The word senses are derived from Word- Net (Fellbaum, 1998). We expand the English word sense entry correspondences by adding the translations of the members of target word sense synonym set as listed in WordNet.</abstract>
<note confidence="0.629152285714286">For alignment, we specifically use the GIZA++ software for inducing word alignments across the parallel corpora (Och &amp; Ney, 2003). We apply GIZA++ to the parallel corpus in both directions English to l2 and l2 to English then take only the of the two alignment sets, hence fo- 129</note>
<abstract confidence="0.973396333333333">In this paper, we present a word sense disambiguation (WSD) based system for multilingual lexical substitution. Our method depends on having a WSD system for English and an automatic word alignment method. Crucially the approach relies on having parallel corpora. For Task (Sinha 2009) we apply a supervised WSD system to derive the English word senses. For Task 3 (Lefever &amp; Hoste, 2009), we apply an unsupervised approach to the training and test data. Both of our systems that participated in Task 2 achieve a decent ranking among the participating systems. For Task 3 we achieve the highest ranking on several of the language pairs: French, German and Italian.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M CARPUAT</author>
<author>D WU</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>61--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic:</location>
<marker>CARPUAT, WU, 2007</marker>
<rawString>CARPUAT M. &amp; WU D. (2007). Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), p. 61–72, Prague, Czech Republic: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S CHAN</author>
<author>H T NG</author>
<author>D CHIANG</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic:</location>
<marker>CHAN, NG, CHIANG, 2007</marker>
<rawString>CHAN Y. S., NG H. T. &amp; CHIANG D. (2007). Word sense disambiguation improves statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, p. 33–40, Prague, Czech Republic: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G DAHL</author>
<author>A FRASSICA</author>
<author>R WICENTOWSKI</author>
</authors>
<title>SW-AG: Local Context Matching for English Lexical Substitution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>DAHL, FRASSICA, WICENTOWSKI, 2007</marker>
<rawString>DAHL G., FRASSICA A. &amp; WICENTOWSKI R. (2007). SW-AG: Local Context Matching for English Lexical Substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C FELLBAUM</author>
</authors>
<title>wordnet: An electronic lexical database”.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>FELLBAUM, 1998</marker>
<rawString>FELLBAUM C. (1998). ”wordnet: An electronic lexical database”. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C GIULIANO</author>
<author>A GLIOZZO</author>
<author>C STRAPPARAVA</author>
</authors>
<title>FBK-irst: Lexical Substitution Task Exploiting Domain and Syntagmatic Coherence.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>GIULIANO, GLIOZZO, STRAPPARAVA, 2007</marker>
<rawString>GIULIANO C., GLIOZZO A. &amp; STRAPPARAVA C (2007). FBK-irst: Lexical Substitution Task Exploiting Domain and Syntagmatic Coherence. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W GUO</author>
<author>M DIAB</author>
</authors>
<title>Improvements to monolingual English word sense disambiguation”.</title>
<date>2009</date>
<booktitle>In ACL Workshop on Semantics Evaluations.</booktitle>
<marker>GUO, DIAB, 2009</marker>
<rawString>GUO W. &amp; DIAB M. (2009). ”Improvements to monolingual English word sense disambiguation”. In ACL Workshop on Semantics Evaluations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W GUO</author>
<author>M DIAB</author>
</authors>
<title>Combining orthogonal monolingual and multilingual sources of evidence for All Words WSD”.</title>
<date>2010</date>
<booktitle>In ACL</booktitle>
<marker>GUO, DIAB, 2010</marker>
<rawString>GUO W. &amp; DIAB M. (2010). ”Combining orthogonal monolingual and multilingual sources of evidence for All Words WSD”. In ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S HASSAN</author>
<author>A CSOMAI</author>
<author>C BANEA</author>
<author>R SINHA</author>
<author>R MIHALCEA</author>
</authors>
<title>UNT: SubFinder: Combining Knowledge Sources for Automatic Lexical Substitution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>HASSAN, CSOMAI, BANEA, SINHA, MIHALCEA, 2007</marker>
<rawString>HASSAN S., CSOMAI A., BANEA C., SINHA R. &amp; MIHALCEA R. (2007). UNT: SubFinder: Combining Knowledge Sources for Automatic Lexical Substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N IDE</author>
<author>V RONIS J</author>
</authors>
<title>Word sense disambiguation: The state of the art.</title>
<date>1998</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>1--40</pages>
<marker>IDE, J, 1998</marker>
<rawString>IDE N. &amp; V RONIS J. (1998). Word sense disambiguation: The state of the art. In Computational Linguistics, p. 1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Conference on Research in Computational Linguistics,</booktitle>
<marker>D, 1997</marker>
<rawString>JIANG J. &amp; CONRATH. D. (1997). Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of the International Conference on Research in Computational Linguistics, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C LEACOCK</author>
<author>M CHODOROW</author>
</authors>
<title>Combining local context and wordnet sense similarity for word sense identification. In WordNet, An Electronic Lexical Database:</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<marker>LEACOCK, CHODOROW, 1998</marker>
<rawString>LEACOCK C. &amp; CHODOROW M. (1998). Combining local context and wordnet sense similarity for word sense identification. In WordNet, An Electronic Lexical Database: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C LEFEVER</author>
<author>V HOSTE</author>
</authors>
<title>SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions,</booktitle>
<location>Boulder, Colorado.</location>
<marker>LEFEVER, HOSTE, 2009</marker>
<rawString>LEFEVER C. &amp; HOSTE V. (2009). SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M LESK</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In</title>
<date>1986</date>
<booktitle>In Proceedings of the SIGDOC Conference,</booktitle>
<location>Toronto.</location>
<marker>LESK, 1986</marker>
<rawString>LESK M. (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In In Proceedings of the SIGDOC Conference, Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D MARTINEZ</author>
<author>S KIM</author>
<author>T BALDWIN</author>
</authors>
<title>MELB-MKB: Lexical Substitution system based on Relatives in Context</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval2007),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>MARTINEZ, KIM, BALDWIN, 2007</marker>
<rawString>MARTINEZ D., KIM S. &amp; BALDWIN T. (2007). MELB-MKB: Lexical Substitution system based on Relatives in Context In Proceedings of the 4th workshop on Semantic Evaluations (SemEval2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M PALMER</author>
<author>C FELLBAUM S C L D</author>
<author>H DANG</author>
</authors>
<title>English tasks: all-words and verb lexical sample. In</title>
<date>2001</date>
<booktitle>In Proceedings of ACL/SIGLEX Senseval-2,</booktitle>
<location>Toulouse, France.</location>
<marker>PALMER, D, DANG, 2001</marker>
<rawString>M. PALMER, C. FELLBAUM S. C. L. D. &amp; DANG H. (2001). English tasks: all-words and verb lexical sample. In In Proceedings of ACL/SIGLEX Senseval-2, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R MIHALCEA</author>
</authors>
<title>Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>411--418</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada:</location>
<marker>MIHALCEA, 2005</marker>
<rawString>MIHALCEA R. (2005). Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, p. 411–418, Vancouver, British Columbia, Canada: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A MILLER</author>
</authors>
<title>Wordnet: a lexical database for 132 english.</title>
<date>1990</date>
<booktitle>In Communications of the ACM,</booktitle>
<pages>39--41</pages>
<marker>MILLER, 1990</marker>
<rawString>MILLER G. A. (1990). Wordnet: a lexical database for 132 english. In Communications of the ACM, p. 39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R NAVIGLI</author>
</authors>
<title>Word sense disambiguation: a survey. In</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<pages>1--69</pages>
<publisher>ACM Press.</publisher>
<marker>NAVIGLI, 2009</marker>
<rawString>NAVIGLI R. (2009). Word sense disambiguation: a survey. In ACM Computing Surveys, p. 1–69: ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J OCH</author>
<author>H NEY</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>OCH, NEY, 2003</marker>
<rawString>OCH F. J. &amp; NEY H. (2003). A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1), 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B PEDERSEN</author>
<author>PATWARDHAN</author>
</authors>
<title>Maximizing semantic relatedness to perform word sense disambiguation.</title>
<date>2005</date>
<tech>Report UMSI 2005/25, Minnesotta.</tech>
<institution>In University of Minnesota Supercomputing Institute Research</institution>
<marker>PEDERSEN, PATWARDHAN, 2005</marker>
<rawString>PEDERSEN B. &amp; PATWARDHAN (2005). Maximizing semantic relatedness to perform word sense disambiguation. In University of Minnesota Supercomputing Institute Research Report UMSI 2005/25, Minnesotta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S PRADHAN</author>
<author>E LOPER</author>
<author>D DLIGACH</author>
<author>M PALMER</author>
</authors>
<title>Semeval-2007 task-17: English lexical sample, srl and all words.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>87--92</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic:</location>
<marker>PRADHAN, LOPER, DLIGACH, PALMER, 2007</marker>
<rawString>PRADHAN S., LOPER E., DLIGACH D. &amp; PALMER M. (2007). Semeval-2007 task-17: English lexical sample, srl and all words. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), p. 87–92, Prague, Czech Republic: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R SINHA</author>
<author>R MIHALCEA</author>
</authors>
<title>Unsupervised graph-based word sense disambiguation using measures of word semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Semantic Computing (ICSC</booktitle>
<location>Irvine, CA.</location>
<marker>SINHA, MIHALCEA, 2007</marker>
<rawString>SINHA R. &amp; MIHALCEA R. (2007). Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. In Proceedings of the IEEE International Conference on Semantic Computing (ICSC 2007), Irvine, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R SINHA</author>
<author>D MCCARTHY</author>
<author>R MIHALCEA</author>
</authors>
<title>SemEval-2010 Task 2: Cross-Lingual Lexical Substitution.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions,</booktitle>
<location>Irvine, CA.</location>
<marker>SINHA, MCCARTHY, MIHALCEA, 2009</marker>
<rawString>SINHA R., MCCARTHY D. &amp; MIHALCEA R. (2009). SemEval-2010 Task 2: Cross-Lingual Lexical Substitution. In Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, Irvine, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B SNYDER</author>
<author>M PALMER</author>
</authors>
<title>The english allwords task. In</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>41--43</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Barcelona, Spain:</location>
<marker>SNYDER, PALMER, 2004</marker>
<rawString>SNYDER B. &amp; PALMER M. (2004). The english allwords task. In R. MIHALCEA &amp; P. EDMONDS, Eds., Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, p. 41–43, Barcelona, Spain: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D YURET</author>
</authors>
<title>KU: Word sense disambiguation by substitution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>YURET, 2007</marker>
<rawString>YURET D. (2007). KU: Word sense disambiguation by substitution. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>