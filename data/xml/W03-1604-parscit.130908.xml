<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.99915">
Exploiting Paraphrases in a Question Answering System
</title>
<author confidence="0.937789">
Fabio Rinaldi, James Dowdall, Diego Moll´a
Kaarel Kaljurand, Michael Hess Centre for Language Technology,
</author>
<affiliation confidence="0.9989965">
Institute of Computational Linguistics, Macquarie University,
University of Z¨urich Sydney NSW 2109, Australia
</affiliation>
<address confidence="0.513889666666667">
Winterthurerstrasse 190 {diego}@ics.mq.edu.au
CH-8057 Z¨urich, Switzerland
{rinaldi,dowdall,kalju,hess}
</address>
<email confidence="0.96463">
@ifi.unizh.ch
</email>
<sectionHeader confidence="0.994949" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999789636363636">
We present a Question Answering system
for technical domains which makes an in-
telligent use of paraphrases to increase the
likelihood of finding the answer to the user’s
question. The system implements a simple
and efficient logic representation of ques-
tions and answers that maps paraphrases
to the same underlying semantic represen-
tation. Further, paraphrases of technical
terminology are dealt with by a separate
process that detects surface variants.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996584875">
The problem of paraphrases conceals a number of
different linguistic problems, which in our opinion
need to be treated in separate ways. In fact, para-
phrases can happen at various levels in language. Us-
ing the examples provided in the call for papers for
this workshop, we would like to attempt a simple
classification, without any pretense of being exhaus-
tive:
</bodyText>
<listItem confidence="0.648495066666667">
1. Lexical synonymy.
Example: article, paper, publication
2. Morpho-syntactic variants.
a) Oswald killed Kennedy. / Kennedy was killed
by Oswald.
b) Edison invented the light bulb. / Edison’s
invention of the light bulb.
while (a) is purely syntactical (active vs pas-
sive), (b) involves a nominalisation.
3. PP-attachment.
a plant in Alabama / the Alabama plant
4. Comparatives vs superlatives.
be better than anybody else / be the best
5. Subordinate clauses vs separate sentences linked
by anaphoric pronouns.
</listItem>
<bodyText confidence="0.9597835">
The tree healed its wounds by growing new bark.
/ The tree healed its wounds. It grew new bark.
</bodyText>
<sectionHeader confidence="0.992809" genericHeader="introduction">
6. Inference.
</sectionHeader>
<bodyText confidence="0.981094695652174">
The stapler costs $10. / The price of the stapler
is $10.
Where is Thimphu located? / Thimphu is capi-
tal of what country?
Of course combinations of the different types are
possible, e.g. Oswald killed Kennedy / Kennedy
was assassinated by Oswald is a combination of (1)
and (2).
Different types of knowledge and different linguis-
tic resources are needed to deal with each of the
above types. While type (1) can be dealt with us-
ing a resource such as WordNet (Fellbaum, 1998),
type (2) needs effective parsing and mapping of syn-
tactic structures into a common deeper structure,
possibly using a repository of nominalisations like
NOMLEX (Meyers et al., 1998). More complex
approaches are needed for the other types, up to
type (6) where generic world knowledge is required,
for instance to know that being a capital of a country
implies being located in that country. &apos; Such world
knowledge could be expressed in the form of axioms,
like the following:
(X costs Y) iff (the price of X is Y)
</bodyText>
<subsectionHeader confidence="0.950945">
In this paper we focus on the role of paraphrases
in a Question Answering (QA) system targeted at
</subsectionHeader>
<bodyText confidence="0.999918454545455">
&apos;Note that the reverse is not true, and therefore this
is not a perfect paraphrase.
technical manuals. Technical documentation is char-
acterised by vast amounts of domain-specific termi-
nology, which needs to be exploited for providing in-
telligent access to the information contained in the
manuals (Rinaldi et al., 2002b). The approach taken
by QA systems is to allow a user to ask a query (for-
mulated in natural language) and have the system
search a background collection of documents in order
to locate an answer. The field of Question Answer-
ing has flourished in recent years2, in part, due to
the QA track of the TREC competitions (Voorhees
and Harman, 2001). These competitions evaluate
systems over a common data set allowing develop-
ers to benchmark performance in relation to other
competitors.
It is a common assumption that technical termi-
nology is subject to strict controls and cannot vary
within a given editing process. However this assump-
tion proves all too often to be incorrect. Unless edi-
tors are making use of a terminology control system
that forces them to use a specific version of a term,
they will naturally tend to use various paraphrases
to refer to the intended domain concept. Besides in
a query a user could use an arbitrary paraphrases of
the target term, which might happen to be one of
those used in the manual itself or might happen to
be a novel one.
We describe some potential solutions to this prob-
lem, taking our Question Answering system as an ex-
ample. We show which benefits our approach based
on paraphrases bring to the system. So far two dif-
ferent domains have been targeted by the system.
An initial application aims at answering questions
about the Unix man pages (Moll´a et al., 2000a; Moll´a
et al., 2000b). A more complex application targets
the Aircraft Maintenance Manual (AMM) of the Air-
bus A320 (Rinaldi et al., 2002b). Recently we have
started new work, using the Linux HOWTOs as a
new target domain.
In dealing with these domains we have identified
two major obstacles for a QA system, which we can
summarise as follows:
</bodyText>
<listItem confidence="0.9377825">
• The Parsing Problem
• The Paraphrase Problem
</listItem>
<bodyText confidence="0.94976">
The Parsing Problem consists in the increased
difficulty of parsing text in a technical domain due to
domain-specific sublanguage. Various types of multi
word expressions characterise these domains, in par-
ticular referring to specific concepts like tools, parts
or procedures. These multi word expressions might
</bodyText>
<footnote confidence="0.470376">
2Although early work in AI already touched upon the
topic, e.g. (Woods, 1977).
</footnote>
<bodyText confidence="0.999607297297297">
include lexical items which are either unknown to
a generic lexicon (e.g. coax cable) or have a spe-
cific meaning unique to this domain. Abbreviations
and acronyms are another common source of incon-
sistencies. In such cases the parser might either
fail to identify the compound as a phrase and con-
sequently fail to parse the sentence including such
items. Alternatively the parser might attempt to
‘guess’ their lexical category (in the set of open class
categories), leading to an exponential growth of the
number of possible syntactic parses. Not only the in-
ternal structure of the compound can be multi-way
ambiguous, even the boundaries of the compounds
might be difficult to detect and the parsers might
try odd combinations of the tokens belonging to the
compounds with neighbouring tokens.
The Paraphrase Problem resides in the imper-
fect knowledge of users of the systems, who can-
not be expected to be completely familiar with the
domain terminology. Even experienced users, who
know very well the domain, might not remember the
exact wording of a compound and use a paraphrase
to refer to the underlying domain concept. Besides
even in the manual itself, unless the editors have been
forced to use some strict terminology control system,
various paraphrases of the same compound will ap-
pear, and they need to be identified as co-referent.
However, it is not enough to identify all paraphrases
within the manual, novel paraphrases might be cre-
ated by the users each time they query the system.
In the rest of this paper we describe first our Ques-
tion Answering System (in Section 2) and briefly
show how we solved the first of the two problems
described above. Then, in Section 3 we show in de-
tail how the system is capable of coping with the
Paraphrase Problem. Finally in Section 4 we discuss
some related work.
</bodyText>
<sectionHeader confidence="0.903139" genericHeader="method">
2 A Question Answering System for
</sectionHeader>
<subsectionHeader confidence="0.644368">
Technical Domains
</subsectionHeader>
<bodyText confidence="0.999698923076923">
Over the past few years our research group has devel-
oped an Answer Extraction system (ExtrAns) that
works by transforming documents and queries into a
semantic representation called Minimal Logical Form
(MLF) (Moll´a et al., 2000a) and derives the answers
by logical proof from the documents. A full linguis-
tic (syntactic and semantic) analysis, complete with
lexical alternations (synonyms and hyponyms) is per-
formed. While documents are processed in an off-line
stage, the query is processed on-line.
Two real world applications have so far been im-
plemented with the same underlying technology. The
original ExtrAns system (Moll´a et al., 2000b) is used
</bodyText>
<figure confidence="0.808863">
RW
///// a.d electrical coax cable.n4 connects.v062 the.d external antenna.n1 to.o the.d ANT connection.n1 /////
</figure>
<figureCaption confidence="0.980987">
Figure 1: An Example of LG Output
</figureCaption>
<figure confidence="0.996355090909091">
MVp

Os
 Ds
Js
 Ds



Dsu  Ss
Wd
</figure>
<bodyText confidence="0.999063261904762">
to extract answers to arbitrary user queries over the
Unix documentation files (“man pages”). A set of
500+ unedited man pages has been used for this ap-
plication. An on-line demo of ExtrAns can be found
at the project web page.3
More recently we tackled
a different domain, the Air-
plane Maintenance Manu-
als (AMM) of the Air-
bus A320 (Rinaldi et al.,
2002b), which offered the
additional challenges of an
SGML-based format and a
much larger size (120MB).4
Despite being developed
initially for a specific do-
main, ExtrAns has demon-
strated a high level of do-
main independence.
As we work on relatively
small volumes of data we
can afford to process (in
an off-line stage) all the
documents in our collection
rather than just a few se-
lected paragraphs (see Fig-
ure 2). Clearly in some sit-
uations (e.g. processing in-
coming news) such an ap-
proach might not be fea-
sible and paragraph index-
ing techniques would need
to be used. Our current ap-
proach is particularly tar-
geted to small and medium sized collections.
In an initial phase all multi-word expressions
from the domain are collected and structured in
an external resource, which we will refer to as the
TermBase (Rinaldi et al., 2003; Dowdall et al., 2003).
The document sentences (and user queries) are syn-
tactically processed with the Link Grammar (LG)
parser (Sleator and Temperley, 1993) which uses a
</bodyText>
<footnote confidence="0.892522">
3http://www.ifi.unizh.ch/cl/extrans/
4Still considerably smaller than the size of the docu-
ment collections used for TREC
</footnote>
<bodyText confidence="0.999904844444445">
grammar with a wide coverage of English and has
a robust treatment of ungrammatical sentences and
unknown words. The multi-word terms from the the-
saurus are identified and passed to the parser as sin-
gle tokens. This prevents (futile) analysis of the in-
ternal structure of terms (see Figure 1), simplifying
parsing by 46%. This solves the first of the problems
that we have identified in the introduction (“The
Parsing Problem”).
In later stages of processing, a corpus-based ap-
proach (Brill and Resnik, 1994) is used to deal with
ambiguities that cannot be solved with syntactic in-
formation only, in particular attachments of preposi-
tional phrases, gerunds and infinitive constructions.
ExtrAns adopts an anaphora resolution algorithm
(Moll´a et al., 2003) that is based on Lappin and Le-
ass’ approach (Lappin and Leass, 1994). The original
algorithm, which was applied to the syntactic struc-
tures generated by McCord’s Slot Grammar (Mc-
Cord et al., 1992), has been ported to the output of
Link Grammar. So far the resolution is restricted to
sentence-internal pronouns but the same algorithm
can be applied to sentence-external pronouns too.
A lexicon of nominalisations based on NOMLEX
(Meyers et al., 1998) is used for the most important
cases. The main problem here is that the semantic
relationship between the base words (mostly, but not
exclusively, verbs) and the derived words (mostly,
but not exclusively, nouns) is not sufficiently sys-
tematic to allow a derivation lexicon to be compiled
automatically. Only in relatively rare cases is the
relationship as simple as with to edit &lt;a text&gt; H
editor of &lt;a text&gt; / &lt;text&gt; editor, as the effort
that went into building resources such as NOMLEX
also shows.
User queries are processed on-line and converted
into MLFs (possibly expanded by synonyms) and
proved by refutation over the document knowledge
base (see Figure 3). Pointers to the original text at-
tached to the retrieved logical forms allow the system
to identify and highlight those words in the retrieved
sentence that contribute most to that particular an-
swer. When the user clicks on one of the answers
provided, the corresponding document will be dis-
played with the relevant passages highlighted.
</bodyText>
<figure confidence="0.998495285714286">
Document
Term
processing
Linguistic
Analysis
Knowledge
Base
</figure>
<figureCaption confidence="0.96973125">
Figure 2: Off-line
Processing of Docu-
ments
Figure 3: On-line Processing of Queries
</figureCaption>
<figure confidence="0.992642">
Query
Paraphrase
Identification
Linguistic
Analysis
Knowledge
Base
Document
ANSWERS
</figure>
<bodyText confidence="0.99971692">
The meaning of the documents and of the queries
produced by ExtrAns is expressed by means of Mini-
mal Logical Forms (MLFs). The MLFs are designed
so that they can be found for any sentence (using
robust approaches to treat very complex or ungram-
matical sentences), and they are optimized for NLP
tasks that involve the semantic comparison of sen-
tences, such as Answer Extraction.
The expressivity of the MLFs is minimal in the
sense that the main syntactic dependencies between
the words are used to express verb-argument rela-
tions, and modifier and adjunct relations. However,
complex quantification, tense and aspect, temporal
relations, plurality, and modality are not expressed.
One of the effects of this kind of underspecification
is that several natural language queries, although
slightly different in meaning, produce the same logi-
cal form.
The main feature of the MLFs is the use of reifi-
cation (the expression of abstract concepts as con-
crete objects) to achieve flat expressions (Moll´a et
al., 2000b). The MLFs are expressed as conjunc-
tions of predicates with all the variables existentially
bound with wide scope. For example, the MLF of
the sentence “cp will quickly copy the files” is:
</bodyText>
<equation confidence="0.7507426">
(1) holds(e4), object(cp,o1,[x1]),
object(s command,o2,[x1]),
evt(s copy,e4,[x1,x6]),
object(s file,o3,[x6]),
prop(quickly,p3,[e4]).
</equation>
<bodyText confidence="0.994129027777778">
In other words, there is an entity x1 which rep-
resents an object of type cp and of type command,
there is an entity x6 (a file), there is an entity e4,
which represents a copying event where the first ar-
gument is x1 and the second argument is x6, there
is an entity p3 which states that e4 is done quickly,
and the event e4, that is, the copying, holds. The
entities o1, o2, o3, e4, and p3 are the result of reifi-
cation. The reification of the event, e4, has been used
to express that the event is done quickly. The other
entities are not used in this MLF, but other more
complex sentences may need to refer to the reifica-
tion of properties (adjective-modifying adverbs) or
object predicates (non-intersective adjectives such as
the alleged suspect).
ExtrAns finds the answers to the questions by
forming the MLFs of the questions and then run-
ning Prolog’s default resolution mechanism to find
those MLFs that can prove the question. When no
direct proof for the user query is found, the system
is capable of relaxing the proof criteria in a stepwise
manner. First, hyponyms of the query terms will be
added as disjunctions in the logical form of the ques-
tion, thus making it more general but still logically
correct. If that fails, the system will attempt approx-
imate matching, in which the sentence (or sentences)
with the highest overlap of predicates with the query
is retrieved. The (partially) matching sentences are
scored and the best fits are returned. In the case
that this method finds too many answers because
the overlap is too low, the system will attempt key-
word matching, in which syntactic criteria are aban-
doned and only information about word classes is
used. This last step corresponds approximately to a
traditional passage-retrieval methodology with con-
sideration of the POS tags.
</bodyText>
<sectionHeader confidence="0.84616" genericHeader="method">
3 Dealing with Paraphrases
</sectionHeader>
<bodyText confidence="0.9999521">
The system is capable of dealing with paraphrases
at two different levels. On the phrase level, differ-
ent surface realizations (terms) which refer to the
same domain concept will be mapped into a com-
mon identifier (synset identifier). On the sentence
level, paraphrases which involve a (simple) syntactic
transformation will be dealt with by mapping them
into the same logical form. In this section we will
describe these two approaches and discuss ways to
cope with complex types of parapharases.
</bodyText>
<subsectionHeader confidence="0.999842">
3.1 Identifying Terminological Paraphrases
</subsectionHeader>
<bodyText confidence="0.999488444444444">
During the construction of the MLFs, thesaurus
terms are replaced by their synset identifiers. This
results in an implicit ‘terminological normalization’
for the domain. The benefit to the QA process is
an assurance that a query and answer need not in-
volve exactly the same surface realization of a term.
Utilizing the synsets in the semantic representation
means that when the query includes a term, ExtrAns
returns sentences that logically answer the query, in-
</bodyText>
<figureCaption confidence="0.99608">
Figure 4: Term Processing
</figureCaption>
<bodyText confidence="0.97761064516129">
volving any known paraphrase of that term.
For example, the logical form of the query Where
are the stowage compartments installed? is trans-
lated internally into the Horn query (2).
(2) evt(install,A,[B,C]),
object(D,E,[B]),
object(s stowage compartment,G,[C])
This means that a term (belonging to the same
synset as stowage compartment) is involved in an in-
stall event with an anonymous object. If there is
an MLF from the document that can match exam-
ple (2), then it is selected as a candidate answer and
the sentence it originates from is shown to the user.
The process of terminological variation is well
investigated (Ibekwe-SanJuan and Dubois, 2002;
Daille et al., 1996; Ibekwe-Sanjuan, 1998). The
primary focus has been to use linguistically based
variation to expand existing term sets through cor-
pus investigation or to produce domain representa-
tions. A subset of such variations identifies terms
which are strictly synonymous. ExtrAns gathers
these morpho-syntactic variations into synsets. The
sets are augmented with terms exhibiting three
weaker synonymy relations described by Hamon &amp;
Nazarenko (2001). These synsets are organized into
a hyponymy (isa) hierarchy, a small example of which
can be seen in Figure 5. Figure 4 shows a schematic
representation of this process.
The first stage is to normalize any terms that con-
tain punctuation by creating a punctuation free ver-
sion and recording the fact that that the two are
strictly synonymous. Further processing is involved
in terms containing brackets to determine if the
bracketed token is an acronym or simply optional. In
the former case an acronym-free term is created and
the acronym is stored as a synonym of the remain-
ing tokens which contain it as a regular expression.
So evac is synonymous with evacuation and ohsc is
synonymous with overhead stowage compartment. In
cases such as emergency (hard landings) the brack-
eted tokens can not be interpreted as acronyms and
so are not removed.
The synonymy relations are identified using the
terminology tool Fastr (Jacquemin, 2001). Every to-
ken of each term is associated with its part-of-speech,
its morphological root, and its synonyms. Phrasal
rules represent the manner in which tokens combine
to form multi-token terms, and feature-value pairs
carry the token specific information. Metarules li-
cense the relation between two terms by constrain-
ing their phrase structures in conjunction with the
morphological and semantic information on the indi-
vidual tokens.
The metarules can identify simple paraphrases
that result from morpho-syntactic variation (cargo
compartment door −&gt; doors of the cargo compart-
ment), terms with synonymous heads (electrical ca-
ble −&gt; electrical line), terms with synonymous mod-
ifiers (fastener strip −&gt; attachment strip) and both
(functional test −&gt; operational check). For a de-
scription of the frequency and range of types of vari-
ation present in the AMM see Rinaldi et al. (2002a).
</bodyText>
<subsectionHeader confidence="0.999923">
3.2 Identifying Syntactic Paraphrases
</subsectionHeader>
<bodyText confidence="0.999949458333333">
An important effect of using a simplified semantic-
based representation such as the Minimal Logical
Forms is that various types of syntactic variations
are automatically captured by a common representa-
tion. This ensures that many potential paraphrases
in a user query can map to the same answer into the
manual.
For example the question shown in Figure 6 can
be answered thanks to the combination of two fac-
tors. On the lexical level ExtrAns knows that APU
is an abbreviation of Auxiliary Power Unit, while on
the syntactic level the active and passive voices (sup-
plies vs supplied with) map into the same underlying
representation (the same MLF).
Another type of paraphrase which can be detected
at this level is the kind that was classified as type (3)
in the introduction. For example the question: Is
the sensor connected to the APU ECB?, can locate
the answer This sensor is connected to the Elec-
tronic Control Box (ECB) of the APU. This has been
achieved by introducing meaning postulates that op-
erate at the level of the MLFs (such as “any predicate
that affects an object will also affect the of-modifiers
of that object”).
</bodyText>
<subsectionHeader confidence="0.998079">
3.3 Weaker Types of Paraphrases
</subsectionHeader>
<bodyText confidence="0.9997178">
When the thesaurus definition of terminological syn-
onymy fails to locate an answer from the docu-
ment collection, ExtrAns explores weaker types of
paraphrases, where the equivalence between the two
terms might not be complete.
</bodyText>
<figure confidence="0.99889725">
Document
Fastr
Thesaurus
Term
Extraction
Hyponymy
ExtrAns
TERM
</figure>
<figureCaption confidence="0.999986">
Figure 5: A Sample of the TermBase
Figure 6: Active vs Passive Voice
</figureCaption>
<bodyText confidence="0.70925925">
doors of the cargo compartment
cargo compartment door
cargo comparment doors
cargo-compartment door
</bodyText>
<figure confidence="0.983030461538461">
emergency evacuation (evac)
emergency evacuation
evacuation
evac
3
2
1
overhead stowage compartment
OHSC
stowage compartment
6
5
emergency ( hard landings )
emergency hard landings
emergency hard landing
7
fastner strip
attachment strip
electrical cable
electrical line
8
functional test
operational check
door functional test
9
10
</figure>
<page confidence="0.514763">
11
</page>
<bodyText confidence="0.96035925">
First, ExtrAns makes use of the hyponymy rela-
tions, which can be considered as sort of unidirec-
tional paraphrases. Instead of looking for synset
members, the query is reformulated to included hy-
ponyms and hyperonyms of the terms:
(3) (object(s stowage compartment,A,[B]);
object(s overhead stowage compartment,A,[B])),
evt(install,C,[D,B]),
object(E,F,[D|G])
Now the alternative objects are in a logical OR rela-
tion. This query finds the answer in Figure 7 (where
stowage compartment is a hyperonym of overhead
stowage compartment).
We have implemented a very simple ad-hoc algo-
rithm to determine lexical hyponymy between terms.
Term A is a hyponym of term B if (i) A has more to-
kens than B, (ii) all the tokens of B are present in A,
and (iii) both terms have the same head. There are
three provisions. First, ignore terms with dashes and
brackets as cargo compartment is not a hyponym of
cargo - compartment and this relation (synonymy) is
already known from the normalisation process. Sec-
ond, compare lemmatised versions of the terms to
capture that stowage compartment is a hyperonym
of overhead stowage compartments. Finally, the head
of a term is the rightmost non-symbol token (i.e. a
word) which can be determined from the part-of-
speech tags. This hyponymy relation is compara-
ble to the insertion variations defined by Daille et
al. (1996).
The expressivity of the MLF can further be ex-
panded through the use of meaning postulates of the
type: “If x is installed in y, then x is in y”. This
ensures that the query Where are the equipment and
furnishings? extracts the answer The equipment and
furnishings are installed in the cockpit.
</bodyText>
<sectionHeader confidence="0.99998" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999007538461538">
The importance of detecting paraphrasing in Ques-
tion Answering has been shown dramatically in
TREC9 by the Falcon system (Harabagiu et al.,
2001), which made use of an ad-hoc module capable
of caching answers and detecting question similar-
ity. As in that particular evaluation the organisers
deliberately used a set of paraphrases of the same
questions, such approach certainly helped in boost-
ing the performance of the system. In an environ-
ment where the same question (in different formula-
tions) is likely to be repeated a number of times, a
module capable of detecting paraphrases can signif-
icantly improve the performance of a Question An-
</bodyText>
<figureCaption confidence="0.997544">
Figure 7: Overhead stowage compartment is a Hyponym of Stowage compartment
</figureCaption>
<bodyText confidence="0.982755153846154">
swering system.
Another example of application of paraphrases for
Question Answering is given in (Murata and Isahara,
2001), which further argues for the importance of
paraphrases for other applications such Summarisa-
tion, error correction and speech generation.
Our approach for the acquisition of terminological
paraphrases might have some points in common with
the approach described in (Terada and Tokunaga,
2001). The motivation that they bring forward for
the necessity of identifying abbreviations is related to
the problem that we have called “the Parsing Prob-
lem”.
A very different approach to paraphrases is taken
in (Takahashi et al., 2001) where they formulate the
problem as a special case of Machine Translation,
where the source and target language are the same
but special rules, based on different parameters, li-
cense different types of surface realizations.
Hamon &amp; Nazarenko (2001) explore the termino-
logical needs of consulting systems. This type of IR
guides the user in query/keyword expansion or pro-
poses various levels of access into the document base
on the original query. A method of generating three
types of synonymy relations is investigated using gen-
eral language and domain specific dictionaries.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.968225">
Automatic recognition of paraphrases is an effec-
tive technique to ease the information access bur-
den in a technical domain. We have presented some
techniques that we have adopted in a Question An-
swering system for dealing with paraphrases. These
techniques range from the detection of lexical para-
phrases and terminology variants, to the use of a
simplified logical form that provides the same repre-
sentation for morpho-syntactic paraphrases, and the
use of meaning postulates for paraphrases that re-
quire inferences.
</bodyText>
<sectionHeader confidence="0.998887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746322033898">
Eric Brill and Philip Resnik. 1994. A rule-based
approach to prepositional phrase attachment dis-
ambiguation. In Proc. COLING ’94, volume 2,
pages 998–1004, Kyoto, Japan.
Beatrice Daille, Benot Habert, Christian Jacquemin,
and Jean Royaut´e. 1996. Empirical observation of
term variations and principles for their description.
Terminology, 3(2):197–258.
James Dowdall, Fabio Rinaldi, Fidelia Ibekwe-
SanJuan, and Eric SanJuan. 2003. Complex
structuring of term variants for Question Answer-
ing. In Proc. ACL-2003 Workshop on Multiword
Expressions, Sapporo, Japan.
Christiane Fellbaum 1998. WordNet: an electronic
lexical database. MIT Press, Cambridge, MA.
Thierry Hamon and Adeline Nazarenko. 2001. De-
tection of synonymy links between terms: Experi-
ment and results. In Didier Bourigault, Christian
Jacquemin, and Marie-Claude L’Homme, editors,
Recent Advances in Computational Terminology,
pages 185–208. John Benjamins Publishing Com-
pany.
Sanda Harabagiu, Dan Moldovan, Marius Pa¸sca,
Rada Mihalcea, Mihai Surdeanu, Razvan Bunescu,
Roxana Girju, Vasile Rus, and Paul Morarescu.
2001. FALCON: Boosting knowledge for answer
engines. In Voorhees and Harman (Voorhees and
Harman, 2001).
Fidelia Ibekwe-SanJuan and Cyrille Dubois. 2002.
Can Syntactic Variations Highlight Semantic
Links Between Domain Topics? In Proceedings
of the 6th International Conference on Terminol-
ogy and Knowledge Engineering (TKE02), pages
57–64, Nancy, August.
Fidelia Ibekwe-Sanjuan. 1998. Terminological Vari-
ation, a Means of Identifying Research Topics from
Texts. In Proceedings of COLING-ACL, pages
571–577, Quebec,Canada, August.
Christian Jacquemin. 2001. Spotting and Discover-
ing Terms through Natural Language Processing.
MIT Press.
Shalom Lappin and Herbert J. Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Com-
putational Linguistics, 20(4):535–561.
Michael McCord, Arendse Bernth, Shalom Lap-
pin, and Wlodek Zadrozny. 1992. Natural lan-
guage processing within a slot grammar frame-
work. International Journal on Artificial Intelli-
gence Tools, 1(2):229–277.
Adam Meyers, Catherine Macleod, Roman Yangar-
ber, Ralph Grishman, Leslie Barrett, and Ruth
Reeves. 1998. Using NOMLEX to produce
nominalization patterns for information extrac-
tion. In Proceedings: the Computational Treat-
ment of Nominals, Montreal, Canada, (Coling-
ACL98 workshop), August.
Diego Moll´a, Gerold Schneider, Rolf Schwitter, and
Michael Hess. 2000a. Answer Extraction using
a Dependency Grammar in ExtrAns. Traitement
Automatique de Langues (T.A.L.), Special Issue
on Dependency Grammar, 41(1):127–156.
Diego Moll´a, Rolf Schwitter, Michael Hess, and
Rachel Fournier. 2000b. Extrans, an answer ex-
traction system. T.A.L. special issue on Informa-
tion Retrieval oriented Natural Language Process-
ing.
Diego Moll´a, Rolf Schwitter, Fabio Rinaldi, James
Dowdall, and Michael Hess. 2003. Anaphora res-
olution in ExtrAns. In Proceedings of the Interna-
tional Symposium on Reference Resolution and Its
Applications to Question Answering and Summa-
rization, 23–25 June, Venice, Italy.
Masaki Murata and Hitoshi Isahara. 2001. Univer-
sal model for paraphrasing - using transformation
based on a defined criteria. In Proceedings of the
NLPRS2001 Workshop on Automatic Paraphras-
ing: Theories and Applications.
Fabio Rinaldi, James Dowdall, Michael Hess, Kaarel
Kaljurand, Mare Koit, Kadri Vider, and Neeme
Kahusk. 2002a. Terminology as Knowledge in An-
swer Extraction. In Proceedings of the 6th Interna-
tional Conference on Terminology and Knowledge
Engineering (TKE02), pages 107–113, Nancy, 28–
30 August.
Fabio Rinaldi, James Dowdall, Michael Hess, Diego
Moll´a, and Rolf Schwitter. 2002b. Towards An-
swer Extraction: an application to Technical Do-
mains. In ECAI2002, European Conference on Ar-
tificial Intelligence, Lyon, 21–26 July.
Fabio Rinaldi, James Dowdall, Michael Hess, Kaarel
Kaljurand, and Magnus Karlsson. 2003. The Role
of Technical Terminology in Question Answering.
In Proceedings of TIA-2003, Terminologie et In-
telligence Artificielle, Strasbourg, April.
Daniel D. Sleator and Davy Temperley. 1993. Pars-
ing English with a link grammar. In Proc. Third
International Workshop on Parsing Technologies,
pages 277–292.
Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, and
Kentaro Inui. 2001. Kura: A revision-based
lexico-structural paraphrasing engine. In Proceed-
ings of the NLPRS2001 Workshop on Automatic
Paraphrasing: Theories and Applications.
Akira Terada and Takenobu Tokunaga. 2001. Au-
tomatic disabbreviation by using context informa-
tion. In Proceedings of the NLPRS2001 Workshop
on Automatic Paraphrasing: Theories and Appli-
cations.
Ellen M. Voorhees and Donna Harman, editors.
2001. Proceedings of the Ninth Text REtrieval
Conference (TREC-9), Gaithersburg, Maryland,
November 13-16, 2000.
W.A. Woods. 1977. Lunar rocks in natural English:
Explorations in Natural Language Question An-
swering. In A. Zampolli, editor, Linguistic Struc-
tures Processing, volume 5 of Fundamental Studies
in Computer Science, pages 521–569. North Hol-
land.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.408175">
<title confidence="0.999995">Exploiting Paraphrases in a Question Answering System</title>
<author confidence="0.999893">Fabio Rinaldi</author>
<author confidence="0.999893">James Diego</author>
<affiliation confidence="0.85747525">Kaarel Kaljurand, Michael Centre for Language Institute of Computational Macquarie University of Sydney NSW 2109, Winterthurerstrasse</affiliation>
<address confidence="0.889807">CH-8057 Z¨urich,</address>
<email confidence="0.994679">@ifi.unizh.ch</email>
<abstract confidence="0.999386">We present a Question Answering system for technical domains which makes an intelligent use of paraphrases to increase the likelihood of finding the answer to the user’s question. The system implements a simple and efficient logic representation of questions and answers that maps paraphrases to the same underlying semantic representation. Further, paraphrases of technical terminology are dealt with by a separate process that detects surface variants.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Philip Resnik</author>
</authors>
<title>A rule-based approach to prepositional phrase attachment disambiguation.</title>
<date>1994</date>
<booktitle>In Proc. COLING ’94,</booktitle>
<volume>2</volume>
<pages>998--1004</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="10148" citStr="Brill and Resnik, 1994" startWordPosition="1675" endWordPosition="1678">//www.ifi.unizh.ch/cl/extrans/ 4Still considerably smaller than the size of the document collections used for TREC grammar with a wide coverage of English and has a robust treatment of ungrammatical sentences and unknown words. The multi-word terms from the thesaurus are identified and passed to the parser as single tokens. This prevents (futile) analysis of the internal structure of terms (see Figure 1), simplifying parsing by 46%. This solves the first of the problems that we have identified in the introduction (“The Parsing Problem”). In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. ExtrAns adopts an anaphora resolution algorithm (Moll´a et al., 2003) that is based on Lappin and Leass’ approach (Lappin and Leass, 1994). The original algorithm, which was applied to the syntactic structures generated by McCord’s Slot Grammar (McCord et al., 1992), has been ported to the output of Link Grammar. So far the resolution is restricted to sentence-internal pronouns but the same algorithm can be applied to</context>
</contexts>
<marker>Brill, Resnik, 1994</marker>
<rawString>Eric Brill and Philip Resnik. 1994. A rule-based approach to prepositional phrase attachment disambiguation. In Proc. COLING ’94, volume 2, pages 998–1004, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
<author>Benot Habert</author>
<author>Christian Jacquemin</author>
<author>Jean Royaut´e</author>
</authors>
<title>Empirical observation of term variations and principles for their description.</title>
<date>1996</date>
<journal>Terminology,</journal>
<volume>3</volume>
<issue>2</issue>
<marker>Daille, Habert, Jacquemin, Royaut´e, 1996</marker>
<rawString>Beatrice Daille, Benot Habert, Christian Jacquemin, and Jean Royaut´e. 1996. Empirical observation of term variations and principles for their description. Terminology, 3(2):197–258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Dowdall</author>
<author>Fabio Rinaldi</author>
<author>Fidelia IbekweSanJuan</author>
<author>Eric SanJuan</author>
</authors>
<title>Complex structuring of term variants for Question Answering.</title>
<date>2003</date>
<booktitle>In Proc. ACL-2003 Workshop on Multiword Expressions,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="9370" citStr="Dowdall et al., 2003" startWordPosition="1553" endWordPosition="1556">k on relatively small volumes of data we can afford to process (in an off-line stage) all the documents in our collection rather than just a few selected paragraphs (see Figure 2). Clearly in some situations (e.g. processing incoming news) such an approach might not be feasible and paragraph indexing techniques would need to be used. Our current approach is particularly targeted to small and medium sized collections. In an initial phase all multi-word expressions from the domain are collected and structured in an external resource, which we will refer to as the TermBase (Rinaldi et al., 2003; Dowdall et al., 2003). The document sentences (and user queries) are syntactically processed with the Link Grammar (LG) parser (Sleator and Temperley, 1993) which uses a 3http://www.ifi.unizh.ch/cl/extrans/ 4Still considerably smaller than the size of the document collections used for TREC grammar with a wide coverage of English and has a robust treatment of ungrammatical sentences and unknown words. The multi-word terms from the thesaurus are identified and passed to the parser as single tokens. This prevents (futile) analysis of the internal structure of terms (see Figure 1), simplifying parsing by 46%. This sol</context>
</contexts>
<marker>Dowdall, Rinaldi, IbekweSanJuan, SanJuan, 2003</marker>
<rawString>James Dowdall, Fabio Rinaldi, Fidelia IbekweSanJuan, and Eric SanJuan. 2003. Complex structuring of term variants for Question Answering. In Proc. ACL-2003 Workshop on Multiword Expressions, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2326" citStr="Fellbaum, 1998" startWordPosition="358" endWordPosition="359"> linked by anaphoric pronouns. The tree healed its wounds by growing new bark. / The tree healed its wounds. It grew new bark. 6. Inference. The stapler costs $10. / The price of the stapler is $10. Where is Thimphu located? / Thimphu is capital of what country? Of course combinations of the different types are possible, e.g. Oswald killed Kennedy / Kennedy was assassinated by Oswald is a combination of (1) and (2). Different types of knowledge and different linguistic resources are needed to deal with each of the above types. While type (1) can be dealt with using a resource such as WordNet (Fellbaum, 1998), type (2) needs effective parsing and mapping of syntactic structures into a common deeper structure, possibly using a repository of nominalisations like NOMLEX (Meyers et al., 1998). More complex approaches are needed for the other types, up to type (6) where generic world knowledge is required, for instance to know that being a capital of a country implies being located in that country. &apos; Such world knowledge could be expressed in the form of axioms, like the following: (X costs Y) iff (the price of X is Y) In this paper we focus on the role of paraphrases in a Question Answering (QA) syste</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum 1998. WordNet: an electronic lexical database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Hamon</author>
<author>Adeline Nazarenko</author>
</authors>
<title>Detection of synonymy links between terms: Experiment and results.</title>
<date>2001</date>
<booktitle>Recent Advances in Computational Terminology,</booktitle>
<pages>185--208</pages>
<editor>In Didier Bourigault, Christian Jacquemin, and Marie-Claude L’Homme, editors,</editor>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="17387" citStr="Hamon &amp; Nazarenko (2001)" startWordPosition="2836" endWordPosition="2839">date answer and the sentence it originates from is shown to the user. The process of terminological variation is well investigated (Ibekwe-SanJuan and Dubois, 2002; Daille et al., 1996; Ibekwe-Sanjuan, 1998). The primary focus has been to use linguistically based variation to expand existing term sets through corpus investigation or to produce domain representations. A subset of such variations identifies terms which are strictly synonymous. ExtrAns gathers these morpho-syntactic variations into synsets. The sets are augmented with terms exhibiting three weaker synonymy relations described by Hamon &amp; Nazarenko (2001). These synsets are organized into a hyponymy (isa) hierarchy, a small example of which can be seen in Figure 5. Figure 4 shows a schematic representation of this process. The first stage is to normalize any terms that contain punctuation by creating a punctuation free version and recording the fact that that the two are strictly synonymous. Further processing is involved in terms containing brackets to determine if the bracketed token is an acronym or simply optional. In the former case an acronym-free term is created and the acronym is stored as a synonym of the remaining tokens which contai</context>
<context position="24476" citStr="Hamon &amp; Nazarenko (2001)" startWordPosition="3977" endWordPosition="3980">for the acquisition of terminological paraphrases might have some points in common with the approach described in (Terada and Tokunaga, 2001). The motivation that they bring forward for the necessity of identifying abbreviations is related to the problem that we have called “the Parsing Problem”. A very different approach to paraphrases is taken in (Takahashi et al., 2001) where they formulate the problem as a special case of Machine Translation, where the source and target language are the same but special rules, based on different parameters, license different types of surface realizations. Hamon &amp; Nazarenko (2001) explore the terminological needs of consulting systems. This type of IR guides the user in query/keyword expansion or proposes various levels of access into the document base on the original query. A method of generating three types of synonymy relations is investigated using general language and domain specific dictionaries. 5 Conclusion Automatic recognition of paraphrases is an effective technique to ease the information access burden in a technical domain. We have presented some techniques that we have adopted in a Question Answering system for dealing with paraphrases. These techniques r</context>
</contexts>
<marker>Hamon, Nazarenko, 2001</marker>
<rawString>Thierry Hamon and Adeline Nazarenko. 2001. Detection of synonymy links between terms: Experiment and results. In Didier Bourigault, Christian Jacquemin, and Marie-Claude L’Homme, editors, Recent Advances in Computational Terminology, pages 185–208. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Dan Moldovan</author>
<author>Marius Pa¸sca</author>
<author>Rada Mihalcea</author>
<author>Mihai Surdeanu</author>
<author>Razvan Bunescu</author>
<author>Roxana Girju</author>
<author>Vasile Rus</author>
<author>Paul Morarescu</author>
</authors>
<title>FALCON: Boosting knowledge for answer engines.</title>
<date>2001</date>
<booktitle>In Voorhees and</booktitle>
<marker>Harabagiu, Moldovan, Pa¸sca, Mihalcea, Surdeanu, Bunescu, Girju, Rus, Morarescu, 2001</marker>
<rawString>Sanda Harabagiu, Dan Moldovan, Marius Pa¸sca, Rada Mihalcea, Mihai Surdeanu, Razvan Bunescu, Roxana Girju, Vasile Rus, and Paul Morarescu. 2001. FALCON: Boosting knowledge for answer engines. In Voorhees and Harman (Voorhees and Harman, 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fidelia Ibekwe-SanJuan</author>
<author>Cyrille Dubois</author>
</authors>
<title>Can Syntactic Variations Highlight Semantic Links Between Domain Topics?</title>
<date>2002</date>
<booktitle>In Proceedings of the 6th International Conference on Terminology and Knowledge Engineering (TKE02),</booktitle>
<pages>57--64</pages>
<location>Nancy,</location>
<contexts>
<context position="16926" citStr="Ibekwe-SanJuan and Dubois, 2002" startWordPosition="2770" endWordPosition="2773">hrase of that term. For example, the logical form of the query Where are the stowage compartments installed? is translated internally into the Horn query (2). (2) evt(install,A,[B,C]), object(D,E,[B]), object(s stowage compartment,G,[C]) This means that a term (belonging to the same synset as stowage compartment) is involved in an install event with an anonymous object. If there is an MLF from the document that can match example (2), then it is selected as a candidate answer and the sentence it originates from is shown to the user. The process of terminological variation is well investigated (Ibekwe-SanJuan and Dubois, 2002; Daille et al., 1996; Ibekwe-Sanjuan, 1998). The primary focus has been to use linguistically based variation to expand existing term sets through corpus investigation or to produce domain representations. A subset of such variations identifies terms which are strictly synonymous. ExtrAns gathers these morpho-syntactic variations into synsets. The sets are augmented with terms exhibiting three weaker synonymy relations described by Hamon &amp; Nazarenko (2001). These synsets are organized into a hyponymy (isa) hierarchy, a small example of which can be seen in Figure 5. Figure 4 shows a schematic</context>
</contexts>
<marker>Ibekwe-SanJuan, Dubois, 2002</marker>
<rawString>Fidelia Ibekwe-SanJuan and Cyrille Dubois. 2002. Can Syntactic Variations Highlight Semantic Links Between Domain Topics? In Proceedings of the 6th International Conference on Terminology and Knowledge Engineering (TKE02), pages 57–64, Nancy, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fidelia Ibekwe-Sanjuan</author>
</authors>
<title>Terminological Variation, a Means of Identifying Research Topics from Texts.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<pages>571--577</pages>
<location>Quebec,Canada,</location>
<contexts>
<context position="16970" citStr="Ibekwe-Sanjuan, 1998" startWordPosition="2778" endWordPosition="2779">he query Where are the stowage compartments installed? is translated internally into the Horn query (2). (2) evt(install,A,[B,C]), object(D,E,[B]), object(s stowage compartment,G,[C]) This means that a term (belonging to the same synset as stowage compartment) is involved in an install event with an anonymous object. If there is an MLF from the document that can match example (2), then it is selected as a candidate answer and the sentence it originates from is shown to the user. The process of terminological variation is well investigated (Ibekwe-SanJuan and Dubois, 2002; Daille et al., 1996; Ibekwe-Sanjuan, 1998). The primary focus has been to use linguistically based variation to expand existing term sets through corpus investigation or to produce domain representations. A subset of such variations identifies terms which are strictly synonymous. ExtrAns gathers these morpho-syntactic variations into synsets. The sets are augmented with terms exhibiting three weaker synonymy relations described by Hamon &amp; Nazarenko (2001). These synsets are organized into a hyponymy (isa) hierarchy, a small example of which can be seen in Figure 5. Figure 4 shows a schematic representation of this process. The first s</context>
</contexts>
<marker>Ibekwe-Sanjuan, 1998</marker>
<rawString>Fidelia Ibekwe-Sanjuan. 1998. Terminological Variation, a Means of Identifying Research Topics from Texts. In Proceedings of COLING-ACL, pages 571–577, Quebec,Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing.</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="18324" citStr="Jacquemin, 2001" startWordPosition="2994" endWordPosition="2995">e strictly synonymous. Further processing is involved in terms containing brackets to determine if the bracketed token is an acronym or simply optional. In the former case an acronym-free term is created and the acronym is stored as a synonym of the remaining tokens which contain it as a regular expression. So evac is synonymous with evacuation and ohsc is synonymous with overhead stowage compartment. In cases such as emergency (hard landings) the bracketed tokens can not be interpreted as acronyms and so are not removed. The synonymy relations are identified using the terminology tool Fastr (Jacquemin, 2001). Every token of each term is associated with its part-of-speech, its morphological root, and its synonyms. Phrasal rules represent the manner in which tokens combine to form multi-token terms, and feature-value pairs carry the token specific information. Metarules license the relation between two terms by constraining their phrase structures in conjunction with the morphological and semantic information on the individual tokens. The metarules can identify simple paraphrases that result from morpho-syntactic variation (cargo compartment door −&gt; doors of the cargo compartment), terms with synon</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Christian Jacquemin. 2001. Spotting and Discovering Terms through Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="10465" citStr="Lappin and Leass, 1994" startWordPosition="1724" endWordPosition="1727"> tokens. This prevents (futile) analysis of the internal structure of terms (see Figure 1), simplifying parsing by 46%. This solves the first of the problems that we have identified in the introduction (“The Parsing Problem”). In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. ExtrAns adopts an anaphora resolution algorithm (Moll´a et al., 2003) that is based on Lappin and Leass’ approach (Lappin and Leass, 1994). The original algorithm, which was applied to the syntactic structures generated by McCord’s Slot Grammar (McCord et al., 1992), has been ported to the output of Link Grammar. So far the resolution is restricted to sentence-internal pronouns but the same algorithm can be applied to sentence-external pronouns too. A lexicon of nominalisations based on NOMLEX (Meyers et al., 1998) is used for the most important cases. The main problem here is that the semantic relationship between the base words (mostly, but not exclusively, verbs) and the derived words (mostly, but not exclusively, nouns) is n</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert J. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
<author>Arendse Bernth</author>
<author>Shalom Lappin</author>
<author>Wlodek Zadrozny</author>
</authors>
<title>Natural language processing within a slot grammar framework.</title>
<date>1992</date>
<journal>International Journal on Artificial Intelligence Tools,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="10593" citStr="McCord et al., 1992" startWordPosition="1744" endWordPosition="1748"> the first of the problems that we have identified in the introduction (“The Parsing Problem”). In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. ExtrAns adopts an anaphora resolution algorithm (Moll´a et al., 2003) that is based on Lappin and Leass’ approach (Lappin and Leass, 1994). The original algorithm, which was applied to the syntactic structures generated by McCord’s Slot Grammar (McCord et al., 1992), has been ported to the output of Link Grammar. So far the resolution is restricted to sentence-internal pronouns but the same algorithm can be applied to sentence-external pronouns too. A lexicon of nominalisations based on NOMLEX (Meyers et al., 1998) is used for the most important cases. The main problem here is that the semantic relationship between the base words (mostly, but not exclusively, verbs) and the derived words (mostly, but not exclusively, nouns) is not sufficiently systematic to allow a derivation lexicon to be compiled automatically. Only in relatively rare cases is the rela</context>
</contexts>
<marker>McCord, Bernth, Lappin, Zadrozny, 1992</marker>
<rawString>Michael McCord, Arendse Bernth, Shalom Lappin, and Wlodek Zadrozny. 1992. Natural language processing within a slot grammar framework. International Journal on Artificial Intelligence Tools, 1(2):229–277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Catherine Macleod</author>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>Using NOMLEX to produce nominalization patterns for information extraction.</title>
<date>1998</date>
<booktitle>In Proceedings: the Computational Treatment of Nominals,</booktitle>
<location>Montreal, Canada, (ColingACL98 workshop),</location>
<contexts>
<context position="2509" citStr="Meyers et al., 1998" startWordPosition="384" endWordPosition="387"> the stapler is $10. Where is Thimphu located? / Thimphu is capital of what country? Of course combinations of the different types are possible, e.g. Oswald killed Kennedy / Kennedy was assassinated by Oswald is a combination of (1) and (2). Different types of knowledge and different linguistic resources are needed to deal with each of the above types. While type (1) can be dealt with using a resource such as WordNet (Fellbaum, 1998), type (2) needs effective parsing and mapping of syntactic structures into a common deeper structure, possibly using a repository of nominalisations like NOMLEX (Meyers et al., 1998). More complex approaches are needed for the other types, up to type (6) where generic world knowledge is required, for instance to know that being a capital of a country implies being located in that country. &apos; Such world knowledge could be expressed in the form of axioms, like the following: (X costs Y) iff (the price of X is Y) In this paper we focus on the role of paraphrases in a Question Answering (QA) system targeted at &apos;Note that the reverse is not true, and therefore this is not a perfect paraphrase. technical manuals. Technical documentation is characterised by vast amounts of domain</context>
<context position="10847" citStr="Meyers et al., 1998" startWordPosition="1785" endWordPosition="1788">ion only, in particular attachments of prepositional phrases, gerunds and infinitive constructions. ExtrAns adopts an anaphora resolution algorithm (Moll´a et al., 2003) that is based on Lappin and Leass’ approach (Lappin and Leass, 1994). The original algorithm, which was applied to the syntactic structures generated by McCord’s Slot Grammar (McCord et al., 1992), has been ported to the output of Link Grammar. So far the resolution is restricted to sentence-internal pronouns but the same algorithm can be applied to sentence-external pronouns too. A lexicon of nominalisations based on NOMLEX (Meyers et al., 1998) is used for the most important cases. The main problem here is that the semantic relationship between the base words (mostly, but not exclusively, verbs) and the derived words (mostly, but not exclusively, nouns) is not sufficiently systematic to allow a derivation lexicon to be compiled automatically. Only in relatively rare cases is the relationship as simple as with to edit &lt;a text&gt; H editor of &lt;a text&gt; / &lt;text&gt; editor, as the effort that went into building resources such as NOMLEX also shows. User queries are processed on-line and converted into MLFs (possibly expanded by synonyms) and pr</context>
</contexts>
<marker>Meyers, Macleod, Yangarber, Grishman, Barrett, Reeves, 1998</marker>
<rawString>Adam Meyers, Catherine Macleod, Roman Yangarber, Ralph Grishman, Leslie Barrett, and Ruth Reeves. 1998. Using NOMLEX to produce nominalization patterns for information extraction. In Proceedings: the Computational Treatment of Nominals, Montreal, Canada, (ColingACL98 workshop), August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Moll´a</author>
<author>Gerold Schneider</author>
<author>Rolf Schwitter</author>
<author>Michael Hess</author>
</authors>
<title>Answer Extraction using a Dependency Grammar in ExtrAns.</title>
<date>2000</date>
<journal>Traitement Automatique de Langues (T.A.L.), Special Issue on Dependency Grammar,</journal>
<volume>41</volume>
<issue>1</issue>
<marker>Moll´a, Schneider, Schwitter, Hess, 2000</marker>
<rawString>Diego Moll´a, Gerold Schneider, Rolf Schwitter, and Michael Hess. 2000a. Answer Extraction using a Dependency Grammar in ExtrAns. Traitement Automatique de Langues (T.A.L.), Special Issue on Dependency Grammar, 41(1):127–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Moll´a</author>
<author>Rolf Schwitter</author>
<author>Michael Hess</author>
<author>Rachel Fournier</author>
</authors>
<title>Extrans, an answer extraction system.</title>
<date>2000</date>
<booktitle>T.A.L. special issue on Information Retrieval oriented Natural Language Processing.</booktitle>
<marker>Moll´a, Schwitter, Hess, Fournier, 2000</marker>
<rawString>Diego Moll´a, Rolf Schwitter, Michael Hess, and Rachel Fournier. 2000b. Extrans, an answer extraction system. T.A.L. special issue on Information Retrieval oriented Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Moll´a</author>
<author>Rolf Schwitter</author>
<author>Fabio Rinaldi</author>
<author>James Dowdall</author>
<author>Michael Hess</author>
</authors>
<title>Anaphora resolution in ExtrAns.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Symposium on Reference Resolution and Its Applications to Question Answering and Summarization,</booktitle>
<pages>23--25</pages>
<location>Venice, Italy.</location>
<marker>Moll´a, Schwitter, Rinaldi, Dowdall, Hess, 2003</marker>
<rawString>Diego Moll´a, Rolf Schwitter, Fabio Rinaldi, James Dowdall, and Michael Hess. 2003. Anaphora resolution in ExtrAns. In Proceedings of the International Symposium on Reference Resolution and Its Applications to Question Answering and Summarization, 23–25 June, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Universal model for paraphrasing - using transformation based on a defined criteria.</title>
<date>2001</date>
<booktitle>In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</booktitle>
<contexts>
<context position="23699" citStr="Murata and Isahara, 2001" startWordPosition="3858" endWordPosition="3861">tecting question similarity. As in that particular evaluation the organisers deliberately used a set of paraphrases of the same questions, such approach certainly helped in boosting the performance of the system. In an environment where the same question (in different formulations) is likely to be repeated a number of times, a module capable of detecting paraphrases can significantly improve the performance of a Question AnFigure 7: Overhead stowage compartment is a Hyponym of Stowage compartment swering system. Another example of application of paraphrases for Question Answering is given in (Murata and Isahara, 2001), which further argues for the importance of paraphrases for other applications such Summarisation, error correction and speech generation. Our approach for the acquisition of terminological paraphrases might have some points in common with the approach described in (Terada and Tokunaga, 2001). The motivation that they bring forward for the necessity of identifying abbreviations is related to the problem that we have called “the Parsing Problem”. A very different approach to paraphrases is taken in (Takahashi et al., 2001) where they formulate the problem as a special case of Machine Translati</context>
</contexts>
<marker>Murata, Isahara, 2001</marker>
<rawString>Masaki Murata and Hitoshi Isahara. 2001. Universal model for paraphrasing - using transformation based on a defined criteria. In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Rinaldi</author>
<author>James Dowdall</author>
<author>Michael Hess</author>
<author>Kaarel Kaljurand</author>
<author>Mare Koit</author>
<author>Kadri Vider</author>
<author>Neeme Kahusk</author>
</authors>
<title>Terminology as Knowledge in Answer Extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 6th International Conference on Terminology and Knowledge Engineering (TKE02),</booktitle>
<volume>28</volume>
<pages>107--113</pages>
<location>Nancy,</location>
<contexts>
<context position="3258" citStr="Rinaldi et al., 2002" startWordPosition="513" endWordPosition="516">to know that being a capital of a country implies being located in that country. &apos; Such world knowledge could be expressed in the form of axioms, like the following: (X costs Y) iff (the price of X is Y) In this paper we focus on the role of paraphrases in a Question Answering (QA) system targeted at &apos;Note that the reverse is not true, and therefore this is not a perfect paraphrase. technical manuals. Technical documentation is characterised by vast amounts of domain-specific terminology, which needs to be exploited for providing intelligent access to the information contained in the manuals (Rinaldi et al., 2002b). The approach taken by QA systems is to allow a user to ask a query (formulated in natural language) and have the system search a background collection of documents in order to locate an answer. The field of Question Answering has flourished in recent years2, in part, due to the QA track of the TREC competitions (Voorhees and Harman, 2001). These competitions evaluate systems over a common data set allowing developers to benchmark performance in relation to other competitors. It is a common assumption that technical terminology is subject to strict controls and cannot vary within a given ed</context>
<context position="4806" citStr="Rinaldi et al., 2002" startWordPosition="783" endWordPosition="786">itrary paraphrases of the target term, which might happen to be one of those used in the manual itself or might happen to be a novel one. We describe some potential solutions to this problem, taking our Question Answering system as an example. We show which benefits our approach based on paraphrases bring to the system. So far two different domains have been targeted by the system. An initial application aims at answering questions about the Unix man pages (Moll´a et al., 2000a; Moll´a et al., 2000b). A more complex application targets the Aircraft Maintenance Manual (AMM) of the Airbus A320 (Rinaldi et al., 2002b). Recently we have started new work, using the Linux HOWTOs as a new target domain. In dealing with these domains we have identified two major obstacles for a QA system, which we can summarise as follows: • The Parsing Problem • The Paraphrase Problem The Parsing Problem consists in the increased difficulty of parsing text in a technical domain due to domain-specific sublanguage. Various types of multi word expressions characterise these domains, in particular referring to specific concepts like tools, parts or procedures. These multi word expressions might 2Although early work in AI already</context>
<context position="8520" citStr="Rinaldi et al., 2002" startWordPosition="1405" endWordPosition="1408">erlying technology. The original ExtrAns system (Moll´a et al., 2000b) is used RW ///// a.d electrical coax cable.n4 connects.v062 the.d external antenna.n1 to.o the.d ANT connection.n1 ///// Figure 1: An Example of LG Output MVp  Os  Ds Js  Ds    Dsu  Ss Wd to extract answers to arbitrary user queries over the Unix documentation files (“man pages”). A set of 500+ unedited man pages has been used for this application. An on-line demo of ExtrAns can be found at the project web page.3 More recently we tackled a different domain, the Airplane Maintenance Manuals (AMM) of the Airbus A320 (Rinaldi et al., 2002b), which offered the additional challenges of an SGML-based format and a much larger size (120MB).4 Despite being developed initially for a specific domain, ExtrAns has demonstrated a high level of domain independence. As we work on relatively small volumes of data we can afford to process (in an off-line stage) all the documents in our collection rather than just a few selected paragraphs (see Figure 2). Clearly in some situations (e.g. processing incoming news) such an approach might not be feasible and paragraph indexing techniques would need to be used. Our current approach is particularl</context>
<context position="19203" citStr="Rinaldi et al. (2002" startWordPosition="3128" endWordPosition="3131">arules license the relation between two terms by constraining their phrase structures in conjunction with the morphological and semantic information on the individual tokens. The metarules can identify simple paraphrases that result from morpho-syntactic variation (cargo compartment door −&gt; doors of the cargo compartment), terms with synonymous heads (electrical cable −&gt; electrical line), terms with synonymous modifiers (fastener strip −&gt; attachment strip) and both (functional test −&gt; operational check). For a description of the frequency and range of types of variation present in the AMM see Rinaldi et al. (2002a). 3.2 Identifying Syntactic Paraphrases An important effect of using a simplified semanticbased representation such as the Minimal Logical Forms is that various types of syntactic variations are automatically captured by a common representation. This ensures that many potential paraphrases in a user query can map to the same answer into the manual. For example the question shown in Figure 6 can be answered thanks to the combination of two factors. On the lexical level ExtrAns knows that APU is an abbreviation of Auxiliary Power Unit, while on the syntactic level the active and passive voices</context>
</contexts>
<marker>Rinaldi, Dowdall, Hess, Kaljurand, Koit, Vider, Kahusk, 2002</marker>
<rawString>Fabio Rinaldi, James Dowdall, Michael Hess, Kaarel Kaljurand, Mare Koit, Kadri Vider, and Neeme Kahusk. 2002a. Terminology as Knowledge in Answer Extraction. In Proceedings of the 6th International Conference on Terminology and Knowledge Engineering (TKE02), pages 107–113, Nancy, 28– 30 August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Rinaldi</author>
<author>James Dowdall</author>
<author>Michael Hess</author>
<author>Diego Moll´a</author>
<author>Rolf Schwitter</author>
</authors>
<title>Towards Answer Extraction: an application to Technical Domains. In</title>
<date>2002</date>
<booktitle>ECAI2002, European Conference on Artificial Intelligence,</booktitle>
<pages>21--26</pages>
<location>Lyon,</location>
<marker>Rinaldi, Dowdall, Hess, Moll´a, Schwitter, 2002</marker>
<rawString>Fabio Rinaldi, James Dowdall, Michael Hess, Diego Moll´a, and Rolf Schwitter. 2002b. Towards Answer Extraction: an application to Technical Domains. In ECAI2002, European Conference on Artificial Intelligence, Lyon, 21–26 July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Rinaldi</author>
<author>James Dowdall</author>
<author>Michael Hess</author>
<author>Kaarel Kaljurand</author>
<author>Magnus Karlsson</author>
</authors>
<title>The Role of Technical Terminology in Question Answering.</title>
<date>2003</date>
<booktitle>In Proceedings of TIA-2003, Terminologie et Intelligence Artificielle,</booktitle>
<location>Strasbourg,</location>
<contexts>
<context position="9347" citStr="Rinaldi et al., 2003" startWordPosition="1549" endWordPosition="1552">ndependence. As we work on relatively small volumes of data we can afford to process (in an off-line stage) all the documents in our collection rather than just a few selected paragraphs (see Figure 2). Clearly in some situations (e.g. processing incoming news) such an approach might not be feasible and paragraph indexing techniques would need to be used. Our current approach is particularly targeted to small and medium sized collections. In an initial phase all multi-word expressions from the domain are collected and structured in an external resource, which we will refer to as the TermBase (Rinaldi et al., 2003; Dowdall et al., 2003). The document sentences (and user queries) are syntactically processed with the Link Grammar (LG) parser (Sleator and Temperley, 1993) which uses a 3http://www.ifi.unizh.ch/cl/extrans/ 4Still considerably smaller than the size of the document collections used for TREC grammar with a wide coverage of English and has a robust treatment of ungrammatical sentences and unknown words. The multi-word terms from the thesaurus are identified and passed to the parser as single tokens. This prevents (futile) analysis of the internal structure of terms (see Figure 1), simplifying p</context>
</contexts>
<marker>Rinaldi, Dowdall, Hess, Kaljurand, Karlsson, 2003</marker>
<rawString>Fabio Rinaldi, James Dowdall, Michael Hess, Kaarel Kaljurand, and Magnus Karlsson. 2003. The Role of Technical Terminology in Question Answering. In Proceedings of TIA-2003, Terminologie et Intelligence Artificielle, Strasbourg, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel D Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar. In</title>
<date>1993</date>
<booktitle>Proc. Third International Workshop on Parsing Technologies,</booktitle>
<pages>277--292</pages>
<contexts>
<context position="9505" citStr="Sleator and Temperley, 1993" startWordPosition="1573" endWordPosition="1576"> than just a few selected paragraphs (see Figure 2). Clearly in some situations (e.g. processing incoming news) such an approach might not be feasible and paragraph indexing techniques would need to be used. Our current approach is particularly targeted to small and medium sized collections. In an initial phase all multi-word expressions from the domain are collected and structured in an external resource, which we will refer to as the TermBase (Rinaldi et al., 2003; Dowdall et al., 2003). The document sentences (and user queries) are syntactically processed with the Link Grammar (LG) parser (Sleator and Temperley, 1993) which uses a 3http://www.ifi.unizh.ch/cl/extrans/ 4Still considerably smaller than the size of the document collections used for TREC grammar with a wide coverage of English and has a robust treatment of ungrammatical sentences and unknown words. The multi-word terms from the thesaurus are identified and passed to the parser as single tokens. This prevents (futile) analysis of the internal structure of terms (see Figure 1), simplifying parsing by 46%. This solves the first of the problems that we have identified in the introduction (“The Parsing Problem”). In later stages of processing, a cor</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Daniel D. Sleator and Davy Temperley. 1993. Parsing English with a link grammar. In Proc. Third International Workshop on Parsing Technologies, pages 277–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuro Takahashi</author>
<author>Tomoya Iwakura</author>
<author>Ryu Iida</author>
<author>Kentaro Inui</author>
</authors>
<title>Kura: A revision-based lexico-structural paraphrasing engine.</title>
<date>2001</date>
<booktitle>In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</booktitle>
<contexts>
<context position="24227" citStr="Takahashi et al., 2001" startWordPosition="3938" endWordPosition="3941">ple of application of paraphrases for Question Answering is given in (Murata and Isahara, 2001), which further argues for the importance of paraphrases for other applications such Summarisation, error correction and speech generation. Our approach for the acquisition of terminological paraphrases might have some points in common with the approach described in (Terada and Tokunaga, 2001). The motivation that they bring forward for the necessity of identifying abbreviations is related to the problem that we have called “the Parsing Problem”. A very different approach to paraphrases is taken in (Takahashi et al., 2001) where they formulate the problem as a special case of Machine Translation, where the source and target language are the same but special rules, based on different parameters, license different types of surface realizations. Hamon &amp; Nazarenko (2001) explore the terminological needs of consulting systems. This type of IR guides the user in query/keyword expansion or proposes various levels of access into the document base on the original query. A method of generating three types of synonymy relations is investigated using general language and domain specific dictionaries. 5 Conclusion Automatic</context>
</contexts>
<marker>Takahashi, Iwakura, Iida, Inui, 2001</marker>
<rawString>Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, and Kentaro Inui. 2001. Kura: A revision-based lexico-structural paraphrasing engine. In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akira Terada</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Automatic disabbreviation by using context information.</title>
<date>2001</date>
<booktitle>In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</booktitle>
<contexts>
<context position="23993" citStr="Terada and Tokunaga, 2001" startWordPosition="3900" endWordPosition="3903">to be repeated a number of times, a module capable of detecting paraphrases can significantly improve the performance of a Question AnFigure 7: Overhead stowage compartment is a Hyponym of Stowage compartment swering system. Another example of application of paraphrases for Question Answering is given in (Murata and Isahara, 2001), which further argues for the importance of paraphrases for other applications such Summarisation, error correction and speech generation. Our approach for the acquisition of terminological paraphrases might have some points in common with the approach described in (Terada and Tokunaga, 2001). The motivation that they bring forward for the necessity of identifying abbreviations is related to the problem that we have called “the Parsing Problem”. A very different approach to paraphrases is taken in (Takahashi et al., 2001) where they formulate the problem as a special case of Machine Translation, where the source and target language are the same but special rules, based on different parameters, license different types of surface realizations. Hamon &amp; Nazarenko (2001) explore the terminological needs of consulting systems. This type of IR guides the user in query/keyword expansion o</context>
</contexts>
<marker>Terada, Tokunaga, 2001</marker>
<rawString>Akira Terada and Takenobu Tokunaga. 2001. Automatic disabbreviation by using context information. In Proceedings of the NLPRS2001 Workshop on Automatic Paraphrasing: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
<author>Donna Harman</author>
<author>editors</author>
</authors>
<date>2001</date>
<booktitle>Proceedings of the Ninth Text REtrieval Conference (TREC-9),</booktitle>
<location>Gaithersburg, Maryland,</location>
<marker>Voorhees, Harman, editors, 2001</marker>
<rawString>Ellen M. Voorhees and Donna Harman, editors. 2001. Proceedings of the Ninth Text REtrieval Conference (TREC-9), Gaithersburg, Maryland, November 13-16, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Lunar rocks in natural English: Explorations in Natural Language Question Answering.</title>
<date>1977</date>
<booktitle>Linguistic Structures Processing,</booktitle>
<volume>5</volume>
<pages>521--569</pages>
<editor>In A. Zampolli, editor,</editor>
<publisher>North Holland.</publisher>
<contexts>
<context position="5449" citStr="Woods, 1977" startWordPosition="887" endWordPosition="888">w work, using the Linux HOWTOs as a new target domain. In dealing with these domains we have identified two major obstacles for a QA system, which we can summarise as follows: • The Parsing Problem • The Paraphrase Problem The Parsing Problem consists in the increased difficulty of parsing text in a technical domain due to domain-specific sublanguage. Various types of multi word expressions characterise these domains, in particular referring to specific concepts like tools, parts or procedures. These multi word expressions might 2Although early work in AI already touched upon the topic, e.g. (Woods, 1977). include lexical items which are either unknown to a generic lexicon (e.g. coax cable) or have a specific meaning unique to this domain. Abbreviations and acronyms are another common source of inconsistencies. In such cases the parser might either fail to identify the compound as a phrase and consequently fail to parse the sentence including such items. Alternatively the parser might attempt to ‘guess’ their lexical category (in the set of open class categories), leading to an exponential growth of the number of possible syntactic parses. Not only the internal structure of the compound can be</context>
</contexts>
<marker>Woods, 1977</marker>
<rawString>W.A. Woods. 1977. Lunar rocks in natural English: Explorations in Natural Language Question Answering. In A. Zampolli, editor, Linguistic Structures Processing, volume 5 of Fundamental Studies in Computer Science, pages 521–569. North Holland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>