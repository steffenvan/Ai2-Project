<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001336">
<title confidence="0.979476">
Web-based Annotation of Anaphoric Relations and Lexical Chains
</title>
<author confidence="0.94572">
Maik Stührenberg and Daniela Goecke and Nils Diewald and Alexander Mehler
</author>
<affiliation confidence="0.7620915">
Bielefeld University
Germany
</affiliation>
<email confidence="0.331745">
{maik.stuehrenberg|daniela.goecke|nils.diewald|alexander.mehler}@uni-bielefeld.de
</email>
<author confidence="0.983972">
Irene Cramer
</author>
<affiliation confidence="0.778459">
Dortmund University
Germany
</affiliation>
<email confidence="0.663542">
irene.cramer@uni-dortmund.de
</email>
<sectionHeader confidence="0.990496" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999910888888889">
Annotating large text corpora is a time-
consuming effort. Although single-user an-
notation tools are available, web-based an-
notation applications allow for distributed
annotation and file access from different lo-
cations. In this paper we present the web-
based annotation application Serengeti for
annotating anaphoric relations which will be
extended for the annotation of lexical chains.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999926409090909">
The relevance of corpus work for different tasks in
the fields of linguistics is widely accepted. This
holds especially for the area of (semi-)automatic
text and discourse analysis which demands reference
corpora in which instances of various levels of dis-
course structure have been annotated. Such anno-
tation tasks are typically carried out by a combina-
tion of automatic and manual techniques. Manual
annotation of large text corpora is a time consum-
ing effort. Therefore, annotation tools are an indis-
pensable means to overcome the limits of manual
annotations. In spite of their limited level of au-
tomatization, such tools nevertheless help to semi-
automatically support the annotation process and to
secure consistency of manual annotations. This pa-
per describes such an annotation tool which focuses
on a certain type of discourse structures. More
specifically, we deal with anaphoric relations and
lexical cohesion. Our starting point is the obser-
vation that these two resources of textual cohesion
(Halliday and Hasan, 1976) homogeneously induce
chain-like discourse structures: one the one hand we
have reference chains started by some antecedence
and continued by some anaphora linked to the same
antecedence. On the other hand, lexical cohesion
generates so called lexical chains of semantically
related tokens. Based on this observation we de-
scribe the annotation tool Serengeti which reflects
this structural homogeneity on the level of its struc-
tural representation model as well as by its proce-
dural annotation model. Serengeti includes an an-
notation scheme which is extended in order to sup-
port the annotation of reference chains and lexical
chains. The paper is organized as follows: Section
2.1 describes the application scenario of anaphoric
relations and the scheme we use to annotate them.
Section 2.2 deals with the second application sce-
nario: lexical chains. As our starting point was the
former scenario, its extension to the latter one will be
motivated by a separate case study of lexical chain-
ing. Section 3 refers to related work, while Section
4 describes our annotation tool in detail. Finally, the
application of Serengeti to annotating lexical chains
is described in Section 5.
</bodyText>
<sectionHeader confidence="0.946201" genericHeader="method">
2 Annotating Large Text Corpora
</sectionHeader>
<bodyText confidence="0.62656975">
The main focus of the joint work presented in this
paper1 is text technological information modelling
and analysis of various types of discourse. Within
our research group we deal with the integration of
</bodyText>
<footnote confidence="0.9573622">
1The work presented in this paper is a joint ef-
fort of the projects A2, A4 and B1 of the Research
Group Text-technological modelling of information funded
by the German Research Foundation. See http://www.
text-technology.de for further details.
</footnote>
<page confidence="0.915546">
140
</page>
<note confidence="0.713343">
Proceedings of the Linguistic Annotation Workshop, pages 140–147,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999942227272727">
heterogeneous linguistic resources. This applies es-
pecially to the Sekimo project (A2) which focusses
on the application domain of anaphora resolution.
We use the term ’heterogeneity’ to refer to resources
that differ either in terms of form (text, audio, video)
or in terms of function (e. g. lexicons, annotated
texts). Connection between these resources can
be established with the means of XML, cf. Si-
mons (2004). Integrating resources via an abstract
interface is necessary due to different reasons: The
resources used have often been developed indepen-
dently from each other and a cascaded application
of one resource to the output of another resource is
not always possible. Furthermore, the output of dif-
ferent resources often cannot be encoded in a single
structure without driving into incompatibilites (i. e.
XML overlap). Therefore an architecture was devel-
oped which allows for the combination of the out-
put structures of several linguistic resources into a
single XML annotated document and which is de-
scribed in detail in Witt et al. (2005) and Stühren-
berg et al. (2006) .
</bodyText>
<subsectionHeader confidence="0.995207">
2.1 Anaphoric Relations
</subsectionHeader>
<bodyText confidence="0.998302098591549">
Motivation and Background Resolving anapho-
ric relations needs a variety of different informa-
tion (e. g. POS, distance information, grammati-
cal function, semantic knowledge, see, for exam-
ple, Mitkov (2002) for an overview). Several re-
sources are applied to a corpus of 47 texts and the
output structures are combined into a single XML
document using the architecture mentioned above.
In order not only to integrate but also evaluate re-
sources for a given linguistic task formally in terms
of precision and recall, it should be possible to ei-
ther switch on or switch off a given resource. In
the application domain of anaphora resolution eval-
uation is done as follows. Each discourse entity
or referent (cf. Karttunen (1976)) is annotated as
an XML element which holds a variety of attribute
information. Each XML element is reinterpreted
as a feature vector; pairs of discourse entities be-
tween which an anaphoric relation holds form a sin-
gle feature vector with additional information rele-
vant for anaphora resolution (e. g. distance informa-
tion, identity of grammatical form, semantic relat-
edness of underlying lemmata and the like). In or-
der to evaluate different resource settings, decision
trees with varying sets of feature vectors are used
for the process of anaphora resolution. Xiaofeng et
al. (2004) or Strube and Müller (2003) have shown
the feasibility of decision trees for the domain of
anaphora resolution; we have chosen this approach
as it makes it possible to easily switch the informa-
tion set for training and evaluation as opposed to e. g.
rewriting rule sets. Both, training and evaluation as
well as empirically based analysis of anaphora need
an annotated reference corpus (Poesio et al., 2002).
Scheme and annotation process are described in the
following section.
The Annotation Scheme for Anaphoric Rela-
tions Several annotation schemes for annotat-
ing anaphoric relations have been developed in
the last years, e.g. the UCREL anaphora an-
notation scheme (Fligelstone, 1992; Garside et
al., 1997), the SGML-based MUC annotation
scheme (Hirschmann, 1997), and the MATE/G-
NOME Scheme (Poesio, 2004), amongst others.
In order to annotate discourse relations – either
anaphoric relations or lexical chains (cf. Sec-
tion 2.2) – two types of information have to be spec-
ified. First, the markables, i. e. the elements that can
be part of a relation, have to be specified (cf. Müller
and Strube (2003)). Second, the relation(s) between
markables and their respective types and subtypes
have to be defined. The markables form a basis for
the annotation process and therefore have to be an-
notated in advance. Normally, for a domain under
investigation, elements are denoted as being mark-
ables either via a specific element or via the use of
a universal attribute. In our system, discourse enti-
ties are detected automatically on the basis of POS
and parsing information. The annotation scheme
for annotating anaphoric relations is an extension
of the scheme presented by Holler et al. (2004) that
has been developed for annotations in the context of
text-to-hypertext conversion in the project B1 Hy-
Tex. We adopt the distinction between coreference
and cospecification but we extend the annotation
scheme for an explicit distinction between cospec-
ification (direct anaphora) and bridging (associative
or indirect anaphora). Thus, we add the primary re-
lation type bridgingLink (denoting bridging) to the
already existing one (cospecLink). Each primary
relation type includes different secondary relation
</bodyText>
<page confidence="0.994728">
141
</page>
<figureCaption confidence="0.667012">
Listing 1: The annotation format for anaphoric relations. Shortened and manually revised output
</figureCaption>
<figure confidence="0.992542826923077">
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
&lt;chs:chs&gt;
&lt;chs:text&gt;
&lt;cnx:de deID=&amp;quot;de8&amp;quot; deType=&amp;quot;namedEntity&amp;quot; headRef=&amp;quot;w36&amp;quot;&gt;
&lt;cnx:token ref=&amp;quot;w36&amp;quot;&gt;Maik&lt;/cnx:token&gt;&lt;/cnx:de&gt;
&lt;cnx:token ref=&amp;quot;w37&amp;quot;&gt;hat&lt;/cnx:token&gt; &lt;cnx:token ref=&amp;quot;w38&amp;quot;&gt;kein&lt;/cnx:token&gt;
&lt;cnx:token ref=&amp;quot;w39&amp;quot;&gt;eigenes&lt;/cnx:token&gt; &lt;cnx:token ref=&amp;quot;w40&amp;quot;&gt;Fahrrad&lt;/cnx:token&gt;,
&lt;cnx:token ref=&amp;quot;w42&amp;quot;&gt;und&lt;/cnx:token&gt;
&lt;cnx:de deID=&amp;quot;de10&amp;quot; deType=&amp;quot;namedEntity&amp;quot; headRef=&amp;quot;w43&amp;quot;&gt;
&lt;cnx:token ref=&amp;quot;w43&amp;quot;&gt;Marie&lt;/cnx:token&gt;&lt;/cnx:de&gt;
&lt;cnx:token ref=&amp;quot;w45&amp;quot;&gt;fährt&lt;/cnx:token&gt; &lt;cnx:token ref=&amp;quot;w46&amp;quot;&gt;nicht&lt;/cnx:token&gt;
&lt;cnx:token ref=&amp;quot;w47&amp;quot;&gt;in&lt;/cnx:token&gt;
&lt;cnx:de deID=&amp;quot;de11&amp;quot; deType=&amp;quot;nom&amp;quot; headRef=&amp;quot;w49&amp;quot;&gt;
&lt;cnx:token ref=&amp;quot;w48&amp;quot;&gt;den&lt;/cnx:token&gt;
&lt;cnx:token ref=&amp;quot;w49&amp;quot;&gt;Urlaub&lt;/cnx:token&gt;&lt;/cnx:de&gt;.
&lt;cnx:de deID=&amp;quot;de12&amp;quot; deType=&amp;quot;nom&amp;quot; headRef=&amp;quot;w53&amp;quot;&gt;
&lt;cnx:token ref=&amp;quot;w52&amp;quot;&gt;Zwei&lt;/cnx:token&gt;
&lt;cnx:token ref=&amp;quot;w53&amp;quot;&gt;Kinder&lt;/cnx:token&gt;&lt;/cnx:de&gt;,
&lt;cnx:de deID=&amp;quot;de13&amp;quot; deType=&amp;quot;nom&amp;quot; headRef=&amp;quot;w56&amp;quot;&gt;
&lt;cnx:token ref=&amp;quot;w55&amp;quot;&gt;eine&lt;/cnx:token&gt;
&lt;cnx:token ref=&amp;quot;w56&amp;quot;&gt;Gemeinsamkeit&lt;/cnx:token&gt;&lt;/cnx:de&gt;:
&lt;/chs:text&gt;
&lt;cnx:token_ref id=&amp;quot;w36&amp;quot; head=&amp;quot;w37&amp;quot; pos=&amp;quot;N&amp;quot; syn=&amp;quot;@NH&amp;quot; depV=&amp;quot;subj&amp;quot; morph=&amp;quot;MSC SG NOM&amp;quot; /&gt;
&lt;chs:semRel&gt;
&lt;chs:bridgingLink relType=&amp;quot;hasMember&amp;quot; antecedentIDRefs=&amp;quot;de8 de10&amp;quot; phorIDRef=&amp;quot;de12&amp;quot;/&gt;
&lt;/chs:semRel&gt;
&lt;/chs:chs&gt;
</figure>
<bodyText confidence="0.999657625">
types that specify the subtype of the relation, e. g.
ident or hypernym as secondary types of cospecLink
or meronym or setMember as secondary types of
bridgingLink. An example annotation of an indirect
anaphoric relation (element bridgingLink, line
30) between the discourse entities de12 (lines 18 to
21) and de8 (lines 3 to 5) and de10 (lines 9 to 11)
can be seen in Listing 1.
</bodyText>
<subsectionHeader confidence="0.999588">
2.2 Lexical Chaining
</subsectionHeader>
<bodyText confidence="0.999869642857143">
Motivation and Background Based on the con-
cept of lexical cohesion (Halliday and Hasan,
1976), computational linguists (inter alia Morris and
Hirst (1991)) developed a method to compute a par-
tial text representation: lexical chains. These span
over passages or even the complete text linking lex-
ical items. The exemplary annotation in Figure 1
illustrates that lexical chaining is achieved by the
selection of vocabulary and significantly accounts
for the cohesive structure of a text passage. Items
in a lexical chain are connected via semantic re-
lations. Accordingly, lexical chains are computed
on the basis of a lexical semantic resource such as
WordNet (Fellbaum, 1998). Figure 1 also depicts
</bodyText>
<figureCaption confidence="0.896805">
Figure 1: Chaining Example (adapted from Halliday
et al. (1976))
</figureCaption>
<bodyText confidence="0.9990221">
several unsystematic relations, which should in prin-
ciple be considered. Unfortunately, common lexical
resources do not incorporate them sufficiently. Most
systems consist of the fundamental modules shown
in Table 1.
However, in order to formally evaluate the perfor-
mance of a given chainer in terms of precision and
recall, a (preferably standardized and freely avail-
able) test set would be required. To our knowledge
such a resource does not exist – neither for English
</bodyText>
<page confidence="0.979106">
142
</page>
<table confidence="0.999893357142857">
Module Subtasks
chaining candidate selection preprocessing of corpora:
determine chaining window,
sentence boundaries,
tokens, POS-tagging
chunks etc.
calculation of chains / look-up: lexical semantic
meta-chains resource (e.g. WordNet),
scoring of relations,
sense disambiguation
output creation rate chain strength
(e.g. select strong chains),
build application specific
representation
</table>
<tableCaption confidence="0.999905">
Table 1: Overview of Chainer Modules
</tableCaption>
<bodyText confidence="0.99986628">
nor for German. We therefore plan to develop an
evaluation corpus (gold standard), which on the one
hand includes the annotation of lexical chains and
on the other hand reveals the rich interaction be-
tween various principles to achieve a cohesive text
structure. In order to systematically construct sound
guidelines for the annotation of this gold standard,
we conducted a case study.
Case Study Six subjects were asked to annotate
lexical chains in three short texts and in doing so
record all challenges and uncertainties they experi-
enced. The subjects were asked to read three texts
– a wikipedia entry (137 words), a newspaper
article (233 words), and an interview (306 words).
They were then given a list of all nouns occurring
in the articles (almost all chainers exclusively con-
sider nouns as chaining candidates), which they had
to rate with respect to their ’importance’ in under-
standing the text. On this basis they were asked
to determine the semantic relations of every pos-
sible chaining candidate pair, thus chain the nouns
and annotate the three texts. Just like previously re-
ported case studies (Beigman Klebanov, 2005; Mor-
ris and Hirst, 2004; Morris and Hirst, 2005) aim-
ing at the annotation of lexical chains, we found
that the inter-annotator agreement was in general
relatively low. Only the annotation of very promi-
nent items in the three texts, which accounted for
approximately one fifth of the chaining candidates,
resulted in a satisfying agreement (that is: the ma-
jority of the subjects produced an identical or very
similar annotation). However, all subjects com-
plained about the task. They found it rather diffi-
cult to construct linearized or quasi-linearized struc-
tures, in short, chains. Instead, most of the subjects
built clusters and drew very complex graphs to illus-
trate the cohesive relations they found. They also
pointed out that only a small fraction of the can-
didate list contributed to their text understanding.
This clearly supports our observation that most of
the subjects first skimmed through the text to find
the most prominent items, established chains for this
selection and then worked the text over to distribute
the remaining items to these chains. We therefore as-
sume that lexical chains do not directly reflect read-
ing and understanding processes. Nevertheless, they
do in some way contribute to them. Many subjects
additionally noted that a reasonable candidate list
should also include multi-word units (e.g. techni-
cal terms) or even phrases. Furthermore, as already
reported in previous work (Morris and Hirst, 2004),
the semantic relations usually considered seem not
to suffice. Accordingly, some subjects proposed new
relations to characterize the links connecting can-
didate pairs. Given our own findings and the re-
sults reported in previous work, it is obviously de-
manding to find a clear-cut border between the con-
cepts of lexical chaining, semantic fields, and co-
reference/anaphora resolution. Definitely, the anno-
tation of co-reference/anaphora and lexical chains is
inherently analogous. In both cases an annotation
layer consisting of labelled edges between pairs of
annotation candidates is constructed. However, we
assume that the lexical chaining layer might contain
more edges between annotation candidates. As a
consequence, its structure presumably is more com-
plex and its connectivity higher. We thus plan to
conduct an extended follow-up study in order to ex-
plore these differences between the annotation of
lexical chains and co-reference/anaphora. We also
intend to take advantage of – amongst other aspects
– the inter-annotator comparison functionality pro-
vided by Serengeti (see Section 4 for a detailed de-
scription) in order to implement a formally correct
inter-annotator agreement test.
</bodyText>
<sectionHeader confidence="0.8254435" genericHeader="method">
3 Available Tools for Annotating
Linguistic Corpora
</sectionHeader>
<bodyText confidence="0.9929645">
Both the anaphora resolution and the lexical chain-
ing scenario have shown the importance of an easy-
</bodyText>
<page confidence="0.998191">
143
</page>
<bodyText confidence="0.999766583333333">
to-use annotation tool. Although a wide range of
annotation tools is available, one has to separate
tools for annotating multimodal corpora from tools
for annotating unimodal (i. e. text) corpora. Dip-
per et al. (2004) evaluated some of the most com-
monly used tools of both categories (TASX Anno-
tator, EXMARaLDA, MMAX, PALinkA and Sys-
tematic Coder). Besides, other tools such as ELAN2
or Anvil3 are available as well, as are tool kits such
as the Annotation Graph Toolkit (AGTK)4 or the
NITE XML Toolkit.5 While multimodal annotation
demands a framework supporting the time-aligned
handling of video and audio streams and, therefore,
much effort has been spent on the design and devel-
opment of tools, unimodal annotation has often been
fulfilled by using ordinary XML editors which can
be error-prone. Nevertheless, specialized annota-
tion frameworks are available as well, e. g. MMAX
can be used for multi-level annotation projects (cf.
Müller and Strube (2001; 2003)). However, as an-
notation projects grow in size and complexity (often
multiple annotation layers are generated), collabo-
rative annotation and the use of annotation tools is
vital.
</bodyText>
<listItem confidence="0.987779692307692">
• Ma et al. (2002), for example, describe collab-
orative annotation in the context of the AGTK.
But since most of the aforementioned applica-
tions have to be installed locally on a PC, work-
ing on a corpus and managing annotations ex-
ternally can be difficult.
• Another problem worth to be mentioned is data
management. Having several annotators work-
ing on one text, unification and comparison of
the markup produced is quite difficult.
• Furthermore, annotation tools help to increase
both the quality and quantity of the annotation
process.
</listItem>
<bodyText confidence="0.99980775">
Recent web technologies allow the design of web-
based applications that resemble locally installed
desktop programs on the one hand and provide cen-
tral data management on the other hand. Therefore
</bodyText>
<footnote confidence="0.99994625">
2http://www.lat-mpi.eu/tools/elan/
3http://www.dfki.de/~kipp/anvil/
4http://agtk.sourceforge.net/
5http://www.ltg.ed.ac.uk/NITE/
</footnote>
<bodyText confidence="0.99916175">
distributed annotation is possible regardless of loca-
tion, provided that an internet connection is avail-
able. In this paper we propose the web-based anno-
tation application Serengeti.
</bodyText>
<sectionHeader confidence="0.96307" genericHeader="method">
4 A new Approach: Serengeti
</sectionHeader>
<bodyText confidence="0.9999872">
As the Sekimo project is part of a research group
with interrelated application domains, annotation
layers from different projects have been evaluated
for their interrelationship (e. g. Bayerl et al. (2003;
2006)). This led directly to the open design of
Serengeti – an annotation tool with the fundamen-
tal idea in mind: making possible the annotation
of a single layer (or resource) and the use of the
best annotation possible and the best available re-
sources. Serengeti allows for several experts to an-
notate a single text at the same time as well as to
compare the different annotations (inter-annotator-
agreement) and merge them afterwards. Access to
the documents is available from everywhere (an in-
ternet connection and a browser is required).
</bodyText>
<subsectionHeader confidence="0.995733">
4.1 Technical Overview
</subsectionHeader>
<bodyText confidence="0.999675375">
Serengeti is a web application developed for Mozilla
Firefox,6 thus its architecture is separated into a
client and a server side, following the principles and
tools of AJAX (Asynchronous JavaScript and XML,
cf. Garrett (2005)). While groups, documents and
annotations are managed centrally on the server side,
all user interactions are rendered locally on the client
side.7
</bodyText>
<subsectionHeader confidence="0.999079">
4.2 Graphical User Interface
</subsectionHeader>
<bodyText confidence="0.999666555555556">
The Graphical User Interface (GUI) of Serengeti is
subdivided into several areas (cf. Figure 2). The
main area renders the text to be annotated, roughly
laid out in terms of paragraphs, lists, tables and non-
text sections according to the input XML data. Ad-
ditionally, predefined markables are underlined and
followed by boxes containing the markables’ unique
identifiers. These boxes serve as clickable buttons
to choose markables during the annotation. At this
</bodyText>
<footnote confidence="0.9982145">
6Serengeti is targeted at platform independence, so we’ve
chosen Firefox, which is freely available for several operating
systems. Future versions will support other browsers as well.
7Each Serengeti installation supports more than one work-
group. Server sided data management allows the use of ver-
sioning systems like CVS or, in our case, Subversion.
</footnote>
<page confidence="0.997432">
144
</page>
<bodyText confidence="0.99997875">
time, adding markables, i.e. changing the input
data, is not allowed.8 This ensures that all annota-
tors use the same base layer. A section at the bottom
of the interface represents the annotation panel with
a list of all annotated relations on the left and all
editing tools on the right side. An application bar at
the top of the GUI provides functions for choosing
and managing groups, documents and annotations.
</bodyText>
<subsectionHeader confidence="0.998507">
4.3 Annotation Process
</subsectionHeader>
<bodyText confidence="0.999963631578947">
After logging in and choosing a document to anno-
tate, new relations between markables can be cre-
ated. The markables that take part in the relation
are chosen by left-clicking the boxes attached to the
underlined markables in the text and, if necessary,
unchecked by clicking them once again. To encode
the type of a relation between chosen markables, an
input form at the bottom right of the page provides
various options for specifying the relation accord-
ing to the annotation scheme. The OKAY command
adds created relations to the list, which can subse-
quently be edited or deleted. In regard to their state,
relation bars in the list can be highlighted differ-
ently to simplify the post-editing (i. e. new relations,
old/saved relations, commented relations or incom-
plete relations).9 The user can save his work to the
server at any time. After the annotation process is
completed, the COMMIT command (located in the
document menu) declares the annotation as finished.
</bodyText>
<subsectionHeader confidence="0.9948865">
4.4 Comparing Annotations and Reaching a
Consensus
</subsectionHeader>
<bodyText confidence="0.99998">
In order to achieve the best annotation results it is
necessary to provide an opportunity for the evalua-
tion of single annotations or comparing of multiple
annotations on one single document (either by dif-
ferent annotators or identical annotators at different
points in time). This allows for verification of the
quality of the annotation scheme and for valid train-
ing data for automated natural language processing
tools. For this purpose, a special user access, the
Consensus User (CU), has been developed as part of
Serengeti’s concept. Loading a document as a CU, it
</bodyText>
<footnote confidence="0.9970354">
8The definition of XML elements as markables and the lay-
out and relation type specification is driven via an external con-
figuration script, adjustable for each group.
9It is possible to hide relations according to their state as
well.
</footnote>
<bodyText confidence="0.999676166666667">
is possible to choose a single annotation done by any
other annotator (either work in progress or commit-
ted) as the basis for the final annotation. This is done
with the same tools as those for the annotation pro-
cess. If satisfied, the CU can declare the annotation
as ultimately closed via the COMMIT command.
</bodyText>
<figureCaption confidence="0.9557905">
Figure 3: Serengeti’s comparison window in the
lower left part of the GUI.
</figureCaption>
<bodyText confidence="0.999663230769231">
Furthermore, the CU can compare two annota-
tions with each other. The relations annotated by
both users are then displayed in the relation list and
juxtaposed in case they differ in at least one aspect
(e. g. different relation types as in Figure 3).10 On
this basis the CU can decide which relation to accept
and which one to reject. Again, all editing options
are at the user’s disposal.
While editing single or multiple user annotations,
the CU can save the current state of his work at any
time. Afterwards these annotations will appear in
the ANNOTATIONS MENU as well and can be se-
lected for further evaluation and comparison.11
</bodyText>
<sectionHeader confidence="0.988602" genericHeader="method">
5 Extending Serengeti
</sectionHeader>
<bodyText confidence="0.95462205882353">
Although one might doubt that Serengeti is directly
applicable to annotating lexical chains, this can nev-
ertheless be done straightforwardly using the anno-
tation described in Section 2.1. Our starting point is
as follows: As markables we refer to entities of the
parser output (i. e. tokens) where a user can mark
a token as the initial vertex of a chain. In order
to reflect the findings of our case study on lexical
chaining we distinguish two cases: Either the an-
notator decides that a newly entered token enlarges
10At this point the assignment of relations is important.
Anaphoric relations, for example, are assigned to each other
if their anaphoric element is the same. If there is more than
one relation with identical anaphoric elements, the relations are
sorted by their relation types and their antecedent(s).
11Comparisons require conflictless annotations, i.e. saved
comparisons have to be free from juxtaposed relations.
</bodyText>
<page confidence="0.997548">
145
</page>
<figureCaption confidence="0.999392">
Figure 2: Serengeti’s User Interface. Screenshots of Serengeti Version 0.7.1
</figureCaption>
<bodyText confidence="0.999970739130435">
an already marked-up chain by explicitly relating it
to one of its links or he implicitly assigns the to-
ken to that chain as a whole which is visually rep-
resented as part of Serengeti’s interface. In the first
case we just face another use case of our annota-
tion scheme, that is, a link between two tokens or
spans of a text where this link may be typed accord-
ing to some linguistic relation that holds between the
spans, e. g. hyponymy. In the second case of an im-
plicit chain assignment we proceed as follows: We
link the newly processed token to the last vertex of
the lexical chain to which the token is attached and
type this relation non-specifically as association. As
a result, we reduce this use case to the one already
mapped by our general annotation scheme. In or-
der to make this a workable solution, we will in-
tegrate a representation of lexical chains by means
of tag clouds where each chain is represented by a
subset of those lexical units which because of their
frequency are most important in representing that
chain. Following this line of extending Serengeti, we
manage to use it as an annotation tool which handles
anaphoric relations as well as lexical chains.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="discussions">
6 Discussion and Outlook
</sectionHeader>
<bodyText confidence="0.999211333333334">
Serengeti can be used to create corpus data for
training and evaluation purposes. An installation
of Serengeti is available online.12 Currently, the
tool is being generalized to allow the annotation
of lexical chains and several other annotation tasks.
More specifically, we plan to incorporate any kind of
chain-like structuring of text segments and to make
the chains an object of annotation so that they can
be interrelated. This will allow to incorporate con-
stituency relations into the annotation process. Be-
yond that we will incorporate metadata handling to
document all steps of the annotation process.
</bodyText>
<sectionHeader confidence="0.998981" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987251">
P. S. Bayerl, H. Lüngen, D. Goecke, A. Witt, and
D. Naber. 2003. Methods for the Semantic Analy-
sis of Document Markup. In C. Roisin, E. Muson,
and C. Vanoirbeek, editors, Proceedings of the 2003
ACM symposium on Document engineering (DocEng),
pages 161–170, Grenoble. ACM Press.
</reference>
<footnote confidence="0.9050805">
12http://coli.lili.uni-bielefeld.de/
serengeti/
</footnote>
<page confidence="0.993475">
146
</page>
<bodyText confidence="0.541631833333333">
J. Morris and G. Hirst. 1991. Lexical cohesion computed
by thesaural relations as an indicator of the structure of
text. Computational linguistics, 17(1):21–48, March.
B. Beigman Klebanov. 2005. Using readers to identify
lexical cohesive structures in texts. In Proceedings of
ACL Student Research Workshop.
</bodyText>
<reference confidence="0.999551408602151">
S. Dipper, M. Götze, and M. Stede. 2004. Simple Anno-
tation Tools for Complex Annotation Tasks: an Evalu-
ation. In Proceedings of the LREC Workshop on XML-
based Richly Annotated Corpora, pages 54–62, Lis-
bon, Portugal.
C. Fellbaum, editor. 1998. WordNet. An Electronic Lexi-
cal Database. The MIT Press.
S. Fligelstone. 1992. Developing a Scheme for Annotat-
ing Text to Show Anaphoric Relations. In G. Leitner,
editor, New Directions in English Language Corpora:
Methodology, Results, Software Developments, pages
153–170. Mouton de Gruyter, Berlin.
J. J. Garrett, 2005. AJAX: A New Approach to Web
Applications. Adaptive Path LLC, February, 18.
Online: http://www.adaptivepath.com/
publications/essays/archives/000385.
php.
R. Garside, S. Fligelstone, and S. Botley. 1997. Dis-
course Annotation: Anaphoric Relations in Corpora.
In R. Garside, G. Leech, and A. McEnery, editors,
Corpus Annotation: Linguistic Information from Com-
puter Text Corpora, pages 66–84. Addison-Wesley
Longman, London.
D. Goecke and A. Witt. 2006. Exploiting Logical Docu-
ment Structure for Anaphora Resolution. In Proceed-
ings of the 5th International Conference., Genoa, Italy.
Michael A. K. Halliday and Ruqaiya Hasan. 1976. Co-
hesion in English. Longman, London.
L. Hirschmann. 1997. MUC-7 Coreference Task Defini-
tion (version 3.0). In L. Hirschman and N. Chinchor,
editors, Proceedings of Message Understanding Con-
ference (MUC-7).
A. Holler, J.-F. Maas, and A. Storrer. 2004. Exploiting
Coreference Annotations for Text-to-Hypertext Con-
version. In Proceeding of LREC, volume II, pages
651–654, Lisbon, Portugal.
L. Karttunen. 1976. Discourse Referents. Syntax and
Semantics: Notes from the Linguistic Underground,
7:363–385.
X. Ma, L. Haejoong, S. Bird, and K. Maeda. 2002.
Models and Tools for Collaborative Annotation. In
Proceedings of the Third International Conference on
Language Resources and Evaluation, Paris. European
Language Resources Association.
R. Mitkov. 2002. Anaphora Resolution. Longman, Lon-
don.
J. Morris and G. Hirst. 2004. Non-classical lexical
semantic relations. In Proceedings of HLT-NAACL
Workshop on Computational Lexical Semantics.
J. Morris and G. Hirst. 2005. The subjectivity of lexi-
cal cohesion in text. In J. C. Chanahan, C. Qu, and
J. Wiebe, editors, Computing attitude and affect in text.
Springer.
C. Müller and M.l Strube. 2001. Annotating Anaphoric
and Bridging Relations with MMAX. In Proceedings
of the 2nd SIGdial Workshop on Discourse and Dia-
logue, pages 90–95, Aalborg, Denmark.
C. Müller and M. Strube. 2003. Multi-Level Annotation
in MMAX. In Proceedings of the 4th SIGdial Work-
shop on Discourse and Dialogue, pages 198–207, Sap-
poro, Japan.
M. Poesio, T. Ishikawa, S. Schulte im Walde, and
R. Viera. 2002. Acquiring lexical knowledge for
anaphora resolution. In Proc. of the 3rd Conference
on Language Resources and Evaluation (LREC).
M. Poesio. 2004. The MATE/GNOME Scheme for
Anaphoric Annotation, Revisited. In Proceedings of
SIGDIAL, Boston, April.
G. Simons, W. Lewis, S. Farrar, T. Langendoen, B. Fitzsi-
mons, and H. Gonzalez. 2004. The semantics of
markup. In Proceedings of the ACL 2004 Workshop
on RDF/RDFS and OWL in Language Technology
(NLPXML-2004), Barcelona.
M. Strube and C. Müller. 2003. A Machine Learning
Approach to Pronoun Resolution in Spoken Dialogue.
In Proceedings of the 41st Annual Meeting on Associ-
ation for Computational Linguistics, volume 1, pages
168–175. ACL 03.
M. Stührenberg, A. Witt, D. Goecke, D. Metzing, and
O. Schonefeld. 2006. Multidimensional Markup
and Heterogeneous Linguistic Resources. In D. Ahn,
E. T. K. Sang, and G. Wilcock, editors, Proceedings of
the 5th Workshop on NLP and XML (NLPXML-2006):
Multi-Dimensional Markup in Natural Language Pro-
cessing, pages 85–88.
A. Witt, D. Goecke, F. Sasaki, and H. Lüngen.
2005. Unification of XML Documents with Con-
current Markup. Literary and Lingustic Computing,
20(1):103–116.
Y. Xiaofeng, J. Su, G. Zhou, and C. L. Tan. 2004. Im-
proving Pronoun Resolution by Incorporating Coref-
erential Information of Candidates. In Proceedings of
ACL.
</reference>
<page confidence="0.998093">
147
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.908019">
<title confidence="0.999495">Web-based Annotation of Anaphoric Relations and Lexical Chains</title>
<author confidence="0.976058">Stührenberg Goecke Diewald</author>
<affiliation confidence="0.999995">Bielefeld University</affiliation>
<address confidence="0.993825">Germany</address>
<email confidence="0.996048">{maik.stuehrenberg|daniela.goecke|nils.diewald|alexander.mehler}@uni-bielefeld.de</email>
<author confidence="0.991469">Irene Cramer</author>
<affiliation confidence="0.977336">Dortmund</affiliation>
<address confidence="0.987138">Germany</address>
<email confidence="0.999163">irene.cramer@uni-dortmund.de</email>
<abstract confidence="0.9981427">Annotating large text corpora is a timeconsuming effort. Although single-user annotation tools are available, web-based annotation applications allow for distributed annotation and file access from different locations. In this paper we present the webannotation application annotating anaphoric relations which will be extended for the annotation of lexical chains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P S Bayerl</author>
<author>H Lüngen</author>
<author>D Goecke</author>
<author>A Witt</author>
<author>D Naber</author>
</authors>
<title>Methods for the Semantic Analysis of Document Markup. In</title>
<date>2003</date>
<booktitle>Proceedings of the 2003 ACM symposium on Document engineering (DocEng),</booktitle>
<pages>161--170</pages>
<editor>C. Roisin, E. Muson, and C. Vanoirbeek, editors,</editor>
<publisher>ACM Press.</publisher>
<location>Grenoble.</location>
<contexts>
<context position="17937" citStr="Bayerl et al. (2003" startWordPosition="2679" endWordPosition="2682">one hand and provide central data management on the other hand. Therefore 2http://www.lat-mpi.eu/tools/elan/ 3http://www.dfki.de/~kipp/anvil/ 4http://agtk.sourceforge.net/ 5http://www.ltg.ed.ac.uk/NITE/ distributed annotation is possible regardless of location, provided that an internet connection is available. In this paper we propose the web-based annotation application Serengeti. 4 A new Approach: Serengeti As the Sekimo project is part of a research group with interrelated application domains, annotation layers from different projects have been evaluated for their interrelationship (e. g. Bayerl et al. (2003; 2006)). This led directly to the open design of Serengeti – an annotation tool with the fundamental idea in mind: making possible the annotation of a single layer (or resource) and the use of the best annotation possible and the best available resources. Serengeti allows for several experts to annotate a single text at the same time as well as to compare the different annotations (inter-annotatoragreement) and merge them afterwards. Access to the documents is available from everywhere (an internet connection and a browser is required). 4.1 Technical Overview Serengeti is a web application de</context>
</contexts>
<marker>Bayerl, Lüngen, Goecke, Witt, Naber, 2003</marker>
<rawString>P. S. Bayerl, H. Lüngen, D. Goecke, A. Witt, and D. Naber. 2003. Methods for the Semantic Analysis of Document Markup. In C. Roisin, E. Muson, and C. Vanoirbeek, editors, Proceedings of the 2003 ACM symposium on Document engineering (DocEng), pages 161–170, Grenoble. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dipper</author>
<author>M Götze</author>
<author>M Stede</author>
</authors>
<title>Simple Annotation Tools for Complex Annotation Tasks: an Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the LREC Workshop on XMLbased Richly Annotated Corpora,</booktitle>
<pages>54--62</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15727" citStr="Dipper et al. (2004)" startWordPosition="2343" endWordPosition="2347">a. We also intend to take advantage of – amongst other aspects – the inter-annotator comparison functionality provided by Serengeti (see Section 4 for a detailed description) in order to implement a formally correct inter-annotator agreement test. 3 Available Tools for Annotating Linguistic Corpora Both the anaphora resolution and the lexical chaining scenario have shown the importance of an easy143 to-use annotation tool. Although a wide range of annotation tools is available, one has to separate tools for annotating multimodal corpora from tools for annotating unimodal (i. e. text) corpora. Dipper et al. (2004) evaluated some of the most commonly used tools of both categories (TASX Annotator, EXMARaLDA, MMAX, PALinkA and Systematic Coder). Besides, other tools such as ELAN2 or Anvil3 are available as well, as are tool kits such as the Annotation Graph Toolkit (AGTK)4 or the NITE XML Toolkit.5 While multimodal annotation demands a framework supporting the time-aligned handling of video and audio streams and, therefore, much effort has been spent on the design and development of tools, unimodal annotation has often been fulfilled by using ordinary XML editors which can be error-prone. Nevertheless, sp</context>
</contexts>
<marker>Dipper, Götze, Stede, 2004</marker>
<rawString>S. Dipper, M. Götze, and M. Stede. 2004. Simple Annotation Tools for Complex Annotation Tasks: an Evaluation. In Proceedings of the LREC Workshop on XMLbased Richly Annotated Corpora, pages 54–62, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet. An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fligelstone</author>
</authors>
<title>Developing a Scheme for Annotating Text to Show Anaphoric Relations.</title>
<date>1992</date>
<booktitle>New Directions in English Language Corpora: Methodology, Results, Software Developments,</booktitle>
<pages>153--170</pages>
<editor>In G. Leitner, editor,</editor>
<location>Berlin.</location>
<contexts>
<context position="6663" citStr="Fligelstone, 1992" startWordPosition="1026" endWordPosition="1027">ees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e. the elements that can be part of a relation, have to be specified (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to b</context>
</contexts>
<marker>Fligelstone, 1992</marker>
<rawString>S. Fligelstone. 1992. Developing a Scheme for Annotating Text to Show Anaphoric Relations. In G. Leitner, editor, New Directions in English Language Corpora: Methodology, Results, Software Developments, pages 153–170. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Garrett</author>
</authors>
<title>AJAX: A New Approach to Web Applications. Adaptive Path LLC,</title>
<date>2005</date>
<contexts>
<context position="18730" citStr="Garrett (2005)" startWordPosition="2810" endWordPosition="2811">and the use of the best annotation possible and the best available resources. Serengeti allows for several experts to annotate a single text at the same time as well as to compare the different annotations (inter-annotatoragreement) and merge them afterwards. Access to the documents is available from everywhere (an internet connection and a browser is required). 4.1 Technical Overview Serengeti is a web application developed for Mozilla Firefox,6 thus its architecture is separated into a client and a server side, following the principles and tools of AJAX (Asynchronous JavaScript and XML, cf. Garrett (2005)). While groups, documents and annotations are managed centrally on the server side, all user interactions are rendered locally on the client side.7 4.2 Graphical User Interface The Graphical User Interface (GUI) of Serengeti is subdivided into several areas (cf. Figure 2). The main area renders the text to be annotated, roughly laid out in terms of paragraphs, lists, tables and nontext sections according to the input XML data. Additionally, predefined markables are underlined and followed by boxes containing the markables’ unique identifiers. These boxes serve as clickable buttons to choose m</context>
</contexts>
<marker>Garrett, 2005</marker>
<rawString>J. J. Garrett, 2005. AJAX: A New Approach to Web Applications. Adaptive Path LLC, February, 18.</rawString>
</citation>
<citation valid="false">
<note>Online: http://www.adaptivepath.com/ publications/essays/archives/000385. php.</note>
<marker></marker>
<rawString>Online: http://www.adaptivepath.com/ publications/essays/archives/000385. php.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
<author>S Fligelstone</author>
<author>S Botley</author>
</authors>
<title>Discourse Annotation: Anaphoric Relations in Corpora. In</title>
<date>1997</date>
<booktitle>Corpus Annotation: Linguistic Information from Computer Text Corpora,</booktitle>
<pages>66--84</pages>
<editor>R. Garside, G. Leech, and A. McEnery, editors,</editor>
<publisher>Addison-Wesley Longman,</publisher>
<location>London.</location>
<contexts>
<context position="6686" citStr="Garside et al., 1997" startWordPosition="1028" endWordPosition="1031">of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e. the elements that can be part of a relation, have to be specified (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to be annotated in advance.</context>
</contexts>
<marker>Garside, Fligelstone, Botley, 1997</marker>
<rawString>R. Garside, S. Fligelstone, and S. Botley. 1997. Discourse Annotation: Anaphoric Relations in Corpora. In R. Garside, G. Leech, and A. McEnery, editors, Corpus Annotation: Linguistic Information from Computer Text Corpora, pages 66–84. Addison-Wesley Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goecke</author>
<author>A Witt</author>
</authors>
<title>Exploiting Logical Document Structure for Anaphora Resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference.,</booktitle>
<location>Genoa, Italy.</location>
<marker>Goecke, Witt, 2006</marker>
<rawString>D. Goecke and A. Witt. 2006. Exploiting Logical Document Structure for Anaphora Resolution. In Proceedings of the 5th International Conference., Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>Ruqaiya Hasan</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English. Longman,</booktitle>
<location>London.</location>
<contexts>
<context position="1758" citStr="Halliday and Hasan, 1976" startWordPosition="245" endWordPosition="248">otation of large text corpora is a time consuming effort. Therefore, annotation tools are an indispensable means to overcome the limits of manual annotations. In spite of their limited level of automatization, such tools nevertheless help to semiautomatically support the annotation process and to secure consistency of manual annotations. This paper describes such an annotation tool which focuses on a certain type of discourse structures. More specifically, we deal with anaphoric relations and lexical cohesion. Our starting point is the observation that these two resources of textual cohesion (Halliday and Hasan, 1976) homogeneously induce chain-like discourse structures: one the one hand we have reference chains started by some antecedence and continued by some anaphora linked to the same antecedence. On the other hand, lexical cohesion generates so called lexical chains of semantically related tokens. Based on this observation we describe the annotation tool Serengeti which reflects this structural homogeneity on the level of its structural representation model as well as by its procedural annotation model. Serengeti includes an annotation scheme which is extended in order to support the annotation of ref</context>
<context position="10015" citStr="Halliday and Hasan, 1976" startWordPosition="1458" endWordPosition="1461">NOM&amp;quot; /&gt; &lt;chs:semRel&gt; &lt;chs:bridgingLink relType=&amp;quot;hasMember&amp;quot; antecedentIDRefs=&amp;quot;de8 de10&amp;quot; phorIDRef=&amp;quot;de12&amp;quot;/&gt; &lt;/chs:semRel&gt; &lt;/chs:chs&gt; types that specify the subtype of the relation, e. g. ident or hypernym as secondary types of cospecLink or meronym or setMember as secondary types of bridgingLink. An example annotation of an indirect anaphoric relation (element bridgingLink, line 30) between the discourse entities de12 (lines 18 to 21) and de8 (lines 3 to 5) and de10 (lines 9 to 11) can be seen in Listing 1. 2.2 Lexical Chaining Motivation and Background Based on the concept of lexical cohesion (Halliday and Hasan, 1976), computational linguists (inter alia Morris and Hirst (1991)) developed a method to compute a partial text representation: lexical chains. These span over passages or even the complete text linking lexical items. The exemplary annotation in Figure 1 illustrates that lexical chaining is achieved by the selection of vocabulary and significantly accounts for the cohesive structure of a text passage. Items in a lexical chain are connected via semantic relations. Accordingly, lexical chains are computed on the basis of a lexical semantic resource such as WordNet (Fellbaum, 1998). Figure 1 also dep</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Michael A. K. Halliday and Ruqaiya Hasan. 1976. Cohesion in English. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschmann</author>
</authors>
<title>MUC-7 Coreference Task Definition (version 3.0).</title>
<date>1997</date>
<booktitle>Proceedings of Message Understanding Conference (MUC-7).</booktitle>
<editor>In L. Hirschman and N. Chinchor, editors,</editor>
<contexts>
<context position="6743" citStr="Hirschmann, 1997" startWordPosition="1037" endWordPosition="1038">kes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e. the elements that can be part of a relation, have to be specified (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to be annotated in advance. Normally, for a domain under investigation, elements are</context>
</contexts>
<marker>Hirschmann, 1997</marker>
<rawString>L. Hirschmann. 1997. MUC-7 Coreference Task Definition (version 3.0). In L. Hirschman and N. Chinchor, editors, Proceedings of Message Understanding Conference (MUC-7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Holler</author>
<author>J-F Maas</author>
<author>A Storrer</author>
</authors>
<title>Exploiting Coreference Annotations for Text-to-Hypertext Conversion.</title>
<date>2004</date>
<booktitle>In Proceeding of LREC, volume II,</booktitle>
<pages>651--654</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="7668" citStr="Holler et al. (2004)" startWordPosition="1189" endWordPosition="1192">ied (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to be annotated in advance. Normally, for a domain under investigation, elements are denoted as being markables either via a specific element or via the use of a universal attribute. In our system, discourse entities are detected automatically on the basis of POS and parsing information. The annotation scheme for annotating anaphoric relations is an extension of the scheme presented by Holler et al. (2004) that has been developed for annotations in the context of text-to-hypertext conversion in the project B1 HyTex. We adopt the distinction between coreference and cospecification but we extend the annotation scheme for an explicit distinction between cospecification (direct anaphora) and bridging (associative or indirect anaphora). Thus, we add the primary relation type bridgingLink (denoting bridging) to the already existing one (cospecLink). Each primary relation type includes different secondary relation 141 Listing 1: The annotation format for anaphoric relations. Shortened and manually rev</context>
</contexts>
<marker>Holler, Maas, Storrer, 2004</marker>
<rawString>A. Holler, J.-F. Maas, and A. Storrer. 2004. Exploiting Coreference Annotations for Text-to-Hypertext Conversion. In Proceeding of LREC, volume II, pages 651–654, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Discourse Referents. Syntax and Semantics: Notes from the Linguistic Underground,</title>
<date>1976</date>
<pages>7--363</pages>
<contexts>
<context position="5390" citStr="Karttunen (1976)" startWordPosition="824" endWordPosition="825">S, distance information, grammatical function, semantic knowledge, see, for example, Mitkov (2002) for an overview). Several resources are applied to a corpus of 47 texts and the output structures are combined into a single XML document using the architecture mentioned above. In order not only to integrate but also evaluate resources for a given linguistic task formally in terms of precision and recall, it should be possible to either switch on or switch off a given resource. In the application domain of anaphora resolution evaluation is done as follows. Each discourse entity or referent (cf. Karttunen (1976)) is annotated as an XML element which holds a variety of attribute information. Each XML element is reinterpreted as a feature vector; pairs of discourse entities between which an anaphoric relation holds form a single feature vector with additional information relevant for anaphora resolution (e. g. distance information, identity of grammatical form, semantic relatedness of underlying lemmata and the like). In order to evaluate different resource settings, decision trees with varying sets of feature vectors are used for the process of anaphora resolution. Xiaofeng et al. (2004) or Strube and</context>
</contexts>
<marker>Karttunen, 1976</marker>
<rawString>L. Karttunen. 1976. Discourse Referents. Syntax and Semantics: Notes from the Linguistic Underground, 7:363–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ma</author>
<author>L Haejoong</author>
<author>S Bird</author>
<author>K Maeda</author>
</authors>
<title>Models and Tools for Collaborative Annotation.</title>
<date>2002</date>
<journal>European Language Resources Association.</journal>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation,</booktitle>
<location>Paris.</location>
<contexts>
<context position="16674" citStr="Ma et al. (2002)" startWordPosition="2496" endWordPosition="2499">work supporting the time-aligned handling of video and audio streams and, therefore, much effort has been spent on the design and development of tools, unimodal annotation has often been fulfilled by using ordinary XML editors which can be error-prone. Nevertheless, specialized annotation frameworks are available as well, e. g. MMAX can be used for multi-level annotation projects (cf. Müller and Strube (2001; 2003)). However, as annotation projects grow in size and complexity (often multiple annotation layers are generated), collaborative annotation and the use of annotation tools is vital. • Ma et al. (2002), for example, describe collaborative annotation in the context of the AGTK. But since most of the aforementioned applications have to be installed locally on a PC, working on a corpus and managing annotations externally can be difficult. • Another problem worth to be mentioned is data management. Having several annotators working on one text, unification and comparison of the markup produced is quite difficult. • Furthermore, annotation tools help to increase both the quality and quantity of the annotation process. Recent web technologies allow the design of webbased applications that resembl</context>
</contexts>
<marker>Ma, Haejoong, Bird, Maeda, 2002</marker>
<rawString>X. Ma, L. Haejoong, S. Bird, and K. Maeda. 2002. Models and Tools for Collaborative Annotation. In Proceedings of the Third International Conference on Language Resources and Evaluation, Paris. European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Anaphora Resolution.</title>
<date>2002</date>
<publisher>Longman,</publisher>
<location>London.</location>
<contexts>
<context position="4872" citStr="Mitkov (2002)" startWordPosition="735" endWordPosition="736">ut of different resources often cannot be encoded in a single structure without driving into incompatibilites (i. e. XML overlap). Therefore an architecture was developed which allows for the combination of the output structures of several linguistic resources into a single XML annotated document and which is described in detail in Witt et al. (2005) and Stührenberg et al. (2006) . 2.1 Anaphoric Relations Motivation and Background Resolving anaphoric relations needs a variety of different information (e. g. POS, distance information, grammatical function, semantic knowledge, see, for example, Mitkov (2002) for an overview). Several resources are applied to a corpus of 47 texts and the output structures are combined into a single XML document using the architecture mentioned above. In order not only to integrate but also evaluate resources for a given linguistic task formally in terms of precision and recall, it should be possible to either switch on or switch off a given resource. In the application domain of anaphora resolution evaluation is done as follows. Each discourse entity or referent (cf. Karttunen (1976)) is annotated as an XML element which holds a variety of attribute information. E</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>R. Mitkov. 2002. Anaphora Resolution. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Morris</author>
<author>G Hirst</author>
</authors>
<title>Non-classical lexical semantic relations.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL Workshop on Computational Lexical Semantics.</booktitle>
<contexts>
<context position="12744" citStr="Morris and Hirst, 2004" startWordPosition="1880" endWordPosition="1884">enced. The subjects were asked to read three texts – a wikipedia entry (137 words), a newspaper article (233 words), and an interview (306 words). They were then given a list of all nouns occurring in the articles (almost all chainers exclusively consider nouns as chaining candidates), which they had to rate with respect to their ’importance’ in understanding the text. On this basis they were asked to determine the semantic relations of every possible chaining candidate pair, thus chain the nouns and annotate the three texts. Just like previously reported case studies (Beigman Klebanov, 2005; Morris and Hirst, 2004; Morris and Hirst, 2005) aiming at the annotation of lexical chains, we found that the inter-annotator agreement was in general relatively low. Only the annotation of very prominent items in the three texts, which accounted for approximately one fifth of the chaining candidates, resulted in a satisfying agreement (that is: the majority of the subjects produced an identical or very similar annotation). However, all subjects complained about the task. They found it rather difficult to construct linearized or quasi-linearized structures, in short, chains. Instead, most of the subjects built clus</context>
<context position="14159" citStr="Morris and Hirst, 2004" startWordPosition="2106" endWordPosition="2109">g. This clearly supports our observation that most of the subjects first skimmed through the text to find the most prominent items, established chains for this selection and then worked the text over to distribute the remaining items to these chains. We therefore assume that lexical chains do not directly reflect reading and understanding processes. Nevertheless, they do in some way contribute to them. Many subjects additionally noted that a reasonable candidate list should also include multi-word units (e.g. technical terms) or even phrases. Furthermore, as already reported in previous work (Morris and Hirst, 2004), the semantic relations usually considered seem not to suffice. Accordingly, some subjects proposed new relations to characterize the links connecting candidate pairs. Given our own findings and the results reported in previous work, it is obviously demanding to find a clear-cut border between the concepts of lexical chaining, semantic fields, and coreference/anaphora resolution. Definitely, the annotation of co-reference/anaphora and lexical chains is inherently analogous. In both cases an annotation layer consisting of labelled edges between pairs of annotation candidates is constructed. Ho</context>
</contexts>
<marker>Morris, Hirst, 2004</marker>
<rawString>J. Morris and G. Hirst. 2004. Non-classical lexical semantic relations. In Proceedings of HLT-NAACL Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Morris</author>
<author>G Hirst</author>
</authors>
<title>The subjectivity of lexical cohesion in text. In</title>
<date>2005</date>
<editor>J. C. Chanahan, C. Qu, and J. Wiebe, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="12769" citStr="Morris and Hirst, 2005" startWordPosition="1885" endWordPosition="1888"> asked to read three texts – a wikipedia entry (137 words), a newspaper article (233 words), and an interview (306 words). They were then given a list of all nouns occurring in the articles (almost all chainers exclusively consider nouns as chaining candidates), which they had to rate with respect to their ’importance’ in understanding the text. On this basis they were asked to determine the semantic relations of every possible chaining candidate pair, thus chain the nouns and annotate the three texts. Just like previously reported case studies (Beigman Klebanov, 2005; Morris and Hirst, 2004; Morris and Hirst, 2005) aiming at the annotation of lexical chains, we found that the inter-annotator agreement was in general relatively low. Only the annotation of very prominent items in the three texts, which accounted for approximately one fifth of the chaining candidates, resulted in a satisfying agreement (that is: the majority of the subjects produced an identical or very similar annotation). However, all subjects complained about the task. They found it rather difficult to construct linearized or quasi-linearized structures, in short, chains. Instead, most of the subjects built clusters and drew very comple</context>
</contexts>
<marker>Morris, Hirst, 2005</marker>
<rawString>J. Morris and G. Hirst. 2005. The subjectivity of lexical cohesion in text. In J. C. Chanahan, C. Qu, and J. Wiebe, editors, Computing attitude and affect in text. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Müller</author>
<author>M l Strube</author>
</authors>
<title>Annotating Anaphoric and Bridging Relations with MMAX.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>90--95</pages>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="16469" citStr="Müller and Strube (2001" startWordPosition="2463" endWordPosition="2466">atic Coder). Besides, other tools such as ELAN2 or Anvil3 are available as well, as are tool kits such as the Annotation Graph Toolkit (AGTK)4 or the NITE XML Toolkit.5 While multimodal annotation demands a framework supporting the time-aligned handling of video and audio streams and, therefore, much effort has been spent on the design and development of tools, unimodal annotation has often been fulfilled by using ordinary XML editors which can be error-prone. Nevertheless, specialized annotation frameworks are available as well, e. g. MMAX can be used for multi-level annotation projects (cf. Müller and Strube (2001; 2003)). However, as annotation projects grow in size and complexity (often multiple annotation layers are generated), collaborative annotation and the use of annotation tools is vital. • Ma et al. (2002), for example, describe collaborative annotation in the context of the AGTK. But since most of the aforementioned applications have to be installed locally on a PC, working on a corpus and managing annotations externally can be difficult. • Another problem worth to be mentioned is data management. Having several annotators working on one text, unification and comparison of the markup produced</context>
</contexts>
<marker>Müller, Strube, 2001</marker>
<rawString>C. Müller and M.l Strube. 2001. Annotating Anaphoric and Bridging Relations with MMAX. In Proceedings of the 2nd SIGdial Workshop on Discourse and Dialogue, pages 90–95, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Müller</author>
<author>M Strube</author>
</authors>
<title>Multi-Level Annotation in MMAX.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>198--207</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="7081" citStr="Müller and Strube (2003)" startWordPosition="1094" endWordPosition="1097">he Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e. the elements that can be part of a relation, have to be specified (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to be annotated in advance. Normally, for a domain under investigation, elements are denoted as being markables either via a specific element or via the use of a universal attribute. In our system, discourse entities are detected automatically on the basis of POS and parsing information. The annotation scheme for annotating anaphoric relations is an extension of the scheme presented by Holler et al. (2004) that has bee</context>
</contexts>
<marker>Müller, Strube, 2003</marker>
<rawString>C. Müller and M. Strube. 2003. Multi-Level Annotation in MMAX. In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue, pages 198–207, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>T Ishikawa</author>
<author>S Schulte im Walde</author>
<author>R Viera</author>
</authors>
<title>Acquiring lexical knowledge for anaphora resolution.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="6384" citStr="Poesio et al., 2002" startWordPosition="983" endWordPosition="986">s of underlying lemmata and the like). In order to evaluate different resource settings, decision trees with varying sets of feature vectors are used for the process of anaphora resolution. Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e</context>
</contexts>
<marker>Poesio, Ishikawa, Walde, Viera, 2002</marker>
<rawString>M. Poesio, T. Ishikawa, S. Schulte im Walde, and R. Viera. 2002. Acquiring lexical knowledge for anaphora resolution. In Proc. of the 3rd Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>The MATE/GNOME Scheme for Anaphoric Annotation, Revisited.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGDIAL,</booktitle>
<location>Boston,</location>
<contexts>
<context position="6785" citStr="Poesio, 2004" startWordPosition="1044" endWordPosition="1045">on set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e.g. the UCREL anaphora annotation scheme (Fligelstone, 1992; Garside et al., 1997), the SGML-based MUC annotation scheme (Hirschmann, 1997), and the MATE/GNOME Scheme (Poesio, 2004), amongst others. In order to annotate discourse relations – either anaphoric relations or lexical chains (cf. Section 2.2) – two types of information have to be specified. First, the markables, i. e. the elements that can be part of a relation, have to be specified (cf. Müller and Strube (2003)). Second, the relation(s) between markables and their respective types and subtypes have to be defined. The markables form a basis for the annotation process and therefore have to be annotated in advance. Normally, for a domain under investigation, elements are denoted as being markables either via a s</context>
</contexts>
<marker>Poesio, 2004</marker>
<rawString>M. Poesio. 2004. The MATE/GNOME Scheme for Anaphoric Annotation, Revisited. In Proceedings of SIGDIAL, Boston, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Simons</author>
<author>W Lewis</author>
<author>S Farrar</author>
<author>T Langendoen</author>
<author>B Fitzsimons</author>
<author>H Gonzalez</author>
</authors>
<title>The semantics of markup.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL 2004 Workshop on RDF/RDFS and OWL in Language Technology (NLPXML-2004),</booktitle>
<location>Barcelona.</location>
<marker>Simons, Lewis, Farrar, Langendoen, Fitzsimons, Gonzalez, 2004</marker>
<rawString>G. Simons, W. Lewis, S. Farrar, T. Langendoen, B. Fitzsimons, and H. Gonzalez. 2004. The semantics of markup. In Proceedings of the ACL 2004 Workshop on RDF/RDFS and OWL in Language Technology (NLPXML-2004), Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>C Müller</author>
</authors>
<title>A Machine Learning Approach to Pronoun Resolution in Spoken Dialogue.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>168--175</pages>
<contexts>
<context position="6004" citStr="Strube and Müller (2003)" startWordPosition="920" endWordPosition="923">nen (1976)) is annotated as an XML element which holds a variety of attribute information. Each XML element is reinterpreted as a feature vector; pairs of discourse entities between which an anaphoric relation holds form a single feature vector with additional information relevant for anaphora resolution (e. g. distance information, identity of grammatical form, semantic relatedness of underlying lemmata and the like). In order to evaluate different resource settings, decision trees with varying sets of feature vectors are used for the process of anaphora resolution. Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been developed in the last years, e</context>
</contexts>
<marker>Strube, Müller, 2003</marker>
<rawString>M. Strube and C. Müller. 2003. A Machine Learning Approach to Pronoun Resolution in Spoken Dialogue. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, volume 1, pages 168–175. ACL 03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stührenberg</author>
<author>A Witt</author>
<author>D Goecke</author>
<author>D Metzing</author>
<author>O Schonefeld</author>
</authors>
<title>Multidimensional Markup and Heterogeneous Linguistic Resources. In</title>
<date>2006</date>
<booktitle>Proceedings of the 5th Workshop on NLP and XML (NLPXML-2006): Multi-Dimensional Markup in Natural Language Processing,</booktitle>
<pages>85--88</pages>
<editor>D. Ahn, E. T. K. Sang, and G. Wilcock, editors,</editor>
<contexts>
<context position="4641" citStr="Stührenberg et al. (2006)" startWordPosition="698" endWordPosition="702">erface is necessary due to different reasons: The resources used have often been developed independently from each other and a cascaded application of one resource to the output of another resource is not always possible. Furthermore, the output of different resources often cannot be encoded in a single structure without driving into incompatibilites (i. e. XML overlap). Therefore an architecture was developed which allows for the combination of the output structures of several linguistic resources into a single XML annotated document and which is described in detail in Witt et al. (2005) and Stührenberg et al. (2006) . 2.1 Anaphoric Relations Motivation and Background Resolving anaphoric relations needs a variety of different information (e. g. POS, distance information, grammatical function, semantic knowledge, see, for example, Mitkov (2002) for an overview). Several resources are applied to a corpus of 47 texts and the output structures are combined into a single XML document using the architecture mentioned above. In order not only to integrate but also evaluate resources for a given linguistic task formally in terms of precision and recall, it should be possible to either switch on or switch off a gi</context>
</contexts>
<marker>Stührenberg, Witt, Goecke, Metzing, Schonefeld, 2006</marker>
<rawString>M. Stührenberg, A. Witt, D. Goecke, D. Metzing, and O. Schonefeld. 2006. Multidimensional Markup and Heterogeneous Linguistic Resources. In D. Ahn, E. T. K. Sang, and G. Wilcock, editors, Proceedings of the 5th Workshop on NLP and XML (NLPXML-2006): Multi-Dimensional Markup in Natural Language Processing, pages 85–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Witt</author>
<author>D Goecke</author>
<author>F Sasaki</author>
<author>H Lüngen</author>
</authors>
<date>2005</date>
<booktitle>Unification of XML Documents with Concurrent Markup. Literary and Lingustic Computing,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="4611" citStr="Witt et al. (2005)" startWordPosition="693" endWordPosition="696">ces via an abstract interface is necessary due to different reasons: The resources used have often been developed independently from each other and a cascaded application of one resource to the output of another resource is not always possible. Furthermore, the output of different resources often cannot be encoded in a single structure without driving into incompatibilites (i. e. XML overlap). Therefore an architecture was developed which allows for the combination of the output structures of several linguistic resources into a single XML annotated document and which is described in detail in Witt et al. (2005) and Stührenberg et al. (2006) . 2.1 Anaphoric Relations Motivation and Background Resolving anaphoric relations needs a variety of different information (e. g. POS, distance information, grammatical function, semantic knowledge, see, for example, Mitkov (2002) for an overview). Several resources are applied to a corpus of 47 texts and the output structures are combined into a single XML document using the architecture mentioned above. In order not only to integrate but also evaluate resources for a given linguistic task formally in terms of precision and recall, it should be possible to eithe</context>
</contexts>
<marker>Witt, Goecke, Sasaki, Lüngen, 2005</marker>
<rawString>A. Witt, D. Goecke, F. Sasaki, and H. Lüngen. 2005. Unification of XML Documents with Concurrent Markup. Literary and Lingustic Computing, 20(1):103–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Xiaofeng</author>
<author>J Su</author>
<author>G Zhou</author>
<author>C L Tan</author>
</authors>
<title>Improving Pronoun Resolution by Incorporating Coreferential Information of Candidates.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5976" citStr="Xiaofeng et al. (2004)" startWordPosition="915" endWordPosition="918">ty or referent (cf. Karttunen (1976)) is annotated as an XML element which holds a variety of attribute information. Each XML element is reinterpreted as a feature vector; pairs of discourse entities between which an anaphoric relation holds form a single feature vector with additional information relevant for anaphora resolution (e. g. distance information, identity of grammatical form, semantic relatedness of underlying lemmata and the like). In order to evaluate different resource settings, decision trees with varying sets of feature vectors are used for the process of anaphora resolution. Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets. Both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (Poesio et al., 2002). Scheme and annotation process are described in the following section. The Annotation Scheme for Anaphoric Relations Several annotation schemes for annotating anaphoric relations have been de</context>
</contexts>
<marker>Xiaofeng, Su, Zhou, Tan, 2004</marker>
<rawString>Y. Xiaofeng, J. Su, G. Zhou, and C. L. Tan. 2004. Improving Pronoun Resolution by Incorporating Coreferential Information of Candidates. In Proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>