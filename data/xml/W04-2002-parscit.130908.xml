<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.144088">
<title confidence="0.964632">
Robust Models of Human Parsing
</title>
<author confidence="0.993383">
Frank Keller
</author>
<affiliation confidence="0.998935">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.7711535">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.995565">
keller@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.94016" genericHeader="abstract">
1 Robustness and Human Parsing
</sectionHeader>
<bodyText confidence="0.999523245283019">
A striking property of the human parser is its effi-
ciency and robustness. For the vast majority of sen-
tences, the parser will effortlessly and rapidly de-
liver the correct analysis. In doing so, it is robust to
noise, i.e., it can provide an analysis even if the input
is distorted, e.g., by ungrammaticalities. Further-
more, the human parser achieves broad coverage:
it deals with a wide variety of syntactic construc-
tions, and is not restricted by the domain, genre, or
modality of the input.
Current research on human parsing rarely investi-
gates the issues of efficiency, robustness, and broad
coverage, as pointed out by Crocker and Brants
(2000). Instead, most researchers have focussed on
the difficulties that the human parser has with cer-
tain types of sentences. Based on the study of gar-
den path sentences (which involve a local ambiguity
that makes the sentence hard to process), theories
have been developed that successfully explain how
the human parser deals with ambiguities in the in-
put. However, garden path sentences are arguably
a pathological case for the parser; garden paths are
not representative of naturally occurring text. This
means that the corresponding processing theories
face a scaling problem: it is not clear how they can
explain the normal behavior of the human parser,
where sentence processing is highly efficient and
very robust (see Crocker and Brants 2000 for details
on this scalability argument).
This criticism applies to most existing theories
of human parsing, including the classical garden
path model advanced by Frazier and Rayner (1982)
and Frazier (1989), and more recent lexicalist pars-
ing frameworks, of which MacDonald et al. (1994)
and MacDonald (1994) are representative examples.
Both the garden path model and the lexicalist model
are designed to deal with idealized input, i.e., with
input that is (locally) ambiguous, but fully well-
formed. A real life parser, however, has to cope
with a large amount of noise, which often renders
the input ungrammatical or fragmentary, due to er-
rors such as typographical mistakes in the case of
text, or slips of the tongue, disfluencies, or repairs
in the case of speech. A quick search in the Penn
Treebank (Marcus et al., 1993) shows that about
17% of all sentences contain parentheticals or other
sentence fragments, interjections, or unbracketable
constituents. Note that this figure holds for carefully
edited newspaper text; the figure is likely to be much
higher for speech. The human parser is robust to
such noise, i.e., it is able to assign an (approximate)
analysis to a sentence even if it is ungrammatical or
fragmentary.
</bodyText>
<sectionHeader confidence="0.946194" genericHeader="method">
2 Probabilistic Parsing Models
</sectionHeader>
<bodyText confidence="0.999983042553191">
In computational linguistics, probabilistic ap-
proaches to language processing play a central
role. Significant advances toward robust, broad-
coverage parsing models have been made based on
probabilistic techniques such as maximum likeli-
hood estimation or expectation maximization (for
an overview, see Manning and Sch¨utze, 1999).
An example of a simple probabilistic pars-
ing model are probabilistic context-free grammars
(PCFGs), which extend the formalism of context-
free grammars (CFGs) by annotating each rule with
a probability. PCFGs constitute an efficient, well-
understood technique for assigning probabilities to
the analyses produced by a context-free grammar.
They are commonly used for broad-coverage gram-
mars, as CFGs large enough to parse unrestricted
text are typically highly ambiguous, i.e., a single
sentence will receive a large number of parses. The
probabilistic component of the grammar can then be
used to rank the analyses a sentence might receive,
and improbable ones can be eliminated.
In the computational linguistics literature, a num-
ber of highly successful extensions to the basic
PCFG model have been proposed. Of particular in-
terest are lexicalized parsing models such as the
ones developed by Collins (1996, 1997) and Carroll
and Rooth (1998).
In the human parsing literature, a PCFG-based
model has been proposed by Jurafsky (1996) and
Narayanan and Jurafsky (1998). This model shows
how different sources of probabilistic information
(such as subcategorization information and rule fre-
quencies) can be combined using Bayesian infer-
ence. The model accounts for a range of disam-
biguation phenomena in linguistic processing. How-
ever, the model is only small scale, and it is not clear
if it can be extended to provide robustness and cov-
erage of unrestricted text.
This problem is addressed by Brants and Crocker
(2000) and Crocker and Brants (2000), who pro-
pose a broad-coverage model of human parsing
based on PCFGs. This model is incremental, i.e.,
it makes word-by-word predictions, thus mimick-
ing the behavior of the human parser. Also, Brants
and Crocker’s (2000) model imposes memory re-
strictions on the parser that are inspired by findings
from the human sentence processing literature.
</bodyText>
<sectionHeader confidence="0.997301" genericHeader="method">
3 Robust Models of Human Parsing
</sectionHeader>
<bodyText confidence="0.999982116666667">
The main weakness of both the Narayanan/Jurafsky
and the Crocker/Brants model (discussed in the pre-
vious section) is that they have not been evaluated
systematically. The authors only describe the per-
formance of their models on a small set of hand-
picked example sentences. No attempts are made
to test the models against a full set of experimental
materials and the corresponding reading times, even
though a large amount of suitable data are available
in the literature. This makes it very hard to obtain a
realistic estimate of how well these models achieve
the aim of providing robust, broad coverage mod-
els of human parsing. This can only be assessed by
testing the models against realistic samples of unre-
stricted text or speech obtained from corpora.
In this talk, we will present work that aims
to perform such an evaluation. We train a se-
ries of increasingly sophisticated probabilistic pars-
ing models on an identical training set (the Penn
Treebank). These models include a standard un-
lexicalized PCFG parser, a head-lexicalized parser
(Collins, 1997), and a maximum-entropy inspired
parser (Charniak, 2000). We test all three models
on the Embra corpus, a corpus of newspaper texts
annotated with eye-tracking data from 23 subjects
(McDonald and Shillcock, 2003). A series of re-
gression analyses are conducted to determine if per-
sentence reading time measures correlate with sen-
tence probabilities predicted by the parsing models.
Three baseline models are also included in the eval-
uation: word frequency, bigram and trigram prob-
ability (as predicted by a language model), and
part of speech (POS) probability (as predicted by
a POS tagger). Models based on n-grams have al-
ready been used successfully to model eye-tracking
data, both on a word-by-word basis (McDonald and
Shillcock, 2003) and for whole sentences (Keller,
2004).
Our results show that for all three parsing models,
sentence probability is significantly correlated with
reading times measures. However, the models differ
as to whether they predict early or late measures:
the PCFG and the Collins model significantly pre-
dict late reading time measures (total time and gaze
duration), but not early measures (first fixation time
and skipping rate). The Charniak model is able to
significantly predict both early and late measures.
An analysis of the baseline models shows that
word frequency and POS probability only predict
early measures, while bigram and trigram probabil-
ity only predict late measures. This indicates that
the Charniak model is able to predict both early and
late measures because it successfully combines lex-
ical information (word frequencies and POS proba-
bilities) with phrasal information (as modeled by a
PCFG). This finding is in line with Charniak’s own
analysis, which shows that the high performance of
his model is due to the fact that it combines a third-
order Markov grammar with sophisticated phrasal
and lexical features (Charniak, 2000).
</bodyText>
<sectionHeader confidence="0.998341" genericHeader="method">
4 Implications
</sectionHeader>
<bodyText confidence="0.999966111111111">
The results reported in the previous section have in-
teresting theoretical implications. Firstly, there is a
methodological lesson here: simple baseline mod-
els based on n-gram or POS probabilities perform
surprisingly well as robust, broad coverage models
of human language processing. This is an important
point that has not been recognized in the literature,
as previous models have not been tested on realis-
tic corpus samples, and have not been compared to
plausible baselines.
A second point concerns the role of lexical in-
formation in human parsing. We found that the
best performing model was Charniak’s maximum
entropy-inspired parser, which combines lexical and
phrasal information, and manages to predict both
early and late eye-tracking measures. A number of
existing theories of human parsing incorporate lexi-
cal information (MacDonald et al., 1994; MacDon-
ald, 1994), but have so far failed to demonstrate
how the use of such information can be scaled up
to yield robust, broad coverage parsing models that
can be tested on realistic data such as the Embra
eye-tracking corpus.
Finally, a major challenge that remains is the
crosslinguistic aspect of human parsing. Virtually
all existing computational models have only been
implemented and tested for English data. However,
a wide range of interesting problems arise for other
languages. An examples are head-final languages, in
which the probabilistic information associated with
the head becomes available only at the end of the
phrase, which poses a potential problem for incre-
mental parsing models. Some initial results on a
limited dataset have been obtained by Baldewein
and Keller (2004) for head-final constructions in
German.
</bodyText>
<sectionHeader confidence="0.808523" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.954037529411765">
Baldewein, Ulrike and Frank Keller. 2004. Mod-
eling attachment decisions with a probabilistic
parser: The case of head final structures. In Pro-
ceedings of the 26th Annual Conference of the
Cognitive Science Society. Chicago.
Brants, Thorsten and Matthew W. Crocker. 2000.
Probabilistic parsing and psychological plausi-
bility. In Proceedings of the 18th Interna-
tional Conference on Computational Linguistics.
Saarbr¨ucken/Luxembourg/Nancy.
Carroll, Glenn and Mats Rooth. 1998. Valence in-
duction with a head-lexicalized PCFG. In Pro-
ceedings of the Conference on Empirical Meth-
ods in Natural Language Processing. Granada,
pages 36–45.
Charniak, Eugene. 2000. A maximum-entropy-
inspired parser. In Proceedings of the 1st Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics. Seattle,
WA, pages 132–139.
Collins, Michael. 1996. A new statistical parser
based on bigram lexical dependencies. In Pro-
ceedings of the 34th Annual Meeting of the As-
sociation for Computational Linguistics. Santa
Cruz, CA, pages 184–191.
Collins, Michael. 1997. Three generative, lexi-
calised models for statistical parsing. In Pro-
ceedings of the 35th Annual Meeting of the
Association for Computational Linguistics and
the 8th Conference of the European Chapter of
the Association for Computational Linguistics.
Madrid, pages 16–23.
Crocker, Matthew W. and Thorsten Brants. 2000.
Wide-coverage probabilistic sentence processing.
</bodyText>
<reference confidence="0.968543522727272">
Journal of Psycholinguistic Research 29(6):647–
669.
Frazier, Lynn. 1989. Against lexical generation of
syntax. In William D. Marslen-Wilson, editor,
Lexical Representation and Process, MIT Press,
Cambridge, Mass., pages 505–528.
Frazier, Lynn and Keith Rayner. 1982. Making
and correcting errors during sentence comprehen-
sion: Eye movements in the analysis of struc-
turally ambiguous sentences. Cognitive Psychol-
ogy 14:178–210.
Jurafsky, Daniel. 1996. A probabilistic model of
lexical and syntactic access and disambiguation.
Cognitive Science 20(2):137–194.
Keller, Frank. 2004. The entropy rate principle as
a predictor of processing effort: An evaluation
against eye-tracking data. In Dekang Lin and
Dekai Wu, editors, Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing. Barcelona.
MacDonald, Maryellen C. 1994. Probabilistic con-
straints and syntactic ambiguity resolution. Lan-
guage and Cognitive Processes 9:157–201.
MacDonald, Maryellen C., Neal J. Pearlmutter, and
Mark S. Seidenberg. 1994. Lexical nature of syn-
tactic ambiguity resolution. Psychological Re-
view 101:676–703.
Manning, Christopher D. and Hinrich Sch¨utze.
1999. Foundations of Statistical Natural Lan-
guage Processing. MIT Press, Cambridge, MA.
Marcus, Mitchell P., Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building a large
annotated corpus of English: The Penn Treebank.
Computational Linguistics 19(2):313–330.
McDonald, Scott A. and Richard C. Shillcock.
2003. Low-level predictive inference in reading:
The influence of transitional probabilities on eye
movements. Vision Research 43:1735–1751.
Narayanan, Srini and Daniel Jurafsky. 1998.
Bayesian models of human sentence processing.
In Morton A. Gernsbacher and Sharon J. Derry,
editors, Proceedings of the 20th Annual Confer-
ence of the Cognitive Science Society. Lawrence
Erlbaum Associates, Mahwah, NJ.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.998322">Robust Models of Human Parsing</title>
<author confidence="0.998539">Frank</author>
<affiliation confidence="0.965265666666667">School of University of 2 Buccleuch</affiliation>
<address confidence="0.696906">Edinburgh EH8 9LW,</address>
<email confidence="0.794863">keller@inf.ed.ac.uk</email>
<abstract confidence="0.99581335">1 Robustness and Human Parsing A striking property of the human parser is its efficiency and robustness. For the vast majority of sentences, the parser will effortlessly and rapidly deliver the correct analysis. In doing so, it is robust to noise, i.e., it can provide an analysis even if the input is distorted, e.g., by ungrammaticalities. Furthermore, the human parser achieves broad coverage: it deals with a wide variety of syntactic constructions, and is not restricted by the domain, genre, or modality of the input. Current research on human parsing rarely investigates the issues of efficiency, robustness, and broad coverage, as pointed out by Crocker and Brants (2000). Instead, most researchers have focussed on the human parser has with certain types of sentences. Based on the study of garden path sentences (which involve a local ambiguity that makes the sentence hard to process), theories have been developed that successfully explain how the human parser deals with ambiguities in the input. However, garden path sentences are arguably a pathological case for the parser; garden paths are not representative of naturally occurring text. This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument). This criticism applies to most existing theories of human parsing, including the classical garden path model advanced by Frazier and Rayner (1982) and Frazier (1989), and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in the Penn Treebank (Marcus et al., 1993) shows that about 17% of all sentences contain parentheticals or other sentence fragments, interjections, or unbracketable constituents. Note that this figure holds for carefully edited newspaper text; the figure is likely to be much higher for speech. The human parser is robust to such noise, i.e., it is able to assign an (approximate) analysis to a sentence even if it is ungrammatical or fragmentary. 2 Probabilistic Parsing Models In computational linguistics, probabilistic approaches to language processing play a central role. Significant advances toward robust, broadcoverage parsing models have been made based on probabilistic techniques such as maximum likelihood estimation or expectation maximization (for an overview, see Manning and Sch¨utze, 1999). An example of a simple probabilistic parsing model are probabilistic context-free grammars (PCFGs), which extend the formalism of contextfree grammars (CFGs) by annotating each rule with a probability. PCFGs constitute an efficient, wellunderstood technique for assigning probabilities to the analyses produced by a context-free grammar. They are commonly used for broad-coverage grammars, as CFGs large enough to parse unrestricted text are typically highly ambiguous, i.e., a single sentence will receive a large number of parses. The probabilistic component of the grammar can then be used to rank the analyses a sentence might receive, and improbable ones can be eliminated. In the computational linguistics literature, a number of highly successful extensions to the basic PCFG model have been proposed. Of particular interest are lexicalized parsing models such as the ones developed by Collins (1996, 1997) and Carroll and Rooth (1998). In the human parsing literature, a PCFG-based model has been proposed by Jurafsky (1996) and Narayanan and Jurafsky (1998). This model shows how different sources of probabilistic information (such as subcategorization information and rule frequencies) can be combined using Bayesian inference. The model accounts for a range of disambiguation phenomena in linguistic processing. However, the model is only small scale, and it is not clear if it can be extended to provide robustness and coverage of unrestricted text. This problem is addressed by Brants and Crocker (2000) and Crocker and Brants (2000), who propose a broad-coverage model of human parsing based on PCFGs. This model is incremental, i.e., it makes word-by-word predictions, thus mimicking the behavior of the human parser. Also, Brants and Crocker’s (2000) model imposes memory restrictions on the parser that are inspired by findings from the human sentence processing literature. 3 Robust Models of Human Parsing The main weakness of both the Narayanan/Jurafsky and the Crocker/Brants model (discussed in the previous section) is that they have not been evaluated systematically. The authors only describe the performance of their models on a small set of handpicked example sentences. No attempts are made to test the models against a full set of experimental materials and the corresponding reading times, even though a large amount of suitable data are available in the literature. This makes it very hard to obtain a realistic estimate of how well these models achieve the aim of providing robust, broad coverage models of human parsing. This can only be assessed by testing the models against realistic samples of unrestricted text or speech obtained from corpora. In this talk, we will present work that aims to perform such an evaluation. We train a series of increasingly sophisticated probabilistic parsing models on an identical training set (the Penn Treebank). These models include a standard unlexicalized PCFG parser, a head-lexicalized parser (Collins, 1997), and a maximum-entropy inspired parser (Charniak, 2000). We test all three models on the Embra corpus, a corpus of newspaper texts annotated with eye-tracking data from 23 subjects (McDonald and Shillcock, 2003). A series of regression analyses are conducted to determine if persentence reading time measures correlate with sentence probabilities predicted by the parsing models. Three baseline models are also included in the evaluation: word frequency, bigram and trigram probability (as predicted by a language model), and part of speech (POS) probability (as predicted by POS tagger). Models based on have already been used successfully to model eye-tracking data, both on a word-by-word basis (McDonald and Shillcock, 2003) and for whole sentences (Keller, 2004). Our results show that for all three parsing models, sentence probability is significantly correlated with reading times measures. However, the models differ as to whether they predict early or late measures: the PCFG and the Collins model significantly predict late reading time measures (total time and gaze duration), but not early measures (first fixation time and skipping rate). The Charniak model is able to significantly predict both early and late measures. An analysis of the baseline models shows that word frequency and POS probability only predict early measures, while bigram and trigram probability only predict late measures. This indicates that the Charniak model is able to predict both early and late measures because it successfully combines lexical information (word frequencies and POS probabilities) with phrasal information (as modeled by a PCFG). This finding is in line with Charniak’s own analysis, which shows that the high performance of his model is due to the fact that it combines a thirdorder Markov grammar with sophisticated phrasal and lexical features (Charniak, 2000). 4 Implications The results reported in the previous section have interesting theoretical implications. Firstly, there is a methodological lesson here: simple baseline modbased on or POS probabilities perform surprisingly well as robust, broad coverage models of human language processing. This is an important point that has not been recognized in the literature, as previous models have not been tested on realistic corpus samples, and have not been compared to plausible baselines. A second point concerns the role of lexical information in human parsing. We found that the best performing model was Charniak’s maximum entropy-inspired parser, which combines lexical and phrasal information, and manages to predict both early and late eye-tracking measures. A number of existing theories of human parsing incorporate lexical information (MacDonald et al., 1994; MacDonald, 1994), but have so far failed to demonstrate how the use of such information can be scaled up to yield robust, broad coverage parsing models that can be tested on realistic data such as the Embra eye-tracking corpus. Finally, a major challenge that remains is the crosslinguistic aspect of human parsing. Virtually all existing computational models have only been implemented and tested for English data. However, a wide range of interesting problems arise for other languages. An examples are head-final languages, in which the probabilistic information associated with the head becomes available only at the end of the phrase, which poses a potential problem for incremental parsing models. Some initial results on a limited dataset have been obtained by Baldewein and Keller (2004) for head-final constructions in German.</abstract>
<note confidence="0.870955307692308">References Baldewein, Ulrike and Frank Keller. 2004. Modeling attachment decisions with a probabilistic The case of head final structures. In Proceedings of the 26th Annual Conference of the Science Chicago. Brants, Thorsten and Matthew W. Crocker. 2000. Probabilistic parsing and psychological plausi- In of the 18th Interna- Conference on Computational Saarbr¨ucken/Luxembourg/Nancy. Carroll, Glenn and Mats Rooth. 1998. Valence inwith a head-lexicalized PCFG. In Pro-</note>
<affiliation confidence="0.8390235">ceedings of the Conference on Empirical Methin Natural Language Granada,</affiliation>
<address confidence="0.671732">pages 36–45. Charniak, Eugene. 2000. A maximum-entropy-</address>
<note confidence="0.8898585">parser. In of the 1st Conference of the North American Chapter of the Asfor Computational Seattle, WA, pages 132–139. Collins, Michael. 1996. A new statistical parser on bigram lexical dependencies. In Proceedings of the 34th Annual Meeting of the Asfor Computational Santa Cruz, CA, pages 184–191. Collins, Michael. 1997. Three generative, leximodels for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of Association for Computational Madrid, pages 16–23. Crocker, Matthew W. and Thorsten Brants. 2000. Wide-coverage probabilistic sentence processing. of Psycholinguistic Research 669. Frazier, Lynn. 1989. Against lexical generation of syntax. In William D. Marslen-Wilson, editor,</note>
<affiliation confidence="0.787434">Representation and MIT Press,</affiliation>
<address confidence="0.8054">Cambridge, Mass., pages 505–528. Frazier, Lynn and Keith Rayner. 1982. Making</address>
<abstract confidence="0.9841026">correcting errors during sentence comprehension: Eye movements in the analysis of strucambiguous sentences. Psychol- Jurafsky, Daniel. 1996. A probabilistic model of lexical and syntactic access and disambiguation.</abstract>
<affiliation confidence="0.552846">Science</affiliation>
<address confidence="0.63551">Keller, Frank. 2004. The entropy rate principle as</address>
<abstract confidence="0.5652862">a predictor of processing effort: An evaluation against eye-tracking data. In Dekang Lin and Wu, editors, of the Conference on Empirical Methods in Natural Language Barcelona.</abstract>
<author confidence="0.530896">Lan-</author>
<affiliation confidence="0.807843">and Cognitive Processes</affiliation>
<address confidence="0.554767">MacDonald, Maryellen C., Neal J. Pearlmutter, and</address>
<author confidence="0.856185666666667">Lexical nature of synambiguity resolution Re- Manning</author>
<author confidence="0.856185666666667">D Christopher</author>
<author confidence="0.856185666666667">Hinrich Sch¨utze</author>
<affiliation confidence="0.9574675">of Statistical Natural Lan- MIT Press, Cambridge, MA.</affiliation>
<address confidence="0.439123">Marcus, Mitchell P., Beatrice Santorini, and</address>
<author confidence="0.899498">Building a large</author>
<note confidence="0.895642333333333">annotated corpus of English: The Penn Treebank. Linguistics McDonald, Scott A. and Richard C. Shillcock. 2003. Low-level predictive inference in reading: The influence of transitional probabilities on eye Research Narayanan, Srini and Daniel Jurafsky. 1998. Bayesian models of human sentence processing. In Morton A. Gernsbacher and Sharon J. Derry, of the 20th Annual Conferof the Cognitive Science Lawrence Erlbaum Associates, Mahwah, NJ.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<journal>Journal of Psycholinguistic Research</journal>
<volume>29</volume>
<issue>6</issue>
<pages>669</pages>
<marker></marker>
<rawString>Journal of Psycholinguistic Research 29(6):647– 669.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Frazier</author>
</authors>
<title>Against lexical generation of syntax.</title>
<date>1989</date>
<booktitle>Lexical Representation and Process,</booktitle>
<pages>505--528</pages>
<editor>In William D. Marslen-Wilson, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.,</location>
<contexts>
<context position="1782" citStr="Frazier (1989)" startWordPosition="283" endWordPosition="284">in the input. However, garden path sentences are arguably a pathological case for the parser; garden paths are not representative of naturally occurring text. This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument). This criticism applies to most existing theories of human parsing, including the classical garden path model advanced by Frazier and Rayner (1982) and Frazier (1989), and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in the Penn Treebank </context>
</contexts>
<marker>Frazier, 1989</marker>
<rawString>Frazier, Lynn. 1989. Against lexical generation of syntax. In William D. Marslen-Wilson, editor, Lexical Representation and Process, MIT Press, Cambridge, Mass., pages 505–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Frazier</author>
<author>Keith Rayner</author>
</authors>
<title>Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences.</title>
<date>1982</date>
<journal>Cognitive Psychology</journal>
<pages>14--178</pages>
<contexts>
<context position="1763" citStr="Frazier and Rayner (1982)" startWordPosition="278" endWordPosition="281">parser deals with ambiguities in the input. However, garden path sentences are arguably a pathological case for the parser; garden paths are not representative of naturally occurring text. This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument). This criticism applies to most existing theories of human parsing, including the classical garden path model advanced by Frazier and Rayner (1982) and Frazier (1989), and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in</context>
</contexts>
<marker>Frazier, Rayner, 1982</marker>
<rawString>Frazier, Lynn and Keith Rayner. 1982. Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. Cognitive Psychology 14:178–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
</authors>
<title>A probabilistic model of lexical and syntactic access and disambiguation.</title>
<date>1996</date>
<journal>Cognitive Science</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="4202" citStr="Jurafsky (1996)" startWordPosition="660" endWordPosition="661">se unrestricted text are typically highly ambiguous, i.e., a single sentence will receive a large number of parses. The probabilistic component of the grammar can then be used to rank the analyses a sentence might receive, and improbable ones can be eliminated. In the computational linguistics literature, a number of highly successful extensions to the basic PCFG model have been proposed. Of particular interest are lexicalized parsing models such as the ones developed by Collins (1996, 1997) and Carroll and Rooth (1998). In the human parsing literature, a PCFG-based model has been proposed by Jurafsky (1996) and Narayanan and Jurafsky (1998). This model shows how different sources of probabilistic information (such as subcategorization information and rule frequencies) can be combined using Bayesian inference. The model accounts for a range of disambiguation phenomena in linguistic processing. However, the model is only small scale, and it is not clear if it can be extended to provide robustness and coverage of unrestricted text. This problem is addressed by Brants and Crocker (2000) and Crocker and Brants (2000), who propose a broad-coverage model of human parsing based on PCFGs. This model is i</context>
</contexts>
<marker>Jurafsky, 1996</marker>
<rawString>Jurafsky, Daniel. 1996. A probabilistic model of lexical and syntactic access and disambiguation. Cognitive Science 20(2):137–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
</authors>
<title>The entropy rate principle as a predictor of processing effort: An evaluation against eye-tracking data.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="6934" citStr="Keller, 2004" startWordPosition="1099" endWordPosition="1100">from 23 subjects (McDonald and Shillcock, 2003). A series of regression analyses are conducted to determine if persentence reading time measures correlate with sentence probabilities predicted by the parsing models. Three baseline models are also included in the evaluation: word frequency, bigram and trigram probability (as predicted by a language model), and part of speech (POS) probability (as predicted by a POS tagger). Models based on n-grams have already been used successfully to model eye-tracking data, both on a word-by-word basis (McDonald and Shillcock, 2003) and for whole sentences (Keller, 2004). Our results show that for all three parsing models, sentence probability is significantly correlated with reading times measures. However, the models differ as to whether they predict early or late measures: the PCFG and the Collins model significantly predict late reading time measures (total time and gaze duration), but not early measures (first fixation time and skipping rate). The Charniak model is able to significantly predict both early and late measures. An analysis of the baseline models shows that word frequency and POS probability only predict early measures, while bigram and trigr</context>
<context position="9712" citStr="Keller (2004)" startWordPosition="1532" endWordPosition="1533">c data such as the Embra eye-tracking corpus. Finally, a major challenge that remains is the crosslinguistic aspect of human parsing. Virtually all existing computational models have only been implemented and tested for English data. However, a wide range of interesting problems arise for other languages. An examples are head-final languages, in which the probabilistic information associated with the head becomes available only at the end of the phrase, which poses a potential problem for incremental parsing models. Some initial results on a limited dataset have been obtained by Baldewein and Keller (2004) for head-final constructions in German. References Baldewein, Ulrike and Frank Keller. 2004. Modeling attachment decisions with a probabilistic parser: The case of head final structures. In Proceedings of the 26th Annual Conference of the Cognitive Science Society. Chicago. Brants, Thorsten and Matthew W. Crocker. 2000. Probabilistic parsing and psychological plausibility. In Proceedings of the 18th International Conference on Computational Linguistics. Saarbr¨ucken/Luxembourg/Nancy. Carroll, Glenn and Mats Rooth. 1998. Valence induction with a head-lexicalized PCFG. In Proceedings of the Con</context>
</contexts>
<marker>Keller, 2004</marker>
<rawString>Keller, Frank. 2004. The entropy rate principle as a predictor of processing effort: An evaluation against eye-tracking data. In Dekang Lin and Dekai Wu, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing. Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryellen C MacDonald</author>
</authors>
<title>Probabilistic constraints and syntactic ambiguity resolution. Language and Cognitive Processes 9:157–201.</title>
<date>1994</date>
<contexts>
<context position="1884" citStr="MacDonald (1994)" startWordPosition="299" endWordPosition="300"> paths are not representative of naturally occurring text. This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument). This criticism applies to most existing theories of human parsing, including the classical garden path model advanced by Frazier and Rayner (1982) and Frazier (1989), and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in the Penn Treebank (Marcus et al., 1993) shows that about 17% of all sentences contain parentheticals or other sentence f</context>
<context position="8933" citStr="MacDonald, 1994" startWordPosition="1408" endWordPosition="1410">man language processing. This is an important point that has not been recognized in the literature, as previous models have not been tested on realistic corpus samples, and have not been compared to plausible baselines. A second point concerns the role of lexical information in human parsing. We found that the best performing model was Charniak’s maximum entropy-inspired parser, which combines lexical and phrasal information, and manages to predict both early and late eye-tracking measures. A number of existing theories of human parsing incorporate lexical information (MacDonald et al., 1994; MacDonald, 1994), but have so far failed to demonstrate how the use of such information can be scaled up to yield robust, broad coverage parsing models that can be tested on realistic data such as the Embra eye-tracking corpus. Finally, a major challenge that remains is the crosslinguistic aspect of human parsing. Virtually all existing computational models have only been implemented and tested for English data. However, a wide range of interesting problems arise for other languages. An examples are head-final languages, in which the probabilistic information associated with the head becomes available only at</context>
</contexts>
<marker>MacDonald, 1994</marker>
<rawString>MacDonald, Maryellen C. 1994. Probabilistic constraints and syntactic ambiguity resolution. Language and Cognitive Processes 9:157–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryellen C MacDonald</author>
<author>Neal J Pearlmutter</author>
<author>Mark S Seidenberg</author>
</authors>
<title>Lexical nature of syntactic ambiguity resolution. Psychological Review 101:676–703.</title>
<date>1994</date>
<contexts>
<context position="1863" citStr="MacDonald et al. (1994)" startWordPosition="294" endWordPosition="297"> case for the parser; garden paths are not representative of naturally occurring text. This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument). This criticism applies to most existing theories of human parsing, including the classical garden path model advanced by Frazier and Rayner (1982) and Frazier (1989), and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in the Penn Treebank (Marcus et al., 1993) shows that about 17% of all sentences contain parenthetical</context>
<context position="8915" citStr="MacDonald et al., 1994" startWordPosition="1404" endWordPosition="1407">ad coverage models of human language processing. This is an important point that has not been recognized in the literature, as previous models have not been tested on realistic corpus samples, and have not been compared to plausible baselines. A second point concerns the role of lexical information in human parsing. We found that the best performing model was Charniak’s maximum entropy-inspired parser, which combines lexical and phrasal information, and manages to predict both early and late eye-tracking measures. A number of existing theories of human parsing incorporate lexical information (MacDonald et al., 1994; MacDonald, 1994), but have so far failed to demonstrate how the use of such information can be scaled up to yield robust, broad coverage parsing models that can be tested on realistic data such as the Embra eye-tracking corpus. Finally, a major challenge that remains is the crosslinguistic aspect of human parsing. Virtually all existing computational models have only been implemented and tested for English data. However, a wide range of interesting problems arise for other languages. An examples are head-final languages, in which the probabilistic information associated with the head becomes</context>
</contexts>
<marker>MacDonald, Pearlmutter, Seidenberg, 1994</marker>
<rawString>MacDonald, Maryellen C., Neal J. Pearlmutter, and Mark S. Seidenberg. 1994. Lexical nature of syntactic ambiguity resolution. Psychological Review 101:676–703.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Manning, Christopher D. and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2403" citStr="Marcus et al., 1993" startWordPosition="386" endWordPosition="389"> and more recent lexicalist parsing frameworks, of which MacDonald et al. (1994) and MacDonald (1994) are representative examples. Both the garden path model and the lexicalist model are designed to deal with idealized input, i.e., with input that is (locally) ambiguous, but fully wellformed. A real life parser, however, has to cope with a large amount of noise, which often renders the input ungrammatical or fragmentary, due to errors such as typographical mistakes in the case of text, or slips of the tongue, disfluencies, or repairs in the case of speech. A quick search in the Penn Treebank (Marcus et al., 1993) shows that about 17% of all sentences contain parentheticals or other sentence fragments, interjections, or unbracketable constituents. Note that this figure holds for carefully edited newspaper text; the figure is likely to be much higher for speech. The human parser is robust to such noise, i.e., it is able to assign an (approximate) analysis to a sentence even if it is ungrammatical or fragmentary. 2 Probabilistic Parsing Models In computational linguistics, probabilistic approaches to language processing play a central role. Significant advances toward robust, broadcoverage parsing models</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott A McDonald</author>
<author>Richard C Shillcock</author>
</authors>
<title>Low-level predictive inference in reading: The influence of transitional probabilities on eye movements.</title>
<date>2003</date>
<journal>Vision Research</journal>
<pages>43--1735</pages>
<contexts>
<context position="6368" citStr="McDonald and Shillcock, 2003" startWordPosition="1007" endWordPosition="1010">be assessed by testing the models against realistic samples of unrestricted text or speech obtained from corpora. In this talk, we will present work that aims to perform such an evaluation. We train a series of increasingly sophisticated probabilistic parsing models on an identical training set (the Penn Treebank). These models include a standard unlexicalized PCFG parser, a head-lexicalized parser (Collins, 1997), and a maximum-entropy inspired parser (Charniak, 2000). We test all three models on the Embra corpus, a corpus of newspaper texts annotated with eye-tracking data from 23 subjects (McDonald and Shillcock, 2003). A series of regression analyses are conducted to determine if persentence reading time measures correlate with sentence probabilities predicted by the parsing models. Three baseline models are also included in the evaluation: word frequency, bigram and trigram probability (as predicted by a language model), and part of speech (POS) probability (as predicted by a POS tagger). Models based on n-grams have already been used successfully to model eye-tracking data, both on a word-by-word basis (McDonald and Shillcock, 2003) and for whole sentences (Keller, 2004). Our results show that for all th</context>
</contexts>
<marker>McDonald, Shillcock, 2003</marker>
<rawString>McDonald, Scott A. and Richard C. Shillcock. 2003. Low-level predictive inference in reading: The influence of transitional probabilities on eye movements. Vision Research 43:1735–1751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Bayesian models of human sentence processing. In</title>
<date>1998</date>
<booktitle>Proceedings of the 20th Annual Conference of the Cognitive Science Society. Lawrence Erlbaum Associates,</booktitle>
<editor>Morton A. Gernsbacher and Sharon J. Derry, editors,</editor>
<location>Mahwah, NJ.</location>
<contexts>
<context position="4236" citStr="Narayanan and Jurafsky (1998)" startWordPosition="663" endWordPosition="666"> are typically highly ambiguous, i.e., a single sentence will receive a large number of parses. The probabilistic component of the grammar can then be used to rank the analyses a sentence might receive, and improbable ones can be eliminated. In the computational linguistics literature, a number of highly successful extensions to the basic PCFG model have been proposed. Of particular interest are lexicalized parsing models such as the ones developed by Collins (1996, 1997) and Carroll and Rooth (1998). In the human parsing literature, a PCFG-based model has been proposed by Jurafsky (1996) and Narayanan and Jurafsky (1998). This model shows how different sources of probabilistic information (such as subcategorization information and rule frequencies) can be combined using Bayesian inference. The model accounts for a range of disambiguation phenomena in linguistic processing. However, the model is only small scale, and it is not clear if it can be extended to provide robustness and coverage of unrestricted text. This problem is addressed by Brants and Crocker (2000) and Crocker and Brants (2000), who propose a broad-coverage model of human parsing based on PCFGs. This model is incremental, i.e., it makes word-by</context>
</contexts>
<marker>Narayanan, Jurafsky, 1998</marker>
<rawString>Narayanan, Srini and Daniel Jurafsky. 1998. Bayesian models of human sentence processing. In Morton A. Gernsbacher and Sharon J. Derry, editors, Proceedings of the 20th Annual Conference of the Cognitive Science Society. Lawrence Erlbaum Associates, Mahwah, NJ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>