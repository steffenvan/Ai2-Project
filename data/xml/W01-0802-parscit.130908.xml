<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000021">
<title confidence="0.953073">
A Two-stage Model for Content Determination
</title>
<note confidence="0.935401">
Somayajulu G. Ehud Reiter Jim Hunter Jin Yu
Sripada Dept. of Comp. Sc. Dept. of Comp. Sc. Dept. of Comp. Sc.
Dept. of Comp. Sc. Univ. of Aberdeen, Univ. of Aberdeen, Univ. of Aberdeen,
Univ. of Aberdeen, Aberdeen, UK Aberdeen, UK Aberdeen, UK
Aberdeen, UK ereiter@csd.abdn jhunter@csd.abdn jyu@csd.abdn.ac
ssripada@csd. .ac.uk .ac.uk .uk
</note>
<email confidence="0.40635">
abdn.ac.uk
</email>
<sectionHeader confidence="0.994585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999434454545455">
In this paper we describe a two-stage
model for content determination in
systems that summarise time series
data. The first stage involves building a
qualitative overview of the data set, and
the second involves using this
overview, together with the actual data,
to produce summaries of the time-
series data. This model is based on our
observations of how human experts
summarise time-series data.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939914285714">
This paper addresses the problem of content
determination in data summarisation. Content
determination as the name indicates is the
process responsible for determining the content
of the texts generated by an NLG system (Reiter
and Dale 2000). Although content-
determination is probably the most important
part of an NLG system from the end-user&apos;s
perspective, there is little agreement in the NLG
community as to how content-determination
should be done, with different systems adapting
widely varying approaches. Also, algorithms
and architectures for content-determination
seem to often be based on the intuitions of
system developers, instead of on empirical
observations, although detailed content
determination rules are often based on corpus
analysis and interaction with experts.
In this paper we propose a general architecture
for content determination in data summarisation
systems which assumes that content
determination happens in two stages: first a
qualitative overview of the data is formed, and
second the content of the actual summaries is
decided upon. This model is based on extensive
knowledge acquisition (KA) activies that we
have carried out in the SUMTIME project
(Sripada, 2001), and also matches observations
made during KA activities carried out in the
STOP project (Reiter et al 2000). We have not
yet implemented this model, and indeed one of
the issues that we need to think about is to what
degree a content-determination strategy used by
human experts is also an appropriate one for a
computer NLG system.
</bodyText>
<sectionHeader confidence="0.986333" genericHeader="introduction">
2 Content Determination
</sectionHeader>
<bodyText confidence="0.999975377777778">
Content determination is the task of deciding on
the information content of a generated text. In
the three-stage pipeline model of Reiter and
Dale (2000), content determination is part of the
first stage, document planning, along with
document structuring (determining the textual
and rhetorical structure of a text). Content
determination is extremely important to end
users; in most applications users probably prefer
a text which poorly expresses appropriate
content to a text which nicely expresses
inappropriate content. From a theoretical
perspective content determination should
probably be based on deep reasoning about the
system&apos;s communicative goal, the user&apos;s
intentions, and the current context (Allen and
Perrault 1980), but this requires an enormous
amount of knowledge and reasoning, and is
difficult to do robustly in real applications.
In recent years many new content determination
strategies have been proposed, ranging from the
use of sophisticated signal-processing
techniques (Boyd 1997) to complex planning
algorithms (Mittal et al 1998) to systems which
exploit cognitive models of the user (Fiedler
1998). However, most of these strategies have
only been demonstrated in one application.
Furthermore, as far as we can tell these
strategies are usually based on the intuition and
experiences of the developers. While
realisation, microplanning, and document
structuring techniques are increasingly based on
analyses of how humans perform these tasks
(including corpus analysis, psycholinguistic
studies, and KA activities), most papers on
content determination make little reference to
how human experts determine the content of a
text. Human experts are often consulted with
regard to the details of content rules, especially
when schemas are used for content
determination (Goldberg et al 1994, McKeown
et al 1994, Reiter et al 2000); but they rarely
seem to be consulted (as far as we can tell) when
deciding on the general algorithm or strategy to
use for content determination.
</bodyText>
<sectionHeader confidence="0.96772" genericHeader="method">
3 Summarising Time-Series Data
</sectionHeader>
<subsectionHeader confidence="0.999905">
3.1 Text summaries of Time-Series Data
</subsectionHeader>
<bodyText confidence="0.999706166666667">
Time-series data is a collection of values of a set
of parameters over time. Such data is very
common in the modern world, with its
proliferation of databases and sensors, and
humans frequently need to examine and make
inferences from time-series data.
Currently, human examination of time-series
data is generally done either by direct inspection
of the data (for small data sets), by graphical
visualisation, or by statistical analyses.
However, in some cases textual summaries of
time-series data are also useful. For example,
newspapers regularly publish textual summaries
of weather predictions, the results of polls and
surveys, and stock market activity, instead of
just showing numbers and graphs. This may be
because graphical depictions of time-series data
require time and skill to interpret, which is not
always available. A doctor rushing to the side
of a patient who is suffering from a heart attack,
for example, may not have time to examine a set
of graphs of time-series data, and a newspaper
reader may not have the statistical knowledge
necessary to interpret raw poll results.
Perhaps the major problem today with textual
descriptions of time-series data is that they must
be produced manually, which makes them
expensive and also means they can not be
produced instantly. Graphical depictions of
data, in contrast, can be produced quickly and
cheaply using off-the-shelf computer software;
this may be one reason why they are so popular.
If textual summaries of time-series data could be
automatically produced by software as cheaply
and as quickly as graphical depictions, then they
might be more widely used.
</bodyText>
<subsectionHeader confidence="0.994467">
3.2 SUMTIME
</subsectionHeader>
<bodyText confidence="0.99988256097561">
The goal of the SUMTIME project is to develop
better techniques for automatically generating
textual summaries of time-series data, in part by
integrating leading-edge NLG and time-series
analysis technology. We are currently focusing
on two domains:
Meteorology – producing weather forecasts
from numerical weather simulations. This work
is done in collaboration with Weather News Inc
(WNI)/Oceanroutes, a leading meteorological
company.
Gas Turbines – summarising sensor readings
from a gas turbine. This work is done in
collaboration with Intelligent Applications, a
leading developer of monitoring software for
gas turbines.
These domains are quite different in time-series
terms, not least in the size of the data set. A
typical weather forecast is based on tens of
values for tens of parameters, while a summary
of gas-turbine sensor readings may be based on
tens of thousands of values for hundreds of
parameters. We hope that looking at such
different domains will help ensure that our
results are generalisable and not domain-
specific. We will start working on a third
domain in 2002; this is likely to be a medical
one, perhaps (although this is not definite)
summarising sensor readings in neonatal
intensive care units.
The first year of SUMTIME (which started in
April 2000) has mostly been devoted to
knowledge acquisition, that is to trying to
understand how human experts summarise time-
series data. This was done using various
techniques, including corpus analysis,
observation of experts writing texts, analysis of
content rules suggested by experts, discussion
with experts, and think-aloud sessions, where
experts ‘think aloud’ while writing texts
(Sripada, 2001).
</bodyText>
<subsectionHeader confidence="0.991269">
3.3 Example
</subsectionHeader>
<bodyText confidence="0.9994436">
The following table shows an example segment
of meteorological time series data, specifically
predicted wind speed and wind direction at an
offshore oil exploration site. The time field is
shown in ‘day/hour’ format.
</bodyText>
<table confidence="0.744051941176471">
Time Wind Wind
(day/hour) Direction Speed
Knots
05/06 SE 22
05/09 SE 24
05/12 SE 30
05/15 SE 25
05/18 SSE 28
05/21 SSE 22
06/00 SE 16
This data was summarised by WNI&apos;s human
forecasters as follows:
FORECAST 06-24 GMT,FRIDAY,05-Jan
2001
WIND(KTS) CONF HIGH
10M: SE 20-25 OCCASIONALLY
25-30, EASING 15-20 LATER
</table>
<bodyText confidence="0.999960833333333">
The above example is just a sample showing the
data and its corresponding forecast text for the
wind subsystem. Real weather forecast reports
are much longer and are produced from data
involving many more weather parameters than
just wind speed and wind direction.
</bodyText>
<sectionHeader confidence="0.955191" genericHeader="method">
4 Human Summarisation
</sectionHeader>
<subsectionHeader confidence="0.68866">
4.1 Meteorology
</subsectionHeader>
<bodyText confidence="0.999657">
In the domain of weather forecasting, we
observed how human experts carry out the task
of summarising weather data by video recording
a meteorologist thinking aloud while writing
weather forecasts. Details of the KA have been
described in Sripada (2001). Our observations
included the following:
</bodyText>
<listItem confidence="0.950418333333333">
1. In the case of weather forecasts, time-series
data represent the values of important
weather parameters (wind speed, direction,
temperature, rainfall), which collectively
describe a single system, the weather. It
seemed as though the expert was
constructing a mental picture of their source
using the significant patterns in time series.
Thus the first activity is that of data
interpretation to obtain a mental model of
weather.
2. The mental model of the weather is mostly
in terms of the elements/objects related to
atmosphere, like cold fronts and warm
fronts; it also seems to be qualitative instead
of numerical. In other words, it qualitatively
describes the meteorological state of the
atmosphere. The expert calls this an
‘overview of the weather’.
3. Building the overview involves the task of
interpretation of the time series weather
data. While interpreting this data the expert
used his meteorological knowledge (which
includes his personal experience in
interpreting weather data) to arrive at an
overview of the weather. During this phase,
he appeared to be unconcerned about the
end user of the overview (see 4.1.1 below).
We call this process Domain Problem
Solving (DPS) where information is
processed using exclusively the domain
knowledge.
4. Forecasts are written after the forecaster gets
a clear mental picture (overview) of the
weather. Building the overview from the
data is an objective process which does not
</listItem>
<bodyText confidence="0.997122666666666">
depend on the forecast client (user), whereas
writing the forecast is subjective and varies
with client.
</bodyText>
<subsectionHeader confidence="0.439285">
4.1.1 Examples
</subsectionHeader>
<bodyText confidence="0.9929215">
Two examples of the influence of the overview
on wind texts (Section 3.3) are:
</bodyText>
<listItem confidence="0.8442942">
1. When very cold air flows over a warm sea,
surface winds may be underestimated by the
numerical weather model. In such cases the
forecaster uses his ‘overview of the weather’
to increase wind speeds and also perhaps
add other instability features to the forecast
such as squalls.
2. If the data contains an outlier, such as a
wind direction which is always N except for
one time period in which it is NE, then the
expert uses the overview to decide if the
outlier is meteorologically plausible and
hence should be reported or if it is likely to
be an artefact of the simulation and hence
should not be reported.
</listItem>
<bodyText confidence="0.99999">
The above examples involve reasoning about the
weather system. Forecasters also consider user
goals and tasks, but this may be less affected by
the overview. For example, in one think-aloud
session, the forecaster decided to use the phrase
20-24 to describe wind speed when the data file
predicted a wind speed of 19kt. He explained to
us that he did this because he knew that oil-rig
staff used different operational procedures (for
example for docking supply boats) when the
wind exceeded 20kt, and he also knew that even
if the average wind speed in the period was
19kt, the actual speed was going to vary minute
by minute and often be above 20kt. Hence he
decided to send a clear signal to the rig staff that
they should expect to use ‘20kt or higher’
procedures, by predicting a wind speed of 20-24.
This reasoning about the user took place after
the overview had been created, and did not seem
to involve the overview.
</bodyText>
<subsectionHeader confidence="0.983992">
4.2 Gas Turbine Sensors
</subsectionHeader>
<bodyText confidence="0.991599888888889">
Unlike the previous domain, in the domain of
gas turbine (GT), currently there are no textual
summaries of turbine data written by humans.
Thus we have asked the domain experts to
comment orally on the data. However, the
experts have attempted to summarise their
comments at the end of each session if they
found something worth summarising. Our
observations included:
</bodyText>
<listItem confidence="0.941060548387097">
1. The main task is to identify the abnormal
data and summarise it. However, an
abnormal trend in a specific channel might
have been caused due to a change in another
channel (for instance, an increase in the
output voltage can be explained with a
corresponding increase in the fuel input).
Thus individual channel data needs to be
interpreted in the context of the other
channels.
2. The expert agrees during the KA session
that he first analyses the data numerically to
obtain qualitative trends relating to the GT
before generating comments. Therefore the
state of the GT that produced the data is
constructed through data interpretation and
the knowledge of the state is then used to
check if the turbine is in a healthy state or
not. Since GT is an artefact created by
humans it is possible to have a fairly
accurate model of states of a GT (unlike
weather!).
3. The phrases used by the expert often express
the trends in the data as if they were
physical happenings on the turbine, like
“running down” for a decreasing trend in
shaft speed data. This indicates that the
expert is merely expressing the state of the
GT. This in turn indicates that at the time
the summarisation is done, the mental model
of the state of the GT is available.
</listItem>
<sectionHeader confidence="0.981514" genericHeader="method">
5 Evidence from Other Projects
</sectionHeader>
<bodyText confidence="0.9998986">
After making the above observations, we
examined think-aloud transcripts from an earlier
project at the University of Aberdeen, STOP
(Reiter et al 2000), which involved building an
NLG system that produced smoking-cessation
letters from smoking questionnaires. These
transcripts (from think-aloud sessions of doctors
and other health professionals manually writing
smoking-cessation letters) showed that in this
domain as well experts would usually first build
</bodyText>
<figure confidence="0.9996755">
Data Comprehension
Goal (Derived from
Comm. Goal)
Constraints
due to User
Communication
Reasoner (CR)
Domain
Data Source
(DDS)
Data
Overview
Domain
Reasoner (DR)
</figure>
<figureCaption confidence="0.969096">
Figure 1. Two stage model for content determination
</figureCaption>
<figure confidence="0.981150333333333">
Constraints due to other
pragmatic factors
Final
Content
Communication
Goal
</figure>
<bodyText confidence="0.999606352941176">
an overview (in this case, of the smoker) before
starting to determine the detailed content of a
letter. Below is an excerpt from one of the
transcripts of a KA session :
« .... The first thing I have got to do is to read
through the questionaire just to get some idea of
where he is at with his smoking. »
We did not investigate overview formation in
any detail in STOP, but the issue did come up
once in a general discussion with a doctor about
the think-aloud process. This particular doctor
said that he built in his mind a mental image of
the smoker (including a guess at what he or she
looked like), and that he found this image very
useful in deciding how best to communicate
with the smoker.
In another work, RajuGuide, once again there is
evidence of an overview influencing content
determination (Sripada 1997). RajuGuide is a
system that generates route descriptions. At a
higer level of abstraction, RajuGuide has two
parts. The first part is responsible for planning
the route the user wanted. The second module is
responsible for generating the text describing the
route. The route computed by the first part,
which is in the form of a series of coordinates, is
not directly communicated to the user. Instead
the second part attempts to enrich the route
depending upon what the user already knows
and what additional information the knowledge
base knows for that particular route. We believe
that the route computed by the route planner is
the overview in this case and it drives the
content determination process in the second part.
</bodyText>
<sectionHeader confidence="0.9949035" genericHeader="method">
6 Two-stage Model for content
determination
</sectionHeader>
<bodyText confidence="0.998905">
These observations have led us to make the
following hypotheses:
</bodyText>
<listItem confidence="0.79373325">
1. Humans form a qualitative overview of the
input data set.
2. Not all the information in the overview is
used in the text.
3. The overview is not dependent on pragmatic
factors such as the user’s taste, these are
considered at a later stage of the content
determination process.
</listItem>
<bodyText confidence="0.999951">
Based on the above hypotheses, we propose a
two-stage model for content determination as
depicted in Figure 1. It is assumed that Domain
Data Source (DDS) is external to the text
generator. It has been assumed that a Domain
Problem Solver or Domain Reasoner (DR) is
available for data processing. This reasoning
module is essentially useful to draw inferences
while interpreting the input data set and
ultimately is responsible for generating the
overview. Communication Goal (CG) is the
input to the data summarisation system in
response to which it accesses DDS to produce
an overview of the data using the DR. In the
context of the overview produced by DR, the
Communication Reasoner (CR) system
generates the final content specification taking
into account the influence of the User
Constraints (UC) and other pragmatic factors.
This content is then sent to subsequent NLG
modules (not shown), such as microplanning
and surface realisation.
Our model has some similarities to the one
proposed by Barzilay et al (1998), in that the
Domain Reasoner uses general domain
knowledge similar to their RDK, while the
Communication Reasoner uses communication
knowledge similar to their CDK and DCK.
The central feature of the above model is the
idea of data overview and its effect on content
selection. One possible use of overviews is to
trigger context-dependent content rules. The
time-series analysis part of SUMTIME is largely
based on Shahar&apos;s model (1997), which makes
heavy use of such rules. In Shahar&apos;s model
contexts are inferred by separate mechanisms;
we believe that these should be incorporated into
the overview, but this needs further
investigation.
At the current stage of our project we have only
a gross idea of what makes up the proposed data
overview. Our suspicion is that it is hard to
make a generic definition of the data overview
for all domains. Instead, we would like to
imagine the data overview as the result of
inferences made from the input data so as to
help in triggering the right content determination
rules. For example, in out meteorology domain,
the input time-series data comes from a
numerical weather prediction (NWP) model, but
even the most sophisticated NWP models do not
fully represent the real atmosphere – all models
work with approximations. Thus the NWP data
displayed to the meteorologist is interpreted by
him to arrive at a conceptual model in his or her
head, which is the overview.
</bodyText>
<page confidence="0.486813">
7 Issues with the two stage model
</page>
<bodyText confidence="0.770178333333333">
There are a number of issues that need to be
resolved with respect to the two-stage model
described above.
</bodyText>
<subsectionHeader confidence="0.894766">
7.1 Is overview creation a human
</subsectionHeader>
<bodyText confidence="0.987651818181818">
artefact?
The main basis for including the overview in
two stage model has been the observation made
during the think aloud sessions that experts form
overviews before writing texts. Now it can be
argued that even if humans need an overview,
computer programs may not. Evidently, it is
hard to ever prove the contrary. But what can be
done is to show the advantages gained by a
computer program by using an overview for
content selection.
</bodyText>
<subsectionHeader confidence="0.953032">
7.2 Does the overview have any other
</subsectionHeader>
<bodyText confidence="0.995734783333333">
utility than just providing context for
content determination rules?
We believe that the overview can play multiple
roles in the overall process of writing textual
forecasts. First, the overview can bring in
additional information into the text that is not
directly present in the underlying raw data. In
Reiter and Dale&apos;s (2000) terminology, overviews
are a technique for generating Computable Data
content, that is content which is not directly
present in the input data but can be computed or
inferred from it. Such content provides much of
the value of summary texts. Indeed, one could
argue that simple textual descriptions of a set of
data values without extra computed or inferred
content, such as those produced by TREND
(Boyd, 1997), might not be that much more
useful than a graph of the data.
The overview may also help in deciding how
reliable the input data is, which is especially
important in the meteorology domain, since the
data comes from an NWP simulation. This
could, for example, help the generation system
decide whether to use precise temporal terms
such as Midnight or vague temporal terms such
as tonight. Again one could argue that the ability
to convey such uncertainty and reliability
information to a non-specialist is a key
advantage of textual summaries over graphs.
In general, the overview allows reasoning to be
carried out on the raw data and this will
probably be useful in many ways.
7.3 How is the overview related to the
domain ontology?
The basic concepts present in an overview may
be quite different from the basic concepts
present in a written text. For example, the
overview built by our expert meteorologist was
based on concepts such as lapse rate (the rate at
which temperature varies with height),
movement of air masses, and atmospheric
stability. However, the texts he wrote
mentioned none of these, instead it talked about
wind speed, wind direction, and showers. In the
STOP domain, overviews created by doctors
seemed to often contain many qualitative
psychological attributes (depression, self-
confidence, motivation to quit, etc) which were
not explicitly mentioned in the actual texts
written by the doctors.
This suggests that the conceptual ontology, that
is the specification of underlying concepts,
underlying the overview may be quite different
from the ontology underlying the actual texts.
The overview ontology includes concepts used
by experts when reasoning about a domain (such
as air masses or motivation), while the text
ontology includes concepts useful for
communicating information to the end user
(such as wind speed, or longer life expectancy).
</bodyText>
<subsectionHeader confidence="0.518962">
7.4 What do experts think about the two-
</subsectionHeader>
<bodyText confidence="0.997556538461538">
stage model?
When the two stage model was reported back to
a WNI expert who participated in a think-aloud
session, the expert agreed that he does build an
overview (as he did during the KA session)
while writing forecasts, but felt that it’s use may
not be necessary for writing all forecasts. In his
opinion, the interpretation of most data sets
doesn’t require the use of the overview.
However, he was quick to add that the quality of
the forecasts can be improved by using
overviews which faciliate reasoning with the
weather data.
</bodyText>
<sectionHeader confidence="0.999052" genericHeader="evaluation">
8 Evaluation
</sectionHeader>
<bodyText confidence="0.996001666666667">
We are currently building a testbed system
called SUMTIME-MOUSAM which will enable us
to test the hypotheses we have presented in this
paper and other hypotheses suggested by our
KA activities. SUMTIME-MOUSAM is a
framework system that consists of
</bodyText>
<listItem confidence="0.828001363636364">
• &amp;quot;Infrastructure&amp;quot; software for accessing data
files, regression testing of new software
versions, etc.
• An ontology, which defines a conceptual
level of representation of texts.
• A corpus of human-written texts with their
corresponding conceptual representations
defined using the above ontology.
• Scoring software which compares the output
of a module (either at a conceptual or text
level) against the human corpus.
</listItem>
<bodyText confidence="0.999797166666667">
Because we are primarily interested in content
issues, it is important to evaluate our system at a
content level as well as at a text level. To
support this, we are developing conceptual
representations of the texts we will be
generating, which can also be extracted from
human texts by manual analysis.
SUMTIME-MOUSAM is currently best developed
in the area of producing wind texts. In this area,
we have developed a conceptual representation
and manual annotation guide (with good inter-
annotator agreement, generally kappa values of
.9 or higher); built an initial software system to
automatically produce such texts based on a
threshold model without an overview; and
begun the process of analysing differences. We
are currently working on extending SUMTIME-
MOUSAM to other parts of weather forecasts,
such as statements describing clouds and
precipitation, and plan in the future to extend it
to the gas-turbine domain.
With regard to testing hypotheses specifically
about two-stage content determination (the
subject of this paper), our plan is as follows
</bodyText>
<listItem confidence="0.831749">
1. Compare the output of the non-overview
based software to human summary texts,
and identify cases where an overview seems
to be used.
2. Ask human experts to build an overview
</listItem>
<bodyText confidence="0.886803583333333">
(using a GUI), modify our software to use
this overview when generating texts, and see
if this results in texts more similar to the
human texts.
3. Attempt to automatically generate the
overview from the data, and again compare
the resultant texts to human texts.
At some point towards the end of SUMTIME, we
also hope to conduct user task evaluations. For
example, we may show gas-turbine engineers
our summary texts and see if this helps them
detect problems in the gas turbine.
</bodyText>
<sectionHeader confidence="0.998134" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999906777777778">
Our experience in three domains shows that
human experts build qualitative overviews when
writing texts, and that these overviews are used
by the experts for inference and to provide a
context for specific content rules. We believe
that overviews could also be very useful in
computer NLG systems, and are currently
working on testing this hypothesis, as part of the
SUMTIME project.
</bodyText>
<sectionHeader confidence="0.998194" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999734">
Many thanks to our collaborators at
WNI/Oceanroutes and Intelligent Applications,
especially Ian Davy, Dave Selway, Rob Milne,
and Jon Aylett; this work would not be possible
without them! Thanks also to Sandra Williams
and the anonymous reviewers for their
comments on a draft of this paper. This project
is supported by the UK Engineering and
Physical Sciences Research Council (EPSRC),
under grant GR/M76881.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999932444444445">
Allen J. and Perrault C. R. (1980). Analyzing
Intention in Utterances. Artificial Intelligence,
26:1-33.
Barzilay R, McCullough D, Rambow O,
DeChristofaro J, Korelsky T, and Lavoie B (1998)
A New Approach to Expert System Explanations,
In Proceedings of INLG-1998, pages 78-87.
Boyd S (1997). Detecting and Describing Patterns in
Time-varying Data Using Wavelets. In Advances
in Intelligent Data Analysis: Reasoning About
Data, X Lui and P Cohen (Eds.), Lecture Notes in
Computer Science 1280, Springer Verlag.
Fiedler A (1998). Macroplanning with a Cognitive
Architecture for the Adaptive Explanation of
Proofs. In Proceedings of INLG-1998, pp 88-97.
Goldberg E, N Driedger and RL Kittredge (1994),
Using Natural-Language Processing to Produce
Weather Forecasts, IEEE Expert, 9, 2, pp 45-53.
McKeown K, Kukich K, Shaw J (1994). Practical
Issues in Automatic Document Generation. In
Proceedings of ANLP-1994, pp 7-14.
Mittal V, Moore J, Carenini G, and Roth S (1998).
Describing Complex Charts in Natural Language:
A Caption Generation System. Computational
Linguistics 24: 431-467.
Reiter E. and Dale R. (2000) Building Natural
Language Generation Systems. Cambridge
University Press.
Reiter E., Robertson R. and Osman L. (2000)
Knowledge Acquisition for Natural Language
Generation. In Proceedings of the First
International Conference on Natural Language
Generation (INLG-2000), 217-224 pp.
Shahar Y (1997), “Framework for Knowledge-Based
Temporal Abstraction”, Artificial Intelligence
90:79-133..
Sripada S. G. (1997) Communicating Plans in
Natural Language: Planning and Realisation.
PhD Thesis, Indian Institute of Technology,
Madras, India.
Sripada S. G. (2001) SUMTIME: Observations from
KA for Weather Domain. Technical Report,
Computing Science Dept. Univ of Aberdeen,
Aberdeen AB24 3UE, UK. Awaiting approval
from industrial collaborators.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.252677">
<title confidence="0.999973">A Two-stage Model for Content Determination</title>
<author confidence="0.996022">Somayajulu G Ehud Reiter Jim Hunter Jin Yu</author>
<affiliation confidence="0.920824">Sripada Dept. of Comp. Sc. Dept. of Comp. Sc. Dept. of Comp. Sc. Dept. of Comp. Sc. Univ. of Aberdeen, Univ. of Aberdeen, Univ. of Aberdeen, Univ. of Aberdeen, Aberdeen, UK Aberdeen, UK Aberdeen, UK</affiliation>
<abstract confidence="0.914223666666667">Aberdeen, UK ereiter@csd.abdn jhunter@csd.abdn jyu@csd.abdn.ac ssripada@csd. .ac.uk .ac.uk .uk abdn.ac.uk Abstract In this paper we describe a two-stage model for content determination in systems that summarise time series data. The first stage involves building a qualitative overview of the data set, and the second involves using this overview, together with the actual data, to produce summaries of the timeseries data. This model is based on our observations of how human experts summarise time-series data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>C R Perrault</author>
</authors>
<title>Analyzing Intention in Utterances.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>26--1</pages>
<contexts>
<context position="3110" citStr="Allen and Perrault 1980" startWordPosition="467" endWordPosition="470">age pipeline model of Reiter and Dale (2000), content determination is part of the first stage, document planning, along with document structuring (determining the textual and rhetorical structure of a text). Content determination is extremely important to end users; in most applications users probably prefer a text which poorly expresses appropriate content to a text which nicely expresses inappropriate content. From a theoretical perspective content determination should probably be based on deep reasoning about the system&apos;s communicative goal, the user&apos;s intentions, and the current context (Allen and Perrault 1980), but this requires an enormous amount of knowledge and reasoning, and is difficult to do robustly in real applications. In recent years many new content determination strategies have been proposed, ranging from the use of sophisticated signal-processing techniques (Boyd 1997) to complex planning algorithms (Mittal et al 1998) to systems which exploit cognitive models of the user (Fiedler 1998). However, most of these strategies have only been demonstrated in one application. Furthermore, as far as we can tell these strategies are usually based on the intuition and experiences of the developer</context>
</contexts>
<marker>Allen, Perrault, 1980</marker>
<rawString>Allen J. and Perrault C. R. (1980). Analyzing Intention in Utterances. Artificial Intelligence, 26:1-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>D McCullough</author>
<author>O Rambow</author>
<author>J DeChristofaro</author>
<author>T Korelsky</author>
<author>B Lavoie</author>
</authors>
<title>A New Approach to Expert System Explanations,</title>
<date>1998</date>
<booktitle>In Proceedings of INLG-1998,</booktitle>
<pages>78--87</pages>
<contexts>
<context position="17477" citStr="Barzilay et al (1998)" startWordPosition="2799" endWordPosition="2802">d ultimately is responsible for generating the overview. Communication Goal (CG) is the input to the data summarisation system in response to which it accesses DDS to produce an overview of the data using the DR. In the context of the overview produced by DR, the Communication Reasoner (CR) system generates the final content specification taking into account the influence of the User Constraints (UC) and other pragmatic factors. This content is then sent to subsequent NLG modules (not shown), such as microplanning and surface realisation. Our model has some similarities to the one proposed by Barzilay et al (1998), in that the Domain Reasoner uses general domain knowledge similar to their RDK, while the Communication Reasoner uses communication knowledge similar to their CDK and DCK. The central feature of the above model is the idea of data overview and its effect on content selection. One possible use of overviews is to trigger context-dependent content rules. The time-series analysis part of SUMTIME is largely based on Shahar&apos;s model (1997), which makes heavy use of such rules. In Shahar&apos;s model contexts are inferred by separate mechanisms; we believe that these should be incorporated into the overv</context>
</contexts>
<marker>Barzilay, McCullough, Rambow, DeChristofaro, Korelsky, Lavoie, 1998</marker>
<rawString>Barzilay R, McCullough D, Rambow O, DeChristofaro J, Korelsky T, and Lavoie B (1998) A New Approach to Expert System Explanations, In Proceedings of INLG-1998, pages 78-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Boyd</author>
</authors>
<title>Detecting and Describing Patterns in Time-varying Data Using Wavelets.</title>
<date>1997</date>
<booktitle>In Advances in Intelligent Data Analysis: Reasoning About Data, X Lui and P Cohen (Eds.), Lecture Notes in Computer Science</booktitle>
<pages>1280</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="3387" citStr="Boyd 1997" startWordPosition="509" endWordPosition="510">ers probably prefer a text which poorly expresses appropriate content to a text which nicely expresses inappropriate content. From a theoretical perspective content determination should probably be based on deep reasoning about the system&apos;s communicative goal, the user&apos;s intentions, and the current context (Allen and Perrault 1980), but this requires an enormous amount of knowledge and reasoning, and is difficult to do robustly in real applications. In recent years many new content determination strategies have been proposed, ranging from the use of sophisticated signal-processing techniques (Boyd 1997) to complex planning algorithms (Mittal et al 1998) to systems which exploit cognitive models of the user (Fiedler 1998). However, most of these strategies have only been demonstrated in one application. Furthermore, as far as we can tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to</context>
<context position="20283" citStr="Boyd, 1997" startWordPosition="3271" endWordPosition="3272">verall process of writing textual forecasts. First, the overview can bring in additional information into the text that is not directly present in the underlying raw data. In Reiter and Dale&apos;s (2000) terminology, overviews are a technique for generating Computable Data content, that is content which is not directly present in the input data but can be computed or inferred from it. Such content provides much of the value of summary texts. Indeed, one could argue that simple textual descriptions of a set of data values without extra computed or inferred content, such as those produced by TREND (Boyd, 1997), might not be that much more useful than a graph of the data. The overview may also help in deciding how reliable the input data is, which is especially important in the meteorology domain, since the data comes from an NWP simulation. This could, for example, help the generation system decide whether to use precise temporal terms such as Midnight or vague temporal terms such as tonight. Again one could argue that the ability to convey such uncertainty and reliability information to a non-specialist is a key advantage of textual summaries over graphs. In general, the overview allows reasoning </context>
</contexts>
<marker>Boyd, 1997</marker>
<rawString>Boyd S (1997). Detecting and Describing Patterns in Time-varying Data Using Wavelets. In Advances in Intelligent Data Analysis: Reasoning About Data, X Lui and P Cohen (Eds.), Lecture Notes in Computer Science 1280, Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fiedler</author>
</authors>
<title>Macroplanning with a Cognitive Architecture for the Adaptive Explanation of Proofs.</title>
<date>1998</date>
<booktitle>In Proceedings of INLG-1998,</booktitle>
<pages>88--97</pages>
<contexts>
<context position="3507" citStr="Fiedler 1998" startWordPosition="528" endWordPosition="529">content. From a theoretical perspective content determination should probably be based on deep reasoning about the system&apos;s communicative goal, the user&apos;s intentions, and the current context (Allen and Perrault 1980), but this requires an enormous amount of knowledge and reasoning, and is difficult to do robustly in real applications. In recent years many new content determination strategies have been proposed, ranging from the use of sophisticated signal-processing techniques (Boyd 1997) to complex planning algorithms (Mittal et al 1998) to systems which exploit cognitive models of the user (Fiedler 1998). However, most of these strategies have only been demonstrated in one application. Furthermore, as far as we can tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to how human experts determine the content of a text. Human experts are often consulted with regard to the details of cont</context>
</contexts>
<marker>Fiedler, 1998</marker>
<rawString>Fiedler A (1998). Macroplanning with a Cognitive Architecture for the Adaptive Explanation of Proofs. In Proceedings of INLG-1998, pp 88-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Goldberg</author>
<author>N Driedger</author>
<author>RL Kittredge</author>
</authors>
<title>Using Natural-Language Processing to Produce Weather Forecasts,</title>
<date>1994</date>
<journal>IEEE Expert,</journal>
<volume>9</volume>
<pages>45--53</pages>
<contexts>
<context position="4197" citStr="Goldberg et al 1994" startWordPosition="627" endWordPosition="630">application. Furthermore, as far as we can tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to how human experts determine the content of a text. Human experts are often consulted with regard to the details of content rules, especially when schemas are used for content determination (Goldberg et al 1994, McKeown et al 1994, Reiter et al 2000); but they rarely seem to be consulted (as far as we can tell) when deciding on the general algorithm or strategy to use for content determination. 3 Summarising Time-Series Data 3.1 Text summaries of Time-Series Data Time-series data is a collection of values of a set of parameters over time. Such data is very common in the modern world, with its proliferation of databases and sensors, and humans frequently need to examine and make inferences from time-series data. Currently, human examination of time-series data is generally done either by direct inspe</context>
</contexts>
<marker>Goldberg, Driedger, Kittredge, 1994</marker>
<rawString>Goldberg E, N Driedger and RL Kittredge (1994), Using Natural-Language Processing to Produce Weather Forecasts, IEEE Expert, 9, 2, pp 45-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
<author>K Kukich</author>
<author>J Shaw</author>
</authors>
<title>Practical Issues in Automatic Document Generation.</title>
<date>1994</date>
<booktitle>In Proceedings of ANLP-1994,</booktitle>
<pages>7--14</pages>
<contexts>
<context position="4217" citStr="McKeown et al 1994" startWordPosition="631" endWordPosition="634">ore, as far as we can tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to how human experts determine the content of a text. Human experts are often consulted with regard to the details of content rules, especially when schemas are used for content determination (Goldberg et al 1994, McKeown et al 1994, Reiter et al 2000); but they rarely seem to be consulted (as far as we can tell) when deciding on the general algorithm or strategy to use for content determination. 3 Summarising Time-Series Data 3.1 Text summaries of Time-Series Data Time-series data is a collection of values of a set of parameters over time. Such data is very common in the modern world, with its proliferation of databases and sensors, and humans frequently need to examine and make inferences from time-series data. Currently, human examination of time-series data is generally done either by direct inspection of the data (f</context>
</contexts>
<marker>McKeown, Kukich, Shaw, 1994</marker>
<rawString>McKeown K, Kukich K, Shaw J (1994). Practical Issues in Automatic Document Generation. In Proceedings of ANLP-1994, pp 7-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Mittal</author>
<author>J Moore</author>
<author>G Carenini</author>
<author>S Roth</author>
</authors>
<title>Describing Complex Charts in Natural Language: A Caption Generation System.</title>
<date>1998</date>
<journal>Computational Linguistics</journal>
<volume>24</volume>
<pages>431--467</pages>
<contexts>
<context position="3438" citStr="Mittal et al 1998" startWordPosition="515" endWordPosition="518">resses appropriate content to a text which nicely expresses inappropriate content. From a theoretical perspective content determination should probably be based on deep reasoning about the system&apos;s communicative goal, the user&apos;s intentions, and the current context (Allen and Perrault 1980), but this requires an enormous amount of knowledge and reasoning, and is difficult to do robustly in real applications. In recent years many new content determination strategies have been proposed, ranging from the use of sophisticated signal-processing techniques (Boyd 1997) to complex planning algorithms (Mittal et al 1998) to systems which exploit cognitive models of the user (Fiedler 1998). However, most of these strategies have only been demonstrated in one application. Furthermore, as far as we can tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to how human experts determine the content of a text.</context>
</contexts>
<marker>Mittal, Moore, Carenini, Roth, 1998</marker>
<rawString>Mittal V, Moore J, Carenini G, and Roth S (1998). Describing Complex Charts in Natural Language: A Caption Generation System. Computational Linguistics 24: 431-467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>R Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1057" citStr="Reiter and Dale 2000" startWordPosition="159" endWordPosition="162">age model for content determination in systems that summarise time series data. The first stage involves building a qualitative overview of the data set, and the second involves using this overview, together with the actual data, to produce summaries of the timeseries data. This model is based on our observations of how human experts summarise time-series data. 1 Introduction This paper addresses the problem of content determination in data summarisation. Content determination as the name indicates is the process responsible for determining the content of the texts generated by an NLG system (Reiter and Dale 2000). Although contentdetermination is probably the most important part of an NLG system from the end-user&apos;s perspective, there is little agreement in the NLG community as to how content-determination should be done, with different systems adapting widely varying approaches. Also, algorithms and architectures for content-determination seem to often be based on the intuitions of system developers, instead of on empirical observations, although detailed content determination rules are often based on corpus analysis and interaction with experts. In this paper we propose a general architecture for con</context>
<context position="2530" citStr="Reiter and Dale (2000)" startWordPosition="386" endWordPosition="389"> extensive knowledge acquisition (KA) activies that we have carried out in the SUMTIME project (Sripada, 2001), and also matches observations made during KA activities carried out in the STOP project (Reiter et al 2000). We have not yet implemented this model, and indeed one of the issues that we need to think about is to what degree a content-determination strategy used by human experts is also an appropriate one for a computer NLG system. 2 Content Determination Content determination is the task of deciding on the information content of a generated text. In the three-stage pipeline model of Reiter and Dale (2000), content determination is part of the first stage, document planning, along with document structuring (determining the textual and rhetorical structure of a text). Content determination is extremely important to end users; in most applications users probably prefer a text which poorly expresses appropriate content to a text which nicely expresses inappropriate content. From a theoretical perspective content determination should probably be based on deep reasoning about the system&apos;s communicative goal, the user&apos;s intentions, and the current context (Allen and Perrault 1980), but this requires </context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Reiter E. and Dale R. (2000) Building Natural Language Generation Systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>R Robertson</author>
<author>L Osman</author>
</authors>
<title>Knowledge Acquisition for Natural Language Generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the First International Conference on Natural Language Generation</booktitle>
<volume>2000</volume>
<pages>217--224</pages>
<contexts>
<context position="2127" citStr="Reiter et al 2000" startWordPosition="318" endWordPosition="321">content determination rules are often based on corpus analysis and interaction with experts. In this paper we propose a general architecture for content determination in data summarisation systems which assumes that content determination happens in two stages: first a qualitative overview of the data is formed, and second the content of the actual summaries is decided upon. This model is based on extensive knowledge acquisition (KA) activies that we have carried out in the SUMTIME project (Sripada, 2001), and also matches observations made during KA activities carried out in the STOP project (Reiter et al 2000). We have not yet implemented this model, and indeed one of the issues that we need to think about is to what degree a content-determination strategy used by human experts is also an appropriate one for a computer NLG system. 2 Content Determination Content determination is the task of deciding on the information content of a generated text. In the three-stage pipeline model of Reiter and Dale (2000), content determination is part of the first stage, document planning, along with document structuring (determining the textual and rhetorical structure of a text). Content determination is extreme</context>
<context position="4237" citStr="Reiter et al 2000" startWordPosition="635" endWordPosition="638">n tell these strategies are usually based on the intuition and experiences of the developers. While realisation, microplanning, and document structuring techniques are increasingly based on analyses of how humans perform these tasks (including corpus analysis, psycholinguistic studies, and KA activities), most papers on content determination make little reference to how human experts determine the content of a text. Human experts are often consulted with regard to the details of content rules, especially when schemas are used for content determination (Goldberg et al 1994, McKeown et al 1994, Reiter et al 2000); but they rarely seem to be consulted (as far as we can tell) when deciding on the general algorithm or strategy to use for content determination. 3 Summarising Time-Series Data 3.1 Text summaries of Time-Series Data Time-series data is a collection of values of a set of parameters over time. Such data is very common in the modern world, with its proliferation of databases and sensors, and humans frequently need to examine and make inferences from time-series data. Currently, human examination of time-series data is generally done either by direct inspection of the data (for small data sets),</context>
<context position="13919" citStr="Reiter et al 2000" startWordPosition="2215" endWordPosition="2218">y accurate model of states of a GT (unlike weather!). 3. The phrases used by the expert often express the trends in the data as if they were physical happenings on the turbine, like “running down” for a decreasing trend in shaft speed data. This indicates that the expert is merely expressing the state of the GT. This in turn indicates that at the time the summarisation is done, the mental model of the state of the GT is available. 5 Evidence from Other Projects After making the above observations, we examined think-aloud transcripts from an earlier project at the University of Aberdeen, STOP (Reiter et al 2000), which involved building an NLG system that produced smoking-cessation letters from smoking questionnaires. These transcripts (from think-aloud sessions of doctors and other health professionals manually writing smoking-cessation letters) showed that in this domain as well experts would usually first build Data Comprehension Goal (Derived from Comm. Goal) Constraints due to User Communication Reasoner (CR) Domain Data Source (DDS) Data Overview Domain Reasoner (DR) Figure 1. Two stage model for content determination Constraints due to other pragmatic factors Final Content Communication Goal a</context>
</contexts>
<marker>Reiter, Robertson, Osman, 2000</marker>
<rawString>Reiter E., Robertson R. and Osman L. (2000) Knowledge Acquisition for Natural Language Generation. In Proceedings of the First International Conference on Natural Language Generation (INLG-2000), 217-224 pp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Shahar</author>
</authors>
<title>Framework for Knowledge-Based Temporal Abstraction”,</title>
<date>1997</date>
<journal>Artificial Intelligence</journal>
<pages>90--79</pages>
<marker>Shahar, 1997</marker>
<rawString>Shahar Y (1997), “Framework for Knowledge-Based Temporal Abstraction”, Artificial Intelligence 90:79-133..</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Sripada</author>
</authors>
<title>Communicating Plans in Natural Language: Planning and Realisation.</title>
<date>1997</date>
<tech>PhD Thesis,</tech>
<institution>Indian Institute of Technology,</institution>
<location>Madras, India.</location>
<contexts>
<context position="15338" citStr="Sripada 1997" startWordPosition="2449" endWordPosition="2450"> do is to read through the questionaire just to get some idea of where he is at with his smoking. » We did not investigate overview formation in any detail in STOP, but the issue did come up once in a general discussion with a doctor about the think-aloud process. This particular doctor said that he built in his mind a mental image of the smoker (including a guess at what he or she looked like), and that he found this image very useful in deciding how best to communicate with the smoker. In another work, RajuGuide, once again there is evidence of an overview influencing content determination (Sripada 1997). RajuGuide is a system that generates route descriptions. At a higer level of abstraction, RajuGuide has two parts. The first part is responsible for planning the route the user wanted. The second module is responsible for generating the text describing the route. The route computed by the first part, which is in the form of a series of coordinates, is not directly communicated to the user. Instead the second part attempts to enrich the route depending upon what the user already knows and what additional information the knowledge base knows for that particular route. We believe that the route</context>
</contexts>
<marker>Sripada, 1997</marker>
<rawString>Sripada S. G. (1997) Communicating Plans in Natural Language: Planning and Realisation. PhD Thesis, Indian Institute of Technology, Madras, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Sripada</author>
</authors>
<title>SUMTIME: Observations from KA for Weather Domain.</title>
<date>2001</date>
<tech>Technical Report,</tech>
<institution>Computing Science Dept. Univ of Aberdeen,</institution>
<location>Aberdeen</location>
<contexts>
<context position="2018" citStr="Sripada, 2001" startWordPosition="302" endWordPosition="303">be based on the intuitions of system developers, instead of on empirical observations, although detailed content determination rules are often based on corpus analysis and interaction with experts. In this paper we propose a general architecture for content determination in data summarisation systems which assumes that content determination happens in two stages: first a qualitative overview of the data is formed, and second the content of the actual summaries is decided upon. This model is based on extensive knowledge acquisition (KA) activies that we have carried out in the SUMTIME project (Sripada, 2001), and also matches observations made during KA activities carried out in the STOP project (Reiter et al 2000). We have not yet implemented this model, and indeed one of the issues that we need to think about is to what degree a content-determination strategy used by human experts is also an appropriate one for a computer NLG system. 2 Content Determination Content determination is the task of deciding on the information content of a generated text. In the three-stage pipeline model of Reiter and Dale (2000), content determination is part of the first stage, document planning, along with docume</context>
<context position="7780" citStr="Sripada, 2001" startWordPosition="1191" endWordPosition="1192">n a third domain in 2002; this is likely to be a medical one, perhaps (although this is not definite) summarising sensor readings in neonatal intensive care units. The first year of SUMTIME (which started in April 2000) has mostly been devoted to knowledge acquisition, that is to trying to understand how human experts summarise timeseries data. This was done using various techniques, including corpus analysis, observation of experts writing texts, analysis of content rules suggested by experts, discussion with experts, and think-aloud sessions, where experts ‘think aloud’ while writing texts (Sripada, 2001). 3.3 Example The following table shows an example segment of meteorological time series data, specifically predicted wind speed and wind direction at an offshore oil exploration site. The time field is shown in ‘day/hour’ format. Time Wind Wind (day/hour) Direction Speed Knots 05/06 SE 22 05/09 SE 24 05/12 SE 30 05/15 SE 25 05/18 SSE 28 05/21 SSE 22 06/00 SE 16 This data was summarised by WNI&apos;s human forecasters as follows: FORECAST 06-24 GMT,FRIDAY,05-Jan 2001 WIND(KTS) CONF HIGH 10M: SE 20-25 OCCASIONALLY 25-30, EASING 15-20 LATER The above example is just a sample showing the data and its </context>
</contexts>
<marker>Sripada, 2001</marker>
<rawString>Sripada S. G. (2001) SUMTIME: Observations from KA for Weather Domain. Technical Report, Computing Science Dept. Univ of Aberdeen, Aberdeen AB24 3UE, UK. Awaiting approval from industrial collaborators.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>