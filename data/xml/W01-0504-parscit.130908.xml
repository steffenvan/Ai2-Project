<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000093">
<figure confidence="0.997757677419355">
allotment
lot
proportion
quota
rate
share
in terest
advantage
benefit
vantage
importance
meaningfulness
momentousness
opp ortunity
concern
Anteil
Interesse
Zins
Vorteil
Wichtigkeit
Bedeutung
importance
meaning
prominence
relevenacy
significance
weight
acceptance
denotation
sense
impact
</figure>
<sectionHeader confidence="0.5479815" genericHeader="abstract">
2 Relevance of Word-Level
Translations
</sectionHeader>
<bodyText confidence="0.991562746987952">
To get a better understanding of the problem,
we performed a small-scale investigation of par-
allel text to measure the relevance of word-level
translation. We examined two German-English
aligned text sources, the monthly bulletin of the
European Central Bank (ECB)1- and the Min-
utes of the European Parliament (Europar1)2.
A small excerpt is displayed in Figure 2.
Imagining the English text as a translation
of the German, we examined what happened
to each of the 443 German words during the
assumed translation to English. We defined six
categories for this purpose:
Translation in dictionary — The word is
translated to a English word that could be
found in an adequate bilingual dictionary.
Translation unusual — The translation word
is translated to an English word, which is
generally not a good translation, but valid
in the given context. Example: last session
(literal: yesterdays session)
POS changed in translation — The transla-
tion word is a literal translation, except
that it is of a different part-of-speech. Ex-
ample: economic activity (literal: economy
activity)
Part of a phrase — The word is part of a
phrase that as a whole is not translated lit-
erally. Examples: are consistent (literal:
stand in harmony), both ... and (literal: as
well as), suggests (literal: gives indication
to)
Dropped for syntactic reasons — The orig-
inal word is part of a syntactic construction
that does not exist in the target language,
for example some articles are dropped when
translated from German to English.
Dropped otherwise — Words that are
dropped, often for no clear reason at all.
This may even slightly change the meaning
of the sentence. Example: in the euro
[currency] area
We found that only about 68% of the Ger-
man words (also 68% of the German nouns)
were translated to an English word that may be
found in an adequate German-English bilingual
German side of the parallel corpus
Die neuen Daten und Umfrageergebnisse, die seit
Ende Juni 1999 vorliegen, stehen im Einklang mit
den zuvor gehegten Erwartungen, daf3 die Wirt-
schaftstatigkeit im Euro-Wahrungsgebiet in der er-
sten Jahreshalfte 1999 zunachst nicht weiter zu-
rackgegangen ist, sich dann stabilisiert hat und sich
in der zweiten Jahreshalfte beschleunigen darfte.
Die Wachstumsrate der Geldmengen- und Kredit-
aggregate bis einschlief3lich Juni 1999 unterstatzt
diese Beurteilung weitgehend, obwohl einige Auf-
wartsrisiken far die kiinftige Preisstabilitat nicht
ausgeschlossen werden konnen.
English side of the parallel corpus
The data and surveys which have become available
since end-June 1999 are consistent with earlier ex-
pectations, according to which economic activity in
the euro area first ceased to decline and then stabi-
lized in the first part of 1999 and should accelerate
in the second part of the year.
The evolution of monetary and credit aggregates
up to June 1999 broadly supports this assessment,
although some upward risks to future price stability
cannot be ruled out.
More literal translation of German side of
the parallel corpus
The new data and survey results that have been
available since the end of June 1999 are consistent
with the previously held expectations that the ac-
tivity of the economy in the Euro currency area
initially did not further decline in the first half of
1999, then stabilized itself and should accelerate in
the second half of the year.
The growth rate of money size and credit aggregate
until June 1999 inclusively supports this assessment
widely, although some upward risks for the future
price stability can not be excluded.
</bodyText>
<subsectionHeader confidence="0.61818">
Commercial MT Translation (Systran)
</subsectionHeader>
<bodyText confidence="0.997546454545455">
The new data and survey data, which are present
since at the end of of June 1999, are in confor-
mity with expectations preserved before that the
economic activity in the Euro-currency area in the
first yearly half 1999 did not continue to decrease
first, then stabilized and in the second yearly half
accelerate itself might.
The growth rate of the money supply and credit
units to including June 1999 supports this evalua-
tion to a large extent, although some upward risks
for the future price stability cannot be excluded.
</bodyText>
<page confidence="0.390216">
lhttp://www.ecb.int/pub/period.htm
</page>
<figureCaption confidence="0.745633">
Figure 2: Part of the ECB corpus
</figureCaption>
<footnote confidence="0.787916">
2http://www3.europarl.eu.int/
</footnote>
<table confidence="0.9994341">
Official Translation Literal Translation
ECB Europarl Europarl ECB Europarl Europarl
German German Port. German German Port.
all n. all n. all n. all n. all n. all n.
Translation in dictionary 70% 65% 66% 71% 61% 77% 91% 94% 90% 95% 93% 98%
Translation unusual 4% 13% 1% 2% 1% 2% 1% 2% 0% 0% 0% 0%
Part of idiomatic phrase 10% 2% 20% 16% 20% 11% 3% 2% 6% 3% 2% 2%
Dropped for syn. reasons 7% 0% 5% 0% 8% 0% 3% 0% 3% 0% 5% 0%
Dropped otherwise 3% 5% 5% 8% 9% 7% 1% 2% 0% 0% 2% 0%
POS changed 6% 15% 3% 3% 2% 1% 1% 0% 1% 2% 0% 0%
</table>
<figureCaption confidence="0.80606475">
Figure 3: Breakdown of what happens to words during translation — both for official translations
found in a parallel corpus and for a more literal translations which is the target of machine trans-
lation systems. Analysis for all words and nouns (n.) on three corpora: German-English European
Central Bank bulletin, German-English and Portuguese-English European Parliament Minutes.
</figureCaption>
<bodyText confidence="0.996973096153846">
dictionary. A detailed break-down is provided
in Figure 3.
There are many reasons for the low number
of literal translations. It is quite frequent that a
word gets translated in a way that is only justi-
fiable in this particular context. Some words are
simply dropped or change their part-of speech,
e.g., a noun may be turned into an adjective.
Sometimes this seems arbitrary, but in many
cases it seems motivated by a more fluent text
in the target language.
A serious problem for machine translation
systems that rely on word-level translation
models are phrases that cannot be translated
literally. This ranges from idiomatic expressions
such as den Loffel abgeben (literal: to give up the
spoon, meaning: to die) to constructions whose
translations are understandable, but just do not
sound right, e.g. im Einklang stehen (literal: to
stand in harmony, meaning: to be consistent).
Another issue are words that are dropped,
changed, or added due to their idiosyncratic
syntactic nature in a particular language. Hope-
fully, a more syntactic approach to translation
will be able to deal with this.
Of course, there are many ways to correctly
translate a text. In the second stage of our in-
vestigation, we emulate the behavior that can
be expected from an MT system: a more lit-
eral translation. We tried to translate as many
words as possible with translations that may be
found in a bilingual lexicon.
We can achieve a much higher percentage of
literal word translations this way, as detailed in
Figure 3. About 90% of all words and about
95% of the nouns can be translated using terms
from a dictionary. The lower number for all
words is mostly due to syntactic reasons, e.g.
determiners that are used in German, but not
in English. For open class words such as nouns,
the biggest remaining problem are phrases that
cannot be translated literally.
We carried out the same analysis on Portu-
guese-English data with similar results.
The high accuracy of word-by-word transla-
tion suggests that we will be able to address the
core of the machine translation problem with an
approach that basically does word-level transla-
tion, occasional dropping and inserting, and re-
ordering of words. This is what current statis-
tical machine translation projects are shooting
for.
</bodyText>
<sectionHeader confidence="0.997939" genericHeader="introduction">
3 Resources
</sectionHeader>
<bodyText confidence="0.997705470588235">
A large number of resources have recently be-
come available for machine translation research,
both corpora and tools. We chose German-
English translation for the experiments in this
paper. The following details the resources used.
The LEO bilingual German-English dictio-
nary3 is an ongoing volunteer effort. While
it is still not finished, it already provides an
outstanding resource with over 230,000 entries.
Bilingual dictionaries may not be easily avail-
able for other language pairs, especially for low-
density languages. Also, these dictionaries are
general-purpose and may not be suited for spe-
cialized domains such as medicine, law, or fi-
nance.
Parallel corpora are slowly becoming more
available. Currently, they tend to derive from
</bodyText>
<footnote confidence="0.69489">
3http://dict.leo.org/
</footnote>
<bodyText confidence="0.999821636363636">
government sources, such as parliament pro-
ceedings or laws, which may not be suitable
for other domains. For our experiments we de-
cided not to use the Europarl and ECB cor-
pora mentioned in the previous Section, but the
more general DE-NEWS corpus. It contains
transcript and translation of German news re-
ports from 1996-2000. The size of the corpus
is 50,000 sentences pairs (one million words per
language), which could be considered medium-
sized — in comparison, the Canadian Hansard
has about two million sentence pairs with forty
million words per language. We sentence-
aligned the corpus by an implementation of an
algorithm proposed by Gale and Church (1993),
with manual post-editing.
Fortunately, the evolution of the World Wide
Web and widespread use of digital publishing
has created a wealth of monolingual corpora.
We use the Wall Street Journal (WSJ) and Ger-
man news wire (DPA) corpora, which are both
available through the Linguistic Data Consor-
tium (LDC)4. Both consist of over one million
sentences and about twenty million words each.
Also, recent research in natural language
processing has equipped us with many useful
tools. For instance, the performance of part-
of-speech taggers is currently considered on-par
with humans. For our experiments, we also used
Morphy as morphological analyzer and part of
speech tagger for German, and Eric Brill&apos;s part
of speech tagger for English (Brill, 1994).
In summary, we used the following resources:
</bodyText>
<listItem confidence="0.999923142857143">
• Morphy, a German POS tagger and mor-
phological analyzer5
• Eric Brill&apos;s English POS tagger6
• the DE-NEWS German-English corpus7
• the LEO German-English dictionary
• the Wall Street Journal corpus (English)
• the DPA news wire corpus (German)
</listItem>
<bodyText confidence="0.997772">
Other knowledge sources that may be useful
are natural language parsers or ontologies such
as WordNet (Miller et al., 1993).
</bodyText>
<sectionHeader confidence="0.998259" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.964201">
For this paper we want to investigate the role
of different knowledge sources for the training
</bodyText>
<footnote confidence="0.99981825">
4http://www.ldc.upenn.edu/
5http://www-psycho.uni-paderborn.de/lezius/
ehttp://www.cs.jhu.edu/ brill/
7http://www.isi.edu/ koehn/publications/de-news/
</footnote>
<bodyText confidence="0.999565583333334">
of word-level translation models. We evaluate
the methods by the accuracy of the suggested
word-level translations with respect to a refer-
ence parallel corpus.
When translating the limited number of
closed class words such as articles, syntactical
issues and language ideosyncracies play a big
role. The emphasis of the lexical component of
a machine translation system is to perform well
for the much larger number of open class words
— nouns, verbs, adjectives and adverbs. In this
work, we decided to focus on nouns.
We examined the behavior of 9,206 German
and 10,645 English distinct nouns. Some of
these have unique, while most have multiple
translations. The lexicon consists of 19,782
word pairs. So, on average, there are two en-
tries per word.
5,000 sentence pairs of the DE-NEWS corpus
are used as evaluation set. We identified word
translations using a bilingual lexicon. The task
for the following methods is to find the same
English translation for a German word, given
the German, but not the English part of the
evaluation corpus.
Given nouns in the German sentence, the lex-
icon constrains the possible matching English
nouns sufficiently in nearly all cases. It is very
rare that two or more nouns in the German sen-
tence may map to the same word in the English
sentence.
If there is no English translation for a Ger-
man word within the lexicon, we do not place
it in the evaluation set. While this excludes a
considerable portion of the German words, we
do not view this as a weakness of the evalua-
tion metric. As we pointed out in Section 2, we
are looking for a more literal translation as the
goal of a machine translation system than the
parallel corpus provides.
Of course, a method that does not use the
lexicon may find good translations outside the
dictionary and may get punished by this metric.
For our data, however, this did not constitute a
significant problem.
Another issue is that in some cases two trans-
lations might be perfectly fitting. A method
that picks the translation that is not in the eval-
uation set is unfairly discounted. But since this
is the same for all methods, it should have no
effect on the comparison of the methods. Still,
it does mean that 100% accuracy according to
the metric may not be achievable.
We focused the following investigation on
nouns. We can identify the nouns in the corpus
using the part-of-speech taggers. These tools al-
low us to reduce the found surface forms to word
stems. In addition, the German Morphy also al-
lows us to split up compounds such as Bundes-
verteidigungshaushalt (federal defense budget).
</bodyText>
<sectionHeader confidence="0.872866" genericHeader="method">
5 Using Parallel Corpus and Lexicon
</sectionHeader>
<subsectionHeader confidence="0.757794">
5.1 Background
</subsectionHeader>
<bodyText confidence="0.999940636363636">
The best results can be achieved provided both
a parallel corpus and a bilingual dictionary. As
with our evaluation corpus, we can use the bilin-
gual lexicon to extract word-level noun transla-
tion pairs from the parallel corpus.
Having word-level translations in context, we
can use supervised word sense disambiguation
methods, which have been extensively stud-
ied. For instance, Mooney (1996) provides a
good comparison these methods. See also the
overview by Ide and Veronis (1998).
</bodyText>
<subsectionHeader confidence="0.954628">
5.2 Experiment
</subsectionHeader>
<bodyText confidence="0.993403333333333">
In the method used here, we extracted the fol-
lowing context features for each noun occur-
rence:
</bodyText>
<listItem confidence="0.999496333333333">
• Up to three words of local context around
the target word, using part-of-speech tags
as back-off.
• Any open-class word (noun, verb, adjec-
tive, adverb) in the same sentence
• Any open-class word in the same document
</listItem>
<bodyText confidence="0.9977475">
These features allow us to train a decision list
as described by Yarowsky (1994).
</bodyText>
<sectionHeader confidence="0.643591" genericHeader="method">
5.3 Results
</sectionHeader>
<bodyText confidence="0.9999471875">
The resulting classifier finds the correct word-
level translation in our test data with 89.5%
accuracy. The baseline method for this data,
which is to choose always the most frequent
word-level translation, as found in the train-
ing data, however, performs only slightly worse
(88.9%).
Let us already point out at this point the sig-
nificance of these results: Without any word
sense disambiguation we could achieve almost
90% accuracy. None of the following experi-
ments will reach this performance. So, at least
in the framework of these experiments, the main
problem is still finding the overall best transla-
tion for a word, not the advanced task of finding
the right translation in a given context.
</bodyText>
<sectionHeader confidence="0.9256525" genericHeader="method">
6 Using Parallel and Monolingual
Corpora and Lexicon
</sectionHeader>
<subsectionHeader confidence="0.99432">
6.1 Background
</subsectionHeader>
<bodyText confidence="0.999956833333333">
Yarowsky (1995) proposes a bootstrapping
scheme that uses a initial decision list trained on
supervised data as a starting point. By labeling
new word occurrences in a monolingual corpus,
he was able to collect more evidence that enable
the construction of a superior decision list.
</bodyText>
<subsectionHeader confidence="0.963399">
6.2 Experiment
</subsectionHeader>
<bodyText confidence="0.999994375">
We can easily apply this idea to our problem:
We already trained a decision list for word-level
translations. Using this decision list on a Ger-
man monolingual corpus and additional clues
such as &amp;quot;one sense per discourse&amp;quot;, we can la-
bel more occurrences of the German words with
English translations. This, in turn, provides a
larger training set to retrain the decision list.
</bodyText>
<subsectionHeader confidence="0.51456">
6.3 Results
</subsectionHeader>
<bodyText confidence="0.999982625">
Applying this idea to our data, however, was
not successful. Nearly all ambiguous German
words have a strong majority translation. After
applying the decision list to monolingual data,
an even larger portion of the occurrences is la-
beled with the majority translation. The algo-
rithm quickly converges to a decision list that
always predicts the majority case.
Apparently the initial decision lists are not
good enough to find strong context features for
the minority translations. This is underscored
by the accuracy just above the baseline. The
original training set with at most a few hun-
dred occurrences for each German word does
not seem to be big enough. It might be more
successful, if a larger parallel corpus is available.
</bodyText>
<sectionHeader confidence="0.753053" genericHeader="method">
7 Using only Parallel Corpus
7.1 Background
</sectionHeader>
<bodyText confidence="0.999864166666667">
The Candide machine translation approach
(Brown et al., 1990) is based on the noisy chan-
nel model. It takes the view that the foreign
language sentence is just distorted English that
has been corrupted by a translation process. It
can be decoded by using the Bayes rule:
</bodyText>
<equation confidence="0.635021">
argmaxep(elg) = argmaxep(g le)P(e)
</equation>
<figure confidence="0.951100333333333">
1008
908
B08
708
608
508
408
308
208
108
08
Decision List (Section 5)
Giza (Section 7)
0 1 2+ 4+ B+ 16+ 32+ 64+ 12B+ 256+ 512+ 1024+
Number of examples per word
</figure>
<bodyText confidence="0.999603823529412">
ing of machine translation systems, but this is a
costly option — professional translation rates are
roughly between 5 and 20 US cents per word.
But ultimately we have to face the fact that
people do not naturally produce the same text
in multiple language. Therefore, parallel cor-
pora will always be a limited resource, often
from unsuitable domains. The previous section
highlighted that a word has to occur a suffi-
cient number of times to be able to learn rea-
sonable translation models. But even in the
forty million sentence Hansard Corpus common
words such as directory, empathy, reflex, ant,
filth, gangster, and fake occur only once.
On the other hand, we can surely assume,
that we will have a large monolingual corpus
available in a language for which we want to
build a machine translation system. After all, if
this would not be the case, what would be the
purpose of such a system? We have also good
reason to believe that the information technol-
ogy revolution will bring large monolingual text
resources forward. The World Wide Wide alone
currently consists of over one billion documents.
According to the search engine Google9, the
words above occur extremely often — directory
42 million times, empathy 180,000 times, reflex
372,000 times, ant 859,000 times, and so on.
We are optimistic that much can be learned
from this vast amount of data. This section
will discuss methods how to learn translation
models from monolingual data which require a
bilingual lexicon. The next section will drop
this requirement.
</bodyText>
<subsectionHeader confidence="0.988044">
8.2 Experiment
</subsectionHeader>
<bodyText confidence="0.999824571428571">
If we have a corpus in the target language, we
can apply two simple ideas:
Firstly, we could always choose the word in
the lexicon that occurs most frequently in the
target language corpus. This simple principle
shows surprisingly good results.
Secondly, we can build a language model and
choose the most likely sequence of words in the
target language. This allows the use of con-
text clues. Research in generation, such as
the Nitrogen generation system (Langkilde and
Knight, 1998) demonstrate the effectiveness of
this method.
A more sophisticated approach is proposed
</bodyText>
<footnote confidence="0.836818">
9http://www.google.com/
</footnote>
<bodyText confidence="0.999606090909091">
by Koehn and Knight (2000). It uses a lexicon,
a corpus in the target language, and a compa-
rable corpus in the source language. The ap-
proach views the corpus in the source language
(German) as actually being an English corpus,
corrupted by a noisy channel.
Given word-level translation probabilities and
a language model we can determine for each
German word the most likely English word in
its place. Also, given such a corpus of German-
English word pairs, we can easily estimate word-
level translation probabilities.
This set-up constitutes a chicken and egg
problem: On the one hand we do not have
word-level translation probabilities to estimate
the best English word matches. On the other
hand, we do not have these German-English
word pairs to estimate word-level translation
probabilities.
Fortunately this problem can be addressed
using the Expectation Maximization (EM) al-
gorithm. The algorithm alternatively scores the
possible English words for each German word
(the expectation step) and estimates translation
probabilities based on this (the maximization
step) until convergence.
The resulting word-level translation probabil-
ities and the language model can be used com-
bined with the target language model (trained
on the target corpus) in the usual statistical ma-
chine translation setup to translate unseen Ger-
man text. As before, we apply this method only
to the nouns in the text.
</bodyText>
<subsectionHeader confidence="0.7617">
8.3 Results
</subsectionHeader>
<bodyText confidence="0.999887363636364">
Using frequency counts results in 75.3% accu-
racy, the use of a language model 77.3%, and
the EM method raises this to 79.0%. Still, when
both a parallel corpus and a bilingual lexicon
are used, the accuracy of noun translations is
about ten percent higher (88.9%). However,
these numbers are on par with the results for
training from only a parallel corpus (76.9%).
Thus, for our set of resources, a parallel cor-
pus can be replaced with monolingual corpora
and a bilingual lexicon.
</bodyText>
<sectionHeader confidence="0.464795" genericHeader="method">
9 Using only Monolingual Corpora
</sectionHeader>
<subsectionHeader confidence="0.892535">
9.1 Background
</subsectionHeader>
<bodyText confidence="0.998863244444445">
We already argued that the most easily avail-
able knowledge source is monolingual text.
Some ideas have been investigated in the at-
tempt to construct lexicons using only monolin-
gual corpora. All these approaches try to create
a one-to-one or one-to-many mapping. While
this is not realistic (recall Figure 1), it is a good
starting point.
Similarities between a word and its transla-
tion make this a feasible endeavor. Rapp (1995,
1999) bases his work on the notion that words
that co-occur frequently in one language have
translations that also co-occur frequently in an-
other language. He uses this properties to fill
gaps in an existing lexicon. Work by Fung
(1995); Fung and Yee (1998) is based on the
same principal: This allows her to add novel
terms to a lexicon.
Diab and Finch (2000) make another interest-
ing observation: Words that have a certain sim-
ilarity in one language (say dog and cat) have
translations that are similar in the other lan-
guage. They measure similarity as occurring in
a similar context (say her new X is cute). Sim-
ilarity is measured by a context vector using
4-word window.
But also simpler clues may provide useful in-
formation: Words that are very frequent in one
language have translations that may also be fre-
quent in a comparable corpus in another lan-
guage.
Also, some words have similar spelling across
languages. This may be due to same roots (En-
glish: mother, German: Mutter, Portuguese:
mcie, Spanish: madre), or cultural exchange
(English: computer, German: Computer, Por-
tuguese: computador, Japanese: konpyuta).
Rapp (1999) points out the need for a seed for
lexicon construction from monolingual corpora.
Only the algorithm by Diab and Finch (2000)
does not require a seed. However, although we
successfully duplicated their work when applied
to two comparable English corpora, the method
failed to produce a useful lexicon for our com-
parable German and English corpora.
</bodyText>
<subsectionHeader confidence="0.790991">
9.2 Experiments
</subsectionHeader>
<bodyText confidence="0.999808736842105">
Without a lexicon to start with, we could collect
an initial lexicon from a small parallel corpus.
But to stick to the spirit of this section, we used
a different seed: words that have the exactly the
same spelling in German and English.
From the 9,206 German nouns in our bilin-
gual lexicon, we could find 1,016 words that oc-
cur also in English (such as nation, computer,
email). The assumption that these words are
in fact translations of each other is accurate for
88% of the words (exceptions are mostly shorter
words, for example ton, fee, kind, rat, art, rock,
boot, gang, plane, taste, hut). When relying
solely on this same-word seed lexicon, we can
achieve 11.9% accuracy on our evaluation met-
ric.
Then we used four different methods to ex-
tend the lexicon, which exploit the fact that a
word and its translation have similar:
</bodyText>
<listItem confidence="0.9995074">
• context (Rapp, 1999)
• spelling
• relationship to other words (Diab and
Finch, 2000)
• frequency
</listItem>
<sectionHeader confidence="0.713428" genericHeader="evaluation">
9.3 Results
</sectionHeader>
<bodyText confidence="0.999936833333333">
For computational reasons we focus on the 1000
most frequent German and English words ac-
cording to the monolingual corpora. Only the
context and the spelling property helped us to
extend the lexicon. When adding lexicon entries
based on similar spelling, we achieved 25.4% ac-
curacy on our evaluation metric, with the con-
text property 31.9%. When both properties are
combined, we achieve 38.6%. This is quite sig-
nificant, since the baseline — mapping words at
random — is no better than the original score of
11.9% for identical words.
</bodyText>
<sectionHeader confidence="0.995485" genericHeader="conclusions">
10 Conclusions
</sectionHeader>
<bodyText confidence="0.999952888888889">
We established that a word-level translation
model is a core element of machine translation
systems — 95% of nouns can be translated within
a conventional bilingual lexicon.
These models are usually trained on paral-
lel texts. We investigated various methods to
augment and replace the need for parallel cor-
pora with monolingual corpora and bilingual
lexicons. A common evaluation metric enabled
a first quantitative comparison, as summarized
in Figure 5.
A bilingual lexicon provides a clear benefit:
While training on a parallel corpus alone we
achieved 76.9% accuracy, the lexicon boosted
this to 89.5%. Also, using both monolingual
data and a lexicon allowed us to replace the
parallel corpus and get similar performance
(79.0%). Finally we showed how to acquire a
</bodyText>
<table confidence="0.8994995">
Parallel corpus Giza 76.9%
Monoling. corpus, lexicon most frequent 75.3%
Monoling. corpus, lexicon language model 77.3%
Monoling. corpus, lexicon EM 79.0%
Monoling. corpus identical 11.9%
Monoling. corpus spelling 25.4%
Monoling. corpus context 31.9%
Monoling. corpus spell.±context 38.6%
</table>
<figureCaption confidence="0.992417">
Figure 5: Results for methods from Section 5-9
</figureCaption>
<bodyText confidence="0.988327833333333">
translation model purely from monolingual cor-
pora.
The heart of the problem still seems to be
finding the overall best translation for all the
words, rather than advanced word sense disam-
biguation task of finding the right translation
in a given context. This is even more true for
low density languages, where less resources are
available.
Clearly, there is still much room for improve-
ment - many ideas that we touched upon here
require further investigation.
</bodyText>
<sectionHeader confidence="0.95769" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.998228">
This work was supported by DARPA-ITO grant
N66001-00-1-9814.
</bodyText>
<sectionHeader confidence="0.998042" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999642333333333">
Al-Onaizan, Y., Curin, J., Jahr, M., Knight, K.,
Lafferty, J., Melamed, D., Och, F.-J., Purdy,
D., Smith, N. A., and Yarowsky, D. (1999).
Statistical machine translation. Technical re-
port, John Hopkins University Summer Workshop
http : //www. clsp j hu. edu/ws99/projects/mt/.
Brill, E. (1994). Some advances in rule-based part of
speech tagging. In Proceedings of AAAI.
Brown, P., Cocke, J., Della Pietra, S. A., Della Pietra,
V. J., Jelinek, F., Lafferty, J. D., Mercer, R. L., and
Rossin, P. (1990). A statistical approach to machine
translation. Computational Linguistics, 16(2):76-85.
Diab, M. (2000). An unsupervised method for multi-
lingual word sense tagging using parallel corpora: A
preliminary investigation. In SIGLEX Workshop on
Word Senses and Multi-Linguality, pages 1-9.
Diab, M. and Finch, S. (2000). A statistical word-level
translation model for comparable corpora. In Proceed-
ings of the Conference on Content-based multimedia
information access (RIAO).
Fung, P. (1995). Compiling bilingual lexicon entries from
a non-parallel english-chinese corpus. In Third Work-
shop on Very Large Corpora, pages 173-183.
Fung, P. and Yee, L. Y. (1998). An IR approach for
translating new words from nonparallel, comparable
texts. In Proceedings of ACL 36, pages 414-420.
Gale, W. and Church, K. (1993). A program for aligning
sentences in bilingual corpora. Computational Lingus-
tics, 19(1).
Germann, U., Jahr, M., Knight, K., Marcu, D., and Ya-
mada, K. (2001). Fast decoding and optimal decoding
for machine translation. In Proceedings of ACL 39.
Ide, N. and Veronis, J. (1998). Introduction to the spe-
cial issue on word sense disambiguation: The state of
the art. Computational Linguistics, 24(1):1-40.
Koehn, P. and Knight, K. (2000). Estimating word trans-
lation probabilities from unrelated monolingual cor-
pora using the EM algorithm. In Proceedings of AAAI.
Langkilde, I. and Knight, K. (1998). Generaton that
exploits corpus-based statistical knowledge. In Pro-
ceedings of ACL 36, pages 704-710.
Melamed, I. D. (2000). Models of translational equiv-
alence among words. Computational Lingustics,
26(2):221-249.
Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D.,
and Miller, K. J. (1993). Introduction to WordNet:
An online lexical database. Technical Report CSL 43,
Cognitive Science Laboratory Princeton University.
Mooney, R. (1996). Comparative experiments on dis-
ambiguation word senses: An illustration of bias in
machine learning. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP.
Rapp, R. (1995). Identifying word translations in non-
parallel texts. In Proceedings of ACL 33, pages 320-
322.
Rapp, R. (1999). Automatic identification of word trans-
lations from unrelated english and german corpora. In
Proceedings of ACL 37, pages 519-526.
Resnik, P. (1999). Mining the web for bilingual text. In
Proceedings of ACL 37, pages 527-534.
Yamada, K. and Knight, K. (2001). A syntax-based sta-
tistical translation model. In Proceedings of ACL 39.
Yarowsky, D. (1994). Decision lists for lexical ambiguity
resolution: Application to accent restoration in Span-
ish and French. In Proceedings of ACL 32.
Yarowsky, D. (1995). Unsupervised word sense disam-
biguation rivaling supervised methods. In Proceedings
of ACL 33, pages 189-196.
</reference>
<figure confidence="0.99853">
Knowledge sources
Method
Acc.
Parallel corpus, lexicon
Parallel corpus, lexicon
most frequent
decision list
88.9%
89.5%
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000014">
<abstract confidence="0.993300015625">allotment lot proportion quota rate share in terest advantage benefit vantage importance momentousness opp concern Anteil Interesse Zins Vorteil Wichtigkeit Bedeutung importance meaning prominence relevenacy significance weight acceptance denotation sense impact 2 Relevance of Word-Level Translations To get a better understanding of the problem, we performed a small-scale investigation of parallel text to measure the relevance of word-level translation. We examined two German-English aligned text sources, the monthly bulletin of the Central Bank and the Minof the European Parliament A small excerpt is displayed in Figure 2. Imagining the English text as a translation of the German, we examined what happened to each of the 443 German words during the assumed translation to English. We defined six categories for this purpose: in dictionary — word is translated to a English word that could be found in an adequate bilingual dictionary. unusual — translation word is translated to an English word, which is generally not a good translation, but valid the given context. Example: session session) changed in translation — translation word is a literal translation, except that it is of a different part-of-speech. Exactivity activity) of a phrase — word is part of a phrase that as a whole is not translated lit- Examples: consistent in harmony), both ... and as), suggests indication to) for syntactic reasons — original word is part of a syntactic construction that does not exist in the target language, for example some articles are dropped when translated from German to English. otherwise — that dropped, often for no clear reason at all. This may even slightly change the meaning the sentence. Example: in euro [currency] area We found that only about 68% of the German words (also 68% of the German nouns) were translated to an English word that may be found in an adequate German-English bilingual German side of the parallel corpus Die neuen Daten und Umfrageergebnisse, die seit Ende Juni 1999 vorliegen, stehen im Einklang mit den zuvor gehegten Erwartungen, daf3 die Wirtschaftstatigkeit im Euro-Wahrungsgebiet in der ersten Jahreshalfte 1999 zunachst nicht weiter zurackgegangen ist, sich dann stabilisiert hat und sich in der zweiten Jahreshalfte beschleunigen darfte. Die Wachstumsrate der Geldmengenund Kreditaggregate bis einschlief3lich Juni 1999 unterstatzt diese Beurteilung weitgehend, obwohl einige Aufwartsrisiken far die kiinftige Preisstabilitat nicht ausgeschlossen werden konnen. English side of the parallel corpus The data and surveys which have become available since end-June 1999 are consistent with earlier expectations, according to which economic activity in the euro area first ceased to decline and then stabilized in the first part of 1999 and should accelerate in the second part of the year. The evolution of monetary and credit aggregates up to June 1999 broadly supports this assessment, although some upward risks to future price stability cannot be ruled out. More literal translation of German side of the parallel corpus The new data and survey results that have been available since the end of June 1999 are consistent with the previously held expectations that the activity of the economy in the Euro currency area initially did not further decline in the first half of 1999, then stabilized itself and should accelerate in the second half of the year. The growth rate of money size and credit aggregate until June 1999 inclusively supports this assessment widely, although some upward risks for the future price stability can not be excluded. Commercial MT Translation (Systran) The new data and survey data, which are present since at the end of of June 1999, are in conformity with expectations preserved before that the economic activity in the Euro-currency area in the first yearly half 1999 did not continue to decrease first, then stabilized and in the second yearly half accelerate itself might. The growth rate of the money supply and credit units to including June 1999 supports this evaluation to a large extent, although some upward risks for the future price stability cannot be excluded. 2: of the ECB corpus</abstract>
<title confidence="0.8884995">Official Translation Literal Translation ECB Europarl Europarl ECB Europarl Europarl</title>
<author confidence="0.896517">German German Port</author>
<note confidence="0.856299142857143">all n. all n. all n. all n. all n. all n. Translation in dictionary 70% 65% 66% 71% 61% 77% 91% 94% 90% 95% 93% 98% Translation unusual 4% 13% 1% 2% 1% 2% 1% 2% 0% 0% 0% 0% Part of idiomatic phrase 10% 2% 20% 16% 20% 11% 3% 2% 6% 3% 2% 2% Dropped for syn. reasons 7% 0% 5% 0% 8% 0% 3% 0% 3% 0% 5% 0% Dropped otherwise 3% 5% 5% 8% 9% 7% 1% 2% 0% 0% 2% 0% POS changed 6% 15% 3% 3% 2% 1% 1% 0% 1% 2% 0% 0%</note>
<abstract confidence="0.996360719101123">Figure 3: Breakdown of what happens to words during translation — both for official translations found in a parallel corpus and for a more literal translations which is the target of machine translation systems. Analysis for all words and nouns (n.) on three corpora: German-English European Central Bank bulletin, German-English and Portuguese-English European Parliament Minutes. dictionary. A detailed break-down is provided in Figure 3. There are many reasons for the low number of literal translations. It is quite frequent that a word gets translated in a way that is only justifiable in this particular context. Some words are simply dropped or change their part-of speech, e.g., a noun may be turned into an adjective. Sometimes this seems arbitrary, but in many cases it seems motivated by a more fluent text in the target language. A serious problem for machine translation systems that rely on word-level translation models are phrases that cannot be translated literally. This ranges from idiomatic expressions as Loffel abgeben give up the die) constructions whose translations are understandable, but just do not right, e.g. im stehen in harmony, be consistent). Another issue are words that are dropped, changed, or added due to their idiosyncratic syntactic nature in a particular language. Hopefully, a more syntactic approach to translation will be able to deal with this. Of course, there are many ways to correctly translate a text. In the second stage of our investigation, we emulate the behavior that can be expected from an MT system: a more literal translation. We tried to translate as many words as possible with translations that may be found in a bilingual lexicon. We can achieve a much higher percentage of literal word translations this way, as detailed in Figure 3. About 90% of all words and about 95% of the nouns can be translated using terms from a dictionary. The lower number for all words is mostly due to syntactic reasons, e.g. determiners that are used in German, but not in English. For open class words such as nouns, the biggest remaining problem are phrases that cannot be translated literally. We carried out the same analysis on Portuguese-English data with similar results. The high accuracy of word-by-word translation suggests that we will be able to address the core of the machine translation problem with an approach that basically does word-level translation, occasional dropping and inserting, and reordering of words. This is what current statistical machine translation projects are shooting for. A large number of resources have recently become available for machine translation research, both corpora and tools. We chose German- English translation for the experiments in this paper. The following details the resources used. The LEO bilingual German-English dictiois an ongoing volunteer effort. While it is still not finished, it already provides an outstanding resource with over 230,000 entries. Bilingual dictionaries may not be easily available for other language pairs, especially for lowdensity languages. Also, these dictionaries are general-purpose and may not be suited for specialized domains such as medicine, law, or finance. Parallel corpora are slowly becoming more available. Currently, they tend to derive from 3http://dict.leo.org/ government sources, such as parliament proceedings or laws, which may not be suitable for other domains. For our experiments we decided not to use the Europarl and ECB corpora mentioned in the previous Section, but the more general DE-NEWS corpus. It contains transcript and translation of German news reports from 1996-2000. The size of the corpus is 50,000 sentences pairs (one million words per language), which could be considered mediumsized — in comparison, the Canadian Hansard has about two million sentence pairs with forty million words per language. We sentencealigned the corpus by an implementation of an algorithm proposed by Gale and Church (1993), with manual post-editing. Fortunately, the evolution of the World Wide Web and widespread use of digital publishing has created a wealth of monolingual corpora. We use the Wall Street Journal (WSJ) and German news wire (DPA) corpora, which are both available through the Linguistic Data Consor- Both consist of over one million sentences and about twenty million words each. Also, recent research in natural language processing has equipped us with many useful tools. For instance, the performance of partof-speech taggers is currently considered on-par with humans. For our experiments, we also used Morphy as morphological analyzer and part of speech tagger for German, and Eric Brill&apos;s part of speech tagger for English (Brill, 1994). In summary, we used the following resources: • Morphy, a German POS tagger and mor- Eric Brill&apos;s English POS the DE-NEWS German-English • the LEO German-English dictionary • the Wall Street Journal corpus (English) • the DPA news wire corpus (German) Other knowledge sources that may be useful are natural language parsers or ontologies such as WordNet (Miller et al., 1993). 4 Experimental Setup For this paper we want to investigate the role of different knowledge sources for the training brill/ koehn/publications/de-news/ of word-level translation models. We evaluate the methods by the accuracy of the suggested word-level translations with respect to a reference parallel corpus. When translating the limited number of closed class words such as articles, syntactical issues and language ideosyncracies play a big role. The emphasis of the lexical component of a machine translation system is to perform well for the much larger number of open class words — nouns, verbs, adjectives and adverbs. In this work, we decided to focus on nouns. We examined the behavior of 9,206 German and 10,645 English distinct nouns. Some of these have unique, while most have multiple translations. The lexicon consists of 19,782 word pairs. So, on average, there are two entries per word. 5,000 sentence pairs of the DE-NEWS corpus are used as evaluation set. We identified word translations using a bilingual lexicon. The task for the following methods is to find the same English translation for a German word, given the German, but not the English part of the evaluation corpus. Given nouns in the German sentence, the lexicon constrains the possible matching English nouns sufficiently in nearly all cases. It is very rare that two or more nouns in the German sentence may map to the same word in the English sentence. If there is no English translation for a German word within the lexicon, we do not place it in the evaluation set. While this excludes a considerable portion of the German words, we do not view this as a weakness of the evaluation metric. As we pointed out in Section 2, we are looking for a more literal translation as the goal of a machine translation system than the parallel corpus provides. Of course, a method that does not use the lexicon may find good translations outside the dictionary and may get punished by this metric. For our data, however, this did not constitute a significant problem. Another issue is that in some cases two translations might be perfectly fitting. A method that picks the translation that is not in the evaluation set is unfairly discounted. But since this is the same for all methods, it should have no effect on the comparison of the methods. Still, it does mean that 100% accuracy according to the metric may not be achievable. We focused the following investigation on nouns. We can identify the nouns in the corpus using the part-of-speech taggers. These tools allow us to reduce the found surface forms to word stems. In addition, the German Morphy also alus to split up compounds such as Bundesverteidigungshaushalt (federal defense budget). 5 Using Parallel Corpus and Lexicon 5.1 Background The best results can be achieved provided both a parallel corpus and a bilingual dictionary. As with our evaluation corpus, we can use the bilingual lexicon to extract word-level noun translation pairs from the parallel corpus. Having word-level translations in context, we can use supervised word sense disambiguation methods, which have been extensively studied. For instance, Mooney (1996) provides a good comparison these methods. See also the overview by Ide and Veronis (1998). 5.2 Experiment In the method used here, we extracted the following context features for each noun occurrence: • Up to three words of local context around the target word, using part-of-speech tags as back-off. • Any open-class word (noun, verb, adjective, adverb) in the same sentence • Any open-class word in the same document These features allow us to train a decision list as described by Yarowsky (1994). 5.3 Results The resulting classifier finds the correct wordlevel translation in our test data with 89.5% accuracy. The baseline method for this data, which is to choose always the most frequent word-level translation, as found in the training data, however, performs only slightly worse (88.9%). Let us already point out at this point the significance of these results: Without any word sense disambiguation we could achieve almost 90% accuracy. None of the following experiments will reach this performance. So, at least in the framework of these experiments, the main problem is still finding the overall best translation for a word, not the advanced task of finding the right translation in a given context. 6 Using Parallel and Monolingual Corpora and Lexicon 6.1 Background Yarowsky (1995) proposes a bootstrapping scheme that uses a initial decision list trained on supervised data as a starting point. By labeling new word occurrences in a monolingual corpus, he was able to collect more evidence that enable the construction of a superior decision list. 6.2 Experiment We can easily apply this idea to our problem: We already trained a decision list for word-level translations. Using this decision list on a German monolingual corpus and additional clues such as &amp;quot;one sense per discourse&amp;quot;, we can label more occurrences of the German words with English translations. This, in turn, provides a larger training set to retrain the decision list. 6.3 Results Applying this idea to our data, however, was not successful. Nearly all ambiguous German words have a strong majority translation. After applying the decision list to monolingual data, an even larger portion of the occurrences is labeled with the majority translation. The algorithm quickly converges to a decision list that always predicts the majority case. Apparently the initial decision lists are not good enough to find strong context features for the minority translations. This is underscored by the accuracy just above the baseline. The original training set with at most a few hundred occurrences for each German word does not seem to be big enough. It might be more successful, if a larger parallel corpus is available. 7 Using only Parallel Corpus 7.1 Background The Candide machine translation approach (Brown et al., 1990) is based on the noisy channel model. It takes the view that the foreign language sentence is just distorted English that has been corrupted by a translation process. It can be decoded by using the Bayes rule: = le)P(e)</abstract>
<date confidence="0.2186">1008</date>
<note confidence="0.461419153846154">908 B08 708 608 508 408 308 208 108 08 Decision List (Section 5) Giza (Section 7) 0 1 2+ 4+ B+ 16+ 32+ 64+ 12B+ 256+ 512+ 1024+</note>
<abstract confidence="0.994739680203046">Number of examples per word ing of machine translation systems, but this is a costly option — professional translation rates are roughly between 5 and 20 US cents per word. But ultimately we have to face the fact that people do not naturally produce the same text in multiple language. Therefore, parallel corpora will always be a limited resource, often from unsuitable domains. The previous section highlighted that a word has to occur a sufficient number of times to be able to learn reasonable translation models. But even in the forty million sentence Hansard Corpus common such as empathy, reflex, ant, gangster, only once. On the other hand, we can surely assume, that we will have a large monolingual corpus available in a language for which we want to build a machine translation system. After all, if this would not be the case, what would be the purpose of such a system? We have also good reason to believe that the information technology revolution will bring large monolingual text resources forward. The World Wide Wide alone currently consists of over one billion documents. to the search engine the above occur extremely often — million times, times, times, times, and so on. We are optimistic that much can be learned from this vast amount of data. This section will discuss methods how to learn translation models from monolingual data which require a bilingual lexicon. The next section will drop this requirement. 8.2 Experiment If we have a corpus in the target language, we can apply two simple ideas: Firstly, we could always choose the word in the lexicon that occurs most frequently in the target language corpus. This simple principle shows surprisingly good results. Secondly, we can build a language model and choose the most likely sequence of words in the target language. This allows the use of context clues. Research in generation, such as the Nitrogen generation system (Langkilde and Knight, 1998) demonstrate the effectiveness of this method. A more sophisticated approach is proposed by Koehn and Knight (2000). It uses a lexicon, a corpus in the target language, and a comparable corpus in the source language. The approach views the corpus in the source language (German) as actually being an English corpus, corrupted by a noisy channel. Given word-level translation probabilities and a language model we can determine for each German word the most likely English word in its place. Also, given such a corpus of German- English word pairs, we can easily estimate wordlevel translation probabilities. This set-up constitutes a chicken and egg problem: On the one hand we do not have word-level translation probabilities to estimate the best English word matches. On the other hand, we do not have these German-English word pairs to estimate word-level translation probabilities. Fortunately this problem can be addressed using the Expectation Maximization (EM) algorithm. The algorithm alternatively scores the possible English words for each German word (the expectation step) and estimates translation probabilities based on this (the maximization step) until convergence. The resulting word-level translation probabilities and the language model can be used combined with the target language model (trained on the target corpus) in the usual statistical machine translation setup to translate unseen German text. As before, we apply this method only to the nouns in the text. 8.3 Results Using frequency counts results in 75.3% accuracy, the use of a language model 77.3%, and the EM method raises this to 79.0%. Still, when both a parallel corpus and a bilingual lexicon are used, the accuracy of noun translations is about ten percent higher (88.9%). However, these numbers are on par with the results for training from only a parallel corpus (76.9%). Thus, for our set of resources, a parallel corpus can be replaced with monolingual corpora and a bilingual lexicon. 9 Using only Monolingual Corpora 9.1 Background We already argued that the most easily available knowledge source is monolingual text. Some ideas have been investigated in the attempt to construct lexicons using only monolingual corpora. All these approaches try to create a one-to-one or one-to-many mapping. While this is not realistic (recall Figure 1), it is a good starting point. Similarities between a word and its translation make this a feasible endeavor. Rapp (1995, 1999) bases his work on the notion that words that co-occur frequently in one language have translations that also co-occur frequently in another language. He uses this properties to fill gaps in an existing lexicon. Work by Fung (1995); Fung and Yee (1998) is based on the same principal: This allows her to add novel terms to a lexicon. Diab and Finch (2000) make another interesting observation: Words that have a certain simin one language (say translations that are similar in the other language. They measure similarity as occurring in similar context (say new X is cute). Similarity is measured by a context vector using 4-word window. But also simpler clues may provide useful information: Words that are very frequent in one language have translations that may also be frequent in a comparable corpus in another language. Also, some words have similar spelling across languages. This may be due to same roots (Encultural exchange Por- Rapp (1999) points out the need for a seed for lexicon construction from monolingual corpora. Only the algorithm by Diab and Finch (2000) does not require a seed. However, although we successfully duplicated their work when applied to two comparable English corpora, the method failed to produce a useful lexicon for our comparable German and English corpora. 9.2 Experiments Without a lexicon to start with, we could collect an initial lexicon from a small parallel corpus. But to stick to the spirit of this section, we used a different seed: words that have the exactly the same spelling in German and English. From the 9,206 German nouns in our bilingual lexicon, we could find 1,016 words that ocalso in English (such as computer, assumption that these words are in fact translations of each other is accurate for 88% of the words (exceptions are mostly shorter for example fee, kind, rat, art, rock, gang, plane, taste, hut). relying solely on this same-word seed lexicon, we can achieve 11.9% accuracy on our evaluation metric. Then we used four different methods to extend the lexicon, which exploit the fact that a word and its translation have similar: • context (Rapp, 1999) • spelling • relationship to other words (Diab and Finch, 2000) • frequency 9.3 Results For computational reasons we focus on the 1000 most frequent German and English words according to the monolingual corpora. Only the context and the spelling property helped us to extend the lexicon. When adding lexicon entries based on similar spelling, we achieved 25.4% accuracy on our evaluation metric, with the context property 31.9%. When both properties are combined, we achieve 38.6%. This is quite significant, since the baseline — mapping words at random — is no better than the original score of 11.9% for identical words. 10 Conclusions We established that a word-level translation model is a core element of machine translation systems — 95% of nouns can be translated within a conventional bilingual lexicon. These models are usually trained on parallel texts. We investigated various methods to augment and replace the need for parallel corpora with monolingual corpora and bilingual lexicons. A common evaluation metric enabled a first quantitative comparison, as summarized in Figure 5. A bilingual lexicon provides a clear benefit: While training on a parallel corpus alone we achieved 76.9% accuracy, the lexicon boosted this to 89.5%. Also, using both monolingual data and a lexicon allowed us to replace the parallel corpus and get similar performance (79.0%). Finally we showed how to acquire a</abstract>
<note confidence="0.823264222222222">Parallel corpus Giza 76.9% Monoling. corpus, lexicon most frequent 75.3% Monoling. corpus, lexicon language model 77.3% Monoling. corpus, lexicon EM 79.0% Monoling. corpus identical 11.9% Monoling. corpus spelling 25.4% Monoling. corpus context 31.9% Monoling. corpus spell.±context 38.6% Figure 5: Results for methods from Section 5-9</note>
<abstract confidence="0.958380846153846">translation model purely from monolingual corpora. The heart of the problem still seems to be finding the overall best translation for all the words, rather than advanced word sense disambiguation task of finding the right translation in a given context. This is even more true for low density languages, where less resources are available. Clearly, there is still much room for improvement many ideas that we touched upon here require further investigation. Acknowledgment</abstract>
<note confidence="0.9569474">This work was supported by DARPA-ITO grant N66001-00-1-9814. References Al-Onaizan, Y., Curin, J., Jahr, M., Knight, K., Lafferty, J., Melamed, D., Och, F.-J., Purdy, N. A., and Yarowsky, D. (1999). machine translation. Technical port, John Hopkins University Summer Workshop http : //www. clsp j hu. edu/ws99/projects/mt/. Brill, E. (1994). Some advances in rule-based part of</note>
<abstract confidence="0.727831125">tagging. In of AAAI. J., Della Pietra, S. A., Della Pietra, V. J., Jelinek, F., Lafferty, J. D., Mercer, R. L., and Rossin, P. (1990). A statistical approach to machine Linguistics, Diab, M. (2000). An unsupervised method for multilingual word sense tagging using parallel corpora: A investigation. In Workshop on Senses and Multi-Linguality, 1-9. Diab, M. and Finch, S. (2000). A statistical word-level model for comparable corpora. In Proceedings of the Conference on Content-based multimedia information access (RIAO). Fung, P. (1995). Compiling bilingual lexicon entries from non-parallel english-chinese corpus. In Workon Very Large Corpora, 173-183. Fung, P. and Yee, L. Y. (1998). An IR approach for translating new words from nonparallel, comparable In of ACL 36, 414-420. Gale, W. and Church, K. (1993). A program for aligning in bilingual corpora. Lingus- U., Jahr, M., Knight, K., Marcu, Yamada, K. (2001). Fast decoding and optimal decoding machine translation. In of ACL 39.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>J Curin</author>
<author>M Jahr</author>
<author>K Knight</author>
<author>J Lafferty</author>
<author>D Melamed</author>
<author>F-J Och</author>
<author>D Purdy</author>
<author>N A Smith</author>
<author>D Yarowsky</author>
</authors>
<date>1999</date>
<marker>Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Al-Onaizan, Y., Curin, J., Jahr, M., Knight, K., Lafferty, J., Melamed, D., Och, F.-J., Purdy, D., Smith, N. A., and Yarowsky, D. (1999).</rawString>
</citation>
<citation valid="false">
<title>Statistical machine translation.</title>
<tech>Technical report,</tech>
<institution>John Hopkins University Summer Workshop</institution>
<note>http : //www. clsp j hu. edu/ws99/projects/mt/.</note>
<marker></marker>
<rawString>Statistical machine translation. Technical report, John Hopkins University Summer Workshop http : //www. clsp j hu. edu/ws99/projects/mt/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some advances in rule-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="9885" citStr="Brill, 1994" startWordPosition="1605" endWordPosition="1606">h of monolingual corpora. We use the Wall Street Journal (WSJ) and German news wire (DPA) corpora, which are both available through the Linguistic Data Consortium (LDC)4. Both consist of over one million sentences and about twenty million words each. Also, recent research in natural language processing has equipped us with many useful tools. For instance, the performance of partof-speech taggers is currently considered on-par with humans. For our experiments, we also used Morphy as morphological analyzer and part of speech tagger for German, and Eric Brill&apos;s part of speech tagger for English (Brill, 1994). In summary, we used the following resources: • Morphy, a German POS tagger and morphological analyzer5 • Eric Brill&apos;s English POS tagger6 • the DE-NEWS German-English corpus7 • the LEO German-English dictionary • the Wall Street Journal corpus (English) • the DPA news wire corpus (German) Other knowledge sources that may be useful are natural language parsers or ontologies such as WordNet (Miller et al., 1993). 4 Experimental Setup For this paper we want to investigate the role of different knowledge sources for the training 4http://www.ldc.upenn.edu/ 5http://www-psycho.uni-paderborn.de/lezi</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, E. (1994). Some advances in rule-based part of speech tagging. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>J Cocke</author>
<author>Della Pietra</author>
<author>S A</author>
<author>Della Pietra</author>
<author>V J</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P Rossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--2</pages>
<contexts>
<context position="16391" citStr="Brown et al., 1990" startWordPosition="2670" endWordPosition="2673">currences is labeled with the majority translation. The algorithm quickly converges to a decision list that always predicts the majority case. Apparently the initial decision lists are not good enough to find strong context features for the minority translations. This is underscored by the accuracy just above the baseline. The original training set with at most a few hundred occurrences for each German word does not seem to be big enough. It might be more successful, if a larger parallel corpus is available. 7 Using only Parallel Corpus 7.1 Background The Candide machine translation approach (Brown et al., 1990) is based on the noisy channel model. It takes the view that the foreign language sentence is just distorted English that has been corrupted by a translation process. It can be decoded by using the Bayes rule: argmaxep(elg) = argmaxep(g le)P(e) 1008 908 B08 708 608 508 408 308 208 108 08 Decision List (Section 5) Giza (Section 7) 0 1 2+ 4+ B+ 16+ 32+ 64+ 12B+ 256+ 512+ 1024+ Number of examples per word ing of machine translation systems, but this is a costly option — professional translation rates are roughly between 5 and 20 US cents per word. But ultimately we have to face the fact that peop</context>
</contexts>
<marker>Brown, Cocke, Pietra, A, Pietra, J, Jelinek, Lafferty, Mercer, Rossin, 1990</marker>
<rawString>Brown, P., Cocke, J., Della Pietra, S. A., Della Pietra, V. J., Jelinek, F., Lafferty, J. D., Mercer, R. L., and Rossin, P. (1990). A statistical approach to machine translation. Computational Linguistics, 16(2):76-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
</authors>
<title>An unsupervised method for multilingual word sense tagging using parallel corpora: A preliminary investigation.</title>
<date>2000</date>
<booktitle>In SIGLEX Workshop on Word Senses and Multi-Linguality,</booktitle>
<pages>1--9</pages>
<marker>Diab, 2000</marker>
<rawString>Diab, M. (2000). An unsupervised method for multilingual word sense tagging using parallel corpora: A preliminary investigation. In SIGLEX Workshop on Word Senses and Multi-Linguality, pages 1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>S Finch</author>
</authors>
<title>A statistical word-level translation model for comparable corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Content-based multimedia information access (RIAO).</booktitle>
<contexts>
<context position="21661" citStr="Diab and Finch (2000)" startWordPosition="3548" endWordPosition="3551"> monolingual corpora. All these approaches try to create a one-to-one or one-to-many mapping. While this is not realistic (recall Figure 1), it is a good starting point. Similarities between a word and its translation make this a feasible endeavor. Rapp (1995, 1999) bases his work on the notion that words that co-occur frequently in one language have translations that also co-occur frequently in another language. He uses this properties to fill gaps in an existing lexicon. Work by Fung (1995); Fung and Yee (1998) is based on the same principal: This allows her to add novel terms to a lexicon. Diab and Finch (2000) make another interesting observation: Words that have a certain similarity in one language (say dog and cat) have translations that are similar in the other language. They measure similarity as occurring in a similar context (say her new X is cute). Similarity is measured by a context vector using 4-word window. But also simpler clues may provide useful information: Words that are very frequent in one language have translations that may also be frequent in a comparable corpus in another language. Also, some words have similar spelling across languages. This may be due to same roots (English: </context>
<context position="23720" citStr="Diab and Finch, 2000" startWordPosition="3894" endWordPosition="3897">d find 1,016 words that occur also in English (such as nation, computer, email). The assumption that these words are in fact translations of each other is accurate for 88% of the words (exceptions are mostly shorter words, for example ton, fee, kind, rat, art, rock, boot, gang, plane, taste, hut). When relying solely on this same-word seed lexicon, we can achieve 11.9% accuracy on our evaluation metric. Then we used four different methods to extend the lexicon, which exploit the fact that a word and its translation have similar: • context (Rapp, 1999) • spelling • relationship to other words (Diab and Finch, 2000) • frequency 9.3 Results For computational reasons we focus on the 1000 most frequent German and English words according to the monolingual corpora. Only the context and the spelling property helped us to extend the lexicon. When adding lexicon entries based on similar spelling, we achieved 25.4% accuracy on our evaluation metric, with the context property 31.9%. When both properties are combined, we achieve 38.6%. This is quite significant, since the baseline — mapping words at random — is no better than the original score of 11.9% for identical words. 10 Conclusions We established that a wor</context>
</contexts>
<marker>Diab, Finch, 2000</marker>
<rawString>Diab, M. and Finch, S. (2000). A statistical word-level translation model for comparable corpora. In Proceedings of the Conference on Content-based multimedia information access (RIAO).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>Compiling bilingual lexicon entries from a non-parallel english-chinese corpus.</title>
<date>1995</date>
<booktitle>In Third Workshop on Very Large Corpora,</booktitle>
<pages>173--183</pages>
<contexts>
<context position="21537" citStr="Fung (1995)" startWordPosition="3526" endWordPosition="3527">edge source is monolingual text. Some ideas have been investigated in the attempt to construct lexicons using only monolingual corpora. All these approaches try to create a one-to-one or one-to-many mapping. While this is not realistic (recall Figure 1), it is a good starting point. Similarities between a word and its translation make this a feasible endeavor. Rapp (1995, 1999) bases his work on the notion that words that co-occur frequently in one language have translations that also co-occur frequently in another language. He uses this properties to fill gaps in an existing lexicon. Work by Fung (1995); Fung and Yee (1998) is based on the same principal: This allows her to add novel terms to a lexicon. Diab and Finch (2000) make another interesting observation: Words that have a certain similarity in one language (say dog and cat) have translations that are similar in the other language. They measure similarity as occurring in a similar context (say her new X is cute). Similarity is measured by a context vector using 4-word window. But also simpler clues may provide useful information: Words that are very frequent in one language have translations that may also be frequent in a comparable c</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Fung, P. (1995). Compiling bilingual lexicon entries from a non-parallel english-chinese corpus. In Third Workshop on Very Large Corpora, pages 173-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>L Y Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL 36,</booktitle>
<pages>414--420</pages>
<contexts>
<context position="21558" citStr="Fung and Yee (1998)" startWordPosition="3528" endWordPosition="3531">s monolingual text. Some ideas have been investigated in the attempt to construct lexicons using only monolingual corpora. All these approaches try to create a one-to-one or one-to-many mapping. While this is not realistic (recall Figure 1), it is a good starting point. Similarities between a word and its translation make this a feasible endeavor. Rapp (1995, 1999) bases his work on the notion that words that co-occur frequently in one language have translations that also co-occur frequently in another language. He uses this properties to fill gaps in an existing lexicon. Work by Fung (1995); Fung and Yee (1998) is based on the same principal: This allows her to add novel terms to a lexicon. Diab and Finch (2000) make another interesting observation: Words that have a certain similarity in one language (say dog and cat) have translations that are similar in the other language. They measure similarity as occurring in a similar context (say her new X is cute). Similarity is measured by a context vector using 4-word window. But also simpler clues may provide useful information: Words that are very frequent in one language have translations that may also be frequent in a comparable corpus in another lang</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Fung, P. and Yee, L. Y. (1998). An IR approach for translating new words from nonparallel, comparable texts. In Proceedings of ACL 36, pages 414-420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1993</date>
<journal>Computational Lingustics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="9136" citStr="Gale and Church (1993)" startWordPosition="1485" endWordPosition="1488">roceedings or laws, which may not be suitable for other domains. For our experiments we decided not to use the Europarl and ECB corpora mentioned in the previous Section, but the more general DE-NEWS corpus. It contains transcript and translation of German news reports from 1996-2000. The size of the corpus is 50,000 sentences pairs (one million words per language), which could be considered mediumsized — in comparison, the Canadian Hansard has about two million sentence pairs with forty million words per language. We sentencealigned the corpus by an implementation of an algorithm proposed by Gale and Church (1993), with manual post-editing. Fortunately, the evolution of the World Wide Web and widespread use of digital publishing has created a wealth of monolingual corpora. We use the Wall Street Journal (WSJ) and German news wire (DPA) corpora, which are both available through the Linguistic Data Consortium (LDC)4. Both consist of over one million sentences and about twenty million words each. Also, recent research in natural language processing has equipped us with many useful tools. For instance, the performance of partof-speech taggers is currently considered on-par with humans. For our experiments,</context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>Gale, W. and Church, K. (1993). A program for aligning sentences in bilingual corpora. Computational Lingustics, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Germann</author>
<author>M Jahr</author>
<author>K Knight</author>
<author>D Marcu</author>
<author>K Yamada</author>
</authors>
<title>Fast decoding and optimal decoding for machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL 39.</booktitle>
<marker>Germann, Jahr, Knight, Marcu, Yamada, 2001</marker>
<rawString>Germann, U., Jahr, M., Knight, K., Marcu, D., and Yamada, K. (2001). Fast decoding and optimal decoding for machine translation. In Proceedings of ACL 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J Veronis</author>
</authors>
<title>Introduction to the special issue on word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="13679" citStr="Ide and Veronis (1998)" startWordPosition="2223" endWordPosition="2226">s us to split up compounds such as Bundesverteidigungshaushalt (federal defense budget). 5 Using Parallel Corpus and Lexicon 5.1 Background The best results can be achieved provided both a parallel corpus and a bilingual dictionary. As with our evaluation corpus, we can use the bilingual lexicon to extract word-level noun translation pairs from the parallel corpus. Having word-level translations in context, we can use supervised word sense disambiguation methods, which have been extensively studied. For instance, Mooney (1996) provides a good comparison these methods. See also the overview by Ide and Veronis (1998). 5.2 Experiment In the method used here, we extracted the following context features for each noun occurrence: • Up to three words of local context around the target word, using part-of-speech tags as back-off. • Any open-class word (noun, verb, adjective, adverb) in the same sentence • Any open-class word in the same document These features allow us to train a decision list as described by Yarowsky (1994). 5.3 Results The resulting classifier finds the correct wordlevel translation in our test data with 89.5% accuracy. The baseline method for this data, which is to choose always the most fre</context>
</contexts>
<marker>Ide, Veronis, 1998</marker>
<rawString>Ide, N. and Veronis, J. (1998). Introduction to the special issue on word sense disambiguation: The state of the art. Computational Linguistics, 24(1):1-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Estimating word translation probabilities from unrelated monolingual corpora using the EM algorithm.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="18961" citStr="Koehn and Knight (2000)" startWordPosition="3104" endWordPosition="3107"> If we have a corpus in the target language, we can apply two simple ideas: Firstly, we could always choose the word in the lexicon that occurs most frequently in the target language corpus. This simple principle shows surprisingly good results. Secondly, we can build a language model and choose the most likely sequence of words in the target language. This allows the use of context clues. Research in generation, such as the Nitrogen generation system (Langkilde and Knight, 1998) demonstrate the effectiveness of this method. A more sophisticated approach is proposed 9http://www.google.com/ by Koehn and Knight (2000). It uses a lexicon, a corpus in the target language, and a comparable corpus in the source language. The approach views the corpus in the source language (German) as actually being an English corpus, corrupted by a noisy channel. Given word-level translation probabilities and a language model we can determine for each German word the most likely English word in its place. Also, given such a corpus of GermanEnglish word pairs, we can easily estimate wordlevel translation probabilities. This set-up constitutes a chicken and egg problem: On the one hand we do not have word-level translation prob</context>
</contexts>
<marker>Koehn, Knight, 2000</marker>
<rawString>Koehn, P. and Knight, K. (2000). Estimating word translation probabilities from unrelated monolingual corpora using the EM algorithm. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
<author>K Knight</author>
</authors>
<title>Generaton that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL 36,</booktitle>
<pages>704--710</pages>
<contexts>
<context position="18822" citStr="Langkilde and Knight, 1998" startWordPosition="3086" endWordPosition="3089">o learn translation models from monolingual data which require a bilingual lexicon. The next section will drop this requirement. 8.2 Experiment If we have a corpus in the target language, we can apply two simple ideas: Firstly, we could always choose the word in the lexicon that occurs most frequently in the target language corpus. This simple principle shows surprisingly good results. Secondly, we can build a language model and choose the most likely sequence of words in the target language. This allows the use of context clues. Research in generation, such as the Nitrogen generation system (Langkilde and Knight, 1998) demonstrate the effectiveness of this method. A more sophisticated approach is proposed 9http://www.google.com/ by Koehn and Knight (2000). It uses a lexicon, a corpus in the target language, and a comparable corpus in the source language. The approach views the corpus in the source language (German) as actually being an English corpus, corrupted by a noisy channel. Given word-level translation probabilities and a language model we can determine for each German word the most likely English word in its place. Also, given such a corpus of GermanEnglish word pairs, we can easily estimate wordlev</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Langkilde, I. and Knight, K. (1998). Generaton that exploits corpus-based statistical knowledge. In Proceedings of ACL 36, pages 704-710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Models of translational equivalence among words.</title>
<date>2000</date>
<journal>Computational Lingustics,</journal>
<pages>26--2</pages>
<marker>Melamed, 2000</marker>
<rawString>Melamed, I. D. (2000). Models of translational equivalence among words. Computational Lingustics, 26(2):221-249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K J Miller</author>
</authors>
<title>Introduction to WordNet: An online lexical database.</title>
<date>1993</date>
<tech>Technical Report CSL 43,</tech>
<institution>Cognitive Science Laboratory Princeton University.</institution>
<contexts>
<context position="10300" citStr="Miller et al., 1993" startWordPosition="1670" endWordPosition="1673">ntly considered on-par with humans. For our experiments, we also used Morphy as morphological analyzer and part of speech tagger for German, and Eric Brill&apos;s part of speech tagger for English (Brill, 1994). In summary, we used the following resources: • Morphy, a German POS tagger and morphological analyzer5 • Eric Brill&apos;s English POS tagger6 • the DE-NEWS German-English corpus7 • the LEO German-English dictionary • the Wall Street Journal corpus (English) • the DPA news wire corpus (German) Other knowledge sources that may be useful are natural language parsers or ontologies such as WordNet (Miller et al., 1993). 4 Experimental Setup For this paper we want to investigate the role of different knowledge sources for the training 4http://www.ldc.upenn.edu/ 5http://www-psycho.uni-paderborn.de/lezius/ ehttp://www.cs.jhu.edu/ brill/ 7http://www.isi.edu/ koehn/publications/de-news/ of word-level translation models. We evaluate the methods by the accuracy of the suggested word-level translations with respect to a reference parallel corpus. When translating the limited number of closed class words such as articles, syntactical issues and language ideosyncracies play a big role. The emphasis of the lexical com</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1993</marker>
<rawString>Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D., and Miller, K. J. (1993). Introduction to WordNet: An online lexical database. Technical Report CSL 43, Cognitive Science Laboratory Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mooney</author>
</authors>
<title>Comparative experiments on disambiguation word senses: An illustration of bias in machine learning.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP.</booktitle>
<contexts>
<context position="13589" citStr="Mooney (1996)" startWordPosition="2210" endWordPosition="2211"> the found surface forms to word stems. In addition, the German Morphy also allows us to split up compounds such as Bundesverteidigungshaushalt (federal defense budget). 5 Using Parallel Corpus and Lexicon 5.1 Background The best results can be achieved provided both a parallel corpus and a bilingual dictionary. As with our evaluation corpus, we can use the bilingual lexicon to extract word-level noun translation pairs from the parallel corpus. Having word-level translations in context, we can use supervised word sense disambiguation methods, which have been extensively studied. For instance, Mooney (1996) provides a good comparison these methods. See also the overview by Ide and Veronis (1998). 5.2 Experiment In the method used here, we extracted the following context features for each noun occurrence: • Up to three words of local context around the target word, using part-of-speech tags as back-off. • Any open-class word (noun, verb, adjective, adverb) in the same sentence • Any open-class word in the same document These features allow us to train a decision list as described by Yarowsky (1994). 5.3 Results The resulting classifier finds the correct wordlevel translation in our test data with</context>
</contexts>
<marker>Mooney, 1996</marker>
<rawString>Mooney, R. (1996). Comparative experiments on disambiguation word senses: An illustration of bias in machine learning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Identifying word translations in nonparallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of ACL 33,</booktitle>
<pages>320--322</pages>
<contexts>
<context position="21299" citStr="Rapp (1995" startWordPosition="3486" endWordPosition="3487">el corpus (76.9%). Thus, for our set of resources, a parallel corpus can be replaced with monolingual corpora and a bilingual lexicon. 9 Using only Monolingual Corpora 9.1 Background We already argued that the most easily available knowledge source is monolingual text. Some ideas have been investigated in the attempt to construct lexicons using only monolingual corpora. All these approaches try to create a one-to-one or one-to-many mapping. While this is not realistic (recall Figure 1), it is a good starting point. Similarities between a word and its translation make this a feasible endeavor. Rapp (1995, 1999) bases his work on the notion that words that co-occur frequently in one language have translations that also co-occur frequently in another language. He uses this properties to fill gaps in an existing lexicon. Work by Fung (1995); Fung and Yee (1998) is based on the same principal: This allows her to add novel terms to a lexicon. Diab and Finch (2000) make another interesting observation: Words that have a certain similarity in one language (say dog and cat) have translations that are similar in the other language. They measure similarity as occurring in a similar context (say her new</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Rapp, R. (1995). Identifying word translations in nonparallel texts. In Proceedings of ACL 33, pages 320-322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL 37,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="22435" citStr="Rapp (1999)" startWordPosition="3676" endWordPosition="3677">age. They measure similarity as occurring in a similar context (say her new X is cute). Similarity is measured by a context vector using 4-word window. But also simpler clues may provide useful information: Words that are very frequent in one language have translations that may also be frequent in a comparable corpus in another language. Also, some words have similar spelling across languages. This may be due to same roots (English: mother, German: Mutter, Portuguese: mcie, Spanish: madre), or cultural exchange (English: computer, German: Computer, Portuguese: computador, Japanese: konpyuta). Rapp (1999) points out the need for a seed for lexicon construction from monolingual corpora. Only the algorithm by Diab and Finch (2000) does not require a seed. However, although we successfully duplicated their work when applied to two comparable English corpora, the method failed to produce a useful lexicon for our comparable German and English corpora. 9.2 Experiments Without a lexicon to start with, we could collect an initial lexicon from a small parallel corpus. But to stick to the spirit of this section, we used a different seed: words that have the exactly the same spelling in German and Englis</context>
<context position="23656" citStr="Rapp, 1999" startWordPosition="3885" endWordPosition="3886">e 9,206 German nouns in our bilingual lexicon, we could find 1,016 words that occur also in English (such as nation, computer, email). The assumption that these words are in fact translations of each other is accurate for 88% of the words (exceptions are mostly shorter words, for example ton, fee, kind, rat, art, rock, boot, gang, plane, taste, hut). When relying solely on this same-word seed lexicon, we can achieve 11.9% accuracy on our evaluation metric. Then we used four different methods to extend the lexicon, which exploit the fact that a word and its translation have similar: • context (Rapp, 1999) • spelling • relationship to other words (Diab and Finch, 2000) • frequency 9.3 Results For computational reasons we focus on the 1000 most frequent German and English words according to the monolingual corpora. Only the context and the spelling property helped us to extend the lexicon. When adding lexicon entries based on similar spelling, we achieved 25.4% accuracy on our evaluation metric, with the context property 31.9%. When both properties are combined, we achieve 38.6%. This is quite significant, since the baseline — mapping words at random — is no better than the original score of 11.</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Rapp, R. (1999). Automatic identification of word translations from unrelated english and german corpora. In Proceedings of ACL 37, pages 519-526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Mining the web for bilingual text.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL 37,</booktitle>
<pages>527--534</pages>
<marker>Resnik, 1999</marker>
<rawString>Resnik, P. (1999). Mining the web for bilingual text. In Proceedings of ACL 37, pages 527-534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL 39.</booktitle>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada, K. and Knight, K. (2001). A syntax-based statistical translation model. In Proceedings of ACL 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French.</title>
<date>1994</date>
<booktitle>In Proceedings of ACL 32.</booktitle>
<contexts>
<context position="14089" citStr="Yarowsky (1994)" startWordPosition="2296" endWordPosition="2297"> use supervised word sense disambiguation methods, which have been extensively studied. For instance, Mooney (1996) provides a good comparison these methods. See also the overview by Ide and Veronis (1998). 5.2 Experiment In the method used here, we extracted the following context features for each noun occurrence: • Up to three words of local context around the target word, using part-of-speech tags as back-off. • Any open-class word (noun, verb, adjective, adverb) in the same sentence • Any open-class word in the same document These features allow us to train a decision list as described by Yarowsky (1994). 5.3 Results The resulting classifier finds the correct wordlevel translation in our test data with 89.5% accuracy. The baseline method for this data, which is to choose always the most frequent word-level translation, as found in the training data, however, performs only slightly worse (88.9%). Let us already point out at this point the significance of these results: Without any word sense disambiguation we could achieve almost 90% accuracy. None of the following experiments will reach this performance. So, at least in the framework of these experiments, the main problem is still finding the</context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>Yarowsky, D. (1994). Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French. In Proceedings of ACL 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of ACL 33,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="14885" citStr="Yarowsky (1995)" startWordPosition="2426" endWordPosition="2427"> most frequent word-level translation, as found in the training data, however, performs only slightly worse (88.9%). Let us already point out at this point the significance of these results: Without any word sense disambiguation we could achieve almost 90% accuracy. None of the following experiments will reach this performance. So, at least in the framework of these experiments, the main problem is still finding the overall best translation for a word, not the advanced task of finding the right translation in a given context. 6 Using Parallel and Monolingual Corpora and Lexicon 6.1 Background Yarowsky (1995) proposes a bootstrapping scheme that uses a initial decision list trained on supervised data as a starting point. By labeling new word occurrences in a monolingual corpus, he was able to collect more evidence that enable the construction of a superior decision list. 6.2 Experiment We can easily apply this idea to our problem: We already trained a decision list for word-level translations. Using this decision list on a German monolingual corpus and additional clues such as &amp;quot;one sense per discourse&amp;quot;, we can label more occurrences of the German words with English translations. This, in turn, pro</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, D. (1995). Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of ACL 33, pages 189-196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>