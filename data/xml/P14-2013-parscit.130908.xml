<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004385">
<title confidence="0.997337">
Graph Ranking for Collective Named Entity Disambiguation
</title>
<author confidence="0.994778">
Ayman Alhelbawy&apos;,2 and Robert Gaizauskas&apos;
</author>
<affiliation confidence="0.9964205">
&apos;The University of Sheffield, Regent Court, 211 Portobello Street, Sheffield, S1 4DP, U.K
2Faculty of Computers and Information, Fayoum University, Fayoum, Egypt
</affiliation>
<email confidence="0.991072">
ayman,R.Gaizauskas@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.993593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9988638">
Named Entity Disambiguation (NED)
refers to the task of mapping different
named entity mentions in running text to
their correct interpretations in a specific
knowledge base (KB). This paper presents
a collective disambiguation approach us-
ing a graph model. All possible NE candi-
dates are represented as nodes in the graph
and associations between different candi-
dates are represented by edges between the
nodes. Each node has an initial confidence
score, e.g. entity popularity. Page-Rank
is used to rank nodes and the final rank
is combined with the initial confidence
for candidate selection. Experiments on
27,819 NE textual mentions show the ef-
fectiveness of using Page-Rank in con-
junction with initial confidence: 87% ac-
curacy is achieved, outperforming both
baseline and state-of-the-art approaches.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999895388888889">
Named entities (NEs) have received much atten-
tion over the last two decades (Nadeau and Sekine,
2007), mostly focused on recognizing the bound-
aries of textual NE mentions and classifying them
as, e.g., Person, Organization or Location. How-
ever, references to entities in the real world are of-
ten ambiguous: there is a many-to-many relation
between NE mentions and the entities they denote
in the real world. For example, Norfolk may refer
to a person, “Peter Norfolk, a wheelchair tennis
player”, a place in the UK, “Norfolk County”, or
in the US, “Norfolk, Massachusetts”; conversely,
one entity may be known by many names, such as
“Cat Stevens”, “Yusuf Islam” and “Steven Geor-
giou”. The NED task is to establish a correct map-
ping between each NE mention in a document and
the real world entity it denotes. Following most re-
searchers in this area, we treat entries in a large
</bodyText>
<figureCaption confidence="0.999715">
Figure 1: Example of solution graph
</figureCaption>
<bodyText confidence="0.999737935483871">
knowledge base (KB) as surrogates for real world
entities when carrying out NED and, in particu-
lar, use Wikipedia as the reference KB for dis-
ambiguating NE mentions. NED is important for
tasks like KB population, where we want to ex-
tract new information from text about an entity and
add this to a pre-existing entry in a KB; or for in-
formation retrieval, where we may want to cluster
or filter results for different entities with the same
textual mentions.
The main hypothesis in this work is that differ-
ent NEs in a document help to disambiguate each
other. The problem is that other textual mentions
in the document are also ambiguous. So, what is
needed is a collective disambiguation approach
that jointly disambiguates all NE textual mentions.
In our approach we model each possible can-
didate for every NE mention in a document as a
distinct node in a graph and model candidate co-
herence by links between the nodes. We call such
graphs solution graphs. Figure 1 shows an exam-
ple of the solution graph for three mentions “A”,
“B”, and “C” found in a document, where the can-
didate entities for each mention are referred to us-
ing the lower case form of the mention’s letter to-
gether with a distinguishing subscript. The goal of
disambiguation is to find a set of nodes where only
one candidate is selected from the set of entities
associated with each mention, e.g. a3, b2, c2.
Our approach first ranks all nodes in the solu-
tion graph using the Page-Rank algorithm, then re-
</bodyText>
<page confidence="0.985676">
75
</page>
<bodyText confidence="0.941148136363636">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 75–80,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
ranks all nodes by combining the initial confidence
and graph ranking scores. We consider several dif-
ferent measures for computing the initial confi-
dence assigned to each node and several measures
for determining and weighting the graph edges.
Node linking relies on the fact that the textual por-
tion of KB entries typically contains mentions of
other NEs. When these mentions are hyper-linked
to KB entries, we can infer that there is some rela-
tion between the real world entities corresponding
to the KB entries, i.e. that they should be linked
in our solution graph. These links also allow us to
build up statistical co-occurrence counts between
entities that occur in the same context which may
be used to weight links in our graph.
We evaluate our approach on the AIDA dataset
(Hoffart et al., 2011). Comparison with the
baseline approach and some state-of-the-art ap-
proaches shows our approach offers substantial
improvements in disambiguation accuracy.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998815">
In 2009, NIST proposed the shared task challenge
of Entity Linking (EL) (McNamee and Dang,
2009). EL is a similar but broader task than NED
because NED is concerned with disambiguating
a textual NE mention where the correct entity is
known to be one of the KB entries, while EL also
requires systems to deal with the case where there
is no entry for the NE in the reference KB. Ji et
al. (2011) group and summarise the different ap-
proaches to EL taken by participating systems.
In general, there are two main lines of approach
to the NED problem. Single entity disambigua-
tion approaches (SNED), disambiguate one entity
at a time without considering the effect of other
NEs. These approaches use local context textual
features of the mention and compare them to the
textual features of NE candidate documents in the
KB, and link to the most similar. The first ap-
proach in this line was Bunescu and Pasca (2006),
who measure similarity between the textual con-
text of the NE mention and the Wikipedia cate-
gories of the candidate. More similarity features
were added by Cucerzan (2007) who realized that
topical coherence between a candidate entity and
other entities in the context will improve NED ac-
curacy and by Milne and Witten (2008) who built
on Cucerzan’s work. Han and Sun (2011) combine
different forms of disambiguation knowledge us-
ing evidence from mention-entity associations and
entity popularity in the KB, and context similarity.
The second line of approach is collective named
entity disambiguation (CNED), where all men-
tions of entities in the document are disambiguated
jointly. These approaches try to model the interde-
pendence between the different candidate entities
for different NE mentions in the query document,
and reformulate the problem of NED as a global
optimization problem whose aim is to find the best
set of entities. As this new formulation is NP-
hard, many approximations have been proposed.
Alhelbawy and Gaizauskas (2013) proposed a se-
quence dependency model using HMMs to model
NE interdependency. Another approximation uses
a mixture of local and global features to train the
coefficients of a linear ranking SVM to rank dif-
ferent NE candidates (Ratinov et al., 2011). Shi-
rakawa et al. (2011) cluster related textual men-
tions and assign a concept to each cluster using
a probabilistic taxonomy. The concept associated
with a mention is used in selecting the correct en-
tity from the Freebase KB.
Graph models are widely used in collective ap-
proaches1. All these approaches model NE in-
terdependencies, while different methods may be
used for disambiguation. Han (2011) uses local
dependency between NE mention and the can-
didate entity, and semantic relatedness between
candidate entities to construct a referent graph,
proposing a collective inference algorithm to in-
fer the correct reference node in the graph. Hoffert
(2011) poses the problem as one of finding a dense
sub-graph, which is infeasible in a huge graph. So,
an algorithm originally used to find strongly inter-
connected, size-limited groups in social media is
adopted to prune the graph, and then a greedy al-
gorithm is used to find the densest graph.
Our proposed model uses the Page-Rank (PR)
algorithm (Page et al., 1999), which to our knowl-
edge has not previously been applied to NED.
Xing and Ghorbani (2004) adopted PR to consider
the weights of links and the nodes’ importance. PR
and Personalized PR algorithms have been used
successfully in WSD (Sinha and Mihalcea, 2007;
Agirre and Soroa, 2009).
</bodyText>
<sectionHeader confidence="0.947996" genericHeader="method">
3 Solution Graph
</sectionHeader>
<bodyText confidence="0.983506">
In this section we discuss the construction of
a graph representation that we call the solution
</bodyText>
<footnote confidence="0.852181666666667">
1Graph models are also widely used in Word Sense Dis-
ambiguation (WSD), which has lots of similarities to NED
(Guti´errez et al., 2011; Guti´errez et al., 2012).
</footnote>
<page confidence="0.975578">
76
</page>
<bodyText confidence="0.999965318181818">
graph. The input is a document containing pre-
tagged NE textual mentions. The solution graph
is an undirected graph G = (V, D) where V is the
node set of all possible NE candidates for differ-
ent textual mentions in the input document and D
is the set of edges between nodes. Edges are not
drawn between different nodes for the same men-
tion. They are drawn between two entities when
there is a relation between them, as described be-
low. Each candidate has associated with it an ini-
tial confidence score, also detailed below.
Assume the input document D has a set of
mentions M = {m1, m2, m3, ..., mk}. For each
mi E M, we rank each candidate entity, where
the list of candidates for a mention mi is Ei =
{ei,1, ei,2, ..., ei,j}. The graph nodes are formu-
lated as a set V = {(mi, ei,j)  |bei,j E Ei, bmi E
M}. Nodes are represented as ordered pairs of
textual mentions and candidate entities, since the
same entity may be found multiple times as a can-
didate for different textual mentions and each oc-
currence must be evaluated independently.
</bodyText>
<subsectionHeader confidence="0.994785">
3.1 NE Candidate Generation
</subsectionHeader>
<bodyText confidence="0.9999822">
The first step in constructing a solution graph is to
find all possible candidates for each NE mention
in the query document. For each such mention the
KB entry titles are searched to find all entries to
which the mention could refer. This includes en-
tries with titles that fully or partially contain the
query mention and those that could be an acronym
of the query mention. These candidate entries are
paired with their textual mentions in the document
to become nodes in the solution graph.
</bodyText>
<subsectionHeader confidence="0.995897">
3.2 Initial Confidence
</subsectionHeader>
<bodyText confidence="0.999710767857143">
Initial confidence IConf(ei,j) is an independent
feature of the NE candidate regardless of other
candidates in the document. This confidence may
be calculated locally using the local mention con-
text, or globally using, e.g., the Freebase popular-
ity score for the KB entry (Bollacker et al., 2008).
Local NE Candidate Confidence: The local
confidence is computed by a similarity measure
between the NE mention in the query document
and the KB entry of the candidate entity. We pro-
pose four different measures to be used in the dis-
ambiguation phase.
cos: The cosine similarity between the named en-
tity textual mention and the KB entry title.
jwSim: While the cosine similarity between a tex-
tual mention in the document and the candidate
NE title in the KB is widely used in NED, this
similarity is a misleading feature. For example,
the textual mention “Essex” may refer to either
of the following candidates “Essex County Cricket
Club” or “Danbury, Essex”, both of which are re-
turned by the candidate generation process. The
cosine similarity between “Essex” and “Danbury,
Essex” is higher than that between “Essex” and
“Essex County Cricket Club”, which is not helpful
in the NED setting. We adopted a new mention-
candidate similarity function, jw5im, which uses
Jaro-Winkler similarity as a first estimate of the
initial confidence value for each candidate. This
function considers all terms found in the candidate
entity KB entry title, but not in the textual mention
as disambiguation terms. The percentage of dis-
ambiguation terms found in the query document is
used to boost in the initial jw5im value, in addi-
tion to an acronym check (whether the NE textual
mention could be an acronym for a specific can-
didate entity title). Experiments show that jw5im
performs much better than cos.
ctxt: The cosine similarity between the sentence
containing the NE mention in the query document
and the textual description of the candidate NE in
the KB (we use the first section of the Wikipedia
article as the candidate entity description).
Global NE Candidate Confidence: Global
confidence is a measure of the global importance
of the candidate entity. Entity popularity has been
used successfully as a discriminative feature for
NED (Nebhi, 2013). Freebase provides an API
to get an entity’s popularity score (FB), which is
computed during Freebase indexing. This score is
a function of the entity’s inbound and outbound
link counts in Freebase and Wikipedia2. The initial
confidence is not normalized across all NEs be-
cause each score is calculated independently. Ini-
tial confidence scores of all candidates for a single
NE mention are normalized to sum to 1.
</bodyText>
<subsectionHeader confidence="0.994119">
3.3 Entity Coherence
</subsectionHeader>
<bodyText confidence="0.999959875">
Entity coherence refers to the real world related-
ness of different entities which are candidate inter-
pretations of different textual mentions in the doc-
ument. It is not based on context, so it is always
the same regardless of the query document. Co-
herence is represented as an edge between nodes
in the solution graph. We used two measures for
coherence, described as follows:
</bodyText>
<footnote confidence="0.968859">
2https://developers.google.com/freebase/v1/search
</footnote>
<page confidence="0.998015">
77
</page>
<bodyText confidence="0.9423272">
Ref: Uses the Wikipedia documents for both en-
tity candidates to check if either document has a
link to the other. This relation is directed, but we
assume an inverse relation also exists; so this rela-
tion is represented as undirected.
</bodyText>
<equation confidence="0.96873425">
�
1, if ei or ej refers to the other
Ref(ei, ej) = (1)
0, otherwise
</equation>
<bodyText confidence="0.99967">
JProb: An estimate of the probability of both
entities appearing in the same sentence. Wikipedia
documents are used to estimate this probability, as
shown in (2), where S(e) is the set of all sentences
that contain the entity e and S the set of sentences
containing any entity references.
</bodyText>
<equation confidence="0.9942405">
JProb(ei, ej) = |S(ei) � S(ej) |(2)
|S|
</equation>
<sectionHeader confidence="0.99544" genericHeader="method">
4 Disambiguation
</sectionHeader>
<bodyText confidence="0.998539088235294">
The solution graph contains all possible candi-
dates for each NE mention in the document. Each
candidate has an initial confidence, with some
connected by association relations. The disam-
biguation phase ranks all nodes in the solution
graph and selects the best from the candidate list
for each NE textual mention. The process of dis-
ambiguation consists of three steps. The first step
is initial graph ranking, where all nodes are ranked
according to the link structure. The second step is
to re-rank the nodes by combining the graph rank
with the initial confidence. The highest rank is not
always correct, so in the third step a selection al-
gorithm is used to choose the best candidate.
Graph Ranking: The links between different
candidates in the solution graph represent real
world relations. These relations may be used to re-
liably boost relevant candidates. All nodes in the
graph are ranked according to these relations using
PR. Initial confidence is used as an initial rank for
the graph nodes, while entities’ coherence mea-
sures are used as link weights which play a role in
distributing a node’s rank over its outgoing nodes.
Candidate Re-ranking: A problem with Page-
Rank for our purposes is the dissipation of initial
node weight (confidence) over all outgoing nodes.
The final rank of a node is based solely on the im-
portance of incoming nodes and the initial confi-
dence play no further role. In our case this is not
appropriate, so the final rank for each mention is
determined after graph ranking, by combining the
graph rank with the initial confidence.
Let us refer to the graph rank of a candidate as
PR(ei). Two combination schemes are used:
</bodyText>
<equation confidence="0.999998">
R3(ei,j) = IConf(ei,j) + PR(ei,j) (3)
Rm(ei,j) = IConf(ei,j) x PR(ei,j) (4)
</equation>
<bodyText confidence="0.999571857142857">
Named Entity Selection: The simplest ap-
proach is to select the highest ranked entity in the
list for each mention mi according to equation
5, where R could refer to Rm or Rs. However,
we found that a dynamic choice between the re-
ranking schemes, based on the difference between
the top two candidates, as described in algorithm
1 and indicated by eg,works best. The underlying
intuition of this algorithm is that a greater differ-
ence between the top ranks reflects more confident
discrimination between candidates. So, the two
combination schemes assign different ranks to the
candidates and the algorithm selects the scheme
which appears more discriminative.
</bodyText>
<equation confidence="0.9882745">
ˆei = argmax R(ei,j) (5)
ei,j
Data: Two lists, R1 and R2, of candidates Ei, where R1
is ranked using R3, and R2 is ranked using Rm
Result: One NE egi
Sort R1 and R2 in descending order;
R1diff = R1[0]-R1[1];
R2diff = R2[0]-R2[1];
</equation>
<figure confidence="0.315495">
if R1diff &gt; R2diff then
return highest rank scored entity of R1
else
return highest rank scored entity of R2
end
</figure>
<figureCaption confidence="0.515435">
Algorithm 1: Selection Algorithm
</figureCaption>
<sectionHeader confidence="0.992044" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999988266666667">
We used AIDA dataset3, which is based on the
CoNLL 2003 data for NER tagging. All mentions
are manually disambiguated against Wikipedia
(Hoffart et al., 2011). This dataset contains 1393
documents and 34,965 annotated mentions. We
only consider NE mentions with an entry in the
Wikipedia KB, ignoring the 20% of query men-
tions (7136) without a link to the KB, as Hoffart
did. Micro-averaged and macro-averaged accu-
racy are used for evaluation. In this context micro-
averaged accuracy corresponds to the propor-
tion of textual mentions correctly disambiguated
while macro-averaged accuracy corresponds to the
proportion of textual mentions correctly disam-
biguated per entity, averaged over all entities.
</bodyText>
<subsectionHeader confidence="0.594119">
5.1 Results
</subsectionHeader>
<bodyText confidence="0.999641">
Initially, we evaluated the performance of two
baselines. One is a setup where a ranking based
solely on different initial confidence scores is used
</bodyText>
<footnote confidence="0.963957">
3http://www.mpi-inf.mpg.de/yago-naga/aida/
</footnote>
<page confidence="0.993116">
78
</page>
<table confidence="0.996901333333333">
IConf PRC PRI PRIC Cucerzan Kulkarni Hoffart Shirakawa Alhelbawy
Amacro 78.09 80.98 84.19 82.80 43.74 76.74 81.91 83.02 74.18
Amicro 80.55 83.59 87.59 86.10 51.03 72.87 81.82 82.29 78.49
</table>
<tableCaption confidence="0.996851">
Table 1: Results comparison between Proposed Approach and State-of-the-art
</tableCaption>
<table confidence="0.999832333333333">
PR eg
IConf Amicro Amacro Amicro Amacro
cos 70.6 60.83 78.41 72.35
jwSim 70.61 60.94 83.16 78.28
ctxt 70.61 60.83 75.45 65.22
freebase 71.78 81.07 87.59 84.19
</table>
<tableCaption confidence="0.986507">
Table 2: Results using initial confidence (PRI)
</tableCaption>
<table confidence="0.9998076">
PR eg
Edge Weight Amicro Amacro Amicro Amacro
Jprob 66.52 55.83 83.31 80.38
Ref 67.48 59.76 81.80 78.53
prob + refs 72.69 65.71 83.46 80.69
</table>
<tableCaption confidence="0.999933">
Table 3: Results using weighted edges (PRC)
</tableCaption>
<bodyText confidence="0.9989479375">
for candidate selection, i.e. without using PR. In
this setup a ranking based on Freebase popularity
does best, with micro- and macro-averaged accu-
racy scores of 80.55% and 78.09% respectively.
This is a high baseline, close to the state-of-the-
art. Our second baseline is the basic PR algorithm,
where weights of nodes and edges are uniform (i.e.
initial node and edge weights set to 1, edges be-
ing created wherever REF or JProb are not zero).
Micro and macro accuracy scores of 70.60% and
60.91% were obtained with this baseline.
To study graph ranking using PR, and the con-
tributions of the initial confidence and entity co-
herence, experiments were carried out using PR in
different modes and with different selection tech-
niques. In the first experiment, referred to as PRI,
initial confidence is used as an initial node rank for
PR and edge weights are uniform, edges, as in the
PR baseline, being created wherever REF or JProb
are not zero. Table 2 shows the results both before
re-ranking, i.e. using only the PR score for rank-
ing, and after re-ranking using the dynamic selec-
tion scheme eg. When comparing these results to
the PR baseline we notice a slight positive effect
when using the initial confidence as an initial rank
instead of uniform ranking. The major improve-
ment comes from re-ranking nodes by combining
initial confidence with PR score.
In our second experiment, PRC, entity coher-
ence features are tested by setting the edge weights
to the coherence score and using uniform ini-
tial node weights. We compared JProb and Ref
</bodyText>
<table confidence="0.9905014">
eg(jwSim) eg(freebase)
Edge Weight Amicro Amacro Amicro Amacro
Jprob 82.56 76.16 86.29 82.77
Ref 78.61 71.12 83.16 80.01
Jprob + Ref 81.97 75.63 86.10 82.80
</table>
<tableCaption confidence="0.999867">
Table 4: Results using IConf and weighted edges PRIC
</tableCaption>
<bodyText confidence="0.999991710526316">
edge weighting approaches, where for each ap-
proach edges were created only where the coher-
ence score according to the approach was non-
zero. We also investigated a variant, called JProb +
Ref, in which the Ref edge weights are normalized
to sum to 1 over the whole graph and then added
to the JProb edge weights (here edges result wher-
ever JProb or Ref scores are non-zero). Results in
Table 3 show the JProb feature seems to be more
discriminative than the Ref feature but the com-
bined Jprob + Ref feature performs better than
each separately, just outperforming the baseline.
We used the best initial confidence score (Free-
base) for re-ranking. Again, combining the initial
confidence with the PR score improves the results.
Finally, Table 4 shows the accuracy when using
different combinations of initial confidence and
entity coherence scores just in the case when re-
ranking is applied. Here the jprob + refs com-
bination does not add any value over jprob alone.
Interestingly using initial confidence with differ-
entially weighted edges does not show any ben-
efit over using initial confidence and uniformly
weighted edges (Table 2).
To compare our results with the state-of-the-art,
we report Hoffart et al.’s (2011) results as they re-
implemented two other systems and also ran them
over the AIDA dataset. We also compare with Al-
helbawy and Gaizauskas (2013) and Shirakawa et
al. (2011) who carried out their experiments using
the same dataset. Table 1 presents a comparison
between our approach and the state-of-the-art and
shows our approach exceeds the state-of-the-art.
Futhermore our approach is very simple and direct
to apply, unlike Hoffart et al.’s and Shirakawa et
al.’s which are considerably more complex. Also,
our approach does not need any kind of training,
as does the Alhelbawy approach.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999836777777778">
Our results show that Page-Rank in conjunction
with re-ranking by initial confidence score can be
used as an effective approach to collectively dis-
ambiguate named entity textual mentions in a doc-
ument. Our proposed features are very simple and
easy to extract, and work well when employed in
PR. In future work we plan to explore enriching
the edges between nodes by incorporating seman-
tic relations extracted from an ontology.
</bodyText>
<page confidence="0.99798">
79
</page>
<sectionHeader confidence="0.978811" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99752220952381">
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing pagerank for word sense disambiguation. In
Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, pages 33–41. Association for Computa-
tional Linguistics.
Ayman Alhelbawy and Robert Gaizauskas. 2013.
Named entity disambiguation using hmms. In
Web Intelligence (WI) and Intelligent Agent Tech-
nologies (IAT), 2013 IEEE/WIC/ACM International
Joint Conferences on, volume 3, pages 159–162.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: A col-
laboratively created graph database for structuring
human knowledge. In Proceedings of the 2008
ACM SIGMOD International Conference on Man-
agement of Data, SIGMOD ’08, pages 1247–1250,
New York, NY, USA. ACM.
Razvan C. Bunescu and Marius Pasca. 2006. Us-
ing encyclopedic knowledge for named entity dis-
ambiguation. In EACL. The Association for Com-
puter Linguistics.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on wikipedia data. In Proceed-
ings of EMNLP-CoNLL, volume 6, pages 708–716.
Yoan Guti´errez, Sonia V´azquez, and Andr´es Montoyo.
2011. Word sense disambiguation: a graph-based
approach using n-cliques partitioning technique. In
Natural Language Processing and Information Sys-
tems, pages 112–124. Springer.
Yoan Guti´errez, Sonia V´azquez, and Andr´es Montoyo.
2012. A graph-based approach to wsd using rele-
vant semantic trees and n-cliques model. In Compu-
tational Linguistics and Intelligent Text Processing,
pages 225–237. Springer.
Xianpei Han and Le Sun. 2011. A generative entity-
mention model for linking entities with knowledge
base. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies-Volume 1, pages 945–
954. Association for Computational Linguistics.
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, pages 765–774. ACM.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 782–792. Association for Computational
Linguistics.
Heng Ji and Ralph Grishman. 2011. Knowledge
base population: successful approaches and chal-
lenges. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies-Volume 1, pages
1148–1158. Association for Computational Linguis-
tics.
Paul McNamee and Hoa Trang Dang. 2009. Overview
of the tac 2009 knowledge base population track. In
Text Analysis Conference (TAC), volume 17, pages
111–113.
David Milne and Ian H Witten. 2008. Learning to link
with wikipedia. In Proceeding of the 17th ACM con-
ference on Information and knowledge management,
pages 509–518. ACM.
David Nadeau and Satoshi Sekine. 2007. A sur-
vey of named entity recognition and classification.
Lingvisticae Investigationes, 30(1):3–26.
Kamel Nebhi. 2013. Named entity disambiguation
using freebase and syntactic parsing. In CEUR-
WS.org, editor, Proceedings of the First Interna-
tional Workshop on Linked Data for Information Ex-
traction (LD4IE 2013) co-located with the 12th In-
ternational Semantic Web Conference (ISWC 2013).
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November. Previous
number = SIDL-WP-1999-0120.
Lev Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. 2011. Local and global algorithms
for disambiguation to wikipedia. In Proceedings
of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 1375–1384. Associ-
ation for Computational Linguistics.
Masumi Shirakawa, Haixun Wang, Yangqiu Song,
Zhongyuan Wang, Kotaro Nakayama, Takahiro
Hara, and Shojiro Nishio. 2011. Entity disam-
biguation based on a. Technical report, Technical
report, Technical Report MSR-TR-2011-125, Mi-
crosoft Research.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
graph-basedword sense disambiguation using mea-
sures of word semantic similarity. In Semantic Com-
puting, 2007. ICSC 2007. International Conference
on, pages 363–369. IEEE.
Wenpu Xing and Ali Ghorbani. 2004. Weighted pager-
ank algorithm. In Communication Networks and
Services Research, 2004. Proceedings. Second An-
nual Conference on, pages 305–314. IEEE.
</reference>
<page confidence="0.998234">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.710338">
<title confidence="0.989759">Graph Ranking for Collective Named Entity Disambiguation</title>
<affiliation confidence="0.948024">University of Sheffield, Regent Court, 211 Portobello Street, Sheffield, S1 4DP, of Computers and Information, Fayoum University, Fayoum,</affiliation>
<email confidence="0.996358">ayman,R.Gaizauskas@dcs.shef.ac.uk</email>
<abstract confidence="0.999640333333333">Named Entity Disambiguation (NED) refers to the task of mapping different named entity mentions in running text to their correct interpretations in a specific knowledge base (KB). This paper presents a collective disambiguation approach using a graph model. All possible NE candidates are represented as nodes in the graph and associations between different candidates are represented by edges between the nodes. Each node has an initial confidence score, e.g. entity popularity. Page-Rank is used to rank nodes and the final rank is combined with the initial confidence for candidate selection. Experiments on 27,819 NE textual mentions show the effectiveness of using Page-Rank in conjunction with initial confidence: 87% accuracy is achieved, outperforming both baseline and state-of-the-art approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing pagerank for word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>33--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8203" citStr="Agirre and Soroa, 2009" startWordPosition="1343" endWordPosition="1346"> as one of finding a dense sub-graph, which is infeasible in a huge graph. So, an algorithm originally used to find strongly interconnected, size-limited groups in social media is adopted to prune the graph, and then a greedy algorithm is used to find the densest graph. Our proposed model uses the Page-Rank (PR) algorithm (Page et al., 1999), which to our knowledge has not previously been applied to NED. Xing and Ghorbani (2004) adopted PR to consider the weights of links and the nodes’ importance. PR and Personalized PR algorithms have been used successfully in WSD (Sinha and Mihalcea, 2007; Agirre and Soroa, 2009). 3 Solution Graph In this section we discuss the construction of a graph representation that we call the solution 1Graph models are also widely used in Word Sense Disambiguation (WSD), which has lots of similarities to NED (Guti´errez et al., 2011; Guti´errez et al., 2012). 76 graph. The input is a document containing pretagged NE textual mentions. The solution graph is an undirected graph G = (V, D) where V is the node set of all possible NE candidates for different textual mentions in the input document and D is the set of edges between nodes. Edges are not drawn between different nodes for</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing pagerank for word sense disambiguation. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 33–41. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ayman Alhelbawy</author>
<author>Robert Gaizauskas</author>
</authors>
<title>Named entity disambiguation using hmms.</title>
<date>2013</date>
<booktitle>In Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on,</booktitle>
<volume>3</volume>
<pages>159--162</pages>
<contexts>
<context position="6657" citStr="Alhelbawy and Gaizauskas (2013)" startWordPosition="1088" endWordPosition="1091">on knowledge using evidence from mention-entity associations and entity popularity in the KB, and context similarity. The second line of approach is collective named entity disambiguation (CNED), where all mentions of entities in the document are disambiguated jointly. These approaches try to model the interdependence between the different candidate entities for different NE mentions in the query document, and reformulate the problem of NED as a global optimization problem whose aim is to find the best set of entities. As this new formulation is NPhard, many approximations have been proposed. Alhelbawy and Gaizauskas (2013) proposed a sequence dependency model using HMMs to model NE interdependency. Another approximation uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates (Ratinov et al., 2011). Shirakawa et al. (2011) cluster related textual mentions and assign a concept to each cluster using a probabilistic taxonomy. The concept associated with a mention is used in selecting the correct entity from the Freebase KB. Graph models are widely used in collective approaches1. All these approaches model NE interdependencies, while different met</context>
<context position="21292" citStr="Alhelbawy and Gaizauskas (2013)" startWordPosition="3537" endWordPosition="3541">ally, Table 4 shows the accuracy when using different combinations of initial confidence and entity coherence scores just in the case when reranking is applied. Here the jprob + refs combination does not add any value over jprob alone. Interestingly using initial confidence with differentially weighted edges does not show any benefit over using initial confidence and uniformly weighted edges (Table 2). To compare our results with the state-of-the-art, we report Hoffart et al.’s (2011) results as they reimplemented two other systems and also ran them over the AIDA dataset. We also compare with Alhelbawy and Gaizauskas (2013) and Shirakawa et al. (2011) who carried out their experiments using the same dataset. Table 1 presents a comparison between our approach and the state-of-the-art and shows our approach exceeds the state-of-the-art. Futhermore our approach is very simple and direct to apply, unlike Hoffart et al.’s and Shirakawa et al.’s which are considerably more complex. Also, our approach does not need any kind of training, as does the Alhelbawy approach. 6 Conclusion Our results show that Page-Rank in conjunction with re-ranking by initial confidence score can be used as an effective approach to collectiv</context>
</contexts>
<marker>Alhelbawy, Gaizauskas, 2013</marker>
<rawString>Ayman Alhelbawy and Robert Gaizauskas. 2013. Named entity disambiguation using hmms. In Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on, volume 3, pages 159–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: A collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08,</booktitle>
<pages>1247--1250</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="10361" citStr="Bollacker et al., 2008" startWordPosition="1724" endWordPosition="1727">ll entries to which the mention could refer. This includes entries with titles that fully or partially contain the query mention and those that could be an acronym of the query mention. These candidate entries are paired with their textual mentions in the document to become nodes in the solution graph. 3.2 Initial Confidence Initial confidence IConf(ei,j) is an independent feature of the NE candidate regardless of other candidates in the document. This confidence may be calculated locally using the local mention context, or globally using, e.g., the Freebase popularity score for the KB entry (Bollacker et al., 2008). Local NE Candidate Confidence: The local confidence is computed by a similarity measure between the NE mention in the query document and the KB entry of the candidate entity. We propose four different measures to be used in the disambiguation phase. cos: The cosine similarity between the named entity textual mention and the KB entry title. jwSim: While the cosine similarity between a textual mention in the document and the candidate NE title in the KB is widely used in NED, this similarity is a misleading feature. For example, the textual mention “Essex” may refer to either of the following </context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08, pages 1247–1250, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Marius Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In EACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="5611" citStr="Bunescu and Pasca (2006)" startWordPosition="923" endWordPosition="926">quires systems to deal with the case where there is no entry for the NE in the reference KB. Ji et al. (2011) group and summarise the different approaches to EL taken by participating systems. In general, there are two main lines of approach to the NED problem. Single entity disambiguation approaches (SNED), disambiguate one entity at a time without considering the effect of other NEs. These approaches use local context textual features of the mention and compare them to the textual features of NE candidate documents in the KB, and link to the most similar. The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. More similarity features were added by Cucerzan (2007) who realized that topical coherence between a candidate entity and other entities in the context will improve NED accuracy and by Milne and Witten (2008) who built on Cucerzan’s work. Han and Sun (2011) combine different forms of disambiguation knowledge using evidence from mention-entity associations and entity popularity in the KB, and context similarity. The second line of approach is collective named entity disambiguati</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Razvan C. Bunescu and Marius Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In EACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<volume>6</volume>
<pages>708--716</pages>
<contexts>
<context position="5783" citStr="Cucerzan (2007)" startWordPosition="953" endWordPosition="954">ng systems. In general, there are two main lines of approach to the NED problem. Single entity disambiguation approaches (SNED), disambiguate one entity at a time without considering the effect of other NEs. These approaches use local context textual features of the mention and compare them to the textual features of NE candidate documents in the KB, and link to the most similar. The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. More similarity features were added by Cucerzan (2007) who realized that topical coherence between a candidate entity and other entities in the context will improve NED accuracy and by Milne and Witten (2008) who built on Cucerzan’s work. Han and Sun (2011) combine different forms of disambiguation knowledge using evidence from mention-entity associations and entity popularity in the KB, and context similarity. The second line of approach is collective named entity disambiguation (CNED), where all mentions of entities in the document are disambiguated jointly. These approaches try to model the interdependence between the different candidate entit</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on wikipedia data. In Proceedings of EMNLP-CoNLL, volume 6, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoan Guti´errez</author>
<author>Sonia V´azquez</author>
<author>Andr´es Montoyo</author>
</authors>
<title>Word sense disambiguation: a graph-based approach using n-cliques partitioning technique.</title>
<date>2011</date>
<booktitle>In Natural Language Processing and Information Systems,</booktitle>
<pages>112--124</pages>
<publisher>Springer.</publisher>
<marker>Guti´errez, V´azquez, Montoyo, 2011</marker>
<rawString>Yoan Guti´errez, Sonia V´azquez, and Andr´es Montoyo. 2011. Word sense disambiguation: a graph-based approach using n-cliques partitioning technique. In Natural Language Processing and Information Systems, pages 112–124. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoan Guti´errez</author>
<author>Sonia V´azquez</author>
<author>Andr´es Montoyo</author>
</authors>
<title>A graph-based approach to wsd using relevant semantic trees and n-cliques model.</title>
<date>2012</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>225--237</pages>
<publisher>Springer.</publisher>
<marker>Guti´errez, V´azquez, Montoyo, 2012</marker>
<rawString>Yoan Guti´errez, Sonia V´azquez, and Andr´es Montoyo. 2012. A graph-based approach to wsd using relevant semantic trees and n-cliques model. In Computational Linguistics and Intelligent Text Processing, pages 225–237. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
</authors>
<title>A generative entitymention model for linking entities with knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>945--954</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Han, Le Sun, 2011</marker>
<rawString>Xianpei Han and Le Sun. 2011. A generative entitymention model for linking entities with knowledge base. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 945– 954. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>765--774</pages>
<publisher>ACM.</publisher>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 765–774. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 782–792. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Knowledge base population: successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1148--1158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Ralph Grishman. 2011. Knowledge base population: successful approaches and challenges. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1148–1158. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2009 knowledge base population track.</title>
<date>2009</date>
<booktitle>In Text Analysis Conference (TAC),</booktitle>
<volume>17</volume>
<pages>111--113</pages>
<contexts>
<context position="4798" citStr="McNamee and Dang, 2009" startWordPosition="778" endWordPosition="781">n between the real world entities corresponding to the KB entries, i.e. that they should be linked in our solution graph. These links also allow us to build up statistical co-occurrence counts between entities that occur in the same context which may be used to weight links in our graph. We evaluate our approach on the AIDA dataset (Hoffart et al., 2011). Comparison with the baseline approach and some state-of-the-art approaches shows our approach offers substantial improvements in disambiguation accuracy. 2 Related Work In 2009, NIST proposed the shared task challenge of Entity Linking (EL) (McNamee and Dang, 2009). EL is a similar but broader task than NED because NED is concerned with disambiguating a textual NE mention where the correct entity is known to be one of the KB entries, while EL also requires systems to deal with the case where there is no entry for the NE in the reference KB. Ji et al. (2011) group and summarise the different approaches to EL taken by participating systems. In general, there are two main lines of approach to the NED problem. Single entity disambiguation approaches (SNED), disambiguate one entity at a time without considering the effect of other NEs. These approaches use l</context>
</contexts>
<marker>McNamee, Dang, 2009</marker>
<rawString>Paul McNamee and Hoa Trang Dang. 2009. Overview of the tac 2009 knowledge base population track. In Text Analysis Conference (TAC), volume 17, pages 111–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5937" citStr="Milne and Witten (2008)" startWordPosition="977" endWordPosition="980">entity at a time without considering the effect of other NEs. These approaches use local context textual features of the mention and compare them to the textual features of NE candidate documents in the KB, and link to the most similar. The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate. More similarity features were added by Cucerzan (2007) who realized that topical coherence between a candidate entity and other entities in the context will improve NED accuracy and by Milne and Witten (2008) who built on Cucerzan’s work. Han and Sun (2011) combine different forms of disambiguation knowledge using evidence from mention-entity associations and entity popularity in the KB, and context similarity. The second line of approach is collective named entity disambiguation (CNED), where all mentions of entities in the document are disambiguated jointly. These approaches try to model the interdependence between the different candidate entities for different NE mentions in the query document, and reformulate the problem of NED as a global optimization problem whose aim is to find the best set</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H Witten. 2008. Learning to link with wikipedia. In Proceeding of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Satoshi Sekine</author>
</authors>
<title>A survey of named entity recognition and classification.</title>
<date>2007</date>
<journal>Lingvisticae Investigationes,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="1227" citStr="Nadeau and Sekine, 2007" startWordPosition="174" endWordPosition="177">d as nodes in the graph and associations between different candidates are represented by edges between the nodes. Each node has an initial confidence score, e.g. entity popularity. Page-Rank is used to rank nodes and the final rank is combined with the initial confidence for candidate selection. Experiments on 27,819 NE textual mentions show the effectiveness of using Page-Rank in conjunction with initial confidence: 87% accuracy is achieved, outperforming both baseline and state-of-the-art approaches. 1 Introduction Named entities (NEs) have received much attention over the last two decades (Nadeau and Sekine, 2007), mostly focused on recognizing the boundaries of textual NE mentions and classifying them as, e.g., Person, Organization or Location. However, references to entities in the real world are often ambiguous: there is a many-to-many relation between NE mentions and the entities they denote in the real world. For example, Norfolk may refer to a person, “Peter Norfolk, a wheelchair tennis player”, a place in the UK, “Norfolk County”, or in the US, “Norfolk, Massachusetts”; conversely, one entity may be known by many names, such as “Cat Stevens”, “Yusuf Islam” and “Steven Georgiou”. The NED task is </context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamel Nebhi</author>
</authors>
<title>Named entity disambiguation using freebase and syntactic parsing.</title>
<date>2013</date>
<booktitle>Proceedings of the First International Workshop on Linked Data for Information Extraction (LD4IE 2013) co-located with the 12th International Semantic Web Conference (ISWC</booktitle>
<editor>In CEURWS.org, editor,</editor>
<contexts>
<context position="12305" citStr="Nebhi, 2013" startWordPosition="2046" endWordPosition="2047">nym check (whether the NE textual mention could be an acronym for a specific candidate entity title). Experiments show that jw5im performs much better than cos. ctxt: The cosine similarity between the sentence containing the NE mention in the query document and the textual description of the candidate NE in the KB (we use the first section of the Wikipedia article as the candidate entity description). Global NE Candidate Confidence: Global confidence is a measure of the global importance of the candidate entity. Entity popularity has been used successfully as a discriminative feature for NED (Nebhi, 2013). Freebase provides an API to get an entity’s popularity score (FB), which is computed during Freebase indexing. This score is a function of the entity’s inbound and outbound link counts in Freebase and Wikipedia2. The initial confidence is not normalized across all NEs because each score is calculated independently. Initial confidence scores of all candidates for a single NE mention are normalized to sum to 1. 3.3 Entity Coherence Entity coherence refers to the real world relatedness of different entities which are candidate interpretations of different textual mentions in the document. It is</context>
</contexts>
<marker>Nebhi, 2013</marker>
<rawString>Kamel Nebhi. 2013. Named entity disambiguation using freebase and syntactic parsing. In CEURWS.org, editor, Proceedings of the First International Workshop on Linked Data for Information Extraction (LD4IE 2013) co-located with the 12th International Semantic Web Conference (ISWC 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<booktitle>Previous number =</booktitle>
<tech>Technical Report 1999-66,</tech>
<pages>1999--0120</pages>
<institution>Stanford InfoLab,</institution>
<contexts>
<context position="7923" citStr="Page et al., 1999" startWordPosition="1296" endWordPosition="1299">uses local dependency between NE mention and the candidate entity, and semantic relatedness between candidate entities to construct a referent graph, proposing a collective inference algorithm to infer the correct reference node in the graph. Hoffert (2011) poses the problem as one of finding a dense sub-graph, which is infeasible in a huge graph. So, an algorithm originally used to find strongly interconnected, size-limited groups in social media is adopted to prune the graph, and then a greedy algorithm is used to find the densest graph. Our proposed model uses the Page-Rank (PR) algorithm (Page et al., 1999), which to our knowledge has not previously been applied to NED. Xing and Ghorbani (2004) adopted PR to consider the weights of links and the nodes’ importance. PR and Personalized PR algorithms have been used successfully in WSD (Sinha and Mihalcea, 2007; Agirre and Soroa, 2009). 3 Solution Graph In this section we discuss the construction of a graph representation that we call the solution 1Graph models are also widely used in Word Sense Disambiguation (WSD), which has lots of similarities to NED (Guti´errez et al., 2011; Guti´errez et al., 2012). 76 graph. The input is a document containing</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, November. Previous number = SIDL-WP-1999-0120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1375--1384</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6905" citStr="Ratinov et al., 2011" startWordPosition="1129" endWordPosition="1132">ed jointly. These approaches try to model the interdependence between the different candidate entities for different NE mentions in the query document, and reformulate the problem of NED as a global optimization problem whose aim is to find the best set of entities. As this new formulation is NPhard, many approximations have been proposed. Alhelbawy and Gaizauskas (2013) proposed a sequence dependency model using HMMs to model NE interdependency. Another approximation uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates (Ratinov et al., 2011). Shirakawa et al. (2011) cluster related textual mentions and assign a concept to each cluster using a probabilistic taxonomy. The concept associated with a mention is used in selecting the correct entity from the Freebase KB. Graph models are widely used in collective approaches1. All these approaches model NE interdependencies, while different methods may be used for disambiguation. Han (2011) uses local dependency between NE mention and the candidate entity, and semantic relatedness between candidate entities to construct a referent graph, proposing a collective inference algorithm to infe</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1375–1384. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masumi Shirakawa</author>
<author>Haixun Wang</author>
<author>Yangqiu Song</author>
<author>Zhongyuan Wang</author>
<author>Kotaro Nakayama</author>
<author>Takahiro Hara</author>
<author>Shojiro Nishio</author>
</authors>
<title>Entity disambiguation based on a.</title>
<date>2011</date>
<tech>Technical report, Technical report, Technical Report MSR-TR-2011-125, Microsoft Research.</tech>
<contexts>
<context position="6930" citStr="Shirakawa et al. (2011)" startWordPosition="1133" endWordPosition="1137">aches try to model the interdependence between the different candidate entities for different NE mentions in the query document, and reformulate the problem of NED as a global optimization problem whose aim is to find the best set of entities. As this new formulation is NPhard, many approximations have been proposed. Alhelbawy and Gaizauskas (2013) proposed a sequence dependency model using HMMs to model NE interdependency. Another approximation uses a mixture of local and global features to train the coefficients of a linear ranking SVM to rank different NE candidates (Ratinov et al., 2011). Shirakawa et al. (2011) cluster related textual mentions and assign a concept to each cluster using a probabilistic taxonomy. The concept associated with a mention is used in selecting the correct entity from the Freebase KB. Graph models are widely used in collective approaches1. All these approaches model NE interdependencies, while different methods may be used for disambiguation. Han (2011) uses local dependency between NE mention and the candidate entity, and semantic relatedness between candidate entities to construct a referent graph, proposing a collective inference algorithm to infer the correct reference n</context>
<context position="21320" citStr="Shirakawa et al. (2011)" startWordPosition="3543" endWordPosition="3546">n using different combinations of initial confidence and entity coherence scores just in the case when reranking is applied. Here the jprob + refs combination does not add any value over jprob alone. Interestingly using initial confidence with differentially weighted edges does not show any benefit over using initial confidence and uniformly weighted edges (Table 2). To compare our results with the state-of-the-art, we report Hoffart et al.’s (2011) results as they reimplemented two other systems and also ran them over the AIDA dataset. We also compare with Alhelbawy and Gaizauskas (2013) and Shirakawa et al. (2011) who carried out their experiments using the same dataset. Table 1 presents a comparison between our approach and the state-of-the-art and shows our approach exceeds the state-of-the-art. Futhermore our approach is very simple and direct to apply, unlike Hoffart et al.’s and Shirakawa et al.’s which are considerably more complex. Also, our approach does not need any kind of training, as does the Alhelbawy approach. 6 Conclusion Our results show that Page-Rank in conjunction with re-ranking by initial confidence score can be used as an effective approach to collectively disambiguate named entit</context>
</contexts>
<marker>Shirakawa, Wang, Song, Wang, Nakayama, Hara, Nishio, 2011</marker>
<rawString>Masumi Shirakawa, Haixun Wang, Yangqiu Song, Zhongyuan Wang, Kotaro Nakayama, Takahiro Hara, and Shojiro Nishio. 2011. Entity disambiguation based on a. Technical report, Technical report, Technical Report MSR-TR-2011-125, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised graph-basedword sense disambiguation using measures of word semantic similarity.</title>
<date>2007</date>
<booktitle>In Semantic Computing,</booktitle>
<pages>363--369</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="8178" citStr="Sinha and Mihalcea, 2007" startWordPosition="1339" endWordPosition="1342">t (2011) poses the problem as one of finding a dense sub-graph, which is infeasible in a huge graph. So, an algorithm originally used to find strongly interconnected, size-limited groups in social media is adopted to prune the graph, and then a greedy algorithm is used to find the densest graph. Our proposed model uses the Page-Rank (PR) algorithm (Page et al., 1999), which to our knowledge has not previously been applied to NED. Xing and Ghorbani (2004) adopted PR to consider the weights of links and the nodes’ importance. PR and Personalized PR algorithms have been used successfully in WSD (Sinha and Mihalcea, 2007; Agirre and Soroa, 2009). 3 Solution Graph In this section we discuss the construction of a graph representation that we call the solution 1Graph models are also widely used in Word Sense Disambiguation (WSD), which has lots of similarities to NED (Guti´errez et al., 2011; Guti´errez et al., 2012). 76 graph. The input is a document containing pretagged NE textual mentions. The solution graph is an undirected graph G = (V, D) where V is the node set of all possible NE candidates for different textual mentions in the input document and D is the set of edges between nodes. Edges are not drawn be</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised graph-basedword sense disambiguation using measures of word semantic similarity. In Semantic Computing, 2007. ICSC 2007. International Conference on, pages 363–369. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenpu Xing</author>
<author>Ali Ghorbani</author>
</authors>
<title>Weighted pagerank algorithm.</title>
<date>2004</date>
<booktitle>In Communication Networks and Services Research,</booktitle>
<pages>305--314</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="8012" citStr="Xing and Ghorbani (2004)" startWordPosition="1312" endWordPosition="1315">atedness between candidate entities to construct a referent graph, proposing a collective inference algorithm to infer the correct reference node in the graph. Hoffert (2011) poses the problem as one of finding a dense sub-graph, which is infeasible in a huge graph. So, an algorithm originally used to find strongly interconnected, size-limited groups in social media is adopted to prune the graph, and then a greedy algorithm is used to find the densest graph. Our proposed model uses the Page-Rank (PR) algorithm (Page et al., 1999), which to our knowledge has not previously been applied to NED. Xing and Ghorbani (2004) adopted PR to consider the weights of links and the nodes’ importance. PR and Personalized PR algorithms have been used successfully in WSD (Sinha and Mihalcea, 2007; Agirre and Soroa, 2009). 3 Solution Graph In this section we discuss the construction of a graph representation that we call the solution 1Graph models are also widely used in Word Sense Disambiguation (WSD), which has lots of similarities to NED (Guti´errez et al., 2011; Guti´errez et al., 2012). 76 graph. The input is a document containing pretagged NE textual mentions. The solution graph is an undirected graph G = (V, D) wher</context>
</contexts>
<marker>Xing, Ghorbani, 2004</marker>
<rawString>Wenpu Xing and Ali Ghorbani. 2004. Weighted pagerank algorithm. In Communication Networks and Services Research, 2004. Proceedings. Second Annual Conference on, pages 305–314. IEEE.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>