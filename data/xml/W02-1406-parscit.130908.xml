<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993595">
Probabilistic named entity verification
</title>
<author confidence="0.992996">
Yi-Chung Lin and Peng-Hsiang Hung
</author>
<affiliation confidence="0.998412">
Advanced Technology Center, Computer and Communications Laboratories,
Industrial Technology Research Institute, Taiwan
</affiliation>
<email confidence="0.99027">
{lyc,phhung}@itri.org.tw
</email>
<sectionHeader confidence="0.993735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905416666667">
Named entity (NE) recognition is an impor-
tant task for many natural language applica-
tions, such as Internet search engines,
document indexing, information extraction
and machine translation. Moreover, in ori-
ental languages (such as Chinese, Japanese
and Korean), NE recognition is even more
important because it significantly affects the
performance of word segmentation, the most
fundamental task for understanding the texts
in oriental languages. In this paper, a prob-
abilistic verification model is designed for
verifying the correctness of a named entity
candidate. This model assesses the confi-
dence level of a candidate not only accord-
ing to the candidate’s structure but also ac-
cording to its context. In our design, the
clues for confidence measurement are col-
lected from both positive and negative ex-
amples in the training data in a statistical
manner. Experimental results show that the
proposed method significantly improves the
F-measure of Chinese personal name recog-
nition from 86.5% to 94.4%.
</bodyText>
<sectionHeader confidence="0.960922" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.998758921052632">
Named entity (NE) recognition (or proper name
recognition) is a task to find the entities of per-
son, location, organization, date, time, percent-
age and monetary value in text documents. It is
an important task for many natural language
applications, such as Internet search engines,
document indexing, information extraction and
machine translation. Moreover, in oriental lan-
guages (such as Chinese, Japanese and Korean),
NE recognition is even more important because
it significantly affects the performance of word
segmentation, the most fundamental task for
understanding the texts in oriental languages.
Therefore, a high-accuracy NE recognition
method is highly demanded for most natural
language applications in various languages.
There are two major approaches to NE
recognition: the handcrafted approach (Grish-
man, 1995) and the statistical approach (Bikel,
1997; Chen, 1998; Yu, 1998). In the first ap-
proach, a system usually relies on a large num-
ber of handcrafted rules. This kind of systems
can be rapid prototyped but are hard to scale up.
In fact, there will be numerous exceptions for
most handcrafted rules. It is generally expensive
and impossible to code for every exception we
can imagine, not to mention those exceptions we
are not able to think of. Another serious problem
with the handcrafted approach is that systems
are hard to be ported across different domains
and different languages. Porting a handcrafted
system usually means rewriting all its rules.
Therefore, the statistical approach is becoming
more and more popular because of its cost-
effectiveness in scaling up and porting systems.
In general, the statistical approach to NE
recognition can be viewed as a two-stage proc-
ess. First, according to dictionaries and/or pat-
tern matching rules, the input text is tokenized
into tokens. Each token may be a word or an NE
candidate which can consist of more than one
word. Then, the most likely token sequence is
selected according to a statistical model, such as
Markov model (Bikel, 1997; Yu, 1998) or
maximum entropy model (Borthwick, 1999).
Although, the statistical NE recognition is much
more scalable and portable, its performance is
still not satisfactory. The insufficient cover-
age/precision of pattern matching rules and
unknown words are the major sources of errors.
Furthermore, the role of the statistical model is
to assess the relative possibilities of all possible
token sequences and select the most probable
“
one. The scores obtained from the statistical
model can be used for a comparison of compet-
ing token sequences, but not for an assessment
of the probability that a spotted named entity is
correct.
To reduce the recognition errors, we pro-
pose a probabilistic verification model to verify
the correctness of a named entity. This model
assesses the confidence level of a named entity
candidate not only according to the candidate’s
structure but also according to its contexts. In
our design, the clues for confidence measure-
ment are collected from both positive and nega-
tive examples in the training data. Therefore, the
confidence measure has strong discriminant
power for judging the correctness of a named
entity. In the experiments of Chinese personal
name recognition, the proposed verification
model increases the F-measure from 86.5% to
94.4%, which corresponds to 58.5% error re-
duction rate, where “error rate” is defined as
“100% − F-measure ”.
</bodyText>
<sectionHeader confidence="0.854458" genericHeader="method">
1. Named Entity Verification
</sectionHeader>
<bodyText confidence="0.984688647058824">
As mentioned before, there are several kinds of
named entities, including person, location, or-
ganization, date, time, percentage and monetary
value. In the following description, we use the
task of verifying Chinese personal name as an
example. However, our proposed method is also
applicable on verifying other kinds of named
entities in different languages.
Before introducing our approach, we first
describe the notations that will be used. In this
proposal, a random variable is written with a
boldface italic letter. An outcome of a random
variable is written with the same italic letter but
in normal face. For example, an outcome of the
random variable o is denoted as o . If there is
no confusion, we usually use P(o) to denote
the probability P(o = o) . A symbol sequence
</bodyText>
<equation confidence="0.829104666666666">
x1, &amp;quot; ,xn” is denoted as “ 1
x ”. Likewise, “ ,
Y n
n xY ”
,1
denotes the sequence “xY ,1,&amp;quot;,xY,n ”.
</equation>
<bodyText confidence="0.9996372">
The task of verifying a named entity can-
didate is viewed as making an acceptance or
rejection decision according to the text segment
consisting of the candidate and its context.
Without loss of generality, a text segment is
</bodyText>
<figure confidence="0.9339735">
Candidate
Left Context Right Context
</figure>
<figureCaption confidence="0.999921">
Figure 1: Example of a text segment.
</figureCaption>
<bodyText confidence="0.510949">
considered as an outcome of the random vector
</bodyText>
<equation confidence="0.748261">
O = CJ
[oi,i , oC, ORi The outcome of each ran-
</equation>
<bodyText confidence="0.997358461538462">
dom variable in O is one basic element of text.
In Chinese, the basic elements of text are Chine-
se characters. However, in English, the basic
elements are English words. Figure 1 shows an
example of a text segment in which the size of
the candidate to be verified is 3 (i.e., consists of
three Chinese characters) and the sizes of its left
context and right context are set to 2 (i.e., two
Chinese characters).
Figure 2 depicts the flowchart of our veri-
fication approach. First, the candidate in the
input text segment is parsed by a predefined
grammar. If the candidate is ill-formed (i.e., fail
</bodyText>
<figure confidence="0.709376666666667">
Confidence
Measurement
cm &lt; δ Yes Reject
</figure>
<figureCaption confidence="0.9949075">
Figure 2: Flowchart of the verification
method.
</figureCaption>
<figure confidence="0.9228669375">
oL ,1 oL ,2 oC, 1 oC ,2 oC,3 oR, 1 oR,2
I V �����
shi
zhang ma
ying
jiu
biao
shi
Text
Segment
Ill-formed? Yes Reject
No
Candidate
Parsing
No
Accept
</figure>
<bodyText confidence="0.999607">
to be parsed), it will be rejected immediately.
Otherwise, the text segment is passed to the
confidence measurement module to assess the
confidence level that the candidate in the text
segment is to be a named entity. If the confi-
dence measure is less than a predefined thresh-
old, the candidate will be rejected. Otherwise, it
will be accepted.
</bodyText>
<sectionHeader confidence="0.977715" genericHeader="method">
2. Confidence Measurement
</sectionHeader>
<bodyText confidence="0.992537888888889">
The basic idea of our approach is to formulate
the confidence measurement problem as the
problem of hypothesis testing. The null hypothe-
sis H0 in which the candidate is a name is
tested against the alternative hypothesis H1 in
which the candidate is not a name. According to
Neyman-Pearson Lemma, an optimal hypothesis
test involves the evaluation of the following log
likelihood ratio:
</bodyText>
<equation confidence="0.984521153846154">
LLR (L,x C y R,z
oL ,1 ,oC ,1 ,oR,1 )
P(oLL,x C,y R,z
1 ,oC ,1 ,oR,1  |H0)
log L , ,x C,y R,z
P(oL ,1 ,o C ,1 ,oR,1  |H1)
L,x C,y R,z
logP(oL ,1 ,oC ,1 ,oR,1  |H0)
L x C y R z
, , ,
− log P(oL ,1 ,oC ,1 , oR,1  |H1 )
L x C y R z
, ,
</equation>
<bodyText confidence="0.881059">
where P o L o C o R H is the likelihood of
</bodyText>
<equation confidence="0.6514375">
( ,1 , ,1 , ,1  |0)
,
</equation>
<bodyText confidence="0.998323">
the candidate and its left and right contexts
given the hypothesis that the candidate is a name
</bodyText>
<equation confidence="0.9258218">
L x C y R z
, ,
and P o L o C o R H is the likelihood of
( ,1 , ,1 , ,1  |1)
,
</equation>
<bodyText confidence="0.99777875">
the candidate and its left and right contexts
given the hypothesis that the candidate is not a
name. The hypothesis test is performed by com-
paring the log likelihood ratio
</bodyText>
<equation confidence="0.704105">
LLR oL oC oR to a predefined critical
( ,1 , ,1 , ,1 )
L x C y R z
, , ,
NE Model
SNE(⋅)
cm
Anti-NE Model
Santi-NE(⋅)
</equation>
<figureCaption confidence="0.976495">
Figure 3: Block diagram of the confi-
dence measurement module.
</figureCaption>
<equation confidence="0.9841244">
L x C y R z
, ,
threshold δ . If LLR o L o C o R ≥ δ , the
( ,1 , ,1 , ,1 )
,
</equation>
<bodyText confidence="0.999884666666667">
null hypothesis will be accepted. Otherwise, it
will be rejected.
In our design, as shown in Figure 3, the
confidence measurement module consists of two
models, named NE model and anti-NE model.
The NE model is used to assess the value of
</bodyText>
<equation confidence="0.994319857142857">
log ( ,1 , ,1 , ,1  |0)
P oL oC oR H and the anti-NE model
L x C y R z
, , ,
is used to assess the value of
logP(oLL,x C,y R,z
,1 ,oC,1 ,oR,1  |H1)
</equation>
<subsectionHeader confidence="0.463701">
2.1. NE Model
</subsectionHeader>
<bodyText confidence="0.984696">
The purpose of the NE model is to evaluate the
</bodyText>
<equation confidence="0.990268166666667">
L x C y R z
,
value of log ( ,1 , ,1 , ,1  |0)
,
P o L o C o R H , the log like-
,
</equation>
<bodyText confidence="0.996592333333333">
lihood of the candidate and its left and right
contexts given the hypothesis that the candidate
is a name. Since it is infeasible to directly esti-
</bodyText>
<equation confidence="0.990575071428571">
L x C y R z
, ,
mate the probability P o L o C o R H , it is
( ,1, ,1, ,1  |0)
,
approximated as follows:
L x C y R z
, , , , , ,
L x C y R z
≡
P ( , ,  |) ( , , )
o o o H P o o o
L ,1 C ,1 R ,1 0 0 L ,1 C ,1 R ,1
P0(oL ,1 )P0(oC ,1 C,y)P0(oR,1 )
</equation>
<bodyText confidence="0.998441">
where the subscript of P0(⋅) indicates the prob-
ability is evaluated given that the null hypothesis
</bodyText>
<equation confidence="0.791461">
L x
</equation>
<bodyText confidence="0.566201">
is true. The probability P o L is further ap-
</bodyText>
<equation confidence="0.917239">
0 ( ,1 )
,
</equation>
<bodyText confidence="0.9991335">
proximated according to the bigram model as
follows:
</bodyText>
<equation confidence="0.99197875">
x
( )
,
P o L x ≈ ∏ P o o −
(  |) (3)
0 L ,1 0 L i L i
, , 1
i 1
</equation>
<bodyText confidence="0.997160333333333">
where P0 (oL,1  |oL,0) ≡ P0 (oL,1) . One should notice
that we do not assume that the random sequence
oL is time invariant. For example, the prob-
</bodyText>
<equation confidence="0.932949">
L x
,
,1
</equation>
<bodyText confidence="0.896111">
ability P(oL ,i = x  |oL ,i−1 = y) is not assumed to
be equal to P(oL ,2 = x  |oL,1 = y) for i ≥ 3.
</bodyText>
<equation confidence="0.9857037">
R z
Likewise, the probability P o R is also fur-
0 ( ,1 )
,
ther approximated as follows:
z
R z
,
P0 (oR,1) ≈∏ P0 (oR,i  |oR,i−1) (4)
i 1
</equation>
<bodyText confidence="0.887312">
where P0 (oR,1  |oR,0) ≡ P0 (oR,1) .
The probability corresponding to the can-
didate is evaluated by applying the SCFG (Sto-
</bodyText>
<figure confidence="0.966739428571429">
(1)
Text
Segment
(2)
S
SNC GNC GNC
(ma) (ying) (jiu)
</figure>
<figureCaption confidence="0.9651065">
Figure 4: A parse tree of the Chinese per-
sonal name “(ma ying jiu)”.
</figureCaption>
<bodyText confidence="0.4465495">
chastic Context-free Grammar) model (Fujisaki,
1989) as follows:
</bodyText>
<equation confidence="0.878653833333333">
C y
,
P o
( ) = ∑P T
( )
0 C ,1 0
</equation>
<sectionHeader confidence="0.563221" genericHeader="method">
2.2. Anti-NE Model
</sectionHeader>
<bodyText confidence="0.900782">
The purpose of the anti-NE model is to evaluate
</bodyText>
<equation confidence="0.6848175">
L x C y R z
,
the value of log ( ,1 , ,1 , ,1  |1)
,
P o L o C o R H , the log
,
</equation>
<bodyText confidence="0.998954333333333">
likelihood of the candidate and its left and right
contexts given the hypothesis that the candidate
is not a name. Since it is infeasible to directly
</bodyText>
<equation confidence="0.998208285714286">
L x C y R z
, ,
estimate the probability P o L o C o R H , it
( ,1 , ,1 , ,1  |1)
,
is approximated as follows:
L x C y R z
, , , , , ,
P o o o H P o o o
( , ,  |) ( , , )
L x C y R z
=
L ,1 C ,1 R ,1 1 1 L ,1 C ,1 R ,1
y
P o o ×
1 (  |) ∏ P o o
, , 1 1 (  |)
L i L i − C i C i
, , 1
−
i=1 i=1
z
∏ (  |)
P o o
1 R i R i
, , 1
−
i 1
x
≈ ∏
(7)
×
max P0(T) = max ∏ P0(α  |A)
T TA→α∈T
T (5)
</equation>
<bodyText confidence="0.999988823529412">
where T stands for one possible parse tree that
derive the candidate, A → α indicates a rule in
the parse tree T , A stands for the left-hand-
side symbol of the rule and α stands for the
sequence of right-hand-side symbols of the rule.
Figure 4 shows an example of a parse tree of the
Chinese personal name candidate “(ma
ying jiu)”, where “(ma)” is the surname and
“(ying jiu)” is the given name. In this figure,
the symbol “S” denotes the start symbol, the
symbol “SNG” denotes the nonterminal deriving
surname characters and the symbol “GNC”
denotes the nonterminal deriving given name
characters. As a result, according to equations (2)
-(5), the scoring function in the NE model is
defined as equation (6) to assess the log likeli-
hood of the text segment “oL,x oC,y oR,z ” given
</bodyText>
<equation confidence="0.991719105263158">
L,1 , C,1,R,1
the null hypothesis that “ ,
oC ” is a name.
C y
,1
L,x C,y R,z
SNE (oL ,1 , oC ,1 , oR,1 )
x z
=∑ log (  |) log (  |)
P o o + ∑ P o o (6)
0 L i L i
, , 1
− 0 R i R i
, , 1
−
i=
1 i=1
+max ∑ logP0(α  |A)
T A→α∈T
</equation>
<bodyText confidence="0.6897465">
where T is one possible parse tree that derive
the candidate “ ,
</bodyText>
<equation confidence="0.937252">
oC ”.
C y
</equation>
<page confidence="0.75677">
,1
</page>
<bodyText confidence="0.998675">
where oR,0 ≡ oC,y , oC,0 ≡ oL,x , and P1 (oL,1  |oL,0 )
≡ P1 (oL,1) . Therefore, the following scoring
function is used in the anti-NE model to assess
the log likelihood of the text segment
“ ,
</bodyText>
<equation confidence="0.993560653846154">
o L o C o R ” given the alternative hypothesis
L x C y R z
,1 , ,1 , ,1
, ,
that “ ,
oC ” is not a name.
C y
,1
L,x C,y R,z
anti-NE (oL ,1 , C ,1 , R,1 )
y
log (  |) log (  |)
P o o + ∑ P o o
1 L i L i
, , 1
− 1 C i C i
, , 1
−
1 i=1
z
+ ∑ log (  |)
P o o
1 R i R i
, , 1
−
i 1
</equation>
<sectionHeader confidence="0.988469" genericHeader="method">
3. Experiment Setup
</sectionHeader>
<bodyText confidence="0.999833625">
The proposed named entity verification method
is used to recognize Chinese personal names
from news. In Chinese, most of the personal
names consist of three Chinese characters. The
first character is a surname. The last two char-
acters are a given name. Therefore, our prelimi-
nary experiments are focused on recognizing the
personal names of three Chinese characters.
In our experiments, the training corpus
consists of about 14,339,000 Chinese characters
collected from economy and industry news. This
corpus should be annotated to estimate the prob-
abilistic parameters of the scoring functions
SNE(⋅) and S anti-NE(⋅) . However, labeling such
large amount of data is too costly or prohibited
even if it is possible. Therefore, labeling
</bodyText>
<figure confidence="0.8821436">
S
x
= ∑
(8)
i=
</figure>
<figureCaption confidence="0.999609">
Figure 5: EM-style bootstrapping.
</figureCaption>
<bodyText confidence="0.999948285714286">
methods that can be bootstrapped from a little
seed data or a few seed rules (Collins, 1999;
Cucerzan, 1999) are highly demanded to auto-
matically annotate the training data. In the fol-
lowing section, we propose an EM-style boot-
strapping procedure (Cucerzan, 1999) for anno-
tating the training data automatically.
</bodyText>
<subsectionHeader confidence="0.991509">
3.1. EM-Style Bootstrapping
</subsectionHeader>
<bodyText confidence="0.999981825">
The Expectation-Maximization (EM) algorithm
(Moon, 1996) has been widely used to estimate
model parameters from incomplete data in many
different applications. In this section, an EM-
style bootstrapping procedure is proposed to
automatically annotate the named entities in the
training corpus. It iteratively uses the proposed
verification model to label the training corpus
(expectation step), and then uses the labeled
training corpus to re-estimate the parameters of
the verification model (maximization step).
Figure 5 shows the flowchart of the bootstrap-
ping procedure. First, we collect the names of
541 famous people, including government offi-
cers and CEOs of big companies. These names
are used as seed names of the name corpus.
Then, the news is automatically annotated ac-
cording to the name corpus. The annotated cor-
pus is used to estimate the probabilistic
parameters of the scoring functions. Afterward,
the proposed verification procedure is used to
verify every possible name candidate in the
news. The candidates whose confidence meas-
ures are larger than a predefined threshold are
determined to be names. Currently, if the confi-
dence measures of two overlapped candidates
(such as “ma ying jiu” and “ying jiu biao” in
Figure 1) pass the threshold, both of them are
determined as names. Although this strategy is
inadequate, it does not make too much trouble
because the chance to get overlapped names is
very small in our experiments. Finally, these
guessed names are added to the name corpus
which will be used to annotate the news in next
iteration.
In our case, after four iterations, the size
of name corpus is enlarged from 541 to 6,296, as
shown in Table 1. The total occurrence frequen-
cy of these 6,296 names in the training corpus is
40,345.
</bodyText>
<subsectionHeader confidence="0.866911">
3.2. Baseline Model
</subsectionHeader>
<bodyText confidence="0.999956894736842">
In the past, many researchers have studied the
problem of Chinese personal name recognition.
Chang (1994) used the 0-order Markov model to
segment a text into words, including Chinese
personal names. In his approach, a name prob-
ability model is proposed to estimate the prob-
abilities of Chinese personal names. Sproat
(1994) proposed to recognize Chinese personal
names with the stochastic finite-state word seg-
mentation algorithm. His approach is similar to
Chang’s, except that the name probability model
is slightly different. In addition to name prob-
ability, Chen (1998) also add extra scores to a
name candidate according to context clues (such
as position, title, speech-act verbs). In the re-
searches mentioned above, the reported F-
measure performances on recognizing Chinese
personal names are somewhere between 70%
and 86%. Since these performances are meas-
</bodyText>
<table confidence="0.991110428571429">
Iteration Nunber of Total frequency
distinct names of names
0 541 18310
1 3389 31157
2 5327 37423
3 6055 39977
4 6296 40345
</table>
<tableCaption confidence="0.995413">
Table 1: Number of distinct names in
</tableCaption>
<bodyText confidence="0.885182">
the name corpus and total frequency
of names in the annotated news dur-
ing the bootstrapping iteration.
</bodyText>
<figure confidence="0.998426">
Seed
Names
Name
Corpus
News
Guessed
Names
Name
Verification
News
Annotation
Parameter
Estimation
0 1 2 3 4
Iteration
</figure>
<figureCaption confidence="0.993946">
Figure 6: The performances of baseline
and name entity verification (NEV).
</figureCaption>
<bodyText confidence="0.999961846153846">
ured based on different data, higher reported
performance does not imply better. In fact, the
name probability models used in these re-
searches are very similar. Their performances
should be comparable to each other. Therefore,
in this paper, Chang’s approach, whose reported
F-measure is 86%, is chosen as the baseline
model.
The baseline model is additionally
equipped with a dictionary of 72,333 Chinese
words. The prior probabilities of words are esti-
mated from Academia Sinica Balanced Corpus,
which contains about 2 million Chinese words.
</bodyText>
<sectionHeader confidence="0.946448" genericHeader="evaluation">
4. Experimental Results and Discussions
</sectionHeader>
<bodyText confidence="0.9993873">
Both the baseline model and the proposed name
entity verification model (named NEV model)
are tested on the same testing corpus. The testing
corpus, also collected from economy and indus-
try news, consists of about 737,000 characters.
This corpus is annotated manually and contains
totally 2,545 Chinese personal names.
The F-measure of the baseline model is
86.5% (as indicated by the dashed line in Figure
6). The precision and recall rates of the baseline
model are 79.1% and 95.5% respectively. Alt-
hough the recall rate of the baseline model is
high, the precision rate is pretty low. Over 20%
of the name candidates proposed by the baseline
model are incorrect.
In our experiments, the sizes of the left-
and right-context windows of the NEV model
are set to 2. In Figure 6, the solid line with trian-
gle markers depicts the F-measure of the NEV
model versus the iteration number of bootstrap-
ping. The F-measure saturates after 3 iterations.
After 4 iterations, the F-measure of the NEV
model reaches 94.4%. The corresponding preci-
sion and recall rates are 96.4% and 92.5% re-
spectively. Compared with the baseline model,
the precision rate is greatly improved from
79.1% to 96.4% with a little sacrifice in recall
rate. The F-measure is improved from 86.5% to
94.4%, which corresponds to 58.5% error re-
duction rate, where “error rate” is defined as
“100% − F-measure ”.
Table 2 lists three examples of the mis-
recognized names made by the baseline model.
These examples clearly show that the baseline
model tends to incorrectly group consecutive
single characters, either from unknown words or
single-character words, into names. In the first
two examples, the single characters come from
the unknown location name “(ga luo
lai na; Carolina) and the unknown company
name “(luo ji; Logitech)”. The single char-
acters in the last example are single-character
words “(gi; quarter)”, “(quan; all)” and “
(mei; USA)”.
Without the inadequate strong tendency of
grouping single characters, the NEV model is
able to avoid the misrecognition errors made by
the baseline model. The NEV model assesses the
confidence measure of each name candidate
according to the context around the candidate. In
</bodyText>
<tableCaption confidence="0.527527">
Table 2, the name candidates in the shaded
boxes are rejected by the NEV model because
Table 2: Examples of the incorrect Chi-
nese personal names (in the shaded boxes)
produced by the baseline model.
</tableCaption>
<figure confidence="0.862223619047619">
0.95
0.90
0.85
1.00
NEV
Baseline
(In the first quarter, the workers in all USA ...)
di yi
dong zhe ...
lao
ji quan mei
(take North Carolina State as an example)
yi
bei ga
luo lai na zhou wei li
(In last year, the big company Logitech ...)
da chang luo ji zai
nian ...
qu
F−measure
their confidence measures are too low.
</figure>
<bodyText confidence="0.999613727272727">
To sum up, the experimental results de-
monstrate that the contextual information, either
from positive examples or from negative exam-
ples, is very helpful for named entity verification.
Besides, the superiority of the NEV model also
shows that the proposed probabilistic score
functions SNE(⋅) and S anti-NE(⋅) are effective in
providing the scores to produce a reliable confi-
dence measure. Especially, the proposed named
entity verification approach does not require any
dictionary in advance.
</bodyText>
<sectionHeader confidence="0.95127" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999931714285714">
Named entity (NE) recognition is an important
task for many natural language applications,
such as Internet search engines, document in-
dexing, information extraction and machine
translation. Moreover, in oriental languages
(such as Chinese, Japanese and Korean), NE
recognition is even more important because it
significantly affects the performance of word
segmentation, the most fundamental task for
understanding the texts in oriental languages.
In this paper, a probabilistic verification
model is proposed to verify the correctness of a
named entity. This model assesses the confi-
dence level of a name candidate not only ac-
cording to the candidate’s structure but also
according to its contexts. The clues for confi-
dence measurement are collected from both
positive and negative examples in the training
data. Therefore, the confidence measure has
strong discriminant power for judging the cor-
rectness of a named entity. In the experiments of
Chinese personal name recognition, the pro-
posed verification model greatly increases the
precision rate from 79.1% to 96.4% with a little
sacrifice in recall rate. The F-measure is im-
proved from 86.5% to 94.4%, which corre-
sponds to 58.5% error reduction rate, where
“error rate” is defined as “100% − F-measure ”.
</bodyText>
<sectionHeader confidence="0.997621" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999413666666667">
This paper is a partial result of Project
A311XS1211 conducted by ITRI under sponsor-
ship of the Ministry of Economic Affairs, R.O.C.
Especially thanks to the CKIP group of Acade-
mia Sinica for providing the Academia Sinica
Balanced Corpus.
</bodyText>
<sectionHeader confidence="0.996308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999808458333333">
Bikel, D., Miller S., Schwartz R., and Weischedel R.
(1997) Nymble: A High-performance Learning
Name Finder. In Proceedings of the Fifth Confer-
ence on Applied Natural Language Processing, pp.
194–201.
Borthwick, A. (1999) A Maximum Entropy Approach
to Named Entity Recognition. Ph.D. Thesis, New
York University.
Chang J., Chen S., Ker S., Chen Y. and Liu J. (1994)
A Multiple-Corpus Approach to Recognition of
Proper Names in Chinese Texts. Computer Proc-
essing of Chinese and Oriental Languages, Vol. 8,
No. 1, pp. 75-85.
Chen, H., Ding Y., Tsai S. and Bian G. (1998) De-
scription of the NTU System used for MET2. in
Proceedings of the 7th Message Understanding
Conference (MUC-7)
Collins, M. and Singer, Y. (1999) Unsupervised
Models for Named Entity Classification. In Pro-
ceedings of the Joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing
and Very Large Corpora, pp. 100-110.
Cucerzan S. and Yarowsky D. (1999) Language
independent named entity recognition combining
morphological and contextual evidence. In Pro-
ceedings of the Joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing
and Very Large Corpora, pp. 90-99.
Fujisaki, T., Jelinek F., Cocke J., Black E. and Nishi-
no T. (1989), A Probabilistic Parsing Method for
Sentence Disambiguation. In Proceedings of the
International Workshop on Parsing Technologies,
pp. 85-94.
Grishman, R. (1995) The NYU system for MUC-6 or
where&apos;s the syntax? In Proceedings of the 6th Mes-
sage Understanding Conference (MUC-6), pp. 167-
175.
Moon, T. K. (1996) The Expectation-Maximization
Algorithm, IEEE Signal Processing Magazine, No-
vember, 1996, pp. 47-60.
Sproat R. and Chang N. (1994) A Stochastic Finite-
State Word-Segmentation Algorithm for Chinese.
In Proceeding of 32nd Annual Meeting of the As-
sociation for Computational Linguistics, pp. 66-73.
Yu, S., Bai S. and Wu P. (1998) Description of the
Kent Ridge Digital Labs System Used for MUC-7.
In Proceedings of the 7th Message Understanding
Conference (MUC-7)
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416481">
<title confidence="0.999695">Probabilistic named entity verification</title>
<author confidence="0.697339">Yi-Chung Lin</author>
<author confidence="0.697339">Peng-Hsiang</author>
<affiliation confidence="0.845753">Advanced Technology Center, Computer and Communications Industrial Technology Research Institute,</affiliation>
<email confidence="0.932412">lyc@itri.org.tw</email>
<email confidence="0.932412">phhung@itri.org.tw</email>
<abstract confidence="0.98587692">Named entity (NE) recognition is an important task for many natural language applications, such as Internet search engines, document indexing, information extraction and machine translation. Moreover, in oriental languages (such as Chinese, Japanese and Korean), NE recognition is even more important because it significantly affects the performance of word segmentation, the most fundamental task for understanding the texts in oriental languages. In this paper, a probabilistic verification model is designed for verifying the correctness of a named entity candidate. This model assesses the confidence level of a candidate not only according to the candidate’s structure but also according to its context. In our design, the clues for confidence measurement are collected from both positive and negative examples in the training data in a statistical manner. Experimental results show that the proposed method significantly improves the F-measure of Chinese personal name recognition from 86.5% to 94.4%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bikel</author>
<author>S Miller</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: A High-performance Learning Name Finder.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>194--201</pages>
<marker>Bikel, Miller, Schwartz, Weischedel, 1997</marker>
<rawString>Bikel, D., Miller S., Schwartz R., and Weischedel R. (1997) Nymble: A High-performance Learning Name Finder. In Proceedings of the Fifth Conference on Applied Natural Language Processing, pp. 194–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<tech>Ph.D. Thesis,</tech>
<location>New York University.</location>
<contexts>
<context position="3319" citStr="Borthwick, 1999" startWordPosition="504" endWordPosition="505">rewriting all its rules. Therefore, the statistical approach is becoming more and more popular because of its costeffectiveness in scaling up and porting systems. In general, the statistical approach to NE recognition can be viewed as a two-stage process. First, according to dictionaries and/or pattern matching rules, the input text is tokenized into tokens. Each token may be a word or an NE candidate which can consist of more than one word. Then, the most likely token sequence is selected according to a statistical model, such as Markov model (Bikel, 1997; Yu, 1998) or maximum entropy model (Borthwick, 1999). Although, the statistical NE recognition is much more scalable and portable, its performance is still not satisfactory. The insufficient coverage/precision of pattern matching rules and unknown words are the major sources of errors. Furthermore, the role of the statistical model is to assess the relative possibilities of all possible token sequences and select the most probable “ one. The scores obtained from the statistical model can be used for a comparison of competing token sequences, but not for an assessment of the probability that a spotted named entity is correct. To reduce the recog</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>Borthwick, A. (1999) A Maximum Entropy Approach to Named Entity Recognition. Ph.D. Thesis, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chang</author>
<author>S Chen</author>
<author>S Ker</author>
<author>Y Chen</author>
<author>J Liu</author>
</authors>
<title>A Multiple-Corpus Approach to Recognition of</title>
<date>1994</date>
<booktitle>Proper Names in Chinese Texts. Computer Processing of Chinese and Oriental Languages,</booktitle>
<volume>8</volume>
<pages>75--85</pages>
<marker>Chang, Chen, Ker, Chen, Liu, 1994</marker>
<rawString>Chang J., Chen S., Ker S., Chen Y. and Liu J. (1994) A Multiple-Corpus Approach to Recognition of Proper Names in Chinese Texts. Computer Processing of Chinese and Oriental Languages, Vol. 8, No. 1, pp. 75-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chen</author>
<author>Y Ding</author>
<author>S Tsai</author>
<author>G Bian</author>
</authors>
<title>Description of the NTU System used for MET2.</title>
<date>1998</date>
<booktitle>in Proceedings of the 7th Message Understanding Conference (MUC-7)</booktitle>
<marker>Chen, Ding, Tsai, Bian, 1998</marker>
<rawString>Chen, H., Ding Y., Tsai S. and Bian G. (1998) Description of the NTU System used for MET2. in Proceedings of the 7th Message Understanding Conference (MUC-7)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Y Singer</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>100--110</pages>
<marker>Collins, Singer, 1999</marker>
<rawString>Collins, M. and Singer, Y. (1999) Unsupervised Models for Named Entity Classification. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pp. 100-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>D Yarowsky</author>
</authors>
<title>Language independent named entity recognition combining morphological and contextual evidence.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>90--99</pages>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>Cucerzan S. and Yarowsky D. (1999) Language independent named entity recognition combining morphological and contextual evidence. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pp. 90-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Fujisaki</author>
<author>F Jelinek</author>
<author>J Cocke</author>
<author>E Black</author>
<author>T Nishino</author>
</authors>
<title>A Probabilistic Parsing Method for Sentence Disambiguation.</title>
<date>1989</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies,</booktitle>
<pages>85--94</pages>
<marker>Fujisaki, Jelinek, Cocke, Black, Nishino, 1989</marker>
<rawString>Fujisaki, T., Jelinek F., Cocke J., Black E. and Nishino T. (1989), A Probabilistic Parsing Method for Sentence Disambiguation. In Proceedings of the International Workshop on Parsing Technologies, pp. 85-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
</authors>
<title>The NYU system for MUC-6 or where&apos;s the syntax?</title>
<date>1995</date>
<booktitle>In Proceedings of the 6th Message Understanding Conference (MUC-6),</booktitle>
<pages>167--175</pages>
<contexts>
<context position="2076" citStr="Grishman, 1995" startWordPosition="296" endWordPosition="298"> many natural language applications, such as Internet search engines, document indexing, information extraction and machine translation. Moreover, in oriental languages (such as Chinese, Japanese and Korean), NE recognition is even more important because it significantly affects the performance of word segmentation, the most fundamental task for understanding the texts in oriental languages. Therefore, a high-accuracy NE recognition method is highly demanded for most natural language applications in various languages. There are two major approaches to NE recognition: the handcrafted approach (Grishman, 1995) and the statistical approach (Bikel, 1997; Chen, 1998; Yu, 1998). In the first approach, a system usually relies on a large number of handcrafted rules. This kind of systems can be rapid prototyped but are hard to scale up. In fact, there will be numerous exceptions for most handcrafted rules. It is generally expensive and impossible to code for every exception we can imagine, not to mention those exceptions we are not able to think of. Another serious problem with the handcrafted approach is that systems are hard to be ported across different domains and different languages. Porting a handcr</context>
</contexts>
<marker>Grishman, 1995</marker>
<rawString>Grishman, R. (1995) The NYU system for MUC-6 or where&apos;s the syntax? In Proceedings of the 6th Message Understanding Conference (MUC-6), pp. 167-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Moon</author>
</authors>
<title>The Expectation-Maximization Algorithm,</title>
<date>1996</date>
<booktitle>IEEE Signal Processing Magazine,</booktitle>
<pages>47--60</pages>
<contexts>
<context position="13796" citStr="Moon, 1996" startWordPosition="2714" endWordPosition="2715">f the scoring functions SNE(⋅) and S anti-NE(⋅) . However, labeling such large amount of data is too costly or prohibited even if it is possible. Therefore, labeling S x = ∑ (8) i= Figure 5: EM-style bootstrapping. methods that can be bootstrapped from a little seed data or a few seed rules (Collins, 1999; Cucerzan, 1999) are highly demanded to automatically annotate the training data. In the following section, we propose an EM-style bootstrapping procedure (Cucerzan, 1999) for annotating the training data automatically. 3.1. EM-Style Bootstrapping The Expectation-Maximization (EM) algorithm (Moon, 1996) has been widely used to estimate model parameters from incomplete data in many different applications. In this section, an EMstyle bootstrapping procedure is proposed to automatically annotate the named entities in the training corpus. It iteratively uses the proposed verification model to label the training corpus (expectation step), and then uses the labeled training corpus to re-estimate the parameters of the verification model (maximization step). Figure 5 shows the flowchart of the bootstrapping procedure. First, we collect the names of 541 famous people, including government officers an</context>
</contexts>
<marker>Moon, 1996</marker>
<rawString>Moon, T. K. (1996) The Expectation-Maximization Algorithm, IEEE Signal Processing Magazine, November, 1996, pp. 47-60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>N Chang</author>
</authors>
<title>A Stochastic FiniteState Word-Segmentation Algorithm for Chinese.</title>
<date>1994</date>
<booktitle>In Proceeding of 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>66--73</pages>
<marker>Sproat, Chang, 1994</marker>
<rawString>Sproat R. and Chang N. (1994) A Stochastic FiniteState Word-Segmentation Algorithm for Chinese. In Proceeding of 32nd Annual Meeting of the Association for Computational Linguistics, pp. 66-73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yu</author>
<author>S Bai</author>
<author>P Wu</author>
</authors>
<title>Description of the Kent Ridge Digital Labs System Used for MUC-7.</title>
<date>1998</date>
<booktitle>In Proceedings of the 7th Message Understanding Conference (MUC-7)</booktitle>
<marker>Yu, Bai, Wu, 1998</marker>
<rawString>Yu, S., Bai S. and Wu P. (1998) Description of the Kent Ridge Digital Labs System Used for MUC-7. In Proceedings of the 7th Message Understanding Conference (MUC-7)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>