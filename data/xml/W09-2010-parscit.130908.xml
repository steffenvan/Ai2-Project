<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.997166">
An Unsupervised Model for Text Message Normalization
</title>
<author confidence="0.99783">
Paul Cook
</author>
<affiliation confidence="0.914121">
Department of Computer Science
University of Toronto
Toronto, Canada
</affiliation>
<email confidence="0.982149">
pcook@cs.toronto.edu
</email>
<author confidence="0.987818">
Suzanne Stevenson
</author>
<affiliation confidence="0.913355666666667">
Department of Computer Science
University of Toronto
Toronto, Canada
</affiliation>
<email confidence="0.992769">
suzanne@cs.toronto.edu
</email>
<sectionHeader confidence="0.994927" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999680076923077">
Cell phone text messaging users express them-
selves briefly and colloquially using a variety
of creative forms. We analyze a sample of cre-
ative, non-standard text message word forms
to determine frequent word formation pro-
cesses in texting language. Drawing on these
observations, we construct an unsupervised
noisy-channel model for text message normal-
ization. On a test set of 303 text message
forms that differ from their standard form, our
model achieves 59% accuracy, which is on par
with the best supervised results reported on
this dataset.
</bodyText>
<sectionHeader confidence="0.960302" genericHeader="method">
1 Text Messaging
</sectionHeader>
<bodyText confidence="0.9998746875">
Cell phone text messages—or SMS—contain many
shortened and non-standard forms due to a variety
of factors, particularly the desire for rapid text entry
(Grinter and Eldridge, 2001; Thurlow, 2003).1 Fur-
thermore, text messages are written in an informal
register; non-standard forms are used to reflect this,
and even for personal style (Thurlow, 2003). These
factors result in tremendous linguistic creativity, and
hence many novel lexical items, in the language of
text messaging, or texting language.
Normalization of non-standard forms—
converting non-standard forms to their standard
forms—is a challenge that must be tackled before
other types of natural language processing can
take place (Sproat et al., 2001). In the case of
text messages, text-to-speech synthesis may be
</bodyText>
<note confidence="0.977498">
1The number of characters in a text message may also be
limited to 160 characters, although this is not always the case.
</note>
<page confidence="0.711819">
71
</page>
<bodyText confidence="0.998968482758621">
particularly useful for the visually impaired; au-
tomatic translation has also been considered (e.g.,
Aw et al., 2006). For texting language, given the
abundance of creative forms, and the wide-ranging
possibilities for creating new forms, normalization
is a particularly important problem, and has indeed
received some attention in computational linguistics
(e.g., Aw et al., 2006; Choudhury et al., 2007;
Kobus et al., 2008).
In this paper we propose an unsupervised noisy
channel method for texting language normalization,
that gives performance on par with that of a super-
vised system. We pursue unsupervised approaches
to this problem, as large collections of text mes-
sages, and their corresponding standard forms, are
not readily available.2 Furthermore, other forms of
computer-mediated communication, such as Inter-
net messaging, exhibit creative phenomena similar
to text messaging, although at a lower frequency
(Ling and Baron, 2007). Moreover, technological
changes, such as new input devices, are likely to
have an impact on the language of such media (Thur-
low, 2003).3 An unsupervised approach, drawing
on linguistic properties of creative word formations,
has the potential to be adapted for normalization of
text in other similar genres—such as Internet dis-
cussion forums—without the cost of developing a
large training corpus. Moreover, normalization may
be particularly important for such genres, given the
</bodyText>
<note confidence="0.823016125">
2One notable exception is Fairon and Paumier (2006), al-
though this resource is in French. The resource used in our
study, Choudhury et al. (2007), is quite small in comparison.
3The rise of other technology, such as word prediction, could
reduce the use of abbreviations, although it’s not clear such
technology is widely used (Grinter and Eldridge, 2001).
Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 71–78,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.995345714285715">
Formation type Freq.
Stylistic variation 152
Subseq. abbrev. 111
Prefix clipping 24
Syll. letter/digit 19
G-clipping 14
Phonetic abbrev. 12
H-clipping 10
Spelling error 5
Suffix clipping 4
Punctuation 3
Unclear 34
Error 12
Total 400
</table>
<tableCaption confidence="0.997061">
Table 1: Frequency of texting forms in the development
set by formation type.
</tableCaption>
<bodyText confidence="0.997494333333333">
need for applications such as translation and ques-
tion answering.
We observe that many creative texting forms are
the result of a small number of specific word for-
mation processes. Rather than using a generic er-
ror model to capture all of them, we propose a mix-
ture model in which each word formation process is
modeled explicitly according to linguistic observa-
tions specific to that formation.
</bodyText>
<subsectionHeader confidence="0.493496">
2 Analysis of Texting Forms
</subsectionHeader>
<bodyText confidence="0.999290534482759">
To better understand the creative processes present
in texting language, we categorize the word forma-
tion process of each texting form in our development
data, which consists of 400 texting forms paired with
their standard forms.4 Several iterations of catego-
rization were done in order to determine sensible
categories, and ensure categories were used consis-
tently. Since this data is only to be used to guide
the construction of our system, and not for formal
evaluation, only one judge (a native English speak-
ing author of this paper) categorized the expressions.
The findings are presented in Table 1.
Stylistic variations, by far the most frequent cat-
egory, exhibit non-standard spelling, such as repre-
4Most texting forms have a unique standard form; however,
some have multiple standard forms, e.g., will and well can both
be shortened to wl. In such cases we choose the category of the
most frequent standard form; in the case of frequency ties we
choose arbitrarily among the categories of the standard forms.
senting sounds phonetically. Subsequence abbrevi-
ations, also very frequent, are composed of a sub-
sequence of the graphemes in a standard form, of-
ten omitting vowels. These two formation types ac-
count for approximately 66% of our development
data; the remaining formation types are much less
frequent. Prefix clippings and suffix clippings con-
sist of a prefix or suffix, respectively, of a standard
form, and in some cases a diminutive ending; we
also consider clippings which omit just a g or h from
a standard form as they are rather frequent.5 A sin-
gle letter or digit can be used to represent a syllable;
we refer to these as syllabic (syll.) letter/digit. Pho-
netic abbreviations are variants of clippings and sub-
sequence abbreviations where some sounds in the
standard form are represented phonetically. Several
texting forms appear to be spelling errors; we took
the layout of letters on cell phone keypads into ac-
count when making this judgement. The items that
did not fit within the above texting form categories
were marked as unclear. Finally, for some expres-
sions the given standard form did not appear to be
appropriate. For example, girl is not the standard
form for the texting form gal; rather, gal is an En-
glish word that is a colloquial form of girl. Such
cases were marked as errors.
No texting forms in our development data corre-
spond to multiple standard form words, e.g., wanna
for want to.6 Since such forms are not present in our
development data, we assume that a texting form al-
ways corresponds to a single standard form word.
It is important to note that some text forms have
properties of multiple categories, e.g., bak (back)
could be considered a stylistic variation or a subse-
quence abbreviation. In such cases, we simply at-
tempt to assign the most appropriate category.
The design of our model for text message normal-
ization, presented below, uses properties of the ob-
served formation processes.
</bodyText>
<sectionHeader confidence="0.84626" genericHeader="method">
3 An Unsupervised Noisy Channel Model
</sectionHeader>
<subsectionHeader confidence="0.747703">
for Text Message Normalization
</subsectionHeader>
<bodyText confidence="0.992208">
Let S be a sentence consisting of standard forms
s1s2...sn; in this study the standard forms are reg-
</bodyText>
<footnote confidence="0.869102333333333">
5Thurlow (2003) also observes an abundance of g-clippings.
6A small number of similar forms, however, appear with a
single standard form word, and are therefore marked as errors.
</footnote>
<figure confidence="0.942775071428571">
Example
betta (better)
dng (doing)
hol (holiday)
neway (anyway)
talkin (talking)
cuz (because)
ello (hello)
darliog (darling)
morrow (tomorrow)
b/day (birthday)
mobs (mobile)
gal (*girl)
72
</figure>
<bodyText confidence="0.995093857142857">
ular English words. Let T be a sequence of texting
forms t1t2...tn, which are the texting language real-
ization of the standard forms, and may differ from
the standard forms. Given a sequence of texting
forms T, the challenge is then to determine the cor-
responding standard forms S.
Following Choudhury et al. (2007)—and vari-
ous approaches to spelling error correction, such
as, e.g., Mays et al. (1991)—we model text mes-
sage normalization using a noisy channel. We
want to find argmaxSP(S|T). We apply Bayes
rule and ignore the constant term P(T), giving
argmaxSP(T |S)P(S). Making the independence
assumption that each ti depends only on si, and not
on the context in which it occurs, as in Choudhury
et al., we express P(T |S) as a product of probabili-
ties: argmaxS (Hi P(ti|si)) P(S).
We note in Section 2 that many texting forms are
created through a small number of specific word for-
mation processes. Rather than model each of these
processes at once using a generic model for P(ti|si),
as in Choudhury et al., we instead create several such
models, each corresponding to one of the observed
common word formation processes. We therefore
rewrite P(ti|si) as Ewf P(ti|si, wf )P(wf) where
wf is a word formation process, e.g., subsequence
abbreviation. Since, like Choudhury et al., we focus
on the word model, we simplify our model as below.
</bodyText>
<equation confidence="0.8698775">
�argmaxsi P(ti|si, wf )P(wf )P(si)
wf
</equation>
<bodyText confidence="0.999966">
We next explain the components of the model,
P(ti|si, wf ), P(wf ), and P(si), referred to as the
word model, word formation prior, and language
model, respectively.
</bodyText>
<subsectionHeader confidence="0.998342">
3.1 Word Models
</subsectionHeader>
<bodyText confidence="0.979511692307692">
We now consider which of the word formation pro-
cesses discussed in Section 2 should be captured
with a word model P (ti|si, wf ). We model stylis-
tic variations and subsequence abbreviations simply
due to their frequency. We also choose to model
prefix clippings since this word formation process is
common outside of text messaging (Kreidler, 1979;
Algeo, 1991) and fairly frequent in our data. Al-
though g-clippings and h-clippings are moderately
frequent, we do not model them, as these very spe-
cific word formations are also (non-prototypical)
graphemes w i th ou t
phonemes w z T au t
</bodyText>
<tableCaption confidence="0.983696">
Table 2: Grapheme–phoneme alignment for without.
</tableCaption>
<bodyText confidence="0.9999302">
subsequence abbreviations. We do not model syl-
labic letters and digits, or punctuation, explicitly; in-
stead, we simply substitute digits with a graphemic
representation (e.g., 4 is replaced by for), and re-
move punctuation, before applying the model. The
other less frequent formations—phonetic abbrevia-
tions, spelling errors, and suffix clippings—are not
modeled; we hypothesize that the similarity of these
formation processes to those we do model will allow
the system to perform reasonably well on them.
</bodyText>
<subsectionHeader confidence="0.779714">
3.1.1 Stylistic Variations
</subsectionHeader>
<bodyText confidence="0.999986935483871">
We propose a probabilistic version of edit-
distance—referred to here as edit-probability—
inspired by Brill and Moore (2000) to model
P(ti|si, stylistic variation). To compute edit-
probability, we consider the probability of each edit
operation—substitution, insertion, and deletion—
instead of its cost, as in edit-distance. We then sim-
ply multiply the probabilities of edits as opposed to
summing their costs.
In this version of edit-probability, we allow two-
character edits. Ideally, we would compute the edit-
probability of two strings as the sum of the edit-
probability of each partitioning of those strings into
one or two character segments. However, following
Brill and Moore, we approximate this by the prob-
ability of the partition with maximum probability.
This allows us to compute edit-probability using a
simple adaptation of edit-distance, in which we con-
sider edit operations spanning two characters at each
cell in the chart maintained by the algorithm.
We then estimate two probabilities: P(gt|gs, pos)
is the probability of texting form grapheme gt given
standard form grapheme gs at position pos, where
pos is the beginning, middle, or end of the word;
P(ht|ps, hs, pos) is the probability of texting form
graphemes ht given the standard form phonemes ps
and graphemes hs at position pos. ht, ps, and hs can
be a single grapheme or phoneme, or a bigram.
We compute edit-probability between the
graphemes of si and ti. When filling each cell
in the chart, we consider edit operations between
</bodyText>
<page confidence="0.704377">
73
</page>
<bodyText confidence="0.979300846153846">
segments of si and ti of length 0–2, referred to as a
and b, respectively. If a aligns with phonemes in si,
we also consider those phonemes, p. In our lexicon,
the graphemes and phonemes of each word are
aligned according to the method of Jiampojamarn
et al. (2007). For example, the alignment for
without is given in Table 2. The probability of
each edit operation is then determined by three
properties—the length of a, whether a aligns with
any phonemes in si, and if so, p—as shown below:
|a|= 0 or 1, not aligned w/ si phonemes: P(b|a, pos)
|a|= 2, not aligned w/ si phonemes: 0
|a|= 1 or 2, aligned w/ si phonemes: P(b|p, a, pos)
</bodyText>
<subsectionHeader confidence="0.68766">
3.1.2 Subsequence Abbreviations
</subsectionHeader>
<bodyText confidence="0.9995145">
We model subsequence abbreviations according
to the equation below:
</bodyText>
<equation confidence="0.9556906">
�
P(ti  |si, subseq abrv)
c if ti is a subseq of si
_
0 otherwise
</equation>
<bodyText confidence="0.996921882352941">
where c is a constant.
Note that this is similar to the error model for
spelling correction presented by Mays et al. (1991),
in which all words (in our terms, all si) within
a specified edit-distance of the out-of-vocabulary
word (ti in our model) are given equal probability.
The key difference is that in our formulation, we
only consider standard forms for which the texting
form is potentially a subsequence abbreviation.
In combination with the language model,
P(ti|si, subseq abbrev) assigns a non-zero prob-
ability to each standard form si for which ti is
a subsequence, according to the likelihood of si
(under the language model). The models interact
in this way since we expect a standard form to be
recognizable relative to the other words for which ti
could be a subsequence abbreviation
</bodyText>
<subsectionHeader confidence="0.534811">
3.1.3 Prefix Clippings
</subsectionHeader>
<bodyText confidence="0.9468865">
We model prefix clippings similarly to subse-
quence abbreviations.
{ c if ti is possible
pre. clip. of si
</bodyText>
<sectionHeader confidence="0.548676" genericHeader="method">
0 otherwise
</sectionHeader>
<bodyText confidence="0.999331076923077">
Kreidler (1979) observes that clippings tend to be
mono-syllabic and end in a consonant. Further-
more, when they do end in a vowel, it is often
of a regular form, such as telly for television and
breaky for breakfast. We therefore only consider
P(ti|si, prefix clipping) if ti is a prefix clipping ac-
cording to the following heuristics: ti is mono-
syllabic after stripping any word-final vowels, and
subsequently removing duplicated word-final con-
sonants (e.g, telly becomes tel, which is a candidate
prefix clipping). If ti is not a prefix clipping accord-
ing to these criteria, P(ti|si) simply sums over all
models except prefix clipping.
</bodyText>
<subsectionHeader confidence="0.998623">
3.2 Word Formation Prior
</subsectionHeader>
<bodyText confidence="0.9999886">
Keeping with our goal of an unsupervised method,
we estimate P(wf ) with a uniform distribution. We
also consider estimating P(wf ) using maximum
likelihood estimates (MLEs) from our observations
in Section 2. This gives a model that is not fully
unsupervised, since it relies on labelled training
data. However, we consider this a lightly-supervised
method, since it only requires an estimate of the fre-
quency of the relevant word formation types, and not
labelled texting form–standard form pairs.
</bodyText>
<subsectionHeader confidence="0.977783">
3.3 Language Model
</subsectionHeader>
<bodyText confidence="0.999969636363636">
Choudhury et al. (2007) find that using a bigram lan-
guage model estimated over a balanced corpus of
English had a negative effect on their results com-
pared with a unigram language model, which they
attribute to the unique characteristics of text messag-
ing that were not reflected in the corpus. We there-
fore use a unigram language model for P(si), which
also enables comparison with their results. Never-
theless, alternative language models, such as higher
order ngram models, could easily be used in place of
our unigram language model.
</bodyText>
<sectionHeader confidence="0.995169" genericHeader="method">
4 Materials and Methods
</sectionHeader>
<subsectionHeader confidence="0.844788">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.9999815">
We use the data provided by Choudhury et al. (2007)
which consists of texting forms—extracted from a
collection of 900 text messages—and their manu-
ally determined standard forms. Our development
data—used for model development and discussed in
Section 2—consists of the 400 texting form types
that are not in Choudhury et al.’s held-out test set,
and that are not the same as one of their standard
</bodyText>
<equation confidence="0.69317">
P(ti|si, prefix clipping) _
74
</equation>
<bodyText confidence="0.9996384">
forms. The test data consists of 1213 texting forms
and their corresponding standard forms. A subset of
303 of these texting forms differ from their standard
form.7 This subset is the focus of this study, but we
also report results on the full dataset.
</bodyText>
<subsectionHeader confidence="0.976354">
4.2 Lexicon
</subsectionHeader>
<bodyText confidence="0.9999859">
We construct a lexicon of potential standard forms
such that it contains most words that we expect to
encounter in text messages, yet is not so large as
to make it difficult to identify the correct standard
form. Our subjective analysis of the standard forms
in the development data is that they are frequent,
non-specialized, words. To reflect this observation,
we create a lexicon consisting of all single-word en-
tries containing only alphabetic characters found in
both the CELEX Lexical Database (Baayen et al.,
1995) and the CMU Pronouncing Dictionary.8 We
remove all words of length one (except a and I) to
avoid choosing, e.g., the letter r as the standard form
for the texting form r. We further limit the lexicon
to words in the 20K most frequent alphabetic uni-
grams, ignoring case, in the Web 1T 5-gram Corpus
(Brants and Franz, 2006). The resulting lexicon con-
tains approximately 14K words, and excludes only
three of the standard forms—cannot, email, and on-
line—for the 400 development texting forms.
</bodyText>
<subsectionHeader confidence="0.999504">
4.3 Model Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.9969965">
MLEs for P(gt|gs,pos)—needed to estimate
P(ti|si, stylistic variation)—could be estimated
from texting form–standard form pairs. However,
since our system is unsupervised, no such data is
available. We therefore assume that many texting
forms, and other similar creative shortenings, occur
on the web. We develop a number of character
substitution rules, e.g., s ⇒ z, and use them to create
hypothetical texting forms from standard words.
We then compute MLEs for P(gt|gs, pos) using the
frequencies of these derived forms on the web.
7Choudhury et al. report that this dataset contains 1228 tex-
ting forms. We found it to contain 1213 texting forms cor-
responding to 1228 standard forms (recall that a texting form
may have multiple standard forms). There were similar incon-
sistencies with the subset of texting forms that differ from their
standard forms. Nevertheless, we do not expect these small dif-
ferences to have an appreciable effect on the results.
</bodyText>
<equation confidence="0.433721">
8http://www.speech.cs.cmu.edu/cgi-bin/
cmudict
</equation>
<bodyText confidence="0.998577481481481">
We create the substitution rules by examining ex-
amples in the development data, considering fast
speech variants and dialectal differences (e.g., voic-
ing), and drawing on our intuition. The derived
forms are produced by applying the substitution
rules to the words in our lexicon. To avoid con-
sidering forms that are themselves words, we elimi-
nate any form found in a list of approximately 480K
words taken from SOWPODS9 and the Moby Word
Lists.10 Finally, we obtain the frequency of the de-
rived forms from the Web 1T 5-gram Corpus.
To estimate P(ht|ps, hs, pos), we first esti-
mate two simpler distributions: P(ht|hs, pos) and
P(ht|ps, pos). P(ht|hs, pos) is estimated in the
same manner as P(gt|gs, pos), except that two char-
acter substitutions are allowed. P (ht|ps, pos) is es-
timated from the frequency of ps, and its align-
ment with ht, in a version of CELEX in which
the graphemic and phonemic representation of each
word is many–many aligned using the method of
Jiampojamarn et al. (2007).11 P(ht|ps, hs, pos)
is then an evenly-weighted linear combination of
P(ht|hs, pos) and P(ht|ps, pos). Finally, we
smooth each of P(gt|gs, pos) and P(ht|ps, hs, pos)
using add-alpha smoothing.
We set the constant c in our word models for
subsequence abbreviations and prefix clippings such
</bodyText>
<construct confidence="0.5686565">
that Esz P(ti|si, wf )P(si) = 1. We similarly nor-
malize P(ti|si, stylistic variation)P(si).
</construct>
<bodyText confidence="0.9999652">
We use the frequency of unigrams (ignoring case)
in the Web 1T 5-gram Corpus to estimate our lan-
guage model. We expect the language of text mes-
saging to be more similar to that found on the web
than that in a balanced corpus of English.
</bodyText>
<subsectionHeader confidence="0.990919">
4.4 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99964">
To evaluate our system, we consider three accuracy
metrics: in-top-1, in-top-10, and in-top-20.12 In-
top-n considers the system correct if a correct stan-
dard form is in the n most probable standard forms.
The in-top-1 accuracy shows how well the system
determines the correct standard form; the in-top-10
</bodyText>
<footnote confidence="0.690324">
9http://en.wikipedia.org/wiki/SOWPODS
10http://icon.shef.ac.uk/Moby/
</footnote>
<bodyText confidence="0.820064">
11We are very grateful to Sittichai Jiampojamarn for provid-
ing this alignment.
12These are the same metrics used by Choudhury et al.
(2007), although we refer to them by different names.
</bodyText>
<page confidence="0.782091">
75
</page>
<table confidence="0.9812434">
Model % accuracy
Top-1 Top-10 Top-20
Uniform 59.4 83.8 87.8
MLE 55.4 84.2 86.5
Choudhury et al. 59.9 84.3 88.7
</table>
<tableCaption confidence="0.931488333333333">
Table 3: % in-top-1, in-top-10, and in-top-20 accuracy
on test data using both estimates for P(wf ). The results
reported by Choudhury et al. (2007) are also shown.
</tableCaption>
<bodyText confidence="0.999942">
and in-top-20 accuracies may be indicative of the
usefulness of the output of our system in other tasks
which could exploit a ranked list of standard forms,
such as machine translation.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999866137931034">
In Table 3 we report the results of our system using
both the uniform estimate and the MLE of P(wf ).
Note that there is no meaningful random baseline
to compare against here; randomly ordering the
14K words in our lexicon gives very low accuracy.
The results using the uniform estimate of P(wf )—
a fully unsupervised system—are very similar to
the supervised results of Choudhury et al. (2007).
Surprisingly, when we estimate P(wf ) using MLEs
from the development data—resulting in a lightly-
supervised system—the results are slightly worse
than when using the uniform estimate of this proba-
bility. Moreover, we observe the same trend on de-
velopment data where we expect to have an accurate
estimate of P(wf ) (results not shown). We hypothe-
size that the ambiguity of the categories of text forms
(see Section 2) results in poor MLEs for P(wf ),
thus making a uniform distribution, and hence fully-
unsupervised approach, more appropriate.
Results by Formation Type We now consider in-
top-1 accuracy for each word formation type, in Ta-
ble 4. We show results for the same word forma-
tion processes as in Table 1, except for h-clippings
and punctuation, as no words of these categories are
present in the test data. We present results using the
same experimental setup as before with a uniform
estimate of P(wf ) (All), and using just the model
corresponding to the word formation process (Spe-
cific), where applicable.13
</bodyText>
<table confidence="0.927834">
13In this case our model then becomes, for each word forma-
tionprocess wf , argmaxs,P(ti|si, wf)P(si).
Formation type Freq. % in-top-1 acc.
n = 303 Specific All
Stylistic variation 121 62.8 67.8
Subseq. abbrev. 65 56.9 46.2
Prefix clipping 25 44.0 20.0
G-clipping 56 - 91.1
Syll. letter/digit 16 - 50.0
Unclear 12 - 0.0
Spelling error 5 - 80.0
Suffix clipping 1 - 0.0
Phonetic abbrev. 1 - 0.0
Error 1 - 0.0
</table>
<tableCaption confidence="0.9704885">
Table 4: Frequency (Freq.), and % in-top-1 accuracy us-
ing the formation-specific model where applicable (Spe-
cific) and all models (All) with a uniform estimate for
P(wf ), presented by formation type.
</tableCaption>
<bodyText confidence="0.993533597402598">
We first examine the top panel of Table 3 where
we compare the performance on each word forma-
tion type for both experimental conditions (Specific
and All). We first note that the performance using
the formation-specific model on subsequence abbre-
viations and prefix clippings is better than that of
the overall model. This is unsurprising since we ex-
pect that when we know a texting form’s formation
process, and invoke a corresponding specific model,
our system should outperform a model designed to
handle a range of formation types. However, this is
not the case for stylistic variations; here the over-
all model performs better than the specific model.
We observed in Section 2 that some texting forms
do not fit neatly into our categorization scheme; in-
deed, many stylistic variations are also analyzable
as subsequence abbreviations. Therefore, the subse-
quence abbreviation model may benefit normaliza-
tion of stylistic variations. This model, used in iso-
lation on stylistic variations, gives an in-top-1 accu-
racy of 33.1%, indicating that this may be the case.
Comparing the performance of the individual
word models on only word types that they were de-
signed for (column Specific in Table 4), we see that
the prefix clipping model is by far the lowest, in-
dicating that in the future we should consider ways
of improving this word model. One possibility is
to incorporate phonemic knowledge. For example,
both friday and friend have the same probability un-
76
der P(ti|si, prefix clipping) for the texting form fri,
which has the standard form friday in our data. (The
language model, however, does distinguish between
these forms.) However, if we consider the phonemic
representations of these words, friday might emerge
as more likely. Syllable structure information may
also be useful, as we hypothesize that clippings will
tend to be formed by truncating a word at a syllable
boundary. We may similarly be able to improve our
estimate of P(ti|si, subseq. abrrev.). For example,
both text and taxation have the same probability un-
der this distribution, but intuitively text, the correct
standard form in our data, seems more likely. We
could incorporate knowledge about the likelihood of
omitting specific characters, as in Choudhury et al.
(2007), to improve this estimate.
We now examine the lower panel of Table 4, in
which we consider the performance of the overall
model on the word formation types that are not ex-
plicitly modeled. The very high accuracy on g-
clippings indicates that since these forms are also a
type of subsequence abbreviation, we do not need to
construct a separate model for them. We in fact also
conducted experiments in which g-clippings and h-
clippings were modeled explicitly, but found these
extra models to have little effect on the results.
Recall from Section 3.1 our hypothesis that suf-
fix clippings, spelling errors, and phonetic abbrevia-
tions have common properties with formation types
that we do model, and therefore the system will per-
form reasonably well on them. Here we find pre-
liminary evidence to support this hypothesis as the
accuracy on these three word formation types (com-
bined) is 57.1%. However, we must interpret this
result cautiously as it only considers seven expres-
sions. On the syllabic letter and digit texting forms
the accuracy is 50.0%, indicating that our heuris-
tic to replace digits in texting forms with an ortho-
graphic representation is reasonable.
The performance on types of expressions that
we did not consider when designing the system—
unclear and error—is very poor. However, this has
little impact on the overall performance as these ex-
pressions are rather infrequent.
Results by Model We now consider in-top-1 ac-
curacy using each model on the 303 test expres-
sions; results are shown in Table 5. No model on its
</bodyText>
<table confidence="0.8847765">
Model % in-top-1 accuracy
Stylistic variation 51.8
Subseq. Abbrev. 44.2
Prefix clipping 10.6
</table>
<tableCaption confidence="0.990975">
Table 5: % in-top-1 accuracy on the 303 test expressions
using each model individually.
</tableCaption>
<bodyText confidence="0.99993740625">
own gives results comparable to those of the over-
all model (59.4%, see Table 3). This indicates that
the overall model successfully combines informa-
tion from the specific word formation models.
Each model used on its own gives an accuracy
greater than the proportion of expressions of the
word formation type for which the model was de-
signed (compare accuracies in Table 5 to the num-
ber of expressions of the corresponding word forma-
tion type in the test data in Table 4). As we note in
Section 2, the distinctions between the word forma-
tion types are not sharp; these results show that the
shared properties of word formation types enable a
model for a specific formation type to infer the stan-
dard form of texting forms of other formation types.
All Unseen Data Until now we have discussed re-
sults on our test data of 303 texting forms which dif-
fer from their standard forms. We now consider the
performance of our system on all 1213 unseen tex-
ting forms, 910 of which are identical to their stan-
dard form. Since our model was not designed with
such expressions in mind, we slightly adapt it for
this new task; if ti is in our lexicon, we return that
form as si, otherwise we apply our model as usual,
using the uniform estimate of P(wf ). This gives
an in-top-1 accuracy of 88.2%, which is very sim-
ilar to the results of Choudhury et al. (2007) on this
data of 89.1%. Note, however, that Choudhury et al.
only report results on this dataset using a uniform
language model;14 since we use a unigram language
model, it is difficult to draw firm conclusions about
the performance of our system relative to theirs.
</bodyText>
<sectionHeader confidence="0.999966" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9699336">
Aw et al. (2006) model text message normaliza-
tion as translation from the texting language into the
14Choudhury et al. do use a unigram language model for their
experiments on the 303 texting forms which differ from their
standard forms (see Section 3.3).
</bodyText>
<page confidence="0.766802">
77
</page>
<bodyText confidence="0.999951714285714">
standard language. Kobus et al. (2008) incorporate
ideas from both machine translation and automatic
speech recognition for text message normalization.
However, both of these approaches are supervised,
and have only limited means for normalizing texting
forms that do not occur in the training data.
Our work, like that of Choudhury et al. (2007),
can be viewed as a noisy-channel model for spelling
error correction (e.g., Mays et al., 1991; Brill and
Moore, 2000), in which texting forms are seen as
a kind of spelling error. Furthermore, like our ap-
proach to text message normalization, approaches to
spelling correction have incorporated phonemic in-
formation (Toutanova and Moore, 2002).
The word model of the supervised approach of
Choudhury et al. consists of hidden Markov models,
which capture properties of texting language similar
to those of our stylistic variation model. We pro-
pose multiple word models—corresponding to fre-
quent texting language formation processes—and an
unsupervised method for parameter estimation.
</bodyText>
<sectionHeader confidence="0.99949" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999991777777778">
We analyze a sample of texting forms to determine
frequent word formation processes in creative tex-
ting language. Drawing on these observations, we
construct an unsupervised noisy-channel model for
text message normalization. On an unseen test set
of 303 texting forms that differ from their standard
form, our model achieves 59% accuracy, which is on
par with that obtained by the supervised approach of
Choudhury et al. (2007) on the same data.
More research is required to determine the impact
of our normalization method on the performance of
a system that further processes the resulting text. In
the future, we intend to improve our word models by
incorporating additional linguistic knowledge, such
as information about syllable structure. Since con-
text likely plays a role in human interpretation of
texting forms, we also intend to examine the perfor-
mance of higher order ngram language models.
</bodyText>
<sectionHeader confidence="0.997285" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9952915">
This work is financially supported by the Natu-
ral Sciences and Engineering Research Council of
Canada, the University of Toronto, and the Dictio-
nary Society of North America.
</bodyText>
<sectionHeader confidence="0.998034" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999736407407408">
John Algeo, editor. 1991. Fifty Years Among the New
Words. Cambridge University Press, Cambridge.
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A
phrase-based statistical model for SMS text normaliza-
tion. In Proc. of the COLING/ACL 2006 Main Confer-
ence Poster Sessions, pages 33–40. Sydney.
R.H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The
CELEX Lexical Database (release 2). Linguistic Data
Consortium, University of Pennsylvania.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
Corpus version 1.1.
Eric Brill and Robert C. Moore. 2000. An improved error
model for noisy channel spelling correction. In Pro-
ceedings ofACL 2000, pages 286–293. Hong Kong.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar, and Anupam Basu.
2007. Investigation and modeling of the structure of
texting language. International Journal of Document
Analysis and Recognition, 10(3/4):157–174.
C´edrick Fairon and S´ebastien Paumier. 2006. A trans-
lated corpus of 30,000 French SMS. In Proceedings of
LREC 2006. Genoa, Italy.
Rebecca E. Grinter and Margery A. Eldridge. 2001. y do
tngrs luv 2 txt msg. In Proceedings of the 7th Euro-
pean Conf. on Computer-Supported Cooperative Work
(ECSCW ’01), pages 219–238. Bonn, Germany.
Sittichai Jiampojamarn, Gregorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments and
hidden markov models to letter-to-phoneme conver-
sion. In Proc. of NAACL-HLT 2007, pages 372–379.
Rochester, NY.
Catherine Kobus, Franc¸ois Yvon, and G´eraldine
Damnati. 2008. Normalizing SMS: are two metaphors
better than one? In Proc. of the 22nd Int. Conf. on
Computational Linguistics, pp. 441–448. Manchester.
Charles W. Kreidler. 1979. Creating new words by short-
ening. English Linguistics, 13:24–36.
Rich Ling and Naomi S. Baron. 2007. Text messaging
and IM: Linguistic comparison of American college
data. Journal of Language and Social Psychology,
26:291–98.
Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991.
Context based spelling correction. Information Pro-
cessing and Management, 27(5):517–522.
Richard Sproat, Alan W. Black, Stanley Chen, Shankar
Kumar, Mari Ostendorf, and Christopher Richards.
2001. Normalization of non-standard words. Com-
puter Speech and Language, 15:287–333.
Crispin Thurlow. 2003. Generation txt? The sociolin-
guistics of young people’s text-messaging. Discourse
Analysis Online, 1(1).
Kristina Toutanova and Robert C. Moore. 2002. Pronun-
ciation modeling for improved spelling correction. In
Proc. ofACL 2002, pages 144–151. Philadelphia.
</reference>
<page confidence="0.919945">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000032">
<title confidence="0.999963">An Unsupervised Model for Text Message Normalization</title>
<author confidence="0.997739">Paul</author>
<affiliation confidence="0.872672666666667">Department of Computer University of Toronto,</affiliation>
<email confidence="0.999577">pcook@cs.toronto.edu</email>
<author confidence="0.940186">Suzanne</author>
<affiliation confidence="0.875508666666667">Department of Computer University of Toronto,</affiliation>
<email confidence="0.999902">suzanne@cs.toronto.edu</email>
<abstract confidence="0.999310117647059">Cell phone text messaging users express themselves briefly and colloquially using a variety of creative forms. We analyze a sample of creative, non-standard text message word forms to determine frequent word formation processes in texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normal- On a test set of message forms that differ from their standard form, our achieves accuracy, which is on par with the best supervised results reported on this dataset. 1 Text Messaging Cell phone text messages—or SMS—contain many shortened and non-standard forms due to a variety of factors, particularly the desire for rapid text entry and Eldridge, 2001; Thurlow, Furthermore, text messages are written in an informal register; non-standard forms are used to reflect this, and even for personal style (Thurlow, 2003). These factors result in tremendous linguistic creativity, and hence many novel lexical items, in the language of messaging, or Normalization of non-standard forms— converting non-standard forms to their standard forms—is a challenge that must be tackled before other types of natural language processing can take place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be number of characters in a text message may also be to although this is not always the case. 71 particularly useful for the visually impaired; automatic translation has also been considered (e.g., Aw et al., 2006). For texting language, given the abundance of creative forms, and the wide-ranging possibilities for creating new forms, normalization is a particularly important problem, and has indeed received some attention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus et al., 2008). In this paper we propose an unsupervised noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms, are readily Furthermore, other forms of computer-mediated communication, such as Internet messaging, exhibit creative phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, are likely to have an impact on the language of such media (Thur- An unsupervised approach, drawing on linguistic properties of creative word formations, has the potential to be adapted for normalization of text in other similar genres—such as Internet discussion forums—without the cost of developing a large training corpus. Moreover, normalization may be particularly important for such genres, given the notable exception is Fairon and Paumier (2006), although this resource is in French. The resource used in our study, Choudhury et al. (2007), is quite small in comparison. rise of other technology, such as word prediction, could reduce the use of abbreviations, although it’s not clear such</abstract>
<note confidence="0.904974">technology is widely used (Grinter and Eldridge, 2001). of the NAACL HLT Workshop on Computational Approaches to Linguistic pages 71–78, Colorado, June 2009. Association for Computational Linguistics Formation type Freq. Stylistic variation 152 Subseq. abbrev. 111 Prefix clipping 24 Syll. letter/digit 19 G-clipping 14 Phonetic abbrev. 12 H-clipping 10 Spelling error 5 Suffix clipping 4 Punctuation 3 Unclear 34 Error 12 Total 400 Table 1: Frequency of texting forms in the development</note>
<abstract confidence="0.99786535221239">set by formation type. need for applications such as translation and question answering. We observe that many creative texting forms are the result of a small number of specific word formation processes. Rather than using a generic error model to capture all of them, we propose a mixture model in which each word formation process is modeled explicitly according to linguistic observations specific to that formation. 2 Analysis of Texting Forms To better understand the creative processes present in texting language, we categorize the word formation process of each texting form in our development which consists of forms paired with standard Several iterations of categorization were done in order to determine sensible categories, and ensure categories were used consistently. Since this data is only to be used to guide the construction of our system, and not for formal evaluation, only one judge (a native English speaking author of this paper) categorized the expressions. The findings are presented in Table 1. Stylistic variations, by far the most frequent catexhibit non-standard spelling, such as repretexting forms have a unique standard form; however, have multiple standard forms, e.g., both shortened to In such cases we choose the category of the most frequent standard form; in the case of frequency ties we choose arbitrarily among the categories of the standard forms. senting sounds phonetically. Subsequence abbreviations, also very frequent, are composed of a subsequence of the graphemes in a standard form, often omitting vowels. These two formation types acfor approximately of our development data; the remaining formation types are much less frequent. Prefix clippings and suffix clippings consist of a prefix or suffix, respectively, of a standard form, and in some cases a diminutive ending; we consider clippings which omit just a standard form as they are rather A single letter or digit can be used to represent a syllable; we refer to these as syllabic (syll.) letter/digit. Phonetic abbreviations are variants of clippings and subsequence abbreviations where some sounds in the standard form are represented phonetically. Several texting forms appear to be spelling errors; we took the layout of letters on cell phone keypads into account when making this judgement. The items that did not fit within the above texting form categories were marked as unclear. Finally, for some expressions the given standard form did not appear to be For example, not the standard for the texting form rather, an Enword that is a colloquial form of Such cases were marked as errors. No texting forms in our development data correto multiple standard form words, e.g., Since such forms are not present in our development data, we assume that a texting form always corresponds to a single standard form word. It is important to note that some text forms have of multiple categories, e.g., could be considered a stylistic variation or a subsequence abbreviation. In such cases, we simply attempt to assign the most appropriate category. The design of our model for text message normalization, presented below, uses properties of the observed formation processes. 3 An Unsupervised Noisy Channel Model for Text Message Normalization a sentence consisting of forms in this study the standard forms are reg- (2003) also observes an abundance of g-clippings. small number of similar forms, however, appear with a single standard form word, and are therefore marked as errors. Example 72 English words. Let a sequence of which are the texting language realization of the standard forms, and may differ from the standard forms. Given a sequence of texting the challenge is then to determine the corstandard forms Following Choudhury et al. (2007)—and various approaches to spelling error correction, such as, e.g., Mays et al. (1991)—we model text message normalization using a noisy channel. We to find We apply Bayes and ignore the constant term giving Making the independence that each only on and not on the context in which it occurs, as in Choudhury al., we express a product of probabili- We note in Section 2 that many texting forms are created through a small number of specific word formation processes. Rather than model each of these at once using a generic model for as in Choudhury et al., we instead create several such models, each corresponding to one of the observed common word formation processes. We therefore a word formation process, e.g., subsequence abbreviation. Since, like Choudhury et al., we focus on the word model, we simplify our model as below. wf We next explain the components of the model, and referred to as the word model, word formation prior, and language model, respectively. 3.1 Word Models We now consider which of the word formation processes discussed in Section 2 should be captured a word model We model stylistic variations and subsequence abbreviations simply due to their frequency. We also choose to model prefix clippings since this word formation process is common outside of text messaging (Kreidler, 1979; Algeo, 1991) and fairly frequent in our data. Although g-clippings and h-clippings are moderately frequent, we do not model them, as these very specific word formations are also (non-prototypical) graphemes w i th ou z T au t 2: Grapheme–phoneme alignment for subsequence abbreviations. We do not model syllabic letters and digits, or punctuation, explicitly; instead, we simply substitute digits with a graphemic (e.g., replaced by and remove punctuation, before applying the model. The other less frequent formations—phonetic abbreviations, spelling errors, and suffix clippings—are not modeled; we hypothesize that the similarity of these formation processes to those we do model will allow the system to perform reasonably well on them. 3.1.1 Stylistic Variations We propose a probabilistic version of editdistance—referred to here as edit-probability— inspired by Brill and Moore (2000) to model To compute probability, we consider the probability of each edit operation—substitution, insertion, and deletion— instead of its cost, as in edit-distance. We then simply multiply the probabilities of edits as opposed to summing their costs. In this version of edit-probability, we allow twocharacter edits. Ideally, we would compute the editprobability of two strings as the sum of the editprobability of each partitioning of those strings into one or two character segments. However, following Brill and Moore, we approximate this by the probability of the partition with maximum probability. This allows us to compute edit-probability using a simple adaptation of edit-distance, in which we consider edit operations spanning two characters at each cell in the chart maintained by the algorithm. then estimate two probabilities: the probability of texting form grapheme form grapheme at position where the beginning, middle, or end of the word; the probability of texting form the standard form phonemes graphemes at position and can be a single grapheme or phoneme, or a bigram. We compute edit-probability between the of When filling each cell in the chart, we consider edit operations between 73 of length referred to as respectively. If with phonemes in also consider those phonemes, In our lexicon, the graphemes and phonemes of each word are aligned according to the method of Jiampojamarn et al. (2007). For example, the alignment for given in Table 2. The probability of each edit operation is then determined by three length of whether with phonemes in and if so, shown below: not aligned w/ not aligned w/ aligned w/ a, 3.1.2 Subsequence Abbreviations We model subsequence abbreviations according to the equation below: � a subseq of _ a constant. Note that this is similar to the error model for spelling correction presented by Mays et al. (1991), which all words (in our terms, all within a specified edit-distance of the out-of-vocabulary our model) are given equal probability. The key difference is that in our formulation, we only consider standard forms for which the texting form is potentially a subsequence abbreviation. In combination with the language model, a non-zero probto each standard form which subsequence, according to the likelihood of (under the language model). The models interact in this way since we expect a standard form to be relative to the other words for which could be a subsequence abbreviation 3.1.3 Prefix Clippings We model prefix clippings similarly to subsequence abbreviations. possible clip. of Kreidler (1979) observes that clippings tend to be and end in a consonant. Furthermore, when they do end in a vowel, it is often a regular form, such as We therefore only consider a prefix clipping acto the following heuristics: monosyllabic after stripping any word-final vowels, and subsequently removing duplicated word-final con- (e.g, which is a candidate clipping). If not a prefix clipping accordto these criteria, sums over all models except prefix clipping. 3.2 Word Formation Prior Keeping with our goal of an unsupervised method, estimate a uniform distribution. We consider estimating maximum likelihood estimates (MLEs) from our observations in Section 2. This gives a model that is not fully unsupervised, since it relies on labelled training data. However, we consider this a lightly-supervised method, since it only requires an estimate of the frequency of the relevant word formation types, and not labelled texting form–standard form pairs. 3.3 Language Model Choudhury et al. (2007) find that using a bigram language model estimated over a balanced corpus of English had a negative effect on their results compared with a unigram language model, which they attribute to the unique characteristics of text messaging that were not reflected in the corpus. We thereuse a unigram language model for which also enables comparison with their results. Nevertheless, alternative language models, such as higher order ngram models, could easily be used in place of our unigram language model. 4 Materials and Methods 4.1 Datasets We use the data provided by Choudhury et al. (2007) which consists of texting forms—extracted from a of messages—and their manually determined standard forms. Our development data—used for model development and discussed in 2—consists of the form types that are not in Choudhury et al.’s held-out test set, and that are not the same as one of their standard _ 74 The test data consists of forms and their corresponding standard forms. A subset of these texting forms differ from their standard This subset is the focus of this study, but we also report results on the full dataset. 4.2 Lexicon We construct a lexicon of potential standard forms such that it contains most words that we expect to encounter in text messages, yet is not so large as to make it difficult to identify the correct standard form. Our subjective analysis of the standard forms in the development data is that they are frequent, non-specialized, words. To reflect this observation, we create a lexicon consisting of all single-word entries containing only alphabetic characters found in both the CELEX Lexical Database (Baayen et al., and the CMU Pronouncing We all words of length one (except to choosing, e.g., the letter the standard form the texting form We further limit the lexicon words in the most frequent alphabetic unigrams, ignoring case, in the Web 1T 5-gram Corpus (Brants and Franz, 2006). The resulting lexicon contains approximately 14K words, and excludes only of the standard and onthe texting forms. 4.3 Model Parameter Estimation for to estimate be estimated from texting form–standard form pairs. However, since our system is unsupervised, no such data is available. We therefore assume that many texting forms, and other similar creative shortenings, occur on the web. We develop a number of character rules, e.g., and use them to create hypothetical texting forms from standard words. then compute MLEs for the frequencies of these derived forms on the web. et al. report that this dataset contains texforms. We found it to contain forms corto forms (recall that a texting form may have multiple standard forms). There were similar inconsistencies with the subset of texting forms that differ from their standard forms. Nevertheless, we do not expect these small differences to have an appreciable effect on the results. cmudict We create the substitution rules by examining examples in the development data, considering fast speech variants and dialectal differences (e.g., voicing), and drawing on our intuition. The derived forms are produced by applying the substitution rules to the words in our lexicon. To avoid considering forms that are themselves words, we elimiany form found in a list of approximately taken from and the Moby Word Finally, we obtain the frequency of the derived forms from the Web 1T 5-gram Corpus. estimate we first estitwo simpler distributions: estimated in the manner as except that two charsubstitutions are allowed. esfrom the frequency of and its alignwith in a version of CELEX in which the graphemic and phonemic representation of each word is many–many aligned using the method of et al. is then an evenly-weighted linear combination of Finally, each of using add-alpha smoothing. set the constant our word models for subsequence abbreviations and prefix clippings such = We similarly nor- We use the frequency of unigrams (ignoring case) in the Web 1T 5-gram Corpus to estimate our language model. We expect the language of text messaging to be more similar to that found on the web than that in a balanced corpus of English. 4.4 Evaluation Metrics To evaluate our system, we consider three accuracy and Inthe system correct if a correct stanform is in the probable standard forms. shows how well the system the correct standard form; the are very grateful to Sittichai Jiampojamarn for providing this alignment. are the same metrics used by Choudhury et al. (2007), although we refer to them by different names. 75 Model % accuracy et al. 3: % and test data using both estimates for The results reported by Choudhury et al. (2007) are also shown. may be indicative of the usefulness of the output of our system in other tasks which could exploit a ranked list of standard forms, such as machine translation. 5 Results and Discussion In Table 3 we report the results of our system using the uniform estimate and the MLE of Note that there is no meaningful random baseline to compare against here; randomly ordering the words in our lexicon gives very low accuracy. results using the uniform estimate of a fully unsupervised system—are very similar to the supervised results of Choudhury et al. (2007). when we estimate MLEs from the development data—resulting in a lightlysupervised system—the results are slightly worse than when using the uniform estimate of this probability. Moreover, we observe the same trend on development data where we expect to have an accurate of not shown). We hypothesize that the ambiguity of the categories of text forms Section 2) results in poor MLEs for thus making a uniform distribution, and hence fullyunsupervised approach, more appropriate. by Formation Type now consider infor each word formation type, in Table 4. We show results for the same word formation processes as in Table 1, except for h-clippings and punctuation, as no words of these categories are present in the test data. We present results using the same experimental setup as before with a uniform of and using just the model corresponding to the word formation process (Spewhere this case our model then becomes, for each word forma- Formation type Freq. 303 Specific All Stylistic variation 121 Subseq. abbrev. 65 Prefix clipping 25 G-clipping 56 Syll. letter/digit 16 Unclear 12 Spelling error 5 Suffix clipping 1 Phonetic abbrev. 1 Error 1 4: Frequency (Freq.), and % using the formation-specific model where applicable (Specific) and all models (All) with a uniform estimate for presented by formation type. We first examine the top panel of Table 3 where we compare the performance on each word formation type for both experimental conditions (Specific and All). We first note that the performance using the formation-specific model on subsequence abbreviations and prefix clippings is better than that of the overall model. This is unsurprising since we expect that when we know a texting form’s formation process, and invoke a corresponding specific model, our system should outperform a model designed to handle a range of formation types. However, this is not the case for stylistic variations; here the overall model performs better than the specific model. We observed in Section 2 that some texting forms do not fit neatly into our categorization scheme; indeed, many stylistic variations are also analyzable as subsequence abbreviations. Therefore, the subsequence abbreviation model may benefit normalization of stylistic variations. This model, used in isoon stylistic variations, gives an accuof indicating that this may be the case. Comparing the performance of the individual word models on only word types that they were designed for (column Specific in Table 4), we see that the prefix clipping model is by far the lowest, indicating that in the future we should consider ways of improving this word model. One possibility is to incorporate phonemic knowledge. For example, the same probability un- 76 the texting form has the standard form our data. (The language model, however, does distinguish between these forms.) However, if we consider the phonemic of these words, emerge as more likely. Syllable structure information may also be useful, as we hypothesize that clippings will tend to be formed by truncating a word at a syllable boundary. We may similarly be able to improve our of For example, the same probability unthis distribution, but intuitively the correct standard form in our data, seems more likely. We could incorporate knowledge about the likelihood of omitting specific characters, as in Choudhury et al. (2007), to improve this estimate. We now examine the lower panel of Table 4, in which we consider the performance of the overall model on the word formation types that are not explicitly modeled. The very high accuracy on gclippings indicates that since these forms are also a type of subsequence abbreviation, we do not need to construct a separate model for them. We in fact also conducted experiments in which g-clippings and hclippings were modeled explicitly, but found these extra models to have little effect on the results. Recall from Section 3.1 our hypothesis that suffix clippings, spelling errors, and phonetic abbreviations have common properties with formation types that we do model, and therefore the system will perform reasonably well on them. Here we find preliminary evidence to support this hypothesis as the accuracy on these three word formation types (comis However, we must interpret this result cautiously as it only considers seven expressions. On the syllabic letter and digit texting forms accuracy is indicating that our heuristic to replace digits in texting forms with an orthographic representation is reasonable. The performance on types of expressions that we did not consider when designing the system— unclear and error—is very poor. However, this has little impact on the overall performance as these expressions are rather infrequent. by Model now consider acusing each model on the expressions; results are shown in Table 5. No model on its % variation Abbrev. clipping 5: % on the expressions using each model individually. own gives results comparable to those of the overmodel see Table 3). This indicates that the overall model successfully combines information from the specific word formation models. Each model used on its own gives an accuracy greater than the proportion of expressions of the word formation type for which the model was designed (compare accuracies in Table 5 to the number of expressions of the corresponding word formation type in the test data in Table 4). As we note in Section 2, the distinctions between the word formation types are not sharp; these results show that the shared properties of word formation types enable a model for a specific formation type to infer the standard form of texting forms of other formation types. Unseen Data now we have discussed reon our test data of forms which differ from their standard forms. We now consider the of our system on all texforms, which are identical to their standard form. Since our model was not designed with such expressions in mind, we slightly adapt it for new task; if in our lexicon, we return that as otherwise we apply our model as usual, the uniform estimate of This gives of which is very similar to the results of Choudhury et al. (2007) on this of Note, however, that Choudhury et al. only report results on this dataset using a uniform since we use a unigram language model, it is difficult to draw firm conclusions about the performance of our system relative to theirs. 6 Related Work Aw et al. (2006) model text message normalization as translation from the texting language into the et al. do use a unigram language model for their on the forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas from both machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be viewed as a noisy-channel model for spelling error correction (e.g., Mays et al., 1991; Brill and Moore, 2000), in which texting forms are seen as a kind of spelling error. Furthermore, like our approach to text message normalization, approaches to spelling correction have incorporated phonemic information (Toutanova and Moore, 2002). The word model of the supervised approach of Choudhury et al. consists of hidden Markov models, which capture properties of texting language similar to those of our stylistic variation model. We propose multiple word models—corresponding to frequent texting language formation processes—and an unsupervised method for parameter estimation. 7 Conclusions We analyze a sample of texting forms to determine frequent word formation processes in creative texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normalization. On an unseen test set forms that differ from their standard our model achieves accuracy, which is on par with that obtained by the supervised approach of Choudhury et al. (2007) on the same data. More research is required to determine the impact of our normalization method on the performance of a system that further processes the resulting text. In the future, we intend to improve our word models by incorporating additional linguistic knowledge, such as information about syllable structure. Since context likely plays a role in human interpretation of texting forms, we also intend to examine the performance of higher order ngram language models.</abstract>
<note confidence="0.821229666666667">Acknowledgements This work is financially supported by the Natural Sciences and Engineering Research Council of Canada, the University of Toronto, and the Dictionary Society of North America. References Algeo, editor. 1991. Years Among the New Cambridge University Press, Cambridge. AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normaliza- In of the COLING/ACL 2006 Main Confer- Poster pages 33–40. Sydney. R.H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX Lexical Database (release 2). Linguistic Data Consortium, University of Pennsylvania. Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Corpus version 1.1. Eric Brill and Robert C. Moore. 2000. An improved error for noisy channel spelling correction. In ProofACL pages 286–293. Hong Kong. Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh</note>
<abstract confidence="0.730298931034483">Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of language. Journal of Document and 10(3/4):157–174. C´edrick Fairon and S´ebastien Paumier. 2006. A transcorpus of 30,000 French SMS. In of Genoa, Italy. Rebecca E. Grinter and Margery A. Eldridge. 2001. y do luv 2 txt msg. In of the 7th European Conf. on Computer-Supported Cooperative Work pages 219–238. Bonn, Germany. Sittichai Jiampojamarn, Gregorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conver- In of NAACL-HLT pages 372–379. Rochester, NY. Kobus, Yvon, and G´eraldine Damnati. 2008. Normalizing SMS: are two metaphors than one? In of the 22nd Int. Conf. on pp. 441–448. Manchester. Charles W. Kreidler. 1979. Creating new words by short- 13:24–36. Rich Ling and Naomi S. Baron. 2007. Text messaging and IM: Linguistic comparison of American college of Language and Social 26:291–98. Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. based spelling correction. Proand 27(5):517–522.</abstract>
<author confidence="0.3709805">Richard Sproat</author>
<author confidence="0.3709805">Alan W Black</author>
<author confidence="0.3709805">Stanley Chen</author>
<author confidence="0.3709805">Shankar Kumar</author>
<author confidence="0.3709805">Mari Ostendorf</author>
<author confidence="0.3709805">Christopher Richards</author>
<affiliation confidence="0.251528">Normalization of non-standard words. Com-</affiliation>
<note confidence="0.928100875">Speech and 15:287–333. Crispin Thurlow. 2003. Generation txt? The sociolinof young people’s text-messaging. 1(1). Kristina Toutanova and Robert C. Moore. 2002. Pronunciation modeling for improved spelling correction. In ofACL pages 144–151. Philadelphia. 78</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Fifty Years Among the New Words.</title>
<date>1991</date>
<editor>John Algeo, editor.</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8323" citStr="(1991)" startWordPosition="1316" endWordPosition="1316">ed as errors. Example betta (better) dng (doing) hol (holiday) neway (anyway) talkin (talking) cuz (because) ello (hello) darliog (darling) morrow (tomorrow) b/day (birthday) mobs (mobile) gal (*girl) 72 ular English words. Let T be a sequence of texting forms t1t2...tn, which are the texting language realization of the standard forms, and may differ from the standard forms. Given a sequence of texting forms T, the challenge is then to determine the corresponding standard forms S. Following Choudhury et al. (2007)—and various approaches to spelling error correction, such as, e.g., Mays et al. (1991)—we model text message normalization using a noisy channel. We want to find argmaxSP(S|T). We apply Bayes rule and ignore the constant term P(T), giving argmaxSP(T |S)P(S). Making the independence assumption that each ti depends only on si, and not on the context in which it occurs, as in Choudhury et al., we express P(T |S) as a product of probabilities: argmaxS (Hi P(ti|si)) P(S). We note in Section 2 that many texting forms are created through a small number of specific word formation processes. Rather than model each of these processes at once using a generic model for P(ti|si), as in Chou</context>
<context position="13091" citStr="(1991)" startWordPosition="2112" endWordPosition="2112">Table 2. The probability of each edit operation is then determined by three properties—the length of a, whether a aligns with any phonemes in si, and if so, p—as shown below: |a|= 0 or 1, not aligned w/ si phonemes: P(b|a, pos) |a|= 2, not aligned w/ si phonemes: 0 |a|= 1 or 2, aligned w/ si phonemes: P(b|p, a, pos) 3.1.2 Subsequence Abbreviations We model subsequence abbreviations according to the equation below: � P(ti |si, subseq abrv) c if ti is a subseq of si _ 0 otherwise where c is a constant. Note that this is similar to the error model for spelling correction presented by Mays et al. (1991), in which all words (in our terms, all si) within a specified edit-distance of the out-of-vocabulary word (ti in our model) are given equal probability. The key difference is that in our formulation, we only consider standard forms for which the texting form is potentially a subsequence abbreviation. In combination with the language model, P(ti|si, subseq abbrev) assigns a non-zero probability to each standard form si for which ti is a subsequence, according to the likelihood of si (under the language model). The models interact in this way since we expect a standard form to be recognizable r</context>
</contexts>
<marker>1991</marker>
<rawString>John Algeo, editor. 1991. Fifty Years Among the New Words. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AiTi Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for SMS text normalization.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>33--40</pages>
<location>Sydney.</location>
<contexts>
<context position="1856" citStr="Aw et al., 2006" startWordPosition="275" endWordPosition="278">vity, and hence many novel lexical items, in the language of text messaging, or texting language. Normalization of non-standard forms— converting non-standard forms to their standard forms—is a challenge that must be tackled before other types of natural language processing can take place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be 1The number of characters in a text message may also be limited to 160 characters, although this is not always the case. 71 particularly useful for the visually impaired; automatic translation has also been considered (e.g., Aw et al., 2006). For texting language, given the abundance of creative forms, and the wide-ranging possibilities for creating new forms, normalization is a particularly important problem, and has indeed received some attention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus et al., 2008). In this paper we propose an unsupervised noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms</context>
<context position="28732" citStr="Aw et al. (2006)" startWordPosition="4715" endWordPosition="4718">not designed with such expressions in mind, we slightly adapt it for this new task; if ti is in our lexicon, we return that form as si, otherwise we apply our model as usual, using the uniform estimate of P(wf ). This gives an in-top-1 accuracy of 88.2%, which is very similar to the results of Choudhury et al. (2007) on this data of 89.1%. Note, however, that Choudhury et al. only report results on this dataset using a uniform language model;14 since we use a unigram language model, it is difficult to draw firm conclusions about the performance of our system relative to theirs. 6 Related Work Aw et al. (2006) model text message normalization as translation from the texting language into the 14Choudhury et al. do use a unigram language model for their experiments on the 303 texting forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas from both machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be vi</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normalization. In Proc. of the COLING/ACL 2006 Main Conference Poster Sessions, pages 33–40. Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>L Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX Lexical Database (release 2). Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania.</institution>
<contexts>
<context position="16878" citStr="Baayen et al., 1995" startWordPosition="2733" endWordPosition="2736">his subset is the focus of this study, but we also report results on the full dataset. 4.2 Lexicon We construct a lexicon of potential standard forms such that it contains most words that we expect to encounter in text messages, yet is not so large as to make it difficult to identify the correct standard form. Our subjective analysis of the standard forms in the development data is that they are frequent, non-specialized, words. To reflect this observation, we create a lexicon consisting of all single-word entries containing only alphabetic characters found in both the CELEX Lexical Database (Baayen et al., 1995) and the CMU Pronouncing Dictionary.8 We remove all words of length one (except a and I) to avoid choosing, e.g., the letter r as the standard form for the texting form r. We further limit the lexicon to words in the 20K most frequent alphabetic unigrams, ignoring case, in the Web 1T 5-gram Corpus (Brants and Franz, 2006). The resulting lexicon contains approximately 14K words, and excludes only three of the standard forms—cannot, email, and online—for the 400 development texting forms. 4.3 Model Parameter Estimation MLEs for P(gt|gs,pos)—needed to estimate P(ti|si, stylistic variation)—could </context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>R.H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX Lexical Database (release 2). Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram Corpus version 1.1.</title>
<date>2006</date>
<contexts>
<context position="17201" citStr="Brants and Franz, 2006" startWordPosition="2792" endWordPosition="2795">ective analysis of the standard forms in the development data is that they are frequent, non-specialized, words. To reflect this observation, we create a lexicon consisting of all single-word entries containing only alphabetic characters found in both the CELEX Lexical Database (Baayen et al., 1995) and the CMU Pronouncing Dictionary.8 We remove all words of length one (except a and I) to avoid choosing, e.g., the letter r as the standard form for the texting form r. We further limit the lexicon to words in the 20K most frequent alphabetic unigrams, ignoring case, in the Web 1T 5-gram Corpus (Brants and Franz, 2006). The resulting lexicon contains approximately 14K words, and excludes only three of the standard forms—cannot, email, and online—for the 400 development texting forms. 4.3 Model Parameter Estimation MLEs for P(gt|gs,pos)—needed to estimate P(ti|si, stylistic variation)—could be estimated from texting form–standard form pairs. However, since our system is unsupervised, no such data is available. We therefore assume that many texting forms, and other similar creative shortenings, occur on the web. We develop a number of character substitution rules, e.g., s ⇒ z, and use them to create hypotheti</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Corpus version 1.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proceedings ofACL 2000,</booktitle>
<pages>286--293</pages>
<publisher>Hong Kong.</publisher>
<contexts>
<context position="10781" citStr="Brill and Moore (2000)" startWordPosition="1714" endWordPosition="1717">t model syllabic letters and digits, or punctuation, explicitly; instead, we simply substitute digits with a graphemic representation (e.g., 4 is replaced by for), and remove punctuation, before applying the model. The other less frequent formations—phonetic abbreviations, spelling errors, and suffix clippings—are not modeled; we hypothesize that the similarity of these formation processes to those we do model will allow the system to perform reasonably well on them. 3.1.1 Stylistic Variations We propose a probabilistic version of editdistance—referred to here as edit-probability— inspired by Brill and Moore (2000) to model P(ti|si, stylistic variation). To compute editprobability, we consider the probability of each edit operation—substitution, insertion, and deletion— instead of its cost, as in edit-distance. We then simply multiply the probabilities of edits as opposed to summing their costs. In this version of edit-probability, we allow twocharacter edits. Ideally, we would compute the editprobability of two strings as the sum of the editprobability of each partitioning of those strings into one or two character segments. However, following Brill and Moore, we approximate this by the probability of </context>
<context position="29440" citStr="Brill and Moore, 2000" startWordPosition="4828" endWordPosition="4831">Choudhury et al. do use a unigram language model for their experiments on the 303 texting forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas from both machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be viewed as a noisy-channel model for spelling error correction (e.g., Mays et al., 1991; Brill and Moore, 2000), in which texting forms are seen as a kind of spelling error. Furthermore, like our approach to text message normalization, approaches to spelling correction have incorporated phonemic information (Toutanova and Moore, 2002). The word model of the supervised approach of Choudhury et al. consists of hidden Markov models, which capture properties of texting language similar to those of our stylistic variation model. We propose multiple word models—corresponding to frequent texting language formation processes—and an unsupervised method for parameter estimation. 7 Conclusions We analyze a sample</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert C. Moore. 2000. An improved error model for noisy channel spelling correction. In Proceedings ofACL 2000, pages 286–293. Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
<author>Rahul Saraf</author>
<author>Vijit Jain</author>
<author>Animesh Mukherjee</author>
<author>Sudeshna Sarkar</author>
<author>Anupam Basu</author>
</authors>
<title>Investigation and modeling of the structure of texting language.</title>
<date>2007</date>
<journal>International Journal of Document Analysis and Recognition,</journal>
<pages>10--3</pages>
<contexts>
<context position="2143" citStr="Choudhury et al., 2007" startWordPosition="316" endWordPosition="319">ke place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be 1The number of characters in a text message may also be limited to 160 characters, although this is not always the case. 71 particularly useful for the visually impaired; automatic translation has also been considered (e.g., Aw et al., 2006). For texting language, given the abundance of creative forms, and the wide-ranging possibilities for creating new forms, normalization is a particularly important problem, and has indeed received some attention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus et al., 2008). In this paper we propose an unsupervised noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms, are not readily available.2 Furthermore, other forms of computer-mediated communication, such as Internet messaging, exhibit creative phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, </context>
<context position="8236" citStr="Choudhury et al. (2007)" startWordPosition="1299" endWordPosition="1302"> small number of similar forms, however, appear with a single standard form word, and are therefore marked as errors. Example betta (better) dng (doing) hol (holiday) neway (anyway) talkin (talking) cuz (because) ello (hello) darliog (darling) morrow (tomorrow) b/day (birthday) mobs (mobile) gal (*girl) 72 ular English words. Let T be a sequence of texting forms t1t2...tn, which are the texting language realization of the standard forms, and may differ from the standard forms. Given a sequence of texting forms T, the challenge is then to determine the corresponding standard forms S. Following Choudhury et al. (2007)—and various approaches to spelling error correction, such as, e.g., Mays et al. (1991)—we model text message normalization using a noisy channel. We want to find argmaxSP(S|T). We apply Bayes rule and ignore the constant term P(T), giving argmaxSP(T |S)P(S). Making the independence assumption that each ti depends only on si, and not on the context in which it occurs, as in Choudhury et al., we express P(T |S) as a product of probabilities: argmaxS (Hi P(ti|si)) P(S). We note in Section 2 that many texting forms are created through a small number of specific word formation processes. Rather th</context>
<context position="15112" citStr="Choudhury et al. (2007)" startWordPosition="2439" endWordPosition="2442">si) simply sums over all models except prefix clipping. 3.2 Word Formation Prior Keeping with our goal of an unsupervised method, we estimate P(wf ) with a uniform distribution. We also consider estimating P(wf ) using maximum likelihood estimates (MLEs) from our observations in Section 2. This gives a model that is not fully unsupervised, since it relies on labelled training data. However, we consider this a lightly-supervised method, since it only requires an estimate of the frequency of the relevant word formation types, and not labelled texting form–standard form pairs. 3.3 Language Model Choudhury et al. (2007) find that using a bigram language model estimated over a balanced corpus of English had a negative effect on their results compared with a unigram language model, which they attribute to the unique characteristics of text messaging that were not reflected in the corpus. We therefore use a unigram language model for P(si), which also enables comparison with their results. Nevertheless, alternative language models, such as higher order ngram models, could easily be used in place of our unigram language model. 4 Materials and Methods 4.1 Datasets We use the data provided by Choudhury et al. (200</context>
<context position="20553" citStr="Choudhury et al. (2007)" startWordPosition="3325" endWordPosition="3328"> to be more similar to that found on the web than that in a balanced corpus of English. 4.4 Evaluation Metrics To evaluate our system, we consider three accuracy metrics: in-top-1, in-top-10, and in-top-20.12 Intop-n considers the system correct if a correct standard form is in the n most probable standard forms. The in-top-1 accuracy shows how well the system determines the correct standard form; the in-top-10 9http://en.wikipedia.org/wiki/SOWPODS 10http://icon.shef.ac.uk/Moby/ 11We are very grateful to Sittichai Jiampojamarn for providing this alignment. 12These are the same metrics used by Choudhury et al. (2007), although we refer to them by different names. 75 Model % accuracy Top-1 Top-10 Top-20 Uniform 59.4 83.8 87.8 MLE 55.4 84.2 86.5 Choudhury et al. 59.9 84.3 88.7 Table 3: % in-top-1, in-top-10, and in-top-20 accuracy on test data using both estimates for P(wf ). The results reported by Choudhury et al. (2007) are also shown. and in-top-20 accuracies may be indicative of the usefulness of the output of our system in other tasks which could exploit a ranked list of standard forms, such as machine translation. 5 Results and Discussion In Table 3 we report the results of our system using both the </context>
<context position="25369" citStr="Choudhury et al. (2007)" startWordPosition="4130" endWordPosition="4133">rms.) However, if we consider the phonemic representations of these words, friday might emerge as more likely. Syllable structure information may also be useful, as we hypothesize that clippings will tend to be formed by truncating a word at a syllable boundary. We may similarly be able to improve our estimate of P(ti|si, subseq. abrrev.). For example, both text and taxation have the same probability under this distribution, but intuitively text, the correct standard form in our data, seems more likely. We could incorporate knowledge about the likelihood of omitting specific characters, as in Choudhury et al. (2007), to improve this estimate. We now examine the lower panel of Table 4, in which we consider the performance of the overall model on the word formation types that are not explicitly modeled. The very high accuracy on gclippings indicates that since these forms are also a type of subsequence abbreviation, we do not need to construct a separate model for them. We in fact also conducted experiments in which g-clippings and hclippings were modeled explicitly, but found these extra models to have little effect on the results. Recall from Section 3.1 our hypothesis that suffix clippings, spelling err</context>
<context position="28434" citStr="Choudhury et al. (2007)" startWordPosition="4663" endWordPosition="4666"> other formation types. All Unseen Data Until now we have discussed results on our test data of 303 texting forms which differ from their standard forms. We now consider the performance of our system on all 1213 unseen texting forms, 910 of which are identical to their standard form. Since our model was not designed with such expressions in mind, we slightly adapt it for this new task; if ti is in our lexicon, we return that form as si, otherwise we apply our model as usual, using the uniform estimate of P(wf ). This gives an in-top-1 accuracy of 88.2%, which is very similar to the results of Choudhury et al. (2007) on this data of 89.1%. Note, however, that Choudhury et al. only report results on this dataset using a uniform language model;14 since we use a unigram language model, it is difficult to draw firm conclusions about the performance of our system relative to theirs. 6 Related Work Aw et al. (2006) model text message normalization as translation from the texting language into the 14Choudhury et al. do use a unigram language model for their experiments on the 303 texting forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas fr</context>
<context position="30449" citStr="Choudhury et al. (2007)" startWordPosition="4981" endWordPosition="4984">f our stylistic variation model. We propose multiple word models—corresponding to frequent texting language formation processes—and an unsupervised method for parameter estimation. 7 Conclusions We analyze a sample of texting forms to determine frequent word formation processes in creative texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normalization. On an unseen test set of 303 texting forms that differ from their standard form, our model achieves 59% accuracy, which is on par with that obtained by the supervised approach of Choudhury et al. (2007) on the same data. More research is required to determine the impact of our normalization method on the performance of a system that further processes the resulting text. In the future, we intend to improve our word models by incorporating additional linguistic knowledge, such as information about syllable structure. Since context likely plays a role in human interpretation of texting forms, we also intend to examine the performance of higher order ngram language models. Acknowledgements This work is financially supported by the Natural Sciences and Engineering Research Council of Canada, the </context>
</contexts>
<marker>Choudhury, Saraf, Jain, Mukherjee, Sarkar, Basu, 2007</marker>
<rawString>Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. International Journal of Document Analysis and Recognition, 10(3/4):157–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edrick Fairon</author>
<author>S´ebastien Paumier</author>
</authors>
<title>A translated corpus of 30,000 French SMS.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="3213" citStr="Fairon and Paumier (2006)" startWordPosition="476" endWordPosition="479">ive phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, are likely to have an impact on the language of such media (Thurlow, 2003).3 An unsupervised approach, drawing on linguistic properties of creative word formations, has the potential to be adapted for normalization of text in other similar genres—such as Internet discussion forums—without the cost of developing a large training corpus. Moreover, normalization may be particularly important for such genres, given the 2One notable exception is Fairon and Paumier (2006), although this resource is in French. The resource used in our study, Choudhury et al. (2007), is quite small in comparison. 3The rise of other technology, such as word prediction, could reduce the use of abbreviations, although it’s not clear such technology is widely used (Grinter and Eldridge, 2001). Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 71–78, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Formation type Freq. Stylistic variation 152 Subseq. abbrev. 111 Prefix clipping 24 Syll. letter/digit 19 G-cl</context>
</contexts>
<marker>Fairon, Paumier, 2006</marker>
<rawString>C´edrick Fairon and S´ebastien Paumier. 2006. A translated corpus of 30,000 French SMS. In Proceedings of LREC 2006. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca E Grinter</author>
<author>Margery A Eldridge</author>
</authors>
<title>y do tngrs luv 2 txt msg.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th European Conf. on Computer-Supported Cooperative Work (ECSCW ’01),</booktitle>
<pages>219--238</pages>
<location>Bonn, Germany.</location>
<contexts>
<context position="1015" citStr="Grinter and Eldridge, 2001" startWordPosition="145" endWordPosition="148">lyze a sample of creative, non-standard text message word forms to determine frequent word formation processes in texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normalization. On a test set of 303 text message forms that differ from their standard form, our model achieves 59% accuracy, which is on par with the best supervised results reported on this dataset. 1 Text Messaging Cell phone text messages—or SMS—contain many shortened and non-standard forms due to a variety of factors, particularly the desire for rapid text entry (Grinter and Eldridge, 2001; Thurlow, 2003).1 Furthermore, text messages are written in an informal register; non-standard forms are used to reflect this, and even for personal style (Thurlow, 2003). These factors result in tremendous linguistic creativity, and hence many novel lexical items, in the language of text messaging, or texting language. Normalization of non-standard forms— converting non-standard forms to their standard forms—is a challenge that must be tackled before other types of natural language processing can take place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be </context>
<context position="3517" citStr="Grinter and Eldridge, 2001" startWordPosition="526" endWordPosition="529"> word formations, has the potential to be adapted for normalization of text in other similar genres—such as Internet discussion forums—without the cost of developing a large training corpus. Moreover, normalization may be particularly important for such genres, given the 2One notable exception is Fairon and Paumier (2006), although this resource is in French. The resource used in our study, Choudhury et al. (2007), is quite small in comparison. 3The rise of other technology, such as word prediction, could reduce the use of abbreviations, although it’s not clear such technology is widely used (Grinter and Eldridge, 2001). Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 71–78, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Formation type Freq. Stylistic variation 152 Subseq. abbrev. 111 Prefix clipping 24 Syll. letter/digit 19 G-clipping 14 Phonetic abbrev. 12 H-clipping 10 Spelling error 5 Suffix clipping 4 Punctuation 3 Unclear 34 Error 12 Total 400 Table 1: Frequency of texting forms in the development set by formation type. need for applications such as translation and question answering. We observe that many creative texting</context>
</contexts>
<marker>Grinter, Eldridge, 2001</marker>
<rawString>Rebecca E. Grinter and Margery A. Eldridge. 2001. y do tngrs luv 2 txt msg. In Proceedings of the 7th European Conf. on Computer-Supported Cooperative Work (ECSCW ’01), pages 219–238. Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Gregorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. of NAACL-HLT</booktitle>
<pages>372--379</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="12432" citStr="Jiampojamarn et al. (2007)" startWordPosition="1988" endWordPosition="1991">or end of the word; P(ht|ps, hs, pos) is the probability of texting form graphemes ht given the standard form phonemes ps and graphemes hs at position pos. ht, ps, and hs can be a single grapheme or phoneme, or a bigram. We compute edit-probability between the graphemes of si and ti. When filling each cell in the chart, we consider edit operations between 73 segments of si and ti of length 0–2, referred to as a and b, respectively. If a aligns with phonemes in si, we also consider those phonemes, p. In our lexicon, the graphemes and phonemes of each word are aligned according to the method of Jiampojamarn et al. (2007). For example, the alignment for without is given in Table 2. The probability of each edit operation is then determined by three properties—the length of a, whether a aligns with any phonemes in si, and if so, p—as shown below: |a|= 0 or 1, not aligned w/ si phonemes: P(b|a, pos) |a|= 2, not aligned w/ si phonemes: 0 |a|= 1 or 2, aligned w/ si phonemes: P(b|p, a, pos) 3.1.2 Subsequence Abbreviations We model subsequence abbreviations according to the equation below: � P(ti |si, subseq abrv) c if ti is a subseq of si _ 0 otherwise where c is a constant. Note that this is similar to the error mo</context>
<context position="19398" citStr="Jiampojamarn et al. (2007)" startWordPosition="3144" endWordPosition="3147"> list of approximately 480K words taken from SOWPODS9 and the Moby Word Lists.10 Finally, we obtain the frequency of the derived forms from the Web 1T 5-gram Corpus. To estimate P(ht|ps, hs, pos), we first estimate two simpler distributions: P(ht|hs, pos) and P(ht|ps, pos). P(ht|hs, pos) is estimated in the same manner as P(gt|gs, pos), except that two character substitutions are allowed. P (ht|ps, pos) is estimated from the frequency of ps, and its alignment with ht, in a version of CELEX in which the graphemic and phonemic representation of each word is many–many aligned using the method of Jiampojamarn et al. (2007).11 P(ht|ps, hs, pos) is then an evenly-weighted linear combination of P(ht|hs, pos) and P(ht|ps, pos). Finally, we smooth each of P(gt|gs, pos) and P(ht|ps, hs, pos) using add-alpha smoothing. We set the constant c in our word models for subsequence abbreviations and prefix clippings such that Esz P(ti|si, wf )P(si) = 1. We similarly normalize P(ti|si, stylistic variation)P(si). We use the frequency of unigrams (ignoring case) in the Web 1T 5-gram Corpus to estimate our language model. We expect the language of text messaging to be more similar to that found on the web than that in a balanced</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Gregorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion. In Proc. of NAACL-HLT 2007, pages 372–379. Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Kobus</author>
<author>Franc¸ois Yvon</author>
<author>G´eraldine Damnati</author>
</authors>
<title>Normalizing SMS: are two metaphors better than one?</title>
<date>2008</date>
<booktitle>In Proc. of the 22nd Int. Conf. on Computational Linguistics,</booktitle>
<pages>441--448</pages>
<location>Manchester.</location>
<contexts>
<context position="2164" citStr="Kobus et al., 2008" startWordPosition="320" endWordPosition="323"> 2001). In the case of text messages, text-to-speech synthesis may be 1The number of characters in a text message may also be limited to 160 characters, although this is not always the case. 71 particularly useful for the visually impaired; automatic translation has also been considered (e.g., Aw et al., 2006). For texting language, given the abundance of creative forms, and the wide-ranging possibilities for creating new forms, normalization is a particularly important problem, and has indeed received some attention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus et al., 2008). In this paper we propose an unsupervised noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms, are not readily available.2 Furthermore, other forms of computer-mediated communication, such as Internet messaging, exhibit creative phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, are likely to have an</context>
<context position="29013" citStr="Kobus et al. (2008)" startWordPosition="4761" endWordPosition="4764">o the results of Choudhury et al. (2007) on this data of 89.1%. Note, however, that Choudhury et al. only report results on this dataset using a uniform language model;14 since we use a unigram language model, it is difficult to draw firm conclusions about the performance of our system relative to theirs. 6 Related Work Aw et al. (2006) model text message normalization as translation from the texting language into the 14Choudhury et al. do use a unigram language model for their experiments on the 303 texting forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas from both machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be viewed as a noisy-channel model for spelling error correction (e.g., Mays et al., 1991; Brill and Moore, 2000), in which texting forms are seen as a kind of spelling error. Furthermore, like our approach to text message normalization, approaches to spelling correction have incorpora</context>
</contexts>
<marker>Kobus, Yvon, Damnati, 2008</marker>
<rawString>Catherine Kobus, Franc¸ois Yvon, and G´eraldine Damnati. 2008. Normalizing SMS: are two metaphors better than one? In Proc. of the 22nd Int. Conf. on Computational Linguistics, pp. 441–448. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles W Kreidler</author>
</authors>
<title>Creating new words by shortening.</title>
<date>1979</date>
<journal>English Linguistics,</journal>
<pages>13--24</pages>
<contexts>
<context position="9834" citStr="Kreidler, 1979" startWordPosition="1570" endWordPosition="1571">he word model, we simplify our model as below. �argmaxsi P(ti|si, wf )P(wf )P(si) wf We next explain the components of the model, P(ti|si, wf ), P(wf ), and P(si), referred to as the word model, word formation prior, and language model, respectively. 3.1 Word Models We now consider which of the word formation processes discussed in Section 2 should be captured with a word model P (ti|si, wf ). We model stylistic variations and subsequence abbreviations simply due to their frequency. We also choose to model prefix clippings since this word formation process is common outside of text messaging (Kreidler, 1979; Algeo, 1991) and fairly frequent in our data. Although g-clippings and h-clippings are moderately frequent, we do not model them, as these very specific word formations are also (non-prototypical) graphemes w i th ou t phonemes w z T au t Table 2: Grapheme–phoneme alignment for without. subsequence abbreviations. We do not model syllabic letters and digits, or punctuation, explicitly; instead, we simply substitute digits with a graphemic representation (e.g., 4 is replaced by for), and remove punctuation, before applying the model. The other less frequent formations—phonetic abbreviations, s</context>
<context position="13922" citStr="Kreidler (1979)" startWordPosition="2248" endWordPosition="2249">r standard forms for which the texting form is potentially a subsequence abbreviation. In combination with the language model, P(ti|si, subseq abbrev) assigns a non-zero probability to each standard form si for which ti is a subsequence, according to the likelihood of si (under the language model). The models interact in this way since we expect a standard form to be recognizable relative to the other words for which ti could be a subsequence abbreviation 3.1.3 Prefix Clippings We model prefix clippings similarly to subsequence abbreviations. { c if ti is possible pre. clip. of si 0 otherwise Kreidler (1979) observes that clippings tend to be mono-syllabic and end in a consonant. Furthermore, when they do end in a vowel, it is often of a regular form, such as telly for television and breaky for breakfast. We therefore only consider P(ti|si, prefix clipping) if ti is a prefix clipping according to the following heuristics: ti is monosyllabic after stripping any word-final vowels, and subsequently removing duplicated word-final consonants (e.g, telly becomes tel, which is a candidate prefix clipping). If ti is not a prefix clipping according to these criteria, P(ti|si) simply sums over all models e</context>
</contexts>
<marker>Kreidler, 1979</marker>
<rawString>Charles W. Kreidler. 1979. Creating new words by shortening. English Linguistics, 13:24–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich Ling</author>
<author>Naomi S Baron</author>
</authors>
<title>Text messaging and IM: Linguistic comparison of American college data.</title>
<date>2007</date>
<journal>Journal of Language and Social Psychology,</journal>
<pages>26--291</pages>
<contexts>
<context position="2681" citStr="Ling and Baron, 2007" startWordPosition="396" endWordPosition="399">tention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus et al., 2008). In this paper we propose an unsupervised noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms, are not readily available.2 Furthermore, other forms of computer-mediated communication, such as Internet messaging, exhibit creative phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, are likely to have an impact on the language of such media (Thurlow, 2003).3 An unsupervised approach, drawing on linguistic properties of creative word formations, has the potential to be adapted for normalization of text in other similar genres—such as Internet discussion forums—without the cost of developing a large training corpus. Moreover, normalization may be particularly important for such genres, given the 2One notable exception is Fairon and Paumier (2006), although this resource is in French. The resource used in our stud</context>
</contexts>
<marker>Ling, Baron, 2007</marker>
<rawString>Rich Ling and Naomi S. Baron. 2007. Text messaging and IM: Linguistic comparison of American college data. Journal of Language and Social Psychology, 26:291–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
<author>Fred J Damerau</author>
<author>Robert L Mercer</author>
</authors>
<title>Context based spelling correction.</title>
<date>1991</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>27--5</pages>
<contexts>
<context position="8323" citStr="Mays et al. (1991)" startWordPosition="1313" endWordPosition="1316">erefore marked as errors. Example betta (better) dng (doing) hol (holiday) neway (anyway) talkin (talking) cuz (because) ello (hello) darliog (darling) morrow (tomorrow) b/day (birthday) mobs (mobile) gal (*girl) 72 ular English words. Let T be a sequence of texting forms t1t2...tn, which are the texting language realization of the standard forms, and may differ from the standard forms. Given a sequence of texting forms T, the challenge is then to determine the corresponding standard forms S. Following Choudhury et al. (2007)—and various approaches to spelling error correction, such as, e.g., Mays et al. (1991)—we model text message normalization using a noisy channel. We want to find argmaxSP(S|T). We apply Bayes rule and ignore the constant term P(T), giving argmaxSP(T |S)P(S). Making the independence assumption that each ti depends only on si, and not on the context in which it occurs, as in Choudhury et al., we express P(T |S) as a product of probabilities: argmaxS (Hi P(ti|si)) P(S). We note in Section 2 that many texting forms are created through a small number of specific word formation processes. Rather than model each of these processes at once using a generic model for P(ti|si), as in Chou</context>
<context position="13091" citStr="Mays et al. (1991)" startWordPosition="2109" endWordPosition="2112">is given in Table 2. The probability of each edit operation is then determined by three properties—the length of a, whether a aligns with any phonemes in si, and if so, p—as shown below: |a|= 0 or 1, not aligned w/ si phonemes: P(b|a, pos) |a|= 2, not aligned w/ si phonemes: 0 |a|= 1 or 2, aligned w/ si phonemes: P(b|p, a, pos) 3.1.2 Subsequence Abbreviations We model subsequence abbreviations according to the equation below: � P(ti |si, subseq abrv) c if ti is a subseq of si _ 0 otherwise where c is a constant. Note that this is similar to the error model for spelling correction presented by Mays et al. (1991), in which all words (in our terms, all si) within a specified edit-distance of the out-of-vocabulary word (ti in our model) are given equal probability. The key difference is that in our formulation, we only consider standard forms for which the texting form is potentially a subsequence abbreviation. In combination with the language model, P(ti|si, subseq abbrev) assigns a non-zero probability to each standard form si for which ti is a subsequence, according to the likelihood of si (under the language model). The models interact in this way since we expect a standard form to be recognizable r</context>
<context position="29416" citStr="Mays et al., 1991" startWordPosition="4824" endWordPosition="4827">anguage into the 14Choudhury et al. do use a unigram language model for their experiments on the 303 texting forms which differ from their standard forms (see Section 3.3). 77 standard language. Kobus et al. (2008) incorporate ideas from both machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be viewed as a noisy-channel model for spelling error correction (e.g., Mays et al., 1991; Brill and Moore, 2000), in which texting forms are seen as a kind of spelling error. Furthermore, like our approach to text message normalization, approaches to spelling correction have incorporated phonemic information (Toutanova and Moore, 2002). The word model of the supervised approach of Choudhury et al. consists of hidden Markov models, which capture properties of texting language similar to those of our stylistic variation model. We propose multiple word models—corresponding to frequent texting language formation processes—and an unsupervised method for parameter estimation. 7 Conclus</context>
</contexts>
<marker>Mays, Damerau, Mercer, 1991</marker>
<rawString>Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. Context based spelling correction. Information Processing and Management, 27(5):517–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Alan W Black</author>
<author>Stanley Chen</author>
<author>Shankar Kumar</author>
<author>Mari Ostendorf</author>
<author>Christopher Richards</author>
</authors>
<title>Normalization of non-standard words.</title>
<date>2001</date>
<journal>Computer Speech and Language,</journal>
<pages>15--287</pages>
<contexts>
<context position="1551" citStr="Sproat et al., 2001" startWordPosition="224" endWordPosition="227">of factors, particularly the desire for rapid text entry (Grinter and Eldridge, 2001; Thurlow, 2003).1 Furthermore, text messages are written in an informal register; non-standard forms are used to reflect this, and even for personal style (Thurlow, 2003). These factors result in tremendous linguistic creativity, and hence many novel lexical items, in the language of text messaging, or texting language. Normalization of non-standard forms— converting non-standard forms to their standard forms—is a challenge that must be tackled before other types of natural language processing can take place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be 1The number of characters in a text message may also be limited to 160 characters, although this is not always the case. 71 particularly useful for the visually impaired; automatic translation has also been considered (e.g., Aw et al., 2006). For texting language, given the abundance of creative forms, and the wide-ranging possibilities for creating new forms, normalization is a particularly important problem, and has indeed received some attention in computational linguistics (e.g., Aw et al., 2006; Choudhury et al., 2007; Kobus </context>
</contexts>
<marker>Sproat, Black, Chen, Kumar, Ostendorf, Richards, 2001</marker>
<rawString>Richard Sproat, Alan W. Black, Stanley Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. 2001. Normalization of non-standard words. Computer Speech and Language, 15:287–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Crispin Thurlow</author>
</authors>
<title>Generation txt? The sociolinguistics of young people’s text-messaging.</title>
<date>2003</date>
<booktitle>Discourse Analysis Online,</booktitle>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="1031" citStr="Thurlow, 2003" startWordPosition="149" endWordPosition="150">on-standard text message word forms to determine frequent word formation processes in texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normalization. On a test set of 303 text message forms that differ from their standard form, our model achieves 59% accuracy, which is on par with the best supervised results reported on this dataset. 1 Text Messaging Cell phone text messages—or SMS—contain many shortened and non-standard forms due to a variety of factors, particularly the desire for rapid text entry (Grinter and Eldridge, 2001; Thurlow, 2003).1 Furthermore, text messages are written in an informal register; non-standard forms are used to reflect this, and even for personal style (Thurlow, 2003). These factors result in tremendous linguistic creativity, and hence many novel lexical items, in the language of text messaging, or texting language. Normalization of non-standard forms— converting non-standard forms to their standard forms—is a challenge that must be tackled before other types of natural language processing can take place (Sproat et al., 2001). In the case of text messages, text-to-speech synthesis may be 1The number of c</context>
<context position="2817" citStr="Thurlow, 2003" startWordPosition="420" endWordPosition="422">sed noisy channel method for texting language normalization, that gives performance on par with that of a supervised system. We pursue unsupervised approaches to this problem, as large collections of text messages, and their corresponding standard forms, are not readily available.2 Furthermore, other forms of computer-mediated communication, such as Internet messaging, exhibit creative phenomena similar to text messaging, although at a lower frequency (Ling and Baron, 2007). Moreover, technological changes, such as new input devices, are likely to have an impact on the language of such media (Thurlow, 2003).3 An unsupervised approach, drawing on linguistic properties of creative word formations, has the potential to be adapted for normalization of text in other similar genres—such as Internet discussion forums—without the cost of developing a large training corpus. Moreover, normalization may be particularly important for such genres, given the 2One notable exception is Fairon and Paumier (2006), although this resource is in French. The resource used in our study, Choudhury et al. (2007), is quite small in comparison. 3The rise of other technology, such as word prediction, could reduce the use o</context>
<context position="7567" citStr="Thurlow (2003)" startWordPosition="1194" endWordPosition="1196">orm always corresponds to a single standard form word. It is important to note that some text forms have properties of multiple categories, e.g., bak (back) could be considered a stylistic variation or a subsequence abbreviation. In such cases, we simply attempt to assign the most appropriate category. The design of our model for text message normalization, presented below, uses properties of the observed formation processes. 3 An Unsupervised Noisy Channel Model for Text Message Normalization Let S be a sentence consisting of standard forms s1s2...sn; in this study the standard forms are reg5Thurlow (2003) also observes an abundance of g-clippings. 6A small number of similar forms, however, appear with a single standard form word, and are therefore marked as errors. Example betta (better) dng (doing) hol (holiday) neway (anyway) talkin (talking) cuz (because) ello (hello) darliog (darling) morrow (tomorrow) b/day (birthday) mobs (mobile) gal (*girl) 72 ular English words. Let T be a sequence of texting forms t1t2...tn, which are the texting language realization of the standard forms, and may differ from the standard forms. Given a sequence of texting forms T, the challenge is then to determine </context>
</contexts>
<marker>Thurlow, 2003</marker>
<rawString>Crispin Thurlow. 2003. Generation txt? The sociolinguistics of young people’s text-messaging. Discourse Analysis Online, 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction.</title>
<date>2002</date>
<booktitle>In Proc. ofACL 2002,</booktitle>
<pages>144--151</pages>
<location>Philadelphia.</location>
<contexts>
<context position="29665" citStr="Toutanova and Moore, 2002" startWordPosition="4862" endWordPosition="4865">th machine translation and automatic speech recognition for text message normalization. However, both of these approaches are supervised, and have only limited means for normalizing texting forms that do not occur in the training data. Our work, like that of Choudhury et al. (2007), can be viewed as a noisy-channel model for spelling error correction (e.g., Mays et al., 1991; Brill and Moore, 2000), in which texting forms are seen as a kind of spelling error. Furthermore, like our approach to text message normalization, approaches to spelling correction have incorporated phonemic information (Toutanova and Moore, 2002). The word model of the supervised approach of Choudhury et al. consists of hidden Markov models, which capture properties of texting language similar to those of our stylistic variation model. We propose multiple word models—corresponding to frequent texting language formation processes—and an unsupervised method for parameter estimation. 7 Conclusions We analyze a sample of texting forms to determine frequent word formation processes in creative texting language. Drawing on these observations, we construct an unsupervised noisy-channel model for text message normalization. On an unseen test </context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>Kristina Toutanova and Robert C. Moore. 2002. Pronunciation modeling for improved spelling correction. In Proc. ofACL 2002, pages 144–151. Philadelphia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>