<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019789">
<title confidence="0.9985">
JU_CSE: A Conditional Random Field (CRF) Based Approach to
Aspect Based Sentiment Analysis
</title>
<author confidence="0.984876">
Braja Gopal Patra, Soumik Mandal, Dipankar Das and Sivaji Bandyopadhyay
</author>
<affiliation confidence="0.980436">
Department of Computer Science &amp; Engineering,
Jadavpur University, Kolkata, India
</affiliation>
<email confidence="0.99013">
brajagopal.cse@gmail.com, mandal.soumik@gmail.com,
dipankar.dipnil2005@gmail.com, sivaji_cse_ju@yahoo.com
</email>
<sectionHeader confidence="0.993841" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999875533333333">
The fast upswing of online reviews and their
sentiments on the Web became very useful
information to the people. Thus, the opin-
ion/sentiment mining has been adopted as a
subject of increasingly research interest in
the recent years. Being a participant in the
Shared Task Challenge, we have developed a
Conditional Random Field based system to
accomplish the Aspect Based Sentiment
Analysis task. The aspect term in a sentence
is defined as the target entity. The present
system identifies aspect term, aspect catego-
ries and their sentiments from the Laptop
and Restaurants review datasets provided by
the organizers.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999455">
In recent times, the research activities in the
areas of Opinion Mining/Sentiment Analysis in
natural language texts and other media are gain-
ing ground under the umbrella of subjectivity
analysis and affect computing1. The reason may
be the huge amount of available text data in So-
cial Web in the forms of news, reviews, blogs,
chat and twitter etc. Majority of research efforts
are being carried out for the identification of pos-
itive or negative polarity from the textual con-
tents like sentence, paragraph, or text span re-
gardless of the entities (e.g., laptops, restaurants)
and their aspects (e.g., battery, screen; food, ser-
vice).
</bodyText>
<footnote confidence="0.9247558">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1http://www.saaip.org/
</footnote>
<bodyText confidence="0.999709">
Aspect is a multinomial distribution over
words that represent a more specific topic in re-
views (Jo and Oh, 2011). For example, in case of
Laptop reviews, “touchpad” is considered an
aspect. Similarly, given a predefined entity, an
aspect term describes a specific aspect of that
entity (e.g., for the entity “restaurant”, “wine”
can be an aspect term). Aspect term can be ap-
peared as a single word (e.g., “menu”) or multi-
ple words (“side dish”).
It is observed that for a particular entity, one
or more number of aspect terms can be grouped
into a single category (e.g., aspect terms
“drinks”, “main course” belongs to the same cat-
egory, “food”).
The main goal of the Aspect Based Sentiment
Analysis (ABSA) (Pontiki et al., 2014) task is to
identify the aspect terms and their categories
from the given target entities as well as to identi-
fy the sentiments expressed towards each of the
aspect terms. The datasets provided by the
shared task organizers consist of customer re-
views with human-annotations.
We have participated in all of the four tasks. A
combination of Conditional Random Field (CRF)
based machine learning algorithm and rule based
techniques has been adopted for identifying the
aspect term, aspect category and their senti-
ments. We have used several features like Part of
Speech (POS), Stanford dependency relations2,
WordNet information, and sentiment lexicon
(SentiWordNet3) to accomplish these tasks.
The rest of the paper is organized in the fol-
lowing manner. Section 2 provides the details of
previous works. Section 3 provides an elabora-
tive description of the data used in the task. Fea-
tures used in these experiments are described in
Section 4. The detailed setup of experimentation
and analysis of the results are described in Sec-
</bodyText>
<footnote confidence="0.999246">
2 http://nlp.stanford.edu/software/lex-parser.shtml
3 http://sentiwordnet.isti.cnr.it/
</footnote>
<page confidence="0.92729">
370
</page>
<note confidence="0.7374185">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 370–374,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.9699965">
tion 5. Finally, conclusions and future directions
are presented.
</bodyText>
<sectionHeader confidence="0.999311" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997900625">
It has been observed that most of the previous
works on aspect detection were based on infor-
mation extraction, to find the most frequent noun
phrases (Hu and Liu, 2004). This approach is
generally useful in finding aspects which are
strongly associated with a single noun. But, one
principal disadvantage of this approach is that it
cannot detect the aspect terms which are of low
frequency and noun phrases (e.g., different
names of dishes like Biryani, Dosa and Uttapam
etc. for the aspect category, “food”). The pro-
posed work of such problem involves semantic
hierarchy, rule-based or combination of both
(Popescu and Etzioni 2005). More recent ap-
proaches of aspect detection are based on topic
modelling, that use Latent Dirichlet Allocation
(LDA) (Brody and Elhadad, 2010). But, the
standard Latent Dirichlet Allocation (LDA) is
not exactly suitable for the task of aspect detec-
tion due to their inherent nature of capturing
global topics in the data, rather than finding local
aspects related to the predefined entity. This ap-
proach was further modified in Sentence-LDA
(SLDA) and Aspect and Sentiment Unification
Model (ASUM) (Jo and Oh, 2011). Similarly, the
identification of focussed text spans for opinion
topics and targets were identified in (Das and
Bandyopadhyay, 2010).
Snyder and Barzilay (2007) addressed the
problem of identifying categories for multiple
related aspect terms appeared in the text. For
instance, in a restaurant review, such categories
may include food, ambience and service etc. In
our task, we call them as aspect or review cate-
gories. The authors implemented the Good Grief
decoding algorithm on a corpus collected on res-
taurant review4, which outperforms over the fa-
mous PRank algorithm (Crammer and Singer,
2001).
Ganu et al., (2009) have classified the restau-
rant reviews collected from City search New
York5 into six categories namely Food, Service,
Price, Ambience, Anecdotes, and Miscellaneous.
Sentiment associated with each category has also
been identified and both the experiments were
carried out using Support Vector Machine classi-
fiers. Finally, they implemented the regression
based model containing MATLAB regression
</bodyText>
<footnote confidence="0.9932695">
4 http://people.csail.mit.edu/bsnyder/naacl07/
5 http://www.citysearch.com/guide/newyork-ny-metro
</footnote>
<bodyText confidence="0.999925466666667">
function (mvregress) to give rating (1 to 5) to
each review.
To determine the sentiment or polarity of the
aspect term and aspect category, we need a prior
sentiment annotated lexicon. Several works have
been conducted on building emotional corpora in
different English languages such as SentiWord-
Net (Baccianella et al., 2010), WordNet Affect
(Strapparava and Valitutti, 2004) (Patra et al.,
2013) etc. Among all these publicly available
sentiment lexicons, SentiWordNet is one of the
well-known and widely used ones (number of
citations is higher than other resources6) that has
been utilized in several applications such as sen-
timent analysis, opinion mining and emotion
analysis.
Several works have been performed on the au-
tomated opinion detection or polarity identifica-
tion from reviews (Yu and Hatzivassiloglou,
2003; Hu and Liu, 2004). Yu and Hatzivass-
iloglou (2003) has focused on characterizing
opinions and facts in a generic manner, without
examining who the opinion holder is or what the
opinion is about. Then, they have identified the
polarity or sentiment of the fact using Naive
Bayes classifier. Hu and Liu, (2004) has summa-
rized the customer review and then identified the
sentiment of that review. They have achieved
promising accuracy in case of identifying polari-
ty of the reviews.
</bodyText>
<sectionHeader confidence="0.996791" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.998869117647059">
The sentences collected from the customer re-
views of Restaurants and Laptops are used in
these tasks. The training data of Restaurant re-
views contains 3041 English sentences annotated
with aspect terms and aspect categories along
with their polarity. The training data of Laptop
reviews contains 3045 sentences annotated with
aspect terms along with their polarity. The test
data contains 800 sentences from each of the re-
view sets.
An example extracted from the corpus is as
follows:
But the staff was so horrible to us.
Here, &amp;quot;staff&amp;quot; is the aspect term and its polarity
is &amp;quot;negative&amp;quot;. The aspect category is &amp;quot;service&amp;quot;
and polarity of the aspect category is also &amp;quot;nega-
tive&amp;quot;.
</bodyText>
<footnote confidence="0.941843">
6 http://citeseerx.ist.psu.edu/index
</footnote>
<page confidence="0.996457">
371
</page>
<sectionHeader confidence="0.996748" genericHeader="method">
4 Feature Analysis
</sectionHeader>
<bodyText confidence="0.988144163265306">
In general, the feature selection always plays
an important role in any machine learning
framework and depends upon the data set used
for the experiments. Based on a preliminary in-
vestigation of the dataset, we have identified
some of the following features. Different combi-
nations of the features have also been used to get
the best results from the classification task.
Parts-of-Speech (POS): the aspect terms are
basically represented by the noun phrases. On the
other hand, the POS tag plays an important role
in aspect term identification (Hu and Liu, 2004;
Brody and Elhadad, 2010). Thus, we have used
the Stanford CoreNLP7 tool to parse each of the
review sentences to find out the part-of-speech
tag of each word and included them as a feature
in all of our experiments.
POS Frequency: We have observed that the
aspect terms surrounded by a noun or adjective
are also denoted as aspect terms. Therefore, we
have utilized this information in our system. For
example, in the phrase “external_JJ mouse_NN”.
Here the word “mouse” is an object and aspect
term. The word “external” is also tagged as as-
pect term.
Before be verb: We have observed that the
nouns occur before the “be” verbs denote the
aspect terms in most of the cases. e.g. “The hard
disk is noisy”. Here “hark disk” is an aspect term
and is followed by the “be” verb &amp;quot;is&amp;quot;.
Inanimate words: In case of the Restaurant
and Laptop reviews, we observed that many of
the inanimate nouns occur as aspect terms. We
have used the hyponym tree of RiTa.WordNet8 to
identify the inanimate words. For example, in the
following sentence, the words food, kitchen and
menu are inanimate nouns occurred as aspect
terms.
“The food is uniformly exceptional, with a
very capable kitchen which will proudly whip up
whatever you feel like eating, whether it&apos;s on the
menu or not.”
Dependency Relation for finding Object: We
have identified the object based dependency rela-
tions from parsed sentences, as we have observed
that the words occupied in such relations are rep-
resented as aspect terms in many cases. “dobj”,
“obj” and “xobj” are considered as the probable
candidate relations for identifying the aspect
</bodyText>
<footnote confidence="0.999513">
7http://nlp.stanford.edu/software/corenlp.shtml
8www.rednoise.org/rita/reference/RiWordNet.html
</footnote>
<bodyText confidence="0.987604388888889">
terms. Here, the Stanford Parser9 has been used
to get the dependency relations.
Ontology Information (Liu, 2012): We have
counted the aspect terms in the training data. The
aspect terms occurred more than five times in the
corpus are considered during our experiments. At
first, we have tested this ontology information on
the development set and observed that the aspect
terms with frequency five or more also give bet-
ter results in the test set.
Sentiment Words: We have used the senti-
ment words as a feature for the sentiment identi-
fication tasks (Liu, 2012; Brody and Elhadad,
2010). Words are identified as positive, negative
or neutral using SentiWordNet10.
WordNet Information: The RiTa.WordNet
package has been used to extract different prop-
erties of the words.
For aspect category identification, we have
matched the hypernym tree of each word with
the four categories (service, price, food, and am-
bience). If the hypernym tree does not contain
any of such words, we check the next level hy-
pernym tree of the words derived from hypernym
of previous word. We have checked up to the
second degree hypernym tree. We also searched
hypernym tree of the synset of each word.
Number of Sentence: It has been found that
many reviews contain more than one sentence.
Therefore, we have included the number of sen-
tence as a feature based on the output of Stanford
Parser. We have split the output of Stanford
Parser by the mark, “(S”.
In case of our experiments, the stop words are
excluded. Total of 329 stop words was prepared
manually.
</bodyText>
<sectionHeader confidence="0.988459" genericHeader="evaluation">
5 Experimentation and Result Analysis
</sectionHeader>
<bodyText confidence="0.999984636363636">
We have used the CRF++ 0.58 11, an open
source tool for implementing the machine learn-
ing framework for our experiments. CRF is well
known for sequence labeling tasks (Lafferty et
al., 2001). Similarly, in the present task, the as-
pect terms use the context information and are
represented in sequences. Many of the aspect
terms are multiword expressions such as “hard
disk”. We have created different templates for
different subtasks to capture all the relations be-
tween different sequence related features.
</bodyText>
<footnote confidence="0.999914666666667">
9http://nlp.stanford.edu/software/lex-parser.shtml
10http://sentiwordnet.isti.cnr.it/
11http://crfpp.googlecode.com/svn/trunk/doc/index.htm
</footnote>
<page confidence="0.992424">
372
</page>
<subsectionHeader confidence="0.486967">
a. Classification of Aspect Term
</subsectionHeader>
<bodyText confidence="0.997807521739131">
Features used in case of identifying aspect
terms are POS, POS Frequency, Before be verb,
Inanimate word, objects of the sentence, ontolo-
gy information. We have used several rules to
identify these features. Then, we have used the
CRF++ to identify the aspect terms. Some post
processing techniques are also used in order to
get better accuracy. The present system identifies
only single word aspect terms. But it is found in
the training data that many aspect terms consist
of multiple words. Therefore, if there is a stop
word in between two system identified aspect
words, the stop word is also considered as a part
of the aspect term. We have joined the aspect
words along with the stop words to form a single
but multiword aspect terms.
Precisions, Recalls and F-scores are recorded
for our system in Table 1. The maximum F-
scores achieved in the aspect term identification
task for Laptop and Restaurant are 0.7455012
and 0.84012544, respectively. Our system per-
forms better on Restaurant reviews than Laptop
reviews.
</bodyText>
<tableCaption confidence="0.8690625">
Table 1: JU_CSE system result for aspect
term identification.
</tableCaption>
<subsectionHeader confidence="0.831722">
b. Classification of Aspect Category
</subsectionHeader>
<bodyText confidence="0.9988804">
Features used in this experiment are POS, De-
pendency relations for object and a few semantic
relations of WordNet. In this subtask, we have
also used aspect term knowledge as a feature.
We identified the POS of the words using Stan-
ford CoreNLP tool and used the words which are
not listed in our stop-word list. The objects are
identified from the dependency relations. The
hpernym trees of these words are searched up to
second degree to find four aspect categories
(service, price, food, and ambience). If we don’t
find these four categories in the hypernym tree,
we increase the frequency of anecdotes/ miscel-
laneous category. Frequency counts of these
matched words are listed as a feature. The accu-
racy of the system for aspect categories in the
Restaurant reviews are shown in Table 2.
Maximum F-score achieved in this aspect cat-
egory identification is 0.8857715. The main
problem faced in this task was to assign the an-
ecdotes/ miscellaneous category to the respective
reviews. There are many cases in which the an-
ecdotes/miscellaneous categories occurred with
other categories. In these cases, our system fails
to identify the anecdotes/miscellaneous category.
</bodyText>
<tableCaption confidence="0.92042">
Table 2: JU_CSE system result for aspect
category identification.
</tableCaption>
<bodyText confidence="0.948321882352941">
We have also observed that every review has
at least one category. If any word of the review
does not belong to any of the four categories, we
assign these reviews with anecdotes/ miscellane-
ous category at the time of post processing.
c. Classification of Sentiment of Aspect
term and category
Features used in these experiments are POS,
Positive, Negative and Neutral words and num-
ber of sentences. Some reviews with multiple
sentences contain different sentiments associated
with different aspect terms. This observation also
leads to conflict sentiment. Therefore, we have
also included the aspect term and aspect catego-
ry information during sentiment identification.
The accuracy of the system is given in the Table
3.
</bodyText>
<tableCaption confidence="0.994287">
Table 3: JU_CSE system result for aspect
term and category sentiment identification.
</tableCaption>
<bodyText confidence="0.999965307692308">
Our system performs moderate in case of sen-
timent identification. Mainly, the system was
biased towards the positive tags. It is found that
the number of positive tags in the training data
was more as compared to others. We have ob-
served that a conflict tag occurs when an aspect
term was present as both positive and negative.
As the present system identifies the sentiment
based on word level only, it was unable to detect
the conflict tags. The feature, number of sentenc-
es fails to identify the conflict tags. Therefore,
we need to find more suitable features for our
system to improve the accuracy.
</bodyText>
<figure confidence="0.993849235294118">
Laptop Restaurant
Precision 0.4938838 0.6481481
Recall 0.7442396 0.8184855
F-score 0.59375 0.72342515
Restaurant
Precision Recall F-score
0.7307317 0.68029064 0.7046096
Laptop 0.5321101 NaN
Restaurant 0.65547705 0.6409756
Accuracy

Aspect
Term
Sentiment
Aspect
Category
Sentiment
</figure>
<page confidence="0.997507">
373
</page>
<sectionHeader confidence="0.998511" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999976">
In this paper, we have presented a CRF based
system for identifying the aspect terms, aspect
categories and their sentiments. We believe that
this problem will become increasingly important
for common people. This task will not only be
useful to common shoppers, but also crucial to
product manufacturers and restaurateurs.
Overall accuracies of our system were moder-
ate. In future, we will include more suitable fea-
tures to improve accuracy of our system. We also
intend to explore different machine learning al-
gorithms for these tasks in future.
</bodyText>
<sectionHeader confidence="0.989616" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999598043956044">
Benjamin Snyder and Regina Barzilay. 2007. Multi-
ple Aspect Ranking Using the Good Grief Algo-
rithm. In Proceedings of the Human Language
Technologies: The Annual Conference of the Iorth
American Chapter of the Association for Computa-
tional Linguistics (IAACL-HLT 2007), pp. 300-
307.
Bing Liu. 2012. Sentiment Analysis and Opinion
Mining. Synthesis Lectures on Human Language
Technologies 5, no. 1 (2012): 1-167.
Braja G. Patra, Hiroya Takamura, Dipankar Das,
Manabu Okumura, and Sivaji Bandyopadhyay.
2013. Construction of Emotional Lexicon Using
Potts Model. In Proceedings of the 6th Internation-
al Joint Conference on Iatural Language Pro-
cessing (IJCILP-2013), Nagoya, Japan, pp. 674–
679.
Carlo Strapparava, and Alessandro Valitutti. 2004.
WordNet Affect: an Affective Extension of Word-
Net. In LREC, vol. 4, pp. 1083-1086.
Dipankar Das and Sivaji Bandyopadhyay. 2010. Ex-
tracting emotion topics from blog sentences: use of
voting from multi-engine supervised classifiers. In
Proceedings of the 2nd international workshop on
Search and mining user-generated contents, pp.
119-126.
Ganu Gayatree, Noemie Elhadad, and Amelie Marian.
2009. Beyond the stars: Improving rating predic-
tions using review text content. In Proceedings of
the 12th International Workshop on the Web and
Databases, Providence, Rhode Island.
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating
facts from opinions and identifying the polarity of
opinion sentences. In Proceedings of the Confer-
ence on Empirical Methods in Iatural Language
Processing (EMILP-2013), pp. 129-136.
Koby Crammer and Yoram Singer. 2001. Pranking
with ranking. In IIPS, vol. 14, pp. 641-647.
John Lafferty, Andrew McCallum, Fernando C.N.
Pereira. 2001. Conditional Random Fields: Proba-
bilistic Models for Segmenting and Labeling Se-
quence Data. In Proceedings of the 18th Interna-
tional Conference on Machine Learning (ICML
2001), pp. 282-289.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the 10th
ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 168-
177.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
proceedings of the Human Language Technology
Conference: Conference on Empirical Methods in
Iatural Language Processing (HLT-EMILP).
Morristown, NJ, USA, pp. 339–346.
Samaneh Moghaddam and Martin Ester. 2010. Opin-
ion digger: an unsupervised opinion miner from
unstructured product reviews. In Proceedings of the
19th ACM international conference on Information
and knowledge management, pp. 1825-1828.
Samuel Brody and Noemie Elhadad. 2010. An unsu-
pervised aspect-sentiment model for online re-
views. In Proceedings of the Human Language
Technologies: The 2010 Annual Conference of the
Iorth American Chapter of the Association for
Computational Linguistics (HLT-IAACL).
Soo-Min Kim and Eduard Hovy. 2006. Extracting
opinions, opinion holders, and topics expressed in
online news media text. In Proceedings of the
Workshop on Sentiment and Subjectivity in Text,
pp. 1-8.
Stefano Baccianella, Andrea Esuli, and Fabrizio Se-
bastiani. 2010. SentiWordNet 3.0: An Enhanced
Lexical Resource for Sentiment Analysis and
Opinion Mining. In LREC, vol. 10, pp. 2200-2204.
Yohan Jo and Alice H. Oh. 2011. Aspect and senti-
ment unification model for online review analysis.
In Proceedings of the fourth ACM international
conference on Web search and data mining.
Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia.
2011. Clustering product features for opinion min-
ing. In Proceedings of the fourth ACM internation-
al conference on Web search and data mining, pp.
347-354.
Maria Pontiki, Dimitrios Galanis, John Pavlopoulos,
Haris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 Task 4:
Aspect Based Sentiment Analysis. In Proceedings
of the 8th International Workshop on Semantic
Evaluation (SemEval 2014), Dublin, Ireland.
</reference>
<page confidence="0.999023">
374
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.714027">
<title confidence="0.996684">JU_CSE: A Conditional Random Field (CRF) Based Approach Aspect Based Sentiment Analysis</title>
<author confidence="0.986325">Braja Gopal Patra</author>
<author confidence="0.986325">Soumik Mandal</author>
<author confidence="0.986325">Dipankar Das</author>
<author confidence="0.986325">Sivaji</author>
<affiliation confidence="0.952033">Department of Computer Science &amp; Jadavpur University, Kolkata, India</affiliation>
<email confidence="0.95333">brajagopal.cse@gmail.com,dipankar.dipnil2005@gmail.com,sivaji_cse_ju@yahoo.com</email>
<abstract confidence="0.9907873125">The fast upswing of online reviews and their sentiments on the Web became very useful information to the people. Thus, the opinion/sentiment mining has been adopted as a subject of increasingly research interest in the recent years. Being a participant in the Shared Task Challenge, we have developed a Conditional Random Field based system to accomplish the Aspect Based Sentiment task. The term a sentence is defined as the target entity. The present identifies categotheir sentiments from the datasets provided by the organizers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Multiple Aspect Ranking Using the Good Grief Algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technologies: The Annual Conference of the Iorth American Chapter of the Association for Computational Linguistics (IAACL-HLT</booktitle>
<pages>300--307</pages>
<contexts>
<context position="5243" citStr="Snyder and Barzilay (2007)" startWordPosition="800" endWordPosition="803">ed on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple related aspect terms appeared in the text. For instance, in a restaurant review, such categories may include food, ambience and service etc. In our task, we call them as aspect or review categories. The authors implemented the Good Grief decoding algorithm on a corpus collected on restaurant review4, which outperforms over the famous PRank algorithm (Crammer and Singer, 2001). Ganu et al., (2009) have classified the restaurant reviews collected from City search New York5 into six categories namely Food, Service, Price, Ambience, Ane</context>
</contexts>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2007. Multiple Aspect Ranking Using the Good Grief Algorithm. In Proceedings of the Human Language Technologies: The Annual Conference of the Iorth American Chapter of the Association for Computational Linguistics (IAACL-HLT 2007), pp. 300-307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies</journal>
<volume>5</volume>
<pages>1--167</pages>
<contexts>
<context position="10615" citStr="Liu, 2012" startWordPosition="1645" endWordPosition="1646"> up whatever you feel like eating, whether it&apos;s on the menu or not.” Dependency Relation for finding Object: We have identified the object based dependency relations from parsed sentences, as we have observed that the words occupied in such relations are represented as aspect terms in many cases. “dobj”, “obj” and “xobj” are considered as the probable candidate relations for identifying the aspect 7http://nlp.stanford.edu/software/corenlp.shtml 8www.rednoise.org/rita/reference/RiWordNet.html terms. Here, the Stanford Parser9 has been used to get the dependency relations. Ontology Information (Liu, 2012): We have counted the aspect terms in the training data. The aspect terms occurred more than five times in the corpus are considered during our experiments. At first, we have tested this ontology information on the development set and observed that the aspect terms with frequency five or more also give better results in the test set. Sentiment Words: We have used the sentiment words as a feature for the sentiment identification tasks (Liu, 2012; Brody and Elhadad, 2010). Words are identified as positive, negative or neutral using SentiWordNet10. WordNet Information: The RiTa.WordNet package ha</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies 5, no. 1 (2012): 1-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Braja G Patra</author>
<author>Hiroya Takamura</author>
<author>Dipankar Das</author>
<author>Manabu Okumura</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Construction of Emotional Lexicon Using Potts Model.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Iatural Language Processing (IJCILP-2013),</booktitle>
<pages>674--679</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="6597" citStr="Patra et al., 2013" startWordPosition="995" endWordPosition="998">sing Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 http://people.csail.mit.edu/bsnyder/naacl07/ 5 http://www.citysearch.com/guide/newyork-ny-metro function (mvregress) to give rating (1 to 5) to each review. To determine the sentiment or polarity of the aspect term and aspect category, we need a prior sentiment annotated lexicon. Several works have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinion holder is or what t</context>
</contexts>
<marker>Patra, Takamura, Das, Okumura, Bandyopadhyay, 2013</marker>
<rawString>Braja G. Patra, Hiroya Takamura, Dipankar Das, Manabu Okumura, and Sivaji Bandyopadhyay. 2013. Construction of Emotional Lexicon Using Potts Model. In Proceedings of the 6th International Joint Conference on Iatural Language Processing (IJCILP-2013), Nagoya, Japan, pp. 674– 679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>WordNet Affect: an Affective Extension of WordNet.</title>
<date>2004</date>
<booktitle>In LREC,</booktitle>
<volume>4</volume>
<pages>1083--1086</pages>
<contexts>
<context position="6576" citStr="Strapparava and Valitutti, 2004" startWordPosition="991" endWordPosition="994">the experiments were carried out using Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 http://people.csail.mit.edu/bsnyder/naacl07/ 5 http://www.citysearch.com/guide/newyork-ny-metro function (mvregress) to give rating (1 to 5) to each review. To determine the sentiment or polarity of the aspect term and aspect category, we need a prior sentiment annotated lexicon. Several works have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinio</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava, and Alessandro Valitutti. 2004. WordNet Affect: an Affective Extension of WordNet. In LREC, vol. 4, pp. 1083-1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipankar Das</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Extracting emotion topics from blog sentences: use of voting from multi-engine supervised classifiers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2nd international workshop on Search and mining user-generated contents,</booktitle>
<pages>119--126</pages>
<contexts>
<context position="5215" citStr="Das and Bandyopadhyay, 2010" startWordPosition="796" endWordPosition="799">es of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple related aspect terms appeared in the text. For instance, in a restaurant review, such categories may include food, ambience and service etc. In our task, we call them as aspect or review categories. The authors implemented the Good Grief decoding algorithm on a corpus collected on restaurant review4, which outperforms over the famous PRank algorithm (Crammer and Singer, 2001). Ganu et al., (2009) have classified the restaurant reviews collected from City search New York5 into six categories namely Food, S</context>
</contexts>
<marker>Das, Bandyopadhyay, 2010</marker>
<rawString>Dipankar Das and Sivaji Bandyopadhyay. 2010. Extracting emotion topics from blog sentences: use of voting from multi-engine supervised classifiers. In Proceedings of the 2nd international workshop on Search and mining user-generated contents, pp. 119-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ganu Gayatree</author>
<author>Noemie Elhadad</author>
<author>Amelie Marian</author>
</authors>
<title>Beyond the stars: Improving rating predictions using review text content.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th International Workshop on the Web and Databases,</booktitle>
<location>Providence, Rhode Island.</location>
<marker>Gayatree, Elhadad, Marian, 2009</marker>
<rawString>Ganu Gayatree, Noemie Elhadad, and Amelie Marian. 2009. Beyond the stars: Improving rating predictions using review text content. In Proceedings of the 12th International Workshop on the Web and Databases, Providence, Rhode Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Iatural Language Processing (EMILP-2013),</booktitle>
<pages>129--136</pages>
<contexts>
<context position="7022" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="1059" endWordPosition="1062">orks have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinion holder is or what the opinion is about. Then, they have identified the polarity or sentiment of the fact using Naive Bayes classifier. Hu and Liu, (2004) has summarized the customer review and then identified the sentiment of that review. They have achieved promising accuracy in case of identifying polarity of the reviews. 3 Data The sentences collected from the customer reviews of Restaurants and Laptops are used in these tasks. The traini</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the Conference on Empirical Methods in Iatural Language Processing (EMILP-2013), pp. 129-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Pranking with ranking.</title>
<date>2001</date>
<booktitle>In IIPS,</booktitle>
<volume>14</volume>
<pages>641--647</pages>
<contexts>
<context position="5683" citStr="Crammer and Singer, 2001" startWordPosition="870" endWordPosition="873">ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple related aspect terms appeared in the text. For instance, in a restaurant review, such categories may include food, ambience and service etc. In our task, we call them as aspect or review categories. The authors implemented the Good Grief decoding algorithm on a corpus collected on restaurant review4, which outperforms over the famous PRank algorithm (Crammer and Singer, 2001). Ganu et al., (2009) have classified the restaurant reviews collected from City search New York5 into six categories namely Food, Service, Price, Ambience, Anecdotes, and Miscellaneous. Sentiment associated with each category has also been identified and both the experiments were carried out using Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 http://people.csail.mit.edu/bsnyder/naacl07/ 5 http://www.citysearch.com/guide/newyork-ny-metro function (mvregress) to give rating (1 to 5) to each review. To determine the sentim</context>
</contexts>
<marker>Crammer, Singer, 2001</marker>
<rawString>Koby Crammer and Yoram Singer. 2001. Pranking with ranking. In IIPS, vol. 14, pp. 641-647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML</booktitle>
<pages>282--289</pages>
<contexts>
<context position="12268" citStr="Lafferty et al., 2001" startWordPosition="1925" endWordPosition="1928">m tree of the synset of each word. Number of Sentence: It has been found that many reviews contain more than one sentence. Therefore, we have included the number of sentence as a feature based on the output of Stanford Parser. We have split the output of Stanford Parser by the mark, “(S”. In case of our experiments, the stop words are excluded. Total of 329 stop words was prepared manually. 5 Experimentation and Result Analysis We have used the CRF++ 0.58 11, an open source tool for implementing the machine learning framework for our experiments. CRF is well known for sequence labeling tasks (Lafferty et al., 2001). Similarly, in the present task, the aspect terms use the context information and are represented in sequences. Many of the aspect terms are multiword expressions such as “hard disk”. We have created different templates for different subtasks to capture all the relations between different sequence related features. 9http://nlp.stanford.edu/software/lex-parser.shtml 10http://sentiwordnet.isti.cnr.it/ 11http://crfpp.googlecode.com/svn/trunk/doc/index.htm 372 a. Classification of Aspect Term Features used in case of identifying aspect terms are POS, POS Frequency, Before be verb, Inanimate word,</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, Fernando C.N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of the 18th International Conference on Machine Learning (ICML 2001), pp. 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="4099" citStr="Hu and Liu, 2004" startWordPosition="621" endWordPosition="624">used in these experiments are described in Section 4. The detailed setup of experimentation and analysis of the results are described in Sec2 http://nlp.stanford.edu/software/lex-parser.shtml 3 http://sentiwordnet.isti.cnr.it/ 370 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 370–374, Dublin, Ireland, August 23-24, 2014. tion 5. Finally, conclusions and future directions are presented. 2 Related Work It has been observed that most of the previous works on aspect detection were based on information extraction, to find the most frequent noun phrases (Hu and Liu, 2004). This approach is generally useful in finding aspects which are strongly associated with a single noun. But, one principal disadvantage of this approach is that it cannot detect the aspect terms which are of low frequency and noun phrases (e.g., different names of dishes like Biryani, Dosa and Uttapam etc. for the aspect category, “food”). The proposed work of such problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhad</context>
<context position="7041" citStr="Hu and Liu, 2004" startWordPosition="1063" endWordPosition="1066">lding emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in a generic manner, without examining who the opinion holder is or what the opinion is about. Then, they have identified the polarity or sentiment of the fact using Naive Bayes classifier. Hu and Liu, (2004) has summarized the customer review and then identified the sentiment of that review. They have achieved promising accuracy in case of identifying polarity of the reviews. 3 Data The sentences collected from the customer reviews of Restaurants and Laptops are used in these tasks. The training data of Restaura</context>
<context position="8807" citStr="Hu and Liu, 2004" startWordPosition="1351" endWordPosition="1354">p://citeseerx.ist.psu.edu/index 371 4 Feature Analysis In general, the feature selection always plays an important role in any machine learning framework and depends upon the data set used for the experiments. Based on a preliminary investigation of the dataset, we have identified some of the following features. Different combinations of the features have also been used to get the best results from the classification task. Parts-of-Speech (POS): the aspect terms are basically represented by the noun phrases. On the other hand, the POS tag plays an important role in aspect term identification (Hu and Liu, 2004; Brody and Elhadad, 2010). Thus, we have used the Stanford CoreNLP7 tool to parse each of the review sentences to find out the part-of-speech tag of each word and included them as a feature in all of our experiments. POS Frequency: We have observed that the aspect terms surrounded by a noun or adjective are also denoted as aspect terms. Therefore, we have utilized this information in our system. For example, in the phrase “external_JJ mouse_NN”. Here the word “mouse” is an object and aspect term. The word “external” is also tagged as aspect term. Before be verb: We have observed that the noun</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 168-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In proceedings of the Human Language Technology Conference: Conference on Empirical Methods in Iatural Language Processing (HLT-EMILP).</booktitle>
<pages>339--346</pages>
<location>Morristown, NJ, USA,</location>
<contexts>
<context position="4565" citStr="Popescu and Etzioni 2005" startWordPosition="695" endWordPosition="698">en observed that most of the previous works on aspect detection were based on information extraction, to find the most frequent noun phrases (Hu and Liu, 2004). This approach is generally useful in finding aspects which are strongly associated with a single noun. But, one principal disadvantage of this approach is that it cannot detect the aspect terms which are of low frequency and noun phrases (e.g., different names of dishes like Biryani, Dosa and Uttapam etc. for the aspect category, “food”). The proposed work of such problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and target</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In proceedings of the Human Language Technology Conference: Conference on Empirical Methods in Iatural Language Processing (HLT-EMILP). Morristown, NJ, USA, pp. 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>Opinion digger: an unsupervised opinion miner from unstructured product reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management,</booktitle>
<pages>1825--1828</pages>
<marker>Moghaddam, Ester, 2010</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2010. Opinion digger: an unsupervised opinion miner from unstructured product reviews. In Proceedings of the 19th ACM international conference on Information and knowledge management, pp. 1825-1828.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of the Human Language Technologies: The 2010 Annual Conference of the Iorth American Chapter of the Association for Computational Linguistics (HLT-IAACL).</booktitle>
<contexts>
<context position="4708" citStr="Brody and Elhadad, 2010" startWordPosition="717" endWordPosition="720"> and Liu, 2004). This approach is generally useful in finding aspects which are strongly associated with a single noun. But, one principal disadvantage of this approach is that it cannot detect the aspect terms which are of low frequency and noun phrases (e.g., different names of dishes like Biryani, Dosa and Uttapam etc. for the aspect category, “food”). The proposed work of such problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple rel</context>
<context position="8833" citStr="Brody and Elhadad, 2010" startWordPosition="1355" endWordPosition="1358">psu.edu/index 371 4 Feature Analysis In general, the feature selection always plays an important role in any machine learning framework and depends upon the data set used for the experiments. Based on a preliminary investigation of the dataset, we have identified some of the following features. Different combinations of the features have also been used to get the best results from the classification task. Parts-of-Speech (POS): the aspect terms are basically represented by the noun phrases. On the other hand, the POS tag plays an important role in aspect term identification (Hu and Liu, 2004; Brody and Elhadad, 2010). Thus, we have used the Stanford CoreNLP7 tool to parse each of the review sentences to find out the part-of-speech tag of each word and included them as a feature in all of our experiments. POS Frequency: We have observed that the aspect terms surrounded by a noun or adjective are also denoted as aspect terms. Therefore, we have utilized this information in our system. For example, in the phrase “external_JJ mouse_NN”. Here the word “mouse” is an object and aspect term. The word “external” is also tagged as aspect term. Before be verb: We have observed that the nouns occur before the “be” ve</context>
<context position="11089" citStr="Brody and Elhadad, 2010" startWordPosition="1725" endWordPosition="1728">se.org/rita/reference/RiWordNet.html terms. Here, the Stanford Parser9 has been used to get the dependency relations. Ontology Information (Liu, 2012): We have counted the aspect terms in the training data. The aspect terms occurred more than five times in the corpus are considered during our experiments. At first, we have tested this ontology information on the development set and observed that the aspect terms with frequency five or more also give better results in the test set. Sentiment Words: We have used the sentiment words as a feature for the sentiment identification tasks (Liu, 2012; Brody and Elhadad, 2010). Words are identified as positive, negative or neutral using SentiWordNet10. WordNet Information: The RiTa.WordNet package has been used to extract different properties of the words. For aspect category identification, we have matched the hypernym tree of each word with the four categories (service, price, food, and ambience). If the hypernym tree does not contain any of such words, we check the next level hypernym tree of the words derived from hypernym of previous word. We have checked up to the second degree hypernym tree. We also searched hypernym tree of the synset of each word. Number o</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of the Human Language Technologies: The 2010 Annual Conference of the Iorth American Chapter of the Association for Computational Linguistics (HLT-IAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Extracting opinions, opinion holders, and topics expressed in online news media text.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Sentiment and Subjectivity in Text,</booktitle>
<pages>1--8</pages>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Extracting opinions, opinion holders, and topics expressed in online news media text. In Proceedings of the Workshop on Sentiment and Subjectivity in Text, pp. 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="6526" citStr="Baccianella et al., 2010" startWordPosition="985" endWordPosition="988">category has also been identified and both the experiments were carried out using Support Vector Machine classifiers. Finally, they implemented the regression based model containing MATLAB regression 4 http://people.csail.mit.edu/bsnyder/naacl07/ 5 http://www.citysearch.com/guide/newyork-ny-metro function (mvregress) to give rating (1 to 5) to each review. To determine the sentiment or polarity of the aspect term and aspect category, we need a prior sentiment annotated lexicon. Several works have been conducted on building emotional corpora in different English languages such as SentiWordNet (Baccianella et al., 2010), WordNet Affect (Strapparava and Valitutti, 2004) (Patra et al., 2013) etc. Among all these publicly available sentiment lexicons, SentiWordNet is one of the well-known and widely used ones (number of citations is higher than other resources6) that has been utilized in several applications such as sentiment analysis, opinion mining and emotion analysis. Several works have been performed on the automated opinion detection or polarity identification from reviews (Yu and Hatzivassiloglou, 2003; Hu and Liu, 2004). Yu and Hatzivassiloglou (2003) has focused on characterizing opinions and facts in </context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In LREC, vol. 10, pp. 2200-2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice H Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the fourth ACM international conference on Web search and data mining.</booktitle>
<contexts>
<context position="1977" citStr="Jo and Oh, 2011" startWordPosition="286" endWordPosition="289">ch efforts are being carried out for the identification of positive or negative polarity from the textual contents like sentence, paragraph, or text span regardless of the entities (e.g., laptops, restaurants) and their aspects (e.g., battery, screen; food, service). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 1http://www.saaip.org/ Aspect is a multinomial distribution over words that represent a more specific topic in reviews (Jo and Oh, 2011). For example, in case of Laptop reviews, “touchpad” is considered an aspect. Similarly, given a predefined entity, an aspect term describes a specific aspect of that entity (e.g., for the entity “restaurant”, “wine” can be an aspect term). Aspect term can be appeared as a single word (e.g., “menu”) or multiple words (“side dish”). It is observed that for a particular entity, one or more number of aspect terms can be grouped into a single category (e.g., aspect terms “drinks”, “main course” belongs to the same category, “food”). The main goal of the Aspect Based Sentiment Analysis (ABSA) (Pont</context>
<context position="5081" citStr="Jo and Oh, 2011" startWordPosition="777" endWordPosition="780">ch problem involves semantic hierarchy, rule-based or combination of both (Popescu and Etzioni 2005). More recent approaches of aspect detection are based on topic modelling, that use Latent Dirichlet Allocation (LDA) (Brody and Elhadad, 2010). But, the standard Latent Dirichlet Allocation (LDA) is not exactly suitable for the task of aspect detection due to their inherent nature of capturing global topics in the data, rather than finding local aspects related to the predefined entity. This approach was further modified in Sentence-LDA (SLDA) and Aspect and Sentiment Unification Model (ASUM) (Jo and Oh, 2011). Similarly, the identification of focussed text spans for opinion topics and targets were identified in (Das and Bandyopadhyay, 2010). Snyder and Barzilay (2007) addressed the problem of identifying categories for multiple related aspect terms appeared in the text. For instance, in a restaurant review, such categories may include food, ambience and service etc. In our task, we call them as aspect or review categories. The authors implemented the Good Grief decoding algorithm on a corpus collected on restaurant review4, which outperforms over the famous PRank algorithm (Crammer and Singer, 200</context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice H. Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of the fourth ACM international conference on Web search and data mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongwu Zhai</author>
<author>Bing Liu</author>
<author>Hua Xu</author>
<author>Peifa Jia</author>
</authors>
<title>Clustering product features for opinion mining.</title>
<date>2011</date>
<booktitle>In Proceedings of the fourth ACM international conference on Web search and data mining,</booktitle>
<pages>347--354</pages>
<marker>Zhai, Liu, Xu, Jia, 2011</marker>
<rawString>Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia. 2011. Clustering product features for opinion mining. In Proceedings of the fourth ACM international conference on Web search and data mining, pp. 347-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Haris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>SemEval-2014 Task 4: Aspect Based Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2594" citStr="Pontiki et al., 2014" startWordPosition="391" endWordPosition="394">011). For example, in case of Laptop reviews, “touchpad” is considered an aspect. Similarly, given a predefined entity, an aspect term describes a specific aspect of that entity (e.g., for the entity “restaurant”, “wine” can be an aspect term). Aspect term can be appeared as a single word (e.g., “menu”) or multiple words (“side dish”). It is observed that for a particular entity, one or more number of aspect terms can be grouped into a single category (e.g., aspect terms “drinks”, “main course” belongs to the same category, “food”). The main goal of the Aspect Based Sentiment Analysis (ABSA) (Pontiki et al., 2014) task is to identify the aspect terms and their categories from the given target entities as well as to identify the sentiments expressed towards each of the aspect terms. The datasets provided by the shared task organizers consist of customer reviews with human-annotations. We have participated in all of the four tasks. A combination of Conditional Random Field (CRF) based machine learning algorithm and rule based techniques has been adopted for identifying the aspect term, aspect category and their sentiments. We have used several features like Part of Speech (POS), Stanford dependency relat</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Haris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Ireland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>