<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012159">
<title confidence="0.9989485">
Fostering Digital Inclusion and Accessibility:
The PorSimples project for Simplification of Portuguese Texts
</title>
<author confidence="0.990552">
Sandra Maria Aluísio and Caroline Gasperin
</author>
<affiliation confidence="0.997793">
Department of Computer Sciences, University of São Paulo
</affiliation>
<address confidence="0.616007">
Av. Trabalhador São-Carlense, 400. 13560-970 - São Carlos/SP, Brazil
</address>
<email confidence="0.990085">
{sandra,cgasperin}@icmc.usp.br
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994797571428572">
In this paper we present the PorSimples
project, whose aim is to develop text adapta-
tions tools for Brazilian Portuguese. The tools
developed cater for both people at poor litera-
cy levels and authors that want to produce
texts for this audience. Here we describe the
tools and resources developed over two years
of this project and point directions for future
work and collaboration. Since Portuguese and
Spanish have many aspects in common, we
believe our main point for collaboration lies in
transferring our knowledge and experience to
researches willing to developed simplification
and elaboration tools for Spanish.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999827823529412">
In Brazil, according to the index used to measure
the literacy level of the population (INAF - Na-
tional Indicator of Functional Literacy) (INAF,
2007), only 28% of the population is classified as
literate at the advanced level, while 65% of the
population face difficulties in activities involving
reading and comprehension depending on text
length and complexity; therefore, their access to
textual media is limited. The latter ones belong to
the so-called rudimentary and basic literacy levels.
These people are only able to find explicit informa-
tion in short texts (rudimentary level) and also
process slightly longer texts and make simple infe-
rences (basic level).
The production of texts with different lengths
and complexities can be addressed by the task of
Text Adaptation (TA), a very well known practice
</bodyText>
<page confidence="0.991764">
46
</page>
<bodyText confidence="0.999815575757576">
in educational settings. Young (1999) and Burstein
(2009) mention two different techniques for TA:
Text Simplification and Text Elaboration.
The first can be defined as any task that reduces
the lexical or syntactic complexity of a text, while
trying to preserve meaning and information. Text
Simplification can be subdivided into Syntactic
Simplification, Lexical Simplification, Automatic
Summarization, and other techniques.
As to Text Elaboration, it aims at clarifying and
explaining information and making connections
explicit in a text, for example, providing short de-
finitions or synonyms for words known to only a
few speakers of a language.
The PorSimples project&apos; (Simplification of Por-
tuguese Text for Digital Inclusion and Accessibili-
ty) (Aluisio et al, 2008a) started in November 2007
and will finish in April 2010. It aims at developing
technologies to make access to information easier
for low-literacy individuals, and possibly for
people with other kinds of reading disabilities, by
means of Automatic Summarization, Lexical Sim-
plification, Syntactic Simplification, and Text Ela-
boration. More specifically, the goal is to help
these readers to process documents available on
the web. Additionally, it could help children learn-
ing to read texts of different genres, adults being
alphabetized, hearing-impaired people who com-
municate to each other using sign languages and
people undertaking Distance Education, in which
text intelligibility is of great importance.
The focus is on texts published in government
sites or by relevant news agencies, both of impor-
</bodyText>
<footnote confidence="0.976533">
1 http://caravelas.icmc.usp.br/wiki/index.php/Principal
</footnote>
<note confidence="0.9809205">
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 46–53, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998402">
tance to a large audience with various literacy le-
vels. The language of the texts is Brazilian Portu-
guese, for which there are no text simplification
systems to the best of our knowledge.
In the project we have developed resources in
Portuguese for research on text simplification, text
simplification technology for Portuguese, and cur-
rently we are developing and adapting resources
and technologies for text elaboration. We have also
built applications that make the developed technol-
ogy available to the public. In the Sections 2 to 4
we describe all these outcomes of the project.
We intend to foster a new interdisciplinary re-
search area to study written text comprehension
problems via the research on readability assess-
ment, text simplification and elaboration once Por-
Simples ends. In Section 5 we describe future
work, and in Section 6 we outline potential points
for collaboration with researchers from Brazil and
the rest of the Americas.
</bodyText>
<sectionHeader confidence="0.997549" genericHeader="introduction">
2 Resources
</sectionHeader>
<bodyText confidence="0.999993285714286">
In order to understand the task of text simplifica-
tion in Portuguese and to build training and evalua-
tion data for the systems developed in the project,
we have created a set of resources that formed the
basis of PorSimples. Moreover, we are currently
working on building resources for text elaboration.
Below we describe these resources.
</bodyText>
<sectionHeader confidence="0.564656" genericHeader="method">
2.1 Manual for Syntactic Simplification in Por-
tuguese
</sectionHeader>
<bodyText confidence="0.999897545454546">
We have created a Manual for Syntactic Simplifi-
cation for Portuguese (Specia et al., 2008). This
manual recommends how particular syntactic phe-
nomena should be simplified. It is based on a care-
ful study of the Brazilian Portuguese grammar, of
simplification systems developed for English (for
example, (Siddharthan, 2003)), and on the Plain
Language initiative2 (Aluisio et al., 2008b).
The manual was the basis for the development
of our rule-based system for syntactic simplifica-
tion described in Section 3.2.
</bodyText>
<subsectionHeader confidence="0.999899">
2.2 Corpora of Simple and Simplified Texts
</subsectionHeader>
<bodyText confidence="0.9995835">
We have built 9 corpora within 2 different genres
(general news and popular science articles). Our
</bodyText>
<footnote confidence="0.715293">
2 http://www.plainlanguage.gov/
</footnote>
<bodyText confidence="0.99980104">
first corpus is composed of general news articles
from the Brazilian newspaper Zero Hora (ZH orig-
inal). We had these articles manually simplified by
a linguist, specialized in text simplification, ac-
cording to the two levels of simplification pro-
posed in PorSimples, natural (ZH natural) and
strong (ZH strong). The Zero Hora newspaper also
provides along its articles a simple version of them
targeting children from 7 to 11 years old; this sec-
tion is called Para seu Filho Ler (ZH PFSL) and
our corpus from this section contains simple ar-
ticles corresponding to the articles in the ZH origi-
nal corpus plus additional ones.
Popular science articles compose our next set of
corpora. We compiled a corpus of these articles
from the Caderno Ciência issue of the Brazilian
newspaper Folha de São Paulo, a leading newspa-
per in Brazil (CC original). We also had this cor-
pus manually simplified according to the natural
(CC natural) and strong (CC strong) levels. We
also collected texts from a popular science maga-
zine called Ciência Hoje (CH) and from its version
aimed at children from 12-15, called Ciência Hoje
Crianca (CHC). Table 1 shows a few statistics
from these corpora.
</bodyText>
<subsectionHeader confidence="0.999779">
2.3 Dictionary of Simple Words
</subsectionHeader>
<bodyText confidence="0.9987277">
While for English some lexical resources that help
to identify difficult words using psycholinguistic
measures are available, such as the MRC Psycho-
linguistic Database3, no such resources exist for
Portuguese. In PorSimples, we have compiled a
dictionary of simple words composed by words
that are common to youngsters (from Biderman
(2005)), a list of frequent words from news texts
for children and nationwide newspapers and a list
of concrete words (from Janczura et. al (2007)).
</bodyText>
<table confidence="0.998930083333334">
Corpus Art. Sent Words Avg. words Avg.
. per text (std. words p.
deviation) sentence
ZH original 104 2184 46190 444.1 (133.7) 21.1
ZH natural 104 3234 47296 454.7 (134.2) 14.6
ZH strong 104 3668 47938 460.9 (137.5) 13.0
ZH PSFL 166 1224 22148 133.4 (48.6) 18.0
CC original 50 882 20263 405.2 (175.6) 22.9
CC natural 50 975 19603 392.0 (176.0) 20.1
CC strong 50 1454 20518 410.3 (169.6) 14.1
CH 130 3624 95866 737.4 (226.1) 26.4
CHC 127 3282 65124 512.7 (185.3) 19.8
</table>
<tableCaption confidence="0.999943">
Table 1. Corpus statistics.
</tableCaption>
<footnote confidence="0.955488">
3 http://www.psych.rl.ac.uk/
</footnote>
<page confidence="0.999595">
47
</page>
<bodyText confidence="0.992416666666667">
This dictionary is being used in applications de-
scribed in Section 4, such as SIMPLIFICA and the
Simplification Annotation Editor.
</bodyText>
<sectionHeader confidence="0.947615" genericHeader="method">
3 Simplification &amp; Elaboration technology
</sectionHeader>
<subsectionHeader confidence="0.998947">
3.1 Lexical Simplification
</subsectionHeader>
<bodyText confidence="0.999975540540541">
Lexical simplification consists on replacing com-
plex words by simpler words.
The first step of lexical simplification consists of
tokenizing the original text and selecting the words
that are considered complex. In order to judge a
word as complex or not, we use the dictionaries of
simple words described in Section 2.3.
The lexical simplification system also uses the
Unitex-PB dictionary4 for finding the lemma of the
words in the text, so that it is possible to look for it
in the simple words dictionaries. The problem of
looking for a lemma directly in a dictionary is that
there are ambiguous words and we are not able to
deal with different word senses. For dealing with
part-of-speech (POS) ambiguity, we use the
MXPOST POS tagger5 trained over NILC tagset6.
Among the words that were selected as com-
plex, the ones that are not proper nouns, preposi-
tions and numerals are processed: their POS tags
are used to look for their lemmas in the dictiona-
ries. As the tagger has not a 100% precision and
some words may not be in the dictionary, we look
for the lemma only (without the tag) when we are
not able to find the lemma-tag combination in the
dictionary. Still, if we are not able to find the word,
the lexical simplification module assumes that the
word is complex and marks it for simplification.
The last step of the process consists in providing
simpler synonyms for the complex words. For this
task, we use the thesauri for Portuguese TeP 2.07
and the lexical ontology for Portuguese PAPEL8.
This task is carried out when the user clicks on a
marked word, which triggers a search in the the-
sauri for synonyms that are also present in the
common words dictionary. If simpler words are
found, they are sorted from the simpler to the more
complex. To determine this order, we used Google
</bodyText>
<footnote confidence="0.9963815">
4 http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web
/dicionarios.html
5 http://sites.google.com/site/adwaitratnaparkhi/home
6 www.nilc.icmc.usp.br/nilc/TagSet/ManualEtiquetagem.htm
7 http://www.nilc.icmc.usp.br/tep2/
8 http://www.linguateca.pt/PAPEL/
</footnote>
<bodyText confidence="0.999551666666667">
API to search each word in the web: we assume
that the higher a word frequency, the simpler it is.
Automatic word sense disambiguation is left for
future work. In PorSimples, we aim to use Textual
Entailment (Dagan et al., 2005) as a method for
gathering resources for lexical simplification.
</bodyText>
<subsectionHeader confidence="0.999557">
3.2 Syntactic Simplification
</subsectionHeader>
<bodyText confidence="0.999988657894737">
Syntactic simplification is accomplished by a rule-
based system, which comprises seven operations
that are applied sentence-by-sentence to a text in
order to make its syntactic structure simpler.
Our rule-based text simplification system is
based on the manual for Brazilian Portuguese syn-
tactic simplification described in Section 2.1. Ac-
cording to this manual, simplification operations
should be applied when any of the 22 linguistic
phenomena covered by our system (see Candido et
al. (2009) for details) is detected. Our system treats
appositive, relative, coordinate and subordinate
clauses, which have already been addressed by
previous work on text simplification (Siddharthan,
2003). Additionally, we treat passive voice, sen-
tences in an order other than Subject-Verb-Object
(SVO), and long adverbial phrases. The simplifica-
tion operations to treat these phenomena are: split
sentence, change particular discourse markers by
simpler ones, change passive to active voice, invert
the order of clauses, convert to subject-verb-object
ordering, and move long adverbial phrases.
Each sentence is parsed in order to identify syn-
tactic phenomena for simplification and to segment
the sentence into portions that will be handled by
the operations. We use the parser PALAVRAS
(Bick, 2000) for Portuguese. Gasperin et al. (2010)
present the evaluation of the performance of our
syntactic simplification system.
Since our syntactic simplifications are conserva-
tive, the simplified texts become longer than the
original due to sentence splitting. We acknowledge
that low-literacy readers prefer short texts; this is
why we use summarization before applying simpli-
fication in FACILITA (see (Watanabe et al.,
2009)). In the future we aim to provide summariza-
tion also within SIMPLIFICA. These two applica-
tions are described in Section 4.
</bodyText>
<subsectionHeader confidence="0.991116">
3.3 Natural and Strong Simplification
</subsectionHeader>
<bodyText confidence="0.9999525">
To attend the needs of people with different levels
of literacy, PorSimples propose two types of sim-
</bodyText>
<page confidence="0.995456">
48
</page>
<bodyText confidence="0.999955219512195">
plification: natural and strong. The first is aimed at
people with a basic literacy level and the second,
rudimentary level. The difference between these
two is the degree of application of simplification
operations to the sentences. For strong simplifica-
tion we apply the syntactic simplification process
to all complex phenomena found in the sentence in
order to make the sentence as simple as possible,
while for natural simplification the simplification
operations are applied only when the resulting text
remains &amp;quot;natural&amp;quot;, considering the overall complex-
ity of the sentence. This naturalness is based on a
group of factors which are difficult to define using
hand-crafted rules, and we intend to learn them
from examples of natural simplifications.
We developed a corpus-based approach for se-
lecting sentences that require simplification. Based
on parallel corpora of original and natural simpli-
fied texts (ZH original, ZH natural, CC original,
CC natural), we apply a binary classifier to decide
in which circumstances a sentence should be split
or not so that the resulting simplified text is natural
and not over simplified. Sentence splitting is the
most important and most frequent syntactic simpli-
fication operation, and it can be seen as a key dis-
tinctive feature between natural and strong simpli-
fication. We described this system in detail in
(Gasperin et al., 2009).
Our feature set contains 209 features, including
superficial, morphological, syntactic and dis-
course-related features. We did several feature se-
lection experiments to determine the optimal set of
features. As classification algorithm we use We-
ka&apos;s9 SMO implementation of Support Vector Ma-
chines (SVM). The ZH corpus contains 728 exam-
ples of the splitting operation and 1328 examples
of non-split sentences, and the CC corpus contains
59 positive and 510 negatives examples. The clas-
sifier’s average performance scores (optimal fea-
ture set, both corpora as training data, and cross-
validation) are 80.5% precision and 80.7% recall.
</bodyText>
<subsectionHeader confidence="0.926098">
3.4 Readability Assessment
</subsectionHeader>
<bodyText confidence="0.999801">
We developed a readability assessment system that
can predict the complexity level of a text, which
corresponds to the literacy level expected from the
target reader: rudimentary, basic or advanced.
We have adopted a machine-learning classifier
</bodyText>
<footnote confidence="0.683728">
9 http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<bodyText confidence="0.99920675">
to identify the level of the input text; we use the
Support Vector Machines implementation from
Weka toolkit (SMO). We have used 7 of our cor-
pora presented in Section 2.2 (all but the ones with
texts written for children) to train the classifier.
Our feature set is composed by cognitively-
motivated features derived from the Coh-Metrix-
PORT tool10, which is an adaptation for Brazilian
Portuguese of Coh-Metrix 2.0 (free version of
Coh-Metrix (Graesser et al, 2004)) also developed
in the context of the PorSimples project. Coh-
Metrix-PORT implements the metrics in Table 2.
We also included seven new metrics to Coh-
Metrix-PORT: average verb, noun, adjective and
adverb ambiguity, incidence of high-level constitu-
ents, content words and functional words.
</bodyText>
<table confidence="0.972737441176471">
Categories Subcategories Metrics
Shallow - Flesch Reading Ease index
Readabili- for Portuguese.
ty metric
Words and Basic counts Number of words, sen-
textual tences, paragraphs, words
informa- per sentence, sentences per
tion paragraph, syllables per
word, incidence of verbs,
nouns, adjectives and ad-
verbs.
Frequencies Raw frequencies of content
words and minimum fre-
quency of content words.
Hyperonymy Average number of hyper-
nyms of verbs.
Syntactic Constituents Incidence of nominal
informa- phrases, modifiers per
tion noun phrase and words
preceding main verbs.
Pronouns, Incidence of personal pro-
Types and nouns, number of pronouns
Tokens per noun phrase, types and
tokens.
Connectives Number of connectives,
number of positive and
negative additive connec-
tives, causal / temporal /
logical positive and nega-
tive connectives.
Logical - Incidence of the particles
operators “e” (and), “ou” (or), “se”
(if), incidence of negation
and logical operators.
</table>
<tableCaption confidence="0.997602">
Table 2. Metrics of Coh-Metrix-PORT.
</tableCaption>
<bodyText confidence="0.9944595">
We measured the performance of the classifier
on identifying the levels of the input texts by a
</bodyText>
<footnote confidence="0.800874">
10 http://caravelas.icmc.usp.br:3000/
</footnote>
<page confidence="0.998159">
49
</page>
<bodyText confidence="0.99994625">
cross-validation experiment. We trained the clas-
sifier on our 7 corpora and reached 90% F-measure
on identifying texts at advanced level, 48% at basic
level, and 73% at rudimentary level.
</bodyText>
<subsectionHeader confidence="0.969842">
3.5 Semantic Role Labeling: Understanding
Sense Relations between Verb and Arguments
</subsectionHeader>
<bodyText confidence="0.999866807692308">
To attend the goal of eliciting sense relations be-
tween verbs and their arguments through the exhi-
bition of question words such as who, what, which,
when, where, why, how, how much, how many,
how long, how often and what for, we are specify-
ing a new annotation task that assigns these wh-
question labels to verbal arguments in a corpus of
simplified texts in Portuguese. The aim is to pro-
vide a training corpus for machine learning, aiming
at automatic assignment of wh-questions (Duran et
al., 2010a; Duran et al., 2010b).
The annotation task involves recognizing seg-
ments that constitute answers to questions made to
the verbs. Each segment should suitably answer the
wh-question label. For example, in the sentence
“João acordou às 6 horas da manhã.” (John woke
up at 6 in the morning.), two questions come up
naturally in relation to the verb “acordar” (wake
up): 1) Who woke up? and 2) When?.
Linking the verb and its arguments through wh-
questions is a process that requires text understand-
ing. This is a skill that the target audience of this
project is weak at. In Figure 1 we show the link
between the verb and its arguments (which can be
subject, direct object, indirect object, time or loca-
tion adverbial phrases, and also named entities).
</bodyText>
<figureCaption confidence="0.99794">
Figure 1. Assigning wh-question labels to arguments.
</figureCaption>
<bodyText confidence="0.99994952631579">
The corpus chosen for this work consists of the
strong simplified version of 154 texts extracted
from general news and popular science articles
(ZH strong and CC strong) which were described
in Section 2.2.
Results of such a semantic layer of annotation
may be used, in addition, to identify adjunct se-
mantic roles and multi-word expressions with spe-
cific adverbial syntactic roles. This training corpus,
as well as the automatic labeling tool, an “answer-
questioning” system, will be made publicly availa-
ble at PorSimples site. Besides helping poor-
literacy readers, the assignment of wh-questions
will be used in the near future to map adjunct se-
mantic roles (ArgMs of Propbank (Palmer et al.,
2005)) in a project to build the PropBank.Br for
Portuguese language. One may also take profit of
this automatic tool and its training corpus to im-
prove its opposite, question-answering systems.
</bodyText>
<sectionHeader confidence="0.99757" genericHeader="method">
4 Applications
</sectionHeader>
<bodyText confidence="0.999761666666667">
The text simplification and elaboration technolo-
gies developed in the context of the project are
available by means of three systems aimed to dis-
tinct users:
An authoring system, called SIMPLIFICA11, to
help authors to produce simplified texts target-
ing people with low literacy levels,
An assistive technology system, called FACI-
LITA12, which explores the tasks of summari-
zation and simplification to allow poor literate
people to read Web content, and
A web content adaptation tool, named Educa-
tional FACILITA, for assisting low-literacy
readers to perform detailed reading. It exhibits
questions that clarify the semantic relations
linking verbs to their arguments, highlighting
the associations amongst the main ideas of the
texts, named entities, and perform lexical ela-
boration.
In the following subsections we detail these and
other systems developed in the project.
</bodyText>
<subsectionHeader confidence="0.980461">
4.1 SIMPLIFICA Authoring Tool
</subsectionHeader>
<bodyText confidence="0.999992363636364">
SIMLIFICA is a web-based WYSIWYG editor,
based on TinyMCE web editor13. The user inputs a
text in the editor and customizes the simplification
settings, where he/she can choose: (i) strong sim-
plification, where all the complex syntactic phe-
nomena (see details in Section 3.2) are treated for
each sentence, or customized simplification, where
the user chooses one or more syntactic simplifica-
tion phenomena to be treated for each sentence,
and (ii) one or more thesauri to be used in the syn-
tactic and lexical simplification processes. Then
</bodyText>
<footnote confidence="0.82403175">
11 http://www.nilc.icmc.usp.br/porsimples/simplifica/
12 http://vinho.intermidia.icmc.usp.br:3001/facilita/
13 http://tinymce.moxiecode.com/
at 6 in the morning
</footnote>
<figure confidence="0.563189666666667">
When?
Who woke up?
John woke up
</figure>
<page confidence="0.986519">
50
</page>
<bodyText confidence="0.999964888888889">
the user activates the readability assessment mod-
ule to predict the complexity level of a text. This
module maps the text to one of the three levels of
literacy defined by INAF: rudimentary, basic or
advanced. According to the resulting readability
level the user can trigger the lexical and/or syntac-
tic simplifications modules, revise the automatic
simplification and restart the cycle by checking the
readability level of the current version of the text.
</bodyText>
<subsectionHeader confidence="0.782458">
4.2 FACILITA
</subsectionHeader>
<bodyText confidence="0.999950047619047">
FACILITA is a browser plug-in that aims to facili-
tate the reading of online content by poor literate
people. It includes separate modules for text sum-
marization and text simplification. The user can
select a text on any website and call FACILITA to
summarize and simplify this text. The system is
described in details in Watanabe et al. (2009).
The text summarization module aims to extract
only the most important information from a text. It
relies on the EPC-P technique (extraction of key-
words per pattern), which checks the presence of
keywords in the sentences: sentences that contain
keywords are retained for the final summary. The
summarization system is reported in Margarido et
al. (2008).
The text simplification module follows the syn-
tactic simplification framework described in Sec-
tion 3.2. We have chosen to run the summarization
process first and then proceed to the simplification
of the summarized text since simplification in-
creases text length.
</bodyText>
<subsectionHeader confidence="0.998122">
4.3 Educational FACILITA
</subsectionHeader>
<bodyText confidence="0.999861846153846">
Educational FACILITA14 is a Web application
aimed at assisting users in understanding textual
content available on the Web. Currently, it ex-
plores the NLP tasks of lexical elaboration and
named entity labeling to assist poor literacy readers
having access to web content. It is described in
Watanabe et al. (2010).
Lexical Elaboration consists of mechanisms that
present users with synonymous or short definitions
for words, which are classified as unusual or diffi-
cult to be understood by the users. This process
relies on the framework developed for lexical sim-
plification described in Section 3.1.
</bodyText>
<footnote confidence="0.816574">
14 http://vinho.intermidia.icmc.usp.br/watinha/Educational-
Facilita/
</footnote>
<bodyText confidence="0.9996799">
Named-entity labeling consists of displaying ad-
ditional and complementary semantic and descrip-
tive information about named entities that are con-
tained on the Web sites text. The descriptions are
extracted from Wikipedia.
It is expected that these additional information
presented in the text by the proposed approach
would help users better understand websites’ tex-
tual content and allow users to learn the meaning
of new or unusual words/expressions.
</bodyText>
<subsectionHeader confidence="0.998942">
4.4 Simplification Annotation Editor
</subsectionHeader>
<bodyText confidence="0.999983588235294">
This editor15 was created to support the manual
simplification of texts for the creation of our cor-
pus of simplified texts. It records and labels all the
operations made by the annotator and encode texts
using a new XCES16-based schema for linking the
original-simplified information. XCES has been
used in projects involving both only one language,
e.g. American National Corpus (ANC)17 (English)
and PLN-BR18 (Brazilian Portuguese); and mul-
tiple languages as parallel data, e.g.: CroCo19 (Eng-
lish-German). However, to our knowledge, Por-
Simples is the first project to use XCES to encode
original-simplified parallel texts and also the sim-
plification operations. Two annotation layers have
been added to the traditional stand-off annotation
layers in order to store the information related to
simplification (Caseli et al., 2009).
</bodyText>
<subsectionHeader confidence="0.99943">
4.5 Portal of Parallel Corpora
</subsectionHeader>
<bodyText confidence="0.9998355">
The portal20 allows for online querying and
download of our corpora of simplified texts. The
queries can include information about syntactic
constructions, simplification operations, etc.
</bodyText>
<sectionHeader confidence="0.998636" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.9998915">
Our main area for future work lies on the evalua-
tion of the simplified texts resulting from our sys-
tems with the end user, that is, people at low litera-
cy levels. We are carrying out a large-scale study
with readers who fit in the rudimentary and basic
literacy levels to verify whether syntactic and lexi-
</bodyText>
<footnote confidence="0.997782666666667">
15 http://caravelas.icmc.usp.br/anotador
16 http://www.w3.org/XML/
17 http://americannationalcorpus.org
18 http://www.nilc.icmc.usp.br/plnbr
19 http://fr46.uni-saarland.de/croco/index_en.html
20 http://caravelas.icmc.usp.br/portal/index.php
</footnote>
<page confidence="0.998816">
51
</page>
<bodyText confidence="0.999733947368421">
cal simplification indeed contribute to the under-
standing of Portuguese texts. We are applying
reading comprehension tests with original texts
(control group) and manually simplified texts at
strong level. However we still need to assess the
impact of automatic lexical and syntactic simplifi-
cation and text elaboration on the understanding of
a text by the target user of our applications.
We also intend to investigate how to balance
simplification/elaboration and text length. We have
shown that in our syntactic simplification approach
it is usual to divide long sentences, which reduce
sentence length but increase text length due to the
repetition of the subject in the new sentences. On
the other hand, in summarization-based Text Sim-
plification, such as FACILITA’s approach, text
length is reduced, but relevant information can be
lost, which may hinder text comprehensibility.
Text Elaboration enhances text comprehensibility,
but it always increases text length, since it inserts
information and repetition to reinforce understand-
ing and make explicit the connections between the
parts of a text. Therefore, since we cannot achieve
all the requisites at once there is a need to evaluate
each aspect of our systems with the target users.
We also intend to improve the performance of
our syntactic simplification approach by experi-
menting with different Portuguese syntactic pars-
ers. Moreover, several methods of text elaboration
are still under development and will be imple-
mented and evaluated in this current year.
As future research, we aim to explore the impact
of simplification on text entailment recognition
systems. We believe simplification can facilitate
the alignment of entailment pairs. In the opposite
direction, text entailment or paraphrase identifica-
tion may help us find word pairs for enriching the
lexical resources used for lexical simplification.
</bodyText>
<sectionHeader confidence="0.999899" genericHeader="method">
6 Opportunities for Collaboration
</sectionHeader>
<bodyText confidence="0.999973">
Enhancing the accessibility of Portuguese and
Spanish Web texts is of foremost importance to
improve insertion of Latin America (LA) into the
information society and to preserve the diverse
cultures in LA. We believe several countries in LA
present similar statistics to Brazil in relation to the
number of people at low literacy levels. We see our
experience in developing text simplification and
elaboration tools for Portuguese as the major con-
tribution that we can offer to other research groups
in LA. We are interested in actively taking part in
joint research projects that aim to create text sim-
plification and elaboration tools for Spanish.
Since all resources that we have developed are
language-dependent, they cannot be used directly
for Spanish, but we foresee that due to similarities
between Portuguese and Spanish a straightforward
adaptation of solutions at the lexical and syntactic-
al levels can be achieved with reasonable effort.
We are willing to share the lessons learned during
the PorSimples project and offer our expertise on
selecting and creating the appropriate resources
(e.g. corpora, dictionaries) and technology for text
simplification and elaboration in order to create
similar ones for Spanish.
The advances in text simplification and elabora-
tion methods strongly depend on the availability of
annotated corpora for several tasks: text simplifica-
tion, text entailment, semantic role labeling, to
name only a few. English has the major number of
data resources in Natural Language Processing
(NLP); Portuguese and Spanish are low-density
languages. To solve this problem, we believe that
there is a need for: (i) the development of a new
area recently coined as Annotation Science; (ii) a
centralized resource center to create, collect and
distribute linguistic resources in LA.
We would appreciate collaboration with re-
searchers in the USA in relation to readability as-
sessment measures, such as those of Coh-Metrix
(see Section 3.4), whose researchers already devel-
oped up to 500 measures. Only 60 of them are
open to public access. Besides, the know-how
needed to develop a proposition bank of Portu-
guese would be welcome since this involves lexi-
cal resources, such as a Verbnet21, which do not
exist for Portuguese. Other lexical resources such
as the MRC Psycholinguistic Database, which help
to identify difficult words using psycholinguistic
measures, are also urgent for Portuguese since we
have sparse projects dealing with several aspects of
this database but no common project to unite them.
Brazilian research funding agencies, mainly
CAPES22, CNPq23 and FAPESP24, often release
calls for projects with international collaboration;
these could be a path to start the collaborative re-
search suggested above.
</bodyText>
<footnote confidence="0.99727775">
21 http://verbs.colorado.edu/~mpalmer/projects/verbnet.html
22 http://www.capes.gov.br/
23 http://www.cnpq.br/
24 http://www.fapesp.br/
</footnote>
<page confidence="0.998198">
52
</page>
<sectionHeader confidence="0.999213" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99677">
We thank FAPESP and Microsoft Research for
supporting the PorSimples project.
</bodyText>
<sectionHeader confidence="0.995612" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999321441176471">
Sandra Aluisio, Lucia Specia, Thiago Pardo, Erick Ma-
ziero and Renata Fortes. 2008a. Towards Brazilian
Portuguese Automatic Text Simplification Systems.
In: Proceedings of The Eight ACM Symposium on
Document Engineering (DocEng 2008), 240-248,
São Paulo, Brazil.
Sandra Aluisio, Lucia Specia, Thiago Pardo, Erick Ma-
ziero, Helena de M. Caseli, Renata Fortes. 2008b. A
Corpus Analysis of Simple Account Texts and the
Proposal of Simplification Strategies: First Steps to-
wards Text Simplification Systems In: Proceedings
of The 26th ACM Symposium on Design of Commu-
nication (SIGDOC 2008), pp. 15-22.
Eckhard Bick. 2000. The Parsing System &amp;quot;Palavras&amp;quot;:
Automatic Grammatical Analysis of Portuguese in a
Constraint Grammar Framework. PhD Thesis. Aar-
hus University.
Maria Teresa Biderman. 2005. DICIONÁRIO ILU-
STRADO DE PORTUGUÊS. São Paulo, Editora
Ática. 1ª. ed. São Paulo: Ática. (2005)
Jill Burstein. 2009. Opportunities for Natural Language
Processing Research in Education. In the Proceedings
of CICLing, 6-27.
Arnaldo Candido Junior, Erick Maziero, Caroline Gas-
perin, Thiago Pardo, Lucia Specia and Sandra M.
Aluisio. 2009. Supporting the Adaptation of Texts
for Poor Literacy Readers: a Text Simplification Edi-
tor for Brazilian Portuguese. In the Proceedings of
the NAACL HLT Workshop on Innovative Use of
NLP for Building Educational Applications, pages
34–42, Boulder, Colorado, June 2009.
Helena Caseli, Tiago Pereira, Lucia Specia, Thiago Par-
do, Caroline Gasperin and Sandra Aluisio. 2009.
Building a Brazilian Portuguese parallel corpus of
original and simplified texts. In Alexander Gelbukh
(ed), Advances in Computational Linguistics, Re-
search in Computer Science, vol 41, pp. 59-70. 10th
Conference on Intelligent Text Processing and Com-
putational Linguistics (CICLing-2009).
Ido Dagan, Oren Glickman and Bernado Magnini. 2005.
The PASCAL Recognising Textual Entailment Chal-
lenge. In: Proceedings of The First PASCAL Recog-
nising Textual Entailment Challenge (RTE 1), [S.l.]:
Springer, 2005. p. 1–8.
Magali Duran, Marcelo Amâncio and Sandra Aluisio.
2010a. Assigning wh-questions to verbal arguments
in a corpus of simplified texts. Accepted for publica-
tion at Propor 2010 (http://www.inf.pucrs.br/~pro
por2010).
Magali Duran, Marcelo Amâncio and Sandra Aluisio.
2010b. Assigning Wh-Questions to Verbal Argu-
ments: Annotation Tools Evaluation and Corpus
Building. Accepted for publication in LREC 2010.
Caroline Gasperin, Lucia Specia, Tiago Pereira and
Sandra Aluisio. 2009. Learning When to Simplify
Sentences for Natural Text Simplification. In: Pro-
ceedings of ENIA 2009, 809-818.
Caroline Gasperin, Erick Masiero and Sandra M. Alui-
sio. 2010. Challenging choices for text simplifica-
tion. Accepted for publication at Propor 2010
(http://www.inf.pucrs.br/~propor201O).
O).
Arthur Graesser, Danielle McNamara, Max Louwerse
and Zhiqiang Cai. 2004. Coh-Metrix: Analysis of
text on cohesion and language. In: Behavioral Re-
search Methods, Instruments, and Computers, 36,
páginas 193-202.
INAF. 2007. Indicador de Alfabetismo Funcional IN-
AF/Brasil - 2007. Available at http://www.acaoedu
cativa.org.br/portal/images/stories/pdfs/inaf2007.pdf
Gerson A Janczura, Goiara M Castilho, Nelson O Ro-
cha, Terezinha de Jesus C. van Erven and Tin Po
Huang. 2007. Normas de concretude para 909 pala-
vras da lingua portuguesa. Psicologia: Teoria e Pes-
quisa Abr-Jun 2007, Vol. 23 n. 2, pp. 195-204.
Martha Palmer, Daniel Gildea and Paul Kingsbury.
2005. The Proposition Bank: A Corpus Annotated
with Semantic Roles, Computational Linguistics
Journal, 31:1.
Advaith Siddharthan. 2003. Syntactic Simplification
and Text Cohesion. PhD Thesis. University of
Cambridge.
Lucia Specia, Sandra Aluisio and Tiago Pardo. 2008.
Manual de Simplificação Sintática para o Português.
Technical Report NILC-TR-08-06, 27 p. Junho 2008,
São Carlos-SP.
Willian Watanabe, Arnaldo Candido Junior, Vinicius
Uzêda, Renata Fortes, Tiago Pardo and Sandra
Aluisio. 2009. Facilita: reading assistance for low-
literacy readers. In: Proceedings of the 27th ACM In-
ternational Conference on Design of Communica-
tion. SIGDOC &apos;09. ACM, New York, NY, 29-36.
Willian Watanabe, Arnaldo Candido Junior, Marcelo
Amancio, Matheus de Oliveira, Renata Fortes, Tiago
Pardo, Renata Fortes, Sandra Aluisio. 2010. Adapt-
ing web content for low-literacy readers by using lex-
ical elaboration and named entities labeling. Ac-
cepted for publication at W4A 2010
(http://www.w4a.info/).
Dolly J. Young. Linguistic simplification of SL reading
material: effective instructional practice. The Modern
Language Journal, 83(3):350–366, 1999.
</reference>
<page confidence="0.99935">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.399153">
<title confidence="0.999494">Fostering Digital Inclusion and Accessibility: The PorSimples project for Simplification of Portuguese Texts</title>
<author confidence="0.994922">Sandra Maria Aluísio</author>
<author confidence="0.994922">Caroline</author>
<affiliation confidence="0.669692">Department of Computer Sciences, University of São Av. Trabalhador São-Carlense, 400. 13560-970 - São Carlos/SP,</affiliation>
<email confidence="0.89131">sandra@icmc.usp.br</email>
<email confidence="0.89131">cgasperin@icmc.usp.br</email>
<abstract confidence="0.995562533333333">In this paper we present the PorSimples project, whose aim is to develop text adaptations tools for Brazilian Portuguese. The tools developed cater for both people at poor literacy levels and authors that want to produce texts for this audience. Here we describe the tools and resources developed over two years of this project and point directions for future work and collaboration. Since Portuguese and Spanish have many aspects in common, we believe our main point for collaboration lies in transferring our knowledge and experience to researches willing to developed simplification and elaboration tools for Spanish.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sandra Aluisio</author>
</authors>
<title>Lucia Specia, Thiago Pardo, Erick Maziero and Renata Fortes. 2008a. Towards Brazilian Portuguese Automatic Text Simplification Systems. In:</title>
<date>2008</date>
<booktitle>Proceedings of The Eight ACM Symposium on Document Engineering (DocEng</booktitle>
<pages>240--248</pages>
<location>São Paulo, Brazil.</location>
<marker>Aluisio, 2008</marker>
<rawString>Sandra Aluisio, Lucia Specia, Thiago Pardo, Erick Maziero and Renata Fortes. 2008a. Towards Brazilian Portuguese Automatic Text Simplification Systems. In: Proceedings of The Eight ACM Symposium on Document Engineering (DocEng 2008), 240-248, São Paulo, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Aluisio</author>
<author>Lucia Specia</author>
<author>Thiago Pardo</author>
<author>Erick Maziero</author>
<author>Helena de M Caseli</author>
</authors>
<title>Renata Fortes. 2008b. A Corpus Analysis of Simple Account Texts and the Proposal of Simplification Strategies: First Steps towards Text Simplification Systems In:</title>
<date>2008</date>
<booktitle>Proceedings of The 26th ACM Symposium on Design of Communication (SIGDOC</booktitle>
<pages>15--22</pages>
<contexts>
<context position="2542" citStr="Aluisio et al, 2008" startWordPosition="378" endWordPosition="381">an be defined as any task that reduces the lexical or syntactic complexity of a text, while trying to preserve meaning and information. Text Simplification can be subdivided into Syntactic Simplification, Lexical Simplification, Automatic Summarization, and other techniques. As to Text Elaboration, it aims at clarifying and explaining information and making connections explicit in a text, for example, providing short definitions or synonyms for words known to only a few speakers of a language. The PorSimples project&apos; (Simplification of Portuguese Text for Digital Inclusion and Accessibility) (Aluisio et al, 2008a) started in November 2007 and will finish in April 2010. It aims at developing technologies to make access to information easier for low-literacy individuals, and possibly for people with other kinds of reading disabilities, by means of Automatic Summarization, Lexical Simplification, Syntactic Simplification, and Text Elaboration. More specifically, the goal is to help these readers to process documents available on the web. Additionally, it could help children learning to read texts of different genres, adults being alphabetized, hearing-impaired people who communicate to each other using </context>
<context position="5362" citStr="Aluisio et al., 2008" startWordPosition="808" endWordPosition="811">have created a set of resources that formed the basis of PorSimples. Moreover, we are currently working on building resources for text elaboration. Below we describe these resources. 2.1 Manual for Syntactic Simplification in Portuguese We have created a Manual for Syntactic Simplification for Portuguese (Specia et al., 2008). This manual recommends how particular syntactic phenomena should be simplified. It is based on a careful study of the Brazilian Portuguese grammar, of simplification systems developed for English (for example, (Siddharthan, 2003)), and on the Plain Language initiative2 (Aluisio et al., 2008b). The manual was the basis for the development of our rule-based system for syntactic simplification described in Section 3.2. 2.2 Corpora of Simple and Simplified Texts We have built 9 corpora within 2 different genres (general news and popular science articles). Our 2 http://www.plainlanguage.gov/ first corpus is composed of general news articles from the Brazilian newspaper Zero Hora (ZH original). We had these articles manually simplified by a linguist, specialized in text simplification, according to the two levels of simplification proposed in PorSimples, natural (ZH natural) and stron</context>
</contexts>
<marker>Aluisio, Specia, Pardo, Maziero, Caseli, 2008</marker>
<rawString>Sandra Aluisio, Lucia Specia, Thiago Pardo, Erick Maziero, Helena de M. Caseli, Renata Fortes. 2008b. A Corpus Analysis of Simple Account Texts and the Proposal of Simplification Strategies: First Steps towards Text Simplification Systems In: Proceedings of The 26th ACM Symposium on Design of Communication (SIGDOC 2008), pp. 15-22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eckhard Bick</author>
</authors>
<title>The Parsing System &amp;quot;Palavras&amp;quot;: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. PhD Thesis.</title>
<date>2000</date>
<institution>Aarhus University.</institution>
<contexts>
<context position="11747" citStr="Bick, 2000" startWordPosition="1822" endWordPosition="1823">harthan, 2003). Additionally, we treat passive voice, sentences in an order other than Subject-Verb-Object (SVO), and long adverbial phrases. The simplification operations to treat these phenomena are: split sentence, change particular discourse markers by simpler ones, change passive to active voice, invert the order of clauses, convert to subject-verb-object ordering, and move long adverbial phrases. Each sentence is parsed in order to identify syntactic phenomena for simplification and to segment the sentence into portions that will be handled by the operations. We use the parser PALAVRAS (Bick, 2000) for Portuguese. Gasperin et al. (2010) present the evaluation of the performance of our syntactic simplification system. Since our syntactic simplifications are conservative, the simplified texts become longer than the original due to sentence splitting. We acknowledge that low-literacy readers prefer short texts; this is why we use summarization before applying simplification in FACILITA (see (Watanabe et al., 2009)). In the future we aim to provide summarization also within SIMPLIFICA. These two applications are described in Section 4. 3.3 Natural and Strong Simplification To attend the nee</context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>Eckhard Bick. 2000. The Parsing System &amp;quot;Palavras&amp;quot;: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. PhD Thesis. Aarhus University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Teresa Biderman</author>
</authors>
<date>2005</date>
<editor>DICIONÁRIO ILUSTRADO DE PORTUGUÊS. São Paulo, Editora Ática. 1ª. ed. São Paulo: Ática.</editor>
<contexts>
<context position="7212" citStr="Biderman (2005)" startWordPosition="1109" endWordPosition="1110">trong (CC strong) levels. We also collected texts from a popular science magazine called Ciência Hoje (CH) and from its version aimed at children from 12-15, called Ciência Hoje Crianca (CHC). Table 1 shows a few statistics from these corpora. 2.3 Dictionary of Simple Words While for English some lexical resources that help to identify difficult words using psycholinguistic measures are available, such as the MRC Psycholinguistic Database3, no such resources exist for Portuguese. In PorSimples, we have compiled a dictionary of simple words composed by words that are common to youngsters (from Biderman (2005)), a list of frequent words from news texts for children and nationwide newspapers and a list of concrete words (from Janczura et. al (2007)). Corpus Art. Sent Words Avg. words Avg. . per text (std. words p. deviation) sentence ZH original 104 2184 46190 444.1 (133.7) 21.1 ZH natural 104 3234 47296 454.7 (134.2) 14.6 ZH strong 104 3668 47938 460.9 (137.5) 13.0 ZH PSFL 166 1224 22148 133.4 (48.6) 18.0 CC original 50 882 20263 405.2 (175.6) 22.9 CC natural 50 975 19603 392.0 (176.0) 20.1 CC strong 50 1454 20518 410.3 (169.6) 14.1 CH 130 3624 95866 737.4 (226.1) 26.4 CHC 127 3282 65124 512.7 (185</context>
</contexts>
<marker>Biderman, 2005</marker>
<rawString>Maria Teresa Biderman. 2005. DICIONÁRIO ILUSTRADO DE PORTUGUÊS. São Paulo, Editora Ática. 1ª. ed. São Paulo: Ática. (2005)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Burstein</author>
</authors>
<title>Opportunities for Natural Language Processing Research in Education.</title>
<date>2009</date>
<booktitle>In the Proceedings of CICLing,</booktitle>
<pages>6--27</pages>
<contexts>
<context position="1828" citStr="Burstein (2009)" startWordPosition="274" endWordPosition="275">e difficulties in activities involving reading and comprehension depending on text length and complexity; therefore, their access to textual media is limited. The latter ones belong to the so-called rudimentary and basic literacy levels. These people are only able to find explicit information in short texts (rudimentary level) and also process slightly longer texts and make simple inferences (basic level). The production of texts with different lengths and complexities can be addressed by the task of Text Adaptation (TA), a very well known practice 46 in educational settings. Young (1999) and Burstein (2009) mention two different techniques for TA: Text Simplification and Text Elaboration. The first can be defined as any task that reduces the lexical or syntactic complexity of a text, while trying to preserve meaning and information. Text Simplification can be subdivided into Syntactic Simplification, Lexical Simplification, Automatic Summarization, and other techniques. As to Text Elaboration, it aims at clarifying and explaining information and making connections explicit in a text, for example, providing short definitions or synonyms for words known to only a few speakers of a language. The Po</context>
</contexts>
<marker>Burstein, 2009</marker>
<rawString>Jill Burstein. 2009. Opportunities for Natural Language Processing Research in Education. In the Proceedings of CICLing, 6-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnaldo Candido Junior</author>
<author>Erick Maziero</author>
<author>Caroline Gasperin</author>
<author>Thiago Pardo</author>
<author>Lucia Specia</author>
<author>Sandra M Aluisio</author>
</authors>
<title>Supporting the Adaptation of Texts for Poor Literacy Readers: a Text Simplification Editor for Brazilian Portuguese.</title>
<date>2009</date>
<booktitle>In the Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>34--42</pages>
<location>Boulder, Colorado,</location>
<marker>Junior, Maziero, Gasperin, Pardo, Specia, Aluisio, 2009</marker>
<rawString>Arnaldo Candido Junior, Erick Maziero, Caroline Gasperin, Thiago Pardo, Lucia Specia and Sandra M. Aluisio. 2009. Supporting the Adaptation of Texts for Poor Literacy Readers: a Text Simplification Editor for Brazilian Portuguese. In the Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 34–42, Boulder, Colorado, June 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helena Caseli</author>
<author>Tiago Pereira</author>
<author>Lucia Specia</author>
<author>Thiago Pardo</author>
<author>Caroline Gasperin</author>
<author>Sandra Aluisio</author>
</authors>
<title>Building a Brazilian Portuguese parallel corpus of original and simplified texts.</title>
<date>2009</date>
<booktitle>In Alexander Gelbukh (ed), Advances in Computational Linguistics, Research in Computer Science,</booktitle>
<volume>41</volume>
<pages>59--70</pages>
<contexts>
<context position="24208" citStr="Caseli et al., 2009" startWordPosition="3746" endWordPosition="3749">a new XCES16-based schema for linking the original-simplified information. XCES has been used in projects involving both only one language, e.g. American National Corpus (ANC)17 (English) and PLN-BR18 (Brazilian Portuguese); and multiple languages as parallel data, e.g.: CroCo19 (English-German). However, to our knowledge, PorSimples is the first project to use XCES to encode original-simplified parallel texts and also the simplification operations. Two annotation layers have been added to the traditional stand-off annotation layers in order to store the information related to simplification (Caseli et al., 2009). 4.5 Portal of Parallel Corpora The portal20 allows for online querying and download of our corpora of simplified texts. The queries can include information about syntactic constructions, simplification operations, etc. 5 Future Work Our main area for future work lies on the evaluation of the simplified texts resulting from our systems with the end user, that is, people at low literacy levels. We are carrying out a large-scale study with readers who fit in the rudimentary and basic literacy levels to verify whether syntactic and lexi15 http://caravelas.icmc.usp.br/anotador 16 http://www.w3.or</context>
</contexts>
<marker>Caseli, Pereira, Specia, Pardo, Gasperin, Aluisio, 2009</marker>
<rawString>Helena Caseli, Tiago Pereira, Lucia Specia, Thiago Pardo, Caroline Gasperin and Sandra Aluisio. 2009. Building a Brazilian Portuguese parallel corpus of original and simplified texts. In Alexander Gelbukh (ed), Advances in Computational Linguistics, Research in Computer Science, vol 41, pp. 59-70. 10th Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernado Magnini</author>
</authors>
<title>The PASCAL Recognising Textual Entailment Challenge. In:</title>
<date>2005</date>
<booktitle>Proceedings of The First PASCAL Recognising Textual Entailment Challenge (RTE 1),</booktitle>
<pages>1--8</pages>
<publisher>Springer,</publisher>
<location>[S.l.]:</location>
<contexts>
<context position="10366" citStr="Dagan et al., 2005" startWordPosition="1619" endWordPosition="1622">dictionary. If simpler words are found, they are sorted from the simpler to the more complex. To determine this order, we used Google 4 http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web /dicionarios.html 5 http://sites.google.com/site/adwaitratnaparkhi/home 6 www.nilc.icmc.usp.br/nilc/TagSet/ManualEtiquetagem.htm 7 http://www.nilc.icmc.usp.br/tep2/ 8 http://www.linguateca.pt/PAPEL/ API to search each word in the web: we assume that the higher a word frequency, the simpler it is. Automatic word sense disambiguation is left for future work. In PorSimples, we aim to use Textual Entailment (Dagan et al., 2005) as a method for gathering resources for lexical simplification. 3.2 Syntactic Simplification Syntactic simplification is accomplished by a rulebased system, which comprises seven operations that are applied sentence-by-sentence to a text in order to make its syntactic structure simpler. Our rule-based text simplification system is based on the manual for Brazilian Portuguese syntactic simplification described in Section 2.1. According to this manual, simplification operations should be applied when any of the 22 linguistic phenomena covered by our system (see Candido et al. (2009) for details</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman and Bernado Magnini. 2005. The PASCAL Recognising Textual Entailment Challenge. In: Proceedings of The First PASCAL Recognising Textual Entailment Challenge (RTE 1), [S.l.]: Springer, 2005. p. 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magali Duran</author>
</authors>
<title>Marcelo Amâncio and Sandra Aluisio. 2010a. Assigning wh-questions to verbal arguments in a corpus of simplified texts. Accepted for publication at Propor</title>
<date>2010</date>
<note>(http://www.inf.pucrs.br/~pro por2010).</note>
<marker>Duran, 2010</marker>
<rawString>Magali Duran, Marcelo Amâncio and Sandra Aluisio. 2010a. Assigning wh-questions to verbal arguments in a corpus of simplified texts. Accepted for publication at Propor 2010 (http://www.inf.pucrs.br/~pro por2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magali Duran</author>
</authors>
<title>Marcelo Amâncio and Sandra Aluisio. 2010b. Assigning Wh-Questions to Verbal Arguments: Annotation Tools Evaluation and Corpus Building. Accepted for publication in LREC</title>
<date>2010</date>
<marker>Duran, 2010</marker>
<rawString>Magali Duran, Marcelo Amâncio and Sandra Aluisio. 2010b. Assigning Wh-Questions to Verbal Arguments: Annotation Tools Evaluation and Corpus Building. Accepted for publication in LREC 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Gasperin</author>
<author>Lucia Specia</author>
</authors>
<title>Tiago Pereira and Sandra Aluisio.</title>
<date>2009</date>
<booktitle>Proceedings of ENIA 2009,</booktitle>
<pages>809--818</pages>
<marker>Gasperin, Specia, 2009</marker>
<rawString>Caroline Gasperin, Lucia Specia, Tiago Pereira and Sandra Aluisio. 2009. Learning When to Simplify Sentences for Natural Text Simplification. In: Proceedings of ENIA 2009, 809-818.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Gasperin</author>
<author>Erick Masiero</author>
<author>Sandra M Aluisio</author>
</authors>
<title>Challenging choices for text simplification. Accepted for publication at Propor</title>
<date>2010</date>
<contexts>
<context position="11786" citStr="Gasperin et al. (2010)" startWordPosition="1826" endWordPosition="1829">, we treat passive voice, sentences in an order other than Subject-Verb-Object (SVO), and long adverbial phrases. The simplification operations to treat these phenomena are: split sentence, change particular discourse markers by simpler ones, change passive to active voice, invert the order of clauses, convert to subject-verb-object ordering, and move long adverbial phrases. Each sentence is parsed in order to identify syntactic phenomena for simplification and to segment the sentence into portions that will be handled by the operations. We use the parser PALAVRAS (Bick, 2000) for Portuguese. Gasperin et al. (2010) present the evaluation of the performance of our syntactic simplification system. Since our syntactic simplifications are conservative, the simplified texts become longer than the original due to sentence splitting. We acknowledge that low-literacy readers prefer short texts; this is why we use summarization before applying simplification in FACILITA (see (Watanabe et al., 2009)). In the future we aim to provide summarization also within SIMPLIFICA. These two applications are described in Section 4. 3.3 Natural and Strong Simplification To attend the needs of people with different levels of l</context>
</contexts>
<marker>Gasperin, Masiero, Aluisio, 2010</marker>
<rawString>Caroline Gasperin, Erick Masiero and Sandra M. Aluisio. 2010. Challenging choices for text simplification. Accepted for publication at Propor 2010 (http://www.inf.pucrs.br/~propor201O). O).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Graesser</author>
<author>Danielle McNamara</author>
<author>Max Louwerse</author>
<author>Zhiqiang Cai</author>
</authors>
<title>Coh-Metrix: Analysis of text on cohesion and language.</title>
<date>2004</date>
<journal>In: Behavioral Research Methods, Instruments, and Computers,</journal>
<volume>36</volume>
<pages>193--202</pages>
<contexts>
<context position="15221" citStr="Graesser et al, 2004" startWordPosition="2355" endWordPosition="2358"> level expected from the target reader: rudimentary, basic or advanced. We have adopted a machine-learning classifier 9 http://www.cs.waikato.ac.nz/ml/weka/ to identify the level of the input text; we use the Support Vector Machines implementation from Weka toolkit (SMO). We have used 7 of our corpora presented in Section 2.2 (all but the ones with texts written for children) to train the classifier. Our feature set is composed by cognitivelymotivated features derived from the Coh-MetrixPORT tool10, which is an adaptation for Brazilian Portuguese of Coh-Metrix 2.0 (free version of Coh-Metrix (Graesser et al, 2004)) also developed in the context of the PorSimples project. CohMetrix-PORT implements the metrics in Table 2. We also included seven new metrics to CohMetrix-PORT: average verb, noun, adjective and adverb ambiguity, incidence of high-level constituents, content words and functional words. Categories Subcategories Metrics Shallow - Flesch Reading Ease index Readabili- for Portuguese. ty metric Words and Basic counts Number of words, sentextual tences, paragraphs, words informa- per sentence, sentences per tion paragraph, syllables per word, incidence of verbs, nouns, adjectives and adverbs. Freq</context>
</contexts>
<marker>Graesser, McNamara, Louwerse, Cai, 2004</marker>
<rawString>Arthur Graesser, Danielle McNamara, Max Louwerse and Zhiqiang Cai. 2004. Coh-Metrix: Analysis of text on cohesion and language. In: Behavioral Research Methods, Instruments, and Computers, 36, páginas 193-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>INAF</author>
</authors>
<title>Indicador de Alfabetismo Funcional INAF/Brasil -</title>
<date>2007</date>
<note>Available at http://www.acaoedu cativa.org.br/portal/images/stories/pdfs/inaf2007.pdf</note>
<contexts>
<context position="1104" citStr="INAF, 2007" startWordPosition="161" endWordPosition="162">eracy levels and authors that want to produce texts for this audience. Here we describe the tools and resources developed over two years of this project and point directions for future work and collaboration. Since Portuguese and Spanish have many aspects in common, we believe our main point for collaboration lies in transferring our knowledge and experience to researches willing to developed simplification and elaboration tools for Spanish. 1 Introduction In Brazil, according to the index used to measure the literacy level of the population (INAF - National Indicator of Functional Literacy) (INAF, 2007), only 28% of the population is classified as literate at the advanced level, while 65% of the population face difficulties in activities involving reading and comprehension depending on text length and complexity; therefore, their access to textual media is limited. The latter ones belong to the so-called rudimentary and basic literacy levels. These people are only able to find explicit information in short texts (rudimentary level) and also process slightly longer texts and make simple inferences (basic level). The production of texts with different lengths and complexities can be addressed </context>
</contexts>
<marker>INAF, 2007</marker>
<rawString>INAF. 2007. Indicador de Alfabetismo Funcional INAF/Brasil - 2007. Available at http://www.acaoedu cativa.org.br/portal/images/stories/pdfs/inaf2007.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerson A Janczura</author>
<author>Goiara M Castilho</author>
<author>Nelson O Rocha</author>
<author>Terezinha de Jesus C van Erven</author>
<author>Tin Po Huang</author>
</authors>
<title>Normas de concretude para 909 palavras da lingua portuguesa. Psicologia: Teoria e Pesquisa Abr-Jun</title>
<date>2007</date>
<volume>23</volume>
<pages>195--204</pages>
<marker>Janczura, Castilho, Rocha, van Erven, Huang, 2007</marker>
<rawString>Gerson A Janczura, Goiara M Castilho, Nelson O Rocha, Terezinha de Jesus C. van Erven and Tin Po Huang. 2007. Normas de concretude para 909 palavras da lingua portuguesa. Psicologia: Teoria e Pesquisa Abr-Jun 2007, Vol. 23 n. 2, pp. 195-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: A Corpus Annotated with Semantic Roles,</title>
<date>2005</date>
<journal>Computational Linguistics Journal,</journal>
<volume>31</volume>
<contexts>
<context position="18914" citStr="Palmer et al., 2005" startWordPosition="2944" endWordPosition="2947">4 texts extracted from general news and popular science articles (ZH strong and CC strong) which were described in Section 2.2. Results of such a semantic layer of annotation may be used, in addition, to identify adjunct semantic roles and multi-word expressions with specific adverbial syntactic roles. This training corpus, as well as the automatic labeling tool, an “answerquestioning” system, will be made publicly available at PorSimples site. Besides helping poorliteracy readers, the assignment of wh-questions will be used in the near future to map adjunct semantic roles (ArgMs of Propbank (Palmer et al., 2005)) in a project to build the PropBank.Br for Portuguese language. One may also take profit of this automatic tool and its training corpus to improve its opposite, question-answering systems. 4 Applications The text simplification and elaboration technologies developed in the context of the project are available by means of three systems aimed to distinct users: An authoring system, called SIMPLIFICA11, to help authors to produce simplified texts targeting people with low literacy levels, An assistive technology system, called FACILITA12, which explores the tasks of summarization and simplificat</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea and Paul Kingsbury. 2005. The Proposition Bank: A Corpus Annotated with Semantic Roles, Computational Linguistics Journal, 31:1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Syntactic Simplification and Text Cohesion. PhD Thesis.</title>
<date>2003</date>
<institution>University of Cambridge.</institution>
<contexts>
<context position="5300" citStr="Siddharthan, 2003" startWordPosition="800" endWordPosition="801">valuation data for the systems developed in the project, we have created a set of resources that formed the basis of PorSimples. Moreover, we are currently working on building resources for text elaboration. Below we describe these resources. 2.1 Manual for Syntactic Simplification in Portuguese We have created a Manual for Syntactic Simplification for Portuguese (Specia et al., 2008). This manual recommends how particular syntactic phenomena should be simplified. It is based on a careful study of the Brazilian Portuguese grammar, of simplification systems developed for English (for example, (Siddharthan, 2003)), and on the Plain Language initiative2 (Aluisio et al., 2008b). The manual was the basis for the development of our rule-based system for syntactic simplification described in Section 3.2. 2.2 Corpora of Simple and Simplified Texts We have built 9 corpora within 2 different genres (general news and popular science articles). Our 2 http://www.plainlanguage.gov/ first corpus is composed of general news articles from the Brazilian newspaper Zero Hora (ZH original). We had these articles manually simplified by a linguist, specialized in text simplification, according to the two levels of simplif</context>
<context position="11150" citStr="Siddharthan, 2003" startWordPosition="1733" endWordPosition="1734">mprises seven operations that are applied sentence-by-sentence to a text in order to make its syntactic structure simpler. Our rule-based text simplification system is based on the manual for Brazilian Portuguese syntactic simplification described in Section 2.1. According to this manual, simplification operations should be applied when any of the 22 linguistic phenomena covered by our system (see Candido et al. (2009) for details) is detected. Our system treats appositive, relative, coordinate and subordinate clauses, which have already been addressed by previous work on text simplification (Siddharthan, 2003). Additionally, we treat passive voice, sentences in an order other than Subject-Verb-Object (SVO), and long adverbial phrases. The simplification operations to treat these phenomena are: split sentence, change particular discourse markers by simpler ones, change passive to active voice, invert the order of clauses, convert to subject-verb-object ordering, and move long adverbial phrases. Each sentence is parsed in order to identify syntactic phenomena for simplification and to segment the sentence into portions that will be handled by the operations. We use the parser PALAVRAS (Bick, 2000) fo</context>
</contexts>
<marker>Siddharthan, 2003</marker>
<rawString>Advaith Siddharthan. 2003. Syntactic Simplification and Text Cohesion. PhD Thesis. University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Specia</author>
</authors>
<title>Sandra Aluisio and Tiago Pardo.</title>
<date>2008</date>
<tech>Technical Report NILC-TR-08-06, 27 p. Junho</tech>
<note>São Carlos-SP.</note>
<marker>Specia, 2008</marker>
<rawString>Lucia Specia, Sandra Aluisio and Tiago Pardo. 2008. Manual de Simplificação Sintática para o Português. Technical Report NILC-TR-08-06, 27 p. Junho 2008, São Carlos-SP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willian Watanabe</author>
<author>Arnaldo Candido Junior</author>
</authors>
<title>Vinicius Uzêda, Renata Fortes, Tiago Pardo and Sandra Aluisio.</title>
<date>2009</date>
<booktitle>Proceedings of the 27th ACM International Conference on Design of Communication. SIGDOC &apos;09.</booktitle>
<pages>29--36</pages>
<publisher>ACM,</publisher>
<location>New York, NY,</location>
<marker>Watanabe, Junior, 2009</marker>
<rawString>Willian Watanabe, Arnaldo Candido Junior, Vinicius Uzêda, Renata Fortes, Tiago Pardo and Sandra Aluisio. 2009. Facilita: reading assistance for lowliteracy readers. In: Proceedings of the 27th ACM International Conference on Design of Communication. SIGDOC &apos;09. ACM, New York, NY, 29-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willian Watanabe</author>
<author>Arnaldo Candido Junior</author>
<author>Marcelo Amancio</author>
<author>Matheus de Oliveira</author>
</authors>
<title>Renata Fortes, Tiago Pardo, Renata Fortes, Sandra Aluisio.</title>
<date>2010</date>
<marker>Watanabe, Junior, Amancio, de Oliveira, 2010</marker>
<rawString>Willian Watanabe, Arnaldo Candido Junior, Marcelo Amancio, Matheus de Oliveira, Renata Fortes, Tiago Pardo, Renata Fortes, Sandra Aluisio. 2010. Adapting web content for low-literacy readers by using lexical elaboration and named entities labeling. Accepted for publication at W4A 2010 (http://www.w4a.info/).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dolly J Young</author>
</authors>
<title>Linguistic simplification of SL reading material: effective instructional practice.</title>
<date>1999</date>
<journal>The Modern Language Journal,</journal>
<volume>83</volume>
<issue>3</issue>
<contexts>
<context position="1808" citStr="Young (1999)" startWordPosition="271" endWordPosition="272">he population face difficulties in activities involving reading and comprehension depending on text length and complexity; therefore, their access to textual media is limited. The latter ones belong to the so-called rudimentary and basic literacy levels. These people are only able to find explicit information in short texts (rudimentary level) and also process slightly longer texts and make simple inferences (basic level). The production of texts with different lengths and complexities can be addressed by the task of Text Adaptation (TA), a very well known practice 46 in educational settings. Young (1999) and Burstein (2009) mention two different techniques for TA: Text Simplification and Text Elaboration. The first can be defined as any task that reduces the lexical or syntactic complexity of a text, while trying to preserve meaning and information. Text Simplification can be subdivided into Syntactic Simplification, Lexical Simplification, Automatic Summarization, and other techniques. As to Text Elaboration, it aims at clarifying and explaining information and making connections explicit in a text, for example, providing short definitions or synonyms for words known to only a few speakers o</context>
</contexts>
<marker>Young, 1999</marker>
<rawString>Dolly J. Young. Linguistic simplification of SL reading material: effective instructional practice. The Modern Language Journal, 83(3):350–366, 1999.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>