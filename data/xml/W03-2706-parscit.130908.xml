<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.995967">
Policies and Procedures for Spoken Dialogue Systems
</title>
<author confidence="0.992846">
Matthias Denecke
</author>
<affiliation confidence="0.977233">
Human Computer Interaction Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.798912">
Pittsburgh, PA, 15213
</address>
<email confidence="0.99838">
denecke@cs.cmu.edu
</email>
<sectionHeader confidence="0.996658" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99990975">
In this paper, we present a framework
for task oriented dialogue systems that
separates as much as possible the dif-
ferent concerns in the design of the sys-
tem. Specifically, we address how poli-
cies that control the form of interaction
can be specified independently of do-
main or language specific specifications.
We illustrate the application of policies
by way of specifying three confirmation
policies and apply them to four different
dialogue systems.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998716">
In spoken dialogue systems, there are often sev-
eral ways to determine the users&apos; intention. The
system may alter the sequence of questions and
database accesses to implement a dialogue strat-
egy that fulfills certain criteria, such as imposing
minimal burden on the user, or minimizing com-
plexity of the expected answers.
In this paper, we present a framework that al-
lows the system designer to specify and vary cri-
teria according to which the actions of the dia-
logue system are determined We proceed as fol-
lows. In section 2, we introduce a formal applica-
tion description. The application description con-
tains all the domain and language specific infor-
mation a generic dialogue manager needs to pro-
cess dialogues. In section 3, we propose a way to
annotate the elements of the application descrip-
tion with certain properties. Policies then deter-
mine which of the applicable actions can be se-
lected. To demonstrate the feasibility of our ap-
proach, we augmented four existing dialogue ap-
plications (that were designed previously without
property and policy specifications) by adding poli-
cies and were able to influence the interactions of
the system with the user &amp;quot;from the outside&amp;quot;.
</bodyText>
<sectionHeader confidence="0.993331" genericHeader="introduction">
2 The Framework
</sectionHeader>
<bodyText confidence="0.98780144">
In the following, we restrict ourselves to task ori-
ented dialogue systems for which the following
working hypothesis is true:
(i) The system needs to determine which task the
user would like the system to perform,
(ii) the dialogue system needs to determine all
parameters that are necessary for that task to
be performed, and
(iii) once the information described in (i) and (ii)
has been established, the dialogue system
passes control to the back end application that
executes the task.
The purpose of this hypothesis is to define the
responsibilities of the dialogue system. It is used
to derive a classification of dialogue state (called
abstract dialogue state, see section 2.5). Note that
step (i) and (ii) do not necessarily need to be exe-
cuted in that order, but the completion of step (i)
and (ii) is necessary before step (iii) can be exe-
cuted. In this paper, we concern ourselves with the
problem how the execution of step (i) and (ii) can
be controlled by means of a specification, called
policy specification. We show that policy specifi-
cations are orthogonal to the specifications used by
the dialogue manager to achieve (i) and (ii), such
</bodyText>
<page confidence="0.998498">
35
</page>
<bodyText confidence="0.999928571428571">
as ontologies, dialogue goal specifications and so
on. Policy specifications control selection of dia-
logue moves whenever the dialogue manager has
several alternatives to implement step (i) and (ii).
Furthermore, we address the question to what ex-
tent the policy specification is domain and lan-
guage independent.
</bodyText>
<subsectionHeader confidence="0.8848">
2.1 Representations
</subsectionHeader>
<bodyText confidence="0.999962115384615">
The representational formalism used in the frame-
work are multidimensinal typed feature structures
(Denecke and Yang, 2000), a simple generaliza-
tion of typed feature structures (Carpenter, 1992).
n dimensional typed feature structures are typed
feature structures in which the nodes are annotated
not with only one element drawn from an upper
semilattice, but with an n dimensional vector, each
element of which is drawn from an upper semilat-
tice (typed feature structures are multidimensional
feature structures of dimension 1). Unification and
subsumption are then defined componentwise on
the elements of the vectors.
This generalization is motivated by the need to
annotate semantic representations with attributes
relevant for dynamic selection of dialogue actions.
For example, multidimensional feature structures
allow us to express confidence annotation, or
whether a value of a feature path has been con-
firmed or not. The decision which policy to select
can be based (indirectly) on this information.
We would like to note, however, that the dia-
logue manager could in principle use any other de-
scription logic as long as that logic supports oper-
ations for subsumption, unification and determina-
tion of well-typedness.I
</bodyText>
<subsectionHeader confidence="0.967222">
2.2 Discourse
</subsectionHeader>
<bodyText confidence="0.99986955882353">
There are two kinds of dialogue state, referred to
as discourse (or concrete dialogue state) and ab-
stract dialogue state. The concrete dialogue state
is given by a tree shaped dialogue history along
the lines of (Grosz and Sidner, 1986). Each node
in the tree represents one turn and consists of three
components. These are the text of the utterance of
&apos;We also need to determine the compatibility between
representations, but this can be done using copying and uni-
fication. We also note at this point that subsumption is a
stronger relationship than compatibility; if one representa-
tion subsumes another, the representations are compatible,
whereas the opposite is not true.
that turn, its semantic representation and a repre-
sentation of the objects the semantic representa-
tion refers to. The representations are typed fea-
ture structures and contain domain specific con-
cepts. In contrast, the abstract dialogue state, de-
scribed in section 2.5, represents domain and lan-
guage independent properties of the concrete dia-
logue state.
The text, semantic representation and object
representation at a given turn in the dialogue t can
be referred to by the variables text (t), sem(t) and
objs(t). The variable text(t) refers to a text as
received from the speech recognizer, whereas the
variables sem (t) and objs(t) refer to a (possibly
empty) set of descriptions that represent the se-
mantics of the utterances and the objects, actions
and properties &amp;quot;in the real world&amp;quot; the utterance
refers to. The cardinality of sem(t) is greater than
one in the case of ambiguous parse trees, while the
cardinality of objs(t) is greater than one in case
there are multiply objects the utterance refers to.
</bodyText>
<subsectionHeader confidence="0.995597">
2.3 Primitives
</subsectionHeader>
<bodyText confidence="0.99990976">
As mentioned above, the dialogue system has sev-
eral degrees of freedom in selecting its next ac-
tion. In the current framework, possible actions
include (i) database access to resolve referring ex-
pressions, (ii) generation of information seeking
questions for slot filling or disjunctive questions
aiming at disambiguating results from a database
request, (iii) reactions to presupposition violations
for error handling, and (iv) passing control to the
back end application sanctioned by dialogue goals
once all relevant information has been established.
Each of these dialogue objects can be composed
of a set of primitive objects that form a canonical
base both of the dialogue objects and the function-
ality supported by the dialogue system. The prim-
itive objects ecapsulate functionality needed in the
dialogue manager, such as access of databases, or
invocation of a service in the back end application.
We proceed to define an ontology of these prim-
itive objects. This is similar to the approach taken
by (Crowley et al., 2002) who define an ontology
of objects for an application in computer vision.
Figure 1 illustrates how the objects are related to
each other. In the following section, we will define
dialogue objects in terms of the primitives.
</bodyText>
<page confidence="0.996782">
36
</page>
<subsectionHeader confidence="0.745242">
2.3.1 Constraints
</subsectionHeader>
<bodyText confidence="0.999505857142857">
Constraints partition the space created by the
abstract dialogue states. A constraint is of the form
o- : v o c where o- is the sort of the constraint, v is
a variable, c is a constant and 0 is a relation that
may or may not hold between c and v. Examples
of constraints are given below in section 2.5 when
the abstract dialogue state is introduced.
</bodyText>
<subsectionHeader confidence="0.937757">
2.3.2 Descriptions
</subsectionHeader>
<bodyText confidence="0.999938578947368">
Descriptions partition the space created by the
objects under discussion. Descriptions are of the
form a : F, where a is the sort of the descrip-
tion and F is a term in the chosen description logic
(typed feature structures in our case). Descriptions
come in three sorts, namely preconditions, post-
conditions and properties. It is the purpose of pre-
conditions and postconditions to make explicit a
contract of the dialogue object: The dialogue sys-
tem may choose to apply a given dialogue object
only if the dialogue state fulfills the constraints in
its precondition. But if it does so and the action
specified by the dialogue object can be carried out
successfully, then the dialogue object guarantees
that the dialogue state fulfills the constraints in its
postcondition after execution. On the other hand,
properties are descriptions of dialogue objects that
allow policies to select dialogue objects based on
their characteristics.
</bodyText>
<subsectionHeader confidence="0.933351">
2.3.3 Bindings
</subsectionHeader>
<bodyText confidence="0.9997386">
Bindings describe method invocations of the
back end application. There are two different
sorts, one for method invocations and one for asso-
ciative retrieval (such as database requests or web
searches).
</bodyText>
<subsectionHeader confidence="0.996541">
2.4 Dialogue Objects
</subsectionHeader>
<bodyText confidence="0.9948696">
The four kinds of dialogue objects, namely
databases, goals, moves, and presuppositions,
each of which consists of constraints, descriptions,
and bindings. We can now proceed to a formal
definition of dialogue objects.
</bodyText>
<equation confidence="0.6616506">
Definition 2.1 Dialogue Object A dialogue ob-
ject is a tttple DO = (D, C, S), where D —
{di, , dir„ di,. , dp} is a set of descriptions,
C = {ci,... , cp} is a set of constraints, and
S = {si, , sp} is a set of services.
</equation>
<bodyText confidence="0.999728666666666">
Informally, a dialogue object is not much more
than a notation of an 1F-THEN construct conve-
nient for dialogue processing. It says that if all
the constraints c, are satisfied and the information
in the discourse objs(t) is subsumed by one of
the descriptions di, but by none of the descrip-
tions dk, then it is appropriate to invoke the ser-
vices .31. The descriptions di are interpreted as
preconditions and the descriptions d&apos;A, as postcon-
ditions. It is expected that the invocation of the
services brings about enough information so that
after integration of that information into the dis-
course, objs(t +1) is subsumed by one of the d&apos;k
Surprisingly, the generic concept of dialogue
object is generic enough to describe all aspects of
task oriented dialogue processing that are needed
for our purposes. In the following, the different
dialogue objects are described in more detail.
</bodyText>
<table confidence="0.92743">
Database Presupp. Move Goal
DCB DCB DCB DCB
Descriptions 1 1 1
Constraints 1 1 I I I I I I I I I 1 1 1
Bindings I I I I I I I I I I I I 1 1 1
</table>
<figureCaption confidence="0.995007">
Figure 1: Ontology of objects
</figureCaption>
<subsectionHeader confidence="0.704955">
2.4.1 Databases
</subsectionHeader>
<bodyText confidence="0.9999927">
A database is a dialogue object where the pre-
conditions among the d, are interpreted as guards.
The information in the concrete dialogue state
needs to be at least as specific as one of the pre-
conditions. Using this mechanism, it is possible to
access databases only after certain information has
been established in the discourse.2 Figure 2 shows
a simple database specification stating that songs
can be retrieved from a database and inserted in
the discourse according to the conversion equa-
</bodyText>
<footnote confidence="0.9811285">
2This is helpful to have the user of a flight information
system specify, say, departure and arrival city first before a
database request takes place in order to avoid having too large
record sets copied in the concrete dialogue state
</footnote>
<page confidence="0.999371">
37
</page>
<bodyText confidence="0.99372675">
currently is. They are useful to avoid misunder-
standings and keep the dialogue on track.
tions, provided that either the name or the artist
of the song is given.
</bodyText>
<figure confidence="0.987385357142857">
database Song {
precondition:
obj_song
L ARTIST string]
or
obj_song
L NAME string]
bindings:
table Song {
Name = ARTIST
Artist = ARTIST
Filename = FILENAME
1;
};
</figure>
<figureCaption confidence="0.998021">
Figure 2: Database specification
</figureCaption>
<subsectionHeader confidence="0.65974">
2.4.2 Moves
</subsectionHeader>
<bodyText confidence="0.999986642857143">
A move is the specification of any communica-
tive action of the dialogue system. Moves typ-
ically result in utterances processed by the text-
to-speech system, but can also (alternatively or
in conjunction) modify display or environment
through service invocation. Dialogue moves are
similar to the ones described in (Bohlin et al.,
1999). A turn by the dialogue system consists of
a sequence of moves in which only the last move
cedes the turn to the user. Figure 3 shows an ex-
ample of the dialogue move. The purpose of the
postcondition is to prevent multiple instantiations
of the the same actions once it has been yielded
the desired result.
</bodyText>
<equation confidence="0.935159555555555">
move Song {
precondition:
[ obj_song]
postcondition:
obj_song
L NAME string]
goal:(PlaySong = determined) — &gt;
bindings:
say &amp;quot;What is the name of the song you
</equation>
<bodyText confidence="0.764374">
would like me to play?&amp;quot;
</bodyText>
<figure confidence="0.429841">
1;
</figure>
<figureCaption confidence="0.998381">
Figure 3: Move specification
</figureCaption>
<subsectionHeader confidence="0.827299">
2.4.3 Presuppositions
</subsectionHeader>
<bodyText confidence="0.983471666666667">
Presuppositions serve to specify actions to be
taken in cases where the user assumes the back
end application to be in a different state than it
</bodyText>
<subsectionHeader confidence="0.624985">
2.4.4 Goals
</subsectionHeader>
<bodyText confidence="0.999761545454545">
Dialogue goals establish the link between infor-
mation in the discourse and the services offered
by the back end application. There is exactly one
precondition for each dialogue goal. A dialogue
is said to be finalized (i.e., the goal is reached) iff
objs(t) is subsumed by the description of exactly
one goal. This implies that the descriptions for any
given pair of goals need to be incompatible in or-
der to avoid unreachable goals. 3 This condition
can be verified at compile time. Figure 4 shows a
simple dialogue goal specification.
</bodyText>
<figure confidence="0.994938181818182">
goal PlaySong {
precondition:
[act_playsong
[
obj_song
ARG
FILENAME string]
path:(Sobjs.[ARG FILENAME] : num =1)— &gt;
bindings:
playSong Sobjs.[ARG FILENAME];
1;
</figure>
<figureCaption confidence="0.999781">
Figure 4: A dialogue goal.4
</figureCaption>
<subsectionHeader confidence="0.970249">
2.5 Abstract Dialogue State
</subsectionHeader>
<bodyText confidence="0.999985222222222">
The purpose of the abstract dialogue state is to de-
scribe in domain and language independent terms
how far the dialogue has progressed towards a
goal and how the progress has been achieved. It
can be seen as an ensemble of predicates that de-
scribe how the dialogue objects relate to the infor-
mation that has been established in the discourse
(Denecke, 2000). More specifically, the dialogue
manager needs to know which of the dialogue ob-
jects can be applied to the current dialogue. This
is dependent on the information established in the
discourse, as represented by sem(t) and objs(t).
Depending on the class and number of dialogue
objects that stand in a certain relationship to the
discourse, the dialogue manager decides on the
next action.
In order to determine the abstract dialogue state,
each description (as described in section 2.3.2) is
</bodyText>
<footnote confidence="0.56836925">
31f this were not the case, we had, e.g., precondition di of
goal I subsume precondition d2 of goal 2. This implies that
goal 1 is always reached before goal 2. Since a reached goal
means the end of the dialogue, goal 2 can never be reached.
</footnote>
<page confidence="0.997382">
38
</page>
<bodyText confidence="0.9986636">
endowed with a state. The state of a description
represents its relation with obj s(t). The following
example illustrates this by way of dialogue goals.
Consider the dialogue goals shown in figure 4 and
figure 5.
</bodyText>
<figure confidence="0.970904857142857">
goal PlaySong
precondition:
[ act_stopsong]
— &gt;
bindings:
stopSong ;
1;
</figure>
<figureCaption confidence="0.999945">
Figure 5: A second dialogue goal.
</figureCaption>
<bodyText confidence="0.999966944444445">
Before the dialogue starts, we have sem(0) =
obj s(0) = I. Assume the users&apos; input is &amp;quot;Please
play me some music.&amp;quot;. Assuming that speech
recognition and parsing succeed, the semantic rep-
resentation sem(1) equals [act_playsong]. The
description of goal 2 is incompatible with obj s (1) ,
meaning that goal 2 cannot possibly represent the
users&apos; intention. The description of goal 1 is
compatible with obj s(1) but does not subsume
objs (1). In order for objs(t) to be subsumed by
the description of goal 1, the information which
song the user wishes to hear needs to be estab-
lished. The dialogue system asks an information
seeking question accordingly, integrates the infor-
mation provided by the user, performs a database
request to retrieve the name of the song and in-
tegrates that information in the discourse to form
obj s (2). Now, we have
</bodyText>
<equation confidence="0.697093">
obj s(2) = act_playsong (1)
</equation>
<bodyText confidence="0.998446">
meaning that the intention of the user has been de-
termined uniquely, and all necessary information
is in place.
A variable called Intention represents the fol-
lowing relationships between the descriptions of
dialogue goals anf objs(t). Possible values are
selected (more than one dialogue goal is compat-
ible with objs(t), determined (exactly one dia-
logue goal is compatible with objs(t), but does not
subsume it), finalized (exactly one dialogue goal
subsumes objs(t)) and inconsistent (no dialogue
goal is compatible with objs(t).
</bodyText>
<tableCaption confidence="0.543508">
Table 1 summarizes the above example w.r.t.
the values of intention.
</tableCaption>
<table confidence="0.99964525">
Turn 11O 1 2
Goal 1 compatible compatible subsumes
Goal 2 compatible incompatible incompatible
Intention selected determined finalized
</table>
<tableCaption confidence="0.999879">
Table 1: Example
</tableCaption>
<bodyText confidence="0.99872815">
Note that the last line of the table does not
rely on any domain specific specifications. Con-
sequently, the variable Intention allows us to
formulate dialogue strategies independent of the
application domain. For example, we can ex-
press the following (simplistic) dialogue strat-
egy using constraints over the variable Intention:
If variable : (Intention = selected) holds,
ask disambiguation question between the goals,
if variable : (Intention = determined), ask
information seeking question for unfilled feature
paths, if variable : (Intention = finalized),
confirm the execution of the goal, and if variable :
(Intention = inconsistent), apologize and start
over. This strategy works independently if the user
wants to order pizza or book a flight.
Assuming monotonically increasing specificity
of objs(t) over time, the value of variable
Intention can change only according to the di-
agram in figure 6 (cf. the last line in table 1).
</bodyText>
<figure confidence="0.966623">
Selected Determined
■66,
Inconsistent
</figure>
<figureCaption confidence="0.932072666666667">
Figure 6: Possible transitions of the values of the
variable Intention, assuming monotonic increasing
representations in the discourse.
</figureCaption>
<bodyText confidence="0.961272625">
Similarly, we can abstract over the states of the
databases, presuppositions and moves. However,
there is a fundamental difference between goals
and the other dialogue objects. Dialogue goals
establish a link between the intention of the user
with the services to be invoked (cf. working as-
sumption in section 2). This in turn implies the re-
quirement that goals be incompatible (cf. section
2.4.4). Moves, database accesses and presupposi-
tions, however, are not subject to this requirement.
In fact, in the case of databases, presuppositions
and moves, we would like to have multiple objects
selected as possible actions. The resulting set of
possible actions can then be reranked using policy
specifications. The object with the highest ranking
Finalized
</bodyText>
<page confidence="0.988101">
39
</page>
<bodyText confidence="0.9999712">
represents the most appropriate action. In other
words, the transition from the state selected to the
state determined as shown in figure 6 is achieved
through applying a policy to all selected objects in
the case of databases, moves and presuppositions.
</bodyText>
<subsectionHeader confidence="0.997932">
2.6 Application Specification
</subsectionHeader>
<bodyText confidence="0.996241222222222">
The application specification for the dialogue
manager is the ensemble of dialgue objects, to-
gether with the ontology over which the feature
structures are defined. Appendix B shows a com-
plete example of a dialogue and the corresponding
abstract dialogue states.
Definition 2.2 Application Specification An ap-
plication specification AS is given by a tuple
AS = G, 111. P. D, GrP GrG) where 0 is
the ontology of domain specific concepts, G is the
set of goals, AI is the set of moves,P is the set
of presuppositions, and D is the set of databases.
In addition, parsing and generation grammars are
given by Gr&apos; and GrG , respectively
Due to the fact that we use typed feature struc-
tures for our description language, we have the on-
tology 0 given by the type hierarchy as needed for
typed feature structures, 0 = (Type. E).
</bodyText>
<sectionHeader confidence="0.800003" genericHeader="method">
3 Properties, Policies and Procedures
</sectionHeader>
<bodyText confidence="0.999954277777778">
In the previous section, we established an ontol-
ogy of dialogue object classes each of which con-
trols one aspect of the functionality of the dialogue
manager. It is our goal to control the form of the
dialogue by means of a specification, called pol-
icy specification, external to dialogue objects. For
each dialogue object, we need to be in position
to determine whether its execution implements the
current policy. We achieve this by endowing each
dialogue object (except goals, see below) with a
description of its properties (recall that descrip-
tions of dialogue objects come in three sorts, one
of which is properties). The properties can then
be checked against the properties required by the
current policy. A policy specification then induces
a binary function, called policy, that determines if
a given dialogue object adheres to the policy spec-
ification or not.
</bodyText>
<subsectionHeader confidence="0.984267">
3.1 Properties
</subsectionHeader>
<bodyText confidence="0.999788272727273">
Properties describe certain aspects of dialogue ob-
jects that are relevant for their selection. For ex-
ample, a question can be classified as one seeking
explicit confirmation of previously established in-
formation, or one implicitly confirming what has
been said while moving on to the next information
to be established.
Since it is not possible to predict all proper-
ties relevant to all applications, a vocabulary over
which properties are to be expressed needs to be
established.5
</bodyText>
<subsectionHeader confidence="0.994694">
3.2 Policies
</subsectionHeader>
<bodyText confidence="0.984492846153846">
Informally, a policy is a governing principle that
mandates or constrains actions. The actions to
be mandated or constrained, of course, are those
specified by the dialogue objects. In other words,
policies, mandate or constrain the application of
dialogue objects to the current dialogue. Poli-
cies describe how the interaction between dialogue
system and the user lead to one of the specified
goals. For this reason, goals are not subject to poli-
cies as they represent the final state of some inter-
action; subjecting dialogue goals to policies would
be alike to specifying interactions with varying
goals.
Definition 3.1 Policy Specification A pol-
icy specification is given by a tuple
P = C, DG, DM, DP) where the set of
constraints C = {ci, , cm} defines the do-
main of the policy, and the sets of descriptions
Diu = {diu , ,d111, DP = {Cif dnPl,
and DD , , el describe the prop-
erties of those goals, moves, presuppositions
and databases, respectively whose services are
permitted to be invoked under the policy P.
This leads then to the definition of policy as fol-
lows.
Definition 3.2 Policy A policy implemented by a
policy specification is a mapping p(ads, d) = do
from an abstract dialogue state ads and a dis-
course d to a dialogue object do where do is a pre-
5This seems to be contradictory to the claim that proper-
ties are domain independent. However, if existing property
vocabularies are found to be inappropriate for new applica-
tions, new property vocabularies (say, for a high security ap-
plication), can be established. These, in turn, can be applied
to existing applications. This does not always make sense,
so it might be advisable to establish &amp;quot;classes of applications&amp;quot;
such as internet shopping, tutorial application, high security
applications, etc., each of which comes with its own property
vocabulary specific to that class of application.
</bodyText>
<page confidence="0.996539">
40
</page>
<bodyText confidence="0.8985875">
supposition, move or database such that its pre-
conditions and constraints are satisfied.
</bodyText>
<subsectionHeader confidence="0.963373">
3.3 Procedures
</subsectionHeader>
<bodyText confidence="0.999843461538461">
The mechanisms introduced so far allow to anno-
tate dialogue objects with properties and to ex-
press desired properties in policies. In addition,
there needs to be an instance that determines di-
alogue objects according to the selected policies
and controls their execution. This is done by pro-
cedures. In the current implementation of the sys-
tem, there are four different procedures. Each pro-
cedure is responsible for generating a sequence of
speech acts, called interaction pattern, designed to
update the informational content in the discourse.
The procedures can generate the following inter-
action sequences.
</bodyText>
<listItem confidence="0.96532952173913">
1. The QUESTION interaction pattern seeks to
obtain information from the user to be added
to the discourse. An example is &amp;quot;Would
you like a,b or c?&amp;quot;.
2. The UNDO interaction pattern causes to re-
move information from the discourse. This
interaction pattern can be triggered through
user utterances such as &amp;quot;Undo&amp;quot; or &amp;quot;No,
not a.&amp;quot;.
3. The CORRECTION interaction pattern both
adds and removes information from the
discourse. Examples are &amp;quot;I said a not
b&amp;quot; (for a user initiated example) or &amp;quot;I do
not know a b but I do know a c
or d b. Which one would you
like? for cooperative system initiated
example.
4. The STATE interaction pattern does not add
to nor remove information from the discourse
but has influence on the dialogue flow. This
interaction pattern can be triggered through
user utterances such as &amp;quot;I don&apos;t know&amp;quot;,
&amp;quot;Repeat&amp;quot; or &amp;quot;Help&amp;quot;.
</listItem>
<bodyText confidence="0.997810833333333">
Please note that interaction patterns can be in-
stantiated in various shapes. The concrete shape
of the interaction pattern is determined as the
dialogue develops and depends on the abstract
classification of dialogue state. For example,
the dialogues &amp;quot;Would you like a,b or
</bodyText>
<note confidence="0.7087695">
C?&amp;quot; &amp;quot;a.&amp;quot; and &amp;quot;Would you like a,b or
C?&amp;quot; &amp;quot;a.&amp;quot; &amp;quot;Please say again.&amp;quot; &amp;quot;a.&amp;quot;
&amp;quot;Did you say a? Please say &apos;yes&apos;
or &apos;no&apos; . &amp;quot; &amp;quot;Yes . &amp;quot; are two instantiations of
</note>
<bodyText confidence="0.995549333333333">
the same interaction pattern. The selection of the
appropriate actions taken by the dialogue manager
is determined by the policies.
</bodyText>
<sectionHeader confidence="0.998464" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999036">
We conducted an experiment to verify the charac-
teristics of policies discussed in the previous sec-
tion. The goal of the experiment is to show that,
with the help of policy specifications, these appli-
cations can be extended such that
</bodyText>
<subsectionHeader confidence="0.895616">
4.1 Setup
</subsectionHeader>
<bodyText confidence="0.999881787878788">
We took four application specifications developed
by participants in a previous experiment (Denecke,
2002). In that experiment, the participants devel-
oped application specifications for different dia-
logue systems to demonstrate the system&apos;s capa-
bilities for rapid prototyping. The domain of the
application could be chosen freely by the partic-
ipants, as long as it was conform with the work-
ing hypothesis (cf. section 2). The dialogue ob-
jects in these application specifications do not con-
tain properties; nor are there policy specifications
available for those applications. The dialogues
generated by these application specifications do
not perform any form of explicit or implict con-
firmation.
As these specifications were designed for a pre-
vious version of the dialogue system, we had to
perform minor syntactic transformations (such as
the inclusion of namespaces). However, these
transformations did not alter the behavior of the
specified system.
We then determined the confirmation moves to
be added to the specification. We proceeded as
follows: First, we had to determine those feature
paths whose values can be enunciated by the user.
Then, we added a move for explicit confirmation
for each feature path. We also duplicated existing
moves and augmented the output by statements
confirming acquired information implicitly. Fi-
nally, we added moves to confirm all acquired in-
formation.
Example dialogues generated by a dialogue sys-
tem without confirmation policy (as specified by
</bodyText>
<page confidence="0.998671">
41
</page>
<bodyText confidence="0.999947">
one of the participants in the earlier experiment)
and dialogue with three different confirmation
policies are shown in appendix 5. Finally, we
specified four different policies as follows:
</bodyText>
<listItem confidence="0.894173">
(i) no confirmation,
(ii) explicit confirmation of everything that has
been said directly after the turn,
(iii) explicit confirmation of all goal relevant in-
formation just before the services associated
with the finalized goal are to be invoked,
(iv) implicit confirmation.
4.2 Property Vocabulary
</listItem>
<bodyText confidence="0.9995267">
As properties are expressed in typed feature struc-
ture, we need to define a signature (type hierar-
chy) over which the feature structures can be con-
structed. Since in this experiment, our concern is
the selection of confirmation questions, we need
to characterize the moves accordingly. The type
hierarchy used is shown in figure 7. This illustra-
tion is simplified in that only the speech acts and
properties are shown that are directly relevant to
the discussion.
</bodyText>
<figure confidence="0.481559333333333">
properties question answer
SPEECHACT : speechact
ISIMPLICIT : boolean speechact
</figure>
<figureCaption confidence="0.995996">
Figure 7: Vocabulary and type hierarchy used to
express properties of moves.
</figureCaption>
<subsectionHeader confidence="0.893829">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.9998462">
In all four cases, it was possible to &amp;quot;retrofit&amp;quot; the
existing application specifications such that each
system can run using one of the four policies.
This show that policies are independent of dia-
logue move specifications.
</bodyText>
<sectionHeader confidence="0.99513" genericHeader="method">
5 Summary
</sectionHeader>
<bodyText confidence="0.999986263157895">
We presented a framework for spoken dialogue
systems that separates the specification of a do-
main and language specific application specifica-
tion from a policy specification. The policy speci-
fication allows to control the form of the dialogue
independently from the domain.
Further work will investigate how to select poli-
cies automatically. The selection of policies could
be made dependent on the abstract dialogue state.
For example, a deteriorating dialogue would trig-
ger the selection of a policy favoring moves with
constrained anwers.
The presented framework would even be more
powerful if combined with a real generation gram-
mar, as opposed to the template based generation
that is used in the current implementation. Then,
the dialogue moves would specify a set of seman-
tic representations as well as a set of properties the
generated output needs to satisfy.
</bodyText>
<sectionHeader confidence="0.995883" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.985204923076923">
P. Bohlin, R. Cooper, E. Engdahl, and S. Larsson.
1999. Information states and dialogue move en-
gines. In IJCAI-99 Workshop on Knowledge and
Reasoning in Practical Dialogue Systems.
B. Carpenter. 1992. The Logic of Typed Feature Struc-
tures. Cambridge Tracts in Theoretical Computer
Science, Cambridge University Press.
J.L. Crowley, J. Coutaz, G. Rey, and P. Reignier. 2002.
Perceptual Components for Context Aware Comput-
ing. In UBICOMP 2002, International Conference
on Ubiquitous Computing, Goteborg, Sweden.
M. Denecke and J. Yang. 2000. Partial Information
in Multimodal Dialogue Systems. in Proceedings of
the International Conference on Multimodal Inter-
faces. Available at http://www.is.cs.cmu.edu.
M. Denecke. 2000. Informational Characterization
of Dialogue States. In Proceedings of the Interna-
tional Conference on Speech and Language Process-
ing, Beijing, China.
M. Denecke. 2002. Rapid Pprototyping for Spoken
Dialogue Systems. In Proceedings of the Inter-
national Conference on Computational Linguistics,
Taipei, Taiwan.
B. Grosz and C. Sidner. 1986. Attention, intentions,
and the structure of discourse. Computational Lin-
guistics, pages 175-204.
</reference>
<page confidence="0.996032">
42
</page>
<figure confidence="0.9923690625">
Detailed Example
dialogue object states
User:&amp;quot;Please play some music&amp;quot;
t 7:3 &amp;quot;t Ct t
C.) 02. &amp;quot;&apos;t &amp;quot;333 &amp;quot;333 723
c) Q.: g- &amp;quot;--&apos; g- --, --., •■■-,
Q.) Z3 C..) t t t
II II II II II II II II II
v. uc cr.
0 0 0
o o o
.,. ..., • •-&apos; C)•0 a)
C.) c..) cL)
.... ;-. C. c.) 0
C)
d 6 vc • ,-.
0 0 .,..&apos;&amp;quot; 0 ,-- 3,&amp;quot; 0 • •-3, C7)
&apos; `33c C.) ;-• 3 c&amp;quot;&apos;&amp;quot; C.) C... IL&apos; 33..) C.- .7&amp;quot;-d Cl.) ).
2 CC) 0.) • ,-.
70 ). -.•
4g,s.,) „., t..., 42.2 .......,.......,
C.) Ct
1-3--■ I2 &apos;2.1 C: C: ,2,... cSa&apos; (1)
• .)•- •
W• •--1
• ,-. A .--6&apos; °
-o
-... -... -... -1...
C.) C..) C..) C..) C.)
C..) Ct ,.(Z
,J CL) &apos;• Ct
&apos;••••&apos; CJ C.3 C.3
c/J c/J 31) CL)
.D crJ •r-1
C.) ;4
• . .
Cil -,..,
C.) C.) Q.) CO (1) CL) Ct
uD
ti al,
Ct ,-I.
›.., a.)
ct
II II II II c.) a)
II II • -&apos; 0 -6
0
&amp;quot;..„
_ ,,, • ,--1 • ,-1 • ,-I
0 C/: 7,)
CL),
-,.. -,.. -,... &apos;2 0 &gt;
C..)
•-... 0 0
E 5
-_,
0
II II II II II II
uc
,C)
0-0 o ,-1
0-co
0-0 5. -c-d°
0: zt
0, -.0 Z3.) &amp;quot;-&lt;: •&amp;quot;..&amp;quot;) &amp;quot;&amp;quot;t): 7C$ • ,
CD
C..) 7i
CD
Ct ).■]&apos; 4.
CD ..•
E.1
•ft 01) V.&apos;
,C n
t Cl..)
o E, 44 • 1-1 ›l
C..1CD ;-1
= 0
,.t Z.:•• 0.4 0.1 .. l, bIJ . ,--1
0
a.)
•-_,.,..-, ■-,,-, sa, • . • .
0
0 &amp;quot;;---1&amp;quot; 0 7:/ ct CD
4 &amp;quot;,^-1 &amp;quot;,^-1
0
- =-1
-:-.-.&apos; -- -- -
i., &apos;-,, ° ,...,
„..,. ,...,
0
-0.
-0.
0
--
0
,..)
0
</figure>
<equation confidence="0.885567769230769">
,... z.
-0 --,
, -
=
0
-..., -.0 - 0 ,
.0 0 -0 , -
. . 0 ,&lt; 0
0 0 0 0w , 0 ,
..._. --, -; =,) 5
0 ^. 7 0 v
,-) a.) = ..t7.&apos; • ,-1
..&apos;., ;-
</equation>
<figure confidence="0.855280488888889">
0 ct --, v) W Z
9. A) Cl&apos;&amp;quot; 9&amp;quot; E7 2 w ;,, 0 z 0
T&apos;t
... t &apos;&apos; t&apos; c4 &lt; • ,-I
c..
z .2 .,: a z zt a z
70 -
0 zt =
.,, ,- 0 &apos;F&apos;_, 0
.._ .
._ ,i.,
: 0 cll LI-4
0 a.)a tr)
,-- :: cd &apos; • ,-,
&apos;77 0&apos; V
.,-. • .
,., :: 0 :: ^-4:0 ,- ,Sl-)
=
&gt;,
&gt;, 0 cv ct
0
5 C.).0 .0 174 m
CV
-0 &amp;quot;0 0 -0 c, ci: 0 CI)
:-■ ,-1
I) • ,-.
&apos;....
0.&apos;
,•n
,-0
cd
3&apos;. H
;tt)
,
cl
L ,
Ct 0
cf: • ,--1
C_)
42J 0
,--)
--, t v) ul v)
,_ .w 1...a ...., •W &apos;&apos;&apos;&apos;&apos; Ce &lt; 0 0
cA
,A
</figure>
<reference confidence="0.8768503">
Ct • ,--1
•.•.4,+ ■&apos;&apos;
- cu
a) col cz
c..)
• --, -0
cr. oi I)
•,.. ,._,
L-
= ct LS v)
</reference>
<page confidence="0.999779">
43
</page>
<sectionHeader confidence="0.992728" genericHeader="method">
Appendix B Evaluation Example Dialogues
</sectionHeader>
<bodyText confidence="0.951320375">
Call Michael
What is the first name of the person
you would like to call?
Michael.
What is the last name of the person
you would like to call?
Bett.
I am calling Michael Bett. Please wait.
</bodyText>
<subsectionHeader confidence="0.708113">
Call Michael
</subsectionHeader>
<bodyText confidence="0.9217145">
What is the first name of the person
you would like to call?
</bodyText>
<figure confidence="0.9067955">
Michael.
What is Michael&apos;s last name?
Bett.
I am calling Michael Bett. Please wait.
User:
System:
User:
System:
User:
System:
User:
System:
User:
System:
User:
System:
(a) Example dialogue without confirmation policy as
specified by one participant in the experiment.
(b) Example dialogue with implicit confirmation
policy. Please note that all necessary concepts are
confirmed.
Call Michael
</figure>
<bodyText confidence="0.977435111111111">
What is the first name of the person
you would like to call?
Michael.
What is Michael&apos;s last name?
Bett.
I am calling Michael Bett. Please wait.
(c) Example dialogue with implicit confirmation
policy. Please note that all necessary concepts are
confirmed. In one case.
</bodyText>
<sectionHeader confidence="0.994837166666667" genericHeader="method">
User:
System:
User:
System:
User:
System:
User:
System:
User:
System:
User:
System:
</sectionHeader>
<subsectionHeader confidence="0.577526">
Call Michael
</subsectionHeader>
<bodyText confidence="0.921788956521739">
You said you would like to make a call.
Is this correct?
Yes.
What is the first name of the person
you would like to call?
Michael.
You said you would like to call
Michael. Is this correct?
Yes.
What is Michael&apos;s last name?
Bett.
You said you would like to call
Michael Bett. Is this correct?
Yes.
I am calling Michael Bett. Please wait.
User:
System:
User:
System:
User:
System:
(d) Example dialogue with explicit confirmation
policy, confirmation taking place after each turn.
</bodyText>
<page confidence="0.997323">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.693727">
<title confidence="0.999964">Policies and Procedures for Spoken Dialogue Systems</title>
<author confidence="0.956401">Matthias</author>
<affiliation confidence="0.99155">Human Computer Interaction Carnegie Mellon</affiliation>
<address confidence="0.736654">Pittsburgh, PA,</address>
<email confidence="0.99978">denecke@cs.cmu.edu</email>
<abstract confidence="0.999308307692308">In this paper, we present a framework for task oriented dialogue systems that separates as much as possible the different concerns in the design of the system. Specifically, we address how policies that control the form of interaction can be specified independently of domain or language specific specifications. We illustrate the application of policies by way of specifying three confirmation policies and apply them to four different dialogue systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Bohlin</author>
<author>R Cooper</author>
<author>E Engdahl</author>
<author>S Larsson</author>
</authors>
<title>Information states and dialogue move engines.</title>
<date>1999</date>
<booktitle>In IJCAI-99 Workshop on Knowledge and Reasoning in Practical Dialogue Systems.</booktitle>
<contexts>
<context position="12050" citStr="Bohlin et al., 1999" startWordPosition="1982" endWordPosition="1985">rack. tions, provided that either the name or the artist of the song is given. database Song { precondition: obj_song L ARTIST string] or obj_song L NAME string] bindings: table Song { Name = ARTIST Artist = ARTIST Filename = FILENAME 1; }; Figure 2: Database specification 2.4.2 Moves A move is the specification of any communicative action of the dialogue system. Moves typically result in utterances processed by the textto-speech system, but can also (alternatively or in conjunction) modify display or environment through service invocation. Dialogue moves are similar to the ones described in (Bohlin et al., 1999). A turn by the dialogue system consists of a sequence of moves in which only the last move cedes the turn to the user. Figure 3 shows an example of the dialogue move. The purpose of the postcondition is to prevent multiple instantiations of the the same actions once it has been yielded the desired result. move Song { precondition: [ obj_song] postcondition: obj_song L NAME string] goal:(PlaySong = determined) — &gt; bindings: say &amp;quot;What is the name of the song you would like me to play?&amp;quot; 1; Figure 3: Move specification 2.4.3 Presuppositions Presuppositions serve to specify actions to be taken in </context>
</contexts>
<marker>Bohlin, Cooper, Engdahl, Larsson, 1999</marker>
<rawString>P. Bohlin, R. Cooper, E. Engdahl, and S. Larsson. 1999. Information states and dialogue move engines. In IJCAI-99 Workshop on Knowledge and Reasoning in Practical Dialogue Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures. Cambridge Tracts in Theoretical Computer Science,</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3534" citStr="Carpenter, 1992" startWordPosition="566" endWordPosition="567">gonal to the specifications used by the dialogue manager to achieve (i) and (ii), such 35 as ontologies, dialogue goal specifications and so on. Policy specifications control selection of dialogue moves whenever the dialogue manager has several alternatives to implement step (i) and (ii). Furthermore, we address the question to what extent the policy specification is domain and language independent. 2.1 Representations The representational formalism used in the framework are multidimensinal typed feature structures (Denecke and Yang, 2000), a simple generalization of typed feature structures (Carpenter, 1992). n dimensional typed feature structures are typed feature structures in which the nodes are annotated not with only one element drawn from an upper semilattice, but with an n dimensional vector, each element of which is drawn from an upper semilattice (typed feature structures are multidimensional feature structures of dimension 1). Unification and subsumption are then defined componentwise on the elements of the vectors. This generalization is motivated by the need to annotate semantic representations with attributes relevant for dynamic selection of dialogue actions. For example, multidimen</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>B. Carpenter. 1992. The Logic of Typed Feature Structures. Cambridge Tracts in Theoretical Computer Science, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Crowley</author>
<author>J Coutaz</author>
<author>G Rey</author>
<author>P Reignier</author>
</authors>
<title>Perceptual Components for Context Aware Computing.</title>
<date>2002</date>
<booktitle>In UBICOMP 2002, International Conference on Ubiquitous Computing,</booktitle>
<location>Goteborg, Sweden.</location>
<contexts>
<context position="7316" citStr="Crowley et al., 2002" startWordPosition="1166" endWordPosition="1169">handling, and (iv) passing control to the back end application sanctioned by dialogue goals once all relevant information has been established. Each of these dialogue objects can be composed of a set of primitive objects that form a canonical base both of the dialogue objects and the functionality supported by the dialogue system. The primitive objects ecapsulate functionality needed in the dialogue manager, such as access of databases, or invocation of a service in the back end application. We proceed to define an ontology of these primitive objects. This is similar to the approach taken by (Crowley et al., 2002) who define an ontology of objects for an application in computer vision. Figure 1 illustrates how the objects are related to each other. In the following section, we will define dialogue objects in terms of the primitives. 36 2.3.1 Constraints Constraints partition the space created by the abstract dialogue states. A constraint is of the form o- : v o c where o- is the sort of the constraint, v is a variable, c is a constant and 0 is a relation that may or may not hold between c and v. Examples of constraints are given below in section 2.5 when the abstract dialogue state is introduced. 2.3.2</context>
</contexts>
<marker>Crowley, Coutaz, Rey, Reignier, 2002</marker>
<rawString>J.L. Crowley, J. Coutaz, G. Rey, and P. Reignier. 2002. Perceptual Components for Context Aware Computing. In UBICOMP 2002, International Conference on Ubiquitous Computing, Goteborg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denecke</author>
<author>J Yang</author>
</authors>
<title>Partial Information in Multimodal Dialogue Systems.</title>
<date>2000</date>
<booktitle>in Proceedings of the International Conference on Multimodal Interfaces. Available at http://www.is.cs.cmu.edu.</booktitle>
<contexts>
<context position="3463" citStr="Denecke and Yang, 2000" startWordPosition="554" endWordPosition="557">ion, called policy specification. We show that policy specifications are orthogonal to the specifications used by the dialogue manager to achieve (i) and (ii), such 35 as ontologies, dialogue goal specifications and so on. Policy specifications control selection of dialogue moves whenever the dialogue manager has several alternatives to implement step (i) and (ii). Furthermore, we address the question to what extent the policy specification is domain and language independent. 2.1 Representations The representational formalism used in the framework are multidimensinal typed feature structures (Denecke and Yang, 2000), a simple generalization of typed feature structures (Carpenter, 1992). n dimensional typed feature structures are typed feature structures in which the nodes are annotated not with only one element drawn from an upper semilattice, but with an n dimensional vector, each element of which is drawn from an upper semilattice (typed feature structures are multidimensional feature structures of dimension 1). Unification and subsumption are then defined componentwise on the elements of the vectors. This generalization is motivated by the need to annotate semantic representations with attributes rele</context>
</contexts>
<marker>Denecke, Yang, 2000</marker>
<rawString>M. Denecke and J. Yang. 2000. Partial Information in Multimodal Dialogue Systems. in Proceedings of the International Conference on Multimodal Interfaces. Available at http://www.is.cs.cmu.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denecke</author>
</authors>
<title>Informational Characterization of Dialogue States.</title>
<date>2000</date>
<booktitle>In Proceedings of the International Conference on Speech and Language Processing,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="13861" citStr="Denecke, 2000" startWordPosition="2291" endWordPosition="2292">ws a simple dialogue goal specification. goal PlaySong { precondition: [act_playsong [ obj_song ARG FILENAME string] path:(Sobjs.[ARG FILENAME] : num =1)— &gt; bindings: playSong Sobjs.[ARG FILENAME]; 1; Figure 4: A dialogue goal.4 2.5 Abstract Dialogue State The purpose of the abstract dialogue state is to describe in domain and language independent terms how far the dialogue has progressed towards a goal and how the progress has been achieved. It can be seen as an ensemble of predicates that describe how the dialogue objects relate to the information that has been established in the discourse (Denecke, 2000). More specifically, the dialogue manager needs to know which of the dialogue objects can be applied to the current dialogue. This is dependent on the information established in the discourse, as represented by sem(t) and objs(t). Depending on the class and number of dialogue objects that stand in a certain relationship to the discourse, the dialogue manager decides on the next action. In order to determine the abstract dialogue state, each description (as described in section 2.3.2) is 31f this were not the case, we had, e.g., precondition di of goal I subsume precondition d2 of goal 2. This </context>
</contexts>
<marker>Denecke, 2000</marker>
<rawString>M. Denecke. 2000. Informational Characterization of Dialogue States. In Proceedings of the International Conference on Speech and Language Processing, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denecke</author>
</authors>
<title>Rapid Pprototyping for Spoken Dialogue Systems.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="25268" citStr="Denecke, 2002" startWordPosition="4165" endWordPosition="4166">,b or C?&amp;quot; &amp;quot;a.&amp;quot; &amp;quot;Please say again.&amp;quot; &amp;quot;a.&amp;quot; &amp;quot;Did you say a? Please say &apos;yes&apos; or &apos;no&apos; . &amp;quot; &amp;quot;Yes . &amp;quot; are two instantiations of the same interaction pattern. The selection of the appropriate actions taken by the dialogue manager is determined by the policies. 4 Evaluation We conducted an experiment to verify the characteristics of policies discussed in the previous section. The goal of the experiment is to show that, with the help of policy specifications, these applications can be extended such that 4.1 Setup We took four application specifications developed by participants in a previous experiment (Denecke, 2002). In that experiment, the participants developed application specifications for different dialogue systems to demonstrate the system&apos;s capabilities for rapid prototyping. The domain of the application could be chosen freely by the participants, as long as it was conform with the working hypothesis (cf. section 2). The dialogue objects in these application specifications do not contain properties; nor are there policy specifications available for those applications. The dialogues generated by these application specifications do not perform any form of explicit or implict confirmation. As these </context>
</contexts>
<marker>Denecke, 2002</marker>
<rawString>M. Denecke. 2002. Rapid Pprototyping for Spoken Dialogue Systems. In Proceedings of the International Conference on Computational Linguistics, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>175--204</pages>
<contexts>
<context position="4818" citStr="Grosz and Sidner, 1986" startWordPosition="765" endWordPosition="768">tation, or whether a value of a feature path has been confirmed or not. The decision which policy to select can be based (indirectly) on this information. We would like to note, however, that the dialogue manager could in principle use any other description logic as long as that logic supports operations for subsumption, unification and determination of well-typedness.I 2.2 Discourse There are two kinds of dialogue state, referred to as discourse (or concrete dialogue state) and abstract dialogue state. The concrete dialogue state is given by a tree shaped dialogue history along the lines of (Grosz and Sidner, 1986). Each node in the tree represents one turn and consists of three components. These are the text of the utterance of &apos;We also need to determine the compatibility between representations, but this can be done using copying and unification. We also note at this point that subsumption is a stronger relationship than compatibility; if one representation subsumes another, the representations are compatible, whereas the opposite is not true. that turn, its semantic representation and a representation of the objects the semantic representation refers to. The representations are typed feature structur</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, pages 175-204.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ct</author>
</authors>
<title>1 •.•.4,+ ■&apos;&apos; - cu a) col cz c..</title>
<marker>Ct, </marker>
<rawString>Ct • ,--1 •.•.4,+ ■&apos;&apos; - cu a) col cz c..)</rawString>
</citation>
<citation valid="false">
<title>0 cr. oi I) •,..</title>
<journal>L= ct LS v</journal>
<marker></marker>
<rawString>• --, -0 cr. oi I) •,.. ,._, L= ct LS v)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>