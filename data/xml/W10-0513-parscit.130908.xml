<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.060662">
<title confidence="0.599358">
The Edinburgh Twitter Corpus
</title>
<author confidence="0.614583">
Saga Petrovic Miles Osborne Victor Lavrenko
</author>
<affiliation confidence="0.999166">
School of Informatics School of Informatics School of Informatics
University of Edinburgh University of Edinburgh University of Edinburgh
</affiliation>
<email confidence="0.99668">
sasa.petrovic@ed.ac.uk miles@inf.ed.ac.uk vlavrenk@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.995598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9979808">
We describe the first release of our corpus of
97 million Twitter posts. We believe that this
data will prove valuable to researchers working
in social media, natural language processing,
large-scale data processing, and similar areas.
</bodyText>
<sectionHeader confidence="0.998516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999889">
In the recent years, the microblogging service Twit-
ter has become a popular tool for expressing opin-
ions, broadcasting news, and simply communicating
with friends. People often comment on events in
real time, with several hundred micro-blogs (tweets)
posted each second for significant events. Despite
this popularity, there still does not exist a publicly
available corpus of Twitter posts. In this paper we
describe the first such corpus collected over a period
of two months using the Twitter streaming API.1
Our corpus contains 97 million tweets, and takes up
14 GB of disk space uncompressed. The corpus is
distributed under a Creative Commons Attribution-
NonCommercial-ShareAlike licensee and can be ob-
tained at http://demeter.inf.ed.ac.uk/. Each
tweet has the following information:
</bodyText>
<listItem confidence="0.7274554">
• timestamp – time (in GMT) when the tweet was
written
• anonymized username – the author of the tweet,
where the author’s original Twitter username
is replaced with an id of type userABC. We
anonymize the usernames in this way to avoid
malicious use of the data (e.g., by spammers).
Note that usernames are anonymized consis-
tently, i.e., every time user A is mentioned in
the stream, he is replaced with the same id.
</listItem>
<footnote confidence="0.991227">
1http://stream.twitter.com/
2http://creativecommons.org/licenses/by-nc-sa/3.0/
legalcode
</footnote>
<tableCaption confidence="0.999209">
Table 1: N-gram statistics.
</tableCaption>
<table confidence="0.9926036">
N-grams tokens unique
Unigrams 2,263,886,631 31,883,775
Bigrams 2,167,567,986 174,785,693
Trigrams 2,072,595,131 948,850,470
4-grams 1,980,386,036 1,095,417,876
</table>
<listItem confidence="0.617553666666667">
• posting method – method used to publish the
tweet (e.g., web, API, some Twitter client).
Given that there are dozen of Twitter clients in
use today, we believe this information could be
very useful in determining, e.g., any differences
in content that comes through different clients.
</listItem>
<bodyText confidence="0.999941428571429">
The format of our data is very simple. Each line
has the following format:
timestamp \t username \t tweet \t client
where \t is the tab character, and client is the pro-
gram used for posting the tweet. Note that the ad-
ditional whitespaces seen above are only added for
readability, and don’t exist in the corpus.
</bodyText>
<sectionHeader confidence="0.957356" genericHeader="method">
2 Corpus statistics
</sectionHeader>
<bodyText confidence="0.999821066666667">
We collected the corpus from a period spanning
November 11th 2009 until February 1st 2010. As was
already mentioned, the data was collected through
Twitter’s streaming API and is thus a representa-
tive sample of the entire stream. Table 1 shows the
basic n-gram statistics – note that our corpus con-
tains over 2 billion words. We made no attempt to
distinguish between English and non-English tweets,
as we believe that a multilingual stream might be of
use for various machine translation experiments.
Table 2 shows some basic statistics specific to the
Twitter stream. In particular, we give the number
of users that posted the tweets, the number of links
(URLs) in the corpus, the number of topics and the
number of replies. From the first two rows of Table 2
</bodyText>
<page confidence="0.975112">
25
</page>
<note confidence="0.94443">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 25–26,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<tableCaption confidence="0.997049">
Table 2: Twitter-specific statistics.
</tableCaption>
<table confidence="0.999790714285714">
Unique Total
tweets - 96,369,326
users 9,140,015 -
links - 20,627,320
topics 1,416,967 12,588,431
replies 5,426,030 54,900,387
clients 33,860 -
</table>
<tableCaption confidence="0.992497">
Table 3: Most cited Twitter users
</tableCaption>
<table confidence="0.683083272727273">
Username number of replies
@justinbieber 279,622
@nickjonas 95,545
@addthis 56,761
@revrunwisdom 51,203
@ 50,565
@luansantanaevc 49,106
@donniewahlberg 46,126
@eduardosurita 36,495
@fiuk 33,570
@ddlovato 32,327
</table>
<bodyText confidence="0.994933074074074">
we can see that the average number of tweets per user
is 10.5. Topics are defined as single word preceded by
a # symbol, and replies are single words preceded by
a @ symbol. This is the standard way Twitter users
add metadata to their posts. For topics and replies,
we give both the number of unique tokens and the
total number of tokens.
Table 3 shows a list of 10 users which received the
most replies. The more replies a user receives, more
influential we might consider him. We can see that
the two top ranking users are Justin Bieber and Nick
Jonas, two teenage pop-stars who apparently have a
big fan base on Twitter. In fact, six out of ten users
on the list are singers, suggesting that many artists
have turned to Twitter as a means of communicating
with their fans. Note also that one of the entries is
an empty username – this is probably a consequence
of mistakes people make when posting a reply.
Similarly to Table 3, Table 4 shows the ten most
popular topics in our corpus. We can see that the
most popular topics include music (#nowplaying,
#mm – music monday), jobs ads, facebook updates
(#fb), politics (#tcot – top conservatives on Twit-
ter), and random chatter (#ff – follow friday, #tiny-
chat, #fail, #formspringme). The topic #39;s is an
error in interpreting the apostrophe sign, which has
the ascii value 39 (decimal).
</bodyText>
<tableCaption confidence="0.989722">
Table 4: Most popular topics on Twitter
</tableCaption>
<table confidence="0.891779818181818">
Topic number of occurences
#nowplaying 255,715
#ff 220,607
#jobs 181,205
#fb 144,835
#39;s 110,150
#formspringme 85,775
#tcot 77,294
#fail 56,730
#tinychat 56,174
#mm 52,971
</table>
<figureCaption confidence="0.99444">
Figure 1: Different sources of tweets.
</figureCaption>
<bodyText confidence="0.987275888888889">
Figure 1 shows the ten most popular clients used
for posting to Twitter. Despite the large amount
of different Twitter clients used (over 33 thousand,
cf. Table 2), figure 1 shows that almost 80% of all the
tweets in our corpus were posted using one of the top
ten most popular clients. We can see that traditional
posting through the Twitter web site is still by far
the most popular method, while UberTwitter and
TweetDeck seem to be the next most popular choices.
</bodyText>
<sectionHeader confidence="0.999218" genericHeader="method">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.9986336">
In this paper we presented a corpus of almost 100
million tweets which we made available for public
use. Basic properties of the corpus are given and a
simple analysis of the most popular users and topics
revealed that Twitter is in large part used to talk
about music by communicating both with artists and
other fans. We believe that this corpus could be
a very useful resource for researchers dealing with
social media, natural language processing, or large-
scale data processing.
</bodyText>
<page confidence="0.995712">
26
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963914">
<title confidence="0.995768">The Edinburgh Twitter Corpus</title>
<author confidence="0.997489">Saga Petrovic Miles Osborne Victor Lavrenko</author>
<affiliation confidence="0.999856">School of Informatics School of Informatics School of Informatics University of Edinburgh University of Edinburgh University of Edinburgh</affiliation>
<email confidence="0.984013">sasa.petrovic@ed.ac.ukmiles@inf.ed.ac.ukvlavrenk@inf.ed.ac.uk</email>
<abstract confidence="0.9976415">We describe the first release of our corpus of 97 million Twitter posts. We believe that this data will prove valuable to researchers working in social media, natural language processing, large-scale data processing, and similar areas.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>