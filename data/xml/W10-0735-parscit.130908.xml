<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014846">
<title confidence="0.988018">
Error Driven Paraphrase Annotation using Mechanical Turk
</title>
<author confidence="0.996923">
Olivia Buzek
</author>
<affiliation confidence="0.995898">
Computer Science and Linguistics
University of Maryland
</affiliation>
<address confidence="0.845216">
College Park, MD 20742, USA
</address>
<email confidence="0.987912">
olivia.buzek@gmail.com
</email>
<author confidence="0.910297">
Philip Resnik
</author>
<affiliation confidence="0.896361">
Linguistics and UMIACS
University of Maryland
</affiliation>
<address confidence="0.832849">
College Park, MD 20742, USA
</address>
<email confidence="0.995645">
resnik@umd.edu
</email>
<author confidence="0.995623">
Benjamin B. Bederson
</author>
<affiliation confidence="0.995108">
Computer Science and HCIL
University of Maryland
</affiliation>
<address confidence="0.880573">
College Park, MD 20742, USA
</address>
<email confidence="0.999425">
bederson@cs.umd.edu
</email>
<sectionHeader confidence="0.995631" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995127833333333">
The source text provided to a machine translation
system is typically only one of many ways the input
sentence could have been expressed, and alternative
forms of expression can often produce a better trans-
lation. We introduce here error driven paraphras-
ing of source sentences: instead of paraphrasing a
source sentence exhaustively, we obtain paraphrases
for only the parts that are predicted to be problematic
for the translation system. We report on an Amazon
Mechanical Turk study that explores this idea, and
establishes via an oracle evaluation that it holds the
potential to substantially improve translation quality.
</bodyText>
<sectionHeader confidence="0.998982" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.970057">
The source text provided to a translation system is typ-
ically only one of many ways the input sentence could
have been expressed, and alternative forms of expression
can often produce better translation. This observation is
familiar to most statistical MT researchers in the form of
preprocessing choices — for example, one segmentation
of a Chinese sentence might yield better translations than
another.&apos; Over the past several years, MT frameworks
have been developed that permit all the alternatives to be
used as input, represented efficiently as a confusion net-
work, lattice, or forest, rather than forcing selection of
a single input representation. This has improved perfor-
mance when applied to phenomena including segmenta-
tion, morphological analysis, and more recently source
langage word order (Dyer, 2007; Dyer et al., 2008; Dyer
and Resnik, to appear).
We have begun to explore the application of the same
key idea beyond low-level processing phenomena such
as segmentation, instead looking at alternative expres-
sions of meaning. For example, consider translating The
&apos;Chinese is written without spaces, so most MT systems need to
segment the input into words as a preprocessing step.
Democratic candidates stepped up their attacks during
the debate. The same basic meaning could have been ex-
pressed in many different ways, e.g.:
</bodyText>
<listItem confidence="0.992674375">
• During the debate the Democratic candidates
stepped up their attacks.
• The Democratic contenders ratcheted up their at-
tacks during the debate.
• The Democratic candidates attacked more aggres-
sively during the debate.
• The candidates in the Democratic debate attacked
more vigorously.
</listItem>
<bodyText confidence="0.999793833333333">
These examples illustrate lexical variation, as well as syn-
tactic differences, e.g. whether the attacking or the in-
creasing serves as the main verb. We hypothesize that
variation of this kind holds a potential advantage for
translation systems, namely that some variations may be
more easily translated than others depending on the train-
ing data that was given to the system, and we can im-
prove translation quality by allowing a system to take best
advantage of the variations it knows about, at the sub-
sentential level, just as the systems described above can
take advantage of alternative segmentations.
Paraphrase lattices provide a way to make this hypoth-
esis operational. This idea is a variation on the uses of
paraphrase in translation introduced by Callison-Burch
and explored by others, as well (Callison-Burch et al.,
2006; Madnani et al., 2007; Callison-Burch, 2008; Mar-
ton et al., 2009). These authors have shown that perfor-
mance improvements can be gained by exploiting para-
phrases using phrase pivoting. We have investigated us-
ing pivoting to create exhaustive paraphrase lattices, and
we have also investigated defining upper bounds by elic-
iting human sub-sentential paraphrases using Mechani-
cal Turk. Unfortunately, in both cases, we have found
the size of the paraphrase lattice prohibitive: there are
</bodyText>
<page confidence="0.993191">
217
</page>
<note confidence="0.7569715">
Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 217–221,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999833285714286">
too many spans to paraphrase to make using Turk cost-
effective, and automatically generated paraphrase lattices
turn out to be too noisy to produce improved translations.
A potential solution to this problem comes from a dif-
ferent line of work we are pursuing, in which translation
is viewed as a collaborative process involving people and
machines (Bederson et al., 2010). Here, the idea is that
in translating from a source to a target language, source-
and target-language speakers who are not bilingual can
collaborate to improve the quality of automatic transla-
tion, via an iterative protocol involving translation, back
translation, and the use of a very rich user interface. For
example, consider the following translation from English
to French by an automatic MT system:
</bodyText>
<listItem confidence="0.9999918">
• Source: Polls indicate Brown, a state senator,
and Coakley, Massachusetts’ Attorney General, are
locked in a virtual tie to fill the late Sen. Ted
Kennedy’s Senate seat.
• System: Les sondages indiquent Brown,
</listItem>
<bodyText confidence="0.995027454545454">
un s ´enateur d’´etat, et Coakley,
Massachusetts’ Procureur g´en´eral, sont enferm´es
dans une cravate virtuel a` remplir le regrett´e
s´enateur Ted Kennedy’s si`ege au S´enat.
Someone with only a semester of college French (one of
the authors) can look at this automatic translation, and
see that the underlined parts are probably wrong. Chang-
ing the source sentence to rephrase the underlined pieces
(e.g. changing Massachusetts’ Attorney General to the
Attorney General of Massachusetts), we obtain a transla-
tion that is still imperfect but is more acceptable:
</bodyText>
<listItem confidence="0.6148262">
• System: Les sondages indiquent que Brown, un
s´enateur d’´etat, et Coakley, le procureur g´en´eral
du Massachusetts, sont enferm´es dans une cravate
virtuel pourvoir le sige au S´enat de Sen. Ted
Kennedy, qui est d´ec´ed´e r´ecemment.
</listItem>
<bodyText confidence="0.985875363636364">
One could imagine (and, indeed, we are building) a vi-
sual interface that allows a human participant on the tar-
get side to communicate back to a source-side collabora-
tor, in effect saying, “These underlined pieces look like
they were translated poorly; can you rephrase the rele-
vant parts of your sentence, and perhaps that will lead to
a better translation?”2
Putting these ideas together — source paraphrase and
identification of difficult regions of input for translation
— we arrive at the idea of error driven paraphrasing of
source sentences: instead of paraphrasing to introduce as
much variation as possible everywhere in the sentence,
we suggest that instead it makes sense to paraphrase only
2Communicating which parts of the sentence are relevant across lan-
guages is being done via projection across languages using word align-
ments; cf. (Hwa et al., 2001).
the parts of a source sentence that are problematic for the
translation system. In Section 2 we give a first-pass algo-
rithm for error driven paraphrasing, in Section 3 we de-
scribe how this was realized using MTurk, and Sections 4
and 5 provide an oracle evaluation, discussion, and con-
clusions.
</bodyText>
<sectionHeader confidence="0.767779" genericHeader="method">
2 Identifying source spans with errors
</sectionHeader>
<bodyText confidence="0.954021093023255">
In error driven paraphrasing, the key idea is to focus on
source spans that are likely to be problematic for trans-
lation. Although in principle one could use human feed-
back from the target side to identify relevant spans, in
this paper we begin with an automatic approach, auto-
matically identifying that are likely to be incorrect via
a novel algorithm. Briefly, we automatically translate
source F to target E, then back-translate to produce F’ in
the source language. We compare F and F’ using TERp
(Snover et al., 2009), a form of string-edit distance that
identifies various categories of differences between two
sentences, and when at least two consecutive non-P (non-
paraphrase) edits are found, we flag their smallest con-
taining syntactic constituent.
In more detail, we posit that areas of F’ where there
were many edits from F will correspond to areas in where
the target translation did not match the English very well.
Specifically, deletions (D), insertions (I), and shifts (S)
are likely to represent errors, while matches (M) and
paraphrases (P) probably represent a fairly accurate trans-
lation. Furthermore, we assume that while a single D, S,
or I edit might be fairly meaningless, a string of at least 2
of those types of edits is likely to represent a substantive
problem in the translation.
In order to identify reasonably meaningful paraphrase
units based on potential errors, we rely on a source lan-
guage constituency parser. Using the parse, we find the
smallest constituent of the sentence containing all of the
tokens in a particular error string. At times, these con-
stituents can be quite large, even the entire sentence. To
weed out these cases, we restrict constituent length to no
more than 7 tokens.
For example, given
F The most recent probe to visit Jupiter was the Pluto-
bound New Horizons spacecraft in late February 2007.
E La investigaci´on m´as reciente fue la visita de J´upiter a
Plut´on de la envolvente sonda New Horizons a fines de
febrero de 2007.
F’ The latest research visit Jupiter was the Pluto-bound New
Horizons spacecraft in late February 2007.
spans in the the bolded phrase in F would be identified,
based on the TERp alignment and smallest containing
constituent as shown in Figure 1.
</bodyText>
<page confidence="0.989174">
218
</page>
<figure confidence="0.968476">
NP
NP PP
</figure>
<figureCaption confidence="0.999755">
Figure 1: TERp alignment of a source sentence and its back-translation in order to identify a problematic source span.
</figureCaption>
<sectionHeader confidence="0.913506" genericHeader="method">
3 Error driven paraphrasing on MTurk
</sectionHeader>
<bodyText confidence="0.999994391304348">
We chose to use translation from English to Chinese in
this first foray into Mechanical Turk for error driven para-
phrase. This made sense for a number of reasons: first,
because we expected to have a much easier time finding
Turkers; second, because we could make use of a high
quality English parser (in this case the Stanford parser);
and, third, because it meant that we as researchers could
easily read and judge the quality of Turkers’ paraphrases.
To create an English-to-Chinese data set, we used the
Chinese-to-English data from the MT08 NIST machine
translation evaluation. We used English reference 0 as
the source sentence, and the original Chinese sentence as
the target. We chose reference 0 because on inspection
these references seemed most reflective of native English
grammar and usage. The data set comprises 1357 sen-
tence pairs. Using the the above described algorithm to
identify possible problem areas in the translation, with
the Google Translate API providing both the translation
and back-translation, we generated 1780 potential error
regions in 1006 of the sentences. Then we created HITs
both to obtain paraphrases, and to validate the quality of
paraphrase responses. Costs were $117.48 for obtaining
multiple paraphrases, and $44.06 for verification.
</bodyText>
<subsectionHeader confidence="0.999604">
3.1 Obtaining paraphrases
</subsectionHeader>
<bodyText confidence="0.999993928571429">
Based on the phrases marked as problematic by our algo-
rithm, we created HITs asking for paraphrases within 5
sentences, as illustrated in Figure 2. Workers were given
60 minutes to come up with a single paraphrase for each
of the five indicated problematic regions, for a reward of
$0.10. If a worker felt they could not come up with an
alternate phrasing for the marked phrase, they had the
option of marking an ”Unable to paraphrase” checkbox.
We assigned each task to 3 workers, resulting in 3 para-
phrases for every marked phrase. From the 1780 errors,
we got 5340 responses. Of these, 4821 contained actual
paraphrase data, while the rest of the responses indicated
an inability to paraphrase, via the checkbox response. All
paraphrases were passed on to the verification phase.
</bodyText>
<subsectionHeader confidence="0.998979">
3.2 Paraphrase Verification
</subsectionHeader>
<bodyText confidence="0.9999846">
In the verification phase, we generated alternative full
sentences based on the 4821 paraphrases. Workers were
shown an original sentence F and asked to compare it to at
most 5 alternatives, with a maximum of 20 comparisons
made in a HIT. (Recall that although F is the conven-
tional notation for source sentences in machine transla-
tion, in this study the F sentences are in English.) Re-
sponses were given in the form of radio buttons, mark-
ing ”Yes” for an alternate sentence if workers felt it was
grammatical and accurately reflected the content of the
</bodyText>
<page confidence="0.997551">
219
</page>
<bodyText confidence="0.9995922">
original sentence, or ”No” if it did not meet both of those
criteria. Workers were given 30 minutes to make their
decisions, for a reward of $0.05. This task was also as-
signed to 3 workers, resulting in 3 judgments for every
paraphrase.
</bodyText>
<sectionHeader confidence="0.9394" genericHeader="method">
4 Evaluating Results
</sectionHeader>
<bodyText confidence="0.999959029411765">
Using the paraphrase results from Mechanical Turk, we
constructed rephrased full sentences for every combina-
tion of paraphrase alternatives. For example, if a sentence
had 2 sub-spans paraphrased, and the two sub-spans had 2
and 3 unique paraphrasings, respectively, we would con-
struct 2 x 3 = 6 alternative full sentences. From the
1780 predicted problematic phrases (within the 1006 au-
tomatically identified sentences with possible translation
errors), we generated 14,934 rephrased sentences. Each
rephrased English sentence was translated into a Chinese
sentence, again via the Google Translate API. We then
evaluated results for translation of the original sentences,
and of all their paraphrase alternatives, via the TER met-
ric, using the MT08 original Chinese sentence as the
target-language reference translation. The evaluation set
includes the 1000 sentence where at least one paraphrase
was provided.3
Our evaluation takes the form of an oracle study: if
we knew with perfect accuracy which variant of a sen-
tence to translate, i.e. among the original and all its para-
phrases, based on knowledge of the reference translation,
how well could we do? An “oracle” telling us which vari-
ant is best is not available in the real world, of course, but
in situations like this one, oracle studies are often used
to establish the magnitude of the potential gain (Och et
al., 2004). In this case, the baseline is the average TER
score for the 1000 original sentences, 84.4. If an ora-
cle were permitted to choose which variant was the best
to translate, the average TER score would drop to 80.6.4
Drilling down a bit further, we find that a better-translated
paraphrase sentence is available in 313 of the 1000 cases,
or31.3%, and for those 313 cases, TER for the best para-
phrase alternative improves on the TER for the original
sentence by 12.16 TER points.
</bodyText>
<sectionHeader confidence="0.997495" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999646">
This annotation effort has produced gold standard sub-
sentential paraphrases and paraphrase quality ratings for
spans in a large number of sentences, where the choice
of spans to paraphrase is specifically focused on regions
of the sentence that are difficult to translate. In addi-
</bodyText>
<footnote confidence="0.941684666666667">
3For the other 6 sentences, all problematic spans were marked “Un-
able to paraphrase” by all 3 MTurkers.
4TER measures errors, so lower is better. A reduction in TER of 3.8
</footnote>
<bodyText confidence="0.983228095238095">
for an MT evaluation dataset would be considered quite substantial; a
reduction of 1 point would typically be a publishable result.
tion, we have performed an initial analysis, using human-
generated paraphrases to provide an oracle evaluation of
how much could be gained in translation by translating
paraphrases of problematic regions in the source sen-
tence. The results suggest if paraphrasing is automati-
cally targeted to problematic source spans using a back-
translation comparison, good paraphrases of the problem-
atic spans could improve translation performance quite
substantially.
In future work, we will use a translation system sup-
porting lattice input (Dyer et al., 2008), rather than the
Google Translation API, in order to take advantage of
fully automatic error-driven paraphrasing, using pivot-
based approaches (e.g. (Callison-Burch et al., 2006)) to
complete the automation of the error-driven paraphrase
process. We will also investigate the use of human rather
than machine identification of likely translation prob-
lems, in the context of collaborative translation (Beder-
son et al., 2010).
</bodyText>
<sectionHeader confidence="0.998641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997269325">
Benjamin B. Bederson, Chang Hu, and Philip Resnik. 2010. Trans-
lation by iterative collaboration between monolingual users. In
Graphics Interface (GI) conference.
Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006.
Improved statistical machine translation using paraphrases. In
Robert C. Moore, Jeff A. Bilmes, Jennifer Chu-Carroll, and Mark
Sanderson, editors, HLT-NAACL. The Association for Computa-
tional Linguistics.
Chris Callison-Burch. 2008. Syntactic constraints on paraphrases ex-
tracted from parallel corpora. In EMNLP, pages 196–205. ACL.
Chris Dyer and Philip Resnik. to appear. Forest translation. In
NAACL’10.
C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing word lattice
translation. In Proceedings of HLT-ACL, Columbus, OH.
C. Dyer. 2007. Noisier channel translation: translation from morpho-
logically complex languages. In Proceedings of the Second Work-
shop on Statistical Machine Translation, Prague, June.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2001.
Evaluating translational correspondence using annotation projection.
In ACL ’02: Proceedings of the 40th Annual Meeting on Associa-
tion for Computational Linguistics, pages 392–399, Morristown, NJ,
USA. Association for Computational Linguistics.
Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie Dorr.
2007. Using paraphrases for parameter tuning in statistical ma-
chine translation. In Proceedings of the Second Workshop on Statis-
tical Machine Translation, pages 120–127, Prague, Czech Republic,
June. Association for Computational Linguistics.
Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Im-
proved statistical machine translation using monolingually-derived
paraphrases. In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages 381–390, Singa-
pore, August. Association for Computational Linguistics.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar,
Kenji Yamada, Alexander Fraser, Shankar Kumar, Libin Shen, David
Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir R. Radev.
2004. A smorgasbord of features for statistical machine translation.
In HLT-NAACL, pages 161–168.
Matt Snover, Nitin Madnani, Bonnie Dorr, and Richard Schwartz.
2009. TER-Plus: Paraphrases, Semantic, and Alignment Enhance-
ments to Translation Edit Rate. Machine Translation.
</reference>
<page confidence="0.997915">
220
</page>
<figureCaption confidence="0.995235">
Figure 2: HIT format 1: Obtaining sub-sentential paraphrases. Note that as the MTurker types a paraphrase into the box,what
is typed appears immediately (character by character) in the full-sentence context under “New sentence”, so that they can see
immediately how the entire sentence looks with their paraphrase.
</figureCaption>
<bodyText confidence="0.993707333333334">
the press trust of india quoted
the government minister for relief and rehabilitation kadam
kadam, the governments relief and rehabilitation minister (2/3)
the government minister concerned with relief and rehabiliation kadam (1/3)
as revealing today that in the last week, the monsoon has started in
all of indias states one
every one of indias state, one (3/3)
each of Indias states one (2/3)
all states of india one (1/3)
after another, and that the financial losses and casualties have been serious in all areas. just in maharashtra, the state which
includes
mumbai, indias largest city,
india’s largest city, mumbai (3/3)
the largest city in India, Mumbai, (3/3)
mumbai, the largest city of india, (3/3)
the number of people
known to have died
who died (3/3)
identified to have died (2/3)
known to have passed away (2/3)
has now reached 358.
</bodyText>
<figureCaption confidence="0.991693666666667">
Figure 3: Example of error-driven paraphrases produced via HIT format 1, above, for a single sentence. The paraphrase spans
(indented) are shown with the number of MTurkers, out of 3, who labeled that paraphrase in context as acceptable using a “vali-
dation” HIT.
</figureCaption>
<page confidence="0.994949">
221
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.820053">
<title confidence="0.972753">Error Driven Paraphrase Annotation using Mechanical Turk</title>
<author confidence="0.979813">Olivia</author>
<affiliation confidence="0.999828">Computer Science and University of</affiliation>
<address confidence="0.998297">College Park, MD 20742,</address>
<email confidence="0.999608">olivia.buzek@gmail.com</email>
<author confidence="0.962586">Philip</author>
<affiliation confidence="0.980887">Linguistics and University of</affiliation>
<address confidence="0.996797">College Park, MD 20742,</address>
<email confidence="0.999713">resnik@umd.edu</email>
<author confidence="0.985965">B Benjamin</author>
<affiliation confidence="0.9998765">Computer Science and University of</affiliation>
<address confidence="0.996781">College Park, MD 20742,</address>
<email confidence="0.99987">bederson@cs.umd.edu</email>
<abstract confidence="0.994637153846154">The source text provided to a machine translation system is typically only one of many ways the input sentence could have been expressed, and alternative forms of expression can often produce a better translation. We introduce here error driven paraphrasing of source sentences: instead of paraphrasing a source sentence exhaustively, we obtain paraphrases for only the parts that are predicted to be problematic for the translation system. We report on an Amazon Mechanical Turk study that explores this idea, and establishes via an oracle evaluation that it holds the potential to substantially improve translation quality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Benjamin B Bederson</author>
<author>Chang Hu</author>
<author>Philip Resnik</author>
</authors>
<title>Translation by iterative collaboration between monolingual users.</title>
<date>2010</date>
<booktitle>In Graphics Interface (GI) conference.</booktitle>
<contexts>
<context position="4582" citStr="Bederson et al., 2010" startWordPosition="700" endWordPosition="703">rase lattice prohibitive: there are 217 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 217–221, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics too many spans to paraphrase to make using Turk costeffective, and automatically generated paraphrase lattices turn out to be too noisy to produce improved translations. A potential solution to this problem comes from a different line of work we are pursuing, in which translation is viewed as a collaborative process involving people and machines (Bederson et al., 2010). Here, the idea is that in translating from a source to a target language, sourceand target-language speakers who are not bilingual can collaborate to improve the quality of automatic translation, via an iterative protocol involving translation, back translation, and the use of a very rich user interface. For example, consider the following translation from English to French by an automatic MT system: • Source: Polls indicate Brown, a state senator, and Coakley, Massachusetts’ Attorney General, are locked in a virtual tie to fill the late Sen. Ted Kennedy’s Senate seat. • System: Les sondages</context>
</contexts>
<marker>Bederson, Hu, Resnik, 2010</marker>
<rawString>Benjamin B. Bederson, Chang Hu, and Philip Resnik. 2010. Translation by iterative collaboration between monolingual users. In Graphics Interface (GI) conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<editor>In Robert C. Moore, Jeff A. Bilmes, Jennifer Chu-Carroll, and Mark Sanderson, editors, HLT-NAACL.</editor>
<publisher>The Association for Computational Linguistics.</publisher>
<contexts>
<context position="3509" citStr="Callison-Burch et al., 2006" startWordPosition="536" endWordPosition="539">tial advantage for translation systems, namely that some variations may be more easily translated than others depending on the training data that was given to the system, and we can improve translation quality by allowing a system to take best advantage of the variations it knows about, at the subsentential level, just as the systems described above can take advantage of alternative segmentations. Paraphrase lattices provide a way to make this hypothesis operational. This idea is a variation on the uses of paraphrase in translation introduced by Callison-Burch and explored by others, as well (Callison-Burch et al., 2006; Madnani et al., 2007; Callison-Burch, 2008; Marton et al., 2009). These authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting. We have investigated using pivoting to create exhaustive paraphrase lattices, and we have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using Mechanical Turk. Unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Robert C. Moore, Jeff A. Bilmes, Jennifer Chu-Carroll, and Mark Sanderson, editors, HLT-NAACL. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In EMNLP,</booktitle>
<pages>196--205</pages>
<publisher>ACL. Chris</publisher>
<contexts>
<context position="3553" citStr="Callison-Burch, 2008" startWordPosition="544" endWordPosition="545"> some variations may be more easily translated than others depending on the training data that was given to the system, and we can improve translation quality by allowing a system to take best advantage of the variations it knows about, at the subsentential level, just as the systems described above can take advantage of alternative segmentations. Paraphrase lattices provide a way to make this hypothesis operational. This idea is a variation on the uses of paraphrase in translation introduced by Callison-Burch and explored by others, as well (Callison-Burch et al., 2006; Madnani et al., 2007; Callison-Burch, 2008; Marton et al., 2009). These authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting. We have investigated using pivoting to create exhaustive paraphrase lattices, and we have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using Mechanical Turk. Unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 217–221, Los Angeles, California, Ju</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In EMNLP, pages 196–205. ACL. Chris Dyer and Philip Resnik. to appear. Forest translation. In NAACL’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>S Muresan</author>
<author>P Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<booktitle>In Proceedings of HLT-ACL,</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="1881" citStr="Dyer et al., 2008" startWordPosition="277" endWordPosition="280">tion is familiar to most statistical MT researchers in the form of preprocessing choices — for example, one segmentation of a Chinese sentence might yield better translations than another.&apos; Over the past several years, MT frameworks have been developed that permit all the alternatives to be used as input, represented efficiently as a confusion network, lattice, or forest, rather than forcing selection of a single input representation. This has improved performance when applied to phenomena including segmentation, morphological analysis, and more recently source langage word order (Dyer, 2007; Dyer et al., 2008; Dyer and Resnik, to appear). We have begun to explore the application of the same key idea beyond low-level processing phenomena such as segmentation, instead looking at alternative expressions of meaning. For example, consider translating The &apos;Chinese is written without spaces, so most MT systems need to segment the input into words as a preprocessing step. Democratic candidates stepped up their attacks during the debate. The same basic meaning could have been expressed in many different ways, e.g.: • During the debate the Democratic candidates stepped up their attacks. • The Democratic con</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing word lattice translation. In Proceedings of HLT-ACL, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
</authors>
<title>Noisier channel translation: translation from morphologically complex languages.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague,</location>
<contexts>
<context position="1862" citStr="Dyer, 2007" startWordPosition="275" endWordPosition="276">This observation is familiar to most statistical MT researchers in the form of preprocessing choices — for example, one segmentation of a Chinese sentence might yield better translations than another.&apos; Over the past several years, MT frameworks have been developed that permit all the alternatives to be used as input, represented efficiently as a confusion network, lattice, or forest, rather than forcing selection of a single input representation. This has improved performance when applied to phenomena including segmentation, morphological analysis, and more recently source langage word order (Dyer, 2007; Dyer et al., 2008; Dyer and Resnik, to appear). We have begun to explore the application of the same key idea beyond low-level processing phenomena such as segmentation, instead looking at alternative expressions of meaning. For example, consider translating The &apos;Chinese is written without spaces, so most MT systems need to segment the input into words as a preprocessing step. Democratic candidates stepped up their attacks during the debate. The same basic meaning could have been expressed in many different ways, e.g.: • During the debate the Democratic candidates stepped up their attacks. •</context>
</contexts>
<marker>Dyer, 2007</marker>
<rawString>C. Dyer. 2007. Noisier channel translation: translation from morphologically complex languages. In Proceedings of the Second Workshop on Statistical Machine Translation, Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Okan Kolak</author>
</authors>
<title>Evaluating translational correspondence using annotation projection.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>392--399</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6866" citStr="Hwa et al., 2001" startWordPosition="1061" endWordPosition="1064">ly; can you rephrase the relevant parts of your sentence, and perhaps that will lead to a better translation?”2 Putting these ideas together — source paraphrase and identification of difficult regions of input for translation — we arrive at the idea of error driven paraphrasing of source sentences: instead of paraphrasing to introduce as much variation as possible everywhere in the sentence, we suggest that instead it makes sense to paraphrase only 2Communicating which parts of the sentence are relevant across languages is being done via projection across languages using word alignments; cf. (Hwa et al., 2001). the parts of a source sentence that are problematic for the translation system. In Section 2 we give a first-pass algorithm for error driven paraphrasing, in Section 3 we describe how this was realized using MTurk, and Sections 4 and 5 provide an oracle evaluation, discussion, and conclusions. 2 Identifying source spans with errors In error driven paraphrasing, the key idea is to focus on source spans that are likely to be problematic for translation. Although in principle one could use human feedback from the target side to identify relevant spans, in this paper we begin with an automatic a</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2001</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2001. Evaluating translational correspondence using annotation projection. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 392–399, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Necip Fazil Ayan</author>
<author>Philip Resnik</author>
<author>Bonnie Dorr</author>
</authors>
<title>Using paraphrases for parameter tuning in statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>120--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="3531" citStr="Madnani et al., 2007" startWordPosition="540" endWordPosition="543">n systems, namely that some variations may be more easily translated than others depending on the training data that was given to the system, and we can improve translation quality by allowing a system to take best advantage of the variations it knows about, at the subsentential level, just as the systems described above can take advantage of alternative segmentations. Paraphrase lattices provide a way to make this hypothesis operational. This idea is a variation on the uses of paraphrase in translation introduced by Callison-Burch and explored by others, as well (Callison-Burch et al., 2006; Madnani et al., 2007; Callison-Burch, 2008; Marton et al., 2009). These authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting. We have investigated using pivoting to create exhaustive paraphrase lattices, and we have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using Mechanical Turk. Unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 217–221, Los A</context>
</contexts>
<marker>Madnani, Ayan, Resnik, Dorr, 2007</marker>
<rawString>Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie Dorr. 2007. Using paraphrases for parameter tuning in statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Chris Callison-Burch</author>
<author>Philip Resnik</author>
</authors>
<title>Improved statistical machine translation using monolingually-derived paraphrases.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>381--390</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3575" citStr="Marton et al., 2009" startWordPosition="546" endWordPosition="550">e more easily translated than others depending on the training data that was given to the system, and we can improve translation quality by allowing a system to take best advantage of the variations it knows about, at the subsentential level, just as the systems described above can take advantage of alternative segmentations. Paraphrase lattices provide a way to make this hypothesis operational. This idea is a variation on the uses of paraphrase in translation introduced by Callison-Burch and explored by others, as well (Callison-Burch et al., 2006; Madnani et al., 2007; Callison-Burch, 2008; Marton et al., 2009). These authors have shown that performance improvements can be gained by exploiting paraphrases using phrase pivoting. We have investigated using pivoting to create exhaustive paraphrase lattices, and we have also investigated defining upper bounds by eliciting human sub-sentential paraphrases using Mechanical Turk. Unfortunately, in both cases, we have found the size of the paraphrase lattice prohibitive: there are 217 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 217–221, Los Angeles, California, June 2010. c�2010 Associ</context>
</contexts>
<marker>Marton, Callison-Burch, Resnik, 2009</marker>
<rawString>Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Improved statistical machine translation using monolingually-derived paraphrases. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
</authors>
<title>Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alexander Fraser, Shankar Kumar,</title>
<date>2004</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>161--168</pages>
<location>Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen</location>
<marker>Och, Gildea, 2004</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alexander Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir R. Radev. 2004. A smorgasbord of features for statistical machine translation. In HLT-NAACL, pages 161–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>TER-Plus: Paraphrases, Semantic, and Alignment Enhancements to Translation Edit Rate. Machine Translation.</title>
<date>2009</date>
<contexts>
<context position="7724" citStr="Snover et al., 2009" startWordPosition="1208" endWordPosition="1211">provide an oracle evaluation, discussion, and conclusions. 2 Identifying source spans with errors In error driven paraphrasing, the key idea is to focus on source spans that are likely to be problematic for translation. Although in principle one could use human feedback from the target side to identify relevant spans, in this paper we begin with an automatic approach, automatically identifying that are likely to be incorrect via a novel algorithm. Briefly, we automatically translate source F to target E, then back-translate to produce F’ in the source language. We compare F and F’ using TERp (Snover et al., 2009), a form of string-edit distance that identifies various categories of differences between two sentences, and when at least two consecutive non-P (nonparaphrase) edits are found, we flag their smallest containing syntactic constituent. In more detail, we posit that areas of F’ where there were many edits from F will correspond to areas in where the target translation did not match the English very well. Specifically, deletions (D), insertions (I), and shifts (S) are likely to represent errors, while matches (M) and paraphrases (P) probably represent a fairly accurate translation. Furthermore, </context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2009</marker>
<rawString>Matt Snover, Nitin Madnani, Bonnie Dorr, and Richard Schwartz. 2009. TER-Plus: Paraphrases, Semantic, and Alignment Enhancements to Translation Edit Rate. Machine Translation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>