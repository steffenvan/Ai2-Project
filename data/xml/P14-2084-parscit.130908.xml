<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001902">
<title confidence="0.9983345">
Humans Require Context to Infer Ironic Intent
(so Computers Probably do, too)
</title>
<author confidence="0.996464">
Byron C. Wallace, Do Kook Choe, Laura Kertz and Eugene Charniak
</author>
<affiliation confidence="0.970195">
Brown University
</affiliation>
<email confidence="0.776629">
{byron wallace, do kook choe, laura kertz, eugene charniak}@brown.edu
</email>
<sectionHeader confidence="0.995358" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999741684210526">
Automatically detecting verbal irony
(roughly, sarcasm) is a challenging task
because ironists say something other
than – and often opposite to – what they
actually mean. Discerning ironic intent
exclusively from the words and syntax
comprising texts (e.g., tweets, forum
posts) is therefore not always possible:
additional contextual information about
the speaker and/or the topic at hand is
often necessary. We introduce a new
corpus that provides empirical evidence
for this claim. We show that annota-
tors frequently require context to make
judgements concerning ironic intent, and
that machine learning approaches tend
to misclassify those same comments for
which annotators required additional
context.
</bodyText>
<sectionHeader confidence="0.995588" genericHeader="keywords">
1 Introduction &amp; Motivation
</sectionHeader>
<bodyText confidence="0.999292878787879">
This work concerns the task of detecting verbal
irony online. Our principal argument is that sim-
ple bag-of-words based text classification models
– which, when coupled with sufficient data, have
proven to be extremely successful for many natu-
ral language processing tasks (Halevy et al., 2009)
– are inadequate for irony detection. In this paper
we provide empirical evidence that context is often
necessary to recognize ironic intent.
This is consistent with the large body of prag-
matics/linguistics literature on irony and its us-
age, which has emphasized the role that context
plays in recognizing and decoding ironic utter-
ances (Grice, 1975; Clark and Gerrig, 1984; Sper-
ber and Wilson, 1981). But existing work on au-
tomatic irony detection – reviewed in Section 2
– has not explicitly attempted to operationalize
such theories, and has instead relied on features
(mostly word counts) intrinsic to the texts that are
to be classified as ironic. These approaches have
achieved some success, but necessarily face an
upper-bound: the exact same sentence can be both
intended ironically and unironically, depending on
the context (including the speaker and the topic at
hand). Only obvious verbal ironies will be recog-
nizable from intrinsic features alone.
Here we provide empirical evidence for the
above claims. We also introduce a new annotated
corpus that will allow researchers to build models
that augment existing approaches to irony detec-
tion with contextual information regarding the text
(utterance) to be classified and its author. Briefly,
our contributions are summarized as follows.
</bodyText>
<listItem confidence="0.866461947368421">
• We introduce the first version of the reddit
irony corpus, composed of annotated com-
ments from the social news website reddit.
Each sentence in every comment in this cor-
pus has been labeled by three independent an-
notators as having been intended by the au-
thor ironically or not. This dataset is publicly
available.1
• We provide empirical evidence that human
annotators consistently rely on contextual in-
formation to make ironic/unironic sentence
judgements.
• We show that the standard ‘bag-of-words’ ap-
proach to text classification fails to accurately
judge ironic intent on those cases for which
humans required additional context. This
suggests that, as humans require context to
make their judgements for this task, so too do
computers.
</listItem>
<bodyText confidence="0.998038666666667">
Our hope is that these observations and this
dataset will spur innovative new research on meth-
ods for verbal irony detection.
</bodyText>
<footnote confidence="0.9987475">
1https://github.com/bwallace/
ACL-2014-irony
</footnote>
<page confidence="0.872847">
512
</page>
<note confidence="0.386605">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.994325" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99991787755102">
There has recently been a flurry of interesting
work on automatic irony detection (Tepperman
et al., 2006; Davidov et al., 2010; Carvalho et
al., 2009; Burfoot and Baldwin, 2009; Tsur et
al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova,
2012; Reyes et al., 2012; Lukin and Walker, 2013;
Riloff et al., 2013). In these works, verbal irony
detection has mostly been treated as a standard
text classification task, though with some innova-
tive approaches specific to detecting irony.
The most common data source used to experi-
ment with irony detection systems has been Twit-
ter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al.,
2011; Davidov et al., 2010), though Amazon prod-
uct reviews have been used experimentally as well
(Tsur et al., 2010; Davidov et al., 2010; Reyes et
al., 2012; Filatova, 2012). Walker et al. (2012)
also recently introduced the Internet Argument
Corpus (IAC), which includes a sarcasm label
(among others).
Some of the findings from these previous ef-
forts have squared with intuition: e.g., overzealous
punctuation (as in “great idea!!!!”) is indicative of
ironic intent (Carvalho et al., 2009). Other works
have proposed novel approaches specifically for
irony detection: Davidov et al. (2010), for ex-
ample, proposed a semi-supervised approach in
which they look for sentence templates indicative
of irony. Elsewhere, Riloff et al. (2013) proposed
a method that exploits contrasting sentiment in the
same utterance to detect irony.
To our knowledge, however, no previous work
on irony detection has attempted to leverage
contextual information regarding the author or
speaker (external to the utterance). But this is nec-
essary in some cases, however. For example, in
the case of Amazon product reviews, knowing the
kinds of books that an individual typically likes
might inform our judgement: someone who tends
to read and review Dostoevsky is probably be-
ing ironic if she writes a glowing review of Twi-
light. Of course, many people genuinely do enjoy
Twilight and so if the review is written subtly it
will likely be difficult to discern the author’s in-
tent without this background. In the case of Twit-
ter, it is likely to be difficult to classify utterances
without considering the contextualizing exchange
of tweets (i.e., the conversation) to which they be-
long.
</bodyText>
<figureCaption confidence="0.766869">
Figure 1: The web-based tool used by our annotators to la-
bel reddit comments. Enumerated interface elements are de-
</figureCaption>
<bodyText confidence="0.918129833333333">
scribed as follows: 1 the text of the comment to be anno-
tated – sentences marked as ironic are highlighted; 2 buttons
to label sentences as ironic or unironic; 3 buttons to request
additional context (the embedding discussion thread or asso-
ciated webpage – see Section 3.2); 4 radio button to provide
confidence in comment labels (low, medium or high).
</bodyText>
<sectionHeader confidence="0.993038" genericHeader="method">
3 Introducing the reddit Irony Dataset
</sectionHeader>
<bodyText confidence="0.99998885">
Here we introduce the first version (β 1.0) of
our irony corpus. Reddit (http://reddit.
com) is a social-news website to which news
stories (and other links) are posted, voted on
and commented upon. The forum compo-
nent of reddit is extremely active: popular
posts often have well into 1000’s of user com-
ments. Reddit comprises ‘sub-reddits’, which fo-
cus on specific topics. For example, http://
reddit.com/r/politics features articles
(and hence comments) centered around political
news. The current version of the corpus is avail-
able at: https://github.com/bwallace/
ACL-2014-irony. Data collection and annota-
tion is ongoing, so we will continue to release new
(larger) versions of the corpus in the future. The
present version comprises 3,020 annotated com-
ments scraped from the six subreddits enumerated
in Table 1. These comments in turn comprise a
total of 10,401 labeled sentences.2
</bodyText>
<subsectionHeader confidence="0.998313">
3.1 Annotation Process
</subsectionHeader>
<bodyText confidence="0.9997162">
Three university undergraduates independently
annotated each sentence in the corpus. More
specifically, annotators have provided binary ‘la-
bels’ for each sentence indicating whether or not
they (the annotator) believe it was intended by the
author ironically (or not). This annotation was
provided via a custom-built browser-based anno-
tation tool, shown in Figure 1.
We intentionally did not provide much guid-
ance to annotators regarding the criteria for what
</bodyText>
<footnote confidence="0.8454995">
2We performed naive ‘segmentation’ of comments based
on punctuation.
</footnote>
<page confidence="0.552621">
2
</page>
<figure confidence="0.960213333333333">
1
3
4
</figure>
<page confidence="0.974625">
513
</page>
<table confidence="0.986549571428571">
sub-reddit (URL) description number of labeled comments
politics (r/politics) Political news and editorials; focus on the US. 873
conservative (r/conservative) A community for political conservatives. 573
progressive (r/progressive) A community for political progressives (liberals). 543
atheism (r/atheism) A community for non-believers. 442
Christianity (r/Christianity) News and viewpoints on the Christian faith. 312
technology (r/technology) Technology news and commentary. 277
</table>
<tableCaption confidence="0.988836333333333">
Table 1: The six sub-reddits that we have downloaded comments from and the corresponding number of comments for which
we have acquired annotations in this β version of the corpus. Note that we acquired labels at the sentence level, whereas the
counts above reflect comments, all of which contain at least one sentence.
</tableCaption>
<bodyText confidence="0.989539916666667">
constitutes an ‘ironic’ statement, for two reasons.
First, verbal irony is a notoriously slippery concept
(Gibbs and Colston, 2007) and coming up with an
operational definition to be consistently applied is
non-trivial. Second, we were interested in assess-
ing the extent of natural agreement between an-
notators for this task. The raw average agreement
between all annotators on all sentences is 0.844.
Average pairwise Cohen’s Kappa (Cohen, 1960)
is 0.341, suggesting fair to moderate agreement
(Viera and Garrett, 2005), as we might expect for
a subjective task like this one.
</bodyText>
<subsectionHeader confidence="0.997743">
3.2 Context
</subsectionHeader>
<bodyText confidence="0.995359928571429">
Reddit is a good corpus for the irony detection
task in part because it provides a natural prac-
tical realization of the otherwise ill-defined con-
text for comments. In particular, each comment is
associated with a specific user (the author), and
we can view their previous comments. More-
over, comments are embedded within discussion
threads that pertain to the (usually external) con-
tent linked to in the corresponding submission (see
Figure 2). These pieces of information (previous
comments by the same user, the external link of
the embedding reddit thread, and the other com-
ments in this thread) constitute our context. All
of this is readily accessible. Labelers can opt to
request these pieces of context via the annotation
tool, and we record when they do so.
Consider the following example comment taken
from our dataset: “Great idea on the talkathon
Cruz. Really made the republicans look like the
sane ones.” Did the author intend this statement
ironically, or was this a subtle dig on Senator
Ted Cruz? Without additional context it is diffi-
cult to know. And indeed, all three annotators re-
quested additional context for this comment. This
context at first suggests that the comment may
have been intended literally: it was posted in the
r/conservative subreddit (Ted Cruz is a conserva-
tive senator). But if we peruse the author’s com-
</bodyText>
<figureCaption confidence="0.994191285714286">
Figure 2: An illustrative reddit comment (highlighted). The
title (“Virginia Republican ...”) links to an article, providing
one example of contextualizing content. The conversational
thread in which this comment is embedded provides addi-
tional context. The comment in question was presumably in-
tended ironically, though without the aforementioned context
this would be difficult to conclude with any certainty.
</figureCaption>
<bodyText confidence="0.970800857142857">
ment history, we see that he or she repeatedly de-
rides Senator Cruz (e.g., writing “Ted Cruz is no
Ronald Reagan. They aren’t even close.”). From
this contextual information, then, we can reason-
ably assume that the comment was intended iron-
ically (and all three annotators did so after assess-
ing the available contextual information).
</bodyText>
<sectionHeader confidence="0.990667" genericHeader="method">
4 Humans Need Context to Infer Irony
</sectionHeader>
<bodyText confidence="0.999996222222223">
We explore the extent to which human annotators
rely on contextual information to decide whether
or not sentences were intended ironically. Recall
that our annotation tool allows labelers to request
additional context if they cannot make a decision
based on the comment text alone (Figure 1). On
average, annotators requested additional context
for 30% of comments (range across annotators of
12% to 56%). As shown in Figure 3, annotators
are consistently more confident once they have
consulted this information.
We tested for a correlation between these re-
quests for context and the final decisions regard-
ing whether comments contain at least one ironic
sentence. We denote the probability of at least one
annotator requesting additional context for com-
ment i by P(CZ). We then model the probability
of this event as a linear function of whether or not
</bodyText>
<page confidence="0.993603">
514
</page>
<table confidence="0.7515978">
ironic →ironic 64 annotator 1 152 annotator 2 176 annotator 3
ironic →unironic 86 90 207
unironic →unironic 174 529 364
unironic →ironic 30 51 25
forced decision final decision forced decision final decision forced decision final decision
</table>
<figureCaption confidence="0.969505666666667">
Figure 3: This plot illustrates the effect of viewing contextual information for three annotators (one table for each annotator).
For all comments for which these annotators requested context, we show forced (before viewing the requested contextual
content) and final (after) decisions regarding perceived ironic intent on behalf of the author. Each row shows one of four
possible decision sequences (e.g., a judgement of ironic prior to seeing context and unironic after). Numbers correspond to
counts of these sequences for each annotator (e.g., the first annotator changed their mind from ironic to unironic 86 times).
Cases that involve the annotator changing his or her mind are shown in red; those in which the annotator stuck with their initial
judgement are shown in blue. Color intensity is proportional to the average confidence judgements the annotator provided:
these are uniformly stronger after they have consulted contextualizing information. Note also that the context frequently results
in annotators changing their judgement.
</figureCaption>
<bodyText confidence="0.9969306">
any annotator labeled any sentence in comment i
as ironic. We code this via the indicator variable
Ii which is 1 when comment i has been deemed
to contain an ironic sentence (by any of the three
annotators) and 0 otherwise.
</bodyText>
<equation confidence="0.999861">
logit{P(Ci)} = Q0 + Q1Ii (1)
</equation>
<bodyText confidence="0.999992352941177">
We used the regression model shown in Equa-
tion 1, where Q0 is an intercept and Q1 captures
the correlation between requests for context for a
given comment and its ultimately being deemed
to contain at least one ironic sentence. We fit this
model to the annotated corpus, and found a signif-
icant correlation: ˆQ1 = 1.508 with a 95% confi-
dence interval of (1.326, 1.690); p &lt; 0.001.
In other words, annotators request context sig-
nificantly more frequently for those comments
that (are ultimately deemed to) contain an ironic
sentence. This would suggest that the words
and punctuation comprising online comments
alone are not sufficient to distinguish ironic from
unironic comments. Despite this, most machine
learning based approaches to irony detection have
relied nearly exclusively on such intrinsic features.
</bodyText>
<sectionHeader confidence="0.98595" genericHeader="method">
5 Machines Probably do, too
</sectionHeader>
<bodyText confidence="0.999952702702703">
We show that the misclassifications (with respect
to whether comments contain irony or not) made
by a standard text classification model signifi-
cantly correlate with those comments for which
human annotators requested additional context.
This provides evidence that bag-of-words ap-
proaches are insufficient for the general task of
irony detection: more context is necessary.
We implemented a baseline classification ap-
proach using vanilla token count features (binary
bag-of-words). We removed stop-words and lim-
ited the vocabulary to the 50,000 most frequently
occurring unigrams and bigrams. We added ad-
ditional binary features coding for the presence
of punctuational features, such as exclamation
points, emoticons (for example, ‘;)’) and question
marks: previous work (Davidov et al., 2010; Car-
valho et al., 2009) has found that these are good
indicators of ironic intent.
For our predictive model, we used a linear-
kernel SVM (tuning the C parameter via grid-
search over the training dataset to maximize F1
score). We performed five-fold cross-validation,
recording the predictions ˆyi for each (held-out)
comment i. Average F1 score over the five-folds
was 0.383 with range (0.330, 0.412); mean recall
was 0.496 (0.446, 0.548) and average precision
was 0.315 (0.261, 0.380). The five most predictive
tokens were: !, yeah, guys, oh and shocked. This
represents reasonable performance (with intuitive
predictive tokens); but obviously there is quite a
bit of room for improvement.3
We now explore empirically whether these mis-
classifications are made on the same comments for
which annotators requested context. To this end,
we introduce a variable Mi for each comment i
such that Mi = 1 if ˆyi =� yi, i.e., Mi is an in-
</bodyText>
<footnote confidence="0.53967">
3Some of the recently proposed strategies mentioned in
Section 2 may improve performance here, but none of these
address the fundamental issue of context.
</footnote>
<page confidence="0.995285">
515
</page>
<bodyText confidence="0.9992178">
dicator variable that encodes whether or not the
classifier misclassified comment i. We then ran
a second regression in which the output variable
was the logit-transformed probability of the model
misclassifying comment i, i.e., P(Mi). Here we
are interested in the correlation of the event that
one or more annotators requested additional con-
text for comment i (denoted by Ci) and model mis-
classifications (adjusting for the comment’s true
label). Formally:
</bodyText>
<equation confidence="0.99696">
logit{P(Mi)} = 00 + 01Ii + 02Ci (2)
</equation>
<bodyText confidence="0.999971666666667">
Fitting this to the data, we estimated ˆ02 = 0.971
with a 95% CI of (0.810, 1.133); p &lt; 0.001. Put
another way, the model makes mistakes on those
comments for which annotators requested addi-
tional context (even after accounting for the an-
notator designation of comments).
</bodyText>
<sectionHeader confidence="0.999387" genericHeader="conclusions">
6 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999998363636364">
We have described a new (publicly available) cor-
pus for the task of verbal irony detection. The
data comprises comments scraped from the so-
cial news website reddit. We recorded confidence
judgements and requests for contextualizing infor-
mation for each comment during annotation. We
analyzed this corpus to provide empirical evidence
that annotators quite often require context beyond
the comment under consideration to discern irony;
especially for those comments ultimately deemed
as being intended ironically. We demonstrated
that a standard token-based machine learning ap-
proach misclassified many of the same comments
for which annotators tend to request context.
We have shown that annotators rely on contex-
tual cues (in addition to word and grammatical fea-
tures) to discern irony and argued that this implies
computers should, too. The obvious next step is to
develop new machine learning models that exploit
the contextual information available in the corpus
we have curated (e.g., previous comments by the
same user, the thread topic).
</bodyText>
<sectionHeader confidence="0.998565" genericHeader="acknowledgments">
7 Acknowledgement
</sectionHeader>
<bodyText confidence="0.763174">
This work was made possible by the Army Re-
search Office (ARO), grant #64481-MA.
</bodyText>
<sectionHeader confidence="0.999271" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999443">
C Burfoot and T Baldwin. 2009. Automatic satire de-
tection: are you having a laugh? In ACL-IJCNLP,
pages 161–164. ACL.
P Carvalho, L Sarmento, MJ Silva, and E de Oliveira.
2009. Clues for detecting irony in user-generated
contents: oh...!! it’s so easy;-). In CIKM workshop
on Topic-sentiment analysis for mass opinion, pages
53–56. ACM.
HH Clark and RJ Gerrig. 1984. On the pretense the-
ory of irony. Journal of Experimental Psychology,
113:121–126.
J Cohen. 1960. A coefficient of agreement for nom-
inal scales. Educational and Psychological Mea-
surement, 20:37–46.
D Davidov, O Tsur, and A Rappoport. 2010. Semi-
supervised recognition of sarcastic sentences in twit-
ter and amazon. pages 107–116.
E Filatova. 2012. Irony and sarcasm: Corpus gener-
ation and analysis using crowdsourcing. In LREC,
volume 12, pages 392–398.
RW Gibbs and HL Colston. 2007. Irony in language
and thought: a cognitive science reader. Lawrence
Erlbaum.
R Gonz´alez-Ib´a˜nez, S Muresan, and N Wacholder.
2011. Identifying sarcasm in twitter: a closer look.
In ACL, volume 2, pages 581–586. Citeseer.
HP Grice. 1975. Logic and conversation. 1975, pages
41–58.
A Halevy, P Norvig, and F Pereira. 2009. The unrea-
sonable effectiveness of data. Intelligent Systems,
IEEE, 24(2):8–12.
S Lukin and M Walker. 2013. Really? well. ap-
parently bootstrapping improves the performance of
sarcasm and nastiness classifiers for online dialogue.
NAACL, pages 30–40.
A Reyes, P Rosso, and T Veale. 2012. A multidimen-
sional approach for detecting irony in twitter. LREC,
pages 1–30.
E Riloff, A Qadir, P Surve, LD Silva, N Gilbert, and
R Huang. 2013. Sarcasm as contrast between a pos-
itive sentiment and negative situation. In EMNLP,
pages 704–714.
D Sperber and D Wilson. 1981. Irony and the use-
mention distinction. 1981.
J Tepperman, D Traum, and S Narayanan. 2006.
“Yeah Right”: Sarcasm Recognition for Spoken Di-
alogue Systems.
O Tsur, D Davidov, and A Rappoport. 2010. ICWSM-
a great catchy name: Semi-supervised recognition
of sarcastic sentences in online product reviews. In
AAAI Conference on Weblogs and Social Media.
AJ Viera and JM Garrett. 2005. Understanding in-
terobserver agreement: the kappa statistic. Family
Medicine, 37(5):360–363.
MA Walker, JEF Tree, P Anand, R Abbott, and J King.
2012. A corpus for research on deliberation and de-
bate. In LREC, pages 812–817.
</reference>
<page confidence="0.998338">
516
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538403">
<title confidence="0.8563925">Humans Require Context to Infer Ironic (so Computers Probably do, too)</title>
<author confidence="0.997326">C Wallace</author>
<author confidence="0.997326">Do Kook Choe</author>
<author confidence="0.997326">Laura Kertz</author>
<affiliation confidence="0.999986">Brown University</affiliation>
<address confidence="0.846416">wallace, do kook choe, laura kertz, eugene</address>
<abstract confidence="0.99307755">Automatically detecting verbal irony (roughly, sarcasm) is a challenging task because ironists say something other than – and often opposite to – what they actually mean. Discerning ironic intent exclusively from the words and syntax comprising texts (e.g., tweets, forum posts) is therefore not always possible: additional contextual information about the speaker and/or the topic at hand is often necessary. We introduce a new corpus that provides empirical evidence for this claim. We show that annotators frequently require context to make judgements concerning ironic intent, and that machine learning approaches tend to misclassify those same comments for which annotators required additional context.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Burfoot</author>
<author>T Baldwin</author>
</authors>
<title>Automatic satire detection: are you having a laugh? In</title>
<date>2009</date>
<booktitle>ACL-IJCNLP,</booktitle>
<pages>161--164</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="3892" citStr="Burfoot and Baldwin, 2009" startWordPosition="590" endWordPosition="593">udgements for this task, so too do computers. Our hope is that these observations and this dataset will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al.,</context>
</contexts>
<marker>Burfoot, Baldwin, 2009</marker>
<rawString>C Burfoot and T Baldwin. 2009. Automatic satire detection: are you having a laugh? In ACL-IJCNLP, pages 161–164. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Carvalho</author>
<author>L Sarmento</author>
<author>MJ Silva</author>
<author>E de Oliveira</author>
</authors>
<title>Clues for detecting irony in user-generated contents: oh...!! it’s so easy;-).</title>
<date>2009</date>
<booktitle>In CIKM workshop on Topic-sentiment analysis for mass opinion,</booktitle>
<pages>53--56</pages>
<publisher>ACM.</publisher>
<marker>Carvalho, Sarmento, Silva, de Oliveira, 2009</marker>
<rawString>P Carvalho, L Sarmento, MJ Silva, and E de Oliveira. 2009. Clues for detecting irony in user-generated contents: oh...!! it’s so easy;-). In CIKM workshop on Topic-sentiment analysis for mass opinion, pages 53–56. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HH Clark</author>
<author>RJ Gerrig</author>
</authors>
<title>On the pretense theory of irony.</title>
<date>1984</date>
<journal>Journal of Experimental Psychology,</journal>
<pages>113--121</pages>
<contexts>
<context position="1641" citStr="Clark and Gerrig, 1984" startWordPosition="244" endWordPosition="247">al irony online. Our principal argument is that simple bag-of-words based text classification models – which, when coupled with sufficient data, have proven to be extremely successful for many natural language processing tasks (Halevy et al., 2009) – are inadequate for irony detection. In this paper we provide empirical evidence that context is often necessary to recognize ironic intent. This is consistent with the large body of pragmatics/linguistics literature on irony and its usage, which has emphasized the role that context plays in recognizing and decoding ironic utterances (Grice, 1975; Clark and Gerrig, 1984; Sperber and Wilson, 1981). But existing work on automatic irony detection – reviewed in Section 2 – has not explicitly attempted to operationalize such theories, and has instead relied on features (mostly word counts) intrinsic to the texts that are to be classified as ironic. These approaches have achieved some success, but necessarily face an upper-bound: the exact same sentence can be both intended ironically and unironically, depending on the context (including the speaker and the topic at hand). Only obvious verbal ironies will be recognizable from intrinsic features alone. Here we prov</context>
</contexts>
<marker>Clark, Gerrig, 1984</marker>
<rawString>HH Clark and RJ Gerrig. 1984. On the pretense theory of irony. Journal of Experimental Psychology, 113:121–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--37</pages>
<contexts>
<context position="9212" citStr="Cohen, 1960" startWordPosition="1418" endWordPosition="1419">s β version of the corpus. Note that we acquired labels at the sentence level, whereas the counts above reflect comments, all of which contain at least one sentence. constitutes an ‘ironic’ statement, for two reasons. First, verbal irony is a notoriously slippery concept (Gibbs and Colston, 2007) and coming up with an operational definition to be consistently applied is non-trivial. Second, we were interested in assessing the extent of natural agreement between annotators for this task. The raw average agreement between all annotators on all sentences is 0.844. Average pairwise Cohen’s Kappa (Cohen, 1960) is 0.341, suggesting fair to moderate agreement (Viera and Garrett, 2005), as we might expect for a subjective task like this one. 3.2 Context Reddit is a good corpus for the irony detection task in part because it provides a natural practical realization of the otherwise ill-defined context for comments. In particular, each comment is associated with a specific user (the author), and we can view their previous comments. Moreover, comments are embedded within discussion threads that pertain to the (usually external) content linked to in the corresponding submission (see Figure 2). These piece</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>J Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20:37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>O Tsur</author>
<author>A Rappoport</author>
</authors>
<title>Semisupervised recognition of sarcastic sentences in twitter and amazon.</title>
<date>2010</date>
<pages>107--116</pages>
<contexts>
<context position="3842" citStr="Davidov et al., 2010" startWordPosition="582" endWordPosition="585">at, as humans require context to make their judgements for this task, so too do computers. Our hope is that these observations and this dataset will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur</context>
<context position="15514" citStr="Davidov et al., 2010" startWordPosition="2413" endWordPosition="2416">mments for which human annotators requested additional context. This provides evidence that bag-of-words approaches are insufficient for the general task of irony detection: more context is necessary. We implemented a baseline classification approach using vanilla token count features (binary bag-of-words). We removed stop-words and limited the vocabulary to the 50,000 most frequently occurring unigrams and bigrams. We added additional binary features coding for the presence of punctuational features, such as exclamation points, emoticons (for example, ‘;)’) and question marks: previous work (Davidov et al., 2010; Carvalho et al., 2009) has found that these are good indicators of ironic intent. For our predictive model, we used a linearkernel SVM (tuning the C parameter via gridsearch over the training dataset to maximize F1 score). We performed five-fold cross-validation, recording the predictions ˆyi for each (held-out) comment i. Average F1 score over the five-folds was 0.383 with range (0.330, 0.412); mean recall was 0.496 (0.446, 0.548) and average precision was 0.315 (0.261, 0.380). The five most predictive tokens were: !, yeah, guys, oh and shocked. This represents reasonable performance (with </context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>D Davidov, O Tsur, and A Rappoport. 2010. Semisupervised recognition of sarcastic sentences in twitter and amazon. pages 107–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Filatova</author>
</authors>
<title>Irony and sarcasm: Corpus generation and analysis using crowdsourcing.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<volume>12</volume>
<pages>392--398</pages>
<contexts>
<context position="3960" citStr="Filatova, 2012" startWordPosition="602" endWordPosition="603">ns and this dataset will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 2012). Walker et al. (2012) also recently introduce</context>
</contexts>
<marker>Filatova, 2012</marker>
<rawString>E Filatova. 2012. Irony and sarcasm: Corpus generation and analysis using crowdsourcing. In LREC, volume 12, pages 392–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>RW Gibbs</author>
<author>HL Colston</author>
</authors>
<title>Irony in language and thought: a cognitive science reader. Lawrence Erlbaum.</title>
<date>2007</date>
<contexts>
<context position="8897" citStr="Gibbs and Colston, 2007" startWordPosition="1367" endWordPosition="1370"> community for non-believers. 442 Christianity (r/Christianity) News and viewpoints on the Christian faith. 312 technology (r/technology) Technology news and commentary. 277 Table 1: The six sub-reddits that we have downloaded comments from and the corresponding number of comments for which we have acquired annotations in this β version of the corpus. Note that we acquired labels at the sentence level, whereas the counts above reflect comments, all of which contain at least one sentence. constitutes an ‘ironic’ statement, for two reasons. First, verbal irony is a notoriously slippery concept (Gibbs and Colston, 2007) and coming up with an operational definition to be consistently applied is non-trivial. Second, we were interested in assessing the extent of natural agreement between annotators for this task. The raw average agreement between all annotators on all sentences is 0.844. Average pairwise Cohen’s Kappa (Cohen, 1960) is 0.341, suggesting fair to moderate agreement (Viera and Garrett, 2005), as we might expect for a subjective task like this one. 3.2 Context Reddit is a good corpus for the irony detection task in part because it provides a natural practical realization of the otherwise ill-defined</context>
</contexts>
<marker>Gibbs, Colston, 2007</marker>
<rawString>RW Gibbs and HL Colston. 2007. Irony in language and thought: a cognitive science reader. Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gonz´alez-Ib´a˜nez</author>
<author>S Muresan</author>
<author>N Wacholder</author>
</authors>
<title>Identifying sarcasm in twitter: a closer look.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<volume>2</volume>
<pages>581--586</pages>
<publisher>Citeseer.</publisher>
<marker>Gonz´alez-Ib´a˜nez, Muresan, Wacholder, 2011</marker>
<rawString>R Gonz´alez-Ib´a˜nez, S Muresan, and N Wacholder. 2011. Identifying sarcasm in twitter: a closer look. In ACL, volume 2, pages 581–586. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HP Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<pages>41--58</pages>
<contexts>
<context position="1617" citStr="Grice, 1975" startWordPosition="242" endWordPosition="243">etecting verbal irony online. Our principal argument is that simple bag-of-words based text classification models – which, when coupled with sufficient data, have proven to be extremely successful for many natural language processing tasks (Halevy et al., 2009) – are inadequate for irony detection. In this paper we provide empirical evidence that context is often necessary to recognize ironic intent. This is consistent with the large body of pragmatics/linguistics literature on irony and its usage, which has emphasized the role that context plays in recognizing and decoding ironic utterances (Grice, 1975; Clark and Gerrig, 1984; Sperber and Wilson, 1981). But existing work on automatic irony detection – reviewed in Section 2 – has not explicitly attempted to operationalize such theories, and has instead relied on features (mostly word counts) intrinsic to the texts that are to be classified as ironic. These approaches have achieved some success, but necessarily face an upper-bound: the exact same sentence can be both intended ironically and unironically, depending on the context (including the speaker and the topic at hand). Only obvious verbal ironies will be recognizable from intrinsic feat</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>HP Grice. 1975. Logic and conversation. 1975, pages 41–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Halevy</author>
<author>P Norvig</author>
<author>F Pereira</author>
</authors>
<title>The unreasonable effectiveness of data. Intelligent Systems,</title>
<date>2009</date>
<pages>24--2</pages>
<publisher>IEEE,</publisher>
<contexts>
<context position="1267" citStr="Halevy et al., 2009" startWordPosition="184" endWordPosition="187"> We introduce a new corpus that provides empirical evidence for this claim. We show that annotators frequently require context to make judgements concerning ironic intent, and that machine learning approaches tend to misclassify those same comments for which annotators required additional context. 1 Introduction &amp; Motivation This work concerns the task of detecting verbal irony online. Our principal argument is that simple bag-of-words based text classification models – which, when coupled with sufficient data, have proven to be extremely successful for many natural language processing tasks (Halevy et al., 2009) – are inadequate for irony detection. In this paper we provide empirical evidence that context is often necessary to recognize ironic intent. This is consistent with the large body of pragmatics/linguistics literature on irony and its usage, which has emphasized the role that context plays in recognizing and decoding ironic utterances (Grice, 1975; Clark and Gerrig, 1984; Sperber and Wilson, 1981). But existing work on automatic irony detection – reviewed in Section 2 – has not explicitly attempted to operationalize such theories, and has instead relied on features (mostly word counts) intrin</context>
</contexts>
<marker>Halevy, Norvig, Pereira, 2009</marker>
<rawString>A Halevy, P Norvig, and F Pereira. 2009. The unreasonable effectiveness of data. Intelligent Systems, IEEE, 24(2):8–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lukin</author>
<author>M Walker</author>
</authors>
<title>Really? well. apparently bootstrapping improves the performance of sarcasm and nastiness classifiers for online dialogue.</title>
<date>2013</date>
<journal>NAACL,</journal>
<pages>30--40</pages>
<contexts>
<context position="4004" citStr="Lukin and Walker, 2013" startWordPosition="608" endWordPosition="611">tive new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 2012). Walker et al. (2012) also recently introduced the Internet Argument Corpus (IAC), which </context>
</contexts>
<marker>Lukin, Walker, 2013</marker>
<rawString>S Lukin and M Walker. 2013. Really? well. apparently bootstrapping improves the performance of sarcasm and nastiness classifiers for online dialogue. NAACL, pages 30–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reyes</author>
<author>P Rosso</author>
<author>T Veale</author>
</authors>
<title>A multidimensional approach for detecting irony in twitter. LREC,</title>
<date>2012</date>
<pages>1--30</pages>
<contexts>
<context position="3980" citStr="Reyes et al., 2012" startWordPosition="604" endWordPosition="607">set will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 2012). Walker et al. (2012) also recently introduced the Internet Argum</context>
</contexts>
<marker>Reyes, Rosso, Veale, 2012</marker>
<rawString>A Reyes, P Rosso, and T Veale. 2012. A multidimensional approach for detecting irony in twitter. LREC, pages 1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>A Qadir</author>
<author>P Surve</author>
<author>LD Silva</author>
<author>N Gilbert</author>
<author>R Huang</author>
</authors>
<title>Sarcasm as contrast between a positive sentiment and negative situation.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>704--714</pages>
<contexts>
<context position="4026" citStr="Riloff et al., 2013" startWordPosition="612" endWordPosition="615">hods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 2012). Walker et al. (2012) also recently introduced the Internet Argument Corpus (IAC), which includes a sarcasm lab</context>
</contexts>
<marker>Riloff, Qadir, Surve, Silva, Gilbert, Huang, 2013</marker>
<rawString>E Riloff, A Qadir, P Surve, LD Silva, N Gilbert, and R Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In EMNLP, pages 704–714.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sperber</author>
<author>D Wilson</author>
</authors>
<title>Irony and the usemention distinction.</title>
<date>1981</date>
<contexts>
<context position="1668" citStr="Sperber and Wilson, 1981" startWordPosition="248" endWordPosition="252">ncipal argument is that simple bag-of-words based text classification models – which, when coupled with sufficient data, have proven to be extremely successful for many natural language processing tasks (Halevy et al., 2009) – are inadequate for irony detection. In this paper we provide empirical evidence that context is often necessary to recognize ironic intent. This is consistent with the large body of pragmatics/linguistics literature on irony and its usage, which has emphasized the role that context plays in recognizing and decoding ironic utterances (Grice, 1975; Clark and Gerrig, 1984; Sperber and Wilson, 1981). But existing work on automatic irony detection – reviewed in Section 2 – has not explicitly attempted to operationalize such theories, and has instead relied on features (mostly word counts) intrinsic to the texts that are to be classified as ironic. These approaches have achieved some success, but necessarily face an upper-bound: the exact same sentence can be both intended ironically and unironically, depending on the context (including the speaker and the topic at hand). Only obvious verbal ironies will be recognizable from intrinsic features alone. Here we provide empirical evidence for </context>
</contexts>
<marker>Sperber, Wilson, 1981</marker>
<rawString>D Sperber and D Wilson. 1981. Irony and the usemention distinction. 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tepperman</author>
<author>D Traum</author>
<author>S Narayanan</author>
</authors>
<title>Yeah Right”: Sarcasm Recognition for Spoken Dialogue Systems.</title>
<date>2006</date>
<contexts>
<context position="3820" citStr="Tepperman et al., 2006" startWordPosition="578" endWordPosition="581">ontext. This suggests that, as humans require context to make their judgements for this task, so too do computers. Our hope is that these observations and this dataset will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experi</context>
</contexts>
<marker>Tepperman, Traum, Narayanan, 2006</marker>
<rawString>J Tepperman, D Traum, and S Narayanan. 2006. “Yeah Right”: Sarcasm Recognition for Spoken Dialogue Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Tsur</author>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>ICWSMa great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews.</title>
<date>2010</date>
<booktitle>In AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="3911" citStr="Tsur et al., 2010" startWordPosition="594" endWordPosition="597"> too do computers. Our hope is that these observations and this dataset will spur innovative new research on methods for verbal irony detection. 1https://github.com/bwallace/ ACL-2014-irony 512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512–516, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Previous Work There has recently been a flurry of interesting work on automatic irony detection (Tepperman et al., 2006; Davidov et al., 2010; Carvalho et al., 2009; Burfoot and Baldwin, 2009; Tsur et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 20</context>
</contexts>
<marker>Tsur, Davidov, Rappoport, 2010</marker>
<rawString>O Tsur, D Davidov, and A Rappoport. 2010. ICWSMa great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews. In AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AJ Viera</author>
<author>JM Garrett</author>
</authors>
<title>Understanding interobserver agreement: the kappa statistic.</title>
<date>2005</date>
<journal>Family Medicine,</journal>
<volume>37</volume>
<issue>5</issue>
<contexts>
<context position="9286" citStr="Viera and Garrett, 2005" startWordPosition="1427" endWordPosition="1430"> sentence level, whereas the counts above reflect comments, all of which contain at least one sentence. constitutes an ‘ironic’ statement, for two reasons. First, verbal irony is a notoriously slippery concept (Gibbs and Colston, 2007) and coming up with an operational definition to be consistently applied is non-trivial. Second, we were interested in assessing the extent of natural agreement between annotators for this task. The raw average agreement between all annotators on all sentences is 0.844. Average pairwise Cohen’s Kappa (Cohen, 1960) is 0.341, suggesting fair to moderate agreement (Viera and Garrett, 2005), as we might expect for a subjective task like this one. 3.2 Context Reddit is a good corpus for the irony detection task in part because it provides a natural practical realization of the otherwise ill-defined context for comments. In particular, each comment is associated with a specific user (the author), and we can view their previous comments. Moreover, comments are embedded within discussion threads that pertain to the (usually external) content linked to in the corresponding submission (see Figure 2). These pieces of information (previous comments by the same user, the external link of</context>
</contexts>
<marker>Viera, Garrett, 2005</marker>
<rawString>AJ Viera and JM Garrett. 2005. Understanding interobserver agreement: the kappa statistic. Family Medicine, 37(5):360–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MA Walker</author>
<author>JEF Tree</author>
<author>P Anand</author>
<author>R Abbott</author>
<author>J King</author>
</authors>
<title>A corpus for research on deliberation and debate.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>812--817</pages>
<contexts>
<context position="4536" citStr="Walker et al. (2012)" startWordPosition="696" endWordPosition="699">z´alez-Ib´a˜nez et al., 2011; Filatova, 2012; Reyes et al., 2012; Lukin and Walker, 2013; Riloff et al., 2013). In these works, verbal irony detection has mostly been treated as a standard text classification task, though with some innovative approaches specific to detecting irony. The most common data source used to experiment with irony detection systems has been Twitter (Reyes et al., 2012; Gonz´alez-Ib´a˜nez et al., 2011; Davidov et al., 2010), though Amazon product reviews have been used experimentally as well (Tsur et al., 2010; Davidov et al., 2010; Reyes et al., 2012; Filatova, 2012). Walker et al. (2012) also recently introduced the Internet Argument Corpus (IAC), which includes a sarcasm label (among others). Some of the findings from these previous efforts have squared with intuition: e.g., overzealous punctuation (as in “great idea!!!!”) is indicative of ironic intent (Carvalho et al., 2009). Other works have proposed novel approaches specifically for irony detection: Davidov et al. (2010), for example, proposed a semi-supervised approach in which they look for sentence templates indicative of irony. Elsewhere, Riloff et al. (2013) proposed a method that exploits contrasting sentiment in t</context>
</contexts>
<marker>Walker, Tree, Anand, Abbott, King, 2012</marker>
<rawString>MA Walker, JEF Tree, P Anand, R Abbott, and J King. 2012. A corpus for research on deliberation and debate. In LREC, pages 812–817.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>