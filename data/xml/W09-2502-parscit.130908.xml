<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000762">
<title confidence="0.969864">
A Proposal on Evaluation Measures for RTE
</title>
<author confidence="0.99393">
Richard Bergmair
</author>
<affiliation confidence="0.990528">
recipient of a DOC-fellowship of the Austrian Academy of Sciences
at the University of Cambridge Computer Laboratory;
</affiliation>
<address confidence="0.931531">
15 JJ Thomson Avenue, Cambridge CB3 0FD, UK;
</address>
<email confidence="0.997971">
rbergmair@acm.org
</email>
<sectionHeader confidence="0.994776" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999118">
We outline problems with the interpreta-
tion of accuracy in the presence of bias,
arguing that the issue is a particularly
pressing concern for RTE evaluation. Fur-
thermore, we argue that average precision
scores are unsuitable for RTE, and should
not be reported. We advocate mutual in-
formation as a new evaluation measure
that should be reported in addition to ac-
curacy and confidence-weighted score.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.707273695652174">
We assume that the reader is familiar with the eval-
uation methodology employed in the RTE chal-
lenge.1 We address the following three problems
we currently see with this methodology.
1. The distribution of three-way gold standard
labels is neither balanced nor representative of an
application scenario. Yet, systems are rewarded
for learning this artificial bias from training data,
while there is no indication of whether they could
learn a different bias.
2. The notion of confidence ranking is mislead-
ing in the context of evaluating a ranking by aver-
age precision. The criteria implicitly invoked on
rankings by the current evaluation measures can,
in fact, contradict those invoked on labellings de-
rived by rank-based thresholding.
3. Language allows for the expression of logical
negation, thus imposing a symmetry on the judge-
ments ENTAILED vs. CONTRADICTION. Average
precision does not properly reflect this symmetry.
In this paper, we will first summarize relevant
aspects of the current methodology, and outline
these three problems in greater depth.
</bodyText>
<footnote confidence="0.8804735">
1see the reports on RTE-1 (Dagan et al., 2005), RTE-2
(Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007),
the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al.,
2008), and RTE-5 (TAC, 2009)
</footnote>
<bodyText confidence="0.99972595">
The problem of bias is quite general and widely
known. Artstein and Poesio (2005) discuss it
in the context of Cohen’s kappa (Cohen, 1960),
which is one way of addressing the problem. Yet,
it has not received sufficient attention in the RTE
community, which is why we will show how it ap-
plies to RTE, in particular, and why it is an espe-
cially pressing concern for RTE.
Average precision has been imported into the
RTE evaluation methodology from IR, tacitly as-
suming a great level of analogy between IR and
RTE. However, we will argue that the analogy is
flawed, and that average precision is not suitable
for RTE evaluation.
Then, we will then reframe the problem in in-
formation theoretic terms, advocating mutual in-
formation as a new evaluation measure. We will
show that it addresses all of the issues raised con-
cerning accuracy and average precision and has
advantages over Cohen’s kappa.
</bodyText>
<sectionHeader confidence="0.827214" genericHeader="method">
2 The Structure of RTE Data
</sectionHeader>
<bodyText confidence="0.997671368421053">
Let X be the set of all candidate entailments that
can be formed over a natural language of interest,
such as English. An RTE dataset X (-- X is a set of
N candidate entailments X = Ix1, x2, ... , xN}.
The RTE task is characterized as a classifica-
tion task. A given candidate entailment xi can
be associated with either a positive class label A
(TRUE / YES / ENTAILED) or a negative class la-
bel 5 (FALSE / NO / NOT ENTAILED), but never
both. In the three-way subtask, the positive class,
which we will denote as ❵, is defined as before,
but the negative class 5 is further subdivided into
a class ❛ (NO / CONTRADICTION) and a class ♦
(UNKNOWN). To model this subdivision, we de-
fine equivalence classes [•]3 and [•]2 on the three-
way labels as follows: [❵]3 = ❵, [♦]3 = ♦,
[❛]3 = ❛, [❵]2 = A, [♦]2 = V, and [❛]2 = 0.
The gold standard G for dataset X is then a la-
belling G : X H I❵, ♦, ❛}. We call a candidate
</bodyText>
<page confidence="0.987176">
10
</page>
<note confidence="0.998984">
Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 10–17,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.995894166666667">
entailment xi a A-instance iff rG♣xiqs2 ✏ A, and
analogously for the other class labels.
The output ♣L, →q of an RTE system on dataset
X also contains such a labelling L : X ÞÑ
t❵, 0, ❛✉, in addition to a strict total order → on
X representing a ranking of candidate entailments.
</bodyText>
<subsectionHeader confidence="0.963458">
2.1 Logical Preliminaries
</subsectionHeader>
<bodyText confidence="0.998546951219512">
The notation chosen here is inspired by modal
logic. Let’s say a candidate entailment xi were
of the logical form cp Ñ 0. The formula “✆♣cp Ñ
0q” would then assert that 0 necessarily follows
from cp (ENTAILMENT), and the formula “✆♣cp Ñ
✥0q”, which would be equivalent to “✥0♣cp❫0q”,
would mean that we can not possibly have cp ❫ 0
(CONTRADICTION). We think of the former as a
positive form of necessity (❵), and of the latter
as a negative form of necessity (❛). The formula
“0♣cp Ñ 0q” would assert that 0 possibly follows
from cp (UNKNOWN).
We will have to assume that this negation oper-
ator ✥ is in fact within the expressive power of the
natural language of interest, i.e. “cp Ñ ✥0” P X,
whenever “cp Ñ 0” P X. It imposes a symmetry
on the two labels ❵ and ❛, with 0 being neutral.
For example: “Socrates is a man and every man
is mortal; Therefore Socrates is mortal.” This can-
didate entailment is a ❵-instance. It corresponds
to the following ❛-instance: “Socrates is a man
and every man is mortal; Therefore Socrates is
not mortal”. But then, consider the 0-instance
“Socrates is mortal; Therefore Socrates is a man”.
Here “Socrates is mortal; Therefore Socrates is
not a man” is still a 0-instance.
It is this modal logic interpretation which
matches most closely the ideas conveyed by the
task definitions (TAC, 2009), and the annota-
tion guidelines (de Marneffe and Manning, 2007).
However, for the two-way task, they allude more
to probabilistic logic or fuzzy logic, where a can-
didate entailment is a A-instance iff it holds to a
higher degree or likelihood or probability than its
negation, and a 5-instance otherwise.
We believe that either a three-way modal logic
entailment task or a two-way probabilistic logic
entailment task on its own could make perfect
sense. However, they are qualitatively different
and not trivially related by equating A with ❵, and
subdividing 5 into 0 and ❛.
</bodyText>
<sectionHeader confidence="0.97073" genericHeader="method">
3 Accuracy &amp; Related Measures
</sectionHeader>
<bodyText confidence="0.999763666666667">
Both the system and the gold standard apply to the
dataset X a total labelling L and G respectively,
i.e. they are forced to assign their best guess la-
bel to every instance. A degree of agreement can
be determined as a percentage agreement either on
the two-way or the three-way distinction:
</bodyText>
<equation confidence="0.993323">
1 N
A3 (L; G) ✏ N
i✏1
1(rL♣xiqs2 ✏ rG♣xiqs2),
</equation>
<bodyText confidence="0.999122666666667">
where 1 is a counter which takes on a numerical
value of one, when the logical expression in its ar-
gument is true, and zero otherwise.
The RTE-3 PILOT (Voorhees, 2008) reported
some accuracy measures conditioned on gold stan-
dard labels as follows:
</bodyText>
<equation confidence="0.99677625">
A✶(LG�9) ✏ iiNi✏ 1 1(rL♣xiqs3 ✏ rG♣xiqs3 ✏ g)
3 ;
A2 ;
(LG, g) ✏ iiNi✏ 1 1(rL♣xiqs2 ✏ rG♣xiqs2 ✏ g)
</equation>
<bodyText confidence="0.99982355">
Assuming the usual analogy with IR, we note
that A✶2(L; G, A)is akin to recall. On the other
hand, A✶2(G; L, A), which conditions accuracy on
the system-assigned labels rather than the gold
standard labels, is precision.
The conditioned accuracy measures do not pro-
vide a single summary statistic as the others do.
However, such a summary could be defined by tak-
ing the mean across the different labels:
It is instructive to consider a number of trivial
baseline systems. Let S❵, S♦, and S❛, be the sys-
tems that uniformly assign to everything the la-
bels ❵, 0, and ❛, respectively, so that for all i:
L❵♣xiq ✏ ❵, L♦♣xiq ✏ 0, and L❛♣xiq ✏ ❛. Also
consider system S☛, which assigns labels at ran-
dom, according to a uniform distribution.
The performance of these systems depends on
the distribution of gold-standard labels. The pol-
icy at RTE was to sample in such a way that the re-
sulting two-way labels in the gold standard would
</bodyText>
<equation confidence="0.999446285714286">
1(rL♣xiqs3 ✏ rG♣xiqs3),
1 N
A2 (L; G) ✏
N i✏1
iiNi✏1 1(rG♣xiqs3 ✏ g) ,
iiNi✏1 1(rG♣xiqs2 ✏ g) .
1
A✶3 (L; G) ✏ 3
gPt❵,♦,❛✉
1
A✶2 (L; G) ✏ 2
gPtA,p✉
A✶3(L; G; g),
A✶2(L; G; g).
</equation>
<page confidence="0.993819">
11
</page>
<bodyText confidence="0.999364294117647">
be balanced. So 50% of all i had [G(xi)12 = 4,
while the other 50% had [G(xi)12 = 5.
This means that all trivial baselines have an ac-
curacy of A2 = A✶2 = 50%. If the data were bal-
anced on the three-way labels, which they are not,
we would analogously have A3 = A✶3 = 33%.
When interpreting a two-way accuracy, one
would thus expect values between 50% and 100%,
where 50% indicates a trivial system and 100%
indicates a perfect system. A value of, for ex-
ample, 70% could be interpreted as-is, mindful of
the above range restriction, or the range restriction
could be factored into the value by using a linear
transformation. One would then say that the accu-
racy of 70% is 40% of the way into the relevant
range of 50% — 100%, and quote the value as a
Cohen’s Kappa of κ = 0.4.
</bodyText>
<subsectionHeader confidence="0.99869">
3.1 Bias
</subsectionHeader>
<bodyText confidence="0.99971275">
While the RTE datasets are balanced on two-way
gold standard labels, they are not balanced on the
three-way gold standard labels. Among the candi-
date entailments xi with [G(xi)12 = 5, in RTE-4,
70% of all xi had [G(xi)13 = ♦, while only 30%
had [G(xi)13 = R. In the RTE-3 PILOT, the distri-
bution was even more skewed, at 82%/18%.
So, we observe that SM has A3(LM; G) = .500
and therefore outperforms two thirds of all RTE-3
PILOT participants and one third of all RTE-4 par-
ticipants. On the other hand, only very few par-
ticipants performed worse than the random choice
system S*, which had A3(L*; G) = .394 on RTE-
4. The other trivial systems have A3(L♦; G) =
.350, followed by A3(LEI; G) = .150 on RTE-4.
The conditioned accuracies seem to promise
a way out, since they provide an artificial bal-
ance across the gold standard labels. We have
A✶3(LM; G) = A✶3(L♦; G) = A✶3(LEI; G) = .33.
But this measure is then counter-intuitive in that
the random-choice system S* gets A✶3(L*; G) =
.394 on RTE-4 and would thus be considered
strictly superior to the system SM, which, if noth-
ing else, at least reproduces the right bias. Another
caveat is that this would weigh errors on rare labels
more heavily than errors on common labels.
In some form or another the problem of bias ap-
plies not only to accuracy itself, but also to related
statistics, such as precision, recall, precision/recall
curves, and confidence weighted score. It is there-
fore quite general, and there are three responses
which are commonly seen:
</bodyText>
<listItem confidence="0.997814">
1. For purposes of intrinsic evaluation, one can
use samples that have been balanced artificially, as
it is being done in the two-way RTE task. Yet, it is
impossible to balance a dataset both on a two-way
and a three-way labelling at the same time.
2. One can use representative samples and ar-
gue that the biased accuracies have an extrinsic in-
terpretation. For example, in IR, precision is the
probability that a document chosen randomly from
the result set will be considered relevant by the
user. Yet, for RTE, one cannot provide a repre-
sentative sample, as the task is an abstraction over
a number of different applications, such as infor-
mation extraction (IE), question answering (QA),
and summarization (SUM), all of which give rise
to potentially very different distributions of labels.
3. On statistical grounds, one can account for
the possibility of random agreement in the pres-
ence of bias using Cohen’s kappa (Artstein and
Poesio, 2005; Di Eugenio and Glass, 2004). We
will outline mutual information as an alternative,
arguing that it has additional advantages.
</listItem>
<sectionHeader confidence="0.886449" genericHeader="method">
4 Average Precision
</sectionHeader>
<bodyText confidence="0.999944666666667">
The purpose of average precision is to evaluate
against the gold standard labelling G the system-
assigned ranking &gt;, rather than directly compar-
ing the two labellings G and L.
This is done by deriving from the ranking &gt; a
series of binary labellings. The i-th labelling in
that series is that which labels all instances up to
rank i as 4. A precision value can be computed
for each of these labellings, compared to the same
gold standard, and then averaged.
More formally, &gt; is the strict total ordering on
the dataset X which has been produced by the sys-
tem. Let xj &gt; xi iff xj &gt; xi or xj = xi. We
can then associate with each instance xi a numeric
rank, according to its position in &gt;:
</bodyText>
<equation confidence="0.859176125">
Il(xj &gt; xi).
We can then define the cutoff labelling &gt;♣rq as
&gt;♣rq
(x.) — 4 if #&gt;(xi) r,
z —
5
d average precision as
N
E
✏1
#&gt;(xi) =
otherwise;
an
aP(G; &gt;) = 1 N
N r✏1
A✶2✁G;&gt;♣rq,4✠.
</equation>
<page confidence="0.950414">
12
</page>
<bodyText confidence="0.999903">
The system-assigned labelling L and the series
of ranking-based labellings &gt;♣&apos;q are initially inde-
pendent, but, since both accuracy and average pre-
cision refer to the same gold standard G, we get
the following condition on how L must relate to
&gt;: We call a system output (L, &gt;) sound if there
exists a cutoff rank r, such that L equals &gt;♣&apos;q, and
self-contradictory otherwise. This is because, for
a self-contradictory system output, there does not
exist a gold standard for which it would be perfect,
in the sense that both accuracy and average preci-
sion would simultaneously yield a value of 100%.
So far, we avoided the common terminology re-
ferring to &gt; as a “confidence ranking”, as the no-
tion of confidence would imply that we force the
system to give its best guess labels, but also allow
it to provide a measure of confidence, in this case
by ranking the instances, to serve as a modality for
the interpretation of such a best guess.
This is not what is being evaluated by average
precision. Here, a system can remain entirely ig-
norant as to what is a 4- or a 5-instance. System-
assigned labels do not enter the definition, and sys-
tems are not required to choose a cutoff r to derive
a labelling &gt;♣&apos;q. This sort of evaluation is ade-
quate for IR purposes, where the system output is
genuinely a ranking, and it is up to the user to set
a cutoff on what is relevant to them. As for RTE, it
is unclear to us whether this applies.
</bodyText>
<subsectionHeader confidence="0.987199">
4.1 Thresholding
</subsectionHeader>
<bodyText confidence="0.999451185185185">
In the previous section, we have seen that it is
somewhat misleading to see &gt; as a confidence-
ranking on the labelling L. Here, we argue that,
even worse than that, the interpretations of &gt; and
L may contradict each other. It is impossible for a
system to optimize its output (L, &gt;) for accuracy
A2 (G; L✟ and simultaneously for average preci-
sion aP(G; &gt;), while maintaining as a side condi-
tion that the information state (L, &gt;) remain sound
at all times. We show this by indirect argument.
For the sake of contradiction, assume that the
system has come up with an internal information
state consisting of the ranking &gt; and the labelling
L, as a best guess. Also assume that this informa-
tion state is sound.
Let’s assume furthermore, again for the sake of
contradiction, that the system is now allowed to
query an oracle with access to the gold standard in
order to revise the internal information state with
the goal of improving its performance as measured
by accuracy, and simultaneously also improving
its performance as measured by average precision.
First, the oracle reveals r, the number of 4-
instances in the gold standard. Let instance xi at
rank #&gt;(xi) = r be correctly classified, and the
instance xj at some rank #&gt;(xj) &gt; r + 1 be incor-
rectly classified. So we would have [L(xi)12 =
</bodyText>
<equation confidence="0.95698875">
L♣rq
&gt; (xi) = [G(xi)12 = 4, and [L(xj)12 =
L♣rq
&gt; (xj) = 5 :A [G(xj)12.
</equation>
<bodyText confidence="0.99676096969697">
Next, the oracle reveals the fact that xj had been
misclassified. In response to that new information,
the system could change the classification and set
L(xj) &lt;-- 4. This would lead to an increase in
accuracy. Average precision would remain unaf-
fected, as it is a function of &gt;, not L.
However, the information state (L, &gt;) is now
self-contradictory. The ranking &gt; would have to
be adapted as well to reflect the new information.
Let’s say xj were reranked by inserting it at some
rank r✶ &lt; r. This would lead to all intervening in-
stances, including xi, to be ranked down, and thus
to an increase in average precision.
But, since xi has now fallen below the threshold
r, which was, by definition, the correct threshold
chosen by the oracle, the system would reclassify
it as [L(xj)12 = 5, which now introduces a la-
belling error. While average precision would not
react to this relabelling, accuracy would now drop.
So there are two rather counterintuitive con-
clusions concerning the simultaneous application
of accuracy, average precision, and thresholding.
First, accuracy may prefer self-contradictory out-
puts to sound outputs. Second, when soundness is
being forced, average precision may prefer lower
accuracy to higher accuracy labellings.
Again, it should be stressed that RTE is the only
prominent evaluation scheme we know of that in-
sists on this combination of accuracy and average
precision. If we had used precision and average
precision, as in IR, the above argument would not
hold. Also, in IR, average precision clearly domi-
nates other measures in its importance.
</bodyText>
<subsectionHeader confidence="0.995877">
4.2 Logical Symmetry
</subsectionHeader>
<bodyText confidence="0.999421571428571">
Besides the above arguments on bias, and on the
contradictions between accuracy and average pre-
cision under a thresholding interpretation, there
is a third problem with the current evaluation
methodology. It arises from the symmetry be-
tween the classes ❑+ and 0 which we introduced in
section 2.1. This problem is a direct result of the
</bodyText>
<page confidence="0.997957">
13
</page>
<bodyText confidence="0.979901666666667">
inherent properties of language and logic, and is,
thus, the argument which is most specific to RTE.
Let X ✏ tx1, x2, ... , xN✉ be a dataset, and let
</bodyText>
<equation confidence="0.907374">
✥X ✏ t✥x1, ✥x2, ... , ✥xN✉
</equation>
<bodyText confidence="0.999901">
be the dataset resulting from the application of
negation to each of the candidate entailments.
Similarly, let G : X ÞÑ t❵, 0, ❛✉ be a gold stan-
dard and for all x P X, let
</bodyText>
<equation confidence="0.994067666666667">
{ ❛ if G♣xq ✏ ❵,
0 if G♣xq ✏ 0,
❵ if G♣xq ✏ ❛,
</equation>
<bodyText confidence="0.999929652173913">
and analogously for the system-assigned labels L.
Intuitively, we would now expect the following
of an evaluation measure: A system that produces
the labelling L for dataset X is equivalent, in terms
of the evaluation measure, to a system that pro-
duces labelling ✥L for dataset ✥X. This is indeed
true for three-way accuracy, where A3 (G; L) ✏
A3(✥G; ✥L), but it is not true for two-way accu-
racy, where the three-way classes are now lumped
together in a different way.
Also, this symmetry is not present in average
precision, which looks only at positive instances.
Since the set of A-instances of X and the set of A-
instances of ✥X are disjoint, the two average pre-
cisions A1P♣G; →q and A1P♣✥G; →&apos;q, regardless of
how → relates to →&apos;, need not be functionally re-
lated. – This makes sense in IR, where the set of
irrelevant and non-retrieved documents must not
enter into the evaluation of a retrieval system. But
it makes no sense for the RTE task, where we do
need to evaluate systems on the ability to assign a
single label to all and only the contradictory can-
didate entailments.
</bodyText>
<sectionHeader confidence="0.994355" genericHeader="method">
5 Mutual Information
</sectionHeader>
<bodyText confidence="0.999407190476191">
In this section, we define mutual information as a
possible new evaluation measure for RTE. In par-
ticular, we return to the problem of bias and show
that, like Cohen’s kappa, mutual information does
not suffer from bias. We will then introduce a
new problem, which we shall call degradation. We
show that Cohen’s kappa suffers from degradation,
but mutual information does not. Finally, we will
extend the discussion to account for confidence.
Recall that an RTE dataset is a set of N candi-
date entailments X ✏ tx1, x2, ... , xN✉, and let X
be a random variable representing the result of a
random draw from this set. Let P♣X ✏ xiq be
the probability that xi comes up in the draw. This
could represent, for example, the prior probabil-
ity that a particular question is asked in a question
answering scenario. In the absence of any extrin-
sically defined interpretations, one could set ran-
dom variable X to be uniformly distributed, i.e.
P♣X ✏ xiq ✏ N1 for all i.
This yields a number of further random vari-
ables: Let G and L be the label G♣xiq and L♣xiq
respectively, assigned to the candidate xi which
has been drawn at random. As usual, we will be
interested in their joint distribution, and the result-
ing marginals and conditionals.
We give the remaining definitions leading to
mutual information in Figure 1, and will discuss
them by considering the particular contingency ta-
ble in Figure 2 as an example. It also spells out the
information theoretic calculations in detail. Fur-
thermore, we will present corresponding values
for Cohen’s kappa, which should be easy for the
reader to retrace, and thus have been omitted from
the Figure for brevity.
The unconditional entropy H♣Gq serves as a
convenient measure of the hardness of the classi-
fication task itself, taking into account the number
of labels and their distribution in the gold standard.
In the example, this distribution has been chosen
to match that of the RTE-4 dataset almost pre-
cisely, yielding a value for H♣Gq of 1.4277 bits.
This indicates that it is much harder to guess the
three-way gold standard label of an RTE-4 candi-
date entailment than it is to guess the two-way la-
bel, or the outcome of a toss of a fair coin, which
would both have an entropy of exactly 1 bit. On
the other hand, due to the skewness of the distri-
bution, it is easier to guess this outcome than it
would be if the distribution was uniform, in which
case we would have an entropy of 1.5850 bits.
Similarly, we can calculate a conditional en-
tropy H♣G⑤L ✏ lq over a conditional distribution
of gold standard labels observed, given that the
system has assigned label l to our randomly cho-
sen candidate entailment. In the example, we have
calculated a value of 1.0746 bits for H♣G⑤L ✏ ❵q.
So, while the hardness of guessing the correct la-
bel without any additional knowledge is 1.4277, it
will be easier to guess this label correctly once the
system-assigned label is known to be ❵.
Our best guess would be to always assign label
❵, which would be successful 50% of the time.
</bodyText>
<equation confidence="0.951276277777778">
✥G♣✥xq ✏
14
P(G = g,L = l) = XN P(X = xi) 1(G(xi) = g n L(xi) = l); (1)
i✏1
P(G = g) =X P(G = g, L = l) (2)
t
P(L = l) =X P(G = g, L = l) (3)
s
P(G = g,L = l)
P(G = gIL = l) =
P(L = l) ; (4)
H(G) = —X P(G = g) log(P(G = g)); (5)
s
H(GIL = l) = —X P(G = gIL = l) log(P(G = gIL = l)); (6)
s
H(GIL) =X P(L = l) H(GIL = l); (7)
t
ff(G; L) = H(G) — H(GIL). (8)
</equation>
<figureCaption confidence="0.973894">
Figure 1: definitions for mutual information ff(G; L)
</figureCaption>
<table confidence="0.617862">
20 25 5 P(G = ❵)
(45) (0) = .5
9 18 9 P(G = 0)
(27) (0) = .36
1 7 6 P(G = ❛)
(8) (0) = .14
</table>
<equation confidence="0.992881235294118">
P(L = ❵) P(L = 0) P(L = ❛)
= .3 = .5 = .2 N = 100
(.8) (0) (.2)
—H(G) = .5 log2(.5)
+ .36 log2(.36)
+ .14 log2(.14)
= —1.4277
—H(GIL = ❵) = 30 log2(20
20
30)
+ 30 log2(9
9
30)
+ 30 log2(1
1
30)
= —1.0746
H(GIL) = .3 * 1.0746
+ .5 * 1.4277
+ .2 * 1.5395
= 1.3441
25
—H(GIL = 0) = 50 log2(25
50)
+ 50 log2(18
18
50)
+ 50log2( 7
7 50)
= —1.4277
45
—H(GIL&apos; = ❵) = 80 log2(45
80)
27
+ 80 log2( 27
80)
+ 80 log2( 8
8
80)
= —1.3280
—H(GIL = ❛) = 20 log2( 5
5
20)
+ 20log2( 9
9 20)
+ 20log2( 6
6 20)
= —1.5395
H(GIL&apos;) = .8 * 1.3280
+ .2 * 1.5395
= 1.3703
</equation>
<figureCaption confidence="0.98893">
Figure 2: example contingency table and entropy calculations
</figureCaption>
<page confidence="0.992504">
15
</page>
<bodyText confidence="0.9999266">
But, among the cases where the system in Figure 2
has assigned label ❵, this would be an even better
guess. It would now be correct 66% of the time.
We have gained information about the gold stan-
dard by looking at the system-assigned label.
</bodyText>
<subsectionHeader confidence="0.995551">
5.1 Bias
</subsectionHeader>
<bodyText confidence="0.999990673469388">
The conditional entropy H♣G⑤Lq is the expected
value of the conditional entropy H♣G⑤L ✏ lq
across all possible labels l, when, as before, we
draw a candidate entailment at random.
One very noteworthy property of this measure is
that all of the baseline systems we considered, i.e.
systems assigning constant labels, or systems as-
signing labels at random, would have H♣G⑤Lq ✏
H♣Gq, since the distribution of gold standard la-
bels given the system labels, in all of these cases,
is the same as the prior distribution. Furthermore,
H♣Gq ✏ 1.4277 is, in fact, an upper bound on
H♣G⑤Lq. All the trivial baseline systems would
perform at this upper bound level.
At the other extreme end of the spectrum, con-
sider a perfect contingency table, where all the
non-diagonal cells are zero. In this case all the
conditional entropies H♣G⑤L ✏ lq would be en-
tropies over delta distributions concentrating all
probability mass on a single label. This would
yield a value of H♣G⑤Lq ✏ 0, which is a lower
bound for any entropy. – For Cohen’s kappa we
would have κ ✏ 1.
The system producing our contingency table
performs worse than this ideal but better than the
baselines, at H♣G⑤Lq ✏ 1.3441. One can subtract
H♣G⑤Lq from the upper bound H♣Gq to obtain
the mutual information ff♣G; Lq. It is the infor-
mation gained about G once the value of L is re-
vealed. It is obviously still bounded between 0 and
H♣Gq, but is somewhat more intuitive as an evalu-
ation measure, as it restores the basic intuition that
larger values indicate higher performance. – Due
to a surprising result of information theory it also
turns out that ff♣G; Lq ✏ ff♣L; Gq. This symmetry
is another property one would intuitively expect
when comparing two labellings G and L to each
other, and is also present for accuracy and kappa.
We can compare the behaviour of this measure
to that of accuracy. The accuracy of our exam-
ple system is simply the sum of the diagonal con-
tingency counts, so it scores at 44%, compared
to 50% for the baseline that always assigns la-
bel ❵. The new bias-aware framework provides a
quite different point of view. We would now note
that the example system does provide ff♣L; Gq ✏
0.0836 bits worth of information about G, show-
ing an agreement of κ ✏ 0.1277, compared to zero
information and κ ✏ 0 agreement for the baseline.
</bodyText>
<subsectionHeader confidence="0.98614">
5.2 Degradation
</subsectionHeader>
<bodyText confidence="0.999990307692308">
The numbers in the example have been chosen so
as to illustrate a problem we call degradation. The
conditional distribution P♣G ✏ g⑤L ✏ ♦q is the
same as the unconditional distribution P♣G ✏ gq,
so when it turns out that L ✏ ♦, no additional
information has been revealed about G. But in
information theoretic terms, it is considered good
to know when exactly we know nothing.
What happens if we conflate the labels ♦ and ❵
in the system output? In Figure, 2, the numbers in
brackets illustrate this. Previously, the system as-
signed label ❵ in 30% of all cases. In those cases,
the system’s choice was relatively well-informed,
as ❵ actually turned out to be the correct gold stan-
dard label 66% of the time. But now, with the la-
bels conflated, the system chooses ❵ in 80% of
the cases; a choice which is now much less well-
informed, as it is correct only 45% of the time.
Mutual information shows a drop from 0.0836
bits down to 0.0262. On the other hand, accuracy
increases from 44% to 51%, and Cohen’s kappa
also increases from 0.1277 to 0.1433. But this is
clearly counter-intuitive. Surely, it must be a bad
thing to conflate a well-informed label with a less
well-informed label, thus obscuring the output to
less certainty and more guesswork.
</bodyText>
<subsectionHeader confidence="0.996038">
5.3 Confidence Ranking
</subsectionHeader>
<bodyText confidence="0.999982882352941">
One final issue that has still remained unaddressed
is that of confidence ranking. This takes us back
to the very first probabilistic notion we introduced,
that of a probability distribution P♣X ✏ xiq gov-
erning the choice of the test-instances xi. The uni-
form distribution we suggested earlier results in all
instances carrying equal weight in the evaluation.
But for some applications, it makes sense to
give the system some control over which test-
instances it wants to be tested on, independently
of the question of what results it produces for that
test. – So, from a probabilistic point of view, the
most natural take on confidence would be to have
the system itself output the values P♣X ✏ xiq as
confidence weights.
This would affect H♣Gq, which we previously
introduced as a measure of the difficulty of the task
</bodyText>
<page confidence="0.990154">
16
</page>
<bodyText confidence="0.99980336">
faced by the system. But now, the system has some
control over what task it wants to try and solve.
In an extreme scenario, it could concentrate all its
confidence mass in a single instance. Another sys-
tem might force itself to give equal weight to ev-
ery instance. Clearly, these are two very differ-
ent scenarios, so it seems natural that, as soon as
the issue of confidence enters the scene, the eval-
uation has to consider two dimensions. The un-
conditional entropy H(G) would have to be re-
ported for every system, together with the mutual
information ff(L; G). While H(G) would measure
how effective a system was at using its confidence
weighting as a tool to make the task easier on it-
self, ff(L; G) would measure how successful the
system ultimately was at the task it set for itself.
The example of a system concentrating all of
its confidence mass in a single instance shows that
the ability to freely choose P(X = xi) might not
fit with realistic application scenarios. This leads
to the idea of confidence ranking, where a system
could only rank, not weigh, its decisions, and it
would be up to the evaluation framework to then
assign weights according to the ranks.
For example, one could let
</bodyText>
<equation confidence="0.997258">
N + 1 — #→(xi)
P(X = xi) = (N + 1) * (N/2)
</equation>
<bodyText confidence="0.999987909090909">
This would assign a weight of N to the highest-
ranked instance, a weight of N — 1 to the next,
and continue in this manner down to the instance
at rank N, which would get weight 1. The de-
nominator in the above expression then serves to
normalize this weighting to a probability distri-
bution. Note that, in principle, nothing speaks
against using any other series of weights. Perhaps
further investigation into the application scenarios
of RTE systems will provide an extrinsically moti-
vated choice for such a confidence weighting.
</bodyText>
<sectionHeader confidence="0.9985" genericHeader="method">
6 Final Recommendations
</sectionHeader>
<bodyText confidence="0.999671">
Ultimately, our proposal boils down to four points,
which we believe are well-supported by the evi-
dence presented throughout this paper:
</bodyText>
<listItem confidence="0.995857777777778">
1. Additional clarification is needed as to the
logical definitions of the two-way and the three-
way distinction of entailment classes.
2. Accuracy and related evaluation measures
suffer from bias, and thus scores of theoretical
baselines must be reported and compared to sys-
tem scores. These include random choice and
choice of a constant label.
3. Average precision scores are misleading and
</listItem>
<bodyText confidence="0.85356">
should not be reported. The confidence-weighted
score that has been dropped after RTE-1 would
be preferable to average precision, but still suffers
from bias.
4. Mutual information should be reported,
in addition to accuracy and possibly confidence-
weighted score, to account for bias and the degra-
dation problem.
</bodyText>
<sectionHeader confidence="0.998132" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999967714285714">
I would like to thank the anonymous reviewers and my col-
league Ekaterina Shutova for providing many helpful com-
ments and my supervisor Ann Copestake for reading multiple
drafts of this paper and providing a great number of sugges-
tions within a very short timeframe. All errors and omissions
are, of course, entirely my own. I gratefully acknowledge
financial support by the Austrian Academy of Sciences.
</bodyText>
<sectionHeader confidence="0.999205" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999637388888889">
Ron Artstein and Massimo Poesio. 2005. Kappa3 = alpha
(or beta). Technical Report CSM-437, University of Essex
Department of Computer Science.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Gi-
ampiccolo, Bernardo Magnini, and Idan Szpektor. 2006.
The second pascal recognising textual entailment chal-
lenge. In Proceedings of the Second PASCAL Challenges
Workshop on Recognising Textual Entailment (RTE-2).
Jacob Cohen. 1960. A coefficient of agreement for nomi-
nal scales. Educational and Psychological Measurement,
20:37–46.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.
The pascal recognising textual entailment challenge. In
Ido Dagan, Oren Glickman, and Bernardo Magnini, ed-
itors, Proceedings of the PASCAL Challenges Workshop
on Recognising Textual Entailment (RTE-1).
Marie-Catherine de Marneffe and Christopher Manning.
2007. Contradiction annotation. http:// nlp.stanford.edu/
RTE3-pilot/ contradictions.pdf.
Barbara Di Eugenio and Michael Glass. 2004. The kappa
statistic: A second look. Computational Linguistics,
30(1):95–101.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill
Dolan. 2007. The third pascal recognising textual en-
tailment challenge. In Proceedings of the Workshop on
Textual Entailment and paraphrasing (RTE-3).
Danilo Giampicolo, Hoa Trang Dang, Bernardo Magnini, Ido
Dagan, and Bill Dolan. 2008. The fourth pascal recogniz-
ing textual entailment challenge. In Preproceedings of the
Text Analysis Conference (TAC).
TAC. 2009. Tac2009 rte-5 main task guide-
lines. http:// www.nist.gov/ tac/ 2009/ RTE/
RTE5 Main Guidelines.pdf.
Ellen M. Voorhees. 2008. Contradictions and justifications:
Extensions to the textual entailment task. In Proceedings
of ACL-08: HLT, pages 63–71.
</reference>
<page confidence="0.999409">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.462191">
<title confidence="0.998076">Proposal on Evaluation Measures for</title>
<author confidence="0.982836">Richard</author>
<affiliation confidence="0.6468625">recipient of a DOC-fellowship of the Austrian Academy of at the University of Cambridge Computer</affiliation>
<address confidence="0.500743">15 JJ Thomson Avenue, Cambridge CB3 0FD,</address>
<email confidence="0.984705">rbergmair@acm.org</email>
<abstract confidence="0.997853363636364">We outline problems with the interpretation of accuracy in the presence of bias, arguing that the issue is a particularly concern for Furthermore, we argue that average precision are unsuitable for and should not be reported. We advocate mutual information as a new evaluation measure that should be reported in addition to accuracy and confidence-weighted score.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Kappa3 = alpha (or beta).</title>
<date>2005</date>
<tech>Technical Report CSM-437,</tech>
<institution>University of Essex Department of Computer Science.</institution>
<contexts>
<context position="2009" citStr="Artstein and Poesio (2005)" startWordPosition="311" endWordPosition="314">ased thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great level of analogy between IR and RTE. However, we will argue that the analogy is flawed, and that average precision is not suitable for RTE evaluation. Then, we will then reframe the problem in information </context>
<context position="11181" citStr="Artstein and Poesio, 2005" startWordPosition="1982" endWordPosition="1985">s have an extrinsic interpretation. For example, in IR, precision is the probability that a document chosen randomly from the result set will be considered relevant by the user. Yet, for RTE, one cannot provide a representative sample, as the task is an abstraction over a number of different applications, such as information extraction (IE), question answering (QA), and summarization (SUM), all of which give rise to potentially very different distributions of labels. 3. On statistical grounds, one can account for the possibility of random agreement in the presence of bias using Cohen’s kappa (Artstein and Poesio, 2005; Di Eugenio and Glass, 2004). We will outline mutual information as an alternative, arguing that it has additional advantages. 4 Average Precision The purpose of average precision is to evaluate against the gold standard labelling G the systemassigned ranking &gt;, rather than directly comparing the two labellings G and L. This is done by deriving from the ranking &gt; a series of binary labellings. The i-th labelling in that series is that which labels all instances up to rank i as 4. A precision value can be computed for each of these labellings, compared to the same gold standard, and then avera</context>
</contexts>
<marker>Artstein, Poesio, 2005</marker>
<rawString>Ron Artstein and Massimo Poesio. 2005. Kappa3 = alpha (or beta). Technical Report CSM-437, University of Essex Department of Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Lisa Ferro</author>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Idan Szpektor</author>
</authors>
<title>The second pascal recognising textual entailment challenge.</title>
<date>2006</date>
<booktitle>In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment (RTE-2).</booktitle>
<contexts>
<context position="1803" citStr="Bar-Haim et al., 2006" startWordPosition="278" endWordPosition="281">ontext of evaluating a ranking by average precision. The criteria implicitly invoked on rankings by the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great</context>
</contexts>
<marker>Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, Szpektor, 2006</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor. 2006. The second pascal recognising textual entailment challenge. In Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment (RTE-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--37</pages>
<contexts>
<context position="2066" citStr="Cohen, 1960" startWordPosition="323" endWordPosition="324">ation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great level of analogy between IR and RTE. However, we will argue that the analogy is flawed, and that average precision is not suitable for RTE evaluation. Then, we will then reframe the problem in information theoretic terms, advocating mutual information as a new e</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20:37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment (RTE-1).</booktitle>
<editor>In Ido Dagan, Oren Glickman, and Bernardo Magnini, editors,</editor>
<contexts>
<context position="1772" citStr="Dagan et al., 2005" startWordPosition="273" endWordPosition="276">nking is misleading in the context of evaluating a ranking by average precision. The criteria implicitly invoked on rankings by the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology fr</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In Ido Dagan, Oren Glickman, and Bernardo Magnini, editors, Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment (RTE-1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher Manning</author>
</authors>
<title>Contradiction annotation.</title>
<date>2007</date>
<note>http:// nlp.stanford.edu/ RTE3-pilot/ contradictions.pdf.</note>
<marker>de Marneffe, Manning, 2007</marker>
<rawString>Marie-Catherine de Marneffe and Christopher Manning. 2007. Contradiction annotation. http:// nlp.stanford.edu/ RTE3-pilot/ contradictions.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Michael Glass</author>
</authors>
<title>The kappa statistic: A second look.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<marker>Di Eugenio, Glass, 2004</marker>
<rawString>Barbara Di Eugenio and Michael Glass. 2004. The kappa statistic: A second look. Computational Linguistics, 30(1):95–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognising textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Textual Entailment and paraphrasing (RTE-3).</booktitle>
<contexts>
<context position="1837" citStr="Giampiccolo et al., 2007" startWordPosition="283" endWordPosition="286">by average precision. The criteria implicitly invoked on rankings by the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great level of analogy between IR and R</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognising textual entailment challenge. In Proceedings of the Workshop on Textual Entailment and paraphrasing (RTE-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampicolo</author>
<author>Hoa Trang Dang</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The fourth pascal recognizing textual entailment challenge.</title>
<date>2008</date>
<booktitle>In Preproceedings of the Text Analysis Conference (TAC).</booktitle>
<contexts>
<context position="1904" citStr="Giampicolo et al., 2008" startWordPosition="293" endWordPosition="296"> the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great level of analogy between IR and RTE. However, we will argue that the analogy is flawed, and that ave</context>
</contexts>
<marker>Giampicolo, Dang, Magnini, Dagan, Dolan, 2008</marker>
<rawString>Danilo Giampicolo, Hoa Trang Dang, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2008. The fourth pascal recognizing textual entailment challenge. In Preproceedings of the Text Analysis Conference (TAC).</rawString>
</citation>
<citation valid="true">
<title>Tac2009 rte-5 main task guidelines. http:// www.nist.gov/ tac/</title>
<date>2009</date>
<booktitle>RTE/ RTE5 Main Guidelines.pdf.</booktitle>
<marker>2009</marker>
<rawString>TAC. 2009. Tac2009 rte-5 main task guidelines. http:// www.nist.gov/ tac/ 2009/ RTE/ RTE5 Main Guidelines.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Contradictions and justifications: Extensions to the textual entailment task.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>63--71</pages>
<contexts>
<context position="1871" citStr="Voorhees, 2008" startWordPosition="290" endWordPosition="291">y invoked on rankings by the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding. 3. Language allows for the expression of logical negation, thus imposing a symmetry on the judgements ENTAILED vs. CONTRADICTION. Average precision does not properly reflect this symmetry. In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth. 1see the reports on RTE-1 (Dagan et al., 2005), RTE-2 (Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007), the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al., 2008), and RTE-5 (TAC, 2009) The problem of bias is quite general and widely known. Artstein and Poesio (2005) discuss it in the context of Cohen’s kappa (Cohen, 1960), which is one way of addressing the problem. Yet, it has not received sufficient attention in the RTE community, which is why we will show how it applies to RTE, in particular, and why it is an especially pressing concern for RTE. Average precision has been imported into the RTE evaluation methodology from IR, tacitly assuming a great level of analogy between IR and RTE. However, we will argue that th</context>
<context position="6653" citStr="Voorhees, 2008" startWordPosition="1158" endWordPosition="1159">and not trivially related by equating A with ❵, and subdividing 5 into 0 and ❛. 3 Accuracy &amp; Related Measures Both the system and the gold standard apply to the dataset X a total labelling L and G respectively, i.e. they are forced to assign their best guess label to every instance. A degree of agreement can be determined as a percentage agreement either on the two-way or the three-way distinction: 1 N A3 (L; G) ✏ N i✏1 1(rL♣xiqs2 ✏ rG♣xiqs2), where 1 is a counter which takes on a numerical value of one, when the logical expression in its argument is true, and zero otherwise. The RTE-3 PILOT (Voorhees, 2008) reported some accuracy measures conditioned on gold standard labels as follows: A✶(LG�9) ✏ iiNi✏ 1 1(rL♣xiqs3 ✏ rG♣xiqs3 ✏ g) 3 ; A2 ; (LG, g) ✏ iiNi✏ 1 1(rL♣xiqs2 ✏ rG♣xiqs2 ✏ g) Assuming the usual analogy with IR, we note that A✶2(L; G, A)is akin to recall. On the other hand, A✶2(G; L, A), which conditions accuracy on the system-assigned labels rather than the gold standard labels, is precision. The conditioned accuracy measures do not provide a single summary statistic as the others do. However, such a summary could be defined by taking the mean across the different labels: It is instructi</context>
</contexts>
<marker>Voorhees, 2008</marker>
<rawString>Ellen M. Voorhees. 2008. Contradictions and justifications: Extensions to the textual entailment task. In Proceedings of ACL-08: HLT, pages 63–71.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>