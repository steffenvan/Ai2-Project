<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002498">
<title confidence="0.9992205">
A Graph-Theoretic Algorithm for Automatic Extension of Translation
Lexicons
</title>
<author confidence="0.989014">
Beate Dorow Florian Laws Lukas Michelbacher Christian Scheible Jason Utt
</author>
<affiliation confidence="0.7734635">
Institute for Natural Language Processing
Universit¨at Stuttgart
</affiliation>
<email confidence="0.995759">
{dorowbe,lawsfn,michells,scheibcn,uttjn}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.99734" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999879272727273">
This paper presents a graph-theoretic
approach to the identification of yet-
unknown word translations. The proposed
algorithm is based on the recursive Sim-
Rank algorithm and relies on the intuition
that two words are similar if they estab-
lish similar grammatical relationships with
similar other words. We also present a for-
mulation of SimRank in matrix form and
extensions for edge weights, edge labels
and multiple graphs.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982918367347">
This paper describes a cross-linguistic experiment
which attempts to extend a given translation dic-
tionary with translations of novel words.
In our experiment, we use an English and
a German text corpus and represent each cor-
pus as a graph whose nodes are words and
whose edges represent grammatical relationships
between words. The corpora need not be parallel.
Our intuition is that a node in the English and a
node in the German graph are similar (that is, are
likely to be translations of one another), if their
neighboring nodes are. Figure 1 shows part of the
English and the German word graph.
Many of the (first and higher order) neighbors
of food and Lebensmittel translate to one another
(marked by dotted lines), indicating that food and
Lebensmittel, too, are likely mutual translations.
Our hypothesis yields a recursive algorithm for
computing node similarities based on the simi-
larities of the nodes they are connected to. We
initialize the node similarities using an English-
German dictionary whose entries correspond to
known pairs of equivalent nodes (words). These
node equivalences constitute the “seeds” from
which novel English-German node (word) corre-
spondences are bootstrapped.
We are not aware of any previous work using a
measure of similarity between nodes in graphs for
cross-lingual lexicon acquisition.
Our approach is appealing in that it is language
independent, easily implemented and visualized,
and readily generalized to other types of data.
Section 2 is dedicated to related research on
the automatic extension of translation lexicons. In
Section 3 we review SimRank (Jeh and Widom,
2002), an algorithm for computing similarities of
nodes in a graph, which forms the basis of our
work. We provide a formulation of SimRank in
terms of simple matrix operations which allows
an efficient implementation using optimized ma-
trix packages. We further present a generalization
of SimRank to edge-weighted and edge-labeled
graphs and to inter-graph node comparison.
Section 4 describes the process used for build-
ing the word graphs. Section 5 presents an experi-
ment for evaluating our approach to bilingual lex-
icon acquisition. Section 6 reports the results. We
present our conclusions and directions for future
research in Section 7.
</bodyText>
<sectionHeader confidence="0.984125" genericHeader="related work">
2 Related Work on cross-lingual lexical
acquisition
</sectionHeader>
<bodyText confidence="0.999894428571429">
The work by Rapp (1999) is driven by the idea
that a word and its translation to another lan-
guage are likely to co-occur with similar words.
Given a German and an English corpus, he com-
putes two word-by-word co-occurrence matrices,
one for each language, whose columns span a vec-
tor space representing the corresponding corpus.
In order to find the English translation of a Ger-
man word, he uses a base dictionary to translate
all known column labels to English. This yields
a new vector representation of the German word
in the English vector space. This mapped vector
is then compared to all English word vectors, the
most similar ones being candidate translations.
</bodyText>
<note confidence="0.3612215">
Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 91–95,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.992702">
91
</page>
<figure confidence="0.999847466666667">
boat
waste
publish
buy
award Preis
food evidence Beweis Lebensmittel
provide
book Buch
receive
erhalten
liefern
verlegen
kaufen
ablehnen
Haus
</figure>
<figureCaption confidence="0.999965">
Figure 1: Likely translations based on neighboring nodes
</figureCaption>
<bodyText confidence="0.999702268292683">
Rapp reports an accuracy of 72% for a small
number of test words with well-defined meaning.
Diab and Finch (2000) first compute word sim-
ilarities within each language corpus separately
by comparing their co-occurrence vectors. Their
challenge then is to derive a mapping from one
language to the other (i.e. a translation lexicon)
which best preserves the intra-language word sim-
ilarities. The mapping is initialized with a few seed
“translations” (punctuation marks) which are as-
sumed to be common to both corpora.
They test their method on two corpora written
in the same language and report accuracy rates of
over 90% on this pseudo-translation task. The ap-
proach is attractive in that it does not require a
seed lexicon. A drawback is its high computational
cost.
Koehn and Knight (2002) use a (linear) com-
bination of clues for bootstrapping an English-
German noun translation dictionary. In addition to
similar assumptions as above, they consider words
to be likely translations of one another if they have
the same or similar spelling and/or occur with sim-
ilar frequencies. Koehn and Knight reach an accu-
racy of 39% on a test set consisting of the 1,000
most frequent English and German nouns. The
experiment excludes verbs whose semantics are
more complex than those of nouns.
Otero and Campos (2005) extract English-
Spanish pairs of lexico-syntactic patterns from a
small parallel corpus. They then construct con-
text vectors for all English and Spanish words by
recording their frequency of occurrence in each of
these patterns. English and Spanish vectors thus
reside in the same vector space and are readily
compared.
The approach reaches an accuracy of 89% on a
test set consisting of 100 randomly chosen words
from among those with a frequency of 100 or
higher. The authors do not report results for low-
frequency words.
</bodyText>
<sectionHeader confidence="0.993067" genericHeader="method">
3 The SimRank algorithm
</sectionHeader>
<bodyText confidence="0.999808090909091">
An algorithm for computing similarities of nodes
in graphs is the SimRank algorithm (Jeh and
Widom, 2002). It was originally proposed for di-
rected unweighted graphs of web pages (nodes)
and hyperlinks (links).
The idea of SimRank is to recursively com-
pute node similarity scores based on the scores
of neighboring nodes. The similarity Sij of two
different nodes i and j in a graph is defined as
the normalized sum of the pairwise similarities of
their neighbors:
</bodyText>
<equation confidence="0.835882">
Sij = |N(i) |c  |N(j)  |1: Skl. (1)
kEN(i),lEN(j)
</equation>
<bodyText confidence="0.955457333333333">
N(i) and N(j) are the set of i’s and j’s neigh-
bors respectively, and c is a multiplicative factor
smaller than but close to 1 which demotes the con-
tribution of higher order neighbors. Sij is set to 1
if i and j are identical, which provides a basis for
the recursion.
</bodyText>
<subsectionHeader confidence="0.997533">
3.1 Matrix formulation of SimRank
</subsectionHeader>
<bodyText confidence="0.999732">
We derive a formulation of the SimRank similarity
updates which merely consists of matrix multipli-
cations as follows. In terms of the graph’s (binary)
adjacency matrix A, the SimRank recursion reads:
</bodyText>
<equation confidence="0.815579">
|N(i) ||N(j) |1: Aik Ajl Skl
kEN(i),lEN(j)
(2)
</equation>
<bodyText confidence="0.9970285">
noting that AikAjl = 1, iff k is a neighbor of i
and l is a neighbor of j at the same time. This is
</bodyText>
<figure confidence="0.7680435">
Sij =
c
92
Ajl Skl (3)
N(j)|
Ajl Skl.
</figure>
<subsectionHeader confidence="0.557548">
Pν Ajν
</subsectionHeader>
<bodyText confidence="0.992264">
The Sij can be assembled in a square node sim-
ilarity matrix S, and it is easy to see that the indi-
vidual similarity updates can be summarized as:
</bodyText>
<equation confidence="0.968655">
Sk = c A˜ Sk−1˜AT (4)
</equation>
<bodyText confidence="0.9996552">
where A˜ is the row-normalized adjacency matrix
and k denotes the current level of recursion. A˜ is
obtained by dividing each entry of A by the sum of
the entries in its row. The SimRank iteration is ini-
tialized with S = I, and the diagonal of S, which
contains the node self-similarities, is reset to ones
after each iteration.
This representation of SimRank in closed ma-
trix form allows the use of optimized off-the-shelf
sparse matrix packages for the implementation of
the algorithm. This rendered the pruning strate-
gies proposed in the original paper unnecessary.
We also note that the Bipartite SimRank algorithm
introduced in (Jeh and Widom, 2002) is just a spe-
cial case of Equation 4.
</bodyText>
<subsectionHeader confidence="0.999685">
3.2 Extension with weights and link types
</subsectionHeader>
<bodyText confidence="0.9999665">
The SimRank algorithm assumes an unweighted
graph, i.e. a binary adjacency matrix A. Equa-
tion 4 can equally be used to compute similarities
in a weighted graph by letting A˜ be the graph’s
row-normalized weighted adjacency matrix. The
entries of A˜ then represent transition probabili-
ties between nodes rather than hard (binary) adja-
cency. The proof of the existence and uniqueness
of a solution to this more general recursion pro-
ceeds in analogy to the proof given in the original
paper.
Furthermore, we allow the links in the graph to
be of different types and define the following gen-
eralized SimRank recursion, where T is the set of
link types and Nt(i) denotes the set of nodes con-
nected to node i via a link of type t.
</bodyText>
<equation confidence="0.9859547">
c X 1 X
Sij = Skl.
|T  ||Nt(i) ||Nt(j)|
t∈T k∈Nt(i),l∈Nt(j)
(5)
In matrix formulation:
cX
Sk = ˜At Sk−1 ˜At T (6)
|T |
t∈T
</equation>
<bodyText confidence="0.999719">
where At is the adjacency matrix associated with
link type t and, again, may be weighted.
</bodyText>
<subsectionHeader confidence="0.997966">
3.3 SimRank across graphs
</subsectionHeader>
<bodyText confidence="0.998336">
SimRank was originally designed for the com-
parison of nodes within a single graph. However,
SimRank is readily and accordingly applied to
the comparison of nodes of two different graphs.
The original SimRank algorithm starts off with the
nodes’ self-similarities which propagate to other
non-identical pairs of nodes. In the case of two dif-
ferent graphs A and B, we can instead initialize the
algorithm with a set of initially known node-node
correspondences.
The original SimRank equation (2) then be-
comes
</bodyText>
<equation confidence="0.964891333333333">
Sij =|N(i)|c|N(j) |XAik Bjl Skl, (7)
k,l
which is equivalent to
Sk = c A˜ Sk−1 ˜BT, (8)
or, if links are typed,
c X
Sk = ˜At Sk−1 ˜Bt T . (9)
|T |
t∈T
</equation>
<bodyText confidence="0.999859">
The similarity matrix S is now a rectangular
matrix containing the similarities between nodes
in A and nodes in B. Those entries of S which
correspond to known node-node correspondences
are reset to 1 after each iteration.
</bodyText>
<sectionHeader confidence="0.993709" genericHeader="method">
4 The graph model
</sectionHeader>
<bodyText confidence="0.999949294117647">
The grammatical relationships were extracted
from the British National Corpus (BNC) (100 mil-
lion words), and the Huge German Corpus (HGC)
(180 million words of newspaper text). We com-
piled a list of English verb-object (V-O) pairs
based on the verb-argument information extracted
by (Schulte im Walde, 1998) from the BNC. The
German V-O pairs were extracted from a syntactic
analysis of the HGC carried out using the BitPar
parser (Schmid, 2004).
We used only V-O pairs because they consti-
tute far more sense-discriminative contexts than,
for example, verb-subject pairs, but we plan to ex-
amine these and other grammatical relationships
in future work.
We reduced English compound nouns to their
heads and lemmatized all data. In English phrasal
</bodyText>
<figure confidence="0.995947285714286">
equivalent to Aik
XSij = c
k,l
|N(i)|
X= c Aik
k,l
Pν Aiν
</figure>
<page confidence="0.754957">
93
</page>
<table confidence="0.5522135">
English German
Low Mid High Low Mid High
N V N V N V N V N V N V
0.313 0.228 0.253 0.288 0.253 0.255 0.232 0.247 0.205 0.237 0.211 0.205
</table>
<tableCaption confidence="0.997466">
Table 1: The 12 categories of test words, with mean relative ranks of test words
</tableCaption>
<bodyText confidence="0.999974521739131">
verbs, we attach the particles to the verbs to dis-
tinguish them from the original verb (e.g put off
vs. put). Both the English and German V-O pairs
were filtered using stop lists consisting of modal
and auxiliary verbs as well as pronouns. To reduce
noise, we decided to keep only those relationships
which occurred at least three times in the respec-
tive corpus.
The English and German data alike are then rep-
resented as a bipartite graph whose nodes divide
into two sets, verbs and nouns, and whose edges
are the V-O relationships which connect verbs to
nouns (cf. Figure 1). The edges of the graph are
weighted by frequency of occurrence.
We “prune” both the English and German graph
by recursively removing all leaf nodes (nodes with
a single neighbor). As these correspond to words
which appear only in a single relationship, there is
only limited evidence of their meaning.
After pruning, there are 4,926 nodes (3,365
nouns, 1,561 verbs) and 43,762 links in the En-
glish, and 3,074 nodes (2,207 nouns, 867 verbs)
and 15,386 links in the German word graph.
</bodyText>
<sectionHeader confidence="0.986111" genericHeader="method">
5 Evaluation experiment
</sectionHeader>
<bodyText confidence="0.999303941176471">
The aim of our evaluation experiment is to test
the extended SimRank algorithm for its ability to
identify novel word translations given the English
and German word graph of the previous section
and an English-German seed lexicon. We use the
dict.cc English-German dictionary 1.
Our evaluation strategy is as follows. We se-
lect a set of test words at random from among the
words listed in the dictionary, and remove their en-
tries from the dictionary. We run six iterations of
SimRank using the remaining dictionary entries
as the seed translations (the known node equiv-
alences), and record the similarities of each test
word to its known translations. As in the original
SimRank paper, c is set to 0.8.
We include both English and German test words
and let them vary in frequency: high- (&gt; 100),
</bodyText>
<footnote confidence="0.989877">
1http://www.dict.cc/ (May 5th 2008)
</footnote>
<bodyText confidence="0.9995535">
mid- (&gt; 20 and &lt; 100), and low- (&lt; 20) fre-
quent as well as word class (noun, verb). Thus, we
obtain 12 categories of test words (summarized in
Table 1), each of which is filled with 50 randomly
selected words, giving a total of 600 test words.
SimRank returns a matrix of English-German
node-node similarities. Given a test word, we ex-
tract its row from the similarity matrix and sort the
corresponding words by their similarities to the
test word. We then scan this sorted list of words
and their similarities for the test word’s reference
translations (those listed in the original dictionary)
and record their positions (i.e. ranks) in this list.
We then replace absolute ranks with relative ranks
by dividing by the total number of candidate trans-
lations.
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9990574">
Table 1 lists the mean relative rank of the reference
translations for each of the test categories. The
values of around 0.2-0.3 clearly indicate that our
approach ranks the reference translations much
higher than a random process would.
</bodyText>
<figure confidence="0.97666225">
Frequency
0 5 15 25
0.0 0.2 0.4 0.6 0.8 1.0
Relative rank
</figure>
<figureCaption confidence="0.918718666666667">
Figure 2: Distribution of the relative ranks of the
reference translations in the English-High-N test
set.
</figureCaption>
<bodyText confidence="0.999439285714286">
Exemplary of all test sets, Figure 2 shows the
distribution of the relative ranks of the reference
translations for the test words in English-High-N.
The bulk of the distribution lies below 0.3, i.e. in
the top 30% of the candidate list.
In order to give the reader an idea of the results,
we present some examples of test words and their
</bodyText>
<page confidence="0.998167">
94
</page>
<table confidence="0.999247916666667">
Test word Top 10 predicted translations Ranks
sanction Ausgangssperre Wirtschaftssanktion Sanktion(6)
Ausnahmezustand Embargo Moratorium Maßnahme(1407)
Sanktion Todesurteil Geldstrafe Bußgeld
Anmeldung
delay anfechten revidieren zur¨uckstellen verz¨ogern(78)
f¨ullen verk¨unden quittieren vertagen aufhalten(712)
verschieben aufheben respektieren
Kosten hallmark trouser blouse makup uniform cost(285)
armour robe testimony witness jumper
¨offnen unlock lock usher step peer shut guard open(12)
hurry slam close undo(481)
</table>
<tableCaption confidence="0.983613">
Table 2: Some examples of test words, their pre-
</tableCaption>
<bodyText confidence="0.9889223">
dicted translations, and the ranks of their true
translations.
predicted translations in Table 2.
Most of the 10 top-ranked candidate transla-
tions of sanction are hyponyms of the correct
translations. This is mainly due to insufficient
noun compound analysis. Both the English and
German nouns in our graph model are single
words. Whereas the English nouns consist only of
head nouns, the German nouns include many com-
pounds (as they are written without spaces), and
thus tend to be more specific.
Some of the top candidate translations of de-
lay are correct (verschieben) or at least acceptable
(vertagen), but do not count as such as they are
missing in the gold standard dictionary.
The mistranslation of the German noun Kosten
is due to semantic ambiguity. Kosten co-occurs of-
ten with the verb tragen as in to bear costs. The
verb tragen however is ambiguous and may as
well be translated as to wear which is strongly as-
sociated with clothes.
We find several antonyms of ¨offnen among its
top predicted translations. Verb-object relation-
ships alone do not suffice to distinguish synonyms
from antonyms. Similarly, it is extremely difficult
to differentiate between the members of closed
categories (e.g. the days of the week, months of
the year, mass and time units) using only syntactic
relationships.
</bodyText>
<sectionHeader confidence="0.999067" genericHeader="conclusions">
7 Conclusions and Future Research
</sectionHeader>
<bodyText confidence="0.999982583333333">
The matrix formulation of the SimRank algorithm
given in this paper allows an implementation using
efficient off-the-shelf software libraries for matrix
computation.
We presented an extension of the SimRank
algorithm to edge-weighted and edge-labeled
graphs. We further generalized the SimRank equa-
tions to permit the comparison of nodes from two
different graphs, and proposed an application to
bilingual lexicon induction.
Our system is not yet accurate enough to be
used for actual compilation of translation dictio-
naries. We further need to address the problem of
data sparsity. In particular, we need to remove the
bias towards low-degree words whose similarities
to other words are unduly high.
In order to solve the problem of ambiguity, we
intend to apply SimRank to the incidence repre-
sentation of the word graphs, which is constructed
by putting a node on each link. The proposed al-
gorithm will then naturally return similarities be-
tween the more sense-discriminative links (syn-
tactic relationships) in addition to similarities be-
tween the often ambiguous nodes (isolated words).
</bodyText>
<sectionHeader confidence="0.999573" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997795066666667">
M. Diab and S. Finch. 2000. A statistical word-
level translation model for comparable corpora. In
In Proceedings of the Conference on Content-Based
Multimedia Information Access (RIAO).
G. Jeh and J. Widom. 2002. Simrank: A measure of
structural-context similarity. In KDD ’02: Proceed-
ings of the eighth ACMSIGKDD International Con-
ference on Knowledge Discovery and Data Mining,
pages 538–543.
P. Koehn and K. Knight. 2002. Learning a translation
lexicon from monolingual corpora. In Proceedings
of the ACL-02 Workshop on Unsupervised Lexical
Acquisition, pages 9–16.
P. Gamallo Otero and J. Ramon Pichel Campos. 2005.
An approach to acquire word translations from non-
parallel texts. In EPIA, pages 600–610.
R. Rapp. 1999. Automatic identification of word trans-
lations from unrelated English and German corpora.
In Proceedings of the 37th Annual Meeting of the
Association for Computational Linguistics on Com-
putational Linguistics, pages 519–526.
Helmut Schmid. 2004. Efficient parsing of highly am-
biguous context-free grammars with bit vectors. In
COLING ’04: Proceedings of the 20th International
Conference on Computational Linguistics, page 162.
Sabine Schulte im Walde. 1998. Automatic Se-
mantic Classification of Verbs According to Their
Alternation Behaviour. Master’s thesis, Insti-
tut f¨ur Maschinelle Sprachverarbeitung, Universit¨at
Stuttgart.
</reference>
<page confidence="0.999069">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.797209">
<title confidence="0.9972415">A Graph-Theoretic Algorithm for Automatic Extension of Translation Lexicons</title>
<author confidence="0.983205">Beate Dorow Florian Laws Lukas Michelbacher Christian Scheible Jason</author>
<affiliation confidence="0.9041075">Institute for Natural Language Universit¨at</affiliation>
<abstract confidence="0.999377833333333">This paper presents a graph-theoretic approach to the identification of yetunknown word translations. The proposed algorithm is based on the recursive Sim- Rank algorithm and relies on the intuition that two words are similar if they establish similar grammatical relationships with similar other words. We also present a formulation of SimRank in matrix form and extensions for edge weights, edge labels and multiple graphs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>S Finch</author>
</authors>
<title>A statistical wordlevel translation model for comparable corpora. In</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Content-Based Multimedia Information Access (RIAO).</booktitle>
<contexts>
<context position="4210" citStr="Diab and Finch (2000)" startWordPosition="647" endWordPosition="650">This mapped vector is then compared to all English word vectors, the most similar ones being candidate translations. Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 91–95, Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics 91 boat waste publish buy award Preis food evidence Beweis Lebensmittel provide book Buch receive erhalten liefern verlegen kaufen ablehnen Haus Figure 1: Likely translations based on neighboring nodes Rapp reports an accuracy of 72% for a small number of test words with well-defined meaning. Diab and Finch (2000) first compute word similarities within each language corpus separately by comparing their co-occurrence vectors. Their challenge then is to derive a mapping from one language to the other (i.e. a translation lexicon) which best preserves the intra-language word similarities. The mapping is initialized with a few seed “translations” (punctuation marks) which are assumed to be common to both corpora. They test their method on two corpora written in the same language and report accuracy rates of over 90% on this pseudo-translation task. The approach is attractive in that it does not require a se</context>
</contexts>
<marker>Diab, Finch, 2000</marker>
<rawString>M. Diab and S. Finch. 2000. A statistical wordlevel translation model for comparable corpora. In In Proceedings of the Conference on Content-Based Multimedia Information Access (RIAO).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Jeh</author>
<author>J Widom</author>
</authors>
<title>Simrank: A measure of structural-context similarity.</title>
<date>2002</date>
<booktitle>In KDD ’02: Proceedings of the eighth ACMSIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>538--543</pages>
<contexts>
<context position="2349" citStr="Jeh and Widom, 2002" startWordPosition="351" endWordPosition="354">ry whose entries correspond to known pairs of equivalent nodes (words). These node equivalences constitute the “seeds” from which novel English-German node (word) correspondences are bootstrapped. We are not aware of any previous work using a measure of similarity between nodes in graphs for cross-lingual lexicon acquisition. Our approach is appealing in that it is language independent, easily implemented and visualized, and readily generalized to other types of data. Section 2 is dedicated to related research on the automatic extension of translation lexicons. In Section 3 we review SimRank (Jeh and Widom, 2002), an algorithm for computing similarities of nodes in a graph, which forms the basis of our work. We provide a formulation of SimRank in terms of simple matrix operations which allows an efficient implementation using optimized matrix packages. We further present a generalization of SimRank to edge-weighted and edge-labeled graphs and to inter-graph node comparison. Section 4 describes the process used for building the word graphs. Section 5 presents an experiment for evaluating our approach to bilingual lexicon acquisition. Section 6 reports the results. We present our conclusions and directi</context>
<context position="6056" citStr="Jeh and Widom, 2002" startWordPosition="951" endWordPosition="954">lexico-syntactic patterns from a small parallel corpus. They then construct context vectors for all English and Spanish words by recording their frequency of occurrence in each of these patterns. English and Spanish vectors thus reside in the same vector space and are readily compared. The approach reaches an accuracy of 89% on a test set consisting of 100 randomly chosen words from among those with a frequency of 100 or higher. The authors do not report results for lowfrequency words. 3 The SimRank algorithm An algorithm for computing similarities of nodes in graphs is the SimRank algorithm (Jeh and Widom, 2002). It was originally proposed for directed unweighted graphs of web pages (nodes) and hyperlinks (links). The idea of SimRank is to recursively compute node similarity scores based on the scores of neighboring nodes. The similarity Sij of two different nodes i and j in a graph is defined as the normalized sum of the pairwise similarities of their neighbors: Sij = |N(i) |c |N(j) |1: Skl. (1) kEN(i),lEN(j) N(i) and N(j) are the set of i’s and j’s neighbors respectively, and c is a multiplicative factor smaller than but close to 1 which demotes the contribution of higher order neighbors. Sij is se</context>
<context position="7979" citStr="Jeh and Widom, 2002" startWordPosition="1299" endWordPosition="1302">acency matrix and k denotes the current level of recursion. A˜ is obtained by dividing each entry of A by the sum of the entries in its row. The SimRank iteration is initialized with S = I, and the diagonal of S, which contains the node self-similarities, is reset to ones after each iteration. This representation of SimRank in closed matrix form allows the use of optimized off-the-shelf sparse matrix packages for the implementation of the algorithm. This rendered the pruning strategies proposed in the original paper unnecessary. We also note that the Bipartite SimRank algorithm introduced in (Jeh and Widom, 2002) is just a special case of Equation 4. 3.2 Extension with weights and link types The SimRank algorithm assumes an unweighted graph, i.e. a binary adjacency matrix A. Equation 4 can equally be used to compute similarities in a weighted graph by letting A˜ be the graph’s row-normalized weighted adjacency matrix. The entries of A˜ then represent transition probabilities between nodes rather than hard (binary) adjacency. The proof of the existence and uniqueness of a solution to this more general recursion proceeds in analogy to the proof given in the original paper. Furthermore, we allow the link</context>
</contexts>
<marker>Jeh, Widom, 2002</marker>
<rawString>G. Jeh and J. Widom. 2002. Simrank: A measure of structural-context similarity. In KDD ’02: Proceedings of the eighth ACMSIGKDD International Conference on Knowledge Discovery and Data Mining, pages 538–543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="4888" citStr="Koehn and Knight (2002)" startWordPosition="757" endWordPosition="760">orpus separately by comparing their co-occurrence vectors. Their challenge then is to derive a mapping from one language to the other (i.e. a translation lexicon) which best preserves the intra-language word similarities. The mapping is initialized with a few seed “translations” (punctuation marks) which are assumed to be common to both corpora. They test their method on two corpora written in the same language and report accuracy rates of over 90% on this pseudo-translation task. The approach is attractive in that it does not require a seed lexicon. A drawback is its high computational cost. Koehn and Knight (2002) use a (linear) combination of clues for bootstrapping an EnglishGerman noun translation dictionary. In addition to similar assumptions as above, they consider words to be likely translations of one another if they have the same or similar spelling and/or occur with similar frequencies. Koehn and Knight reach an accuracy of 39% on a test set consisting of the 1,000 most frequent English and German nouns. The experiment excludes verbs whose semantics are more complex than those of nouns. Otero and Campos (2005) extract EnglishSpanish pairs of lexico-syntactic patterns from a small parallel corp</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>P. Koehn and K. Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gamallo Otero</author>
<author>J Ramon Pichel Campos</author>
</authors>
<title>An approach to acquire word translations from nonparallel texts.</title>
<date>2005</date>
<booktitle>In EPIA,</booktitle>
<pages>600--610</pages>
<contexts>
<context position="5403" citStr="Otero and Campos (2005)" startWordPosition="843" endWordPosition="846"> that it does not require a seed lexicon. A drawback is its high computational cost. Koehn and Knight (2002) use a (linear) combination of clues for bootstrapping an EnglishGerman noun translation dictionary. In addition to similar assumptions as above, they consider words to be likely translations of one another if they have the same or similar spelling and/or occur with similar frequencies. Koehn and Knight reach an accuracy of 39% on a test set consisting of the 1,000 most frequent English and German nouns. The experiment excludes verbs whose semantics are more complex than those of nouns. Otero and Campos (2005) extract EnglishSpanish pairs of lexico-syntactic patterns from a small parallel corpus. They then construct context vectors for all English and Spanish words by recording their frequency of occurrence in each of these patterns. English and Spanish vectors thus reside in the same vector space and are readily compared. The approach reaches an accuracy of 89% on a test set consisting of 100 randomly chosen words from among those with a frequency of 100 or higher. The authors do not report results for lowfrequency words. 3 The SimRank algorithm An algorithm for computing similarities of nodes in </context>
</contexts>
<marker>Otero, Campos, 2005</marker>
<rawString>P. Gamallo Otero and J. Ramon Pichel Campos. 2005. An approach to acquire word translations from nonparallel texts. In EPIA, pages 600–610.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="3062" citStr="Rapp (1999)" startWordPosition="465" endWordPosition="466">rovide a formulation of SimRank in terms of simple matrix operations which allows an efficient implementation using optimized matrix packages. We further present a generalization of SimRank to edge-weighted and edge-labeled graphs and to inter-graph node comparison. Section 4 describes the process used for building the word graphs. Section 5 presents an experiment for evaluating our approach to bilingual lexicon acquisition. Section 6 reports the results. We present our conclusions and directions for future research in Section 7. 2 Related Work on cross-lingual lexical acquisition The work by Rapp (1999) is driven by the idea that a word and its translation to another language are likely to co-occur with similar words. Given a German and an English corpus, he computes two word-by-word co-occurrence matrices, one for each language, whose columns span a vector space representing the corresponding corpus. In order to find the English translation of a German word, he uses a base dictionary to translate all known column labels to English. This yields a new vector representation of the German word in the English vector space. This mapped vector is then compared to all English word vectors, the most</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>R. Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>162</pages>
<contexts>
<context position="10367" citStr="Schmid, 2004" startWordPosition="1722" endWordPosition="1723">rities between nodes in A and nodes in B. Those entries of S which correspond to known node-node correspondences are reset to 1 after each iteration. 4 The graph model The grammatical relationships were extracted from the British National Corpus (BNC) (100 million words), and the Huge German Corpus (HGC) (180 million words of newspaper text). We compiled a list of English verb-object (V-O) pairs based on the verb-argument information extracted by (Schulte im Walde, 1998) from the BNC. The German V-O pairs were extracted from a syntactic analysis of the HGC carried out using the BitPar parser (Schmid, 2004). We used only V-O pairs because they constitute far more sense-discriminative contexts than, for example, verb-subject pairs, but we plan to examine these and other grammatical relationships in future work. We reduced English compound nouns to their heads and lemmatized all data. In English phrasal equivalent to Aik XSij = c k,l |N(i)| X= c Aik k,l Pν Aiν 93 English German Low Mid High Low Mid High N V N V N V N V N V N V 0.313 0.228 0.253 0.288 0.253 0.255 0.232 0.247 0.205 0.237 0.211 0.205 Table 1: The 12 categories of test words, with mean relative ranks of test words verbs, we attach the</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Helmut Schmid. 2004. Efficient parsing of highly ambiguous context-free grammars with bit vectors. In COLING ’04: Proceedings of the 20th International Conference on Computational Linguistics, page 162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Automatic Semantic Classification of Verbs According to Their Alternation Behaviour. Master’s thesis, Institut f¨ur Maschinelle Sprachverarbeitung,</title>
<date>1998</date>
<location>Universit¨at Stuttgart.</location>
<contexts>
<context position="10229" citStr="Walde, 1998" startWordPosition="1698" endWordPosition="1699"> or, if links are typed, c X Sk = ˜At Sk−1 ˜Bt T . (9) |T | t∈T The similarity matrix S is now a rectangular matrix containing the similarities between nodes in A and nodes in B. Those entries of S which correspond to known node-node correspondences are reset to 1 after each iteration. 4 The graph model The grammatical relationships were extracted from the British National Corpus (BNC) (100 million words), and the Huge German Corpus (HGC) (180 million words of newspaper text). We compiled a list of English verb-object (V-O) pairs based on the verb-argument information extracted by (Schulte im Walde, 1998) from the BNC. The German V-O pairs were extracted from a syntactic analysis of the HGC carried out using the BitPar parser (Schmid, 2004). We used only V-O pairs because they constitute far more sense-discriminative contexts than, for example, verb-subject pairs, but we plan to examine these and other grammatical relationships in future work. We reduced English compound nouns to their heads and lemmatized all data. In English phrasal equivalent to Aik XSij = c k,l |N(i)| X= c Aik k,l Pν Aiν 93 English German Low Mid High Low Mid High N V N V N V N V N V N V 0.313 0.228 0.253 0.288 0.253 0.255</context>
</contexts>
<marker>Walde, 1998</marker>
<rawString>Sabine Schulte im Walde. 1998. Automatic Semantic Classification of Verbs According to Their Alternation Behaviour. Master’s thesis, Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>