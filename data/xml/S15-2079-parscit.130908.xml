<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025419">
<title confidence="0.992314">
UNITN: Training Deep Convolutional Neural Network for Twitter
Sentiment Classification
</title>
<author confidence="0.996947">
Aliaksei Severyn Alessandro Moschitti
</author>
<affiliation confidence="0.999234">
DISI, University of Trento Qatar Computing Research Institue
</affiliation>
<address confidence="0.534762">
38123 Povo (TN), Italy 5825 Doha, Qatar
</address>
<email confidence="0.997737">
severyn@disi.unitn.it amoschitti@qf.org.qa
</email>
<sectionHeader confidence="0.995612" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956761904762">
This paper describes our deep learning system
for sentiment analysis of tweets. The main
contribution of this work is a process to ini-
tialize the parameter weights of the convolu-
tional neural network, which is crucial to train
an accurate model while avoiding the need to
inject any additional features. Briefly, we use
an unsupervised neural language model to ini-
tialize word embeddings that are further tuned
by our deep learning model on a distant super-
vised corpus. At a final stage, the pre-trained
parameters of the network are used to initialize
the model which is then trained on the super-
vised training data from Semeval-2015. Ac-
cording to results on the official test sets, our
model ranks 1st in the phrase-level subtask A
(among 11 teams) and 2nd on the message-
level subtask B (among 40 teams). Interest-
ingly, computing an average rank over all six
test sets (official and five progress test sets)
puts our system 1st in both subtasks A and B.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972444444444">
In this work we describe our deep convolutional neu-
ral network for sentiment analysis of tweets. Its
architecture is most similar to the deep learning
systems presented in (Kalchbrenner et al., 2014;
Kim, 2014) that have recently established new state-
of-the-art results on various NLP sentence clas-
sification tasks also including sentiment analysis.
While already demonstrating excellent results, train-
ing a convolutional neural network that would beat
hand-engineered approaches that also rely on multi-
ple manual and automatically constructed lexicons,
e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014;
Severyn and Moschitti, 2015), requires careful at-
tention. This becomes an even harder problem espe-
cially in cases when the amount of labelled data is
relatively small, e.g., thousands of examples.
Turns out, providing the network with good ini-
tialisation parameters makes all the difference in
training an accurate model. We propose a three-step
process we follow to train our deep learning model
for sentiment classification. It can be summarized as
follows: (i) word embeddings are initialized using
a neural language model (Ronan Collobert, 2008;
Mikolov et al., 2013) which is trained on a large un-
supervised collection of tweets; (ii) we use our con-
volutional neural network to further refine the em-
beddings on a large distant supervised corpus (Go
et al., 2009); (iii) the word embeddings and other
parameters of the network obtained at the previous
stage are used to initialize the network that is then
trained on a supervised corpus from Semeval-2015.
We apply our deep learning model on two sub-
tasks of Semeval-2015 Twitter Sentiment Analysis
(Task 10) challenge (Rosenthal et al., 2015): phrase-
level (subtask A) and message-level (subtask B).
Our system ranks 1st on the official test set of the
phrase-level and 2nd on the message-level subtask.
In addition to the test set used to establish the fi-
nal ranking in Semeval-2015, all systems were also
evaluated on the progress test set which consists of
five test sets, where our system also shows strong re-
sults. In particular, we rank all systems according to
their performance on each test set and compute their
average ranks. Interestingly, our model appears to
be the most robust across all six test sets ranking 1st
</bodyText>
<page confidence="0.993471">
464
</page>
<bodyText confidence="0.82224">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 464–469,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
according to the average rank in both subtasks A and sentence (see Fig. 1): J J J ⎤
B. ⎡ w1 ... w|s |⎦
In the following, we describe the architecture of S = ⎣ J J J
our convolutional neural network and the parameter
initialization process process we follow to train it.
</bodyText>
<sectionHeader confidence="0.9774" genericHeader="method">
2 Our Deep Learning model for sentiment
classification
</sectionHeader>
<bodyText confidence="0.999964608695652">
The architecture of our convolutional neural net-
work for sentiment classification is shown on Fig. 1.
It is mainly inspired by the architectures used in
(Kalchbrenner et al., 2014; Kim, 2014) for per-
forming various sentence classification tasks. Given
that our training process (described in Sec. 3.3) re-
quires to run the network on a rather large corpus,
our design choices are mainly driven by the com-
putational efficiency of our network. Hence, differ-
ent from (Kalchbrenner et al., 2014) that presents
an architecture with several layers of convolutional
feature maps, we adopt a single level architecture,
which has been shown in (Kim, 2014) to perform
equally well.
Our network is composed of a single convolu-
tional layer followed by a non-linearity, max pooling
and a soft-max classification layer.
In the following we give a brief explanation of the
main components of our network architecture: sen-
tence matrix, activations, convolutional, pooling and
softmax layers. We also describe how to adapt the
network for predicting sentiment of phrases inside
the tweets.
</bodyText>
<subsectionHeader confidence="0.99828">
2.1 Sentence matrix
</subsectionHeader>
<bodyText confidence="0.998793052631579">
The input to our model are tweets each treated as a
sequence of words: [wi, .., w|s|], where each word
is drawn from a vocabulary V . Words are repre-
sented by distributional vectors w E Rd looked
up in a word embeddings matrix W E Rd×|V |.
This matrix is formed by concatentating embeddings
of all words in V . For convenience and ease of
lookup operations in W, words are mapped to in-
dices 1, ... , JV J.
For each input tweet s we build a sentence matrix
S E Rd×|s|, where each column i represents a word
embedding wi at the corresponding position i in a
To learn to capture and compose features of individ-
ual words in a given sentence from low-level word
embeddings into higher level semantic concepts, the
neural network applies a series of transformations to
the input sentence matrix S using convolution, non-
linearity and pooling operations, which we describe
next.
</bodyText>
<subsectionHeader confidence="0.999709">
2.2 Convolutional feature maps
</subsectionHeader>
<bodyText confidence="0.999982125">
The aim of the convolutional layer is to extract
patterns, i.e., discriminative word sequences found
within the input tweets that are common throughout
the training instances.
More formally, the convolution operation * be-
tween an input matrix s E Rd×|s |and a filter F E
Rd×m of width m results in a vector c E R|s|+m−1
where each component is computed as follows:
</bodyText>
<equation confidence="0.8498085">
�ci = (S * F)i = (S[:,i−m+1:i] ® F)kj (1)
k,j
</equation>
<bodyText confidence="0.999925130434782">
where ® is the element-wise multiplication and
S[:,i−m+1:i] is a matrix slice of size m along the
columns. Note that the convolution filter is of the
same dimensionality d as the input sentence matrix.
As shown in Fig. 1, it slides along the column di-
mension of S producing a vector c E R1×(|s|−m+1)
in output. Each component ci is the result of com-
puting an element-wise product between a column
slice of S and a filter matrix F, which is then
summed to a single value.
So far we have described a way to compute a con-
volution between the input sentence matrix and a
single filter. To form a richer representation of the
data, deep learning models apply a set of filters that
work in parallel generating multiple feature maps
(also shown on Fig. 1). A set of filters form a fil-
ter bank F E Rn×d×m sequentially convolved with
the sentence matrix S and producing a feature map
matrix C E Rn×(|s|−m+1).
In practice, we also need to add a bias vector b E
Rn to the result of a convolution – a single bi value
for each feature map ci. This allows the network to
learn an appropriate threshold.
</bodyText>
<page confidence="0.999489">
465
</page>
<figureCaption confidence="0.999825">
Figure 1: The architecture of our deep learning model for sentiment classification.
</figureCaption>
<subsectionHeader confidence="0.999756">
2.3 Activation units
</subsectionHeader>
<bodyText confidence="0.999994">
To allow the network learn non-linear decision
boundaries, each convolutional layer is typically
followed by a non-linear activation function α()
applied element-wise. Among the most common
choices of activation functions are: sigmoid (or lo-
gistic), hyperbolic tangent tanh, and a rectified lin-
ear (ReLU) function defined as simply max(0, x) to
ensure that feature maps are always positive.
We use ReLU in our model since, as shown
in (Nair and Hinton, 2010), it speeds up the train-
ing and sometimes produces more accurate results.
</bodyText>
<subsectionHeader confidence="0.998238">
2.4 Pooling
</subsectionHeader>
<bodyText confidence="0.99998976">
The output from the convolutional layer (passed
through the activation function) are then passed to
the pooling layer, whose goal is to aggregate the in-
formation and reduce the representation. The result
of the pooling operation is:
where cz is the ith convolutional feature map with
added bias (the bias is added to each element of cz
and e is a unit vector of the same size as cz) and
passed through the activation function α().
Among the most popular choices for pooling op-
eration are: max and average pooling. Recently,
max pooling has been generalized to k-max pool-
ing (Kalchbrenner et al., 2014), where instead of a
single max value, k values are extracted in their orig-
inal order. We use max pooling in our model which
simply returns the maximum value. It operates on
columns of the feature map matrix C returning the
largest value: pool(cz) : R1×(|s|+m−1) ! R (also
shown schematically in Fig. 1).
Convolutional layer passed through the activation
function together with pooling layer acts as a non-
linear feature extractor. Given that multiple feature
maps are used in parallel to process the input, deep
learning networks are able to build rich feature rep-
resentations of the input.
</bodyText>
<subsectionHeader confidence="0.963925">
2.5 Softmax
</subsectionHeader>
<bodyText confidence="0.999683">
The output of the penultimate convolutional and
pooling layers x is passed to a fully connected soft-
max layer. It computes the probability distribution
over the labels:
</bodyText>
<equation confidence="0.968354">
P(y = jjx, s, b) = softmaxj(xTw + b)
+bj
= K k=1 exT wk+bk ,
exT wj
</equation>
<bodyText confidence="0.998097">
where wk and bk are the weight vector and bias of
the k-th class.
</bodyText>
<equation confidence="0.982574833333333">
⎡ ⎤
pool(α(c1 + b1 * e))
⎣ . . . ⎦
pool(α(cn
cpooled =
+ bn * e))
</equation>
<page confidence="0.99766">
466
</page>
<subsectionHeader confidence="0.96832">
2.6 Phrase-level sentiment analysis
</subsectionHeader>
<bodyText confidence="0.999924894736842">
To perform phrase-level sentiment analysis, we feed
the network with an additional input sequence indi-
cating the location of the target phrase in a tweet.
The elements are encoded using only two word
types: tokens spanning the phrase to be predicted
are encoded with 1s and all the other with 0s. Each
word type is associated with its own embedding. So,
when tackling the phrase-level sentiment classifica-
tion, we form a sentence matrix S as follows: for
each token in a tweet we have to look up its corre-
sponding word embedding in the word matrix W,
and the embedding for one of the two word types.
Hence, the input sentence matrix is augmented with
an additional set of rows from the word type em-
beddings. Other than that, the architecture of our
network remains unchanged.
This ends the description of our convolutional
neural network for sentiment classification of
tweets.
</bodyText>
<sectionHeader confidence="0.898907" genericHeader="method">
3 Our approach to train the network
</sectionHeader>
<bodyText confidence="0.9999005">
Convolutional neural networks can be tricky to train
often severely overfitting on small datasets. In the
following we describe our approach to train our deep
learning model.
</bodyText>
<subsectionHeader confidence="0.99729">
3.1 Network Parameters and Training
</subsectionHeader>
<bodyText confidence="0.999206714285714">
We use stochastic gradient descent (SGD) to
train the network and use backpropogation algo-
rithm to compute the gradients. We opt for the
Adadelta (Zeiler, 2012) update rule to automatically
tune the learning rate.
The following parameters are optimized by our
network:
</bodyText>
<equation confidence="0.816973">
0 = {W; F; b; ws; bs},
</equation>
<bodyText confidence="0.999036666666667">
namely the word embeddings matrix W, filter
weights and biases of the convolutional layer, the
weight and bias of the softmax layers.
</bodyText>
<subsectionHeader confidence="0.994355">
3.2 Regularization
</subsectionHeader>
<bodyText confidence="0.999881533333333">
While neural networks have a large capacity to learn
complex decision functions they tend to easily over-
fit especially on small and medium sized datasets.
To mitigate the overfitting issue we augment the cost
function with l2-norm regularization terms for the
parameters of the network.
We also adopt another popular and effective tech-
nique to improve regularization of the NNs —
dropout (Srivastava et al., 2014). Dropout prevents
feature co-adaptation by setting to zero (dropping
out) a portion of hidden units during the forward
phase when computing the activations at the soft-
max output layer. As suggested in (Goodfellow et
al., 2013) dropout acts as an approximate model av-
eraging.
</bodyText>
<subsectionHeader confidence="0.996681">
3.3 Initializing the model parameters
</subsectionHeader>
<bodyText confidence="0.961935666666667">
Convolutional neural networks live in the world of
non-convex function optimization leading to locally
optimal solutions. Hence, starting the optimization
from a good point can be crucial to train an accurate
model. We propose the following 3-step process to
initialize the parameter weights of the network:
1. Given that the largest parameter of the network
is the word matrix W, it is crucial to feed
the network with the high quality embeddings.
We use a popular word2vec neural language
model (Mikolov et al., 2013) to learn the word
embeddings on an unsupervised tweet corpus.
For this purpose, we collect 50M tweets over the
two-month period. We perform minimal prepro-
cessing tokenizing the tweets, normalizing the
URLs and author ids. To train the embeddings
we use a skipgram model with window size 5 and
filtering words with frequency less than 5.
2. When dealing with small amounts of labelled
data, starting from pre-trained word embeddings
is a large step towards successfully training an
accurate deep learning system. However, while
the word embeddings obtained at the previous
step should already capture important syntactic
and semantic aspects of the words they repre-
sent, they are completely clueless about their sen-
timent behaviour. Hence, we use a distant su-
pervision approach (Go et al., 2009) using our
convolutional neural network to further refine the
embeddings.
</bodyText>
<listItem confidence="0.90528">
3. Finally, we take the the parameters 0 of the net-
work obtained at the previous step and use it to
</listItem>
<page confidence="0.999645">
467
</page>
<tableCaption confidence="0.999437">
Table 1: Semeval-2015 data.
</tableCaption>
<table confidence="0.9982092">
Dataset Subtask A Subtask B
Twitter’13-train 5,895 9,728
Twitter’13-dev 648 1,654
Twitter’13-test 2,734 3,813
LiveJournal’14 660 1,142
SMS’13 1,071 2,093
Twitter’14 1,807 1,853
Sarcasm’14 82 86
Twitter’15 3,092 2,390
# Teams 11 40
</table>
<bodyText confidence="0.817824">
initialize the network which is trained on a super-
vised training corpus from Semeval-2015.
</bodyText>
<sectionHeader confidence="0.983818" genericHeader="evaluation">
4 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.998450633333333">
Data and setup. We test our model on two subtasks
from Semeval-2015 Task 10: phrase-level (subtask
A) and message-level (subtask B). The datasets use
in Semeval-2015 are summarized in Table 1. We
use train and dev from Twitter’13 for training and
Twitter’13-test as a validation set. The other datasets
are used for testing, whereas Twitter’15 is used to
establish the official ranking of the systems.
Additionally, to pre-train the weights of our net-
work, we use a large unsupervised corpus containing
50M tweets for training the word embeddings and a
10M tweet corpus for distant supervision. The lat-
ter corpus was built similarly to (Go et al., 2009),
where tweets with positive emoticons, like ’:)’, are
assumed to be positive, and tweets with negative
emoticons, like ’:(’, are labeled as negative. The
dataset contains equal number of positive and nega-
tive tweets.
The parameters of our model were (chosen on the
validation set) as follows: the width m of the convo-
lution filters is set to 5 and the number of convolu-
tional feature maps is 300. We use ReLU activation
function and a simple max-pooling. The L2 regular-
ization term is set to 1e − 4, dropout is applied to
the penultimate level with p = 0.5. The dimension-
ality of the word embeddings d is set to 100. For the
phrase-level subtask the size of the word type em-
beddings, which encode tokens that span the target
phrase or not, is set to 10.
Pre-training the network. To train our deep learn-
</bodyText>
<tableCaption confidence="0.9501952">
Table 2: Testing the model on the progress test sets
from Semeval-2015 with different parameter initializion
schemes: Random (random word embeddings); Unsup
(word2vec embeddings); Distant (all parameters from
a network trained on a distant supervised dataset).
</tableCaption>
<table confidence="0.998071166666667">
Dataset Random Unsup Distant
LiveJournal’14 63.58 73.09 72.48
SMS’13 58.41 65.21 68.37
Twitter’13 64.51 72.35 72.79
Twitter’14 63.69 71.07 73.60
Sarcasm’14 46.10 52.56 55.44
</table>
<bodyText confidence="0.999909257142857">
ing model we follow our 3-step process as described
in Sec. 3.3. We report the results for training the
network on the official supervised dataset from Se-
meval’15 using parameters that were initialized: (i)
completely at random (Random); (ii) using word
embeddings from the neural language model trained
on a large unsupervised dataset (Unsup) with the
word2vec tool and (iii) initializing all the parame-
ters of our model with the parameters of the network
which uses the word embeddings from the previous
step and are further tuned on a distant supervised
dataset (Distant).
Table 2 summarizes the performance of our model
on five test sets using three parameter initialization
schemas. First, we observe that training the network
with all parameters initialized completely at random
results in a rather mediocre performance. This is due
to a small size of the training set. Secondly, using
embeddings pre-trained by a neural language model
considerably boosts the performance. Finally, using
a large distant supervised corpus to further tune the
word embeddings to also capture the sentiment as-
pect of the words they represent results in a further
improvement across all test sets (except for a small
drop on LiveJournal’14).
Official rankings. The results from the official
rankings for both subtasks A and B are summarized
in Table 3. As we can see our system performs par-
ticularly well on subtask A ranking 1st on the official
Twitter’15 set, while also showing excellent perfor-
mance on all other test sets.
On subtask B our system ranks 2nd also show-
ing high rankings on the other test sets (apart from
the LiveJournal’14). In fact, no single system at
Semeval-2015 performed equally well across all test
</bodyText>
<page confidence="0.999621">
468
</page>
<tableCaption confidence="0.9493555">
Table 3: Results on Semeval-2015 for phrase and tweet-
level subtasks. Rank shows the absolute position of our
</tableCaption>
<table confidence="0.996830421052632">
system on each test set. AveRank is the averaged rank
across all test sets.
Dataset Score Rank
Phrase-level subtask A
LJournal’14 84.46 2
SMS’13 88.60 2
Twitter’13 90.10 1
Twitter’14 87.12 1
Sarcasm’14 73.65 5
Twitter’15 84.79 1
AveRank 2.0 1
Message-level subtask B
LJournal’14 72.48 12
SMS’13 68.37 2
Twitter’13 72.79 3
Twitter’14 73.60 2
Sarcasm’14 55.44 5
Twitter’15 64.59 2
AveRank 4.3 1
</table>
<bodyText confidence="0.9998053">
sets. For example, a system that ranked 1st on the
official Twitter’15 dataset performs much worse on
the progress test sets ranking {14,14,11, 7,12} on
{LiveJournal’14, SMS’13, Twitter’13,
Twitter’14, and Sarcasm’14} correspond-
ingly. It has an AveRank of 9.8, which is only 6th
best result if systems were ranked according to this
metric. In contrast, our system shows robust re-
sults across all tests having the best AveRank of 4.3
among all 40 systems.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999566">
We described our deep learning approach to Twit-
ter sentiment analysis on both message and phrase
levels. We gave a detailed description of our 3-
step process to train the parameters of the network
that is the key to our success. The resulting model
demonstrates state-of-the-art performance on both
the phrase-level and message-level subtasks. Con-
sidering the average rank across all test sets (includ-
ing progress test sets) our system is 1st on both sub-
tasks.
</bodyText>
<sectionHeader confidence="0.996443" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999891788461538">
Alex Go, Richa Bhayani, and Lei Huang. 2009. Twitter
sentiment classification using distant supervision. In
CS224N Project Report, Stanford.
Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza,
Aaron C. Courville, and Yoshua Bengio. 2013. Max-
out networks. In ICML, pages 1319–1327.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for mod-
elling sentences. Proceedings of the 52nd Annual
Meeting of the Association for Computational Linguis-
tics.
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In EMNLP, pages 1746–1751,
Doha, Qatar.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representations
of words and phrases and their compositionality. In
Advances in Neural Information Processing Systems
26, pages 3111–3119.
Saif M. Mohammad, Svetlana Kiritchenko, and Xiaodan
Zhu. 2013. Nrc-canada: Building the state-of-the-art
in sentiment analysis of tweets. In 7th International
Workshop on Semantic Evaluation (Semeval’13).
Vinod Nair and Geoffrey E. Hinton. 2010. Rectified lin-
ear units improve restricted boltzmann machines. In
ICML, pages 807–814.
Jason Weston Ronan Collobert. 2008. A unified archi-
tecture for natural language processing: deep neural
networks with multitask learning. In ICML.
Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko,
Saif M Mohammad, Alan Ritter, and Veselin Stoy-
anov. 2015. Semeval-2015 task 10: Sentiment analy-
sis in twitter. In Proceedings of the 9th International
Workshop on Semantic Evaluation, SemEval ’2015,
Denver, Colorado.
Aliaksei Severyn and Alessandro Moschitti. 2015. On
the automatic learning of sentiment lexicons. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Linguis-
tics (NAACL HLT 2015).
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15:1929–1958.
Saif M. Mohammad Xiaodan Zhu, Svetlana Kiritchenko.
2014. Nrc-canada-2014: Recent improvements in sen-
timent analysis of tweets, and the Voted Perceptron.
In Eighth International Workshop on Semantic Evalu-
ation Exercises (SemEval-2014).
Matthew D. Zeiler. 2012. Adadelta: An adaptive learn-
ing rate method. CoRR.
</reference>
<page confidence="0.999625">
469
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.566967">
<title confidence="0.999514">UNITN: Training Deep Convolutional Neural Network for Sentiment Classification</title>
<author confidence="0.99978">Aliaksei Severyn Alessandro Moschitti</author>
<affiliation confidence="0.999913">DISI, University of Trento Qatar Computing Research Institue</affiliation>
<address confidence="0.999201">38123 Povo (TN), Italy 5825 Doha, Qatar</address>
<email confidence="0.91365">severyn@disi.unitn.itamoschitti@qf.org.qa</email>
<abstract confidence="0.982207">This paper describes our deep learning system for sentiment analysis of tweets. The main contribution of this work is a process to initialize the parameter weights of the convolutional neural network, which is crucial to train an accurate model while avoiding the need to inject any additional features. Briefly, we use an unsupervised neural language model to initialize word embeddings that are further tuned by our deep learning model on a distant supervised corpus. At a final stage, the pre-trained parameters of the network are used to initialize the model which is then trained on the supervised training data from Semeval-2015. According to results on the official test sets, our model ranks 1st in the phrase-level subtask A (among 11 teams) and 2nd on the messagelevel subtask B (among 40 teams). Interestingly, computing an average rank over all six test sets (official and five progress test sets) puts our system 1st in both subtasks A and B.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alex Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>In CS224N Project Report,</booktitle>
<location>Stanford.</location>
<contexts>
<context position="2618" citStr="Go et al., 2009" startWordPosition="407" endWordPosition="410">elatively small, e.g., thousands of examples. Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model. We propose a three-step process we follow to train our deep learning model for sentiment classification. It can be summarized as follows: (i) word embeddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which is trained on a large unsupervised collection of tweets; (ii) we use our convolutional neural network to further refine the embeddings on a large distant supervised corpus (Go et al., 2009); (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network that is then trained on a supervised corpus from Semeval-2015. We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge (Rosenthal et al., 2015): phraselevel (subtask A) and message-level (subtask B). Our system ranks 1st on the official test set of the phrase-level and 2nd on the message-level subtask. In addition to the test set used to establish the final ranking in Semeval-2015, all systems were also evaluat</context>
<context position="13415" citStr="Go et al., 2009" startWordPosition="2236" endWordPosition="2239">weets, normalizing the URLs and author ids. To train the embeddings we use a skipgram model with window size 5 and filtering words with frequency less than 5. 2. When dealing with small amounts of labelled data, starting from pre-trained word embeddings is a large step towards successfully training an accurate deep learning system. However, while the word embeddings obtained at the previous step should already capture important syntactic and semantic aspects of the words they represent, they are completely clueless about their sentiment behaviour. Hence, we use a distant supervision approach (Go et al., 2009) using our convolutional neural network to further refine the embeddings. 3. Finally, we take the the parameters 0 of the network obtained at the previous step and use it to 467 Table 1: Semeval-2015 data. Dataset Subtask A Subtask B Twitter’13-train 5,895 9,728 Twitter’13-dev 648 1,654 Twitter’13-test 2,734 3,813 LiveJournal’14 660 1,142 SMS’13 1,071 2,093 Twitter’14 1,807 1,853 Sarcasm’14 82 86 Twitter’15 3,092 2,390 # Teams 11 40 initialize the network which is trained on a supervised training corpus from Semeval-2015. 4 Experiments and evaluation Data and setup. We test our model on two su</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alex Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. In CS224N Project Report, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian J Goodfellow</author>
<author>David Warde-Farley</author>
<author>Mehdi Mirza</author>
<author>Aaron C Courville</author>
<author>Yoshua Bengio</author>
</authors>
<title>Maxout networks.</title>
<date>2013</date>
<booktitle>In ICML,</booktitle>
<pages>1319--1327</pages>
<contexts>
<context position="12014" citStr="Goodfellow et al., 2013" startWordPosition="2012" endWordPosition="2015">works have a large capacity to learn complex decision functions they tend to easily overfit especially on small and medium sized datasets. To mitigate the overfitting issue we augment the cost function with l2-norm regularization terms for the parameters of the network. We also adopt another popular and effective technique to improve regularization of the NNs — dropout (Srivastava et al., 2014). Dropout prevents feature co-adaptation by setting to zero (dropping out) a portion of hidden units during the forward phase when computing the activations at the softmax output layer. As suggested in (Goodfellow et al., 2013) dropout acts as an approximate model averaging. 3.3 Initializing the model parameters Convolutional neural networks live in the world of non-convex function optimization leading to locally optimal solutions. Hence, starting the optimization from a good point can be crucial to train an accurate model. We propose the following 3-step process to initialize the parameter weights of the network: 1. Given that the largest parameter of the network is the word matrix W, it is crucial to feed the network with the high quality embeddings. We use a popular word2vec neural language model (Mikolov et al.,</context>
</contexts>
<marker>Goodfellow, Warde-Farley, Mirza, Courville, Bengio, 2013</marker>
<rawString>Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron C. Courville, and Yoshua Bengio. 2013. Maxout networks. In ICML, pages 1319–1327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural network for modelling sentences.</title>
<date>2014</date>
<booktitle>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1447" citStr="Kalchbrenner et al., 2014" startWordPosition="227" endWordPosition="230">itialize the model which is then trained on the supervised training data from Semeval-2015. According to results on the official test sets, our model ranks 1st in the phrase-level subtask A (among 11 teams) and 2nd on the messagelevel subtask B (among 40 teams). Interestingly, computing an average rank over all six test sets (official and five progress test sets) puts our system 1st in both subtasks A and B. 1 Introduction In this work we describe our deep convolutional neural network for sentiment analysis of tweets. Its architecture is most similar to the deep learning systems presented in (Kalchbrenner et al., 2014; Kim, 2014) that have recently established new stateof-the-art results on various NLP sentence classification tasks also including sentiment analysis. While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and automatically constructed lexicons, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples.</context>
<context position="4223" citStr="Kalchbrenner et al., 2014" startWordPosition="674" endWordPosition="677">uation (SemEval 2015), pages 464–469, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics according to the average rank in both subtasks A and sentence (see Fig. 1): J J J ⎤ B. ⎡ w1 ... w|s |⎦ In the following, we describe the architecture of S = ⎣ J J J our convolutional neural network and the parameter initialization process process we follow to train it. 2 Our Deep Learning model for sentiment classification The architecture of our convolutional neural network for sentiment classification is shown on Fig. 1. It is mainly inspired by the architectures used in (Kalchbrenner et al., 2014; Kim, 2014) for performing various sentence classification tasks. Given that our training process (described in Sec. 3.3) requires to run the network on a rather large corpus, our design choices are mainly driven by the computational efficiency of our network. Hence, different from (Kalchbrenner et al., 2014) that presents an architecture with several layers of convolutional feature maps, we adopt a single level architecture, which has been shown in (Kim, 2014) to perform equally well. Our network is composed of a single convolutional layer followed by a non-linearity, max pooling and a soft-</context>
<context position="8792" citStr="Kalchbrenner et al., 2014" startWordPosition="1464" endWordPosition="1467">ate results. 2.4 Pooling The output from the convolutional layer (passed through the activation function) are then passed to the pooling layer, whose goal is to aggregate the information and reduce the representation. The result of the pooling operation is: where cz is the ith convolutional feature map with added bias (the bias is added to each element of cz and e is a unit vector of the same size as cz) and passed through the activation function α(). Among the most popular choices for pooling operation are: max and average pooling. Recently, max pooling has been generalized to k-max pooling (Kalchbrenner et al., 2014), where instead of a single max value, k values are extracted in their original order. We use max pooling in our model which simply returns the maximum value. It operates on columns of the feature map matrix C returning the largest value: pool(cz) : R1×(|s|+m−1) ! R (also shown schematically in Fig. 1). Convolutional layer passed through the activation function together with pooling layer acts as a nonlinear feature extractor. Given that multiple feature maps are used in parallel to process the input, deep learning networks are able to build rich feature representations of the input. 2.5 Softm</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification.</title>
<date>2014</date>
<booktitle>In EMNLP,</booktitle>
<pages>1746--1751</pages>
<location>Doha, Qatar.</location>
<contexts>
<context position="1459" citStr="Kim, 2014" startWordPosition="231" endWordPosition="232"> then trained on the supervised training data from Semeval-2015. According to results on the official test sets, our model ranks 1st in the phrase-level subtask A (among 11 teams) and 2nd on the messagelevel subtask B (among 40 teams). Interestingly, computing an average rank over all six test sets (official and five progress test sets) puts our system 1st in both subtasks A and B. 1 Introduction In this work we describe our deep convolutional neural network for sentiment analysis of tweets. Its architecture is most similar to the deep learning systems presented in (Kalchbrenner et al., 2014; Kim, 2014) that have recently established new stateof-the-art results on various NLP sentence classification tasks also including sentiment analysis. While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and automatically constructed lexicons, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples. Turns out, </context>
<context position="4235" citStr="Kim, 2014" startWordPosition="678" endWordPosition="679">s 464–469, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics according to the average rank in both subtasks A and sentence (see Fig. 1): J J J ⎤ B. ⎡ w1 ... w|s |⎦ In the following, we describe the architecture of S = ⎣ J J J our convolutional neural network and the parameter initialization process process we follow to train it. 2 Our Deep Learning model for sentiment classification The architecture of our convolutional neural network for sentiment classification is shown on Fig. 1. It is mainly inspired by the architectures used in (Kalchbrenner et al., 2014; Kim, 2014) for performing various sentence classification tasks. Given that our training process (described in Sec. 3.3) requires to run the network on a rather large corpus, our design choices are mainly driven by the computational efficiency of our network. Hence, different from (Kalchbrenner et al., 2014) that presents an architecture with several layers of convolutional feature maps, we adopt a single level architecture, which has been shown in (Kim, 2014) to perform equally well. Our network is composed of a single convolutional layer followed by a non-linearity, max pooling and a soft-max classifi</context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In EMNLP, pages 1746–1751, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems 26,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="2422" citStr="Mikolov et al., 2013" startWordPosition="372" endWordPosition="375">, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples. Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model. We propose a three-step process we follow to train our deep learning model for sentiment classification. It can be summarized as follows: (i) word embeddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which is trained on a large unsupervised collection of tweets; (ii) we use our convolutional neural network to further refine the embeddings on a large distant supervised corpus (Go et al., 2009); (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network that is then trained on a supervised corpus from Semeval-2015. We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge (Rosenthal et al., 2015): phraselevel (subtask A) and message-level (subtask B). Our system ranks 1</context>
<context position="12620" citStr="Mikolov et al., 2013" startWordPosition="2109" endWordPosition="2112">w et al., 2013) dropout acts as an approximate model averaging. 3.3 Initializing the model parameters Convolutional neural networks live in the world of non-convex function optimization leading to locally optimal solutions. Hence, starting the optimization from a good point can be crucial to train an accurate model. We propose the following 3-step process to initialize the parameter weights of the network: 1. Given that the largest parameter of the network is the word matrix W, it is crucial to feed the network with the high quality embeddings. We use a popular word2vec neural language model (Mikolov et al., 2013) to learn the word embeddings on an unsupervised tweet corpus. For this purpose, we collect 50M tweets over the two-month period. We perform minimal preprocessing tokenizing the tweets, normalizing the URLs and author ids. To train the embeddings we use a skipgram model with window size 5 and filtering words with frequency less than 5. 2. When dealing with small amounts of labelled data, starting from pre-trained word embeddings is a large step towards successfully training an accurate deep learning system. However, while the word embeddings obtained at the previous step should already capture</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>In 7th International Workshop on Semantic Evaluation (Semeval’13).</booktitle>
<contexts>
<context position="1830" citStr="Mohammad et al., 2013" startWordPosition="280" endWordPosition="283">n both subtasks A and B. 1 Introduction In this work we describe our deep convolutional neural network for sentiment analysis of tweets. Its architecture is most similar to the deep learning systems presented in (Kalchbrenner et al., 2014; Kim, 2014) that have recently established new stateof-the-art results on various NLP sentence classification tasks also including sentiment analysis. While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and automatically constructed lexicons, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples. Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model. We propose a three-step process we follow to train our deep learning model for sentiment classification. It can be summarized as follows: (i) word embeddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which i</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M. Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets. In 7th International Workshop on Semantic Evaluation (Semeval’13).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinod Nair</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>Rectified linear units improve restricted boltzmann machines.</title>
<date>2010</date>
<booktitle>In ICML,</booktitle>
<pages>807--814</pages>
<contexts>
<context position="8105" citStr="Nair and Hinton, 2010" startWordPosition="1346" endWordPosition="1349"> allows the network to learn an appropriate threshold. 465 Figure 1: The architecture of our deep learning model for sentiment classification. 2.3 Activation units To allow the network learn non-linear decision boundaries, each convolutional layer is typically followed by a non-linear activation function α() applied element-wise. Among the most common choices of activation functions are: sigmoid (or logistic), hyperbolic tangent tanh, and a rectified linear (ReLU) function defined as simply max(0, x) to ensure that feature maps are always positive. We use ReLU in our model since, as shown in (Nair and Hinton, 2010), it speeds up the training and sometimes produces more accurate results. 2.4 Pooling The output from the convolutional layer (passed through the activation function) are then passed to the pooling layer, whose goal is to aggregate the information and reduce the representation. The result of the pooling operation is: where cz is the ith convolutional feature map with added bias (the bias is added to each element of cz and e is a unit vector of the same size as cz) and passed through the activation function α(). Among the most popular choices for pooling operation are: max and average pooling. </context>
</contexts>
<marker>Nair, Hinton, 2010</marker>
<rawString>Vinod Nair and Geoffrey E. Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In ICML, pages 807–814.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston Ronan Collobert</author>
</authors>
<title>A unified architecture for natural language processing: deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="2399" citStr="Collobert, 2008" startWordPosition="370" endWordPosition="371">structed lexicons, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples. Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model. We propose a three-step process we follow to train our deep learning model for sentiment classification. It can be summarized as follows: (i) word embeddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which is trained on a large unsupervised collection of tweets; (ii) we use our convolutional neural network to further refine the embeddings on a large distant supervised corpus (Go et al., 2009); (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network that is then trained on a supervised corpus from Semeval-2015. We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge (Rosenthal et al., 2015): phraselevel (subtask A) and message-level (subtask</context>
</contexts>
<marker>Collobert, 2008</marker>
<rawString>Jason Weston Ronan Collobert. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Svetlana Kiritchenko</author>
<author>Saif M Mohammad</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<title>Semeval-2015 task 10: Sentiment analysis in twitter.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="2947" citStr="Rosenthal et al., 2015" startWordPosition="460" endWordPosition="463">ddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which is trained on a large unsupervised collection of tweets; (ii) we use our convolutional neural network to further refine the embeddings on a large distant supervised corpus (Go et al., 2009); (iii) the word embeddings and other parameters of the network obtained at the previous stage are used to initialize the network that is then trained on a supervised corpus from Semeval-2015. We apply our deep learning model on two subtasks of Semeval-2015 Twitter Sentiment Analysis (Task 10) challenge (Rosenthal et al., 2015): phraselevel (subtask A) and message-level (subtask B). Our system ranks 1st on the official test set of the phrase-level and 2nd on the message-level subtask. In addition to the test set used to establish the final ranking in Semeval-2015, all systems were also evaluated on the progress test set which consists of five test sets, where our system also shows strong results. In particular, we rank all systems according to their performance on each test set and compute their average ranks. Interestingly, our model appears to be the most robust across all six test sets ranking 1st 464 Proceedings</context>
</contexts>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2015</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko, Saif M Mohammad, Alan Ritter, and Veselin Stoyanov. 2015. Semeval-2015 task 10: Sentiment analysis in twitter. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>On the automatic learning of sentiment lexicons.</title>
<date>2015</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<contexts>
<context position="1879" citStr="Severyn and Moschitti, 2015" startWordPosition="287" endWordPosition="290"> this work we describe our deep convolutional neural network for sentiment analysis of tweets. Its architecture is most similar to the deep learning systems presented in (Kalchbrenner et al., 2014; Kim, 2014) that have recently established new stateof-the-art results on various NLP sentence classification tasks also including sentiment analysis. While already demonstrating excellent results, training a convolutional neural network that would beat hand-engineered approaches that also rely on multiple manual and automatically constructed lexicons, e.g. (Mohammad et al., 2013; Xiaodan Zhu, 2014; Severyn and Moschitti, 2015), requires careful attention. This becomes an even harder problem especially in cases when the amount of labelled data is relatively small, e.g., thousands of examples. Turns out, providing the network with good initialisation parameters makes all the difference in training an accurate model. We propose a three-step process we follow to train our deep learning model for sentiment classification. It can be summarized as follows: (i) word embeddings are initialized using a neural language model (Ronan Collobert, 2008; Mikolov et al., 2013) which is trained on a large unsupervised collection of t</context>
</contexts>
<marker>Severyn, Moschitti, 2015</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2015. On the automatic learning of sentiment lexicons. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2015).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitish Srivastava</author>
<author>Geoffrey Hinton</author>
</authors>
<title>Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.</title>
<date>2014</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>15--1929</pages>
<marker>Srivastava, Hinton, 2014</marker>
<rawString>Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15:1929–1958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad Xiaodan Zhu</author>
<author>Svetlana Kiritchenko</author>
</authors>
<title>Nrc-canada-2014: Recent improvements in sentiment analysis of tweets, and the Voted Perceptron.</title>
<date>2014</date>
<booktitle>In Eighth International Workshop on Semantic Evaluation Exercises (SemEval-2014).</booktitle>
<marker>Zhu, Kiritchenko, 2014</marker>
<rawString>Saif M. Mohammad Xiaodan Zhu, Svetlana Kiritchenko. 2014. Nrc-canada-2014: Recent improvements in sentiment analysis of tweets, and the Voted Perceptron. In Eighth International Workshop on Semantic Evaluation Exercises (SemEval-2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Zeiler</author>
</authors>
<title>Adadelta: An adaptive learning rate method.</title>
<date>2012</date>
<publisher>CoRR.</publisher>
<contexts>
<context position="11089" citStr="Zeiler, 2012" startWordPosition="1865" endWordPosition="1866">rows from the word type embeddings. Other than that, the architecture of our network remains unchanged. This ends the description of our convolutional neural network for sentiment classification of tweets. 3 Our approach to train the network Convolutional neural networks can be tricky to train often severely overfitting on small datasets. In the following we describe our approach to train our deep learning model. 3.1 Network Parameters and Training We use stochastic gradient descent (SGD) to train the network and use backpropogation algorithm to compute the gradients. We opt for the Adadelta (Zeiler, 2012) update rule to automatically tune the learning rate. The following parameters are optimized by our network: 0 = {W; F; b; ws; bs}, namely the word embeddings matrix W, filter weights and biases of the convolutional layer, the weight and bias of the softmax layers. 3.2 Regularization While neural networks have a large capacity to learn complex decision functions they tend to easily overfit especially on small and medium sized datasets. To mitigate the overfitting issue we augment the cost function with l2-norm regularization terms for the parameters of the network. We also adopt another popula</context>
</contexts>
<marker>Zeiler, 2012</marker>
<rawString>Matthew D. Zeiler. 2012. Adadelta: An adaptive learning rate method. CoRR.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>