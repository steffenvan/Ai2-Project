<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.983885">
Intrinsic Property-based Taxonomic Relation Extraction from Category
Structure
</title>
<author confidence="0.960404">
DongHyun Choi and Eun-Kyung Kim and Sang-Ah Shim and Key-Sun Choi
</author>
<affiliation confidence="0.957021">
Semantic Web Research Center
</affiliation>
<email confidence="0.584882">
KAIST
cdh4696, kekeeo, sashim, kschoi@world.kaist.ac.kr
</email>
<sectionHeader confidence="0.997037" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968714285714">
We propose a novel algorithm to ex-
tract taxonomic (or isa/instanceOf) rela-
tions from category structure by classi-
fying each category link. Previous algo-
rithms mainly focus on lexical patterns of
category names to classify whether or not
a given category link is an isa/instanceOf.
In contrast, our algorithm extracts intrin-
sic properties that represent the definition
of given category name, and uses those
properties to classify each category link.
Experimental result shows about 5 to 18 %
increase in F-Measure, compared to other
existing systems.
</bodyText>
<sectionHeader confidence="0.999853" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.998096">
1.1 Problem Description
</subsectionHeader>
<bodyText confidence="0.999784764705883">
Taxonomies are a crucial component of many ap-
plications, including document clustering (Hotho
et al., 2003) and database search (Byron et al.,
1997). Due to their importance, many studies
have examined methods of extracting taxonomic
relations automatically - either from unstructured
text (Cimiano et al., 2005; Cimiano(2) et al.,
2005), or from structured data such as Wikipedia
category structures (Ponzetto and Strube, 2007;
Nastase and Strube, 2008; Suchanek et al., 2007).
Many researchers have attempted to obtain tax-
onomic relations from unstructured text to con-
stuct a taxonomy, but in most cases such a system
shows poor precision and low recall. Approaches
to extracting taxonomic relations from structured
data show relatively high performance, but to ob-
tain a taxonomy these require huge amounts of
structured data. Recently, as large amounts of
structured data such as the infoboxes and category
structures of Wikipedia or DBpedia (Auer et al.,
2007) have become available, an obstacle to this
approach has been removed.
Although a category structure does contain
some kind of hierarchical structure, in many cases
it cannot be considered as an isa/instanceOf hier-
archy. For example, the article “Pioneer 111” on
Wikipedia is categorized under “Radio frequency
propagation”, which is related to the “Pioneer 11”
but is obviously not a taxonomical parent of “Pio-
neer 11”.
In this paper, we propose a method for extract-
ing taxonomic relations from a given category
structure. More precisely, for a category link in
the given category structure, the algorithm deter-
mines whether the link could be considered an
isa/instanceOf relation, or if the link simply rep-
resents a broader term/narrower term/related term
relation. For a given category link &lt;A, B&gt;, in
which A is the upper category name and B is the
lower category/article name, we attempt to get the
definition of B to classify the link. More precisely,
we analyze the upper categories of B from the
given category structure, to get tokens that rep-
resents the definition of B. Once we get the to-
kens, we compare the tokens with the name of A,
to classify the given category link. We call the
tokens that represent the definition of B “intrin-
sic tokens” of B; a more precise definition will be
presented in section 3.1.
To show the validity of this approach, the algo-
rithm is applied to Wikipedia’s category structure,
</bodyText>
<footnote confidence="0.877275333333333">
1Pioneer 11 was the probe for second mission of the Pio-
neer program (after its sister probe Pioneer 10) to investigate
Jupiter and the outer solar system.
</footnote>
<page confidence="0.982426">
48
</page>
<note confidence="0.841992">
Proceedings of the 6th Workshop on Ontologies and Lexical Resources (Ontolex 2010), pages 48–57,
Beijing, August 2010
</note>
<bodyText confidence="0.999921684210526">
to obtain taxonomic relations there. Wikipedia’s
category structure consists of categories, article
titles and links between them. A Wikipedia arti-
cle represents one document, and a category is the
grouping of those articles by non-categorization-
expert users. Each category has its own name,
which is assigned by these users.
Although Wikipedia’s category structure is
built by non-experts, it can be thought of as reli-
able since it is refined by many people, and it con-
tains 35,904,116 category links between 764,581
categories and 6,301,594 articles, making it a per-
fect target for an experimental taxonomic relation
extraction algorithm.
After describing related works in section 2, our
detailed algorithm is proposed in section 3, and its
experimental results are discussed in section 4. In
section 5, we make some conclusions and propos-
als for future work.
</bodyText>
<sectionHeader confidence="0.99985" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.998758214285714">
Methods of taxonomic relation extraction can be
divided into two broad categories depending on
the input: unstructured or structured data. The ex-
traction of taxonomic relations from unstructured
text is mainly carried out using lexical patterns on
the text. The Hearst pattern (Hearst, 1992) is used
in many pattern-based approaches, such as Cimi-
ano (2005).
In addition, there has been research that at-
tempted to use existing structured data, like the
Wikipedia category structure or the contents of a
thesaurus. The system of Ponzetto (2007) deter-
mines whether or not the given Wikipedia cate-
gory link is an isa/instanceOf relation by applying
a set of rules to the category names, while Nas-
tase (2008) defined lexical patterns on category
names, in addition to Ponzetto (2007). The YAGO
system (Suchanek et al., 2007) attempts to classify
whether the given article-category link represents
an instanceOf relation by checking the plurality
of the upper category name.
The algorithm proposed in this paper focuses
on the structured data, mainly the category struc-
ture, to gather isa/instanceOf relations. The
system gets a category structure as input, and
classifies each category link inside the category
structure according to whether it represents an
isa/instanceOf relation or not.
</bodyText>
<sectionHeader confidence="0.993803" genericHeader="method">
3 Algorithm Description
</sectionHeader>
<bodyText confidence="0.999980888888889">
In section 3.1, we introduce the necessary defini-
tions for isa/instanceOf relations and the required
terms to describe the algorithm. In section 3.2,
we will discuss the hypotheses based on the defi-
nitions described in section 3.1. Next, two binary
classification algorithms will be proposed based
on the hypotheses, which will determine whether
the given category link is an isa/instanceOf rela-
tion or not.
</bodyText>
<subsectionHeader confidence="0.991008">
3.1 Definitions
</subsectionHeader>
<bodyText confidence="0.844347625">
To define isa and instanceOf relations, Mi-
zoguchi (2004) introduces the concept of intrin-
sic property and other related concepts, which are
shown in the following definitions 1, 2 and 3:
Definition 1: Intrinsic property. The intrinsic
property of a thing is a property which is essen-
tial to the thing and it loses its identity when the
property changes.
</bodyText>
<listItem confidence="0.782117714285714">
Definition 2: The ontological definition of a
class. A thing which is a conceptualization of a set
X can be a class if and only if each element x of X
belongs to the class X if and only if the intrinsic
property of x satisfies the intensional condition of
X. And, then and only then, &lt;x instanceOf X&gt;
holds.
</listItem>
<bodyText confidence="0.872580583333333">
Definition 3: isa relation. isa relation holds
only between classes. &lt;class A isa class B&gt;
holds iff the instance set of A is a subset of the
instance set of B.
In addition, we define the following terms for
algorithm description:
Definition 4: intrinsic token. Token 2 T is an
intrinsic token of B iff T represents the intrinsic
property of B.
For example, when B is “Pioneer 11”, the in-
trinsic tokens of B are “spacecraft”, “escape3”,
“Jupiter”, etc.
</bodyText>
<footnote confidence="0.514677714285714">
2For example, token is a segmented term in category
names of Wikipedia category structure.
3Since the main purpose of Pioneer 11 is to escape from
the solar system and fly into the deep space, we thought “es-
cape” is the intrinsic token of “Pioneer 11”. In the same con-
text, “spacecraft escaping the solar system” is a taxonomical
parent of “Pioneer 11”.
</footnote>
<page confidence="0.999237">
49
</page>
<bodyText confidence="0.974665875">
Definition 5: category link. &lt;A, B&gt; is called
category link iff A is a category of B, and that fact
is explicitly stated in the given category structure.
Consider the example of Wikipedia. If B is
an article, &lt;A, B&gt; is called an article-category
link, and if B is a category, &lt;A, B&gt; is called a
category-category link. The article is a catego-
rized terminal object.
Definition 6: category structure. Category
structure is the collection of category links, its
component categories, and categorized terminal
objects.
Definition 7: upper category set. The upper
category set of B is defined as the set of upper
categories of B up to n step in the given category
structure, and it is expressed as U(B, n).
For example, if the two category links &lt;Jupiter
spacecraft, Pioneer 11&gt; and &lt;Jupiter, Jupiter
spacecraft&gt; exist inside the given category struc-
ture, then Jupiter spacecraft is the element of
U(Pioneer 11, 1), while Jupiter is not.
Figure 1 shows the category structure of
U(Pioneer 11, 3),which we refer to throughout
this paper to explain our algorithm.
</bodyText>
<subsectionHeader confidence="0.997123">
3.2 Hypotheses
</subsectionHeader>
<bodyText confidence="0.998890278688525">
According to the classical Aristotelian view, cat-
egories are discrete entities characterized by a set
of properties shared by their members. Thus, we
make the following lemmas:
Lemma 1: If some objects are grouped into the
same category, then they share at least more than
one property.
According to definition 2, if x is an instanceOf
X, then the intrinsic property of x satisfies the def-
inition of X. Since the intrinsic property is the
property related to the definition of the object, we
can assume that in most categorization systems,
the intrinsic property is the most frequently shared
property among those objects categorized in the
same category.
Lemma 2. Intrinsic properties are shared most
frequently among objects in a category.
Lemma 2 means that, for example, the intrin-
sic token T of B will show up frequently among
the names of upper categories of B. But lemma
2 does NOT mean that non-intrinsic tokens will
not frequently appear among the upper category
names. For example, the elements of U(Pioneer
11, 3) from the Wikipedia category structure con-
tain the token “spacecraft” 4 times, but it also
contain token “technology” 3 times. Therefore,
we cannot directly use the token frequency to de-
termine which one is the intrinsic token: rather,
we make another assumption to get the “intrinsic
score” for each token.
Lemma 3. Intrinsic tokens co-occur frequently
with other intrinsic tokens.
Lemma 3 means that, if T1 is an intrinsic to-
ken of B, and T2 co-occurs with T1 inside the
upper category names of B, then there is a high
probability that T2 is also an intrinsic token of B.
For example, for the category link &lt;Jupiter space-
craft, Pioneer 11&gt;, if the token “spacecraft” is an
intrinsic token of “Pioneer 11”, we can assume
that the token “Jupiter” is also an intrinsic token
of “Pioneer 11”. Since some intrinsic tokens that
are appropriate as modifiers are not appropriate as
head words – for example, if the token “Jupiter”
is used as a modifier, it will be a good intrinsic
token of “Pioneer 11”, but if it is used as a head
word, choosing it as the intrinsic token of “Pio-
neer 11” would be bad choice – thus, we distin-
guish between intrinsic score as head word, and
intrinsic score as modifier. If the intrinsic score
of token T is high for article/category name B,
then it means the probability is high that T is an
intrinsic token of B. We assumed that only the
co-occurrences as head word and its modifier are
meaningful. Corollary 3-1. If a modifier co-
occurs with a head word, and the head word is
frequently an intrinsic token of an object, then the
modifier is an intrinsic token of the object.
Corollary 3-2. If a head word co-occurs with a
modifier, and the modifier is frequently an intrin-
sic token of an object, then the head word is an
intrinsic token of the object.
</bodyText>
<subsectionHeader confidence="0.998727">
3.3 Proposed Algorithm
</subsectionHeader>
<bodyText confidence="0.999970714285714">
Based on the hypotheses proposed in section 3.2,
we propose two algorithms to get the intrinsic
score of each token in the following sections. The
first algorithm, a counting-based approach, uses
only lemmas 1 and 2, and it will be shown why
this algorithm will not work. The second algo-
rithm, a graph-based approach, uses all of the hy-
</bodyText>
<page confidence="0.994496">
50
</page>
<figureCaption confidence="0.999859">
Figure 1: category structure of U(Pioneer 11, 3) from Wikipedia.
</figureCaption>
<bodyText confidence="0.9979194375">
potheses to solve the problem.
For the given category link &lt;A, B&gt;, the intrin-
sic score of each token will be calculated based
on its frequency inside U(B, n) while separately
counting the token’s intrinsic score as modifiers
and the intrinsic score as head word. We here
propose a scoring mechanism based on the HITS
page ranking algorithm (Kleinberg, 1999): For the
given category link &lt;A, B&gt;, we first construct a
“modifier graph” using U(B, n), and then calcu-
late the intrinsic score for each token in U(B, n)
using the HITS algorithm. After that, the intrinsic
score of each token will be used to calculate the
score of &lt;A, B&gt;. If the score is higher than some
predefined threshold, then &lt;A, B&gt; is classified as
an isa/instanceOf link, and otherwise it is not.
</bodyText>
<subsectionHeader confidence="0.766675">
3.3.1 Counting-based Approach
</subsectionHeader>
<bodyText confidence="0.999295357142857">
This method utilizes lemmas 1 and 2 to get the
intrinsic score for each token, and then uses the
score to determine whether the given category link
is an isa/instanceOf link or not.
To utilize this approach, we first score each to-
ken from U(B, n) by counting the frequency of
each token from the words of U(B, n). Table 1
shows the score of each token from U(Pioneer, 3)
for figure 1.
For the “Pioneer 11” article, there are seven
category links in Wikipedia’s category struc-
ture: &lt;1973 in space exploration, Pioneer 11&gt;,
&lt;Inactive extraterrestrial probes, Pioneer 11&gt;,
&lt;Jupiter spacecraft, Pioneer 11&gt;, &lt;Pioneer pro-
</bodyText>
<table confidence="0.896781181818182">
Token Score
space 6
exploration 5
spacecraft, probe 4
1973, technology, year, radio, solar, 3
system, nasa
vehicle, radio, program, 1970s, 2
extraterrestrial, transport, Saturn,
Jupiter
escape, inactive, frequency, propa- 1
gation, pioneer, ...
</table>
<tableCaption confidence="0.913277">
Table 1: Score for each token from U(Pioneer 11,
3)
</tableCaption>
<bodyText confidence="0.997717125">
gram, Pioneer 11&gt;, &lt;Radio frequency propaga-
tion, Pioneer 11&gt;, &lt;Saturn spacecraft, Pioneer
11&gt;, and &lt;Spacecraft escaping the Solar System,
Pioneer 11&gt;, as shown in figure 1. The scores
of each link using a counting-based approach are
acquired by adding the scores for each token in ta-
ble 1 that is matched with single term occurrence
in category names. Table 2 shows the result of
counting-based approach.
Although the link &lt;1973 in space exploration,
Pioneer 11&gt; receives the highest score among
those seven links, obviously the link does not rep-
resent isa/instanceOf relation. This shows that
the counting approach does not guarantee accu-
racy. Table 1 shows that non-intrinsic tokens oc-
cur frequently (such as ‘technology’ in this exam-
</bodyText>
<page confidence="0.988345">
51
</page>
<table confidence="0.999719466666667">
Article-Category Links Score
&lt;1973 in space exploration, 3+6+5=14
Pioneer 11&gt;
&lt;Spacecraft escaping the So- 4+1+3+3=11
lar System, Pioneer 11&gt;
&lt;Inactive extraterrestrial 1+2+4=7
probes, Pioneer 11&gt;,
&lt;Saturn spacecraft, Pioneer 2+4=6
11&gt;
&lt;Jupiter spacecraft, Pioneer 2+4=6
11&gt;
&lt;Radio frequency propaga- 2+1+1=4
tion, Pioneer 11&gt;
&lt;Pioneer program, Pioneer 1+2=3
11&gt;
</table>
<tableCaption confidence="0.9170785">
Table 2: Scoring each category links using count-
ing approach
</tableCaption>
<bodyText confidence="0.999955833333333">
ple). We call this an ‘overloaded existence’ error.
To solve the problems described above, we apply
Lemma 3, Corollary 3-1 and 3-2 to our calcula-
tion, and propose a second algorithm based on a
graph-based approach, which will be explained in
the next section.
</bodyText>
<subsectionHeader confidence="0.533282">
3.3.2 Graph-based Approach
</subsectionHeader>
<bodyText confidence="0.992996">
In this section, we propose a graph-based ap-
proach to get the intrinsic score of each token. To
do this, we first construct a modifier graph from
the words of U(B, n) for a given category link &lt;A,
B&gt;, with each node representing a token from the
elements of U(B, n), and each edge representing
the co-occurrence of tokens inside each element
of U(B, n). Next, we apply a well-known graph
analysis algorithm to that graph, and get the in-
trinsic scores for each node. Finally, we use the
score of each node to get the score of the given
category link.
Constructing modifier graph Modifier graph
constructed here is defined as a directed graph,
in which each node represents each token inside
U(B, n), and each edge represents a co-occurrence
as modifier-head relation inside each category
name of U(B, n). Using the subset of U(Pioneer
11, 3), we get the modifier graph of figure 2.4
</bodyText>
<figureCaption confidence="0.95763525">
Figure 2: Modifier graph of the subset of
U(Pioneer 11, 3): {Spacecraft escaping the Solar
System, Jupiter spacecraft, 1973 in space explo-
ration, NASA probes, Saturn}
</figureCaption>
<bodyText confidence="0.985016833333333">
Calculating Intrinsic score After constructing
the modifier graph, we apply the HITS algorithm
to the modifier graph. Since the HITS algorithm
cannot reflect the weight of edges, a modified ver-
sion of the HITS algorithm (Mihalcea and Tarau,
2005) is adopted:
</bodyText>
<equation confidence="0.99915025">
Authority(Vi) = � eji · Hub(Vj) (1)
Vj∈In(Vi)
Hub(Vi) = � eij · Authority(Vj) (2)
Vj∈Out(Vi)
</equation>
<bodyText confidence="0.997847">
In(Vi) represents the set of vertices which has
the outgoing edge to Vi, Out(Vi) represents the
set of vertices which has the incoming edge from
Vi, and eij represents the weight of the edge from
Vi to Vj. The algorithm for calculating the scores
is as follows:
</bodyText>
<listItem confidence="0.990661666666667">
1. Initialize the authority and hub score of each
node to one.
2. Calculate hub score of each node using the
formula 2.
3. Calculate authority score of each node using
the formula 1.
4. Normalize authority &amp; hub score so that the
sum of authority score of every node and the sum
of hub score of every node are one.
</listItem>
<footnote confidence="0.7174795">
4We used the full set of U(B, n) to create the modifier
graph for the full scale of experimentation in section 4.
</footnote>
<page confidence="0.986319">
52
</page>
<listItem confidence="0.6418305">
5. Iterate from step 2 until the score of every
node converges.
</listItem>
<bodyText confidence="0.962308571428571">
In the modifier graph, Authority score can be
mapped to the intrinsic score of a node(token) as
a head word, and Hub score can be mapped to the
intrinsic score of a node(token) as a modifier.
Scoring Category Link Now, we can score the
input category link. The score of category link
&lt;A, B&gt; is given as follows:
</bodyText>
<figure confidence="0.7090035">
Score(&lt; A, B &gt;) Hub(a) (3)
�
= Authority(h) +
a in mod(A)
</figure>
<bodyText confidence="0.9849417">
Here, Score(&lt; A, B &gt;) represents the final
score of category link &lt;A, B&gt;, h represents the
head word of A, and mod(A) represents the set
of modifiers of A. Since the score of head word
and modifiers are calculated based on the upper
categories of B, this formula can integrate both
meaning of A and B to classify whether the link is
isa/instanceOf. Table 3 shows the scores of seven
article-category links from table 2, calculated us-
ing the graph-based approach.
</bodyText>
<table confidence="0.9987105">
Article-Category Links Score
&lt;Spacecraft escaping the Solar 0.5972
System, Pioneer 11&gt;
&lt;1973 in space exploration, Pio- 0.4018
neer 11&gt;
&lt;Jupiter spacecraft, Pioneer 11&gt; 0.2105
&lt;Saturn spacecraft, Pioneer 11&gt; 0.2105
&lt;Inactive extraterrestrial probes, 0.0440
Pioneer 11&gt;,
&lt;Radio frequency propagation, Pi- 0.0440
oneer 11&gt;
&lt;Pioneer program, Pioneer 11&gt; 0.0132
</table>
<tableCaption confidence="0.767527">
Table 3: Scoring each category links using graph-
based approach
</tableCaption>
<bodyText confidence="0.999783533333333">
The link &lt;Spacecraft escaping the Solar Sys-
tem, Pioneer 11&gt; gets the highest score, while
the link &lt;1973 in space exploration, Pioneer
11&gt;, which got the highest score using counting-
based approach, gets the second place. That
proves the algorithm’s effectiveness for distin-
guishing isa/instanceOf link from other non-
isa/instanceOf links. But there is still a problem -
although the first-ranked link is a isa/instanceOf
link, the second-ranked is not, while the third
and fourth-ranked links (&lt;Jupiter spacecraft, Pi-
oneer 11&gt;, &lt;Saturn spacecraft, Pioneer 11&gt; are
isa/instanceOf links. To get a better result, we
propose four additional modifications in the next
secton.
</bodyText>
<subsectionHeader confidence="0.8620815">
3.4 Additional Modifications to the
Graph-based Approach
</subsectionHeader>
<bodyText confidence="0.999898625">
To better reflect the category structure and the
property of category names to the scoring mech-
anism, the following four modifications can be
made. Each of these modification could be ap-
plied independently to the original algorithm de-
scribed in section 3.3.2.
Authority Impact Factor (I). In most cases,
a category name contains only one head word,
while it contains 2 or more modifiers. As Formula
(3) is just the linear sum of the hub scores of each
modifier and the authority score of the head word,
the resultant score is more affected by hub score,
because the number of modifiers is normally big-
ger than the number of head words. To balance
the effect of hub score and authority score, we in-
troduce authority impact factor I:
</bodyText>
<equation confidence="0.893993">
Score(&lt; A, B &gt;)
�
= I · Authority(h) +
a in mod(A)
</equation>
<bodyText confidence="0.999784416666667">
The authority impact factor is defined as the aver-
age number of modifiers in the elements of U(B,
n), since normally each category name contains
only one head word.
Dummy Node (D). There are some category
names that contain only one head word and no
modifier, thus making it impossible to create the
modifier graph.5 Thus, for such category names
we introduce dummy nodes to include their infor-
mation into the modifier graph. In figure 3, you
can observe the introduction of the dummy node
‘dummy0’.
</bodyText>
<footnote confidence="0.6870245">
5For example, in figure 2, we cannot find node ‘Saturn’
while U(Pioneer 11, 3) contains category name ‘Saturn’
</footnote>
<equation confidence="0.944526">
Hub(a) (4)
</equation>
<page confidence="0.995891">
53
</page>
<figureCaption confidence="0.9917415">
Figure 3: Modifier graph of the subset of
U(Pioneer 11, 3), with dummy node.
</figureCaption>
<bodyText confidence="0.996664722222222">
Category Distance Factor (C). We define the
category distance between category/article A and
B as the minimum number of category links re-
quired to reach B from A by following the cate-
gory links. Category distance factor C of a cat-
egory name A from U(B, n) is the reverse of the
category distance between A and B. We assumed
that, if the distance between A and B is higher,
then it is less probable for A to have the intrinsic
property of B. Based on this assumption, category
distance factor C of category name A is multiplied
by the edge score of an edge generated by cate-
gory name A.
Figure 4 shows the modifier graph of figure 2
that applies the category distance factor. Since
the category distance between “Pioneer 11” and
“NASA probe” is two, the score of edge (NASA,
probe) is 1/2 = 0.5.
</bodyText>
<figureCaption confidence="0.959183">
Figure 4: Modifier graph of the subset of
U(Pioneer 11, 3), with category distance factor.
</figureCaption>
<bodyText confidence="0.995838631578947">
Modifier Number Normalization Factor (W).
In the algorithm of building a modifier graph, the
head word of a category name with many mod-
ifiers has the advantage over the head word of a
category name with few modifiers, as if a cate-
gory name contains n modifiers it will generate
n edges incoming to its head word. To overcome
this problem, we defined the modifier number nor-
malization factor W for each category name: it is
defined as the reverse of the number of modifiers
in the category name, and it is multiplied by the
edge score of an edge, generated by the category
name, of the modifier graph. Figure 5 shows the
modifier graph of figure 2 with the modifier num-
ber normalization factor. Since the category name
“Spacecraft escaping the Solar System” has three
modifiers, the scores of edge (escape, Pioneer 11),
(solar, Pioneer 11) and (system, Pioneer 11) are
1/3 = 0.33.
</bodyText>
<figureCaption confidence="0.908284333333333">
Figure 5: Modifier graph of the subset of
U(Pioneer 11, 3), with modifier number normal-
ization factor.
</figureCaption>
<bodyText confidence="0.999411571428572">
Removing roleOf Relation (E). To distinguish
the roleOf relation from taxonomic relation,we in-
troduce a new E. This feature simply classify the
link &lt;A, B&gt; as non-instanceOf if category name
A has endings like -er, -ers, -or, -ors, -ian, -ians.
Since only the terminal node can represent the
name of person in category structure, we applied
this feature to classify only article-category links.
One of the example from Wikipedia which should
be judged as roleOf relation is &lt;La Liga foot-
baller, Cristiano Ronaldo&gt;.
After applying above four modifications, we get
the result in table 4. Now, top 3 links all represent
instanceOf links.
</bodyText>
<page confidence="0.995109">
54
</page>
<table confidence="0.997335333333333">
Article-Category Links Score
&lt;Spacecraft escaping the Solar 2.1416
System, Pioneer 11&gt;
&lt;Jupiter spacecraft, Pioneer 11&gt; 2.1286
&lt;Saturn spacecraft, Pioneer 11&gt; 2.1286
&lt;1973 in space exploration, Pio- 0.0241
neer 11&gt;
&lt;Pioneer program, Pioneer 11&gt; 0.0062
&lt;Inactive extraterrestrial probes, 0.0026
Pioneer 11&gt;,
&lt;Radio frequency propagation, Pi- 0.0021
oneer 11&gt;
</table>
<tableCaption confidence="0.805827">
Table 4: Scoring each category links using graph-
based approach with four modifications.
</tableCaption>
<sectionHeader confidence="0.996536" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999930318181818">
We implemented a combinatory system that com-
bines the algorithm suggested by this paper with
existing lexical pattern-based algorithms. More
precisely, we set two parameters α and 0, in which
0 has a consistently higher value than α. If score
of the given category link, which is retrieved by
the proposed system, is higher than 0, it is classi-
fied as isa/instanceOf. If the score is higher than α
but lower or equal to 0, the system uses an exist-
ing lexical pattern-based algorithm to classify the
link. If the score is lower than or equal to α, it is
classified as not isa/instanceOf.
To test the system, we used Wikipedia’s
category structure, which contains 1,160,248
category-category links and 15,778,801 article-
category links between 505,277 categories and
6,808,543 articles. We extract category links from
the Wikipedia category structure and annotate
them to construct the test corpus. During the pro-
cess of choosing category links, we intentionally
removed category links with names containing
any of the following words: “stub”, “wikiproject”,
“wikipedia”, “template”, “article”, “start-class”,
“category”, “redirect”, “mediawiki”, “user”, “por-
tal”, “page”, and “list”. These words are normally
used to represent Wikipedia maintenance pages.
After we remove the links described before, we
randomly choose 3,951 category-category links
and 1,688 article-category links. Two annotators
worked separately to annotate whether or not the
given link is an isa/instanceOf link, and in the
event of conflict they would discuss the case and
make a final decision.
We carried out experiments on category-
category link set and article-category link set sep-
arately, since their characteristics are different.
We assumed that the taxonomic relation in a
category-category link is an isa link, while the tax-
onomic relation in an article-category link is an in-
stanceOf link. To acquire the upper category set,
we set n=3 throughout the experiment. For head
word extraction, the method of Collins (1999) is
used, and for lemmatization we used the Lingpipe
toolkit (Alias-i, 2008).
</bodyText>
<subsectionHeader confidence="0.972488">
4.1 Experiments on category-category link
</subsectionHeader>
<bodyText confidence="0.99998996875">
We divided the 3,951 category-category links into
two equally-sized sets, and used one set as a train-
ing set and the other one as a test set. The training
set was used to identify the α and 0 values for
isa link classification: in other words, the α and
0 values that showed the best performance when
applied to training set were selected as the actual
parameters used by the system. As Wikipedia’s
category structure contains a huge number of cat-
egory links, precision is more important than re-
call. As recall cannot be ignored, we chose the
parameters that gave the highest precision on the
training set, while giving a recall of at least 0.7.
Also, we carried out experiments on three base-
line systems.The first one determined every link
as an isa link. The second one applied the head
word matching rule (M) only, which says that for
category-category link &lt;A, B&gt;, if the head words
of A and B are the same, then &lt;A, B&gt; should
be classified as an isa link. The third one applies
the method of Ponzetto (P) (Ponzetto and Strube,
2007). The ruleset of Ponzetto includes Head
word matching rule, Modifier-head word match-
ing rule(Ex. &lt;Crime, Crime Comics&gt;: Head
word of “Crime” and modifier of “Crime Comics”
matches: Not isa), and the plurality rule used by
YAGO system(Explained at the next chapter)).
Table 5 shows the baseline results, the results
of existing systems, and our best results on the
test set. Usage of authority score is represented
as A, and usage of hub score is represented as H.
Also,we did experiments on all possible combina-
</bodyText>
<page confidence="0.995099">
55
</page>
<bodyText confidence="0.991908125">
tion of features A, H, I, D, C, W, M, P. For exam-
ple, Comb(AHICDM) means that we used feature
A, H, I, C, D to construct the modifier graph and
score the category link, and for those whose score
is between α and β we used head word matching
rule to classify them. At the table, P stands for
Precision, R stands for Recall, and F stands for
F-measure.
</bodyText>
<table confidence="0.999849714285714">
Setting P R F
Baseline1 0.7277 1.0 0.8424
Baseline2(M) 0.9480 0.6335 0.7595
Baseline3(P) 0.9232 0.6516 0.7640
Comb1(AHM) 0.9223 0.7350 0.8181
Comb2(AHP) 0.8606 0.7211 0.7847
Comb3(AHICM) 0.9325 0.7302 0.8190
</table>
<tableCaption confidence="0.793335">
Table 5: Experimental result on test set of
category-category links: Baseline vs. System best
result
</tableCaption>
<bodyText confidence="0.999919045454545">
As you can observe, the precision of head-word
matching (M) is high, meaning that in many cases
the head word represents the intrinsic property.
Also, its recall shows that for category-category
links, at least more than half of the categories are
categorized using the intrinsic property of the ob-
jects grouped within them, which strongly sup-
ports lemma 2 in section 3.2. The comparison of
setting M and AHM, P and AHP shows that the
intrinsic-property based approach increases recall
of the existing system about 7-10 %, at the cost of
of 2-6 % precision loss. This shows that, rather
than looking only at the given category link and
analyzing patterns on its name, by gathering in-
formation from the upper category set, we were
able to significantly increase recall. However, it
also shows that some “garbage” information is in-
troduced through the upper category set, resulting
in a 2-6 % precision loss. The best system shows
about a 8-10 % increase in recall, with compara-
bly good precision compared to the two baseline
systems.
</bodyText>
<subsectionHeader confidence="0.944067">
4.2 Experiments on article-category link
</subsectionHeader>
<bodyText confidence="0.999848777777778">
In a similar manner to the experiments on
category-category links, we divided the 1,688
article-category links into two equally-sized sets,
and used one set as a training set and the other one
as a test set. The training set is used to determine
the parameters for instanceOf link classification.
The parameter setting procedure was the same as
in the experiments on category-category links, ex-
cept that we used the article-category links for the
procedure. In this experiment, we also adapted
three baseline systems. The first system classi-
fies every link as an instanceOf link, the second
system adapts the head word matching rule (M),
and the third system applies the rule from Yago
(Y) (Suchanek et al., 2007), which states that for
article-category link &lt;A, B&gt;, if A is plural then
the link could be classified as an instanceOf rela-
tion.
</bodyText>
<table confidence="0.999700333333333">
Setting P R F
Baseline1 0.5261 1.0 0.6894
Baseline2(M) 0.7451 0.0856 0.1535
Baseline3(Y) 0.6036 0.5315 0.5653
Comb1(AHY) 0.6082 0.6718 0.6381
Comb2(ADWEY) 0.7581 0.7410 0.7494
</table>
<tableCaption confidence="0.955525">
Table 6: Experimental result on test set of article-
category links on some settings
</tableCaption>
<bodyText confidence="0.9949912">
Table 6 shows the baseline results and the best
results of the combinatory system. As you can ob-
serve from the above table, M (head word match-
ing rule) does not work well in article-category
links, although its precision is still high or compa-
rable to that of other methods. Since in most cases
an article represents one instance, in many cases
they have their own name, making the recall of
the head word matching rule extremely low. Also,
the combination system 1 (AHY) shows compa-
rable precision with Y but 14 % higher in reall,
resulting 7 % increse in F-Measure.The best sys-
tem shows about 18 % increase in F-measure, es-
pecially 15 % precision increase and 21 % recall
increase compared to YAGO system.
</bodyText>
<sectionHeader confidence="0.998787" genericHeader="conclusions">
5 Conclusion and Future work
</sectionHeader>
<bodyText confidence="0.999918">
In this paper, we explored a intrinsic token-based
approach to the problem of classifying whether a
category link is a taxonomic relation or not. Un-
like previous works that classify category links,
we acquired the definition of a lower category
</bodyText>
<page confidence="0.985991">
56
</page>
<bodyText confidence="0.9999683">
name by extracting intrinsic tokens and using
them to score the given category link, rather than
by applying predefined lexical rules to the cat-
egory link. Our intrinsic token-based approach
leads to a significant improvement in F-measure
compared to previous state-of-the-art systems.
One possible future direction for research is au-
tomatic instance population, by using those ex-
tracted intrinsic tokens and gathering taxonomic
relations from the category structure.
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996430166666667">
This work was supported by the Industrial
Strategic Technology Development Program
(10035348, Development of a Cognitive Planning
and Learning Model for Mobile Platforms) funded
by the Ministry of Knowledge Economy(MKE,
Korea).
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999168603448276">
Soumen C. Byron, Byron Dom, Rakesh Agrawal, and
Prabhakar Raghavan. 1997. Using taxonomy, dis-
criminants, and signatures for navigating in text
databases. Proceedings of the international confer-
ence on very large data bases, 446–455.
Philipp Cimiano, Andreas Hotho, and Steffen Staab.
2005. Learning Concept Hierarchies from Text Cor-
pora using Formal Concept Analysis. Journal ofAr-
tificial Intelligence Research, 24:305–339.
Philipp Cimiano, Aleksander Pivk, Lars Schmidt-
Thieme, and Steffen Staab. 2005. Learning Tax-
onomic Relations from Heterogeneous Sources of
Evidence. Ontology Learning from Text: Methods,
Evaluation and Applications, 59–73.
Marti A. Hearst. 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. Proceedings of
the 14th conference on Computational linguistics,
2:539–545.
Andreas Hotho, Steffen Staab, and Gerd Stumme.
2003. Ontologies improve text document cluster-
ing. Proceedings of the IEEE International Confer-
ence on Data Mining, 541–544.
Jon M. Kleinberg. 1999. Authoritative sources in
a hyperlinked environment. Journal of the ACM,
46(5):604–632
Simone P. Ponzetto, and Michael Strube. 2007. Deriv-
ing a Large Scale Taxonomy from Wikipedia. Pro-
ceedings of the AAAI07.
Vivi Nastase, and Michael Strube. 2008. Decoding
Wikipedia category names for knowledge acquisi-
tion . Proceedings of the AAAI08.
Riichiro Mizoguchi. 2004. Part 3: Advanced course
of ontological engineering. New Generation Com-
puting, 22(2): 193–220
Rada Mihalcea, and Paul Tarau. 2005. A Language In-
dependent Algorithm for Single and Multiple Doc-
ument Summarization. Proceedings of IJCNLP
2005.
Ian Niles, and Adam Pease. 2003. Linking Lexi-
cons and Ontologies: Mapping WordNet to the Sug-
gested Upper Merged Ontology. Proceedings of the
IEEE International Conference on Information and
Knowledge Engineering.
Soeren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. DBpedia: A Nucleus for a Web of
Open Data. Lecture Notes in Computer Science,
4825/2007:722–735.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. YAGO: A Core of Semantic
Knowledge Unifying WordNet and Wikipedia Pro-
ceedings of the 16th international conference on
World Wide Web, 697–706.
Michael Collins. 1999. Head-driven Statistical Mod-
els for Natural Language Parsing. University of
Pennsylvania PhD Thesis.
Alias-i. 2008. LingPipe 3.9.1. http://alias-
i.com/lingpipe.
</reference>
<page confidence="0.99905">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.514931">
<title confidence="0.858854666666667">Intrinsic Property-based Taxonomic Relation Extraction from Category Structure DongHyun Choi and Eun-Kyung Kim and Sang-Ah Shim and Key-Sun</title>
<author confidence="0.795057">Semantic Web Research</author>
<email confidence="0.922307">cdh4696,kekeeo,sashim,kschoi@world.kaist.ac.kr</email>
<abstract confidence="0.999589866666667">We propose a novel algorithm to extaxonomic (or relations from category structure by classifying each category link. Previous algorithms mainly focus on lexical patterns of category names to classify whether or not given category link is an In contrast, our algorithm extracts intrinsic properties that represent the definition of given category name, and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Soumen C Byron</author>
<author>Byron Dom</author>
<author>Rakesh Agrawal</author>
<author>Prabhakar Raghavan</author>
</authors>
<title>Using taxonomy, discriminants, and signatures for navigating in text databases.</title>
<date>1997</date>
<booktitle>Proceedings of the international conference on very large data bases,</booktitle>
<pages>446--455</pages>
<contexts>
<context position="977" citStr="Byron et al., 1997" startWordPosition="139" endWordPosition="142">each category link. Previous algorithms mainly focus on lexical patterns of category names to classify whether or not a given category link is an isa/instanceOf. In contrast, our algorithm extracts intrinsic properties that represent the definition of given category name, and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high perf</context>
</contexts>
<marker>Byron, Dom, Agrawal, Raghavan, 1997</marker>
<rawString>Soumen C. Byron, Byron Dom, Rakesh Agrawal, and Prabhakar Raghavan. 1997. Using taxonomy, discriminants, and signatures for navigating in text databases. Proceedings of the international conference on very large data bases, 446–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Andreas Hotho</author>
<author>Steffen Staab</author>
</authors>
<title>Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis.</title>
<date>2005</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>24--305</pages>
<contexts>
<context position="1140" citStr="Cimiano et al., 2005" startWordPosition="162" endWordPosition="165">In contrast, our algorithm extracts intrinsic properties that represent the definition of given category name, and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category s</context>
</contexts>
<marker>Cimiano, Hotho, Staab, 2005</marker>
<rawString>Philipp Cimiano, Andreas Hotho, and Steffen Staab. 2005. Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis. Journal ofArtificial Intelligence Research, 24:305–339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Aleksander Pivk</author>
<author>Lars SchmidtThieme</author>
<author>Steffen Staab</author>
</authors>
<title>Learning Taxonomic Relations from Heterogeneous Sources of Evidence. Ontology Learning from Text: Methods, Evaluation and Applications,</title>
<date>2005</date>
<pages>59--73</pages>
<contexts>
<context position="1140" citStr="Cimiano et al., 2005" startWordPosition="162" endWordPosition="165">In contrast, our algorithm extracts intrinsic properties that represent the definition of given category name, and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category s</context>
</contexts>
<marker>Cimiano, Pivk, SchmidtThieme, Staab, 2005</marker>
<rawString>Philipp Cimiano, Aleksander Pivk, Lars SchmidtThieme, and Steffen Staab. 2005. Learning Taxonomic Relations from Heterogeneous Sources of Evidence. Ontology Learning from Text: Methods, Evaluation and Applications, 59–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic Acquisition of Hyponyms from Large Text Corpora.</title>
<date>1992</date>
<booktitle>Proceedings of the 14th conference on Computational linguistics,</booktitle>
<pages>2--539</pages>
<contexts>
<context position="4660" citStr="Hearst, 1992" startWordPosition="733" endWordPosition="734">ing it a perfect target for an experimental taxonomic relation extraction algorithm. After describing related works in section 2, our detailed algorithm is proposed in section 3, and its experimental results are discussed in section 4. In section 5, we make some conclusions and proposals for future work. 2 Related Works Methods of taxonomic relation extraction can be divided into two broad categories depending on the input: unstructured or structured data. The extraction of taxonomic relations from unstructured text is mainly carried out using lexical patterns on the text. The Hearst pattern (Hearst, 1992) is used in many pattern-based approaches, such as Cimiano (2005). In addition, there has been research that attempted to use existing structured data, like the Wikipedia category structure or the contents of a thesaurus. The system of Ponzetto (2007) determines whether or not the given Wikipedia category link is an isa/instanceOf relation by applying a set of rules to the category names, while Nastase (2008) defined lexical patterns on category names, in addition to Ponzetto (2007). The YAGO system (Suchanek et al., 2007) attempts to classify whether the given article-category link represents</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. Proceedings of the 14th conference on Computational linguistics, 2:539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Hotho</author>
<author>Steffen Staab</author>
<author>Gerd Stumme</author>
</authors>
<title>Ontologies improve text document clustering.</title>
<date>2003</date>
<booktitle>Proceedings of the IEEE International Conference on Data Mining,</booktitle>
<pages>541--544</pages>
<contexts>
<context position="936" citStr="Hotho et al., 2003" startWordPosition="132" endWordPosition="135">s from category structure by classifying each category link. Previous algorithms mainly focus on lexical patterns of category names to classify whether or not a given category link is an isa/instanceOf. In contrast, our algorithm extracts intrinsic properties that represent the definition of given category name, and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from </context>
</contexts>
<marker>Hotho, Staab, Stumme, 2003</marker>
<rawString>Andreas Hotho, Steffen Staab, and Gerd Stumme. 2003. Ontologies improve text document clustering. Proceedings of the IEEE International Conference on Data Mining, 541–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="12236" citStr="Kleinberg, 1999" startWordPosition="2027" endWordPosition="2028">e first algorithm, a counting-based approach, uses only lemmas 1 and 2, and it will be shown why this algorithm will not work. The second algorithm, a graph-based approach, uses all of the hy50 Figure 1: category structure of U(Pioneer 11, 3) from Wikipedia. potheses to solve the problem. For the given category link &lt;A, B&gt;, the intrinsic score of each token will be calculated based on its frequency inside U(B, n) while separately counting the token’s intrinsic score as modifiers and the intrinsic score as head word. We here propose a scoring mechanism based on the HITS page ranking algorithm (Kleinberg, 1999): For the given category link &lt;A, B&gt;, we first construct a “modifier graph” using U(B, n), and then calculate the intrinsic score for each token in U(B, n) using the HITS algorithm. After that, the intrinsic score of each token will be used to calculate the score of &lt;A, B&gt;. If the score is higher than some predefined threshold, then &lt;A, B&gt; is classified as an isa/instanceOf link, and otherwise it is not. 3.3.1 Counting-based Approach This method utilizes lemmas 1 and 2 to get the intrinsic score for each token, and then uses the score to determine whether the given category link is an isa/inst</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604–632</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone P Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Deriving a Large Scale Taxonomy from Wikipedia.</title>
<date>2007</date>
<booktitle>Proceedings of the AAAI07.</booktitle>
<contexts>
<context position="1256" citStr="Ponzetto and Strube, 2007" startWordPosition="179" endWordPosition="182">and uses those properties to classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category structures of Wikipedia or DBpedia (Auer et al., 2007) have become available, an obstacle to this approach has been r</context>
<context position="26787" citStr="Ponzetto and Strube, 2007" startWordPosition="4453" endWordPosition="4456">ucture contains a huge number of category links, precision is more important than recall. As recall cannot be ignored, we chose the parameters that gave the highest precision on the training set, while giving a recall of at least 0.7. Also, we carried out experiments on three baseline systems.The first one determined every link as an isa link. The second one applied the head word matching rule (M) only, which says that for category-category link &lt;A, B&gt;, if the head words of A and B are the same, then &lt;A, B&gt; should be classified as an isa link. The third one applies the method of Ponzetto (P) (Ponzetto and Strube, 2007). The ruleset of Ponzetto includes Head word matching rule, Modifier-head word matching rule(Ex. &lt;Crime, Crime Comics&gt;: Head word of “Crime” and modifier of “Crime Comics” matches: Not isa), and the plurality rule used by YAGO system(Explained at the next chapter)). Table 5 shows the baseline results, the results of existing systems, and our best results on the test set. Usage of authority score is represented as A, and usage of hub score is represented as H. Also,we did experiments on all possible combina55 tion of features A, H, I, D, C, W, M, P. For example, Comb(AHICDM) means that we used </context>
</contexts>
<marker>Ponzetto, Strube, 2007</marker>
<rawString>Simone P. Ponzetto, and Michael Strube. 2007. Deriving a Large Scale Taxonomy from Wikipedia. Proceedings of the AAAI07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>Decoding Wikipedia category names for knowledge acquisition .</title>
<date>2008</date>
<booktitle>Proceedings of the AAAI08.</booktitle>
<contexts>
<context position="1282" citStr="Nastase and Strube, 2008" startWordPosition="183" endWordPosition="186">o classify each category link. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category structures of Wikipedia or DBpedia (Auer et al., 2007) have become available, an obstacle to this approach has been removed. Although a categor</context>
</contexts>
<marker>Nastase, Strube, 2008</marker>
<rawString>Vivi Nastase, and Michael Strube. 2008. Decoding Wikipedia category names for knowledge acquisition . Proceedings of the AAAI08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riichiro Mizoguchi</author>
</authors>
<title>Part 3: Advanced course of ontological engineering.</title>
<date>2004</date>
<journal>New Generation Computing,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>193--220</pages>
<contexts>
<context position="6159" citStr="Mizoguchi (2004)" startWordPosition="966" endWordPosition="968">tegory link inside the category structure according to whether it represents an isa/instanceOf relation or not. 3 Algorithm Description In section 3.1, we introduce the necessary definitions for isa/instanceOf relations and the required terms to describe the algorithm. In section 3.2, we will discuss the hypotheses based on the definitions described in section 3.1. Next, two binary classification algorithms will be proposed based on the hypotheses, which will determine whether the given category link is an isa/instanceOf relation or not. 3.1 Definitions To define isa and instanceOf relations, Mizoguchi (2004) introduces the concept of intrinsic property and other related concepts, which are shown in the following definitions 1, 2 and 3: Definition 1: Intrinsic property. The intrinsic property of a thing is a property which is essential to the thing and it loses its identity when the property changes. Definition 2: The ontological definition of a class. A thing which is a conceptualization of a set X can be a class if and only if each element x of X belongs to the class X if and only if the intrinsic property of x satisfies the intensional condition of X. And, then and only then, &lt;x instanceOf X&gt; h</context>
</contexts>
<marker>Mizoguchi, 2004</marker>
<rawString>Riichiro Mizoguchi. 2004. Part 3: Advanced course of ontological engineering. New Generation Computing, 22(2): 193–220</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>A Language Independent Algorithm for Single and Multiple Document Summarization.</title>
<date>2005</date>
<booktitle>Proceedings of IJCNLP</booktitle>
<contexts>
<context position="16332" citStr="Mihalcea and Tarau, 2005" startWordPosition="2695" endWordPosition="2698">s each token inside U(B, n), and each edge represents a co-occurrence as modifier-head relation inside each category name of U(B, n). Using the subset of U(Pioneer 11, 3), we get the modifier graph of figure 2.4 Figure 2: Modifier graph of the subset of U(Pioneer 11, 3): {Spacecraft escaping the Solar System, Jupiter spacecraft, 1973 in space exploration, NASA probes, Saturn} Calculating Intrinsic score After constructing the modifier graph, we apply the HITS algorithm to the modifier graph. Since the HITS algorithm cannot reflect the weight of edges, a modified version of the HITS algorithm (Mihalcea and Tarau, 2005) is adopted: Authority(Vi) = � eji · Hub(Vj) (1) Vj∈In(Vi) Hub(Vi) = � eij · Authority(Vj) (2) Vj∈Out(Vi) In(Vi) represents the set of vertices which has the outgoing edge to Vi, Out(Vi) represents the set of vertices which has the incoming edge from Vi, and eij represents the weight of the edge from Vi to Vj. The algorithm for calculating the scores is as follows: 1. Initialize the authority and hub score of each node to one. 2. Calculate hub score of each node using the formula 2. 3. Calculate authority score of each node using the formula 1. 4. Normalize authority &amp; hub score so that the su</context>
</contexts>
<marker>Mihalcea, Tarau, 2005</marker>
<rawString>Rada Mihalcea, and Paul Tarau. 2005. A Language Independent Algorithm for Single and Multiple Document Summarization. Proceedings of IJCNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Niles</author>
<author>Adam Pease</author>
</authors>
<title>Linking Lexicons and Ontologies: Mapping WordNet to the Suggested Upper Merged Ontology.</title>
<date>2003</date>
<booktitle>Proceedings of the IEEE International Conference on Information and Knowledge Engineering.</booktitle>
<marker>Niles, Pease, 2003</marker>
<rawString>Ian Niles, and Adam Pease. 2003. Linking Lexicons and Ontologies: Mapping WordNet to the Suggested Upper Merged Ontology. Proceedings of the IEEE International Conference on Information and Knowledge Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soeren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>DBpedia: A Nucleus for a Web of Open Data.</title>
<date>2007</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>4825--2007</pages>
<contexts>
<context position="1793" citStr="Auer et al., 2007" startWordPosition="264" endWordPosition="267"> structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category structures of Wikipedia or DBpedia (Auer et al., 2007) have become available, an obstacle to this approach has been removed. Although a category structure does contain some kind of hierarchical structure, in many cases it cannot be considered as an isa/instanceOf hierarchy. For example, the article “Pioneer 111” on Wikipedia is categorized under “Radio frequency propagation”, which is related to the “Pioneer 11” but is obviously not a taxonomical parent of “Pioneer 11”. In this paper, we propose a method for extracting taxonomic relations from a given category structure. More precisely, for a category link in the given category structure, the alg</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>Soeren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. DBpedia: A Nucleus for a Web of Open Data. Lecture Notes in Computer Science, 4825/2007:722–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<date>2007</date>
<booktitle>YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<contexts>
<context position="1306" citStr="Suchanek et al., 2007" startWordPosition="187" endWordPosition="190">ink. Experimental result shows about 5 to 18 % increase in F-Measure, compared to other existing systems. 1 Introduction 1.1 Problem Description Taxonomies are a crucial component of many applications, including document clustering (Hotho et al., 2003) and database search (Byron et al., 1997). Due to their importance, many studies have examined methods of extracting taxonomic relations automatically - either from unstructured text (Cimiano et al., 2005; Cimiano(2) et al., 2005), or from structured data such as Wikipedia category structures (Ponzetto and Strube, 2007; Nastase and Strube, 2008; Suchanek et al., 2007). Many researchers have attempted to obtain taxonomic relations from unstructured text to constuct a taxonomy, but in most cases such a system shows poor precision and low recall. Approaches to extracting taxonomic relations from structured data show relatively high performance, but to obtain a taxonomy these require huge amounts of structured data. Recently, as large amounts of structured data such as the infoboxes and category structures of Wikipedia or DBpedia (Auer et al., 2007) have become available, an obstacle to this approach has been removed. Although a category structure does contain</context>
<context position="5188" citStr="Suchanek et al., 2007" startWordPosition="819" endWordPosition="822">xt is mainly carried out using lexical patterns on the text. The Hearst pattern (Hearst, 1992) is used in many pattern-based approaches, such as Cimiano (2005). In addition, there has been research that attempted to use existing structured data, like the Wikipedia category structure or the contents of a thesaurus. The system of Ponzetto (2007) determines whether or not the given Wikipedia category link is an isa/instanceOf relation by applying a set of rules to the category names, while Nastase (2008) defined lexical patterns on category names, in addition to Ponzetto (2007). The YAGO system (Suchanek et al., 2007) attempts to classify whether the given article-category link represents an instanceOf relation by checking the plurality of the upper category name. The algorithm proposed in this paper focuses on the structured data, mainly the category structure, to gather isa/instanceOf relations. The system gets a category structure as input, and classifies each category link inside the category structure according to whether it represents an isa/instanceOf relation or not. 3 Algorithm Description In section 3.1, we introduce the necessary definitions for isa/instanceOf relations and the required terms to</context>
<context position="29748" citStr="Suchanek et al., 2007" startWordPosition="4949" endWordPosition="4952">icle-category links into two equally-sized sets, and used one set as a training set and the other one as a test set. The training set is used to determine the parameters for instanceOf link classification. The parameter setting procedure was the same as in the experiments on category-category links, except that we used the article-category links for the procedure. In this experiment, we also adapted three baseline systems. The first system classifies every link as an instanceOf link, the second system adapts the head word matching rule (M), and the third system applies the rule from Yago (Y) (Suchanek et al., 2007), which states that for article-category link &lt;A, B&gt;, if A is plural then the link could be classified as an instanceOf relation. Setting P R F Baseline1 0.5261 1.0 0.6894 Baseline2(M) 0.7451 0.0856 0.1535 Baseline3(Y) 0.6036 0.5315 0.5653 Comb1(AHY) 0.6082 0.6718 0.6381 Comb2(ADWEY) 0.7581 0.7410 0.7494 Table 6: Experimental result on test set of articlecategory links on some settings Table 6 shows the baseline results and the best results of the combinatory system. As you can observe from the above table, M (head word matching rule) does not work well in article-category links, although its </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia Proceedings of the 16th international conference on World Wide Web, 697–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>PhD Thesis.</tech>
<institution>University of Pennsylvania</institution>
<contexts>
<context position="25630" citStr="Collins (1999)" startWordPosition="4250" endWordPosition="4251"> annotators worked separately to annotate whether or not the given link is an isa/instanceOf link, and in the event of conflict they would discuss the case and make a final decision. We carried out experiments on categorycategory link set and article-category link set separately, since their characteristics are different. We assumed that the taxonomic relation in a category-category link is an isa link, while the taxonomic relation in an article-category link is an instanceOf link. To acquire the upper category set, we set n=3 throughout the experiment. For head word extraction, the method of Collins (1999) is used, and for lemmatization we used the Lingpipe toolkit (Alias-i, 2008). 4.1 Experiments on category-category link We divided the 3,951 category-category links into two equally-sized sets, and used one set as a training set and the other one as a test set. The training set was used to identify the α and 0 values for isa link classification: in other words, the α and 0 values that showed the best performance when applied to training set were selected as the actual parameters used by the system. As Wikipedia’s category structure contains a huge number of category links, precision is more im</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-driven Statistical Models for Natural Language Parsing. University of Pennsylvania PhD Thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alias-i</author>
</authors>
<date>2008</date>
<journal>LingPipe</journal>
<volume>3</volume>
<note>http://aliasi.com/lingpipe.</note>
<contexts>
<context position="25706" citStr="Alias-i, 2008" startWordPosition="4262" endWordPosition="4263">n isa/instanceOf link, and in the event of conflict they would discuss the case and make a final decision. We carried out experiments on categorycategory link set and article-category link set separately, since their characteristics are different. We assumed that the taxonomic relation in a category-category link is an isa link, while the taxonomic relation in an article-category link is an instanceOf link. To acquire the upper category set, we set n=3 throughout the experiment. For head word extraction, the method of Collins (1999) is used, and for lemmatization we used the Lingpipe toolkit (Alias-i, 2008). 4.1 Experiments on category-category link We divided the 3,951 category-category links into two equally-sized sets, and used one set as a training set and the other one as a test set. The training set was used to identify the α and 0 values for isa link classification: in other words, the α and 0 values that showed the best performance when applied to training set were selected as the actual parameters used by the system. As Wikipedia’s category structure contains a huge number of category links, precision is more important than recall. As recall cannot be ignored, we chose the parameters th</context>
</contexts>
<marker>Alias-i, 2008</marker>
<rawString>Alias-i. 2008. LingPipe 3.9.1. http://aliasi.com/lingpipe.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>