<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000790">
<title confidence="0.997127">
UtahPOET: Disorder mention identification and context slot filling with
cognitive inspiration
</title>
<author confidence="0.998461">
Kristina Doing-Harris Sean Igo
</author>
<affiliation confidence="0.9991755">
Department of Biomedical Informatics Department of Biomedical Informatics
University of Utah Health Sciences Center University of Utah Health Sciences Center
</affiliation>
<address confidence="0.488421">
421 Wakara Way, Ste 140 421 Wakara Way, Ste 140
Salt Lake City, UT 84108 USA Salt Lake City, UT 84108 USA
</address>
<email confidence="0.991842">
kristina.doing-harris@utah.edu Sean.igo@utah.edu
</email>
<author confidence="0.993647">
Jianlin Shi John Hurdle
</author>
<affiliation confidence="0.999064">
Department of Biomedical Informatics Department of Biomedical Informatics
University of Utah Health Sciences Center University of Utah Health Sciences Center
</affiliation>
<address confidence="0.4876405">
421 Wakara Way, Ste 140 421 Wakara Way, Ste 140
Salt Lake City, UT 84108 USA Salt Lake City, UT 84108 USA
</address>
<email confidence="0.989242">
Jianlin.shi@utah.edu John.hurdel@utah.edu
</email>
<sectionHeader confidence="0.982323" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.636814571428571">
We describe the performance of UtahPOET
on SemEval 2015 Task 14. UtahPOET is a
cognitively inspired system designed to ex-
tract semantic content from general clinical
texts. We find that our system performs much
better on the context slot-filling aspects of
Tasks 2A and 2B than the disorder CUI map-
ping of Tasks 1 and 2B or the body location
CUI mapping of Task 2B. Our problems with
CUI mapping suggested several possible sys-
tem improvements. An alteration in the corre-
spondence between the system architecture
and psycholinguistic findings is also indicat-
ed.
</bodyText>
<sectionHeader confidence="0.987531" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999599">
We note at the outset that our team approaches
clinical NLP using a new, cognitively inspired ar-
chitecture. We value dataset independence, so our
design priorities do not completely overlap those
encompassed by the goals of Task 14. We share
the SemEval vision of extracting the full semantic
content of clinical text. Our short-term goal, how-
ever, was to field test an early prototype of our
new architecture and Task 14 provided a conven-
ient and well-designed use case.
</bodyText>
<subsectionHeader confidence="0.983657">
1.1 Cognitive inspirations
</subsectionHeader>
<bodyText confidence="0.999980111111111">
Only the human brain is currently able to extract
full semantic content from text. We propose an
intermediate step between artificial neurons (Mer-
olla et al., 2014; Sowa, 2010) and statistical ma-
chine learning (ML). We use ML and rule-based
NLP components with demonstrated success in
clinical information extraction arranged in an ar-
chitecture inspired by well-documented findings
with respect to cortical processing.
Briefly, UtahPOET is inspired by findings re-
lated to: layered cognitive processes, the distinc-
tion between the dorsal and ventral language
processing streams, and the phenomenon of itera-
tive refinement. The type of layered (i.e., staged or
hierarchical) processing we use shares much in
common with traditional NLP and biologically
inspired cognitive architectures (Chella, Cossenti-
no, Gaglio, &amp; Seidita, 2012; Indurkhya &amp;
Damerau, 2010; Sowa, 2010). We will discuss our
system’s layering in the system description below.
Our distinctive model of dorsal-ventral pro-
cessing streams comes from psycholinguistic find-
ings. The interpretation of unfamiliar or
ungrammatical constructions, rule-based pro-
cessing, and learning have been linked to dorsal
processing streams in the brain. Ventral processing
streams handle familiar, expected, regular con-
</bodyText>
<page confidence="0.699422">
399
</page>
<note confidence="0.737301">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999950242424242">
structions as well as heuristic-type processing
(Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004;
Kellmeyer et al., 2013; Levy et al., 2009; Price,
2013; Yeatman, Rauschecker, &amp; Wandell, 2013).
Iterative refinement is the repeated application of
top-down processing during bottom-up processing.
In Cognitive Science top-down and bottom-up re-
fer, in essence, to processes that rely on previous
knowledge and those that do not, respectively
(Traxler, 2012).
Top-down processing is evident in each stage of
an NLP pipeline, e.g., “knowing” how the end of a
sentence is marked. We see combining world
knowledge with the outcome of one processing
stage and then using that to update the outcome of
a previous stage as iterative refinement. This re-
sembles how humans ‘re-parse’ garden path sen-
tences (McKoon &amp; Ratcliff, 2007).
The UtahPOET approaches solving semantic
extraction problems by enabling dependency pars-
ing. However, ungrammatical text is common in
clinical notes (Fan et al., 2013; Meystre, Savova,
Kipper-Schuler, &amp; Hurdle, 2008). This text often
“breaks” dependency parsers, so we process
grammatical and ungrammatical text separately.
Dependency parsing is useful because it exploits
world knowledge about the structure of English
sentences. As such, it simplifies the processing of
conjunctions and the aggregation of words and re-
lationships, particularly those separated in the text,
without supervised training. Retaining sentence
structure allows dataset independence and latitude
in future relationship finding.
</bodyText>
<subsectionHeader confidence="0.946528">
1.2 Considerations for evaluation
</subsectionHeader>
<bodyText confidence="0.999937">
We propose a couple of considerations useful for
evaluating NLP systems’ results under Task 14.
The current evaluation includes strict matching to a
Gold Standard set of Unified Medical Library Sys-
tem (UMLS) Metathesaurus (Browne, Divita, Ar-
onson, &amp; McCray, 2003) CUIs. We think this
standard leads to over-fitting the data, which leads
to less generally useful systems. Clinical terms do
not guarantee a one-to-one correspondence be-
tween term and referent. A point demonstrated by
inter-annotator agreement of anything less than
100%.
The redundancy of the UMLS Methathesaurus
further undermines strict CUI mapping. Redundan-
cy is best illustrated by body location mapping.
Within the UMLS semantic types relevant to body
location are T023 (Body part, organ or organ com-
ponent) and T029 (Body location or region). We
notice inconsistency in the Gold Standard in the
use of these semantic types. For one document an-
notators chose ‘Pericardial sac structure (T023)’
over “Pericardial body location (T029)’, while in
another annotators preferred ‘Neck (T029)’ over
‘Entire neck (T023).’
Partial matches create problems as well. The
Task evaluation only considers partial span match-
es correct if the CUI for the full match is reported.
However, if the span is only partially matched the
correct CUI should change. For example, the map-
ping ‘Left ventricular hypertrophy’ to C0149721,
when partially matched with ‘Ventricular hyper-
trophy’ would seem to be more correctly mapped
to C0340279.
</bodyText>
<sectionHeader confidence="0.703648" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999991714285714">
The UtahPOET system is built in Apache UIMA
(Ferrucci &amp; Lally, 1999). It has the layered struc-
ture common to NLP pipelines (see Figure 1). The
pre-processing stage finds sentence boundaries
(stages A), breaks the sentence into tokens (stage
B), and assigns each token a part-of-speech (POS)
tag (stage B).
</bodyText>
<subsectionHeader confidence="0.954115">
2.1 Dorsal-ventral stream separation and it-
erative refinement
</subsectionHeader>
<bodyText confidence="0.9979805">
After preprocessing, we add stages to begin dorsal
and ventral separation and iterative refinement. In
stage C, we divide dorsal and ventral streams by
separating ungrammatical and grammatical text.
We refer to ungrammatical text as nonprose
qs_segments. Nonprose is differentiated from prose
(well-formed sentences) by two rules. First, well-
formed sentences contain at least one verb. Sec-
ond, well-formed sentences do not contain more
than four numbers (e.g., labs) per verb.
Iterative refinement occurs in Stage D. Realiz-
ing that standard sentence segmentation may not
perform well with nonprose (e.g., consider com-
mon lists like medications with no periods), we
then re-segment the text breaking each nonprose
qs_segment at the next carriage return, line break,
or end-of-line character. The dotted line in Figure
1 signifies that it is a repeated process.
</bodyText>
<page confidence="0.550181">
400
</page>
<figureCaption confidence="0.999762">
Figure 1. The overall UIMA pipeline for UtahPOET (please zoom for readability).
</figureCaption>
<bodyText confidence="0.989147985714287">
2.2 UtahPOET specific parallel ‘prepro-
cessing’
UtahPOET has section header identification and
short-form expansion processes that run parallel to
the ‘pre-processing’ stages. These stages are E and
F in Figure 1.
In stage E regular expressions are used to identi-
fy section headers. The regular expression rules are
found using automatic regular expression extrac-
tion (Bui &amp; Zeng-Treitler, 2014).
In stage F, a series of SVMs are used to expand
short forms. The feature vectors for these SVMs
include context vectors as bags-of-words and sec-
tion headers. The short form-long form pairs are
extracted from the ADAM dataset (Zhou, Torvik,
&amp; Smalheiser, 2006) but limited to clinical terms.
One classifier is trained for each ambiguous nor-
malized short form that has multiple corresponding
long forms. Classifiers are trained using the UMN
clinical abbreviation and acronym sense inventory
(Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014)
and context information retrieved from PubMed
case reports. The features are built on LVG
(Browne et al., 2003) normalized bag of word, sec-
tion header and short form string. The expanded
short forms are inserted into the original text, pre-
serving the original span information in UIMA
annotations for span matching back to original text
in the final stage.
2.3 Disorder detection in dorsal and ventral
streams
Stage G has two purposes: to identify single-word
disorder terms and to limit the number of words
that will be looked up in later stages. After stop-
words are removed, each word in the document is
stemmed using LVG (Browne et al., 2003) and
fetched from a Lucene index made from the UMLS
Metathesaurus restricted to the clinical sources
indicated in (Wu et al., 2012), including
SNOMEDCT, MSH, NCI, RDC, MTH, SNMI,
MDR, SCTSPA, CHV, CCPS. The sematic types
included reflect disorders, body locations, and
modifiers. Modifiers include qualitative, quantita-
tive and spatial concepts.
For the identification of multi-word terms and
context slot filling in stages H and I, we split the
text segments based on the previously described
nonprose (stage H) prose (stage I) distinction. The
dorsal stream is associated with rule-based pro-
cessing. In this case the rule associated with
nonprose qs_segments, is that adjacent unigram
disorder terms are likely to be part of a multi-word
term. Equivalently, the body location and severity
relevant to a disorder will be adjacent to the disor-
der mention. The ventral processing stream ex-
ploits world knowledge about regularity of
construction by dependency parsing. Unigram
matches that share dependencies are likely to be
part of a multi-word term and reflect relevant body
locations and severities.
In both stages (H and I), we build as long a mul-
ti-word term as possible then attempt to match the
term to a Lucene index into the UMLS Metathe-
saurus restricted to the clinical sources listed above
and only the disorder semantic types. If the term
does not match, it is incrementally reduced token-
by-token, with all combinations of words checked
for a match at each step.
Context slots are filled by overwriting entries in
a default template: the mention is not negated, the
</bodyText>
<page confidence="0.734389">
401
</page>
<bodyText confidence="0.999900888888889">
subject is the patient, the mention is not uncertain,
severity and course are unmarked, the mention is
not conditional or generic, and there is no body
location given.
Negation, uncertainty, subject, and generic
mention are found at the sentence level in nonprose
and the dependency level in prose by looking for
specific text. The remaining slot values were locat-
ed by adjacency (nonprose) or dependency (prose).
</bodyText>
<subsectionHeader confidence="0.998582">
2.4 Post-processing
</subsectionHeader>
<bodyText confidence="0.999992875">
Stage K takes place outside of UIMA. It collapses
expanded short-forms back to their original spans
and updates spans of all the other annotations in
the file so our output spans reflect those from the
SemEval gold standard. Stage L (SemEval clean
up) is the final stage of the pipeline in Figure 1.
Here we map, where possible, disorder CUIs from
SNOMED CT. This stage also incorporates a pro-
cess for identifying terms matched to the UMLS
Metathesaurus semantic type finding (T033) that
are considered CUI-less disorders in the SemEval
gold standard. We use a structured SVM to classify
the spans of findings to CUI-less disorder or not.
We used the Cornell SVMstruct SVMhmm model.
(Joachims, n.d.) Feature vectors are 4-word con-
text-window (2 before and 2 after), bag-of-words
stemmed with stopwords removed using NLTK
(Bird, Loper, &amp; Klein, 2009). The SVM parame-
ters were slack vs. weight vector magnitude (-c) of
25000 and epsilon (-e) of 0.5.
This stage also removes all disorders found
within section headers as well as annotations that
reflect either spurious UMLS Metathesaurus map-
pings or problems with short-form expansion.
</bodyText>
<sectionHeader confidence="0.999896" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.999980411764706">
UtahPOET was not expected to perform well on
either Task 1 or Task 2A. In both cases, our un-
willingness to adhere to the gold standard CUIs
caused us to score at the bottom of the pack. Six-
teen teams competed in Task 1. We were 15th. On-
ly 6 teams competed in Task 2A, we were last.
Considering the context slot filling, apart from CUI
and body location, in Task 2A would have moved
us up one rank.
We were mainly focused on Task 2B where we
scored in the middle of the pack until many of the
teams withdrew. Nine teams remain in the Task 2B
competition. Our three runs come second to the
last. Again looking at only slot filling, we would
have moved up three ranks.
Our results for the development set closely mir-
rored those on the test set; so will not be described.
</bodyText>
<subsectionHeader confidence="0.997304">
3.1 Difference between runs
</subsectionHeader>
<bodyText confidence="0.97064025">
We were unsure whether scoring favored F-scores
or accuracy so we submitted runs favoring one or
the other. For both tasks, we submitted 2 copies of
our best run in case there was a problem creating
one of the submissions. If one failed, there would
still be one left. In tasks 1 and 2A runs 1 and 2
were the same. Run 3 had a stricter Lucene match
leading to higher accuracy and lower F-score (i.e.,
reduced numbers of true positive, false positive
and false negative concepts). The stricter match
required that only the words found in the document
appear in the matched term, no extra words were
allowed. Thus, “hypertension” would not match
the UMLS Metathesaurus entry “hypertensive dis-
ease.” In task 2B, runs 2 and 3 are the same. This
time run 1 has a slightly higher accuracy, but lower
F-score due to change in Lucene matching.
For task 2A, we also realized that we could use
the gold standard spans to match the context found
by UtahPOET without finding an associated con-
cept, if we reported the span as a CUI-less disor-
der.
Table 2. Examples of CUI mapping error for dis-
orders (please zoom for readability).
</bodyText>
<subsectionHeader confidence="0.952191">
3.2 CUI and body location error analysis
</subsectionHeader>
<bodyText confidence="0.9999338">
Tables 2 and 3 list examples of the CUI mapping
errors made by UtahPOET. For disorders, they fall
into three increasingly large groups, system prob-
lems, UMLS diffuseness, and disagreement with
the gold standard.
</bodyText>
<page confidence="0.849379">
402
</page>
<bodyText confidence="0.9446775">
CUI-mapping errors in body location assign-
ment were, in increasing order of size, due to sys-
tem problems, disagreement with the gold standard
and near misses or equivalences.
Table 3. Examples of CUI mapping error for body
locations.
</bodyText>
<sectionHeader confidence="0.996821" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999971125">
The UtahPOET system can successfully extract
semantic information from clinical text. The sys-
tem construction has slightly different priorities
than the Task organizers. Our priority of creating a
dataset agnostic solution for semantic extraction
problems prompted us to offer considerations for
the evaluation and to look to cognitive findings for
system design inspiration.
</bodyText>
<subsectionHeader confidence="0.989512">
4.1 Implications for system improvement
</subsectionHeader>
<bodyText confidence="0.999974958333333">
Necessary system alterations are revealed by dis-
order CUI mapping error analysis in Table 3. CUI-
less disorders are the most error prone. We will be
adding features to the CUI-less disorder SVM to
improve performance. Two mapping mistakes
‘CT’ and ‘he’ that may be fixed by a walk back to
the most common form. We will investigate a
method to implement a walk back. Standardizing
the expanded long-forms would catch the missed
‘SOB’ mappings. Checking for phrase ‘secondary
to’ would also be helpful.
We find support for our evaluation considera-
tions above in CUI and body location mappings,
which disagree with the gold standard. For exam-
ple, if ‘shortness of breath’ is given the body loca-
tion ‘breath,’ giving ‘vomiting’ to body location
‘vomitus’ and ‘drainage’ to location ‘body fluid
discharge’ should be acceptable.
UtahPOET is prone to near misses. We see
these near misses as a type of graceful degradation,
which is a hallmark of cognitive systems. Graceful
degradation is the ability to function despite mak-
ing errors. Ferreira and Patson call this “good
enough” processing (Ferreira &amp; Patson, 2007).
</bodyText>
<subsectionHeader confidence="0.981459">
4.2 Implications for cognitive architecture
</subsectionHeader>
<bodyText confidence="0.99999037037037">
The hierarchical layers from psycholinguistics are
lexical, syntactic and semantic processing, which
proceed in that order. We do not adhere strictly to
this hierarchy. Many cognitive scientists think a
proper hierarchy is unlikely (Frank, Bod, &amp; Chris-
tiansen, 2012).
We were inspired to separate prose and
nonprose based on the ventral-dorsal distinction
between grammatical and ungrammatical text. It is
tempting to equate heuristics with ML and rules
with specific if...then statements. The cognitive
science literature indicates that this is a mistake
(Hahn &amp; Chater, 1998). All heuristics are thought
to start as rule-based. The rule-based decision is
overlearned to the point of automaticity and called
a heuristic. Therefore we do not use ML compo-
nents in only one path.
Currently, UtahPOET leverages iterative re-
finement for sentence segmentation only. Once we
implement greater integration with long-term
memory (LTM) representation, we will have the
facility to recognize clashes and implement more
extensive iterative refinement. With our ML com-
ponents, we can clearly see how learning requires
its own pathway. Each of these systems is trained
outside the UtahPOET pipeline and would require
retraining, if new information were introduced.
</bodyText>
<sectionHeader confidence="0.977627" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999940777777778">
We are grateful for the support of the National Li-
brary of Medicine grant R01LM010981. The sup-
port and resources from the Center for High
Performance Computing at the University of Utah
are gratefully acknowledged. We would like to
thank Duy Duc An Bui for building the Section
Header component and Sarathkrishna Swamina-
than for building the CUI-less disorder structure
SVM.
</bodyText>
<sectionHeader confidence="0.920191" genericHeader="references">
References
</sectionHeader>
<page confidence="0.940786">
403
</page>
<reference confidence="0.986001757281553">
Bird, Steven, Loper, Edward, &amp; Klein, Edward.
(2009). Natural Language Processing with Python.
O’Reilly Media Inc.
Browne, Allen C., Divita, Guy, Aronson, Alan R.,
&amp; McCray, Alexa T. (2003). UMLS Language and
Vocabulary Tools: AMIA 2003 Open Source Ex-
po, 2003, 798.
Bui, Duy D. A., &amp; Zeng-Treitler, Qing. (2014).
Learning regular expressions for clinical text clas-
sification. Journal of the American Medical Infor-
matics Association, 21(5), 850–857.
Chella, Antonio, Cossentino, Massimo, Gaglio,
Salvatore, &amp; Seidita, Valeria. (2012). A general
theoretical framework for designing cognitive ar-
chitectures: Hybrid and meta-level architectures
for BICA. Biologically Inspired Cognitive Archi-
tectures, 2(C), 100–108.
Doing-Harris, K.ristina Patterson, Olga, Igo, Sean,
&amp; Hurdle, John. (2013). Document sublanguage
clustering to detect medical specialty in cross-
institutional clinical texts. Proceedings of the 7th
international workshop on Data and text mining in
biomedical informatics, ACM, 9-12.
Dominey, Peter F., &amp; Inui, Toshio. (2009). Corti-
co-striatal function in sentence comprehension:
Insights from neurophysiology and modeling. Cor-
tex, 45(8), 1012–1018.
Fan, Jung-wei, Yang, Elly W., Jiang, Min, Prasad,
Rashmi, Loomis, Richard M., Zisook, Daniel S., et
al. (2013). Syntactic parsing of clinical text: guide-
line and corpus development with handling ill-
formed sentences. Journal of the American Medi-
cal Informatics Association, 20(6), 1168-1177.
Ferreira, Fernanda, &amp; Patson, Nikole D. (2007).
The “good enough” approach to language compre-
hension. Language and Linguistics Compass, 1(1-
2), 71–83.
Ferrucci, David, &amp; Lally, Adam. (1999). UIMA:
an architectural approach to unstructured infor-
mation processing in the corporate research envi-
ronment. Natural Language Engineering, 10(3-4),
327–348.
Frank, Stefan L., Bod, Rens, &amp; Christiansen,
Morten H. (2012). How hierarchical is language
use? Proceedings of the Royal Society B: Biologi-
cal Sciences, 279(1747), 4522-4531.
Hahn, Ulrike, &amp; Chater, Nick. (1998). Similarity
and rules: distinct? Exhaustive? Empirically dis-
tinguishable? Cognition, 65(2-3), 197–230.
Hickok, Gregory, &amp; Poeppel, David. (2004). Dor-
sal and ventral streams: a framework for under-
standing aspects of the functional anatomy of lan-
guage. Cognition, 92(1-2), 67–99.
Indurkhya, Nitin, &amp; Damerau, Fred J. (Eds.).
(2010). Handbook of Natural Language Pro-
cessing (Second.). Chapman and Hall. p. 168.
Joachims, Thorston. (Ed.). Cornell SVMstruct. Re-
trieved January 30, 2015, from
http://www.cs.cornell.edu/people/tj/svm_light/svm
hmm.html
_
Kellmeyer, Phillipp, Ziegler, Wolfram, Peschke,
Claudia, Juliane, Eisenberger, Schnell, Susanne,
Baumgaertner, Annette, et al. (2013). Fronto-
parietal dorsal and ventral pathways in the context
of different linguistic manipulations. Brain and
Language, 127(2), 241–250.
Levy, Jonathan, Pernet, Cyril, Treserras, Sébastien,
Boulanouar, Kader, Aubry, Florent, Démonet,
Jean-Fronçois, &amp; Celsis, Pierre. (2009). Testing for
the dual-route cascade reading model in the brain:
An fMRI Effective Connectivity Account of an
Efficient Reading Style. PLoS ONE, 4(8), e6675.
McKoon, Gail, &amp; Ratcliff, Roger. (2007). Interac-
tions of meaning and syntax: Implications for
models of sentence comprehension. Journal of
Memory and Language, 56(2), 270–290.
Merolla, Paul A., Arthur, John V., Alvarez-Icaza,
Rodrigo, Cassidy, Andrew S., Sawada, Jun,
Akopyan, Filipp, et al. (2014). A million spiking-
neuron integrated circuit with a scalable communi-
cation network and interface. Science, 345(6197),
668–673.
Meystre, Stéphane M., Savova, Guergana K., Kip-
per-Schuler, Karin C., &amp; Hurdle, John F. (2008).
Extracting information from textual documents in
the electronic health record: a review of recent re-
search. Yearb Med Inform, 35, 128–144.
Moon, Sungrim, Pahkhomov, Serguei, Liu, Na-
than, Ryan, James O., &amp; Melton, Genevieve B.
(2014). A sense inventory for clinical abbrevia-
tions and acronyms created using clinical notes and
medical dictionary resources. Journal of the Amer-
ican Medical Informatics Association, 21(2), 299–
307.
Price, Cathy J. (2013). Current themes in neuroim-
aging studies of reading. Brain and Language,
125(2), 131–133.
Sowa, John F. (2010). Biological and psycholin-
guistic influences on architectures for natural lan-
guage processing. Proceedings of the First Annual
Meeting of the BICA Society, IOS Press, Incorpo-
rated, 221, 131.
</reference>
<page confidence="0.710189">
404
</page>
<reference confidence="0.999620823529412">
Traxler, Matthew. (2012). Introduction to Psycho-
linguistics. Wiley-Blackwell.
Wu, Stephen T., Liu, Hongfang, Li, DDingcheng,
Tao, Cui, Musen, Mark A., Chute, Christopher G.,
&amp; Shah, Nigam H. (2012). Unified Medical Lan-
guage System term occurrences in clinical notes: a
large-scale corpus analysis. Journal of the Ameri-
can Medical Informatics Association, 19(e1),
e149–56.
Yeatman, Jason D., Rauschecker, Andreas M., &amp;
Wandell, Brian A. (2013). Anatomy of the visual
word form area: adjacent cortical circuits and long-
range white matter connections. Brain and Lan-
guage, 125(2), 146–155.
Zhou, Wei, Torvik, Vetle I., &amp; Smalheiser, Neil R.
(2006). ADAM: another database of abbreviations
in MEDLINE. Bioinformatics, 22(22), 2813–2818.
</reference>
<page confidence="0.965982">
405
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.533734">
<title confidence="0.9986845">UtahPOET: Disorder mention identification and context slot filling with cognitive inspiration</title>
<author confidence="0.999984">Kristina Doing-Harris Sean Igo</author>
<affiliation confidence="0.9999825">Department of Biomedical Informatics Department of Biomedical Informatics University of Utah Health Sciences Center University of Utah Health Sciences Center</affiliation>
<address confidence="0.988982">421 Wakara Way, Ste 140 421 Wakara Way, Ste 140 Salt Lake City, UT 84108 USA Salt Lake City, UT 84108 USA</address>
<email confidence="0.989921">kristina.doing-harris@utah.eduSean.igo@utah.edu</email>
<author confidence="0.999504">Jianlin Shi John Hurdle</author>
<affiliation confidence="0.999982">Department of Biomedical Informatics Department of Biomedical Informatics University of Utah Health Sciences Center University of Utah Health Sciences Center</affiliation>
<address confidence="0.9844485">421 Wakara Way, Ste 140 421 Wakara Way, Ste 140 Salt Lake City, UT 84108 USA Salt Lake City, UT 84108 USA</address>
<email confidence="0.833551">Jianlin.shi@utah.eduJohn.hurdel@utah.edu</email>
<abstract confidence="0.978610066666667">We describe the performance of UtahPOET on SemEval 2015 Task 14. UtahPOET is a cognitively inspired system designed to extract semantic content from general clinical texts. We find that our system performs much better on the context slot-filling aspects of Tasks 2A and 2B than the disorder CUI mapping of Tasks 1 and 2B or the body location CUI mapping of Task 2B. Our problems with CUI mapping suggested several possible system improvements. An alteration in the correspondence between the system architecture and psycholinguistic findings is also indicated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Edward Loper</author>
<author>Edward Klein</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media Inc.</booktitle>
<contexts>
<context position="12118" citStr="Bird, Loper, &amp; Klein, 2009" startWordPosition="1868" endWordPosition="1872">d. Stage L (SemEval clean up) is the final stage of the pipeline in Figure 1. Here we map, where possible, disorder CUIs from SNOMED CT. This stage also incorporates a process for identifying terms matched to the UMLS Metathesaurus semantic type finding (T033) that are considered CUI-less disorders in the SemEval gold standard. We use a structured SVM to classify the spans of findings to CUI-less disorder or not. We used the Cornell SVMstruct SVMhmm model. (Joachims, n.d.) Feature vectors are 4-word context-window (2 before and 2 after), bag-of-words stemmed with stopwords removed using NLTK (Bird, Loper, &amp; Klein, 2009). The SVM parameters were slack vs. weight vector magnitude (-c) of 25000 and epsilon (-e) of 0.5. This stage also removes all disorders found within section headers as well as annotations that reflect either spurious UMLS Metathesaurus mappings or problems with short-form expansion. 3 Results UtahPOET was not expected to perform well on either Task 1 or Task 2A. In both cases, our unwillingness to adhere to the gold standard CUIs caused us to score at the bottom of the pack. Sixteen teams competed in Task 1. We were 15th. Only 6 teams competed in Task 2A, we were last. Considering the contex</context>
</contexts>
<marker>Bird, Loper, Klein, 2009</marker>
<rawString>Bird, Steven, Loper, Edward, &amp; Klein, Edward. (2009). Natural Language Processing with Python. O’Reilly Media Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allen C Browne</author>
<author>Guy Divita</author>
<author>Alan R Aronson</author>
<author>Alexa T McCray</author>
</authors>
<date>2003</date>
<booktitle>UMLS Language and Vocabulary Tools: AMIA 2003 Open Source Expo,</booktitle>
<pages>798</pages>
<contexts>
<context position="5123" citStr="Browne, Divita, Aronson, &amp; McCray, 2003" startWordPosition="754" endWordPosition="760"> exploits world knowledge about the structure of English sentences. As such, it simplifies the processing of conjunctions and the aggregation of words and relationships, particularly those separated in the text, without supervised training. Retaining sentence structure allows dataset independence and latitude in future relationship finding. 1.2 Considerations for evaluation We propose a couple of considerations useful for evaluating NLP systems’ results under Task 14. The current evaluation includes strict matching to a Gold Standard set of Unified Medical Library System (UMLS) Metathesaurus (Browne, Divita, Aronson, &amp; McCray, 2003) CUIs. We think this standard leads to over-fitting the data, which leads to less generally useful systems. Clinical terms do not guarantee a one-to-one correspondence between term and referent. A point demonstrated by inter-annotator agreement of anything less than 100%. The redundancy of the UMLS Methathesaurus further undermines strict CUI mapping. Redundancy is best illustrated by body location mapping. Within the UMLS semantic types relevant to body location are T023 (Body part, organ or organ component) and T029 (Body location or region). We notice inconsistency in the Gold Standard in </context>
<context position="8721" citStr="Browne et al., 2003" startWordPosition="1313" endWordPosition="1316">Ms are used to expand short forms. The feature vectors for these SVMs include context vectors as bags-of-words and section headers. The short form-long form pairs are extracted from the ADAM dataset (Zhou, Torvik, &amp; Smalheiser, 2006) but limited to clinical terms. One classifier is trained for each ambiguous normalized short form that has multiple corresponding long forms. Classifiers are trained using the UMN clinical abbreviation and acronym sense inventory (Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014) and context information retrieved from PubMed case reports. The features are built on LVG (Browne et al., 2003) normalized bag of word, section header and short form string. The expanded short forms are inserted into the original text, preserving the original span information in UIMA annotations for span matching back to original text in the final stage. 2.3 Disorder detection in dorsal and ventral streams Stage G has two purposes: to identify single-word disorder terms and to limit the number of words that will be looked up in later stages. After stopwords are removed, each word in the document is stemmed using LVG (Browne et al., 2003) and fetched from a Lucene index made from the UMLS Metathesaurus </context>
</contexts>
<marker>Browne, Divita, Aronson, McCray, 2003</marker>
<rawString>Browne, Allen C., Divita, Guy, Aronson, Alan R., &amp; McCray, Alexa T. (2003). UMLS Language and Vocabulary Tools: AMIA 2003 Open Source Expo, 2003, 798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duy D A Bui</author>
<author>Qing Zeng-Treitler</author>
</authors>
<title>Learning regular expressions for clinical text classification.</title>
<date>2014</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>21</volume>
<issue>5</issue>
<pages>850--857</pages>
<contexts>
<context position="8073" citStr="Bui &amp; Zeng-Treitler, 2014" startWordPosition="1210" endWordPosition="1213"> qs_segment at the next carriage return, line break, or end-of-line character. The dotted line in Figure 1 signifies that it is a repeated process. 400 Figure 1. The overall UIMA pipeline for UtahPOET (please zoom for readability). 2.2 UtahPOET specific parallel ‘preprocessing’ UtahPOET has section header identification and short-form expansion processes that run parallel to the ‘pre-processing’ stages. These stages are E and F in Figure 1. In stage E regular expressions are used to identify section headers. The regular expression rules are found using automatic regular expression extraction (Bui &amp; Zeng-Treitler, 2014). In stage F, a series of SVMs are used to expand short forms. The feature vectors for these SVMs include context vectors as bags-of-words and section headers. The short form-long form pairs are extracted from the ADAM dataset (Zhou, Torvik, &amp; Smalheiser, 2006) but limited to clinical terms. One classifier is trained for each ambiguous normalized short form that has multiple corresponding long forms. Classifiers are trained using the UMN clinical abbreviation and acronym sense inventory (Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014) and context information retrieved from PubMed case reports. The</context>
</contexts>
<marker>Bui, Zeng-Treitler, 2014</marker>
<rawString>Bui, Duy D. A., &amp; Zeng-Treitler, Qing. (2014). Learning regular expressions for clinical text classification. Journal of the American Medical Informatics Association, 21(5), 850–857.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Chella</author>
<author>Massimo Cossentino</author>
<author>Salvatore Gaglio</author>
<author>Valeria Seidita</author>
</authors>
<title>A general theoretical framework for designing cognitive architectures: Hybrid and meta-level architectures for BICA. Biologically Inspired Cognitive Architectures,</title>
<date>2012</date>
<volume>2</volume>
<pages>100--108</pages>
<contexts>
<context position="2680" citStr="Chella, Cossentino, Gaglio, &amp; Seidita, 2012" startWordPosition="401" endWordPosition="407">istical machine learning (ML). We use ML and rule-based NLP components with demonstrated success in clinical information extraction arranged in an architecture inspired by well-documented findings with respect to cortical processing. Briefly, UtahPOET is inspired by findings related to: layered cognitive processes, the distinction between the dorsal and ventral language processing streams, and the phenomenon of iterative refinement. The type of layered (i.e., staged or hierarchical) processing we use shares much in common with traditional NLP and biologically inspired cognitive architectures (Chella, Cossentino, Gaglio, &amp; Seidita, 2012; Indurkhya &amp; Damerau, 2010; Sowa, 2010). We will discuss our system’s layering in the system description below. Our distinctive model of dorsal-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Com</context>
</contexts>
<marker>Chella, Cossentino, Gaglio, Seidita, 2012</marker>
<rawString>Chella, Antonio, Cossentino, Massimo, Gaglio, Salvatore, &amp; Seidita, Valeria. (2012). A general theoretical framework for designing cognitive architectures: Hybrid and meta-level architectures for BICA. Biologically Inspired Cognitive Architectures, 2(C), 100–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K ristina Patterson Doing-Harris</author>
<author>Igo Olga</author>
<author>Sean</author>
<author>John Hurdle</author>
</authors>
<title>Document sublanguage clustering to detect medical specialty in crossinstitutional clinical texts.</title>
<date>2013</date>
<booktitle>Proceedings of the 7th international workshop on Data and text mining in biomedical informatics, ACM,</booktitle>
<pages>9--12</pages>
<marker>Doing-Harris, Olga, Sean, Hurdle, 2013</marker>
<rawString>Doing-Harris, K.ristina Patterson, Olga, Igo, Sean, &amp; Hurdle, John. (2013). Document sublanguage clustering to detect medical specialty in crossinstitutional clinical texts. Proceedings of the 7th international workshop on Data and text mining in biomedical informatics, ACM, 9-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Dominey</author>
<author>Toshio Inui</author>
</authors>
<title>Cortico-striatal function in sentence comprehension: Insights from neurophysiology and modeling.</title>
<date>2009</date>
<journal>Cortex,</journal>
<volume>45</volume>
<issue>8</issue>
<pages>1012--1018</pages>
<contexts>
<context position="3372" citStr="Dominey &amp; Inui, 2009" startWordPosition="498" endWordPosition="501">ayering in the system description below. Our distinctive model of dorsal-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to u</context>
</contexts>
<marker>Dominey, Inui, 2009</marker>
<rawString>Dominey, Peter F., &amp; Inui, Toshio. (2009). Cortico-striatal function in sentence comprehension: Insights from neurophysiology and modeling. Cortex, 45(8), 1012–1018.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung-wei Fan</author>
<author>Elly W Yang</author>
<author>Min Jiang</author>
<author>Rashmi Prasad</author>
<author>Richard M Loomis</author>
<author>Daniel S Zisook</author>
</authors>
<title>Syntactic parsing of clinical text: guideline and corpus development with handling illformed sentences.</title>
<date>2013</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>20</volume>
<issue>6</issue>
<pages>1168--1177</pages>
<contexts>
<context position="4287" citStr="Fan et al., 2013" startWordPosition="640" endWordPosition="643">that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This resembles how humans ‘re-parse’ garden path sentences (McKoon &amp; Ratcliff, 2007). The UtahPOET approaches solving semantic extraction problems by enabling dependency parsing. However, ungrammatical text is common in clinical notes (Fan et al., 2013; Meystre, Savova, Kipper-Schuler, &amp; Hurdle, 2008). This text often “breaks” dependency parsers, so we process grammatical and ungrammatical text separately. Dependency parsing is useful because it exploits world knowledge about the structure of English sentences. As such, it simplifies the processing of conjunctions and the aggregation of words and relationships, particularly those separated in the text, without supervised training. Retaining sentence structure allows dataset independence and latitude in future relationship finding. 1.2 Considerations for evaluation We propose a couple of con</context>
</contexts>
<marker>Fan, Yang, Jiang, Prasad, Loomis, Zisook, 2013</marker>
<rawString>Fan, Jung-wei, Yang, Elly W., Jiang, Min, Prasad, Rashmi, Loomis, Richard M., Zisook, Daniel S., et al. (2013). Syntactic parsing of clinical text: guideline and corpus development with handling illformed sentences. Journal of the American Medical Informatics Association, 20(6), 1168-1177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernanda Ferreira</author>
<author>Nikole D Patson</author>
</authors>
<title>The “good enough” approach to language comprehension.</title>
<date>2007</date>
<journal>Language and Linguistics Compass,</journal>
<volume>1</volume>
<issue>1</issue>
<pages>71--83</pages>
<contexts>
<context position="16357" citStr="Ferreira &amp; Patson, 2007" startWordPosition="2591" endWordPosition="2594">so be helpful. We find support for our evaluation considerations above in CUI and body location mappings, which disagree with the gold standard. For example, if ‘shortness of breath’ is given the body location ‘breath,’ giving ‘vomiting’ to body location ‘vomitus’ and ‘drainage’ to location ‘body fluid discharge’ should be acceptable. UtahPOET is prone to near misses. We see these near misses as a type of graceful degradation, which is a hallmark of cognitive systems. Graceful degradation is the ability to function despite making errors. Ferreira and Patson call this “good enough” processing (Ferreira &amp; Patson, 2007). 4.2 Implications for cognitive architecture The hierarchical layers from psycholinguistics are lexical, syntactic and semantic processing, which proceed in that order. We do not adhere strictly to this hierarchy. Many cognitive scientists think a proper hierarchy is unlikely (Frank, Bod, &amp; Christiansen, 2012). We were inspired to separate prose and nonprose based on the ventral-dorsal distinction between grammatical and ungrammatical text. It is tempting to equate heuristics with ML and rules with specific if...then statements. The cognitive science literature indicates that this is a mistak</context>
</contexts>
<marker>Ferreira, Patson, 2007</marker>
<rawString>Ferreira, Fernanda, &amp; Patson, Nikole D. (2007). The “good enough” approach to language comprehension. Language and Linguistics Compass, 1(1-2), 71–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>UIMA: an architectural approach to unstructured information processing in the corporate research environment.</title>
<date>1999</date>
<journal>Natural Language Engineering,</journal>
<volume>10</volume>
<issue>3</issue>
<pages>327--348</pages>
<contexts>
<context position="6435" citStr="Ferrucci &amp; Lally, 1999" startWordPosition="961" endWordPosition="964">ture (T023)’ over “Pericardial body location (T029)’, while in another annotators preferred ‘Neck (T029)’ over ‘Entire neck (T023).’ Partial matches create problems as well. The Task evaluation only considers partial span matches correct if the CUI for the full match is reported. However, if the span is only partially matched the correct CUI should change. For example, the mapping ‘Left ventricular hypertrophy’ to C0149721, when partially matched with ‘Ventricular hypertrophy’ would seem to be more correctly mapped to C0340279. 2 System description The UtahPOET system is built in Apache UIMA (Ferrucci &amp; Lally, 1999). It has the layered structure common to NLP pipelines (see Figure 1). The pre-processing stage finds sentence boundaries (stages A), breaks the sentence into tokens (stage B), and assigns each token a part-of-speech (POS) tag (stage B). 2.1 Dorsal-ventral stream separation and iterative refinement After preprocessing, we add stages to begin dorsal and ventral separation and iterative refinement. In stage C, we divide dorsal and ventral streams by separating ungrammatical and grammatical text. We refer to ungrammatical text as nonprose qs_segments. Nonprose is differentiated from prose (well-f</context>
</contexts>
<marker>Ferrucci, Lally, 1999</marker>
<rawString>Ferrucci, David, &amp; Lally, Adam. (1999). UIMA: an architectural approach to unstructured information processing in the corporate research environment. Natural Language Engineering, 10(3-4), 327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan L Frank</author>
<author>Rens Bod</author>
<author>Morten H Christiansen</author>
</authors>
<title>How hierarchical is language use?</title>
<date>2012</date>
<journal>Proceedings of the Royal Society B: Biological Sciences,</journal>
<volume>279</volume>
<issue>1747</issue>
<pages>4522--4531</pages>
<contexts>
<context position="16668" citStr="Frank, Bod, &amp; Christiansen, 2012" startWordPosition="2633" endWordPosition="2638"> discharge’ should be acceptable. UtahPOET is prone to near misses. We see these near misses as a type of graceful degradation, which is a hallmark of cognitive systems. Graceful degradation is the ability to function despite making errors. Ferreira and Patson call this “good enough” processing (Ferreira &amp; Patson, 2007). 4.2 Implications for cognitive architecture The hierarchical layers from psycholinguistics are lexical, syntactic and semantic processing, which proceed in that order. We do not adhere strictly to this hierarchy. Many cognitive scientists think a proper hierarchy is unlikely (Frank, Bod, &amp; Christiansen, 2012). We were inspired to separate prose and nonprose based on the ventral-dorsal distinction between grammatical and ungrammatical text. It is tempting to equate heuristics with ML and rules with specific if...then statements. The cognitive science literature indicates that this is a mistake (Hahn &amp; Chater, 1998). All heuristics are thought to start as rule-based. The rule-based decision is overlearned to the point of automaticity and called a heuristic. Therefore we do not use ML components in only one path. Currently, UtahPOET leverages iterative refinement for sentence segmentation only. Once</context>
</contexts>
<marker>Frank, Bod, Christiansen, 2012</marker>
<rawString>Frank, Stefan L., Bod, Rens, &amp; Christiansen, Morten H. (2012). How hierarchical is language use? Proceedings of the Royal Society B: Biological Sciences, 279(1747), 4522-4531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike Hahn</author>
<author>Nick Chater</author>
</authors>
<title>Similarity and rules: distinct? Exhaustive? Empirically distinguishable?</title>
<date>1998</date>
<journal>Cognition,</journal>
<volume>65</volume>
<issue>2</issue>
<pages>197--230</pages>
<contexts>
<context position="16980" citStr="Hahn &amp; Chater, 1998" startWordPosition="2681" endWordPosition="2684">.2 Implications for cognitive architecture The hierarchical layers from psycholinguistics are lexical, syntactic and semantic processing, which proceed in that order. We do not adhere strictly to this hierarchy. Many cognitive scientists think a proper hierarchy is unlikely (Frank, Bod, &amp; Christiansen, 2012). We were inspired to separate prose and nonprose based on the ventral-dorsal distinction between grammatical and ungrammatical text. It is tempting to equate heuristics with ML and rules with specific if...then statements. The cognitive science literature indicates that this is a mistake (Hahn &amp; Chater, 1998). All heuristics are thought to start as rule-based. The rule-based decision is overlearned to the point of automaticity and called a heuristic. Therefore we do not use ML components in only one path. Currently, UtahPOET leverages iterative refinement for sentence segmentation only. Once we implement greater integration with long-term memory (LTM) representation, we will have the facility to recognize clashes and implement more extensive iterative refinement. With our ML components, we can clearly see how learning requires its own pathway. Each of these systems is trained outside the UtahPOET </context>
</contexts>
<marker>Hahn, Chater, 1998</marker>
<rawString>Hahn, Ulrike, &amp; Chater, Nick. (1998). Similarity and rules: distinct? Exhaustive? Empirically distinguishable? Cognition, 65(2-3), 197–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Hickok</author>
<author>David Poeppel</author>
</authors>
<title>Dorsal and ventral streams: a framework for understanding aspects of the functional anatomy of language.</title>
<date>2004</date>
<journal>Cognition,</journal>
<volume>92</volume>
<issue>1</issue>
<pages>67--99</pages>
<contexts>
<context position="3396" citStr="Hickok &amp; Poeppel, 2004" startWordPosition="502" endWordPosition="505">description below. Our distinctive model of dorsal-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a p</context>
</contexts>
<marker>Hickok, Poeppel, 2004</marker>
<rawString>Hickok, Gregory, &amp; Poeppel, David. (2004). Dorsal and ventral streams: a framework for understanding aspects of the functional anatomy of language. Cognition, 92(1-2), 67–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Indurkhya</author>
<author>Fred J Damerau</author>
</authors>
<date>2010</date>
<booktitle>Handbook of Natural Language Processing (Second.). Chapman and Hall. p. 168. Joachims, Thorston. (Ed.). Cornell SVMstruct.</booktitle>
<location>Re-</location>
<contexts>
<context position="2707" citStr="Indurkhya &amp; Damerau, 2010" startWordPosition="408" endWordPosition="411">rule-based NLP components with demonstrated success in clinical information extraction arranged in an architecture inspired by well-documented findings with respect to cortical processing. Briefly, UtahPOET is inspired by findings related to: layered cognitive processes, the distinction between the dorsal and ventral language processing streams, and the phenomenon of iterative refinement. The type of layered (i.e., staged or hierarchical) processing we use shares much in common with traditional NLP and biologically inspired cognitive architectures (Chella, Cossentino, Gaglio, &amp; Seidita, 2012; Indurkhya &amp; Damerau, 2010; Sowa, 2010). We will discuss our system’s layering in the system description below. Our distinctive model of dorsal-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics stru</context>
</contexts>
<marker>Indurkhya, Damerau, 2010</marker>
<rawString>Indurkhya, Nitin, &amp; Damerau, Fred J. (Eds.). (2010). Handbook of Natural Language Processing (Second.). Chapman and Hall. p. 168. Joachims, Thorston. (Ed.). Cornell SVMstruct. Re-</rawString>
</citation>
<citation valid="false">
<note>trieved January 30, 2015, from http://www.cs.cornell.edu/people/tj/svm_light/svm hmm.html</note>
<marker></marker>
<rawString>trieved January 30, 2015, from http://www.cs.cornell.edu/people/tj/svm_light/svm hmm.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillipp Kellmeyer</author>
<author>Wolfram Ziegler</author>
<author>Claudia Peschke</author>
<author>Eisenberger Juliane</author>
<author>Susanne Schnell</author>
<author>Annette Baumgaertner</author>
</authors>
<title>Frontoparietal dorsal and ventral pathways in the context of different linguistic manipulations.</title>
<date>2013</date>
<journal>Brain and Language,</journal>
<volume>127</volume>
<issue>2</issue>
<pages>241--250</pages>
<contexts>
<context position="3420" citStr="Kellmeyer et al., 2013" startWordPosition="506" endWordPosition="509">istinctive model of dorsal-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterati</context>
</contexts>
<marker>Kellmeyer, Ziegler, Peschke, Juliane, Schnell, Baumgaertner, 2013</marker>
<rawString>Kellmeyer, Phillipp, Ziegler, Wolfram, Peschke, Claudia, Juliane, Eisenberger, Schnell, Susanne, Baumgaertner, Annette, et al. (2013). Frontoparietal dorsal and ventral pathways in the context of different linguistic manipulations. Brain and Language, 127(2), 241–250.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jonathan Levy</author>
<author>Cyril Pernet</author>
<author>Sébastien Treserras</author>
<author>Kader Boulanouar</author>
<author>Florent Aubry</author>
<author>Jean-Fronçois Démonet</author>
<author>Pierre Celsis</author>
</authors>
<title>Testing for the dual-route cascade reading model in the brain: An fMRI Effective Connectivity Account of an Efficient Reading Style.</title>
<date>2009</date>
<journal>PLoS ONE,</journal>
<volume>4</volume>
<issue>8</issue>
<pages>6675</pages>
<location>McKoon, Gail, &amp; Ratcliff, Roger.</location>
<contexts>
<context position="3439" citStr="Levy et al., 2009" startWordPosition="510" endWordPosition="513">al-ventral processing streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This</context>
</contexts>
<marker>Levy, Pernet, Treserras, Boulanouar, Aubry, Démonet, Celsis, 2009</marker>
<rawString>Levy, Jonathan, Pernet, Cyril, Treserras, Sébastien, Boulanouar, Kader, Aubry, Florent, Démonet, Jean-Fronçois, &amp; Celsis, Pierre. (2009). Testing for the dual-route cascade reading model in the brain: An fMRI Effective Connectivity Account of an Efficient Reading Style. PLoS ONE, 4(8), e6675. McKoon, Gail, &amp; Ratcliff, Roger. (2007). Interactions of meaning and syntax: Implications for models of sentence comprehension. Journal of Memory and Language, 56(2), 270–290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul A Merolla</author>
<author>John V Arthur</author>
<author>Rodrigo Alvarez-Icaza</author>
<author>Andrew S Cassidy</author>
<author>Jun Sawada</author>
<author>Filipp Akopyan</author>
</authors>
<title>A million spikingneuron integrated circuit with a scalable communication network and interface.</title>
<date>2014</date>
<journal>Science,</journal>
<volume>345</volume>
<issue>6197</issue>
<pages>668--673</pages>
<contexts>
<context position="2015" citStr="Merolla et al., 2014" startWordPosition="307" endWordPosition="311">ches clinical NLP using a new, cognitively inspired architecture. We value dataset independence, so our design priorities do not completely overlap those encompassed by the goals of Task 14. We share the SemEval vision of extracting the full semantic content of clinical text. Our short-term goal, however, was to field test an early prototype of our new architecture and Task 14 provided a convenient and well-designed use case. 1.1 Cognitive inspirations Only the human brain is currently able to extract full semantic content from text. We propose an intermediate step between artificial neurons (Merolla et al., 2014; Sowa, 2010) and statistical machine learning (ML). We use ML and rule-based NLP components with demonstrated success in clinical information extraction arranged in an architecture inspired by well-documented findings with respect to cortical processing. Briefly, UtahPOET is inspired by findings related to: layered cognitive processes, the distinction between the dorsal and ventral language processing streams, and the phenomenon of iterative refinement. The type of layered (i.e., staged or hierarchical) processing we use shares much in common with traditional NLP and biologically inspired cog</context>
</contexts>
<marker>Merolla, Arthur, Alvarez-Icaza, Cassidy, Sawada, Akopyan, 2014</marker>
<rawString>Merolla, Paul A., Arthur, John V., Alvarez-Icaza, Rodrigo, Cassidy, Andrew S., Sawada, Jun, Akopyan, Filipp, et al. (2014). A million spikingneuron integrated circuit with a scalable communication network and interface. Science, 345(6197), 668–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stéphane M Meystre</author>
<author>Guergana K Savova</author>
<author>Karin C Kipper-Schuler</author>
<author>John F Hurdle</author>
</authors>
<title>Extracting information from textual documents in the electronic health record: a review of recent research.</title>
<date>2008</date>
<journal>Yearb Med Inform,</journal>
<volume>35</volume>
<pages>128--144</pages>
<contexts>
<context position="4336" citStr="Meystre, Savova, Kipper-Schuler, &amp; Hurdle, 2008" startWordPosition="644" endWordPosition="649">ous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This resembles how humans ‘re-parse’ garden path sentences (McKoon &amp; Ratcliff, 2007). The UtahPOET approaches solving semantic extraction problems by enabling dependency parsing. However, ungrammatical text is common in clinical notes (Fan et al., 2013; Meystre, Savova, Kipper-Schuler, &amp; Hurdle, 2008). This text often “breaks” dependency parsers, so we process grammatical and ungrammatical text separately. Dependency parsing is useful because it exploits world knowledge about the structure of English sentences. As such, it simplifies the processing of conjunctions and the aggregation of words and relationships, particularly those separated in the text, without supervised training. Retaining sentence structure allows dataset independence and latitude in future relationship finding. 1.2 Considerations for evaluation We propose a couple of considerations useful for evaluating NLP systems’ re</context>
</contexts>
<marker>Meystre, Savova, Kipper-Schuler, Hurdle, 2008</marker>
<rawString>Meystre, Stéphane M., Savova, Guergana K., Kipper-Schuler, Karin C., &amp; Hurdle, John F. (2008). Extracting information from textual documents in the electronic health record: a review of recent research. Yearb Med Inform, 35, 128–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungrim Moon</author>
<author>Serguei Pahkhomov</author>
<author>Nathan Liu</author>
<author>James O Ryan</author>
<author>Genevieve B Melton</author>
</authors>
<title>A sense inventory for clinical abbreviations and acronyms created using clinical notes and medical dictionary resources.</title>
<date>2014</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>299--307</pages>
<contexts>
<context position="8608" citStr="Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014" startWordPosition="1292" endWordPosition="1298">egular expression rules are found using automatic regular expression extraction (Bui &amp; Zeng-Treitler, 2014). In stage F, a series of SVMs are used to expand short forms. The feature vectors for these SVMs include context vectors as bags-of-words and section headers. The short form-long form pairs are extracted from the ADAM dataset (Zhou, Torvik, &amp; Smalheiser, 2006) but limited to clinical terms. One classifier is trained for each ambiguous normalized short form that has multiple corresponding long forms. Classifiers are trained using the UMN clinical abbreviation and acronym sense inventory (Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014) and context information retrieved from PubMed case reports. The features are built on LVG (Browne et al., 2003) normalized bag of word, section header and short form string. The expanded short forms are inserted into the original text, preserving the original span information in UIMA annotations for span matching back to original text in the final stage. 2.3 Disorder detection in dorsal and ventral streams Stage G has two purposes: to identify single-word disorder terms and to limit the number of words that will be looked up in later stages. After stopwords are removed, each word in the docu</context>
</contexts>
<marker>Moon, Pahkhomov, Liu, Ryan, Melton, 2014</marker>
<rawString>Moon, Sungrim, Pahkhomov, Serguei, Liu, Nathan, Ryan, James O., &amp; Melton, Genevieve B. (2014). A sense inventory for clinical abbreviations and acronyms created using clinical notes and medical dictionary resources. Journal of the American Medical Informatics Association, 21(2), 299– 307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cathy J Price</author>
</authors>
<title>Current themes in neuroimaging studies of reading.</title>
<date>2013</date>
<journal>Brain and Language,</journal>
<volume>125</volume>
<issue>2</issue>
<pages>131--133</pages>
<contexts>
<context position="3452" citStr="Price, 2013" startWordPosition="514" endWordPosition="515">ng streams comes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This resembles ho</context>
</contexts>
<marker>Price, 2013</marker>
<rawString>Price, Cathy J. (2013). Current themes in neuroimaging studies of reading. Brain and Language, 125(2), 131–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John F Sowa</author>
</authors>
<title>Biological and psycholinguistic influences on architectures for natural language processing.</title>
<date>2010</date>
<journal>Proceedings of the First Annual Meeting of the BICA Society, IOS Press, Incorporated,</journal>
<volume>221</volume>
<pages>131</pages>
<contexts>
<context position="2028" citStr="Sowa, 2010" startWordPosition="312" endWordPosition="313">g a new, cognitively inspired architecture. We value dataset independence, so our design priorities do not completely overlap those encompassed by the goals of Task 14. We share the SemEval vision of extracting the full semantic content of clinical text. Our short-term goal, however, was to field test an early prototype of our new architecture and Task 14 provided a convenient and well-designed use case. 1.1 Cognitive inspirations Only the human brain is currently able to extract full semantic content from text. We propose an intermediate step between artificial neurons (Merolla et al., 2014; Sowa, 2010) and statistical machine learning (ML). We use ML and rule-based NLP components with demonstrated success in clinical information extraction arranged in an architecture inspired by well-documented findings with respect to cortical processing. Briefly, UtahPOET is inspired by findings related to: layered cognitive processes, the distinction between the dorsal and ventral language processing streams, and the phenomenon of iterative refinement. The type of layered (i.e., staged or hierarchical) processing we use shares much in common with traditional NLP and biologically inspired cognitive archit</context>
</contexts>
<marker>Sowa, 2010</marker>
<rawString>Sowa, John F. (2010). Biological and psycholinguistic influences on architectures for natural language processing. Proceedings of the First Annual Meeting of the BICA Society, IOS Press, Incorporated, 221, 131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Traxler</author>
</authors>
<title>Introduction to Psycholinguistics.</title>
<date>2012</date>
<publisher>Wiley-Blackwell.</publisher>
<contexts>
<context position="3754" citStr="Traxler, 2012" startWordPosition="556" endWordPosition="557">th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This resembles how humans ‘re-parse’ garden path sentences (McKoon &amp; Ratcliff, 2007). The UtahPOET approaches solving semantic extraction problems by enabling dependency parsing. However, ungrammatical text is common in clinical notes (Fan et al., 2013; Meystre, Savova, Kipper-Schuler, &amp; Hurdle, 2008). This text often</context>
</contexts>
<marker>Traxler, 2012</marker>
<rawString>Traxler, Matthew. (2012). Introduction to Psycholinguistics. Wiley-Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen T Wu</author>
<author>Hongfang Liu</author>
<author>DDingcheng Li</author>
<author>Cui Tao</author>
<author>Mark A Musen</author>
<author>Christopher G Chute</author>
<author>Nigam H Shah</author>
</authors>
<title>Unified Medical Language System term occurrences in clinical notes: a large-scale corpus analysis.</title>
<date>2012</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>19</volume>
<pages>149--56</pages>
<contexts>
<context position="9386" citStr="Wu et al., 2012" startWordPosition="1427" endWordPosition="1430"> form string. The expanded short forms are inserted into the original text, preserving the original span information in UIMA annotations for span matching back to original text in the final stage. 2.3 Disorder detection in dorsal and ventral streams Stage G has two purposes: to identify single-word disorder terms and to limit the number of words that will be looked up in later stages. After stopwords are removed, each word in the document is stemmed using LVG (Browne et al., 2003) and fetched from a Lucene index made from the UMLS Metathesaurus restricted to the clinical sources indicated in (Wu et al., 2012), including SNOMEDCT, MSH, NCI, RDC, MTH, SNMI, MDR, SCTSPA, CHV, CCPS. The sematic types included reflect disorders, body locations, and modifiers. Modifiers include qualitative, quantitative and spatial concepts. For the identification of multi-word terms and context slot filling in stages H and I, we split the text segments based on the previously described nonprose (stage H) prose (stage I) distinction. The dorsal stream is associated with rule-based processing. In this case the rule associated with nonprose qs_segments, is that adjacent unigram disorder terms are likely to be part of a mu</context>
</contexts>
<marker>Wu, Liu, Li, Tao, Musen, Chute, Shah, 2012</marker>
<rawString>Wu, Stephen T., Liu, Hongfang, Li, DDingcheng, Tao, Cui, Musen, Mark A., Chute, Christopher G., &amp; Shah, Nigam H. (2012). Unified Medical Language System term occurrences in clinical notes: a large-scale corpus analysis. Journal of the American Medical Informatics Association, 19(e1), e149–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Yeatman</author>
<author>Andreas M Rauschecker</author>
<author>Brian A Wandell</author>
</authors>
<title>Anatomy of the visual word form area: adjacent cortical circuits and longrange white matter connections.</title>
<date>2013</date>
<journal>Brain and Language,</journal>
<volume>125</volume>
<issue>2</issue>
<pages>146--155</pages>
<contexts>
<context position="3491" citStr="Yeatman, Rauschecker, &amp; Wandell, 2013" startWordPosition="516" endWordPosition="520">mes from psycholinguistic findings. The interpretation of unfamiliar or ungrammatical constructions, rule-based processing, and learning have been linked to dorsal processing streams in the brain. Ventral processing streams handle familiar, expected, regular con399 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 399–405, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics structions as well as heuristic-type processing (Dominey &amp; Inui, 2009; Hickok &amp; Poeppel, 2004; Kellmeyer et al., 2013; Levy et al., 2009; Price, 2013; Yeatman, Rauschecker, &amp; Wandell, 2013). Iterative refinement is the repeated application of top-down processing during bottom-up processing. In Cognitive Science top-down and bottom-up refer, in essence, to processes that rely on previous knowledge and those that do not, respectively (Traxler, 2012). Top-down processing is evident in each stage of an NLP pipeline, e.g., “knowing” how the end of a sentence is marked. We see combining world knowledge with the outcome of one processing stage and then using that to update the outcome of a previous stage as iterative refinement. This resembles how humans ‘re-parse’ garden path sentenc</context>
</contexts>
<marker>Yeatman, Rauschecker, Wandell, 2013</marker>
<rawString>Yeatman, Jason D., Rauschecker, Andreas M., &amp; Wandell, Brian A. (2013). Anatomy of the visual word form area: adjacent cortical circuits and longrange white matter connections. Brain and Language, 125(2), 146–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Zhou</author>
<author>Vetle I Torvik</author>
<author>Neil R Smalheiser</author>
</authors>
<title>ADAM: another database of abbreviations in MEDLINE.</title>
<date>2006</date>
<journal>Bioinformatics,</journal>
<volume>22</volume>
<issue>22</issue>
<pages>2813--2818</pages>
<contexts>
<context position="8333" citStr="Zhou, Torvik, &amp; Smalheiser, 2006" startWordPosition="1253" endWordPosition="1257">parallel ‘preprocessing’ UtahPOET has section header identification and short-form expansion processes that run parallel to the ‘pre-processing’ stages. These stages are E and F in Figure 1. In stage E regular expressions are used to identify section headers. The regular expression rules are found using automatic regular expression extraction (Bui &amp; Zeng-Treitler, 2014). In stage F, a series of SVMs are used to expand short forms. The feature vectors for these SVMs include context vectors as bags-of-words and section headers. The short form-long form pairs are extracted from the ADAM dataset (Zhou, Torvik, &amp; Smalheiser, 2006) but limited to clinical terms. One classifier is trained for each ambiguous normalized short form that has multiple corresponding long forms. Classifiers are trained using the UMN clinical abbreviation and acronym sense inventory (Moon, Pahkhomov, Liu, Ryan, &amp; Melton, 2014) and context information retrieved from PubMed case reports. The features are built on LVG (Browne et al., 2003) normalized bag of word, section header and short form string. The expanded short forms are inserted into the original text, preserving the original span information in UIMA annotations for span matching back to </context>
</contexts>
<marker>Zhou, Torvik, Smalheiser, 2006</marker>
<rawString>Zhou, Wei, Torvik, Vetle I., &amp; Smalheiser, Neil R. (2006). ADAM: another database of abbreviations in MEDLINE. Bioinformatics, 22(22), 2813–2818.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>