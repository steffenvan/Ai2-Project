<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000329">
<title confidence="0.990232">
Exploring dialect phonetic variation using PARAFAC
</title>
<author confidence="0.997298">
Jelena Proki´c Tim Van de Cruys
</author>
<affiliation confidence="0.9096555">
University of Groningen University of Groningen
The Netherlands The Netherlands
</affiliation>
<email confidence="0.978649">
j.prokic@rug.nl t.van.de.cruys@rug.nl
</email>
<sectionHeader confidence="0.997146" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999469541666667">
In this paper we apply the multi-way de-
composition method PARAFAC in order to
detect the most prominent sound changes
in dialect variation. We investigate various
phonetic patterns, both in stressed and un-
stressed syllables. We proceed from regu-
lar sound correspondences which are auto-
matically extracted from the aligned tran-
scriptions and analyzed using PARAFAC.
This enables us to analyze simultaneously
the co-occurrence patterns of all sound
correspondences found in the data set and
determine the most important factors of
the variation. The first ten dimensions are
examined in more detail by recovering the
geographical distribution of the extracted
correspondences. We also compare dia-
lect divisions based on the extracted cor-
respondences to the divisions based on the
whole data set and to the traditional schol-
arship as well. The results show that PAR-
AFAC can be successfully used to detect
the linguistic basis of the automatically
obtained dialect divisions.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929342857143">
Dialectometry is a multidisciplinary field that uses
quantitative methods in the analysis of dialect
data. From the very beginning, most of the re-
search in dialectometry has been focused on the
identification of dialect groups and development
of methods that would tell us how similar (or dif-
ferent) one variety is when compared to the neigh-
boring varieties. Dialect data is usually analyzed
on the aggregate level by summing up the differ-
ences between various language varieties into a
single number. The main drawback of aggregate
analyses is that it does not expose the underlying
linguistic structure, i.e. the specific linguistic ele-
ments that contributed to the differences between
the dialects. In recent years there have been sev-
eral attempts to automatically extract linguistic
basis from the aggregate analysis, i.e. to determine
which linguistic features are responsible for which
dialect divisions. Although interesting for dialect-
ology itself, this kind of research is very important
in the investigation of sound variation and change,
both on the synchronic and diachronic level.
The paper is structured as follows. In the next
section, we discuss a number of earlier approaches
to the problem of identifying underlying linguistic
structure in dialect divisions. In section 3, we give
a description of the dialect data used in this re-
search. Section 4 then describes the methodology
of our method, explaining our data representation
using tensors, our three-way factorization method,
and the design of our data set. In section 5, the res-
ults of our method are discussed, examining the
values that come out of our factorization method
in a number of ways. Section 6, then, draws con-
clusions and gives some pointers for future work.
</bodyText>
<sectionHeader confidence="0.998534" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999891444444444">
In order to detect the linguistic basis of dialect
variation Nerbonne (2006) applied factor analysis
to the results of the dialectometric analysis of
southern American dialects. The analysis is based
on 1132 different vowels found in the data. 204
vowel positions are investigated, where a vowel
position is, e.g., the first vowel in the word’Wash-
ington’ or the second vowel in the word ’thirty’.
Factor analysis has shown that 3 factors are most
important, explaining 35% of the total amount of
variation. However, this approach is based only on
vowel positions in specific words.
Proki´c (2007) extracted the 10 most frequent
non-identical sound correspondences from the
aligned word transcriptions. Based on the relative
frequency of each of these correspondences each
site in the data set was assigned a correspondence
index. Higher value of this index indicates sites
</bodyText>
<page confidence="0.995096">
46
</page>
<bodyText confidence="0.979379651162791">
Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 46–53,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
where the presence of a certain sound is domin-
ant with respect to some sound alternation. Al-
though successful in describing some important
sound alternations in the dialect variation, it ex-
amines only the 10 most frequent sound alterna-
tions without testing patterns of variation between
different sound correspondences.
Shackleton (2007) applies principal compon-
ent analysis (PCA) to a group of self constructed
articulation-based features. All segments found in
the data are translated into vectors of numerical
features and analyzed using PCA. Based on the
component scores for features, different groups
of varieties (in which a certain group of features
is present) are identified. We note that the main
drawback of this approach is the subjectivity of the
feature selection and segment quantification.
Wieling and Nerbonne (2009) used a bipart-
ite spectral graph partitioning method to simul-
taneously cluster dialect varieties and sound cor-
respondences. Although promising, this method
compares the pronunciation of every site only to
the reference site, rather than comparing it to all
other sites. Another drawback of this method is
that it does not use any information on the frequen-
cies of sound correspondences, but instead em-
ploys binary features to represent whether a cer-
tain correspondence is present at a certain site or
not.
In this paper we present an approach that tries
to overcome some of the problems described in
the previous approaches. It proceeds from auto-
matically aligned phonetic transcriptions, where
pronunciations of every site are compared to the
corresponding pronunciations for all other sites.
Extracted sound correspondences are analyzed us-
ing the multi-way decomposition method PARA-
FAC. The method allows us to make generaliza-
tions over multi-way co-occurrence data, and to
look simultaneously at the co-occurrence patterns
of all sound correspondences found in the data set.
</bodyText>
<sectionHeader confidence="0.988685" genericHeader="method">
3 Data description
</sectionHeader>
<bodyText confidence="0.966493571428572">
The data set used in this paper consists of phon-
etic transcriptions of 152 words collected at 197
sites evenly distributed all over Bulgaria. It is part
of the project Buldialect – Measuring Linguistic
unity and diversity in Europe. Phonetic transcrip-
tions include various diacritics and suprasegment-
als, making the total number of unique phones in
the data set 95: 43 vowels and 52 consonants.1
The sign for primary stress is moved to a cor-
responding vowel, so that there is a distinction
between stressed and unstressed vowels. Vowels
are also marked for their length. Sonorants /r/ and
/l/ have a mark for syllabicity and for stress in case
they are syllabic. Here we list all phones present
in the data set:
&amp;quot;A, e, i, &amp;quot;e, @, &amp;quot;E, 7, &amp;quot;6, A, I, o, &amp;quot;o, u, &amp;quot;A:, U, &amp;quot;u:, &amp;quot;7, &amp;quot;@,
&amp;quot;a, &amp;quot;i, &amp;quot;I, &amp;quot;e:, E, &amp;quot;O, &amp;quot;2, &amp;quot;i:, &amp;quot;u, e:, 1, &amp;quot;1, &amp;quot;o:, &amp;quot;E:, &amp;quot;7:, u:, A:,
y, &amp;quot;a:, a, o:, 7:, &amp;quot;U, &amp;quot;y, &amp;quot;I:, j, g, n, nj, é, r, w, x, rj, h,
&gt;
C, f, s, v, c¸, F, p, Ù, m, k, &gt; ťC, pj, c,l,lj,t,tj,S,d,dj,
ćý,
scription of all features can be found in
et
al. (2009). For all villages only one speaker was
recorded. In the data set, for some villages there
were multiple pronunciations of the same word. In
this reasearch we have randomly picked only one
per every
</bodyText>
<equation confidence="0.4689145">
Proki´c
village.
</equation>
<sectionHeader confidence="0.999711" genericHeader="method">
4 Methodology
</sectionHeader>
<subsectionHeader confidence="0.999144">
4.1 Tensors
</subsectionHeader>
<bodyText confidence="0.99360725">
although a tensor can easily be generalized to
more than three modes.
Tensor operations come with their own algeb-
raic machinery. We refer the interested reader to
Kolda and Bader (2009) for a thorough an
–
d in-
sightful introduction to the subject.
Each of the 152 words in the data set shows
phonetic variation, with some words displaying
more than one change. There are in total 39 dif-
ferent dialectal features that are represented in the
data set, with each of the features being present in
a similar number of words. For example, the re-
flexes of Old Bulgarian vowels that show dialect
variation are represented with the same or nearly
the same number of words. Amore detailed de-
Co-occurrence data (such as the sound corres-
pondences used in this research) are usually rep-
resented in the form of a matrix. This form is per-
fectly suited to represent two-way co-occurrence
data, but for co-occurrence data beyond two
modes, we need a more general representation.
The generalization of a matrix is called a tensor.
A tensor is able to encode co-occurrence data of
any n modes. Figure 1 shows a graphical com-
parison of a matrix and a tensor with three modes
data is publicly available and can be down-
</bodyText>
<footnote confidence="0.5937885">
loaded fr
1The
om http://www.bultreebank.org/
BulDialects/index.html
</footnote>
<equation confidence="0.793825333333333">
&amp;quot;r&amp;quot;, vj, &gt;dz,Z, ý, &gt; ţ,r&amp;quot;,cj,z,sj,b,gj, mj, l&amp;quot;,zj,&amp;quot;l&amp;quot;,kj,bj,
&gt; dz, fj, î
&gt;
</equation>
<page confidence="0.943744">
47
</page>
<figure confidence="0.995012333333333">
sites
sites cc
sites
</figure>
<figureCaption confidence="0.999963">
Figure 1: Matrix representation vs. tensor representation.
</figureCaption>
<subsectionHeader confidence="0.929114">
4.2 PARAFAC
</subsectionHeader>
<bodyText confidence="0.99995616">
In order to create a succinct and generalized
model, the co-occurrence data are often ana-
lyzed with dimensionality reduction techniques.
One of the best known dimensionality reduction
techniques is principal component analysis (PCA,
Pearson (1901)). PCA transforms the data into a
new coordinate system, yielding the best possible
fit in a least squares sense given a limited num-
ber of dimensions. Singular value decomposition
(SVD) is the generalization of the eigenvalue de-
composition used in PCA (Wall et al., 2003).
To be able to make generalizations among the
three-way co-occurrence data, we apply a statist-
ical dimensionality reduction technique called par-
allel factor analysis (PARAFAC, Harshman (1970);
Carroll and Chang (1970)), a technique that has
been sucessfully applied in areas such as psycho-
logy and bio-chemistry. PARAFAC is a multilinear
analogue of SVD. The key idea is to minimize the
sum of squares between the original tensor and the
factorized model of the tensor. For the three mode
case of a tensor T E RD1xD2xD3 this gives the
objective function in 1, where k is the number of
dimensions in the factorized model and o denotes
the outer product.
</bodyText>
<equation confidence="0.999079666666667">
min 11 T −
xi∈RD1,yi∈RD2,zi∈RD3
(1)
</equation>
<bodyText confidence="0.9999651875">
The algorithm results in three matrices, indic-
ating the loadings of each mode on the factorized
dimensions. The model is represented graphically
in Figures 2 and 3. Figure 2 visualizes the fact
that the PARAFAC decomposition consists of the
summation over the outer products of n (in this
case three) vectors. Figure 3 represents the three
resulting matrices that come out of the factoriza-
tion, indicating the loadings of each mode on the
factorized dimensions. We will be using the latter
representation in our research.
Computationally, the PARAFAC model is fitted
by applying an alternating least-squares algorithm.
In each iteration, two of the modes are fixed and
the third one is fitted in a least squares sense. This
process is repeated until convergence.2
</bodyText>
<subsectionHeader confidence="0.99605">
4.3 Sound correspondences
</subsectionHeader>
<bodyText confidence="0.999783823529412">
In order to detect the most important sound vari-
ation within Bulgarian dialects, we proceed from
extracting all sound correspondences from the
automatically aligned word transcriptions. All
transcriptions were pairwise aligned using the
Levenshtein algorithm (Levenshtein, 1965) as im-
plemented in the program L04.3 The Leven-
shtein algorithm is a dynamic programming al-
gorithm used to measure the differences between
two strings. The distance between two strings is
the smallest number of insertions, deletions, and
substitutions needed to transform one string to the
other. In this work all three operations were as-
signed the same value, namely 1. The algorithm is
also directly used to align two sequences. An ex-
ample showing two aligned pronunciations of the
word vъlna /vxlna/ ‘wool’ is given in Figure 4.4
</bodyText>
<figure confidence="0.54465">
v &apos;x - n a
v &apos;a l n a
</figure>
<figureCaption confidence="0.7778055">
Figure 4: Example of two pairwise aligned word
transcriptions.
From the aligned transcriptions for all words
and all villages in the data set we first extracted
</figureCaption>
<footnote confidence="0.996507571428571">
2The algorithm has been implemented in MATLAB, using
the Tensor Toolbox for sparse tensor calculations (Bader and
Kolda, 2009).
3http://www.let.rug.nl/kleiweg/L04
4For some pairs of transcriptions there are two or more
possible alignments, i.e. alignments that have the same cost.
In these cases we have randomly picked only one of them.
</footnote>
<equation confidence="0.89291475">
2
xi o yi o zi �F
k
i=1
</equation>
<page confidence="0.993819">
48
</page>
<figureCaption confidence="0.999886">
Figure 2: Graphical representation of PARAFAC as the sum of outer products.
Figure 3: Graphical representation of the PARAFAC as three loadings matrices.
</figureCaption>
<figure confidence="0.990554">
k c-pmMerces
�
sites
k
sites
comsporMences
</figure>
<bodyText confidence="0.999911730769231">
all corresponding non-identical sounds. For ex-
ample, from the aligned transcriptions in Figure 4
we would extract the following sound pairs: [&amp;quot;7]-
[&amp;quot;A], [-]-[l], [A]-[@]. The hyphen (‘-’) stands for a
missing (i.e. inserted or deleted) sound, and in fur-
ther analyses it is treated the same as any sound
in the data set. For each pair of corresponding
sounds from the data set we counted how often it
appeared in the aligned transcriptions for each pair
of villages separately. In total we extracted 907
sound correspondences and stored the information
on each of them in a separate matrix. Every matrix
records the distances between each two villages
in the data set, measured as the number of times
a certain phonetic alternation is recorded while
comparing pronunciations from these sites.
Since we are interested in analyzing all sound
correspondences simultaneously, we merged the
information from all 907 two-mode matrices into
a three-mode tensor n × n × v, where n represents
the sites in the data set, and v represents the sound
alternations. By arranging our data in a cube in-
stead of a matrix, we are able to look into several
sets of variables simultaneously. We are especially
interested in the loadings for the third mode, that
contains the values for the sound correspondences.
</bodyText>
<sectionHeader confidence="0.999955" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999965055555556">
In order to detect the most prominent sound cor-
respondences we analyzed the three-mode tensor
described in the previous section using a PARAFAC
factorization with k = 10 dimensions. In Table 5
we present only the first five dimensions extracted
by the algorithm. The final model fits 44% of the
original data. The contribution of the first extrac-
ted dimension (dim1) to the final fit of the model
is the largest – 23.81 per cent – while the next four
dimensions contribute to the final fit with similar
percentages: dim2 with 10.63 per cent, dim3 with
9.50 per cent, dim4 with 9.26 per cent, and dim5
with 9.09 per cent. Dimensions six to ten contrib-
ute in the range from 8.66 per cent to 6.98 per cent.
For every dimension we extracted the twenty
sound correspondences with the highest scores. In
the first dimension we find 11 pairs involving vow-
els and 9 involving consonant variation. The three
sound correspondences with the highest scores
are the [A]-[@], [o]-[u], and [e]-[i] alternations.
This finding corresponds well with the traditional
scholarly views on Bulgarian phonetics (Wood
and Pettersson, 1988; Barnes, 2006) where we find
that in unstressed syllables mid vowels [e] and [o]
raise to neutralize with the high vowels [i] and [u].
The low vowel [a] raises to merge with [@].
For every sound alternation we also check their
geographical distribution. We do so by applying
the following procedure. From the aligned pairs
of transcriptions we extract corresponding pairs of
sounds for every alternation. We count how many
times each of the two sounds appears in the tran-
scriptions for every village. Thus, for every pair of
sound correspondences, we can create two maps
that show the distribution of each of the sounds
separately. On the map of Bulgaria these values
</bodyText>
<page confidence="0.999825">
49
</page>
<tableCaption confidence="0.9718255">
Table 1: First five dimensions for the sound cor-
respondences.
</tableCaption>
<table confidence="0.995035190476191">
dim1 dim2 dim3 dim4 dim5
[A]-[@] [@]-[7] [u]-[o] [A]-[@] [e]-[i]
[u]-[o] [e]-[i] [A]-[7] [@]-[7] [i]-[&amp;quot;e]
[e]-[i] [&amp;quot;e]-[&amp;quot;E] [A]-[@] [U]-[o] [e]-[@]
[-]-[j] [-]-[j] [7]-[e] [e]-[@] [r]-[rj]
[e]-[&amp;quot;e] [S]-[C] [e]-[&amp;quot;e] [d]-[dj] [d]-[dj]
[S]-[C] [&gt;Ù]-[&gt;ťC] [&amp;quot;e]-[&amp;quot;E] [v]-[vj] [&amp;quot;e]-[&amp;quot;A]
[&gt;Ù]-[&gt;ťC] [&amp;quot;A]-[&amp;quot;E] [-]-[j] [n]-[nj] [-]-[j]
[&amp;quot;e]-[&amp;quot;E] [r]-[rj] [&amp;quot;e]-[&amp;quot;A] [-]-[j] [&amp;quot;o]-[u]
[n]-[nj] [l]-[lj] [e]-[i] [&amp;quot;e]-[&amp;quot;E] [l]-[lj]
[A]-[7] [e]-[@] [n]-[nj] [l]-[lj] [v]-[vj]
[e]-[@] [d]-[dj] [r]-[rj] [t]-[tj] [u]-[o]
[&amp;quot;A]-[&amp;quot;E] [n]-[nj] [&gt;Ù]-[&gt;ťC] [&amp;quot;e]-[&amp;quot;A] [n]-[nj]
[&amp;quot;e]-[&amp;quot;A] [u]-[U] [&amp;quot;7]-[&amp;quot;A] [e]-[&amp;quot;e] [-]-[v]
[d]-[dj] [&amp;quot;7]-[&amp;quot;O] [-]-[r] [S]-[C] [&amp;quot;7]-[@]
[7]-[e] [@]-[&amp;quot;A] [S]-[C] [&gt;Ù]-[&gt;ťC] [u]-[U]
[l]-[lj] [7]-[e] [l]-[lj] [r]-[rj] [&gt;Ù]-[&gt;ťC]
[v]-[vj] [&amp;quot;o]-[u] [u]-[e] [p]-[pj] [&amp;quot;A]-[&amp;quot;E]
[r]-[rj] [Z]-[ý] [-]-[&amp;quot;7] [Z]-[ý] [A]-[&amp;quot;7]
[Z]-[ý] [i]-[@] [v]-[-] [@]-[&amp;quot;A] [@]-[&amp;quot;A]
[&amp;quot;7]-[&amp;quot;O] [v]-[vj] [A]-[&amp;quot;7] [e]-[i] [b]-[bj]
</table>
<bodyText confidence="0.944796911392405">
are represented using a gradual color, which en-
ables us to see not only the geographic distribution
of a certain sound but also how regular it is in a
given sound alternation. The highest scoring sites
are coloured black and the lowest scoring sites are
coloured white.
In Figure 5 we see the geographical distribu-
tion of the first three extracted correspondences.
The first two alternations [A]-[@] and [o]-[u] have
almost the same geographical distribution and di-
vide the country into west and east. While in the
west there is a clear presence of vowels [A] and [o],
in the east those vowels would be pronounced as
[@] and [u]. The division into east and west corres-
ponds well with the so-called jat line, which is,
according to traditional dialectologists (Stojkov,
2002) the main dialect border in Bulgaria. On the
maps in Figure 5 we represent it with the black line
that roughly divides Bulgaria into east and west.
The third correspondence follows a slightly dif-
ferent pattern: mid vowel [e] is present not only
west of the jat line, but also in the southern part
of the country, in the region of Rodopi mountains.
In the central and northeastern areas this sound is
pronounced as high vowel [i]. For all three sound
correspondences we see a clear two-way division
of the country, with almost all sites being charac-
terized by one of the two pronunciations, which,
as we shall see later, is not always the case due
to multiple reflections of some sounds at certain
positions.
We also note that the distribution of the sound
correspondences that involve soft consonants and
their counterparts have the same east-west dis-
tribution (see Figure 6). In the first dimension
we find the following consonants and their pal-
atal counterparts [n], [d], [l], [v] and [r], but be-
cause of space limitations we show maps only
for three correspondences. The east-west division
also emerges with respect to the distribution of the
[A]-[7] and [&amp;quot;e]-[&amp;quot;A] sounds.
Unlike the correspondences mentioned before,
&gt;
the [S]-[C], [Ù]-
the south part of the country as a separate zone.
As shown on the maps in Figure 7, the southern
part of the country (the region of Rodopi moun-
tains) is characterized by a soft pronunciation of
&gt;
[S], [Ù] and [Z]. In traditonal literature on Bul-
garain dialectology (Stojkov, 2002), we also find
&gt;
that soft pronunciation of [S], [Ù] and [Z] is one of
the most important phonetic features of the variet-
ies in the Rodopi zone. Based on the correspond-
ences extracted in the first dimension, this area
is also defined by the presence of the vowel [&amp;quot;E]
in stressed syllables ([&amp;quot;e]-[&amp;quot;E] and [&amp;quot;A]-[&amp;quot;E] corres-
pondences).
In some extracted correspondences, only one of
the sounds has a geographically coherent distri-
bution, like in the case of the [7]-[e] pair where
[e] is found in the west and south, while the [7]
sound is only sporadically present in the central
region. This kind of asymmetrical distribution is
also found with respect to the pair [A]-[7].
Most of the sound correspondences in the first
dimension either divide the country along the jat
line or separate the Rodopi area from the rest of the
varieties. The only two exceptions are the [-]-[j]
and [&amp;quot;7]-[&amp;quot;O] pairs. They both define the southwest
area as a separate zone, while the northwest shares
its pronunciation of the sound in question with the
eastern part of the country.
We use the first 20 correspondences from the
first dimension and perform k-means clustering in
order to check which dialect areas would emerge
based on this limited set of sound correspond-
[&gt;ťC], and [Z]-[ý] pairs are defining
</bodyText>
<page confidence="0.978343">
50
</page>
<figureCaption confidence="0.9999615">
Figure 5: [A]-[@] (left), [o]-[u] (middle), [e]-[i] (right) sound correspondences.
Figure 6: [d]-[dj] (left), [v]-[vj] (middle), [r]-[rj] (right) sound correspondences.
</figureCaption>
<bodyText confidence="0.999955657894737">
ences. The results of the 2-way, 3-way and 4-way
clustering are given in Figure 8.
In two-way clustering the algorithm detects an
east-west split approximately along the jat line,
slightly moved to the east. This fully corres-
ponds to the traditional dialectology but also to
the results obtained using Levenshtein algorithm
on the whole data set where only east, west and
south varieties could be asserted with great con-
fidence (Proki´c and Nerbonne, 2008). In Figure 9
we present the dialect divisions that we get if the
distances between the sites are calculated using
whole word transcriptions instead of only the 20
most prominent sound correspondences. We no-
tice a high correspondence between the two ana-
lyses at the two- and three-level division. On the
level of four and more groups, the two analyses
start detecting different groups. In the analysis
based on 20 sound correspondences, southern dia-
lects are divided into smaller and smaller groups,
while in the analysis based on the whole data set,
the area in the west – near the Serbian border –
emerges as the fourth group. This is no surprise, as
the first 20 extracted correspondences do not con-
tain any sounds typical only for this western area.
In order to compare two divisions of sites, we
calculated the adjusted Rand index (Hubert and
Arabie, 1985). The adjusted Rand index (ARI) is
used in classification for comparing two different
partitions of a finite set of objects. It is based on
the Rand index (Rand, 1971), one of the most pop-
ular measures for comparing the degree to which
partitions agree (in classification). Value 1 of the
ARI indicates that two classifications match per-
fectly, while value 0 means that two partitions do
not agree on any pair of points. For both two-
level and three-level divisions of the sites the ARI
for two classifications is 0.84. We also compared
</bodyText>
<page confidence="0.990904">
51
</page>
<figure confidence="0.883843">
� �
</figure>
<figureCaption confidence="0.9998475">
Figure 7: [ ]-[p] (left), [1]- [*] (middle), [3]-[4 (right) sound correspondences.
Figure 8: Dialect varieties detected by k-means clustering algorithm based on the first 20 sound corres-
pondences in the first dimension.
Figure 9: Dialect varieties detected by k-means clustering algorithm based on all word transcriptions.
</figureCaption>
<bodyText confidence="0.996792025641026">
both of the classifications to the classification of
the sites done by Stojkov (2002). For the classi-
fication based on the first dimension extracted by
PARAFAC, ARI is 0.73 for two-way and 0.64 for
the three-way division. ARI score for the clas-
sification based on whole word transcriptions is
0.69 for two-way and 0.62 for three-way. As in-
dicated by ARI the two classifications correspond
with a high degree to each other, but to the tra-
ditional classification as well. We note that two-
way classification based on the extracted sound
correspondences corresponds higher to the tradi-
tional classification than classification that takes
all sounds into account.
We conclude that the sound correspondences
detected by PARAFAC form the linguistic basis
of the two-way and three-way divisions of Bul-
garian dialect area. Using the PARAFAC method
we are able to detect that the most important sound
changes on which two-way division is based are
[o]-[u], [a]-[a] and palatal pronunciation of con-
sonants. In the three-way division of sites done
by k-means, the area in the south of the country
appears as the third most important dialect zone.
In the twenty investigated sound correspondences
�
we find that the soft pronunciation of [ ],[1] and
[3] sounds is typical only for the varieties in this
area. Apart from divisions that divide the country
into west and east, including the southern variet-
ies, we also detect sound correspondences whose
distribution groups together western and southern
areas.
We also analyzed in more depth sound corres-
pondences extracted in other dimensions by the
PARAFAC algorithm. Most of the correspondences
found in the first dimension, also reappear in the
following nine dimensions. Closer inspection of
the language groups obtained using information
</bodyText>
<page confidence="0.994533">
52
</page>
<bodyText confidence="0.9999762">
from these dimensions show that eastern, western
and southern varieties are the only three that are
identified. No other dialect areas were detected
based on the sound correspondences from these
nine dimensions.
</bodyText>
<sectionHeader confidence="0.999149" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999545142857143">
In this paper we have applied PARAFAC in the task
of detecting the linguistic basis of dialect phonetic
variation. The distances between varieties were
expressed as a numerical vector that records in-
formation on all sound correspondences found in
the data set. Using PARAFAC we were able to ex-
tract the most important sound correspondences.
Based on the 20 most important sound correspond-
ences we performed clustering of all sites in the
data set and were able to detect three groups of
sites. As found in traditional literature on Bul-
garian dialects, these three dialects are the main
dialect groups in Bulgaria. Using the aggregate
approach on the same data set, the same three dia-
lects were the only groups in the data that could be
asserted with high confidence. We conclude that
this approach is successful in extracting underly-
ing linguistic structure in dialect variation, while
at the same time overcoming some of the problems
found in the earlier approaches to this problem.
In future work sounds in the data set could be
defined in a more sophisticated way, using some
kind of feature representation. Also, the role of
stress should be examined in more depth, since
there are different patterns of change in stressed
in unstressed syllables. We would also like to ex-
tend the method and examine more than just two
sound correspondences at a time.
</bodyText>
<sectionHeader confidence="0.999319" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999124242424242">
Brett W. Bader and Tamara G. Kolda. 2009. Matlab
tensor toolbox version 2.3. http://csmr.ca.
sandia.gov/∼tgkolda/TensorToolbox/,
July.
Jonathan Barnes. 2006. Strength and Weakness at
the Interface: Positional Neutralization in Phonetics
and Phonology. Walter de Gruyter GmbH, Berlin.
J. Douglas Carroll and Jih-Jie Chang. 1970. Analysis
of individual differences in multidimensional scal-
ing via an n-way generalization of ”eckart-young”
decomposition. Psychometrika, 35:283–319.
Richard A. Harshman. 1970. Foundations of the par-
afac procedure: models and conditions for an ”ex-
planatory” multi-mode factor analysis. In UCLA
Working Papers in Phonetics, volume 16, pages 1–
84, Los Angeles. University of California.
Lawrence Hubert and Phipps Arabie. 1985. Compar-
ing partitions. Journal of Classification, 2:193–218.
Tamara G. Kolda and Brett W. Bader. 2009. Tensor de-
compositions and applications. SIAMReview, 51(3),
September.
Vladimir Levenshtein. 1965. Binary codes capable of
correcting deletions, insertions and reversals. Dok-
lady Akademii Nauk SSSR, 163:845–848.
John Nerbonne. 2006. Identifying linguistic structure
in aggregate comparison. Literary and Linguistic
Computing, 21(4):463–476.
Karl Pearson. 1901. On lines and planes of closest
fit to systems of points in space. Philosophical
Magazine, 2(6):559–572.
Jelena Proki´c and John Nerbonne. 2008. Recogniz-
ing groups among dialects. International Journal of
Humanities and Arts Computing, Special Issue on
Language Variation ed. by John Nerbonne, Char-
lotte Gooskens, Sebastian K¨urschner, and Ren´ee van
Bezooijen:153–172.
Jelena Proki´c, John Nerbonne, Vladimir Zhobov, Petya
Osenova, Krili Simov, Thomas Zastrow, and Erhard
Hinrichs. 2009. The Computational Analysis of
Bulgarian Dialect Pronunciation. Serdica Journal of
Computing, 3:269–298.
Jelena Proki´c. 2007. Identifying linguistic structure
in a quantitative analysis of dialect pronunciation.
In Proceedings of the ACL 2007 Student Research
Workshop, pages 61–66.
William M. Rand. 1971. Objective criteria for the eval-
uation of clustering methods. Journal of American
Statistical Association, 66(336):846–850, Decem-
ber.
Robert G. Shackleton. 2007. Phonetic variation in the
traditional English dialects. Journal of English Lin-
guistics, 35(1):30–102.
Stojko Stojkov. 2002. Bulgarska dialektologiya.
Sofia, 4th ed.
Michael E. Wall, Andreas Rechtsteiner, and Luis M.
Rocha, 2003. Singular Value Decomposition and
Principal Component Analysis, chapter 5, pages 91–
109. Kluwer, Norwell, MA, Mar.
Martijn Wieling and John Nerbonne. 2009. Bipart-
ite spectral graph partitioning to co-cluster varieties
and sound correspondences in dialectology. In Text
Graphs 4, Workshop at the 47th Meeting of the Asso-
ciation for Computational Linguistics, pages 14–22.
Sidney A. J. Wood and Thore Pettersson. 1988. Vowel
reduction in Bulgarian: the phonetic data and model
experiments. Folia Linguistica, 22(3-4):239–262.
</reference>
<page confidence="0.999351">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898638">
<title confidence="0.997122">Exploring dialect phonetic variation using PARAFAC</title>
<author confidence="0.95096">Jelena Proki´c Tim Van_de_Cruys</author>
<affiliation confidence="0.999755">University of Groningen University of Groningen</affiliation>
<address confidence="0.975795">The Netherlands The Netherlands</address>
<email confidence="0.97733">j.prokic@rug.nlt.van.de.cruys@rug.nl</email>
<abstract confidence="0.99949208">In this paper we apply the multi-way demethod order to detect the most prominent sound changes in dialect variation. We investigate various phonetic patterns, both in stressed and unstressed syllables. We proceed from regular sound correspondences which are automatically extracted from the aligned tranand analyzed using This enables us to analyze simultaneously the co-occurrence patterns of all sound correspondences found in the data set and determine the most important factors of the variation. The first ten dimensions are examined in more detail by recovering the geographical distribution of the extracted correspondences. We also compare dialect divisions based on the extracted correspondences to the divisions based on the whole data set and to the traditional scholas well. The results show that be successfully used to detect the linguistic basis of the automatically obtained dialect divisions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Brett W Bader</author>
<author>Tamara G Kolda</author>
</authors>
<title>Matlab tensor toolbox version 2.3.</title>
<date>2009</date>
<note>http://csmr.ca. sandia.gov/∼tgkolda/TensorToolbox/,</note>
<contexts>
<context position="11752" citStr="Bader and Kolda, 2009" startWordPosition="1900" endWordPosition="1903">s, deletions, and substitutions needed to transform one string to the other. In this work all three operations were assigned the same value, namely 1. The algorithm is also directly used to align two sequences. An example showing two aligned pronunciations of the word vъlna /vxlna/ ‘wool’ is given in Figure 4.4 v &apos;x - n a v &apos;a l n a Figure 4: Example of two pairwise aligned word transcriptions. From the aligned transcriptions for all words and all villages in the data set we first extracted 2The algorithm has been implemented in MATLAB, using the Tensor Toolbox for sparse tensor calculations (Bader and Kolda, 2009). 3http://www.let.rug.nl/kleiweg/L04 4For some pairs of transcriptions there are two or more possible alignments, i.e. alignments that have the same cost. In these cases we have randomly picked only one of them. 2 xi o yi o zi �F k i=1 48 Figure 2: Graphical representation of PARAFAC as the sum of outer products. Figure 3: Graphical representation of the PARAFAC as three loadings matrices. k c-pmMerces � sites k sites comsporMences all corresponding non-identical sounds. For example, from the aligned transcriptions in Figure 4 we would extract the following sound pairs: [&amp;quot;7]- [&amp;quot;A], [-]-[l], [A</context>
</contexts>
<marker>Bader, Kolda, 2009</marker>
<rawString>Brett W. Bader and Tamara G. Kolda. 2009. Matlab tensor toolbox version 2.3. http://csmr.ca. sandia.gov/∼tgkolda/TensorToolbox/, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Barnes</author>
</authors>
<title>Strength and Weakness at the Interface: Positional Neutralization</title>
<date>2006</date>
<booktitle>in Phonetics and Phonology. Walter de Gruyter GmbH,</booktitle>
<location>Berlin.</location>
<contexts>
<context position="14618" citStr="Barnes, 2006" startWordPosition="2379" endWordPosition="2380"> dim2 with 10.63 per cent, dim3 with 9.50 per cent, dim4 with 9.26 per cent, and dim5 with 9.09 per cent. Dimensions six to ten contribute in the range from 8.66 per cent to 6.98 per cent. For every dimension we extracted the twenty sound correspondences with the highest scores. In the first dimension we find 11 pairs involving vowels and 9 involving consonant variation. The three sound correspondences with the highest scores are the [A]-[@], [o]-[u], and [e]-[i] alternations. This finding corresponds well with the traditional scholarly views on Bulgarian phonetics (Wood and Pettersson, 1988; Barnes, 2006) where we find that in unstressed syllables mid vowels [e] and [o] raise to neutralize with the high vowels [i] and [u]. The low vowel [a] raises to merge with [@]. For every sound alternation we also check their geographical distribution. We do so by applying the following procedure. From the aligned pairs of transcriptions we extract corresponding pairs of sounds for every alternation. We count how many times each of the two sounds appears in the transcriptions for every village. Thus, for every pair of sound correspondences, we can create two maps that show the distribution of each of the s</context>
</contexts>
<marker>Barnes, 2006</marker>
<rawString>Jonathan Barnes. 2006. Strength and Weakness at the Interface: Positional Neutralization in Phonetics and Phonology. Walter de Gruyter GmbH, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Douglas Carroll</author>
<author>Jih-Jie Chang</author>
</authors>
<title>Analysis of individual differences in multidimensional scaling via an n-way generalization of ”eckart-young” decomposition.</title>
<date>1970</date>
<tech>Psychometrika,</tech>
<pages>35--283</pages>
<contexts>
<context position="9371" citStr="Carroll and Chang (1970)" startWordPosition="1509" endWordPosition="1512">ty reduction techniques. One of the best known dimensionality reduction techniques is principal component analysis (PCA, Pearson (1901)). PCA transforms the data into a new coordinate system, yielding the best possible fit in a least squares sense given a limited number of dimensions. Singular value decomposition (SVD) is the generalization of the eigenvalue decomposition used in PCA (Wall et al., 2003). To be able to make generalizations among the three-way co-occurrence data, we apply a statistical dimensionality reduction technique called parallel factor analysis (PARAFAC, Harshman (1970); Carroll and Chang (1970)), a technique that has been sucessfully applied in areas such as psychology and bio-chemistry. PARAFAC is a multilinear analogue of SVD. The key idea is to minimize the sum of squares between the original tensor and the factorized model of the tensor. For the three mode case of a tensor T E RD1xD2xD3 this gives the objective function in 1, where k is the number of dimensions in the factorized model and o denotes the outer product. min 11 T − xi∈RD1,yi∈RD2,zi∈RD3 (1) The algorithm results in three matrices, indicating the loadings of each mode on the factorized dimensions. The model is represe</context>
</contexts>
<marker>Carroll, Chang, 1970</marker>
<rawString>J. Douglas Carroll and Jih-Jie Chang. 1970. Analysis of individual differences in multidimensional scaling via an n-way generalization of ”eckart-young” decomposition. Psychometrika, 35:283–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard A Harshman</author>
</authors>
<title>Foundations of the parafac procedure: models and conditions for an ”explanatory” multi-mode factor analysis.</title>
<date>1970</date>
<booktitle>In UCLA Working Papers in Phonetics,</booktitle>
<volume>16</volume>
<pages>1--84</pages>
<institution>Los Angeles. University of California.</institution>
<contexts>
<context position="9345" citStr="Harshman (1970)" startWordPosition="1507" endWordPosition="1508">with dimensionality reduction techniques. One of the best known dimensionality reduction techniques is principal component analysis (PCA, Pearson (1901)). PCA transforms the data into a new coordinate system, yielding the best possible fit in a least squares sense given a limited number of dimensions. Singular value decomposition (SVD) is the generalization of the eigenvalue decomposition used in PCA (Wall et al., 2003). To be able to make generalizations among the three-way co-occurrence data, we apply a statistical dimensionality reduction technique called parallel factor analysis (PARAFAC, Harshman (1970); Carroll and Chang (1970)), a technique that has been sucessfully applied in areas such as psychology and bio-chemistry. PARAFAC is a multilinear analogue of SVD. The key idea is to minimize the sum of squares between the original tensor and the factorized model of the tensor. For the three mode case of a tensor T E RD1xD2xD3 this gives the objective function in 1, where k is the number of dimensions in the factorized model and o denotes the outer product. min 11 T − xi∈RD1,yi∈RD2,zi∈RD3 (1) The algorithm results in three matrices, indicating the loadings of each mode on the factorized dimens</context>
</contexts>
<marker>Harshman, 1970</marker>
<rawString>Richard A. Harshman. 1970. Foundations of the parafac procedure: models and conditions for an ”explanatory” multi-mode factor analysis. In UCLA Working Papers in Phonetics, volume 16, pages 1– 84, Los Angeles. University of California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Hubert</author>
<author>Phipps Arabie</author>
</authors>
<title>Comparing partitions.</title>
<date>1985</date>
<journal>Journal of Classification,</journal>
<pages>2--193</pages>
<contexts>
<context position="21314" citStr="Hubert and Arabie, 1985" startWordPosition="3458" endWordPosition="3461">ween the two analyses at the two- and three-level division. On the level of four and more groups, the two analyses start detecting different groups. In the analysis based on 20 sound correspondences, southern dialects are divided into smaller and smaller groups, while in the analysis based on the whole data set, the area in the west – near the Serbian border – emerges as the fourth group. This is no surprise, as the first 20 extracted correspondences do not contain any sounds typical only for this western area. In order to compare two divisions of sites, we calculated the adjusted Rand index (Hubert and Arabie, 1985). The adjusted Rand index (ARI) is used in classification for comparing two different partitions of a finite set of objects. It is based on the Rand index (Rand, 1971), one of the most popular measures for comparing the degree to which partitions agree (in classification). Value 1 of the ARI indicates that two classifications match perfectly, while value 0 means that two partitions do not agree on any pair of points. For both twolevel and three-level divisions of the sites the ARI for two classifications is 0.84. We also compared 51 � � Figure 7: [ ]-[p] (left), [1]- [*] (middle), [3]-[4 (righ</context>
</contexts>
<marker>Hubert, Arabie, 1985</marker>
<rawString>Lawrence Hubert and Phipps Arabie. 1985. Comparing partitions. Journal of Classification, 2:193–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara G Kolda</author>
<author>Brett W Bader</author>
</authors>
<title>Tensor decompositions and applications.</title>
<date>2009</date>
<journal>SIAMReview,</journal>
<volume>51</volume>
<issue>3</issue>
<contexts>
<context position="7384" citStr="Kolda and Bader (2009)" startWordPosition="1185" endWordPosition="1188"> u:, A:, y, &amp;quot;a:, a, o:, 7:, &amp;quot;U, &amp;quot;y, &amp;quot;I:, j, g, n, nj, é, r, w, x, rj, h, &gt; C, f, s, v, c¸, F, p, Ù, m, k, &gt; ťC, pj, c,l,lj,t,tj,S,d,dj, ćý, scription of all features can be found in et al. (2009). For all villages only one speaker was recorded. In the data set, for some villages there were multiple pronunciations of the same word. In this reasearch we have randomly picked only one per every Proki´c village. 4 Methodology 4.1 Tensors although a tensor can easily be generalized to more than three modes. Tensor operations come with their own algebraic machinery. We refer the interested reader to Kolda and Bader (2009) for a thorough an – d insightful introduction to the subject. Each of the 152 words in the data set shows phonetic variation, with some words displaying more than one change. There are in total 39 different dialectal features that are represented in the data set, with each of the features being present in a similar number of words. For example, the reflexes of Old Bulgarian vowels that show dialect variation are represented with the same or nearly the same number of words. Amore detailed deCo-occurrence data (such as the sound correspondences used in this research) are usually represented in </context>
</contexts>
<marker>Kolda, Bader, 2009</marker>
<rawString>Tamara G. Kolda and Brett W. Bader. 2009. Tensor decompositions and applications. SIAMReview, 51(3), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1965</date>
<booktitle>Doklady Akademii Nauk SSSR,</booktitle>
<pages>163--845</pages>
<contexts>
<context position="10911" citStr="Levenshtein, 1965" startWordPosition="1758" endWordPosition="1759">dimensions. We will be using the latter representation in our research. Computationally, the PARAFAC model is fitted by applying an alternating least-squares algorithm. In each iteration, two of the modes are fixed and the third one is fitted in a least squares sense. This process is repeated until convergence.2 4.3 Sound correspondences In order to detect the most important sound variation within Bulgarian dialects, we proceed from extracting all sound correspondences from the automatically aligned word transcriptions. All transcriptions were pairwise aligned using the Levenshtein algorithm (Levenshtein, 1965) as implemented in the program L04.3 The Levenshtein algorithm is a dynamic programming algorithm used to measure the differences between two strings. The distance between two strings is the smallest number of insertions, deletions, and substitutions needed to transform one string to the other. In this work all three operations were assigned the same value, namely 1. The algorithm is also directly used to align two sequences. An example showing two aligned pronunciations of the word vъlna /vxlna/ ‘wool’ is given in Figure 4.4 v &apos;x - n a v &apos;a l n a Figure 4: Example of two pairwise aligned word</context>
</contexts>
<marker>Levenshtein, 1965</marker>
<rawString>Vladimir Levenshtein. 1965. Binary codes capable of correcting deletions, insertions and reversals. Doklady Akademii Nauk SSSR, 163:845–848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>Identifying linguistic structure in aggregate comparison.</title>
<date>2006</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>21--4</pages>
<contexts>
<context position="3034" citStr="Nerbonne (2006)" startWordPosition="469" endWordPosition="470"> underlying linguistic structure in dialect divisions. In section 3, we give a description of the dialect data used in this research. Section 4 then describes the methodology of our method, explaining our data representation using tensors, our three-way factorization method, and the design of our data set. In section 5, the results of our method are discussed, examining the values that come out of our factorization method in a number of ways. Section 6, then, draws conclusions and gives some pointers for future work. 2 Previous work In order to detect the linguistic basis of dialect variation Nerbonne (2006) applied factor analysis to the results of the dialectometric analysis of southern American dialects. The analysis is based on 1132 different vowels found in the data. 204 vowel positions are investigated, where a vowel position is, e.g., the first vowel in the word’Washington’ or the second vowel in the word ’thirty’. Factor analysis has shown that 3 factors are most important, explaining 35% of the total amount of variation. However, this approach is based only on vowel positions in specific words. Proki´c (2007) extracted the 10 most frequent non-identical sound correspondences from the ali</context>
</contexts>
<marker>Nerbonne, 2006</marker>
<rawString>John Nerbonne. 2006. Identifying linguistic structure in aggregate comparison. Literary and Linguistic Computing, 21(4):463–476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Pearson</author>
</authors>
<title>On lines and planes of closest fit to systems of points in space.</title>
<date>1901</date>
<journal>Philosophical Magazine,</journal>
<volume>2</volume>
<issue>6</issue>
<contexts>
<context position="8882" citStr="Pearson (1901)" startWordPosition="1435" endWordPosition="1436">odes. Figure 1 shows a graphical comparison of a matrix and a tensor with three modes data is publicly available and can be downloaded fr 1The om http://www.bultreebank.org/ BulDialects/index.html &amp;quot;r&amp;quot;, vj, &gt;dz,Z, ý, &gt; ţ,r&amp;quot;,cj,z,sj,b,gj, mj, l&amp;quot;,zj,&amp;quot;l&amp;quot;,kj,bj, &gt; dz, fj, î &gt; 47 sites sites cc sites Figure 1: Matrix representation vs. tensor representation. 4.2 PARAFAC In order to create a succinct and generalized model, the co-occurrence data are often analyzed with dimensionality reduction techniques. One of the best known dimensionality reduction techniques is principal component analysis (PCA, Pearson (1901)). PCA transforms the data into a new coordinate system, yielding the best possible fit in a least squares sense given a limited number of dimensions. Singular value decomposition (SVD) is the generalization of the eigenvalue decomposition used in PCA (Wall et al., 2003). To be able to make generalizations among the three-way co-occurrence data, we apply a statistical dimensionality reduction technique called parallel factor analysis (PARAFAC, Harshman (1970); Carroll and Chang (1970)), a technique that has been sucessfully applied in areas such as psychology and bio-chemistry. PARAFAC is a mu</context>
</contexts>
<marker>Pearson, 1901</marker>
<rawString>Karl Pearson. 1901. On lines and planes of closest fit to systems of points in space. Philosophical Magazine, 2(6):559–572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jelena Proki´c</author>
<author>John Nerbonne</author>
</authors>
<title>Recognizing groups among dialects.</title>
<date>2008</date>
<booktitle>International Journal of Humanities and Arts Computing, Special Issue on Language Variation</booktitle>
<editor>ed. by John Nerbonne, Charlotte Gooskens, Sebastian K¨urschner, and Ren´ee van Bezooijen:153–172.</editor>
<marker>Proki´c, Nerbonne, 2008</marker>
<rawString>Jelena Proki´c and John Nerbonne. 2008. Recognizing groups among dialects. International Journal of Humanities and Arts Computing, Special Issue on Language Variation ed. by John Nerbonne, Charlotte Gooskens, Sebastian K¨urschner, and Ren´ee van Bezooijen:153–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jelena Proki´c</author>
<author>John Nerbonne</author>
<author>Vladimir Zhobov</author>
<author>Petya Osenova</author>
<author>Krili Simov</author>
<author>Thomas Zastrow</author>
<author>Erhard Hinrichs</author>
</authors>
<title>The Computational Analysis of Bulgarian Dialect Pronunciation.</title>
<date>2009</date>
<journal>Serdica Journal of Computing,</journal>
<pages>3--269</pages>
<marker>Proki´c, Nerbonne, Zhobov, Osenova, Simov, Zastrow, Hinrichs, 2009</marker>
<rawString>Jelena Proki´c, John Nerbonne, Vladimir Zhobov, Petya Osenova, Krili Simov, Thomas Zastrow, and Erhard Hinrichs. 2009. The Computational Analysis of Bulgarian Dialect Pronunciation. Serdica Journal of Computing, 3:269–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jelena Proki´c</author>
</authors>
<title>Identifying linguistic structure in a quantitative analysis of dialect pronunciation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL 2007 Student Research Workshop,</booktitle>
<pages>61--66</pages>
<marker>Proki´c, 2007</marker>
<rawString>Jelena Proki´c. 2007. Identifying linguistic structure in a quantitative analysis of dialect pronunciation. In Proceedings of the ACL 2007 Student Research Workshop, pages 61–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Rand</author>
</authors>
<title>Objective criteria for the evaluation of clustering methods.</title>
<date>1971</date>
<journal>Journal of American Statistical Association,</journal>
<volume>66</volume>
<issue>336</issue>
<contexts>
<context position="21481" citStr="Rand, 1971" startWordPosition="3489" endWordPosition="3490">nd correspondences, southern dialects are divided into smaller and smaller groups, while in the analysis based on the whole data set, the area in the west – near the Serbian border – emerges as the fourth group. This is no surprise, as the first 20 extracted correspondences do not contain any sounds typical only for this western area. In order to compare two divisions of sites, we calculated the adjusted Rand index (Hubert and Arabie, 1985). The adjusted Rand index (ARI) is used in classification for comparing two different partitions of a finite set of objects. It is based on the Rand index (Rand, 1971), one of the most popular measures for comparing the degree to which partitions agree (in classification). Value 1 of the ARI indicates that two classifications match perfectly, while value 0 means that two partitions do not agree on any pair of points. For both twolevel and three-level divisions of the sites the ARI for two classifications is 0.84. We also compared 51 � � Figure 7: [ ]-[p] (left), [1]- [*] (middle), [3]-[4 (right) sound correspondences. Figure 8: Dialect varieties detected by k-means clustering algorithm based on the first 20 sound correspondences in the first dimension. Figu</context>
</contexts>
<marker>Rand, 1971</marker>
<rawString>William M. Rand. 1971. Objective criteria for the evaluation of clustering methods. Journal of American Statistical Association, 66(336):846–850, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert G Shackleton</author>
</authors>
<title>Phonetic variation in the traditional English dialects.</title>
<date>2007</date>
<journal>Journal of English Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<contexts>
<context position="4329" citStr="Shackleton (2007)" startWordPosition="668" endWordPosition="669">respondences each site in the data set was assigned a correspondence index. Higher value of this index indicates sites 46 Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 46–53, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics where the presence of a certain sound is dominant with respect to some sound alternation. Although successful in describing some important sound alternations in the dialect variation, it examines only the 10 most frequent sound alternations without testing patterns of variation between different sound correspondences. Shackleton (2007) applies principal component analysis (PCA) to a group of self constructed articulation-based features. All segments found in the data are translated into vectors of numerical features and analyzed using PCA. Based on the component scores for features, different groups of varieties (in which a certain group of features is present) are identified. We note that the main drawback of this approach is the subjectivity of the feature selection and segment quantification. Wieling and Nerbonne (2009) used a bipartite spectral graph partitioning method to simultaneously cluster dialect varieties and so</context>
</contexts>
<marker>Shackleton, 2007</marker>
<rawString>Robert G. Shackleton. 2007. Phonetic variation in the traditional English dialects. Journal of English Linguistics, 35(1):30–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stojko Stojkov</author>
</authors>
<date>2002</date>
<note>Bulgarska dialektologiya. Sofia, 4th ed.</note>
<contexts>
<context position="17018" citStr="Stojkov, 2002" startWordPosition="2738" endWordPosition="2739">nd alternation. The highest scoring sites are coloured black and the lowest scoring sites are coloured white. In Figure 5 we see the geographical distribution of the first three extracted correspondences. The first two alternations [A]-[@] and [o]-[u] have almost the same geographical distribution and divide the country into west and east. While in the west there is a clear presence of vowels [A] and [o], in the east those vowels would be pronounced as [@] and [u]. The division into east and west corresponds well with the so-called jat line, which is, according to traditional dialectologists (Stojkov, 2002) the main dialect border in Bulgaria. On the maps in Figure 5 we represent it with the black line that roughly divides Bulgaria into east and west. The third correspondence follows a slightly different pattern: mid vowel [e] is present not only west of the jat line, but also in the southern part of the country, in the region of Rodopi mountains. In the central and northeastern areas this sound is pronounced as high vowel [i]. For all three sound correspondences we see a clear two-way division of the country, with almost all sites being characterized by one of the two pronunciations, which, as </context>
<context position="18539" citStr="Stojkov, 2002" startWordPosition="2998" endWordPosition="2999"> the following consonants and their palatal counterparts [n], [d], [l], [v] and [r], but because of space limitations we show maps only for three correspondences. The east-west division also emerges with respect to the distribution of the [A]-[7] and [&amp;quot;e]-[&amp;quot;A] sounds. Unlike the correspondences mentioned before, &gt; the [S]-[C], [Ù]- the south part of the country as a separate zone. As shown on the maps in Figure 7, the southern part of the country (the region of Rodopi mountains) is characterized by a soft pronunciation of &gt; [S], [Ù] and [Z]. In traditonal literature on Bulgarain dialectology (Stojkov, 2002), we also find &gt; that soft pronunciation of [S], [Ù] and [Z] is one of the most important phonetic features of the varieties in the Rodopi zone. Based on the correspondences extracted in the first dimension, this area is also defined by the presence of the vowel [&amp;quot;E] in stressed syllables ([&amp;quot;e]-[&amp;quot;E] and [&amp;quot;A]-[&amp;quot;E] correspondences). In some extracted correspondences, only one of the sounds has a geographically coherent distribution, like in the case of the [7]-[e] pair where [e] is found in the west and south, while the [7] sound is only sporadically present in the central region. This kind of a</context>
<context position="22265" citStr="Stojkov (2002)" startWordPosition="3617" endWordPosition="3618">fectly, while value 0 means that two partitions do not agree on any pair of points. For both twolevel and three-level divisions of the sites the ARI for two classifications is 0.84. We also compared 51 � � Figure 7: [ ]-[p] (left), [1]- [*] (middle), [3]-[4 (right) sound correspondences. Figure 8: Dialect varieties detected by k-means clustering algorithm based on the first 20 sound correspondences in the first dimension. Figure 9: Dialect varieties detected by k-means clustering algorithm based on all word transcriptions. both of the classifications to the classification of the sites done by Stojkov (2002). For the classification based on the first dimension extracted by PARAFAC, ARI is 0.73 for two-way and 0.64 for the three-way division. ARI score for the classification based on whole word transcriptions is 0.69 for two-way and 0.62 for three-way. As indicated by ARI the two classifications correspond with a high degree to each other, but to the traditional classification as well. We note that twoway classification based on the extracted sound correspondences corresponds higher to the traditional classification than classification that takes all sounds into account. We conclude that the sound</context>
</contexts>
<marker>Stojkov, 2002</marker>
<rawString>Stojko Stojkov. 2002. Bulgarska dialektologiya. Sofia, 4th ed.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael E Wall</author>
<author>Andreas Rechtsteiner</author>
<author>Luis M Rocha</author>
</authors>
<date>2003</date>
<booktitle>Singular Value Decomposition and Principal Component Analysis, chapter 5,</booktitle>
<pages>91--109</pages>
<publisher>Kluwer,</publisher>
<location>Norwell, MA,</location>
<contexts>
<context position="9153" citStr="Wall et al., 2003" startWordPosition="1478" endWordPosition="1481"> î &gt; 47 sites sites cc sites Figure 1: Matrix representation vs. tensor representation. 4.2 PARAFAC In order to create a succinct and generalized model, the co-occurrence data are often analyzed with dimensionality reduction techniques. One of the best known dimensionality reduction techniques is principal component analysis (PCA, Pearson (1901)). PCA transforms the data into a new coordinate system, yielding the best possible fit in a least squares sense given a limited number of dimensions. Singular value decomposition (SVD) is the generalization of the eigenvalue decomposition used in PCA (Wall et al., 2003). To be able to make generalizations among the three-way co-occurrence data, we apply a statistical dimensionality reduction technique called parallel factor analysis (PARAFAC, Harshman (1970); Carroll and Chang (1970)), a technique that has been sucessfully applied in areas such as psychology and bio-chemistry. PARAFAC is a multilinear analogue of SVD. The key idea is to minimize the sum of squares between the original tensor and the factorized model of the tensor. For the three mode case of a tensor T E RD1xD2xD3 this gives the objective function in 1, where k is the number of dimensions in </context>
</contexts>
<marker>Wall, Rechtsteiner, Rocha, 2003</marker>
<rawString>Michael E. Wall, Andreas Rechtsteiner, and Luis M. Rocha, 2003. Singular Value Decomposition and Principal Component Analysis, chapter 5, pages 91– 109. Kluwer, Norwell, MA, Mar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martijn Wieling</author>
<author>John Nerbonne</author>
</authors>
<title>Bipartite spectral graph partitioning to co-cluster varieties and sound correspondences in dialectology.</title>
<date>2009</date>
<booktitle>In Text Graphs 4, Workshop at the 47th Meeting of the Association for Computational Linguistics,</booktitle>
<pages>14--22</pages>
<contexts>
<context position="4826" citStr="Wieling and Nerbonne (2009)" startWordPosition="742" endWordPosition="745"> most frequent sound alternations without testing patterns of variation between different sound correspondences. Shackleton (2007) applies principal component analysis (PCA) to a group of self constructed articulation-based features. All segments found in the data are translated into vectors of numerical features and analyzed using PCA. Based on the component scores for features, different groups of varieties (in which a certain group of features is present) are identified. We note that the main drawback of this approach is the subjectivity of the feature selection and segment quantification. Wieling and Nerbonne (2009) used a bipartite spectral graph partitioning method to simultaneously cluster dialect varieties and sound correspondences. Although promising, this method compares the pronunciation of every site only to the reference site, rather than comparing it to all other sites. Another drawback of this method is that it does not use any information on the frequencies of sound correspondences, but instead employs binary features to represent whether a certain correspondence is present at a certain site or not. In this paper we present an approach that tries to overcome some of the problems described in </context>
</contexts>
<marker>Wieling, Nerbonne, 2009</marker>
<rawString>Martijn Wieling and John Nerbonne. 2009. Bipartite spectral graph partitioning to co-cluster varieties and sound correspondences in dialectology. In Text Graphs 4, Workshop at the 47th Meeting of the Association for Computational Linguistics, pages 14–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney A J Wood</author>
<author>Thore Pettersson</author>
</authors>
<title>Vowel reduction in Bulgarian: the phonetic data and model experiments. Folia Linguistica,</title>
<date>1988</date>
<pages>22--3</pages>
<contexts>
<context position="14603" citStr="Wood and Pettersson, 1988" startWordPosition="2375" endWordPosition="2378">t with similar percentages: dim2 with 10.63 per cent, dim3 with 9.50 per cent, dim4 with 9.26 per cent, and dim5 with 9.09 per cent. Dimensions six to ten contribute in the range from 8.66 per cent to 6.98 per cent. For every dimension we extracted the twenty sound correspondences with the highest scores. In the first dimension we find 11 pairs involving vowels and 9 involving consonant variation. The three sound correspondences with the highest scores are the [A]-[@], [o]-[u], and [e]-[i] alternations. This finding corresponds well with the traditional scholarly views on Bulgarian phonetics (Wood and Pettersson, 1988; Barnes, 2006) where we find that in unstressed syllables mid vowels [e] and [o] raise to neutralize with the high vowels [i] and [u]. The low vowel [a] raises to merge with [@]. For every sound alternation we also check their geographical distribution. We do so by applying the following procedure. From the aligned pairs of transcriptions we extract corresponding pairs of sounds for every alternation. We count how many times each of the two sounds appears in the transcriptions for every village. Thus, for every pair of sound correspondences, we can create two maps that show the distribution o</context>
</contexts>
<marker>Wood, Pettersson, 1988</marker>
<rawString>Sidney A. J. Wood and Thore Pettersson. 1988. Vowel reduction in Bulgarian: the phonetic data and model experiments. Folia Linguistica, 22(3-4):239–262.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>