<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000495">
<title confidence="0.9936455">
Handling Unknown Words in Statistical Latent-Variable Parsing Models for
Arabic, English and French
</title>
<author confidence="0.936033">
Mohammed Attia, Jennifer Foster, Deirdre Hogan, Joseph Le Roux, Lamia Tounsi,
Josef van Genabith*
</author>
<affiliation confidence="0.993991">
National Centre for Language Technology
School of Computing, Dublin City University
</affiliation>
<email confidence="0.997928">
{mattia,jfoster,dhogan,jleroux,ltounsi,josef}@computing.dcu.ie
</email>
<sectionHeader confidence="0.998592" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998696">
This paper presents a study of the impact
of using simple and complex morphological
clues to improve the classification of rare and
unknown words for parsing. We compare
this approach to a language-independent tech-
nique often used in parsers which is based
solely on word frequencies. This study is ap-
plied to three languages that exhibit different
levels of morphological expressiveness: Ara-
bic, French and English. We integrate infor-
mation about Arabic affixes and morphotac-
tics into a PCFG-LA parser and obtain state-
of-the-art accuracy. We also show that these
morphological clues can be learnt automati-
cally from an annotated corpus.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99438775">
For a parser to do a reasonable job of analysing free
text, it must have a strategy for assigning part-of-
speech tags to words which are not in its lexicon.
This problem, also known as the problem of un-
known words, has received relatively little attention
in the vast literature on Wall-Street-Journal (WSJ)
statistical parsing. This is likely due to the fact that
the proportion of unknown words in the standard
English test set, Section 23 of the WSJ section of
Penn Treebank, is quite small. The problem mani-
fests itself when the text to be analysed comes from
a different domain to the text upon which the parser
has been trained, when the treebank upon which the
parser has been trained is limited in size and when
*Author names are listed in alphabetical order. For further
correspondence, contact L. Tounsi, D. Hogan or J. Foster.
</bodyText>
<page confidence="0.994287">
67
</page>
<bodyText confidence="0.999951058823529">
the language to be parsed is heavily inflected. We
concentrate on the latter case, and examine the prob-
lem of unknown words for two languages which lie
on opposite ends of the spectrum of morphologi-
cal expressiveness and for one language which lies
somewhere in between: Arabic, English and French.
In our experiments we use a Berkeley-style latent-
variable PCFG parser and we contrast two tech-
niques for handling unknown words within the gen-
erative parsing model: one in which no language-
specific information is employed and one in which
morphological clues (or signatures) are exploited.
We find that the improvement accrued from look-
ing at a word’s morphology is greater for Arabic
and French than for English. The morphological
clues we use for English are taken directly from the
Berkeley parser (Petrov et al., 2006) and those for
French from recent work on French statistical pars-
ing with the Berkeley parser (Crabb´e and Candito,
2008; Candito et al., 2009). For Arabic, we present
our own set of heuristics to extract these signatures
and demonstrate a statistically significant improve-
ment of 3.25% over the baseline model which does
not employ morphological information.
We next try to establish to what extent these clues
can be learnt automatically by extracting affixes
from the words in the training data and ranking these
using information gain. We show that this automatic
method performs quite well for all three languages.
The paper is organised as follows: In Section 2
we describe latent variable PCFG parsing models.
This is followed in Section 3 by a description of our
three datasets, including statistics on the extent of
the unknown word problem in each. In Section 4, we
</bodyText>
<note confidence="0.984513">
Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 67–75,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999914866666667">
present results on applying a version of the parser
which uses a simple, language-agnostic, unknown-
word handling technique to our three languages. In
Section 5, we show how this technique is extended
to include morphological information and present
parsing results for English and French. In Section 6,
we describe the Arabic morphological system and
explain how we used heuristic rules to cluster words
into word-classes or signatures. We present parsing
results for the version of the parser which uses this
information. In Section 7, we describe our attempts
to automatically determine the signatures for a lan-
guage and present parsing results for the three lan-
guages. Finally, in Section 8, we discuss how this
work might be fruitfully extended.
</bodyText>
<sectionHeader confidence="0.989193" genericHeader="introduction">
2 Latent Variable PCFG Parsing
</sectionHeader>
<bodyText confidence="0.99927625">
Johnson (1998) showed that refining treebank cate-
gories with parent information leads to more accu-
rate grammars. This was followed by a collection of
linguistically motivated propositions for manual or
semi-automatic modifications of categories in tree-
banks (Klein and Manning, 2003). In PCFG-LAs,
first introduced by Matsuzaki et al. (2005), the re-
fined categories are learnt from the treebank us-
ing unsupervised techniques. Each base category
– and this includes part-of-speech tags – is aug-
mented with an annotation that refines its distribu-
tional properties.
Following Petrov et al. (2006) latent annotations
and probabilities for the associated rules are learnt
incrementally following an iterative process consist-
ing of the repetition of three steps.
</bodyText>
<listItem confidence="0.996">
1. Split each annotation of each symbol into n
(usually 2) new annotations and create rules
with the new annotated symbols. Estimate1 the
probabilities of the newly created rules.
2. Evaluate the impact of the newly created anno-
tations and discard the least useful ones. Re-
estimate probabilities with the new set of anno-
tations.
3. Smooth the probabilities to prevent overfitting.
</listItem>
<bodyText confidence="0.9986485">
We use our own parser which trains a PCFG-LA us-
ing the above procedure and parses using the max-
</bodyText>
<footnote confidence="0.839868">
1Estimation of the parameters is performed by running Ex-
pectation/Maximisation on the training corpus.
</footnote>
<bodyText confidence="0.999650333333333">
rule parsing algorithm (Petrov et al., 2006; Petrov
and Klein, 2007). PCFG-LA parsing is relatively
language-independent but has been shown to be very
effective on several languages (Petrov, 2009). For
our experiments, we set the number of iterations to
be 5 and we test on sentences less than or equal to
40 words in length. All our experiments, apart from
the final one, are carried out on the development sets
of our three languages.
</bodyText>
<sectionHeader confidence="0.989801" genericHeader="method">
3 The Datasets
</sectionHeader>
<bodyText confidence="0.9996303125">
Arabic We use the the Penn Arabic Treebank
(ATB) (Bies and Maamouri, 2003; Maamouri and
Bies., 2004). The ATB describes written Modern
Standard Arabic newswire and follows the style and
guidelines of the English Penn-II treebank. We use
the part-of-speech tagset defined by Bikel and Bies
(Bikel, 2004). We employ the usual treebank split
(80% training, 10% development and 10% test).
English We use the Wall Street Journal section of
the Penn-II Treebank (Marcus et al., 1994). We train
our parser on sections 2-21 and use section 22 con-
catenated with section 24 as our development set.
Final testing is carried out on Section 23.
French We use the French Treebank (Abeill´e et
al., 2003) and divide it into 80% for training, 10%
for development and 10% for final results. We fol-
low the methodology defined by Crabb´e and Can-
dito (2008): compound words are merged and the
tagset consists of base categories augmented with
morphological information in some cases2.
Table 1 gives basic unknown word statistics for
our three datasets. We calculate the proportion of
words in our development sets which are unknown
or rare (specified by the cutoff value) in the corre-
sponding training set. To control for training set
size, we also provide statistics when the English
training set is reduced to the size of the Arabic and
French training sets and when the Arabic training set
is reduced to the size of the French training set. In an
ideal world where training set sizes are the same for
all languages, the problem of unknown words will
be greatest for Arabic and smallest for English. It is
</bodyText>
<footnote confidence="0.974922">
2This is called the CC tagset: base categories with verbal
moods and extraction features
</footnote>
<page confidence="0.998671">
68
</page>
<bodyText confidence="0.950644923076923">
language cutoff #train #dev #unk %unk language #train #dev #unk %unk
Arabic 0 594,683 70,188 3794 5.40 Reduced English 597,999 72,970 2627 3.60
- 1 - - 6023 8.58 (Arabic Size) - - 3849 5.27
- 5 - - 11,347 16.17 - - - 6700 9.18
- 10 - - 15,035 21.42 - - - 9083 12.45
English 0 950,028 72,970 2062 2.83 Reduced Arabic 266,132 70,188 7027 10.01
- 1 - - 2983 4.09 (French Size) - - 10,208 14.54
- 5 - - 5306 7.27 - - - 16,977 24.19
- 10 - - 7230 9.91 - - - 21,434 30.54
French 0 268,842 35,374 2116 5.98 Reduced English 265,464 72,970 4188 5.74
- 1 - - 3136 8.89 (French Size) - - 5894 8.08
- 5 - - 5697 16.11 - - - 10,105 13.85
- 10 - - 7584 21.44 - - - 13,053 17.89
</bodyText>
<tableCaption confidence="0.995516">
Table 1: Basic Unknown Word Statistics for Arabic, French and English
</tableCaption>
<bodyText confidence="0.7481825">
reasonable to assume that the levels of inflectional
richness have a role to play in these differences.
</bodyText>
<sectionHeader confidence="0.992804" genericHeader="method">
4 A Simple Lexical Probability Model
</sectionHeader>
<bodyText confidence="0.9935998">
The simplest method for handling unknown words
within a generative probabilistic parsing/tagging
model is to reserve a proportion of the lexical rule
probability mass for such cases. This is done by
mapping rare words in the training data to a spe-
cial UNKNOWN terminal symbol and estimating rule
probabilities in the usual way. We illustrate the pro-
cess with the toy unannotated PCFG in Figures 1
and 2. The lexical rules in Fig. 1 are the original
rules and the ones in Fig. 2 are the result of apply-
ing the rare-word-to-unknown-symbol transforma-
tion. Given the input sentence The shares recovered,
the word recovered is mapped to the UNKNOWN to-
ken and the three edges corresponding to the rules
NNS —* UNKNOWN, VBD —* UNKNOWN and
JJ —* UNKNOWN are added to the chart at this posi-
tion. The disadvantage of this simple approach is ob-
vious: all unknown words are treated equally and the
tag whose probability distribution is most dominated
by rare words in the training will be deemed the
most likely (JJ for this example), regardless of the
characteristics of the individual word. Apart from
its ease of implementation, its main advantage is its
language-independence - it can be used off-the-shelf
for any language for which a PCFG is available.3
One parameter along which the simple lexical
3Our simple lexical model is equivalent to the Berkeley sim-
pleLexicon option.
probability model can vary is the threshold used to
decide whether a word in the training data is rare or
“unknown”. When the threshold is set to n, a word
in the training data is considered to be unknown if it
occurs n or fewer times. We experiment with three
thresholds: 1, 5 and 10. The result of this experi-
ment for our three languages is shown in Table 2.
The general trend we see in Table 2 is that the
number of training set words considered to be un-
known should be minimized. For all three lan-
guages, the worst performing grammar is the one
obtained when the threshold is increased to 10. This
result is not unexpected. With this simple lexical
probability model, there is a trade-off between ob-
taining good guesses for words which do not occur
in the training data and obtaining reliable statistics
for words which do. The greater the proportion of
the probability mass that we reserve for the unknown
word section of the grammar, the more performance
suffers on the known yet rare words since these are
the words which are mapped to the UNKNOWN sym-
bol. For example, assume the word restructuring oc-
curs 10 times in the training data, always tagged as
a VBG. If the unknown threshold is less than ten and
if the word occurs in the sentence to be parsed, a
VBG edge will be added to the chart at this word’s
position with the probability 10/#VBG. If, however,
the threshold is set to 10, the word (in the training set
and the input sentence) will be mapped to UNKNOWN
and more possibilities will be explored (an edge for
each TAG —* UNKNOWN rule in the grammar). We
can see from Table 1 that at threshold 10, one fifth
</bodyText>
<page confidence="0.990866">
69
</page>
<figure confidence="0.700490444444444">
VBD -&gt; fell 50/153
VBD -&gt; reoriented 2/153
VBD -&gt; went 100/153
VBD -&gt; latched 1/153
NNS -&gt; photofinishers 1/201
NNS -&gt; shares 200/201
JJ -&gt; financial 20/24
JJ -&gt; centrist 4/24
DT -&gt; the 170/170
</figure>
<figureCaption confidence="0.994164">
Figure 1: The original toy PCFG
</figureCaption>
<table confidence="0.82825140625">
VBD -&gt; fell 50/153
VBD -&gt; UNKNOWN 3/153
VBD -&gt; went 100/153
NNS -&gt; UNKNOWN 1/201
NNS -&gt; shares 200/201
JJ -&gt; financial 20/24
JJ -&gt; UNKNOWN 4/24
DT -&gt; the 170/170
Figure 2: Rare → UNKNOWN
VBD -&gt; fell 50/153
VBD -&gt; UNK-ed 3/153
VBD -&gt; went 100/153
NNS -&gt; UNK-s 1/201
NNS -&gt; shares 200/201
JJ -&gt; financial 20/24
JJ -&gt; UNK-ist 4/24
DT -&gt; the 170/170
Figure 3: Rare → UN-
KNOWN+SIGNATURE
Unknown Threshold Recall Precision F-Score Tagging Accuracy
Arabic
1 78.60 80.49 79.53 94.03
5 77.17 79.81 78.47 91.16
10 75.32 78.69 76.97 89.06
English
1 89.20 89.73 89.47 95.60
5 88.91 89.74 89.33 94.66
10 88.00 88.97 88.48 93.61
French
1 83.60 84.17 83.88 94.90
5 82.31 83.10 82.70 92.99
10 80.87 82.05 81.45 91.56
</table>
<tableCaption confidence="0.999099">
Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model
</tableCaption>
<bodyText confidence="0.999203">
of the words in the Arabic and French development
sets are unknown, and this is reflected in the drop in
parsing performance at these thresholds.
</bodyText>
<sectionHeader confidence="0.948633" genericHeader="method">
5 Making use of Morphology
</sectionHeader>
<bodyText confidence="0.999897411764706">
Unknown words are not all the same. We exploit this
fact by examining the effect on parsing accuracy of
clustering rare training set words using cues from
the word’s morphological structure. Affixes have
been shown to be useful in part-of-speech tagging
(Schmid, 1994; Tseng et al., 2005) and have been
used in the Charniak (Charniak, 2000), Stanford
(Klein and Manning, 2003) and Berkeley (Petrov et
al., 2006) parsers. In this section, we contrast the
effect on parsing accuracy of making use of such in-
formation for our three languages of interest.
Returning to our toy English example in Figures 1
and 2, and given the input sentence The shares re-
covered, we would like to use the fact that the un-
known word recovered ends with the past tense
suffix -ed to boost the probability of the lexical
rule VBD → UNKNOWN. If we specialise the
UNKNOWN terminal using information from English
morphology, we can do just that, resulting in the
grammar in Figure 3. Now the word recovered is
mapped to the symbol UNK-ed and the only edge
which is added to the chart at this position is the one
corresponding to the rule VBD → UNK-ed.
For our English experiments we use the unknown
word classes (or signatures) which are used in the
Berkeley parser. A signature indicates whether a
words contains a digit or a hyphen, if a word starts
with a capital letter or ends with one of the following
English suffixes (both derivational and inflectional):
-s, -ed, -ing, -ion, -er, -est, -ly, -ity, -y and -al.
For our French experiments we employ the same
signature list as Crabb´e and Candito (2008), which
itself was adapted from Arun and Keller (2005).
This list consists of (a) conjugation suffixes of regu-
</bodyText>
<page confidence="0.990147">
70
</page>
<bodyText confidence="0.999349428571429">
lar verbs for common tenses (eg. -ons, -ez, -ent... )
and (b) derivational suffixes for nouns, adverbs and
adjectives (eg. -tion, -ment, -able... ).
The result of employing signature information
for French and English is shown in Table 3. Be-
side each f-score the absolute improvement over the
UNKNOWN baseline (Table 2) is given. For both
languages there is an improvement at all unknown
thresholds. The improvement for English is statis-
tically significant at unknown thresholds 1 and 10.4
The improvement is more marked for French and is
statistically significant at all levels.
In the next section, we experiment with signature
lists for Arabic.5
</bodyText>
<sectionHeader confidence="0.997468" genericHeader="method">
6 Arabic Signatures
</sectionHeader>
<bodyText confidence="0.9999345">
In order to use morphological clues for Arabic we
go further than just looking at suffixes. We exploit
all the richness of the morphology of this language
which can be expressed through morphotactics.
</bodyText>
<subsectionHeader confidence="0.998871">
6.1 Handling Arabic Morphotactics
</subsectionHeader>
<bodyText confidence="0.999982764705882">
Morphotactics refers to the way morphemes com-
bine together to form words (Beesley, 1998; Beesley
and Karttunen, 2003). Generally speaking, morpho-
tactics can be concatenative, with morphemes either
prefixed or suffixed to stems, or non-concatenative,
with stems undergoing internal alternations to con-
vey morphosyntactic information. Arabic is consid-
ered a typical example of a language that employs
non-concatenative morphotactics.
Arabic words are traditionally classified into three
types: verbs, nouns and particles. Adjectives take
almost all the morphological forms of, and share the
same templatic structures with, nouns. Adjectives,
for example, can be definite, and are inflected for
case, number and gender.
There are a number of indicators that tell us
whether the word is a verb or a noun. Among
</bodyText>
<footnote confidence="0.9939718">
4Statistical significance was determined using the strati-
fied shuffling method. The software used to perform the test
was downloaded from http://www.cis.upenn.edu/
˜dbikel/software.html.
5An inspection of the Berkeley Arabic grammar (available
at http://code.google.com/p/berkeleyparser/
downloads/list) shows that no Arabic-specific signatures
were employed. The Stanford parser uses 9 signatures for Ara-
bic, designed for use with unvocalised text. An immediate fu-
ture goal is to test this signature list with our parser.
</footnote>
<bodyText confidence="0.99995625">
these indicators are prefixes, suffixes and word tem-
plates. A template (Beesley and Karttunen, 2003) is
a kind of vocalization mould in which a word fits. In
derivational morphology Arabic words are formed
through the amalgamation of two tiers, namely, root
and template. A root is a sequence of three (rarely
two or four) consonants which are called radicals,
and the template is a pattern of vowels, or a com-
bination of consonants and vowels, with slots into
which the radicals of the root are inserted.
For the purpose of detection we use the reverse
of this information. Given that we have a word, we
try to extract the stem, by removing prefixes and suf-
fixes, and match the word against a number of verbal
and nominal templates. We found that most Ara-
bic templatic structures are in complementary dis-
tribution, i.e. they are either restricted to nominal
or verbal usage, and with simple regular expression
matching we can decide whether a word form is a
noun or a verb.
</bodyText>
<subsectionHeader confidence="0.996888">
6.2 Noun Indicators
</subsectionHeader>
<bodyText confidence="0.923503894736842">
In order to detect that a word form is a noun (or ad-
jective), we employ heuristic rules related to Arabic
prefixes/suffixes and if none of these rules apply we
attempt to match the word against templatic struc-
tures. Using this methodology, we are able to detect
95% of ATB nouns.6
We define a list of 42 noun templates which are
used to indicate active/passive participle nouns, ver-
bal nouns, nouns of instrument and broken plural
nouns (see Table 4 for some examples). Note that
templates ending with taa marboutah “ap” or start-
ing with meem madmoumah “mu” are not consid-
ered since they are covered by our suffix/prefix rules,
which are as follows:
1- The definite article prefixPor in Buckwalter
transliteration “Al”.
2- The tanween suffix �I,I�, v Ior “N”, “F”, “K”, “AF”.
3- The feminine plural suffix .D t, or “+At”.
4- The taa marboutah ending o or “ap” whether as a
</bodyText>
<footnote confidence="0.8430175">
6The heuristics we developed are designed to work on dia-
critized texts. Although diacritics are generally ignored in mod-
ern writing, the issue of restoring diacritics has been satisfac-
torily addressed by different researchers. For example, Nelken
and Shieber (2005) presented an algorithm for restoring diacrit-
ics to undiacritized MSA texts with an accuracy of over 90%
and Habasah et al. (2009) reported on a freely-available toolkit
(MADA-TOKAN) an accuracy of over 96%.
</footnote>
<page confidence="0.994384">
71
</page>
<table confidence="0.999937307692308">
Unknown Threshold Recall Precision F-Score Tagging Accuracy
Arabic
1 80.67 82.19 *81.42 (+ 1.89) 96.32
5 80.66 82.81 *81.72 (+ 3.25) 95.15
10 79.86 82.49 *81.15 (+ 4.18) 94.38
English
1 ***89.64 89.95 89.79 (+ 0.32) 96.44
5 89.16 89.80 89.48 (+ 0.15) 96.32
10 89.14 89.78 **89.46 (+ 0.98) 96.21
French
1 85.15 85.77 *85.46 (+ 1.58) 96.13
5 84.08 84.80 *84.44 (+ 1.74) 95.54
10 84.21 84.78 *84.49 (+ 3.04) 94.68
</table>
<tableCaption confidence="0.927498">
Table 3: Baseline Signatures for Arabic, French and English
</tableCaption>
<table confidence="0.986965583333333">
statistically significant with *:P &lt; 10−4, **: P &lt; 10−3, ***: P &lt; 0.004,
Arabic Template Regular Specification
Name Expression
Buckwalter
ÈA,�®~ KI~ {inofiEAl {ino.i.A. verbal noun (masdar)
ÈA;,cÓ�
Éª~ ®�
ÉJ�«�A mifoEAl mi.o.A. noun instrument
�� �ÓmusotafoEil musota.o.i. noun participle
É«�ñJ‚��®��ÓmafAEiyl ma.A.iy. noun plural
É~Jƒ��{isotafoEal {isota.o.a. verb
ª ®~¯ fuwEil .uw.i. verb passive
</table>
<tableCaption confidence="0.999539">
Table 4: Sample Arabic Templatic Structures for Nouns and Verbs
</tableCaption>
<bodyText confidence="0.7397525">
feminine marker suffix or part of the word.
5- The genitive case marking kasrah @, or “+i”.
</bodyText>
<listItem confidence="0.945183333333333">
6- Words of length of at least five characters ending
with doubled yaa ø or “y˜”.
7- Words of length of at least six characters ending
with alif mamdoudah and hamzah J or “A’ ”.
8- Words of length of at least seven characters start-
ing with meem madmoumahAor “mu”.
</listItem>
<subsectionHeader confidence="0.99553">
6.3 Verb Indicators
</subsectionHeader>
<bodyText confidence="0.995700714285714">
In the same way, we define a list of 16 templates and
we combine them with heuristic rules related to Ara-
bic prefixes/suffixes to detect whether a word form
is exclusively a verb. The prefix/suffix heuristics are
as follows:
9-The plural marker suffix@9or “uwA” indicates a
verb.
</bodyText>
<page confidence="0.391260666666667">
“sa”,“&gt;a”,
L
10- The prefixes u or
</page>
<bodyText confidence="0.972747857142857">
prefective verb.
The verbal templates are less in number than the
noun templates yet they are no less effective in de-
tecting the word class (see Table 4 for examples).
Using these heuristics we are able to detect 85% of
ATB verbs.
“&gt;u”, “na”, “nu”, “ya”, “yu”, “ta”, “tu” indicate im-
</bodyText>
<subsectionHeader confidence="0.998399">
6.4 Arabic Signatures
</subsectionHeader>
<bodyText confidence="0.999963818181818">
We map the 72 noun/verb classes that are identi-
fied using our hand-crafted heuristics into sets of
signatures of varying sizes: 4, 6, 14, 21, 25, 28
and 72. The very coarse-grained set considers just
4 signatures UNK-noun, UNK-verb, UNK-num,
and UNK and the most fine-grained set of 72 signa-
tures associates one signature per heuristic. In ad-
dition, we have evaluated the effect of reordering
rules and templates and also the effect of collating
all signatures satisfying an unknown word. The re-
sults of using these various signatures sets in parsing
</bodyText>
<page confidence="0.996364">
72
</page>
<table confidence="0.999181818181818">
UNK
NUM NOUN VERB
digits (see section 6.2) (see section 6.3)
Al definiteness tashkil At suffix ap suffix imperfect
rule 1 rules 2 and 5 rule 3 rule 4 rule 10
y suffix A’ suffix mu prefix verbal noun templates suffixes
rule 6 rule 7 rule 8 3 groupings dual/plural suffixes
plural templates participle active templates participle passive templates instrument templates passive templates
4 groupings
other templates verbal templates
5 groupings
</table>
<tableCaption confidence="0.874226">
Table 6: Arabic signatures
</tableCaption>
<table confidence="0.999549454545455">
Cutoff 1 5 10
4 80.78 80.71 80.09
6 81.14 81.16 81.06
14 80.88 81.45 81.19
14 reorder 81.39 81.01 80.81
21 81.38 81.55 81.35
21 reorder 81.20 81.13 80.58
21 collect 80.94 80.56 79.63
25 81.18 81.25 81.26
28 81.42 81.72 (+ 3.25) 81.15
72 79.64 78.87 77.58
</table>
<tableCaption confidence="0.997738">
Table 5: Baseline Signatures for Arabic
</tableCaption>
<bodyText confidence="0.9997537">
our Arabic development set are presented in Table 5.
We achieve our best labeled bracketing f-score using
28 signatures with an unknown threshold of five. In
fact we get an improvement of 3.25% over using no
signatures at all (see Table 2). Table 3 describes in
more detail the scores obtained using the 28 signa-
tures present in Table 6. Apart from the set contain-
ing 72 signatures, all of the baseline signature sets in
Table 5 yield a statistically significant improvement
over the generic UNKNOWN results (p &lt; 10−4).
</bodyText>
<sectionHeader confidence="0.5785575" genericHeader="method">
7 Using Information Gain to Determine
Signatures
</sectionHeader>
<bodyText confidence="0.999412636363636">
It is clear that dividing the UNKNOWN terminal into
more fine-grained categories based on morpholog-
ical information helps parsing for our three lan-
guages. In this section we explore whether useful
morphological clues can be learnt automatically. If
they can, it means that a latent-variable PCFG parser
can be adapted to any language without knowledge
of the language in question since the only language-
specific component in such a parser is the unknown-
signature specification.
In a nutshell, we extract affix features from train-
ing set words7 and then use information gain to rank
these features in terms of their predictive power in a
POS-tagging task. The features deemed most dis-
criminative are then used as signatures, replacing
our baseline signatures described in Sections 5 and
6. We are not going as far as actual POS-tagging,
but rather seeing whether the affixes that make good
features for a part-of-speech tagger also make good
unknown word signatures.
We experiment with English and French suffixes
of length 1-3 and Arabic prefixes and suffixes of var-
ious lengths as well as stem prefixes and suffixes of
length 2, 4 and 6. For each of our languages we
experiment with several information gain thresholds
on our development sets and we fix on an English
signature list containing 24 suffixes, a French list
containing 48 suffixes and an Arabic list containing
38 prefixes and suffixes.
Our development set results are presented in Ta-
ble 7. For all three languages, the information gain
signatures perform at a comparable level to the base-
line hand-crafted signatures (Table 3). For each
of the three unknown-word handling techniques, no
signature (UNKNOWN), hand-crafted signatures and
information gain signatures, we select the best un-
known threshold for each language’s development
set and apply these grammars to our test sets. The
f-scores are presented in Table 8, along with the up-
per bounds obtained by parsing with these grammars
in gold-tag mode. For French, the effect of tagging
accuracy on overall parse accuracy is striking. The
improvements that we get from using morphological
signatures are greatest for Arabic8 and smallest for
</bodyText>
<footnote confidence="0.9819115">
7We omit all function words and high frequency words be-
cause we are interested in the behaviour of words which are
likely to be similar to rare words.
8Bikel’s parser trained on the same Arabic data and tested
on the same input achieves an f-score of 76.50%. We trained
a 5-split-merge-iteration Berkeley grammar and parsed with the
</footnote>
<page confidence="0.990454">
73
</page>
<table confidence="0.999953">
Unknown Threshold Recall Precision F-Score Tagging Accuracy
Arabic IG
1 80.10 82.15 *81.11 (+ 1.58) 96.53
5 80.03 82.49 *81.32 (+ 2.85) 95.30
10 80.17 82.40 *81.27 (+ 4.3) 94.66
English IG
1 89.38 89.87 89.63 (+ 0.16) 96.45
5 89.54 90.22 ***89.88 (+ 0.55) 96.41
10 89.22 90.05 *89.63 (+ 1.15) 96.19
French IG
1 84.78 85.36 *85.07 (+ 1.19) 96.17
5 84.63 85.24 **84.93 (+ 2.23) 95.30
10 84.18 84.80 *84.49 (+ 3.09) 94.68
</table>
<tableCaption confidence="0.994006">
Table 7: Information Gain Signature Results
</tableCaption>
<table confidence="0.991231222222222">
statistically significant with *:p &lt; 10−4, **: p &lt; 2 · 10−4, ***: p &lt; 0.005
Language No Sig Baseline Sig IG Sig
Arabic 78.34 *81.59 *81.33
Arabic Gold Tag 81.46 82.43 81.90
English 89.48 89.65 89.77
English Gold Tag 89.94 90.10 90.23
French 83.74 *85.77 **85.55
French Gold Tag 88.82 88.41 88.86
statistically significant with *: p &lt; 10−4, **: p &lt; 10−3
</table>
<tableCaption confidence="0.999174">
Table 8: F-Scores on Test Sets
</tableCaption>
<bodyText confidence="0.9801615">
English. The results for the information gain signa-
tures are promising and warrant further exploration.
</bodyText>
<sectionHeader confidence="0.998863" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999255292682927">
We experiment with two unknown-word-handling
techniques in a statistical generative parsing model,
applying them to Arabic, French and English. One
technique is language-agnostic and the other makes
use of some morphological information (signatures)
in assigning part-of-speech tags to unknown words.
The performance differences from the two tech-
niques are smallest for English, the language with
the sparsest morphology of the three and the small-
est proportion of unknown words in its development
set. As a result of carrying out these experiments,
we have developed a list of Arabic signatures which
can be used with any statistical parser which does
Berkeley parser, achieving an f-score of 75.28%. We trained the
Berkeley parser with the -treebank SINGLEFILE option so that
English signatures were not employed.
its own tagging. We also present results which show
that signatures can be learnt automatically.
Our experiments have been carried out using gold
tokens. Tokenisation is an issue particularly for Ara-
bic, but also for French (since the treebank contains
merged compounds) and to a much lesser extent for
English (unedited text with missing apostrophes). It
is important that the experiments in this paper are re-
peated on untokenised text using automatic tokeni-
sation methods (e.g. MADA-TOKAN).
The performance improvements that we demon-
strate for Arabic unknown-word handling are obvi-
ously just the tip of the iceberg in terms of what can
be done to improve performance on a morpholog-
ically rich language. The simple generative lexical
probability model we use can be improved by adopt-
ing a more sophisticated approach in which known
and unknown word counts are combined when esti-
mating lexical rule probabilities for rare words (see
Huang and Harper (2009) and the Berkeley sophis-
ticatedLexicon training option). Further work will
also include making use of a lexical resource exter-
nal to the treebank (Goldberg et al., 2009; Habash,
2008) and investigating clustering techniques to re-
duce data sparseness (Candito and Crabb´e, 2009).
</bodyText>
<sectionHeader confidence="0.997754" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9445554">
This research is funded by Enterprise Ireland
(CFTD/07/229 and PC/09/037) and the Irish Re-
search Council for Science Engineering and Tech-
nology (IRCSET). We thank Marie Candito and our
three reviewers for their very helpful suggestions.
</bodyText>
<page confidence="0.998103">
74
</page>
<sectionHeader confidence="0.994692" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999533134615385">
Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel,
2003. Treebanks: Building and Using Parsed
Corpora, chapter Building a Treebank for French.
Kluwer, Dordrecht.
Abhishek Arun and Frank Keller. 2005. Lexicalization
in crosslinguistic probabilistic parsing: The case of
French. In ACL. The Association for Computer Lin-
guistics.
Kenneth R. Beesley and Lauri Karttunen. 2003. Finite
State Morphology. CSLI studies in computational lin-
guistics.
Kenneth R. Beesley. 1998. Arabic morphology using
only finite-state operations. In The Workshop on Com-
putational Approaches to Semitic Languages.
Ann Bies and Mohammed Maamouri. 2003. Penn Ara-
bic Treebank guidelines. Technical Report TB-1-28-
03.
Dan Bikel. 2004. On the Parameter Space of Generative
Lexicalized Parsing Models. Ph.D. thesis, University
of Pennslyvania.
Marie Candito and Benoit Crabb´e. 2009. Improving gen-
erative statistical parsing with semi-supervised word
clustering. In Proceedings ofIWPT’09.
Marie Candito, Benoit Crabb´e, and Djam´e Seddah. 2009.
On statistical parsing of French with supervised and
semi-supervised strategies. In Proceedings of the
EACL 2009 Workshop on Computational Linguis-
tic Aspects of Grammatical Inference, pages 49–57,
Athens, Greece, March.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the Annual Meeting of the
North American Association for Computational Lin-
guistics (NAACL-00), pages 132–139, Seattle, Wash-
ington.
Benoit Crabb´e and Marie Candito. 2008. Exp´eriences
d’analyse syntaxique statistique du franc¸ais. In Actes
de TALN.
Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael
Elhadad. 2009. Enhancing unlexicalized parsing per-
formance using a wide coverage lexicon, fuzzy tag-set
mapping, and EM-HMM-based lexical probabilities.
In EACL, pages 327–335. The Association for Com-
puter Linguistics.
Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
Mada+tokan: A toolkit for Arabic tokenization, di-
acritization, morphological disambiguation, pos tag-
ging, stemming and lemmatization. In Proceedings of
the 2nd International Conference on Arabic Language
Resources and Tools (MEDAR).
Nizar Habash. 2008. Four techniques for online handling
of out-of-vocabulary words in arabic-english statistical
machine translation. In Proceedings ofAssociationfor
Computational Linguistics, pages 57–60.
Zhongqiang Huang and Mary Harper. 2009. Self-
training pcfg grammars with latent annotations across
languages. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
Singapore, August.
Mark Johnson. 1998. PCFG models of linguis-
tic tree representations. Computational Linguistics,
24(4):613–632.
Dan Klein and Chris Manning. 2003. Accurate unlex-
icalised parsing. In Proceedings of the 41st Annual
Meeting of the ACL.
Mohammed Maamouri and Ann Bies. 2004. Developing
an Arabic Treebank: Methods, guidelines, procedures,
and tools. In Workshop on Computational Approaches
to Arabic Script-based Languages, COLING.
Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,
Robert MacIntyre, Ann Bies, Mark Ferguson, Karen
Katz, and Britta Schasberger. 1994. The Penn Tree-
bank: Annotating predicate argument structure. In
Proceedings of the 1994 ARPA Speech and Natural
Language Workshop, pages 114–119, Princeton, New
Jersey.
Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
Proceedings of the 43rd Annual Meeting of the ACL,
pages 75–82, Ann Arbor, June.
Rani Nelken and Stuart M. Shieber. 2005. Arabic dia-
critization using weighted finite-state transducers. In
ACL-05 Workshop on Computational Approaches to
Semitic Languages.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL, Rochester, NY, April.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact and inter-
pretable tree annotation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th Annual Meeting of the ACL, Sydney,
Australia, July.
Slav Petrov. 2009. Coarse-to-Fine Natural Language
Processing. Ph.D. thesis, University of California at
Berkeley, Berkeley, CA, USA.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proceedings of the In-
ternational Conference on New Methods in Language
Processing (NeMLaP-1), pages 44–49.
Huihsin Tseng, Daniel Jurafsky, and Christopher Man-
ning. 2005. Morphological features help POS tagging
of unknown words across language varieties. In Pro-
ceedings of the Fourth SIGHAN Workshop on Chinese
Language Processing.
</reference>
<page confidence="0.999123">
75
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.737218">
<title confidence="0.9954195">Handling Unknown Words in Statistical Latent-Variable Parsing Models for Arabic, English and French</title>
<author confidence="0.9111595">Mohammed Attia</author>
<author confidence="0.9111595">Jennifer Foster</author>
<author confidence="0.9111595">Deirdre Hogan</author>
<author confidence="0.9111595">Joseph Le_Roux</author>
<author confidence="0.9111595">Lamia van</author>
<affiliation confidence="0.964858">National Centre for Language School of Computing, Dublin City</affiliation>
<abstract confidence="0.99833475">This paper presents a study of the impact of using simple and complex morphological clues to improve the classification of rare and unknown words for parsing. We compare this approach to a language-independent technique often used in parsers which is based solely on word frequencies. This study is applied to three languages that exhibit different levels of morphological expressiveness: Arabic, French and English. We integrate information about Arabic affixes and morphotactics into a PCFG-LA parser and obtain stateof-the-art accuracy. We also show that these morphological clues can be learnt automatically from an annotated corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Franc¸ois Toussenel</author>
</authors>
<title>Treebanks: Building and Using Parsed Corpora, chapter Building a Treebank for French.</title>
<date>2003</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel, 2003. Treebanks: Building and Using Parsed Corpora, chapter Building a Treebank for French. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abhishek Arun</author>
<author>Frank Keller</author>
</authors>
<title>Lexicalization in crosslinguistic probabilistic parsing: The case of French.</title>
<date>2005</date>
<booktitle>In ACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="14690" citStr="Arun and Keller (2005)" startWordPosition="2502" endWordPosition="2505">d the only edge which is added to the chart at this position is the one corresponding to the rule VBD → UNK-ed. For our English experiments we use the unknown word classes (or signatures) which are used in the Berkeley parser. A signature indicates whether a words contains a digit or a hyphen, if a word starts with a capital letter or ends with one of the following English suffixes (both derivational and inflectional): -s, -ed, -ing, -ion, -er, -est, -ly, -ity, -y and -al. For our French experiments we employ the same signature list as Crabb´e and Candito (2008), which itself was adapted from Arun and Keller (2005). This list consists of (a) conjugation suffixes of regu70 lar verbs for common tenses (eg. -ons, -ez, -ent... ) and (b) derivational suffixes for nouns, adverbs and adjectives (eg. -tion, -ment, -able... ). The result of employing signature information for French and English is shown in Table 3. Beside each f-score the absolute improvement over the UNKNOWN baseline (Table 2) is given. For both languages there is an improvement at all unknown thresholds. The improvement for English is statistically significant at unknown thresholds 1 and 10.4 The improvement is more marked for French and is st</context>
</contexts>
<marker>Arun, Keller, 2005</marker>
<rawString>Abhishek Arun and Frank Keller. 2005. Lexicalization in crosslinguistic probabilistic parsing: The case of French. In ACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite State Morphology. CSLI studies in computational linguistics.</title>
<date>2003</date>
<contexts>
<context position="15770" citStr="Beesley and Karttunen, 2003" startWordPosition="2674" endWordPosition="2677">holds. The improvement for English is statistically significant at unknown thresholds 1 and 10.4 The improvement is more marked for French and is statistically significant at all levels. In the next section, we experiment with signature lists for Arabic.5 6 Arabic Signatures In order to use morphological clues for Arabic we go further than just looking at suffixes. We exploit all the richness of the morphology of this language which can be expressed through morphotactics. 6.1 Handling Arabic Morphotactics Morphotactics refers to the way morphemes combine together to form words (Beesley, 1998; Beesley and Karttunen, 2003). Generally speaking, morphotactics can be concatenative, with morphemes either prefixed or suffixed to stems, or non-concatenative, with stems undergoing internal alternations to convey morphosyntactic information. Arabic is considered a typical example of a language that employs non-concatenative morphotactics. Arabic words are traditionally classified into three types: verbs, nouns and particles. Adjectives take almost all the morphological forms of, and share the same templatic structures with, nouns. Adjectives, for example, can be definite, and are inflected for case, number and gender. </context>
<context position="17083" citStr="Beesley and Karttunen, 2003" startWordPosition="2860" endWordPosition="2863">mong 4Statistical significance was determined using the stratified shuffling method. The software used to perform the test was downloaded from http://www.cis.upenn.edu/ ˜dbikel/software.html. 5An inspection of the Berkeley Arabic grammar (available at http://code.google.com/p/berkeleyparser/ downloads/list) shows that no Arabic-specific signatures were employed. The Stanford parser uses 9 signatures for Arabic, designed for use with unvocalised text. An immediate future goal is to test this signature list with our parser. these indicators are prefixes, suffixes and word templates. A template (Beesley and Karttunen, 2003) is a kind of vocalization mould in which a word fits. In derivational morphology Arabic words are formed through the amalgamation of two tiers, namely, root and template. A root is a sequence of three (rarely two or four) consonants which are called radicals, and the template is a pattern of vowels, or a combination of consonants and vowels, with slots into which the radicals of the root are inserted. For the purpose of detection we use the reverse of this information. Given that we have a word, we try to extract the stem, by removing prefixes and suffixes, and match the word against a number</context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Kenneth R. Beesley and Lauri Karttunen. 2003. Finite State Morphology. CSLI studies in computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
</authors>
<title>Arabic morphology using only finite-state operations.</title>
<date>1998</date>
<booktitle>In The Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="15740" citStr="Beesley, 1998" startWordPosition="2672" endWordPosition="2673">l unknown thresholds. The improvement for English is statistically significant at unknown thresholds 1 and 10.4 The improvement is more marked for French and is statistically significant at all levels. In the next section, we experiment with signature lists for Arabic.5 6 Arabic Signatures In order to use morphological clues for Arabic we go further than just looking at suffixes. We exploit all the richness of the morphology of this language which can be expressed through morphotactics. 6.1 Handling Arabic Morphotactics Morphotactics refers to the way morphemes combine together to form words (Beesley, 1998; Beesley and Karttunen, 2003). Generally speaking, morphotactics can be concatenative, with morphemes either prefixed or suffixed to stems, or non-concatenative, with stems undergoing internal alternations to convey morphosyntactic information. Arabic is considered a typical example of a language that employs non-concatenative morphotactics. Arabic words are traditionally classified into three types: verbs, nouns and particles. Adjectives take almost all the morphological forms of, and share the same templatic structures with, nouns. Adjectives, for example, can be definite, and are inflected</context>
</contexts>
<marker>Beesley, 1998</marker>
<rawString>Kenneth R. Beesley. 1998. Arabic morphology using only finite-state operations. In The Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Mohammed Maamouri</author>
</authors>
<title>Penn Arabic Treebank guidelines.</title>
<date>2003</date>
<tech>Technical Report TB-1-28-03.</tech>
<contexts>
<context position="6391" citStr="Bies and Maamouri, 2003" startWordPosition="1014" endWordPosition="1017">mation of the parameters is performed by running Expectation/Maximisation on the training corpus. rule parsing algorithm (Petrov et al., 2006; Petrov and Klein, 2007). PCFG-LA parsing is relatively language-independent but has been shown to be very effective on several languages (Petrov, 2009). For our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn-II treebank. We use the part-of-speech tagset defined by Bikel and Bies (Bikel, 2004). We employ the usual treebank split (80% training, 10% development and 10% test). English We use the Wall Street Journal section of the Penn-II Treebank (Marcus et al., 1994). We train our parser on sections 2-21 and use section 22 concatenated with section 24 as our development set. Final testing is carried out on Section 23. French We use the French Treebank (Abeill</context>
</contexts>
<marker>Bies, Maamouri, 2003</marker>
<rawString>Ann Bies and Mohammed Maamouri. 2003. Penn Arabic Treebank guidelines. Technical Report TB-1-28-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bikel</author>
</authors>
<title>On the Parameter Space of Generative Lexicalized Parsing Models.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennslyvania.</institution>
<contexts>
<context position="6620" citStr="Bikel, 2004" startWordPosition="1051" endWordPosition="1052"> be very effective on several languages (Petrov, 2009). For our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn-II treebank. We use the part-of-speech tagset defined by Bikel and Bies (Bikel, 2004). We employ the usual treebank split (80% training, 10% development and 10% test). English We use the Wall Street Journal section of the Penn-II Treebank (Marcus et al., 1994). We train our parser on sections 2-21 and use section 22 concatenated with section 24 as our development set. Final testing is carried out on Section 23. French We use the French Treebank (Abeill´e et al., 2003) and divide it into 80% for training, 10% for development and 10% for final results. We follow the methodology defined by Crabb´e and Candito (2008): compound words are merged and the tagset consists of base categ</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Dan Bikel. 2004. On the Parameter Space of Generative Lexicalized Parsing Models. Ph.D. thesis, University of Pennslyvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
</authors>
<title>Improving generative statistical parsing with semi-supervised word clustering.</title>
<date>2009</date>
<booktitle>In Proceedings ofIWPT’09.</booktitle>
<marker>Candito, Crabb´e, 2009</marker>
<rawString>Marie Candito and Benoit Crabb´e. 2009. Improving generative statistical parsing with semi-supervised word clustering. In Proceedings ofIWPT’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
<author>Djam´e Seddah</author>
</authors>
<title>On statistical parsing of French with supervised and semi-supervised strategies.</title>
<date>2009</date>
<booktitle>In Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference,</booktitle>
<pages>49--57</pages>
<location>Athens, Greece,</location>
<marker>Candito, Crabb´e, Seddah, 2009</marker>
<rawString>Marie Candito, Benoit Crabb´e, and Djam´e Seddah. 2009. On statistical parsing of French with supervised and semi-supervised strategies. In Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 49–57, Athens, Greece, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the Annual Meeting of the North American Association for Computational Linguistics (NAACL-00),</booktitle>
<pages>132--139</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="13394" citStr="Charniak, 2000" startWordPosition="2275" endWordPosition="2276">87 82.05 81.45 91.56 Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the unknown word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule VBD → UNKNOWN. If we specialise the UNKNOWN terminal using information from English morphology, we can do just that, resulting in the gra</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the Annual Meeting of the North American Association for Computational Linguistics (NAACL-00), pages 132–139, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Crabb´e</author>
<author>Marie Candito</author>
</authors>
<title>Exp´eriences d’analyse syntaxique statistique du franc¸ais.</title>
<date>2008</date>
<booktitle>In Actes de TALN.</booktitle>
<marker>Crabb´e, Candito, 2008</marker>
<rawString>Benoit Crabb´e and Marie Candito. 2008. Exp´eriences d’analyse syntaxique statistique du franc¸ais. In Actes de TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities.</title>
<date>2009</date>
<booktitle>In EACL,</booktitle>
<pages>327--335</pages>
<publisher>The Association</publisher>
<institution>for Computer Linguistics.</institution>
<marker>Goldberg, Tsarfaty, Adler, Elhadad, 2009</marker>
<rawString>Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael Elhadad. 2009. Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities. In EACL, pages 327–335. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>Mada+tokan: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, pos tagging, stemming and lemmatization.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools (MEDAR).</booktitle>
<marker>Habash, Rambow, Roth, 2009</marker>
<rawString>Nizar Habash, Owen Rambow, and Ryan Roth. 2009. Mada+tokan: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, pos tagging, stemming and lemmatization. In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools (MEDAR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Four techniques for online handling of out-of-vocabulary words in arabic-english statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings ofAssociationfor Computational Linguistics,</booktitle>
<pages>57--60</pages>
<marker>Habash, 2008</marker>
<rawString>Nizar Habash. 2008. Four techniques for online handling of out-of-vocabulary words in arabic-english statistical machine translation. In Proceedings ofAssociationfor Computational Linguistics, pages 57–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongqiang Huang</author>
<author>Mary Harper</author>
</authors>
<title>Selftraining pcfg grammars with latent annotations across languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Singapore,</location>
<marker>Huang, Harper, 2009</marker>
<rawString>Zhongqiang Huang and Mary Harper. 2009. Selftraining pcfg grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>PCFG models of linguistic tree representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="4544" citStr="Johnson (1998)" startWordPosition="720" endWordPosition="721">hnique is extended to include morphological information and present parsing results for English and French. In Section 6, we describe the Arabic morphological system and explain how we used heuristic rules to cluster words into word-classes or signatures. We present parsing results for the version of the parser which uses this information. In Section 7, we describe our attempts to automatically determine the signatures for a language and present parsing results for the three languages. Finally, in Section 8, we discuss how this work might be fruitfully extended. 2 Latent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations a</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. PCFG models of linguistic tree representations. Computational Linguistics, 24(4):613–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Chris Manning</author>
</authors>
<title>Accurate unlexicalised parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="4813" citStr="Klein and Manning, 2003" startWordPosition="757" endWordPosition="760">present parsing results for the version of the parser which uses this information. In Section 7, we describe our attempts to automatically determine the signatures for a language and present parsing results for the three languages. Finally, in Section 8, we discuss how this work might be fruitfully extended. 2 Latent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps. 1. Split each annotation of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Es</context>
<context position="13430" citStr="Klein and Manning, 2003" startWordPosition="2278" endWordPosition="2281">2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the unknown word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule VBD → UNKNOWN. If we specialise the UNKNOWN terminal using information from English morphology, we can do just that, resulting in the grammar in Figure 3. Now the word recov</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Chris Manning. 2003. Accurate unlexicalised parsing. In Proceedings of the 41st Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammed Maamouri</author>
<author>Ann Bies</author>
</authors>
<title>Developing an Arabic Treebank: Methods, guidelines, procedures, and tools.</title>
<date>2004</date>
<booktitle>In Workshop on Computational Approaches to Arabic Script-based Languages, COLING.</booktitle>
<marker>Maamouri, Bies, 2004</marker>
<rawString>Mohammed Maamouri and Ann Bies. 2004. Developing an Arabic Treebank: Methods, guidelines, procedures, and tools. In Workshop on Computational Approaches to Arabic Script-based Languages, COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn Treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In Proceedings of the 1994 ARPA Speech and Natural Language Workshop,</booktitle>
<pages>114--119</pages>
<location>Princeton, New Jersey.</location>
<contexts>
<context position="6795" citStr="Marcus et al., 1994" startWordPosition="1078" endWordPosition="1081">words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn-II treebank. We use the part-of-speech tagset defined by Bikel and Bies (Bikel, 2004). We employ the usual treebank split (80% training, 10% development and 10% test). English We use the Wall Street Journal section of the Penn-II Treebank (Marcus et al., 1994). We train our parser on sections 2-21 and use section 22 concatenated with section 24 as our development set. Final testing is carried out on Section 23. French We use the French Treebank (Abeill´e et al., 2003) and divide it into 80% for training, 10% for development and 10% for final results. We follow the methodology defined by Crabb´e and Candito (2008): compound words are merged and the tagset consists of base categories augmented with morphological information in some cases2. Table 1 gives basic unknown word statistics for our three datasets. We calculate the proportion of words in our </context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn Treebank: Annotating predicate argument structure. In Proceedings of the 1994 ARPA Speech and Natural Language Workshop, pages 114–119, Princeton, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Probabilistic CFG with latent annotations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>75--82</pages>
<location>Ann Arbor,</location>
<contexts>
<context position="4871" citStr="Matsuzaki et al. (2005)" startWordPosition="766" endWordPosition="769"> uses this information. In Section 7, we describe our attempts to automatically determine the signatures for a language and present parsing results for the three languages. Finally, in Section 8, we discuss how this work might be fruitfully extended. 2 Latent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps. 1. Split each annotation of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. E</context>
</contexts>
<marker>Matsuzaki, Miyao, Tsujii, 2005</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In Proceedings of the 43rd Annual Meeting of the ACL, pages 75–82, Ann Arbor, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart M Shieber</author>
</authors>
<title>Arabic diacritization using weighted finite-state transducers.</title>
<date>2005</date>
<booktitle>In ACL-05 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="19116" citStr="Nelken and Shieber (2005)" startWordPosition="3212" endWordPosition="3215">ah “ap” or starting with meem madmoumah “mu” are not considered since they are covered by our suffix/prefix rules, which are as follows: 1- The definite article prefixPor in Buckwalter transliteration “Al”. 2- The tanween suffix �I,I�, v Ior “N”, “F”, “K”, “AF”. 3- The feminine plural suffix .D t, or “+At”. 4- The taa marboutah ending o or “ap” whether as a 6The heuristics we developed are designed to work on diacritized texts. Although diacritics are generally ignored in modern writing, the issue of restoring diacritics has been satisfactorily addressed by different researchers. For example, Nelken and Shieber (2005) presented an algorithm for restoring diacritics to undiacritized MSA texts with an accuracy of over 90% and Habasah et al. (2009) reported on a freely-available toolkit (MADA-TOKAN) an accuracy of over 96%. 71 Unknown Threshold Recall Precision F-Score Tagging Accuracy Arabic 1 80.67 82.19 *81.42 (+ 1.89) 96.32 5 80.66 82.81 *81.72 (+ 3.25) 95.15 10 79.86 82.49 *81.15 (+ 4.18) 94.38 English 1 ***89.64 89.95 89.79 (+ 0.32) 96.44 5 89.16 89.80 89.48 (+ 0.15) 96.32 10 89.14 89.78 **89.46 (+ 0.98) 96.21 French 1 85.15 85.77 *85.46 (+ 1.58) 96.13 5 84.08 84.80 *84.44 (+ 1.74) 95.54 10 84.21 84.78 </context>
</contexts>
<marker>Nelken, Shieber, 2005</marker>
<rawString>Rani Nelken and Stuart M. Shieber. 2005. Arabic diacritization using weighted finite-state transducers. In ACL-05 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLTNAACL,</booktitle>
<location>Rochester, NY,</location>
<contexts>
<context position="5934" citStr="Petrov and Klein, 2007" startWordPosition="935" endWordPosition="938"> of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. Evaluate the impact of the newly created annotations and discard the least useful ones. Reestimate probabilities with the new set of annotations. 3. Smooth the probabilities to prevent overfitting. We use our own parser which trains a PCFG-LA using the above procedure and parses using the max1Estimation of the parameters is performed by running Expectation/Maximisation on the training corpus. rule parsing algorithm (Petrov et al., 2006; Petrov and Klein, 2007). PCFG-LA parsing is relatively language-independent but has been shown to be very effective on several languages (Petrov, 2009). For our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLTNAACL, Rochester, NY, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL,</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="2668" citStr="Petrov et al., 2006" startWordPosition="422" endWordPosition="425"> expressiveness and for one language which lies somewhere in between: Arabic, English and French. In our experiments we use a Berkeley-style latentvariable PCFG parser and we contrast two techniques for handling unknown words within the generative parsing model: one in which no languagespecific information is employed and one in which morphological clues (or signatures) are exploited. We find that the improvement accrued from looking at a word’s morphology is greater for Arabic and French than for English. The morphological clues we use for English are taken directly from the Berkeley parser (Petrov et al., 2006) and those for French from recent work on French statistical parsing with the Berkeley parser (Crabb´e and Candito, 2008; Candito et al., 2009). For Arabic, we present our own set of heuristics to extract these signatures and demonstrate a statistically significant improvement of 3.25% over the baseline model which does not employ morphological information. We next try to establish to what extent these clues can be learnt automatically by extracting affixes from the words in the training data and ranking these using information gain. We show that this automatic method performs quite well for a</context>
<context position="5123" citStr="Petrov et al. (2006)" startWordPosition="806" endWordPosition="809">tent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps. 1. Split each annotation of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. Evaluate the impact of the newly created annotations and discard the least useful ones. Reestimate probabilities with the new set of annotations. 3. Smooth the probabilities to prevent overfitting. We use our own parser which trains a PCFG-LA using the </context>
<context position="13465" citStr="Petrov et al., 2006" startWordPosition="2284" endWordPosition="2287">he Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the unknown word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule VBD → UNKNOWN. If we specialise the UNKNOWN terminal using information from English morphology, we can do just that, resulting in the grammar in Figure 3. Now the word recovered is mapped to the symbol UNK-ed</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
</authors>
<title>Coarse-to-Fine Natural Language Processing.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California at Berkeley,</institution>
<location>Berkeley, CA, USA.</location>
<contexts>
<context position="6062" citStr="Petrov, 2009" startWordPosition="955" endWordPosition="956">ly created rules. 2. Evaluate the impact of the newly created annotations and discard the least useful ones. Reestimate probabilities with the new set of annotations. 3. Smooth the probabilities to prevent overfitting. We use our own parser which trains a PCFG-LA using the above procedure and parses using the max1Estimation of the parameters is performed by running Expectation/Maximisation on the training corpus. rule parsing algorithm (Petrov et al., 2006; Petrov and Klein, 2007). PCFG-LA parsing is relatively language-independent but has been shown to be very effective on several languages (Petrov, 2009). For our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn-II treebank. We use the part-of-speech tagset defined by Bikel and Bies (Bikel, 2004). We employ the usual treebank split (80% </context>
</contexts>
<marker>Petrov, 2009</marker>
<rawString>Slav Petrov. 2009. Coarse-to-Fine Natural Language Processing. Ph.D. thesis, University of California at Berkeley, Berkeley, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing (NeMLaP-1),</booktitle>
<pages>44--49</pages>
<contexts>
<context position="13321" citStr="Schmid, 1994" startWordPosition="2262" endWordPosition="2263">3.61 French 1 83.60 84.17 83.88 94.90 5 82.31 83.10 82.70 92.99 10 80.87 82.05 81.45 91.56 Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the unknown word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule VBD → UNKNOWN. If we specialise the UNKNOWN terminal using infor</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing (NeMLaP-1), pages 44–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huihsin Tseng</author>
<author>Daniel Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>Morphological features help POS tagging of unknown words across language varieties.</title>
<date>2005</date>
<booktitle>In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing.</booktitle>
<contexts>
<context position="13342" citStr="Tseng et al., 2005" startWordPosition="2264" endWordPosition="2267">83.60 84.17 83.88 94.90 5 82.31 83.10 82.70 92.99 10 80.87 82.05 81.45 91.56 Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the unknown word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule VBD → UNKNOWN. If we specialise the UNKNOWN terminal using information from English m</context>
</contexts>
<marker>Tseng, Jurafsky, Manning, 2005</marker>
<rawString>Huihsin Tseng, Daniel Jurafsky, and Christopher Manning. 2005. Morphological features help POS tagging of unknown words across language varieties. In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>