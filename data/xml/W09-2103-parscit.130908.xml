<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017770">
<title confidence="0.977605">
Inferring Tutorial Dialogue Structure with Hidden Markov Modeling
</title>
<author confidence="0.852887333333333">
Kristy Eun Young Robert Michael Mladen A. James C.
Elizabeth Haa Phillipsab D. Vouka Lestera
Boyera Wallisab
</author>
<affiliation confidence="0.9503945">
aDepartment of Computer Science, North Carolina State University
bApplied Research Associates
</affiliation>
<address confidence="0.636091">
Raleigh, NC, USA
</address>
<email confidence="0.891834">
{keboyer, eha, rphilli, mdwallis, vouk, lester}@ncsu.edu
</email>
<sectionHeader confidence="0.995331" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985533333333">
The field of intelligent tutoring systems has
seen many successes in recent years. A
significant remaining challenge is the
automatic creation of corpus-based tutorial
dialogue management models. This paper
reports on early work toward this goal. We
identify tutorial dialogue modes in an
unsupervised fashion using hidden Markov
models (HMMs) trained on input
sequences of manually-labeled dialogue
acts and adjacency pairs. The two best-fit
HMMs are presented and compared with
respect to the dialogue structure they
suggest; we also discuss potential uses of
the methodology for future work.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.987566">
The field of intelligent tutoring systems has made
great strides toward bringing the benefits of one-
on-one tutoring to a wider population of learners.
Some intelligent tutoring systems, called tutorial
dialogue systems, support learners by engaging in
rich natural language dialogue, e.g., (Graesser et
al. 2003; Zinn, Moore &amp; Core 2002; Evens &amp;
Michael 2006; Aleven, Koedinger &amp; Popescu
2003; Litman et al. 2006; Arnott, Hastings &amp;
Allbritton 2008; VanLehn et al. 2002). However,
creating these systems comes at a high cost: it
entails handcrafting each pedagogical strategy the
tutor might use and then realizing these strategies
in a dialogue management framework that is also
custom-engineered for the application. It is hoped
that the next generation of these systems can
leverage corpora of tutorial dialogue in order to
provide more robust dialogue management models
that capture the discourse phenomena present in
effective natural language tutoring.
The structure of tutorial dialogue has
traditionally been studied by manually examining
corpora and focusing on cognitive and
motivational aspects of tutorial strategies (e.g.,
Lepper et al. 1993; Graesser, Person &amp; Magliano
1995). While these approaches yielded
foundational results for the field, such analyses
suffer from two serious limitations: manual
approaches are not easily scalable to different or
larger corpora, and the rigidity of handcrafted
dialogue structure tagging schemes may not
capture all the phenomena that occur in practice.
In contrast, the stochastic nature of dialogue
lends itself to description through probabilistic
models. In tutorial dialogue, some early work has
adapted language processing techniques, namely n-
gram analyses, to examine human tutors’ responses
to student uncertainty (Forbes-Riley &amp; Litman
2005), as well as to find correlations between local
tutoring strategies and student outcomes (Boyer et
al. 2008). However, this work is limited by its
consideration of small dialogue windows.
Looking at a broader window of turns is often
accomplished by modeling the dialogue as a
Markov decision process. With this approach,
</bodyText>
<page confidence="0.992343">
19
</page>
<note confidence="0.9921685">
Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19–26,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99981214">
techniques such as reinforcement learning can be
used to compare potential policies in terms of
effectiveness for student learning. Determining
relevant feature sets (Tetreault &amp; Litman 2008)
and conducting focussed experiments for localized
strategy effectiveness (Chi et al. 2008) are active
areas of research in this line of investigation.
These approches often fix the dialogue structures
under consideration in order to compare the
outcomes associated with those structures or the
features that influence policy choice.
In contrast to treating dialogue structure as a
fixed entity, one approach for modeling the
progression of complete dialogues involves
learning the higher-level structure in order to infer
succinct probabilistic models of the interaction.
For example, data-driven approaches for
discovering dialogue structure have been applied to
corpora of human-human task-oriented dialogue
using general models of task structure (Bangalore,
Di Fabbrizio &amp; Stent 2006). Encouraging results
have emerged from using a general model of the
task structure to inform automatic dialogue act
tagging as well as subtask segmentation.
Our current work examines a modeling
technique that does not require a priori knowledge
of the task structure: specifically, we propose to
use hidden Markov models (HMMs) (Rabiner
1989) to capture the structure of tutorial dialogue
implicit within sequences of tagged dialogue acts.
Such probablistic inference of discourse structure
has been used in recent work with HMMs for topic
identification (Barzilay &amp; Lee 2004) and related
graphical models for segmenting multi-party
spoken discourse (Purver et al. 2006).
Analogously, our current work focuses on
identifying dialogic structures that emerge during
tutorial dialogue. Our approach is based on the
premise that at any given point in the tutorial
dialogue, the collaborative interaction is “in” a
dialogue mode (Cade et al. 2008) that characterizes
the nature of the exchanges between tutor and
student; these modes correspond to the hidden
states in the HMM. Results to date suggest that
meaningful descriptive models of tutorial dialogue
can be generated by this simple stochastic
modeling technique. This paper focuses on the
comparison of two first-order HMMs: one trained
on sequences of dialogue acts, and the second
trained on sequences of adjacency pairs.
</bodyText>
<sectionHeader confidence="0.857877" genericHeader="method">
2 Corpus Analysis
</sectionHeader>
<bodyText confidence="0.999827285714286">
The HMMs were trained on a corpus of human-
human tutorial dialogue collected in the domain of
introductory computer science. Forty-three
learners interacted remotely with one of fourteen
tutors through a keyboard-to-keyboard remote
learning environment yielding 4,864 dialogue
moves.
</bodyText>
<subsectionHeader confidence="0.987476">
2.1 Dialogue Act Tagging
</subsectionHeader>
<bodyText confidence="0.999921333333333">
The tutoring corpus was manually tagged with
dialogue acts designed to capture the salient
characteristics of the tutoring process (Table 1).
</bodyText>
<figure confidence="0.875191166666667">
Tag Act Example
Q Question Where should I
Declare i?
EQ Evaluation Question How does that look?
S Statement You need a
closing brace.
G Grounding Ok.
EX Extra-Domain You may use
your book.
PF Positive Feedback Yes, that’s right.
LF Lukewarm Feedback Sort of.
NF Negative Feedback No, that’s not right.
</figure>
<tableCaption confidence="0.973611">
Table 1. Dialogue Act Tags
</tableCaption>
<bodyText confidence="0.999870375">
The correspondence between utterances and
dialogue act tags is one-to-one; compound
utterances were split by the primary annotator prior
to the inter-rater reliability study.1 This dialogue
act tagging effort produced sequences of dialogue
acts that have been used in their un-altered forms
to train one of the two HMMs presented here
(Section 3).
</bodyText>
<subsectionHeader confidence="0.999533">
2.2 Adjacency Pair Identification
</subsectionHeader>
<bodyText confidence="0.99999575">
In addition to the HMM trained on sequences of
individual dialogue acts, another HMM was
trained on sequences of dialogue act adjacency
pairs. The importance of adjacency pairs is well-
established in natural language dialogue (e.g.,
Schlegoff &amp; Sacks 1973), and adjacency pair
analysis has illuminated important phenomena in
tutoring as well (Forbes-Riley et al. 2007). The
</bodyText>
<footnote confidence="0.984649333333333">
1 Details of the study procedure used to collect the corpus, as
well as Kappa statistics for inter-rater reliability, are reported
in (Boyer et al. 2008).
</footnote>
<page confidence="0.994484">
20
</page>
<bodyText confidence="0.999898464285714">
intuition behind adjacency pairs is that certain
dialogue acts naturally occur together, and by
grouping these acts we capture an exchange
between two conversants in a single structure.
This formulation is of interest for our purposes
because when treating sequences of dialogue acts
as a Markov process, with or without hidden states,
the addition of adjacency pairs may offer a
semantically richer observation alphabet.
To find adjacency pairs we utilize a χ2 test for
independence of the categorical variables act; and
act;+l for all sequential pairs of dialogue acts that
occur in the corpus. Only pairs in which
speaker(act;) ≠ speaker(act;+l) were considered.
Table 2 displays a list of all dependent adjacency
pairs sorted by descending (unadjusted) statistical
significance; the subscript on each dialogue act tag
indicates tutor (t) or student (s).
An adjacency pair joining algorithm was applied
to join statistically significant pairs of dialogue
acts (p&lt;0.01) into atomic units according to a
priority determined by the strength of the statistical
significance. Dialogue acts that were “left out” of
adjacency pair groupings were treated as atomic
elements in subsequent analysis. Figure 1
illustrates the application of the adjacency pair
joining algorithm on a sequence of dialogue acts
from the corpus.
</bodyText>
<figureCaption confidence="0.996101">
Figure 1. DA Sequence Before/After Joining
</figureCaption>
<sectionHeader confidence="0.92276" genericHeader="method">
3 HMM of Dialogue Structure
</sectionHeader>
<bodyText confidence="0.9995605">
A hidden Markov model is defined by three
constituents: 1) the set of h;dden states (dialogue
modes), each characterized by its emission
probability distribution over the possible
observat;ons (dialogue acts and/or adjacency
pairs), 2) the transition probability matrix among
observat;ons (dialogue acts and/or adjacency
pairs), 2) the transition probability matrix among
</bodyText>
<table confidence="0.99658868">
act; act;+, P(act;��� P(act;��� χ2 p��al
act;) react;) �al
EQ, PFt 0.48 0.07 654 &lt;0.0001
Gs Gt 0.27 0.03 380 &lt;0.0001
EXs EXt 0.34 0.03 378 &lt;0.0001
EQt PFs 0.18 0.01 322 &lt;0.0001
EQt Ss 0.24 0.03 289 &lt;0.0001
EQs LFt 0.13 0.01 265 &lt;0.0001
Qt Ss 0.65 0.04 235 &lt;0.0001
EQt LFs 0.07 0.00 219 &lt;0.0001
Qs St 0.82 0.38 210 &lt;0.0001
EQs NFt 0.08 0.01 207 &lt;0.0001
EXt EXs 0.19 0.02 177 &lt;0.0001
NFs Gt 0.29 0.03 172 &lt;0.0001
EQt NFs 0.11 0.01 133 &lt;0.0001
Ss Gt 0.16 0.03 95 &lt;0.0001
Ss PFt 0.30 0.10 90 &lt;0.0001
St Gs 0.07 0.04 36 &lt;0.0001
PFs Gt 0.14 0.04 34 &lt;0.0001
LFs Gt 0.22 0.04 30 &lt;0.0001
St EQs 0.11 0.07 29 &lt;0.0001
Gt EXs 0.07 0.03 14 0.002
St Qs 0.07 0.05 14 0.0002
Gt Gs 0.10 0.05 9 0.0027
EQt EQs 0.13 0.08 8 0.0042
</table>
<tableCaption confidence="0.999841">
Table 2. All Dependent Adjacency Pairs
</tableCaption>
<bodyText confidence="0.9892495">
hidden states, and 3) the initial hidden state
(dialogue mode) probability distribution.
</bodyText>
<subsectionHeader confidence="0.99992">
3.1 Discovering Number of Dialogue Modes
</subsectionHeader>
<bodyText confidence="0.999985875">
In keeping with the goal of automatically
discovering dialogue structure, it was desirable to
learn n, the best number of hidden states for the
HMM, during modeling. To this end, we trained
and ten-fold cross-validated seven models, each
featuring randomly-initialized parameters, for each
number of hidden states n from 2 to 15, inclusive.2
The average log-likelihood fit from ten-fold cross-
</bodyText>
<footnote confidence="0.8720938">
2 n=15 was chosen as an initial maximum number of states
because it comfortably exceeded our hypothesized range of 3
to 7 (informed by the tutoring literature). The Akaike
Information Criterion measure steadily worsened above n = 5,
confirming no need to train models with n &gt; 15.
</footnote>
<page confidence="0.998525">
21
</page>
<bodyText confidence="0.999748875">
validation was computed across all seven models
for each n, and this average log-likelihood ln was
used to compute the Akaike Information Criterion,
a maximum-penalized likelihood estimator that
prefers simpler models (Scott 2002). This
modeling approach was used to train HMMs on
both the dialogue act and the adjacency pair input
sequences.
</bodyText>
<subsectionHeader confidence="0.989795">
3.2 Best-Fit Models
</subsectionHeader>
<bodyText confidence="0.99996205882353">
The input sequences of individual dialogue acts
contain 16 unique symbols because each of the 8
dialogue act tags (Table 1) was augmented with a
label of the speaker, either tutor or student. The
best-fit HMM for this input sequence contains
nDA=5 hidden states. The adjacency pair input
sequences contain 39 unique symbols, including all
dependent adjacency pairs (Table 2) along with all
individual dialogue acts because each dialogue act
occurs at some point outside an adjacency pair.
The best-fit HMM for this input sequence contains
nAP=4 hidden states. In both cases, the best-fit
number of dialogue modes implied by the hidden
states is within the range of what is often
considered in traditional tutorial dialogue analysis
(Cade et al. 2008; Graesser, Person &amp; Magliano
1995).
</bodyText>
<sectionHeader confidence="0.996336" genericHeader="method">
4 Analysis
</sectionHeader>
<bodyText confidence="0.9999078">
Evaluating the impact of grouping the dialogue
acts into adjacency pairs requires a fine-grained
examination of the generated HMMs to gain
insight into how each model interprets the student
sessions.
</bodyText>
<subsectionHeader confidence="0.986202">
4.1 Dialogue Act HMM
</subsectionHeader>
<bodyText confidence="0.968490090909091">
Figure 2 displays the emission probability
distributions for the dialogue act HMM. State 0DA,
Tutor Lecture,3 is strongly dominated by tutor
statements with some student questions and
positive tutor feedback. State 1DA constitutes
Grounding/Extra-Domain, a conversational state
consisting of acknowledgments, backchannels, and
discussions that do not relate to the computer
science task. State 2DA, Student Reflection,
3 For simplicity, the states of each HMM have been named
according to an intuitive interpretation of the emission
probability distribution.
generates student evaluation questions, statements,
and positive and negative feedback. State 3DA is
comprised of tutor utterances, with positive
feedback occurring most commonly followed by
statements, grounding, lukewarm feedback, and
negative feedback. This state is interpreted as a
Tutor Feedback mode. Finally, State 4DA, Tutor
Lecture/Probing, is characterized by tutor
statements and evaluative questions with some
student grounding statements.
</bodyText>
<figureCaption confidence="0.977691">
Figure 2. Emission Probability Distributions for
Dialogue Act HMM
</figureCaption>
<bodyText confidence="0.999466230769231">
The state transition diagram (Figure 3) illustrates
that Tutor Lecture (0DA) and Grounding/Extra-
Domain (1DA) are stable states whose probability of
self-transition is high: 0.75 and 0.79, respectively.
Perhaps not surprisingly, Student Reflection (2DA)
is most likely to transition to Tutor Feedback (3DA)
with probability 0.77. Tutor Feedback (3DA)
transitions to Tutor Lecture (0DA) with probability
0.60, Tutor Lecture/Probing (4DA) with probability
0.26, and Student Reflection (2DA) with probability
0.09. Finally, Tutor Lecture/Probing (4DA) very
often transitions to Student Reflection (2DA) with
probability 0.82.
</bodyText>
<page confidence="0.997053">
22
</page>
<figureCaption confidence="0.999237">
Figure 3. Transition diagram for dialogue act HMM
</figureCaption>
<subsectionHeader confidence="0.934118">
4.2 Adjacency Pair HMM
</subsectionHeader>
<bodyText confidence="0.999471043478261">
Figure 4 displays the emission probability
distributions for the HMM that was trained on the
input sequences of adjacency pairs. State 0AP,
Tutor Lecture, consists of tutorial statements,
positive feedback, and dialogue turns initiated by
student questions. In this state, student evaluation
questions occur in adjacency pairs with positive
tutor feedback, and other student questions are
answered by tutorial statements. State 1AP, Tutor
Evaluation, generates primarily tutor evaluation
questions, along with the adjacency pair of tutorial
statements followed by student acknowledgements.
State 2AP generates conversational grounding and
extra-domain talk; this Grounding/Extra-Domain
state is dominated by the adjacency pair of student
grounding followed by tutor grounding. State 3AP
is comprised of several adjacency pairs: student
questions followed by tutor answers, student
statements with positive tutor feedback, and
student evaluation questions followed by positive
feedback. This Question/Answer state also
generates some tutor grounding and student
evaluation questions outside of adjacency pairs.
</bodyText>
<figureCaption confidence="0.896962">
Figure 4. Emission Probability Distributions for
Adjacency Pair HMM
</figureCaption>
<figure confidence="0.9998032">
p &gt; 0.5
0.1 ≤ p ≤ 0.50
0.05 ≤ p &lt; 0.1
ODA
4DA
2DA
3DA
1DA
DAP
3AP
1AP
2AP
p &gt; 0.5
0.1 ≤ p ≤ 0.50
0.05 ≤ p &lt; 0.1
</figure>
<figureCaption confidence="0.9998">
Figure 5. Transition diagram for adjacency pair HMM
</figureCaption>
<page confidence="0.993226">
23
</page>
<subsectionHeader confidence="0.975402">
4.3 Dialogue Mode Sequences
</subsectionHeader>
<bodyText confidence="0.999856666666667">
In order to illustrate how the above models fit the
data, Figure 6 depicts the progression of dialogue
modes that generate an excerpt from the corpus.
</bodyText>
<figureCaption confidence="0.815105">
Figure 6. Best-fit sequences of hidden states
</figureCaption>
<bodyText confidence="0.999882692307692">
In both models, the most commonly-occurring
dialogue mode is Tutor Lecture, which generates
45% of observations in the dialogue act model and
around 60% in the adjacency pair model.
Approximately 15% of the dialogue act HMM
observations are fit to each of states Student
Reflection, Tutor Feedback, and Tutor
Lecture/probing. This model spends the least
time, around 8%, in Grounding/Extra Domain.
The adjacency pair model fits approximately 15%
of its observations to each of Tutor Evaluation and
Question/Answer, with around 8% in
Grounding/Extra-Domain.
</bodyText>
<subsectionHeader confidence="0.997984">
4.4 Model Comparison
</subsectionHeader>
<bodyText confidence="0.9926980625">
While the two models presented here describe the
same corpus, it is important to exercise caution
when making direct structural comparisons. The
models contain neither the same number of hidden
states nor the same emission symbol alphabet;
therefore, our comparison will be primarily
qualitative. It is meaningful to note, however, that
the adjacency pair model with nAp=4 achieved an
average log-likelihood fit on the training data that
was 5.8% better than the same measure achieved
by the dialogue act model with nDA=5, despite the
adjacency pair input sequences containing greater
than twice the number of unique symbols.4
4 This comparison is meaningful because the models depicted
here provided the best fit among all sizes of models trained for
the same input scenario.
Our qualitative comparison begins by examining
the modes that are highly similar in the two
models. State 2Ap generates grounding and extra-
domain statements, as does State 1DA. These two
states both constitute a Grounding/Extra-Domain
dialogue mode. One artifact of the tutoring study
design is that all sessions begin in this state due to
a compulsory greeting that signaled the start of
each session. More precisely, the initial state
probability distribution for each HMM assigns
probability 1 to this state and probability 0 to all
other states.
Another dialogue mode that is structurally
similar in the two models is Tutor Lecture, in
which the majority of utterances are tutor
statements. This mode is captured in State 0 in
both models, with State 0Ap implying more detail
than State 0DA because it is certain in the former
that some of the tutor statements and positive
feedback occurred in response to student questions.
While student questions are present in State 0DA, no
such precise ordering of the acts can be inferred, as
discussed in Section 1.
Other states do not have one-to-one
correspondence between the two models. State
2DA, Student Reflection, generates only student
utterances and the self-transition probability for the
state is very low; the dialogue usually visits State
2DA for one turn and then transitions immediately
to another state. Although this aspect of the model
reflects the fact that students rarely keep the floor
for more than one utterance at a time in the corpus,
such quick dialogue mode transitions are
inconsistent with an intuitive understanding of
tutorial dialogue modes as meta-structures that
usually encompass more than one dialogue turn.
This phenomenon is perhaps more accurately
captured in the adjacency pair model. For
example, the dominant dialogue act of State 2DA is
a student evaluation question (EQs). In contrast,
these dialogue acts are generated as part of an
adjacency pair by State 3Ap; this model joins the
student questions with subsequent positive
feedback from the tutor rather than generating the
question and then transitioning to a new dialogue
mode. Further addressing the issue of frequent
state transitions is discussed as future work in
Section 6.
</bodyText>
<page confidence="0.998849">
24
</page>
<sectionHeader confidence="0.964487" genericHeader="evaluation">
5 Discussion and Limitations
</sectionHeader>
<bodyText confidence="0.999975333333333">
Overall, the adjacency pair model is preferable for
our purposes because its structure lends itself more
readily to interpretation as a set of dialogue modes
each of which encompasses more than one
dialogue move. This structural property is
guaranteed by the inclusion of adjacency pairs as
atomic elements. In addition, although the set of
emission symbols increased to include significant
adjacency pairs along with all dialogue acts, the
log-likelihood fit of this model was slightly higher
than the same measure for the HMM trained on the
sequences of dialogue acts alone. The remainder
of this section focuses on properties of the
adjacency pair model.
One promising result of this early work emerges
from the fact that by applying hidden Markov
modeling to sequences of adjacency pairs,
meaningful dialogue modes have emerged that are
empirically justified. The number of these
dialogue modes is consistent with what researchers
have traditionally used as a set of hypothesized
tutorial dialogue modes. Moreover, the
composition of the dialogue modes reflects some
recognizable aspects of tutoring sessions: tutors
teach through the Tutor Lecture mode and give
feedback on student knowledge in a Tutor
Evaluation mode. Students ask questions and state
their own perception of their knowledge in a
Question/�nswer mode. Both parties engage in
“housekeeping” talk containing such things as
greetings and acknowledgements, and sometimes,
even in a controlled environment, extra-domain
conversation occurs between the conversants in the
Grounding/Extra-Domain mode.
Although the tutorial modes discovered may not
map perfectly to sets of handcrafted tutorial
dialogue modes from the literature (e.g., Cade et
al. 2008), it is rare for such a perfect mapping to
exist even between those sets of handcrafted
modes. In addition, the HMM framework allows
for succinct probabilistic description of the
phenomena at work during the tutoring session:
through the state transition matrix, we can see the
back-and-forth flow of the dialogue among its
modes.
</bodyText>
<sectionHeader confidence="0.99617" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999953432432432">
Automatically learning dialogue structure is an
important step toward creating more robust tutorial
dialogue management systems. We have presented
two hidden Markov models in which the hidden
states are interpreted as dialogue modes for task-
oriented tutorial dialogue. These models were
learned in an unsupervised fashion from manually-
labeled dialogue acts. HMMs offer concise
stochastic models of the complex interaction
patterns occurring in natural language tutorial
dialogue. The evidence suggests this
methodology, which as presented requires only a
sequence of dialogue acts as input, holds promise
for automatically discovering the structure of
tutorial dialogue.
Future work will involve conducting evaluations
to determine the benefits gained by using HMMs
compared to simpler statistical models. In
addition, it is possible that more general types of
graphical models will prove useful in overcoming
some limitations of HMMs, such as their arbitrarily
frequent state transitions, to more readily capture
the phenomena of interest. The descriptive insight
offered by these exploratory models may also be
increased by future work in which the input
sequences are enhanced with information about the
surface-level content of the utterance. In addition,
knowledge of the task state within the tutoring
session can be used to segment the dialogue in
meaningful ways to further refine model structure.
It is also hoped that these models can identify
empirically-derived tutorial dialogue structures that
can be associated with measures of effectiveness
such as student learning (Soller &amp; Stevens 2007).
These lines of investigation could inform the
development of next-generation natural language
tutorial dialogue systems.
</bodyText>
<sectionHeader confidence="0.998311" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995871888888889">
Thanks to Marilyn Walker and Dennis Bahler for
insightful early discussions on the dialogue and machine
learning aspects of this work, respectively. This
research was supported by the National Science
Foundation under Grants REC-0632450, IIS-0812291,
CNS-0540523, and GRFP. Any opinions, findings, and
conclusions or recommendations expressed in this
material are those of the authors and do not necessarily
reflect the views of the National Science Foundation.
</bodyText>
<page confidence="0.997393">
25
</page>
<sectionHeader confidence="0.989469" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996426460784314">
Aleven, V., K. Koedinger, and O. Popescu. 2003. A
tutorial dialog system to support self-explanation:
Evaluation and open questions. Proceedings of the
11th International Conference on Artificial
Intelligence in Education: 39-46.
Arnott, E., P. Hastings, and D. Allbritton. 2008.
Research methods tutor: Evaluation of a dialogue-
based tutoring system in the classroom. Behavioral
Research Methods 40(3): 694-698.
Bangalore, S., Di Fabbrizio, G., and Stent, A. 2006.
Learning the structure of task-driven human-human
dialogs. Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the ACL: 201-208.
Barzilay, R., and Lee, L. 2004. Catching the drift:
Probabilistic content models, with applications to
generation and summarization. Proceedings of
NAACL HLT: 113–120.
Boyer, K. E., Phillips, R., Wallis, M., Vouk, M., and
Lester, J. 2008. Balancing cognitive and
motivational scaffolding in tutorial dialogue.
Proceedings of the 9th International Conference on
Intelligent Tutoring Systems: 239-249.
Cade, W., Copeland, J., Person, N., and D&apos;Mello, S.
2008. Dialog modes in expert tutoring. Proceedings
of the 9th International Conference on Intelligent
Tutoring Systems: 470-479.
Chi, M., Jordan, P., VanLehn, K., and Hall, M. 2008.
Reinforcement learning-based feature selection for
developing pedagogically effective tutorial dialogue
tactics. Proceedings of the 1st International
Conference on Educational Data Mining: 258-265.
Evens, M., and J. Michael. 2006. One-on-one tutoring
by humans and computers. Lawrence Erlbaum
Associates, Mahwah, New Jersey.
Forbes-Riley, K., and Litman, D. J. 2005. Using
bigrams to identify relationships between student
certainness states and tutor responses in a spoken
dialogue corpus. Proceedings of the 6th SIGdial
Workshop on Discourse and Dialogue: 87-96.
Forbes-Riley, K., Rotaru, M., Litman, D. J., and
Tetreault, J. 2007. Exploring affect-context
dependencies for adaptive system development.
Proceedings ofNAACL HLT: 41-44.
Graesser, A., G. Jackson, E. Mathews, H. Mitchell, A.
Olney, M. Ventura, and P. Chipman. 2003.
Why/AutoTutor: A test of learning gains from a
physics tutor with natural language dialog.
Proceedings of the Twenty-Fifth Annual Conference
of the Cognitive Science Society: 1-6.
Graesser, A. C., N. K. Person, and J. P. Magliano. 1995.
Collaborative dialogue patterns in naturalistic one-
to-one tutoring. Applied Cognitive Psychology 9(6):
495–522.
Lepper, M. R., M. Woolverton, D. L. Mumme, and J. L.
Gurtner. 1993. Motivational techniques of expert
human tutors: Lessons for the design of computer-
based tutors. Pages 75-105 in S. P. Lajoie, and S. J.
Derry, editors. Computers as cognitive tools.
Lawrence Erlbaum Associates, Hillsdale, New
Jersey.
Litman, D. J., C. P. Rosé, K. Forbes-Riley, K. VanLehn,
D. Bhembe, and S. Silliman. 2006. Spoken versus
typed human and computer dialogue tutoring.
International Journal of Artificial Intelligence in
Education 16(2): 145-170.
Purver, M., Kording, K. P., Griffiths, T. L., and
Tenenbaum, J. B. 2006. Unsupervised topic
modelling for multi-party spoken discourse.
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting
of the ACL: 17-24.
Rabiner, L. R. 1989. A tutorial on hidden Markov
models and selected applications in speech
recognition. Proceedings of the IEEE 77(2): 257-
286.
Schlegoff, E., and H. Sacks. 1973. Opening up closings.
Semiotica 7(4): 289-327.
Scott, S. L. 2002. Bayesian methods for hidden Markov
models: Recursive computing in the 21st century.
Journal of the American Statistical Association
97(457): 337-352.
Soller, A., and R. Stevens. 2007. Applications of
stochastic analyses for collaborative learning and
cognitive assessment. Pages 217-253 in G. R.
Hancock, and K. M. Samuelsen, editors. Advances
in latent variable mixture models. Information Age
Publishing.
Tetreault, J. R., and D. J. Litman. 2008. A
reinforcement learning approach to evaluating state
representations in spoken dialogue systems. Speech
Communication 50(8-9): 683-696.
VanLehn, K., P. W. Jordan, C. P. Rose, D. Bhembe, M.
Bottner, A. Gaydos, M. Makatchev, U.
Pappuswamy, M. Ringenberg, and A. Roque. 2002.
The architecture of Why2-atlas: A coach for
qualitative physics essay writing. Proceedings of
Intelligent Tutoring Systems Conference: 158–167.
Zinn, C., Moore, J. D., and Core, M. G. 2002. A 3-tier
planning architecture for managing tutorial dialogue.
Proceedings of the 6th International Conference on
Intelligent Tutoring Systems: 574-584.
</reference>
<page confidence="0.998051">
26
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.506313">
<title confidence="0.999837">Inferring Tutorial Dialogue Structure with Hidden Markov Modeling</title>
<author confidence="0.7613665">Kristy Elizabeth Eun Robert Michael D Mladen James of Computer Science</author>
<author confidence="0.7613665">North Carolina State</author>
<affiliation confidence="0.981279">Research</affiliation>
<address confidence="0.994119">Raleigh, NC, USA</address>
<email confidence="0.999793">keboyer@ncsu.edu</email>
<email confidence="0.999793">eha@ncsu.edu</email>
<email confidence="0.999793">rphilli@ncsu.edu</email>
<email confidence="0.999793">mdwallis@ncsu.edu</email>
<email confidence="0.999793">vouk@ncsu.edu</email>
<email confidence="0.999793">lester@ncsu.edu</email>
<abstract confidence="0.9996904375">The field of intelligent tutoring systems has seen many successes in recent years. A significant remaining challenge is the automatic creation of corpus-based tutorial dialogue management models. This paper reports on early work toward this goal. We tutorial dialogue an unsupervised fashion using hidden Markov models (HMMs) trained on input sequences of manually-labeled dialogue acts and adjacency pairs. The two best-fit HMMs are presented and compared with respect to the dialogue structure they suggest; we also discuss potential uses of the methodology for future work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>V Aleven</author>
<author>K Koedinger</author>
<author>O Popescu</author>
</authors>
<title>A tutorial dialog system to support self-explanation: Evaluation and open questions.</title>
<date>2003</date>
<booktitle>Proceedings of the 11th International Conference on Artificial Intelligence in Education:</booktitle>
<pages>39--46</pages>
<marker>Aleven, Koedinger, Popescu, 2003</marker>
<rawString>Aleven, V., K. Koedinger, and O. Popescu. 2003. A tutorial dialog system to support self-explanation: Evaluation and open questions. Proceedings of the 11th International Conference on Artificial Intelligence in Education: 39-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Arnott</author>
<author>P Hastings</author>
<author>D Allbritton</author>
</authors>
<title>Research methods tutor: Evaluation of a dialoguebased tutoring system in the classroom.</title>
<date>2008</date>
<journal>Behavioral Research Methods</journal>
<volume>40</volume>
<issue>3</issue>
<pages>694--698</pages>
<marker>Arnott, Hastings, Allbritton, 2008</marker>
<rawString>Arnott, E., P. Hastings, and D. Allbritton. 2008. Research methods tutor: Evaluation of a dialoguebased tutoring system in the classroom. Behavioral Research Methods 40(3): 694-698.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Di Fabbrizio</author>
<author>A Stent</author>
</authors>
<title>Learning the structure of task-driven human-human dialogs.</title>
<date>2006</date>
<booktitle>Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL:</booktitle>
<pages>201--208</pages>
<marker>Bangalore, Di Fabbrizio, Stent, 2006</marker>
<rawString>Bangalore, S., Di Fabbrizio, G., and Stent, A. 2006. Learning the structure of task-driven human-human dialogs. Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL: 201-208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>Proceedings of NAACL HLT:</booktitle>
<pages>113--120</pages>
<contexts>
<context position="4841" citStr="Barzilay &amp; Lee 2004" startWordPosition="701" endWordPosition="704">ture (Bangalore, Di Fabbrizio &amp; Stent 2006). Encouraging results have emerged from using a general model of the task structure to inform automatic dialogue act tagging as well as subtask segmentation. Our current work examines a modeling technique that does not require a priori knowledge of the task structure: specifically, we propose to use hidden Markov models (HMMs) (Rabiner 1989) to capture the structure of tutorial dialogue implicit within sequences of tagged dialogue acts. Such probablistic inference of discourse structure has been used in recent work with HMMs for topic identification (Barzilay &amp; Lee 2004) and related graphical models for segmenting multi-party spoken discourse (Purver et al. 2006). Analogously, our current work focuses on identifying dialogic structures that emerge during tutorial dialogue. Our approach is based on the premise that at any given point in the tutorial dialogue, the collaborative interaction is “in” a dialogue mode (Cade et al. 2008) that characterizes the nature of the exchanges between tutor and student; these modes correspond to the hidden states in the HMM. Results to date suggest that meaningful descriptive models of tutorial dialogue can be generated by thi</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Barzilay, R., and Lee, L. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. Proceedings of NAACL HLT: 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K E Boyer</author>
<author>R Phillips</author>
<author>M Wallis</author>
<author>M Vouk</author>
<author>J Lester</author>
</authors>
<title>Balancing cognitive and motivational scaffolding in tutorial dialogue.</title>
<date>2008</date>
<booktitle>Proceedings of the 9th International Conference on Intelligent Tutoring Systems:</booktitle>
<pages>239--249</pages>
<contexts>
<context position="2874" citStr="Boyer et al. 2008" startWordPosition="414" endWordPosition="417">s limitations: manual approaches are not easily scalable to different or larger corpora, and the rigidity of handcrafted dialogue structure tagging schemes may not capture all the phenomena that occur in practice. In contrast, the stochastic nature of dialogue lends itself to description through probabilistic models. In tutorial dialogue, some early work has adapted language processing techniques, namely ngram analyses, to examine human tutors’ responses to student uncertainty (Forbes-Riley &amp; Litman 2005), as well as to find correlations between local tutoring strategies and student outcomes (Boyer et al. 2008). However, this work is limited by its consideration of small dialogue windows. Looking at a broader window of turns is often accomplished by modeling the dialogue as a Markov decision process. With this approach, 19 Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19–26, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics techniques such as reinforcement learning can be used to compare potential policies in terms of effectiveness for student learning. Determining relevant feature sets (Tetreault &amp; Litman 200</context>
<context position="7347" citStr="Boyer et al. 2008" startWordPosition="1087" endWordPosition="1090"> to train one of the two HMMs presented here (Section 3). 2.2 Adjacency Pair Identification In addition to the HMM trained on sequences of individual dialogue acts, another HMM was trained on sequences of dialogue act adjacency pairs. The importance of adjacency pairs is wellestablished in natural language dialogue (e.g., Schlegoff &amp; Sacks 1973), and adjacency pair analysis has illuminated important phenomena in tutoring as well (Forbes-Riley et al. 2007). The 1 Details of the study procedure used to collect the corpus, as well as Kappa statistics for inter-rater reliability, are reported in (Boyer et al. 2008). 20 intuition behind adjacency pairs is that certain dialogue acts naturally occur together, and by grouping these acts we capture an exchange between two conversants in a single structure. This formulation is of interest for our purposes because when treating sequences of dialogue acts as a Markov process, with or without hidden states, the addition of adjacency pairs may offer a semantically richer observation alphabet. To find adjacency pairs we utilize a χ2 test for independence of the categorical variables act; and act;+l for all sequential pairs of dialogue acts that occur in the corpus</context>
</contexts>
<marker>Boyer, Phillips, Wallis, Vouk, Lester, 2008</marker>
<rawString>Boyer, K. E., Phillips, R., Wallis, M., Vouk, M., and Lester, J. 2008. Balancing cognitive and motivational scaffolding in tutorial dialogue. Proceedings of the 9th International Conference on Intelligent Tutoring Systems: 239-249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cade</author>
<author>J Copeland</author>
<author>N Person</author>
<author>S D&apos;Mello</author>
</authors>
<title>Dialog modes in expert tutoring.</title>
<date>2008</date>
<booktitle>Proceedings of the 9th International Conference on Intelligent Tutoring Systems:</booktitle>
<pages>470--479</pages>
<contexts>
<context position="5207" citStr="Cade et al. 2008" startWordPosition="756" endWordPosition="759">s) (Rabiner 1989) to capture the structure of tutorial dialogue implicit within sequences of tagged dialogue acts. Such probablistic inference of discourse structure has been used in recent work with HMMs for topic identification (Barzilay &amp; Lee 2004) and related graphical models for segmenting multi-party spoken discourse (Purver et al. 2006). Analogously, our current work focuses on identifying dialogic structures that emerge during tutorial dialogue. Our approach is based on the premise that at any given point in the tutorial dialogue, the collaborative interaction is “in” a dialogue mode (Cade et al. 2008) that characterizes the nature of the exchanges between tutor and student; these modes correspond to the hidden states in the HMM. Results to date suggest that meaningful descriptive models of tutorial dialogue can be generated by this simple stochastic modeling technique. This paper focuses on the comparison of two first-order HMMs: one trained on sequences of dialogue acts, and the second trained on sequences of adjacency pairs. 2 Corpus Analysis The HMMs were trained on a corpus of humanhuman tutorial dialogue collected in the domain of introductory computer science. Forty-three learners in</context>
<context position="11781" citStr="Cade et al. 2008" startWordPosition="1807" endWordPosition="1810">nted with a label of the speaker, either tutor or student. The best-fit HMM for this input sequence contains nDA=5 hidden states. The adjacency pair input sequences contain 39 unique symbols, including all dependent adjacency pairs (Table 2) along with all individual dialogue acts because each dialogue act occurs at some point outside an adjacency pair. The best-fit HMM for this input sequence contains nAP=4 hidden states. In both cases, the best-fit number of dialogue modes implied by the hidden states is within the range of what is often considered in traditional tutorial dialogue analysis (Cade et al. 2008; Graesser, Person &amp; Magliano 1995). 4 Analysis Evaluating the impact of grouping the dialogue acts into adjacency pairs requires a fine-grained examination of the generated HMMs to gain insight into how each model interprets the student sessions. 4.1 Dialogue Act HMM Figure 2 displays the emission probability distributions for the dialogue act HMM. State 0DA, Tutor Lecture,3 is strongly dominated by tutor statements with some student questions and positive tutor feedback. State 1DA constitutes Grounding/Extra-Domain, a conversational state consisting of acknowledgments, backchannels, and disc</context>
<context position="20729" citStr="Cade et al. 2008" startWordPosition="3155" endWordPosition="3158"> sessions: tutors teach through the Tutor Lecture mode and give feedback on student knowledge in a Tutor Evaluation mode. Students ask questions and state their own perception of their knowledge in a Question/�nswer mode. Both parties engage in “housekeeping” talk containing such things as greetings and acknowledgements, and sometimes, even in a controlled environment, extra-domain conversation occurs between the conversants in the Grounding/Extra-Domain mode. Although the tutorial modes discovered may not map perfectly to sets of handcrafted tutorial dialogue modes from the literature (e.g., Cade et al. 2008), it is rare for such a perfect mapping to exist even between those sets of handcrafted modes. In addition, the HMM framework allows for succinct probabilistic description of the phenomena at work during the tutoring session: through the state transition matrix, we can see the back-and-forth flow of the dialogue among its modes. 6 Conclusions and Future Work Automatically learning dialogue structure is an important step toward creating more robust tutorial dialogue management systems. We have presented two hidden Markov models in which the hidden states are interpreted as dialogue modes for ta</context>
</contexts>
<marker>Cade, Copeland, Person, D&apos;Mello, 2008</marker>
<rawString>Cade, W., Copeland, J., Person, N., and D&apos;Mello, S. 2008. Dialog modes in expert tutoring. Proceedings of the 9th International Conference on Intelligent Tutoring Systems: 470-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chi</author>
<author>P Jordan</author>
<author>K VanLehn</author>
<author>M Hall</author>
</authors>
<title>Reinforcement learning-based feature selection for developing pedagogically effective tutorial dialogue tactics.</title>
<date>2008</date>
<booktitle>Proceedings of the 1st International Conference on Educational Data Mining:</booktitle>
<pages>258--265</pages>
<contexts>
<context position="3567" citStr="Chi et al. 2008" startWordPosition="514" endWordPosition="517">s. Looking at a broader window of turns is often accomplished by modeling the dialogue as a Markov decision process. With this approach, 19 Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19–26, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics techniques such as reinforcement learning can be used to compare potential policies in terms of effectiveness for student learning. Determining relevant feature sets (Tetreault &amp; Litman 2008) and conducting focussed experiments for localized strategy effectiveness (Chi et al. 2008) are active areas of research in this line of investigation. These approches often fix the dialogue structures under consideration in order to compare the outcomes associated with those structures or the features that influence policy choice. In contrast to treating dialogue structure as a fixed entity, one approach for modeling the progression of complete dialogues involves learning the higher-level structure in order to infer succinct probabilistic models of the interaction. For example, data-driven approaches for discovering dialogue structure have been applied to corpora of human-human tas</context>
</contexts>
<marker>Chi, Jordan, VanLehn, Hall, 2008</marker>
<rawString>Chi, M., Jordan, P., VanLehn, K., and Hall, M. 2008. Reinforcement learning-based feature selection for developing pedagogically effective tutorial dialogue tactics. Proceedings of the 1st International Conference on Educational Data Mining: 258-265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Evens</author>
<author>J Michael</author>
</authors>
<title>One-on-one tutoring by humans and computers. Lawrence Erlbaum Associates,</title>
<date>2006</date>
<location>Mahwah, New Jersey.</location>
<contexts>
<context position="1320" citStr="Evens &amp; Michael 2006" startWordPosition="187" endWordPosition="190">ned on input sequences of manually-labeled dialogue acts and adjacency pairs. The two best-fit HMMs are presented and compared with respect to the dialogue structure they suggest; we also discuss potential uses of the methodology for future work. 1 Introduction The field of intelligent tutoring systems has made great strides toward bringing the benefits of oneon-one tutoring to a wider population of learners. Some intelligent tutoring systems, called tutorial dialogue systems, support learners by engaging in rich natural language dialogue, e.g., (Graesser et al. 2003; Zinn, Moore &amp; Core 2002; Evens &amp; Michael 2006; Aleven, Koedinger &amp; Popescu 2003; Litman et al. 2006; Arnott, Hastings &amp; Allbritton 2008; VanLehn et al. 2002). However, creating these systems comes at a high cost: it entails handcrafting each pedagogical strategy the tutor might use and then realizing these strategies in a dialogue management framework that is also custom-engineered for the application. It is hoped that the next generation of these systems can leverage corpora of tutorial dialogue in order to provide more robust dialogue management models that capture the discourse phenomena present in effective natural language tutoring.</context>
</contexts>
<marker>Evens, Michael, 2006</marker>
<rawString>Evens, M., and J. Michael. 2006. One-on-one tutoring by humans and computers. Lawrence Erlbaum Associates, Mahwah, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes-Riley</author>
<author>D J Litman</author>
</authors>
<title>Using bigrams to identify relationships between student certainness states and tutor responses in a spoken dialogue corpus.</title>
<date>2005</date>
<booktitle>Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue:</booktitle>
<pages>87--96</pages>
<contexts>
<context position="2766" citStr="Forbes-Riley &amp; Litman 2005" startWordPosition="397" endWordPosition="400">gliano 1995). While these approaches yielded foundational results for the field, such analyses suffer from two serious limitations: manual approaches are not easily scalable to different or larger corpora, and the rigidity of handcrafted dialogue structure tagging schemes may not capture all the phenomena that occur in practice. In contrast, the stochastic nature of dialogue lends itself to description through probabilistic models. In tutorial dialogue, some early work has adapted language processing techniques, namely ngram analyses, to examine human tutors’ responses to student uncertainty (Forbes-Riley &amp; Litman 2005), as well as to find correlations between local tutoring strategies and student outcomes (Boyer et al. 2008). However, this work is limited by its consideration of small dialogue windows. Looking at a broader window of turns is often accomplished by modeling the dialogue as a Markov decision process. With this approach, 19 Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19–26, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics techniques such as reinforcement learning can be used to compare potential polici</context>
</contexts>
<marker>Forbes-Riley, Litman, 2005</marker>
<rawString>Forbes-Riley, K., and Litman, D. J. 2005. Using bigrams to identify relationships between student certainness states and tutor responses in a spoken dialogue corpus. Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue: 87-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes-Riley</author>
<author>M Rotaru</author>
<author>D J Litman</author>
<author>J Tetreault</author>
</authors>
<title>Exploring affect-context dependencies for adaptive system development.</title>
<date>2007</date>
<booktitle>Proceedings ofNAACL HLT:</booktitle>
<pages>41--44</pages>
<contexts>
<context position="7188" citStr="Forbes-Riley et al. 2007" startWordPosition="1060" endWordPosition="1063">otator prior to the inter-rater reliability study.1 This dialogue act tagging effort produced sequences of dialogue acts that have been used in their un-altered forms to train one of the two HMMs presented here (Section 3). 2.2 Adjacency Pair Identification In addition to the HMM trained on sequences of individual dialogue acts, another HMM was trained on sequences of dialogue act adjacency pairs. The importance of adjacency pairs is wellestablished in natural language dialogue (e.g., Schlegoff &amp; Sacks 1973), and adjacency pair analysis has illuminated important phenomena in tutoring as well (Forbes-Riley et al. 2007). The 1 Details of the study procedure used to collect the corpus, as well as Kappa statistics for inter-rater reliability, are reported in (Boyer et al. 2008). 20 intuition behind adjacency pairs is that certain dialogue acts naturally occur together, and by grouping these acts we capture an exchange between two conversants in a single structure. This formulation is of interest for our purposes because when treating sequences of dialogue acts as a Markov process, with or without hidden states, the addition of adjacency pairs may offer a semantically richer observation alphabet. To find adjace</context>
</contexts>
<marker>Forbes-Riley, Rotaru, Litman, Tetreault, 2007</marker>
<rawString>Forbes-Riley, K., Rotaru, M., Litman, D. J., and Tetreault, J. 2007. Exploring affect-context dependencies for adaptive system development. Proceedings ofNAACL HLT: 41-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Graesser</author>
<author>G Jackson</author>
<author>E Mathews</author>
<author>H Mitchell</author>
<author>A Olney</author>
<author>M Ventura</author>
<author>P Chipman</author>
</authors>
<title>Why/AutoTutor: A test of learning gains from a physics tutor with natural language dialog.</title>
<date>2003</date>
<booktitle>Proceedings of the Twenty-Fifth Annual Conference of the Cognitive Science Society:</booktitle>
<pages>1--6</pages>
<contexts>
<context position="1273" citStr="Graesser et al. 2003" startWordPosition="178" endWordPosition="181"> fashion using hidden Markov models (HMMs) trained on input sequences of manually-labeled dialogue acts and adjacency pairs. The two best-fit HMMs are presented and compared with respect to the dialogue structure they suggest; we also discuss potential uses of the methodology for future work. 1 Introduction The field of intelligent tutoring systems has made great strides toward bringing the benefits of oneon-one tutoring to a wider population of learners. Some intelligent tutoring systems, called tutorial dialogue systems, support learners by engaging in rich natural language dialogue, e.g., (Graesser et al. 2003; Zinn, Moore &amp; Core 2002; Evens &amp; Michael 2006; Aleven, Koedinger &amp; Popescu 2003; Litman et al. 2006; Arnott, Hastings &amp; Allbritton 2008; VanLehn et al. 2002). However, creating these systems comes at a high cost: it entails handcrafting each pedagogical strategy the tutor might use and then realizing these strategies in a dialogue management framework that is also custom-engineered for the application. It is hoped that the next generation of these systems can leverage corpora of tutorial dialogue in order to provide more robust dialogue management models that capture the discourse phenomena </context>
</contexts>
<marker>Graesser, Jackson, Mathews, Mitchell, Olney, Ventura, Chipman, 2003</marker>
<rawString>Graesser, A., G. Jackson, E. Mathews, H. Mitchell, A. Olney, M. Ventura, and P. Chipman. 2003. Why/AutoTutor: A test of learning gains from a physics tutor with natural language dialog. Proceedings of the Twenty-Fifth Annual Conference of the Cognitive Science Society: 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Graesser</author>
<author>N K Person</author>
<author>J P Magliano</author>
</authors>
<title>Collaborative dialogue patterns in naturalistic oneto-one tutoring.</title>
<date>1995</date>
<journal>Applied Cognitive Psychology</journal>
<volume>9</volume>
<issue>6</issue>
<pages>495--522</pages>
<marker>Graesser, Person, Magliano, 1995</marker>
<rawString>Graesser, A. C., N. K. Person, and J. P. Magliano. 1995. Collaborative dialogue patterns in naturalistic oneto-one tutoring. Applied Cognitive Psychology 9(6): 495–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Lepper</author>
<author>M Woolverton</author>
<author>D L Mumme</author>
<author>J L Gurtner</author>
</authors>
<title>Motivational techniques of expert human tutors: Lessons for the design of computerbased tutors.</title>
<date>1993</date>
<pages>75--105</pages>
<editor>in S. P. Lajoie, and S. J. Derry, editors.</editor>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="2116" citStr="Lepper et al. 1993" startWordPosition="305" endWordPosition="308"> handcrafting each pedagogical strategy the tutor might use and then realizing these strategies in a dialogue management framework that is also custom-engineered for the application. It is hoped that the next generation of these systems can leverage corpora of tutorial dialogue in order to provide more robust dialogue management models that capture the discourse phenomena present in effective natural language tutoring. The structure of tutorial dialogue has traditionally been studied by manually examining corpora and focusing on cognitive and motivational aspects of tutorial strategies (e.g., Lepper et al. 1993; Graesser, Person &amp; Magliano 1995). While these approaches yielded foundational results for the field, such analyses suffer from two serious limitations: manual approaches are not easily scalable to different or larger corpora, and the rigidity of handcrafted dialogue structure tagging schemes may not capture all the phenomena that occur in practice. In contrast, the stochastic nature of dialogue lends itself to description through probabilistic models. In tutorial dialogue, some early work has adapted language processing techniques, namely ngram analyses, to examine human tutors’ responses t</context>
</contexts>
<marker>Lepper, Woolverton, Mumme, Gurtner, 1993</marker>
<rawString>Lepper, M. R., M. Woolverton, D. L. Mumme, and J. L. Gurtner. 1993. Motivational techniques of expert human tutors: Lessons for the design of computerbased tutors. Pages 75-105 in S. P. Lajoie, and S. J. Derry, editors. Computers as cognitive tools. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Litman</author>
<author>C P Rosé</author>
<author>K Forbes-Riley</author>
<author>K VanLehn</author>
<author>D Bhembe</author>
<author>S Silliman</author>
</authors>
<title>Spoken versus typed human and computer dialogue tutoring.</title>
<date>2006</date>
<journal>International Journal of Artificial Intelligence in Education</journal>
<volume>16</volume>
<issue>2</issue>
<pages>145--170</pages>
<contexts>
<context position="1374" citStr="Litman et al. 2006" startWordPosition="196" endWordPosition="199"> and adjacency pairs. The two best-fit HMMs are presented and compared with respect to the dialogue structure they suggest; we also discuss potential uses of the methodology for future work. 1 Introduction The field of intelligent tutoring systems has made great strides toward bringing the benefits of oneon-one tutoring to a wider population of learners. Some intelligent tutoring systems, called tutorial dialogue systems, support learners by engaging in rich natural language dialogue, e.g., (Graesser et al. 2003; Zinn, Moore &amp; Core 2002; Evens &amp; Michael 2006; Aleven, Koedinger &amp; Popescu 2003; Litman et al. 2006; Arnott, Hastings &amp; Allbritton 2008; VanLehn et al. 2002). However, creating these systems comes at a high cost: it entails handcrafting each pedagogical strategy the tutor might use and then realizing these strategies in a dialogue management framework that is also custom-engineered for the application. It is hoped that the next generation of these systems can leverage corpora of tutorial dialogue in order to provide more robust dialogue management models that capture the discourse phenomena present in effective natural language tutoring. The structure of tutorial dialogue has traditionally </context>
</contexts>
<marker>Litman, Rosé, Forbes-Riley, VanLehn, Bhembe, Silliman, 2006</marker>
<rawString>Litman, D. J., C. P. Rosé, K. Forbes-Riley, K. VanLehn, D. Bhembe, and S. Silliman. 2006. Spoken versus typed human and computer dialogue tutoring. International Journal of Artificial Intelligence in Education 16(2): 145-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Purver</author>
<author>K P Kording</author>
<author>T L Griffiths</author>
<author>J B Tenenbaum</author>
</authors>
<title>Unsupervised topic modelling for multi-party spoken discourse.</title>
<date>2006</date>
<booktitle>Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL:</booktitle>
<pages>17--24</pages>
<contexts>
<context position="4935" citStr="Purver et al. 2006" startWordPosition="714" endWordPosition="717">ral model of the task structure to inform automatic dialogue act tagging as well as subtask segmentation. Our current work examines a modeling technique that does not require a priori knowledge of the task structure: specifically, we propose to use hidden Markov models (HMMs) (Rabiner 1989) to capture the structure of tutorial dialogue implicit within sequences of tagged dialogue acts. Such probablistic inference of discourse structure has been used in recent work with HMMs for topic identification (Barzilay &amp; Lee 2004) and related graphical models for segmenting multi-party spoken discourse (Purver et al. 2006). Analogously, our current work focuses on identifying dialogic structures that emerge during tutorial dialogue. Our approach is based on the premise that at any given point in the tutorial dialogue, the collaborative interaction is “in” a dialogue mode (Cade et al. 2008) that characterizes the nature of the exchanges between tutor and student; these modes correspond to the hidden states in the HMM. Results to date suggest that meaningful descriptive models of tutorial dialogue can be generated by this simple stochastic modeling technique. This paper focuses on the comparison of two first-orde</context>
</contexts>
<marker>Purver, Kording, Griffiths, Tenenbaum, 2006</marker>
<rawString>Purver, M., Kording, K. P., Griffiths, T. L., and Tenenbaum, J. B. 2006. Unsupervised topic modelling for multi-party spoken discourse. Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL: 17-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE</booktitle>
<volume>77</volume>
<issue>2</issue>
<pages>257--286</pages>
<contexts>
<context position="4607" citStr="Rabiner 1989" startWordPosition="668" endWordPosition="669">nfer succinct probabilistic models of the interaction. For example, data-driven approaches for discovering dialogue structure have been applied to corpora of human-human task-oriented dialogue using general models of task structure (Bangalore, Di Fabbrizio &amp; Stent 2006). Encouraging results have emerged from using a general model of the task structure to inform automatic dialogue act tagging as well as subtask segmentation. Our current work examines a modeling technique that does not require a priori knowledge of the task structure: specifically, we propose to use hidden Markov models (HMMs) (Rabiner 1989) to capture the structure of tutorial dialogue implicit within sequences of tagged dialogue acts. Such probablistic inference of discourse structure has been used in recent work with HMMs for topic identification (Barzilay &amp; Lee 2004) and related graphical models for segmenting multi-party spoken discourse (Purver et al. 2006). Analogously, our current work focuses on identifying dialogic structures that emerge during tutorial dialogue. Our approach is based on the premise that at any given point in the tutorial dialogue, the collaborative interaction is “in” a dialogue mode (Cade et al. 2008)</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>Rabiner, L. R. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE 77(2): 257-286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Schlegoff</author>
<author>H Sacks</author>
</authors>
<title>Opening up closings.</title>
<date>1973</date>
<journal>Semiotica</journal>
<volume>7</volume>
<issue>4</issue>
<pages>289--327</pages>
<contexts>
<context position="7076" citStr="Schlegoff &amp; Sacks 1973" startWordPosition="1044" endWordPosition="1047">ence between utterances and dialogue act tags is one-to-one; compound utterances were split by the primary annotator prior to the inter-rater reliability study.1 This dialogue act tagging effort produced sequences of dialogue acts that have been used in their un-altered forms to train one of the two HMMs presented here (Section 3). 2.2 Adjacency Pair Identification In addition to the HMM trained on sequences of individual dialogue acts, another HMM was trained on sequences of dialogue act adjacency pairs. The importance of adjacency pairs is wellestablished in natural language dialogue (e.g., Schlegoff &amp; Sacks 1973), and adjacency pair analysis has illuminated important phenomena in tutoring as well (Forbes-Riley et al. 2007). The 1 Details of the study procedure used to collect the corpus, as well as Kappa statistics for inter-rater reliability, are reported in (Boyer et al. 2008). 20 intuition behind adjacency pairs is that certain dialogue acts naturally occur together, and by grouping these acts we capture an exchange between two conversants in a single structure. This formulation is of interest for our purposes because when treating sequences of dialogue acts as a Markov process, with or without hid</context>
</contexts>
<marker>Schlegoff, Sacks, 1973</marker>
<rawString>Schlegoff, E., and H. Sacks. 1973. Opening up closings. Semiotica 7(4): 289-327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Scott</author>
</authors>
<title>Bayesian methods for hidden Markov models: Recursive computing in the 21st century.</title>
<date>2002</date>
<journal>Journal of the American Statistical Association</journal>
<volume>97</volume>
<issue>457</issue>
<pages>337--352</pages>
<contexts>
<context position="10899" citStr="Scott 2002" startWordPosition="1666" endWordPosition="1667">r of hidden states n from 2 to 15, inclusive.2 The average log-likelihood fit from ten-fold cross2 n=15 was chosen as an initial maximum number of states because it comfortably exceeded our hypothesized range of 3 to 7 (informed by the tutoring literature). The Akaike Information Criterion measure steadily worsened above n = 5, confirming no need to train models with n &gt; 15. 21 validation was computed across all seven models for each n, and this average log-likelihood ln was used to compute the Akaike Information Criterion, a maximum-penalized likelihood estimator that prefers simpler models (Scott 2002). This modeling approach was used to train HMMs on both the dialogue act and the adjacency pair input sequences. 3.2 Best-Fit Models The input sequences of individual dialogue acts contain 16 unique symbols because each of the 8 dialogue act tags (Table 1) was augmented with a label of the speaker, either tutor or student. The best-fit HMM for this input sequence contains nDA=5 hidden states. The adjacency pair input sequences contain 39 unique symbols, including all dependent adjacency pairs (Table 2) along with all individual dialogue acts because each dialogue act occurs at some point outsi</context>
</contexts>
<marker>Scott, 2002</marker>
<rawString>Scott, S. L. 2002. Bayesian methods for hidden Markov models: Recursive computing in the 21st century. Journal of the American Statistical Association 97(457): 337-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Soller</author>
<author>R Stevens</author>
</authors>
<title>Applications of stochastic analyses for collaborative learning and cognitive assessment.</title>
<date>2007</date>
<booktitle>Advances in latent variable mixture models. Information</booktitle>
<pages>217--253</pages>
<editor>in G. R. Hancock, and K. M. Samuelsen, editors.</editor>
<publisher>Age Publishing.</publisher>
<contexts>
<context position="22695" citStr="Soller &amp; Stevens 2007" startWordPosition="3448" endWordPosition="3451">tions, to more readily capture the phenomena of interest. The descriptive insight offered by these exploratory models may also be increased by future work in which the input sequences are enhanced with information about the surface-level content of the utterance. In addition, knowledge of the task state within the tutoring session can be used to segment the dialogue in meaningful ways to further refine model structure. It is also hoped that these models can identify empirically-derived tutorial dialogue structures that can be associated with measures of effectiveness such as student learning (Soller &amp; Stevens 2007). These lines of investigation could inform the development of next-generation natural language tutorial dialogue systems. Acknowledgments Thanks to Marilyn Walker and Dennis Bahler for insightful early discussions on the dialogue and machine learning aspects of this work, respectively. This research was supported by the National Science Foundation under Grants REC-0632450, IIS-0812291, CNS-0540523, and GRFP. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</context>
</contexts>
<marker>Soller, Stevens, 2007</marker>
<rawString>Soller, A., and R. Stevens. 2007. Applications of stochastic analyses for collaborative learning and cognitive assessment. Pages 217-253 in G. R. Hancock, and K. M. Samuelsen, editors. Advances in latent variable mixture models. Information Age Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Tetreault</author>
<author>D J Litman</author>
</authors>
<title>A reinforcement learning approach to evaluating state representations in spoken dialogue systems.</title>
<date>2008</date>
<journal>Speech Communication</journal>
<volume>50</volume>
<issue>8</issue>
<pages>683--696</pages>
<contexts>
<context position="3476" citStr="Tetreault &amp; Litman 2008" startWordPosition="502" endWordPosition="505">es (Boyer et al. 2008). However, this work is limited by its consideration of small dialogue windows. Looking at a broader window of turns is often accomplished by modeling the dialogue as a Markov decision process. With this approach, 19 Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19–26, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics techniques such as reinforcement learning can be used to compare potential policies in terms of effectiveness for student learning. Determining relevant feature sets (Tetreault &amp; Litman 2008) and conducting focussed experiments for localized strategy effectiveness (Chi et al. 2008) are active areas of research in this line of investigation. These approches often fix the dialogue structures under consideration in order to compare the outcomes associated with those structures or the features that influence policy choice. In contrast to treating dialogue structure as a fixed entity, one approach for modeling the progression of complete dialogues involves learning the higher-level structure in order to infer succinct probabilistic models of the interaction. For example, data-driven ap</context>
</contexts>
<marker>Tetreault, Litman, 2008</marker>
<rawString>Tetreault, J. R., and D. J. Litman. 2008. A reinforcement learning approach to evaluating state representations in spoken dialogue systems. Speech Communication 50(8-9): 683-696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K VanLehn</author>
<author>P W Jordan</author>
<author>C P Rose</author>
<author>D Bhembe</author>
<author>M Bottner</author>
<author>A Gaydos</author>
<author>M Makatchev</author>
<author>U Pappuswamy</author>
<author>M Ringenberg</author>
<author>A Roque</author>
</authors>
<title>The architecture of Why2-atlas: A coach for qualitative physics essay writing.</title>
<date>2002</date>
<booktitle>Proceedings of Intelligent Tutoring Systems Conference:</booktitle>
<pages>158--167</pages>
<contexts>
<context position="1432" citStr="VanLehn et al. 2002" startWordPosition="205" endWordPosition="208">d and compared with respect to the dialogue structure they suggest; we also discuss potential uses of the methodology for future work. 1 Introduction The field of intelligent tutoring systems has made great strides toward bringing the benefits of oneon-one tutoring to a wider population of learners. Some intelligent tutoring systems, called tutorial dialogue systems, support learners by engaging in rich natural language dialogue, e.g., (Graesser et al. 2003; Zinn, Moore &amp; Core 2002; Evens &amp; Michael 2006; Aleven, Koedinger &amp; Popescu 2003; Litman et al. 2006; Arnott, Hastings &amp; Allbritton 2008; VanLehn et al. 2002). However, creating these systems comes at a high cost: it entails handcrafting each pedagogical strategy the tutor might use and then realizing these strategies in a dialogue management framework that is also custom-engineered for the application. It is hoped that the next generation of these systems can leverage corpora of tutorial dialogue in order to provide more robust dialogue management models that capture the discourse phenomena present in effective natural language tutoring. The structure of tutorial dialogue has traditionally been studied by manually examining corpora and focusing on</context>
</contexts>
<marker>VanLehn, Jordan, Rose, Bhembe, Bottner, Gaydos, Makatchev, Pappuswamy, Ringenberg, Roque, 2002</marker>
<rawString>VanLehn, K., P. W. Jordan, C. P. Rose, D. Bhembe, M. Bottner, A. Gaydos, M. Makatchev, U. Pappuswamy, M. Ringenberg, and A. Roque. 2002. The architecture of Why2-atlas: A coach for qualitative physics essay writing. Proceedings of Intelligent Tutoring Systems Conference: 158–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zinn</author>
<author>J D Moore</author>
<author>M G Core</author>
</authors>
<title>A 3-tier planning architecture for managing tutorial dialogue.</title>
<date>2002</date>
<booktitle>Proceedings of the 6th International Conference on Intelligent Tutoring Systems:</booktitle>
<pages>574--584</pages>
<marker>Zinn, Moore, Core, 2002</marker>
<rawString>Zinn, C., Moore, J. D., and Core, M. G. 2002. A 3-tier planning architecture for managing tutorial dialogue. Proceedings of the 6th International Conference on Intelligent Tutoring Systems: 574-584.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>