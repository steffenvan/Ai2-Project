<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.948767">
Cross-lingual Information Retrieval using Hidden Markov Models
</title>
<author confidence="0.732156">
Jinxi Xu
</author>
<affiliation confidence="0.203507">
BBN Technologies
</affiliation>
<address confidence="0.7604605">
70 Fawcett St.
Cambridge, MA, USA 02138
</address>
<email confidence="0.9809">
jxu@bbn.com
</email>
<note confidence="0.3986665">
Ralph Weischedel
BBN Technologies
70 Fawcett St.
Cambridge, MA, USA 02138
</note>
<email confidence="0.994056">
weischedel@bbn.com
</email>
<sectionHeader confidence="0.993801" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888058823529">
This paper presents empirical results in
cross-lingual information retrieval using
English queries to access Chinese
documents (TREC-5 and TREC-6) and
Spanish documents (TREC-4). Since our
interest is in languages where resources
may be minimal, we use an integrated
probabilistic model that requires only a
bilingual dictionary as a resource. We
explore how a combined probability
model of term translation and retrieval can
reduce the effect of translation ambiguity.
In addition, we estimate an upper bound
on performance, if translation ambiguity
were a solved problem. We also measure
performance as a function of bilingual
dictionary size.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99872108">
Cross-language information retrieval (CUR) can
serve both those users with a smattering of
knowledge of other languages and also those
fluent in them. For those with limited
knowledge of the other language(s), CUR offers
a wide pool of documents, even though the user
does not have the skill to prepare a high quality
query in the other language(s). Once documents
are retrieved, machine translation or human
translation, if desired, can make the documents
usable. For the user who is fluent in two or
more languages, even though he/she may be able
to formulate good queries in each of the source
languages, CLIR relieves the user from having
to do so.
Most CUR studies have been based on a variant
of tf idf; our experiments instead use a hidden
Markov model (11MI/) to estimate the
probability that a document is relevant given the
query. We integrated two simple estimates of
term translation probability into the mono-
lingual liMM model, giving an estimate of the
probability that a document is relevant given a
query in another language.
In this paper we address the following questions:
</bodyText>
<listItem confidence="0.988449181818182">
• How can a combined probability model of
term translation and retrieval minimize the
effect of translation ambiguity? (Sections 3,
5, 6, 7, and 10)
• What is the upper bound performance using
bilingual dictionary lookup for term
translation? (Section 8)
• How much does performance degrade due to
omissions from the bilingual dictionary and
how does performance vary with size of
such a dictionary? (Sections 8-9)
</listItem>
<bodyText confidence="0.999711444444444">
All experiments were performed using a
common baseline, an HMM-based (mono-
lingual) indexing and retrieval engine. In order
to design controlled experiments for the
questions above, the IR system was run without
sophisticated query expansion techniques.
Our experiments are based on the Chinese
materials of TREC-5 and TREC-6 and the
Spanish materials of TREC-4.
</bodyText>
<sectionHeader confidence="0.995891" genericHeader="introduction">
2 HMM for Mono-Lingual Retrieval
</sectionHeader>
<bodyText confidence="0.999426833333333">
Following Miller et al., 1999, the IR system
ranks documents according to the probability
that a document D is relevant given the query Q,
P(D is R IQ). Using Bayes Rule, and the fact
that P(Q) is constant for a given query, and our
initial assumption of a uniform a priori
</bodyText>
<page confidence="0.997577">
95
</page>
<bodyText confidence="0.999906">
probability that a document is relevant, ranking
documents according to P(Q1D is R) is the same
as ranking them according to P(D is R1Q). The
approach therefore estimates the probability that
a query Q is generated, given the document D is
relevant. (A glossary of symbols used appears
below.)
We use x to represent the language (e.g.
English) for which retrieval is carried out.
According to that model of monolingual
retrieval, it can be shown that
</bodyText>
<equation confidence="0.6932165">
p(QID is R)= ri(aP(W IGx)+ (1— a)P(W ID)),
WinQ
</equation>
<bodyText confidence="0.999767">
where W&apos;s are query words in Q. Miller et al.
estimated probabilities as follows:
</bodyText>
<listItem confidence="0.9591603">
• The transition probability a is 0.7 using the
EM algorithm (Rabiner, 1989) on the TREC4
ad-hoc query set.
P(v IGx)= number of occurrences of W in Cx
•
length of Cx
which is the general language probability for
word Win language x.
• P(v I D) =number of occurrences of W in D
length of D
</listItem>
<bodyText confidence="0.9989594">
In principle, any large corpus Cx that is
representative of language x can be used in
computing the general language probabilities.
In practice, the collection to be searched is
used for that purpose. The length of a
</bodyText>
<table confidence="0.997216272727273">
Q a query
Q. English query
D a document
Dy a document in foreign language y
D is R document is relevant
W a word
Gx an English corpus
Cx a corpus in language x
Wx an English word WY a word in
foreign language y
BL a bilingual dictionary
</table>
<subsectionHeader confidence="0.738119">
A Glossary of Notation used in Formulas
</subsectionHeader>
<bodyText confidence="0.999127">
collection is the sum of the document
lengths.
</bodyText>
<sectionHeader confidence="0.997267" genericHeader="method">
3 11M11/ for Cross-lingual IR
</sectionHeader>
<bodyText confidence="0.9964795">
For CUR we extend the query generation
process so that a document Dy written in
language y can generate a query Qx in language
x. We use Wx to denote a word in x and Wy to
denote a word in y. As before, to model general
query words from language x, we estimate P(Wx
IG) by using a large corpus Cx in language x.
Also as before, we estimate P(WylDy ) to be the
sample distribution of Wy in Dr
We use P(WxIWy) to denote the probability that
Wy is translated as W. Though terms often
should not be translated independent of their
context, we make that simplifying assumption
here. We assume that the possible translations
are specified by a bilingual lexicon BL. Since
the event spaces for Wy&apos;s in P(WylDy) are
mutually exclusive, we can compute the output
probability P(WxIDy):
</bodyText>
<equation confidence="0.8726832">
P(Wx I Dy)= EP(Vylpy)P047x1Wy)
Wy in BL
We compute P(Q,IDy is R) as below:
P(Qx I Dy is R)= ri(aNIKIGx)+ (1— a)P(Wxj D y))
Mc in Q.,
</equation>
<bodyText confidence="0.9999184">
The above model generates queries from
documents, that is, it attempts to determine how
likely a particular query is given a relevant
document. The retrieval system, however, can
use either query translation or document
translation. We chose query translation over
document translation for its flexibility, since it
allowed us to experiment with a new method of
estimating the translation probabilities without
changing the index structure.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="method">
4 Experimental Set-up
</sectionHeader>
<bodyText confidence="0.999422">
For retrieval using English queries to search
Chinese documents, we used the TREC5 and
TREC6 Chinese data which consists of 164,789
documents from the Xinhua News Agency and
People&apos;s Daily, averaging 450 Chinese
characters/document. Each of the TREC topics
has three Chinese fields: title, description and
</bodyText>
<page confidence="0.985222">
96
</page>
<bodyText confidence="0.98906005">
narrative, plus manually translated, English
versions of each. We corrected some of the
English queries that contained errors, such as
&amp;quot;Dali Lama&amp;quot; instead of the correct &amp;quot;Dalai Lama&amp;quot;
and &amp;quot;Medina&amp;quot; instead of &amp;quot;Medellin.&amp;quot; Stop
words and stop phrases were removed. We
created three versions of Chinese queries and
three versions of English queries: short (title
only), medium (title and description), and long
(all three fields).
For retrieval using English queries to search
Spanish documents, we used the TREC4
Spanish data, which has 57,868 documents. It
has 25 queries in Spanish with manual
translations to English. We will denote the
Chinese data sets as Trec5C and Trec6C and the
Spanish data set as Trec4S.
We used a Chinese-English lexicon from the
Linguistic Data Consortium (LDC). We pre-
processed the dictionary as follows:
</bodyText>
<listItem confidence="0.972764333333333">
1. Stem Chinese words via a simple algorithm
to remove common suffixes and prefixes.
2. Use the Porter stemmer on English words.
3. Split English phrases into words. If an
English phrase is a translation for a Chinese
word, each word in the phrase is taken as a
separate translation for the Chinese word.&apos;
4. Estimate the translation probabilities. (We
first report results assuming a uniform
distribution on a word&apos;s translations. If a
Chinese word c has n translations el, ez —en,
each of them will be assigned equal probability,
i.e., P(eilc)=1/n. Section 10 supplements this
with a corpus-based distribution.)
5. Invert the lexicon to make it an English-
</listItem>
<bodyText confidence="0.986961709090909">
Chinese lexicon. That is, for each English word
e, we associate it with a list of Chinese words c
C2, together with non-zero translation
probabilities P(elc,).
The resulting English-Chinese lexicon has
80,000 English words. On average, each
English word has 2.3 Chinese translations.
Clearly, this is not correct; however, it
simplified implementation.
For Spanish, we downloaded a bilingual
English-Spanish lexicon from the Internet
(http://www.activa.arralcis.es) containing around
22,000 English words (16,000 English stems)
and processed it similarly. Each English word
has around 1.5 translations on average. A co-
occurrence based stemmer (Xu and Croft, 1998)
was used to stem Spanish words. One
difference from the treatment of Chinese is to
include the English word as one of its own
translations in addition to its Spanish
translations in the lexicon. This is useful for
translating proper nouns, which often have
identical spellings in English and Spanish but
are routinely excluded from a lexicon.
One problem is the segmentation of Chinese
text, since Chinese has no spaces between
words. In these initial experiments, we relied on
a simple sub-string matching algorithm to
extract words from Chinese text. To extract
words from a string of Chinese characters, the
algorithm examines any sub-string of length 2 or
greater and recognizes it as a Chinese word if it
is in a predefined dictionary (the LDC lexicon in
our case). In addition, any single character
which is not part of any recognized Chinese
words in the first step is taken as a Chinese
word. Note that this algorithm can extract a
compound Chinese word as well as its
components. For example, the Chinese word for
&amp;quot;particle physics&amp;quot; as well as the Chinese words
for &amp;quot;particle&amp;quot; and &amp;quot;physics&amp;quot; will be extracted.
This seems desirable because it ensures the
retrieval algorithm will match both the
compound words as well as their components.
The above algorithm was used in processing
Chinese documents and Chinese queries.
English data from the 2 GB of TREC disks 1&amp;2
was used to estimate P(WIGEnglish), the general
language probabilities for English words. The
evaluation metric used in this study is the
average precision using the trec_eval program
(Voorhees and Harman, 1997). Mono-lingual
retrieval results (using the Chinese and Spanish
queries) provided our baseline, with the HMNI
retrieval system (Miller et al, 1999).
</bodyText>
<page confidence="0.999196">
97
</page>
<sectionHeader confidence="0.995097" genericHeader="method">
5 Retrieval Results
</sectionHeader>
<bodyText confidence="0.893866333333333">
Table 2 reports average precision for mono-
lingual retrieval, average precision for cross-
lingual, and the relative performance ratio of
cross-lingual retrieval to mono-lingual.
Relative performance of cross-lingual IR varies
between 67% and 84% of mono-lingual IR.
Trec6 Chinese queries have a somewhat higher
relative performance than Trec5 Chinese
queries. Longer queries have higher relative
performance than short queries in general.
Overall, cross-lingual performance using our
HMM retrieval model is around 76% of mono-
lingual retrieval. A comparison of our mono-
lingual results with Trec5 Chinese and Trec6
Chinese results published in the TREC
proceedings (Voorhees and Harman, 1997,
1998) shows that our mono-lingual results are
close to the top performers in the TREC
conferences. Our Spanish mono-lingual
performance is also comparable to the top
automatic runs of the TREC4 Spanish task
(Harman, 1996). Since these mono-lingual
results were obtained without using
sophisticated query processing techniques such
as query expansion, we believe the mono-lingual
results form a valid baseline.
Query sets Mono- Cross- % of
lingual lingual Mono-
lingual
Trec5C-short 0.2830 0.1889 67%
Trec5C-medium 0.3427 0.2449 72%
Trec5C-long 0.3750 0.2735 73%
Trec6C-short 0.3423 0.2617 77%
Trec6C-medium 0.4606 0.3872 84%
Trec6C-long 0.5104 0.4206 82%
Trec4S 0.2252 0.1729 77%
</bodyText>
<tableCaption confidence="0.971091">
Table 2: Comparing mono-lingual and cross-
</tableCaption>
<bodyText confidence="0.762983666666667">
lingual retrieval performance. The scores on
the monolingual and cross-lingual columns are
average precision.
</bodyText>
<sectionHeader confidence="0.945151" genericHeader="method">
6 Comparison with other Methods
</sectionHeader>
<bodyText confidence="0.999926274509804">
In this section we compare our approach with
two other approaches. One approach is &amp;quot;simple
substitution&amp;quot;, i.e., replacing a query term with
all its translations and treating the translated
query as a bag of words in mono-lingual
retrieval. Suppose we have a simple query
Q=(a, b), the translations for a are al, a2, a3, and
the translations for b are b.], b2. The translated
query would be (al, a2, a3,b1,b2). Since all terms
are treated as equal in the translated query, this
gives terms with more translations (potentially
the more common terms) more credit in
retrieval, even though such terms should
potentially be given less credit if they are more
common. Also, a document matching different
translations of one term in the original query
may be ranked higher than a document that
matches translations of different terms in the
original query. That is, a document that
contains terms al, a2 and a3 may be ranked
higher than a document which contains terms al
and b.f. However, the second document is more
likely to be relevant since correct translations of
the query terms are more likely to co-occur
(Ballesteros and Croft, 1998).
A second method is to structure the translated
query, separating the translations for one term
from translations for other terms. This approach
limits how much credit the retrieval algorithm
can give to a single term in the original query
and prevents the translations of one or a few
terms from swamping the whole query. There
are several variations of such a method
(Ballesteros and Croft, 1998; Pirkola, 1998; Hull
1997). One such method is to treat different
translations of the same term as synonyms.
Ballesteros, for example, used the INQUERY
(Callan et al, 1995) synonym operator to group
translations of different query terms. However,
if a term has two translations in the target
language, it will treat them as equal even though
one of them is more likely to be the correct
translation than the other. By contrast, our
HMM approach supports translation
probabilities. The synonym approach is
equivalent to changing all non-zero translation
probabilities P(147,1Wy)&apos;s to 1 in our retrieval
function. Even estimating uniform translation
probabilities gives higher weights to
unambiguous translations and lower weights to
highly ambiguous translations.
</bodyText>
<page confidence="0.988755">
98
</page>
<bodyText confidence="0.999506833333333">
These intuitions are supported empirically by the
results in Table 3. We can see that the HM1v1
performs best for every query set. Simple
substitution performs worst. The synonym
approach is significantly better than substitution,
but is consistently worse than the HMM
</bodyText>
<table confidence="0.9991908">
Substi- Synonym HMM
tution
Trec5C-long 0.0391 0.2306 0.2735
Trec6C-long 0.0941 0.3842 0.4206
Trec4S 0.0935 0.1594 0.1729
</table>
<tableCaption confidence="0.999803">
Table 3: Comparing different methods of
</tableCaption>
<bodyText confidence="0.7261835">
query translation. All numbers are average
precision.
</bodyText>
<sectionHeader confidence="0.959174" genericHeader="method">
7 Impact of Translation Ambiguity
</sectionHeader>
<bodyText confidence="0.999888470588235">
To get an upper bound on performance of any
disambiguation technique, we manually
disambiguated the Trec5C-medium, Trec6C-
medium and Trec4S queries. That is, for each
English query term, a native Chinese or Spanish
speaker scanned the list of translations in the
bilingual lexicon and kept one translation
deemed to be the best for the English term and
discarded the rest. If none of the translations
was correct, the first one was chosen.
The results in Table 4 show that manual
disambiguation improves performance by 17%
on Trec5C, 4% on Trec4S, but not at all on
Trec6C. Furthermore, the improvement on
Trec5C appears to be caused by big
improvements for a small number of queries.
The one-sided t-test (Hull, 1993) at significance
level 0.05 indicated that the improvement on
Trec5C is not statistically significant.
It seems surprising that disambiguation does not
help at all for Trec6C. We found that many
terms have more than one valid translation. For
example, the word &amp;quot;flood&amp;quot; (as in &amp;quot;flood
control&amp;quot;) has 4 valid Chinese translations. Using
all of them achieves the desirable effect of query
expansion. It appears that for Trec6C, the benefit
of disambiguation is cancelled by choosing only
one of several alternatives, discarding those
other good translations. If multiple correct
translations were kept in disambiguation, the
improvement would be 4% for Trec6C-medium.
The results of this manual disambiguation
suggest that there are limits to automatic
disambiguation.
</bodyText>
<table confidence="0.9991977">
Query sets Degree of Disambiguation
None Manual % of
Mono-
lingual
Trec5C-medium 0.2449 0.2873 84%
(+17%)
Trec6C-medium 0.3872 0.3830 83%
(-1%)
Trec4S 0.1729 0.1799 80%
(+4%)
</table>
<tableCaption confidence="0.999505">
Table 4: The effect of disambiguation on
</tableCaption>
<bodyText confidence="0.401262">
retrieval performance. The scores reported
are average precision.
</bodyText>
<sectionHeader confidence="0.781875" genericHeader="method">
8 Impact of Missing Translations
</sectionHeader>
<bodyText confidence="0.999759153846154">
Results in the previous section showed that
manual disambiguation can bring performance
of cross-lingual IR to around 82% of mono-
lingual IR. The remaining performance gap
between mono-lingual and cross-lingual IR is
likely to be caused by the incompleteness of the
bilingual lexicon used for query translation, i.e.,
missing translations for some query terms. This
may be a more serious problem for cross-lingual
IR than ambiguity. To test the conjecture, for
each English query term, a native speaker in
Chinese or Spanish manually checked whether
the bilingual lexicon contains a correct
translation for the term in the context of the
query. If it does not, a correct translation for the
term was added to the lexicon. For the query
sets Trec5C-medium and Trec6C-medium, there
are 100 query terms for which the lexicon does
not have a correct translation. This represents
19% of the 520 query terms (a term is counted
only once in one query). For the query set
Trec4S, the percentage is 12%.
The results in Table 5 show that with augmented
lexicons, performance of cross-lingual IR is
91%, 99% and 95% of mono-lingual IR on
Trec5C-medium, Trec6C-medium and Trec4S.
</bodyText>
<page confidence="0.997158">
99
</page>
<bodyText confidence="0.995232285714286">
The improvement over using the original lexicon
is 28%, 18% and 23% respectively. The results
demonstrate the importance of a complete
lexicon. Compared with the results in section 7,
the results here suggest that missing translations
have a much larger impact on cross-lingual IR
than translation ambiguity does.
</bodyText>
<table confidence="0.999065666666667">
Query sets Original Augmented % of
lexicon lexicon Mono-
lingual
Trec5C- 0.2449 0.3131 91%
medium (+28%)
Trec6C- 0.3872 0.4589 99%
medium (+18%)
Trec4S 0.1729 0.2128 95%
(+23%)
</table>
<tableCaption confidence="0.957308666666667">
Table 5: The impact of missing the right
translations on retrieval performance. All
scores are average precision.
</tableCaption>
<sectionHeader confidence="0.625328" genericHeader="method">
9 Impact of Lexicon Size
</sectionHeader>
<bodyText confidence="0.999072793103448">
In this section we measure CUR performance as
a function of lexicon size. We sorted the
English words from TREC disks 1&amp;2 in order of
decreasing frequency. For a lexicon of size n,
we keep only the n most frequent English words.
The upper graph in Figure 1 shows the curve of
cross-lingual IR performance as a function of the
size of the lexicon based on the Chinese short
and medium-length queries. Retrieval
performance was averaged over Trec5C and
Trec6C. Initially retrieval performance increases
sharply with lexicon size. After the dictionary
exceeds 20,000, performance levels off. An
examination of the translated queries shows that
words not appearing in the 20,000-word lexicon
usually do not appear in the larger lexicons
either. Thus, increases in the general lexicon
beyond 20,000 words did not result in a
substantial increase in the coverage of the query
terms.
The lower graph in Figure 1 plots the retrieval
performance as a function of the percent of the
full lexicon. The figure shows that short queries
are more susceptible to incompleteness of the
lexicon than longer queries. Using a 7,000-word
lexicon, the short queries only achieve 75% of
their performance with the full lexicon. In
comparison, the medium-length queries achieve
87% of their performance.
</bodyText>
<table confidence="0.706878709677419">
--.- Short Query -.-- Medium Query
0.35 -
0.3
025
8
42 02
6- 0.15
r
0 0.1
o.
0.05
0
0 10000 20000 30000 40000 50000 60000
Lexicon Size
[-•- Short --0- Medium
— 120
S •
100
..-
o
et -a- 80
co 0 re.......--•
0
u 60
c ic
c
o 20
r
0
0 10000 20000 30000 40000 50000 60000
Lexicon Size
</table>
<figureCaption confidence="0.962235">
Figure 1 Impact of lexicon size on cross-lingual IR
performance
</figureCaption>
<bodyText confidence="0.999816176470588">
We categorized the missing terms and found that
most of them are proper nouns (especially
locations and person names), highly technical
terms, or numbers. Such words understandably
do not normally appear in traditional lexicons.
Translation of numbers can be solved using
simple rules. Transliteration, a technique that
guesses the likely translations of a word based
on pronunciation, can be readily used in
translating proper nouns.
Another technique is automatic discovery of
translations from parallel or non-parallel corpora
(Fung and Mckeown, 1997). Since traditional
lexicons are more or less static repositories of
knowledge, techniques that discover translation
from newly published materials can supplement
them with corpus-specific vocabularies.
</bodyText>
<page confidence="0.980551">
100
</page>
<subsectionHeader confidence="0.612847">
10 Using a Parallel Corpus
</subsectionHeader>
<bodyText confidence="0.999947105263158">
In this section we estimate translation
probabilities from a parallel corpus rather than
assuming uniform likelihood as in section 4. A
Hong Kong News corpus obtained from the
Linguistic Data Consortium has 9,769 news
stories in Chinese with English translations. It
has 3.4 million English words. Since the
documents are not exact translations of each
other, occasionally having extra or missing
sentences, we used document-level co-
occurrence to estimate translation probabilities.
The Chinese documents were &amp;quot;segmented&amp;quot; using
the technique discussed in section 4. Let co(e,c)
be the number of parallel documents where an
English word e and a Chinese word c co-occur,
and df(c) be the document frequency of c. If a
Chinese word c has n possible translations el to
en in the bilingual lexicon, we estimate the
corpus translation probability as:
</bodyText>
<equation confidence="0.99523825">
co(ei,c)
i=n
MAX (df (c), E co(ei,c))
i=1
</equation>
<bodyText confidence="0.998814333333333">
Since several translations for c may co-occur in
a document, Eco(ei,c) can be greater than df(c).
Using the maximum of the two ensures that
</bodyText>
<equation confidence="0.852424">
E P corpus(eilc).
</equation>
<bodyText confidence="0.996303526315789">
Instead of relying solely on corpus-based
estimates from a small parallel corpus, we
employ a mixture model as follows:
P(e lc) fi P _ corpus(e I c)+ (1— fi)P _lexicon(e I c)
The retrieval results in Table 6 show that
combining the probability estimates from the
lexicon and the parallel corpus does improve
retrieval performance. The best results are
obtained when P=0.7; this is better than using
uniform probabilities by 9% on Trec5C-medium
and 4% on Trec6C-medium. Using the corpus
probability estimates alone results in a
significant drop in performance, the parallel
corpus is not large enough nor diverse enough
for reliable estimation of the translation
probabilities. In fact, many words do not appear
in the corpus at all. With a larger and better
parallel corpus, more weight should be given to
the probability estimates from the corpus.
</bodyText>
<table confidence="0.999443">
Trec5- Trec6-
medium medium
Plexicon 0.2449 0.3872
13=0.3 0.2557 0.3980
13=0.5 0.2605 0.4021
0=0.7 0.2658 0.4035
P_corpus 0.2293 0.2971
</table>
<tableCaption confidence="0.848103">
Table 6: Performance with different values
of (3. All scores are average precision.
</tableCaption>
<sectionHeader confidence="0.99923" genericHeader="related work">
11 Related Work
</sectionHeader>
<bodyText confidence="0.999964620689655">
Other studies which view lR as a query
generation process include Maron and Kuhns,
1960; Hiemstra and Kraaij, 1999; Ponte and
Croft, 1998; Miller et al, 1999. Our work has
focused on cross-lingual retrieval.
Many approaches to cross-lingual IR have been
published. One common approach is using
Machine Translation (MT) to translate the
queries to the language of the documents or
translate documents to the language of the
queries (Gey et al, 1999; Oard, 1998). For most
languages, there are no MT systems at all. Our
focus is on languages where no MT exists, but a
bilingual dictionary may exist or may be
derived.
Another common approach is term translation,
e.g., via a bilingual lexicon. (Davis and Ogden,
1997; Ballesteros and Croft, 1997; Hull and
(3refenstette, 1996). While word sense
disambiguation has been a central topic in
previous studies for cross-lingual IR, our study
suggests that using multiple weighted
translations and compensating for the
incompleteness of the lexicon may be more
valuable. Other studies on the value of
disambiguation for cross-lingual IR include
Hiemstra and de Jong, 1999; Hull, 1997.
Sanderson, 1994 studied the issue of
disambiguation for mono-lingual M.
</bodyText>
<equation confidence="0.905823">
P _corpus(eil c) —
</equation>
<page confidence="0.98723">
101
</page>
<bodyText confidence="0.999958555555556">
The third approach to cross-lingual retrieval is to
map queries and documents to some
intermediate representation, e.g latent semantic
indexing (LSI) (Littman et al, 1998), or the
General Vector space model (GVSM),
(Carbonell et al, 1997). We believe our
approach is computationally less costly than
(LSI and GVSM) and assumes less resources
(WordNet in Diekema et al., 1999).
</bodyText>
<sectionHeader confidence="0.921639" genericHeader="conclusions">
12 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99993825">
We proposed an approach to cross-lingual IR
based on hidden Markov models, where the
system estimates the probability that a query in
one language could be generated from a
document in another language. Experiments
using the TREC5 and TREC6 Chinese test sets
and the TREC4 Spanish test set show the
following:
</bodyText>
<listItem confidence="0.697527333333333">
• Our retrieval model can reduce the
performance degradation due to translation
ambiguity This had been a major limiting
factor for other query-translation
approaches.
• Some earlier studies suggested that query
</listItem>
<bodyText confidence="0.9742085">
translation is not an effective approach to
cross-lingual IR (Carbonell et al, 1997).
However, our results suggest that query
translation can be effective particularly if a
bilingual dictionary is the primary bilingual
resource available.
</bodyText>
<listItem confidence="0.9970825">
• Manual selection from the translations in the
bilingual dictionary improves performance
little over the }MM.
• We believe an algorithm cannot rule out a
possible translation with absolute
confidence; it is more effective to rely on
probability estimation/re-estimation to
differentiate likely translations and unlikely
translations.
• Rather than translation ambiguity, a more
serious limitation to effective cross-lingual
IR is incompleteness of the bilingual lexicon
used for query translation.
• Cross-lingual IR performance is typically
75% that of mono-lingual for our HMM on
the Chinese and Spanish collections.
</listItem>
<bodyText confidence="0.999614888888889">
Future improvements in cross-lingual IR will
come by attacking the incompleteness of
bilingual dictionaries and by improved query
expansion and context-dependent translation.
Our current model assumes that query terms are
generated one at time. We would like to extend
the model to allow phrase generation in the
query generation process. We also wish to
explore techniques to extend bilingual lexicons.
</bodyText>
<sectionHeader confidence="0.998439" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999552621621621">
L. Ballesteros and W.B. Croft 1997. &amp;quot;Phrasal
translation and query expansion techniques for
cross-language information retrieval.&amp;quot; Proceedings
of the 20th ACM SIGIR International Conference
on Research and Development in Information
Retrieval 1997, pp. 84-91.
L. Ballesteros and W.B. Croft, 1998. &amp;quot;Resolving
ambiguity for cross-language retrieval.&amp;quot;
Proceedings of the 21st ACM SIGIR Conference on
Research and Development in Information
Retrieval, 1998, pp. 64-71.
J.P. Callan, W.B. Croft and J. Broglio. 1995. &amp;quot;TREC
and TIPS t&apos;ER Experiments with INQUERY&amp;quot;.
Information Processing and Management, pages
327-343, 1995.
J. Carbonell, Y. Yang, R. Frederlcing, R. Brown, Y.
Geng and D. Lee, 1997. &amp;quot;Translingual information
retrieval: a comparative evaluation.&amp;quot; In
Proceedings of the 15th International Joint
Conference on Artificial Intelligence, 1997.
M. Davis and W. Ogden, 1997. &amp;quot;QUILT:
Implementing a Large Scale Cross-language Text
Retrieval System.&amp;quot; Proceedings of ACM SIGIR
Conference, 1997.
A. Diekema, F. Oroumchain, P. Sheridan and E.
Liddy, 1999. &amp;quot;TREC-7 Evaluation of Conceptual
Interlingual Document Retrieval (ONDOR) in
English and French.&amp;quot; TREC7 Proceedings, NIST
special publication.
P. Fung and K. Mckeown. &amp;quot;Finding Terminology
Translations from Non-parallel Corpora.&amp;quot; The 5th
Annual Workshop on Very Large Corpora, Hong
Kong: August 1997, 192-202
F. Gey, J. He and A. Chen, 1999. &amp;quot;Manual queries
and Machine Translation in cross-language
retrieval at TREC-7&amp;quot;. In TREC7 Proceedings,
NIST Special Publication, 1999.
</reference>
<page confidence="0.977913">
102
</page>
<reference confidence="0.999159015625">
Harman, 1996. The TREC-4 Proceedings. NIST
Special publication, 1996.
D. Hiemstra and F. de Jong, 1999. &amp;quot;Disambiguation
strategies for Cross-language Information
Retrieval.&amp;quot; Proceedings of the third European
Conference on Research and Advanced Technology
for Digital Libraries, pp. 274-293, 1999.
D. Hiemstra and W. Kraaij, 1999. &amp;quot;Twenty-One at
1&apos;REC-7: ad-hoc and cross-language track.&amp;quot; In
TREC-7 Proceedings, NIST Special Publication,
1999.
D. Hull, 1993. &amp;quot;Using Statistical Testing in the
Evaluation of Retrieval Experiments.&amp;quot; Proceedings
of the 16th Annual International ACM SlGIR
Conference on Research and Development in
Information Retrieval, pages 329-338, 1993.
D. A. Hull and G. Grefenstette, 1996. &amp;quot;A dictionary-
based approach to multilingual information
retrieval&amp;quot;. Proceedings of ACM SIGIR Conference,
1996.
D. A. Hull, 1997. &amp;quot;Using structured queries for
disambiguation in cross-language information
retrieval.&amp;quot; In AAAI Symposium on Cross-Language
Text and Speech Retrieval. AAAI, 1997.
M. E. Maron and K. L. Kuhns, 1960. &amp;quot;On
Relevance, Probabilistic Indexing and Information
Retrieval.&amp;quot; Journal of the Association for
Computing Machinery, 1960, pp 216-244.
D. Miller, T. Leek and R. Schwartz, 1999. &amp;quot;A
Hidden Markov Model Information Retrieval
System.&amp;quot; Proceedings of the 22nd Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, pages
214-221, 1999.
D.W. Oard, 1998. &amp;quot;A comparative study of query and
document translation for cross-language
information retrieval.&amp;quot; In Proceedings of the Third
Conference of the Association for Machine
Translation in America (AMTA), 1998.
An Pirkola, 1998. &amp;quot;The effects of query structure
and dictionary setups in dictionary-based cross-
language information retrieval.&amp;quot; Proceedings of
ACM SIGIR Conference, 1998, pp 55-63.
J. Ponte and W.B. Croft, 1998. &amp;quot;A Language
Modeling Approach to Information Retrieval.&amp;quot;
Proceedings of the 21st Annual International ACM
SIGIR Conference on Research and Development
in Information Retrieval, pages 275-281, 1998.
L. Rabiner, 1989. &amp;quot;A tutorial on hidden Markov
models and selected applications in speech
recognition.&amp;quot; Proc. IEEE 77, pp. 257-286, 1989.
M. Sanderson. &amp;quot;Word sense disambiguation and
information retrieval.&amp;quot; Proceedings of ACM SIGIR
Conference, 1994, pp 142-151.
Voorhees and Harman, 1997. TREC-5 Proceedings.
E. Voorhees and D. Harman, Editors. NIST
special publication.
Voorhees and Harman, 1998. TREC-6 Proceedings.
E. Voorhees and D. Harman, Editors. NIST
special publication.
J. Xu and W.B. Croft, 1998. &amp;quot;Corpus-based
stemming using co-occurrence of word variants&amp;quot;.
ACM Transactions on Information Systems,
January 1998, vol 16, no. 1.
</reference>
<page confidence="0.999293">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.686352">
<title confidence="0.96131">Cross-lingual Information Retrieval using Hidden Markov Models</title>
<author confidence="0.869974">Jinxi</author>
<affiliation confidence="0.784079">BBN</affiliation>
<address confidence="0.9926325">70 Fawcett Cambridge, MA, USA</address>
<email confidence="0.999821">jxu@bbn.com</email>
<author confidence="0.999755">Ralph Weischedel</author>
<affiliation confidence="0.975277">BBN Technologies</affiliation>
<address confidence="0.9981795">70 Fawcett St. Cambridge, MA, USA 02138</address>
<email confidence="0.9999">weischedel@bbn.com</email>
<abstract confidence="0.999302666666667">This paper presents empirical results in cross-lingual information retrieval using English queries to access Chinese documents (TREC-5 and TREC-6) and Spanish documents (TREC-4). Since our interest is in languages where resources may be minimal, we use an integrated probabilistic model that requires only a bilingual dictionary as a resource. We explore how a combined probability model of term translation and retrieval can reduce the effect of translation ambiguity. In addition, we estimate an upper bound on performance, if translation ambiguity were a solved problem. We also measure performance as a function of bilingual dictionary size.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Phrasal translation and query expansion techniques for cross-language information retrieval.&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval</booktitle>
<pages>84--91</pages>
<contexts>
<context position="23361" citStr="Ballesteros and Croft, 1997" startWordPosition="3751" endWordPosition="3754">Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996). While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disambiguation for mono-lingual M. P _corpus(eil c) — 101 The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation, e.g la</context>
</contexts>
<marker>Ballesteros, Croft, 1997</marker>
<rawString>L. Ballesteros and W.B. Croft 1997. &amp;quot;Phrasal translation and query expansion techniques for cross-language information retrieval.&amp;quot; Proceedings of the 20th ACM SIGIR International Conference on Research and Development in Information Retrieval 1997, pp. 84-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Resolving ambiguity for cross-language retrieval.&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of the 21st ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>64--71</pages>
<contexts>
<context position="12800" citStr="Ballesteros and Croft, 1998" startWordPosition="2067" endWordPosition="2070">ons (potentially the more common terms) more credit in retrieval, even though such terms should potentially be given less credit if they are more common. Also, a document matching different translations of one term in the original query may be ranked higher than a document that matches translations of different terms in the original query. That is, a document that contains terms al, a2 and a3 may be ranked higher than a document which contains terms al and b.f. However, the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations of the same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al, 1995) synonym operator to group tr</context>
</contexts>
<marker>Ballesteros, Croft, 1998</marker>
<rawString>L. Ballesteros and W.B. Croft, 1998. &amp;quot;Resolving ambiguity for cross-language retrieval.&amp;quot; Proceedings of the 21st ACM SIGIR Conference on Research and Development in Information Retrieval, 1998, pp. 64-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Callan</author>
<author>W B Croft</author>
<author>J Broglio</author>
</authors>
<date>1995</date>
<booktitle>TREC and TIPS t&apos;ER Experiments with INQUERY&amp;quot;. Information Processing and Management,</booktitle>
<pages>327--343</pages>
<contexts>
<context position="13371" citStr="Callan et al, 1995" startWordPosition="2161" endWordPosition="2164">likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations of the same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al, 1995) synonym operator to group translations of different query terms. However, if a term has two translations in the target language, it will treat them as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(147,1Wy)&apos;s to 1 in our retrieval function. Even estimating uniform translation probabilities gives higher weights to unambiguous translations and lower weights to highly ambiguous translations. 98 These </context>
</contexts>
<marker>Callan, Croft, Broglio, 1995</marker>
<rawString>J.P. Callan, W.B. Croft and J. Broglio. 1995. &amp;quot;TREC and TIPS t&apos;ER Experiments with INQUERY&amp;quot;. Information Processing and Management, pages 327-343, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carbonell</author>
<author>Y Yang</author>
<author>R Frederlcing</author>
<author>R Brown</author>
<author>Y Geng</author>
<author>D Lee</author>
</authors>
<title>Translingual information retrieval: a comparative evaluation.&amp;quot;</title>
<date>1997</date>
<booktitle>In Proceedings of the 15th International Joint Conference on Artificial Intelligence,</booktitle>
<contexts>
<context position="24078" citStr="Carbonell et al, 1997" startWordPosition="3859" endWordPosition="3862">evious studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disambiguation for mono-lingual M. P _corpus(eil c) — 101 The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation, e.g latent semantic indexing (LSI) (Littman et al, 1998), or the General Vector space model (GVSM), (Carbonell et al, 1997). We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al., 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probability that a query in one language could be generated from a document in another language. Experiments using the TREC5 and TREC6 Chinese test sets and the TREC4 Spanish test set show the following: • Our retrieval model can reduce the performance degradation due to translation ambiguity This had been a major limiting</context>
</contexts>
<marker>Carbonell, Yang, Frederlcing, Brown, Geng, Lee, 1997</marker>
<rawString>J. Carbonell, Y. Yang, R. Frederlcing, R. Brown, Y. Geng and D. Lee, 1997. &amp;quot;Translingual information retrieval: a comparative evaluation.&amp;quot; In Proceedings of the 15th International Joint Conference on Artificial Intelligence, 1997. M. Davis and W. Ogden, 1997. &amp;quot;QUILT: Implementing a Large Scale Cross-language Text Retrieval System.&amp;quot; Proceedings of ACM SIGIR Conference, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Diekema</author>
<author>F Oroumchain</author>
<author>P Sheridan</author>
<author>E Liddy</author>
</authors>
<date>1999</date>
<booktitle>TREC-7 Evaluation of Conceptual Interlingual Document Retrieval (ONDOR) in English and French.&amp;quot; TREC7 Proceedings, NIST special publication.</booktitle>
<contexts>
<context position="24215" citStr="Diekema et al., 1999" startWordPosition="3881" endWordPosition="3884">of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disambiguation for mono-lingual M. P _corpus(eil c) — 101 The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation, e.g latent semantic indexing (LSI) (Littman et al, 1998), or the General Vector space model (GVSM), (Carbonell et al, 1997). We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al., 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probability that a query in one language could be generated from a document in another language. Experiments using the TREC5 and TREC6 Chinese test sets and the TREC4 Spanish test set show the following: • Our retrieval model can reduce the performance degradation due to translation ambiguity This had been a major limiting factor for other query-translation approaches. • Some earlier studies suggested that query translation is not an effective approach to c</context>
</contexts>
<marker>Diekema, Oroumchain, Sheridan, Liddy, 1999</marker>
<rawString>A. Diekema, F. Oroumchain, P. Sheridan and E. Liddy, 1999. &amp;quot;TREC-7 Evaluation of Conceptual Interlingual Document Retrieval (ONDOR) in English and French.&amp;quot; TREC7 Proceedings, NIST special publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>K Mckeown</author>
</authors>
<title>Finding Terminology Translations from Non-parallel Corpora.&amp;quot;</title>
<date>1997</date>
<booktitle>The 5th Annual Workshop on Very Large Corpora,</booktitle>
<pages>192--202</pages>
<location>Hong Kong:</location>
<contexts>
<context position="20254" citStr="Fung and Mckeown, 1997" startWordPosition="3256" endWordPosition="3259">Size Figure 1 Impact of lexicon size on cross-lingual IR performance We categorized the missing terms and found that most of them are proper nouns (especially locations and person names), highly technical terms, or numbers. Such words understandably do not normally appear in traditional lexicons. Translation of numbers can be solved using simple rules. Transliteration, a technique that guesses the likely translations of a word based on pronunciation, can be readily used in translating proper nouns. Another technique is automatic discovery of translations from parallel or non-parallel corpora (Fung and Mckeown, 1997). Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies. 100 10 Using a Parallel Corpus In this section we estimate translation probabilities from a parallel corpus rather than assuming uniform likelihood as in section 4. A Hong Kong News corpus obtained from the Linguistic Data Consortium has 9,769 news stories in Chinese with English translations. It has 3.4 million English words. Since the documents are not exact translations of each other, occasi</context>
</contexts>
<marker>Fung, Mckeown, 1997</marker>
<rawString>P. Fung and K. Mckeown. &amp;quot;Finding Terminology Translations from Non-parallel Corpora.&amp;quot; The 5th Annual Workshop on Very Large Corpora, Hong Kong: August 1997, 192-202</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Gey</author>
<author>J He</author>
<author>A Chen</author>
</authors>
<title>Manual queries and Machine Translation in cross-language retrieval at TREC-7&amp;quot;.</title>
<date>1999</date>
<booktitle>In TREC7 Proceedings, NIST Special Publication,</booktitle>
<contexts>
<context position="23065" citStr="Gey et al, 1999" startWordPosition="3701" endWordPosition="3704">980 13=0.5 0.2605 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996). While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disa</context>
</contexts>
<marker>Gey, He, Chen, 1999</marker>
<rawString>F. Gey, J. He and A. Chen, 1999. &amp;quot;Manual queries and Machine Translation in cross-language retrieval at TREC-7&amp;quot;. In TREC7 Proceedings, NIST Special Publication, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harman</author>
</authors>
<date>1996</date>
<booktitle>The TREC-4 Proceedings. NIST Special publication,</booktitle>
<contexts>
<context position="11024" citStr="Harman, 1996" startWordPosition="1790" endWordPosition="1791">what higher relative performance than Trec5 Chinese queries. Longer queries have higher relative performance than short queries in general. Overall, cross-lingual performance using our HMM retrieval model is around 76% of monolingual retrieval. A comparison of our monolingual results with Trec5 Chinese and Trec6 Chinese results published in the TREC proceedings (Voorhees and Harman, 1997, 1998) shows that our mono-lingual results are close to the top performers in the TREC conferences. Our Spanish mono-lingual performance is also comparable to the top automatic runs of the TREC4 Spanish task (Harman, 1996). Since these mono-lingual results were obtained without using sophisticated query processing techniques such as query expansion, we believe the mono-lingual results form a valid baseline. Query sets Mono- Cross- % of lingual lingual Monolingual Trec5C-short 0.2830 0.1889 67% Trec5C-medium 0.3427 0.2449 72% Trec5C-long 0.3750 0.2735 73% Trec6C-short 0.3423 0.2617 77% Trec6C-medium 0.4606 0.3872 84% Trec6C-long 0.5104 0.4206 82% Trec4S 0.2252 0.1729 77% Table 2: Comparing mono-lingual and crosslingual retrieval performance. The scores on the monolingual and cross-lingual columns are average pre</context>
</contexts>
<marker>Harman, 1996</marker>
<rawString>Harman, 1996. The TREC-4 Proceedings. NIST Special publication, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hiemstra</author>
<author>F de Jong</author>
</authors>
<title>Disambiguation strategies for Cross-language Information Retrieval.&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the third European Conference on Research and Advanced Technology for Digital Libraries,</booktitle>
<pages>274--293</pages>
<marker>Hiemstra, de Jong, 1999</marker>
<rawString>D. Hiemstra and F. de Jong, 1999. &amp;quot;Disambiguation strategies for Cross-language Information Retrieval.&amp;quot; Proceedings of the third European Conference on Research and Advanced Technology for Digital Libraries, pp. 274-293, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hiemstra</author>
<author>W Kraaij</author>
</authors>
<title>Twenty-One at 1&apos;REC-7: ad-hoc and cross-language track.&amp;quot;</title>
<date>1999</date>
<booktitle>In TREC-7 Proceedings, NIST Special Publication,</booktitle>
<contexts>
<context position="22732" citStr="Hiemstra and Kraaij, 1999" startWordPosition="3647" endWordPosition="3650">orpus is not large enough nor diverse enough for reliable estimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5- Trec6- medium medium Plexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997</context>
</contexts>
<marker>Hiemstra, Kraaij, 1999</marker>
<rawString>D. Hiemstra and W. Kraaij, 1999. &amp;quot;Twenty-One at 1&apos;REC-7: ad-hoc and cross-language track.&amp;quot; In TREC-7 Proceedings, NIST Special Publication, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hull</author>
</authors>
<title>Using Statistical Testing in the Evaluation of Retrieval Experiments.&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the 16th Annual International ACM SlGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>329--338</pages>
<contexts>
<context position="15201" citStr="Hull, 1993" startWordPosition="2445" endWordPosition="2446">-medium, Trec6Cmedium and Trec4S queries. That is, for each English query term, a native Chinese or Spanish speaker scanned the list of translations in the bilingual lexicon and kept one translation deemed to be the best for the English term and discarded the rest. If none of the translations was correct, the first one was chosen. The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C. Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries. The one-sided t-test (Hull, 1993) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant. It seems surprising that disambiguation does not help at all for Trec6C. We found that many terms have more than one valid translation. For example, the word &amp;quot;flood&amp;quot; (as in &amp;quot;flood control&amp;quot;) has 4 valid Chinese translations. Using all of them achieves the desirable effect of query expansion. It appears that for Trec6C, the benefit of disambiguation is cancelled by choosing only one of several alternatives, discarding those other good translations. If multiple correct translations were kept in </context>
</contexts>
<marker>Hull, 1993</marker>
<rawString>D. Hull, 1993. &amp;quot;Using Statistical Testing in the Evaluation of Retrieval Experiments.&amp;quot; Proceedings of the 16th Annual International ACM SlGIR Conference on Research and Development in Information Retrieval, pages 329-338, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Hull</author>
<author>G Grefenstette</author>
</authors>
<title>A dictionarybased approach to multilingual information retrieval&amp;quot;.</title>
<date>1996</date>
<booktitle>Proceedings of ACM SIGIR Conference,</booktitle>
<marker>Hull, Grefenstette, 1996</marker>
<rawString>D. A. Hull and G. Grefenstette, 1996. &amp;quot;A dictionarybased approach to multilingual information retrieval&amp;quot;. Proceedings of ACM SIGIR Conference, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Hull</author>
</authors>
<title>Using structured queries for disambiguation in cross-language information retrieval.&amp;quot;</title>
<date>1997</date>
<booktitle>In AAAI Symposium on Cross-Language Text and Speech Retrieval. AAAI,</booktitle>
<contexts>
<context position="13225" citStr="Hull 1997" startWordPosition="2139" endWordPosition="2140">ains terms al and b.f. However, the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations of the same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al, 1995) synonym operator to group translations of different query terms. However, if a term has two translations in the target language, it will treat them as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(147,1Wy)&apos;s to 1 in our retrieval function. Even estimatin</context>
<context position="23743" citStr="Hull, 1997" startWordPosition="3810" endWordPosition="3811">ur focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996). While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disambiguation for mono-lingual M. P _corpus(eil c) — 101 The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation, e.g latent semantic indexing (LSI) (Littman et al, 1998), or the General Vector space model (GVSM), (Carbonell et al, 1997). We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al., 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system est</context>
</contexts>
<marker>Hull, 1997</marker>
<rawString>D. A. Hull, 1997. &amp;quot;Using structured queries for disambiguation in cross-language information retrieval.&amp;quot; In AAAI Symposium on Cross-Language Text and Speech Retrieval. AAAI, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Maron</author>
<author>K L Kuhns</author>
</authors>
<title>On Relevance, Probabilistic Indexing and Information Retrieval.&amp;quot;</title>
<date>1960</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<pages>216--244</pages>
<contexts>
<context position="22705" citStr="Maron and Kuhns, 1960" startWordPosition="3643" endWordPosition="3646">ormance, the parallel corpus is not large enough nor diverse enough for reliable estimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5- Trec6- medium medium Plexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexi</context>
</contexts>
<marker>Maron, Kuhns, 1960</marker>
<rawString>M. E. Maron and K. L. Kuhns, 1960. &amp;quot;On Relevance, Probabilistic Indexing and Information Retrieval.&amp;quot; Journal of the Association for Computing Machinery, 1960, pp 216-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Miller</author>
<author>T Leek</author>
<author>R Schwartz</author>
</authors>
<title>A Hidden Markov Model Information Retrieval System.&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>214--221</pages>
<contexts>
<context position="2835" citStr="Miller et al., 1999" startWordPosition="439" endWordPosition="442"> for term translation? (Section 8) • How much does performance degrade due to omissions from the bilingual dictionary and how does performance vary with size of such a dictionary? (Sections 8-9) All experiments were performed using a common baseline, an HMM-based (monolingual) indexing and retrieval engine. In order to design controlled experiments for the questions above, the IR system was run without sophisticated query expansion techniques. Our experiments are based on the Chinese materials of TREC-5 and TREC-6 and the Spanish materials of TREC-4. 2 HMM for Mono-Lingual Retrieval Following Miller et al., 1999, the IR system ranks documents according to the probability that a document D is relevant given the query Q, P(D is R IQ). Using Bayes Rule, and the fact that P(Q) is constant for a given query, and our initial assumption of a uniform a priori 95 probability that a document is relevant, ranking documents according to P(Q1D is R) is the same as ranking them according to P(D is R1Q). The approach therefore estimates the probability that a query Q is generated, given the document D is relevant. (A glossary of symbols used appears below.) We use x to represent the language (e.g. English) for whic</context>
<context position="10089" citStr="Miller et al, 1999" startWordPosition="1650" endWordPosition="1653">cted. This seems desirable because it ensures the retrieval algorithm will match both the compound words as well as their components. The above algorithm was used in processing Chinese documents and Chinese queries. English data from the 2 GB of TREC disks 1&amp;2 was used to estimate P(WIGEnglish), the general language probabilities for English words. The evaluation metric used in this study is the average precision using the trec_eval program (Voorhees and Harman, 1997). Mono-lingual retrieval results (using the Chinese and Spanish queries) provided our baseline, with the HMNI retrieval system (Miller et al, 1999). 97 5 Retrieval Results Table 2 reports average precision for monolingual retrieval, average precision for crosslingual, and the relative performance ratio of cross-lingual retrieval to mono-lingual. Relative performance of cross-lingual IR varies between 67% and 84% of mono-lingual IR. Trec6 Chinese queries have a somewhat higher relative performance than Trec5 Chinese queries. Longer queries have higher relative performance than short queries in general. Overall, cross-lingual performance using our HMM retrieval model is around 76% of monolingual retrieval. A comparison of our monolingual r</context>
<context position="22775" citStr="Miller et al, 1999" startWordPosition="3655" endWordPosition="3658">eliable estimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5- Trec6- medium medium Plexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3r</context>
</contexts>
<marker>Miller, Leek, Schwartz, 1999</marker>
<rawString>D. Miller, T. Leek and R. Schwartz, 1999. &amp;quot;A Hidden Markov Model Information Retrieval System.&amp;quot; Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 214-221, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
</authors>
<title>A comparative study of query and document translation for cross-language information retrieval.&amp;quot;</title>
<date>1998</date>
<booktitle>In Proceedings of the Third Conference of the Association for Machine Translation in America (AMTA),</booktitle>
<contexts>
<context position="23078" citStr="Oard, 1998" startWordPosition="3705" endWordPosition="3706"> 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996). While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation fo</context>
</contexts>
<marker>Oard, 1998</marker>
<rawString>D.W. Oard, 1998. &amp;quot;A comparative study of query and document translation for cross-language information retrieval.&amp;quot; In Proceedings of the Third Conference of the Association for Machine Translation in America (AMTA), 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>An Pirkola</author>
</authors>
<title>The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval.&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of ACM SIGIR Conference,</booktitle>
<pages>55--63</pages>
<contexts>
<context position="13213" citStr="Pirkola, 1998" startWordPosition="2137" endWordPosition="2138">ment which contains terms al and b.f. However, the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations of the same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al, 1995) synonym operator to group translations of different query terms. However, if a term has two translations in the target language, it will treat them as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(147,1Wy)&apos;s to 1 in our retrieval function. Ev</context>
</contexts>
<marker>Pirkola, 1998</marker>
<rawString>An Pirkola, 1998. &amp;quot;The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval.&amp;quot; Proceedings of ACM SIGIR Conference, 1998, pp 55-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ponte</author>
<author>W B Croft</author>
</authors>
<title>A Language Modeling Approach to Information Retrieval.&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>275--281</pages>
<contexts>
<context position="22755" citStr="Ponte and Croft, 1998" startWordPosition="3651" endWordPosition="3654">or diverse enough for reliable estimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5- Trec6- medium medium Plexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 0=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of (3. All scores are average precision. 11 Related Work Other studies which view lR as a query generation process include Maron and Kuhns, 1960; Hiemstra and Kraaij, 1999; Ponte and Croft, 1998; Miller et al, 1999. Our work has focused on cross-lingual retrieval. Many approaches to cross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>J. Ponte and W.B. Croft, 1998. &amp;quot;A Language Modeling Approach to Information Retrieval.&amp;quot; Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 275-281, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.&amp;quot;</title>
<date>1989</date>
<booktitle>Proc. IEEE 77,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="3740" citStr="Rabiner, 1989" startWordPosition="600" endWordPosition="601">nking documents according to P(Q1D is R) is the same as ranking them according to P(D is R1Q). The approach therefore estimates the probability that a query Q is generated, given the document D is relevant. (A glossary of symbols used appears below.) We use x to represent the language (e.g. English) for which retrieval is carried out. According to that model of monolingual retrieval, it can be shown that p(QID is R)= ri(aP(W IGx)+ (1— a)P(W ID)), WinQ where W&apos;s are query words in Q. Miller et al. estimated probabilities as follows: • The transition probability a is 0.7 using the EM algorithm (Rabiner, 1989) on the TREC4 ad-hoc query set. P(v IGx)= number of occurrences of W in Cx • length of Cx which is the general language probability for word Win language x. • P(v I D) =number of occurrences of W in D length of D In principle, any large corpus Cx that is representative of language x can be used in computing the general language probabilities. In practice, the collection to be searched is used for that purpose. The length of a Q a query Q. English query D a document Dy a document in foreign language y D is R document is relevant W a word Gx an English corpus Cx a corpus in language x Wx an Engl</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L. Rabiner, 1989. &amp;quot;A tutorial on hidden Markov models and selected applications in speech recognition.&amp;quot; Proc. IEEE 77, pp. 257-286, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sanderson</author>
</authors>
<title>Word sense disambiguation and information retrieval.&amp;quot;</title>
<date>1994</date>
<booktitle>Proceedings of ACM SIGIR Conference,</booktitle>
<pages>142--151</pages>
<contexts>
<context position="23760" citStr="Sanderson, 1994" startWordPosition="3812" endWordPosition="3813">on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996). While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disambiguation for mono-lingual M. P _corpus(eil c) — 101 The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation, e.g latent semantic indexing (LSI) (Littman et al, 1998), or the General Vector space model (GVSM), (Carbonell et al, 1997). We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al., 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probab</context>
</contexts>
<marker>Sanderson, 1994</marker>
<rawString>M. Sanderson. &amp;quot;Word sense disambiguation and information retrieval.&amp;quot; Proceedings of ACM SIGIR Conference, 1994, pp 142-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Voorhees</author>
<author>Harman</author>
</authors>
<date>1997</date>
<pages>5</pages>
<note>NIST special publication.</note>
<contexts>
<context position="9942" citStr="Voorhees and Harman, 1997" startWordPosition="1629" endWordPosition="1632">rd as well as its components. For example, the Chinese word for &amp;quot;particle physics&amp;quot; as well as the Chinese words for &amp;quot;particle&amp;quot; and &amp;quot;physics&amp;quot; will be extracted. This seems desirable because it ensures the retrieval algorithm will match both the compound words as well as their components. The above algorithm was used in processing Chinese documents and Chinese queries. English data from the 2 GB of TREC disks 1&amp;2 was used to estimate P(WIGEnglish), the general language probabilities for English words. The evaluation metric used in this study is the average precision using the trec_eval program (Voorhees and Harman, 1997). Mono-lingual retrieval results (using the Chinese and Spanish queries) provided our baseline, with the HMNI retrieval system (Miller et al, 1999). 97 5 Retrieval Results Table 2 reports average precision for monolingual retrieval, average precision for crosslingual, and the relative performance ratio of cross-lingual retrieval to mono-lingual. Relative performance of cross-lingual IR varies between 67% and 84% of mono-lingual IR. Trec6 Chinese queries have a somewhat higher relative performance than Trec5 Chinese queries. Longer queries have higher relative performance than short queries in </context>
</contexts>
<marker>Voorhees, Harman, 1997</marker>
<rawString>Voorhees and Harman, 1997. TREC-5 Proceedings. E. Voorhees and D. Harman, Editors. NIST special publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Voorhees</author>
<author>Harman</author>
</authors>
<date>1998</date>
<pages>6</pages>
<note>NIST special publication.</note>
<marker>Voorhees, Harman, 1998</marker>
<rawString>Voorhees and Harman, 1998. TREC-6 Proceedings. E. Voorhees and D. Harman, Editors. NIST special publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>W B Croft</author>
</authors>
<title>Corpus-based stemming using co-occurrence of word variants&amp;quot;.</title>
<date>1998</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>16</volume>
<contexts>
<context position="8356" citStr="Xu and Croft, 1998" startWordPosition="1367" endWordPosition="1370">ord e, we associate it with a list of Chinese words c C2, together with non-zero translation probabilities P(elc,). The resulting English-Chinese lexicon has 80,000 English words. On average, each English word has 2.3 Chinese translations. Clearly, this is not correct; however, it simplified implementation. For Spanish, we downloaded a bilingual English-Spanish lexicon from the Internet (http://www.activa.arralcis.es) containing around 22,000 English words (16,000 English stems) and processed it similarly. Each English word has around 1.5 translations on average. A cooccurrence based stemmer (Xu and Croft, 1998) was used to stem Spanish words. One difference from the treatment of Chinese is to include the English word as one of its own translations in addition to its Spanish translations in the lexicon. This is useful for translating proper nouns, which often have identical spellings in English and Spanish but are routinely excluded from a lexicon. One problem is the segmentation of Chinese text, since Chinese has no spaces between words. In these initial experiments, we relied on a simple sub-string matching algorithm to extract words from Chinese text. To extract words from a string of Chinese char</context>
</contexts>
<marker>Xu, Croft, 1998</marker>
<rawString>J. Xu and W.B. Croft, 1998. &amp;quot;Corpus-based stemming using co-occurrence of word variants&amp;quot;. ACM Transactions on Information Systems, January 1998, vol 16, no. 1.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>