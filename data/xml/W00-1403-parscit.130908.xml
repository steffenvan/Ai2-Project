<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001392">
<title confidence="0.995393">
An Empirical Study in Multilingual Natural Language
Generation: What Should A Text Planner Do?
</title>
<author confidence="0.989654">
Daniel Marcu Lynn Carlson Maki Watanabe
</author>
<affiliation confidence="0.996259666666667">
Information Sciences Institute and U.S. Department of Defense Department of Linguistics
Department of Computer Science .FL . Meade,. MD,.20755 University.,of Southern California
University of Southern California lmcarls@afterlife.ncsc.mil Los Angeles, CA 90089
</affiliation>
<address confidence="0.5482065">
4676 Admiralty Way, Suite 1001 mwatancib@tisc.edu
Marina del Rey, CA 90292
</address>
<email confidence="0.76926">
marcu4isi.edu
</email>
<sectionHeader confidence="0.950386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823571428571">
We present discourse annotation work aimed at con-
structing a parallel corpus of Rhetorical Structure
trees for a collection of Japanese texts and their cor-
responding English translations. We discuss impli-
cations of our empirical findings for the task of text
planning in the context of implementing multilingual
natural language generation systems.
</bodyText>
<sectionHeader confidence="0.99551" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983163672727273">
The natural language generation community has em-
phasized for a number of years the strengths of mul-
tilingual generation (MGEN) systems (Iordanskaja
et al., 1992; Wisner and Stede, 1992; Reiter and Mel-
lish, 1993; Goldberg et al., 1994; Paris et al., 1995;
Power and Scott, 1998). These strengths concern the
reuse of knowledge, the support for early drafts in
several languages, the support for maintaining con-
sistency when making changes, the support for pro-
ducing alternative formulations, and the potential
for producing higher quality outputs than machine
translation. (The weaknesses concern the high-cost
of building large, language-independent knowledge
bases, and the difficulty of producing high-quality,
broad-coverage generation algorithms.)
From an economic perspective, the more a sys-
tern can rely on language independent modules for
the purpose of multilingual generation, the better.
If an MGEN system needs to develop language de-
pendent knowledge bases, and language dependent
algorithms for content selection, text planning, and
sentence planning, •it- is difficult to -justify its eco-
nomic viability. However, if most of these compo-
nents are language independent and/or much of the
code can be re-used, an MGEN system becomes a
viable option.
Many of the early implementations of MG EN sys-
tems have adopted the perspective that text plan-
ners can be implemented as language-independent
modules (lordanskaja et al.. 1992: Goldberg et al.,
1994), possibly followed by a lnicari.:alion stage,
in which discourse trees are re-written to reflect
language-specific constraints (Wisner and Steele.
1992: Stede, 1999). Although such an approach may
be adequate for highly restricted text genres, such
as weather forecasts, it usually poses problems for
less restricted genres. Studies of instruction man-
uals (Rosner and Stede, 1992; Delin et al., 1994:
Delin et al., 1996) suggest that there are variations
with respect to the way high-level communicative
goals are realized across languages. For example,
Delin et al. (1994) noticed that sentences (1), (2),
and (3), which were taken from a trilingual instruc-
tion manual for a step-aerobics machine, yield non-
isomorphic Rhetorical Structure (Mann and Thomp-
son, 1988) analyses in English, French, and German
respectively (see Figure 1).
English: [The stepping load can be altered&apos;] (I)
[by loosening the locking lever2] [and changing
the position of the cylinder foot3].
French: [Pour modifier la charge d&apos;appui,&apos; ] (2)
[desserrer les levieres2] [puis deplacer le pied
des verins3] ([To modify the load stepping&apos;]
[loosen the levers2] [then change the foot of
the cylinder foot.1)
</bodyText>
<subsectionHeader confidence="0.604294">
German: [Nach Lockern der Klemnthebel2] (3)
</subsectionHeader>
<bodyText confidence="0.999520705882353">
[kann` ] [durch Verschieben des Zvlinderfu,3es3]
[die Tretbelastung verandert werden.l] ([After
loosening of the levers2] [can&apos;] [by pushing of
the cylinder foot3] [the load changed be,&apos;])
However, previous discourse studies do .not es-
timate how ubiquitous such non-isomorphic analy-
ses are. Are the examples above an exception or
the norm? Are non-isomorphic analyses specific
to discourse structures built across elementary dis-
course units of single sentences, or do they also
occur across sentences and paragraphs? If non-
isomorphism is ubiquitous, how should an MG EN
system be designed in order to effectively deal wit Ii
non-isomorphic discourse structures when mapping
knowledge bases into multiple languages?
In this paper. we describe an experiment that was
designed to answer these questions. To investigate
</bodyText>
<page confidence="0.999236">
17
</page>
<figureCaption confidence="0.999437">
Figure 1: Contrasting multilingual discourse structure representations (Delin et al., 1994, P. 63)
</figureCaption>
<figure confidence="0.9959095">
English French German
Circumstance
2
Loosen Means
(Lockern)
2 3 2 3 3
Loosen Change Loosen Change Change Alter
(Desserrer) (Deplacer) (Verschieben) (Verandert)
</figure>
<bodyText confidence="0.97783175">
how discourse structures differ across languages, we
manually built a parallel corpus of discourse trees of
newspaper Japanese texts and their corresponding
English translations. In section 2, we present some
of the problems specific to the construction of such
a corpus. In section 3, we present our experiment
and discuss our empirical findings. In Section 4, we
discuss the implications of our work for the task of
text planning, in the context of multilingual natural
language generation.
2 Towards building a parallel corpus
of discourse trees: an example
Consider, for example, Japanese sentence (4), a
word-by-word &amp;quot;gloss&amp;quot; of it (5), and a two-sentence
translation of it that was produced by a professional
translator (6).
</bodyText>
<equation confidence="0.83792175">
LI:&apos;] [AD olq3Zttt Et-NI 2] (4)
[12)Z. — • 3] [i-ofkil_hytz
ORt L. [Lit 1.-C oti,
L66] MALL
</equation>
<subsectionHeader confidence="0.976022">
[The Ministry of Health and Welfare last year (.5)
</subsectionHeader>
<bodyText confidence="0.9969398">
revealed&apos;] [population of future estimate ac-
cording to2] [in future 1.499 persons as the
lowest3] [that after *SAB* rising to turn that4]
[*they* estimated but5] [already the estimate
misses a pointG] [prediction became.]
</bodyText>
<subsectionHeader confidence="0.705617">
[In its future population estimates&apos;] [made (6)
</subsectionHeader>
<bodyText confidence="0.9366188125">
public last year.2] [the Ministry of Health and
Welfare predicted that the SAB would drop to
a new low of 1.499 in the future.3] [but would
make a comeback after that .4] [increasing once
again.5] [However, it looks as if t hat prediction
will be quickly shattered.&apos;]
The labeled spans of text represent elementary
discourse units (edits). i.e.. minimal text spans that,
have an unambiguous discourse function (Mann and
Thompson, 1988). If we analyze the text frag-
ments closely, we will notice that in translating sen-
tence (4), a professional translator chose to realize
the information in Japanese unit 2 first (unit 2 in
text (4) corresponds roughly to unit 1 in text (6));
to realize then some of the information in Japanese
unit 1 (part of unit 1 in text (4) corresponds to unit
2 in text (6)); to fuse then information given in units
1, 3, and 5 in text (4) and realize it in English as
unit 3; and so on. Also, the translator chose to re-
package the information in the original Japanese sen-
tence into two English sentences.
At the elementary unit level, the correspondence
between Japanese sentence (4) and its English trans-
lation (6) can be represented as in (7), where j C e
denotes the fact that the semantic content of unit
j is realized fully in unit e; j D e denotes the fact
that the semantic content of unit e is realized fully
in unit j; j = e denotes the fact that units j and e
are semantically equivalent; and j e denotes the
fact that there is a semantic overlap between units j
and e, but neither proper inclusion nor proper equiv-
alence.
</bodyText>
<equation confidence="0.998425857142857">
11 D e2; e3;
J2 ei;
J3 C e3;
j4 e4;i4 es; (7)
15 ea;
16 c e6;
C es
</equation>
<bodyText confidence="0.9728685">
Hence, the mappings in (7) provide an explicit rep-
resentation of the way information is re-ordered and
re-packaged when translated from Japanese into En-
glish. However, when translating text, it is not only
that information is re-packaged and re-ordered; it.
is also that. the rhetorical rendering changes. What.
is realized in Japanese using an ELABORATION rela-
tion can be realized in English using, for example, a
CONTRAST or a CONCESSION relation.
Figure 2 presents in the style of Mann and Thomp-
</bodyText>
<page confidence="0.955403">
18
</page>
<figure confidence="0.99075364516129">
c oncessior
e aboralior -o3ject-attri te-e
•
rediction
:AtirfffiAtflt; ..fflitr,r4.0-5,;..01.,. •
be ane)
attribution alnbuton
e aboraarir—oateet.attti e-_e -temporal-after •
:1) (2) (3)
IgliteSsett )1734)14*1111tt #4X •—• 13/1.1. -t-0)11AtiN4cilkt
Let (rhe Ministry di *(popuation - )-ratet.: `ftutur 6t (that - after
of Health and of future Estimate e 1.499 persons [SA91 hang - to
Welfare last year - axcrding - to) as the lowest) turn that)
revealed)
concession_
(6).
Hoever.
• :IZvits
that.:;
prediction Will
1-2
clabo_rAl -retfon- buto-e
(1) (2) (3)
In Its future made public the Ministry
population tact year, of Health and
estimates WoHare
the SAB
would drop to
a new low of
1.499 in the
future,
</figure>
<figureCaption confidence="0.99189">
Figure 2: The discourse structures of texts (4) and (6).
</figureCaption>
<figure confidence="0.933981555555555">
elaglion=atigttional
(4)
but would
make a
comeback
after that,
(5)
increasing
once again.
</figure>
<bodyText confidence="0.998789767857143">
son (1988) the discourse structures of text frag-
ments (4) and (6). Each discourse structure is a
tree whose leaves correspond to the edus and whose
internal nodes correspond to contiguous text spans.
Each node is characterized by a status (NUCLEUS Or
SATELLITE) and a rhetorical relation, which is a re-
lation that holds between two non-overlapping text
spans. (There are a few exceptions to this rule: some
relations, such as the CONTRAST relation that. holds
between unit. [3] and span [4,5] in the structure of the
English text are multinuclear.) The distinction be-
tween nuclei and satellites comes from the empirical
observation that the nucleus expresses what is more
essential to the writer&apos;s intention than the satellite:
and that the nucleus of .a rhetorical relation is com-
prehensible independent, of the satellite, but. not vice
versa. Rhetorical relationsthat end, in the.suffix &apos;-e&amp;quot; •
denote relations that. correspond to embedded syn-
tactic constituents. For example, the ELABORATION-
OBJECT-ATTRIBUTE-E relation that holds between
units 2 and 1 in the English discourse structure cor-
responds to a restrictive relative. We chose to label
these relations because we have noticed that they
often dominate complex discourse trees. whose ele-
mentary units are fully fleshed clauses.
If one knows the mappings at the edu
one can determine the mappings at the span (dis-
course constituent) level as well. For example. us-
ing the elementary mappings in (7), one can deter-
mine that Japanese span [1,2] corresponds to English
span [1,2], Japanese unit [4] to English span [4.5].
Japanese span [6,7] to English unit [6], Japanese
span [1,5] to English span [1,5], and so on. As Fig-
ure 2 shows, the CONCESSION relation that holds be-
tween spans [1,5] and [6,7] in the Japanese tree corre-
sponds to a similar relation that holds between span
[1.5] and unit [6] in the English tree (modulo the fact
that. in Japanese, the relation holds between sen-
tence fragments, while in English it holds between
full sentences). However, the TEMPORAL-AFTER re-
lation that holds between units [3] and [4] in the
Japanese tree is realized as a CONTRAST relation
between unit • [3] and span [4,5] in the English tree,
And because Japanese units [6] and [7] are fused
into. unit [6] in &amp;quot;English&apos;, -the. relation ELABORATION-
OBJECT-ATTRIBUTE-E is no longer made explicit in
the English text.
Assume now that it is the task of an MGEN sys-
tem to produce from a knowledge base texts (4)
and (6). The system will have to select the ap-
propriate information, generate text. plans for the
two texts. generate sentence plans. and realize them.
Should the system generate a text plan having a
structure similar to the RST analysis at. the top or
the bottom of Figure 2? Or something in between?
As one can see. the discourse trees in Figure 2 are
</bodyText>
<page confidence="0.996284">
19
</page>
<bodyText confidence="0.999874478260869">
quite different: they suggest that depending on the
output language, text plans should use different re-
lations, different orderings of elementary units, dif-
ferent aggregations across semantic units, etc.
Some researchers may argue that the two RST
analyses in Figure 2 are too specific. That they,
in fact, correspond to.,text 1.plans that have beep,
already refined by an aggregation module and ar-
guably, even by a sentence planner. After all, the
re-ordering of units 1 and 2 can be explained only
in terms of different syntactic contraints in Japanese
and English. We agree with such a concern. Never-
theless, as our experiment shows, significant differ-
ences across discourse trees are found not only for
trees built at the sentence level, but also for trees
built at the paragraph and text levels. For these lev-
els, it is difficult to explain the differences in terms
of language-specific syntactic constraints. Rather, it
seems more adequate to assume that there are sig-
nificant differences with respect to the way informa-
tion is organized rhetorically across languages. The
experiment described in the next section estimates
quantitatively this difference.
</bodyText>
<sectionHeader confidence="0.998045" genericHeader="introduction">
3 Experiment
</sectionHeader>
<bodyText confidence="0.999223606741573">
In order to assess how similar discourse structures
are across languages, we built manually a cor-
pus of discourse trees for 40 Japanese texts and
their corresponding translations. The texts, se-
lected randomly from the ARPA corpus (White
and O&apos;Connell, 1994), contained on average about
460 words. We developed a discourse annota-
tion protocol for Japanese and English along the
lines followed by Marcu et al. (1999). We used
Marcu&apos;s discourse annotation tool (1999) in order
to manually construct the discourse structure of all
Japanese and English texts in the corpus. 10% of
the Japanese and English texts were rhetorically
labeled by two of us. The agreement was sta-
tistically significant (Kappa = 0.65.0 &gt; 0.01 for
Japanese and Kappa = 0.748, a &gt; 0.01 for En-
glish (Carletta, 1996; Siegel-and Castellan, 1988)).
The tool and the annotation protocol are available
at iittp://tvie tr. isi. edu/— rna rc u/ soft wa re / For each
pair of Japanese-English discourse, structures, we
also built manually an alignment file, which specified
the correspondence between the edus of the Japanese
and English texts.
Using labeled recall and precision figures, we com-
puted the similarity between English and Japanese
discourse trees with respect t.o their assignment of
Edu boundaries, hierarchical spans, nuclearity. and
rhetorical relations. Because the trees we compared
differ from one language to the other in the number
of elementary units, the orderof these units, and the
way the units are grouped recursively into discourse
spans, we computed two types of recall and precision
figures.
In computing Position-Dependent (P-D) recall
and precision figures, a Japanese span was consid-
ered to match an English span when the Japanese
span contained all the Japanese edus that cor-
responded to the edus in the English span, and
.when :the,Japanese-ArKLEirglish.spans appeared_ in
the same position linearly. For example, the En-
glish tree in Figure 2 is characterized by 10 sub-
sentential spans, which span across positions [1,1],
[2,2], [3,3], [4,4], [5,5], [6,6], [1,2], [4,5], [3,5], and
[1,5]. (Span [1,6] subsumes 2 sentences, so it is
not sub-sentential.) The Japanese discourse tree has
only 4 spans that could be matched in the same po-
sitions with English spans, namely spans [1,2]. [4,4],
[5,5], and [1,5]. Hence the similarity between the
Japanese tree and the English tree with respect to
their discourse structure below the sentence level has
a recall of 4/10 and a precision of 4/11 (in Figure 2,
there are 11 sub-sentential Japanese spans).
In computing Position-Independent (P-I) recall
and precision figures, even when a Japanese span
&amp;quot;floated&amp;quot; during the translation to a position in the
English tree that was different from the position
in the initial tree, the P-I recall and precision fig-
ures are affected less than when computing Position-
Dependent figures. The position-independent fig-
ures reflect the intuition that if two trees ti and t,
both have a subtree t, t1 and t2 are more similar
than if they were if they didn&apos;t share any subtree.
For instance, for the spans at the sub-sentential level
in the trees in Figure 2 the position-independent
recall is 6/10 and the position-independent preci-
sion is 6/11 because in addition to spans [1,2], [4,4],
[5,5], and [1,5], one can also match Japanese span
[1,1] to English span [2,2] and Japanese span [2,2]
to Japanese span [1,1]. The Position-Independent
figures offer a more optimistic metric for comparing
discourse trees. They span a wider range of values
than the Position-Dependent figures. which enables
a finer grained comparison, which in turn enables
a better characterization of the differences between
Japanese and English discourse structures.
In order to provide a better estimate of how close
two discourse trees were, we computed Position-
Dependent and -Independent recall and precision fig-
ures for the sentential level (where units are given
by edus and spans are given by sets of edus or single
sentences), paragraph level (where units are given by
sentences and spans are given by sets of sentences or
single paragraphs): and text level (where units are
given by paragraphs and spans are given by sets of
paragraphs). These figures offer a detailed picture of
how discourse structures and relations are mapped
from one language-to the other. Some of the differ-
ences at the sentence level can be explained by differ-
ences between the syntactic structures of Japanese
</bodyText>
<page confidence="0.98147">
20
</page>
<table confidence="0.999662846153846">
Level Units Spans Nuclei Relations
P-D R P-D P P-D R P-D P P-D R P-D P P-D R P-D P
Sentence 29.1 25.0 27.2 22.7 21.3 17.7 14.9 12.4
Paragraph 53.9 53.4 46.8 47.3 38.6 39.0 31.9 32.3
Text 41.3 42.6 31.5 32.6 28.8 29.9 26.1 27.1
Weighted Average 36.0 32.5 31.8 28.4 26.0 23.1 20.1 17.9
All 8.2 _ 7..4 . 5.9
P-I R P-I P P-I R P-I P P-I R P-I P P-I R P-I P
Sentence 71.0 61.0 56.0 46.6 44.3 36.9 30.5 25.4
Paragraph 62.1 61.6 53.2 53.8 43.3 43.8 35.1 35.5
Text 74.1 76.5 54.4 56.5 48.5 50.4 41.1 42.7
Weighted Average 69.6 63.0 55.2 49.2 44.8 39.9 33.1 29.5
All 74.5 66.8 50.6 45.8 39.4 35.7 26.8 24.3
</table>
<tableCaption confidence="0.999867">
Table 1: Similarity of the Japanese and English discourse structures
</tableCaption>
<bodyText confidence="0.992101344827586">
and English. The differences at the paragraph and
text levels have a purely rhetorical explanation.
As expected, when one computes the recall and
precision figures with respect to the nuclearity and
relation assignments, one also factors in the nucle-
arity status and the rhetorical relation that is asso-
ciated with each span.
Table 1 summarizes the results (P-D and P-I
(R)ecall and (P)recision figures) for each level (Sen-
tence, Paragraph, and Text). It presents Recall and
Precision figures with respect to span assignment,
nuclearity status, and rhetorical relation labeling of
discourse spans. The numbers in the &amp;quot;Weighted
Average&amp;quot; line report averages of the Sentence-,
Paragraph-, and Text-specific figures, weighted ac-
cording to the number of units at each level. The
numbers in the &amp;quot;All&amp;quot; line reflect recall and precision
figures computed across the entire trees, with no at-
tention paid to sentence and paragraph boundaries.
Given the significantly different syntactic struc-
t ures of Japanese and English. we were not. surprised
by the low recall and precision results that reflect
the similarity between discourse trees built below
the sentence level. However, as Table 1 shows, there
are astonishing differences between discourse trees
at the paragraph and text. levels as well. For exam-
ple, the Position-Independent figures show that only
about 62% of the sentenceS, and only bout 53% of
the hierarchical spans built across sentences could be
matched between the two corpora. When one looks
at the nuclearity stat us and rhetorical relations as-
sociated with the spans built across sentences. the
P-I recall and precision figures drop to about -IV
and 357( respectively.
The differences in recall and precision are ex-
plained both by differences in t he way information is
packaged into paragraphs in. the -two languages and
the way it is structured rhetorically both within and
above the paragraph level.
4 How should a multilingual text
planner work?
The results in Section 3 strongly suggest that if one
is to build text plans in the context of a Japanese-
English multilingual generation system, a language-
independent text planning module whose output is
mapped straightforwardly into sentence plans (Ior-
danskaja et al., 1992; Goldberg et al., 1994) will not
do. The differences between the rhetorical structures
of Japanese and English texts are simply too big to
support the derivation of a unique text plan, which
would subsume both the Japanese- and English-
specific realizations. If we are to build MGEN sys-
tems capable of generating rich texts in languages
as distant as English and Japanese, we would need
to use more sophisticated techniques. In the rest of
this section, we discuss a set of possible approaches,
which are consistent with work that has been carried
out to date in the NLG field.
</bodyText>
<subsectionHeader confidence="0.870177">
4.1 Use text plan representations that are
</subsectionHeader>
<bodyText confidence="0.988756368421053">
more abstract than discourse trees
Delin et al. (1994) have shown that although t he
rhetorical renderings in Figure 1 are non-isomorphic.
they are all. subsumed by one -common., more -ab-
stract text-plan representation language that for-
malizes the procedural relations of Generation and
Enablenzent (Goldman, 19.70).. One can conceive of..
text plans being represented as sequences of actions
or hierarchies of actions and goals over which one can
identify Generation and Enablement relations that
hold between them. In such a framework, text. plan-
ning is carried out in a language-independent man-
ner. which is then followed by a rhetorical -fleshing
out-. (Delin et al. (1994) have shown how Gener-
ation and Enablement relations are realized rhetor-
ically in various languages using relations such as
PURPOSE, &apos;SEQUENCE, &apos;CONDITION, and MEANS.)
Bateman and Rondhuis (1997) suggest. that the
variability present in Delin et al.&apos;s Rhetorical Struc-
</bodyText>
<page confidence="0.998045">
21
</page>
<bodyText confidence="0.999926318181818">
ture analyses in Figure 1 can be explained by the
inadequate mixture of intentional and semantic re-
lations, at different levels of granularity. They pro-
pose that discourse phenomena should be accounted
for at a more abstract level than RST relations
and they present a classification system in terms
of &amp;quot;stratification&amp;quot;, ..&amp;quot;Inetafunction&amp;quot;.„.a4d, -&amp;quot;paradig,
inatic/syntagmatic axiality&amp;quot; that enables one to rep-
resent discourse structures at multiple levels of ab-
straction.
Adopting such an approach could be an extremely
rewarding enterprise. Unfortunately, the research
of Delin et al. (1994) and Bateman and Rond-
huis (1997) cannot be applied yet to unrestricted do-
mains. Generation and Enablement are only two of
the abstract relations that can hold between actions
and goals. And some texts, such as descriptions, are
difficult to characterize only in terms of actions and
goals. Building a &amp;quot;complete&amp;quot; taxonomy of such ab-
stract relations and identifying adequate mappings
between there relations and rhetorical relations are
still open problems.
</bodyText>
<subsectionHeader confidence="0.954119">
4.2 Derive a language-independent
</subsectionHeader>
<bodyText confidence="0.997528181818182">
discourse structure, and then linearize
it
Rosner and Stede (1992) and Stede (1999) assume
that a discourse representation a la Mann and
Thompson imposes no contraints on the linear order
of the leaves. For the purpose of multilingual text
planning, one can, hence, assume that a language-
independent text planner derives first a language-
independent rhetorical structure and then linearizes
it, i.e., transforms it to make it language specific.
The transformations that Rosner and Stede have ap-
plied concern primarily re-orderings of the children
of some nodes and re-assignment of rhetorical rela-
tion labels. But given, for example, the significant
differences between the discourse structures in Fig-
ure 2, it is difficult to envision what the language-
independent text plan might look like. It is defi-
nitely possible to conceive of such a text plan rep-
resentation. However, the linearization module will
need then to. be much more sophisticated: it will
need to be able to rewrite full structures, re-order
constituents, aggregate_ across possibly non-adjacent
units, etc.
4.3 Implement a text planning algorithm
for one language only. For all other
languages. devise discourse-tree
rewriting modules
In this approach, the system developer assigns a pre-
ferrential status to one of the languages t hat are
to be handled by the MG EN system. Let&apos;s call
this language P. The system developer implements
text planning algorithms only for this language. For
any other language 0, the developer implements a
discourse-tree rewriting module capable of rewriting
P-specific discourse structures into 0-specific dis-
course structures. When generating texts in lan-
guage P, the MGEN system works as a monolin-
gual generator. When generating texts in language
0, the MGEN system generates a text plan in Lan-
: :guage.B, maps ikirktalanguage.0.,, and .then :proceeds
further with the sentence planning and realization
stages. Marcu et al. (2000) present and evaluate a
discourse-tree rewriting algorithm that exploits ma-
chine learning methods in order to map Japanese
discourse trees into discourse trees that resemble
English-specific renderings.
The advantage of such an approach is that the
tree-rewriting modules can be also used in the con-
text of machine translation systems in order to re-
package and re-organize the input text rhetorically,
to reflect constraints specific to the target language.
The disadvantage is that, from an NLG perspective,
there is no guarantee that such a system could pro-
duce better results than a system that implements
language-dependent text planning modules.
</bodyText>
<subsectionHeader confidence="0.888026">
4.4 Derive language-dependent text plans
</subsectionHeader>
<bodyText confidence="0.999987785714286">
Another viable approach is to acknowledge that
text plans vary significantly across languages and,
therefore, should be derived by language-dependent
planners. To this end, one could use both top-
down (Hovy, 1993; Moore and Paris, 1993) and
bottom-up (Marcu, 1997; Mellish et al., 1998) text
planning algorithms. The advantage of this ap-
proach is that it has the potential of producing trees
that reflect the peculiarities specific to any language.
The disadvantage is that only the text planning al-
gorithms are general: the plan operators and the
rhetorical relations they operate with are language-
dependent, and hence, more expensive to develop
and maintain.
</bodyText>
<subsectionHeader confidence="0.571608">
4.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999892083333333">
Depending on the languages and text. genres it op-
erates with, an MGEN system may get away with
a language-independent text planner. However,
for sophisticated genres and distant languages, im-
plementing a language-independent planner that is
straightforwardly -mapped ilito•seittrice• plans does
not appear to be a felicitous solution. We enu-
merated four possible alternatives for addressing the
text planning problem in an MGEN system. Each
of the approaches has its own pluses and minuses.
Which will eventually win in large-scale deployable
\IGEN systems remains an open question.
</bodyText>
<sectionHeader confidence="0.9979" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.932620333333333">
John A. Bateman and Maas Jan Rendlniis. 1997.
Coherence relations: Towards a general specifica-
tion. Discourse Processes, 24:3-49.
</reference>
<page confidence="0.98983">
22
</page>
<reference confidence="0.99760056701031">
Jean Carletta. 1996. Assessing agreement on clas-
sification tasks: The kappa statistic. Computa-
tional Linguistics, 22(2):249-254, June.
Judy L. Delin, Anthony Hartley, Cecile L. Paris, Do-
nia R. Scott, and Keith Vander Linden. 1994. Ex-
pressing procedural relationships in multilingual
-.instructions. In -Proceedings: ofthe &apos;Seventh-Inter,
national Workshop on Natural Language Genera-
tion, pages 61-70, Kennebunkport, Maine, June.
J. Delin, D. Scott, and A. Hartley. 1996. Prag-
matic congruence through language-specific map-
pings from semantics to syntax. Technical report,
ITRI Research Report ITRI-96-12, University of
Brighton.
E. Goldberg, N. Driedger, and R.. Kittredge. 1994.
Using natural-language processing to produce
weather forecasts. IEEE Expert, 9(2):45-53.
A.I. Goldman. 1970. A Theory of Human Action.
Prentice Hall, Englewood Cliffs, NJ.
Eduard H. Hovy. 1993. Automated discourse gen-
eration using discourse structure relations. Artifi-
cial Intelligence, 63(1-2):341-386, October.
L. lordanskaja, M. Kim, R. Kittredge, B. Lavoie,
and A. Polguere. 1992. Generation of extended
bilingual statistical reports. In Proceedings of
the 14th International Conference on Compu-
tational Linguistics (COLING&apos;92), pages 1019-
1023, Nantes, France.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional
theory of text organization. Text, 8(3):243-281.
Daniel Marcu. 1997. From local to global coherence:
A bottom-up approach to text planning. In PM-
ceedings of the Fourteenth National Conference on
.4rtificial Intelligence (A.4.4I-97), pages 629-635,
Providence, Rhode Island, July 28-31.
Daniel Marcu, Estibaliz Arnorrortu, and Magdalena
Romera. 1999. Experiments in constructing a
corpus of discourse trees. In Proceedings of the
.4CL&apos;99 Workshop on Standards and Tools for
Discourse Tagging, pages 48-57, University of
Maryland. June 22.
Daniel Marcu, Lynn Carlson, and Maki Watan-
abe. 2000. The automatic translation of discourse
structures. In Proceedings of the First Annual
Meeting of the North American Chapter of the As-
sociation for Computational Linguistics NA CL-
2000. Seattle, Washington. April 29 - May 3.
Chris Mellish. Alistair Knott. Jon Oberlander,
and Mick O&apos;Donnell. 1998. Experiments using
stochastic search for text planning. In Proceed-
ings of the 9th International Workshop on .Vataml
Language Generation. pages 98-107. Niagara-on-
the-Lake, Canada. August 5-7.
Johanna D. Moore and C6cile L. Paris. 1993. Plan-
ning text for advisory dialogues: Capturing mien-
tional and rhetorical information. Computational
Linguistics, 19(4):651-694.
C. Paris, K. Vander Linden, M. Fischer, A. Hart-
ley, L. Pemberton, R. Power, and D. Scott. 1995.
A support tool for writing multilingual instruc-
tions.. In Proceedings. of the 14th International
Joint,Conference, din.-Artificial Intelligence (If-
CAI&apos;95), pages 1398-1404, Montreal, Canada.
Richar Power and Donia Scott. 1998. Multilingual
authoring using feedback texts. In Proceedings of
the 36th Annual Meeting of the Association for
Computational Linguistics (ACL&apos;98), Montreal,
Canada, August.
Ehud Reiter and Chris Mellish. 1993. Optimizing
the costs and benefits of natural language gen-
eration. In Proceedings of the 13th International
Joint Conference on Artificial Intelligence, pages
1164-1169.
Dietmar Rosner and Manfred Stede. 1992. Cus-
tomizing RST for the automatic production
of technical manuals. In R. Dale, E. Hovy,
D. Wisner, and 0. Stock, editors, Aspects of Au-
tomated Natural Language Generation; 6th Inter-
national Workshop on Natural Language Gener-
ation, number 587 in Lecture Notes in Artificial
Intelligence, pages 199-214, Trento, Italy, April.
Springer-Verlag.
Sidney Siegel and N.J. Castellan. 1988. Non-
parametric Statistics for the Behavioral Sciences.
McGraw-Hill, second edition.
Manfred Stede. 1999. Rhetorical structure and the-
matic structure in text generation. In Working
Notes of the Workshop on Levels of Represen-
tation in Discourse, pages 117-123, Edinburgh,
Scotland, July 7-9.
J. White and &apos;I&apos;. O&apos;Connell. 1994. Evalua-
tion in the ARPA machine-translation pro-
gram: 1993 methodology. In Proceedings of
the .4RPA Human language Technology Work-
shop, pages 135-140, Washington, D.C. See also
http://ursula.georgeto W71. edu/.
</reference>
<page confidence="0.998917">
23
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912498">
<title confidence="0.9914475">An Empirical Study in Multilingual Natural Generation: What Should A Text Planner Do?</title>
<author confidence="0.999008">Daniel Marcu Lynn Carlson Maki Watanabe</author>
<affiliation confidence="0.9894335">Information Sciences Institute and U.S. Department of Defense Department of Linguistics Department of Computer Science .FL . Meade,. MD,.20755 University.,of Southern California</affiliation>
<address confidence="0.993312333333333">of Southern California Angeles, CA 90089 Admiralty Way, Suite 1001 Marina del Rey, CA 90292</address>
<email confidence="0.969354">marcu4isi.edu</email>
<abstract confidence="0.99959375">We present discourse annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John A Bateman</author>
<author>Maas Jan Rendlniis</author>
</authors>
<title>Coherence relations: Towards a general specification.</title>
<date>1997</date>
<booktitle>Discourse Processes,</booktitle>
<pages>24--3</pages>
<marker>Bateman, Rendlniis, 1997</marker>
<rawString>John A. Bateman and Maas Jan Rendlniis. 1997. Coherence relations: Towards a general specification. Discourse Processes, 24:3-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--2</pages>
<contexts>
<context position="13507" citStr="Carletta, 1996" startWordPosition="2171" endWordPosition="2172">anslations. The texts, selected randomly from the ARPA corpus (White and O&apos;Connell, 1994), contained on average about 460 words. We developed a discourse annotation protocol for Japanese and English along the lines followed by Marcu et al. (1999). We used Marcu&apos;s discourse annotation tool (1999) in order to manually construct the discourse structure of all Japanese and English texts in the corpus. 10% of the Japanese and English texts were rhetorically labeled by two of us. The agreement was statistically significant (Kappa = 0.65.0 &gt; 0.01 for Japanese and Kappa = 0.748, a &gt; 0.01 for English (Carletta, 1996; Siegel-and Castellan, 1988)). The tool and the annotation protocol are available at iittp://tvie tr. isi. edu/— rna rc u/ soft wa re / For each pair of Japanese-English discourse, structures, we also built manually an alignment file, which specified the correspondence between the edus of the Japanese and English texts. Using labeled recall and precision figures, we computed the similarity between English and Japanese discourse trees with respect t.o their assignment of Edu boundaries, hierarchical spans, nuclearity. and rhetorical relations. Because the trees we compared differ from one lang</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):249-254, June.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Judy L Delin</author>
<author>Anthony Hartley</author>
<author>Cecile L Paris</author>
<author>Donia R Scott</author>
<author>Keith Vander Linden</author>
</authors>
<title>Expressing procedural relationships in multilingual -.instructions.</title>
<date>1994</date>
<booktitle>In -Proceedings: ofthe &apos;Seventh-Inter, national Workshop on Natural Language Generation,</booktitle>
<tech>Technical report, ITRI Research Report ITRI-96-12,</tech>
<pages>61--70</pages>
<institution>University of Brighton.</institution>
<location>Kennebunkport, Maine,</location>
<contexts>
<context position="2717" citStr="Delin et al., 1994" startWordPosition="394" endWordPosition="397">s a viable option. Many of the early implementations of MG EN systems have adopted the perspective that text planners can be implemented as language-independent modules (lordanskaja et al.. 1992: Goldberg et al., 1994), possibly followed by a lnicari.:alion stage, in which discourse trees are re-written to reflect language-specific constraints (Wisner and Steele. 1992: Stede, 1999). Although such an approach may be adequate for highly restricted text genres, such as weather forecasts, it usually poses problems for less restricted genres. Studies of instruction manuals (Rosner and Stede, 1992; Delin et al., 1994: Delin et al., 1996) suggest that there are variations with respect to the way high-level communicative goals are realized across languages. For example, Delin et al. (1994) noticed that sentences (1), (2), and (3), which were taken from a trilingual instruction manual for a step-aerobics machine, yield nonisomorphic Rhetorical Structure (Mann and Thompson, 1988) analyses in English, French, and German respectively (see Figure 1). English: [The stepping load can be altered&apos;] (I) [by loosening the locking lever2] [and changing the position of the cylinder foot3]. French: [Pour modifier la char</context>
<context position="4450" citStr="Delin et al., 1994" startWordPosition="654" endWordPosition="657">Are the examples above an exception or the norm? Are non-isomorphic analyses specific to discourse structures built across elementary discourse units of single sentences, or do they also occur across sentences and paragraphs? If nonisomorphism is ubiquitous, how should an MG EN system be designed in order to effectively deal wit Ii non-isomorphic discourse structures when mapping knowledge bases into multiple languages? In this paper. we describe an experiment that was designed to answer these questions. To investigate 17 Figure 1: Contrasting multilingual discourse structure representations (Delin et al., 1994, P. 63) English French German Circumstance 2 Loosen Means (Lockern) 2 3 2 3 3 Loosen Change Loosen Change Change Alter (Desserrer) (Deplacer) (Verschieben) (Verandert) how discourse structures differ across languages, we manually built a parallel corpus of discourse trees of newspaper Japanese texts and their corresponding English translations. In section 2, we present some of the problems specific to the construction of such a corpus. In section 3, we present our experiment and discuss our empirical findings. In Section 4, we discuss the implications of our work for the task of text planning</context>
<context position="20746" citStr="Delin et al. (1994)" startWordPosition="3362" endWordPosition="3365">tween the rhetorical structures of Japanese and English texts are simply too big to support the derivation of a unique text plan, which would subsume both the Japanese- and Englishspecific realizations. If we are to build MGEN systems capable of generating rich texts in languages as distant as English and Japanese, we would need to use more sophisticated techniques. In the rest of this section, we discuss a set of possible approaches, which are consistent with work that has been carried out to date in the NLG field. 4.1 Use text plan representations that are more abstract than discourse trees Delin et al. (1994) have shown that although t he rhetorical renderings in Figure 1 are non-isomorphic. they are all. subsumed by one -common., more -abstract text-plan representation language that formalizes the procedural relations of Generation and Enablenzent (Goldman, 19.70).. One can conceive of.. text plans being represented as sequences of actions or hierarchies of actions and goals over which one can identify Generation and Enablement relations that hold between them. In such a framework, text. planning is carried out in a language-independent manner. which is then followed by a rhetorical -fleshing out</context>
<context position="22231" citStr="Delin et al. (1994)" startWordPosition="3586" endWordPosition="3589">t al.&apos;s Rhetorical Struc21 ture analyses in Figure 1 can be explained by the inadequate mixture of intentional and semantic relations, at different levels of granularity. They propose that discourse phenomena should be accounted for at a more abstract level than RST relations and they present a classification system in terms of &amp;quot;stratification&amp;quot;, ..&amp;quot;Inetafunction&amp;quot;.„.a4d, -&amp;quot;paradig, inatic/syntagmatic axiality&amp;quot; that enables one to represent discourse structures at multiple levels of abstraction. Adopting such an approach could be an extremely rewarding enterprise. Unfortunately, the research of Delin et al. (1994) and Bateman and Rondhuis (1997) cannot be applied yet to unrestricted domains. Generation and Enablement are only two of the abstract relations that can hold between actions and goals. And some texts, such as descriptions, are difficult to characterize only in terms of actions and goals. Building a &amp;quot;complete&amp;quot; taxonomy of such abstract relations and identifying adequate mappings between there relations and rhetorical relations are still open problems. 4.2 Derive a language-independent discourse structure, and then linearize it Rosner and Stede (1992) and Stede (1999) assume that a discourse re</context>
</contexts>
<marker>Delin, Hartley, Paris, Scott, Linden, 1994</marker>
<rawString>Judy L. Delin, Anthony Hartley, Cecile L. Paris, Donia R. Scott, and Keith Vander Linden. 1994. Expressing procedural relationships in multilingual -.instructions. In -Proceedings: ofthe &apos;Seventh-Inter, national Workshop on Natural Language Generation, pages 61-70, Kennebunkport, Maine, June. J. Delin, D. Scott, and A. Hartley. 1996. Pragmatic congruence through language-specific mappings from semantics to syntax. Technical report, ITRI Research Report ITRI-96-12, University of Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Goldberg</author>
<author>N Driedger</author>
<author>R Kittredge</author>
</authors>
<title>Using natural-language processing to produce weather forecasts.</title>
<date>1994</date>
<journal>IEEE Expert,</journal>
<pages>9--2</pages>
<contexts>
<context position="1091" citStr="Goldberg et al., 1994" startWordPosition="152" endWordPosition="155"> marcu4isi.edu Abstract We present discourse annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems. 1 Introduction The natural language generation community has emphasized for a number of years the strengths of multilingual generation (MGEN) systems (Iordanskaja et al., 1992; Wisner and Stede, 1992; Reiter and Mellish, 1993; Goldberg et al., 1994; Paris et al., 1995; Power and Scott, 1998). These strengths concern the reuse of knowledge, the support for early drafts in several languages, the support for maintaining consistency when making changes, the support for producing alternative formulations, and the potential for producing higher quality outputs than machine translation. (The weaknesses concern the high-cost of building large, language-independent knowledge bases, and the difficulty of producing high-quality, broad-coverage generation algorithms.) From an economic perspective, the more a systern can rely on language independent</context>
<context position="2317" citStr="Goldberg et al., 1994" startWordPosition="335" endWordPosition="338">ules for the purpose of multilingual generation, the better. If an MGEN system needs to develop language dependent knowledge bases, and language dependent algorithms for content selection, text planning, and sentence planning, •it- is difficult to -justify its economic viability. However, if most of these components are language independent and/or much of the code can be re-used, an MGEN system becomes a viable option. Many of the early implementations of MG EN systems have adopted the perspective that text planners can be implemented as language-independent modules (lordanskaja et al.. 1992: Goldberg et al., 1994), possibly followed by a lnicari.:alion stage, in which discourse trees are re-written to reflect language-specific constraints (Wisner and Steele. 1992: Stede, 1999). Although such an approach may be adequate for highly restricted text genres, such as weather forecasts, it usually poses problems for less restricted genres. Studies of instruction manuals (Rosner and Stede, 1992; Delin et al., 1994: Delin et al., 1996) suggest that there are variations with respect to the way high-level communicative goals are realized across languages. For example, Delin et al. (1994) noticed that sentences (1</context>
<context position="20095" citStr="Goldberg et al., 1994" startWordPosition="3251" endWordPosition="3254">s drop to about -IV and 357( respectively. The differences in recall and precision are explained both by differences in t he way information is packaged into paragraphs in. the -two languages and the way it is structured rhetorically both within and above the paragraph level. 4 How should a multilingual text planner work? The results in Section 3 strongly suggest that if one is to build text plans in the context of a JapaneseEnglish multilingual generation system, a languageindependent text planning module whose output is mapped straightforwardly into sentence plans (Iordanskaja et al., 1992; Goldberg et al., 1994) will not do. The differences between the rhetorical structures of Japanese and English texts are simply too big to support the derivation of a unique text plan, which would subsume both the Japanese- and Englishspecific realizations. If we are to build MGEN systems capable of generating rich texts in languages as distant as English and Japanese, we would need to use more sophisticated techniques. In the rest of this section, we discuss a set of possible approaches, which are consistent with work that has been carried out to date in the NLG field. 4.1 Use text plan representations that are mor</context>
</contexts>
<marker>Goldberg, Driedger, Kittredge, 1994</marker>
<rawString>E. Goldberg, N. Driedger, and R.. Kittredge. 1994. Using natural-language processing to produce weather forecasts. IEEE Expert, 9(2):45-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Goldman</author>
</authors>
<title>A Theory of Human Action.</title>
<date>1970</date>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, NJ.</location>
<marker>Goldman, 1970</marker>
<rawString>A.I. Goldman. 1970. A Theory of Human Action. Prentice Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Automated discourse generation using discourse structure relations.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="25553" citStr="Hovy, 1993" startWordPosition="4100" endWordPosition="4101">he context of machine translation systems in order to repackage and re-organize the input text rhetorically, to reflect constraints specific to the target language. The disadvantage is that, from an NLG perspective, there is no guarantee that such a system could produce better results than a system that implements language-dependent text planning modules. 4.4 Derive language-dependent text plans Another viable approach is to acknowledge that text plans vary significantly across languages and, therefore, should be derived by language-dependent planners. To this end, one could use both topdown (Hovy, 1993; Moore and Paris, 1993) and bottom-up (Marcu, 1997; Mellish et al., 1998) text planning algorithms. The advantage of this approach is that it has the potential of producing trees that reflect the peculiarities specific to any language. The disadvantage is that only the text planning algorithms are general: the plan operators and the rhetorical relations they operate with are languagedependent, and hence, more expensive to develop and maintain. 4.5 Discussion Depending on the languages and text. genres it operates with, an MGEN system may get away with a language-independent text planner. Howe</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>Eduard H. Hovy. 1993. Automated discourse generation using discourse structure relations. Artificial Intelligence, 63(1-2):341-386, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L lordanskaja</author>
<author>M Kim</author>
<author>R Kittredge</author>
<author>B Lavoie</author>
<author>A Polguere</author>
</authors>
<title>Generation of extended bilingual statistical reports.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING&apos;92),</booktitle>
<pages>1019--1023</pages>
<location>Nantes, France.</location>
<marker>lordanskaja, Kim, Kittredge, Lavoie, Polguere, 1992</marker>
<rawString>L. lordanskaja, M. Kim, R. Kittredge, B. Lavoie, and A. Polguere. 1992. Generation of extended bilingual statistical reports. In Proceedings of the 14th International Conference on Computational Linguistics (COLING&apos;92), pages 1019-1023, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text,</tech>
<pages>8--3</pages>
<contexts>
<context position="3083" citStr="Mann and Thompson, 1988" startWordPosition="450" endWordPosition="454">eele. 1992: Stede, 1999). Although such an approach may be adequate for highly restricted text genres, such as weather forecasts, it usually poses problems for less restricted genres. Studies of instruction manuals (Rosner and Stede, 1992; Delin et al., 1994: Delin et al., 1996) suggest that there are variations with respect to the way high-level communicative goals are realized across languages. For example, Delin et al. (1994) noticed that sentences (1), (2), and (3), which were taken from a trilingual instruction manual for a step-aerobics machine, yield nonisomorphic Rhetorical Structure (Mann and Thompson, 1988) analyses in English, French, and German respectively (see Figure 1). English: [The stepping load can be altered&apos;] (I) [by loosening the locking lever2] [and changing the position of the cylinder foot3]. French: [Pour modifier la charge d&apos;appui,&apos; ] (2) [desserrer les levieres2] [puis deplacer le pied des verins3] ([To modify the load stepping&apos;] [loosen the levers2] [then change the foot of the cylinder foot.1) German: [Nach Lockern der Klemnthebel2] (3) [kann` ] [durch Verschieben des Zvlinderfu,3es3] [die Tretbelastung verandert werden.l] ([After loosening of the levers2] [can&apos;] [by pushing o</context>
<context position="6197" citStr="Mann and Thompson, 1988" startWordPosition="931" endWordPosition="934"> as the lowest3] [that after *SAB* rising to turn that4] [*they* estimated but5] [already the estimate misses a pointG] [prediction became.] [In its future population estimates&apos;] [made (6) public last year.2] [the Ministry of Health and Welfare predicted that the SAB would drop to a new low of 1.499 in the future.3] [but would make a comeback after that .4] [increasing once again.5] [However, it looks as if t hat prediction will be quickly shattered.&apos;] The labeled spans of text represent elementary discourse units (edits). i.e.. minimal text spans that, have an unambiguous discourse function (Mann and Thompson, 1988). If we analyze the text fragments closely, we will notice that in translating sentence (4), a professional translator chose to realize the information in Japanese unit 2 first (unit 2 in text (4) corresponds roughly to unit 1 in text (6)); to realize then some of the information in Japanese unit 1 (part of unit 1 in text (4) corresponds to unit 2 in text (6)); to fuse then information given in units 1, 3, and 5 in text (4) and realize it in English as unit 3; and so on. Also, the translator chose to repackage the information in the original Japanese sentence into two English sentences. At the</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>From local to global coherence: A bottom-up approach to text planning.</title>
<date>1997</date>
<booktitle>In PMceedings of the Fourteenth National Conference on .4rtificial Intelligence (A.4.4I-97),</booktitle>
<pages>629--635</pages>
<location>Providence, Rhode Island,</location>
<contexts>
<context position="25604" citStr="Marcu, 1997" startWordPosition="4108" endWordPosition="4109"> to repackage and re-organize the input text rhetorically, to reflect constraints specific to the target language. The disadvantage is that, from an NLG perspective, there is no guarantee that such a system could produce better results than a system that implements language-dependent text planning modules. 4.4 Derive language-dependent text plans Another viable approach is to acknowledge that text plans vary significantly across languages and, therefore, should be derived by language-dependent planners. To this end, one could use both topdown (Hovy, 1993; Moore and Paris, 1993) and bottom-up (Marcu, 1997; Mellish et al., 1998) text planning algorithms. The advantage of this approach is that it has the potential of producing trees that reflect the peculiarities specific to any language. The disadvantage is that only the text planning algorithms are general: the plan operators and the rhetorical relations they operate with are languagedependent, and hence, more expensive to develop and maintain. 4.5 Discussion Depending on the languages and text. genres it operates with, an MGEN system may get away with a language-independent text planner. However, for sophisticated genres and distant languages</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. From local to global coherence: A bottom-up approach to text planning. In PMceedings of the Fourteenth National Conference on .4rtificial Intelligence (A.4.4I-97), pages 629-635, Providence, Rhode Island, July 28-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Estibaliz Arnorrortu</author>
<author>Magdalena Romera</author>
</authors>
<title>Experiments in constructing a corpus of discourse trees.</title>
<date>1999</date>
<booktitle>In Proceedings of the .4CL&apos;99 Workshop on Standards and Tools for Discourse Tagging,</booktitle>
<pages>48--57</pages>
<institution>University of Maryland.</institution>
<contexts>
<context position="13139" citStr="Marcu et al. (1999)" startWordPosition="2106" endWordPosition="2109"> significant differences with respect to the way information is organized rhetorically across languages. The experiment described in the next section estimates quantitatively this difference. 3 Experiment In order to assess how similar discourse structures are across languages, we built manually a corpus of discourse trees for 40 Japanese texts and their corresponding translations. The texts, selected randomly from the ARPA corpus (White and O&apos;Connell, 1994), contained on average about 460 words. We developed a discourse annotation protocol for Japanese and English along the lines followed by Marcu et al. (1999). We used Marcu&apos;s discourse annotation tool (1999) in order to manually construct the discourse structure of all Japanese and English texts in the corpus. 10% of the Japanese and English texts were rhetorically labeled by two of us. The agreement was statistically significant (Kappa = 0.65.0 &gt; 0.01 for Japanese and Kappa = 0.748, a &gt; 0.01 for English (Carletta, 1996; Siegel-and Castellan, 1988)). The tool and the annotation protocol are available at iittp://tvie tr. isi. edu/— rna rc u/ soft wa re / For each pair of Japanese-English discourse, structures, we also built manually an alignment fi</context>
</contexts>
<marker>Marcu, Arnorrortu, Romera, 1999</marker>
<rawString>Daniel Marcu, Estibaliz Arnorrortu, and Magdalena Romera. 1999. Experiments in constructing a corpus of discourse trees. In Proceedings of the .4CL&apos;99 Workshop on Standards and Tools for Discourse Tagging, pages 48-57, University of Maryland. June 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Lynn Carlson</author>
<author>Maki Watanabe</author>
</authors>
<title>The automatic translation of discourse structures.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics NA CL2000.</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="24650" citStr="Marcu et al. (2000)" startWordPosition="3962" endWordPosition="3965"> handled by the MG EN system. Let&apos;s call this language P. The system developer implements text planning algorithms only for this language. For any other language 0, the developer implements a discourse-tree rewriting module capable of rewriting P-specific discourse structures into 0-specific discourse structures. When generating texts in language P, the MGEN system works as a monolingual generator. When generating texts in language 0, the MGEN system generates a text plan in Lan: :guage.B, maps ikirktalanguage.0.,, and .then :proceeds further with the sentence planning and realization stages. Marcu et al. (2000) present and evaluate a discourse-tree rewriting algorithm that exploits machine learning methods in order to map Japanese discourse trees into discourse trees that resemble English-specific renderings. The advantage of such an approach is that the tree-rewriting modules can be also used in the context of machine translation systems in order to repackage and re-organize the input text rhetorically, to reflect constraints specific to the target language. The disadvantage is that, from an NLG perspective, there is no guarantee that such a system could produce better results than a system that im</context>
</contexts>
<marker>Marcu, Carlson, Watanabe, 2000</marker>
<rawString>Daniel Marcu, Lynn Carlson, and Maki Watanabe. 2000. The automatic translation of discourse structures. In Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics NA CL2000. Seattle, Washington. April 29 - May 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott Jon Oberlander</author>
<author>Mick O&apos;Donnell</author>
</authors>
<title>Experiments using stochastic search for text planning.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on .Vataml Language Generation.</booktitle>
<pages>98--107</pages>
<location>Niagara-onthe-Lake, Canada.</location>
<marker>Oberlander, O&apos;Donnell, 1998</marker>
<rawString>Chris Mellish. Alistair Knott. Jon Oberlander, and Mick O&apos;Donnell. 1998. Experiments using stochastic search for text planning. In Proceedings of the 9th International Workshop on .Vataml Language Generation. pages 98-107. Niagara-onthe-Lake, Canada. August 5-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanna D Moore</author>
<author>C6cile L Paris</author>
</authors>
<title>Planning text for advisory dialogues: Capturing mientional and rhetorical information.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--4</pages>
<contexts>
<context position="25577" citStr="Moore and Paris, 1993" startWordPosition="4102" endWordPosition="4105">f machine translation systems in order to repackage and re-organize the input text rhetorically, to reflect constraints specific to the target language. The disadvantage is that, from an NLG perspective, there is no guarantee that such a system could produce better results than a system that implements language-dependent text planning modules. 4.4 Derive language-dependent text plans Another viable approach is to acknowledge that text plans vary significantly across languages and, therefore, should be derived by language-dependent planners. To this end, one could use both topdown (Hovy, 1993; Moore and Paris, 1993) and bottom-up (Marcu, 1997; Mellish et al., 1998) text planning algorithms. The advantage of this approach is that it has the potential of producing trees that reflect the peculiarities specific to any language. The disadvantage is that only the text planning algorithms are general: the plan operators and the rhetorical relations they operate with are languagedependent, and hence, more expensive to develop and maintain. 4.5 Discussion Depending on the languages and text. genres it operates with, an MGEN system may get away with a language-independent text planner. However, for sophisticated g</context>
</contexts>
<marker>Moore, Paris, 1993</marker>
<rawString>Johanna D. Moore and C6cile L. Paris. 1993. Planning text for advisory dialogues: Capturing mientional and rhetorical information. Computational Linguistics, 19(4):651-694.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Paris</author>
<author>K Vander Linden</author>
<author>M Fischer</author>
<author>A Hartley</author>
<author>L Pemberton</author>
<author>R Power</author>
<author>D Scott</author>
</authors>
<title>A support tool for writing multilingual instructions..</title>
<date>1995</date>
<booktitle>In Proceedings. of the 14th International Joint,Conference, din.-Artificial Intelligence (IfCAI&apos;95),</booktitle>
<pages>1398--1404</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1111" citStr="Paris et al., 1995" startWordPosition="156" endWordPosition="159"> We present discourse annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems. 1 Introduction The natural language generation community has emphasized for a number of years the strengths of multilingual generation (MGEN) systems (Iordanskaja et al., 1992; Wisner and Stede, 1992; Reiter and Mellish, 1993; Goldberg et al., 1994; Paris et al., 1995; Power and Scott, 1998). These strengths concern the reuse of knowledge, the support for early drafts in several languages, the support for maintaining consistency when making changes, the support for producing alternative formulations, and the potential for producing higher quality outputs than machine translation. (The weaknesses concern the high-cost of building large, language-independent knowledge bases, and the difficulty of producing high-quality, broad-coverage generation algorithms.) From an economic perspective, the more a systern can rely on language independent modules for the pur</context>
</contexts>
<marker>Paris, Linden, Fischer, Hartley, Pemberton, Power, Scott, 1995</marker>
<rawString>C. Paris, K. Vander Linden, M. Fischer, A. Hartley, L. Pemberton, R. Power, and D. Scott. 1995. A support tool for writing multilingual instructions.. In Proceedings. of the 14th International Joint,Conference, din.-Artificial Intelligence (IfCAI&apos;95), pages 1398-1404, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richar Power</author>
<author>Donia Scott</author>
</authors>
<title>Multilingual authoring using feedback texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL&apos;98),</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="1135" citStr="Power and Scott, 1998" startWordPosition="160" endWordPosition="163">e annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems. 1 Introduction The natural language generation community has emphasized for a number of years the strengths of multilingual generation (MGEN) systems (Iordanskaja et al., 1992; Wisner and Stede, 1992; Reiter and Mellish, 1993; Goldberg et al., 1994; Paris et al., 1995; Power and Scott, 1998). These strengths concern the reuse of knowledge, the support for early drafts in several languages, the support for maintaining consistency when making changes, the support for producing alternative formulations, and the potential for producing higher quality outputs than machine translation. (The weaknesses concern the high-cost of building large, language-independent knowledge bases, and the difficulty of producing high-quality, broad-coverage generation algorithms.) From an economic perspective, the more a systern can rely on language independent modules for the purpose of multilingual gen</context>
</contexts>
<marker>Power, Scott, 1998</marker>
<rawString>Richar Power and Donia Scott. 1998. Multilingual authoring using feedback texts. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL&apos;98), Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Chris Mellish</author>
</authors>
<title>Optimizing the costs and benefits of natural language generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the 13th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1164--1169</pages>
<contexts>
<context position="1068" citStr="Reiter and Mellish, 1993" startWordPosition="147" endWordPosition="151">u Marina del Rey, CA 90292 marcu4isi.edu Abstract We present discourse annotation work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese texts and their corresponding English translations. We discuss implications of our empirical findings for the task of text planning in the context of implementing multilingual natural language generation systems. 1 Introduction The natural language generation community has emphasized for a number of years the strengths of multilingual generation (MGEN) systems (Iordanskaja et al., 1992; Wisner and Stede, 1992; Reiter and Mellish, 1993; Goldberg et al., 1994; Paris et al., 1995; Power and Scott, 1998). These strengths concern the reuse of knowledge, the support for early drafts in several languages, the support for maintaining consistency when making changes, the support for producing alternative formulations, and the potential for producing higher quality outputs than machine translation. (The weaknesses concern the high-cost of building large, language-independent knowledge bases, and the difficulty of producing high-quality, broad-coverage generation algorithms.) From an economic perspective, the more a systern can rely </context>
</contexts>
<marker>Reiter, Mellish, 1993</marker>
<rawString>Ehud Reiter and Chris Mellish. 1993. Optimizing the costs and benefits of natural language generation. In Proceedings of the 13th International Joint Conference on Artificial Intelligence, pages 1164-1169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietmar Rosner</author>
<author>Manfred Stede</author>
</authors>
<title>Customizing RST for the automatic production of technical manuals. In</title>
<date>1992</date>
<booktitle>Aspects of Automated Natural Language Generation; 6th International Workshop on Natural Language Generation, number 587 in Lecture Notes in Artificial Intelligence,</booktitle>
<pages>199--214</pages>
<editor>R. Dale, E. Hovy, D. Wisner, and 0. Stock, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<location>Trento, Italy,</location>
<contexts>
<context position="2697" citStr="Rosner and Stede, 1992" startWordPosition="390" endWordPosition="393">d, an MGEN system becomes a viable option. Many of the early implementations of MG EN systems have adopted the perspective that text planners can be implemented as language-independent modules (lordanskaja et al.. 1992: Goldberg et al., 1994), possibly followed by a lnicari.:alion stage, in which discourse trees are re-written to reflect language-specific constraints (Wisner and Steele. 1992: Stede, 1999). Although such an approach may be adequate for highly restricted text genres, such as weather forecasts, it usually poses problems for less restricted genres. Studies of instruction manuals (Rosner and Stede, 1992; Delin et al., 1994: Delin et al., 1996) suggest that there are variations with respect to the way high-level communicative goals are realized across languages. For example, Delin et al. (1994) noticed that sentences (1), (2), and (3), which were taken from a trilingual instruction manual for a step-aerobics machine, yield nonisomorphic Rhetorical Structure (Mann and Thompson, 1988) analyses in English, French, and German respectively (see Figure 1). English: [The stepping load can be altered&apos;] (I) [by loosening the locking lever2] [and changing the position of the cylinder foot3]. French: [P</context>
<context position="22787" citStr="Rosner and Stede (1992)" startWordPosition="3671" endWordPosition="3674">ding enterprise. Unfortunately, the research of Delin et al. (1994) and Bateman and Rondhuis (1997) cannot be applied yet to unrestricted domains. Generation and Enablement are only two of the abstract relations that can hold between actions and goals. And some texts, such as descriptions, are difficult to characterize only in terms of actions and goals. Building a &amp;quot;complete&amp;quot; taxonomy of such abstract relations and identifying adequate mappings between there relations and rhetorical relations are still open problems. 4.2 Derive a language-independent discourse structure, and then linearize it Rosner and Stede (1992) and Stede (1999) assume that a discourse representation a la Mann and Thompson imposes no contraints on the linear order of the leaves. For the purpose of multilingual text planning, one can, hence, assume that a languageindependent text planner derives first a languageindependent rhetorical structure and then linearizes it, i.e., transforms it to make it language specific. The transformations that Rosner and Stede have applied concern primarily re-orderings of the children of some nodes and re-assignment of rhetorical relation labels. But given, for example, the significant differences betwe</context>
</contexts>
<marker>Rosner, Stede, 1992</marker>
<rawString>Dietmar Rosner and Manfred Stede. 1992. Customizing RST for the automatic production of technical manuals. In R. Dale, E. Hovy, D. Wisner, and 0. Stock, editors, Aspects of Automated Natural Language Generation; 6th International Workshop on Natural Language Generation, number 587 in Lecture Notes in Artificial Intelligence, pages 199-214, Trento, Italy, April. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill,</title>
<date>1988</date>
<note>second edition.</note>
<marker>Siegel, Castellan, 1988</marker>
<rawString>Sidney Siegel and N.J. Castellan. 1988. Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
</authors>
<title>Rhetorical structure and thematic structure in text generation.</title>
<date>1999</date>
<booktitle>In Working Notes of the Workshop on Levels of Representation in Discourse,</booktitle>
<pages>117--123</pages>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="2483" citStr="Stede, 1999" startWordPosition="359" endWordPosition="360">t selection, text planning, and sentence planning, •it- is difficult to -justify its economic viability. However, if most of these components are language independent and/or much of the code can be re-used, an MGEN system becomes a viable option. Many of the early implementations of MG EN systems have adopted the perspective that text planners can be implemented as language-independent modules (lordanskaja et al.. 1992: Goldberg et al., 1994), possibly followed by a lnicari.:alion stage, in which discourse trees are re-written to reflect language-specific constraints (Wisner and Steele. 1992: Stede, 1999). Although such an approach may be adequate for highly restricted text genres, such as weather forecasts, it usually poses problems for less restricted genres. Studies of instruction manuals (Rosner and Stede, 1992; Delin et al., 1994: Delin et al., 1996) suggest that there are variations with respect to the way high-level communicative goals are realized across languages. For example, Delin et al. (1994) noticed that sentences (1), (2), and (3), which were taken from a trilingual instruction manual for a step-aerobics machine, yield nonisomorphic Rhetorical Structure (Mann and Thompson, 1988)</context>
<context position="22804" citStr="Stede (1999)" startWordPosition="3676" endWordPosition="3677">ly, the research of Delin et al. (1994) and Bateman and Rondhuis (1997) cannot be applied yet to unrestricted domains. Generation and Enablement are only two of the abstract relations that can hold between actions and goals. And some texts, such as descriptions, are difficult to characterize only in terms of actions and goals. Building a &amp;quot;complete&amp;quot; taxonomy of such abstract relations and identifying adequate mappings between there relations and rhetorical relations are still open problems. 4.2 Derive a language-independent discourse structure, and then linearize it Rosner and Stede (1992) and Stede (1999) assume that a discourse representation a la Mann and Thompson imposes no contraints on the linear order of the leaves. For the purpose of multilingual text planning, one can, hence, assume that a languageindependent text planner derives first a languageindependent rhetorical structure and then linearizes it, i.e., transforms it to make it language specific. The transformations that Rosner and Stede have applied concern primarily re-orderings of the children of some nodes and re-assignment of rhetorical relation labels. But given, for example, the significant differences between the discourse </context>
</contexts>
<marker>Stede, 1999</marker>
<rawString>Manfred Stede. 1999. Rhetorical structure and thematic structure in text generation. In Working Notes of the Workshop on Levels of Representation in Discourse, pages 117-123, Edinburgh, Scotland, July 7-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J White</author>
<author>&apos;I&apos; O&apos;Connell</author>
</authors>
<title>Evaluation in the ARPA machine-translation program:</title>
<date>1994</date>
<booktitle>In Proceedings of the .4RPA Human language Technology Workshop,</booktitle>
<pages>135--140</pages>
<location>Washington, D.C.</location>
<note>See also http://ursula.georgeto W71. edu/.</note>
<contexts>
<context position="12982" citStr="White and O&apos;Connell, 1994" startWordPosition="2080" endWordPosition="2083">hese levels, it is difficult to explain the differences in terms of language-specific syntactic constraints. Rather, it seems more adequate to assume that there are significant differences with respect to the way information is organized rhetorically across languages. The experiment described in the next section estimates quantitatively this difference. 3 Experiment In order to assess how similar discourse structures are across languages, we built manually a corpus of discourse trees for 40 Japanese texts and their corresponding translations. The texts, selected randomly from the ARPA corpus (White and O&apos;Connell, 1994), contained on average about 460 words. We developed a discourse annotation protocol for Japanese and English along the lines followed by Marcu et al. (1999). We used Marcu&apos;s discourse annotation tool (1999) in order to manually construct the discourse structure of all Japanese and English texts in the corpus. 10% of the Japanese and English texts were rhetorically labeled by two of us. The agreement was statistically significant (Kappa = 0.65.0 &gt; 0.01 for Japanese and Kappa = 0.748, a &gt; 0.01 for English (Carletta, 1996; Siegel-and Castellan, 1988)). The tool and the annotation protocol are av</context>
</contexts>
<marker>White, O&apos;Connell, 1994</marker>
<rawString>J. White and &apos;I&apos;. O&apos;Connell. 1994. Evaluation in the ARPA machine-translation program: 1993 methodology. In Proceedings of the .4RPA Human language Technology Workshop, pages 135-140, Washington, D.C. See also http://ursula.georgeto W71. edu/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>