<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000065">
<title confidence="0.7393655">
1-WAY FINITE AUTOMATA AND DEPENDENCY GRAMAAR:
A PARSING METHOD FOR INFLECTIONAL FREE WORD ORDER LANGUAGES1
</title>
<author confidence="0.425102">
Esa Nelimarkka, Harri Jappinen and Aarno Lehtola
</author>
<affiliation confidence="0.769521">
Helsinki University of Technology
Helsinki, Finland
</affiliation>
<sectionHeader confidence="0.871389" genericHeader="abstract">
APSTRACT
</sectionHeader>
<bodyText confidence="0.999953636363636">
This paper presents a parser of an
inflectional free word order language, namely
Finnish. Two-way finite automata are used to
specify a functional dependency granuar and to
actually parse Finnish sentences. Each automaton
gives a functional description of a dependency
structure within a constituent. Dynamic local
control of the parser is realized by augmenting the
automata with simple operations to make the
automata, associated with the words of an input
sentence, activate one another.
</bodyText>
<sectionHeader confidence="0.957351" genericHeader="method">
I INT&apos;RODUCITON
</sectionHeader>
<bodyText confidence="0.998334470588235">
This paper introduces a computational model
for the description and analysis of an inflectional
free word order language, namely Finnish. We argue
that such a language can be conveniently described
in the franework of a functional dependency granular
which uses formally defined syntactic functions to
specify dependency structures ani deep case
relations to introduce semantics into syntax. We
show how such a functional granuar can be compactly
and efficiently modelled with finite two-way
automata which recognize the dependants of a word
in various syntactic functions on its both sides
and build corresponding dependency structures.
The automata along with formal descriptions of
the functions define the granmar. The functional
structure specifications are augmented with simple
control instructions so that the automata
associated with the words of an input sentence
actually parse the sentence. This gives a strategy
of local decisions resulting in a strongly data
driven left-to-right and bottom-up parse.
A parser based on this model is being
implemented as a component of a Finnish natural
language data base interface where it follows a
separate morphological analyzer. Hence, throughout
the paper we assume that all relevant morphological
and lexical information has already been extracted
and is conputationally available for the Parser.
1 This research is supported by SITRA (Finnish
National Fund for Research and Development).
Although we focus on Finnish we feel that the
model and its specification formalism might be
applicable to other inflectional free word order
languages as well.
</bodyText>
<sectionHeader confidence="0.987787" genericHeader="method">
II LINGUISTIC MCTIVATION
</sectionHeader>
<bodyText confidence="0.965212677419355">
There are certain features of Finnish which
suggest us to prefer dependency grammar to pure
phrase structure grammars as a linguistic
foundation of our model.
Firstly, Finnish is a &amp;quot;free word order&amp;quot;
language in the sense that the order of the main
constituents of a sentence is relatively free.
Variations in word order configurations convey
thematical and discursional information. Hence, the
parser must be ready to meet sentences with variant
word orders. A computational model should
acknowledge this characteristic and cope
efficiently with it. This demands a structure
within which word order variations can be
conveniently described. An important case in point
is to avoid structural discontinuities and holes
caused by transformations.
We argue that a functional dependency-
constituency structure induced by a dependency
grammar meets the requirements. This structure
consists of part-of-whole relations of constituents
and labelled binary dependency relations between
the regent and its dependants within a constituent.
The labels are pairs which express syntactic
functions and their semantic interpretations.
For example, the sentence &amp;quot;Nuorena poika
heitti kiekkoa&amp;quot; (&amp;quot;As young, the boy used to throw
the discus&amp;quot;) has the structure
or, equivalently, the linearized structure
((Nuorena)advi (poika);ubj heitti (kiekkoa1,hi 1,
TIME AGENT
</bodyText>
<figure confidence="0.9965865">
adverbial
TIME
Nuorena
heitti
subject
AGENT
poika
object
NEUTRAL
kiekkoa
</figure>
<page confidence="0.997507">
389
</page>
<bodyText confidence="0.980550645833334">
whe ndlrate houniaries
ar1 winv. -tch ii:uent, the word wIthout
&apos;,,e3d To be more an
inflected woLO dpoeatis ds a complex of its syntac-
tic, morphological and semantic properties. Hence,
our sentence structure is a labelled tree whose
nodes are complex expressions.
The advantage of the functional dependency
structures lies in the fact that many word order
varying transformations can be described as
permutations of the head and its labelled
dependants in a constituent. Reducing the depth of
structures (e.g. by having a verb and its subject,
object, adverbials on the same level) we bypass
many discontinuities that would otherwise appear in
a deeper structure as a result of certain
transformations. As an example we have the
permutations
((Poika)subj heitti (kiekkoa)bbj (nuorena)adv1)
(Heittiko (poika)subj (nuorena) advl (kiekkoa)bbj)
and
((Kiekkoako)bbj (poika)subj heitti (nuorena)advi).
(&amp;quot;The boy used to throw the discus when he was
young&amp;quot;, &amp;quot;Did the boy use to throw...?&amp;quot;, &amp;quot;Was it
discus that the boy used to throw...?&amp;quot;,
respectively.)
The second argument for our choices is the
well acknowledged prominent role of a finite verb
in regard to the form and meaning of a sentence.
The meaning of a verb includes, for example,
knowledge of its deep cases, and the choice of a
particular verb to express this meaning determines
to a great extent what deep cases are present on
the surface level and in what functions. Moreover,
due to the relatively free word order of Finnish,
the main means of indicating the function of a word
in a sentence is the use of surface case suffixes,
and very often the actual surface case depends not
only on the intended function or role but on the
verb as well.
Finally, we wish to describe the sentence
analysis as a series of local decisions of the
following kind. Suppose we have a sequence
C1,..., Ci_i, Ci, Ci+1, Cb of constituents as
a result of earlier steps of the analysis of an
input sentence, and assune further that the focus
of the analyzer is at the constituent Ci. in such a
situation the parser has to decide whether Ci is
</bodyText>
<listItem confidence="0.960093666666667">
(a) a dependant of the left neighbour Ci_i,
(b) the regent of the left neighbour
(c) a dependant of some fr,rt&apos;---nminel rioht
),11
(H) ,7ent of some forthcoming right
neighbour.
</listItem>
<bodyText confidence="0.98333750877193">
Observe that decisions (c) and (d) refer
either t..) a constiliJent which already ,?xists on the
right side of Ci or which will appear there after
some steps of the analysis. Further, it should be
noticed that we do not want the parser to make any
hypothesis of the syntactic or semantic nature of
the possible dependency relation in (a) and (c) at
this moment.
We claim that a functional combination of
dependency grammar and case grammar can be put into
a computational form, and that the resulting model
efficiently takes advantage of the central role of
a constituent head in the actual parsing process by
letting the head find its dependants using
functional descriptions. We outline in the next
sections how we have done this with formally
defined functions and 2-way automata.
Ili FORMALLY DEFINED SYNTACTIC FUNCTIONS
We abstract the restrictions imposed on the
head and its dependant in a given subordinate
relation. Recall that a constituent consists of the
head - a word regarded as a complex of its relevant
properties - and of the dependants - from zero to n
(sub)constituents.
The traditional parsing categories such as the
(deep structure) subject, object, adverbial and
adjectival attribute will be modelled as functions
f: .17f -&gt;1:,
where C is the set of constituents and .7) cC0C
f
is the domain of the function.
The domain of a function f will be defined
with a kind of Boolean expression over predicates
which test properties of the arguments, i.e. the
regent and the potential dependant. In the analysis
this relation is used to recognize and interprete
an occurance of a &lt;head,dependant&gt;-pair in the
given relation. The actual mapping of such pairs
intoC builds the structure corresponding to this
function.
For notational and implementational reasons we
specify the functions with a conditional expression
formalism. A (primitive) conditional expression is
either a truth valued predicate which tests
properties of a potential constituent head m and
its dependant (D) and deletes non-matching
interoretations of an ambiguous word, or an action
which performs one of the basic construction
operations such as labelling (:=), attaching (:-),
or deletion, and returns a truth value.
Primitive expressions can be written into
series (P1 P2 ... Pn) or in parallel (P17P2: ...;
Pn) to yield complex expressions. Logically, the
former corresponds roughly to an and-operation and
the latter an or-operation. A conditional operation
-&gt; and recursion yield new complex expressions
trom old ones.
</bodyText>
<page confidence="0.994293">
390
</page>
<bodyText confidence="0.99171125">
As an example, consider the expressions for functional dependency structures of a verb.
&apos;Object&apos;, &apos;RecObj&apos; and &apos;IntObj&apos; in Figure 1. (Observe that we do not assume transformations to
describe the variants.) We coMbine the descriptions
of such a paradigm into a modified two-way finite
</bodyText>
<figure confidence="0.969116681818182">
NUM bad automaton.
Illec0101(Int0111 -) III. ObactlIC o 111
RELATIlas Andel
110 • *Transitive -Nottallte • acefeat -Solace)
.3(9 o Part) -) (A •PA);
(a • $9 .1)1 • -Coatallat
la • olealableta • ( Ie
•ockf 3)114
III • Patera Addle • Poi) -) T);
III o t Noo )1111 o ha)
-&gt; ill • Nos) -) (1 • PA);
(11 • SOO • C Past
(Act Isocr ( IP 2? )) ) I));
Ii) • In Adla • Act ( lod
Cad
Pot
thow 3P1 31111
tte . .1riositive (Antall( I • -Sentence Axial)
-) it • ( Noe Gee Oct Part))
AELA11014 (stela
Ilk • t lowlegeerld Ceplabl 31 -(II a. Moutrail);
IM • CommelclorbIltl • eleareotive) -) 11 o Neetrala
</figure>
<figureCaption confidence="0.999886">
Figure 1.
</figureCaption>
<bodyText confidence="0.9999891875">
The relation &apos;RecObj&apos; approximates the
syntactic and morphological restrictions imposed on
a verb and its nominal object in Finnish. (It
represents partly the partitive-accusative
opposition of an Object, and, for an accusative
object, its nominative-genetive distribution.) The
relation &apos;IntObj&apos;, on the other hand, tries to
interprete the postulated object using semantic
features and a subcategorization of verbs with
respect to deep case structures and their
realizations. The semantic restrictions imposed on
the underlying deep cases are checked at this
point. &apos;Object&apos;, after a succesful match of these
syntactic and semantic conditions, labels the
postulated dependant (D) as &apos;Object&apos; and attaches
it to the postulated regent (R).
</bodyText>
<sectionHeader confidence="0.992465" genericHeader="method">
IV FUNCTIONAL DESCRIPTIONS WaqH TWO-WAY At/PCMATA
</sectionHeader>
<bodyText confidence="0.999967">
We introduced the formal functions to define
conditions and structures associated with syntactic
dependency relations. What is also needed is a
description of what dependants a word can have and
in what order.
In a free Word order language we would face,
for example, a paradigm fragment of the form
</bodyText>
<equation confidence="0.9934285">
(subj) V (obj) (advl)
(advl) (subj) V (obj)
V (subj) (obj) (advl)
(obj) (subj) V (advl)
</equation>
<bodyText confidence="0.999441055555556">
A 2-way finite automaton consists of a set nf
states, one of which is the initial state and sone
of which are final states, and of a set of
transition arcs between the states. Each arc
recognizes a word, changes the state of the
automaton and moves the reading head either to the
left or right.
We modify this standard notion to recognize
left and right dependants of a word starting from
its immediate neighbour. Instead of recognizing
words (or word categories) these automata recognize
functions, i.e. instances of abstract relations
between a postulated head and its either
neighbour. In addition to a mere recognition the
transitions build the structures determined by the
observed function, e.g. attach the neighbour as a
dependant, label it in agreement with the function
and its interpretation.
</bodyText>
<table confidence="0.81471325">
STATE: IV LEFT
Ito +Phrase) -) (Subject -) IC 1. ?VS 11;
(Object -) IC I. ?VD )1;
(Adverbial -) IC 1. ?V 1);
(SenSubj -) IC i. VS? 1);
(SentAdvl -) IC s. ?V 11;
*
IT .) IC I. V? )1(;
(ID • -Phrase) -) IC ii V? 11
STATE: V? RIGHT
1111 . *Phrase) -A (Subject -) (C:e VS? )1;
(Object -) IC I. VD? ();
tSentSubj -) IC ts. IISentS?1);
(Seet0111 -) IC o. VS/eta? 11;
(Adverbiel -) IC V? 11;
!Seated,&apos; -) (C I. VSeetA? 11;
(7 -) IC t. Tffiaa( )));
111) • -Phrase) -) (C t. V? IlluildPhrasede 0I6H711
STATE: ?VS LEFT
(ID • •Phrite) -&gt; (Object -) IC 1. TOSO 11;
(Adverbial -) IC ?VS )1;
ISentAdvl -A IC :. VS? 11;
IT -&gt; (C to VS? 111;
1(11 • -Phrase) -A IC t. VII? 11
</table>
<figureCaption confidence="0.897959">
Figure 2.
Figure 2. exhibits part of a verb automaton
which recognizes and builds, for example, partial
structures like
</figureCaption>
<bodyText confidence="0.989581888888889">
/ //4 &apos;,//1 i/&amp;quot;\
subj , obj , advl , obj subj , advl subj,
The states are divided into &apos;left&apos; and &apos;right&apos;
states to indicate the side where the dependant is
to be found. Each state indicates the formal
functions which are available for a verb in that
particular state. A succesfull application of a
function transfers the wrh into ,inother
Look for f,rther dependants.
</bodyText>
<page confidence="0.995747">
391
</page>
<bodyText confidence="0.9976635">
Heuristic rules and look-ahead can als) be
used, For example, the rule
</bodyText>
<equation confidence="0.9860175">
((RI = )(R2 = &apos;etta )(C = +Sattr)
-&gt; (C := N?Sattr) (BuildPhraseOn RIGHT))
</equation>
<bodyText confidence="0.99952525">
in the state N? of the noun automaton anticipates
an evident forthcoming sentence attribute of, say,
a cognitive noun and sets the noun to the state
N?Sattr to wait for this sentence.
</bodyText>
<sectionHeader confidence="0.617104" genericHeader="method">
V PARSING WIIM A SECUENCE OF 2-WAY ALTICMATA
</sectionHeader>
<bodyText confidence="0.999988972972973">
So far we have shown how to associate a 2-way
automaton to a word via its syntactic category.
This gives a local description of the grammar. With
a few simple control instructions these local
automata are made to activate each other and,
after a sequence of local decisions, actually parse
an input sentence.
An unfinished parse of a sentence consists of
a sequence C1,C2,...,Cn of constituents, which
may be complete or incomplete. Each constituent is
associated with an automaton Which is in some state
and reading position. At any time, exactly one of
the automata is active and tries to recognize a
neighbouring constituent as a dependant.
Most often, only a complete constituent (one
featured as &apos;+phrase&apos;) qualifies as a potential
deoendant. To start the completion of an incomplete
constituent the control has to be moved to its
associated automaton. This is done with a kind of
push operation (BuildPhraseOn RIGHT) which
deactivates the current automaton and activates the
neighbour next to the right (see Figure 2). This
decision corresponds to a choice of type (d). A
complete constituent in a final state will be
labelled as a &apos;4-phrase&apos; (along with other relevant
labels such as &amp;quot;±sentence&apos;, &apos;±nominal&apos;, &apos;±main&apos;).
Operations (FindRegOn LEFT) and (FindRegOn RIGHT),
which correspond to choices (a) and (c), deactivate
the current constituent (i.e. the corresponding
automaton) and activate the leftmost or rightmost
constituent, respectively. Observe that the
automata need not remember when and why they were
activated. Such simple &amp;quot;local control&amp;quot; we have
outlined above yields a strongly data driven
bottom-up and left-to-right parsing strategy which
has also top-down features as expectations of
lacking dependants.
</bodyText>
<sectionHeader confidence="0.93702" genericHeader="method">
VI DISCUSSION
</sectionHeader>
<bodyText confidence="0.99113472">
As we have shown, our parser consists of a
collection of finite transition networks which
,-ach other. The use of 2-way instead of
Aut.)matA oqr parser from
ATN-parsers. (There are also other major
differences.) In our dependency oriented model
non-terminal categories (S, VP, NP, AP, ... ) are
not needed, and a constituent is not postulated
until its head is found. This feature separates our
parser from those which build pure constituent
structures without any reference to dependency
relations within a constituent. In fact, each word
collects actively its dependants to make up a
constituent where the word is the head.
A further characteristic of our model is the
late postulation of syntactic functions and
semantic roles. Constituents are built blindly
without any predecided purpose so that the
completed constituents do not know why they were
built. The function or semantic role of a
constituent is not postulated until a neighbour is
activated to recognize its own dependants. Thus, a
constituent just waits to be chosen into sone
function so that no registers for functions or
roles are needed.
</bodyText>
<sectionHeader confidence="0.99482" genericHeader="method">
VII REE&apos;ERENCTS
</sectionHeader>
<reference confidence="0.9882059375">
Hudson, R.: Arguments for a Non-transformational
Grammar. The University of Chicago Press, 1976.
Hudson, R.: Constituency and Dependency.
Linguistics 18, 1980, 179_198.
Jappinen, H., Nelimarkka, E., Lehtola, A. and
Ylilammi, M.: Knowledge engineering approach to
morphological analysis. Proc. of the First
Conference of the European Chapter of ACL, Pisa,
1983, 49-51.
Lehtola, A.: Compilation and implementation of
2-way tree automata for the parsing of Finnish.
Helsinki University of Technology (forthcoming
M.Sc. the thesis).
Nelimarkka, E., Jappinen, H. and Lehtola A.:
Dependency oriented parsing of an inflectional
language (manuscript).
</reference>
<page confidence="0.998284">
392
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000589">
<title confidence="0.9772395">1-WAY FINITE AUTOMATA AND DEPENDENCY GRAMAAR: PARSING METHOD FOR INFLECTIONAL FREE WORD ORDER</title>
<author confidence="0.943596">Esa Nelimarkka</author>
<author confidence="0.943596">Harri Jappinen</author>
<author confidence="0.943596">Aarno Lehtola</author>
<affiliation confidence="0.999954">Helsinki University of Technology</affiliation>
<address confidence="0.998765">Helsinki, Finland</address>
<abstract confidence="0.995378926829268">APSTRACT This paper presents a parser of an inflectional free word order language, namely Finnish. Two-way finite automata are used to specify a functional dependency granuar and to actually parse Finnish sentences. Each automaton gives a functional description of a dependency structure within a constituent. Dynamic local control of the parser is realized by augmenting the automata with simple operations to make the automata, associated with the words of an input sentence, activate one another. I INT&apos;RODUCITON This paper introduces a computational model for the description and analysis of an inflectional free word order language, namely Finnish. We argue that such a language can be conveniently described in the franework of a functional dependency granular which uses formally defined syntactic functions to specify dependency structures ani deep case relations to introduce semantics into syntax. We show how such a functional granuar can be compactly and efficiently modelled with finite two-way automata which recognize the dependants of a word in various syntactic functions on its both sides and build corresponding dependency structures. The automata along with formal descriptions of the functions define the granmar. The functional structure specifications are augmented with simple control instructions so that the automata associated with the words of an input sentence actually parse the sentence. This gives a strategy of local decisions resulting in a strongly data driven left-to-right and bottom-up parse. A parser based on this model is being implemented as a component of a Finnish natural language data base interface where it follows a separate morphological analyzer. Hence, throughout the paper we assume that all relevant morphological and lexical information has already been extracted and is conputationally available for the Parser.</abstract>
<note confidence="0.519053666666667">1 This research is supported by SITRA (Finnish National Fund for Research and Development). Although we focus on Finnish we feel that the</note>
<abstract confidence="0.956505819526627">model and its specification formalism might be applicable to other inflectional free word order languages as well. II LINGUISTIC MCTIVATION There are certain features of Finnish which suggest us to prefer dependency grammar to pure phrase structure grammars as a linguistic foundation of our model. Firstly, Finnish is a &amp;quot;free word order&amp;quot; language in the sense that the order of the main constituents of a sentence is relatively free. Variations in word order configurations convey thematical and discursional information. Hence, the parser must be ready to meet sentences with variant word orders. A computational model should acknowledge this characteristic and cope efficiently with it. This demands a structure within which word order variations can be conveniently described. An important case in point is to avoid structural discontinuities and holes caused by transformations. We argue that a functional dependencyconstituency structure induced by a dependency grammar meets the requirements. This structure consists of part-of-whole relations of constituents and labelled binary dependency relations between the regent and its dependants within a constituent. The labels are pairs which express syntactic functions and their semantic interpretations. For example, the sentence &amp;quot;Nuorena poika kiekkoa&amp;quot; the boy used to throw the discus&amp;quot;) has the structure or, equivalently, the linearized structure heitti (kiekkoa1,hi 1, adverbial TIME Nuorena heitti subject AGENT poika object NEUTRAL kiekkoa 389 whe ndlrate houniaries winv. -tch the word wIthout more an dpoeatis a complex its syntactic, morphological and semantic properties. Hence, our sentence structure is a labelled tree whose nodes are complex expressions. The advantage of the functional dependency structures lies in the fact that many word order varying transformations can be described as permutations of the head and its labelled dependants in a constituent. Reducing the depth of structures (e.g. by having a verb and its subject, object, adverbials on the same level) we bypass many discontinuities that would otherwise appear in a deeper structure as a result of certain example we have the permutations heitti (nuorena) advl(kiekkoa)bbj) and heitti (&amp;quot;The boy used to throw the discus when he was young&amp;quot;, &amp;quot;Did the boy use to throw...?&amp;quot;, &amp;quot;Was it discus that the boy used to throw...?&amp;quot;, respectively.) The second argument for our choices is the well acknowledged prominent role of a finite verb in regard to the form and meaning of a sentence. The meaning of a verb includes, for example, knowledge of its deep cases, and the choice of a particular verb to express this meaning determines to a great extent what deep cases are present on the surface level and in what functions. Moreover, due to the relatively free word order of Finnish, the main means of indicating the function of a word in a sentence is the use of surface case suffixes, and very often the actual surface case depends not only on the intended function or role but on the verb as well. Finally, we wish to describe the sentence analysis as a series of local decisions of the following kind. Suppose we have a sequence Ci_i, Ci, Ci+1, of constituents as a result of earlier steps of the analysis of an sentence, and that the focus of the analyzer is at the constituent Ci. in such a situation the parser has to decide whether Ci is (a) a dependant of the left neighbour Ci_i, (b) the regent of the left neighbour a dependant of some rioht (H) some forthcoming right neighbour. that decisions (d) refer t..) a constiliJent which already on the of Ci which will appear there of the Further, it should be noticed that we do not want the parser to make any hypothesis of the syntactic or semantic nature of the possible dependency relation in (a) and (c) at this moment. We claim that a functional combination of dependency grammar and case grammar can be put into a computational form, and that the resulting model efficiently takes advantage of the central role of a constituent head in the actual parsing process by letting the head find its dependants using functional descriptions. We outline in the next sections how we have done this with formally defined functions and 2-way automata. FORMALLY SYNTACTIC We abstract the restrictions imposed on the head and its dependant in a given subordinate relation. Recall that a constituent consists of the head a word regarded as a complex of its relevant properties and of the dependants from zero to n (sub)constituents. The traditional parsing categories such as the (deep structure) subject, object, adverbial and adjectival attribute will be modelled as functions .17f C is the set of constituents and f is the domain of the function. The domain of a function f will be defined with a kind of Boolean expression over predicates which test properties of the arguments, i.e. the regent and the potential dependant. In the analysis this relation is used to recognize and interprete occurance of a &lt;head,dependant&gt;-pair in given relation. The actual mapping of such pairs intoC builds the structure corresponding to this function. For notational and implementational reasons we specify the functions with a conditional expression formalism. A (primitive) conditional expression is either a truth valued predicate which tests of a potential constituent head m (D) and deletes non-matching of an ambiguous word, or an one of the basic construction operations such as labelling (:=), attaching (:-), or deletion, and returns a truth value. expressions can be written (P1 P2 ... or in (P17P2: ...; to yield complex expressions. the corresponds roughly and-operation and an or-operation. operation -&gt; and recursion yield new complex expressions old 390 As an example, consider the expressions for functional dependency structures of a verb. &apos;Object&apos;, &apos;RecObj&apos; and &apos;IntObj&apos; in Figure 1. (Observe that we do not assume transformations to describe the variants.) We coMbine the descriptions of such a paradigm into a modified two-way finite bad III. o RELATIlas Andel • -Nottallte • acefeat -Solace) o -) (A •PA); • .1)1 • • olealableta • ( ockf • Poi) -) T); o Noo o -&gt; ill • Nos) -) (1 • PA); • SOO • C Isocr 2? )) ) I)); • Adla • Act ( lod Cad Pot 31111 tte . .1riositive (Antall( I • -Sentence Axial) it • ( Gee AELA11014 (stela • t Ceplabl 31 -(II Moutrail); • CommelclorbIltl • -) 11 o Neetrala Figure 1. The relation &apos;RecObj&apos; approximates the syntactic and morphological restrictions imposed on a verb and its nominal object in Finnish. (It represents partly the partitive-accusative opposition of an Object, and, for an accusative object, its nominative-genetive distribution.) The relation &apos;IntObj&apos;, on the other hand, tries to interprete the postulated object using semantic features and a subcategorization of verbs with respect to deep case structures and their realizations. The semantic restrictions imposed on the underlying deep cases are checked at this point. &apos;Object&apos;, after a succesful match of these syntactic and semantic conditions, labels the postulated dependant (D) as &apos;Object&apos; and attaches it to the postulated regent (R). FUNCTIONAL DESCRIPTIONS WaqH TWO-WAY We introduced the formal functions to define conditions and structures associated with syntactic relations. What is also needed is description of what dependants a word can have and in what order. In a free Word order language we would face, for example, a paradigm fragment of the form (subj) V (obj) (advl) (advl) (subj) V (obj) V (subj) (obj) (advl) (obj) (subj) V (advl) 2-way finite automaton consists of a set states, one of which is the initial state and sone which are final states, and of a set transition arcs between the states. Each arc recognizes a word, changes the state of the automaton and moves the reading head either to the left or right. We modify this standard notion to recognize left and right dependants of a word starting from its immediate neighbour. Instead of recognizing words (or word categories) these automata recognize functions, i.e. instances of abstract relations between a postulated head and its either neighbour. In addition to a mere recognition the transitions build the structures determined by the observed function, e.g. attach the neighbour as a dependant, label it in agreement with the function and its interpretation. STATE: IV LEFT +Phrase) -) (Subject -) IC 11; -) IC )1; (Adverbial -) IC 1. ?V 1); (SenSubj -) IC i. VS? 1); -) IC s. ?V * .) IC )1(; (ID • -Phrase) -) IC ii V? 11 STATE: V? RIGHT . *Phrase) -A (Subject -) VS? )1; -) IC (); -) IC (Seet0111 -) IC o. VS/eta? 11; -) IC V? 11; -) (C -) IC ))); • -Phrase) -) (C IlluildPhrasede 0I6H711 STATE: ?VS LEFT • -) IC (Adverbial -) IC ?VS )1; ISentAdvl -A IC :. VS? 11; IT -&gt; (C to VS? 111; 1(11 • -Phrase) -A IC t. VII? 11 Figure 2. Figure 2. exhibits part of a verb automaton which recognizes and builds, for example, partial structures like subj , obj , advl , obj subj , advl subj, The states are divided into &apos;left&apos; and &apos;right&apos; states to indicate the side where the dependant is to be found. Each state indicates the formal functions which are available for a verb in that state. A succesfull application of the into for 391 Heuristic rules and look-ahead can als) be used, For example, the rule ((RI = )(R2 = &apos;etta )(C = +Sattr) -&gt; (C := N?Sattr) (BuildPhraseOn RIGHT)) in the state N? of the noun automaton anticipates an evident forthcoming sentence attribute of, say, a cognitive noun and sets the noun to the state N?Sattr to wait for this sentence. V PARSING WIIM A SECUENCE OF 2-WAY ALTICMATA So far we have shown how to associate a 2-way automaton to a word via its syntactic category. This gives a local description of the grammar. With a few simple control instructions these local automata are made to activate each other and, after a sequence of local decisions, actually parse an input sentence. An unfinished parse of a sentence consists of sequence of which be complete incomplete. Each is with automaton Which in some state and reading position. At any time, exactly one of the automata is active and tries to recognize a neighbouring constituent as a dependant. Most often, only a complete constituent (one featured as &apos;+phrase&apos;) qualifies as a potential deoendant. To start the completion of an incomplete constituent the control has to be moved to its associated automaton. This is done with a kind of push operation (BuildPhraseOn RIGHT) which deactivates the current automaton and activates the neighbour next to the right (see Figure 2). This decision corresponds to a choice of type (d). A complete constituent in a final state will be labelled as a &apos;4-phrase&apos; (along with other relevant labels such as &amp;quot;±sentence&apos;, &apos;±nominal&apos;, &apos;±main&apos;). Operations (FindRegOn LEFT) and (FindRegOn RIGHT), which correspond to choices (a) and (c), deactivate the current constituent (i.e. the corresponding automaton) and activate the leftmost or rightmost constituent, respectively. Observe that the automata need not remember when and why they were activated. Such simple &amp;quot;local control&amp;quot; we have outlined above yields a strongly data driven bottom-up and left-to-right parsing strategy which has also top-down features as expectations of lacking dependants. VI DISCUSSION As we have shown, our parser consists of a collection of finite transition networks which other. The use of instead of oqr parser ATN-parsers. (There are also other major differences.) In our dependency oriented model non-terminal categories (S, VP, NP, AP, ... ) are not needed, and a constituent is not postulated until its head is found. This feature separates our parser from those which build pure constituent structures without any reference to dependency relations within a constituent. In fact, each word collects actively its dependants to make up a constituent where the word is the head. A further characteristic of our model is the late postulation of syntactic functions and semantic roles. Constituents are built blindly without any predecided purpose so that the completed constituents do not know why they were built. The function or semantic role of a constituent is not postulated until a neighbour is activated to recognize its own dependants. Thus, a constituent just waits to be chosen into sone function so that no registers for functions or roles are needed.</abstract>
<note confidence="0.79246675">VII REE&apos;ERENCTS R.: Argumentsfor a Grammar.The University of Chicago Press, 1976. Hudson, R.: Constituency and Dependency. Linguistics18, 1980, 179_198. Jappinen, H., Nelimarkka, E., Lehtola, A. and Ylilammi, M.: Knowledge engineering approach to morphological analysis. Proc. of the First</note>
<affiliation confidence="0.874674">Conference of the European Chapter of ACL, Pisa,</affiliation>
<address confidence="0.815727">1983, 49-51.</address>
<abstract confidence="0.948031571428572">Lehtola, A.: Compilation and implementation of 2-way tree automata for the parsing of Finnish. Helsinki University of Technology (forthcoming M.Sc. the thesis). Nelimarkka, E., Jappinen, H. and Lehtola A.: Dependency oriented parsing of an inflectional language (manuscript).</abstract>
<intro confidence="0.817409">392</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Hudson</author>
</authors>
<title>Arguments for a Non-transformational Grammar.</title>
<date>1976</date>
<publisher>The University of Chicago Press,</publisher>
<marker>Hudson, 1976</marker>
<rawString>Hudson, R.: Arguments for a Non-transformational Grammar. The University of Chicago Press, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hudson</author>
</authors>
<title>Constituency and Dependency.</title>
<date>1980</date>
<journal>Linguistics</journal>
<volume>18</volume>
<pages>179--198</pages>
<marker>Hudson, 1980</marker>
<rawString>Hudson, R.: Constituency and Dependency. Linguistics 18, 1980, 179_198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jappinen</author>
<author>E Nelimarkka</author>
<author>A Lehtola</author>
<author>M Ylilammi</author>
</authors>
<title>Knowledge engineering approach to morphological analysis.</title>
<date>1983</date>
<booktitle>Proc. of the First Conference of the European Chapter of ACL,</booktitle>
<pages>49--51</pages>
<location>Pisa,</location>
<marker>Jappinen, Nelimarkka, Lehtola, Ylilammi, 1983</marker>
<rawString>Jappinen, H., Nelimarkka, E., Lehtola, A. and Ylilammi, M.: Knowledge engineering approach to morphological analysis. Proc. of the First Conference of the European Chapter of ACL, Pisa, 1983, 49-51.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Lehtola</author>
</authors>
<title>Compilation and implementation of 2-way tree automata for the parsing of Finnish. Helsinki University of Technology (forthcoming M.Sc. the thesis).</title>
<marker>Lehtola, </marker>
<rawString>Lehtola, A.: Compilation and implementation of 2-way tree automata for the parsing of Finnish. Helsinki University of Technology (forthcoming M.Sc. the thesis).</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Nelimarkka</author>
<author>H Jappinen</author>
<author>A Lehtola</author>
</authors>
<title>Dependency oriented parsing of an inflectional language (manuscript).</title>
<marker>Nelimarkka, Jappinen, Lehtola, </marker>
<rawString>Nelimarkka, E., Jappinen, H. and Lehtola A.: Dependency oriented parsing of an inflectional language (manuscript).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>