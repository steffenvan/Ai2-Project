<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001160">
<title confidence="0.986494">
Modeling Prosodic Consistency for Automatic Speech
Recognition: Preliminary Investigations
</title>
<author confidence="0.998506">
Ernest Pusateri and James Glass
</author>
<affiliation confidence="0.998762">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<address confidence="0.800642">
Cambridge, MA 02139, USA
</address>
<email confidence="0.998413">
fpusateri, glassl@mit.edu
</email>
<sectionHeader confidence="0.998589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999550473684211">
In this paper we describe a prosody-
dependent duration model as a first step to-
ward incorporating a prosodic consistency
constraint into a speech recognizer. As
part of this model, we describe a text-
based prosody prediction scheme, novel in
its use of a preliminary integrated comma-
prediction/POS tagging step. We also
demonstrate a relative decrease in perplex-
ity using the prosody-dependent duration
model and analyze what conditioning fac-
tors most contributed to that decrease. The
analysis indicates that while word posi-
tion is, by far, the most important fac-
tor, predicted prosodic labeling information
also contributes to the decrease. This fi-
nal result suggests a benefit to integrat-
ing a prosodic consistency constraint into
a speech recognition system.
</bodyText>
<sectionHeader confidence="0.999469" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999937419354839">
While much effort has gone into using prosody in
the areas of speech synthesis and understanding (e.g
(Noth et al., 2000; Taylor and Black, 1998)), less
has been focused on using it to aid directly in the
task of speech recognition (e.g. (Stolcke et al., 1999;
Ostendorf et al., 2003; Chen et al., 2003).) The util-
ity of prosody in speech recognition comes from the
fact that, while prosody is not fully determined by
an utterances lexical content, lexical content does
make some prosodic realizations more probable than
others. This implies that we can meaningfully ask
whether the acoustic cues to the prosody of an ut-
terance are consistent with a textual hypothesis.
In this work we report on an initial effort to de-
velop a prosody-dependent duration model. It is
closely related to (Chen et al., 2003). However, while
that work uses a standard language model for text-
based prosody prediction, we incorporate techniques
borrowed from speech synthesis research as well as an
automatic comma annotation technique in an effort
to increase robustness.
The rest of this paper proceeds as follows. In Sec-
tion 2 we begin with a description of a very general
framework to incorporate a prosodic consistency con-
straint into speech recognition. In Section 3, we de-
scribe our text-based prosody prediction algorithm.
This is followed by a description of duration model-
ing in Section 4. After that, we present experiments
and results in Section 5. We end with a brief sum-
mary in Section 6 and a discussion of future work in
Section 7.
</bodyText>
<sectionHeader confidence="0.957684" genericHeader="method">
2 A Prosodic Consistency
Framework
</sectionHeader>
<bodyText confidence="0.9999263">
Figure 1 illustrates a framework for incorporating a
prosodic consistency constraint into a speech recog-
nizer. On the left path, an N-best list is generated by
the recognizer and text-based prosody prediction is
performed on each of the N-best entries. On the right
path the utterance is analyzed for acoustic-prosodic
cues. The level of consistency between the predicted
prosody for each entry and the acoustic cues mea-
sured in the utterance is then used to rescore the
N-best list.
This work does not implement a speech recognizer.
Instead, our intent is to show that using a particular
prosodic cue in this framework, specifically duration,
has the potential to reduce the recognition search
space. In this effort, the &amp;quot;Acoustic Prosodic Analy-
sis&amp;quot; component shown in Figure 1 simply reads the
phone durations from the N-best list. The &amp;quot;Text-
based Prosody Prediction&amp;quot; component, however, is
fairly complex, and the next section gives a full de-
scription of its inner-workings.
</bodyText>
<figure confidence="0.985048055555556">
N−BEST LIST
ACOUSTIC
PROSODIC
ANALYSIS
TEXT−BASED
PROSODY
PREDICTION
PROSODICALLY ANNOTATED F0, ENERGY, DURATION
N−BEST LIST
MEASURE
PROSODIC
CONSISTENCY
RESCORED
N−BEST LIST
SPEECH
RECOGNIZER
SPEECH INPUT
3.3.1 Break Prediction
</figure>
<bodyText confidence="0.998300428571429">
In obtaining P(BIC, S, W), we first assume that B
is conditionally independent of W given S and C:
This assumption is motivated by the fact that con-
tent words very often are prominent while function
words very often are not. While this simple unigram
model tends to over-predict prominences, it is used
by many speech synthesizers.
</bodyText>
<equation confidence="0.879638">
P(BIC, S, W) P(BIC, S) (10)
</equation>
<bodyText confidence="0.992922375">
While this assumption results in ignoring word-
specific (and thus also semantic) cues to break lo-
cation, it does allow us to use some syntactic infor-
mation. Both (Ostendorf and Veilleux, 1994) and
(Taylor and Black, 1998) have found this approxi-
mation to be workable.
We relate the approximation to the joint probabil-
ity, P(B,C, S):
</bodyText>
<equation confidence="0.9222735">
P(B , C, S)
P(B&apos;&apos;PCS )
</equation>
<bodyText confidence="0.999691333333333">
To find P(B,C, S), we can use the framework pre-
sented in (Taylor and Black, 1998). Let b, be the
type of the boundary between w, and
</bodyText>
<equation confidence="0.9979084">
P(B, C, S) = P(C, SIB)P(B) (12)
= (H P(ci, si, si+11B))P(B) (13)
J=1
(H P(ci, si, si+11b,))P(B) (14)
J=1
</equation>
<bodyText confidence="0.999890866666667">
The first component of the model, P(c.„ sJ, sJ+11/h)
captures the distribution of the parts-of speech sur-
rounding boundaries. The second component, P(B),
captures common boundary type patterns and is
modeled with an N-gram. The normalization term in
Equation 11, P(C, S) is estimated from the training
data.
The parts of speech were collapsed into the classes
described in (Ostendorf and Veilleux, 1994): content
words, determiners, prepositions, and a general class
incorporating function words that were neither deter-
miners nor prepositions. This is a smaller set than
was used in (Taylor and Black, 1998), and seemed
more appropriate given that we were working with a
smaller amount of training data.
</bodyText>
<subsubsectionHeader confidence="0.87532">
3.3.2 Prominence Prediction
</subsubsectionHeader>
<bodyText confidence="0.999809">
A simple model was used to compute
P(RIB,C, S , W). The word classes used for
break prediction were further collapsed into function
and content word classes. A unigram model of
prominence based on these classes was then applied.
Thus, the following assumption was made:
</bodyText>
<equation confidence="0.95621">
P(RIB,C, S,W) P(RIS) (15)
(16)
</equation>
<sectionHeader confidence="0.954655" genericHeader="method">
4 Duration Modeling
</sectionHeader>
<bodyText confidence="0.999575142857143">
In this work we model only vowel durations. The
end result of applying the duration model should
be the probability of the vowel durations, D =
d1,2..., d2,1, d2,2, ...} (where d„,3 corresponds to
the jth vowel in w„), given the word sequence, W.
To allow the incorporation of prosodic prediction,
we decompose P(DIW):
</bodyText>
<equation confidence="0.9991005">
P(DIW) = E P(D, LIW) (17)
= E P(DIW, L)P(LIW) (18)
</equation>
<bodyText confidence="0.999769">
P(LIW) is the probability computed by our text-
based prosody prediction model.
The assumption is made that the duration d„,3 de-
pends only on w, (the word to which the vowel be-
longs), k (the type of the following boundary) and
(whether or not word i is prominent). Also, we
assume that, given the word string and prosodic la-
beling, the durations are independent. This gives us:
</bodyText>
<equation confidence="0.983268666666667">
N Mi
P(DIW, H H P(di,
i=1 j=1
</equation>
<bodyText confidence="0.968187789473684">
Raw durations are normalized for both speaking
rate and vowel identity, using the method described
in (Wightman et al., 1992). This normalization
makes the duration independence assumption rea-
sonable. Normalized durations are modeled as Gaus-
sian distributions, and separate models are built de-
pending on 4 factors. The first factor is the lexical
stress of the vowel. Second is the vowel&apos;s word po-
sition (i.e. whether or not the vowel is in the last
syllable of the word.) These first two factors reflect
the dependence of duration on w,. The third factor
is the boundary type following the word (i.e. whether
the word precedes an intermediate phrase break, a
full phrase break, or no phrase break.) This reflects
the dependence of duration on b. The final factor
is prominence (i.e. whether or not the word contain-
ing the vowel is prominent.) This factor reflects the
dependence of duration on /,.
Iwi, b • (19)
</bodyText>
<sectionHeader confidence="0.903435" genericHeader="method">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.844869">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999979166666667">
Training and testing of the comma/POS prediction
component were completed using the tagged Wall
Street Journal portion of the Treebank corpus (Mar-
cus et al., 1993). 130,226 utterances were used for
training, while 1,986 were used for testing.
Training and testing of the prosodic prediction
component as well as the duration model were com-
pleted using the FM Radio News corpus (Ostendorf
and Veilleux, 1994). 485 (3 news stories read by 5
speakers) utterances were used for training, a super-
set of the 312 used in (Ostendorf and Veilleux, 1994).
For prosodic prediction, 23 sentences were used for
testing with 5 possible prosodic transcriptions con-
sidered correct. This is the same test set used in
(Ostendorf and Veilleux, 1994). The same 23 sen-
tences read by a single speaker were used for dura-
tion model tests. While the test speaker was part of
the training data, the test news story was not.
</bodyText>
<subsectionHeader confidence="0.987201">
5.2 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999805444444444">
In order to evaluate the extent to which duration
modeling was constraining the recognition search
space, we derived a measure of perplexity reduction.
In its standard form, perplexity measures the uncer-
tainty present in a language model. We wanted a
measure of how much prosody-dependent duration
information reduced uncertainty.
Suppose we computed perplexity using P(WID)
instead of P(W):
</bodyText>
<equation confidence="0.997507">
PPdur — 2 74/&amp;quot;2P(wID) (20)
</equation>
<bodyText confidence="0.985319666666667">
To obtain P(WID), we can use Bayes rule with
the probability computed by the duration model (see
Section 4):
</bodyText>
<equation confidence="0.996817">
p(DIW)P(W) (21)
P(WID)
P(D)
</equation>
<bodyText confidence="0.999974416666667">
If we wish to compare the results of two duration
models, a and b, we can look at the percentage by
which model b reduces this duration-dependent per-
plexity:
Thus our evaluation metric, Rpp, can be com-
puted directly from our duration model probability
and a baseline duration model probability. For the
baseline, we use a global model trained on all vowel
data without regard to lexical stress, word position,
or phrase break or prominence locations, although
speaking rate and vowel identity normalization were
still performed.
</bodyText>
<subsectionHeader confidence="0.433257">
5.3 Results
</subsectionHeader>
<subsubsectionHeader confidence="0.727599">
5.3.1 Text-based prediction
</subsubsectionHeader>
<bodyText confidence="0.999970488372093">
We first evaluate the performance of the comma
prediction component of the system. A 61.3% recall
rate and a 3.0% false dection rate are obtained, where
the recall rate is the probability that a comma is
predicted at a word boundary with a comma, and the
false detection rate is the probability that a comma is
predicted where none exists in the transcription. In
this experiment, a 5-gram model was utilized and the
top 1000 words/POS pairs (accounting for 51.2% of
the words in the training data) were assigned special
POS tags.
Now we turn to phrase break prediction results,
shown in Table 1. As mentioned previously, 5 &amp;quot;cor-
rect&amp;quot; prosodic labellings were available for each of
the test utterances, corresponding to the realizations
of 5 different speakers. The labeling most similar to
the automatic labeling for each utterance was used
to compute the results in the table. About 7% of
boundaries were full phrase breaks. For computa-
tional reasons, Equation 2 was not implemented as
is. Instead of summing over all C, the highest proba-
bility comma annotation was chosen and used in the
prosodic prediction step.
The table shows results under three different con-
ditions: using transcribed commas, without using
any comma prediction and using predicted comma
locations (from the model using POS information.)
We see that, while the system using predicted comma
locations does not perform as well as the one us-
ing the transcribed comma locations, it does perform
better overall than the system without comma pre-
diction.
We can also compare these results to those re-
ported in (Ostendorf and Veilleux, 1994), labeled 0
&amp; V in the table. We see that, using transcribed
comma information, our system, which, under this
condition, is virtually identical to (Taylor and Black,
1998), achieves a higher recall rate, but at the cost of
a higher false detection rate. Similarly, our system
using predicted commas has a higher recall rate than
the first 0 &amp; V system, but it also has a higher false
detection rate. Finally, considering that only about
7% of the boundaries are phrase breaks, it does not
</bodyText>
<equation confidence="0.448991454545454">
p p(b)
—
dur
Rpp 1
pp(a)
dur
241092P(b)(WID)
1
241092P(&apos;)(WID)
1
(P(a)(D1W)) N
</equation>
<page confidence="0.4594355">
1
p(b)(Diw)
</page>
<table confidence="0.994416333333333">
Model Commas R FD
- None 69.4 8.3
- Transcribed 87.0 6.0
- Predicted 75.4 7.6
0 &amp; V None 66 5
0 &amp; V (w/syntax) None 71 4
0 &amp; V Transcribed 81 4
Rpp
Conditioning Labeled Predicted
Factors Prosody Prosody
all .16 .14
-word position .03 .03
-break .13 .12
-prominence .13 .13
-lexical stress .15 .13
</table>
<tableCaption confidence="0.998242">
Table 1: Full phrase break prediction recall and false
</tableCaption>
<bodyText confidence="0.954083777777778">
detection percentages without comma information,
with transcribed comma information and with pre-
dicted comma information. Results labeled 0 &amp; V
are taken from (Ostendorf and Veilleux, 1994).
appear to perform as well overall as the 0 &amp; V sys-
tem that incorporates syntax. This was expected, as,
in the 0 &amp; V system the syntax is hand transcribed.
Our simple unigram model for prominence predic-
tion achieved 78.7% recall and 41% false detection.
</bodyText>
<subsubsectionHeader confidence="0.906081">
5.3.2 Duration Modeling
</subsubsectionHeader>
<bodyText confidence="0.991324122448979">
Now we use the evaluation metric described in Sec-
tion 5.2 to assess whether or not we can use these
prosodic differences in duration to aid in recognition.
The results are shown in Table 2. Values for Rpp are
given both using the labeled prosody of the test data
as well as the prosodic labeling predicted by the text-
based model. The first row contains values of Rpp
computed using all of the duration conditioning fac-
tors enumerated in Section 4. The value of the metric
suggests a significant decrease in uncertainty.
The values of Rpp in the remaining rows are com-
puted by removing one conditioning factor. This
gives us an idea of how much each factor contributed
to the value in the first row. We see that, by far, word
position is the most important conditioning factor.
Removing it results in a sharp decrease in Rpp. In-
formation about phrase break location has the next
most significant effect, with its removal resulting in
decreases of .03 and .02 in the value of Rpp in the
labeled and predicted cases respectively. Prominence
is next, showing decreases of .03 and .01, while re-
moving lexical stress as a conditioning factor results
in a decrease of only .01 in both cases.
We were somewhat surprised that word position
was so important in comparison to break location.
We see two possible reasons for this. First, word
position affects one vowel in every word in every
test utterance. Phrase breaks occur only after about
one fifth of the words, resulting in less impact on
the probability P(D IW). Second, the speech in the
corpus was read by professional radio announcers,
whose job involves being exceptionally intelligible.
Table 2: Reduction in conditional perplexity using a
vowel duration model conditioned on word position,
break, prominence, and lexical stress. Dependence
on factors is removed one at a time to gauge the
importance of each.
We speculate that this may make durational differ-
ences less drastic than they may be in more casual
speech.
Table 2 also shows a decrease in Rpp when we
move from using labeled prosody to using predicted
prosody. This was expected. Even the best text-
based prosody model could not predict the exact
prosodic realization of a particular text string, as
it is an inherently ambiguous task. That said, our
text-based model could certainly be improved. Still,
the predicted prosody-dependent factors show some
effect on Rpp.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="method">
6 Summary
</sectionHeader>
<bodyText confidence="0.999938769230769">
In this work we have implemented a text-based
prosody prediction scheme, novel in its use of a
preliminary integrated comma-prediction/POS tag-
ging step. We have also demonstrated an increase
in a word-level constraint metric using prosody-
dependent duration models, and analyzed what con-
ditioning factors most contributed to that increase.
The analysis indicates that while word position is, by
far, the most important factor, predicted prosodic la-
beling information also contributes to the increase.
This final result suggests a benefit to integrating
prosodic consistency into a speech recognition sys-
tem.
</bodyText>
<sectionHeader confidence="0.999615" genericHeader="discussions">
7 Future Work
</sectionHeader>
<bodyText confidence="0.999995642857143">
The ultimate goal of this work is to use prosodic
consistency as a constraint in a speech recognizer.
To this end, we plan to close the loop on the work
described here by incorporating prosody-based du-
ration modeling into a speech recognition system.
We also plan to incorporate more acoustic prosodic
cues including pause duration, and fundamental fre-
quency information into this framework.
We feel that prosodic consistency may provide an
especially valuable constraint in more casual speech.
With this in mind, we are looking to move away
from the read speech domain used here and into more
spontaneous domains like university course lectures
and, at the extreme, phone conversations.
</bodyText>
<sectionHeader confidence="0.999242" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999232">
D. Beeferman, A. Berger, and J. Lafferty. 1998. CY-
BERPUNC: A lightweight puncutation annotation
system for speech. In Proc. ICASSP, pages 689-
693, Seattle.
K. Chen, S. Borys, M. Hasegawa-Johnson, and
J. Cole. 2003. Prosody dependent speech recog-
nition with explicit duration modeling at intona-
tional phrase boundaries. In Proc. Eurospeech,
pages 393-396, Geneva.
S. DeRose. 1988. Grammatical category disam-
biguation by statistical optimization. Computa-
tional Linguistics, 14:31-39.
M. Marcus, B. Santorini, and M. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: the Penn Treebank. Computational Linguis-
tics, 19(1).
E. Noth, A. Batliner, A. Kiebling, R. Kompe, and
H. Niemann. 2000. Verbmobil: The use of prosody
in the linguistic components of a speech under-
standing system. IEEE Transactions on Speech
and Audio Processing, 27:113-134.
M. Ostendorf and N. Veilleux. 1994. A hierarchi-
cal stochastic model for automatic prediction of
prosodic boundary location. Computational Lin-
guistics, 20:27-54.
M. Ostendorf, I. Shafran, and R. Bates. 2003.
Prosody models for conversational speech recogni-
tion. In Proc. for 4th Plenary Meeting and Sym-
posium on Prosody and Speech Processing.
A. Stolcke, E. Shriberg, D. Hakkani-Tur, and G. Tur.
1999. Modeling the prosody of hidden events for
improved word recognition. In Proc. Eurospeech,
pages 311-314.
P. Taylor and A. Black. 1998. Assigning phrase
breaks from part-of-speech sequences. Computer
Speech and Language, 12:99-117.
C. Wightman, S. Shattuck-Hufnagel, M. Ostendorf,
and P. Price. 1992. Segmental durations in the
vicinity of prosodic phrase boundaries. J. Acoust.
Soc. Am., 91(3):1707-1717.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965704">
<title confidence="0.999893">Modeling Prosodic Consistency for Automatic Recognition: Preliminary Investigations</title>
<author confidence="0.998722">Ernest Pusateri</author>
<author confidence="0.998722">James</author>
<affiliation confidence="0.993037">Computer Science and Artificial Intelligence Massachusetts Institute of</affiliation>
<address confidence="0.999782">Cambridge, MA 02139,</address>
<email confidence="0.999957">fpusateri,glassl@mit.edu</email>
<abstract confidence="0.9990245">In this paper we describe a prosodydependent duration model as a first step toward incorporating a prosodic consistency constraint into a speech recognizer. As part of this model, we describe a textbased prosody prediction scheme, novel in its use of a preliminary integrated commaprediction/POS tagging step. We also demonstrate a relative decrease in perplexity using the prosody-dependent duration model and analyze what conditioning factors most contributed to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Beeferman</author>
<author>A Berger</author>
<author>J Lafferty</author>
</authors>
<title>CYBERPUNC: A lightweight puncutation annotation system for speech.</title>
<date>1998</date>
<booktitle>In Proc. ICASSP,</booktitle>
<pages>689--693</pages>
<location>Seattle.</location>
<marker>Beeferman, Berger, Lafferty, 1998</marker>
<rawString>D. Beeferman, A. Berger, and J. Lafferty. 1998. CYBERPUNC: A lightweight puncutation annotation system for speech. In Proc. ICASSP, pages 689-693, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Chen</author>
<author>S Borys</author>
<author>M Hasegawa-Johnson</author>
<author>J Cole</author>
</authors>
<title>Prosody dependent speech recognition with explicit duration modeling at intonational phrase boundaries.</title>
<date>2003</date>
<booktitle>In Proc. Eurospeech,</booktitle>
<pages>393--396</pages>
<location>Geneva.</location>
<contexts>
<context position="1356" citStr="Chen et al., 2003" startWordPosition="202" endWordPosition="205"> to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system. 1 Introduction While much effort has gone into using prosody in the areas of speech synthesis and understanding (e.g (Noth et al., 2000; Taylor and Black, 1998)), less has been focused on using it to aid directly in the task of speech recognition (e.g. (Stolcke et al., 1999; Ostendorf et al., 2003; Chen et al., 2003).) The utility of prosody in speech recognition comes from the fact that, while prosody is not fully determined by an utterances lexical content, lexical content does make some prosodic realizations more probable than others. This implies that we can meaningfully ask whether the acoustic cues to the prosody of an utterance are consistent with a textual hypothesis. In this work we report on an initial effort to develop a prosody-dependent duration model. It is closely related to (Chen et al., 2003). However, while that work uses a standard language model for textbased prosody prediction, we inc</context>
</contexts>
<marker>Chen, Borys, Hasegawa-Johnson, Cole, 2003</marker>
<rawString>K. Chen, S. Borys, M. Hasegawa-Johnson, and J. Cole. 2003. Prosody dependent speech recognition with explicit duration modeling at intonational phrase boundaries. In Proc. Eurospeech, pages 393-396, Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S DeRose</author>
</authors>
<title>Grammatical category disambiguation by statistical optimization.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--31</pages>
<marker>DeRose, 1988</marker>
<rawString>S. DeRose. 1988. Grammatical category disambiguation by statistical optimization. Computational Linguistics, 14:31-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="7713" citStr="Marcus et al., 1993" startWordPosition="1260" endWordPosition="1264">ctors reflect the dependence of duration on w,. The third factor is the boundary type following the word (i.e. whether the word precedes an intermediate phrase break, a full phrase break, or no phrase break.) This reflects the dependence of duration on b. The final factor is prominence (i.e. whether or not the word containing the vowel is prominent.) This factor reflects the dependence of duration on /,. Iwi, b • (19) 5 Experiments and Results 5.1 Data Training and testing of the comma/POS prediction component were completed using the tagged Wall Street Journal portion of the Treebank corpus (Marcus et al., 1993). 130,226 utterances were used for training, while 1,986 were used for testing. Training and testing of the prosodic prediction component as well as the duration model were completed using the FM Radio News corpus (Ostendorf and Veilleux, 1994). 485 (3 news stories read by 5 speakers) utterances were used for training, a superset of the 312 used in (Ostendorf and Veilleux, 1994). For prosodic prediction, 23 sentences were used for testing with 5 possible prosodic transcriptions considered correct. This is the same test set used in (Ostendorf and Veilleux, 1994). The same 23 sentences read by a</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Noth</author>
<author>A Batliner</author>
<author>A Kiebling</author>
<author>R Kompe</author>
<author>H Niemann</author>
</authors>
<title>Verbmobil: The use of prosody in the linguistic components of a speech understanding system.</title>
<date>2000</date>
<booktitle>IEEE Transactions on Speech and Audio Processing,</booktitle>
<pages>27--113</pages>
<contexts>
<context position="1173" citStr="Noth et al., 2000" startWordPosition="169" endWordPosition="172">maprediction/POS tagging step. We also demonstrate a relative decrease in perplexity using the prosody-dependent duration model and analyze what conditioning factors most contributed to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system. 1 Introduction While much effort has gone into using prosody in the areas of speech synthesis and understanding (e.g (Noth et al., 2000; Taylor and Black, 1998)), less has been focused on using it to aid directly in the task of speech recognition (e.g. (Stolcke et al., 1999; Ostendorf et al., 2003; Chen et al., 2003).) The utility of prosody in speech recognition comes from the fact that, while prosody is not fully determined by an utterances lexical content, lexical content does make some prosodic realizations more probable than others. This implies that we can meaningfully ask whether the acoustic cues to the prosody of an utterance are consistent with a textual hypothesis. In this work we report on an initial effort to dev</context>
</contexts>
<marker>Noth, Batliner, Kiebling, Kompe, Niemann, 2000</marker>
<rawString>E. Noth, A. Batliner, A. Kiebling, R. Kompe, and H. Niemann. 2000. Verbmobil: The use of prosody in the linguistic components of a speech understanding system. IEEE Transactions on Speech and Audio Processing, 27:113-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ostendorf</author>
<author>N Veilleux</author>
</authors>
<title>A hierarchical stochastic model for automatic prediction of prosodic boundary location.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--27</pages>
<contexts>
<context position="4371" citStr="Ostendorf and Veilleux, 1994" startWordPosition="692" endWordPosition="695">CY RESCORED N−BEST LIST SPEECH RECOGNIZER SPEECH INPUT 3.3.1 Break Prediction In obtaining P(BIC, S, W), we first assume that B is conditionally independent of W given S and C: This assumption is motivated by the fact that content words very often are prominent while function words very often are not. While this simple unigram model tends to over-predict prominences, it is used by many speech synthesizers. P(BIC, S, W) P(BIC, S) (10) While this assumption results in ignoring wordspecific (and thus also semantic) cues to break location, it does allow us to use some syntactic information. Both (Ostendorf and Veilleux, 1994) and (Taylor and Black, 1998) have found this approximation to be workable. We relate the approximation to the joint probability, P(B,C, S): P(B , C, S) P(B&apos;&apos;PCS ) To find P(B,C, S), we can use the framework presented in (Taylor and Black, 1998). Let b, be the type of the boundary between w, and P(B, C, S) = P(C, SIB)P(B) (12) = (H P(ci, si, si+11B))P(B) (13) J=1 (H P(ci, si, si+11b,))P(B) (14) J=1 The first component of the model, P(c.„ sJ, sJ+11/h) captures the distribution of the parts-of speech surrounding boundaries. The second component, P(B), captures common boundary type patterns and i</context>
<context position="7957" citStr="Ostendorf and Veilleux, 1994" startWordPosition="1300" endWordPosition="1303">ce of duration on b. The final factor is prominence (i.e. whether or not the word containing the vowel is prominent.) This factor reflects the dependence of duration on /,. Iwi, b • (19) 5 Experiments and Results 5.1 Data Training and testing of the comma/POS prediction component were completed using the tagged Wall Street Journal portion of the Treebank corpus (Marcus et al., 1993). 130,226 utterances were used for training, while 1,986 were used for testing. Training and testing of the prosodic prediction component as well as the duration model were completed using the FM Radio News corpus (Ostendorf and Veilleux, 1994). 485 (3 news stories read by 5 speakers) utterances were used for training, a superset of the 312 used in (Ostendorf and Veilleux, 1994). For prosodic prediction, 23 sentences were used for testing with 5 possible prosodic transcriptions considered correct. This is the same test set used in (Ostendorf and Veilleux, 1994). The same 23 sentences read by a single speaker were used for duration model tests. While the test speaker was part of the training data, the test news story was not. 5.2 Evaluation Metric In order to evaluate the extent to which duration modeling was constraining the recogni</context>
<context position="11201" citStr="Ostendorf and Veilleux, 1994" startWordPosition="1834" endWordPosition="1837">mented as is. Instead of summing over all C, the highest probability comma annotation was chosen and used in the prosodic prediction step. The table shows results under three different conditions: using transcribed commas, without using any comma prediction and using predicted comma locations (from the model using POS information.) We see that, while the system using predicted comma locations does not perform as well as the one using the transcribed comma locations, it does perform better overall than the system without comma prediction. We can also compare these results to those reported in (Ostendorf and Veilleux, 1994), labeled 0 &amp; V in the table. We see that, using transcribed comma information, our system, which, under this condition, is virtually identical to (Taylor and Black, 1998), achieves a higher recall rate, but at the cost of a higher false detection rate. Similarly, our system using predicted commas has a higher recall rate than the first 0 &amp; V system, but it also has a higher false detection rate. Finally, considering that only about 7% of the boundaries are phrase breaks, it does not p p(b) — dur Rpp 1 pp(a) dur 241092P(b)(WID) 1 241092P(&apos;)(WID) 1 (P(a)(D1W)) N 1 p(b)(Diw) Model Commas R FD - </context>
</contexts>
<marker>Ostendorf, Veilleux, 1994</marker>
<rawString>M. Ostendorf and N. Veilleux. 1994. A hierarchical stochastic model for automatic prediction of prosodic boundary location. Computational Linguistics, 20:27-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ostendorf</author>
<author>I Shafran</author>
<author>R Bates</author>
</authors>
<title>Prosody models for conversational speech recognition.</title>
<date>2003</date>
<booktitle>In Proc. for 4th Plenary Meeting and Symposium on Prosody and Speech Processing.</booktitle>
<contexts>
<context position="1336" citStr="Ostendorf et al., 2003" startWordPosition="198" endWordPosition="201">factors most contributed to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system. 1 Introduction While much effort has gone into using prosody in the areas of speech synthesis and understanding (e.g (Noth et al., 2000; Taylor and Black, 1998)), less has been focused on using it to aid directly in the task of speech recognition (e.g. (Stolcke et al., 1999; Ostendorf et al., 2003; Chen et al., 2003).) The utility of prosody in speech recognition comes from the fact that, while prosody is not fully determined by an utterances lexical content, lexical content does make some prosodic realizations more probable than others. This implies that we can meaningfully ask whether the acoustic cues to the prosody of an utterance are consistent with a textual hypothesis. In this work we report on an initial effort to develop a prosody-dependent duration model. It is closely related to (Chen et al., 2003). However, while that work uses a standard language model for textbased prosod</context>
</contexts>
<marker>Ostendorf, Shafran, Bates, 2003</marker>
<rawString>M. Ostendorf, I. Shafran, and R. Bates. 2003. Prosody models for conversational speech recognition. In Proc. for 4th Plenary Meeting and Symposium on Prosody and Speech Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>E Shriberg</author>
<author>D Hakkani-Tur</author>
<author>G Tur</author>
</authors>
<title>Modeling the prosody of hidden events for improved word recognition.</title>
<date>1999</date>
<booktitle>In Proc. Eurospeech,</booktitle>
<pages>311--314</pages>
<contexts>
<context position="1312" citStr="Stolcke et al., 1999" startWordPosition="194" endWordPosition="197">yze what conditioning factors most contributed to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system. 1 Introduction While much effort has gone into using prosody in the areas of speech synthesis and understanding (e.g (Noth et al., 2000; Taylor and Black, 1998)), less has been focused on using it to aid directly in the task of speech recognition (e.g. (Stolcke et al., 1999; Ostendorf et al., 2003; Chen et al., 2003).) The utility of prosody in speech recognition comes from the fact that, while prosody is not fully determined by an utterances lexical content, lexical content does make some prosodic realizations more probable than others. This implies that we can meaningfully ask whether the acoustic cues to the prosody of an utterance are consistent with a textual hypothesis. In this work we report on an initial effort to develop a prosody-dependent duration model. It is closely related to (Chen et al., 2003). However, while that work uses a standard language mo</context>
</contexts>
<marker>Stolcke, Shriberg, Hakkani-Tur, Tur, 1999</marker>
<rawString>A. Stolcke, E. Shriberg, D. Hakkani-Tur, and G. Tur. 1999. Modeling the prosody of hidden events for improved word recognition. In Proc. Eurospeech, pages 311-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
<author>A Black</author>
</authors>
<title>Assigning phrase breaks from part-of-speech sequences.</title>
<date>1998</date>
<journal>Computer Speech and Language,</journal>
<pages>12--99</pages>
<contexts>
<context position="1198" citStr="Taylor and Black, 1998" startWordPosition="173" endWordPosition="176">gging step. We also demonstrate a relative decrease in perplexity using the prosody-dependent duration model and analyze what conditioning factors most contributed to that decrease. The analysis indicates that while word position is, by far, the most important factor, predicted prosodic labeling information also contributes to the decrease. This final result suggests a benefit to integrating a prosodic consistency constraint into a speech recognition system. 1 Introduction While much effort has gone into using prosody in the areas of speech synthesis and understanding (e.g (Noth et al., 2000; Taylor and Black, 1998)), less has been focused on using it to aid directly in the task of speech recognition (e.g. (Stolcke et al., 1999; Ostendorf et al., 2003; Chen et al., 2003).) The utility of prosody in speech recognition comes from the fact that, while prosody is not fully determined by an utterances lexical content, lexical content does make some prosodic realizations more probable than others. This implies that we can meaningfully ask whether the acoustic cues to the prosody of an utterance are consistent with a textual hypothesis. In this work we report on an initial effort to develop a prosody-dependent </context>
<context position="4400" citStr="Taylor and Black, 1998" startWordPosition="697" endWordPosition="700">GNIZER SPEECH INPUT 3.3.1 Break Prediction In obtaining P(BIC, S, W), we first assume that B is conditionally independent of W given S and C: This assumption is motivated by the fact that content words very often are prominent while function words very often are not. While this simple unigram model tends to over-predict prominences, it is used by many speech synthesizers. P(BIC, S, W) P(BIC, S) (10) While this assumption results in ignoring wordspecific (and thus also semantic) cues to break location, it does allow us to use some syntactic information. Both (Ostendorf and Veilleux, 1994) and (Taylor and Black, 1998) have found this approximation to be workable. We relate the approximation to the joint probability, P(B,C, S): P(B , C, S) P(B&apos;&apos;PCS ) To find P(B,C, S), we can use the framework presented in (Taylor and Black, 1998). Let b, be the type of the boundary between w, and P(B, C, S) = P(C, SIB)P(B) (12) = (H P(ci, si, si+11B))P(B) (13) J=1 (H P(ci, si, si+11b,))P(B) (14) J=1 The first component of the model, P(c.„ sJ, sJ+11/h) captures the distribution of the parts-of speech surrounding boundaries. The second component, P(B), captures common boundary type patterns and is modeled with an N-gram. The</context>
<context position="11372" citStr="Taylor and Black, 1998" startWordPosition="1862" endWordPosition="1865">fferent conditions: using transcribed commas, without using any comma prediction and using predicted comma locations (from the model using POS information.) We see that, while the system using predicted comma locations does not perform as well as the one using the transcribed comma locations, it does perform better overall than the system without comma prediction. We can also compare these results to those reported in (Ostendorf and Veilleux, 1994), labeled 0 &amp; V in the table. We see that, using transcribed comma information, our system, which, under this condition, is virtually identical to (Taylor and Black, 1998), achieves a higher recall rate, but at the cost of a higher false detection rate. Similarly, our system using predicted commas has a higher recall rate than the first 0 &amp; V system, but it also has a higher false detection rate. Finally, considering that only about 7% of the boundaries are phrase breaks, it does not p p(b) — dur Rpp 1 pp(a) dur 241092P(b)(WID) 1 241092P(&apos;)(WID) 1 (P(a)(D1W)) N 1 p(b)(Diw) Model Commas R FD - None 69.4 8.3 - Transcribed 87.0 6.0 - Predicted 75.4 7.6 0 &amp; V None 66 5 0 &amp; V (w/syntax) None 71 4 0 &amp; V Transcribed 81 4 Rpp Conditioning Labeled Predicted Factors Pros</context>
</contexts>
<marker>Taylor, Black, 1998</marker>
<rawString>P. Taylor and A. Black. 1998. Assigning phrase breaks from part-of-speech sequences. Computer Speech and Language, 12:99-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wightman</author>
<author>S Shattuck-Hufnagel</author>
<author>M Ostendorf</author>
<author>P Price</author>
</authors>
<title>Segmental durations in the vicinity of prosodic phrase boundaries.</title>
<date>1992</date>
<journal>J. Acoust. Soc. Am.,</journal>
<pages>91--3</pages>
<contexts>
<context position="6727" citStr="Wightman et al., 1992" startWordPosition="1095" endWordPosition="1098">osodic prediction, we decompose P(DIW): P(DIW) = E P(D, LIW) (17) = E P(DIW, L)P(LIW) (18) P(LIW) is the probability computed by our textbased prosody prediction model. The assumption is made that the duration d„,3 depends only on w, (the word to which the vowel belongs), k (the type of the following boundary) and (whether or not word i is prominent). Also, we assume that, given the word string and prosodic labeling, the durations are independent. This gives us: N Mi P(DIW, H H P(di, i=1 j=1 Raw durations are normalized for both speaking rate and vowel identity, using the method described in (Wightman et al., 1992). This normalization makes the duration independence assumption reasonable. Normalized durations are modeled as Gaussian distributions, and separate models are built depending on 4 factors. The first factor is the lexical stress of the vowel. Second is the vowel&apos;s word position (i.e. whether or not the vowel is in the last syllable of the word.) These first two factors reflect the dependence of duration on w,. The third factor is the boundary type following the word (i.e. whether the word precedes an intermediate phrase break, a full phrase break, or no phrase break.) This reflects the depende</context>
</contexts>
<marker>Wightman, Shattuck-Hufnagel, Ostendorf, Price, 1992</marker>
<rawString>C. Wightman, S. Shattuck-Hufnagel, M. Ostendorf, and P. Price. 1992. Segmental durations in the vicinity of prosodic phrase boundaries. J. Acoust. Soc. Am., 91(3):1707-1717.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>