<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005018">
<title confidence="0.97549">
Combining Segmenter and Chunker for Chinese Word Segmentation
</title>
<author confidence="0.992665">
Masayuki Asahara, Chooi Ling Goh, Xiaojie Wang, Yuji Matsumoto
</author>
<affiliation confidence="0.9971215">
Graduate School of Information Science
Nara Institute of Science and Technology, Japan
</affiliation>
<email confidence="0.997224">
{masayu-a,ling-g,xiaoji-w,matsu}@is.aist-nara.ac.jp
</email>
<sectionHeader confidence="0.995605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999688125">
Our proposed method is to use a Hidden
Markov Model-based word segmenter and a
Support Vector Machine-based chunker for
Chinese word segmentation. Firstly, input sen-
tences are analyzed by the Hidden Markov
Model-based word segmenter. The word seg-
menter produces n-best word candidates to-
gether with some class information and confi-
dence measures. Secondly, the extracted words
are broken into character units and each char-
acter is annotated with the possible word class
and the position in the word, which are then
used as the features for the chunker. Finally, the
Support Vector Machine-based chunker brings
character units together into words so as to de-
termine the word boundaries.
</bodyText>
<sectionHeader confidence="0.996489" genericHeader="keywords">
1 Methods
</sectionHeader>
<bodyText confidence="0.999865">
We participate in the closed test for all four sets of data
in Chinese Word Segmentation Bakeoff. Our method is
based on the following two steps:
</bodyText>
<listItem confidence="0.7667245">
1. The input sentence is segmented into a word se-
quence by Hidden Markov Model-based word seg-
</listItem>
<bodyText confidence="0.831647666666667">
menter. The segmenter assigns a word class with
a confidence measure for each word at the hidden
states. The model is trained by Baum-Welch algo-
rithm.
2. Each character in the sentence is annotated with the
word class tag and the position in the word. The
n-best word candidates derived from the word seg-
menter are also extracted as the features. A sup-
port vector machine-based chunker corrects the er-
rors made by the segmenter using the extracted fea-
tures.
We will describe each of these steps in more details.
</bodyText>
<subsectionHeader confidence="0.978639">
1.1 Hidden Markov Model-based Word Segmenter
</subsectionHeader>
<bodyText confidence="0.9998585">
Our word segmenter is based on Hidden Markov Model
(HMM). We first decide the number of hidden states
(classes) and assume that the each word can belong to
all the classes with some probability. The problem is de-
fined as a search for the sequence of word classes C =
cl, ... , cn given a word sequence W = wl, ... , wn. The
target is to find W and C for a given input S that maxi-
mizes the following probability:
</bodyText>
<equation confidence="0.894456">
P(W|C)P(C)
</equation>
<bodyText confidence="0.999994545454545">
We assume that the word probability P(W |C) is con-
strained only by its word class, and that the class prob-
ability P(C) is constrained only by the class of the pre-
ceding word. These probabilities are estimated by the
Baum-Welch algorithm using the training material (See
(Manning and Sch¨utze., 1999)). The learning process is
based on the Baum-Welch algorithm and is the same as
the well-known use of HMM for part-of-speech tagging
problem, except that the number of states are arbitrarily
determined and the initial probabilities are randomly as-
signed in our model.
</bodyText>
<subsectionHeader confidence="0.9870775">
1.2 Correction by Support Vector Machine-based
Chunker
</subsectionHeader>
<bodyText confidence="0.950551666666667">
While the HMM-based word segmenter achieves good
accuracy for known words, it cannot identify compound
words and out-of-vocabulary words. Therefore, we in-
troduce a Support Vector Machine(below SVM)-based
chunker (Kudo and Matsumoto, 2001) to cover the er-
rors made by the segmenter. The SVM-based chunker
re-assigns new word boundaries to the output of the seg-
menter.
An SVM (Vapnik, 1998) is a binary classifier. Sup-
pose we have a set of training data for a binary class
problem: (xl, yl), . . . , (xN, yN), where xi E Rn is a
feature vector of the i th sample in the training data and
arg max
W,C
yi E 1+1, −11 is the label of the sample. The goal is to
find a decision function which accurately predicts y for
an unseen x. An SVM classifier gives a decision function
f(x) for an input vector x where
</bodyText>
<equation confidence="0.874771">
f(x) = sign( � αiyiK(x, zi) + b).
z;∈SV
f(x) = +1 means that x is a positive member, and
f(x) = −1 means that x is a negative member. The vec-
</equation>
<bodyText confidence="0.999287733333334">
tors zi are called support vectors, which receive a non-
zero weight αi. Support vectors and the parameters are
determined by solving a quadratic programming prob-
lem. K(x, z) is a kernel function which maps vectors
into a higher dimensional space. We use a polynomial
kernel of degree 2 given by K(x, z) = (1 + x · z)2.
The SVM classifier determines the position tag for
each character. We introduce the word class tag as the
feature, which is generated by the word segmenter. Since
we perform chunking by character units, the feature used
by the classifier will be the information for the character
unit.
The training data for our SVM-based chunker is con-
structed from the output of the HMM-based word seg-
menter defined in the previous section. In the current
setting, the HMM produces all the possible tags (class
labels) for each of the word within a predefined probabil-
ity bound. All the words in the output are then segmented
into characters, and each of the characters is tagged with
pairs of a word class and a position tag. For example,
in the paired tag “0-B”, “0” is a class label of the word
which the character belongs to and “B” indicates the char-
acter’s position in the word. The number of classes is
determined in advance of the HMM learning. The po-
sition tag consists of the following four tags (S/B/E/I):
S means a single-character word; B is the first charac-
ter in a multi-character word; E is the last character in a
multi-character word; I is the intermediate character in a
multi-character word longer than 2 characters. As shown
in Figure 1, we set the HMM-based word segmenter to
produce the classes of n-best word candidates to take into
account multiple possibility of word boundaries.
The correct word boundary can be defined by assigning
either of two kinds of tags to each of the characters. Look
at the rightmost column of Figure 1 named as “Chunker
Outputs.” The label “B” in this column shows that the
character is the first character of a correct word, and “I”
shows that the character is the other part of a word. This
means that the preceding positions of “B” tags are the
word boundaries.
Those two tags correspond to the two classes of the
SVM chunker: In the training (and test) phrase, we use
window size of two characters to the left and right direc-
tion to learn (and estimate) the class for a character. For
example, the shadowed parts in Figure 1 are used as the
</bodyText>
<figureCaption confidence="0.999552">
Figure 1: The Extracted Features for the Chunker
</figureCaption>
<bodyText confidence="0.990754">
features to learn (or estimate) the word boundary tag “I”
for the character “ ”.
</bodyText>
<sectionHeader confidence="0.96727" genericHeader="introduction">
2 Model Validation
</sectionHeader>
<bodyText confidence="0.999888833333333">
To find out the best setting of learning, we would like to
determine “the number of word classes” and “the depth of
n-best word candidates” by using some sort of confidence
measure. We perform validation experiments for these
two types of parameters by using the training material
provided.
</bodyText>
<subsectionHeader confidence="0.9526345">
2.1 Validation Tests for HMM-based Word
Segmenter
</subsectionHeader>
<bodyText confidence="0.9975054">
The first validation experiment is to determine “the num-
ber of word classes” of the HMM. 80% of the material is
used for the HMM training, and the other 20% is used as
the validation set. We test two settings for the number of
classes – 5 &amp; 10. The results are shown in Table 1.
</bodyText>
<tableCaption confidence="0.999553">
Table 1: Validation Results for HMM
</tableCaption>
<table confidence="0.997781666666667">
Data # of classes Rec. Prec. F
AS 5 0.845 0.768 0.804
AS 10 0.900 0.857 0.878
CTB 5 0.909 0.844 0.875
CTB 10 0.912 0.848 0.879
HK 5 0.867 0.742 0.799
HK 10 0.867 0.741 0.799
PK 5 0.942 0.902 0.921
PK 10 0.944 0.905 0.924
</table>
<bodyText confidence="0.998728833333333">
In most cases, models perform slightly better with the
increasing of the number of classes. When the corpus
size is large like the Academia Sinica data, this tendency
becomes more significant.
Whereas it is known that the Baum Welch algorithm is
very sensitive to the initialization of the classes, we ran-
domly assigned the initial classes without making much
effort. There are two reasons: (1) Since the word seg-
menter outputs are used as the clues to the chunker in our
method, we only need some consistent class annotations.
(2) The initial classes did not affect on the word segmen-
tation accuracy in our pilot experiments.
</bodyText>
<tableCaption confidence="0.929857">
Table 4: Validation Results (PK) for Chunking
</tableCaption>
<figure confidence="0.981510777777778">
# of classes n-best
5 1
5 2
5 3
5 4
10 1
10 2
10 3
10 4
</figure>
<table confidence="0.965665">
Rec. Prec. F
0.960 0.934 0.947
0.961 0.935 0.948
0.962 0.936 0.949
0.962 0.935 0.948
0.961 0.932 0.946
0.962 0.935 0.948
0.961 0.934 0.947
0.961 0.934 0.947
</table>
<subsectionHeader confidence="0.986298">
2.2 Validation Tests for SVM-based Chunker
</subsectionHeader>
<bodyText confidence="0.999366">
The second validation test is for the chunking model to
determine both “the number of word classes” and “the
depth of the n-best candidates”. 80% of the material used
for the HMM training, another 10% is used for the chunk-
ing model training and the last 10% is used for the val-
idation test. The results are shown in Table 2, 3 and 4.
Since the training of this model is time- and resource-
consuming, the Academia Sinica data being very large
could not get enough time to finish the validation test.
</bodyText>
<tableCaption confidence="0.999976">
Table 2: Validation Results (CTB) for Chunking
Table 3: Validation Results (HK) for Chunking
</tableCaption>
<table confidence="0.998406444444444">
Rec. Prec. F
0.853 0.793 0.822
0.859 0.799 0.828
0.859 0.799 0.828
0.859 0.800 0.828
0.856 0.793 0.823
0.858 0.797 0.826
0.857 0.796 0.826
0.858 0.797 0.826
</table>
<bodyText confidence="0.999940631578948">
The results show that the chunker actually improves
the word segmentation accuracy compared with the out-
put of the HMM word segmenter for these three data sets.
The segmentation errors made by the word segmenter for
compound words and unknown words are corrected. The
improvement in Chinese Treebank (CTB) data set is sig-
nificant, because the data set contains many compound
words.
There is no significant difference in the results between
the different depths of n-best answers. Still, we choose
the best model for the test materials among them. If we
need to have a faster analyzer, we should employ only the
best answer of the word segmentation.
For the HMM, the larger number of classes tends to
get better accuracy than smaller ones. However, for the
chunking model, the result is the other way round. The
model with the smaller number of classes gets slightly
better accuracy. So, there should be trade-off between
smaller and larger number of classes.
</bodyText>
<sectionHeader confidence="0.989663" genericHeader="method">
3 Final Models for Test Material
</sectionHeader>
<bodyText confidence="0.999778071428571">
For the final models, 80% of the training material is used
for HMM training and 100% of the material is used for
the chunking model training. The parameters, namely
“the number of word classes” and “the depth of n-best
word candidates”, are determined by the validation tests
described in Section 2. While there is no significant dif-
ference between the depths of n-best answers, we choose
the best model among them for the testing. The parame-
ters are shown in Table 7.
We cannot create the model using all the original
Academia Sinica data because of its large size. Therefore,
we use 80% of the data for HMM training (5 classes) and
only 10% for chunking model training (with only the best
candidates).
</bodyText>
<tableCaption confidence="0.983453">
Table 7: The Models for the Test Material
</tableCaption>
<figure confidence="0.9234943">
– with respect to F-Measure in Our Validation Test
# of classes n-best
5 1
5 2
5 3
5 4
10 1
10 2
10 3
10 4
</figure>
<table confidence="0.8541316">
Rec. Prec. F
0.957 0.930 0.943
0.957 0.931 0.944
0.957 0.930 0.943
0.957 0.930 0.943
0.956 0.929 0.943
0.957 0.928 0.942
0.956 0.929 0.942
0.955 0.928 0.941
# of classes n-best
</table>
<footnote confidence="0.522330333333333">
5 1
5 2
5 4
5 3
Data
AS
CTB
HK
PK
</footnote>
<page confidence="0.911363">
F
N/A
0.943
0.828
0.948
</page>
<figure confidence="0.999053">
# of classes n-best
5 1
5 2
5 3
5 4
10 1
10 2
10 3
10 4
</figure>
<tableCaption confidence="0.986517">
Table 5: Throughput Speeds (characters per second)
</tableCaption>
<table confidence="0.9991062">
Data Word Seg. (# of words) Fea. Ext. (n-best) Chunker (# of SV) Total Speed
AS 57000 (462750) 7640 (Only Best) 279 (96452) 241
CTB 54400 (77324) 4040 (to 2nd Best) 894 (16736) 671
HK 38900 (93231) 3870 (to 4th Best) 649 (14904) 524
PK 57400 (215865) 6209 (to 3rd Best) 254 (49736) 200
</table>
<tableCaption confidence="0.748448">
Table 6: Results for the Test Materials
</tableCaption>
<table confidence="0.9994036">
Data T. Rec. T. Prec. F OOV Rec. IV Rec. Ranking
AS 0.944 0.945 0.945 0.574 0.952 3rd/6
CTB 0.852 0.807 0.829 0.412 0.949 8th/10
HK 0.940 0.908 0.924 0.415 0.980 5th/6
PK 0.933 0.916 0.924 0.357 0.975 2nd/4
</table>
<sectionHeader confidence="0.993366" genericHeader="method">
4 Throughput Speeds
</sectionHeader>
<bodyText confidence="0.999987352941177">
As described, our system is based on three modules:
HMM-based word segmenter, Feature extractor and
SVM-based chunker. The word segmenter is composed
by ChaSen (written in C/C++) (Matsumoto et. al., 2003)
which is adopted for GB/Big5 encoding. The feature
extractor is written in Perl. The SVM-based chunker is
composed by YamCha (written in C++) (Kudo and Mat-
sumoto, 2001).
Table 5 shows the speeds 1 of the three modules indi-
vidually and of the total system. “# of words” means the
size of the word segmenter lexicon. Note that, if a word
belongs to more than one class, we regard them as differ-
ent words in our definition. “# of SV” means the number
of support vectors in the chunker. The total system speed
depends highly on that of the chunker. It is known that
the speed of SVM classifiers depends on the number of
support vectors and the number of features.
</bodyText>
<sectionHeader confidence="0.999271" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999972777777778">
We presented our method for Chinese Word Segmenta-
tion Bakeoff in 2nd SIGHAN Workshop. The results for
the test materials are shown in Table 6. The proposed
method is purely corpus-based statistical/machine learn-
ing method. Although we did not incorporate any heuris-
tic rules (e.g. part-of-speeches, functional words and
concatenation for numbers) into the model, the method
achieved considerable accuracy for the word segmenta-
tion task.
</bodyText>
<sectionHeader confidence="0.99895" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998039">
We thank Mr. Taku Kudo of NAIST for his development
of the SVM-based chunker YamCha.
</bodyText>
<footnote confidence="0.993077666666667">
1The throughput speeds are measured on a machine: In-
tel(R) Xeon(TM) CPU 2.80GHz × 2, Memory 4GB, RedHat
Linux 9.
</footnote>
<sectionHeader confidence="0.996501" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999334">
T. Kudo and Y. Matsumoto. 2001. Chunking with Sup-
port Vector Machines. In Proc. ofNAACL 2001, pages
192–199.
C. D. Manning and H. Sch¨utze. 1999. Foundation of
Statistical Natural Language Processing. Chapter 9.
Markov Models, pages 317–340.
Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hirano, K.
Takaoka and M. Asahara 2003. Morphological Ana-
lyzer ChaSen-2.3.0 Users Manual Tech. Report. Nara
Institute of Science and Technology, Japan.
L. A. Ramshaw and M. P. Marcus. 1995 Text chunking
using transformation-bases learning In Proc. of the 3rd
Workshop on Very Large Corpora, pages 83–94.
V. N. Vapnik. 1998. Statistical Learning Theory. A
Wiley-Interscience Publication.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999951">Combining Segmenter and Chunker for Chinese Word Segmentation</title>
<author confidence="0.998156">Masayuki Asahara</author>
<author confidence="0.998156">Chooi Ling Goh</author>
<author confidence="0.998156">Xiaojie Wang</author>
<author confidence="0.998156">Yuji</author>
<affiliation confidence="0.9985505">Graduate School of Information Nara Institute of Science and Technology,</affiliation>
<abstract confidence="0.997076748201439">Our proposed method is to use a Hidden Markov Model-based word segmenter and a Support Vector Machine-based chunker for Chinese word segmentation. Firstly, input sentences are analyzed by the Hidden Markov Model-based word segmenter. The word segmenter produces n-best word candidates together with some class information and confidence measures. Secondly, the extracted words are broken into character units and each character is annotated with the possible word class and the position in the word, which are then used as the features for the chunker. Finally, the Support Vector Machine-based chunker brings character units together into words so as to determine the word boundaries. 1 Methods We participate in the closed test for all four sets of data in Chinese Word Segmentation Bakeoff. Our method is based on the following two steps: 1. The input sentence is segmented into a word sequence by Hidden Markov Model-based word segmenter. The segmenter assigns a word class with a confidence measure for each word at the hidden states. The model is trained by Baum-Welch algorithm. 2. Each character in the sentence is annotated with the word class tag and the position in the word. The n-best word candidates derived from the word segmenter are also extracted as the features. A support vector machine-based chunker corrects the errors made by the segmenter using the extracted features. We will describe each of these steps in more details. 1.1 Hidden Markov Model-based Word Segmenter Our word segmenter is based on Hidden Markov Model (HMM). We first decide the number of hidden states (classes) and assume that the each word can belong to all the classes with some probability. The problem is deas a search for the sequence of word classes ... , given a word sequence ... , The is to find a given input maximizes the following probability: assume that the word probability constrained only by its word class, and that the class probconstrained only by the class of the preceding word. These probabilities are estimated by the Baum-Welch algorithm using the training material (See (Manning and Sch¨utze., 1999)). The learning process is based on the Baum-Welch algorithm and is the same as the well-known use of HMM for part-of-speech tagging problem, except that the number of states are arbitrarily determined and the initial probabilities are randomly assigned in our model. 1.2 Correction by Support Vector Machine-based Chunker While the HMM-based word segmenter achieves good accuracy for known words, it cannot identify compound words and out-of-vocabulary words. Therefore, we introduce a Support Vector Machine(below SVM)-based chunker (Kudo and Matsumoto, 2001) to cover the errors made by the segmenter. The SVM-based chunker re-assigns new word boundaries to the output of the segmenter. An SVM (Vapnik, 1998) is a binary classifier. Suppose we have a set of training data for a binary class . . . , where is a vector of the sample in the training data and W,C the label of the sample. The goal is to a decision function which accurately predicts unseen An SVM classifier gives a decision function an input vector = + = +1 that a positive member, and = that a negative member. The veccalled support vectors, which receive a nonweight Support vectors and the parameters are determined by solving a quadratic programming proba kernel function which maps vectors into a higher dimensional space. We use a polynomial of degree 2 given by = (1 + The SVM classifier determines the position tag for each character. We introduce the word class tag as the feature, which is generated by the word segmenter. Since we perform chunking by character units, the feature used by the classifier will be the information for the character unit. The training data for our SVM-based chunker is constructed from the output of the HMM-based word segmenter defined in the previous section. In the current setting, the HMM produces all the possible tags (class labels) for each of the word within a predefined probability bound. All the words in the output are then segmented into characters, and each of the characters is tagged with pairs of a word class and a position tag. For example, in the paired tag “0-B”, “0” is a class label of the word which the character belongs to and “B” indicates the character’s position in the word. The number of classes is determined in advance of the HMM learning. The position tag consists of the following four tags (S/B/E/I): S means a single-character word; B is the first character in a multi-character word; E is the last character in a multi-character word; I is the intermediate character in a multi-character word longer than 2 characters. As shown in Figure 1, we set the HMM-based word segmenter to produce the classes of n-best word candidates to take into account multiple possibility of word boundaries. The correct word boundary can be defined by assigning either of two kinds of tags to each of the characters. Look at the rightmost column of Figure 1 named as “Chunker Outputs.” The label “B” in this column shows that the is the first character of a and “I” shows that the character is the other part of a word. This means that the preceding positions of “B” tags are the word boundaries. Those two tags correspond to the two classes of the SVM chunker: In the training (and test) phrase, we use window size of two characters to the left and right direction to learn (and estimate) the class for a character. For example, the shadowed parts in Figure 1 are used as the Figure 1: The Extracted Features for the Chunker features to learn (or estimate) the word boundary tag “I” for the character “ ”. 2 Model Validation To find out the best setting of learning, we would like to determine “the number of word classes” and “the depth of n-best word candidates” by using some sort of confidence measure. We perform validation experiments for these two types of parameters by using the training material provided. 2.1 Validation Tests for HMM-based Word Segmenter The first validation experiment is to determine “the number of word classes” of the HMM. 80% of the material is used for the HMM training, and the other 20% is used as the validation set. We test two settings for the number of classes – 5 &amp; 10. The results are shown in Table 1.</abstract>
<title confidence="0.451949">Table 1: Validation Results for HMM</title>
<author confidence="0.412005">F Prec</author>
<address confidence="0.59246825">AS 5 0.845 0.768 0.804 AS 10 0.900 0.857 0.878 CTB 5 0.909 0.844 0.875 CTB 10 0.912 0.848 0.879</address>
<phone confidence="0.5913">HK 5 0.867 0.742 0.799 HK 10 0.867 0.741 0.799 PK 5 0.942 0.902 0.921</phone>
<abstract confidence="0.843243578947368">PK 10 0.944 0.905 0.924 In most cases, models perform slightly better with the increasing of the number of classes. When the corpus size is large like the Academia Sinica data, this tendency becomes more significant. Whereas it is known that the Baum Welch algorithm is very sensitive to the initialization of the classes, we randomly assigned the initial classes without making much effort. There are two reasons: (1) Since the word segmenter outputs are used as the clues to the chunker in our method, we only need some consistent class annotations. (2) The initial classes did not affect on the word segmentation accuracy in our pilot experiments. Table 4: Validation Results (PK) for Chunking 5 1 5 2 5 3 5 4 10 1</abstract>
<phone confidence="0.573320333333333">10 2 10 3 10 4</phone>
<address confidence="0.623118285714286">Rec. Prec. F 0.960 0.934 0.947 0.961 0.935 0.948 0.962 0.936 0.949 0.962 0.935 0.948 0.961 0.932 0.946 0.962 0.935 0.948</address>
<phone confidence="0.538128">0.961 0.934 0.947 0.961 0.934 0.947</phone>
<abstract confidence="0.99527">2.2 Validation Tests for SVM-based Chunker The second validation test is for the chunking model to determine both “the number of word classes” and “the depth of the n-best candidates”. 80% of the material used for the HMM training, another 10% is used for the chunking model training and the last 10% is used for the validation test. The results are shown in Table 2, 3 and 4. Since the training of this model is timeand resourceconsuming, the Academia Sinica data being very large could not get enough time to finish the validation test.</abstract>
<title confidence="0.6668385">Table 2: Validation Results (CTB) for Chunking Table 3: Validation Results (HK) for Chunking</title>
<address confidence="0.521939875">Rec. Prec. F 0.853 0.793 0.822 0.859 0.799 0.828 0.859 0.799 0.828 0.859 0.800 0.828 0.856 0.793 0.823 0.858 0.797 0.826 0.857 0.796 0.826</address>
<phone confidence="0.437111">0.858 0.797 0.826</phone>
<abstract confidence="0.918903878048781">The results show that the chunker actually improves the word segmentation accuracy compared with the output of the HMM word segmenter for these three data sets. The segmentation errors made by the word segmenter for compound words and unknown words are corrected. The improvement in Chinese Treebank (CTB) data set is significant, because the data set contains many compound words. There is no significant difference in the results between the different depths of n-best answers. Still, we choose the best model for the test materials among them. If we need to have a faster analyzer, we should employ only the best answer of the word segmentation. For the HMM, the larger number of classes tends to get better accuracy than smaller ones. However, for the chunking model, the result is the other way round. The model with the smaller number of classes gets slightly better accuracy. So, there should be trade-off between smaller and larger number of classes. 3 Final Models for Test Material For the final models, 80% of the training material is used for HMM training and 100% of the material is used for the chunking model training. The parameters, namely “the number of word classes” and “the depth of n-best word candidates”, are determined by the validation tests described in Section 2. While there is no significant difference between the depths of n-best answers, we choose the best model among them for the testing. The parameters are shown in Table 7. We cannot create the model using all the original Academia Sinica data because of its large size. Therefore, we use 80% of the data for HMM training (5 classes) and only 10% for chunking model training (with only the best candidates). Table 7: The Models for the Test Material – with respect to F-Measure in Our Validation Test 5 1 5 2 5 3 5 4 10 1</abstract>
<phone confidence="0.598938666666667">10 2 10 3 10 4</phone>
<affiliation confidence="0.369458">Rec. Prec. F</affiliation>
<address confidence="0.64111325">0.957 0.930 0.943 0.957 0.931 0.944 0.957 0.930 0.943 0.957 0.930 0.943 0.956 0.929 0.943 0.957 0.928 0.942 0.956 0.929 0.942 0.955 0.928 0.941</address>
<phone confidence="0.640616">5 1 5 2 5 4 5 3</phone>
<title confidence="0.649247571428571">Data AS CTB HK PK F N/A</title>
<date confidence="0.440745333333333">0.943 0.828 0.948</date>
<phone confidence="0.544671875">5 1 5 2 5 3 5 4 10 1 10 2 10 3 10 4</phone>
<note confidence="0.746862928571429">Table 5: Throughput Speeds (characters per second) Data Word Seg. (# of words) Fea. Ext. (n-best) Chunker (# of SV) Total Speed AS 57000 (462750) 7640 (Only Best) 279 (96452) 241 CTB 54400 (77324) 4040 (to 2nd Best) 894 (16736) 671 HK 38900 (93231) 3870 (to 4th Best) 649 (14904) 524 PK 57400 (215865) 6209 (to 3rd Best) 254 (49736) 200 Table 6: Results for the Test Materials Data T. Rec. T. Prec. F OOV Rec. IV Rec. Ranking AS 0.944 0.945 0.945 0.574 0.952 3rd/6 CTB 0.852 0.807 0.829 0.412 0.949 8th/10 HK 0.940 0.908 0.924 0.415 0.980 5th/6 PK 0.933 0.916 0.924 0.357 0.975 2nd/4 4 Throughput Speeds As described, our system is based on three modules:</note>
<abstract confidence="0.985895233333334">HMM-based word segmenter, Feature extractor and SVM-based chunker. The word segmenter is composed in C/C++) (Matsumoto et. al., 2003) which is adopted for GB/Big5 encoding. The feature extractor is written in Perl. The SVM-based chunker is by in C++) (Kudo and Matsumoto, 2001). 5 shows the speeds 1of the three modules individually and of the total system. “# of words” means the size of the word segmenter lexicon. Note that, if a word belongs to more than one class, we regard them as different words in our definition. “# of SV” means the number of support vectors in the chunker. The total system speed depends highly on that of the chunker. It is known that the speed of SVM classifiers depends on the number of support vectors and the number of features. 5 Conclusion We presented our method for Chinese Word Segmentation Bakeoff in 2nd SIGHAN Workshop. The results for the test materials are shown in Table 6. The proposed method is purely corpus-based statistical/machine learning method. Although we did not incorporate any heuristic rules (e.g. part-of-speeches, functional words and concatenation for numbers) into the model, the method achieved considerable accuracy for the word segmentation task. Acknowledgments We thank Mr. Taku Kudo of NAIST for his development the SVM-based chunker throughput speeds are measured on a machine: In-</abstract>
<note confidence="0.813480352941176">Xeon(TM) CPU 2.80GHz Memory 4GB, RedHat Linux 9. References T. Kudo and Y. Matsumoto. 2001. Chunking with Sup- Vector Machines. In ofNAACL pages 192–199. D. Manning and H. Sch¨utze. 1999. of Natural Language Processing. 9. Markov Models, pages 317–340. Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hirano, K. Takaoka and M. Asahara 2003. Morphological Analyzer ChaSen-2.3.0 Users Manual Tech. Report. Nara Institute of Science and Technology, Japan. L. A. Ramshaw and M. P. Marcus. 1995 Text chunking transformation-bases learning In of the 3rd on Very Large pages 83–94. N. Vapnik. 1998. Learning Theory.</note>
<intro confidence="0.820955">Wiley-Interscience Publication.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Chunking with Support Vector Machines.</title>
<date>2001</date>
<booktitle>In Proc. ofNAACL</booktitle>
<pages>192--199</pages>
<contexts>
<context position="3048" citStr="Kudo and Matsumoto, 2001" startWordPosition="495" endWordPosition="498">m using the training material (See (Manning and Sch¨utze., 1999)). The learning process is based on the Baum-Welch algorithm and is the same as the well-known use of HMM for part-of-speech tagging problem, except that the number of states are arbitrarily determined and the initial probabilities are randomly assigned in our model. 1.2 Correction by Support Vector Machine-based Chunker While the HMM-based word segmenter achieves good accuracy for known words, it cannot identify compound words and out-of-vocabulary words. Therefore, we introduce a Support Vector Machine(below SVM)-based chunker (Kudo and Matsumoto, 2001) to cover the errors made by the segmenter. The SVM-based chunker re-assigns new word boundaries to the output of the segmenter. An SVM (Vapnik, 1998) is a binary classifier. Suppose we have a set of training data for a binary class problem: (xl, yl), . . . , (xN, yN), where xi E Rn is a feature vector of the i th sample in the training data and arg max W,C yi E 1+1, −11 is the label of the sample. The goal is to find a decision function which accurately predicts y for an unseen x. An SVM classifier gives a decision function f(x) for an input vector x where f(x) = sign( � αiyiK(x, zi) + b). z;</context>
<context position="11971" citStr="Kudo and Matsumoto, 2001" startWordPosition="2122" endWordPosition="2126">s for the Test Materials Data T. Rec. T. Prec. F OOV Rec. IV Rec. Ranking AS 0.944 0.945 0.945 0.574 0.952 3rd/6 CTB 0.852 0.807 0.829 0.412 0.949 8th/10 HK 0.940 0.908 0.924 0.415 0.980 5th/6 PK 0.933 0.916 0.924 0.357 0.975 2nd/4 4 Throughput Speeds As described, our system is based on three modules: HMM-based word segmenter, Feature extractor and SVM-based chunker. The word segmenter is composed by ChaSen (written in C/C++) (Matsumoto et. al., 2003) which is adopted for GB/Big5 encoding. The feature extractor is written in Perl. The SVM-based chunker is composed by YamCha (written in C++) (Kudo and Matsumoto, 2001). Table 5 shows the speeds 1 of the three modules individually and of the total system. “# of words” means the size of the word segmenter lexicon. Note that, if a word belongs to more than one class, we regard them as different words in our definition. “# of SV” means the number of support vectors in the chunker. The total system speed depends highly on that of the chunker. It is known that the speed of SVM classifiers depends on the number of support vectors and the number of features. 5 Conclusion We presented our method for Chinese Word Segmentation Bakeoff in 2nd SIGHAN Workshop. The resul</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>T. Kudo and Y. Matsumoto. 2001. Chunking with Support Vector Machines. In Proc. ofNAACL 2001, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Sch¨utze</author>
</authors>
<title>Foundation of Statistical Natural Language Processing. Chapter 9. Markov Models,</title>
<date>1999</date>
<pages>317--340</pages>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>C. D. Manning and H. Sch¨utze. 1999. Foundation of Statistical Natural Language Processing. Chapter 9. Markov Models, pages 317–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>A Kitauchi</author>
<author>T Yamashita</author>
<author>Y Hirano</author>
<author>K Takaoka</author>
<author>M Asahara</author>
</authors>
<date>2003</date>
<booktitle>Morphological Analyzer ChaSen-2.3.0 Users Manual Tech. Report. Nara Institute of Science and Technology,</booktitle>
<marker>Matsumoto, Kitauchi, Yamashita, Hirano, Takaoka, Asahara, 2003</marker>
<rawString>Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hirano, K. Takaoka and M. Asahara 2003. Morphological Analyzer ChaSen-2.3.0 Users Manual Tech. Report. Nara Institute of Science and Technology, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-bases learning</title>
<date>1995</date>
<booktitle>In Proc. of the 3rd Workshop on Very Large Corpora,</booktitle>
<pages>83--94</pages>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. P. Marcus. 1995 Text chunking using transformation-bases learning In Proc. of the 3rd Workshop on Very Large Corpora, pages 83–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>Statistical Learning Theory. A Wiley-Interscience Publication.</title>
<date>1998</date>
<contexts>
<context position="3198" citStr="Vapnik, 1998" startWordPosition="524" endWordPosition="525"> of HMM for part-of-speech tagging problem, except that the number of states are arbitrarily determined and the initial probabilities are randomly assigned in our model. 1.2 Correction by Support Vector Machine-based Chunker While the HMM-based word segmenter achieves good accuracy for known words, it cannot identify compound words and out-of-vocabulary words. Therefore, we introduce a Support Vector Machine(below SVM)-based chunker (Kudo and Matsumoto, 2001) to cover the errors made by the segmenter. The SVM-based chunker re-assigns new word boundaries to the output of the segmenter. An SVM (Vapnik, 1998) is a binary classifier. Suppose we have a set of training data for a binary class problem: (xl, yl), . . . , (xN, yN), where xi E Rn is a feature vector of the i th sample in the training data and arg max W,C yi E 1+1, −11 is the label of the sample. The goal is to find a decision function which accurately predicts y for an unseen x. An SVM classifier gives a decision function f(x) for an input vector x where f(x) = sign( � αiyiK(x, zi) + b). z;∈SV f(x) = +1 means that x is a positive member, and f(x) = −1 means that x is a negative member. The vectors zi are called support vectors, which rec</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. N. Vapnik. 1998. Statistical Learning Theory. A Wiley-Interscience Publication.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>