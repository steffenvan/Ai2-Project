<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.78424">
Adjective based inference∗
</title>
<author confidence="0.79098">
Marilisa Amoia
</author>
<affiliation confidence="0.698111">
INRIA/Universit´e de Nancy 1 &amp;
University of the Saarland
Saarbr¨ucken Germany
</affiliation>
<email confidence="0.966826">
amoia@coli.uni-sb.de
</email>
<author confidence="0.651083">
Claire Gardent
</author>
<affiliation confidence="0.57289">
CNRS/Loria
</affiliation>
<address confidence="0.5303345">
Campus Scientifique BP 239
54506 Vandoeuvre-les-Nancy, France
</address>
<email confidence="0.996183">
claire.gardent@loria.fr
</email>
<sectionHeader confidence="0.994743" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.954949083333333">
In this paper, we propose a fine grained
classification of english adjectives geared
at modeling the distinct inference patterns
licensed by each adjective class. We show
how it can be implemented in description
logic and illustrate the predictions made
by a series of examples. The proposal has
been implemented using Description logic
as a semantic representation language and
the prediction verified using the DL theo-
rem prover RACER.
Topics: Textual Entailment, Adjectival Semantics
</bodyText>
<sectionHeader confidence="0.99696" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991840157894737">
Understanding a text is one of the ultimate goals
of computational linguistics. To achieve this goal,
systems need to be developed which can construct
a meaning representation for any given text and
which furthermore, can reason about the meaning
of a text. As is convincingly argued in (Ido Dagan
and Magnini, 2005), one of the major inference
task involved in that reasoning is the entailment
recognition task:
Does text T1 entail text T2?
Indeed entailment recognition can be used to
determine whether a text fragment answers a
question (e.g., in question answering application),
whether a query is entailed by a relevant document
(in information retrieval), whether a text fragment
entails a specific information nugget (in informa-
tion extraction), etc.
Because the Pascal RTE challenge focuses on
real text, the participating systems must be robust
that is, they must be able to handle unconstrained
∗We thank la R´egion Lorraine, INRIA and the University
of Sarrebruecken for partially funding the research presented
in this paper.
input. Most systems therefore are based on sta-
tistical methods (e.g., stochastic parsing and lex-
ical distance or word overlap for semantic simi-
larity) and few provide for a principled integra-
tion of lexical and compositional semantics. On
the other hand, one of the participant teams has
shown that roughly 50% of the RTE cases could
be handled correctly by a system that would ade-
quately cover semantic entailments that are either
syntax based (e.g., active/passive) or lexical se-
mantics based (e.g., bicycle/bike). Given that the
overall system accuracies hovered between 50 and
60 percent with a baseline of 50 %1, this suggests
that a better integration of syntax, compositional
and lexical semantics might improve entailment
recognition accuracy.
In this paper, we consider the case of adjectives
and, building on approaches like those described
in (Raskin and Nirenburg, 1995; Peters and Pe-
ters, 2000), we propose a classification of adjec-
tives which can account for the entailment patterns
that are supported by the interaction of their lexi-
cal and of their compositional semantics. We start
by defining a classification schema for adjectives
based on their syntactic and semantic properties.
We then associate with each class a set of axioms
schemas which translate the knowledge about lex-
ical relations (i.e. antonymy) the adjectives of the
class are involved in by extracting this information
from WordNet (Miller, 1998) and a set of seman-
tic construction rules and we show that these cor-
rectly predicts the observed entailment patterns.
For instance, the approach will account for the fol-
lowing (non)-entailment cases:
</bodyText>
<note confidence="0.6514545">
(1) a. John frightened the child
|= The child is afraid
</note>
<footnote confidence="0.925859333333333">
150% of the cases were true entailment and 50% were
false ones, hence tossing a coin would get half of the cases
right.
</footnote>
<page confidence="0.385197">
20 KRAQ06
</page>
<listItem confidence="0.9995604">
b. Peter claims that John is a murderer
�= John is an alledged murderer
K John is a murderer
c. This is a fake bicycle
�= This is a false bike
�= This is not a real bike
K This is a bike
d. John is not awake
�= John sleeps
K John does not sleep
</listItem>
<bodyText confidence="0.999719166666667">
The approach is implemented using Description
Logic as a semantic representation language and
tested on a hand-built semantic test suite of ap-
proximately 1 000 items. In the latter part of the
paper we discuss this testsuite and the philosophy
behind it.
</bodyText>
<sectionHeader confidence="0.916304" genericHeader="method">
2 A fine grained classification for
adjectives
</sectionHeader>
<bodyText confidence="0.9999887">
As mentioned above, we propose a classification
of adjectives based on their lexical, their model
theoretic and their morpho-derivational properties.
To facilitate the link with compositional semantics
(the construction of a meaning representation for
sentences containing adjectives), we also take into
account syntactic properties such as the predica-
tive/attributive or the static/dynamic distinction.
We now detail each of these properties. The over-
all categorisation system is given in Figure 1.
</bodyText>
<subsectionHeader confidence="0.998756">
2.1 Model theoretic properties
</subsectionHeader>
<bodyText confidence="0.999985714285714">
The main criteria for classification are given by
(Kamp, 1975; Kamp and Partee, 1995) seman-
tic classification of adjectives which is based on
whether it is possible to infer from the Adj+N
combination the Adj or the N denotation.
Intersective adjectives (e.g., red) licence the
following inference inference patterns:
</bodyText>
<equation confidence="0.94792225">
A + N A
A + N N
For instance, if X is a red car then X is a car and
X is red
</equation>
<bodyText confidence="0.9765635">
Subsective adjectives (e.g., big) licence the
following inference pattern:
</bodyText>
<equation confidence="0.935609">
A + N �= N
For instance, ifX is a big mouse, then X is a mouse
but it is not necessarily true X is big
Privative adjectives licence the inference pattern:
A + N �= -,N
</equation>
<bodyText confidence="0.8472166">
For instance, ifX is a fake gun then X is not a gun
Plain non-subsective adjectives (e.g., alledged)
do not licence any inference
For instance, ifX is an alleged murderer then it is
unknown whether X is a murderer or not
</bodyText>
<subsectionHeader confidence="0.999601">
2.2 Lexical semantics
</subsectionHeader>
<bodyText confidence="0.999959375">
From the lexical semantics literature, we take
one additional classification criterion namely
antonymy. As described in (Cruse, 1986), this
term covers different kinds of opposite polarity re-
lations between adjectives namly, binary opposi-
tion, contraries and multiple oppositions.
Binary oppositions covers pairs such as wet/dry
which license the following inference pattern:
</bodyText>
<equation confidence="0.973844714285714">
A1 - -,A2 n -,A1 - A2
So that in particular:
wet - -,dry n -,wet - dry
Contraries are pairs such as long/short where the
implication is unidirectional:
A1 -,A2 n -,A1 A2
A2 -,A1 n -,A2 A1
</equation>
<bodyText confidence="0.8346576">
and in particular:
long �= -,short n -,long K short
short �= -,long n -,short K long
Multiple oppositions involve a finite set of adjec-
tives (e.g., linguistic/economic/mathematical/... )
which are pairwise mutually exclusive. For a set
of opposed adjectives Al ... An, the following ax-
ioms schemas will be licensed:
bi, j s.t. 1 G i, j G and i =� j
AZ �= -,Aj and -,AZ K Aj
</bodyText>
<subsectionHeader confidence="0.847523">
2.2.1 Derivational morphology
</subsectionHeader>
<bodyText confidence="0.9999088">
We also take into account related forms that is,
whether there exists a verb (Va) or a noun that is
semantically related to the adjectives being con-
sidered. Moreover, for nominalizations we distin-
guish whether the morphologically related noun is
an event noun (Ne), a noun denoting a theta role
of the related verb (Ng) or a non-event noun (Na).
As we shall see, this permits capturing entail-
ment relations between sentences containing mor-
phoderivational variants such as for instance :
</bodyText>
<page confidence="0.871705">
21 KRAQ06
</page>
<listItem confidence="0.996819166666667">
(2) a. John is asleep (Adj — Va)
|= John sleeps
b. John is absent (Adj — Nθ)
|= John is the absentee
c. John is deeply asleep (Adj — Ne)
|= John’s sleep is deep
</listItem>
<subsectionHeader confidence="0.761633">
2.2.2 Syntactic properties
</subsectionHeader>
<bodyText confidence="0.99862132">
To better support the syntax/semantic interface,
we refine the adjectives classes distinguishable on
the basis of the above criteria with the following
syntactic ones taken from (Quirk et al., 1985).
Attributiveness/Predicativeness. English adjec-
tives can be divided in adjectives which can be
used only predicatively (such as alone), adjectives
which can be used only attributively (such as me-
chanical in mechanical enginner) and adjectives
which can be used in both constructions such as
red.
Modifiability by very. We distinguish between
adjectives such as nice which can be modified by
very (i.e. very nice) and adjectives such as alleged
which cannot (*very alleged).
Gradability. We distinguish between adjectives
such as big which express gradable properties and
have comparative and superlative forms (bigger,
biggest) and adjectives such as rectangular which
don’t (*more rectangular).
Staticity/Dynamicity. Dynamic adjectives can be
used in imperative constructions and in the pro-
gressive form (Be reasonable, He is being reason-
able), static adjectives cannot (*Be short, He is be-
ing short).
</bodyText>
<sectionHeader confidence="0.647233" genericHeader="method">
3 Semantic Classes and textual
</sectionHeader>
<subsectionHeader confidence="0.806488">
entailment recognition
</subsectionHeader>
<bodyText confidence="0.993623723404255">
In order to build our classification, we have anal-
ysed a set of about 300 english adjectives each
of which was manually mapped to the WordNet
synset correspondent to the more frequent mean-
ing of the adjective. In some case, when an ad-
jective presents polysemic forms which belong to
different semantic classes more than one form has
been considered. For example, for the adjective
civil we consider two senses/forms civil1 (syn-
onym of polite, as in civil man) and civil2 (as in
civil engineer) which belong to different semantic
classes, the first being intersective and the second
subsective. As Figure 1 shows, the proposed clas-
sification includes 15 adjective classes, each with
distinct syntactic and semantic properties.
To account for these differences, we define for
each class a set of axiom schemas capturing the
model theoretic, lexical semantics and morpho-
derivational properties of that class. Lexical se-
mantics and morpho-derivational information are
derived from WordNet. For example, the axioms
describing antonymy are obtained by extracting
from WordNet the antonyms of a particular adjec-
tive and then by considering the direction of the
entailment relevant for the class the adjective be-
longs to:
asleep ≡ wake vs. polite ❁rude
Morpho-derivational information are derived from
WordNet by extracting the derivationally related
forms for the given adjective and then iterating the
extraction on nouns and verbs in order to obtain
information about their antonyms and hyponyms.
For scalar adjective like tall, WordNet contains
also a relation is a value of which offers a
pointer to the noun concept the adjective is a value
of. Moreover, WordNet links the noun concept to
a list of attributes which describe the scalar prop-
erty it represents. For example, the adjective tall
is a value of {stature,height} and attributes
of {stature,height} are tall and short.
Based on some basic syntactic patterns, we then
show that these axioms predict the observed tex-
tual entailment patterns for that class.
Before we illustrate this approach by means of
some example, we first show how we capture log-
ical entailment between NL semantic representa-
tions in a description logic setting.
</bodyText>
<subsectionHeader confidence="0.998094">
3.1 Using description logic to check
entailment between NL sentences
</subsectionHeader>
<bodyText confidence="0.9897699375">
As argued in (Gardent and Jacquey, 2003), de-
scription logic (DL) is an intuitive framework
within which to perform lexical reasoning: it is
efficient (basic versions of description logics are
decidable), it is tailored to reason about complex
taxonomies (taxonomies of descriptions) and it
is equipped with powerful, freely available auto-
mated provers (such as RACER, (Volker Haarslev,
2001)). For these reasons, we are here exploring a
DL encoding of the entailment recognition task for
the set of examples we are considering.The partic-
ular language we assume has the following syntax.
C, D --+ A|T|I|-A  |C n D  |C u D  |`dR.C  |3R.C
The semantics of this language is given below with
A the domain of interpretation and I the interpre-
tation function which assigns to every atomic con-
</bodyText>
<page confidence="0.674875">
22 KRAQ06
</page>
<table confidence="0.9947286875">
Adjective Class Predicative/Attributive Modifiable by very Gradability static/dynamic Antonymy Related forms Semantic class
Class 1: afloat predicative-only - - static multi-opposition Va, Ne, No intersective
Class 2: asleep predicative-only + - static binary-opposition Va, Ne, No intersective
Class 3: polite both + + dynamic contraries Na intersective
Class 4: dry both + + static binary-opposition Va, Ne, No intersective
Class 5: open both - - dynamic binary-opposition Va, Ne, No intersective
Class 6: male both - - static multi-opposition Na, Ne, intersective
Class 7: authentic both + - static binary-opposition Ne intersective
Class 8: big both + + static contraries Ne subsective
Class 9: good both + + dynamic contraries Ne subsective
Class 10: cultural attributive-only - - static multi-opposition Na subsective
Class 11: recent attributive-only + - static multi-opposition Ne subsective
Class 12: fake both - - static binary-opposition Va,Ne privative
Class 13: former attributive-only - - static multi-opposition privative
Class 14: questionable both + - static contraries Va, Ne plain non-subsective
Class 15: alleged attributive-only - - static contraries Va plain non-subsective
</table>
<figureCaption confidence="0.978885">
Figure 1: Classes of Adjectives
</figureCaption>
<bodyText confidence="0.540478">
cept A, a set AI ⊆ A and to every atomic role R
a binary relation RI ⊆ A × A.
</bodyText>
<equation confidence="0.996145">
&gt;I = A
⊥I = ∅
(¬A)I = A\AI
(C u D)I = CI ∩ DI
(C t D)I = CI ∪ DI
(∀R.C)I = {a ∈ A  |∀b(a, b) ∈ RI → b ∈ CI}
(∃R.C)I = {a ∈ A  |∃b ∈ CI ∧ (a, b) ∈ RIn}
</equation>
<bodyText confidence="0.999529111111111">
Now one basic problem with using DL to check
entailment between NL expressions, is that DL
formulae are “directional” in that they refer to a
given set of individuals. For instance the sentence
The boat is floating might be represented by either
of the two formulae given in 3 but these two for-
mulae do not stand in an entailment relation (since
they refer to different kind of objects namely float-
ing event of a boat in 3a and boats that float in 3b).
</bodyText>
<listItem confidence="0.9763155">
(3) a. float u∃theme.boat
b. boat u∃theme−1.float
</listItem>
<bodyText confidence="0.6374035">
To remedy this shortcoming, we introduce the
notion of a rotation. Given a DL formula which
only contains conjunction (disjunction is trans-
lated in DL as different formulas)
</bodyText>
<figure confidence="0.833932428571429">
Φ = ui=1,n Eventi uj=1,m ∃Rj.Typej
a rotation of this formula is defined as:
1. Φ
2. ∀j ∈ {1, ..., m} :
Typej u ∃R−1
j .(ui=1,nEventi u1&lt;k&lt;j,j&lt;k&lt;m
∃Rk.Typek)
</figure>
<bodyText confidence="0.688812">
so that the formula:
Event1u Event2 u ...u Eventn u∃R1.Type1 u∃R2.Type2 ...
u∃Rn.Typen
corresponds to the following n Rotations each of
which describe the same situation from the point
of view of a particular type
</bodyText>
<figure confidence="0.8286995">
0. Event u∃R1.Type1 u∃R2.Type2 ... u∃Rn.Typen
⊆ Event
1. Type1 u∃R−1
1 .(Event u∃R2.Type2 ... u∃Rn.Typen)
⊆ Type1
2. Type2 u∃R−1
2 .(Event u∃R1.Type1 ... u∃Rn.Typen)
⊆ Type2
...
n. Typen u∃R−1
n .(Event u∃R1.Type1 ... u∃Rn−1.Typen−1)
⊆ Typen
</figure>
<bodyText confidence="0.997499">
So for example, the sentence Mary knows that
John is the inventor of the radio will be repre-
sented as a predicate logic formula
</bodyText>
<equation confidence="0.999701666666667">
∃x1mary(x1) ∧ ∃x2john(x2) ∧ ∃x3radio(x3) ∧ ∃e1know(e1) ∧
∃agent(e1, x1)∧∃topic(e1, e2)∧∃e2invent(e2)∧agent(e2, x2)∧
patient(e2,x3)
</equation>
<bodyText confidence="0.947372916666667">
the denotation of this PL formula corresponds to
the set of individuals {x1, x2, x3} ∪ {e1, e2}. The
corresponding DL representation will be the un-
derspecified representation
know u∃ agent.mary u∃ topic.( invent u∃agent.john u∃ pa-
tient.radio)
the denotation of which corresponds to the set
{e1} and all its rotations which permit to access
the other sets of individuals asserted in the sen-
tence. Thus for example, the set {x1} which
describes the individual Mary can be accessed
through the following rotation:
</bodyText>
<equation confidence="0.7192095">
Rotation1: mary u∃ agent−1.(know u∃ topic.( invent
u∃agent.john u∃ patient.radio))
</equation>
<bodyText confidence="0.9737754">
Finally, we say that an arbitrary for-
mula/representation 4b1 implies the formula
4b2 iff it is possible to find a rotation Rotationi of
4b1 the denotation of which describes a subset of
the denotation of 4b2:
</bodyText>
<sectionHeader confidence="0.546776" genericHeader="method">
Definition
</sectionHeader>
<footnote confidence="0.713143">
4b1 |_— 4b2 iff ∃i.Rotationi�4b1) v 4b2 (1)
</footnote>
<page confidence="0.564604">
23 KRAQ06
</page>
<subsectionHeader confidence="0.729527">
3.2 Example class axioms and derivations
</subsectionHeader>
<bodyText confidence="0.999792666666667">
We now illustrate our approach by looking at two
classes in more detail namely, class 1 and class 8.
We make the following assumptions about the
syntax/semantic interface that is, about the seman-
tic representations associated with given sentence
patterns.
</bodyText>
<subsectionHeader confidence="0.660258">
3.2.1 Class 1
</subsectionHeader>
<bodyText confidence="0.997337">
Syntactically, Class 1 contains adjectives like
adrift,afloat,aground which can only be used pred-
icatively, are non gradable and cannot be modified
by very. Semantically, they behave like intersec-
tive adjectives which enter in multiple opposition
relations with other adjectives. They are further-
more morphologically derived from verbs and can
be nominalized. To reflect these semantic proper-
ties we use the following axioms.
Model theoretic semantics. Adjectives of class
1 are intersective adjective. They will thus li-
cence the correponding inference patterns namely:
</bodyText>
<equation confidence="0.886074">
A + N |= A (2)
A + N |= N (3)
</equation>
<bodyText confidence="0.8049245">
Lexical semantics. Adjectives of class 1 enter in
multiple opposition relations. Hence For instance:
</bodyText>
<equation confidence="0.664414">
afloat |= ¬ aground ∧¬ afloat 6|= aground
aground |= ¬ afloat ∧¬ aground 6|= afloat
sunken |= ¬ afloat ∧¬ afloat 6|= sunken
</equation>
<bodyText confidence="0.960453777777778">
afloat |= ¬ sunken ∧¬ sunken 6|= afloat
Morpho-derivational semantics. Adjectives in
Class 1 can be related to both nouns and verbs.
Thus, for example the adjective afloat in WordNet
is related to the noun floating which is related to
the verb float, by assuming that the semantics as-
signed to the verb float is float(e), theme(e,a), the
adjective afloat is assigned the following seman-
tics:
</bodyText>
<equation confidence="0.98638076">
afloat ≡ ∃ Theme−&apos;.float
This is encoded in the following axiom schemas:
MDR 1. Adj1 C ¬ Adj2 If Adj1 = Anto(Adj2)
e.g., afloat C ¬ sunken
MDR 2. Adj1 ≡ ∃ Theme−1.V1 If Adj1 is related to V1
e.g.,afloat ≡ ∃ Theme−1.float
MDR 3. V1 C ¬ V2 If V1 = Anto(V2)
e.g., float C ¬ sink
MDR 4. N1 ≡ V1 If Adj1 is related to an evt denoting N1
e.g., floating ≡ float
MDR 5. N1 C ¬ N2 If N1 is an antonym of N2
e.g., floating C ¬ sinking
MDR 6. N11 ≡ ∃ Theme−1.V1 If Adj1 is related to a
noun N11 denoting the theme role of the verb V1
e.g., floater ≡ ∃ Theme−1.float
SCR 1. NP toBe Adj
ADJ u NP
SCR 2. NP toBe clearly Adj
ADJ u NP
SCR 3. Ni[+event] of NP is clear
V i u ∃theme.NP
SCR 4. Nii[-event] is clear
∃theme−1.V i
SCR 5. NP toBe V[+ing].
V u ∃Theme.NP
</equation>
<bodyText confidence="0.949946666666667">
Given the above axiom schemas and semantic
constructions rules, the following inference pat-
terns can be handled:
</bodyText>
<figure confidence="0.991589413793104">
1. ADJ1 + N |= N
Ex. This boat is afloat. |= This is a boat.
2. ADJ1 + N |= ADJ1
Ex. This boat is afloat. |= This is afloat.
3. ADJ1 + N 6|= ¬ N
Ex. The boat is afloat. 6|= This not a boat.
4. ADJ1 + N |= ¬ ADJ2 u N
Ex. The boat is afloat. |= The boat is not sunken.
5. ¬ ADJ1 + N 6|= ADJ2 u N
Ex. The boat is not afloat. 6|= The boat is sunken.
6. ADJ1 + N |= N u∃theme−1.V 1
Ex. The boat is afloat. |= The boat is the floater.
7. ADJ1 + N |= V1 u∃theme.N
Ex. The boat is afloat. |= The boat is floating.
8. ADJ1 + N |= N1 u∃theme.N
Ex. This boat is clearly afloat. |= The floating of the
boat is clear.
9. ADJ1 + N |= N u∃theme−1.N1
Ex. This boat is clearly afloat. |= The floating of the
boat is clear (or the boat is the floating object).
10. ¬ (ADJ1 + N) |= ¬ (V1 u∃theme.N) 6|= ¬ N
Ex. This is not a floating boat. 6|= This is not a boat.
11. ¬ (ADJ1 + N) 6|= ¬ Adj1
Ex. This is not a floating boat. 6|= This is not afloat.
12. ¬ (ADJ1 + N) 6|= ¬ V1
Ex. This is not a floating boat. 6|= This is not floating.
13. ¬ (ADJ1 + N) 6|= ¬ N1
Ex. This is not a floating boat. 6|= This is not a floating.
14. ¬ (ADJ1 + N) 6|= ¬ ∃ theme−1.V1
</figure>
<footnote confidence="0.728528">
Ex. This is not a floating boat. 6|= This is not the floater.
15. ¬ (ADJ1 + N) 6|= ¬ ∃ theme.N
Ex. This is not a floating boat. 6|= This is not a floating.
</footnote>
<page confidence="0.908493">
24 KRAQ06
</page>
<bodyText confidence="0.998842777777778">
In the inference patterns 10 to 15, the negation
of the adjective-noun compound ¬ (ADJ1 + N) is
syntactically blocked, as the adjectives in this class
are used predicative only, however the equivalent
representation V1 u∃theme.N can be used to mo-
tivate the inferences.
The following show in more detail how the first
three of the above (non) entailments are recog-
nised.
</bodyText>
<listItem confidence="0.7439655">
(4) a. The boat is afloat.
b. |= The boat is floating.
</listItem>
<table confidence="0.65080847368421">
4a ≡ Boat u Afloat (by SCR 1) A
4b ≡ Float u∃Theme.Boat (by SCR 5) B
Afloat ≡ ∃Theme−1.Float (by MDR 2) C
1 ≡ Boat u∃Theme−1.Float (from A and C) D
D |-- B (By Defn 1) E
(5) a. The boat is afloat.
b. |= The boat is the floater.
5a ≡ Boat u Afloat (by SCR 1) A
5b ≡ Boat u∃Theme−1jloat (by SCR 4) B
Afloat ≡ ∃Theme−1.Float (by MDR 2) C
A |-- B (from B und C) D
(6) a. The boat is afloat.
b. |= The boat is not sinking.
6a ≡ Boat u Afloat (by SCR 1) A
6b ≡ ¬ sink u∃Theme.boat (by SCR 5) B
Afloat ≡ ∃Theme−1.Float (by MDR 2) C
Boat u∃Theme−1.Float (from A and C) D
float u∃Theme.boat (By Defn 1) E
E |-- B (by MDR 1) F
</table>
<subsectionHeader confidence="0.451829">
3.2.2 Class 8.
</subsectionHeader>
<bodyText confidence="0.961055916666667">
Class 8 contains adjectives like
big,fast,tall,deep which can be used attribu-
tively and predicatively, are gradable, can be
modified by very. Semantically, they are classified
as subsective adjectives and their antonyms are
contraries. They are morphologically related
to nouns which describe the particular property
denoted by the adjectives and to nouns of which
they are attributes.
Model theoretic semantics. Adjectives of
class 8 are subsective adjective. They will thus li-
cence the correponding inference patterns namely:
</bodyText>
<equation confidence="0.979356">
A + N 6|= A (4)
A + N |= N (5)
</equation>
<bodyText confidence="0.998893">
Lexical semantics. The Adjectives of class 8 en-
ter in contrary opposition relations. Hence, the fol-
lowing axioms schemas will be licensed:
</bodyText>
<equation confidence="0.8776776">
Ai |= ¬Anto(Ai) and ¬Ai 6|= Anto(Ai)
(6)
For instance:
long |= ¬ small ∧¬ long 6|= small
deep |= ¬ shallow ∧¬ deep 6|= shallow
</equation>
<bodyText confidence="0.9670232">
Morpho-derivational semantics. Adjectives in
Class 8 can be related to nouns but not to
verbs. Moreover, such adjectives are mapped
in WordNet to noun concepts through two dif-
ferent links: derivationally related to
and is a value of. For example, the adjec-
tive tall in WordNet is derivationally related to the
noun tallness and is a value of the concept noun
height. The adjectives in this class describe grad-
able properties so that their semantics corresponds
to:
has-property(Related Noun u∃has-measure.Top)
in which the role has-measure account for the
value of the scalar property described by the adjec-
tive, which remain underspecified (Top) if the ad-
jective is used without a reference to the value of
measure. When the value of the measure is speci-
fied, for example by combining the adjective with
a noun, as for example in This is a tall man, then
the noun is assigned as a value of the measure role:
man u∃has-property.(tallness
u∃has-measure.man)
which translate This is tall as a man.
This is encoded in the following axiom
schemas:
</bodyText>
<table confidence="0.98714975">
MDR 1. Adj1 C ¬ Adj2 If Adj1 = Anto(Adj2)
Ex. tall C ¬ short
MDR 2. Adj1 C ∃ has property.(N1 u∃has measure.Top)
If Adj1 is related to a noun N1 denoting the property
described by Adj1
Ex. tall C ∃ has property.(tallness
u∃has measure.Top)
MDR 3. N1 C ¬ N2 If N1=Anto(N2)
Ex. tallness C ¬ shortness
MDR 4. N1 ≡ N’ u∃has value.Adj1
If Adj1 is an attribute of the noun N’
Ex. tallness ≡ height u∃has value.tall
MDR 5. N2 ≡ N’ u∃has value.Adj2
If Adj2 is an attribute of the noun N’
Ex. shortness ≡ height u∃has value.short
MDR 6. N1 C N’ If N1 is an hyponym of N’
Ex. tallness C height
25 KRAQ06
MDR 7. N2 C N’ If N2 is an hyponym of N’
Ex. shortness C height
MDR 8. Adj11 C Adj1 If Adj1 is a
scalar attribute with value less then Adj11 (hyponymy
is not defined for adjectives)
Ex. giant C tall
</table>
<bodyText confidence="0.996253625">
For the moment, we don’t account for the se-
mantics of comparatives forms of adjectives but
we will do that in the feature, by also introducing a
representation for scales as described in (Kennedy,
2005).
We make the following assumptions about the
semantic representations associated with basic
sentence patterns.
</bodyText>
<table confidence="0.8284738">
SCR 1. NP toBe Adj
NP rl3 has property.(N1 rl3has measure.NP)
SCR 2. That toBe Det Adj NP
NP rl3 has property.(N1 rl3has measure.NP)
SCR 3. NP toBe clearly Adj
NP rl3 has property.(N1 rl3has measure.NP)
SCR 4. N1 of NP is clear
NP rl3 has property.(N1 rl3has measure.NP)
SCR 5. The Adj N’ of NP
NP rl3 has property.(N’ rl3 has value.Adj
rl3has measure.NP )
SCR 6. NP1 toBe Adj as a N
NP1 rl N rl3has property.(N’ rl3 value.Adj rl3
has measure.N)
SCR 7. NP1 toBe NP2[+measure] Adj
NP1 rl3has property.(N’ rl3 value.Adj rl3
has measure.NP2)
SCR 8. NP1 toBe NP2[+measure] Adj N
NP1 rl N rl3has property.(N’ rl3has value.Adj rl3
has measure.NP2)
</table>
<bodyText confidence="0.978951">
Given the above axioms, the following exam-
ples can be handled:
</bodyText>
<listItem confidence="0.990427">
(7) (a) John is a 1.50 meter tall man.
|= (b) John is 1.50 meter tall.
</listItem>
<table confidence="0.992152">
7a =_ John rl Man rl3has property.(height A
rlhas value.tall rlhas measure(1.50 meter) )
(by SCR 8)
7b John rl3has property.(height rlhas value.tall B
rlhas measure(1.50 meter) )
(by SCR 7 and from A)
ASB C
</table>
<listItem confidence="0.832904">
(8) (a) John is a 1.50 meter tall man. K (b) John
is a tall man.
</listItem>
<table confidence="0.996785285714286">
8a =_ John rl Man rl3has property.(height A
rlhas value.tall rlhas measure(1.50 meter) )
(by SCR 8)
8b John rl Man rl3has property.(height rl B
has value.tall rlhas measure(man) )
(by SCR1 and from A)
AK- B C
</table>
<sectionHeader confidence="0.997266" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999905272727273">
For each of the 15 classes, we have specified a set
of axioms schemas, some basic semantic construc-
tion rules and a set of inference patterns which
could be deduced to follow from both of these.
The axioms schemas were implemented in De-
scription Logic using RACER and for each infer-
ence pattern identified, the corresponding Descrip-
tion Logic query was checked to verify that the
proposed axioms and semantic construction rules
did indeed correctly predict the deduced inference
patterns.
</bodyText>
<sectionHeader confidence="0.998265" genericHeader="conclusions">
5 Further work and evaluation
</sectionHeader>
<bodyText confidence="0.999986">
The main contribution of this work is a detailed
analysis of the interactions between derivational
morphology, lexical and compositional semantics
and of their impact on the entailment patterns li-
censed by sentences containing adjective or their
related nouns/verbs.
To turn this analysis into a computational sys-
tem, its components need to be integrated into a
semantic analyser and the behaviour of that anal-
yser tested against a collection of data. We are
currently working on developing such an anal-
yser within a symbolic grammar framework. We
have also started to develop an evaluation test
suite geared towards entailment recognition be-
tween sentence pairs containing adjectives. At the
moment, the test suite contains about 1 000 infer-
ence pairs. Each item in the TestSuite (see fig. 2)
is annotated with a judgement about the truth of
the entailment between the pair of sentences, with
the type of inference involved and with the speci-
fication of adjective involved. Moreover, each ad-
jective is annotated with the WordNet sense corre-
sponding to the given class.
The idea behind this test suite is similar to
that underlying the creation of the TSNLP (Test
suite for natural language processing) (see (Oepen
and Netter, 1995)) or the Eurotra testsuites (see
(Arnold and des Tombe, 1987)) namely, to pro-
vide a benchmark against which to evaluate and
compare existing semantic analyzers. Thus this
</bodyText>
<page confidence="0.544722">
26 KRAQ06
</page>
<figure confidence="0.991972875">
&lt;pair id=&amp;quot;1&amp;quot; value=&amp;quot;TRUE&amp;quot; class=&amp;quot;[CLASS1]&amp;quot; inference=&amp;quot;Adj/Verb&amp;quot;&gt;
&lt;t&gt;The boat is &lt;sn n=&amp;quot;1&amp;quot;&gt; afloat &lt;/sn&gt;.&lt;/t&gt;
&lt;h&gt;The boat is floating.&lt;/h&gt;
&lt;/pair&gt;
&lt;pair id=&amp;quot;2&amp;quot; value=&amp;quot;FALSE&amp;quot; class=&amp;quot;[CLASS6]&amp;quot; inference=&amp;quot;Antonymy&amp;quot;&gt;
&lt;t&gt;This is not a &lt;sn n=&amp;quot;1&amp;quot;&gt; rectangular &lt;/sn&gt; table.&lt;/t&gt;
&lt;h&gt;This is a &lt;sn n=&amp;quot;1&amp;quot;&gt; round &lt;/sn&gt; table &lt;/h&gt;
&lt;/pair&gt;
&lt;pair id=&amp;quot;3&amp;quot; value=&amp;quot;TRUE&amp;quot; class=&amp;quot;[CLASS8]&amp;quot; inference=&amp;quot;Adj/Noun&amp;quot;&gt;
&lt;t&gt;The line is 2 meter &lt;sn n=&amp;quot;1&amp;quot;&gt; long &lt;/sn&gt;.&lt;/t&gt;
&lt;h&gt;The length of the line is 2 meter.&lt;/h&gt;
&lt;/pair&gt;
&lt;pair id=&amp;quot;4&amp;quot; value=&amp;quot;FALSE&amp;quot; class &amp;quot;[subs/intersective]&amp;quot; inference=&amp;quot;Attr/Pred&amp;quot;&gt;
&lt;t&gt;The treasurer is &lt;sn n=&amp;quot;2&amp;quot;&gt; present &lt;/sn&gt;.&lt;/t&gt;
&lt;h&gt;This is the &lt;sn n=&amp;quot;1&amp;quot;&gt; present &lt;/sn&gt; treasurer.&lt;/h&gt;
&lt;/pair&gt;
</figure>
<figureCaption confidence="0.999783">
Figure 2: TestSuite
</figureCaption>
<bodyText confidence="0.972082434782609">
test suite illustrates the semantic and syntactic be-
haviour of adjectives and their related verbs/nouns
with respect to textual entailment. One could
imagine other test suites illustrating the seman-
tic behaviour of verbs, of quantifiers, of discourse
connectives, etc. Just as the TSNLP still proves
useful in supporting the development of new sym-
bolic parsers/grammars, hand built test suites of
artificial examples might prove useful in improv-
ing the accuracy of semantic analyser wrt textual
entailment. Indeed the Pascal RTE challenge has
shown that existing systems fares rather poortly at
the textual entailment task. Providing a set of hand
crafted semantic test suites might help in remedy-
ing this shortcoming.
Beside implementing and evaluating the anal-
ysis of adjectives presented in this paper, we are
also working on refining this analysis by combin-
ing it with a detailed analysis of noun semantics so
as to handle (non) entailments such as:
(9)
Lyon is the gastronomical capital of France
K Lyon is the capital of France
</bodyText>
<sectionHeader confidence="0.998895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999932975">
D.J. Arnold and Luis des Tombe. 1987. Basic Theory
and methodology in Eurotra. Cambridge University
Press.
DA. Cruse. 1986. Lexical Semantics. Cambridge Uni-
versity Press.
Claire Gardent and Evelyne Jacquey. 2003. Lexical
reasoning. In Proceedings of the ICON’03 (Inter-
national Conference on Natural Language Process-
ing), Mysore, India.
Oren Glickman Ido Dagan and Bernardo Magnini.
2005. The PASCAL Recognising Textual Entailment
Challenge.
Hans Kamp and Barbara Partee. 1995. Prototype the-
ory and compositionality. Cognition, (57):129–191.
Hans Kamp. 1975. Two theories about adjectives. In
Edward L. Keenan (ed.), Formal Semantics of Nat-
ural Language, pages 123–155. Cambridge Univer-
sity Press.
Christofer Kennedy. 2005. Vagueness and grammar:
The semantics of relative and absolute gradable ad-
jectives. Ms., pages 129–191, June.
K. J. Miller. 1998. Modifiers in wordnet. In
C. Fellbaum (ed.), WordNet An Electronic Lexical
Database. Cambridge, MA, The MIT Press.
Stephan Oepen and Klaus Netter. 1995. TSNLP -
test suites for natural language processing. Gronin-
gen, The Netherlands. Conference on Linguistic
Databases.
I. Peters and W. Peters. 2000. The Treatment ofAdjec-
tives in SIMPLE: Theoretical Observations. Athens.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik.
1985. A Comprehensive Grammar of the English
Language. Longman.
V. Raskin and S. Nirenburg. 1995. Lexical Semantics
ofAdjectives, a micro-theory of adjectival meaning.
MCCS Report.
Ralf M¨oller Volker Haarslev. 2001. Description of the
racer system and its applications. In Proceedings
International Workshop on Description Logics (DL-
2001, Stanford, USA.
</reference>
<page confidence="0.871954">
27 KRAQ06
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.145535">
<title confidence="0.810124">based</title>
<author confidence="0.700787">Marilisa</author>
<affiliation confidence="0.668905666666667">INRIA/Universit´e de Nancy 1 University of the Saarbr¨ucken</affiliation>
<email confidence="0.90874">amoia@coli.uni-sb.de</email>
<author confidence="0.79361">Claire</author>
<affiliation confidence="0.911339">Campus Scientifique BP</affiliation>
<address confidence="0.951643">54506 Vandoeuvre-les-Nancy,</address>
<email confidence="0.989746">claire.gardent@loria.fr</email>
<abstract confidence="0.983911166666667">In this paper, we propose a fine grained classification of english adjectives geared at modeling the distinct inference patterns licensed by each adjective class. We show how it can be implemented in description logic and illustrate the predictions made by a series of examples. The proposal has been implemented using Description logic as a semantic representation language and the prediction verified using the DL theoprover</abstract>
<intro confidence="0.915695">Entailment, Adjectival Semantics</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D J Arnold</author>
<author>Luis des Tombe</author>
</authors>
<title>Basic Theory and methodology in Eurotra.</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<marker>Arnold, Tombe, 1987</marker>
<rawString>D.J. Arnold and Luis des Tombe. 1987. Basic Theory and methodology in Eurotra. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5711" citStr="Cruse, 1986" startWordPosition="920" endWordPosition="921">ive adjectives (e.g., big) licence the following inference pattern: A + N �= N For instance, ifX is a big mouse, then X is a mouse but it is not necessarily true X is big Privative adjectives licence the inference pattern: A + N �= -,N For instance, ifX is a fake gun then X is not a gun Plain non-subsective adjectives (e.g., alledged) do not licence any inference For instance, ifX is an alleged murderer then it is unknown whether X is a murderer or not 2.2 Lexical semantics From the lexical semantics literature, we take one additional classification criterion namely antonymy. As described in (Cruse, 1986), this term covers different kinds of opposite polarity relations between adjectives namly, binary opposition, contraries and multiple oppositions. Binary oppositions covers pairs such as wet/dry which license the following inference pattern: A1 - -,A2 n -,A1 - A2 So that in particular: wet - -,dry n -,wet - dry Contraries are pairs such as long/short where the implication is unidirectional: A1 -,A2 n -,A1 A2 A2 -,A1 n -,A2 A1 and in particular: long �= -,short n -,long K short short �= -,long n -,short K long Multiple oppositions involve a finite set of adjectives (e.g., linguistic/economic/m</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>DA. Cruse. 1986. Lexical Semantics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Evelyne Jacquey</author>
</authors>
<title>Lexical reasoning.</title>
<date>2003</date>
<booktitle>In Proceedings of the ICON’03 (International Conference on Natural Language Processing),</booktitle>
<location>Mysore, India.</location>
<contexts>
<context position="10685" citStr="Gardent and Jacquey, 2003" startWordPosition="1722" endWordPosition="1725">oun concept to a list of attributes which describe the scalar property it represents. For example, the adjective tall is a value of {stature,height} and attributes of {stature,height} are tall and short. Based on some basic syntactic patterns, we then show that these axioms predict the observed textual entailment patterns for that class. Before we illustrate this approach by means of some example, we first show how we capture logical entailment between NL semantic representations in a description logic setting. 3.1 Using description logic to check entailment between NL sentences As argued in (Gardent and Jacquey, 2003), description logic (DL) is an intuitive framework within which to perform lexical reasoning: it is efficient (basic versions of description logics are decidable), it is tailored to reason about complex taxonomies (taxonomies of descriptions) and it is equipped with powerful, freely available automated provers (such as RACER, (Volker Haarslev, 2001)). For these reasons, we are here exploring a DL encoding of the entailment recognition task for the set of examples we are considering.The particular language we assume has the following syntax. C, D --+ A|T|I|-A |C n D |C u D |`dR.C |3R.C The sema</context>
</contexts>
<marker>Gardent, Jacquey, 2003</marker>
<rawString>Claire Gardent and Evelyne Jacquey. 2003. Lexical reasoning. In Proceedings of the ICON’03 (International Conference on Natural Language Processing), Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Glickman Ido Dagan</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL Recognising Textual Entailment Challenge.</title>
<date>2005</date>
<contexts>
<context position="1081" citStr="Dagan and Magnini, 2005" startWordPosition="152" endWordPosition="155">ed in description logic and illustrate the predictions made by a series of examples. The proposal has been implemented using Description logic as a semantic representation language and the prediction verified using the DL theorem prover RACER. Topics: Textual Entailment, Adjectival Semantics 1 Introduction Understanding a text is one of the ultimate goals of computational linguistics. To achieve this goal, systems need to be developed which can construct a meaning representation for any given text and which furthermore, can reason about the meaning of a text. As is convincingly argued in (Ido Dagan and Magnini, 2005), one of the major inference task involved in that reasoning is the entailment recognition task: Does text T1 entail text T2? Indeed entailment recognition can be used to determine whether a text fragment answers a question (e.g., in question answering application), whether a query is entailed by a relevant document (in information retrieval), whether a text fragment entails a specific information nugget (in information extraction), etc. Because the Pascal RTE challenge focuses on real text, the participating systems must be robust that is, they must be able to handle unconstrained ∗We thank l</context>
</contexts>
<marker>Dagan, Magnini, 2005</marker>
<rawString>Oren Glickman Ido Dagan and Bernardo Magnini. 2005. The PASCAL Recognising Textual Entailment Challenge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Barbara Partee</author>
</authors>
<date>1995</date>
<booktitle>Prototype theory and compositionality. Cognition,</booktitle>
<pages>57--129</pages>
<contexts>
<context position="4782" citStr="Kamp and Partee, 1995" startWordPosition="750" endWordPosition="753">tives As mentioned above, we propose a classification of adjectives based on their lexical, their model theoretic and their morpho-derivational properties. To facilitate the link with compositional semantics (the construction of a meaning representation for sentences containing adjectives), we also take into account syntactic properties such as the predicative/attributive or the static/dynamic distinction. We now detail each of these properties. The overall categorisation system is given in Figure 1. 2.1 Model theoretic properties The main criteria for classification are given by (Kamp, 1975; Kamp and Partee, 1995) semantic classification of adjectives which is based on whether it is possible to infer from the Adj+N combination the Adj or the N denotation. Intersective adjectives (e.g., red) licence the following inference inference patterns: A + N A A + N N For instance, if X is a red car then X is a car and X is red Subsective adjectives (e.g., big) licence the following inference pattern: A + N �= N For instance, ifX is a big mouse, then X is a mouse but it is not necessarily true X is big Privative adjectives licence the inference pattern: A + N �= -,N For instance, ifX is a fake gun then X is not a</context>
</contexts>
<marker>Kamp, Partee, 1995</marker>
<rawString>Hans Kamp and Barbara Partee. 1995. Prototype theory and compositionality. Cognition, (57):129–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
</authors>
<title>Two theories about adjectives.</title>
<date>1975</date>
<booktitle>Formal Semantics of Natural Language,</booktitle>
<pages>123--155</pages>
<editor>In Edward L. Keenan (ed.),</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4758" citStr="Kamp, 1975" startWordPosition="748" endWordPosition="749">on for adjectives As mentioned above, we propose a classification of adjectives based on their lexical, their model theoretic and their morpho-derivational properties. To facilitate the link with compositional semantics (the construction of a meaning representation for sentences containing adjectives), we also take into account syntactic properties such as the predicative/attributive or the static/dynamic distinction. We now detail each of these properties. The overall categorisation system is given in Figure 1. 2.1 Model theoretic properties The main criteria for classification are given by (Kamp, 1975; Kamp and Partee, 1995) semantic classification of adjectives which is based on whether it is possible to infer from the Adj+N combination the Adj or the N denotation. Intersective adjectives (e.g., red) licence the following inference inference patterns: A + N A A + N N For instance, if X is a red car then X is a car and X is red Subsective adjectives (e.g., big) licence the following inference pattern: A + N �= N For instance, ifX is a big mouse, then X is a mouse but it is not necessarily true X is big Privative adjectives licence the inference pattern: A + N �= -,N For instance, ifX is a </context>
</contexts>
<marker>Kamp, 1975</marker>
<rawString>Hans Kamp. 1975. Two theories about adjectives. In Edward L. Keenan (ed.), Formal Semantics of Natural Language, pages 123–155. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christofer Kennedy</author>
</authors>
<title>Vagueness and grammar: The semantics of relative and absolute gradable adjectives.</title>
<date>2005</date>
<journal>Ms.,</journal>
<pages>129--191</pages>
<contexts>
<context position="22922" citStr="Kennedy, 2005" startWordPosition="3958" endWordPosition="3959">s ≡ height u∃has value.tall MDR 5. N2 ≡ N’ u∃has value.Adj2 If Adj2 is an attribute of the noun N’ Ex. shortness ≡ height u∃has value.short MDR 6. N1 C N’ If N1 is an hyponym of N’ Ex. tallness C height 25 KRAQ06 MDR 7. N2 C N’ If N2 is an hyponym of N’ Ex. shortness C height MDR 8. Adj11 C Adj1 If Adj1 is a scalar attribute with value less then Adj11 (hyponymy is not defined for adjectives) Ex. giant C tall For the moment, we don’t account for the semantics of comparatives forms of adjectives but we will do that in the feature, by also introducing a representation for scales as described in (Kennedy, 2005). We make the following assumptions about the semantic representations associated with basic sentence patterns. SCR 1. NP toBe Adj NP rl3 has property.(N1 rl3has measure.NP) SCR 2. That toBe Det Adj NP NP rl3 has property.(N1 rl3has measure.NP) SCR 3. NP toBe clearly Adj NP rl3 has property.(N1 rl3has measure.NP) SCR 4. N1 of NP is clear NP rl3 has property.(N1 rl3has measure.NP) SCR 5. The Adj N’ of NP NP rl3 has property.(N’ rl3 has value.Adj rl3has measure.NP ) SCR 6. NP1 toBe Adj as a N NP1 rl N rl3has property.(N’ rl3 value.Adj rl3 has measure.N) SCR 7. NP1 toBe NP2[+measure] Adj NP1 rl3h</context>
</contexts>
<marker>Kennedy, 2005</marker>
<rawString>Christofer Kennedy. 2005. Vagueness and grammar: The semantics of relative and absolute gradable adjectives. Ms., pages 129–191, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Miller</author>
</authors>
<title>Modifiers in wordnet.</title>
<date>1998</date>
<booktitle>WordNet An Electronic Lexical Database.</booktitle>
<editor>In C. Fellbaum (ed.),</editor>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="3233" citStr="Miller, 1998" startWordPosition="491" endWordPosition="492">n approaches like those described in (Raskin and Nirenburg, 1995; Peters and Peters, 2000), we propose a classification of adjectives which can account for the entailment patterns that are supported by the interaction of their lexical and of their compositional semantics. We start by defining a classification schema for adjectives based on their syntactic and semantic properties. We then associate with each class a set of axioms schemas which translate the knowledge about lexical relations (i.e. antonymy) the adjectives of the class are involved in by extracting this information from WordNet (Miller, 1998) and a set of semantic construction rules and we show that these correctly predicts the observed entailment patterns. For instance, the approach will account for the following (non)-entailment cases: (1) a. John frightened the child |= The child is afraid 150% of the cases were true entailment and 50% were false ones, hence tossing a coin would get half of the cases right. 20 KRAQ06 b. Peter claims that John is a murderer �= John is an alledged murderer K John is a murderer c. This is a fake bicycle �= This is a false bike �= This is not a real bike K This is a bike d. John is not awake �= Joh</context>
</contexts>
<marker>Miller, 1998</marker>
<rawString>K. J. Miller. 1998. Modifiers in wordnet. In C. Fellbaum (ed.), WordNet An Electronic Lexical Database. Cambridge, MA, The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Klaus Netter</author>
</authors>
<title>TSNLP -test suites for natural language processing. Groningen, The Netherlands. Conference on Linguistic Databases.</title>
<date>1995</date>
<contexts>
<context position="26059" citStr="Oepen and Netter, 1995" startWordPosition="4488" endWordPosition="4491">towards entailment recognition between sentence pairs containing adjectives. At the moment, the test suite contains about 1 000 inference pairs. Each item in the TestSuite (see fig. 2) is annotated with a judgement about the truth of the entailment between the pair of sentences, with the type of inference involved and with the specification of adjective involved. Moreover, each adjective is annotated with the WordNet sense corresponding to the given class. The idea behind this test suite is similar to that underlying the creation of the TSNLP (Test suite for natural language processing) (see (Oepen and Netter, 1995)) or the Eurotra testsuites (see (Arnold and des Tombe, 1987)) namely, to provide a benchmark against which to evaluate and compare existing semantic analyzers. Thus this 26 KRAQ06 &lt;pair id=&amp;quot;1&amp;quot; value=&amp;quot;TRUE&amp;quot; class=&amp;quot;[CLASS1]&amp;quot; inference=&amp;quot;Adj/Verb&amp;quot;&gt; &lt;t&gt;The boat is &lt;sn n=&amp;quot;1&amp;quot;&gt; afloat &lt;/sn&gt;.&lt;/t&gt; &lt;h&gt;The boat is floating.&lt;/h&gt; &lt;/pair&gt; &lt;pair id=&amp;quot;2&amp;quot; value=&amp;quot;FALSE&amp;quot; class=&amp;quot;[CLASS6]&amp;quot; inference=&amp;quot;Antonymy&amp;quot;&gt; &lt;t&gt;This is not a &lt;sn n=&amp;quot;1&amp;quot;&gt; rectangular &lt;/sn&gt; table.&lt;/t&gt; &lt;h&gt;This is a &lt;sn n=&amp;quot;1&amp;quot;&gt; round &lt;/sn&gt; table &lt;/h&gt; &lt;/pair&gt; &lt;pair id=&amp;quot;3&amp;quot; value=&amp;quot;TRUE&amp;quot; class=&amp;quot;[CLASS8]&amp;quot; inference=&amp;quot;Adj/Noun&amp;quot;&gt; &lt;t&gt;The line is 2 meter &lt;sn n=&amp;quot;</context>
</contexts>
<marker>Oepen, Netter, 1995</marker>
<rawString>Stephan Oepen and Klaus Netter. 1995. TSNLP -test suites for natural language processing. Groningen, The Netherlands. Conference on Linguistic Databases.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Peters</author>
<author>W Peters</author>
</authors>
<title>The Treatment ofAdjectives in SIMPLE: Theoretical Observations.</title>
<date>2000</date>
<location>Athens.</location>
<contexts>
<context position="2710" citStr="Peters and Peters, 2000" startWordPosition="406" endWordPosition="410"> has shown that roughly 50% of the RTE cases could be handled correctly by a system that would adequately cover semantic entailments that are either syntax based (e.g., active/passive) or lexical semantics based (e.g., bicycle/bike). Given that the overall system accuracies hovered between 50 and 60 percent with a baseline of 50 %1, this suggests that a better integration of syntax, compositional and lexical semantics might improve entailment recognition accuracy. In this paper, we consider the case of adjectives and, building on approaches like those described in (Raskin and Nirenburg, 1995; Peters and Peters, 2000), we propose a classification of adjectives which can account for the entailment patterns that are supported by the interaction of their lexical and of their compositional semantics. We start by defining a classification schema for adjectives based on their syntactic and semantic properties. We then associate with each class a set of axioms schemas which translate the knowledge about lexical relations (i.e. antonymy) the adjectives of the class are involved in by extracting this information from WordNet (Miller, 1998) and a set of semantic construction rules and we show that these correctly pr</context>
</contexts>
<marker>Peters, Peters, 2000</marker>
<rawString>I. Peters and W. Peters. 2000. The Treatment ofAdjectives in SIMPLE: Theoretical Observations. Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<date>1985</date>
<journal>A Comprehensive Grammar of the English Language. Longman.</journal>
<contexts>
<context position="7429" citStr="Quirk et al., 1985" startWordPosition="1215" endWordPosition="1218">, a noun denoting a theta role of the related verb (Ng) or a non-event noun (Na). As we shall see, this permits capturing entailment relations between sentences containing morphoderivational variants such as for instance : 21 KRAQ06 (2) a. John is asleep (Adj — Va) |= John sleeps b. John is absent (Adj — Nθ) |= John is the absentee c. John is deeply asleep (Adj — Ne) |= John’s sleep is deep 2.2.2 Syntactic properties To better support the syntax/semantic interface, we refine the adjectives classes distinguishable on the basis of the above criteria with the following syntactic ones taken from (Quirk et al., 1985). Attributiveness/Predicativeness. English adjectives can be divided in adjectives which can be used only predicatively (such as alone), adjectives which can be used only attributively (such as mechanical in mechanical enginner) and adjectives which can be used in both constructions such as red. Modifiability by very. We distinguish between adjectives such as nice which can be modified by very (i.e. very nice) and adjectives such as alleged which cannot (*very alleged). Gradability. We distinguish between adjectives such as big which express gradable properties and have comparative and superla</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
<author>S Nirenburg</author>
</authors>
<title>Lexical Semantics ofAdjectives, a micro-theory of adjectival meaning.</title>
<date>1995</date>
<tech>MCCS Report.</tech>
<contexts>
<context position="2684" citStr="Raskin and Nirenburg, 1995" startWordPosition="402" endWordPosition="405">one of the participant teams has shown that roughly 50% of the RTE cases could be handled correctly by a system that would adequately cover semantic entailments that are either syntax based (e.g., active/passive) or lexical semantics based (e.g., bicycle/bike). Given that the overall system accuracies hovered between 50 and 60 percent with a baseline of 50 %1, this suggests that a better integration of syntax, compositional and lexical semantics might improve entailment recognition accuracy. In this paper, we consider the case of adjectives and, building on approaches like those described in (Raskin and Nirenburg, 1995; Peters and Peters, 2000), we propose a classification of adjectives which can account for the entailment patterns that are supported by the interaction of their lexical and of their compositional semantics. We start by defining a classification schema for adjectives based on their syntactic and semantic properties. We then associate with each class a set of axioms schemas which translate the knowledge about lexical relations (i.e. antonymy) the adjectives of the class are involved in by extracting this information from WordNet (Miller, 1998) and a set of semantic construction rules and we sh</context>
</contexts>
<marker>Raskin, Nirenburg, 1995</marker>
<rawString>V. Raskin and S. Nirenburg. 1995. Lexical Semantics ofAdjectives, a micro-theory of adjectival meaning. MCCS Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf M¨oller Volker Haarslev</author>
</authors>
<title>Description of the racer system and its applications.</title>
<date>2001</date>
<booktitle>In Proceedings International Workshop on Description Logics (DL2001,</booktitle>
<location>Stanford, USA.</location>
<contexts>
<context position="11036" citStr="Haarslev, 2001" startWordPosition="1776" endWordPosition="1777">his approach by means of some example, we first show how we capture logical entailment between NL semantic representations in a description logic setting. 3.1 Using description logic to check entailment between NL sentences As argued in (Gardent and Jacquey, 2003), description logic (DL) is an intuitive framework within which to perform lexical reasoning: it is efficient (basic versions of description logics are decidable), it is tailored to reason about complex taxonomies (taxonomies of descriptions) and it is equipped with powerful, freely available automated provers (such as RACER, (Volker Haarslev, 2001)). For these reasons, we are here exploring a DL encoding of the entailment recognition task for the set of examples we are considering.The particular language we assume has the following syntax. C, D --+ A|T|I|-A |C n D |C u D |`dR.C |3R.C The semantics of this language is given below with A the domain of interpretation and I the interpretation function which assigns to every atomic con22 KRAQ06 Adjective Class Predicative/Attributive Modifiable by very Gradability static/dynamic Antonymy Related forms Semantic class Class 1: afloat predicative-only - - static multi-opposition Va, Ne, No inte</context>
</contexts>
<marker>Haarslev, 2001</marker>
<rawString>Ralf M¨oller Volker Haarslev. 2001. Description of the racer system and its applications. In Proceedings International Workshop on Description Logics (DL2001, Stanford, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>