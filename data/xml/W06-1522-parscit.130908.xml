<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9974195">
Modeling and Analysis of Elliptic Coordination by Dynamic Exploitation
of Derivation Forests in LTAG parsing
</title>
<author confidence="0.555308">
Djamé Seddah (1) &amp; Benoît Sagot (2)
</author>
<listItem confidence="0.391154666666667">
(1) NCLT - Dublin City University - Ireland
djame.seddah@computing.dcu.ie
(2) Projet ATOLL - INRIA - France
</listItem>
<email confidence="0.975097">
benoit.sagot@inria.fr
</email>
<sectionHeader confidence="0.996338" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962307692307">
In this paper, we introduce a generic ap-
proach to elliptic coordination modeling
through the parsing of Ltag grammars. We
show that erased lexical items can be re-
placed during parsing by informations ga-
thered in the other member of the coordi-
nate structure and used as a guide at the
derivation level. Moreover, we show how
this approach can be indeed implemented
as a light extension of the LTAG formalism
throuh a so-called “fusion” operation and
by the use of tree schemata during parsing
in order to obtain a dependency graph.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999724894736842">
The main goal of this research is to provide a
way of solving elliptic coordination through the
use of Derivation Forests. The use of this de-
vice implies that the resolution mechanism de-
pends on syntactic information, therefore we will
not deal with anaphoric resolutions and scope mo-
difier problems. We show how to generate a de-
rivation forest described by a set of context free
rules (similar to (Vijay-Shanker and Weir, 1993))
augmented by a stack of current adjunctions when
a rule describes a spine traversal. We first briefly
discuss the linguistic motivations behind the reso-
lution mechanism we propose, then introduce the
fusion operation and show how it can be compa-
red to the analysis of (Dalrymple et al., 1991) and
(Steedman, 1990) and we show how it differs from
(Sarkar and Joshi, 1996). We assume that the rea-
der is familiar with the Lexicalized Tree Adjoining
Grammars formalism ((Joshi and Schabes, 1992)).
</bodyText>
<sectionHeader confidence="0.8400155" genericHeader="introduction">
2 Linguistic Motivations : a parallelism
of Derivation
</sectionHeader>
<bodyText confidence="0.999942054054054">
The LTAG formalism provides a derivation tree
which is strictly the history of the operations nee-
ded to build a constituent structure, the derived
tree. In order to be fully appropriate for seman-
tic inference 1, the derivation tree should display
every syntactico-semantic argument and therefore
should be a graph. However to obtain this kind
of dependency structure when it is not possible to
rely on lexical information, as opposed to (Seddah
and Gaiffe, 2005a), is significantly more compli-
cated. An example of this is provided by elliptic
coordination.
Consider the sentences Figure 3. They all can be
analyzed as coordinations of S categories2 with
one side lacking one mandatory argument. In (4),
one could argue for VP coordination, because the
two predicates share the same continuum (same
subcategorization frame and semantic space). Ho-
wever the S hypothesis is more generalizable and
supports more easily the analysis of coordination
of unlike categories (“John is a republican and
proud of it” becomes “Johnz isj a republican and
εz εj proud of it”).
The main difficulty is to separate the cases when
a true co-indexation occurs ((2) and (4)) from the
cases of a partial duplication (in (1), the predicate
is not shared and its feature structures could dif-
fer on aspects, tense or number3). In an elliptic
construction, some words are unrealized. There-
fore, their associated syntactic structures are also
non-realized, at least to some extent. However, our
aim is to get, as a result of the parsing process,
the full constituency and dependency structures of
the sentence, including erased semantic items (or
units) and their (empty) syntactic positions. Since
their syntactic realizations have been erased, the
construction of the dependency structure can not
</bodyText>
<footnote confidence="0.793380571428571">
1As elementary trees are lexicalized and must have a mi-
nimal semantic meaning (Abeillé, 1991), the derivation tree
can be seen as a dependency tree with respect to the restric-
tions defined by (Rambow and Joshi, 1994) and (Candito and
Kahane, 1998) to cite a few.
2P for Phrase in french, in Figures given in annex
3see “John lovesi Mary and childreni their gameboy”
</footnote>
<page confidence="0.973757">
147
</page>
<bodyText confidence="0.961195625">
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 147–152,
Sydney, July 2006. c�2006 Association for Computational Linguistics
be anchored to lexical items. Instead, it has to be
anchored on non-realized lexical items and gui-
ded by the dependency structure of the reference
phrase. Indeed, it is because of the parallelism bet-
ween the reference phrase and the elliptical phrase
that an ellipsis can be interpreted.
</bodyText>
<sectionHeader confidence="0.991211" genericHeader="method">
3 The Fusion Operation
</sectionHeader>
<bodyText confidence="0.999979047619048">
In this research, we assume that every coordina-
tor, which occurs in elided sentences, anchors an
initial tree αconj rooted by P and with two sub-
stitution nodes of category P (Figure 1). The fu-
sion operation replaces the missing derivation of
any side of the coordinator by the corresponding
ones from the other side. It shall be noted that the
fusion provide proper node sharing when it is syn-
tactically decidable (cf. 6.4). The implementation
relies on the use of non lexicalized trees (ie tree
schemes) called ghost trees. Their purpose is to
be the support for partial derivations which will
be used to rebuild the derivation walk in the eli-
ded part. We call the partial derivations ghost deri-
vations. The incomplete derivations from the tree
-y are shown as a broken tree in Figure 2. The
ghost derivations are induced by the inclusion of
the ghost tree α′ which must be the scheme of the
tree α. When the two derivation structures from
-y and α′ are processed by the fusion operation, a
complete derivation structure is obtained.
</bodyText>
<subsectionHeader confidence="0.920676">
Derivations before the Fusion After the Fusion
</subsectionHeader>
<bodyText confidence="0.965518">
FIG. 2 – Derivation sketch of the Fusion Operation
</bodyText>
<sectionHeader confidence="0.968123" genericHeader="method">
4 examples anylysis
</sectionHeader>
<bodyText confidence="0.974316">
Let us go back to the following sentences :
</bodyText>
<listItem confidence="0.793511">
(1) Jean aimei Marie et Paul ei Virginie
John loves Mary and Paul Virginia
(2) Pauli aime Virginie et ei déteste Marie
</listItem>
<subsubsectionHeader confidence="0.457629">
Paul loves Virginia and hates Mary
</subsubsectionHeader>
<bodyText confidence="0.967570344827586">
Obviously (1) can have as a logical formula :
aime′(jean′, Marie′) ∧ aime′(paul′, virginie′)
whereas (2) is rewritten by eat(paul′, apple′) ∧
buy′(Paul′, cherries′). The question is to diffe-
rentiate the two occurrence of aime′ in (1) from
the paul′ ones. Of course, the second should be
noted as a sharing of the same argument when the
first is a copy of the predicate aime′. Therefore
in order to represent the sharing, we will use the
same node in the dependency graph while a ghos-
ted node (noted by ghost(-y) in our figures) will be
used in the other case. This leads to the analysis
figure 4. The level of what exactly should be co-
pied, speaking of level of information, is outside
the scope of this paper, but our intuition is that
a state between a pure anchored tree and an tree
schemata is probably the correct answer. As we
said, aspect, tense and in most case diathesis for 4
are shared, as it is showed by the following sen-
tences :
(3)*Paul killed John and Bill by Rodger
(4)*Paul ate apple and Mary will pears
As opposed to (4), we believe “Paul ate apples
and Mary will do pears” to be correct but in
this case, we do not strictly have an ellipsis but
a semi-modal verb which is susbsumed by its
co-referent. Although our proposition focuses on
syntax-semantic interface, mainly missing syntac-
tic arguments.
</bodyText>
<sectionHeader confidence="0.867759" genericHeader="method">
5 Ghost Trees and Logical Abstractions
</sectionHeader>
<bodyText confidence="0.999924833333333">
Looking either at the approach proposed by
(Dalrymple et al., 1991) or (Steedman, 1990) for
the treatment of sentences with gaps, we note that
in both cases5 one wants to abstract the realized
element in one side of the coordination in order to
instantiate it in the other conjunct using the coor-
dinator as the pivot of this process. In our analy-
sis, this is exactly the role of ghost trees to support
such abstraction (talking either about High Order
Variable or A-abstraction). In this regard, the fu-
sion operation has only to check that the deriva-
tions induced by the ghost tree superimpose well
with the derivations of the realized side.
This is where our approach differs strongly from
(Sarkar and Joshi, 1996). Using the fusion opera-
tion involves inserting partial derivations, which
are linked to already existing ones (the realized
derivation), into the shared forest whereas using
</bodyText>
<footnote confidence="0.8894102">
4w.r.t to the examples of (Dalrymple et al., 1991), i.e “It
is possible that this result can be derived (..) but I know of no
theory that does so.”
5Footnote n˚3, page 5 for (Dalrymple et al., 1991), and
pages 41-42 for (Steedman, 1990).
</footnote>
<figure confidence="0.987212216216217">
����
����
������
������
������
������
��
�� γ
���
���
α
���
���
αconj
����
����
������
������
������
������
��
�� γ
���
���
α
�����
�����
�����
����� α’
�����
�����
���
���
αconj
Pαconj
PαconjG↓ et PαconjD↓
FIG. 1 – Initial Tree αconj
</figure>
<page confidence="0.984401">
148
</page>
<bodyText confidence="0.9999026">
the conjoin operation defined in (Sarkar and Joshi,
1996) involves merging nodes from different trees
while the tree anchored by a coordinator acts si-
milarly to an auxiliary tree with two foot nodes.
This may cause difficulties to derive the now dag
into a linear string. In our approach, we use empty
lexical items in order to leave traces in the deriva-
tion forest and to have syntacticly motivated deri-
ved tree (cf fig. 5) if we extract only the regular
LTAG “derivation item” from the forest.
</bodyText>
<sectionHeader confidence="0.995972" genericHeader="method">
6 LTAG implementation
</sectionHeader>
<subsectionHeader confidence="0.999364">
6.1 Working on shared forest
</subsectionHeader>
<bodyText confidence="0.992109184210526">
A shared forest is a structure which combines
all the information coming from derivation trees
and from derived trees. Following (Vijay-Shanker
and Weir, 1993; Lang, 1991), each tree anchored
by the elements of the input sentence is described
by a set of rewriting rules. We use the fact that
each rule which validates a derivation can infer
a derivation item and has access to the whole
chart in order to prepare the inference process.
The goal is to use the shared forest as a guide for
synchronizing the derivation structures from both
parts of the coordinator.
This forest is represented by a context free
grammar augmented by a stack containing the
current adjunctions (Seddah and Gaiffe, 2005a),
which looks like a Linear Indexed Grammar (Aho,
1968).
Each part of a rule corresponds to an
item à la Cock Kasami Younger described
by (Shieber et al., 1995), whose form is
&lt; N, POS, I, J, STACK &gt; with N a node
of an elementary tree, POS the situation relative
to an adjunction (marked T if an adjunction is
still possible, 1 otherwise). This is marked on
figure 5 with a bold dot in high position, T, or a
bold dot in low position, 1). I and J are the start
and end indices of the string dominated by the N
node. STACK is the stack containing all the call
of the subtrees which has started an adjunction et
which must be recognized by the foot recognition
rules. We used S as the starting symbol of the
grammar and n is the length of the initial string.
Only the rules which prove a derivation are shown
in figure 6.
The form of a derivation item is
Name :&lt; Nodeγto, 7from, 7to, Type, 7ghost &gt;
where Name is the derivation, typed Type6, of
the tree 7from to the node Node of 7to.7
</bodyText>
<subsectionHeader confidence="0.998729">
6.2 Overview of the process
</subsectionHeader>
<bodyText confidence="0.995885846153846">
We refer to a ghost derivation as any derivation
which occurs in a tree anchored by an empty
element, and ghost tree as a tree anchored by
this empty element. As we can see in figure 5,
we assume that the proper ghost tree has been
selected. So the problem remains to know which
structure we have to use in order to synchronize
our derivation process.
Elliptic substitution of an initial ghost tree
on a tree αconj : Given a tree αconj (see Fig.
1) anchored by a coordinator and an initial tree
α1 of root P to be substituted in the leftmost P
node of αconj. Then the rule corresponding to
the traversal of the Leftmost P node would be
PαconjG(T,i,j,−,−) −� Pα1(T, i,j,−,−) .
So if this rule is validated, then we infer a deriva-
tion item called D1 :&lt;PαconjG,α1,αconj,subst,-&gt; .
Now, let us assume that the node situated to the
right of the coordinating conjunction dominates a
phrase whose verb has been erased (as in et Paul _
Virginie) and that there exists a tree of Root P with
two argument positions (a quasi tree like N0VN1
in LTAG literature for example). This ghost tree
is anchored by an empty element and is called
αghost. We have a rule, called Call-subst-ghost,
describing the traversal of this node :
</bodyText>
<equation confidence="0.889002">
PαconjD(T,j+1,n,-,-) −� Pαghost(T,j+1,n,-,-) .
</equation>
<bodyText confidence="0.976677">
For the sake of readability, let us call D1′ the
pseudo-derivation of call-subst-ghost :
</bodyText>
<equation confidence="0.574022">
D1′ :&lt; PαconjD, ? , αconj, subst, αghost &gt;
</equation>
<bodyText confidence="0.99994725">
where the non-instantiated variable, ? , indicates
the missing information in the synchronized tree.
If our hypothesis is correct, this tree will be ancho-
red by the anchor of α1. So we have to prepare this
anchoring by performing a synchronization with
existing derivations. This leads us to infer a ghost
substitution derivation of the tree α1 on the node
PαconjD. The inference rule which produces the
</bodyText>
<footnote confidence="0.905535166666667">
6which can be an adjunction (type = adj), a substitu-
tion (subst), an axiom (ax), an anchor which is usually an
implicit derivation in an LTAG derivation tree (anch) or a
“ghosted” one (adjg,substg,anchg)
7 Yghost is here to store the name of the ‘ghost tree’ if the
Node belongs to one or − otherwise.
</footnote>
<equation confidence="0.414243">
,
</equation>
<page confidence="0.85549">
149
</page>
<bodyText confidence="0.607711">
item called ghost(α1) on Figure 5, is therefore:
</bodyText>
<equation confidence="0.978883666666667">
D1′ :&lt; PαoonjD, ? , αconj, subst, αghost &gt;
D1 :&lt; Pα�onj R, α1, αconj, subst, − &gt;
Ghost − D1 :&lt; Pα�onj R, α1, αconj, substg, αghost &gt;
</equation>
<bodyText confidence="0.999645">
The process which is almost the same for the
remaining derivations, is described section 6.4.
</bodyText>
<subsectionHeader confidence="0.996544">
6.3 Ghost derivation and Item retrieving
</subsectionHeader>
<bodyText confidence="0.993434843137255">
In the last section we have described a ghost
derivation as a derivation which deals with a tree
anchored by an empty element, either it is the
source tree or the destination tree. In fact we need
to keep marks on the shared forest between what
we are really traversing during the parsing process
and what we are synchronizing, that is why we
need to have access to all the needed informations.
But the only rule which really knows which tree
will be either co-indexed or duplicated is the rule
describing the substitution of the realized tree.
So, we have to get this information by accessing
the corresponding derivation item. If we are in a
two phase generation process of a shared forest8
we can generate simultaneously the substitution
rules for the leftmost and rightmost nodes of the
tree anchored by a coordination and then we can
easily get the right synchronized derivation from
the start. Here we have to fetch from the chart this
item using unification variables through the path
of the derivations leading to it.
Let us call “climbing” the process of going
from a leaf node N of a tree -y to the node
belonging to the tree anchored by a coordi-
nator (αconj) and which dominates this node.
This “climbing” gives us a list of linked deri-
vations (ie. [&lt; -yx(N), -yy, -yx, Type, IsGhost &gt;
, &lt; -yz(N), -yx, -yz, Type1, IsGhost1 &gt;,..] where
-y(N) is the node of the tree -y where the derivation
takes place9). The last returned item is the one who
has an exact counterpart in the other conjunct, and
which is easy to recover as shown by the inference
rule in the previous section. Given this item, we
start the opposite process, called “descent”, which
use the available data gathered by the climbing
(the derivation starting nodes, the argumental po-
sition marked by an index on nodes in TAG gram-
8The first phase is the generation of the set of rules,
(Vijay-Shanker and Weir, 1993), and the second one is the fo-
rest traversal (Lang, 1992). See (Seddah and Gaiffe, 2005b)
for a way to generate a shared derivation forest where each
derivation rule infers its own derivation item, directly prepa-
red during the generation phase.
9The form of a derivation item is defined section 6.1
mars..) to follow a parallel path. Our algorithm can
be considered as taking the two resulting lists as a
parameter to produce the correct derivation item.
If we apply a two step generation process (shared
forest generation then extraction), the “descent”
and the “climbing” phase can be done in parallel
in the same time efficient way than(2005a).
</bodyText>
<subsectionHeader confidence="0.999524">
6.4 Description of inference rules
</subsectionHeader>
<bodyText confidence="0.99690717948718">
In this section we will describe all of the infe-
rences relative to the derivation in the right part,
resp. left, of the coordination, seen in figure 5.
In the remainder of this paper, we describe the
inference rules involved in so called predicative
derivations (substitutions and ghost substitutions).
Indeed, the status of adjunction is ambiguous. In
the general case, when an adjunct is present on one
side only of the conjunct, there are two possible
readings: one reading with an erased (co-indexed)
modifier on the other side, and one reading with no
such modifier at all on this other side. In the rea-
ding with erasing, there is an additionnal question,
which occurs in the substitution case as well : in
the derivation structure, shall we co-index the era-
sed node with its reference node, or shall we per-
form a (partial) copy, hence creating two (partially
co-indexed) nodes ? The answer to this question
is non-trivial, and an appropriate heuristics is nee-
ded. A first guess could be the following: any fully
erased node (which spans an empty range) is fully
co-indexed, any partially erased node is copied
(with partial co-indexation). In particular, erased
verbs are always copied, since they can not occur
without non-erased arguments (or modifiers).
Elliptic substitution of an initial tree α on a
ghost tree -yghost : If a tree α substituted in
a node Ni of a ghost tree -yghost (ie. Derivation
g-Der2’ on figure 5), where i is the traditional
index of an argumental position (N0,N1...) of this
tree; and if there exists a ghost derivation of a
substitution of the tree -yghost into a coordination
tree αconj (Der. g-Der1) and therefore if this
ghost derivation pertains to a tree αX where
a substitution derivation exists node Ni,(Der.
Der2) then we infer a ghost derivation indicating
the substitution of α on the forwarded tree αX
through the node Ni of the ghost tree -yghost (Der.
Ghost-Der2).
</bodyText>
<page confidence="0.9363">
150
</page>
<equation confidence="0.6562225">
g-Der2’:&lt; Ni., α, ? , substg, 7ghost &gt;
g-Der1:&lt; Pα_j D, αX, αconj, substg, 7ghost
Der2:&lt; Ni.X , −, αX, subst, − &gt;
ghost-Der2:&lt; Ni., α, ghost(αX), substg,7ghost &gt;
</equation>
<bodyText confidence="0.999430931034483">
This is the mechanism seen in the analysis of
“Jean aime Marie et Pierre Virginie” to provide the
derivation tree.
Elliptic substitution of a initial ghost tree αghost
on a tree γ substituted on an tree α onj : We
are here on a kind of opposite situation, we have
a realized subtree which lacks one of its argument
such as Jeani dormit puis ci mourut (Johni slept
then ci died). So we have to first let a mark in the
shared forest, then fetch the tree substituted on
the left part of the coordination, and get the tree
which has substituted on its ith node, then we will
be able to infer the proper substitution. We want
to create a real link, because as opposed to the last
case, it’s really a link, so the resulting structure
would be a graph with two links out of the tree
anchored by Jean, one to [dormir] (to sleep) and
one to [mourir] (to die).
If a ghost tree αghost substituted on a node Ni
of a tree α (Der. g-Der1’), if this tree α has been
substituted on a substitution node,P onjD, in the
rightmost part of a tree α onj, (Der. Der1) ancho-
red by a coordinating conjunction, if the leftmost
part node, P onjL, of α onj received a substitu-
tion of a tree αs, (Der. Der2) and if this tree has
a substitution of a tree αfinal on its ith node, (Der.
Der3) then we infer an item indicating a derivation
between the tree αfinal and the tree α on its node
Ni, (Der. g-Der1)10.
</bodyText>
<sectionHeader confidence="0.992498" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.953887875">
We presented a general framework to model and
to analyze elliptic constructions using simple me-
chanisms namely partial sharing and partial dupli-
cation through the use of a shared derivation fo-
rest in the LTAG framework. The main drawback
of this approach is the use of tree schemata as part
of parsing process because the anchoring process
10This mechanism without any restriction in the general
case, can lead to a exponential complexity w.r.t to the length
of the sentence.
must have a extremely good precision choose al-
gorithm when selecting the relevant trees. For the
best of our knowledge it is one of the first time that
merging tree schemata, shared forest walking and
graph induction, i.e., working with three different
levels of abstraction, is proposed. The mechanism
we presented is powerful enough to model much
more than the ellipsis of verbal heads and/or some
of their arguments. To model elliptic coordinations
for a given langage, the introduction of a specific
saturation feature may be needed to prevent over-
generation (as we presented in (Seddah and Sagot,
2006)). But the same mechanism can be used to go
beyond standard elliptic coordinations. Indeed, the
use of strongly structured anchors (e.g., with a dis-
tinction between the morphological lemma and the
lexeme) could allow a fine-grained specification of
partial value sharing phenomena (e.g. zeugmas).
Apart from an actual large scale implementation
of our approach (both in grammars and parsers),
future work includes applying the technique des-
cribed here to such more complex phenomena.
</bodyText>
<sectionHeader confidence="0.973653" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.964824096774194">
Anne Abeillé. 1991. Une grammaire lexicalisée
d’arbres adjoints pour le français. Ph.D. thesis, Pa-
ris 7.
Alfred V. Aho. 1968. Indexed grammars-an extension
of context-free grammars. J. ACM, 15(4) :647–671.
Marie-Hél’ene Candito and Sylvain Kahane. 1998.
Can the TAG derivation tree represent a semantic
graph? In Proceedings TAG+4, Philadelphie, pages
21–24.
Mary Dalrymple, Stuart M. Shieber, and Fernando
C. N. Pereira. 1991. Ellipsis and higher-order unifi-
cation. Linguistics and Philosophy, 14(4) :399–452.
Aravind K. Joshi and Yves Schabes. 1992. Tree Adjoi-
ning Grammars and lexicalized grammars. In Mau-
rice Nivat and Andreas Podelski, editors, Tree auto-
mata and languages. Elsevier Science.
Bernard Lang. 1991. Towards a Uniform Formal Fra-
mework for Parsing. In M. Tomita, editor, Current
Issues in Parsing Technology. Kluwer Academic Pu-
blishers.
Bernard Lang. 1992. Recognition can be harder than
parsing. In Proceeding of the Second TAG Work-
shop.
Owen Rambow and Aravind K. Joshi. 1994. A Formal
Look at Dependency Grammar and Phrase Structure
Grammars, with Special consideration of Word Or-
der Phenomena. Leo Wanner, Pinter London, 94.
Anoop Sarkar and Aravind Joshi. 1996. Coordination
in tree adjoining grammars : Formalization and im-
plementation. In COLING’96, Copenhagen, pages
610–615.
</reference>
<table confidence="0.980612166666667">
g-Der1’:&lt; Ni. , ? , α, substg, αghost &gt;
ghost
Der1:&lt; Pα_j D, α, αconj, subst, − &gt;
Der2:&lt; Pα_j L, αs, αconj, subst, − &gt;
Der3:&lt; Ni.g, αfinal, αs, subst, − &gt;
g-Der1:&lt; Ni., αfinal, α, subst, αghost &gt;
</table>
<page confidence="0.990618">
151
</page>
<reference confidence="0.889832666666667">
Djamé Seddah and Bertrand Gaiffe. 2005a. How to
build argumental graphs using TAG shared forest :
a view from control verbs problematic. In Proc.
of the 5th International Conference on the Logical
Aspect of Computional Linguistic - LACL’05, Bor-
deaux, France, Apr.
Djamé Seddah and Bertrand Gaiffe. 2005b. Using both
derivation tree and derived tree to get dependency
graph in derivation forest. In Proc. of the 6th In-
ternational Workshop on Computational Semantics
- IWCS-6, Tilburg, The Netherlands, Jan.
Djamé Seddah and Benoît Sagot. 2006. Modélisation
et analyse des coordinations elliptiques via l’exploi-
tation dynamique des forêts de dérivation. In Proc.
of Traitement automatique des Langues Naturelle -
TALN 06 - louveau, Belgium, Apr.
Stuart Shieber, Yves Schabes, and Fernando Pereira.
1995. Principles and implementation of deductive
parsing. Journal ofLogic Programming, 24 :3–36.
Marc Steedman. 1990. Gapping as constituant coordi-
nation. Linguistic and Philosophy, 13 :207–264.
K. Vijay-Shanker and D. Weir. 1993. The use of sha-
red forests in tree adjoining grammar parsing. In
EACL ’93, pages 384–393.
</reference>
<sectionHeader confidence="0.9191" genericHeader="acknowledgments">
8 Figures
</sectionHeader>
<table confidence="0.857794416666667">
1) Jean aimei Marie et Paul εi Virginie
John loves Mary and Paul Virginia
Predicate elision
2) Pauli mange une pomme et εi achète des cerises
Paul eats an apple and buys cherries
Right subject elision
3) Marie cuit εi et Pierre vend des crêpesi
Mary cooks and Peter sells pancakes
Left object elision
4)Mariei cuit εj et εi vend des crêpesj
Mary cooks and sells pancakes
Left object and right subject elision
</table>
<figure confidence="0.93023856">
FIG. 3 – Exemples of elliptic constructions
Derived tree
Et
Aimer ghost(Aimer)
Jean Marie Paul Virginie
FIG. 4 – Gapping and Forword Conjunction reduc-
tion
Shared forest Dependency graph
S
Conj(et)
Der. 0
ghost(α1)
α4 α5
Pconj
Pconj_D
Ghost Der. 1
Pα1
Ghost Der. 3
Ghost Der. 2
Pα1
N0 α1
Nα3
N N N
α3 α4 α5
Jean aime Marie Paul ε
</figure>
<bodyText confidence="0.946936826086957">
FIG. 5 – Shared forest and relative dependancy
graph for “Jean aime Marie et Paul Virginie”( John
loves Mary and Paul Virginie)
The “Call subst” rule is the rule which starts the recognition
of a substitution of the initial tree α on the node N of the tree
γ between the indices i and j. “Call adj” starts the recogni-
tion of the adjunction of the auxiliary tree β on the node N
of an elementary tree γ between i and j. “Call axiom” starts
the recognition α of an elementary tree spawning the whole
string. “Call no subs” starts the recognition of a node N of
a elementary tree γ dominating the empty node between the
indices i and j. “Call foot” starts the recognition of a subtree
dominated by the node Nγ between the indices i and j, the
node Ngamma was the start of the adjunction of the auxi-
liary tree β and ∗Nβ its foot node.
In order to avoid the “call adj” rule to be over generating, we
control the size of the stack by the number of possible ad-
junctions at a given state : if the automata has no cycle and
if each state of the automata goes forward (j always superior
to i), the number of possible adjunctions on a spine (the path
between the root of an auxiliary tree and its foot) is bounded
by the length of the string to be analyzed.
FIG. 6 – Shared forest derivation inference rules
</bodyText>
<figure confidence="0.998782772727273">
P
P et P
Et
Aimer Détester
N1
V
N0
N0
Marie
aime
Paul
i
ε i
Paul Virginie
Marie
N1
Virginie
V
déteste
Jean
N0
aime Marie Paul ε
i i
V
P
N1
et
P
N0
V N1
P
Virginie
Nα2
Nα2
Pconj_G
Vα1
Vα1
N1α1
Pconj
et
N0g Vg
Nα4
Vg
Pg
Pg
Virginie
N1g
Nα5
Der. 1
Der. 2
α2 α3
α1
call transition rules
Call subst &lt; ⊥, Nγ, i, j, −, −, R, Stack &gt; →
Call adj &lt; ⊤, Nα, i, j, −, −, R, Stack &gt;
Call axiom
Call no subs
Call foot
&lt; ⊤, Nγ, i, j, −, −, R, Stack &gt; →
&lt; ⊤, Nβ, i, j, −, −, R, [Nγ|Stack] &gt;
S → →
&lt; ⊤, Nα, �, n, −, −, ∅, ∅ &gt;
&lt; ⊥, Nγ, i, j, −, −, R, Stack &gt; →
true
&lt; ⊥, ∗Nβ, i, j, −, −, R, [Nγ|Stack] &gt;
&lt; ⊤, Nγ, i, j, −, −, R, [Stack] &gt;
</figure>
<page confidence="0.929389">
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.369360">
<title confidence="0.9927785">Modeling and Analysis of Elliptic Coordination by Dynamic Exploitation of Derivation Forests in LTAG parsing</title>
<author confidence="0.859668">Djamé Seddah</author>
<author confidence="0.859668">Benoît Sagot</author>
<affiliation confidence="0.813112">(1) NCLT - Dublin City University -</affiliation>
<address confidence="0.400733">(2) Projet ATOLL - INRIA -</address>
<email confidence="0.938953">benoit.sagot@inria.fr</email>
<abstract confidence="0.998682785714286">In this paper, we introduce a generic approach to elliptic coordination modeling through the parsing of Ltag grammars. We show that erased lexical items can be replaced during parsing by informations gathered in the other member of the coordinate structure and used as a guide at the derivation level. Moreover, we show how this approach can be indeed implemented as a light extension of the LTAG formalism throuh a so-called “fusion” operation and by the use of tree schemata during parsing in order to obtain a dependency graph.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeillé</author>
</authors>
<title>Une grammaire lexicalisée d’arbres adjoints pour le français.</title>
<date>1991</date>
<booktitle>Ph.D. thesis,</booktitle>
<location>Paris</location>
<contexts>
<context position="3674" citStr="Abeillé, 1991" startWordPosition="593" endWordPosition="594">ctures could differ on aspects, tense or number3). In an elliptic construction, some words are unrealized. Therefore, their associated syntactic structures are also non-realized, at least to some extent. However, our aim is to get, as a result of the parsing process, the full constituency and dependency structures of the sentence, including erased semantic items (or units) and their (empty) syntactic positions. Since their syntactic realizations have been erased, the construction of the dependency structure can not 1As elementary trees are lexicalized and must have a minimal semantic meaning (Abeillé, 1991), the derivation tree can be seen as a dependency tree with respect to the restrictions defined by (Rambow and Joshi, 1994) and (Candito and Kahane, 1998) to cite a few. 2P for Phrase in french, in Figures given in annex 3see “John lovesi Mary and childreni their gameboy” 147 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 147–152, Sydney, July 2006. c�2006 Association for Computational Linguistics be anchored to lexical items. Instead, it has to be anchored on non-realized lexical items and guided by the dependency structure of the referen</context>
</contexts>
<marker>Abeillé, 1991</marker>
<rawString>Anne Abeillé. 1991. Une grammaire lexicalisée d’arbres adjoints pour le français. Ph.D. thesis, Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
</authors>
<title>Indexed grammars-an extension of context-free grammars.</title>
<date>1968</date>
<journal>J. ACM,</journal>
<volume>15</volume>
<issue>4</issue>
<pages>647--671</pages>
<contexts>
<context position="9821" citStr="Aho, 1968" startWordPosition="1660" endWordPosition="1661">nd Weir, 1993; Lang, 1991), each tree anchored by the elements of the input sentence is described by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). Each part of a rule corresponds to an item à la Cock Kasami Younger described by (Shieber et al., 1995), whose form is &lt; N, POS, I, J, STACK &gt; with N a node of an elementary tree, POS the situation relative to an adjunction (marked T if an adjunction is still possible, 1 otherwise). This is marked on figure 5 with a bold dot in high position, T, or a bold dot in low position, 1). I and J are the start and end indices of the string dominated by the N node. STACK is the stack containing all the call of the subtrees which has started an adjunction et which must be recognized by the foot recogni</context>
</contexts>
<marker>Aho, 1968</marker>
<rawString>Alfred V. Aho. 1968. Indexed grammars-an extension of context-free grammars. J. ACM, 15(4) :647–671.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Hél’ene Candito</author>
<author>Sylvain Kahane</author>
</authors>
<title>Can the TAG derivation tree represent a semantic graph?</title>
<date>1998</date>
<booktitle>In Proceedings TAG+4, Philadelphie,</booktitle>
<pages>21--24</pages>
<contexts>
<context position="3828" citStr="Candito and Kahane, 1998" startWordPosition="618" endWordPosition="621">c structures are also non-realized, at least to some extent. However, our aim is to get, as a result of the parsing process, the full constituency and dependency structures of the sentence, including erased semantic items (or units) and their (empty) syntactic positions. Since their syntactic realizations have been erased, the construction of the dependency structure can not 1As elementary trees are lexicalized and must have a minimal semantic meaning (Abeillé, 1991), the derivation tree can be seen as a dependency tree with respect to the restrictions defined by (Rambow and Joshi, 1994) and (Candito and Kahane, 1998) to cite a few. 2P for Phrase in french, in Figures given in annex 3see “John lovesi Mary and childreni their gameboy” 147 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 147–152, Sydney, July 2006. c�2006 Association for Computational Linguistics be anchored to lexical items. Instead, it has to be anchored on non-realized lexical items and guided by the dependency structure of the reference phrase. Indeed, it is because of the parallelism between the reference phrase and the elliptical phrase that an ellipsis can be interpreted. 3 The Fusi</context>
</contexts>
<marker>Candito, Kahane, 1998</marker>
<rawString>Marie-Hél’ene Candito and Sylvain Kahane. 1998. Can the TAG derivation tree represent a semantic graph? In Proceedings TAG+4, Philadelphie, pages 21–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>Stuart M Shieber</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Ellipsis and higher-order unification.</title>
<date>1991</date>
<journal>Linguistics and Philosophy,</journal>
<volume>14</volume>
<issue>4</issue>
<pages>399--452</pages>
<contexts>
<context position="1552" citStr="Dalrymple et al., 1991" startWordPosition="252" endWordPosition="255"> of Derivation Forests. The use of this device implies that the resolution mechanism depends on syntactic information, therefore we will not deal with anaphoric resolutions and scope modifier problems. We show how to generate a derivation forest described by a set of context free rules (similar to (Vijay-Shanker and Weir, 1993)) augmented by a stack of current adjunctions when a rule describes a spine traversal. We first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the analysis of (Dalrymple et al., 1991) and (Steedman, 1990) and we show how it differs from (Sarkar and Joshi, 1996). We assume that the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind </context>
<context position="7219" citStr="Dalrymple et al., 1991" startWordPosition="1207" endWordPosition="1210">ly the correct answer. As we said, aspect, tense and in most case diathesis for 4 are shared, as it is showed by the following sentences : (3)*Paul killed John and Bill by Rodger (4)*Paul ate apple and Mary will pears As opposed to (4), we believe “Paul ate apples and Mary will do pears” to be correct but in this case, we do not strictly have an ellipsis but a semi-modal verb which is susbsumed by its co-referent. Although our proposition focuses on syntax-semantic interface, mainly missing syntactic arguments. 5 Ghost Trees and Logical Abstractions Looking either at the approach proposed by (Dalrymple et al., 1991) or (Steedman, 1990) for the treatment of sentences with gaps, we note that in both cases5 one wants to abstract the realized element in one side of the coordination in order to instantiate it in the other conjunct using the coordinator as the pivot of this process. In our analysis, this is exactly the role of ghost trees to support such abstraction (talking either about High Order Variable or A-abstraction). In this regard, the fusion operation has only to check that the derivations induced by the ghost tree superimpose well with the derivations of the realized side. This is where our approac</context>
</contexts>
<marker>Dalrymple, Shieber, Pereira, 1991</marker>
<rawString>Mary Dalrymple, Stuart M. Shieber, and Fernando C. N. Pereira. 1991. Ellipsis and higher-order unification. Linguistics and Philosophy, 14(4) :399–452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Tree Adjoining Grammars and lexicalized grammars.</title>
<date>1992</date>
<editor>In Maurice Nivat and Andreas Podelski, editors,</editor>
<publisher>Elsevier Science.</publisher>
<contexts>
<context position="1751" citStr="Joshi and Schabes, 1992" startWordPosition="285" endWordPosition="288">ms. We show how to generate a derivation forest described by a set of context free rules (similar to (Vijay-Shanker and Weir, 1993)) augmented by a stack of current adjunctions when a rule describes a spine traversal. We first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the analysis of (Dalrymple et al., 1991) and (Steedman, 1990) and we show how it differs from (Sarkar and Joshi, 1996). We assume that the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind of dependency structure when it is not possible to rely on lexical information, as opposed to (Seddah and Gaiffe, 2005a), is significantly more complicated. An example of this is provided by elliptic</context>
</contexts>
<marker>Joshi, Schabes, 1992</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1992. Tree Adjoining Grammars and lexicalized grammars. In Maurice Nivat and Andreas Podelski, editors, Tree automata and languages. Elsevier Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Towards a Uniform Formal Framework for Parsing.</title>
<date>1991</date>
<booktitle>Current Issues in Parsing Technology.</booktitle>
<editor>In M. Tomita, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="9237" citStr="Lang, 1991" startWordPosition="1560" endWordPosition="1561"> the tree anchored by a coordinator acts similarly to an auxiliary tree with two foot nodes. This may cause difficulties to derive the now dag into a linear string. In our approach, we use empty lexical items in order to leave traces in the derivation forest and to have syntacticly motivated derived tree (cf fig. 5) if we extract only the regular LTAG “derivation item” from the forest. 6 LTAG implementation 6.1 Working on shared forest A shared forest is a structure which combines all the information coming from derivation trees and from derived trees. Following (Vijay-Shanker and Weir, 1993; Lang, 1991), each tree anchored by the elements of the input sentence is described by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). Each part of a</context>
</contexts>
<marker>Lang, 1991</marker>
<rawString>Bernard Lang. 1991. Towards a Uniform Formal Framework for Parsing. In M. Tomita, editor, Current Issues in Parsing Technology. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Recognition can be harder than parsing.</title>
<date>1992</date>
<booktitle>In Proceeding of the Second TAG Workshop.</booktitle>
<contexts>
<context position="15146" citStr="Lang, 1992" startWordPosition="2625" endWordPosition="2626"> &gt;,..] where -y(N) is the node of the tree -y where the derivation takes place9). The last returned item is the one who has an exact counterpart in the other conjunct, and which is easy to recover as shown by the inference rule in the previous section. Given this item, we start the opposite process, called “descent”, which use the available data gathered by the climbing (the derivation starting nodes, the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules, (Vijay-Shanker and Weir, 1993), and the second one is the forest traversal (Lang, 1992). See (Seddah and Gaiffe, 2005b) for a way to generate a shared derivation forest where each derivation rule infers its own derivation item, directly prepared during the generation phase. 9The form of a derivation item is defined section 6.1 mars..) to follow a parallel path. Our algorithm can be considered as taking the two resulting lists as a parameter to produce the correct derivation item. If we apply a two step generation process (shared forest generation then extraction), the “descent” and the “climbing” phase can be done in parallel in the same time efficient way than(2005a). 6.4 Descr</context>
</contexts>
<marker>Lang, 1992</marker>
<rawString>Bernard Lang. 1992. Recognition can be harder than parsing. In Proceeding of the Second TAG Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Aravind K Joshi</author>
</authors>
<title>A Formal Look at Dependency Grammar and Phrase Structure Grammars, with Special consideration of Word Order Phenomena. Leo Wanner,</title>
<date>1994</date>
<location>Pinter London,</location>
<contexts>
<context position="3797" citStr="Rambow and Joshi, 1994" startWordPosition="613" endWordPosition="616">re, their associated syntactic structures are also non-realized, at least to some extent. However, our aim is to get, as a result of the parsing process, the full constituency and dependency structures of the sentence, including erased semantic items (or units) and their (empty) syntactic positions. Since their syntactic realizations have been erased, the construction of the dependency structure can not 1As elementary trees are lexicalized and must have a minimal semantic meaning (Abeillé, 1991), the derivation tree can be seen as a dependency tree with respect to the restrictions defined by (Rambow and Joshi, 1994) and (Candito and Kahane, 1998) to cite a few. 2P for Phrase in french, in Figures given in annex 3see “John lovesi Mary and childreni their gameboy” 147 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 147–152, Sydney, July 2006. c�2006 Association for Computational Linguistics be anchored to lexical items. Instead, it has to be anchored on non-realized lexical items and guided by the dependency structure of the reference phrase. Indeed, it is because of the parallelism between the reference phrase and the elliptical phrase that an ellipsis</context>
</contexts>
<marker>Rambow, Joshi, 1994</marker>
<rawString>Owen Rambow and Aravind K. Joshi. 1994. A Formal Look at Dependency Grammar and Phrase Structure Grammars, with Special consideration of Word Order Phenomena. Leo Wanner, Pinter London, 94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anoop Sarkar</author>
<author>Aravind Joshi</author>
</authors>
<title>Coordination in tree adjoining grammars : Formalization and implementation.</title>
<date>1996</date>
<booktitle>In COLING’96, Copenhagen,</booktitle>
<pages>610--615</pages>
<contexts>
<context position="1630" citStr="Sarkar and Joshi, 1996" startWordPosition="266" endWordPosition="269">hanism depends on syntactic information, therefore we will not deal with anaphoric resolutions and scope modifier problems. We show how to generate a derivation forest described by a set of context free rules (similar to (Vijay-Shanker and Weir, 1993)) augmented by a stack of current adjunctions when a rule describes a spine traversal. We first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the analysis of (Dalrymple et al., 1991) and (Steedman, 1990) and we show how it differs from (Sarkar and Joshi, 1996). We assume that the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind of dependency structure when it is not possible to rely on lexical information</context>
<context position="7867" citStr="Sarkar and Joshi, 1996" startWordPosition="1320" endWordPosition="1323">the treatment of sentences with gaps, we note that in both cases5 one wants to abstract the realized element in one side of the coordination in order to instantiate it in the other conjunct using the coordinator as the pivot of this process. In our analysis, this is exactly the role of ghost trees to support such abstraction (talking either about High Order Variable or A-abstraction). In this regard, the fusion operation has only to check that the derivations induced by the ghost tree superimpose well with the derivations of the realized side. This is where our approach differs strongly from (Sarkar and Joshi, 1996). Using the fusion operation involves inserting partial derivations, which are linked to already existing ones (the realized derivation), into the shared forest whereas using 4w.r.t to the examples of (Dalrymple et al., 1991), i.e “It is possible that this result can be derived (..) but I know of no theory that does so.” 5Footnote n˚3, page 5 for (Dalrymple et al., 1991), and pages 41-42 for (Steedman, 1990). ���� ���� ������ ������ ������ ������ �� �� γ ��� ��� α ��� ��� αconj ���� ���� ������ ������ ������ ������ �� �� γ ��� ��� α ����� ����� ����� ����� α’ ����� ����� ��� ��� αconj Pαconj P</context>
</contexts>
<marker>Sarkar, Joshi, 1996</marker>
<rawString>Anoop Sarkar and Aravind Joshi. 1996. Coordination in tree adjoining grammars : Formalization and implementation. In COLING’96, Copenhagen, pages 610–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
<author>Bertrand Gaiffe</author>
</authors>
<title>How to build argumental graphs using TAG shared forest : a view from control verbs problematic.</title>
<date>2005</date>
<booktitle>In Proc. of the 5th International Conference on the Logical Aspect of Computional Linguistic - LACL’05,</booktitle>
<location>Bordeaux, France,</location>
<contexts>
<context position="2270" citStr="Seddah and Gaiffe, 2005" startWordPosition="368" endWordPosition="371">the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind of dependency structure when it is not possible to rely on lexical information, as opposed to (Seddah and Gaiffe, 2005a), is significantly more complicated. An example of this is provided by elliptic coordination. Consider the sentences Figure 3. They all can be analyzed as coordinations of S categories2 with one side lacking one mandatory argument. In (4), one could argue for VP coordination, because the two predicates share the same continuum (same subcategorization frame and semantic space). However the S hypothesis is more generalizable and supports more easily the analysis of coordination of unlike categories (“John is a republican and proud of it” becomes “Johnz isj a republican and εz εj proud of it”).</context>
<context position="9764" citStr="Seddah and Gaiffe, 2005" startWordPosition="1649" endWordPosition="1652">om derivation trees and from derived trees. Following (Vijay-Shanker and Weir, 1993; Lang, 1991), each tree anchored by the elements of the input sentence is described by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). Each part of a rule corresponds to an item à la Cock Kasami Younger described by (Shieber et al., 1995), whose form is &lt; N, POS, I, J, STACK &gt; with N a node of an elementary tree, POS the situation relative to an adjunction (marked T if an adjunction is still possible, 1 otherwise). This is marked on figure 5 with a bold dot in high position, T, or a bold dot in low position, 1). I and J are the start and end indices of the string dominated by the N node. STACK is the stack containing all the call of the subtrees which has started an a</context>
<context position="15176" citStr="Seddah and Gaiffe, 2005" startWordPosition="2628" endWordPosition="2631"> is the node of the tree -y where the derivation takes place9). The last returned item is the one who has an exact counterpart in the other conjunct, and which is easy to recover as shown by the inference rule in the previous section. Given this item, we start the opposite process, called “descent”, which use the available data gathered by the climbing (the derivation starting nodes, the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules, (Vijay-Shanker and Weir, 1993), and the second one is the forest traversal (Lang, 1992). See (Seddah and Gaiffe, 2005b) for a way to generate a shared derivation forest where each derivation rule infers its own derivation item, directly prepared during the generation phase. 9The form of a derivation item is defined section 6.1 mars..) to follow a parallel path. Our algorithm can be considered as taking the two resulting lists as a parameter to produce the correct derivation item. If we apply a two step generation process (shared forest generation then extraction), the “descent” and the “climbing” phase can be done in parallel in the same time efficient way than(2005a). 6.4 Description of inference rules In t</context>
</contexts>
<marker>Seddah, Gaiffe, 2005</marker>
<rawString>Djamé Seddah and Bertrand Gaiffe. 2005a. How to build argumental graphs using TAG shared forest : a view from control verbs problematic. In Proc. of the 5th International Conference on the Logical Aspect of Computional Linguistic - LACL’05, Bordeaux, France, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
<author>Bertrand Gaiffe</author>
</authors>
<title>Using both derivation tree and derived tree to get dependency graph in derivation forest.</title>
<date>2005</date>
<booktitle>In Proc. of the 6th International Workshop on Computational Semantics - IWCS-6,</booktitle>
<location>Tilburg, The Netherlands,</location>
<contexts>
<context position="2270" citStr="Seddah and Gaiffe, 2005" startWordPosition="368" endWordPosition="371">the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind of dependency structure when it is not possible to rely on lexical information, as opposed to (Seddah and Gaiffe, 2005a), is significantly more complicated. An example of this is provided by elliptic coordination. Consider the sentences Figure 3. They all can be analyzed as coordinations of S categories2 with one side lacking one mandatory argument. In (4), one could argue for VP coordination, because the two predicates share the same continuum (same subcategorization frame and semantic space). However the S hypothesis is more generalizable and supports more easily the analysis of coordination of unlike categories (“John is a republican and proud of it” becomes “Johnz isj a republican and εz εj proud of it”).</context>
<context position="9764" citStr="Seddah and Gaiffe, 2005" startWordPosition="1649" endWordPosition="1652">om derivation trees and from derived trees. Following (Vijay-Shanker and Weir, 1993; Lang, 1991), each tree anchored by the elements of the input sentence is described by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). Each part of a rule corresponds to an item à la Cock Kasami Younger described by (Shieber et al., 1995), whose form is &lt; N, POS, I, J, STACK &gt; with N a node of an elementary tree, POS the situation relative to an adjunction (marked T if an adjunction is still possible, 1 otherwise). This is marked on figure 5 with a bold dot in high position, T, or a bold dot in low position, 1). I and J are the start and end indices of the string dominated by the N node. STACK is the stack containing all the call of the subtrees which has started an a</context>
<context position="15176" citStr="Seddah and Gaiffe, 2005" startWordPosition="2628" endWordPosition="2631"> is the node of the tree -y where the derivation takes place9). The last returned item is the one who has an exact counterpart in the other conjunct, and which is easy to recover as shown by the inference rule in the previous section. Given this item, we start the opposite process, called “descent”, which use the available data gathered by the climbing (the derivation starting nodes, the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules, (Vijay-Shanker and Weir, 1993), and the second one is the forest traversal (Lang, 1992). See (Seddah and Gaiffe, 2005b) for a way to generate a shared derivation forest where each derivation rule infers its own derivation item, directly prepared during the generation phase. 9The form of a derivation item is defined section 6.1 mars..) to follow a parallel path. Our algorithm can be considered as taking the two resulting lists as a parameter to produce the correct derivation item. If we apply a two step generation process (shared forest generation then extraction), the “descent” and the “climbing” phase can be done in parallel in the same time efficient way than(2005a). 6.4 Description of inference rules In t</context>
</contexts>
<marker>Seddah, Gaiffe, 2005</marker>
<rawString>Djamé Seddah and Bertrand Gaiffe. 2005b. Using both derivation tree and derived tree to get dependency graph in derivation forest. In Proc. of the 6th International Workshop on Computational Semantics - IWCS-6, Tilburg, The Netherlands, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
<author>Benoît Sagot</author>
</authors>
<title>Modélisation et analyse des coordinations elliptiques via l’exploitation dynamique des forêts de dérivation.</title>
<date>2006</date>
<booktitle>In Proc. of Traitement automatique des Langues Naturelle -TALN 06 - louveau,</booktitle>
<location>Belgium,</location>
<marker>Seddah, Sagot, 2006</marker>
<rawString>Djamé Seddah and Benoît Sagot. 2006. Modélisation et analyse des coordinations elliptiques via l’exploitation dynamique des forêts de dérivation. In Proc. of Traitement automatique des Langues Naturelle -TALN 06 - louveau, Belgium, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
<author>Fernando Pereira</author>
</authors>
<title>Principles and implementation of deductive parsing.</title>
<date>1995</date>
<journal>Journal ofLogic Programming,</journal>
<volume>24</volume>
<pages>3--36</pages>
<contexts>
<context position="9926" citStr="Shieber et al., 1995" startWordPosition="1678" endWordPosition="1681">bed by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). Each part of a rule corresponds to an item à la Cock Kasami Younger described by (Shieber et al., 1995), whose form is &lt; N, POS, I, J, STACK &gt; with N a node of an elementary tree, POS the situation relative to an adjunction (marked T if an adjunction is still possible, 1 otherwise). This is marked on figure 5 with a bold dot in high position, T, or a bold dot in low position, 1). I and J are the start and end indices of the string dominated by the N node. STACK is the stack containing all the call of the subtrees which has started an adjunction et which must be recognized by the foot recognition rules. We used S as the starting symbol of the grammar and n is the length of the initial string. On</context>
</contexts>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Stuart Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and implementation of deductive parsing. Journal ofLogic Programming, 24 :3–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Steedman</author>
</authors>
<title>Gapping as constituant coordination.</title>
<date>1990</date>
<journal>Linguistic and Philosophy,</journal>
<volume>13</volume>
<pages>207--264</pages>
<contexts>
<context position="1573" citStr="Steedman, 1990" startWordPosition="257" endWordPosition="258">se of this device implies that the resolution mechanism depends on syntactic information, therefore we will not deal with anaphoric resolutions and scope modifier problems. We show how to generate a derivation forest described by a set of context free rules (similar to (Vijay-Shanker and Weir, 1993)) augmented by a stack of current adjunctions when a rule describes a spine traversal. We first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the analysis of (Dalrymple et al., 1991) and (Steedman, 1990) and we show how it differs from (Sarkar and Joshi, 1996). We assume that the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree which is strictly the history of the operations needed to build a constituent structure, the derived tree. In order to be fully appropriate for semantic inference 1, the derivation tree should display every syntactico-semantic argument and therefore should be a graph. However to obtain this kind of dependency structu</context>
<context position="7239" citStr="Steedman, 1990" startWordPosition="1212" endWordPosition="1213"> said, aspect, tense and in most case diathesis for 4 are shared, as it is showed by the following sentences : (3)*Paul killed John and Bill by Rodger (4)*Paul ate apple and Mary will pears As opposed to (4), we believe “Paul ate apples and Mary will do pears” to be correct but in this case, we do not strictly have an ellipsis but a semi-modal verb which is susbsumed by its co-referent. Although our proposition focuses on syntax-semantic interface, mainly missing syntactic arguments. 5 Ghost Trees and Logical Abstractions Looking either at the approach proposed by (Dalrymple et al., 1991) or (Steedman, 1990) for the treatment of sentences with gaps, we note that in both cases5 one wants to abstract the realized element in one side of the coordination in order to instantiate it in the other conjunct using the coordinator as the pivot of this process. In our analysis, this is exactly the role of ghost trees to support such abstraction (talking either about High Order Variable or A-abstraction). In this regard, the fusion operation has only to check that the derivations induced by the ghost tree superimpose well with the derivations of the realized side. This is where our approach differs strongly f</context>
</contexts>
<marker>Steedman, 1990</marker>
<rawString>Marc Steedman. 1990. Gapping as constituant coordination. Linguistic and Philosophy, 13 :207–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>D Weir</author>
</authors>
<title>The use of shared forests in tree adjoining grammar parsing.</title>
<date>1993</date>
<booktitle>In EACL ’93,</booktitle>
<pages>384--393</pages>
<contexts>
<context position="1258" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="203" endWordPosition="206">indeed implemented as a light extension of the LTAG formalism throuh a so-called “fusion” operation and by the use of tree schemata during parsing in order to obtain a dependency graph. 1 Introduction The main goal of this research is to provide a way of solving elliptic coordination through the use of Derivation Forests. The use of this device implies that the resolution mechanism depends on syntactic information, therefore we will not deal with anaphoric resolutions and scope modifier problems. We show how to generate a derivation forest described by a set of context free rules (similar to (Vijay-Shanker and Weir, 1993)) augmented by a stack of current adjunctions when a rule describes a spine traversal. We first briefly discuss the linguistic motivations behind the resolution mechanism we propose, then introduce the fusion operation and show how it can be compared to the analysis of (Dalrymple et al., 1991) and (Steedman, 1990) and we show how it differs from (Sarkar and Joshi, 1996). We assume that the reader is familiar with the Lexicalized Tree Adjoining Grammars formalism ((Joshi and Schabes, 1992)). 2 Linguistic Motivations : a parallelism of Derivation The LTAG formalism provides a derivation tree whi</context>
<context position="9224" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="1556" endWordPosition="1559">des from different trees while the tree anchored by a coordinator acts similarly to an auxiliary tree with two foot nodes. This may cause difficulties to derive the now dag into a linear string. In our approach, we use empty lexical items in order to leave traces in the derivation forest and to have syntacticly motivated derived tree (cf fig. 5) if we extract only the regular LTAG “derivation item” from the forest. 6 LTAG implementation 6.1 Working on shared forest A shared forest is a structure which combines all the information coming from derivation trees and from derived trees. Following (Vijay-Shanker and Weir, 1993; Lang, 1991), each tree anchored by the elements of the input sentence is described by a set of rewriting rules. We use the fact that each rule which validates a derivation can infer a derivation item and has access to the whole chart in order to prepare the inference process. The goal is to use the shared forest as a guide for synchronizing the derivation structures from both parts of the coordinator. This forest is represented by a context free grammar augmented by a stack containing the current adjunctions (Seddah and Gaiffe, 2005a), which looks like a Linear Indexed Grammar (Aho, 1968). E</context>
<context position="15089" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="2612" endWordPosition="2615"> [&lt; -yx(N), -yy, -yx, Type, IsGhost &gt; , &lt; -yz(N), -yx, -yz, Type1, IsGhost1 &gt;,..] where -y(N) is the node of the tree -y where the derivation takes place9). The last returned item is the one who has an exact counterpart in the other conjunct, and which is easy to recover as shown by the inference rule in the previous section. Given this item, we start the opposite process, called “descent”, which use the available data gathered by the climbing (the derivation starting nodes, the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules, (Vijay-Shanker and Weir, 1993), and the second one is the forest traversal (Lang, 1992). See (Seddah and Gaiffe, 2005b) for a way to generate a shared derivation forest where each derivation rule infers its own derivation item, directly prepared during the generation phase. 9The form of a derivation item is defined section 6.1 mars..) to follow a parallel path. Our algorithm can be considered as taking the two resulting lists as a parameter to produce the correct derivation item. If we apply a two step generation process (shared forest generation then extraction), the “descent” and the “climbing” phase can be done in paral</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1993</marker>
<rawString>K. Vijay-Shanker and D. Weir. 1993. The use of shared forests in tree adjoining grammar parsing. In EACL ’93, pages 384–393.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>