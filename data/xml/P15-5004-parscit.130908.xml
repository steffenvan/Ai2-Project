<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003334">
<title confidence="0.992862">
Corpus Pattern for Semantic Processing
</title>
<author confidence="0.998368">
Patrick Hanks
</author>
<affiliation confidence="0.997607">
University of Wolverhampton, UK
</affiliation>
<email confidence="0.935825">
patrick.w.hanks@gmail.com
</email>
<author confidence="0.982062">
Daisuke Kawahara
</author>
<affiliation confidence="0.950798">
Kyoto University, JP
</affiliation>
<email confidence="0.98731">
dk@i.kyoto-u.ac.jp
</email>
<author confidence="0.98887">
Elisabetta Jezek
</author>
<affiliation confidence="0.996541">
University of Pavia, IT
</affiliation>
<email confidence="0.919841">
jezek@unipv.it
</email>
<author confidence="0.883146">
Octavian Popescu
</author>
<affiliation confidence="0.76022">
IBM Research, US
</affiliation>
<email confidence="0.979902">
o.popescu@us.ibm.com
</email>
<sectionHeader confidence="0.999624" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976615384616">
This tutorial presents a corpus-driven, pat-
tern-based empirical approach to meaning
representation and computation. Patterns in
text are everywhere, but techniques for iden-
tifying and processing them are still rudi-
mentary. Patterns are not merely syntactic
but syntagmatic: each pattern identifies a
lexico-semantic clause structure consisting
of a predicator (verb or predicative adjective)
together with open-ended lexical sets of col-
locates in different clause roles (subject, ob-
ject, prepositional argument, etc.). If NLP is
to make progress in identifying and pro-
cessing text meaning, pattern recognition and
collocational analysis will play an essential
role, because:
Many, if not most meanings, require
the presence of more than one word
for their normal realization. ... Pat-
terns of co-selection among words,
which are much stronger than any
description has yet allowed for,
have a direct connection with mean-
ing. (J. M. Sinclair, 1998).
The tutorial presents methods for building
patterns on the basis of corpus evidence, us-
ing machine learning methods. It discusses
some possible applications of pattern inven-
tories and invites discussion of others. It is
intended for an audience with heterogeneous
competences but with a common interest in
corpus linguistics and computational models
for meaning-related tasks in NLP. We report
on the methodologies for building resources
for semantic processing and their contribu-
tion to NLP tasks. The goal is to provide the
audience with an operative understanding of
the methodology used to acquire corpus pat-
terns and of their utility in NLP applications.
</bodyText>
<sectionHeader confidence="0.986945" genericHeader="keywords">
2 Overview
</sectionHeader>
<bodyText confidence="0.999953">
Natural language sentences make use of lex-
ical, syntactic, semantic and pragmatic in-
formation in order to fulfill their role of con-
veying meaning. Previous research on com-
puting the meaning of linguistic expressions
- from approaches which consider overt dis-
tributional information on words to deep se-
mantic ones, based on first order and lambda
calculus representations - has highlighted
two major issues: (1) the appropriate level of
formalization for meaning representation
cannot be founded only on premises derived
from prior experience, (2) the lack of large-
scale annotated corpora which combine dif-
ferent levels of semantic annotation hinders
the development of machine-learning appli-
cations. In particular, in the framework of
big data analytics for semantically pro-
cessing large corpora, these two issues must
be addressed.
The regular structure of normal clauses can
be used as a basis in order to learn the rules
that lie behind recurrent meaningful con-
structs in natural language. It has been
</bodyText>
<footnote confidence="0.802829">
shown (Hanks&amp;Pustejovsky 2004,
Pustejovsky&amp;Jezek 2008, Popescu&amp;Magnini
2007, Popescu 2013, Kawahara et al. 2014)
</footnote>
<page confidence="0.980664">
12
</page>
<note confidence="0.7947655">
Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 12–15,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999925393939394">
that it is possible to identify and to learn cor-
pus patterns that encode the information that
accounts for the senses of the verb and its
arguments in the context. These patterns link
the syntactic structure of clauses and the se-
mantic types of argument fillers via the role
that each of these play in the disambiguation
of the clause as a whole. With regard to ir-
regularities, there are quite a few clauses in a
corpus where these patterns do not seem to
match the text, because of the apparent in-
compatibility between the actual and the ex-
pected semantic types of the arguments (Jez-
ek&amp;Hanks 2010, Hanks 2012). However, it
is possible to build statistical models that
simultaneously generate both the regular and
the innovative representation of a clause.
Available solutions developed up to now
range from supervised to totally unsuper-
vised approaches. The patterns obtained en-
code the necessary information for handling
the meaning of each word individually as
well as that of the clause as a whole. As such
they are instrumental in building better lan-
guage models (Dligach&amp;Palmer 2011). In
the contexts matched by such patterns, any
word is unequivocally disambiguated. The
semantic types used in pattern representation
play a discriminative role, therefore the pat-
terns are sense discriminative and as such
they can be used in word sense disambigua-
tion and other meaning-related tasks (see
among others Pustejovsky et al. 2004, Cum-
by&amp;Roth 2003, Popescu&amp;Magnini 2007,
Pustejovsky et al. 2010, Popescu et al. 2014).
Also, the meaning of a pattern as a whole is
expressed as a set of basic implicatures. The
implicatures are instrumental in textual en-
tailment, semantic similarity and paraphras-
ing generation (Popescu et al. 2011, Nico-
lae&amp;Popescu 2013, Vo et. al 2014). Depend-
ing on the proposed application, the implica-
tures associated with a pattern may be ex-
pressed in any of a wide variety of other
ways, e.g. as a translation into another lan-
guage or as a synonym set. The automatic
aligning of the set of patterns of two lan-
guages via their shared semantic types is
used in meaning-preserving translation tasks
(Popescu&amp;Jezek 2013).
The relatively recent research on corpus data
has shown that intermediate text representa-
tions (ITRs), built in a bottom-up manner
from corpus examples towards a complex
representation of clauses, play an important
role in dealing with the meaning disambigua-
tion problem. ITRs offer an important degree
of freedom in finding the right cut between
various levels of semantic information.
Large-scale corpus-driven lexical analysis
leads to two apparently contradictory con-
clusions. On the one hand, the regularities of
word use (valencies, collocations) are more
regular than what most pre-corpus linguists
would have predicted. On the other hand, the
irregularities are more irregular. In particu-
lar, verb usage in language displays a con-
tinuous blend between regular constructs
with clearly distinct senses and new and in-
novative usages. The Theory of Norms and
Exploitations (Hanks 2013) maintains that
language exhibits mainly a rule-governed
behavior, but argues that there is not just one
monolithic system of rules. Instead, there are
two interactive sets of rules: 1) Norms: a set
of rules for using words normally and idio-
matically: these are the rules of grammar;
they account for 70%-90% of all utterances -
depending on the type of the verb, the topic,
and the domain. However, they do not ac-
count for linguistic creativity, nor for chang-
es in word meaning; 2) Exploitation rules,
which account for creativity and innovative
usage (about 10%-30% of corpus examples).
Exploitation rules also account for phenom-
ena such as meaning shift. Pattern Dictionar-
ies are resources based on Corpus Pattern
Analysis (CPA). They contains examples for
each category for a large number of English
and Italian verbs and are available at
http://pdev.org.uk/ (Hanks 2004), and at
http://tpas.fbk.eu/resource (Jezek et al.
2014).
The corpus-pattern methodology is designed
to offer a viable solution to meaning repre-
sentation. The techniques we present are
widely applicable in NLP and they deal effi-
ciently with data sparseness and open do-
main expression of semantic relationships.
</bodyText>
<page confidence="0.996579">
13
</page>
<figure confidence="0.57586075">
Textual Entailment, Paraphrase Gener-
ation and Textual Similarity with Cor-
pus Patterns
4 Tutors
</figure>
<bodyText confidence="0.973993714285714">
The tutorial is divided into three main parts,
which are strongly interconnected: (A)
Building Corpus Patterns via the Theory of
Norms and Exploitations, (B) Inducing Se-
mantic Types and Semantic Task Oriented
Ontologies, and (C) Machine Learning and
Applications of Corpus Patterns.
</bodyText>
<sectionHeader confidence="0.995555" genericHeader="introduction">
3 Outline
</sectionHeader>
<subsectionHeader confidence="0.851831">
3.1 Corpus, Language Usage and Computa-
ble Semantic Properties of Verb Phrases
</subsectionHeader>
<figure confidence="0.686484846153846">
section
Basic Computational Semantic Con-
cepts
Theory of Norm and Exploitation of
Language Usage
Corpus Pattern Analysis in Sketch En-
gine
Sense Discriminative Patterns
3.2 Semantic Types and Ontologies
Argument Structures
Frames and Semantic Types
Inducing Semantic Types
Discriminative Patterns
</figure>
<subsectionHeader confidence="0.796964666666667">
3.3 Statistical Models for Corpus Pattern
Recognition and Extraction. NLP Appli-
cations
</subsectionHeader>
<bodyText confidence="0.70346425">
Finite State Markov Chains
Naive Bayesian and Gaussian Random
Fields for Conditional Probabilities over
Semantic Types
</bodyText>
<subsectionHeader confidence="0.242354">
Latent Dirichlet Analysis for Unsuper-
vised Pattern Extraction
</subsectionHeader>
<bodyText confidence="0.9531435">
Probably Approximately Correct and
Statistical Query Model
Joint Source Channel Model for Recog-
nition of Norm and Exploitation
Patrick Hanks is Professor in Lexicography
at the Research Institute of Information and
Language Processing at the University of
Wolverhampton. He is also a visiting profes-
sor at the Bristol Centre for Linguistics
(University of the West of England). He
studied English Language and Literature at
Oxford and was awarded a PhD in Informat-
ics at the Masaryk University in Brno, Czech
Republic. In the 1980s he was the managing
editor of Cobuild, an innovative corpus-
based dictionary compiled at the University
of Birmingham. In 1989-90 he co-authored
with Ken Church and others a series of pa-
pers on statistical approaches to lexical anal-
ysis. For ten years (1990–2000) he was chief
editor of Current English Dictionaries at Ox-
ford University Press. He is the author of
Lexical Analysis: Norms and Exploitations
(MIT Press, 2013), which presents a new
theory of word meaning and language in
use. He is a consultant on lexicographical
methodology and definition to several insti-
tutions throughout Europe, including Oxford
University Press, and is a frequent invited
plenary speaker at international conferences
on lexicography, corpus linguistics, figura-
tive language, onomastics, and phraseology.
Elisabetta Jezek has been teaching Syntax
and Semantics and Applied Linguistics at the
University of Pavia since 2001. Her research
interests and areas of expertise are lexical
semantics, verb classification, theory of Ar-
gument Structure, event structure in syntax
and semantics, corpus annotation, computa-
tional Lexicography.
Daisuke Kawahara is an Associate Profes-
sor at Kyoto University. He is an expert in
the areas of parsing, knowledge acquisition
and information analysis. He teaches gradu-
</bodyText>
<page confidence="0.996673">
14
</page>
<bodyText confidence="0.999743733333333">
ate classes in natural language processing.
His current work is focused on automatic
induction of semantic frames and semantic
parsing, verb polysemic classes, verb sense
disambiguation, and automatic induction of
semantic frames.
Octavian Popescu is a researcher at IBM T.
J. Watson Research Center, working on
computational semantics with focus on cor-
pus patterns for question answering, textual
entailment and paraphrasing. He taught vari-
ous NLP graduate courses in computational
semantics at Trento University (IT), Colora-
do University at Boulder (US) and Universi-
ty of Bucharest (RO).
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999907738461539">
C. Cumby and D. Roth &amp;quot;On Kernel Methods for
Relational Learning&amp;quot;, in Proceedings of ICML
2003, Washington 2003
D. Dligach and M. Palmer: &amp;quot;Good Seed Makes a
Good Crop: Accelerating Active Learning Using
Language Modeling&amp;quot;, in Proceedings of ACL,
Oregon, 2011
P. Hanks, “Corpus Pattern Analysis”. In Wil-
liams G. and S. Vessier (eds) Proceedings of the
XI Euralex International Congress, Lorient, Uni-
versité de Bretagne-Sud, 2004
P. Hanks and J. Pustejovsky. &amp;quot;Common Sense
About Word Meaning:Sense in Context&amp;quot;, in Pro-
ceedings of the TSD, Volume 3206, 2004.
P. Hanks &amp;quot;How People use words to make Mean-
ings. Semantic Types meet Valencies&amp;quot;. In A.
Bulton and J. Thomas (eds.) Input, Process and
Product: Developments in Teaching and Lan-
guage Corpora. Masaryk University Press, 2012
P. Hanks &amp;quot;Lexical Analysis: Norms and Exploi-
tations.&amp;quot;. MITPress 2013
E. Jezek and P. Hanks, “What lexical sets tell us
about conceptual categories&amp;quot;, In Lexis, E-Journal
in English Lexicology, 4, 7-22, 2010.
E. Jezek, B. Magnini, A. Feltracco, A. Bianchini,
O. Popescu &amp;quot;T-PAS; A resource of Typed Pred-
icate Argument Structures for linguistic analysis
and semantic processing&amp;quot;, in Proceedings of
LREC, Reykjavik 2014
D. Kawahara, D. Pederson, O. Popescu, M.
Palmer 2014. &amp;quot;Inducing Example-based Seman-
tic Frames from a Massive Amount of Verb Us-
es&amp;quot;, in Proceedings of the EACL, Gothenburg,
2014
V. Niculae and O. Popescu, &amp;quot;Determining is-a
relationships for Textual Entailment&amp;quot;, in Prceed-
ings of JSSP , Trento, 2013
O. Popescu, B. Magnini “Sense Discriminative
Patterns for Word Sense Disambiguation”, in
Proceedings of Semantic Content Acquisition
and Representation, NODALIDA, Tartu, 2007.
O. Popescu, E. Cabrio, B. Magnini Journal Pro-
ceedings of the IJCAI Workshop Learning by
Reasoning and its Applications in Intelligent
Question-Answering, Barcelona 2011
O. Popescu , E. Jezek. &amp;quot;Pattern Based Transla-
tion&amp;quot;, in Proceedings of Tralogy-II, Paris 2013
O. Popescu. &amp;quot;Learning Corpus Pattern with Fi-
nite State Automata&amp;quot;, in Proceedings of IWSC,
Berlin, 2013.
O. Popescu, P. Hanks, M. Palmer, &amp;quot;Mapping
CPA onto Ontonotes Senses&amp;quot;, in Proceedings of
LREC, Reykjavik, 2014
J. Pustejovsky, P. Hanks, and A. Rumshisky.
&amp;quot;Sense in Context&amp;quot;, in Proceedings of COLING
2004, Geneva, 2004
J. Pustejovsky, E. Jezek “Semantic Coercion in
Language: Beyond Distributional Analysis&amp;quot;, Ital-
ian Journal of Linguistics 20, 1, 181-214, 2008.
J. M.Sinclair “The Lexical Item”, in E. WEigand
(ed.) Contrastive Lexical Semantics. Benjamins,
1998
N. Vo, O. Popescu, T. Caselli, &amp;quot;FBK-TR: SVM
for Semantic Relatedness and Corpus Patterns
for RTE&amp;quot;, in Proceedings SemEval, Dublin, 2014
</reference>
<page confidence="0.997932">
15
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.197827">
<title confidence="0.999795">Corpus Pattern for Semantic Processing</title>
<author confidence="0.999818">Patrick Hanks</author>
<affiliation confidence="0.999987">University of Wolverhampton,</affiliation>
<email confidence="0.999652">patrick.w.hanks@gmail.com</email>
<author confidence="0.494844">Daisuke</author>
<affiliation confidence="0.999381">Kyoto University,</affiliation>
<email confidence="0.846236">dk@i.kyoto-u.ac.jp</email>
<author confidence="0.614984">Elisabetta</author>
<affiliation confidence="0.999504">University of Pavia,</affiliation>
<email confidence="0.995822">jezek@unipv.it</email>
<author confidence="0.736379">Octavian</author>
<affiliation confidence="0.995851">IBM Research,</affiliation>
<email confidence="0.962747">o.popescu@us.ibm.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Cumby</author>
<author>D Roth</author>
</authors>
<title>On Kernel Methods for Relational Learning&amp;quot;,</title>
<date>2003</date>
<booktitle>in Proceedings of ICML 2003,</booktitle>
<location>Washington</location>
<marker>Cumby, Roth, 2003</marker>
<rawString>C. Cumby and D. Roth &amp;quot;On Kernel Methods for Relational Learning&amp;quot;, in Proceedings of ICML 2003, Washington 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dligach</author>
<author>M Palmer</author>
</authors>
<title>Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling&amp;quot;,</title>
<date>2011</date>
<booktitle>in Proceedings of ACL,</booktitle>
<location>Oregon,</location>
<marker>Dligach, Palmer, 2011</marker>
<rawString>D. Dligach and M. Palmer: &amp;quot;Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling&amp;quot;, in Proceedings of ACL, Oregon, 2011</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
</authors>
<title>Corpus Pattern Analysis”. In</title>
<date>2004</date>
<booktitle>Proceedings of the XI Euralex International Congress, Lorient, Université de Bretagne-Sud,</booktitle>
<contexts>
<context position="7121" citStr="Hanks 2004" startWordPosition="1108" endWordPosition="1109">e rules of grammar; they account for 70%-90% of all utterances - depending on the type of the verb, the topic, and the domain. However, they do not account for linguistic creativity, nor for changes in word meaning; 2) Exploitation rules, which account for creativity and innovative usage (about 10%-30% of corpus examples). Exploitation rules also account for phenomena such as meaning shift. Pattern Dictionaries are resources based on Corpus Pattern Analysis (CPA). They contains examples for each category for a large number of English and Italian verbs and are available at http://pdev.org.uk/ (Hanks 2004), and at http://tpas.fbk.eu/resource (Jezek et al. 2014). The corpus-pattern methodology is designed to offer a viable solution to meaning representation. The techniques we present are widely applicable in NLP and they deal efficiently with data sparseness and open domain expression of semantic relationships. 13 Textual Entailment, Paraphrase Generation and Textual Similarity with Corpus Patterns 4 Tutors The tutorial is divided into three main parts, which are strongly interconnected: (A) Building Corpus Patterns via the Theory of Norms and Exploitations, (B) Inducing Semantic Types and Seman</context>
</contexts>
<marker>Hanks, 2004</marker>
<rawString>P. Hanks, “Corpus Pattern Analysis”. In Williams G. and S. Vessier (eds) Proceedings of the XI Euralex International Congress, Lorient, Université de Bretagne-Sud, 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
<author>J Pustejovsky</author>
</authors>
<title>Common Sense About Word Meaning:Sense in Context&amp;quot;,</title>
<date>2004</date>
<booktitle>in Proceedings of the TSD,</booktitle>
<volume>3206</volume>
<editor>P. Hanks</editor>
<publisher>Masaryk University Press,</publisher>
<marker>Hanks, Pustejovsky, 2004</marker>
<rawString>P. Hanks and J. Pustejovsky. &amp;quot;Common Sense About Word Meaning:Sense in Context&amp;quot;, in Proceedings of the TSD, Volume 3206, 2004. P. Hanks &amp;quot;How People use words to make Meanings. Semantic Types meet Valencies&amp;quot;. In A. Bulton and J. Thomas (eds.) Input, Process and Product: Developments in Teaching and Language Corpora. Masaryk University Press, 2012</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
</authors>
<title>Lexical Analysis: Norms and Exploitations.&amp;quot;.</title>
<date>2013</date>
<tech>MITPress</tech>
<contexts>
<context position="6246" citStr="Hanks 2013" startWordPosition="966" endWordPosition="967">ffer an important degree of freedom in finding the right cut between various levels of semantic information. Large-scale corpus-driven lexical analysis leads to two apparently contradictory conclusions. On the one hand, the regularities of word use (valencies, collocations) are more regular than what most pre-corpus linguists would have predicted. On the other hand, the irregularities are more irregular. In particular, verb usage in language displays a continuous blend between regular constructs with clearly distinct senses and new and innovative usages. The Theory of Norms and Exploitations (Hanks 2013) maintains that language exhibits mainly a rule-governed behavior, but argues that there is not just one monolithic system of rules. Instead, there are two interactive sets of rules: 1) Norms: a set of rules for using words normally and idiomatically: these are the rules of grammar; they account for 70%-90% of all utterances - depending on the type of the verb, the topic, and the domain. However, they do not account for linguistic creativity, nor for changes in word meaning; 2) Exploitation rules, which account for creativity and innovative usage (about 10%-30% of corpus examples). Exploitatio</context>
</contexts>
<marker>Hanks, 2013</marker>
<rawString>P. Hanks &amp;quot;Lexical Analysis: Norms and Exploitations.&amp;quot;. MITPress 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Jezek</author>
<author>P Hanks</author>
</authors>
<title>What lexical sets tell us about conceptual categories&amp;quot;,</title>
<date>2010</date>
<booktitle>In Lexis, E-Journal in English Lexicology,</booktitle>
<volume>4</volume>
<pages>7--22</pages>
<marker>Jezek, Hanks, 2010</marker>
<rawString>E. Jezek and P. Hanks, “What lexical sets tell us about conceptual categories&amp;quot;, In Lexis, E-Journal in English Lexicology, 4, 7-22, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Jezek</author>
<author>B Magnini</author>
<author>A Feltracco</author>
<author>A Bianchini</author>
<author>O Popescu</author>
</authors>
<title>T-PAS; A resource of Typed Predicate Argument Structures for linguistic analysis and semantic processing&amp;quot;,</title>
<date>2014</date>
<booktitle>in Proceedings of LREC, Reykjavik</booktitle>
<contexts>
<context position="7177" citStr="Jezek et al. 2014" startWordPosition="1113" endWordPosition="1116">ll utterances - depending on the type of the verb, the topic, and the domain. However, they do not account for linguistic creativity, nor for changes in word meaning; 2) Exploitation rules, which account for creativity and innovative usage (about 10%-30% of corpus examples). Exploitation rules also account for phenomena such as meaning shift. Pattern Dictionaries are resources based on Corpus Pattern Analysis (CPA). They contains examples for each category for a large number of English and Italian verbs and are available at http://pdev.org.uk/ (Hanks 2004), and at http://tpas.fbk.eu/resource (Jezek et al. 2014). The corpus-pattern methodology is designed to offer a viable solution to meaning representation. The techniques we present are widely applicable in NLP and they deal efficiently with data sparseness and open domain expression of semantic relationships. 13 Textual Entailment, Paraphrase Generation and Textual Similarity with Corpus Patterns 4 Tutors The tutorial is divided into three main parts, which are strongly interconnected: (A) Building Corpus Patterns via the Theory of Norms and Exploitations, (B) Inducing Semantic Types and Semantic Task Oriented Ontologies, and (C) Machine Learning a</context>
</contexts>
<marker>Jezek, Magnini, Feltracco, Bianchini, Popescu, 2014</marker>
<rawString>E. Jezek, B. Magnini, A. Feltracco, A. Bianchini, O. Popescu &amp;quot;T-PAS; A resource of Typed Predicate Argument Structures for linguistic analysis and semantic processing&amp;quot;, in Proceedings of LREC, Reykjavik 2014</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara</author>
<author>D Pederson</author>
<author>O Popescu</author>
<author>M Palmer</author>
</authors>
<title>Inducing Example-based Semantic Frames from a Massive Amount of Verb Uses&amp;quot;,</title>
<date>2014</date>
<booktitle>in Proceedings of the EACL,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="3029" citStr="Kawahara et al. 2014" startWordPosition="445" endWordPosition="448">nly on premises derived from prior experience, (2) the lack of largescale annotated corpora which combine different levels of semantic annotation hinders the development of machine-learning applications. In particular, in the framework of big data analytics for semantically processing large corpora, these two issues must be addressed. The regular structure of normal clauses can be used as a basis in order to learn the rules that lie behind recurrent meaningful constructs in natural language. It has been shown (Hanks&amp;Pustejovsky 2004, Pustejovsky&amp;Jezek 2008, Popescu&amp;Magnini 2007, Popescu 2013, Kawahara et al. 2014) 12 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 12–15, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics that it is possible to identify and to learn corpus patterns that encode the information that accounts for the senses of the verb and its arguments in the context. These patterns link the syntactic structure of clauses and the semantic types of argument fillers via the role that each of these play in the disambiguation of the clause as a whole. With regard to irregularities, there are quite a few clauses in a </context>
</contexts>
<marker>Kawahara, Pederson, Popescu, Palmer, 2014</marker>
<rawString>D. Kawahara, D. Pederson, O. Popescu, M. Palmer 2014. &amp;quot;Inducing Example-based Semantic Frames from a Massive Amount of Verb Uses&amp;quot;, in Proceedings of the EACL, Gothenburg, 2014</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Niculae</author>
<author>O Popescu</author>
</authors>
<title>Determining is-a relationships for Textual Entailment&amp;quot;,</title>
<date>2013</date>
<booktitle>in Prceedings of JSSP ,</booktitle>
<location>Trento,</location>
<marker>Niculae, Popescu, 2013</marker>
<rawString>V. Niculae and O. Popescu, &amp;quot;Determining is-a relationships for Textual Entailment&amp;quot;, in Prceedings of JSSP , Trento, 2013</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Popescu</author>
<author>B</author>
</authors>
<title>Magnini “Sense Discriminative Patterns for Word Sense Disambiguation”,</title>
<date>2007</date>
<booktitle>in Proceedings of Semantic Content Acquisition and Representation,</booktitle>
<location>NODALIDA, Tartu,</location>
<marker>Popescu, B, 2007</marker>
<rawString>O. Popescu, B. Magnini “Sense Discriminative Patterns for Word Sense Disambiguation”, in Proceedings of Semantic Content Acquisition and Representation, NODALIDA, Tartu, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Popescu</author>
<author>E Cabrio</author>
<author>B</author>
</authors>
<date>2011</date>
<booktitle>Magnini Journal Proceedings of the IJCAI Workshop Learning by Reasoning and its Applications in Intelligent Question-Answering,</booktitle>
<location>Barcelona</location>
<contexts>
<context position="4947" citStr="Popescu et al. 2011" startWordPosition="759" endWordPosition="762">ed by such patterns, any word is unequivocally disambiguated. The semantic types used in pattern representation play a discriminative role, therefore the patterns are sense discriminative and as such they can be used in word sense disambiguation and other meaning-related tasks (see among others Pustejovsky et al. 2004, Cumby&amp;Roth 2003, Popescu&amp;Magnini 2007, Pustejovsky et al. 2010, Popescu et al. 2014). Also, the meaning of a pattern as a whole is expressed as a set of basic implicatures. The implicatures are instrumental in textual entailment, semantic similarity and paraphrasing generation (Popescu et al. 2011, Nicolae&amp;Popescu 2013, Vo et. al 2014). Depending on the proposed application, the implicatures associated with a pattern may be expressed in any of a wide variety of other ways, e.g. as a translation into another language or as a synonym set. The automatic aligning of the set of patterns of two languages via their shared semantic types is used in meaning-preserving translation tasks (Popescu&amp;Jezek 2013). The relatively recent research on corpus data has shown that intermediate text representations (ITRs), built in a bottom-up manner from corpus examples towards a complex representation of cl</context>
</contexts>
<marker>Popescu, Cabrio, B, 2011</marker>
<rawString>O. Popescu, E. Cabrio, B. Magnini Journal Proceedings of the IJCAI Workshop Learning by Reasoning and its Applications in Intelligent Question-Answering, Barcelona 2011</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Popescu</author>
</authors>
<title>Pattern Based Translation&amp;quot;,</title>
<date>2013</date>
<booktitle>in Proceedings of Tralogy-II,</booktitle>
<location>Paris</location>
<contexts>
<context position="3006" citStr="Popescu 2013" startWordPosition="443" endWordPosition="444">t be founded only on premises derived from prior experience, (2) the lack of largescale annotated corpora which combine different levels of semantic annotation hinders the development of machine-learning applications. In particular, in the framework of big data analytics for semantically processing large corpora, these two issues must be addressed. The regular structure of normal clauses can be used as a basis in order to learn the rules that lie behind recurrent meaningful constructs in natural language. It has been shown (Hanks&amp;Pustejovsky 2004, Pustejovsky&amp;Jezek 2008, Popescu&amp;Magnini 2007, Popescu 2013, Kawahara et al. 2014) 12 Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 12–15, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics that it is possible to identify and to learn corpus patterns that encode the information that accounts for the senses of the verb and its arguments in the context. These patterns link the syntactic structure of clauses and the semantic types of argument fillers via the role that each of these play in the disambiguation of the clause as a whole. With regard to irregularities, there are qu</context>
<context position="4969" citStr="Popescu 2013" startWordPosition="763" endWordPosition="765"> is unequivocally disambiguated. The semantic types used in pattern representation play a discriminative role, therefore the patterns are sense discriminative and as such they can be used in word sense disambiguation and other meaning-related tasks (see among others Pustejovsky et al. 2004, Cumby&amp;Roth 2003, Popescu&amp;Magnini 2007, Pustejovsky et al. 2010, Popescu et al. 2014). Also, the meaning of a pattern as a whole is expressed as a set of basic implicatures. The implicatures are instrumental in textual entailment, semantic similarity and paraphrasing generation (Popescu et al. 2011, Nicolae&amp;Popescu 2013, Vo et. al 2014). Depending on the proposed application, the implicatures associated with a pattern may be expressed in any of a wide variety of other ways, e.g. as a translation into another language or as a synonym set. The automatic aligning of the set of patterns of two languages via their shared semantic types is used in meaning-preserving translation tasks (Popescu&amp;Jezek 2013). The relatively recent research on corpus data has shown that intermediate text representations (ITRs), built in a bottom-up manner from corpus examples towards a complex representation of clauses, play an importa</context>
</contexts>
<marker>Popescu, 2013</marker>
<rawString>O. Popescu , E. Jezek. &amp;quot;Pattern Based Translation&amp;quot;, in Proceedings of Tralogy-II, Paris 2013 O. Popescu. &amp;quot;Learning Corpus Pattern with Finite State Automata&amp;quot;, in Proceedings of IWSC, Berlin, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Popescu</author>
<author>P Hanks</author>
<author>M Palmer</author>
</authors>
<title>Mapping CPA onto Ontonotes Senses&amp;quot;,</title>
<date>2014</date>
<booktitle>in Proceedings of LREC, Reykjavik,</booktitle>
<contexts>
<context position="4733" citStr="Popescu et al. 2014" startWordPosition="724" endWordPosition="727"> information for handling the meaning of each word individually as well as that of the clause as a whole. As such they are instrumental in building better language models (Dligach&amp;Palmer 2011). In the contexts matched by such patterns, any word is unequivocally disambiguated. The semantic types used in pattern representation play a discriminative role, therefore the patterns are sense discriminative and as such they can be used in word sense disambiguation and other meaning-related tasks (see among others Pustejovsky et al. 2004, Cumby&amp;Roth 2003, Popescu&amp;Magnini 2007, Pustejovsky et al. 2010, Popescu et al. 2014). Also, the meaning of a pattern as a whole is expressed as a set of basic implicatures. The implicatures are instrumental in textual entailment, semantic similarity and paraphrasing generation (Popescu et al. 2011, Nicolae&amp;Popescu 2013, Vo et. al 2014). Depending on the proposed application, the implicatures associated with a pattern may be expressed in any of a wide variety of other ways, e.g. as a translation into another language or as a synonym set. The automatic aligning of the set of patterns of two languages via their shared semantic types is used in meaning-preserving translation task</context>
</contexts>
<marker>Popescu, Hanks, Palmer, 2014</marker>
<rawString>O. Popescu, P. Hanks, M. Palmer, &amp;quot;Mapping CPA onto Ontonotes Senses&amp;quot;, in Proceedings of LREC, Reykjavik, 2014</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Hanks</author>
<author>A Rumshisky</author>
</authors>
<title>Sense in Context&amp;quot;,</title>
<date>2004</date>
<booktitle>in Proceedings of COLING 2004,</booktitle>
<location>Geneva,</location>
<contexts>
<context position="4647" citStr="Pustejovsky et al. 2004" startWordPosition="711" endWordPosition="714">supervised to totally unsupervised approaches. The patterns obtained encode the necessary information for handling the meaning of each word individually as well as that of the clause as a whole. As such they are instrumental in building better language models (Dligach&amp;Palmer 2011). In the contexts matched by such patterns, any word is unequivocally disambiguated. The semantic types used in pattern representation play a discriminative role, therefore the patterns are sense discriminative and as such they can be used in word sense disambiguation and other meaning-related tasks (see among others Pustejovsky et al. 2004, Cumby&amp;Roth 2003, Popescu&amp;Magnini 2007, Pustejovsky et al. 2010, Popescu et al. 2014). Also, the meaning of a pattern as a whole is expressed as a set of basic implicatures. The implicatures are instrumental in textual entailment, semantic similarity and paraphrasing generation (Popescu et al. 2011, Nicolae&amp;Popescu 2013, Vo et. al 2014). Depending on the proposed application, the implicatures associated with a pattern may be expressed in any of a wide variety of other ways, e.g. as a translation into another language or as a synonym set. The automatic aligning of the set of patterns of two la</context>
</contexts>
<marker>Pustejovsky, Hanks, Rumshisky, 2004</marker>
<rawString>J. Pustejovsky, P. Hanks, and A. Rumshisky. &amp;quot;Sense in Context&amp;quot;, in Proceedings of COLING 2004, Geneva, 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>E</author>
</authors>
<title>Jezek “Semantic Coercion in Language: Beyond Distributional Analysis&amp;quot;,</title>
<date>2008</date>
<journal>Italian Journal of Linguistics</journal>
<volume>20</volume>
<pages>181--214</pages>
<marker>Pustejovsky, E, 2008</marker>
<rawString>J. Pustejovsky, E. Jezek “Semantic Coercion in Language: Beyond Distributional Analysis&amp;quot;, Italian Journal of Linguistics 20, 1, 181-214, 2008.</rawString>
</citation>
<citation valid="true">
<title>The Lexical Item”,</title>
<date>1998</date>
<booktitle>Contrastive Lexical Semantics. Benjamins,</booktitle>
<editor>J. M.Sinclair</editor>
<marker>1998</marker>
<rawString>J. M.Sinclair “The Lexical Item”, in E. WEigand (ed.) Contrastive Lexical Semantics. Benjamins, 1998</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Vo</author>
<author>O Popescu</author>
<author>T Caselli</author>
</authors>
<title>FBK-TR: SVM for Semantic Relatedness and Corpus Patterns for RTE&amp;quot;,</title>
<date>2014</date>
<booktitle>in Proceedings SemEval,</booktitle>
<location>Dublin,</location>
<marker>Vo, Popescu, Caselli, 2014</marker>
<rawString>N. Vo, O. Popescu, T. Caselli, &amp;quot;FBK-TR: SVM for Semantic Relatedness and Corpus Patterns for RTE&amp;quot;, in Proceedings SemEval, Dublin, 2014</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>