<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001490">
<title confidence="0.937817">
CITYU-HIF: WSD with Human-Informed Feature Preference
</title>
<author confidence="0.750461">
Oi Yee Kwong
</author>
<affiliation confidence="0.694508">
Language Information Sciences Research Centre
City University of Hong Kong
</affiliation>
<address confidence="0.368015">
Tat Chee Avenue, Kowloon, Hong Kong
</address>
<email confidence="0.982962">
rlolivia@cityu.edu.hk
</email>
<sectionHeader confidence="0.787325" genericHeader="abstract">
bstract
</sectionHeader>
<bodyText confidence="0.999858190476191">
This paper describes our word sense dis-
ambiguation (WSD) system participating in
the SemEval-2007 tasks. The core system
is a fully supervised system based on a Na-
ive Bayes classifier using multiple knowl-
edge sources. Toward a larger goal of in-
corporating the intrinsic nature of individ-
ual target words in disambiguation, thus in-
troducing a cognitive element in automatic
WSD, we tried to fine-tune the results ob-
tained from the core system with human-
informed feature preference, and compared
it with automatic feature selection as com-
monly practised in statistical WSD. De-
spite the insignificant improvement ob-
served in this preliminary attempt, more
systematic analysis remains to be done for
a cognitively plausible account of the fac-
tors underlying the lexical sensitivity of
WSD, which would inform and enhance
the development of WSD systems in return.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999926442307693">
In recent years, many research teams all over the
world have gained rich experience on word sense
disambiguation (WSD) from the shared tasks of
the SENSEVAL workshops. The need for multiple
knowledge sources has become a golden rule, and
the &amp;quot;lexical sensitivity&amp;quot; once remarked by Resnik
and Yarowsky (1997) is addressed by various
means in statistical classifiers, such as learning an
optimal combination of the various knowledge
sources for individual target words (e.g. Mihalcea,
2002; Escudero et al., 2004). Another common
practice is to use an ensemble of classifiers. As
pointed out by Mihalcea et al. (2004), among the
participating systems in the SENSEVAL-3 English
lexical sample task, &amp;quot;several of the top perform-
ance systems are based on combination of multiple
classifiers, which shows once again that voting
scheme that combine several learning algorithms
outperform the accuracy of individual classifiers&amp;quot;.
However, the advancement in WSD is rarely ac-
companie d by any extensive account on the cogni-
tive aspects of the task or qualitative analysis of
the relation between the disambiguation results and
the nature of individual target words underlying
the apparent lexical sensitivity of the task.
Given that humans apparently use different
strategies in making sense of words, it might be
beneficial to have such cognitive aspects, including
the type and strength of various kinds of semantic
association, realised in NLP systems explicitly.
Thus in addition to an optimal combination of clas-
sifiers alone, to better understand the contribution
of different information types for different types of
target words, it is important to look at WSD in re-
lation to the very intrinsic nature of individual tar-
get words, which could comprise many factors
such as frequency, abstractness, sense relatedness
and parts-of-speech (POS). We thus use the con-
cept Information Susceptibility (Kwong, 2005) to
refer to the relationship between the intrinsic fea-
tures of a target word and its senses, and the effec-
tiveness of various lexical information to charac-
terise them.
Our current participation in SemEval-2007 is
thus intended as a means toward a larger goal, i.e.,
to incorporate a cognitive element into automatic
WSD systems. In particular, we tried to fine-tune
the results obtained from the core system with hu-
man-informed feature preference.
In Section 2, we will briefly describe the imple-
mentation of our disambiguation system and the
features used. In Section 3 we will discuss the
</bodyText>
<page confidence="0.991054">
109
</page>
<bodyText confidence="0.939931222222222">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 109–112,
Prague, June 2007. c�2007 Association for Computational Linguistics
optimally disambiguated with other types of in-
formation.
human input on the target nature and the informa-
tiveness of various features. The experiments and
results are presented in Section 4, followed by a
conclusion in Section 5.
Target Features
</bodyText>
<sectionHeader confidence="0.925915" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.985576">
2.1 Core C(assifier
</subsectionHeader>
<bodyText confidence="0.999971111111111">
The core system is a fully supervised one based on
a Naive Bayes classifier. We made use of the
Weka API (Witten and Frank, 2005) in our
implementation. According to Yarowsky and
Radu (2002), Bayesian classifiers belong to one of
the aggregative models which depend heavily on
the multiple reinforcing feature clues obtainable
from wide context. Thus we use all features
described in Section 2.2 below for our core system.
</bodyText>
<subsectionHeader confidence="0.984032">
2.2 Know(edge Sources
</subsectionHeader>
<bodyText confidence="0.999666285714286">
Only the training data provided by the task organ-
isers was used to train the system. We used four
major types of contextual features, which could be
classified into Target features, Local features,
Topical features and Syntactic features, as de-
scribed in Table 1. All features were converted to
binary features.
</bodyText>
<subsectionHeader confidence="0.993381">
2.3 Feature Se(ection
</subsectionHeader>
<bodyText confidence="0.999974">
On top of the core system, we tested two value-
added steps to accommodate for the lexical sensi-
tivity of WSD. One is automatic feature selection
(AFS), for which we used CfsSubsetEval (correla-
tion-based feature selection) as implemented in
Weka, based on the training samples of each target
word. The other is human-informed feature pref-
erence (HIF), for which we ran another Naive
Bayes classifier in parallel with a feature subset
deemed informative by human judges to fine-tune
the disambiguation results obtained from the core
system (see Sections 3 and 4 below).
</bodyText>
<sectionHeader confidence="0.99712" genericHeader="method">
3 Intrinsic Nature of Target Words
</sectionHeader>
<bodyText confidence="0.999472125">
Leacock et al. (1998), for example, observed that
&amp;quot;the benefits of adding topical to local context
alone depend on syntactic category as well as on
the characteristics of the individual word&amp;quot;. In
other words, some target words happen to be more
&amp;quot;topical&amp;quot; than others and might therefore be more
susceptible to topical contextual features during
isambiguation. Others, however, might only be
</bodyText>
<table confidence="0.773432692307692">
Wo Word form of the target wor
Po POS of the target wor
Local Features
P-z POS of words at fixed positions
P-1 from the target word, including
P+1 the first and second word on its
P+z left and the first and second wor
on its right
W-z Word forms of the words at fixe
W-1 positions from the target word,
W+1 including the first and second
W+z word on its left and the first and
second word on its right
Topical Features
W-1o...W+1o Content words appearing within
the window of ten words on each
side of the target word
Syntactic Features
P-z Po POS bigrams composed of the
P-1 Po target word and its neighbouring
Po P+1 words, the non-immediate P-z Po
Po P+z and Po P+z are included to ac-
commodate for some flexibility
P-z P-1 Po POS trigrams composed of the
Po P+1 P+z target word and its neighbouring
words
</table>
<tableCaption confidence="0.998118">
Table 1 Features Used in the Naive Bayes Classifer
</tableCaption>
<bodyText confidence="0.99994675">
While statistical WSD has more or less reached
its ceiling, it is assumed that a more thorough un-
derstanding of the effectiveness of different types
of lexical information for characterising a word
sense and distinguishing it from others should be
able to further inform and enhance the develop-
ment of WSD systems. To this end, three under-
graduate linguistics students in the City University
of Hong Kong were asked to go through the train-
ing data for the Chinese lexical sample task in
SENSEVAL-3 and that for the multilingual Chi-
nese-English lexical sample task (Task 5) in Se-
mEval-2007. For each sense of a given target
word, they were asked to rate the difficulty, ab-
stractness, and topicality of the sense on a 3-point
scale. At the same time, they were asked to indi-
</bodyText>
<page confidence="0.989532">
110
</page>
<bodyText confidence="0.999988333333333">
cate the type of information, among local POS,
local words, and contextual words (i.e. the topical
features in Table 1), which they reckon to be most
useful for disambiguating a given sample of the
target word.1
While the information collected from the human
judges is pending in-depth analysis, the feature
preference indicated by them was used to fine-tune
the results obtained from our core system. During
disambiguation, we run two Naive Bayes classifi-
ers in parallel, the core one on all features above,
and the other only on the type of information
deemed most useful by two or more of the human
judges, and use the latter to adjust the results from
the former, as further discussed in Section 4.2.
</bodyText>
<sectionHeader confidence="0.993618" genericHeader="method">
4 Experiment and Resu(ts
</sectionHeader>
<subsectionHeader confidence="0.766765">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999128678571429">
We participated in the Multilingual Chinese-
English Lexical Sample Task (Task 5) and the
English Lexical Sample Task via English-Chinese
Parallel Text (Task 11).
Task 5 consists of 40 Chinese target words, 19
nouns and 21 verbs. The number of senses for the
target words ranges from 2 to 8, with an average of
3. There are altogether 2,680 training samples, i.e.
on average about 22 for each sense. A total of 935
testing instances were to be tagged, i.e. on average
about 23 for each target word. The data were from
People&apos;s Daily. The sense tags are given in the
form of their English translations in the Chinese
Semantic Dictionary developed by the Institute of
Computational Linguistics of Peking University.
The task organiser has provided the data with word
segmentation and POS for each segmented word.
Task 11 consists of 40 English target words, in-
cluding 20 nouns and 20 adjectives. The average
number of training samples for each sense is about
42. The number of senses for the target words
ranges from 2 to 6, with an average of 3.125. The
average number of testing samples for each target
word is 68. The data were gathered from word-
aligned English-Chinese parallel texts.
In addition, we also used the SENSEVAL-3
Chinese lexical sample data during evaluation,
which contains 20 target words.
</bodyText>
<footnote confidence="0.620520333333333">
1 To simplify the task for the human judges, we did not
distinguish between fixed-position local POS and n-
gram syntactic features, and only used the former.
</footnote>
<subsectionHeader confidence="0.988047">
4.2 Eva(uation
</subsectionHeader>
<bodyText confidence="0.99998548">
For Task 5, we made use of the segmentation and
POS information provided by the task organiser.
For Task 11, we first ran the data through the Brill
tagger (Brill, 1994) to obtain the POS, from which
we then extracted the feature values.
On top of the core system, we also tested two
value-added conditions, namely automatic feature
selection (AFS) and human-informed feature pref-
erence (HIF). For the latter, we run a separate Na-
ive Bayes classifier in parallel to the core system,
using the knowledge source deemed most useful
for a given target word by two or more human
judges. When the probability of the best guess
from the core classifier is under a certain threshold,
the best guess from the other is used instead. For
the current experiment, the probability of the best
guess from the core classifier must at least double
that for the next best guess.
For evaluation, we ran a 10-fold cross validation
on the SemEval-2007 Task 5 training data, with
the core system and AFS. In addition, we tested
with the Senseval-3 Chinese lexical sample data.
We trained the classifier with the Senseval-3 train-
ing data, with the core classifier, AFS, and HIF.
The results are discussed below.
</bodyText>
<subsectionHeader confidence="0.992239">
4.3 Resu(ts
</subsectionHeader>
<bodyText confidence="0.817653">
Table 2 shows the evaluation results of the various
conditions described above.
</bodyText>
<table confidence="0.931180125">
Condition ve. Precision
SemEval-2007 training data (10-�old CV)
Core classifier 77.33%
Core classifier + AFS 85.51%
Senseval-3 testing data
Core classifier 60.2%
Core classifier + AFS 61.7%
Core classifier + HIF 60.7%
</table>
<tableCaption confidence="0.993554">
Table 2 Evaluation Results
</tableCaption>
<bodyText confidence="0.999806571428571">
Apparently, and as known and expected, feature
selection is useful for choosing an optimal set of
features for each target word. How this compares
and works together with human intuition and the
nature of the individual target words and senses is
what we would like to further investigate. In the
above experiment, fine-tuning with human-
</bodyText>
<page confidence="0.997379">
111
</page>
<bodyText confidence="0.999965058823529">
informed feature preference did not improve the
performance as significantly as one would like to
see, and the effect varied with individual target
words. One possibility is that Naive Bayes classi-
fiers favour aggregative features, so it might not be
most appropriate to do the fine-tuning with a sepa-
rate classifier. Rather, we could explore the feasi-
bility of adjusting the weights of individual fea-
tures based on the feature preference.
Our next step is to perform in-depth and system-
atic analysis on the difficulty, abstractness and
topicality of the target words and senses, with the
information gathered from the human judges and
the confusion matrices generated from the experi-
ment, in association with psychological evidence
like semantic activation and the organisation of the
mental lexicon (e.g. Kwong, 2007).
</bodyText>
<subsectionHeader confidence="0.971909">
4.4 Officia( Scores in SemEva(-2007
</subsectionHeader>
<bodyText confidence="0.767685">
The official scores for our system are shown in
</bodyText>
<tableCaption confidence="0.905211">
Table 3.
</tableCaption>
<table confidence="0.725811333333333">
Task System MicroAvg MacroAvg Rank
5 HIF 71.0% 74.9% 3 / 6
11 AFS 75.3%2 - 3 / 3
</table>
<tableCaption confidence="0.888041">
Table 3 Official Scores for CITYU in SemEval-2007
</tableCaption>
<bodyText confidence="0.999845625">
Our scores are comparable to the state-of-the-art
results. Although the HIF step did not increase the
performance significantly, in view of the limitation
of state-of-the-art statistical WSD systems, every
minor improvement counts. It therefore remains
for us to further investigate the cognitive aspects of
WSD in relation to target nature and have them
systematically realised in WSD systems.
</bodyText>
<sectionHeader confidence="0.992176" genericHeader="evaluation">
5 Conc(usion
</sectionHeader>
<bodyText confidence="0.9977691875">
In this paper, we have described our system par-
ticipating in the SemEval-2007 multilingual Chi-
nese-English lexical sample task and English lexi-
cal sample task via English-Chinese parallel text.
Toward a larger goal of supplementing statistical
2 A post-hoc analysis reveals a technical problem for six
of the target words in Task 11 (educational.a, change.n,
future.n, interest.n, need.n, program.n) which were not
properly processed by the system in one of the steps,
and the most frequent sense was used by default. Ignor-
ing these cases, a precision of 78.3% was obtained using
the task organiser&apos;s key and scoring program.
methods with some cognitive elements of WSD,
more systematic analysis of the intrinsic nature of
target words underlying the lexical sensitivity of
WSD is underway.
</bodyText>
<sectionHeader confidence="0.930993" genericHeader="conclusions">
Acknow(edgements
</sectionHeader>
<bodyText confidence="0.98455975">
The work described in this paper was supported by
a grant from the Research Grants Council of the
Hong Kong Special Administrative Region, China
(Project No. CityU 1508/06H).
</bodyText>
<sectionHeader confidence="0.998823" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702783783784">
Brill, E. (1994) Some advances in transformation-based
part of speech tagging. In Proceedings of the 12th
National Conference on Artificial Intelligence (AAAI-
94), pp.722-727.
Escudero, G., Marquez, L. and Rigau, G. (2004) TALP
System for the English Lexical Sample Task. In
Proceedings of SENSEVAL-3, Barcelona, Spain.
Kwong, O.Y. (2005) Word Sense Classification Based
on Information Susceptibility. In A. Lenci, S. Mon-
temagni and V. Pirrelli (E ds.), Acquisition and Rep-
resentation of Word Meaning. Linguistica Compu-
tazionale, pp.89-115.
Kwong, O.Y. (2007) Sense Abstractness, Semantic
Activation and Word Sense Disambiguation: Impli-
cations from Word Association Norms. To appear in
Proceedings of NLPCS-2007, Madeira, Portugal.
Leacock, C., Miller, G.A. and Chodorow, M. (1998)
Using Corpus Statistics and WordNet Relations for
Sense Identification. Computational Linguistics,
24(1):147-166.
Mihalcea, R.F. (2002) Word sense disambiguation with
pattern learning and automatic feature selection.
Natural Language Engineering, 8(4):343-358.
Mihalcea, R., Chklovski, T. and Kilgarriff, A. (2004)
The SENSEVAL-3 English Lexical Sample Task. In
Proceedings of SENSEVAL-3, Barcelona, Spain.
Resnik, P. and Yarowsky, D. (1997) A perspective on
word sense disambiguation methods and their evalua-
tion. In Proceedings of SIGLEX&apos;97 Workshop: Tag-
ging Text with Lexical Semantics: Why, What, and
How?, Washington, D.C., pp.79-86.
Witten, I.H. and Frank, E. (2005) Data Mining: Practi-
cal Machine Learning Tools and Techniques with
Java Implementations. Morgan Kaufmann.
Yarowsky, D. and Radu, F. (2002) Evaluating sense
disambiguation across diverse parameter spaces.
Natural Language Engineering, 8(4):293-310.
</reference>
<page confidence="0.998291">
112
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.464427">
<title confidence="0.9948">CITYU-HIF: WSD with Human-Informed Feature Preference</title>
<author confidence="0.97964">Oi Yee Kwong</author>
<affiliation confidence="0.832117">Language Information Sciences Research Centre City University of Hong Kong</affiliation>
<address confidence="0.755677">Tat Chee Avenue, Kowloon, Hong Kong</address>
<email confidence="0.850185">rlolivia@cityu.edu.hk</email>
<abstract confidence="0.999121727272728">bstract This paper describes our word sense disambiguation (WSD) system participating in the SemEval-2007 tasks. The core system is a fully supervised system based on a Naive Bayes classifier using multiple knowledge sources. Toward a larger goal of incorporating the intrinsic nature of individual target words in disambiguation, thus introducing a cognitive element in automatic WSD, we tried to fine-tune the results obtained from the core system with humaninformed feature preference, and compared it with automatic feature selection as commonly practised in statistical WSD. Despite the insignificant improvement observed in this preliminary attempt, more systematic analysis remains to be done for a cognitively plausible account of the factors underlying the lexical sensitivity of WSD, which would inform and enhance the development of WSD systems in return.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some advances in transformation-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI94),</booktitle>
<pages>722--727</pages>
<contexts>
<context position="9834" citStr="Brill, 1994" startWordPosition="1612" endWordPosition="1613">ge of 3.125. The average number of testing samples for each target word is 68. The data were gathered from wordaligned English-Chinese parallel texts. In addition, we also used the SENSEVAL-3 Chinese lexical sample data during evaluation, which contains 20 target words. 1 To simplify the task for the human judges, we did not distinguish between fixed-position local POS and ngram syntactic features, and only used the former. 4.2 Eva(uation For Task 5, we made use of the segmentation and POS information provided by the task organiser. For Task 11, we first ran the data through the Brill tagger (Brill, 1994) to obtain the POS, from which we then extracted the feature values. On top of the core system, we also tested two value-added conditions, namely automatic feature selection (AFS) and human-informed feature preference (HIF). For the latter, we run a separate Naive Bayes classifier in parallel to the core system, using the knowledge source deemed most useful for a given target word by two or more human judges. When the probability of the best guess from the core classifier is under a certain threshold, the best guess from the other is used instead. For the current experiment, the probability of</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, E. (1994) Some advances in transformation-based part of speech tagging. In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI94), pp.722-727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L Marquez</author>
<author>G Rigau</author>
</authors>
<title>TALP System for the English Lexical Sample Task.</title>
<date>2004</date>
<booktitle>In Proceedings of SENSEVAL-3,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1593" citStr="Escudero et al., 2004" startWordPosition="241" endWordPosition="244">al sensitivity of WSD, which would inform and enhance the development of WSD systems in return. 1 Introduction In recent years, many research teams all over the world have gained rich experience on word sense disambiguation (WSD) from the shared tasks of the SENSEVAL workshops. The need for multiple knowledge sources has become a golden rule, and the &amp;quot;lexical sensitivity&amp;quot; once remarked by Resnik and Yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. Mihalcea, 2002; Escudero et al., 2004). Another common practice is to use an ensemble of classifiers. As pointed out by Mihalcea et al. (2004), among the participating systems in the SENSEVAL-3 English lexical sample task, &amp;quot;several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers&amp;quot;. However, the advancement in WSD is rarely accompanie d by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between the disambiguation result</context>
</contexts>
<marker>Escudero, Marquez, Rigau, 2004</marker>
<rawString>Escudero, G., Marquez, L. and Rigau, G. (2004) TALP System for the English Lexical Sample Task. In Proceedings of SENSEVAL-3, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Y Kwong</author>
</authors>
<title>Word Sense Classification Based on Information Susceptibility. In</title>
<date>2005</date>
<pages>89--115</pages>
<contexts>
<context position="2986" citStr="Kwong, 2005" startWordPosition="458" endWordPosition="459">it might be beneficial to have such cognitive aspects, including the type and strength of various kinds of semantic association, realised in NLP systems explicitly. Thus in addition to an optimal combination of classifiers alone, to better understand the contribution of different information types for different types of target words, it is important to look at WSD in relation to the very intrinsic nature of individual target words, which could comprise many factors such as frequency, abstractness, sense relatedness and parts-of-speech (POS). We thus use the concept Information Susceptibility (Kwong, 2005) to refer to the relationship between the intrinsic features of a target word and its senses, and the effectiveness of various lexical information to characterise them. Our current participation in SemEval-2007 is thus intended as a means toward a larger goal, i.e., to incorporate a cognitive element into automatic WSD systems. In particular, we tried to fine-tune the results obtained from the core system with human-informed feature preference. In Section 2, we will briefly describe the implementation of our disambiguation system and the features used. In Section 3 we will discuss the 109 Proc</context>
</contexts>
<marker>Kwong, 2005</marker>
<rawString>Kwong, O.Y. (2005) Word Sense Classification Based on Information Susceptibility. In A. Lenci, S. Montemagni and V. Pirrelli (E ds.), Acquisition and Representation of Word Meaning. Linguistica Computazionale, pp.89-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Y Kwong</author>
</authors>
<title>Sense Abstractness, Semantic Activation and Word Sense Disambiguation: Implications from Word Association Norms. To appear in</title>
<date>2007</date>
<booktitle>Proceedings of NLPCS-2007,</booktitle>
<location>Madeira, Portugal.</location>
<contexts>
<context position="12351" citStr="Kwong, 2007" startWordPosition="2020" endWordPosition="2021">ur aggregative features, so it might not be most appropriate to do the fine-tuning with a separate classifier. Rather, we could explore the feasibility of adjusting the weights of individual features based on the feature preference. Our next step is to perform in-depth and systematic analysis on the difficulty, abstractness and topicality of the target words and senses, with the information gathered from the human judges and the confusion matrices generated from the experiment, in association with psychological evidence like semantic activation and the organisation of the mental lexicon (e.g. Kwong, 2007). 4.4 Officia( Scores in SemEva(-2007 The official scores for our system are shown in Table 3. Task System MicroAvg MacroAvg Rank 5 HIF 71.0% 74.9% 3 / 6 11 AFS 75.3%2 - 3 / 3 Table 3 Official Scores for CITYU in SemEval-2007 Our scores are comparable to the state-of-the-art results. Although the HIF step did not increase the performance significantly, in view of the limitation of state-of-the-art statistical WSD systems, every minor improvement counts. It therefore remains for us to further investigate the cognitive aspects of WSD in relation to target nature and have them systematically real</context>
</contexts>
<marker>Kwong, 2007</marker>
<rawString>Kwong, O.Y. (2007) Sense Abstractness, Semantic Activation and Word Sense Disambiguation: Implications from Word Association Norms. To appear in Proceedings of NLPCS-2007, Madeira, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>G A Miller</author>
<author>M Chodorow</author>
</authors>
<title>Using Corpus Statistics and WordNet Relations for Sense Identification.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="5440" citStr="Leacock et al. (1998)" startWordPosition="848" endWordPosition="851"> top of the core system, we tested two valueadded steps to accommodate for the lexical sensitivity of WSD. One is automatic feature selection (AFS), for which we used CfsSubsetEval (correlation-based feature selection) as implemented in Weka, based on the training samples of each target word. The other is human-informed feature preference (HIF), for which we ran another Naive Bayes classifier in parallel with a feature subset deemed informative by human judges to fine-tune the disambiguation results obtained from the core system (see Sections 3 and 4 below). 3 Intrinsic Nature of Target Words Leacock et al. (1998), for example, observed that &amp;quot;the benefits of adding topical to local context alone depend on syntactic category as well as on the characteristics of the individual word&amp;quot;. In other words, some target words happen to be more &amp;quot;topical&amp;quot; than others and might therefore be more susceptible to topical contextual features during isambiguation. Others, however, might only be Wo Word form of the target wor Po POS of the target wor Local Features P-z POS of words at fixed positions P-1 from the target word, including P+1 the first and second word on its P+z left and the first and second wor on its right</context>
</contexts>
<marker>Leacock, Miller, Chodorow, 1998</marker>
<rawString>Leacock, C., Miller, G.A. and Chodorow, M. (1998) Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics, 24(1):147-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Mihalcea</author>
</authors>
<title>Word sense disambiguation with pattern learning and automatic feature selection.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<pages>8--4</pages>
<contexts>
<context position="1569" citStr="Mihalcea, 2002" startWordPosition="239" endWordPosition="240">rlying the lexical sensitivity of WSD, which would inform and enhance the development of WSD systems in return. 1 Introduction In recent years, many research teams all over the world have gained rich experience on word sense disambiguation (WSD) from the shared tasks of the SENSEVAL workshops. The need for multiple knowledge sources has become a golden rule, and the &amp;quot;lexical sensitivity&amp;quot; once remarked by Resnik and Yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. Mihalcea, 2002; Escudero et al., 2004). Another common practice is to use an ensemble of classifiers. As pointed out by Mihalcea et al. (2004), among the participating systems in the SENSEVAL-3 English lexical sample task, &amp;quot;several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers&amp;quot;. However, the advancement in WSD is rarely accompanie d by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between t</context>
</contexts>
<marker>Mihalcea, 2002</marker>
<rawString>Mihalcea, R.F. (2002) Word sense disambiguation with pattern learning and automatic feature selection. Natural Language Engineering, 8(4):343-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Chklovski</author>
<author>A Kilgarriff</author>
</authors>
<title>The SENSEVAL-3 English Lexical Sample Task.</title>
<date>2004</date>
<booktitle>In Proceedings of SENSEVAL-3,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1697" citStr="Mihalcea et al. (2004)" startWordPosition="259" endWordPosition="262">uction In recent years, many research teams all over the world have gained rich experience on word sense disambiguation (WSD) from the shared tasks of the SENSEVAL workshops. The need for multiple knowledge sources has become a golden rule, and the &amp;quot;lexical sensitivity&amp;quot; once remarked by Resnik and Yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. Mihalcea, 2002; Escudero et al., 2004). Another common practice is to use an ensemble of classifiers. As pointed out by Mihalcea et al. (2004), among the participating systems in the SENSEVAL-3 English lexical sample task, &amp;quot;several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers&amp;quot;. However, the advancement in WSD is rarely accompanie d by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between the disambiguation results and the nature of individual target words underlying the apparent lexical sensitivity of the task. Giv</context>
</contexts>
<marker>Mihalcea, Chklovski, Kilgarriff, 2004</marker>
<rawString>Mihalcea, R., Chklovski, T. and Kilgarriff, A. (2004) The SENSEVAL-3 English Lexical Sample Task. In Proceedings of SENSEVAL-3, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>D Yarowsky</author>
</authors>
<title>A perspective on word sense disambiguation methods and their evaluation.</title>
<date>1997</date>
<booktitle>In Proceedings of SIGLEX&apos;97 Workshop: Tagging Text with Lexical Semantics: Why, What, and How?,</booktitle>
<pages>79--86</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="1389" citStr="Resnik and Yarowsky (1997)" startWordPosition="211" endWordPosition="214">statistical WSD. Despite the insignificant improvement observed in this preliminary attempt, more systematic analysis remains to be done for a cognitively plausible account of the factors underlying the lexical sensitivity of WSD, which would inform and enhance the development of WSD systems in return. 1 Introduction In recent years, many research teams all over the world have gained rich experience on word sense disambiguation (WSD) from the shared tasks of the SENSEVAL workshops. The need for multiple knowledge sources has become a golden rule, and the &amp;quot;lexical sensitivity&amp;quot; once remarked by Resnik and Yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. Mihalcea, 2002; Escudero et al., 2004). Another common practice is to use an ensemble of classifiers. As pointed out by Mihalcea et al. (2004), among the participating systems in the SENSEVAL-3 English lexical sample task, &amp;quot;several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual </context>
</contexts>
<marker>Resnik, Yarowsky, 1997</marker>
<rawString>Resnik, P. and Yarowsky, D. (1997) A perspective on word sense disambiguation methods and their evaluation. In Proceedings of SIGLEX&apos;97 Workshop: Tagging Text with Lexical Semantics: Why, What, and How?, Washington, D.C., pp.79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="4167" citStr="Witten and Frank, 2005" startWordPosition="644" endWordPosition="647"> In Section 3 we will discuss the 109 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 109–112, Prague, June 2007. c�2007 Association for Computational Linguistics optimally disambiguated with other types of information. human input on the target nature and the informativeness of various features. The experiments and results are presented in Section 4, followed by a conclusion in Section 5. Target Features 2 System Description 2.1 Core C(assifier The core system is a fully supervised one based on a Naive Bayes classifier. We made use of the Weka API (Witten and Frank, 2005) in our implementation. According to Yarowsky and Radu (2002), Bayesian classifiers belong to one of the aggregative models which depend heavily on the multiple reinforcing feature clues obtainable from wide context. Thus we use all features described in Section 2.2 below for our core system. 2.2 Know(edge Sources Only the training data provided by the task organisers was used to train the system. We used four major types of contextual features, which could be classified into Target features, Local features, Topical features and Syntactic features, as described in Table 1. All features were co</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Witten, I.H. and Frank, E. (2005) Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>F Radu</author>
</authors>
<title>Evaluating sense disambiguation across diverse parameter spaces.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<pages>8--4</pages>
<contexts>
<context position="4228" citStr="Yarowsky and Radu (2002)" startWordPosition="653" endWordPosition="656"> International Workshop on Semantic Evaluations (SemEval-2007), pages 109–112, Prague, June 2007. c�2007 Association for Computational Linguistics optimally disambiguated with other types of information. human input on the target nature and the informativeness of various features. The experiments and results are presented in Section 4, followed by a conclusion in Section 5. Target Features 2 System Description 2.1 Core C(assifier The core system is a fully supervised one based on a Naive Bayes classifier. We made use of the Weka API (Witten and Frank, 2005) in our implementation. According to Yarowsky and Radu (2002), Bayesian classifiers belong to one of the aggregative models which depend heavily on the multiple reinforcing feature clues obtainable from wide context. Thus we use all features described in Section 2.2 below for our core system. 2.2 Know(edge Sources Only the training data provided by the task organisers was used to train the system. We used four major types of contextual features, which could be classified into Target features, Local features, Topical features and Syntactic features, as described in Table 1. All features were converted to binary features. 2.3 Feature Se(ection On top of t</context>
</contexts>
<marker>Yarowsky, Radu, 2002</marker>
<rawString>Yarowsky, D. and Radu, F. (2002) Evaluating sense disambiguation across diverse parameter spaces. Natural Language Engineering, 8(4):293-310.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>