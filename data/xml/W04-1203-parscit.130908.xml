<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004108">
<title confidence="0.998235">
Analysis of Link Grammar on Biomedical Dependency Corpus
Targeted at Protein-Protein Interactions
</title>
<author confidence="0.9912965">
Sampo Pyysalo, Filip Ginter, Tapio Pahikkala, Jeppe Koivula
Jorma Boberg, Jouni J¨arvinen, Tapio Salakoski MediCel Ltd.,
</author>
<affiliation confidence="0.9664365">
Turku Centre for Computer Science (TUCS) Haartmaninkatu 8
and Dept. of computer science, University of Turku 00290 Helsinki, Finland,
</affiliation>
<address confidence="0.650128">
Lemmink¨aisenkatu 14A jeppe.koivula@medicel.com
20520 Turku, Finland,
</address>
<email confidence="0.981993">
first name.last name@it.utu.fi
</email>
<sectionHeader confidence="0.992995" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999747142857143">
In this paper, we present an evaluation of the
Link Grammar parser on a corpus consisting
of sentences describing protein-protein interac-
tions. We introduce the notion of an interac-
tion subgraph, which is the subgraph of a de-
pendency graph expressing a protein-protein in-
teraction. We measure the performance of the
parser for recovery of dependencies, fully correct
linkages and interaction subgraphs. We analyze
the causes of parser failure and report specific
causes of error, and identify potential modifica-
tions to the grammar to address the identified
issues. We also report and discuss the effect of
an extension to the dictionary of the parser.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920434782609">
The challenges of processing the vast amounts of
biomedical publications available in databases
such as MEDLINE have recently attracted a
considerable interest in the Natural Language
Processing (NLP) research community. The
task of information extraction, commonly tar-
geting entity relationships, such as protein-
protein interactions, is an often studied prob-
lem to which various NLP methods have been
applied, ranging from keyword-based methods
(see, e.g., Ginter et al. (2004)) to full syntactic
analysis as employed, for example, by Craven
and Kumlien (1999), Temkin and Gilder (2003)
and Daraselia et al. (2004).
In this paper, we focus on the syntactic anal-
ysis component of an information extraction
system targeted to find protein-protein inter-
actions from the dependency output produced
by the Link Grammar&apos; (LG) parser of Sleator
and Temperley (1991). Two recent papers study
LG in the context of biomedical NLP. The work
by Szolovits (2003) proposes a fully automated
method to extend the dictionary of the LG
</bodyText>
<footnote confidence="0.930378">
1http://www.link.cs.cmu.edu/link/
</footnote>
<bodyText confidence="0.99956028">
parser with the UMLS Specialiste lexicon, and
Ding et al. (2003) perform a basic evaluation
of LG performance on biomedical text. As both
papers suggest, LG will require modifications in
order to provide a correct analysis of grammat-
ical phenomena that are rare in general English
text, but common in biomedical language. Im-
plementing such modifications is a major effort
that requires a careful analysis of the perfor-
mance of the LG parser to identify the most
common causes of parsing failures and to target
modification efforts.
While Szolovits (2003) does not attempt to
evaluate parser performance at all and Ding
et al. (2003) provide only an informal evalua-
tion on manually simplified sentences, we focus
on a more formal evaluation of the LG parser.
For the purpose of this study and also for sub-
sequent research of biomedical information ex-
traction with the LG parser, we have developed
a hand-annotated corpus consisting of unmod-
ified sentences from publications. We use this
corpus to evaluate the performance of the LG
parser and to identify problems and potential
improvements to the grammar and parser.
</bodyText>
<sectionHeader confidence="0.598771" genericHeader="introduction">
2 Link Grammar and parser
</sectionHeader>
<bodyText confidence="0.996689071428571">
The Link Grammar and its parser represent an
implementation of a dependency-based compu-
tational grammar. The result of LG analysis for
a sentence is a labeled undirected simple graph,
whose nodes represent the words of the sentence
and whose edges and their labels express the
grammatical relationships between the words.
In LG terminology, the graph is called a link-
age, and its edges are called links. The linkage
must be planar (i.e., links must not cross) when
drawn above the words of the sentence, and the
labels of the links must satisfy the linking con-
straints specified for each word in the grammar.
A connected linkage is termed complete.
</bodyText>
<footnote confidence="0.978474">
2http://www.nlm.nih.gov/research/umls/
</footnote>
<page confidence="0.989992">
15
</page>
<figure confidence="0.542083">
findings suggest that PIP2 binds to proteins such as profilin
</figure>
<figureCaption confidence="0.655410333333333">
Figure 1: Annotation example. The interaction of two proteins, PIP2 and profilin, is stated by
the words binds to. The links joining these words form the interaction subgraph (drawn with solid
lines).
</figureCaption>
<bodyText confidence="0.999976">
Due to the structural ambiguity of natural
language, several linkages can typically be con-
structed for an input sentence. In such cases,
the LG parser enumerates all linkages allowed
by the grammar. A post-processing step is then
employed to enforce a number of additional con-
straints. The number of linkages for some sen-
tences can be very high, making post-processing
and storage prohibitively expensive. This prob-
lem is addressed in the LG parser by defining
kmax, the maximal number of linkages to be
post-processed. If the parsing algorithm pro-
duces more than kmax linkages, the output is
reduced to kmax linkages by random sampling.
The linkages are then ordered from best to worst
using heuristic goodness criteria.
In order to be usable in practice, a parser is
typically required to provide a partial analysis
of a sentence for which it cannot construct a full
analysis. If the LG parser cannot construct a
complete linkage for a sentence, the connected-
ness requirement is relaxed so that some words
do not belong to the linkage at all. The LG
parser is also time-limited. If the full set of
linkages cannot be constructed in a given time
tmax, the parser enters a panic mode, in which it
performs an efficient but considerably restricted
parse, resulting in reduced performance. The
parameters tmax and kmax set the trade-off be-
tween the qualitative performance and the re-
source efficiency of the parser.
</bodyText>
<sectionHeader confidence="0.8704115" genericHeader="method">
3 Corpus annotation and interaction
subgraphs
</sectionHeader>
<bodyText confidence="0.9996654">
To compile a corpus of sentences describing
protein-protein interactions, we first selected
pairs of proteins that are known to interact
from the Database of Interacting Proteins3. We
entered these pairs as search terms into the
PubMed retrieval system. We then split the
publication abstracts returned by the searches
into sentences and included titles. These were
again searched for the protein pairs. This gave
us a set of 1927 sentences that contain the
</bodyText>
<footnote confidence="0.837673">
3http://dip.doe-mbi.ucla.edu/
</footnote>
<bodyText confidence="0.931952941176471">
names of at least two proteins that are known
to interact. A domain expert annotated these
sentences for protein names and for words stat-
ing their interactions. Of these sentences, 1114
described at least one protein-protein interac-
tion.
Thereafter, we performed a dependency anal-
ysis and produced annotation of dependencies.
To minimize the amount of mistakes, each sen-
tence was independently annotated by two an-
notators and differences were then resolved by
discussion. The assigned dependency structure
was produced according to the LG linkage con-
ventions. Link types were not included in the
annotation, and no cycles were introduced in
the dependency graphs. All ambiguities where
the LG parser is capable of at least enumerat-
ing all alternatives (such as prepositional phrase
attachment) were enforced in the annotation.
A random sample consisting of 300 sentences,
including 28 publication titles, has so far been
fully annotated, giving 7098 word-to-word de-
pendencies. This set of sentences is the corpus
we refer to in the following sections.
An information extraction system targeted
at protein-protein interactions and their types
needs to identify three constituents that express
an interaction in a sentence: the proteins in-
volved and the word or phrase that states their
interaction and suggests the type of this inter-
action. To extract this information from a LG
linkage, the links connecting these items must
be recovered correctly by the parser. The fol-
lowing definition formalizes this notion.
</bodyText>
<construct confidence="0.992763666666667">
Definition 1 (Interaction subgraph) The
interaction subgraph for an interaction between
two proteins A and B in a linkage G is the
minimal connected subgraph of G that contains
A, B, and the word or phrase that states their
interaction.
</construct>
<bodyText confidence="0.997614">
The recovery of a connected component con-
taining the protein names and the interaction
word is not sufficient: by the definition of a
complete linkage, such a component is always
present. Consequently, the exact set of links
</bodyText>
<page confidence="0.983217">
16
</page>
<bodyText confidence="0.9998506875">
that forms the interaction subgraph must be re-
covered.
For each interaction stated in a sentence,
the corpus annotation specifies the proteins in-
volved and the interaction word. The interac-
tion subgraph for each interaction can thus be
extracted automatically from the corpus. Be-
cause the corpus does not contain cyclic depen-
dencies, the interaction subgraphs are unique.
366 interaction subgraphs were identified from
the corpus, one for each described interaction.
The interaction subgraphs can be partially over-
lapping, because a single link can be part of
more than one interaction subgraph. Figure 1
shows an example of an annotated text frag-
ment.
</bodyText>
<sectionHeader confidence="0.989838" genericHeader="method">
4 Evaluation criteria
</sectionHeader>
<bodyText confidence="0.998805666666667">
We evaluated the performance of the LG parser
according to the following three quantitative cri-
teria:
</bodyText>
<listItem confidence="0.999898">
• Number of dependencies recovered
• Number of fully correct linkages
• Number of interaction subgraphs recovered
</listItem>
<bodyText confidence="0.999961585365854">
The number of recovered dependencies gives an
estimate of the probability that a dependency
will be correctly identified by the LG parser
(this criterion is also employed by, e.g., Collins
et al. (1999)). The number of fully correct link-
ages, i.e. linkages where all annotated depen-
dencies are recovered, measures the fraction of
sentences that are parsed without error. How-
ever, a fully correct linkage is not necessary to
extract protein-protein interactions from a sen-
tence; to estimate how many interactions can
potentially be recovered, we measure the num-
ber of interaction subgraphs for which all de-
pendencies were recovered.
For each criterion, we measure the perfor-
mance for the first linkage returned by the
parser. However, the first linkage as ordered
by the heuristics of the LG parser was often not
the best (according to the criteria above) of the
linkages returned by the parser. To separate
the effect of the heuristics from overall LG per-
formance, we identify separately for each of the
three criteria the best linkage among the link-
ages returned by the parser, and we also report
performance for the best linkages.
We further divide the parsed sentences into
three categories: (1) sentences for which the
time tmax for producing a normal parse was ex-
hausted and the parser entered panic mode, (2)
sentences where linkages were sampled because
more than kmax linkages were produced, and
(3) stable sentences for which neither of these
occurred. A full analysis of all linkages that
the grammar allows is only possible for stable
sentences. For sentences in the other two cat-
egories, random effects may affect the results:
sentences for which more than kmax linkages are
produced are subject to randomness in sam-
pling, and sentences where the parser enters
panic mode were always subject to subsequent
sampling in our experiments.
</bodyText>
<sectionHeader confidence="0.996016" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999879484848485">
To evaluate the ability of the LG parser to pro-
duce correct linkages, we increased the number
of stable sentences by setting the tmax param-
eter to 10 minutes and the kmax parameter to
10000 instead of using the defaults tmax = 30
seconds and kmax = 1000. When parsing the
corpus using these parameters, 28 sentences fell
into the panic category, 61 into the sampled
category, and 211 were stable. The measured
parser performance for the corpus is presented
in Table 1.
While the fraction of sentences that have a
fully correct linkage as the first linkage is quite
low (approximately 7%), for 28% of sentences
the parser is capable of producing a fully cor-
rect linkage. Performance was especially poor
for the publication titles in the corpus. Because
titles are typically fragments not containing a
verb, and LG is designed to model full clauses,
the parser failed to produce a fully correct link-
age for any of the titles.
The performance for recovered interaction
subgraphs is more encouraging, as 25% of the
subgraphs were recovered in the first linkage and
more than half in the best linkage. Yet many in-
teraction subgraphs remain unrecovered by the
parser: the results suggest an upper limit of
approximately 60% to the fraction of protein-
protein interactions that can be recovered from
any linkage produced by the unmodified LG.
In the following sections we further analyze the
reasons why the parser fails to recover all de-
pendencies.
</bodyText>
<subsectionHeader confidence="0.994282">
5.1 Panics
</subsectionHeader>
<bodyText confidence="0.999891">
No fully correct linkages and very few interac-
tion subgraphs were found in the panic mode.
This effect may be partly due to the complex-
ity of the sentences for which the parser en-
</bodyText>
<page confidence="0.994744">
17
</page>
<table confidence="0.988802272727273">
Category
Criterion Linkage Stable Sampled Panic Overall
Dependency First linkage 3242 (80.0%) 1376 (74.3%) 569 (52.3%) 5187 (73.1%)
Best linkage 3601 (86.6%) 1576 (85.0%) 620 (57.0%) 5797 (81.7%)
Total 4157 1853 1088 7098
Fully correct First linkage 22 (10.4%) 0 (0.0%) 0 (0.0%) 22 (7.3%)
Best linkage 79 (37.4%) 6 (9.8%) 0 (0.0%) 85 (28.3%)
Total 211 61 28 300
Interaction First linkage 75 (30.5%) 16 (20.2%) 0 (0.0%) 91 (24.9%)
subgraph Best linkage 156 (63.4%) 49 (62.0%) 4 (9.8%) 209 (57.1%)
Total 246 79 41 366
</table>
<tableCaption confidence="0.940498">
Table 1: Parser performance. The fraction of fulfilled criteria is shown by category (the criteria and
categories are explained in Section 4). The total rows give the number of criteria for each category,
</tableCaption>
<bodyText confidence="0.985750666666667">
and the overall column gives combined results for all categories.
tered panic mode. The effect of panics can
be better estimated by forcing the parser to
bypass standard parsing and to directly apply
panic options. For the 272 sentences where the
parser did not enter the panic mode, 77% of
dependencies were recovered in the first link-
age. When these sentences were parsed in forced
panic mode, 67% of dependencies were recov-
ered, suggesting that on average parses in panic
mode recover approximately 10% fewer depen-
dencies than in standard parsing mode. Simi-
larly, the number of fully correct first linkages
decreased from 22 to 6 and the number of inter-
action subgraphs recovered in the first linkage
from 91 to 65. These numbers indicate that
panics are a significant cause of error.
Experiments indicate than on a 1GHz ma-
chine approximately 40% of sentences can be
fully parsed in under a second, 80% in under 10
seconds and 90% within 10 minutes; yet approx-
imately 5% of sentences take more than an hour
to fully parse. With tmax set to 10 minutes, the
total parsing time was 165 minutes.
Long parsing times are caused by ambiguous
sentences for which the parser creates thousands
or even millions of alternative linkages. In ad-
dition to simply increasing the time limit, the
fraction of sentences where the parser enters the
panic mode could therefore be reduced by re-
ducing the ambiguity of the sentences, for ex-
ample, by extending the dictionary of the parser
(see Section 7).
</bodyText>
<subsectionHeader confidence="0.99205">
5.2 Heuristics
</subsectionHeader>
<bodyText confidence="0.9999710625">
When several linkages are produced for a sen-
tence, the LG parser applies heuristics to or-
der the sentences so that linkages that are more
likely to be correct are presented first. The
heuristics are based on examination and intu-
itions on general English, and may not be opti-
mal for biomedical text. Note in Table 1 that
both for recovered full linkages and interaction
subgraphs, the number of items that were recov-
ered in the best linkage is more than twice the
number recovered in the first linkage, suggesting
that a better ordering heuristic could dramat-
ically improve the performance of the parser.
Such improvements could perhaps be achieved
by tuning the heuristics to the domain or by
adopting a probabilistic ordering model.
</bodyText>
<sectionHeader confidence="0.932048" genericHeader="method">
6 Failure analysis
</sectionHeader>
<bodyText confidence="0.99997315">
A significant fraction of dependencies were not
recovered in any linkage, even in sentences
where resources were not exhausted. In order to
identify reasons for the parser failing to recover
the correct dependencies, we analyze sentences
for which it is certain that the grammar cannot
produce a fully correct linkage. We thus ana-
lyzed the 132 stable sentences for which some
dependencies were not recovered.
For each sentence, we attempt to identify the
reason for the failure of the parser. For each
identified reason, we manually edit the sentence
to remove the source of failure. We repeat this
procedure until the parser is capable of pro-
ducing a correct parse for the sentence. Note
that this implies that also the interaction sub-
graphs in the sentence are correctly recovered,
and therefore the reasons for failures to recover
interaction subgraphs are a subset of the iden-
tified issues. The results of the analysis are
</bodyText>
<page confidence="0.99716">
18
</page>
<table confidence="0.999486">
Reason for failure Cases
Unknown grammatical structure 72 (34.4%)
Dictionary issue 54 (25.8%)
Unknown word handling 35 (16.7%)
Sentence fragment 27 (12.9%)
Ungrammatical sentence 17 (8.1%)
Other 4 (1.9%)
</table>
<tableCaption confidence="0.999784">
Table 2: Results of failure analysis
</tableCaption>
<bodyText confidence="0.995236">
summarized in Table 2. In many of the sen-
tences, more than one reason for parser failure
was found; in total 209 issues were identified in
the 132 sentences. The results are described in
more detail in the following sections.
</bodyText>
<subsectionHeader confidence="0.902223">
6.1 Fragments and ungrammatical
sentences
</subsectionHeader>
<bodyText confidence="0.9999735">
As some of the analyzed sentences were taken
from publication titles, not all of them were
full clauses. To identify further problems when
parsing fragments not containing a verb, the
phrase “is explained” and required determiners
were added to these fragments, a technique used
also by Ding et al. (2003). The completed frag-
ments were then analyzed for potential further
problems.
A number of other ungrammatical sentences
were also encountered. The most common
problem was the omission of determiners, but
some other issues such as missing possessive
markers and errors in agreement (e.g., “expres-
sions... has”) were also encountered.
Ungrammatical sentences pose interesting
challenges for parsing. Because many authors
are not native English speakers, a greater toler-
ance for grammatical mistakes should allow the
parser to identify the intended parse for more
sentences. Similarly, the ability to parse publi-
cation titles would extend the applicability of
the parser; in some cases it may be possible
to extract information concerning the key find-
ings of a publication from the title. However,
while relaxing completeness and correctness re-
quirements, such as mandatory determiners and
subject-predicate agreement, would allow the
parser to create a complete linkage for more sen-
tences, it would also be expected to lead to in-
creased ambiguity for all sentences, and subse-
quent difficulties in identifying the correct link-
age. If the ability to parse titles is considered
important, a potential solution not incurring
this cost would be to develop a separate version
of the grammar for parsing titles.
</bodyText>
<figureCaption confidence="0.83627825">
Figure 2: Multiple modifier coordination prob-
lem. Above: correct linkage disallowed by the
LG parser. Below: solution by chaining modi-
fiers.
</figureCaption>
<subsectionHeader confidence="0.999733">
6.2 Unknown grammatical structures
</subsectionHeader>
<bodyText confidence="0.999972027777778">
The method of the LG implementation for pars-
ing coordinations was found to be a frequent
cause of failures. A specific coordination prob-
lem occurs with multiple noun-modifiers: the
parser assumes that coordinated constituents
can be connected to the rest of the sentence
through exactly one word, and the grammar at-
taches all noun-modifiers to the head. Biomed-
ical texts frequently contain phrases that cause
these requirements to conflict: for example, in
the phrase “capping protein and actin genes”
(where “capping protein genes” and “actin
genes” is the intended parse), the parser allows
only one of the words “capping” and “protein”
to connect to the word “genes”, and is thus un-
able to produce the correct linkage (for illustra-
tion, see Figure 2(a)).
This multiple modifier coordination issue
could be addressed by modifying the grammar
to chain modifiers (Figure 2(b)). This alterna-
tive model is adopted by another major depen-
dency grammar, the EngCG-based Connexor
Machinese. The problem could also be ad-
dressed by altering the coordination handling
system in the parser.
Other identified grammatical structures not
known to the parser were number postmodifiers
to nouns (e.g., “serine 38”), specifiers in paren-
theses (e.g., “profilin mutant (H119E)”), coor-
dination with the phrase “but not”, and various
unknown uses of colons and quotes. Single in-
stances of several distinct unknown grammati-
cal structures were also noted (e.g., “5 to 10”,
“as expected from”, “most concentrated in”).
Most of these issues can be addressed by local
modifications to the grammar.
</bodyText>
<subsectionHeader confidence="0.998738">
6.3 Unknown word handling
</subsectionHeader>
<bodyText confidence="0.9967412">
The LG parser assigns unknown words to cate-
gories based on morphological or other surface
clues when possible. For remaining unknown
capping protein and actin genes
capping protein and actin genes
</bodyText>
<page confidence="0.985186">
19
</page>
<bodyText confidence="0.999701">
words, parses are attempted by assigning the
words to the generic noun, verb and adjective
types in all possible combinations.
Some problems with the unknown word pro-
cessing method were encountered during analy-
sis; for example, the assumption that unknown
capitalized words are proper nouns often caused
failures, especially in sentences beginning with
an unknown word. Similarly, the assumption
that words containing a hyphen behave as ad-
jectives was violated by a number of unknown
verbs (e.g., “cross-links”).
Another problem that was noted occurred
with lowercase unknown words that should be
treated as proper nouns: because LG does not
allow unknown lowercase words to act as proper
nouns, the parser assigns incorrect structure to
a number of phrases containing words such as
“actin”. Improving unknown word handling re-
quires some modifications to the LG parser.
</bodyText>
<subsectionHeader confidence="0.99078">
6.4 Dictionary issues
</subsectionHeader>
<bodyText confidence="0.999920142857143">
Cases where the LG dictionary contains a word,
but not in the sense in which it appears in a
sentence, almost always lead to errors. For ex-
ample, the LG dictionary does not contain the
word “assembly” in the sense “construction”,
causing the parser to erroneously require a de-
terminer for “protein assembly”4. A related
frequent problem occurred with proper names
headed by a common noun, where the parser ex-
pects a determiner for such names (e.g., “myosin
heavy chain”), and fails when one is not present.
These issues are mostly straightforward to ad-
dress in the grammar, but difficult to identify
automatically.
</bodyText>
<subsectionHeader confidence="0.999556">
6.5 Biomedical entity names
</subsectionHeader>
<bodyText confidence="0.999378142857143">
Many of the causes for parser failure discussed
above are related to the presence of biomed-
ical entity names. While the causes for fail-
ures relating to names can be addressed in the
grammar, the existence of biomedical named en-
tity (NE) recognition systems (for a recent sur-
vey, see, e.g., Bunescu et al. (2004)) suggests
an alternative solution: NEs could be identified
in preprocessing, and treated as single (proper
noun) tokens during the parse. During failure
analysis, 59 cases (28% of all cases) were noted
where this procedure would have eliminated the
error, assuming that no errors are made in NE
430 distinct problematic word definitions were iden-
tified, including “breakdown”, “composed”, “factor”,
“half”, “independent”, “localized”, “parallel”, “pro-
moter”, “segment”, “upstream” and “via”.
recognition. However, the performance of cur-
rent NE recognition systems is not perfect, and
it is not clear what the effect of adopting such
a method would be on parser performance.
</bodyText>
<sectionHeader confidence="0.985687" genericHeader="method">
7 Dictionary extension
</sectionHeader>
<bodyText confidence="0.999984690476191">
Szolovits (2003) describes an automatic method
for mapping lexical information from one lexi-
con to another, and applies this method to aug-
ment the LG dictionary with terms from the ex-
tensive UMLS Specialist lexicon. The extension
introduces more than 125,000 new words into
the LG dictionary, more than tripling its size.
We evaluated the effect of this dictionary exten-
sion on LG parser performance using the criteria
described above. The fraction of distinct tokens
in the corpus found in the parser dictionary in-
creased from 52% to 72% with the dictionary
extension, representing a significant reduction
in uncertainty. This decrease was coupled with
a 32% reduction in total parsing time.
Because the LG parser is unable to produce
any linkage for sentences where it cannot iden-
tify a verb (even incorrectly), extending the dic-
tionary significantly reduced the ability of LG
to extract dependencies in titles, where the frac-
tion of recovered dependencies fell from the al-
ready low value of 67% to 55%.
For the sentences excluding titles, the benefits
of the dictionary extension were most significant
for sentences that were in the panic category
when using the unextended LG dictionary; 12
of these 28 sentences could be parsed without
panic with the dictionary extension. In the first
linkage of these sentences, the fraction of re-
covered dependencies increased by 8%, and the
fraction of recovered interaction subgraphs in-
creased from zero to 15% with the dictionary
extension.
The overall effect of the dictionary extension
was positive but modest, with no more than
2.5% improvement for either the first or best
linkages for any criterion, despite the threefold
increase in dictionary size. This result agrees
with the failure analysis: most problems can-
not be removed by extending the dictionary and
must instead be addressed by modifications of
the grammar or parser.
</bodyText>
<sectionHeader confidence="0.998306" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.99998725">
We have presented an analysis of Link Gram-
mar performance using a custom dependency
corpus targeted at protein-protein interactions.
We introduced the concept of the interaction
</bodyText>
<page confidence="0.979914">
20
</page>
<bodyText confidence="0.99995146">
subgraph and reported parser performance for
three criteria: recovery of dependencies, in-
teraction subgraphs and fully correct linkages.
While LG was able to recover 73% of dependen-
cies in the first linkage, only 7% of sentences had
a fully correct first linkage. However, fully cor-
rect linkages are not required for information ex-
traction, and we found that 25% of interaction
subgraphs were recovered in the first linkage.
Resource exhaustion was found to be a signif-
icant cause of poor performance. Furthermore,
an evaluation of performance in the case when
optimal heuristics for ordering linkages are ap-
plied indicated that the fraction of recovered in-
teraction subgraphs could be more than doubled
(to 57%) by optimal heuristics.
To further analyze the cases where the parser
cannot produce a correct linkage, we carefully
examined the sentences and were able to iden-
tify five problem types. For each identified
case, we discussed potential modifications for
addressing the problems. We also considered
the possibility of using a named entity recogni-
tion system to improve parser performance and
found that 28% of LG failures would be avoided
by a flawless named entity recognition system.
We evaluated the effect of the dictionary ex-
tension proposed by Szolovits (2003), and found
that while it significantly reduced ambiguity
and improved performance for the most ambigu-
ous sentences, overall improvement was only
2.5%. This indicates that extending the dic-
tionary is not sufficient to address the perfor-
mance problems and that modifications to the
grammar and parser are necessary.
The quantitative analysis of LG performance
confirms that, in its current state, LG is not well
suited to the IE task discussed. However, in the
failure analysis we have identified a number of
specific issues and problematic areas for LG in
parsing biomedical publications, and suggested
improvements for adapting the parser to this
domain. The examination and implementation
of these improvements is a natural follow-up of
this study. Our initial experiments suggest that
it is indeed possible to implement general so-
lutions to many of the discussed problems, and
such modifications would be expected to lead to
improved applicability of LG to the biomedical
domain.
</bodyText>
<sectionHeader confidence="0.998603" genericHeader="acknowledgments">
9 Acknowledgments
</sectionHeader>
<bodyText confidence="0.943626">
This work has been supported by Tekes, the
Finnish National Technology Agency.
</bodyText>
<sectionHeader confidence="0.989396" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999643636363636">
Razvan Bunescu, Ruifang Ge, Rohit J. Kate,
Edward M. Marcotte, Raymond J. Mooney,
Arun Kumar Ramani, and Yuk Wah Wong. 2004
(to appear). Comparative experiments on learn-
ing information extractors for proteins and their
interactions. Artificial Intelligence in Medicine.
Special Issue on Summarization and Information
Extraction from Medical Documents.
Michael Collins, Jan Hajic, Lance Ramshaw, and
Christoph Tillmann. 1999. A statistical parser
for Czech. In 37th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 505–
512. Association for Computational Linguistics,
Somerset, New Jersey.
Mark Craven and Johan Kumlien. 1999. Construct-
ing biological knowledge bases by extracting in-
formation from text sources. In T. Lengauer,
R. Schneider, P. Bork, D. Brutlag, J. Glasgow,
H HW Mewes, and Zimmer R., editors, Proceed-
ings of the 7th International Conference on Intel-
ligent Systems in Molecular Biology, pages 77–86.
AAAI Press, Menlo Park, CA.
Nikolai Daraselia, Anton Yuryev, Sergei Egorov,
Svetalana Novichkova, Alexander Nikitin, and
Ilya Mazo. 2004. Extracting human protein in-
teractions from MEDLINE using a full-sentence
parser. Bioinformatics, 20(5):604–611.
Jing Ding, Daniel Berleant, Jun Xu, and Andy W.
Fulmer. 2003. Extracting biochemical interac-
tions from medline using a link grammar parser.
In B. Werner, editor, Proceedings of the 15th
IEEE International Conference on Tools with Ar-
tificial Intelligence, pages 467–471. IEEE Com-
puter Society, Los Alamitos, CA.
Filip Ginter, Tapio Pahikkala, Sampo Pyysalo,
Jorma Boberg, Jouni J¨arvinen, and Tapio
Salakoski. 2004. Extracting protein-protein inter-
action sentences by applying rough set data anal-
ysis. In S. Tsumoto, R. Slowinski, J. Komorowski,
and J.W. Grzymala-Busse, editors, Lecture Notes
in Computer Science 3066. Springer, Heidelberg.
Daniel D. Sleator and Davy Temperley. 1991. Pars-
ing english with a link grammar. Technical Re-
port CMU-CS-91-196, Department of Computer
Science, Carnegie Mellon University, Pittsburgh,
PA.
Peter Szolovits. 2003. Adding a medical lexicon to
an english parser. In Mark Musen, editor, Pro-
ceedings of the 2003 AMIA Annual Symposium,
pages 639–643. American Medical Informatics As-
sociation, Bethesda, MD.
Joshua M. Temkin and Mark R. Gilder. 2003. Ex-
traction of protein interaction information from
unstructured text using a context-free grammar.
Bioinformatics, 19(16):2046–2053.
</reference>
<page confidence="0.999435">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.662430">
<title confidence="0.991404">Analysis of Link Grammar on Biomedical Dependency Targeted at Protein-Protein Interactions</title>
<author confidence="0.991169">Sampo Pyysalo</author>
<author confidence="0.991169">Filip Ginter</author>
<author confidence="0.991169">Tapio Pahikkala</author>
<author confidence="0.991169">Jeppe Koivula</author>
<affiliation confidence="0.890119666666667">Boberg, Jouni J¨arvinen, Tapio Salakoski Ltd., Turku Centre for Computer Science (TUCS) Haartmaninkatu and Dept. of computer science, University of Turku 00290 Helsinki, Finland,</affiliation>
<address confidence="0.9984085">Lemmink¨aisenkatu 14A 20520 Turku, Finland,</address>
<email confidence="0.979564">firstname.lastname@it.utu.fi</email>
<abstract confidence="0.999558733333333">In this paper, we present an evaluation of the Link Grammar parser on a corpus consisting of sentences describing protein-protein interactions. We introduce the notion of an interaction subgraph, which is the subgraph of a dependency graph expressing a protein-protein interaction. We measure the performance of the parser for recovery of dependencies, fully correct linkages and interaction subgraphs. We analyze the causes of parser failure and report specific causes of error, and identify potential modifications to the grammar to address the identified issues. We also report and discuss the effect of an extension to the dictionary of the parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Ruifang Ge</author>
<author>Rohit J Kate</author>
<author>Edward M Marcotte</author>
<author>Raymond J Mooney</author>
<author>Arun Kumar Ramani</author>
<author>Yuk Wah Wong</author>
</authors>
<title>(to appear). Comparative experiments on learning information extractors for proteins and their interactions.</title>
<date>2004</date>
<booktitle>Artificial Intelligence in Medicine. Special Issue on Summarization and Information Extraction from Medical Documents.</booktitle>
<contexts>
<context position="22435" citStr="Bunescu et al. (2004)" startWordPosition="3609" endWordPosition="3612">lem occurred with proper names headed by a common noun, where the parser expects a determiner for such names (e.g., “myosin heavy chain”), and fails when one is not present. These issues are mostly straightforward to address in the grammar, but difficult to identify automatically. 6.5 Biomedical entity names Many of the causes for parser failure discussed above are related to the presence of biomedical entity names. While the causes for failures relating to names can be addressed in the grammar, the existence of biomedical named entity (NE) recognition systems (for a recent survey, see, e.g., Bunescu et al. (2004)) suggests an alternative solution: NEs could be identified in preprocessing, and treated as single (proper noun) tokens during the parse. During failure analysis, 59 cases (28% of all cases) were noted where this procedure would have eliminated the error, assuming that no errors are made in NE 430 distinct problematic word definitions were identified, including “breakdown”, “composed”, “factor”, “half”, “independent”, “localized”, “parallel”, “promoter”, “segment”, “upstream” and “via”. recognition. However, the performance of current NE recognition systems is not perfect, and it is not clear</context>
</contexts>
<marker>Bunescu, Ge, Kate, Marcotte, Mooney, Ramani, Wong, 2004</marker>
<rawString>Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M. Marcotte, Raymond J. Mooney, Arun Kumar Ramani, and Yuk Wah Wong. 2004 (to appear). Comparative experiments on learning information extractors for proteins and their interactions. Artificial Intelligence in Medicine. Special Issue on Summarization and Information Extraction from Medical Documents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajic</author>
<author>Lance Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>505--512</pages>
<location>Somerset, New Jersey.</location>
<contexts>
<context position="9300" citStr="Collins et al. (1999)" startWordPosition="1458" endWordPosition="1461">nteraction subgraphs can be partially overlapping, because a single link can be part of more than one interaction subgraph. Figure 1 shows an example of an annotated text fragment. 4 Evaluation criteria We evaluated the performance of the LG parser according to the following three quantitative criteria: • Number of dependencies recovered • Number of fully correct linkages • Number of interaction subgraphs recovered The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999)). The number of fully correct linkages, i.e. linkages where all annotated dependencies are recovered, measures the fraction of sentences that are parsed without error. However, a fully correct linkage is not necessary to extract protein-protein interactions from a sentence; to estimate how many interactions can potentially be recovered, we measure the number of interaction subgraphs for which all dependencies were recovered. For each criterion, we measure the performance for the first linkage returned by the parser. However, the first linkage as ordered by the heuristics of the LG parser was </context>
</contexts>
<marker>Collins, Hajic, Ramshaw, Tillmann, 1999</marker>
<rawString>Michael Collins, Jan Hajic, Lance Ramshaw, and Christoph Tillmann. 1999. A statistical parser for Czech. In 37th Annual Meeting of the Association for Computational Linguistics, pages 505– 512. Association for Computational Linguistics, Somerset, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>Proceedings of the 7th International Conference on Intelligent Systems in Molecular Biology,</booktitle>
<pages>77--86</pages>
<editor>In T. Lengauer, R. Schneider, P. Bork, D. Brutlag, J. Glasgow, H HW Mewes, and Zimmer R., editors,</editor>
<publisher>AAAI Press,</publisher>
<location>Menlo Park, CA.</location>
<contexts>
<context position="1692" citStr="Craven and Kumlien (1999)" startWordPosition="241" endWordPosition="244">of an extension to the dictionary of the parser. 1 Introduction The challenges of processing the vast amounts of biomedical publications available in databases such as MEDLINE have recently attracted a considerable interest in the Natural Language Processing (NLP) research community. The task of information extraction, commonly targeting entity relationships, such as proteinprotein interactions, is an often studied problem to which various NLP methods have been applied, ranging from keyword-based methods (see, e.g., Ginter et al. (2004)) to full syntactic analysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performan</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In T. Lengauer, R. Schneider, P. Bork, D. Brutlag, J. Glasgow, H HW Mewes, and Zimmer R., editors, Proceedings of the 7th International Conference on Intelligent Systems in Molecular Biology, pages 77–86. AAAI Press, Menlo Park, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikolai Daraselia</author>
<author>Anton Yuryev</author>
<author>Sergei Egorov</author>
<author>Svetalana Novichkova</author>
<author>Alexander Nikitin</author>
<author>Ilya Mazo</author>
</authors>
<title>Extracting human protein interactions from MEDLINE using a full-sentence parser.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="1746" citStr="Daraselia et al. (2004)" startWordPosition="250" endWordPosition="253">duction The challenges of processing the vast amounts of biomedical publications available in databases such as MEDLINE have recently attracted a considerable interest in the Natural Language Processing (NLP) research community. The task of information extraction, commonly targeting entity relationships, such as proteinprotein interactions, is an often studied problem to which various NLP methods have been applied, ranging from keyword-based methods (see, e.g., Ginter et al. (2004)) to full syntactic analysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performance on biomedical text. As both papers suggest, LG will</context>
</contexts>
<marker>Daraselia, Yuryev, Egorov, Novichkova, Nikitin, Mazo, 2004</marker>
<rawString>Nikolai Daraselia, Anton Yuryev, Sergei Egorov, Svetalana Novichkova, Alexander Nikitin, and Ilya Mazo. 2004. Extracting human protein interactions from MEDLINE using a full-sentence parser. Bioinformatics, 20(5):604–611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Ding</author>
<author>Daniel Berleant</author>
<author>Jun Xu</author>
<author>Andy W Fulmer</author>
</authors>
<title>Extracting biochemical interactions from medline using a link grammar parser.</title>
<date>2003</date>
<booktitle>Proceedings of the 15th IEEE International Conference on Tools with Artificial Intelligence,</booktitle>
<pages>467--471</pages>
<editor>In B. Werner, editor,</editor>
<publisher>IEEE Computer Society,</publisher>
<location>Los Alamitos, CA.</location>
<contexts>
<context position="2249" citStr="Ding et al. (2003)" startWordPosition="328" endWordPosition="331">alysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performance on biomedical text. As both papers suggest, LG will require modifications in order to provide a correct analysis of grammatical phenomena that are rare in general English text, but common in biomedical language. Implementing such modifications is a major effort that requires a careful analysis of the performance of the LG parser to identify the most common causes of parsing failures and to target modification efforts. While Szolovits (2003) does not attempt to evaluate parser performance at all and Ding et al. (2003) provide only an informal evalua</context>
<context position="17312" citStr="Ding et al. (2003)" startWordPosition="2800" endWordPosition="2803"> (1.9%) Table 2: Results of failure analysis summarized in Table 2. In many of the sentences, more than one reason for parser failure was found; in total 209 issues were identified in the 132 sentences. The results are described in more detail in the following sections. 6.1 Fragments and ungrammatical sentences As some of the analyzed sentences were taken from publication titles, not all of them were full clauses. To identify further problems when parsing fragments not containing a verb, the phrase “is explained” and required determiners were added to these fragments, a technique used also by Ding et al. (2003). The completed fragments were then analyzed for potential further problems. A number of other ungrammatical sentences were also encountered. The most common problem was the omission of determiners, but some other issues such as missing possessive markers and errors in agreement (e.g., “expressions... has”) were also encountered. Ungrammatical sentences pose interesting challenges for parsing. Because many authors are not native English speakers, a greater tolerance for grammatical mistakes should allow the parser to identify the intended parse for more sentences. Similarly, the ability to par</context>
</contexts>
<marker>Ding, Berleant, Xu, Fulmer, 2003</marker>
<rawString>Jing Ding, Daniel Berleant, Jun Xu, and Andy W. Fulmer. 2003. Extracting biochemical interactions from medline using a link grammar parser. In B. Werner, editor, Proceedings of the 15th IEEE International Conference on Tools with Artificial Intelligence, pages 467–471. IEEE Computer Society, Los Alamitos, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filip Ginter</author>
<author>Tapio Pahikkala</author>
<author>Sampo Pyysalo</author>
<author>Jorma Boberg</author>
<author>Jouni J¨arvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>Extracting protein-protein interaction sentences by applying rough set data analysis.</title>
<date>2004</date>
<booktitle>Lecture Notes in Computer Science</booktitle>
<pages>3066</pages>
<editor>In S. Tsumoto, R. Slowinski, J. Komorowski, and J.W. Grzymala-Busse, editors,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg.</location>
<marker>Ginter, Pahikkala, Pyysalo, Boberg, J¨arvinen, Salakoski, 2004</marker>
<rawString>Filip Ginter, Tapio Pahikkala, Sampo Pyysalo, Jorma Boberg, Jouni J¨arvinen, and Tapio Salakoski. 2004. Extracting protein-protein interaction sentences by applying rough set data analysis. In S. Tsumoto, R. Slowinski, J. Komorowski, and J.W. Grzymala-Busse, editors, Lecture Notes in Computer Science 3066. Springer, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel D Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing english with a link grammar.</title>
<date>1991</date>
<tech>Technical Report CMU-CS-91-196,</tech>
<institution>Department of Computer Science, Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="1990" citStr="Sleator and Temperley (1991)" startWordPosition="288" endWordPosition="291">f information extraction, commonly targeting entity relationships, such as proteinprotein interactions, is an often studied problem to which various NLP methods have been applied, ranging from keyword-based methods (see, e.g., Ginter et al. (2004)) to full syntactic analysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performance on biomedical text. As both papers suggest, LG will require modifications in order to provide a correct analysis of grammatical phenomena that are rare in general English text, but common in biomedical language. Implementing such modifications is a major effort that requires a careful analysis </context>
</contexts>
<marker>Sleator, Temperley, 1991</marker>
<rawString>Daniel D. Sleator and Davy Temperley. 1991. Parsing english with a link grammar. Technical Report CMU-CS-91-196, Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Szolovits</author>
</authors>
<title>Adding a medical lexicon to an english parser.</title>
<date>2003</date>
<booktitle>Proceedings of the 2003 AMIA Annual Symposium,</booktitle>
<pages>639--643</pages>
<editor>In Mark Musen, editor,</editor>
<publisher>American Medical Informatics Association,</publisher>
<location>Bethesda, MD.</location>
<contexts>
<context position="2081" citStr="Szolovits (2003)" startWordPosition="306" endWordPosition="307"> is an often studied problem to which various NLP methods have been applied, ranging from keyword-based methods (see, e.g., Ginter et al. (2004)) to full syntactic analysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performance on biomedical text. As both papers suggest, LG will require modifications in order to provide a correct analysis of grammatical phenomena that are rare in general English text, but common in biomedical language. Implementing such modifications is a major effort that requires a careful analysis of the performance of the LG parser to identify the most common causes of parsing failures </context>
<context position="23149" citStr="Szolovits (2003)" startWordPosition="3716" endWordPosition="3717">e (proper noun) tokens during the parse. During failure analysis, 59 cases (28% of all cases) were noted where this procedure would have eliminated the error, assuming that no errors are made in NE 430 distinct problematic word definitions were identified, including “breakdown”, “composed”, “factor”, “half”, “independent”, “localized”, “parallel”, “promoter”, “segment”, “upstream” and “via”. recognition. However, the performance of current NE recognition systems is not perfect, and it is not clear what the effect of adopting such a method would be on parser performance. 7 Dictionary extension Szolovits (2003) describes an automatic method for mapping lexical information from one lexicon to another, and applies this method to augment the LG dictionary with terms from the extensive UMLS Specialist lexicon. The extension introduces more than 125,000 new words into the LG dictionary, more than tripling its size. We evaluated the effect of this dictionary extension on LG parser performance using the criteria described above. The fraction of distinct tokens in the corpus found in the parser dictionary increased from 52% to 72% with the dictionary extension, representing a significant reduction in uncert</context>
<context position="26482" citStr="Szolovits (2003)" startWordPosition="4249" endWordPosition="4250">action subgraphs could be more than doubled (to 57%) by optimal heuristics. To further analyze the cases where the parser cannot produce a correct linkage, we carefully examined the sentences and were able to identify five problem types. For each identified case, we discussed potential modifications for addressing the problems. We also considered the possibility of using a named entity recognition system to improve parser performance and found that 28% of LG failures would be avoided by a flawless named entity recognition system. We evaluated the effect of the dictionary extension proposed by Szolovits (2003), and found that while it significantly reduced ambiguity and improved performance for the most ambiguous sentences, overall improvement was only 2.5%. This indicates that extending the dictionary is not sufficient to address the performance problems and that modifications to the grammar and parser are necessary. The quantitative analysis of LG performance confirms that, in its current state, LG is not well suited to the IE task discussed. However, in the failure analysis we have identified a number of specific issues and problematic areas for LG in parsing biomedical publications, and suggest</context>
</contexts>
<marker>Szolovits, 2003</marker>
<rawString>Peter Szolovits. 2003. Adding a medical lexicon to an english parser. In Mark Musen, editor, Proceedings of the 2003 AMIA Annual Symposium, pages 639–643. American Medical Informatics Association, Bethesda, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua M Temkin</author>
<author>Mark R Gilder</author>
</authors>
<title>Extraction of protein interaction information from unstructured text using a context-free grammar.</title>
<date>2003</date>
<journal>Bioinformatics,</journal>
<volume>19</volume>
<issue>16</issue>
<contexts>
<context position="1718" citStr="Temkin and Gilder (2003)" startWordPosition="245" endWordPosition="248">ionary of the parser. 1 Introduction The challenges of processing the vast amounts of biomedical publications available in databases such as MEDLINE have recently attracted a considerable interest in the Natural Language Processing (NLP) research community. The task of information extraction, commonly targeting entity relationships, such as proteinprotein interactions, is an often studied problem to which various NLP methods have been applied, ranging from keyword-based methods (see, e.g., Ginter et al. (2004)) to full syntactic analysis as employed, for example, by Craven and Kumlien (1999), Temkin and Gilder (2003) and Daraselia et al. (2004). In this paper, we focus on the syntactic analysis component of an information extraction system targeted to find protein-protein interactions from the dependency output produced by the Link Grammar&apos; (LG) parser of Sleator and Temperley (1991). Two recent papers study LG in the context of biomedical NLP. The work by Szolovits (2003) proposes a fully automated method to extend the dictionary of the LG 1http://www.link.cs.cmu.edu/link/ parser with the UMLS Specialiste lexicon, and Ding et al. (2003) perform a basic evaluation of LG performance on biomedical text. As </context>
</contexts>
<marker>Temkin, Gilder, 2003</marker>
<rawString>Joshua M. Temkin and Mark R. Gilder. 2003. Extraction of protein interaction information from unstructured text using a context-free grammar. Bioinformatics, 19(16):2046–2053.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>