<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000577">
<note confidence="0.9217732">
Methods and Practical Issues in Evaluating Alignment Techniques
Philippe Langlais
CTT/KTH SE-10044 Stockholm
CERI-LIA, AGROPARC BP 1228
F-84911 Avignon Cedex 9
</note>
<email confidence="0.723662">
Philippe.Langlais@speech.kth.se
</email>
<note confidence="0.906645">
Michel Simard
RALI-DIRO
Univ. de Montréal
Québec, Canada H3C 337
</note>
<email confidence="0.918298">
simardm@IRO.UMontreal.CA
</email>
<note confidence="0.9287835">
Jean Veronis
LPL, Univ. de Provence
29, Av. R. Schuman
F-13621 Aix-en-Provence Cedex 1
</note>
<email confidence="0.641878">
veronis@univ-aix.fr
</email>
<sectionHeader confidence="0.992661" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999953947368421">
This paper describes the work achieved in the
first half of a 4-year cooperative research project
(ARCADE), financed by AUPELF-UREF. The
project is devoted to the evaluation of paral-
lel text alignment techniques. In its first period
ARCADE ran a competition between six sys-
tems on a sentence-to-sentence alignment task
which yielded two main types of results. First,
a large reference bilingual corpus comprising of
texts of different genres was created, each pre-
senting various degrees of difficulty with respect
to the alignment task.
Second, significant methodological progress
was made both on the evaluation protocols and
metrics, and the algorithms used by the dif-
ferent systems. For the second phase, which is
now underway, ARCADE has been opened to
a larger number of teams who will tackle the
problem of word-level alignment.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999930965517242">
In the last few years, there has been a growing
interest in parallel text alignment techniques.
These techniques attempt to map various tex-
tual units to their translation and have proven
useful for a wide range of applications and tools.
A simple example of such a tool is probably
the TransSearch bilingual concordancing system
(Isabelle et al., 1993), which allows a user to
query a large archive of existing translations in
order to find ready-made solutions to specific
translation problems. Such a tool has proved ex-
tremely useful not only for translators, but also
for bilingual lexicographers (Langlois, 1996) and
terminologists (Dagan and Church, 1994). More
sophisticated applications based on alignment
technology have also been the object of recent
work, such as the automatic building of bilin-
gual lexical resources (Melamed, 1996; Klavans
and Tzoukermann, 1995), the automatic verifi-
cation of translations (Macklovitch, 1995), the
automatic dictation of translations (Brousseau
et al., 1995) and even interactive machine trans-
lation (Foster et al., 1997).
Enthusiasm for this relatively new field was
sparked early on by the apparent demonstra-
tion that very simple techniques could yield al-
most perfect results. For instance, to produce
sentence alignments, Brown et al. (1991) and
Gale and Church (1991) both proposed meth-
ods that completely ignored the lexical content
of the texts and both reported accuracy lev-
els exceeding 98%. Unfortunately performance
tends to deteriorate significantly when aligners
are applied to corpora which are widely differ-
ent from the training corpus, and/or where the
alignments are not straightforward. For instance
graphics, tables, &amp;quot;floating&amp;quot; notes and missing
segments, which are very common in real texts,
all result in a dramatic loss of efficiency.
The truth is that, while text alignment is
mostly an easy problem, especially when consid-
ered at the sentence level, there are situations
where even humans have a hard time making
the right decision. In fact, it could be argued
that, ultimately, text alignment is no easier than
the more general problem of natural language
understanding.
In addition, most research efforts were
directed towards the easiest problem, that of
sentence-to-sentence alignment (Brown et al.,
1991; Gale and Church, 1991; Debili, 1992;
Kay and Roscheisen, 1993; Simard et al., 1992;
Simard and Plamondon, 1996). Alignment at
the word and term level, which is extremely
useful for applications such as lexical resource
extraction, is still a largely unexplored research
area(Melamed, 1997).
In order to live up to the expectations of the
</bodyText>
<page confidence="0.995689">
711
</page>
<bodyText confidence="0.999922266666667">
various application fields, alignment technology
will therefore have to improve substantially.
As was the case with several other language
processing techniques (such as information
retrieval, document understanding or speech
recognition), it is likely that a systematic evalu-
ation will enable such improvements. However,
before the ARCADE project started, no for-
mal evaluation exercise was underway; and
worse still, there was no multilingual aligned
reference corpus to serve as a &amp;quot;gold standard&amp;quot;
(as the Brown corpus did, for example, for
part of speech tagging), nor any established
methodology for the evaluation of alignment
systems.
</bodyText>
<sectionHeader confidence="0.995801" genericHeader="introduction">
2 Organization
</sectionHeader>
<bodyText confidence="0.999268176470588">
ARCADE is an evaluation exercise financed
by AUPELF-UREF, a network of (at least
partially) French-speaking universities. It was
launched in 1995 to promote research in the
field of multilingual alignment. The first 2-year
period (96-97) was dedicated to two main
tasks: 1) producing a reference bilingual corpus
(French-English) aligned at sentence level; 2)
evaluating several sentence alignment systems
through an ARPA-like competition.
In the first phase of ARCADE, two types of
teams were involved in the project: the corpus
providers (LPL and RALI) and the (RALI, LO-
RIA, ISSCO, IRMC and LIA). General coor-
dination was handled by J. Veronis (LPL); a
discussion group was set up and moderated by
Ph. Langlais (LIA Sc KTH).
</bodyText>
<sectionHeader confidence="0.993188" genericHeader="method">
3 Reference corpus
</sectionHeader>
<bodyText confidence="0.999640090909091">
One of the main results of ARCADE has been
to produce an aligned French-English corpus,
combining texts of different genres and various
degrees of difficulty for the alignment task. It
is important to mention that until ARCADE,
most alignment systems had been tested on ju-
dicial and technical texts which present rela-
tively few difficulties for a sentence-level align-
ment. Therefore, diversity in the nature of the
texts was preferred to the collection of a large
quantity of similar data.
</bodyText>
<subsectionHeader confidence="0.988172">
3.1 Format
</subsectionHeader>
<bodyText confidence="0.999898">
ARCADE contributed to the development
and testing of the Corpus Encoding Standard
(CES), which was initiated during the MUL-
TEXT project (Ide et al., 1995). The CES is
based on SGML and it is an extension of the
now internationally-accepted recommendations
of the Text Encoding Initiative (Ide and
Veronis, 1995). Both the JOC and BAF parts
of the ARCADE corpus (described below) are
encoded in CES format.
</bodyText>
<subsectionHeader confidence="0.997528">
3.2 JOC
</subsectionHeader>
<bodyText confidence="0.999860214285714">
The JOC corpus contains texts which were pub-
lished in 1993 as a section of the C Series of the
Official Journal of the European Community in
all of its official languages. This corpus, which
was collected and prepared during the MLCC
and MULTEXT projects, contains, in 9 parallel
versions, questions asked by members of the Eu-
ropean Parliament on a variety of topics and the
corresponding answers from the European Com-
mission. JOC contains approximately 10 million
words (ca. 1.1 million words per language). The
part used for JOC was composed of one fifth
of the French and English sections (ca. 200 000
words per language).
</bodyText>
<subsectionHeader confidence="0.996896">
3.3 BAF
</subsectionHeader>
<bodyText confidence="0.999989666666667">
The BAF corpus is also a set of parallel French-
English texts of about 400 000 words per lan-
guage. It includes four text genres: 1) INST,
four institutional texts (including transcription
of speech from the Hansard corpus) for a total-
ing close to 300 000 words per language, 2) SCI-
ENCE, five scientific articles of about 50 000
words per language, 3) TECH, technical doc-
umentation of about 40 000 words per language
and 4) VERNE, the Jules Verne novel: &amp;quot;De
la terre a la lune&amp;quot; (ca. 50 000 words per lan-
guage). This last text is very interesting because
the translation of literary texts is much freer
than that of other types of tests. Furthermore,
the English version is slightly abridged, which
adds the problem of detecting missing segments.
The BAF corpus is described in greater detail
in (Simard, 1998).
</bodyText>
<sectionHeader confidence="0.996472" genericHeader="method">
4 Evaluation measures
</sectionHeader>
<bodyText confidence="0.9999764">
We first propose a formal definition of paral-
lel text alignment, as defined in (Isabelle and
Simard, 1996). Based on that definition, the
usual notions of recall and precision can be used
to evaluate the quality of a given alignment with
</bodyText>
<page confidence="0.984695">
712
</page>
<bodyText confidence="0.99998175">
respect to a reference. However, recall and preci-
sion can be computed for various levels of gran-
ularity: an alignment at a given level (e.g. sen-
tences) can be measured in terms of units of a
lower level (e.g. words, characters). Such a fine-
grained measure is less sensitive to segmenta-
tion problems, and can be used to weight errors
according to the number of sub-units they span.
</bodyText>
<subsectionHeader confidence="0.993272">
4.1 Formal definition
</subsectionHeader>
<bodyText confidence="0.962657523809524">
If we consider a text S and its translation T as
two sets of segments S = {.91, s2, sn} and T =
{ti,t2,...,t„,}, an alignment A between S and
T can be defined as a subset of the Cartesian
product p(S) x go(T), where p(S) and p(T) are
respectively the set of all subsets of S and T.
The triple (S, T, A) will be called a bit ext. Each
of the elements (ordered pairs) of the alignment
will be called a bisegment.
This definition is fairly general. However, in
the evaluation exercice described here, segments
were sentences and were supposed to be contigu-
ous, yielding monotonic alignments.
For instance, let us consider the fol-
lowing alignment, which will serve as the
reference alignment in the subsequent ex-
amples. The formal representation of it is:
Ar = {({s 1} , {t1}), ({s2}, {t2, t3})}.
81 Phrase numero un. t1 The first sentence.
82 Phrase numero deux t2 The 2nd sentence.
qui ressemble a la lere. t3 It looks like the first.
</bodyText>
<subsectionHeader confidence="0.996792">
4.2 Recall and precision
</subsectionHeader>
<bodyText confidence="0.993996764705882">
Let us consider a bitext (S,T,Ar) and a
proposed alignment A. The alignment recall
with respect to the reference A,. is defined
as: recall = IA n ArIllArl. It represents the
proportion of bisegments in A that are correct
with respect to the reference A,. The silence
corresponds to 1 — recall. The alignment
precision with respect to the reference A,.
is defined as: precision = IA n ArIllAl. It
represents the proportion of bisegments in A
that are right with respect to the number of
bisegment proposed. The noise corresponds to
1— precision.
We will also use the F-measure (Rijsbergen,
1979) which combines recall and precision in
a single efficiency measure (harmonic mean of
precision and recall):
</bodyText>
<equation confidence="0.9821405">
F = 2. (recall x precision)
(recall + precision).
</equation>
<bodyText confidence="0.977162411764706">
Let us assume the following proposed align-
ment:
81 Phrase numero un.
82 Phrase numero deux
qui ressemble a la lere.
The formal representation of this alignment
is: A =
We note that: A n Ar = {({•91}1{t1})}. Align-
ment recall and precision with respect to A,. are
1/2 = 0.50 and 1/3 = 0.33 respectively. The F-
measure is 0.40.
Improving both recall and precision are an-
tagonistic goals : efforts to improve one often
result in degrading the other. Depending on the
applications, different trade-offs can be sought.
For example, if the bisegments are used to auto-
matically generate a bilingual dictionary, maxi-
mizing precision (i.e. omitting doubtful couples)
is likely to be the preferred option.
Recall and precision as defined above are
rather unforgiving. They do not take into ac-
count the fact that some bisegments could be
partially correct. In the previous example, the
bisegment ({s2}, {t3}) does not belong to the
reference, but can be considered as partially cor-
rect: t3 does match a part of s2. To take partial
correctness into account, we need to compute re-
call and precision at the sentence level instead
of the alignment level.
Assuming the alignment A = {al, a2, ,a,,,}
and the reference AT = {ari, ar2, , arn}, with
= (ashati) and arj = (arsj,arti), we can
derive the following sentence-to-sentence align-
ments:
</bodyText>
<equation confidence="0.6704565">
A&apos; =Ui(asi x at)
= th(arsi x arti)
</equation>
<bodyText confidence="0.9980235">
Sentence-level recall and precision can thus
be defined in the following way:
</bodyText>
<equation confidence="0.9509305">
recall = n
precision = IA&apos; n Air1/1A11
</equation>
<bodyText confidence="0.999883333333333">
In the example above: A&apos; = {(sl,t1),(s2, t3)}
and A&apos;, = {(sl,t1),(s2,t2),(s2,t3)}. Sentence-
level recall and precision for this example are
</bodyText>
<table confidence="0.843117333333333">
t1 The first sentence.
t2 The 2nd sentence.
t3 It looks like the first.
</table>
<page confidence="0.995085">
713
</page>
<bodyText confidence="0.9998235">
therefore 2/3 = 0.66 and 1 respectively, as com-
pared to the alignment-level recall and preci-
sion, 0.50 and 0.33 respectively. The F-measure
becomes 0.80 instead of 0.40.
</bodyText>
<subsectionHeader confidence="0.990972">
4.3 Granularity
</subsectionHeader>
<bodyText confidence="0.998193916666667">
In the definitions above, the sentence is the unit
of granularity used for the computation of recall
and precision at both levels. This results in two
difficulties. First, the measures are very sensi-
tive to sentence segmentation errors. Secondly,
they do not reflect the seriousness of misalign-
ments. It seems reasonable that errors involving
short sentences should be less penalized than
errors involving longer ones, at least from the
perspective of some applications.
These problems can be avoided by taking ad-
vantage of the fact that a unit of a given gran-
ularity (e.g. sentence) can always be seen as
a (possibly discontinuous) sequence of units of
finer granularity (e.g. character).
Thus, when an alignment A is compared to
a reference alignment A, using the recall and
precision measures computed at the char-level,
the values obtained are inversely proportional to
the quantity of text (i.e. number of characters)
in the misaligned sentences, instead of the num-
ber of these misaligned sentences. For instance,
in the example used above, we would have at
sentence level:
</bodyText>
<listItem confidence="0.9753715">
• using word granularity (punctuation marks
are considered as words) :
</listItem>
<equation confidence="0.874229">
IA&apos; I = 4*4 + 0*4 + 9*6 = 106
lAr&apos;I = 4*4 + 9*10 = 70
lAr&apos; A&apos;l = 4*4 + 9*6 = 70
recall = 70/106 = 0.66
precision = 1
F = 0.80
</equation>
<listItem confidence="0.987838">
• using character granularity (excluding
spaces):
</listItem>
<construct confidence="0.554787333333333">
IA&apos; I = 15*17 + 0*15 + 36*20 = 975
IAr&apos; I = 15*17 + 36*35 = 1515
I Ar&apos; - A&apos; I = 15*17 + 36*20 = 975
recall = 975/1515 = 0.64
precision = 1
F = 0.78
</construct>
<sectionHeader confidence="0.96458" genericHeader="method">
5 Systems tested
</sectionHeader>
<bodyText confidence="0.999981653846154">
Six systems were tested, two of which having
been submitted by the RALI.
RALI/Jacal This system uses as a first step
a program that reduces the search space only to
those sentence pairs that are potentially inter-
esting (Simard and Plamondon, 1996). The un-
derlying principle is the automatic detection of
isolated cognates (i.e. for which no other similar
word exists in a window of given size). Once the
search space is reduced, the system aligns the
sentences using the well-known sentence-length
model described in (Gale and Church, 1991).
RALI/Salign The second method proposed
by BALI is based on a dynamic programming
scheme which uses a score function derived from
a translation model similar to that of (Brown
et al., 1990). The search space is reduced to a
beam of fixed width around the diagonal (which
would represent the alignment if the two texts
were perfectly synchronized).
LORIA The strategy adopted in this system
differs from that of the other systems since sen-
tence alignment is performed after the prelim-
inary alignment of larger units (whenever pos-
sible, using mark-up), such as paragraphs and
divisions, on the basis of the SGML structure.
A dynamic programming scheme is applied to
all alignment levels in successive steps.
IRMC This system involves a preliminary,
rough word alignment step which uses a trans-
fer dictionary and a measure of the proximity of
words (Debili et al., 1994). Sentence alignment
is then achieved by an algorithm which opti-
mizes several criteria such as word-order con-
servation and synchronization between the two
texts.
LIA Like Jacal, the LIA system uses a
pre-processing step involving cognate recog-
nition which restricts the search space, but
in a less restrictive way. Sentence alignment
is then achieved through dynamic program-
ming, using a score function which combines
sentence length, cognates, transfer dictionary
and frequency of translation schemes (1-1, 1-2,
etc.).
ISSCO Like the LORIA system, the ISSCO
aligner is sensitive to the macro-structure of
the document. It examines the tree structure
of an SGML document in a first pass, weighting
each node according to the number of charac-
ters contained within the subtree rooted at that
node. The second pass descends the tree, first
</bodyText>
<page confidence="0.995592">
714
</page>
<bodyText confidence="0.994993666666667">
by depth, then by breath, while aligning sen-
tences using a method resembling that of Gale
&amp; Church.
</bodyText>
<sectionHeader confidence="0.99982" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9973635">
Four sets of recall/precision measures were com-
puted for the alignments achieved by the six
systems for each text type previously described
above: Align, alignment-level, Sent sentence-
level, Word, word-level and Char, character-
level. The global efficiency of the different sys-
tems (average F-values) for each text type is
given in Figure 1.
</bodyText>
<table confidence="0.98712795">
: I I I I All. -0—
I 11 •
■ II: I 1 i %MI 1:1 -
. III I i
i 1:1 if I I TECH
1 1 1 I )kIPL : . SCIENCE
I , . • . .)F3----. I
HI • i i . • ! • • .—liela I
I I • i i ...•,...&apos; -
i &apos;&apos;&apos; 1)41:1
41111
,
I I ? • oci I
I - - — I .
Ii • i-4-4--r-
t 1 • ! • ! -!---)p ,e3 CYST
! i
i . VERNE
. . . .1 4.121
: .. - JOC
</table>
<figure confidence="0.474128">
! . •
• ..
711 N
</figure>
<figureCaption confidence="0.979061">
Figure 1: Global efficiency (average F-values for
</figureCaption>
<bodyText confidence="0.991209467741936">
Align, Sent, Word and Char measures) of the
different systems (Jacal, Salign, LORIA, IRMC,
ISSCO, LIA) , by text type (logarithmic scale).
First, note than the Char measures are higher
that the Align measures. This seems to con-
firm that systems tend to fail when dealing
with shorter sentences. In addition, the refer-
ence alignment for the BAF corpus combines
several 1-1 alignments in a single n-n align-
ment, for practical reasons owing to the sen-
tence segmentation process. This results in de-
creased Align measures.
The corpus on which all systems scored high-
est was the JOC. This corpus is relatively sim-
ple to align, since it contains 94% of 1-1 align-
ments, reflecting a translation strategy based
on speed and absolute fidelity. In addition, this
corpus contains a large amount of data that
remains unchanged during the translation pro-
cess (proper names, dates, etc.) and which can
serve as anchor points by some systems. Note
that the LORIA system achieves a slightly bet-
ter performance than the others on this cor-
pus, mainly because it is able to carry out a
structure-alignment since paragraphs and divi-
sions are explicitly marked.
The worst results were achieved on the
VERNE corpus. This is also the corpus for
which the results showed the most scattering
across systems (22% to 90% char-precision).
These poor results are linked to the literary
nature of the corpus, where translation is freer
and more interpretative. In addition, since the
English version is slightly abridged, the occa-
sional omissions result in de-synchronization
in most systems. Nevertheless, the LIA sys-
tem still achieves a satisfactory performance
(90% char-recall and 94% char-precision),
which can be explained by the efficiency of its
word-based pre-alignment step, as well as the
scoring function used to rank the candidate
bisegments.
Significant discrepancy are also noted be-
tween the Align and Char recalls on the TECH
corpus. This document contained a large
glossary as an appendix, and since the terms
are sorted in alphabetic order, they are ordered
differently in each language. This portion of
text was not manually aligned in the reference.
The size of this bisegment (250-250) drastically
lowers the Char-recall. Aligning two glossaries
can be seen as a document-structure alignment
task rather than a sentence-alignment task.
Since the goal of the evaluation was sentence
alignment, the TECH corpus results were not
taken into account in the final grading of the
systems.
The overall ranking for all systems (excluding
the TECH corpus results) is given in Figure 2,
in terms of the Sent and Char F-measures. The
LIA system obtains the best average results and
shows good stability across texts, which is an
</bodyText>
<figure confidence="0.992052325">
Lai
&amp;EV
LOICIA
/ILIAC
CISCO
UA
bed
34141
LORA
BOAC
ISSCO
UA
Loral
SAP
LORIA
MSC
ISSCO
UA
Jacal
Sap
LOW.
IRMC
ISSCO
LIA
Jowl
LORIA
IRMC
CISCO
UA
715
UM
95
PO
65
PO
75
70
65
60
LIA JACAL SALIGN LOMA ISSCO IRNIC
</figure>
<figureCaption confidence="0.992679">
Figure 2: Final ranking on the systems (average
F-values).
</figureCaption>
<bodyText confidence="0.973203">
important criterion for many applications.
</bodyText>
<sectionHeader confidence="0.991135" genericHeader="conclusions">
7 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999896529411765">
The ARCADE evaluation exercise has allowed
for significant methodological progress on paral-
lel text alignment. The discussions among par-
ticipants on the question of a testing proto-
col resulted in the definition of several evalu-
ation measures and an assessment of their rela-
tive merits. The comparative study of the sys-
tems performance also yielded a better under-
standing of the various techniques involved. As
a significant spin-off, the project has produced
a large aligned bilingual corpus, composed of
several types of texts, which can be used as a
gold standard for future evaluation. Grounded
on the experience gained in the first test cam-
paign, the second (1998-1999) has been opened
to more teams and plans to tackle more difficult
problems, such as word-level alignment. 1.
</bodyText>
<sectionHeader confidence="0.998138" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996695">
This work has been partially funded by
AUPELF-UREF. We are indebted to Lucie
Langlois and Elliott Macklovitch for their
fruitful comments on this paper.
</bodyText>
<sectionHeader confidence="0.999007" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999333322033898">
J. Brousseau, C. Drouin, G. Foster, P. Isabelle,
R. Kuhn, Y. Normandin, and P. Plamon-
don. 1995. French Speech Recognition in an
Automatic Dictation System for Translators:
the TransTalk Project. In Proceedings of Eu-
rospeech 95, Madrid, Spain.
&apos;For more information check the Web site at
http://www.lpl.univ-aix.fr/projects/arcade
P. F. Brown, J. Cocke, S. A. Della Pietro.,
V. J. Della Pietra, F. Jelinek, J. D. Lafferty,
R. L. Mercer, and P. S. Roosin. 1990. A Sta-
tistical Approach to Machine Translation. In
Computational Linguistics, volume 16, pages
79-85, June.
P.F. Brown, J.C. Lai, and R.L. Mercer. 1991.
Aligning Sentences in Parallel Corpora. In
29th Annual Meeting of the Association for
Computational Linguistics, pages 169-176,
Berkeley,CA,USA.
Ido Dagan and Kenneth W. Church. 1994. Ter-
might: Identifying and Translating Techni-
cal Terminology. In Proceedings of ANLP-94,
Stuttgart, Germany.
F. Debili, E. Sammouda, and A. Zribi. 1994. De
l&apos;appariement des mots a, la comparaison de
phrases. In 9eme Congres de Reconnaissance
des Formes et Intelligence Artificielle, Paris,
Janvier.
F. Debili. 1992. Aligning Sentences in Bilingual
Texts French - English and French - Arabic.
In COLING, pages 517-525, Nantes, 23-28
Aout.
George Foster, Pierre Isabelle, and Pierre Pla-
mondon. 1997. Target-Text Mediated Inter-
active Machine Translation. Machine Trans-
lation, 21(1-2).
W. A. Gale and Kenneth W. Church. 1991.
A Program for Aligning Sentences in Bilin-
gual Corpora. In 29th Annual Meeting of
the Association for Computational Linguis-
tics, Berkeley, CA.
N. Ide and J. Veronis, 1995. The Text Encod-
ing Initiative: background and context, chap-
ter 342p. Kluwer Academic Publishers, Dor-
drecht.
N. Ide, G. Priest-Dorman, and J. Veronis.
1995. Corpus encoding standard.
Report. Accessible on the World
Wide Web: http://www.lpl. univ-
aix.fr/projects/multext/CES/CES1.html.
Pierre Isabelle and Michel Simard.
1996. Propositions pour la
representation et l&apos;evaluation des
alignements de textes paralleles.
http://www-rali.iro.umontreal.ca/arc-a2/-
PropEval.
Pierre Isabelle, Marc Dymetman, George Fos-
ter, Jean-Marc Jutras, Elliott Macklovitch,
Francois Perrault, Xiaobo Ren, and Michel
</reference>
<page confidence="0.982122">
716
</page>
<reference confidence="0.999794372093023">
Simard. 1993. Translation Analysis and
Translation Automation. In Proceedings of
TMI-93, Kyoto, Japan.
M. Kay and M. R8scheisen. 1993. Text-
translation alignment. Computational Lin-
guistics, 19(1):121-142.
Judith Klavans and Evelyne Tzoukermann.
1995. Combining Corpus and Machine-
readable Dictionary Data for Building Bilin-
gual Lexicons. Machine Translation, 10(3).
Lucie Langlois. 1996. Bilingual Concordances:
A New Tool for Bilingual Lexicographers. In
Proceedings of AMTA-96, Montréal, Canada.
Elliott Macklovitc.h. 1995. 11-ansCheck — or
the Automatic Validation of Human Trans-
lations. In Proceedings of the MT Summit V,
Luxembourg.
I. Dan Melamed. 1996. Automatic Con-
struction of Clean Broad-coverage Transla-
tion Lexicons. In Proceedings of AMTA-96,
Montréal, Canada.
I. Dan Melamed. 1997. A portable algorithm
for mapping bitext correspondence. In 35th
Conference of the Association for Computa-
tional Linguistics, Madrid, Spain.
C.J. Van Rijsbergen. 1979. Information Re-
trieva1,2nd edition, London, Butterworths.
M. Simard and P. Plamondon. 1996. Bilingual
sentence alignment: Balancing robustness and
accuracy. In Proceedings of the Second Con-
ference of the Association for Machine Trans-
lation in the Americas (AMTA), Montréal,
Québec.
M. Simard, G.F. Foster, and P. Isabelle. 1992.
Using Cognates to Align Sentences in Bilin-
gual Corpora. In Fourth International Con-
ference on Theoretical and Methodological Is-
sues in Machine Translation (TMI), pages
67-81, Montréal, Canada.
M. Simard. 1998. The BAF: A corpus of
English-French Bitext. In First International
Conference on Language Resources and Eval-
uation, Granada, Spain.
</reference>
<page confidence="0.997168">
717
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.121330">
<title confidence="0.999775">Methods and Practical Issues in Evaluating Alignment Techniques</title>
<author confidence="0.952469">Philippe Langlais</author>
<affiliation confidence="0.647104">CTT/KTH SE-10044 Stockholm</affiliation>
<address confidence="0.6734335">CERI-LIA, AGROPARC BP 1228 F-84911 Avignon Cedex 9</address>
<title confidence="0.878542">Philippe.Langlais@speech.kth.se</title>
<author confidence="0.999972">Michel Simard</author>
<affiliation confidence="0.9823655">RALI-DIRO Univ. de Montréal</affiliation>
<address confidence="0.996794">Québec, Canada H3C 337</address>
<email confidence="0.891117">simardm@IRO.UMontreal.CA</email>
<author confidence="0.993443">Jean Veronis</author>
<affiliation confidence="0.8202">LPL, Univ. de Provence</affiliation>
<address confidence="0.666894">29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1</address>
<email confidence="0.889461">veronis@univ-aix.fr</email>
<abstract confidence="0.99935635">This paper describes the work achieved in the first half of a 4-year cooperative research project (ARCADE), financed by AUPELF-UREF. The project is devoted to the evaluation of parallel text alignment techniques. In its first period ARCADE ran a competition between six systems on a sentence-to-sentence alignment task which yielded two main types of results. First, a large reference bilingual corpus comprising of texts of different genres was created, each presenting various degrees of difficulty with respect to the alignment task. Second, significant methodological progress was made both on the evaluation protocols and metrics, and the algorithms used by the different systems. For the second phase, which is now underway, ARCADE has been opened to a larger number of teams who will tackle the problem of word-level alignment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Brousseau</author>
<author>C Drouin</author>
<author>G Foster</author>
<author>P Isabelle</author>
<author>R Kuhn</author>
<author>Y Normandin</author>
<author>P Plamondon</author>
</authors>
<title>French Speech Recognition in an Automatic Dictation System for Translators: the TransTalk Project.</title>
<date>1995</date>
<booktitle>In Proceedings of Eurospeech 95,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="2252" citStr="Brousseau et al., 1995" startWordPosition="332" endWordPosition="335">y a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance tends to deteriorate significantly when aligners are applied to corpora which are widely different from the training corpus, and/or </context>
</contexts>
<marker>Brousseau, Drouin, Foster, Isabelle, Kuhn, Normandin, Plamondon, 1995</marker>
<rawString>J. Brousseau, C. Drouin, G. Foster, P. Isabelle, R. Kuhn, Y. Normandin, and P. Plamondon. 1995. French Speech Recognition in an Automatic Dictation System for Translators: the TransTalk Project. In Proceedings of Eurospeech 95, Madrid, Spain.</rawString>
</citation>
<citation valid="false">
<title>For more information check the Web site at http://www.lpl.univ-aix.fr/projects/arcade</title>
<marker></marker>
<rawString>&apos;For more information check the Web site at http://www.lpl.univ-aix.fr/projects/arcade</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A Della Pietro</author>
<author>V J Della Pietra</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P S Roosin</author>
</authors>
<title>A Statistical Approach to Machine Translation.</title>
<date>1990</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>16</volume>
<pages>79--85</pages>
<contexts>
<context position="14103" citStr="Brown et al., 1990" startWordPosition="2331" endWordPosition="2334"> step a program that reduces the search space only to those sentence pairs that are potentially interesting (Simard and Plamondon, 1996). The underlying principle is the automatic detection of isolated cognates (i.e. for which no other similar word exists in a window of given size). Once the search space is reduced, the system aligns the sentences using the well-known sentence-length model described in (Gale and Church, 1991). RALI/Salign The second method proposed by BALI is based on a dynamic programming scheme which uses a score function derived from a translation model similar to that of (Brown et al., 1990). The search space is reduced to a beam of fixed width around the diagonal (which would represent the alignment if the two texts were perfectly synchronized). LORIA The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminary alignment of larger units (whenever possible, using mark-up), such as paragraphs and divisions, on the basis of the SGML structure. A dynamic programming scheme is applied to all alignment levels in successive steps. IRMC This system involves a preliminary, rough word alignment step which uses a tra</context>
</contexts>
<marker>Brown, Cocke, Pietro, Pietra, Jelinek, Lafferty, Mercer, Roosin, 1990</marker>
<rawString>P. F. Brown, J. Cocke, S. A. Della Pietro., V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roosin. 1990. A Statistical Approach to Machine Translation. In Computational Linguistics, volume 16, pages 79-85, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>169--176</pages>
<location>Berkeley,CA,USA.</location>
<contexts>
<context position="2538" citStr="Brown et al. (1991)" startWordPosition="377" endWordPosition="380">isticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance tends to deteriorate significantly when aligners are applied to corpora which are widely different from the training corpus, and/or where the alignments are not straightforward. For instance graphics, tables, &amp;quot;floating&amp;quot; notes and missing segments, which are very common in real texts, all result in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when consi</context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>P.F. Brown, J.C. Lai, and R.L. Mercer. 1991. Aligning Sentences in Parallel Corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 169-176, Berkeley,CA,USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
</authors>
<title>Termight: Identifying and Translating Technical Terminology.</title>
<date>1994</date>
<booktitle>In Proceedings of ANLP-94,</booktitle>
<location>Stuttgart, Germany.</location>
<contexts>
<context position="1908" citStr="Dagan and Church, 1994" startWordPosition="284" endWordPosition="287"> a growing interest in parallel text alignment techniques. These techniques attempt to map various textual units to their translation and have proven useful for a wide range of applications and tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence a</context>
</contexts>
<marker>Dagan, Church, 1994</marker>
<rawString>Ido Dagan and Kenneth W. Church. 1994. Termight: Identifying and Translating Technical Terminology. In Proceedings of ANLP-94, Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Debili</author>
<author>E Sammouda</author>
<author>A Zribi</author>
</authors>
<title>De l&apos;appariement des mots a, la comparaison de phrases.</title>
<date>1994</date>
<booktitle>In 9eme Congres de Reconnaissance des Formes et Intelligence Artificielle,</booktitle>
<location>Paris, Janvier.</location>
<contexts>
<context position="14781" citStr="Debili et al., 1994" startWordPosition="2443" endWordPosition="2446">und the diagonal (which would represent the alignment if the two texts were perfectly synchronized). LORIA The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminary alignment of larger units (whenever possible, using mark-up), such as paragraphs and divisions, on the basis of the SGML structure. A dynamic programming scheme is applied to all alignment levels in successive steps. IRMC This system involves a preliminary, rough word alignment step which uses a transfer dictionary and a measure of the proximity of words (Debili et al., 1994). Sentence alignment is then achieved by an algorithm which optimizes several criteria such as word-order conservation and synchronization between the two texts. LIA Like Jacal, the LIA system uses a pre-processing step involving cognate recognition which restricts the search space, but in a less restrictive way. Sentence alignment is then achieved through dynamic programming, using a score function which combines sentence length, cognates, transfer dictionary and frequency of translation schemes (1-1, 1-2, etc.). ISSCO Like the LORIA system, the ISSCO aligner is sensitive to the macro-structu</context>
</contexts>
<marker>Debili, Sammouda, Zribi, 1994</marker>
<rawString>F. Debili, E. Sammouda, and A. Zribi. 1994. De l&apos;appariement des mots a, la comparaison de phrases. In 9eme Congres de Reconnaissance des Formes et Intelligence Artificielle, Paris, Janvier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Debili</author>
</authors>
<title>Aligning Sentences in Bilingual Texts French - English and French - Arabic. In</title>
<date>1992</date>
<booktitle>COLING,</booktitle>
<pages>517--525</pages>
<location>Nantes,</location>
<contexts>
<context position="3562" citStr="Debili, 1992" startWordPosition="538" endWordPosition="539">missing segments, which are very common in real texts, all result in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when considered at the sentence level, there are situations where even humans have a hard time making the right decision. In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding. In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment (Brown et al., 1991; Gale and Church, 1991; Debili, 1992; Kay and Roscheisen, 1993; Simard et al., 1992; Simard and Plamondon, 1996). Alignment at the word and term level, which is extremely useful for applications such as lexical resource extraction, is still a largely unexplored research area(Melamed, 1997). In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially. As was the case with several other language processing techniques (such as information retrieval, document understanding or speech recognition), it is likely that a systematic evaluation will enable</context>
</contexts>
<marker>Debili, 1992</marker>
<rawString>F. Debili. 1992. Aligning Sentences in Bilingual Texts French - English and French - Arabic. In COLING, pages 517-525, Nantes, 23-28 Aout.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Pierre Isabelle</author>
<author>Pierre Plamondon</author>
</authors>
<date>1997</date>
<booktitle>Target-Text Mediated Interactive Machine Translation. Machine Translation,</booktitle>
<pages>21--1</pages>
<contexts>
<context position="2315" citStr="Foster et al., 1997" startWordPosition="342" endWordPosition="345">made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance tends to deteriorate significantly when aligners are applied to corpora which are widely different from the training corpus, and/or where the alignments are not straightforward. For instance grap</context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1997</marker>
<rawString>George Foster, Pierre Isabelle, and Pierre Plamondon. 1997. Target-Text Mediated Interactive Machine Translation. Machine Translation, 21(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Berkeley, CA.</location>
<contexts>
<context position="2565" citStr="Gale and Church (1991)" startWordPosition="382" endWordPosition="385">ased on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance tends to deteriorate significantly when aligners are applied to corpora which are widely different from the training corpus, and/or where the alignments are not straightforward. For instance graphics, tables, &amp;quot;floating&amp;quot; notes and missing segments, which are very common in real texts, all result in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when considered at the sentence level</context>
<context position="13913" citStr="Gale and Church, 1991" startWordPosition="2299" endWordPosition="2302">17 + 36*20 = 975 recall = 975/1515 = 0.64 precision = 1 F = 0.78 5 Systems tested Six systems were tested, two of which having been submitted by the RALI. RALI/Jacal This system uses as a first step a program that reduces the search space only to those sentence pairs that are potentially interesting (Simard and Plamondon, 1996). The underlying principle is the automatic detection of isolated cognates (i.e. for which no other similar word exists in a window of given size). Once the search space is reduced, the system aligns the sentences using the well-known sentence-length model described in (Gale and Church, 1991). RALI/Salign The second method proposed by BALI is based on a dynamic programming scheme which uses a score function derived from a translation model similar to that of (Brown et al., 1990). The search space is reduced to a beam of fixed width around the diagonal (which would represent the alignment if the two texts were perfectly synchronized). LORIA The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminary alignment of larger units (whenever possible, using mark-up), such as paragraphs and divisions, on the basis o</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W. A. Gale and Kenneth W. Church. 1991. A Program for Aligning Sentences in Bilingual Corpora. In 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J Veronis</author>
</authors>
<title>The Text Encoding Initiative: background and context, chapter 342p.</title>
<date>1995</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="6082" citStr="Ide and Veronis, 1995" startWordPosition="930" endWordPosition="933">portant to mention that until ARCADE, most alignment systems had been tested on judicial and technical texts which present relatively few difficulties for a sentence-level alignment. Therefore, diversity in the nature of the texts was preferred to the collection of a large quantity of similar data. 3.1 Format ARCADE contributed to the development and testing of the Corpus Encoding Standard (CES), which was initiated during the MULTEXT project (Ide et al., 1995). The CES is based on SGML and it is an extension of the now internationally-accepted recommendations of the Text Encoding Initiative (Ide and Veronis, 1995). Both the JOC and BAF parts of the ARCADE corpus (described below) are encoded in CES format. 3.2 JOC The JOC corpus contains texts which were published in 1993 as a section of the C Series of the Official Journal of the European Community in all of its official languages. This corpus, which was collected and prepared during the MLCC and MULTEXT projects, contains, in 9 parallel versions, questions asked by members of the European Parliament on a variety of topics and the corresponding answers from the European Commission. JOC contains approximately 10 million words (ca. 1.1 million words per</context>
</contexts>
<marker>Ide, Veronis, 1995</marker>
<rawString>N. Ide and J. Veronis, 1995. The Text Encoding Initiative: background and context, chapter 342p. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>G Priest-Dorman</author>
<author>J Veronis</author>
</authors>
<date>1995</date>
<note>Corpus encoding standard.</note>
<contexts>
<context position="5925" citStr="Ide et al., 1995" startWordPosition="905" endWordPosition="908">been to produce an aligned French-English corpus, combining texts of different genres and various degrees of difficulty for the alignment task. It is important to mention that until ARCADE, most alignment systems had been tested on judicial and technical texts which present relatively few difficulties for a sentence-level alignment. Therefore, diversity in the nature of the texts was preferred to the collection of a large quantity of similar data. 3.1 Format ARCADE contributed to the development and testing of the Corpus Encoding Standard (CES), which was initiated during the MULTEXT project (Ide et al., 1995). The CES is based on SGML and it is an extension of the now internationally-accepted recommendations of the Text Encoding Initiative (Ide and Veronis, 1995). Both the JOC and BAF parts of the ARCADE corpus (described below) are encoded in CES format. 3.2 JOC The JOC corpus contains texts which were published in 1993 as a section of the C Series of the Official Journal of the European Community in all of its official languages. This corpus, which was collected and prepared during the MLCC and MULTEXT projects, contains, in 9 parallel versions, questions asked by members of the European Parliam</context>
</contexts>
<marker>Ide, Priest-Dorman, Veronis, 1995</marker>
<rawString>N. Ide, G. Priest-Dorman, and J. Veronis. 1995. Corpus encoding standard.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Report</author>
</authors>
<title>Accessible on the World Wide Web:</title>
<note>http://www.lpl. univaix.fr/projects/multext/CES/CES1.html.</note>
<marker>Report, </marker>
<rawString>Report. Accessible on the World Wide Web: http://www.lpl. univaix.fr/projects/multext/CES/CES1.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
<author>Michel Simard</author>
</authors>
<title>Propositions pour la representation et l&apos;evaluation des alignements de textes paralleles.</title>
<date>1996</date>
<note>http://www-rali.iro.umontreal.ca/arc-a2/-PropEval.</note>
<contexts>
<context position="7756" citStr="Isabelle and Simard, 1996" startWordPosition="1221" endWordPosition="1224">of about 50 000 words per language, 3) TECH, technical documentation of about 40 000 words per language and 4) VERNE, the Jules Verne novel: &amp;quot;De la terre a la lune&amp;quot; (ca. 50 000 words per language). This last text is very interesting because the translation of literary texts is much freer than that of other types of tests. Furthermore, the English version is slightly abridged, which adds the problem of detecting missing segments. The BAF corpus is described in greater detail in (Simard, 1998). 4 Evaluation measures We first propose a formal definition of parallel text alignment, as defined in (Isabelle and Simard, 1996). Based on that definition, the usual notions of recall and precision can be used to evaluate the quality of a given alignment with 712 respect to a reference. However, recall and precision can be computed for various levels of granularity: an alignment at a given level (e.g. sentences) can be measured in terms of units of a lower level (e.g. words, characters). Such a finegrained measure is less sensitive to segmentation problems, and can be used to weight errors according to the number of sub-units they span. 4.1 Formal definition If we consider a text S and its translation T as two sets of </context>
</contexts>
<marker>Isabelle, Simard, 1996</marker>
<rawString>Pierre Isabelle and Michel Simard. 1996. Propositions pour la representation et l&apos;evaluation des alignements de textes paralleles. http://www-rali.iro.umontreal.ca/arc-a2/-PropEval.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Pierre Isabelle</author>
<author>Marc Dymetman</author>
<author>George Foster</author>
<author>Jean-Marc Jutras</author>
<author>Elliott Macklovitch</author>
<author>Francois Perrault</author>
</authors>
<title>Xiaobo Ren,</title>
<location>and Michel</location>
<marker>Isabelle, Dymetman, Foster, Jutras, Macklovitch, Perrault, </marker>
<rawString>Pierre Isabelle, Marc Dymetman, George Foster, Jean-Marc Jutras, Elliott Macklovitch, Francois Perrault, Xiaobo Ren, and Michel</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simard</author>
</authors>
<title>Translation Analysis and Translation Automation.</title>
<date>1993</date>
<booktitle>In Proceedings of TMI-93,</booktitle>
<location>Kyoto, Japan.</location>
<marker>Simard, 1993</marker>
<rawString>Simard. 1993. Translation Analysis and Translation Automation. In Proceedings of TMI-93, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M R8scheisen</author>
</authors>
<date>1993</date>
<booktitle>Texttranslation alignment. Computational Linguistics,</booktitle>
<pages>19--1</pages>
<marker>Kay, R8scheisen, 1993</marker>
<rawString>M. Kay and M. R8scheisen. 1993. Texttranslation alignment. Computational Linguistics, 19(1):121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Klavans</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>Combining Corpus and Machinereadable Dictionary Data for Building Bilingual Lexicons.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="2122" citStr="Klavans and Tzoukermann, 1995" startWordPosition="315" endWordPosition="318">le example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance te</context>
</contexts>
<marker>Klavans, Tzoukermann, 1995</marker>
<rawString>Judith Klavans and Evelyne Tzoukermann. 1995. Combining Corpus and Machinereadable Dictionary Data for Building Bilingual Lexicons. Machine Translation, 10(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucie Langlois</author>
</authors>
<title>Bilingual Concordances: A New Tool for Bilingual Lexicographers.</title>
<date>1996</date>
<booktitle>In Proceedings of AMTA-96,</booktitle>
<location>Montréal, Canada.</location>
<contexts>
<context position="1864" citStr="Langlois, 1996" startWordPosition="280" endWordPosition="281">n the last few years, there has been a growing interest in parallel text alignment techniques. These techniques attempt to map various textual units to their translation and have proven useful for a wide range of applications and tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect </context>
</contexts>
<marker>Langlois, 1996</marker>
<rawString>Lucie Langlois. 1996. Bilingual Concordances: A New Tool for Bilingual Lexicographers. In Proceedings of AMTA-96, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elliott Macklovitc h</author>
</authors>
<title>11-ansCheck — or the Automatic Validation of Human Translations.</title>
<date>1995</date>
<booktitle>In Proceedings of the MT Summit V,</booktitle>
<contexts>
<context position="2186" citStr="h, 1995" startWordPosition="325" endWordPosition="326">Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%. Unfortunately performance tends to deteriorate significantly when aligners are applied to co</context>
</contexts>
<marker>h, 1995</marker>
<rawString>Elliott Macklovitc.h. 1995. 11-ansCheck — or the Automatic Validation of Human Translations. In Proceedings of the MT Summit V, Luxembourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic Construction of Clean Broad-coverage Translation Lexicons.</title>
<date>1996</date>
<booktitle>In Proceedings of AMTA-96,</booktitle>
<location>Montréal, Canada.</location>
<contexts>
<context position="2090" citStr="Melamed, 1996" startWordPosition="313" endWordPosition="314">d tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 9</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>I. Dan Melamed. 1996. Automatic Construction of Clean Broad-coverage Translation Lexicons. In Proceedings of AMTA-96, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>A portable algorithm for mapping bitext correspondence.</title>
<date>1997</date>
<booktitle>In 35th Conference of the Association for Computational Linguistics,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="3816" citStr="Melamed, 1997" startWordPosition="576" endWordPosition="577">ans have a hard time making the right decision. In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding. In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment (Brown et al., 1991; Gale and Church, 1991; Debili, 1992; Kay and Roscheisen, 1993; Simard et al., 1992; Simard and Plamondon, 1996). Alignment at the word and term level, which is extremely useful for applications such as lexical resource extraction, is still a largely unexplored research area(Melamed, 1997). In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially. As was the case with several other language processing techniques (such as information retrieval, document understanding or speech recognition), it is likely that a systematic evaluation will enable such improvements. However, before the ARCADE project started, no formal evaluation exercise was underway; and worse still, there was no multilingual aligned reference corpus to serve as a &amp;quot;gold standard&amp;quot; (as the Brown corpus did, for example, for part </context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997. A portable algorithm for mapping bitext correspondence. In 35th Conference of the Association for Computational Linguistics, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Van Rijsbergen</author>
</authors>
<title>Information Retrieva1,2nd edition,</title>
<date>1979</date>
<booktitle>In Proceedings of the Second Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Montréal, Québec.</location>
<marker>Van Rijsbergen, 1979</marker>
<rawString>C.J. Van Rijsbergen. 1979. Information Retrieva1,2nd edition, London, Butterworths. M. Simard and P. Plamondon. 1996. Bilingual sentence alignment: Balancing robustness and accuracy. In Proceedings of the Second Conference of the Association for Machine Translation in the Americas (AMTA), Montréal, Québec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G F Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora.</title>
<date>1992</date>
<booktitle>In Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI),</booktitle>
<pages>67--81</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="3609" citStr="Simard et al., 1992" startWordPosition="544" endWordPosition="547">in real texts, all result in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when considered at the sentence level, there are situations where even humans have a hard time making the right decision. In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding. In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment (Brown et al., 1991; Gale and Church, 1991; Debili, 1992; Kay and Roscheisen, 1993; Simard et al., 1992; Simard and Plamondon, 1996). Alignment at the word and term level, which is extremely useful for applications such as lexical resource extraction, is still a largely unexplored research area(Melamed, 1997). In order to live up to the expectations of the 711 various application fields, alignment technology will therefore have to improve substantially. As was the case with several other language processing techniques (such as information retrieval, document understanding or speech recognition), it is likely that a systematic evaluation will enable such improvements. However, before the ARCADE </context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>M. Simard, G.F. Foster, and P. Isabelle. 1992. Using Cognates to Align Sentences in Bilingual Corpora. In Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI), pages 67-81, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
</authors>
<title>The BAF: A corpus of English-French Bitext.</title>
<date>1998</date>
<booktitle>In First International Conference on Language Resources and Evaluation,</booktitle>
<location>Granada,</location>
<contexts>
<context position="7626" citStr="Simard, 1998" startWordPosition="1202" endWordPosition="1203">ch from the Hansard corpus) for a totaling close to 300 000 words per language, 2) SCIENCE, five scientific articles of about 50 000 words per language, 3) TECH, technical documentation of about 40 000 words per language and 4) VERNE, the Jules Verne novel: &amp;quot;De la terre a la lune&amp;quot; (ca. 50 000 words per language). This last text is very interesting because the translation of literary texts is much freer than that of other types of tests. Furthermore, the English version is slightly abridged, which adds the problem of detecting missing segments. The BAF corpus is described in greater detail in (Simard, 1998). 4 Evaluation measures We first propose a formal definition of parallel text alignment, as defined in (Isabelle and Simard, 1996). Based on that definition, the usual notions of recall and precision can be used to evaluate the quality of a given alignment with 712 respect to a reference. However, recall and precision can be computed for various levels of granularity: an alignment at a given level (e.g. sentences) can be measured in terms of units of a lower level (e.g. words, characters). Such a finegrained measure is less sensitive to segmentation problems, and can be used to weight errors a</context>
</contexts>
<marker>Simard, 1998</marker>
<rawString>M. Simard. 1998. The BAF: A corpus of English-French Bitext. In First International Conference on Language Resources and Evaluation, Granada, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>