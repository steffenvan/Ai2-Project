<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.990954">
Automatic Semantic Role Assignment for a Tree Structure
</title>
<author confidence="0.997484">
Jia-Ming You Keh-Jiann Chen
</author>
<affiliation confidence="0.8573145">
Institute of Information Science Institute of Information Science
Academia Sinica Academia Sinica
</affiliation>
<email confidence="0.942734">
swimming@hp.iis.sinica.edu.tw Kchen@iis.sinica.edu.tw
</email>
<sectionHeader confidence="0.991357" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999993238095238">
We present an automatic semantic roles labeling
system for structured trees of Chinese sentences. It
adopts dependency decision making and
example-based approaches. The training data and
extracted examples are from the Sinica Treebank,
which is a Chinese Treebank with semantic role
assigned for each constituent. It used 74 abstract
semantic roles including thematic roles, such as
‘agent’; ‘theme’, ‘instrument’, and secondary roles of
‘location’, ‘time’, ‘manner’ and roles for nominal
modifiers. The design of role assignment algorithm is
based on the different decision features, such as
head-argument/modifier, case makers, sentence
structures etc. It labels semantic roles of parsed
sentences. Therefore the practical performance of the
system depends on a good parser which labels the
right structures of sentences. The system achieves
92.71% accuracy in labeling the semantic roles for
pre-structure- bracketed texts which is considerably
higher than the simple method using probabilistic
model of head-modifier relations.
</bodyText>
<sectionHeader confidence="0.996136" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999847551724138">
For natural language understanding, the process of
fine-grain semantic role assignment is one of the
prominent steps, which provides semantic relations
between constituents. The sense and sense relations
between constituents are core meaning of a sentence.
Conventionally there are two kinds of methods
for role assignments, one is using only statistical
information (Gildea and Jurafsky, 2002) and the
other is combining with grammar rules (Gildea and
Hockenmaier, 2003). However using only grammar
rules to assign semantic roles could lead to low
coverage. On the other hand, performance of
statistical methods relies on significant dependent
features. Data driven is a suitable strategy for
semantic roles assignments of general texts. We use
the Sinica Treebank as information resource because
of its various domains texts including politics,
society, literature...etc and it is a Chinese Treebank
with semantic role assigned for each constituent
(Chen etc., 2003). It used 74 abstract semantic roles
including thematic roles, such as ‘agent’; ‘theme’,
‘instrument’, and secondary roles of ‘location’,
‘time’, ‘manner’ and modifiers of nouns, such as
‘quantifier’, ‘predication’, ‘possessor’, etc. The
design of role assignment algorithm is based on
the different decision features, such as
head-argument/modifier, case makers, sentence
structures etc. It labels semantic roles of parsed
sentences by example-based probabilistic models.
</bodyText>
<subsectionHeader confidence="0.991863">
1.1 Sinica Treebank
</subsectionHeader>
<bodyText confidence="0.999911052631579">
The Sinica Treebank has been developed and
released to public since 2000 by Chinese
Knowledge Information Processing (CKIP) group
at Academia Sinica. The Sinica Treebank version
2.0 contains 38944 structural trees and 240,979
words in Chinese. Each structural tree is annotated
with words, part-of-speech of words, syntactic
structure brackets, and semantic roles. For
conventional structural trees, only syntactic
information was annotated. However, it is very
important and yet difficult for Chinese to identify
word relations with purely syntactic constraints
(Xia et al., 2000). Thus, partial semantic
information, i.e. semantic role for each constituent,
was annotated in Chinese structural trees. The
grammatical constraints are expressed in terms of
linear order of semantic roles and their syntactic
and semantic restrictions. Below is an example
sentence of the Sinica Treebank.
</bodyText>
<equation confidence="0.616986666666667">
Original sentence:
他 ‘Ta’要 ‘yao’ 張三 ‘ZhangSan’撿 ‘jian’ 球
‘qiu’。
He ask Zhang San to pick up the ball.
Parsed tree:
S(agent:NP(Head:Nhaa:他’He’)|Head:VF2:要’ask’
|goal:NP(Head:Nba:張三’Zhang San’)
|theme:VP(Head:VC2:撿’pick’|goal:NP(Head:Nab:球
&apos;’ball’)))
</equation>
<figureCaption confidence="0.998454">
Figure 1: An example sentence of Sinica Treebank
</figureCaption>
<bodyText confidence="0.999909222222222">
In the Sinica Treebank, not only the semantic
relations of a verbal predicate but also the
modifier head relations were marked. There are 74
different semantic roles, i.e. the task of semantic
role assignment has to establish the semantic
relations among phrasal heads and their
arguments/modifiers within 74 different choices.
The set of semantic roles used in the Sinica Treebank
is listed in the appendix.
</bodyText>
<sectionHeader confidence="0.9392115" genericHeader="method">
2. Example-based Probabilistic Models for
Assigning Semantic Roles
</sectionHeader>
<bodyText confidence="0.9999598">
The idea of example-based approaches is that
semantic roles are preserved for the same event
frames. For a target sentence, if we can find same
examples in the training corpus, we can assign the
same semantic role for each constituent of the target
sentence as the examples. However reoccurrence of
exact same surface structures for a sentence is very
rare, i.e. the probability of finding same example
sentences in a corpus is very low. In fact, by
observing structures of parsed trees, we find that
most of semantic roles are uniquely determined by
semantic relations between phrasal heads and their
arguments/modifiers and semantic relations are
determined by syntactic category, semantic class of
related words. For example:
</bodyText>
<equation confidence="0.920457222222222">
Original sentence:
我們 ‘wo men’ 都 ‘du’ 喜歡 ‘xi huan’ 蝴蝶 ‘hu
die’。
We all like butterflies.
Parsed tree:
S(experiencer:NP(Head:Nhaa:我們
‘we ’ )Jquantity:Dab:都 ‘all’ JHead:VK1:喜歡 ‘like’
Jgoal:NP(Head:Nab:蝴蝶 ‘butterflies’))。
S
</equation>
<table confidence="0.769221">
experiencer
NP
Head quantity Head Head
Nhaa Dab VK1 Nab
Rim a 喜 歡 蝴 蝶
We all like Butterflies.
</table>
<figureCaption confidence="0.998924">
Figure 2: The illustration of the parsed tree.
</figureCaption>
<bodyText confidence="0.999720571428571">
In Figure2, 喜歡 ‘like’ is the sentential head; 我
們 ‘we’ and 蝴蝶 ‘butterflies’ are the arguments;
都 ‘all’ is the modifier. As a result, the semantic role
‘experiencer’ of 我們 ‘we’ is deduced from the
relation between 我們 ‘we’ and 喜歡 ‘like’, since
the event frame of 喜歡 ‘like’ has the two arguments
of experiencer and goal and the experiencer usually
takes the subject position. The semantic roles of 蝴
蝶 ‘butterflies’ and 都 ‘all’ are assigned by the
same way. For the task of automatic role
assignment, once phrase boundaries and phrasal
head are known, the semantic relations will be
resolved by looking for similar
head-argument/modifier pairs in training data.
</bodyText>
<subsectionHeader confidence="0.989715">
2.1 Example Exaction
</subsectionHeader>
<bodyText confidence="0.989035586206897">
To extract head-argument/modifier examples
from the Sinica Treebank is trivial, since phrase
boundaries and semantic roles, including phrasal
head, are labeled. The extracted examples are
pairs of head word and target word. The target
word is represented by the head of the
argument/modifier, since the semantic relations
are established between the phrasal head and the
head of argument/modifier phrase. An extracted
word pair includes the following features.
Target word:
The head word of argument/modifier.
Target POS:
The part-of-speech of the target word.
Target semantic role:
Semantic role of the constituent contains the
target word as phrasal head.
Head word:
The phrasal head.
Head POS:
The part-of-speech of the head word.
Phrase type:
The phrase which contains the head word and
the constituent containing target word.
Position:
Shows whether target word appears before or
after head word.
The examples we extracted from Figure 2 are
listed below.
</bodyText>
<tableCaption confidence="0.9813895">
Table 1: The three head-argument/modifier pairs
extracted from Figure 2.
</tableCaption>
<table confidence="0.6633015">
goal
NP
</table>
<tableCaption confidence="0.991827">
Table 2: Coverage and accuracy of different features combinations
</tableCaption>
<subsectionHeader confidence="0.936208">
2.2 Probabilistic Model for Semantic Role
Assignment
</subsectionHeader>
<bodyText confidence="0.9998775">
It is possible that conflicting examples (or
ambiguous role assignments) occur in the training
data. We like to assign the most probable roles. The
probability of each semantic role in a constituent
with different features combinations are estimated
from extract examples.
</bodyText>
<equation confidence="0.841531571428571">
P r constituent
(  |)
1
h, h_pos, t, t_pos, pt, position )
# (r, h, h_pos, t, t_pos, pt, position)
=
h, h_pos, t, t_pos, pt, position)
</equation>
<bodyText confidence="0.999823266666667">
Due to the sparseness of the training data, it’s not
possible to have example feature combinations
matched all input cases. Therefore the similar
examples will be matched. A back off process will
be carried out to reduce feature constraints during
the example matching. We will evaluate
performances for various features combinations to
see which features combinations are best suited for
semantic roles assignments.
We choose four different feature combinations.
Each has relatively high accuracy. The four
classifiers will be back off in sequence. If none of
the four classifiers is applicable, a baseline model
of assigning the most common semantic role of
target word is applied.
</bodyText>
<figure confidence="0.442397">
if # of (h,h_pos,t,t_pos,pt,position) &gt; threshold
P(r|constituent)=P(r|h,h_pos,t,t_pos,pt,position)
Else
if # of (h_pos,t,t_pos,pt,position) &gt; threshold
P(r|constituent)=P(r|h_pos,t,t_pos,pt,position)
Else
</figure>
<figureCaption confidence="0.308627">
1 r: semantic role; h: the head word;
h_pos: part-of-speech of head word;
t: the target word;
t_pos: part-of-speech of target word;
pt: the phrase type.
</figureCaption>
<figure confidence="0.64943175">
if # of (h,h_pos,t_pos,pt,position) &gt; threshold
P(r|constituent)=P(r|h,h_pos,t_pos,pt,position)
Else
if # of (h_pos,t_pos,pt,position) &gt; threshold
P(r|constituent)=P(r|h_pos,t_pos,pt,position)
Else
Baseline model:
P(r|constituent)=P(r |t, t_pos,pt)
</figure>
<sectionHeader confidence="0.920845" genericHeader="evaluation">
3. Experiments
</sectionHeader>
<bodyText confidence="0.9993506">
We adopt the Sinica Treebank as both training
and testing data. It contains about 40,000 parsed
sentences. We use 35,000 sentences as training data
and the rest 5,000 as testing data. The table 2 shows
the coverage of each classifier, their accuracies, and
performance of each individual classifier without
back off process. The table 3 shows combined
performance of the four classifiers after back off
processes in sequence. The baseline algorithm is the
simple unigram approach to assign the most
common role for the target word. Because the
accuracy of the four classifiers is considerably high,
instead of using linear probability combinations we
will rather use the most reliable classifier for each
different features combination.
</bodyText>
<table confidence="0.986306333333333">
Method Accuracy
Backoff 90.29%
Baseline: 68.68%
</table>
<tableCaption confidence="0.838086">
Table 3: The accuracy of our backoff method and
the base line (the most common semantic roles)
</tableCaption>
<subsectionHeader confidence="0.793755">
3.1 Error Analyses
</subsectionHeader>
<bodyText confidence="0.9999365">
Although the accuracy of back off model is
relatively high to the baseline model, it still has
quite a room for improvement. After analyzed the
errors, we draw following conclusions.
</bodyText>
<equation confidence="0.861694142857143">
|
= P
r
(
(
#
a) Semantic head vs. syntactic head we should inspect the existence of passive voice
</equation>
<bodyText confidence="0.994107923076923">
and then reverse the roles of subject and object.
A semantic role for a prepositional phrase (PP) is
mainly determined by the syntactic head of PP, i.e.
preposition, and the semantic head of PP, i.e. the
head word of the DUMMY-argument of PP. For
example, in Figure 3, the two sentences are almost
the same, only the contents of PP are different.
Obviously, the semantic roles of PP (在 ‘in’ 印尼
‘Indonesia’) is location, and the semantic role of PP
(在 ‘in’ 今年 ‘this year’) is time. Therefore the
semantic roles of the two PPs should be determined
only within the scope of PP and not relevant to
matrix verb.
</bodyText>
<figure confidence="0.995878666666667">
S
S
goal theme
PP
Dummy
NP NP
Head evaluation Head Head Head
Nab Dbb P02 Nad VJ1
蝴蝶 也 被 歌聲 吸引
</figure>
<figureCaption confidence="0.957836">
Butterflies are also be attracted by the voice.
Figure 4: A parsed tree of passive sentence “蝴蝶也
</figureCaption>
<figure confidence="0.936670866666667">
被歌聲吸引”
4 Refined Models
location
PP
agent Dummy
NP NP
Head Head Head manner Head
Nca P21 Nca Dh VC31
台北 在 印尼 加速 投資
Taipei speed-up the investments in Indonesia.
S
time
PP
台北 在 今年 加速 投資
Taipei speed-up the investments this year.
</figure>
<figureCaption confidence="0.774254666666667">
Figure 3: Parsed trees of “台北在印尼加速投資”
and “台北在今年加速投資”
b) Structure-dependent semantic roles assignments
</figureCaption>
<bodyText confidence="0.9983667">
Complex structures are always the hardest part of
semantic roles assignments. For example, the
sentences with passive voice are the typical
complex structures. In Figure 4, the semantic role
of 蝴蝶 ‘Butterflies’ is not solely determined by
the head verb 吸引 ‘attracted’ and itself. Instead
Chen &amp; Huang (1996) had studied the task of
semantic assignment during Chinese sentence
parsing. They concluded that semantic roles are
determined by the following 4 parameters.
</bodyText>
<listItem confidence="0.992595714285714">
1. Syntactic and semantic categories of the target
word,
2. Case markers, i.e. prepositions and
postpositions
3. Phrasal head, and
4. Sub-categorization frame and its syntactic
patterns.
</listItem>
<bodyText confidence="0.999924090909091">
Therefore head-modifier/argument examples
only resolve most of semantic role assignments.
Some of complex cases need other parameters to
determine their semantic roles. For instance, the
argument roles of Bei sentences (passive sentence)
should be determined by all four parameters.
The refined model contain two parts, one is the
refinements of features data which provide more
precisely information and the other is the
improvements of back off process to deal with
special semantic roles assignments.
</bodyText>
<subsectionHeader confidence="0.999786">
4.1 Refinement of Features Extractions
</subsectionHeader>
<bodyText confidence="0.998291333333333">
The refinements of features extractions focus on
two different cases, one is the features extractions
of case-marked structures, such as PP and GP
(postpositional phrases), and the other is the general
semantic class identifications of synonyms.
The features of PP/GP include two different
</bodyText>
<figure confidence="0.989241285714286">
agent
NP
Head
Nca
Head
P21
Dummy
NP
Head
Nca
manner
Dh
Head
VC31
</figure>
<tableCaption confidence="0.954786">
Table 4: The internal/external relations of Figure 5.
</tableCaption>
<bodyText confidence="0.99994775">
feature types: the internal and the external features.
The internal features of phrases compose of phrasal
head and Dummy-head; the external features are
heads (main verbs) of the target phrases.
</bodyText>
<note confidence="0.617518">
aIL IE Mfg MA &amp;*
</note>
<figureCaption confidence="0.850968666666667">
Taipei speed-up the investments in Indonesia.
Figure 5: A parsed tree for demonstrating features
extractions of PP
</figureCaption>
<bodyText confidence="0.9997391875">
The semantic class identifications of synonyms
are crucial for solving data sparseness problems.
Some type of words are very productive, such as
numbers, DM (determinative measurement), proper
names. They need to be classified into different
semantic classes. We use some tricks to classify
them into specific word classes. For example we
label 1 公 斤 ‘one kilogram’, 2 公 斤 ‘two
kilograms’ as their canonical form 某公 斤 ‘n
kilograms’; 第一天 ‘the first day’, 第二天 ‘the
second day ‘ as 第 某 天 ‘the nth days’; 張
三 ’Zhang San’, 李 四 ‘Li Si’ as a personal
name...etc. With this method, we can increase the
number of matched examples and resolve the
problem of occurrences of unknown words in a
large scale.
</bodyText>
<subsectionHeader confidence="0.9940905">
4.2 Dependency Decisions and Refined Back
off Processes
</subsectionHeader>
<bodyText confidence="0.999965666666667">
The refined back off model aimed to solve
semantic roles assignments for certain special
structures. Using only head-modifier features could
result into decision making with insufficient
information. As illustrated before, the semantic role
of 蝴蝶 ‘butterflies’ in Figure 4 is ‘agent’ observed
from the head-argument feature. But in fact the
feature of passive voice 被 ‘passive’ tells us that
the subject role of 蝴蝶 ‘butterflies’ should be the
semantic role ‘goal’ instead of the usual role of
‘agent’.
Therefore we enhanced our back off process by
adding some dependency decisions. The
dependency conditions include special grammar
usage like passive form, quotation, topical
sentences... etc. In the refined back off process,
first we have to detect which dependency condition
is happened and resolved it by using dependency
features. For example, if the feature word 被
‘passive’ occurs in a sentence, we realize that the
subjective priority of semantic roles should be
reversed. For instance, ‘goal’ will take subject
position instead of ‘agent’ (‘goal’ appears before
‘agent’).
</bodyText>
<subsectionHeader confidence="0.995759">
4.3 Experiment Results
</subsectionHeader>
<bodyText confidence="0.999659818181818">
The experiments were carried out for the refined
back off model with the same set of training data
and testing data as in the previous experiments.
Table 5 shows that the refined back off model gains
2.4 % accuracy rate than the original back off
model. However most of the improvement is due to
the refinements of features extractions and
canonical representation for certain classes of words.
A few improvements were contributed to the
decision making on the cases of structure
dependency.
</bodyText>
<table confidence="0.9960285">
Method Accuracy
Refined Backoff 92.71%
Backoff 90.29%
Baseline 68.68%
</table>
<tableCaption confidence="0.967569">
Table 5: Role assignment accuracies of refined
backoff, backoff, and baseline models.
</tableCaption>
<sectionHeader confidence="0.990748" genericHeader="conclusions">
5 Conclusion and Future Works
</sectionHeader>
<bodyText confidence="0.9967975">
Semantic roles are determined by the following 4
parameters.
</bodyText>
<listItem confidence="0.987955714285714">
1. Syntactic and semantic categories of the target
word,
2. Case markers, i.e. prepositions and
postpositions,
3. Phrasal head, and
4. Sub-categorization frame and its syntactic
patterns.
</listItem>
<figure confidence="0.981205333333333">
agent Dummy
NP NP
Head Head Head manner
Nca P21 Nca Dh
location
PP
S
Head
VC31
</figure>
<bodyText confidence="0.999553448275862">
We present an automatic semantic roles labeling
system. It adopts dependency decision making and
example-based approaches, which makes decision
on the amount of parameters by observing the
occurrence of dependency features and to utilize the
minimal amount of feature combinations to assign
semantic roles. It labels semantic roles of parsed
sentences. Therefore the practical performance of
the system depends on a good parser which labels
the right structures of sentences. The system
achieves 92.71% accuracy in labeling the semantic
roles for pre-structure- bracketed texts which is
considerably higher than the simple method using
probabilistic model of head-modifier relations.
In the future, we will consider fine-grain semantic
role assignment problems. The current semantic
roles assignment is focus on one sentence. However,
the occurrences of frame elements are not limited to
a single sentence. For instance, “John bought the
books from Mary”. The semantic roles of ‘John’
and ‘Mary’ are agent and theme respectively.
According to Fillmore’s FrameNet, the frame
element assignment for the above sentence should
be ‘John’ the buyer, ‘Mary’ the seller, ‘the books’
the goods. The precondition of buy-frame says that
the seller should be the owner of the goods.
Therefore after the sentence parsing and logical
reasoning, the following semantic relations should
be established.
</bodyText>
<reference confidence="0.961623090909091">
Event frame: Commerce-buy
Buyer: John
Seller: Mary
Goods: books
Additional frame: Own
Before the buy event
Owner: Mary
Possession: books
After the buy event
Owner: John
Possession: books
</reference>
<bodyText confidence="0.99957125">
The semantic roles assignment is a process of
crossing phrasal and sentential boundaries. Some
semantic roles of an event might occur at left or
right context. Therefore we have to analyze the
relation between two consecutive events. The
relations include causal relation, temporal relation,
resultant relation, etc. How to resolve the above
problems will be our future studies.
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.978707846153846">
Chen, Keh-Jiann, Chu-Ren Huang. 1996.
Information-based Case Grammar: A
Unification-based Formalism for Parsing Chinese.
Journal of Chinese Linguistics Monograph Series
No. 9.
Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen,
Chi-Ching Luo,Ming-Chung Chang, Chao-Jan Chen,
and Zhao-Ming Gao, 2003. Sinica Treebank: Design
Criteria, Representational Issues and
Implementation. In Anne Abeille (Ed.) Treebanks
Building and Using Parsed Corpora. Language and
Speech series. Dordrecht:Kluwer, pp231-248.
Chu-Ren Huang, Keh-Jiann Chen, and Benjamin K.
T’sou Eds. Readings in Chinese Natural Language
Processing. 23-45. Berkeley: JCL.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
Labeling of Semantic Roles. Computational
Linguistics, 28(3):245-288
Daniel Gildea and Julia Hockenmaier. 2003. Identifying
Semantic Roles Using Combinatory Categorial
Grammar. Conference on Empirical Methods in
Natural Language Processing (EMNLP).
Xia, Fei, 2000, The Part-of-Speech Tagging Guidelines
for the Penn Chinese Treebank (3.0). IRCS Report
00-07. Philadelphia, PA: University of Pennsylvania.
Appendix:
</reference>
<figureCaption confidence="0.997989">
Figure 6: The detail classification of semantic roles in the Sinica Treebank
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.496956">
<title confidence="0.999408">Automatic Semantic Role Assignment for a Tree Structure</title>
<author confidence="0.996421">Jia-Ming You Keh-Jiann Chen</author>
<affiliation confidence="0.999132">Institute of Information Science Institute of Information Science</affiliation>
<author confidence="0.512735">Academia Sinica Academia Sinica</author>
<email confidence="0.968072">swimming@hp.iis.sinica.edu.twKchen@iis.sinica.edu.tw</email>
<abstract confidence="0.999727954545455">We present an automatic semantic roles labeling system for structured trees of Chinese sentences. It adopts dependency decision making and example-based approaches. The training data and extracted examples are from the Sinica Treebank, which is a Chinese Treebank with semantic role assigned for each constituent. It used 74 abstract semantic roles including thematic roles, such as and secondary roles of roles for nominal modifiers. The design of role assignment algorithm is based on the different decision features, such as head-argument/modifier, case makers, sentence structures etc. It labels semantic roles of parsed sentences. Therefore the practical performance of the system depends on a good parser which labels the right structures of sentences. The system achieves 92.71% accuracy in labeling the semantic roles for pre-structurebracketed texts which is considerably higher than the simple method using probabilistic model of head-modifier relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Event frame</author>
</authors>
<title>Commerce-buy Buyer: John Seller: Mary Goods: books Additional frame: Own Before the buy event Owner: Mary Possession: books After the buy event Owner:</title>
<publisher>John</publisher>
<marker>frame, </marker>
<rawString>Event frame: Commerce-buy Buyer: John Seller: Mary Goods: books Additional frame: Own Before the buy event Owner: Mary Possession: books After the buy event Owner: John</rawString>
</citation>
<citation valid="false">
<note>Possession: books</note>
<marker></marker>
<rawString>Possession: books</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
<author>Chu-Ren Huang</author>
</authors>
<title>Information-based Case Grammar: A Unification-based Formalism for Parsing Chinese.</title>
<date>1996</date>
<journal>Journal of Chinese Linguistics Monograph Series</journal>
<volume>9</volume>
<contexts>
<context position="11680" citStr="Chen &amp; Huang (1996)" startWordPosition="1764" endWordPosition="1767">els location PP agent Dummy NP NP Head Head Head manner Head Nca P21 Nca Dh VC31 台北 在 印尼 加速 投資 Taipei speed-up the investments in Indonesia. S time PP 台北 在 今年 加速 投資 Taipei speed-up the investments this year. Figure 3: Parsed trees of “台北在印尼加速投資” and “台北在今年加速投資” b) Structure-dependent semantic roles assignments Complex structures are always the hardest part of semantic roles assignments. For example, the sentences with passive voice are the typical complex structures. In Figure 4, the semantic role of 蝴蝶 ‘Butterflies’ is not solely determined by the head verb 吸引 ‘attracted’ and itself. Instead Chen &amp; Huang (1996) had studied the task of semantic assignment during Chinese sentence parsing. They concluded that semantic roles are determined by the following 4 parameters. 1. Syntactic and semantic categories of the target word, 2. Case markers, i.e. prepositions and postpositions 3. Phrasal head, and 4. Sub-categorization frame and its syntactic patterns. Therefore head-modifier/argument examples only resolve most of semantic role assignments. Some of complex cases need other parameters to determine their semantic roles. For instance, the argument roles of Bei sentences (passive sentence) should be determ</context>
</contexts>
<marker>Chen, Huang, 1996</marker>
<rawString>Chen, Keh-Jiann, Chu-Ren Huang. 1996. Information-based Case Grammar: A Unification-based Formalism for Parsing Chinese. Journal of Chinese Linguistics Monograph Series No. 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
<author>Chu-Ren Huang</author>
<author>Feng-Yi Chen</author>
</authors>
<title>Chi-Ching Luo,Ming-Chung Chang, Chao-Jan Chen, and Zhao-Ming Gao,</title>
<date>2003</date>
<journal>Dordrecht:Kluwer,</journal>
<pages>231--248</pages>
<marker>Chen, Huang, Chen, 2003</marker>
<rawString>Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, Chi-Ching Luo,Ming-Chung Chang, Chao-Jan Chen, and Zhao-Ming Gao, 2003. Sinica Treebank: Design Criteria, Representational Issues and Implementation. In Anne Abeille (Ed.) Treebanks Building and Using Parsed Corpora. Language and Speech series. Dordrecht:Kluwer, pp231-248.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chu-Ren Huang</author>
<author>Keh-Jiann Chen</author>
<author>K Benjamin</author>
</authors>
<title>T’sou Eds.</title>
<booktitle>Readings in Chinese Natural Language Processing.</booktitle>
<pages>23--45</pages>
<publisher>JCL.</publisher>
<location>Berkeley:</location>
<marker>Huang, Chen, Benjamin, </marker>
<rawString>Chu-Ren Huang, Keh-Jiann Chen, and Benjamin K. T’sou Eds. Readings in Chinese Natural Language Processing. 23-45. Berkeley: JCL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--3</pages>
<contexts>
<context position="1687" citStr="Gildea and Jurafsky, 2002" startWordPosition="227" endWordPosition="230">tences. The system achieves 92.71% accuracy in labeling the semantic roles for pre-structure- bracketed texts which is considerably higher than the simple method using probabilistic model of head-modifier relations. 1. Introduction For natural language understanding, the process of fine-grain semantic role assignment is one of the prominent steps, which provides semantic relations between constituents. The sense and sense relations between constituents are core meaning of a sentence. Conventionally there are two kinds of methods for role assignments, one is using only statistical information (Gildea and Jurafsky, 2002) and the other is combining with grammar rules (Gildea and Hockenmaier, 2003). However using only grammar rules to assign semantic roles could lead to low coverage. On the other hand, performance of statistical methods relies on significant dependent features. Data driven is a suitable strategy for semantic roles assignments of general texts. We use the Sinica Treebank as information resource because of its various domains texts including politics, society, literature...etc and it is a Chinese Treebank with semantic role assigned for each constituent (Chen etc., 2003). It used 74 abstract sema</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistics, 28(3):245-288</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Julia Hockenmaier</author>
</authors>
<date>2003</date>
<booktitle>Identifying Semantic Roles Using Combinatory Categorial Grammar. Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1764" citStr="Gildea and Hockenmaier, 2003" startWordPosition="239" endWordPosition="242"> for pre-structure- bracketed texts which is considerably higher than the simple method using probabilistic model of head-modifier relations. 1. Introduction For natural language understanding, the process of fine-grain semantic role assignment is one of the prominent steps, which provides semantic relations between constituents. The sense and sense relations between constituents are core meaning of a sentence. Conventionally there are two kinds of methods for role assignments, one is using only statistical information (Gildea and Jurafsky, 2002) and the other is combining with grammar rules (Gildea and Hockenmaier, 2003). However using only grammar rules to assign semantic roles could lead to low coverage. On the other hand, performance of statistical methods relies on significant dependent features. Data driven is a suitable strategy for semantic roles assignments of general texts. We use the Sinica Treebank as information resource because of its various domains texts including politics, society, literature...etc and it is a Chinese Treebank with semantic role assigned for each constituent (Chen etc., 2003). It used 74 abstract semantic roles including thematic roles, such as ‘agent’; ‘theme’, ‘instrument’, </context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Daniel Gildea and Julia Hockenmaier. 2003. Identifying Semantic Roles Using Combinatory Categorial Grammar. Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>The Part-of-Speech Tagging Guidelines for the Penn Chinese Treebank (3.0).</title>
<date>2000</date>
<tech>IRCS Report 00-07.</tech>
<institution>University of Pennsylvania.</institution>
<location>Philadelphia, PA:</location>
<marker>Xia, 2000</marker>
<rawString>Xia, Fei, 2000, The Part-of-Speech Tagging Guidelines for the Penn Chinese Treebank (3.0). IRCS Report 00-07. Philadelphia, PA: University of Pennsylvania.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>