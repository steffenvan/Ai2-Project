<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.979928">
Are School-of-thought Words Characterizable?
</title>
<author confidence="0.998255">
Xiaorui Jiang¶1 Xiaoping Sun¶2 Hai Zhuge¶†‡3*
</author>
<affiliation confidence="0.98885075">
¶ Key Lab of Intelligent Information Processing, Institute
of Computing Technology, CAS, Beijing, China
† Nanjing University of Posts and Telecommunications, Nanjing, China
‡ Aston University, Birmingham, UK
</affiliation>
<email confidence="0.841944">
1xiaoruijiang@gmail.com 2 sunxp@kg.ict.ac.cn
3 zhuge@ict.ac.cn
</email>
<sectionHeader confidence="0.98906" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.962813952380952">
School of thought analysis is an important yet
not-well-elaborated scientific knowledge dis-
covery task. This paper makes the first attempt
at this problem. We focus on one aspect of the
problem: do characteristic school-of-thought
words exist and whether they are characteriza-
ble? To answer these questions, we propose a
probabilistic generative School-Of-Thought
(SOT) model to simulate the scientific author-
ing process based on several assumptions. SOT
defines a school of thought as a distribution of
topics and assumes that authors determine the
school of thought for each sentence before
choosing words to deliver scientific ideas. SOT
distinguishes between two types of school-of-
thought words for either the general back-
ground of a school of thought or the original
ideas each paper contributes to its school of
thought. Narrative and quantitative experi-
ments show positive and promising results to
the questions raised above.
</bodyText>
<sectionHeader confidence="0.998825" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971">
With more powerful computational analysis tools,
researchers are now devoting efforts to establish
a “science of better science” by analyzing the
ecosystem of scientific discovery (Goth, 2012).
Amongst this ambition, school of thought analy-
sis has been identified an important fine-grained
scientific knowledge discovery task. As men-
tioned by Teufel (2010), it is important for an
experienced scientist to know which papers be-
long to which school of thought (or technical
route) through years of knowledge accumulation.
Schools of thought typically emerge with the
evolution of a research domain or scientific topic.
</bodyText>
<note confidence="0.931917">
* Corresponding author.
</note>
<figureCaption confidence="0.9681565">
Figure 1. The citation graph of the reachability
indexing domain (c.f. the RE data set in Table 1).
</figureCaption>
<bodyText confidence="0.999906448275862">
Take reachability indexing for example, which
we will repeatedly turn to later, there are two
schools of thought, the cover-based (since about
1990) and hop-based (since the beginning of the
2000s) methods. Most of the following works
belong to either school of thought and thus two
streams of innovative ideas emerge. Figure 1 il-
lustrates this situation. Two chains of subsequen-
tially published papers represent two schools of
thought of the reachability indexing domain. The
top chain of white double-line circles and the
bottom chain of shaded circles represent the cov-
er-based and hop-based streams respectively.
However it is not easy to gain this knowledge
about school of thought. Current citation index-
ing services are not very helpful for this kind of
knowledge discovery tasks. As explained in Fig-
ure 1, papers of different schools of thought cite
each other heavily and form a rather dense cita-
tion graph. An extreme example is p14, which
cites more hop-based papers than its own school
of thought.
If the current citation indexing service can be
equipped with school of thought knowledge, it
will help scientists, especially novice researchers,
a lot in grasping the core ideas of a scientific
domain quickly and making their own way of
innovation (Upham et al., 2010). School of
thought analysis is also useful for knowledge
</bodyText>
<page confidence="0.960799">
822
</page>
<note confidence="0.9316395">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.983655224137931">
flow discovery (Zhuge, 2006; Zhuge, 2012),
knowledge mapping (Chen, 2004; Herrera et al.,
2010) and scientific paradigm summarization
(Joang and Kan, 2010; Qazvinian et al., 2013)
etc.
This paper makes the first attempts to unsu-
pervised school of thought analysis. Three main
aspects of school of thought analysis can be iden-
tified: determining the number of schools of
thought, characterizing school-of-thought words
and categorizing papers into one or several
school(s) of thought (if applicable). This paper
focuses on the second subproblem and leaves the
other two as future work. Particularly, we pur-
pose to investigate whether characteristic school-
of-thought words exist and whether they can be
automatically characterized. To answer these
questions, we propose the probabilistic genera-
tive School-Of-Thought model (SOT for short)
based on the following assumptions on the scien-
tific authoring process.
Assumption A1. The co-occurrence patterns
are useful for revealing which words and sen-
tences are school-of-thought words and which
schools of thought they describe. Take reachabil-
ity indexing for example, hop-based papers try to
get the “optimum labeling” by finding the
“densest intermediate hops” to encode reach-
ability information captured by an intermediate
data structure called “transitive closure con-
tour”. To accomplish this, they solve the “dens-
est subgraph problem” on specifically created
“bipartite” graphs centered at “hops” by trans-
forming the problem into an equivalent “mini-
mum set cover” framework. Thus, these bold-
faced words often occur as hop-based school-of-
thought words. In cover-based methods, however,
one or several “spanning tree(s)” are extracted
and “(multiple) intervals” are assigned to each
node as reachability labels by “pre-(order)” and
“post-order traversals”. Meanwhile, graph the-
ory terminologies like “root”, “child” and “an-
cestor” etc. also frequently occur as cover-based
school-of-thought words.
Assumption A2. Before writing a sentence to
deliver their ideas, the authors need to determine
which school of thought this sentence is to por-
tray. This is called the one-sot-per-sentence as-
sumption, where “sot” abbreviates “school of
thought”. The one-sot-per-sentence assumption
does not mean that authors intentionally write
this way, but only simulates the outcome of the
scientific paper organization. Investigations into
scientific writing reveal that sentences of differ-
ent schools of thought can occur anywhere and
are often interleaved. This is because authors of a
scientific paper not only contribute to the school
of thought they follow but also discuss different
</bodyText>
<figureCaption confidence="0.999664">
Figure 2. The SOT Model
</figureCaption>
<bodyText confidence="0.999974333333333">
schools of thought. For example, in the Method
part, the authors may turn to discuss another pa-
per (possibly of a different school of thought) for
comparison. This phenomenon also occurs fre-
quently in the Results or Discussions section.
Besides, citation sentences often acknowledge
related works of different schools of thought.
Assumption A3. All the papers of a domain
talk about the general domain backgrounds. For
example, reachability indexing aims to build
“compact indices” for facilitating “reachability
queries” between “source” and “target nodes”.
Other background words include “(complete)
transitive closure”, “index size” and “reach”
etc., as well as classical graph theory terminolo-
gies like “predecessors” and “successors” etc.
Assumption A4. Besides contributing original
ideas, papers of the same school of thought typi-
cally need to follow some general strategies that
make them fall into the same school of thought.
For example, all the hop-based methods follow
the general ideas of designing approximate algo-
rithms for choosing good hops, while the original
ideas of each paper lead to different labeling al-
gorithms. Scientific readers pay attention to the
original ideas of each paper as well as the gen-
eral ideas of each school of thought. This as-
sumes that a word can be either a generality or
originality word to deliver general and original
ideas of a school of thought respectively.
</bodyText>
<sectionHeader confidence="0.962884" genericHeader="introduction">
2 The School-of-Thought Model
</sectionHeader>
<bodyText confidence="0.981231545454545">
Figure 2 shows the proposed SOT model. SOT
reflects all the assumptions made in Sect. 1. The
plate notation follows Bishop (2006) where a
shaded circle means an observed variable, in this
context word occurrence in text, a white circle
denotes either a latent variable or a model pa-
rameter, and a small solid dot represents a hyper-
parameter of the corresponding model parameter.
The generative scientific authoring process illus-
trated in Figure 2 is elaborated as follows.
Step 1. School of thought assignment (A2).
</bodyText>
<page confidence="0.994218">
823
</page>
<table confidence="0.861849928571429">
DATA NL W S Nd
(avg) C SCHOOLS OF THOUGHT
SETS (NUMBER OF PAPERS UNDER THIS SCHOOL OF THOUGHT)
RE 18 54035 5300 294 2 Hop-Based (9), Cover-Based (9)
NP 24 36227 3329 138 3 Mention-Pair Models (14), Entity-Mention Models (5), Ranking Models (5)
PP 20 21941 2182 109 4 Using Single Monolingual Corpus (3), Using Monolingual Parallel Corpora (6), Using Monolingual
Comparable Corpora (5), Using Bilingual Parallel Corpora (5)
TE 34 55671 5335 156 2 Finite-State Transducer models (17), Synchronous Context-Free Grammar models (17)
WA 18 19219 1807 100 3 Asymmetric Models (5), Symmetric Alignment Models (9), Supervised Learning for Alignment (4)
DP 56 68384 6021 107 3 Transition-Based (20), Graph-Based (17), Grammar-Based (19)
LR 44 77024 7395 168 3 Point-wise Approach (11), Pair-wise Approach (17), List-wise Approach (16)
Notes: RE – REachability indexing; NP – Noun Phrase co-reference resolution; PP – ParaPhrase; TE – Translational Equivalence; WA –
Word Alignment; DP – Dependency Parsing; LR – Learning to Rank; W – number of words; S – number of sentences; C – gold-standard
number of schools of thought; Nd − number of sentences in document d.
</table>
<tableCaption confidence="0.998964">
Table 1. Data Sets
</tableCaption>
<bodyText confidence="0.999934111111111">
To simulate the one-sot-per-sentence assump-
tion, we introduce a latent school-of-thought as-
signment variable cd,s (1 ≤ cd,s ≤ C, where C is the
number of schools of thought) for each sentence
s in paper d, dependent on which are topic as-
signment and word occurrence variables. As dif-
ferent papers and their authors have different foci,
flavors and writing styles, it is appropriate to as-
sume that each paper d has its own Dirichlet dis-
</bodyText>
<equation confidence="0.9457052">
c
tribution of schools of thought π  d  Dir α
( )
c
(refer to Heinrich (2008) for Dirichlet analysis of
texts). cd,s is thus multinomially sampled from
πd , that is, ,
c c d s Mutl π d
 ( )
c .
</equation>
<bodyText confidence="0.949181">
Step 2. Background word emission (A3).
Before choosing a word wd,s,n to deliver scien-
tific ideas, the authors first need to determine
whether this word describes domain backgrounds
or depicts a specific school-of-thought. This in-
formation is indicated by the latent background
word indicator variable bd,s,n  Bern π d , where
( ) bπ d Beta α α is the probability of Bernoulli
</bodyText>
<figure confidence="0.9218085">
b ( 0 , 1 )
b b
</figure>
<bodyText confidence="0.550581">
test. bd,s,n = 1 means wd,s,n is a background word
that is multinomially sampled from the Dirichlet

background word distribution ϕ Dir β
</bodyText>
<equation confidence="0.857095142857143">
bg ( )
bg
  ,
i.e. , ,
wd s n Mutl ϕ
 ( )
bg .
</equation>
<bodyText confidence="0.950335869565217">
Step 3. Originality indicator assignment (A4).
If bd,s,n = 0, wd,s,n is a school-of-thought word.
Then the authors need to determine whether wd,s,n
talks about the general ideas of a certain school
of thought (i.e. a generality word when od,s,n = 0)
or delivers original contributions to the specific
school of thought (i.e. an originality word when
od,s,n = 1). The latent originality indicator variable
od,s,n is assigned in a similar way to bd,s,n.
Step 4. Topical word emission.
SOT regards schools of thought and topics as
two different levels of semantic information. A
school of thought is modeled as a distribution of
topics discussed by the papers of a research do-
main. Each topic in turn is defined as a distribu-
tion of the topical words. Reflected in Figure 1,

θcg and o
θc are Dirichlet distributions of general-
ity and originality topics respectively, with γg
and γo being the Dirichlet priors. According to
the assignment of the originality indicator, the
topic td,s,n of the current token is multinomially
</bodyText>
<equation confidence="0.800203333333333">
 
selected from either g
θc
</equation>
<bodyText confidence="0.909496666666667">
1). After that, a word wd,s,n is multinomially emit-
ted from the topical word distribution
where ϕ t Dir β
</bodyText>
<equation confidence="0.9929565">
 
tp ( )
</equation>
<bodyText confidence="0.998975">
tp for each 1 ≤ t ≤ T.
Gibbs sampling is used for SOT model infer-
ence. Considering the logic of presentation, it is
detailed in Appendix B.
</bodyText>
<sectionHeader confidence="0.999763" genericHeader="background">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99775">
3.1 Datasets
</subsectionHeader>
<bodyText confidence="0.995086578947369">
The gold-standard number an
d the classification
of schools of thoughts reflect not only the view-
points of the survey authors but also the consen-
sus of the corresponding research communities.
Lacking standard test benchmarks, we compiled
7 data sets according to well-known recent sur-
veys (see Appendix A). Each data set consists of
several dozens of papers of the same domain.
When constructing these data sets, the only place
of human intervention is the de-duplication step,
which means typically only one of a number of
highly duplicated references is kept in the data
set. Different from previous studies reviewed in
Sect. 4, full texts but not abstracts are used. We
extracted texts from the collected papers and re-
moved tables, figures and sentences full of math
equations or unrecognizable symbols. The statis-
tics of the resulting data sets are listed in Table 1.
</bodyText>
<subsectionHeader confidence="0.999123">
3.2 Qualitative Results
</subsectionHeader>
<bodyText confidence="0.9915425">
This section looks at the capabilities of SOT in
learning background and school-of-thought words
using the RE data set as an example. Given the
estimated model parameters, the distributions of
the school-of-thought words of SOT can be cal-
culated as weighted sums of topical word emis-
sion probabilities
for each word w) over all
the topics
an
</bodyText>
<equation confidence="0.634840333333333">
,
ϕtt
(t)
</equation>
<bodyText confidence="0.881742">
d papers (d), as in Eq. (1).
</bodyText>
<equation confidence="0.5991326">
(od,s,n = 0) or o (od,s,n =
θc
,
ϕt tp
d ,s , n
</equation>
<page confidence="0.992111">
824
</page>
<table confidence="0.99953348">
BACKGROUND WORDS SCHOOL-OF-THOUGHT WORDS
SOT-1 (COVER-BASED) SOT-2 (HOP-BASED)
node arc figure node reachable find 2-hop problem hop
closure size deleted graph reach reachability vertex tree subgraph
chain lists incremental nodes size cover vertices edges proposed
graph procedure predecessor closure chains acyclic cover construction large
nodes arcs directed tree graphs database graph approach path-hop
compressed update edge edges storage traversal algorithm indexing lin
list off-chain systems chain instance components size contour spanning
transitive acyclic connected transitive intervals directed chain processing smaller
successor reduction techniques non-tree spanning lists labeling chain optimal
compression relation single number segment reduction closure pairs densest
storage source cycles compressed order g. reachability compression decomposition
chains reach updates path connected addition transitive reachable dag
required effort depth edge component technique graphs property paths
index obtained materialize index case degree time figure data
number component concatenation list postorder gs number path-tree ratio
database path presented set strongly successors 3-hop bipartite nodes
case assignment added interval original structure index scheme edge
technique predecessors original successor ris single labels density finding
degree addition components figure required paths query queries rank
successors indices strongly compression source arc set reach note
destination (65), determine (76), pair root (67), pre- (85), topological (96), sub- lout (66), segment (68), minimum (69), in-
(77), resulting (84), merging (86), tree (102), ancestor (105), child (106), termediate (77), greedy (87), faster (88),
reached (87), store (96) multiple (113), preorder (117) heuristics (92), approximate (120)
</table>
<tableCaption confidence="0.999167">
Table 2. The distributions of top-120 background and school-of-thought words.
</tableCaption>
<table confidence="0.98463525">
p(w|c,o=0 /1) (1)
Nd,v (d, w)πo  θg/o tpd
Nv (w)
d,0/1t c,t ϕt,w
</table>
<bodyText confidence="0.999800125">
The first row of Table 2 lists the top-60 back-
ground and school-of-thought words learned by
SOT for the RE data set sorted in descending or-
der of their probabilities column by column. The
words at the bottom are some of the remaining
characteristic words together with their positions
on the top-120 list. In the experiments, T is set to
20. As the data sets are relative small, it is not
appropriate to set T too large, otherwise most of
the topics are meaningless or duplicate. Either
case will impose additive negative influences on
the usefulness of the model, for example when
applied to schools of thought clustering in the
next section. C is set to the gold-standard number
of schools of thought as in this study we are
mainly interested in whether school-of-thought
words are characterizable. The problems of iden-
tifying the existence and number of schools of
thought are left to future work. Other parameter
settings follow Griffiths and Steyvers (2010).
The learned word distributions are shown very
meaningful at the first glance. They are further
explained as follows.
For domain backgrounds, reachability index-
ing is a classical problem of the graph database
“domain” which talks about the reachability be-
tween the “source” and “destination nodes” on
a “graph”. Reachability “index” or “indices”
aim at a “reduction” of the “transitive closure”
so as to make the “required storage” smaller.
All current works preprocess the input graphs by
“merging strongly connected components”
into representative nodes to remove “cycles”.
We then give a deep investigation into the
hop-based school-of-thought words (SoT-2).
Cover-based ones conform well to the assump-
tions in Sect. 1 too. “2-hop”, “3-hop” and “path-
hop” are three representative hop-based reacha-
bility “labeling schemes” (a phrase preferred
by hop-based papers). Hop-based methods aim at
“finding” the “optimum labeling” with “mini-
mum cost” and achieving a higher “compres-
sion ratio” than cover-based methods. To ac-
complish this, hop-based methods define a
“densest subgraph problem” on a “bipartite”
graph, transform it to an equivalent “set cover”
problem, and then apply “greedy” algorithms
based on several “heuristics” to find “approxi-
mate” solutions. The “intermediate hops” with
the highest “density” are found as labels and
assigned to “Lout” and “Lin” of certain “contour”
vertices. “contour” is used by hop-based meth-
ods as a concise representation of the remaining
to-be-encoded reachability information.
The underlined bold italic words such as “set”
and “cover” are misleading (yet not necessarily
erroneous) words as both schools of thought use
them heavily, but in quite different contexts, for
example, a “set” of labels versus “set cover”,
and “cover(s)” partial reachability information
versus tree “cover”. To improve, one of our fu-
ture works shall integrate multi-word expressions
or n-grams (Wallach, 2006) and syntactic analy-
sis (Griffiths et al., 2004) into the current model.
</bodyText>
<page confidence="0.992181">
825
</page>
<subsectionHeader confidence="0.996148">
3.3 Quantitative Results
</subsectionHeader>
<bodyText confidence="0.999934875">
To see the usefulness of school-of-thought words,
we use the SOT model as a way to feature space
reduction for a more precise text representation
in the school-of-thought clustering task. A subset
of school-of-thought words whose accumulated
probability exceeds a given threshold fsThr are
used as the reduced feature vector. Text is repre-
sented in the vector space model weighted using
tf⋅idf. K-means is used for clustering. To obtain a
stable and reliable result, we choose 300 random
seeds as initial cluster centroids, run K-means
300 times and, following the heuristic suggestion
by Manning et al. (2009), output the best cluster-
ing by the minimum residual squared sum prin-
ciple. Two baselines are the “RAW” method
without dimension reduction and LDA-based
(Blei et al., 2003) feature selection. Table 3 re-
ports the F-measure values of different competi-
tors. In the parentheses are the corresponding
threshold values under which the reported clus-
tering result is obtained. The larger the threshold
value is, the less effective the method in dimen-
sion reduction.
Compared to the baselines, SOT has consist-
ently the best clustering qualities. When fsThr ≤
0.70, the feature space is reduced from several
thousand words to only a few hundreds. LDA is
typically better than RAW (except on LR) but
less efficient in dimension reduction, e.g. on WA
and DP. In the latter two cases, fsThr = 0.80 typ-
ically means LDA is much less efficient in fea-
ture reduction than SOT on these two data sets.
</bodyText>
<table confidence="0.999320111111111">
F-MEASURE (β = 2.0)
DATA SETS RAW LDA (fsThr) SOT (fsThr)
RE .7464 .7464 (.50) .7482 (.60)
NP .4528 .6150 (.75) .6911 (.75)
PP .3256 .4179 (.60) .6025 (.75)
TE .2580 .5148(.60) .9405 (.40)
WA .3125 .4569 (.80) .5519 (.60)
DP .4787 .6762 (.80) .7155 (.50)
LR .5413 .5276 (.95) .6583 (.75)
</table>
<tableCaption confidence="0.998328">
Table 3. School-of-thought clustering results
</tableCaption>
<sectionHeader confidence="0.999646" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999973093023256">
An early work in semantic analysis of scientific
articles is Griffiths and Steyvers (2004) which
focused on efficient browsing of large literature
collections based on scientific topics. Other re-
lated researches include topic-based reviewer
assignment (Mimno and McCallum, 2007), cita-
tion influence estimation (Dietz et al., 2007), re-
search topic evolution (Hall et al., 2008) and ex-
pert finding (Tu et al., 2010) etc.
Another line of research is the joint modeling
of topics and other types of semantic units such
as perspectives (Lin et al., 2006), sentiment (Mei
et al., 2007) and opinions (Zhao et al., 2010) etc.
These works also took a multi-dimensional view
of document semantics. The TAM model (Paul
and Girju, 2010) might be the most relevant to
SOT. TAM simultaneously models aspects and
topics with different assumptions from SOT and
it models purely on word level.
Studies that introduce an explicit background
distribution include Chemudugunta et al. (2006),
Haghighi and Vanderwende (2009), and Li et al.
(2010) etc. Different from these works, SOT as-
sumes that not only some “meaningless” general-
purpose words but also more meaningful words
about the specific domain backgrounds can be
learned. What’s more these works all model on a
word level.
However, it is very useful to regard sentence
as the basic processing unit, for example in the
text scanning approach simulating human read-
ing process by Xu and Zhuge (2013). Indeed,
sentence-level school of thought assignment is
crucial to SOT as it allows SOT to model the sci-
entific authoring process. There are also other
works that model text semantics on different lev-
els other than words or tokens, such as Wallach
(2006) on n-grams and Titov and McDonald
(2008) on words within multinomially sampled
sliding windows. The latter also distinguishes
between different levels of topics, say global ver-
sus local topics, while in SOT such discrimina-
tion is generality versus originality topics.
</bodyText>
<sectionHeader confidence="0.997675" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999985">
This paper proposes a probabilistic generative
model SOT for characterizing school-of-thought
words. In SOT, a school of thought is modeled as
a distribution of topics, with the latter defined as
a distribution of topical words. School of thought
assignment to each sentence is vital as it allows
SOT to simulate the scientific authoring process
in which each sentence conveys a piece of idea
contributed to a certain school of thought as well
as the domain backgrounds. Narrative and quan-
titative analysis show that high-quality school-of-
thought words can be captured by the proposed
model.
</bodyText>
<sectionHeader confidence="0.992095" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999889125">
This work is partially supported by National Sci-
ence Foundation of China (No. 61075074 and No.
61070183) and funding from Nanjing University
of Posts and Telecommunications. Special thanks
go to Prof. Jianmin Yao at Soochow University
and Suzhou Scientific Service Center of China
for his advices and suggestions that help this pa-
per finally come true.
</bodyText>
<page confidence="0.997847">
826
</page>
<sectionHeader confidence="0.658852" genericHeader="references">
References
</sectionHeader>
<figureCaption confidence="0.872135076923077">
Chemudugunta, C., Smyth P., and Steyvers, M. 2006.
Modeling general ad specific aspects of docu-
ments with a probabilistic topic model. In Proc.
NIPS’06.
Bishop, C. M. 2006. Patter Recognition and Machine
learning. Ch. 8 Graphical Models. Springer.
Blei, D. M., Ng, A. Y., and Jordan, M. I. 2003. Latent
dirichlet allocation. J. Mach. Learn. Res., 3: 993–
1022.
Chen, C. 2004. Searching for intellectual turning
points: Prograssive knowledge domain visualiza-
tion. Proc. Natl. Acad. Sci., 101(suppl. 1): 5303–
5310.
</figureCaption>
<reference confidence="0.839482610526316">
Dietz, L., Bickel, S., and Scheffer, T. 2007. Unsuper-
vised prediction of citation influence. In Proc.
ICML’07, 233–240.
Goth, G. 2012. The science of better science. Com-
mun. ACM, 55(2): 13–15.
Griffiths, T., and Steyvers, M. 2004. Finding scien-
tific topics. Proc. Natl. Acad. Sci., 101 (suppl 1):
5228–5235.
Griffiths, T., Steyvers, M., Blei, D. M., and Tenen-
baum, J. B. 2004. Integrating topics and syntax.
In Proc. NIPS’04.
Haghighi, A., and Vanderwende, L. 2009. Exploring
content models for multi-document summariza-
tion. In Proc. HLT-NAACL’09, 362–370.
Hall, D., Jurafsky, D., and Manning, C. D. 2008.
Studying the history of ideas using topic models.
In Proc. EMNLP’08, 363–371.
Heinrich, G. 2008. Parameter estimation for text anal-
ysis. Available at
www.arbylon.net/publications/text-est.pdf.
Herrera, M., Roberts, D. C., and Gulbahce, N. 2010.
Mapping the evolution of scientific fields. PLoS
ONE, 5(5): e10355.
Joang, C. D. V., and Kan, M.-Y. (2010). Towards
automatic related work summarization. In Proc.
COLING 2010.
Li, P., Jiang, J., and Wang, Y. 2010. Generating tem-
plates of entity summaries with an entity-aspect
model and pattern mining. In Proc. ACL’10, 640–
649.
Lin, W., Wilson, T., Wiebe, J., and Hauptmann, A.
2006. Which side are you on? Identifying per-
spectives at the document and sentence levels. In
Proc. CoNLL’06, 109–116.
Manning, C. D., Raghavan, P., and Schütze, H. 2009.
Introduction to Information Retrieval. Ch. 16.
Flat Clustering. Cambridge University Press.
Mei, Q., Ling, X., Wondra, M., Su, H., and Zhai, C.
2007. Topic sentiment mixture: modeling facets
and opinions in weblogs. In Proc. WWW’07,
171–180.
Mimno, D., and McCallum, A. 2007. Expertise mod-
eling for matching papers with reviewers. In Proc.
SIGKDD’07, 500–509.
Paul, M., and Girju, R. 2010. A two-dimensional top-
ic-aspect model for discovering multi-faceted
topics. In Proc. AAAI’10, 545–550.
Qazvinian, V., Radev, D. R., Mohammad, S. M., Dorr,
B., Zajic, D., Whidby, M., and Moon T. (2013).
Generating extractive summaries of scientific
paradigms. J. Artif. Intell. Res., 46: 165–201.
Teufel, S. 2010. The Structure of Scientific Articles.
CLSI Publications, Stanford, CA, USA.
Titov, I., and McDonald R. 2008. Modeling online
reviews with multi-grain topic models. In Proc.
WWW’08, 111–120.
Tu, Y., Johri, N., Roth, D., and Hockenmaier, J. 2010.
Citation author topic model in expert search. In
Proc. COLING’10, 1265–1273.
Upham, S. P., Rosenkopf, L., Ungar, L. H. 2010. Po-
sitioning knowledge: schools of thought and new
knowledge creation. Scientometrics, 83 (2): 555–
581.
Wallach, H. 2006. Topic modeling: beyond bag-of-
words. In Proc. ICML’06, 977– 984.
Xu, B., and Zhuge, H. 2013. A text scanning mecha-
nism simulating human reading process, In Proc.
IJCAI’13.
Zhao, X., Jiang, J., Yan, H., and Li, X. 2010. Jointly
modeling aspects and opinions with a MaxEnt-
LDA hybrid. In Proc. EMNLP’10, 56– 65.
Zhuge, H. 2006. Discovery of knowledge flow in sci-
ence. Commun. ACM, 49(5): 101-107.
Zhuge, H. 2012. The Knowledge Grid: Toward
Cyber-Physical Society (2nd edition). World Sci-
entific Publishing Company, Singapore.
Appendices
A Survey Papers for Building Data Sets
[RE] Yu, P. X., and Cheng, J. 2010. Managing and
Mining Graph Data, Ch. 6, 181–215. Springer.
[NP] Ng, V. 2010. Supervised noun phrase corefer-
ence research: The first fifteen years. In Proc.
ACL’10, 1396–1141.
[PP] Madnani, N., and Dorr, B. J. 2010. Generating
phrasal and sentential paraphrases: A survey of
data-driven methods. Comput. Linguist., 36 (3):
341–387.
[TE/WA] Lopez, A. 2008. Statistical machine transla-
tion. ACM Comput. Surv., 40(3), Article 8, 49
pages.
[DP] Kübler, S., McDonald, R., and Nivre, J. 2009.
Dependency parsing, Ch. 3–5, 21–78. Morgan &amp;
Claypools Publishers.
[LR] Liu, T. Y. 2011. Learning to rank for infor-
mation retrieval, Ch. 2–4, 33–88. Springer.
</reference>
<subsectionHeader confidence="0.942001">
B Gibbs Sampling of the SOT Model
</subsectionHeader>
<bodyText confidence="0.995078666666667">
Using collapsed Gibbs sampling (Griffiths and
Steyvers, 2004), the latent variable c is infer-
enced in Eq. (B1). In Eq. (B1), Nc ,b,o,t (c,0, o, t)
</bodyText>
<page confidence="0.937095">
827
</page>
<equation confidence="0.988748944444444">
T ¬ ( , )
d s
p(cd,s = c I
 |c ¬(d,s) �) ∝ rl Γ (Nc,b,o,t (c, 0, 0, t) + γ ) × Γ(Nc,b, &amp;quot; (c, 0, 0,Σ) + T ⋅ γ )
( ( ,0,0, ) ) ( ( ,0,0, )
¬ ( , )
d s g g
Γ N c t + γ Γ N c Σ + ⋅
T γ )
t = 1 c b o t
, , , c b o t
, , ,
d s ¬ d s
( ( ,0,1, ) ) (
o o c
Γ N c t + γ Γ N ¬ ( , ) ( , )
( ,0,1, ) )
c Σ + γ N ( , )
</equation>
<figure confidence="0.954883470588235">
d c + α
c b o t
, , , c b
, , ,
o t d c
,
×
× ¬ ( , )
Γ ( ( ,0,1, ) )
o d s
N c Σ + γ N ( , )
d Σ
c b o t
, , , d c
,
N¬(d,s,n d 1 + αb N¬(d,s,n)1 v
p (b = 1  |w = v ) ∝ d,b (d, ) 1 × b,v (, )
,.
d,s,n d,s,n ( , , )
d s n ¬ ( , , )
b b d s n
N ¬ d α α N (1, )
Σ + +
Σ +
( , )
,
d b
, 0 1 b v

p(bd,s,n = 0, od,s,n = 0, td,s,n = t  |cd,s = c, , b¬(d,s,n) O &gt; _(d,s,n) t _(d,s,n) , wd,s,n = v,)
( , , )
d s n b ( , , )
d s n o
N ¬ ( ,0) + N ¬
α
d ( ,0,0)
d + α
d b
, 0 d b o
, , 0
∝ ×
¬ ( , , )
d s n ¬ ( , , )
( , )
Σ + +
b b d s n ( ,0, )
Σ + +
o o
N α α
d N d α α
d b
</figure>
<bodyText confidence="0.668619">
, 0 1 d b o
</bodyText>
<equation confidence="0.9032852">
, , 0 1
× ¬ ( , , )
d s n ¬ ( , , )
( ,0,0, ) T γ g d s n
N tp
c Σ + ⋅ N (0, , )
t Σ + ⋅ β
V
c b o t
, , , b t v
, ,
= O 0 =1 t = t I C = C b_(d,s,n) O_(d,s,n) t _(d,s,n) w
,s,n � d,s,n � d,s,n d,s &gt; &gt; &gt; &gt; d,s,
P(bd n =V,O )
T
×∏
t =1
( ( ,0,1, ) )
( , )
N ¬ d s o
</equation>
<figure confidence="0.988134693548387">
Γ c t + γ
c b o t
, , ,
+C⋅αc
bg
+ β
bg
V ⋅ β
N¬(d,s,n)
c,b o,t
(
( , , )
d s n
,0,0, ) + γ g N ¬
c t (0, , )
t v
b t v
, ,
×
tp
+β
 
∝ ×
Nd
¬ ( , , )
d s n b ¬ ( , , )
d s n
( ,0) + ( ,0,1)+αo
N d d
α N
d b
, 0 d b o
, , 1
¬ ( , , )
d s n b b ( , , )
( , )
d Σ + +
α α N¬ d s n ( ,0,
d
, b 0 1 d b o
, ,
Σ + +
α α
o o
) 0 1
(B4)
×
( , , )
d s n
,0,1, ) + γ o N ¬
c t (0, , )
t v
b t v
, ,
¬ ( ,, )
d s n o ¬ ( , , )
d s n
( ,0,1, )
c Σ + ⋅ γ
T N
, , , , ,
c b o t b t v
</figure>
<figureCaption confidence="0.997062">
Figure B1. The SOT model inference.
</figureCaption>
<figure confidence="0.989208571428571">
N
(
N¬(d,s,n)
c,b o,t
×
tp
+ β
</figure>
<bodyText confidence="0.99739675">
is the number of words of topic t describing the
common ideas (o = 0) or original ideas (o = 1) of
school of thought c. The superscript ¬(d,s)
means that words in sentence s of paper d are not
</bodyText>
<equation confidence="0.827027">
counted. ( , )
Nd c d c
</equation>
<bodyText confidence="0.875104166666667">
¬ d s ( , )) counts the number of sen-
,
tences in paper d describing school of thought c
with sentence s removed from consideration. In
Eqs. (B1)–(B4), the symbol Σ means summation
over the corresponding variable. For example,
</bodyText>
<equation confidence="0.8920315">
Nc,b,o#,0,o,Σ)=t =1,,TNc,b,o,t(c,0,o,0 (B5)
, o and t are jointly sam-
</equation>
<bodyText confidence="0.925767275862069">
pled in Eqs. (B2)–(B4). ( , , )
Nd b d b
¬ d s n ( , ) counts the
,
number of background (b = 0) or school-of-
thought (b = 1) words in document d without
counting the n-th token in sentence s.
Nb v
¬ ( , , )
d s n (1, )
v is the number of times vocabulary
,
item v occurs as background word in the litera-
ture collection without counting the n-th token in
sentence s of paper d. ( , , )
N d b o d o
¬ d s n ( ,0, ) is the
, ,
number of words describing either common ideas
(o = 0) or original ideas (o = 1) of some school
of thought without considering the n-th token in
sentence s of paper d. ( , , )
N c b o t c o t
¬ d s n ( ,0, , ) is the
, , ,
number of words of topic t in the literature col-
lection describing either common ideas (o = 0) or
original ideas (o = 1) of school of thought c
without counting the n-th token in sentence s of
</bodyText>
<equation confidence="0.6426726">
paper d. ( , , )
Nb t v
¬ d s n (0, , )
t v is the number of school-
, ,
</equation>
<bodyText confidence="0.99977025">
of-thought words of topic t which is instantiated
by vocabulary item v in the literature collection
without counting the n-th token in sentence s of
paper d.
</bodyText>
<equation confidence="0.95342975">
tp
(0, , )
t Σ + ⋅
V β
</equation>
<page confidence="0.982169">
828
</page>
<figure confidence="0.9301905">

Latent variables b
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.386717">
<title confidence="0.989182">Are School-of-thought Words Characterizable?</title>
<author confidence="0.910707">Xiaoping Hai</author>
<affiliation confidence="0.955682">Lab of Intelligent Information Processing, of Computing Technology, CAS, Beijing, University of Posts and Telecommunications, Nanjing,</affiliation>
<address confidence="0.992078">University, Birmingham, UK</address>
<note confidence="0.5927235">2sunxp@kg.ict.ac.cn 3zhuge@ict.ac.cn</note>
<abstract confidence="0.995710454545455">School of thought analysis is an important yet not-well-elaborated scientific knowledge discovery task. This paper makes the first attempt at this problem. We focus on one aspect of the problem: do characteristic school-of-thought words exist and whether they are characterizable? To answer these questions, we propose a probabilistic generative School-Of-Thought model to simulate the scientific authorprocess based on several assumptions. defines a school of thought as a distribution of topics and assumes that authors determine the school of thought for each sentence before words to deliver scientific ideas. distinguishes between two types of school-ofthought words for either the general background of a school of thought or the original ideas each paper contributes to its school of thought. Narrative and quantitative experiments show positive and promising results to the questions raised above.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Dietz</author>
<author>S Bickel</author>
<author>T Scheffer</author>
</authors>
<title>Unsupervised prediction of citation influence.</title>
<date>2007</date>
<booktitle>In Proc. ICML’07,</booktitle>
<pages>233--240</pages>
<contexts>
<context position="20389" citStr="Dietz et al., 2007" startWordPosition="3217" endWordPosition="3220"> .7464 .7464 (.50) .7482 (.60) NP .4528 .6150 (.75) .6911 (.75) PP .3256 .4179 (.60) .6025 (.75) TE .2580 .5148(.60) .9405 (.40) WA .3125 .4569 (.80) .5519 (.60) DP .4787 .6762 (.80) .7155 (.50) LR .5413 .5276 (.95) .6583 (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distrib</context>
</contexts>
<marker>Dietz, Bickel, Scheffer, 2007</marker>
<rawString>Dietz, L., Bickel, S., and Scheffer, T. 2007. Unsupervised prediction of citation influence. In Proc. ICML’07, 233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Goth</author>
</authors>
<title>The science of better science.</title>
<date>2012</date>
<journal>Commun. ACM,</journal>
<volume>55</volume>
<issue>2</issue>
<pages>13--15</pages>
<contexts>
<context position="1511" citStr="Goth, 2012" startWordPosition="213" endWordPosition="214">uthors determine the school of thought for each sentence before choosing words to deliver scientific ideas. SOT distinguishes between two types of school-ofthought words for either the general background of a school of thought or the original ideas each paper contributes to its school of thought. Narrative and quantitative experiments show positive and promising results to the questions raised above. 1 Introduction With more powerful computational analysis tools, researchers are now devoting efforts to establish a “science of better science” by analyzing the ecosystem of scientific discovery (Goth, 2012). Amongst this ambition, school of thought analysis has been identified an important fine-grained scientific knowledge discovery task. As mentioned by Teufel (2010), it is important for an experienced scientist to know which papers belong to which school of thought (or technical route) through years of knowledge accumulation. Schools of thought typically emerge with the evolution of a research domain or scientific topic. * Corresponding author. Figure 1. The citation graph of the reachability indexing domain (c.f. the RE data set in Table 1). Take reachability indexing for example, which we wi</context>
</contexts>
<marker>Goth, 2012</marker>
<rawString>Goth, G. 2012. The science of better science. Commun. ACM, 55(2): 13–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Griffiths</author>
<author>M Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<journal>Proc. Natl. Acad. Sci.,</journal>
<volume>101</volume>
<pages>5228--5235</pages>
<contexts>
<context position="20149" citStr="Griffiths and Steyvers (2004)" startWordPosition="3184" endWordPosition="3187">s efficient in dimension reduction, e.g. on WA and DP. In the latter two cases, fsThr = 0.80 typically means LDA is much less efficient in feature reduction than SOT on these two data sets. F-MEASURE (β = 2.0) DATA SETS RAW LDA (fsThr) SOT (fsThr) RE .7464 .7464 (.50) .7482 (.60) NP .4528 .6150 (.75) .6911 (.75) PP .3256 .4179 (.60) .6025 (.75) TE .2580 .5148(.60) .9405 (.40) WA .3125 .4569 (.80) .5519 (.60) DP .4787 .6762 (.80) .7155 (.50) LR .5413 .5276 (.95) .6583 (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. Th</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Griffiths, T., and Steyvers, M. 2004. Finding scientific topics. Proc. Natl. Acad. Sci., 101 (suppl 1): 5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Griffiths</author>
<author>M Steyvers</author>
<author>D M Blei</author>
<author>J B Tenenbaum</author>
</authors>
<title>Integrating topics and syntax.</title>
<date>2004</date>
<booktitle>In Proc. NIPS’04.</booktitle>
<contexts>
<context position="18164" citStr="Griffiths et al., 2004" startWordPosition="2855" endWordPosition="2858">nd “Lin” of certain “contour” vertices. “contour” is used by hop-based methods as a concise representation of the remaining to-be-encoded reachability information. The underlined bold italic words such as “set” and “cover” are misleading (yet not necessarily erroneous) words as both schools of thought use them heavily, but in quite different contexts, for example, a “set” of labels versus “set cover”, and “cover(s)” partial reachability information versus tree “cover”. To improve, one of our future works shall integrate multi-word expressions or n-grams (Wallach, 2006) and syntactic analysis (Griffiths et al., 2004) into the current model. 825 3.3 Quantitative Results To see the usefulness of school-of-thought words, we use the SOT model as a way to feature space reduction for a more precise text representation in the school-of-thought clustering task. A subset of school-of-thought words whose accumulated probability exceeds a given threshold fsThr are used as the reduced feature vector. Text is represented in the vector space model weighted using tf⋅idf. K-means is used for clustering. To obtain a stable and reliable result, we choose 300 random seeds as initial cluster centroids, run K-means 300 times </context>
</contexts>
<marker>Griffiths, Steyvers, Blei, Tenenbaum, 2004</marker>
<rawString>Griffiths, T., Steyvers, M., Blei, D. M., and Tenenbaum, J. B. 2004. Integrating topics and syntax. In Proc. NIPS’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>L Vanderwende</author>
</authors>
<title>Exploring content models for multi-document summarization.</title>
<date>2009</date>
<booktitle>In Proc. HLT-NAACL’09,</booktitle>
<pages>362--370</pages>
<contexts>
<context position="21062" citStr="Haghighi and Vanderwende (2009)" startWordPosition="3327" endWordPosition="3330">008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic processing unit, for example in the text scanning approach simulating human reading process by Xu and Zhuge (2013). Indeed, sentence-level school of thought assignment is crucial to SOT as it allows SOT to model the scientific authoring process. There are also other works that model</context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Haghighi, A., and Vanderwende, L. 2009. Exploring content models for multi-document summarization. In Proc. HLT-NAACL’09, 362–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hall</author>
<author>D Jurafsky</author>
<author>C D Manning</author>
</authors>
<title>Studying the history of ideas using topic models.</title>
<date>2008</date>
<booktitle>In Proc. EMNLP’08,</booktitle>
<pages>363--371</pages>
<contexts>
<context position="20435" citStr="Hall et al., 2008" startWordPosition="3225" endWordPosition="3228">.75) .6911 (.75) PP .3256 .4179 (.60) .6025 (.75) TE .2580 .5148(.60) .9405 (.40) WA .3125 .4569 (.80) .5519 (.60) DP .4787 .6762 (.80) .7155 (.50) LR .5413 .5276 (.95) .6583 (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Hagh</context>
</contexts>
<marker>Hall, Jurafsky, Manning, 2008</marker>
<rawString>Hall, D., Jurafsky, D., and Manning, C. D. 2008. Studying the history of ideas using topic models. In Proc. EMNLP’08, 363–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heinrich</author>
</authors>
<title>Parameter estimation for text analysis. Available at www.arbylon.net/publications/text-est.pdf.</title>
<date>2008</date>
<contexts>
<context position="9882" citStr="Heinrich (2008)" startWordPosition="1528" endWordPosition="1529">d-standard number of schools of thought; Nd − number of sentences in document d. Table 1. Data Sets To simulate the one-sot-per-sentence assumption, we introduce a latent school-of-thought assignment variable cd,s (1 ≤ cd,s ≤ C, where C is the number of schools of thought) for each sentence s in paper d, dependent on which are topic assignment and word occurrence variables. As different papers and their authors have different foci, flavors and writing styles, it is appropriate to assume that each paper d has its own Dirichlet disc tribution of schools of thought π  d  Dir α ( ) c (refer to Heinrich (2008) for Dirichlet analysis of texts). cd,s is thus multinomially sampled from πd , that is, , c c d s Mutl π d  ( ) c . Step 2. Background word emission (A3). Before choosing a word wd,s,n to deliver scientific ideas, the authors first need to determine whether this word describes domain backgrounds or depicts a specific school-of-thought. This information is indicated by the latent background word indicator variable bd,s,n  Bern π d , where ( ) bπ d Beta α α is the probability of Bernoulli b ( 0 , 1 ) b b test. bd,s,n = 1 means wd,s,n is a background word that is multinomially sampled from </context>
</contexts>
<marker>Heinrich, 2008</marker>
<rawString>Heinrich, G. 2008. Parameter estimation for text analysis. Available at www.arbylon.net/publications/text-est.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Herrera</author>
<author>D C Roberts</author>
<author>N Gulbahce</author>
</authors>
<title>Mapping the evolution of scientific fields.</title>
<date>2010</date>
<journal>PLoS ONE,</journal>
<volume>5</volume>
<issue>5</issue>
<pages>10355</pages>
<contexts>
<context position="3684" citStr="Herrera et al., 2010" startWordPosition="554" endWordPosition="557">ought. If the current citation indexing service can be equipped with school of thought knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the number of schools of thought, characterizing school-of-thought words and categorizing papers into one or several school(s) of thought (if applicable). This paper focuses on the second subproblem and leaves the other two as future work. Particularly, we purpose to investigate whether characteristic schoolof-thought words exist and whether they c</context>
</contexts>
<marker>Herrera, Roberts, Gulbahce, 2010</marker>
<rawString>Herrera, M., Roberts, D. C., and Gulbahce, N. 2010. Mapping the evolution of scientific fields. PLoS ONE, 5(5): e10355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D V Joang</author>
<author>M-Y Kan</author>
</authors>
<title>Towards automatic related work summarization.</title>
<date>2010</date>
<booktitle>In Proc. COLING</booktitle>
<contexts>
<context position="3743" citStr="Joang and Kan, 2010" startWordPosition="562" endWordPosition="565">ed with school of thought knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the number of schools of thought, characterizing school-of-thought words and categorizing papers into one or several school(s) of thought (if applicable). This paper focuses on the second subproblem and leaves the other two as future work. Particularly, we purpose to investigate whether characteristic schoolof-thought words exist and whether they can be automatically characterized. To answer these question</context>
</contexts>
<marker>Joang, Kan, 2010</marker>
<rawString>Joang, C. D. V., and Kan, M.-Y. (2010). Towards automatic related work summarization. In Proc. COLING 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Li</author>
<author>J Jiang</author>
<author>Y Wang</author>
</authors>
<title>Generating templates of entity summaries with an entity-aspect model and pattern mining.</title>
<date>2010</date>
<booktitle>In Proc. ACL’10,</booktitle>
<pages>640--649</pages>
<contexts>
<context position="21084" citStr="Li et al. (2010)" startWordPosition="3332" endWordPosition="3335">010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic processing unit, for example in the text scanning approach simulating human reading process by Xu and Zhuge (2013). Indeed, sentence-level school of thought assignment is crucial to SOT as it allows SOT to model the scientific authoring process. There are also other works that model text semantics on dif</context>
</contexts>
<marker>Li, Jiang, Wang, 2010</marker>
<rawString>Li, P., Jiang, J., and Wang, Y. 2010. Generating templates of entity summaries with an entity-aspect model and pattern mining. In Proc. ACL’10, 640– 649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lin</author>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>A Hauptmann</author>
</authors>
<title>Which side are you on? Identifying perspectives at the document and sentence levels.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL’06,</booktitle>
<pages>109--116</pages>
<contexts>
<context position="20608" citStr="Lin et al., 2006" startWordPosition="3257" endWordPosition="3260"> (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful</context>
</contexts>
<marker>Lin, Wilson, Wiebe, Hauptmann, 2006</marker>
<rawString>Lin, W., Wilson, T., Wiebe, J., and Hauptmann, A. 2006. Which side are you on? Identifying perspectives at the document and sentence levels. In Proc. CoNLL’06, 109–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Schütze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2009</date>
<journal>Ch.</journal>
<volume>16</volume>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="18828" citStr="Manning et al. (2009)" startWordPosition="2960" endWordPosition="2963">ve Results To see the usefulness of school-of-thought words, we use the SOT model as a way to feature space reduction for a more precise text representation in the school-of-thought clustering task. A subset of school-of-thought words whose accumulated probability exceeds a given threshold fsThr are used as the reduced feature vector. Text is represented in the vector space model weighted using tf⋅idf. K-means is used for clustering. To obtain a stable and reliable result, we choose 300 random seeds as initial cluster centroids, run K-means 300 times and, following the heuristic suggestion by Manning et al. (2009), output the best clustering by the minimum residual squared sum principle. Two baselines are the “RAW” method without dimension reduction and LDA-based (Blei et al., 2003) feature selection. Table 3 reports the F-measure values of different competitors. In the parentheses are the corresponding threshold values under which the reported clustering result is obtained. The larger the threshold value is, the less effective the method in dimension reduction. Compared to the baselines, SOT has consistently the best clustering qualities. When fsThr ≤ 0.70, the feature space is reduced from several th</context>
</contexts>
<marker>Manning, Raghavan, Schütze, 2009</marker>
<rawString>Manning, C. D., Raghavan, P., and Schütze, H. 2009. Introduction to Information Retrieval. Ch. 16. Flat Clustering. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
<author>C Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proc. WWW’07,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="20638" citStr="Mei et al., 2007" startWordPosition="3262" endWordPosition="3265">ght clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific doma</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Mei, Q., Ling, X., Wondra, M., Su, H., and Zhai, C. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proc. WWW’07, 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mimno</author>
<author>A McCallum</author>
</authors>
<title>Expertise modeling for matching papers with reviewers.</title>
<date>2007</date>
<booktitle>In Proc. SIGKDD’07,</booktitle>
<pages>500--509</pages>
<contexts>
<context position="20337" citStr="Mimno and McCallum, 2007" startWordPosition="3209" endWordPosition="3212">MEASURE (β = 2.0) DATA SETS RAW LDA (fsThr) SOT (fsThr) RE .7464 .7464 (.50) .7482 (.60) NP .4528 .6150 (.75) .6911 (.75) PP .3256 .4179 (.60) .6025 (.75) TE .2580 .5148(.60) .9405 (.40) WA .3125 .4569 (.80) .5519 (.60) DP .4787 .6762 (.80) .7155 (.50) LR .5413 .5276 (.95) .6583 (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. S</context>
</contexts>
<marker>Mimno, McCallum, 2007</marker>
<rawString>Mimno, D., and McCallum, A. 2007. Expertise modeling for matching papers with reviewers. In Proc. SIGKDD’07, 500–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paul</author>
<author>R Girju</author>
</authors>
<title>A two-dimensional topic-aspect model for discovering multi-faceted topics.</title>
<date>2010</date>
<booktitle>In Proc. AAAI’10,</booktitle>
<pages>545--550</pages>
<contexts>
<context position="20783" citStr="Paul and Girju, 2010" startWordPosition="3286" endWordPosition="3289">d on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic proc</context>
</contexts>
<marker>Paul, Girju, 2010</marker>
<rawString>Paul, M., and Girju, R. 2010. A two-dimensional topic-aspect model for discovering multi-faceted topics. In Proc. AAAI’10, 545–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Qazvinian</author>
<author>D R Radev</author>
<author>S M Mohammad</author>
<author>B Dorr</author>
<author>D Zajic</author>
<author>M Whidby</author>
<author>T Moon</author>
</authors>
<title>Generating extractive summaries of scientific paradigms.</title>
<date>2013</date>
<journal>J. Artif. Intell. Res.,</journal>
<volume>46</volume>
<pages>165--201</pages>
<contexts>
<context position="3768" citStr="Qazvinian et al., 2013" startWordPosition="566" endWordPosition="569">ught knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the number of schools of thought, characterizing school-of-thought words and categorizing papers into one or several school(s) of thought (if applicable). This paper focuses on the second subproblem and leaves the other two as future work. Particularly, we purpose to investigate whether characteristic schoolof-thought words exist and whether they can be automatically characterized. To answer these questions, we propose the probabi</context>
</contexts>
<marker>Qazvinian, Radev, Mohammad, Dorr, Zajic, Whidby, Moon, 2013</marker>
<rawString>Qazvinian, V., Radev, D. R., Mohammad, S. M., Dorr, B., Zajic, D., Whidby, M., and Moon T. (2013). Generating extractive summaries of scientific paradigms. J. Artif. Intell. Res., 46: 165–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
</authors>
<title>The Structure of Scientific Articles.</title>
<date>2010</date>
<publisher>CLSI Publications,</publisher>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="1675" citStr="Teufel (2010)" startWordPosition="237" endWordPosition="238">t words for either the general background of a school of thought or the original ideas each paper contributes to its school of thought. Narrative and quantitative experiments show positive and promising results to the questions raised above. 1 Introduction With more powerful computational analysis tools, researchers are now devoting efforts to establish a “science of better science” by analyzing the ecosystem of scientific discovery (Goth, 2012). Amongst this ambition, school of thought analysis has been identified an important fine-grained scientific knowledge discovery task. As mentioned by Teufel (2010), it is important for an experienced scientist to know which papers belong to which school of thought (or technical route) through years of knowledge accumulation. Schools of thought typically emerge with the evolution of a research domain or scientific topic. * Corresponding author. Figure 1. The citation graph of the reachability indexing domain (c.f. the RE data set in Table 1). Take reachability indexing for example, which we will repeatedly turn to later, there are two schools of thought, the cover-based (since about 1990) and hop-based (since the beginning of the 2000s) methods. Most of </context>
</contexts>
<marker>Teufel, 2010</marker>
<rawString>Teufel, S. 2010. The Structure of Scientific Articles. CLSI Publications, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proc. WWW’08,</booktitle>
<pages>111--120</pages>
<contexts>
<context position="21789" citStr="Titov and McDonald (2008)" startWordPosition="3451" endWordPosition="3454">eneralpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic processing unit, for example in the text scanning approach simulating human reading process by Xu and Zhuge (2013). Indeed, sentence-level school of thought assignment is crucial to SOT as it allows SOT to model the scientific authoring process. There are also other works that model text semantics on different levels other than words or tokens, such as Wallach (2006) on n-grams and Titov and McDonald (2008) on words within multinomially sampled sliding windows. The latter also distinguishes between different levels of topics, say global versus local topics, while in SOT such discrimination is generality versus originality topics. 5 Conclusion This paper proposes a probabilistic generative model SOT for characterizing school-of-thought words. In SOT, a school of thought is modeled as a distribution of topics, with the latter defined as a distribution of topical words. School of thought assignment to each sentence is vital as it allows SOT to simulate the scientific authoring process in which each</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Titov, I., and McDonald R. 2008. Modeling online reviews with multi-grain topic models. In Proc. WWW’08, 111–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tu</author>
<author>N Johri</author>
<author>D Roth</author>
<author>J Hockenmaier</author>
</authors>
<title>Citation author topic model in expert search.</title>
<date>2010</date>
<booktitle>In Proc. COLING’10,</booktitle>
<pages>1265--1273</pages>
<contexts>
<context position="20472" citStr="Tu et al., 2010" startWordPosition="3233" endWordPosition="3236">6025 (.75) TE .2580 .5148(.60) .9405 (.40) WA .3125 .4569 (.80) .5519 (.60) DP .4787 .6762 (.80) .7155 (.50) LR .5413 .5276 (.95) .6583 (.75) Table 3. School-of-thought clustering results 4 Related Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li e</context>
</contexts>
<marker>Tu, Johri, Roth, Hockenmaier, 2010</marker>
<rawString>Tu, Y., Johri, N., Roth, D., and Hockenmaier, J. 2010. Citation author topic model in expert search. In Proc. COLING’10, 1265–1273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P Upham</author>
<author>L Rosenkopf</author>
<author>L H Ungar</author>
</authors>
<title>Positioning knowledge: schools of thought and new knowledge creation.</title>
<date>2010</date>
<journal>Scientometrics,</journal>
<volume>83</volume>
<issue>2</issue>
<pages>555--581</pages>
<contexts>
<context position="3340" citStr="Upham et al., 2010" startWordPosition="506" endWordPosition="509">e about school of thought. Current citation indexing services are not very helpful for this kind of knowledge discovery tasks. As explained in Figure 1, papers of different schools of thought cite each other heavily and form a rather dense citation graph. An extreme example is p14, which cites more hop-based papers than its own school of thought. If the current citation indexing service can be equipped with school of thought knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the nu</context>
</contexts>
<marker>Upham, Rosenkopf, Ungar, 2010</marker>
<rawString>Upham, S. P., Rosenkopf, L., Ungar, L. H. 2010. Positioning knowledge: schools of thought and new knowledge creation. Scientometrics, 83 (2): 555– 581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wallach</author>
</authors>
<title>Topic modeling: beyond bag-ofwords.</title>
<date>2006</date>
<booktitle>In Proc. ICML’06, 977–</booktitle>
<pages>984</pages>
<contexts>
<context position="18116" citStr="Wallach, 2006" startWordPosition="2849" endWordPosition="2850">ound as labels and assigned to “Lout” and “Lin” of certain “contour” vertices. “contour” is used by hop-based methods as a concise representation of the remaining to-be-encoded reachability information. The underlined bold italic words such as “set” and “cover” are misleading (yet not necessarily erroneous) words as both schools of thought use them heavily, but in quite different contexts, for example, a “set” of labels versus “set cover”, and “cover(s)” partial reachability information versus tree “cover”. To improve, one of our future works shall integrate multi-word expressions or n-grams (Wallach, 2006) and syntactic analysis (Griffiths et al., 2004) into the current model. 825 3.3 Quantitative Results To see the usefulness of school-of-thought words, we use the SOT model as a way to feature space reduction for a more precise text representation in the school-of-thought clustering task. A subset of school-of-thought words whose accumulated probability exceeds a given threshold fsThr are used as the reduced feature vector. Text is represented in the vector space model weighted using tf⋅idf. K-means is used for clustering. To obtain a stable and reliable result, we choose 300 random seeds as i</context>
<context position="21748" citStr="Wallach (2006)" startWordPosition="3446" endWordPosition="3447"> not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic processing unit, for example in the text scanning approach simulating human reading process by Xu and Zhuge (2013). Indeed, sentence-level school of thought assignment is crucial to SOT as it allows SOT to model the scientific authoring process. There are also other works that model text semantics on different levels other than words or tokens, such as Wallach (2006) on n-grams and Titov and McDonald (2008) on words within multinomially sampled sliding windows. The latter also distinguishes between different levels of topics, say global versus local topics, while in SOT such discrimination is generality versus originality topics. 5 Conclusion This paper proposes a probabilistic generative model SOT for characterizing school-of-thought words. In SOT, a school of thought is modeled as a distribution of topics, with the latter defined as a distribution of topical words. School of thought assignment to each sentence is vital as it allows SOT to simulate the s</context>
</contexts>
<marker>Wallach, 2006</marker>
<rawString>Wallach, H. 2006. Topic modeling: beyond bag-ofwords. In Proc. ICML’06, 977– 984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Xu</author>
<author>H Zhuge</author>
</authors>
<title>A text scanning mechanism simulating human reading process,</title>
<date>2013</date>
<booktitle>In Proc. IJCAI’13.</booktitle>
<contexts>
<context position="21493" citStr="Xu and Zhuge (2013)" startWordPosition="3401" endWordPosition="3404">rent assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. What’s more these works all model on a word level. However, it is very useful to regard sentence as the basic processing unit, for example in the text scanning approach simulating human reading process by Xu and Zhuge (2013). Indeed, sentence-level school of thought assignment is crucial to SOT as it allows SOT to model the scientific authoring process. There are also other works that model text semantics on different levels other than words or tokens, such as Wallach (2006) on n-grams and Titov and McDonald (2008) on words within multinomially sampled sliding windows. The latter also distinguishes between different levels of topics, say global versus local topics, while in SOT such discrimination is generality versus originality topics. 5 Conclusion This paper proposes a probabilistic generative model SOT for ch</context>
</contexts>
<marker>Xu, Zhuge, 2013</marker>
<rawString>Xu, B., and Zhuge, H. 2013. A text scanning mechanism simulating human reading process, In Proc. IJCAI’13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhao</author>
<author>J Jiang</author>
<author>H Yan</author>
<author>X Li</author>
</authors>
<title>Jointly modeling aspects and opinions with a MaxEntLDA hybrid.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP’10, 56–</booktitle>
<pages>65</pages>
<contexts>
<context position="20671" citStr="Zhao et al., 2010" startWordPosition="3268" endWordPosition="3271"> Work An early work in semantic analysis of scientific articles is Griffiths and Steyvers (2004) which focused on efficient browsing of large literature collections based on scientific topics. Other related researches include topic-based reviewer assignment (Mimno and McCallum, 2007), citation influence estimation (Dietz et al., 2007), research topic evolution (Hall et al., 2008) and expert finding (Tu et al., 2010) etc. Another line of research is the joint modeling of topics and other types of semantic units such as perspectives (Lin et al., 2006), sentiment (Mei et al., 2007) and opinions (Zhao et al., 2010) etc. These works also took a multi-dimensional view of document semantics. The TAM model (Paul and Girju, 2010) might be the most relevant to SOT. TAM simultaneously models aspects and topics with different assumptions from SOT and it models purely on word level. Studies that introduce an explicit background distribution include Chemudugunta et al. (2006), Haghighi and Vanderwende (2009), and Li et al. (2010) etc. Different from these works, SOT assumes that not only some “meaningless” generalpurpose words but also more meaningful words about the specific domain backgrounds can be learned. Wh</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Zhao, X., Jiang, J., Yan, H., and Li, X. 2010. Jointly modeling aspects and opinions with a MaxEntLDA hybrid. In Proc. EMNLP’10, 56– 65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhuge</author>
</authors>
<title>Discovery of knowledge flow in science.</title>
<date>2006</date>
<journal>Commun. ACM,</journal>
<volume>49</volume>
<issue>5</issue>
<pages>101--107</pages>
<contexts>
<context position="3616" citStr="Zhuge, 2006" startWordPosition="546" endWordPosition="547">hich cites more hop-based papers than its own school of thought. If the current citation indexing service can be equipped with school of thought knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the number of schools of thought, characterizing school-of-thought words and categorizing papers into one or several school(s) of thought (if applicable). This paper focuses on the second subproblem and leaves the other two as future work. Particularly, we purpose to investigate wh</context>
</contexts>
<marker>Zhuge, 2006</marker>
<rawString>Zhuge, H. 2006. Discovery of knowledge flow in science. Commun. ACM, 49(5): 101-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhuge</author>
</authors>
<title>The Knowledge Grid: Toward Cyber-Physical Society (2nd edition). World Scientific Publishing Company, Singapore. Appendices A Survey Papers for Building Data Sets</title>
<date>2012</date>
<contexts>
<context position="3630" citStr="Zhuge, 2012" startWordPosition="548" endWordPosition="549">re hop-based papers than its own school of thought. If the current citation indexing service can be equipped with school of thought knowledge, it will help scientists, especially novice researchers, a lot in grasping the core ideas of a scientific domain quickly and making their own way of innovation (Upham et al., 2010). School of thought analysis is also useful for knowledge 822 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822–828, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics flow discovery (Zhuge, 2006; Zhuge, 2012), knowledge mapping (Chen, 2004; Herrera et al., 2010) and scientific paradigm summarization (Joang and Kan, 2010; Qazvinian et al., 2013) etc. This paper makes the first attempts to unsupervised school of thought analysis. Three main aspects of school of thought analysis can be identified: determining the number of schools of thought, characterizing school-of-thought words and categorizing papers into one or several school(s) of thought (if applicable). This paper focuses on the second subproblem and leaves the other two as future work. Particularly, we purpose to investigate whether characte</context>
</contexts>
<marker>Zhuge, 2012</marker>
<rawString>Zhuge, H. 2012. The Knowledge Grid: Toward Cyber-Physical Society (2nd edition). World Scientific Publishing Company, Singapore. Appendices A Survey Papers for Building Data Sets</rawString>
</citation>
<citation valid="true">
<authors>
<author>P X Yu</author>
<author>J Cheng</author>
</authors>
<date>2010</date>
<journal>Managing and Mining Graph Data, Ch.</journal>
<volume>6</volume>
<pages>181--215</pages>
<publisher>Springer.</publisher>
<marker>Yu, Cheng, 2010</marker>
<rawString>[RE] Yu, P. X., and Cheng, J. 2010. Managing and Mining Graph Data, Ch. 6, 181–215. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proc. ACL’10,</booktitle>
<pages>1396--1141</pages>
<marker>Ng, 2010</marker>
<rawString>[NP] Ng, V. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proc. ACL’10, 1396–1141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Madnani</author>
<author>B J Dorr</author>
</authors>
<title>Generating phrasal and sentential paraphrases: A survey of data-driven methods.</title>
<date>2010</date>
<journal>Comput. Linguist.,</journal>
<volume>36</volume>
<issue>3</issue>
<pages>341--387</pages>
<marker>Madnani, Dorr, 2010</marker>
<rawString>[PP] Madnani, N., and Dorr, B. J. 2010. Generating phrasal and sentential paraphrases: A survey of data-driven methods. Comput. Linguist., 36 (3): 341–387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Comput. Surv.,</journal>
<volume>40</volume>
<issue>3</issue>
<pages>pages.</pages>
<marker>Lopez, 2008</marker>
<rawString>[TE/WA] Lopez, A. 2008. Statistical machine translation. ACM Comput. Surv., 40(3), Article 8, 49 pages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kübler</author>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Dependency parsing,</title>
<date>2009</date>
<journal>Ch.</journal>
<volume>3</volume>
<pages>21--78</pages>
<publisher>Morgan &amp; Claypools Publishers.</publisher>
<marker>Kübler, McDonald, Nivre, 2009</marker>
<rawString>[DP] Kübler, S., McDonald, R., and Nivre, J. 2009. Dependency parsing, Ch. 3–5, 21–78. Morgan &amp; Claypools Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Y Liu</author>
</authors>
<title>Learning to rank for information retrieval,</title>
<date>2011</date>
<journal>Ch.</journal>
<volume>2</volume>
<pages>33--88</pages>
<publisher>Springer.</publisher>
<marker>Liu, 2011</marker>
<rawString>[LR] Liu, T. Y. 2011. Learning to rank for information retrieval, Ch. 2–4, 33–88. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>