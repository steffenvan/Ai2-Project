<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.99734">
Contrasting Syntagmatic and Paradigmatic Relations:
Insights from Distributional Semantic Models
</title>
<author confidence="0.970172">
Gabriella Lapesa3,1
</author>
<affiliation confidence="0.484442">
1Universit¨at Osnabr¨uck
Institut f¨ur
Kognitionswissenschaft
</affiliation>
<email confidence="0.963124">
glapesa@uos.de
</email>
<author confidence="0.836507">
Stefan Evert2
</author>
<affiliation confidence="0.356913333333333">
2FAU Erlangen-N¨urnberg
Professur f¨ur
Korpuslinguistik
</affiliation>
<email confidence="0.978754">
stefan.evert@fau.de
</email>
<author confidence="0.838403">
Sabine Schulte im Walde3
</author>
<affiliation confidence="0.529350333333333">
3Universit¨at Stuttgart
Institut f¨ur Maschinelle
Sprachverarbeitung
</affiliation>
<email confidence="0.984878">
schulte@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.993492" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999991217391304">
This paper presents a large-scale evalua-
tion of bag-of-words distributional models
on two datasets from priming experiments
involving syntagmatic and paradigmatic
relations. We interpret the variation in
performance achieved by different settings
of the model parameters as an indication
of which aspects of distributional patterns
characterize these types of relations. Con-
trary to what has been argued in the litera-
ture (Rapp, 2002; Sahlgren, 2006) – that
bag-of-words models based on second-
order statistics mainly capture paradig-
matic relations and that syntagmatic rela-
tions need to be gathered from first-order
models – we show that second-order mod-
els perform well on both paradigmatic and
syntagmatic relations if their parameters
are properly tuned. In particular, our re-
sults show that size of the context window
and dimensionality reduction play a key
role in differentiating DSM performance
on paradigmatic vs. syntagmatic relations.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999906285714286">
Distributional takes on the representation and ac-
quisition of word meaning rely on the assump-
tion that words with similar meaning tend to oc-
cur in similar contexts: this assumption, known as
distributional hypothesis, has been first proposed
by Harris (1954). Distributional Semantic Mod-
els (henceforth, DSMs) are computational mod-
els that operationalize the distributional hypoth-
esis; they produce semantic representations for
words in the form of distributional vectors record-
ing patterns of co-occurrence in large samples of
language data (Sahlgren, 2006; Baroni and Lenci,
2010; Turney and Pantel, 2010). Comparison be-
tween distributional vectors allows the identifica-
tion of shared contexts as an empirical correlate of
the semantic similarity between the target words.
As noted in Sahlgren (2008), the notion of seman-
tic similarity applied in distributional approaches
to meaning is an easy target of criticism, as it is
employed to capture a wide range of semantic re-
lations, such as synonymy, antonymy, hypernymy,
up to topical relatedness.
The study presented in this paper contributes
to the debate concerning the nature of the seman-
tic representations built by DSMs, and it does so
by comparing the performance of several DSMs
in a classification task conducted on priming data
and involving paradigmatic and syntagmatic rela-
tions. Paradigmatic relations hold between words
that occur in similar contexts; they are also called
relations in absentia (Sahlgren, 2006) because
paradigmatically related words do not co-occur.
Examples of paradigmatic relations are synonyms
(e.g., frigid–cold) and antonyms (e.g., cold–hot).
Syntagmatic relations hold between words that co-
occur (relations in praesentia) and therefore ex-
hibit a similar distribution across contexts. Typi-
cal examples of syntagmatic relations are phrasal
associates (e.g., help–wanted) and syntactic collo-
cations (e.g., dog–bark).
Distributional modeling has already tackled the
issue of paradigmatic and syntagmatic relations
(Sahlgren, 2006; Rapp, 2002). Key contributions
of the present work are the scope of its evaluation
(in terms of semantic relations and model parame-
ters) and the new perspective on paradigmatic vs.
syntagmatic models provided by our results.
Concerning the scope of the evaluation, this is
the first study in which the comparison involves
such a wide range of semantic relations (paradig-
matic: synonyms, antonyms and co-hyponyms;
syntagmatic: syntactic collocations, backward and
forward phrasal associates). Moreover, our eval-
uation covers a large number of DSM parame-
ters: source corpus, size and direction of the con-
text window, criteria for feature selection, feature
</bodyText>
<page confidence="0.963037">
160
</page>
<note confidence="0.9809685">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 160–170,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999520962962963">
weighting, dimensionality reduction and index of
distributional relatedness. We consider the varia-
tion in performance achieved by different parame-
ter settings as a cue towards characteristic aspects
of specific relations (or groups of relations).
Our work also differs from previous studies
(Sahlgren, 2006; Rapp, 2002) in its focus on
second-order models. We aim to show that they
are able to capture both paradigmatic and syn-
tagmatic relations with appropriate parameter set-
tings. In addition, this focus provides a uniform
experimental design for the evaluation. For ex-
ample, parameters like window size and direction-
ality apply to bag-of-words DSMs and colloca-
tion lists but not to term-context models; dimen-
sionality reduction, whose effect has not yet been
explored systematically in the context of syntag-
matic and paradigmatic relations, is not applicable
to collocation lists.
This paper is structured as follows. Section 2
summarizes previous work. Section 3 describes
the experimental setup, in terms of task, datasets
and evaluated parameters. Section 4 introduces
our model selection methodology. Section 5
presents the results of our evaluation study. Sec-
tion 6 summarizes main findings and sketches on-
going and future work.
</bodyText>
<sectionHeader confidence="0.996193" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999801">
In this section we discuss previous work relevant
to the distributional modeling of paradigmatic and
syntagmatic relations. For space constraints, we
focus only on two studies (Rapp, 2002; Sahlgren,
2006) in which the two classes of relations are
compared at a global level, and not on studies
that are concerned with specific semantic rela-
tions, e.g., synonymy (Edmonds and Hirst, 2002;
Curran, 2003), hypernymy (Weeds et al., 2004;
Lenci and Benotto, 2012) or syntagmatic predicate
preferences (McCarthy and Carroll, 2003; Erk et
al., 2010), etc.
In previous studies, the comparison of syntag-
matic and paradigmatic relations has been imple-
mented in terms of an opposition between differ-
ent classes of corpus-based models: term-context
models (words as targets, documents or context re-
gions as features) vs. bag-of-words models (words
as targets and features) in Sahlgren (2006); col-
location lists vs. bag-of-words models in Rapp
(2002). Given the high terminological variation
in the literature, in this paper we will adopt the
labels syntagmatic and paradigmatic to character-
ize different types of semantic relations, and we
will use the labels first-order and second-order
to characterize corpus-based models with respect
to the kind of co-occurrence information they en-
code. We will refer to collocation lists and term-
document DSMs as first-order models, and to bag-
of-words DSMs as second-order models1.
Rapp (2002) integrates first-order (co-
occurrence lists) and second-order (bag-of-words
DSMs) information to distinguish syntagmatic
and paradigmatic relations. Under the assumption
that paradigmatically related words will be found
among the closest neighbors of a target word in
the DSM space and that paradigmatically and syn-
tagmatically related words will be intermingled
in the list of collocates of the target word, Rapp
proposes to exploit a comparison of the most
salient collocates and the nearest DSM neighbors
to distinguish between the two types of relations.
Sahlgren (2006) compares term-context and
bag-of-words DSMs in a number of tasks involv-
ing syntagmatic and paradigmatic relations. First,
a comparison between the thesaurus entries for tar-
get words (containing both paradigmatically and
syntagmatically related words) and neighbors in
the distributional spaces is conducted. It shows
that, while term-context DSMs produce both syn-
tagmatically and paradigmatically related words,
the nearest neighbors in a bag-of-words DSM
mainly provide paradigmatic information. Bag-
of-words models also performed better than term-
context models in predicting association norms,
in the TOEFL multiple-choice synonymy task and
in the prediction of antonyms (although the dif-
ference in performance was less significant here).
Last, word neighborhoods are analysed in terms of
their part-of-speech distribution. Sahlgren (2006)
observes that bag-of-words spaces contain more
neighbors with the same part of speech as the tar-
get than term-context spaces. He concludes that
bag-of-words spaces privilege paradigmatic rela-
tions, based on the assumption that paradigmati-
cally related word pairs belong to the same part of
speech, while this is not necessarily the case for
syntagmatically related word pairs.
</bodyText>
<footnote confidence="0.997214142857143">
1Term-document models encode first-order information
because dot products between row vectors are related to co-
occurrence counts of the corresponding words (within docu-
ments). More precisely, for a binary term-document matrix,
cosine similarity is identical to the square root of the MI as-
sociation measure. Please note that our terminology differs
from that of Sch¨utze (1998) and Peirsman et al. (2008).
</footnote>
<page confidence="0.997924">
161
</page>
<bodyText confidence="0.999153888888889">
Summing up, in both Rapp (2002) and Sahlgren
(2006) it is claimed that second-order models per-
form poorly in predicting syntagmatic relations.
However, neither of those studies involves datasets
containing exclusively syntagmatic relations, as
the evaluation focuses either on paradigmatic rela-
tions (TOEFL multiple choice test, antonymy test)
or on resources containing both types of relations
(thesauri, association norms).
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="method">
3 Experimental Setting
</sectionHeader>
<subsectionHeader confidence="0.999985">
3.1 Evaluation Task and Data
</subsectionHeader>
<bodyText confidence="0.999696837837838">
In this study, bag-of-words DSMs are evaluated on
two datasets containing experimental items from
two priming studies. Each item is a word triple
(target, consistent prime, inconsistent prime) with
a particular semantic relation between target and
consistent prime. Following previous work on
modeling priming effects as a comparison between
prime-target pairs (McDonald and Brew, 2004;
Pad´o and Lapata, 2007; Herda˘gdelen et al., 2009),
we evaluate our models in a classification task.
The goal is to identify the consistent prime on the
basis of its distributional relatedness to the tar-
get: if a particular DSM (i.e., a certain parame-
ter combination) is sensitive to a specific relation
(or group of relations), we expect the consistent
primes to be closer to the target in semantic space
than the inconsistent ones.
The first dataset is derived from the Semantic
Priming Project (SPP) (Hutchison et al., 2013).
To the best of our knowledge, our study repre-
sents the first evaluation of bag-of-words DSMs
on items from this dataset. The original data con-
sist of 1661 word triples (target, consistent prime,
inconsistent prime) collected within a large-scale
project aiming at characterizing English words in
terms of a set of lexical and associative/semantic
characteristics, along with behavioral data from
visual lexical decision and naming studies2. We
manually discarded all triples containing proper
nouns, adverbs or inflected words. We then
selected five subsets involving different seman-
tic relations, namely: synonyms (SYN), 436
triples (example of a consistent prime and tar-
get: frigid–cold); antonyms (ANT): 135 triples
(e.g., hot–cold); cohyponyms (COH): 159 triples
(e.g., table–chair); forward phrasal associates
(FPA): 144 triples (e.g., help–wanted); back-
</bodyText>
<footnote confidence="0.982747">
2The dataset is available at http://spp.montana.edu/
</footnote>
<bodyText confidence="0.994122848484849">
ward phrasal associates (BPA): 89 triples (e.g.,
wanted–help).
The second priming dataset is the Generalized
Event Knowledge dataset (henceforth GEK), al-
ready evaluated in Lapesa and Evert (2013): a
collection of 402 triples (target, consistent prime,
inconsistent prime) from three priming studies
conducted to demonstrate that event knowledge
is responsible for facilitation of the processing
of words that denote events and their partici-
pants. The first study was conducted by Fer-
retti et al. (2001), who found that verbs facili-
tate the processing of nouns denoting prototypi-
cal participants in the depicted event and of ad-
jectives denoting features of prototypical partic-
ipants. The study covered five thematic rela-
tions: agent (e.g., pay–customer), patient, fea-
ture of the patient, instrument, location. The sec-
ond study (McRae et al., 2005) focussed on prim-
ing from nouns to verbs. It involved four re-
lations: agent (e.g., reporter–interview), patient,
instrument, location. The third study (Hare et
al., 2009) investigated priming from nouns to
nouns, referring to participants of the same event
or the event itself. The dataset involves seven
relations: event-people (e.g., trial–judge), event-
thing, location-living, location-thing, people-
instrument, instrument-people, instrument-thing.
In the presentation of our results we group syn-
onyms with antonyms and cohyponyms from SPP
as paradigmatic relations, and the entire GEK
dataset with backward and forward phrasal asso-
ciates from SPP as syntagmatic relations.
</bodyText>
<subsectionHeader confidence="0.995552">
3.2 Evaluated Parameters
</subsectionHeader>
<bodyText confidence="0.999823272727273">
DSMs evaluated in this paper belong to the class of
bag-of-words models. We defined a large vocab-
ulary of target words (27522 lemma types) con-
taining all the items from the evaluated datasets
as well as items from other state-of-the-art evalu-
ation studies (Baroni and Lenci, 2010; Baroni and
Lenci, 2011). Context words were filtered by part-
of-speech (nouns, verbs, adjectives, and adverbs).
Distributional models were built using the UCS
toolkit3 and the wordspace package for R4. The
following parameters have been evaluated:
</bodyText>
<listItem confidence="0.997862666666667">
• Source corpus (abbreviated as corpus in plots
1-4): We compiled DSMs from three corpora
often used in DSM evaluation studies and that
</listItem>
<footnote confidence="0.9999005">
3http://www.collocations.de/software.html
4http://r-forge.r-project.org/projects/wordspace/
</footnote>
<page confidence="0.994626">
162
</page>
<bodyText confidence="0.570016">
differ in both size and quality: British National
Corpus5, ukWaC, and WaCkypedia EN6.
</bodyText>
<listItem confidence="0.979497857142857">
• Size of the context window (win.size): As
this parameter quantifies the amount of shared
context involved in the computation of similar-
ity, we expect it to be crucial in determining
whether syntagmatic or paradigmatic relations
are captured. We therefore use a finer granu-
larity for window size than Lapesa and Evert
(2013): 1, 2, 4, 8 and 16 words.
• Directionality of the context window
(win.direction): When collecting co-occurrence
information from the source corpora, we use ei-
ther a directed window (i.e., separate frequency
counts for co-occurrences of a context term
to the left and to the right of the target term)
or an undirected window (i.e., no distinction
between left and right context when collecting
co-occurrence counts).
• Context selection: From the full co-occurrence
matrix collected as described above, we select
dimensions (columns) according to the follow-
ing parameters:
</listItem>
<bodyText confidence="0.866394">
– Criterion for context selection (criterion):
We select the top-ranked dimensions either
according to marginal frequency (i.e., we use
the most frequent words as context terms)
or number of nonzero co-occurrence counts
(i.e., we use the context terms that co-occur
with the highest number of targets).
– Number of context dimensions (con-
text.dim): We select the top-ranked 5000,
10000, 20000, 50000 or 100000 dimensions,
according to the criterion above.
</bodyText>
<listItem confidence="0.9944931">
• Feature scoring (score): Co-occurrence counts
are weighted using one of the following associa-
tion measures: frequency, Dice coefficient, sim-
ple log-likelihood, Mutual Information, t-score,
z-score or tf.idf.7
• Feature transformation (transformation): A
transformation function may be applied to re-
duce the skewness of feature scores. Possible
transformations are: none, square root, logarith-
mic and sigmoid.
</listItem>
<footnote confidence="0.914785375">
5http://www.natcorp.ox.ac.uk/
6Both ukWaC and WaCkypedia EN are available at:
wacky.sslmit.unibo.it/doku.php?id=corpora
7See Evert (2008) for a description of these measures and
details on the calculation of association scores. Note that
we compute “sparse” versions of the association measures
(where negative values are clamped to zero) in order to pre-
serve the sparseness of the co-occurrence matrix.
</footnote>
<listItem confidence="0.7964365">
• Distance metric (metric): We apply cosine dis-
tance (i.e., angle between vectors) or Manhattan
distance.
• Dimensionality reduction: We apply singular
value decomposition in order to project distri-
butional vectors to a relatively small number of
latent dimensions and compare the results to the
unreduced runs8. For the SVD-based models,
there are two additional parameters:
– Number of latent dimensions (red.dim):
</listItem>
<bodyText confidence="0.995487363636364">
Whether to use the first 100, 300, 500, 700
or 900 latent dimensions from the SVD anal-
ysis.
– Number of skipped dimensions (dim.skip):
When selecting latent dimensions, we option-
ally skip the first 50 or 100 SVD compo-
nents. This parameter was inspired by Bul-
linaria and Levy (2012), who found that dis-
carding the initial components of the reduced
matrix, i.e. the SVD components with highest
variance, improves evaluation results.
</bodyText>
<listItem confidence="0.647711">
• Index of distributional relatedness (rel.index):
</listItem>
<bodyText confidence="0.999093333333333">
We propose two alternative ways of quantify-
ing the degree of relatedness between two words
a and b represented in a DSM. The first op-
tion (and standard in distributional modeling)
is to compute the distance (cosine or Manhat-
tan) between the vectors of a and b. The sec-
ond option, proposed in this work, is based on
neighbor rank, i.e. we determine the rank of
the target among the nearest neighbors of each
prime. We expect that the target will occur in a
higher position among the neighbors of the con-
sistent prime than among those of the inconsis-
tent prime. Since this corresponds to a lower
numeric rank value for the consistent prime, we
can treat neighbor rank as a measure of dissim-
ilarity. Neighbor rank is particularly interesting
as an index of relatedness because, unlike a dis-
tance metric, it can capture asymmetry effects9.
</bodyText>
<sectionHeader confidence="0.998687" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.988131">
In our evaluation study, we tested all the possible
combinations of the parameters listed in section
8For efficiency reasons, we use randomized SVD (Halko
et al., 2009) with a sufficiently high oversampling factor to
ensure a good approximation.
9Note that our use of neighbor rank is fully consistent with
the experimental design (primes are shown before targets).
See Lapesa and Evert (2013) for an analysis of the perfor-
mance of neighbor rank as a predictor of priming and discus-
sion of the implications of using rank in cognitive modeling.
</bodyText>
<page confidence="0.994672">
163
</page>
<bodyText confidence="0.999884875">
3.2, resulting in a total of 537600 different model
runs (33600 in the setting without dimensionality
reduction, 504000 in the dimensionality-reduced
setting). The models were generated and evaluated
on a large HPC cluster within approx. 4 weeks.
Our methodology for model selection follows
the proposal of Lapesa and Evert (2013), who con-
sider DSM parameters as predictors of model per-
formance. We analyze the influence of individual
parameters and their interactions using general lin-
ear models with performance (percent accuracy)
as a dependent variable and the model parame-
ters as independent variables, including all two-
way interactions. Analysis of variance – which
is straightforward for our full factorial design – is
used to quantify the importance of each parameter
or interaction. Robust optimal parameter settings
are identified with the help of effect displays (Fox,
2003), which marginalize over all the parameters
not shown in a plot and thus allow an intuitive in-
terpretation of the effect sizes of categorical vari-
ables irrespective of the dummy coding scheme.
For each dataset, a separate linear model was
fitted. The results are reported and compared in
section 5. Table 1 lists the global goodness-of-fit
(R2) on each dataset, for the reduced and unre-
duced runs. Despite some variability across re-
lations and between unreduced and reduced runs,
the R2 values are always high (≥ 75%), showing
that the linear model explains a large part of the
observed performance differences. It is therefore
justified to base our analysis on the linear models.
</bodyText>
<table confidence="0.999217428571429">
Relation Dataset Unreduced Reduced
Syntagmatic GEK 93% 87%
Syntagmatic FPA 90% 79%
Syntagmatic BPA 88% 77%
Paradigmatic SYN 92% 85%
Paradigmatic COH 89% 75%
Paradigmatic ANT 89% 76%
</table>
<tableCaption confidence="0.999127">
Table 1: Evaluation, Global R2
</tableCaption>
<sectionHeader confidence="0.999123" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999600363636364">
In this section, we present the results of our study.
We begin by looking at the distribution of accu-
racy for different datasets, and by comparing re-
duced and unreduced experimental runs in terms
of minimum, maximum and mean performance.
The results displayed in table 2 show that di-
mensionality reduction with SVD improves the
performance of the models for all datasets but
GEK. We conclude that the information lost by ap-
plying SVD reduction (namely, meaningful distri-
butional features, which are replaced by the gener-
</bodyText>
<table confidence="0.999130125">
Relation Dataset Unreduced Min Reduced
Min Max Mean Max Mean
Syntagmatic GEK 54.8 98.4 86.6 48.0 97.0 80.8
Syntagmatic FPA 41.0 98.0 82.3 43.0 98.6 82.1
Syntagmatic BPA 49.4 97.7 83.8 41.6 98.9 83.9
Paradigmatic SYN 54.8 98.4 86.6 57.3 99.0 88.2
Paradigmatic COH 49.0 100.0 92.6 54.3 100.0 94.0
Paradigmatic ANT 69.6 100.0 94.2 57.8 100.0 94.3
</table>
<tableCaption confidence="0.995658">
Table 2: Distribution of Accuracy
</tableCaption>
<bodyText confidence="0.999445833333333">
alization encoded in the reduced dimensions) is ir-
relevant to other tasks, but crucial for modeling the
relations in the GEK dataset. This interpretation is
consistent with the detrimental effect of SVD in
tasks involving vector composition reported in the
literature (Baroni and Zamparelli, 2010).
</bodyText>
<subsectionHeader confidence="0.999189">
5.1 Importance of Parameters
</subsectionHeader>
<bodyText confidence="0.999992166666667">
To obtain further insights into DSM performance
we explore the effect of specific model parameters,
comparing syntagmatic vs. paradigmatic relations
and reduced vs. unreduced runs.
In order to establish a ranking of the parameters
according to their importance wrt. model perfor-
mance, we use a feature ablation approach. The
ablation value for a given parameter is the propor-
tion of variance (R2) explained by this parameter
together with all its interactions, corresponding to
the reduction in adjusted R2 of the linear model fit
if the parameter were left out. In other words, it
allows us to find out whether a certain parameter
has a substantial effect on model performance (on
top of all other parameters). Figures 1 to 4 display
the feature ablation values of all the evaluated pa-
rameters in the unreduced and reduced setting, for
paradigmatic and syntagmatic relations. Parame-
ters are ranked according to their average feature
ablation values in each setting.
Two parameters, namely feature score and fea-
ture transformation, are consistently crucial in
determining DSM performance, both in reduced
and unreduced runs, and for both paradigmatic
and syntagmatic relations. In the next section we
will show that it is possible to identify optimal (or
nearly optimal) values for those parameters that
are constant across relations.
A comparison of figures 1 and 2 with figures 3
and 4 allows us to identify parameters that lose
or gain explanatory power when SVD comes into
play. Feature ablation shows that the effect of the
index of distributional relatedness is substan-
tially smaller in the SVD-reduced runs, but this pa-
rameter still plays an important role. On the other
hand, two parameters gain explanatory power in a
</bodyText>
<page confidence="0.976415">
164
</page>
<figure confidence="0.999315434782609">
score
rel.index
transformation
metric
corpus
win.size
context.dim
win.direction
criterion
●
●
●
SYN
● ANT
COH
●
●
●
●
●
●
0 20 40 60
Feature Ablation
</figure>
<figureCaption confidence="0.983678">
Figure 1: Paradigmatic, unreduced
</figureCaption>
<figure confidence="0.99972886">
●
●
SYN
● ANT
COH
●
●
●
●
●
●
●
●
●
0 10 2030
Feature Ablation
score
transformation
corpus
metric
red.dim
win.size
rel.index
dim.skip
context.dim
win.direction
criterion
score
rel.index
win.size
●
●
criterion
●
●
●
●
●
●
GEK
● FPA
BPA
●
context.dim
win.direction
transformation
metric
corpus
0 20 40 60
Feature Ablation
</figure>
<figureCaption confidence="0.649084">
Figure 2: Syntagmatic, unreduced
</figureCaption>
<figure confidence="0.999584555555555">
●
GEK
● FPA
BPA
●
●
●
●
●
●
●
●
●
●
0 10 20 30
Feature Ablation
score
transformation
win.size
corpus
metric
red.dim
dim.skip
rel.index
context.dim
win.direction
criterion
</figure>
<figureCaption confidence="0.999846">
Figure 3: Paradigmatic, reduced Figure 4: Syntagmatic, reduced
</figureCaption>
<bodyText confidence="0.999435823529412">
SVD-reduced setting: the size of the context win-
dow and the source corpus. Optimal values are
discussed in section 5.2.
Three parameters consistently have little or no
explanatory power: directionality of the con-
text window, criterion for context selection and
number of context dimensions.
We conclude this section by comparing rela-
tions within groups. Within paradigmatic rela-
tions, we note a significant drop in explanatory
power for the relatedness index when it comes to
antonyms. Within syntagmatic relations, the size
of the context window appears to be more crucial
on the GEK dataset than it is for FPA and BPA:
in the next section, the analysis of the best choices
for this parameter will provide a clue for the inter-
pretation of this opposition.
</bodyText>
<subsectionHeader confidence="0.999856">
5.2 Best Parameter Values
</subsectionHeader>
<bodyText confidence="0.999905166666667">
In this section, we identify the best parameter val-
ues for syntagmatic and paradigmatic relations by
inspecting partial effects plots10. Our discussion
starts from the parameters that contribute to the
leading topic of this paper, namely the comparison
between syntagmatic and paradigmatic relations:
</bodyText>
<footnote confidence="0.97911175">
10The partial effect plots in figures 5 to 12 display param-
eter values on the x-axis and their effect size in terms of pre-
dicted accuracy on the y-axis (see section 4 for more details
concerning the calculation of effect size).
</footnote>
<bodyText confidence="0.999625285714286">
window size, parameters related to dimensionality
reduction, and relatedness index.
As already anticipated in the feature ablation
analysis, the size of the context window plays
a crucial role in contrasting syntagmatic and
paradigmatic relations, as well as different rela-
tions within those general groups. The plots in fig-
ures 5 and 6 display its partial effect for paradig-
matic relations in the unreduced and reduced set-
tings, respectively. The plots in figures 7 and 8
display its partial effect for syntagmatic relations.
When no dimensionality reduction is involved, a
very small context window (i.e., one word) is suffi-
cient for all paradigmatic relations, and DSM per-
formance decreases as soon as we enlarge the con-
text window. The picture changes when apply-
ing dimensionality reduction: a 4-word window
is a robust choice for all paradigmatic relations
(although ANT show a further increase in perfor-
mance with an 8-word window), even in the SYN
task that is traditionally associated with very small
windows of 1 or 2 words (cf. Sahlgren (2006)).
A significant interaction between window size
and number of skipped dimensions (not shown for
reasons of space) sheds further light on this matter.
Without skipping SVD dimensions, the reduced
models achieve optimal performance for a 2-word
window and degrade more (COH) or less (ANT)
</bodyText>
<page confidence="0.988971">
165
</page>
<figure confidence="0.998892195652174">
●
●
96
●
●
●
●
●
●
●
dataset
● SYN
● ANT
●COH
●
●
●
●
●
●
93
90
87
84
1 2 4 8 16
●
●
●
90
●
●
1 2 4 8 16
96
93
●
●
●
● ●
● ●
●
dataset
● SYN
● ANT
●COH
87
84
</figure>
<figureCaption confidence="0.991013">
Figure 5: Window, paradigmatic, unreduced Figure 6: Window, paradigmatic, reduced
</figureCaption>
<figure confidence="0.999362653846154">
86
84
82
80
78
76
74
1 2 4 8 16
dataset
●GEK
● FPA
● BPA
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
86
84
82
80
78
76
74
1 2 4 8 16
dataset
●GEK
● FPA
● BPA
●
●
●
●
●
●
●
●
● ●
●
●
●
●
</figure>
<figureCaption confidence="0.999990333333333">
Figure 7: Window, syntagmatic, unreduced
Figure 7: Window, syntagmatic, unreduced Figure 8: Window, syntagmatic, reduced
Figure 8: Window, syntagmatic, reduced
</figureCaption>
<bodyText confidence="0.996562064516129">
quickly for larger windows. With 50 or 100 di-
seems to be more similar to the syntagmatic rela-
quickly for larger windows. With 50 or 100 di- seems to be more similar to the syntagmatic rela-
mensions skipped, performance improves up to a
tions than SYN and COH. This is in line with the
mensions skipped, performance improves up to a tions than SYN and COH. This is in line with the
4- or 8-word window. Our interpretation is that the
observations of Justeson and Katz (1992) concern-
4- or 8-word window. Our interpretation is that the observations of Justeson and Katz (1992) concern-
first SVD dimensions capture general domain and
ing the tendency of antonyms to co-occur (e.g., in
first SVD dimensions capture general domain and ing the tendency of antonyms to co-occur (e.g., in
topic information dominating the co-occurrence
coordinations such as short and long). Like syn-
topic information dominating the co-occurrence coordinations such as short and long). Like syn-
data; removing these dimensions reveals paradig-
onyms, antonyms are interchangeable in absentia;
data; removing these dimensions reveals paradig- onyms, antonyms are interchangeable in absentia;
matic semantic relations even for larger windows.
but they also enter into syntagmatic patterns that
matic semantic relations even for larger windows. but they also enter into syntagmatic patterns that
For syntagmatic relations without dimensionality
are uncommon for synonyms.
For syntagmatic relations without dimensionality are uncommon for synonyms.
reduction, a larger context window of 4 words is
reduction, a larger context window of 4 words is We now focus on the parameters related to di-
We now focus on the parameters related to di-
needed for FPA and BPA; a further increase of the
needed for FPA and BPA; a further increase of the mensionality reduction, namely the number of la-
mensionality reduction, namely the number of la-
window is detrimental. For the GEK dataset, per-
window is detrimental. For the GEK dataset, per- tent dimensions (figures 9 and 10) and the num-
tent dimensions (figures 9 and 10) and the num-
formance peaks at 8 words, and decreases only
formance peaks at 8 words, and decreases only ber of skipped dimensions (figures 11 and 12).
ber of skipped dimensions (figures 11 and 12).
minimally for even larger windows. Again, di-
minimally for even larger windows. Again, di- These parameters represent an extension of the
These parameters represent an extension of the
mensionality reduction improves performance for
mensionality reduction improves performance for experiments conducted on the GEK dataset by
experiments conducted on the GEK dataset by
large co-occurrence windows. For FPA and BPA,
large co-occurrence windows. For FPA and BPA, Lapesa and Evert (2013). They have already been
Lapesa and Evert (2013). They have already been
the optimum seems to be achieved with a win-
the optimum seems to be achieved with a win- applied by Bullinaria and Levy (2012) to a differ-
applied by Bullinaria and Levy (2012) to a differ-
dow of 4–8 words; performance on GEK contin-
dow of 4–8 words; performance on GEK contin- ent set of tasks, including the TOEFL multiple-
ent set of tasks, including the TOEFL multiple-
ues to increase up to 16 words, the largest win-
ues to increase up to 16 words, the largest win- choice synonymy task. In particular, Bullinaria
choice synonymy task. In particular, Bullinaria
dow size considered in our experiments. Such pat-
dow size considered in our experiments. Such pat- and Levy found that discarding the initial SVD di-
and Levy found that discarding the initial SVD di-
terns reflect differences in the nature of the se-
terns reflect differences in the nature of the se- mensions (with highest variance) leads to substan-
mensions (with highest variance) leads to substan-
mantic relations involved: smaller windows pro-
mantic relations involved: smaller windows pro- tial improvements, especially in the TOEFL task.
tial improvements, especially in the TOEFL task.
vide better contextual representations for paradig-
vide better contextual representations for paradig- In our experiments, we found no difference be-
In our experiments, we found no difference be-
matic relations while larger windows are needed to
matic relations while larger windows are needed to tween syntagmatic and paradigmatic relations wrt.
tween syntagmatic and paradigmatic relations wrt.
capture syntagmatic relations with bag-of-words
capture syntagmatic relations with bag-of-words the number of latent dimensions: the more, the
the number of latent dimensions: the more, the
DSMs (because co-occurring words then share a
DSMs (because co-occurring words then share a better in both cases (900 dimensions). The number
better in both cases (900 dimensions). The number
large portion of their context windows). Interme-
large portion of their context windows). Interme- of skipped dimensions, however, shows some vari-
of skipped dimensions, however, shows some vari-
diate window sizes are sufficient for phrasal col-
diate window sizes are sufficient for phrasal col- ability across the different relations. The results
ability across the different relations. The results
locates (which are usually adjacent), while event-
locates (which are usually adjacent), while event- for SYN are in agreement with the findings of Bul-
for SYN are in agreement with the findings of Bul-
based relatedness (GEK) requires larger windows.
based relatedness (GEK) requires larger windows. linaria and Levy (2012) on TOEFL: skipping 50
linaria and Levy (2012) on TOEFL: skipping 50
Returning briefly to the slight preference shown
Returning briefly to the slight preference shown or 100 initial dimensions improves performance.
or 100 initial dimensions improves performance.
by ANT for a larger window, we notice that ANT
by ANT for a larger window, we notice that ANT Skipping dimensions makes minimal difference
Skipping dimensions makes minimal difference
</bodyText>
<page confidence="0.993496">
166
</page>
<figure confidence="0.99395662745098">
96
93
100 300 500 700 900
●
●
●
●
●
●
●
●
●
●
dataset
● SYN
● ANT
● COH
●
●
●
●
●
90
87
dataset
●GEK
● FPA
● BPA
100 300
●
●
●
●
●
●
500 700 900
●
●
●
●
●
●
●
●
●
86
84
82
80
78
76
</figure>
<figureCaption confidence="0.993097">
Figure 9: Latent dimensions, paradigmatic Figure 10: Latent dimensions, syntagmatic
</figureCaption>
<figure confidence="0.998782294117647">
●
●
●
●
0 50 100
dataset
● SYN
● ANT
● COH
●
●
●
95
93
91
89
87
0 50 100
84
83
82
81
80
dataset
● GEK
● FPA
● BPA
●
●
●
●
●
●
●
</figure>
<figureCaption confidence="0.999969666666667">
Figure 11: Skipped dimensions, paradigmatic
Figure 11: Skipped dimensions, paradigmatic Figure 12: Skipped dimensions, syntagmatic
Figure 12: Skipped dimensions, syntagmatic
</figureCaption>
<bodyText confidence="0.995745935483871">
for COH (best choice is 50 dimensions), while the
A very strong interaction between score and
for COH (best choice is 50 dimensions), while the A very strong interaction between score and
full range of reduced dimensions is necessary for
transformation characterizes all four settings
full range of reduced dimensions is necessary for transformation characterizes all four settings
ANT. Within syntagmatic relations, the full range
(paradigmatic or syntagmatic datasets, reduced or
ANT. Within syntagmatic relations, the full range (paradigmatic or syntagmatic datasets, reduced or
of latent dimensions ensures good performance on
unreduced experimental runs). Association mea-
of latent dimensions ensures good performance on unreduced experimental runs). Association mea-
phrasal associates (even if skipping 50 dimensions
sures outperform raw co-occurrence frequency.
phrasal associates (even if skipping 50 dimensions sures outperform raw co-occurrence frequency.
is not detrimental for BPA). GEK shows a pattern
Measures based on significance tests (simple-ll,
is not detrimental for BPA). GEK shows a pattern Measures based on significance tests (simple-ll,
similar to SYN, with 50 skipped dimensions lead-
t-score, z-score) are better than Dice, and to a
similar to SYN, with 50 skipped dimensions lead- t-score, z-score) are better than Dice, and to a
ing to a considerable improvement.
lesser extent, MI. Simple-ll is the best choice in
ing to a considerable improvement. lesser extent, MI. Simple-ll is the best choice in
combination with a logarithmic transformation for
We now inspect the best values for the related- combination with a logarithmic transformation for
We now inspect the best values for the related-
paradigmatic relations, z-score appears to be the
ness index. As shown in figure 13 for the unre- paradigmatic relations, z-score appears to be the
ness index. As shown in figure 13 for the unre-
best measure for syntagmatic relations in combi-
duced runs and in figure 14 for the reduced runs, best measure for syntagmatic relations in combi-
duced runs and in figure 14 for the reduced runs,
nation with a square root transformation. The dif-
neighbor rank is consistently better than distance nation with a square root transformation. The dif-
neighbor rank is consistently better than distance
ference is small, however, and simple-ll with log
on all datasets. This is not surprising because, as ference is small, however, and simple-ll with log
on all datasets. This is not surprising because, as
transformation works well across all datasets. On-
discussed in section 3.2, our use of neighbor rank transformation works well across all datasets. On-
discussed in section 3.2, our use of neighbor rank
going experiments with standard tasks show a sim-
captures asymmetry and mirrors the experimental going experiments with standard tasks show a sim-
captures asymmetry and mirrors the experimental
ilar pattern, suggesting that this combination of
setting, in which targets are shown after primes. ilar pattern, suggesting that this combination of
setting, in which targets are shown after primes.
score and transformation parameters is appropri-
A further observation may be made relating to the score and transformation parameters is appropri-
A further observation may be made relating to the
ate for DSMs, regardless of the task involved.
degree of asymmetry of different relations. The ate for DSMs, regardless of the task involved.
degree of asymmetry of different relations. The
unreduced setting in particular shows that syntag-
unreduced setting in particular shows that syntag- The optimal distance metric is the cosine
The optimal distance metric is the cosine
matic relations are subject to stronger asymme-
matic relations are subject to stronger asymme- distance, consistently outperforming Manhattan.
distance, consistently outperforming Manhattan.
try effects than the paradigmatic ones, presumably
try effects than the paradigmatic ones, presumably Concerning source corpus, BNC consistently
Concerning source corpus, BNC consistently
due to the directional nature of the relations in-
due to the directional nature of the relations in- yields the worst results, while WaCkypedia and
yields the worst results, while WaCkypedia and
volved (phrasal associates and syntactic colloca-
volved (phrasal associates and syntactic colloca- ukWaC appear to be almost equivalent in the unre-
ukWaC appear to be almost equivalent in the unre-
tions). Among paradigmatic relations, antonyms
tions). Among paradigmatic relations, antonyms duced runs. The trade-off between quality and
duced runs. The trade-off between quality and
appear to be the least asymmetric ones (because
appear to be the least asymmetric ones (because quantity appears to be strongly biased towards
quantity appears to be strongly biased towards
using neighbor rank instead of distance makes a
using neighbor rank instead of distance makes a sheer corpus size in the case of distributional mod-
sheer corpus size in the case of distributional mod-
comparatively small difference).
comparatively small difference). els. For syntagmatic relations and SVD-reduced
els. For syntagmatic relations and SVD-reduced
We conclude by briefly summarizing the opti-
models, ukWaC is clearly the best choice. This
We conclude by briefly summarizing the opti- models, ukWaC is clearly the best choice. This
mal choices for the remaining parameters. The
suggests that syntagmatic relations are better cap-
mal choices for the remaining parameters. The suggests that syntagmatic relations are better cap-
corresponding partial effects plots are not shown
tured by features from a larger lexical inventory,
corresponding partial effects plots are not shown tured by features from a larger lexical inventory,
because of space constraints.
combined with the abstraction performed by SVD.
because of space constraints. combined with the abstraction performed by SVD.
</bodyText>
<page confidence="0.980841">
167
</page>
<figure confidence="0.448879">
SYN ANT COH GEK FPA BPA
</figure>
<figureCaption confidence="0.997807">
Figure 13: Relatedness index, unreduced
</figureCaption>
<bodyText confidence="0.999950142857143">
Concerning minimally explanatory parameters,
inspection of partial effect plots supported the
choice of “unmarked” default values for direc-
tionality of the context window (i.e., undirected)
and criterion for context selection (i.e., fre-
quency), as well as an intermediate number of
context dimensions (i.e., 50000 dimensions).
</bodyText>
<subsectionHeader confidence="0.99775">
5.3 Best Settings
</subsectionHeader>
<bodyText confidence="0.99996725">
We conclude by comparing the performance
achieved by our robust choice of optimal param-
eter values (“best setting”) from section 5.2 with
the performance of the best model for each dataset.
For space constraints, the analysis of best settings
focuses on the reduced experimental runs. Our
best settings, shown in table 3, perform fairly well
on the respective datasets11.
</bodyText>
<table confidence="0.985579285714286">
dataset corpus win score transf r.dim d.sk acc best
GEK ukwac 16 s-ll log 900 50 96.0 97.0
FPA ukwac 8 z-sc root 900 0 93.0 98.6
BPA ukwac 8 z-sc root 900 0 95.5 98.9
SYN ukwac 4 s-ll log 900 50 96.3 99.0
COH ukwac 4 s-ll log 900 50 98.7 100
ANT wacky 8 s-ll log 900 0 100 100
</table>
<tableCaption confidence="0.98628">
Table 3: Best settings: datasets, parameter values,
accuracy (acc), accuracy of the best model (best)
</tableCaption>
<table confidence="0.96722075">
best setting corpus win score transf r.dim d.sk
Syntagmatic ukwac 8 z-sc root 900 0
Paradigmatic ukwac 4 s-ll log 900 50
General ukwac 4 s-ll log 900 0
</table>
<tableCaption confidence="0.996688">
Table 4: General best settings: parameter values
</tableCaption>
<table confidence="0.999790857142857">
Dataset Best Synt. Best Para. General
GEK 92.5 94.8 91.3
FPA 93.0 90.2 91.7
BPA 95.5 97.7 95.5
SYN 94.4 96.3 96.3
COH 99.3 98.7 98.7
ANT 99.2 99.2 99.2
</table>
<tableCaption confidence="0.999691">
Table 5: General best settings: accuracy
</tableCaption>
<bodyText confidence="0.661983833333333">
11Abbreviations in tables 3 and 4: win = window size;
transf = transformation; z-sc = z-score; s-ll = simple-ll; r.dim
= number of latent dimensions; d.sk = number of skipped di-
mensions. Parameters with fixed values for all datasets: num-
ber of context dimensions = 50k; direction = undirected; cri-
terion = frequency; metric = cosine; relatedness index = rank.
</bodyText>
<figureCaption confidence="0.99393">
Figure 14: Relatedness index, reduced
</figureCaption>
<bodyText confidence="0.99996925">
As a next step, we identified parameter combi-
nations that work well for all types of syntagmatic
and paradigmatic relations, as well as an even
more general setting that is suitable for paradig-
matic and syntagmatic relations alike. Best set-
tings are shown in table 4, their performance on
each dataset is reported in table 5. General models
achieve fairly good performance on all relations.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999945">
We presented a large-scale evaluation study of
bag-of-words DSMs on a classification task de-
rived from priming experiments. The leading
theme of our study is a comparison between syn-
tagmatic and paradigmatic relations in terms of
the aspects of distributional similarity that char-
acterize them. Our results show that second-order
DSMs are capable of capturing both syntagmatic
and paradigmatic relations, if parameters are prop-
erly tuned. Size of the co-occurrence window as
well as parameters connected to dimensionality re-
duction play a key role in adapting DSMs to par-
ticular relations. Even if we do not address the
more specific task of distinguishing between rela-
tions (e.g., synonyms vs. antonyms; see Scheible
et al. (2013) and references therein), we believe
that such applications may benefit from our de-
tailed analyses on the effects of DSM parameters.
Ongoing and future work is concerned with the
expansion of the evaluation setting to other classes
of models (first-order models, dependency-based
second-order models) and parameters (e.g., di-
mensionality reduction with Random Indexing).
</bodyText>
<sectionHeader confidence="0.998297" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998710833333333">
We are grateful to Ken MacRae for providing us
the GEK priming data and to the three review-
ers. This research was funded by the DFG Col-
laborative Research Centre SFB 732 (Gabriella
Lapesa) and the DFG Heisenberg Fellowship
SCHU-2580/1-1 (Sabine Schulte im Walde).
</bodyText>
<figure confidence="0.98838605">
rel.index
● dist
● rank
●
●
●
●
●
●
●
●
●
●
●
95
90
85
80
75
rel.index
● dist
● rank
●
●
●
●
●
●
●
●
●
●
●
●
SYN ANT COH GEK FPA BPA
95
90
85
80
75
</figure>
<page confidence="0.985478">
168
</page>
<sectionHeader confidence="0.994643" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684271028037">
Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional memory: A general framework for
corpus-based semantics. Computational Linguis-
tics, 36(4):1–49.
Marco Baroni and Alessandro Lenci. 2011. How
we BLESSed distributional semantic evaluation. In
Proceedings of the GEMS 2011 Workshop on GE-
ometrical Models of Natural Language Semantics,
pages 1–10.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
1183–1193.
John A. Bullinaria and Joseph P. Levy. 2012. Ex-
tracting semantic representations from word co-
occurrence statistics: stop-lists, stemming and svd.
Behavior Research Methods, 44:890–907.
James Curran. 2003. From distributional to semantic
similarity. Ph.D. thesis, Institute for Communicat-
ing and Collaborative Systems, School of Informat-
ics, University of Edinburgh.
Philip Edmonds and Graeme Hirst. 2002. Near-
synonymy and lexical choice. Computational Lin-
guistics, 28(2):105–144.
Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
flexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics,
36(4):723–763.
Stefan Evert. 2008. Corpora and collocations. In Anke
L¨udeling and Merja Kyt¨o, editors, Corpus Linguis-
tics. An International Handbook, chapter 58. Mou-
ton de Gruyter, Berlin, New York.
Todd Ferretti, Ken McRae, and Ann Hatherell. 2001.
Integrating verbs, situation schemas, and thematic
role concepts. Journal of Memory and Language,
44(4):516–547.
John Fox. 2003. Effect displays in R for gener-
alised linear models. Journal of Statistical Software,
8(15):1–27.
Nathan Halko, Per-Gunnar Martinsson, and Joel A.
Tropp. 2009. Finding structure with randomness:
Stochastic algorithms for constructing approximate
matrix decompositions. Technical Report 2009-05,
ACM, California Institute of Technology.
Mary Hare, Michael Jones, Caroline Thomson, Sarah
Kelly, and Ken McRae. 2009. Activating event
knowledge. Cognition, 111(2):151–167.
Zelig Harris. 1954. Distributional structure. Word,
10(23):146–162.
Amac Herda˘gdelen, Marco Baroni, and Katrin Erk.
2009. Measuring semantic relatedness with vector
space models and random walks. In Proceedings
of the 2009 Workshop on Graph-based Methods for
Natural Language Processing, pages 50–53.
Keith A. Hutchison, David A. Balota, James H. Neely,
Michael J. Cortese, Emily R. Cohen-Shikora, Chi-
Shing Tse, Melvin J. Yap, Jesse J. Bengson, Dale
Niemeyer, and Erin Buchanan. 2013. The seman-
tic priming project. Behavior Research Methods,
45(4):1099–1114.
John. S. Justeson and Slava M. Katz. 1992. Redefining
antonymy: The textual structure of a semantic rela-
tion. Literary and Linguistic Computing, 7(3):176–
184.
Gabriella Lapesa and Stefan Evert. 2013. Evaluat-
ing neighbor rank and distance measures as predic-
tors of semantic priming. In Proceedings of the
ACL Workshop on Cognitive Modeling and Compu-
tational Linguistics (CMCL 2013), pages 66–74.
Alessandro Lenci and Giulia Benotto. 2012. Identi-
fying hypernyms in distributional semantic spaces.
In Proceedings of *SEM 2012: The First Joint Con-
ference on Lexical and Computational Semantics –
Volume 1, pages 75–79.
Diana McCarthy and John Carroll. 2003. Disam-
biguating nouns, verbs and adjectives using auto-
matically acquired selectional preferences. Compu-
tational Linguistics, 29(4):639–654.
Scott McDonald and Chris Brew. 2004. A distri-
butional model of semantic context effects in lexi-
cal processing. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 17–24.
Ken McRae, Mary Hare, Jeffrey L. Elman, and Todd
Ferretti. 2005. A basis for generating expectan-
cies for verbs from nouns. Memory &amp; Cognition,
33(7):1174–1184.
Sebastian Pad´o and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33(2):161–199.
Yves Peirsman, Kris Heylen, and Dirk Speelman.
2008. Putting things in order. First and second order
context models for the calculation of semantic sim-
ilarity. In JADT 2008: 9es Journ´ees internationales
d’Analyse statistique des Donn´ees Textuelles.
Reinhard Rapp. 2002. The computation of word asso-
ciations: Comparing syntagmatic and paradigmatic
approaches. In Proceedings of the 19th Interna-
tional Conference on Computational Linguistics -
Volume 1, pages 1–7.
Magnus Sahlgren. 2006. The word-space model: Us-
ing distributional analysis to represent syntagmatic
and paradigmatic relations between words in high-
dimensional vector spaces. Ph.D. thesis, University
of Stockolm.
</reference>
<page confidence="0.986115">
169
</page>
<reference confidence="0.99954019047619">
Magnus Sahlgren. 2008. The distributional hypothe-
sis. Rivista di Linguistica (Italian Journal of Lin-
guistics), 20(1):33–53.
Silke Scheible, Sabine Schulte im Walde, and Sylvia
Springorum. 2013. Uncovering Distributional Dif-
ferences between Synonyms and Antonyms in a
Word Space Model. In Proceedings of the 6th In-
ternational Joint Conference on Natural Language
Processing, pages 489—497.
Hinrich Sch¨utze. 1998. Automatic word sense dis-
crimination. Computational Linguistics, 27(1):97–
123.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37:141–188.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional
similarity. In Proceedings of the 20th International
Conference of Computational Linguistics, pages
1015–1021, Geneva, Switzerland.
</reference>
<page confidence="0.997428">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.025967">
<title confidence="0.774899666666667">Contrasting Syntagmatic and Paradigmatic Insights from Distributional Semantic Models Institut</title>
<author confidence="0.341743">Kognitionswissenschaft</author>
<email confidence="0.77153">glapesa@uos.de</email>
<abstract confidence="0.837976161290323">Professur Korpuslinguistik stefan.evert@fau.de Schulte im Institut f¨ur Sprachverarbeitung schulte@ims.uni-stuttgart.de Abstract This paper presents a large-scale evaluation of bag-of-words distributional models on two datasets from priming experiments involving syntagmatic and paradigmatic relations. We interpret the variation in performance achieved by different settings of the model parameters as an indication of which aspects of distributional patterns characterize these types of relations. Contrary to what has been argued in the literature (Rapp, 2002; Sahlgren, 2006) – that bag-of-words models based on secondorder statistics mainly capture paradigmatic relations and that syntagmatic relations need to be gathered from first-order models – we show that second-order models perform well on both paradigmatic and syntagmatic relations if their parameters are properly tuned. In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>Distributional memory: A general framework for corpus-based semantics.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<contexts>
<context position="1957" citStr="Baroni and Lenci, 2010" startWordPosition="262" endWordPosition="265">s. syntagmatic relations. 1 Introduction Distributional takes on the representation and acquisition of word meaning rely on the assumption that words with similar meaning tend to occur in similar contexts: this assumption, known as distributional hypothesis, has been first proposed by Harris (1954). Distributional Semantic Models (henceforth, DSMs) are computational models that operationalize the distributional hypothesis; they produce semantic representations for words in the form of distributional vectors recording patterns of co-occurrence in large samples of language data (Sahlgren, 2006; Baroni and Lenci, 2010; Turney and Pantel, 2010). Comparison between distributional vectors allows the identification of shared contexts as an empirical correlate of the semantic similarity between the target words. As noted in Sahlgren (2008), the notion of semantic similarity applied in distributional approaches to meaning is an easy target of criticism, as it is employed to capture a wide range of semantic relations, such as synonymy, antonymy, hypernymy, up to topical relatedness. The study presented in this paper contributes to the debate concerning the nature of the semantic representations built by DSMs, and</context>
<context position="13205" citStr="Baroni and Lenci, 2010" startWordPosition="1933" endWordPosition="1936">ing, location-living, location-thing, peopleinstrument, instrument-people, instrument-thing. In the presentation of our results we group synonyms with antonyms and cohyponyms from SPP as paradigmatic relations, and the entire GEK dataset with backward and forward phrasal associates from SPP as syntagmatic relations. 3.2 Evaluated Parameters DSMs evaluated in this paper belong to the class of bag-of-words models. We defined a large vocabulary of target words (27522 lemma types) containing all the items from the evaluated datasets as well as items from other state-of-the-art evaluation studies (Baroni and Lenci, 2010; Baroni and Lenci, 2011). Context words were filtered by partof-speech (nouns, verbs, adjectives, and adverbs). Distributional models were built using the UCS toolkit3 and the wordspace package for R4. The following parameters have been evaluated: • Source corpus (abbreviated as corpus in plots 1-4): We compiled DSMs from three corpora often used in DSM evaluation studies and that 3http://www.collocations.de/software.html 4http://r-forge.r-project.org/projects/wordspace/ 162 differ in both size and quality: British National Corpus5, ukWaC, and WaCkypedia EN6. • Size of the context window (win</context>
</contexts>
<marker>Baroni, Lenci, 2010</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2010. Distributional memory: A general framework for corpus-based semantics. Computational Linguistics, 36(4):1–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>How we BLESSed distributional semantic evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="13230" citStr="Baroni and Lenci, 2011" startWordPosition="1937" endWordPosition="1940">cation-thing, peopleinstrument, instrument-people, instrument-thing. In the presentation of our results we group synonyms with antonyms and cohyponyms from SPP as paradigmatic relations, and the entire GEK dataset with backward and forward phrasal associates from SPP as syntagmatic relations. 3.2 Evaluated Parameters DSMs evaluated in this paper belong to the class of bag-of-words models. We defined a large vocabulary of target words (27522 lemma types) containing all the items from the evaluated datasets as well as items from other state-of-the-art evaluation studies (Baroni and Lenci, 2010; Baroni and Lenci, 2011). Context words were filtered by partof-speech (nouns, verbs, adjectives, and adverbs). Distributional models were built using the UCS toolkit3 and the wordspace package for R4. The following parameters have been evaluated: • Source corpus (abbreviated as corpus in plots 1-4): We compiled DSMs from three corpora often used in DSM evaluation studies and that 3http://www.collocations.de/software.html 4http://r-forge.r-project.org/projects/wordspace/ 162 differ in both size and quality: British National Corpus5, ukWaC, and WaCkypedia EN6. • Size of the context window (win.size): As this parameter</context>
</contexts>
<marker>Baroni, Lenci, 2011</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2011. How we BLESSed distributional semantic evaluation. In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1183--1193</pages>
<contexts>
<context position="21222" citStr="Baroni and Zamparelli, 2010" startWordPosition="3185" endWordPosition="3188">Mean Max Mean Syntagmatic GEK 54.8 98.4 86.6 48.0 97.0 80.8 Syntagmatic FPA 41.0 98.0 82.3 43.0 98.6 82.1 Syntagmatic BPA 49.4 97.7 83.8 41.6 98.9 83.9 Paradigmatic SYN 54.8 98.4 86.6 57.3 99.0 88.2 Paradigmatic COH 49.0 100.0 92.6 54.3 100.0 94.0 Paradigmatic ANT 69.6 100.0 94.2 57.8 100.0 94.3 Table 2: Distribution of Accuracy alization encoded in the reduced dimensions) is irrelevant to other tasks, but crucial for modeling the relations in the GEK dataset. This interpretation is consistent with the detrimental effect of SVD in tasks involving vector composition reported in the literature (Baroni and Zamparelli, 2010). 5.1 Importance of Parameters To obtain further insights into DSM performance we explore the effect of specific model parameters, comparing syntagmatic vs. paradigmatic relations and reduced vs. unreduced runs. In order to establish a ranking of the parameters according to their importance wrt. model performance, we use a feature ablation approach. The ablation value for a given parameter is the proportion of variance (R2) explained by this parameter together with all its interactions, corresponding to the reduction in adjusted R2 of the linear model fit if the parameter were left out. In oth</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1183–1193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bullinaria</author>
<author>Joseph P Levy</author>
</authors>
<title>Extracting semantic representations from word cooccurrence statistics: stop-lists, stemming and svd. Behavior Research Methods,</title>
<date>2012</date>
<pages>44--890</pages>
<contexts>
<context position="16639" citStr="Bullinaria and Levy (2012)" startWordPosition="2440" endWordPosition="2444">n vectors) or Manhattan distance. • Dimensionality reduction: We apply singular value decomposition in order to project distributional vectors to a relatively small number of latent dimensions and compare the results to the unreduced runs8. For the SVD-based models, there are two additional parameters: – Number of latent dimensions (red.dim): Whether to use the first 100, 300, 500, 700 or 900 latent dimensions from the SVD analysis. – Number of skipped dimensions (dim.skip): When selecting latent dimensions, we optionally skip the first 50 or 100 SVD components. This parameter was inspired by Bullinaria and Levy (2012), who found that discarding the initial components of the reduced matrix, i.e. the SVD components with highest variance, improves evaluation results. • Index of distributional relatedness (rel.index): We propose two alternative ways of quantifying the degree of relatedness between two words a and b represented in a DSM. The first option (and standard in distributional modeling) is to compute the distance (cosine or Manhattan) between the vectors of a and b. The second option, proposed in this work, is based on neighbor rank, i.e. we determine the rank of the target among the nearest neighbors </context>
<context position="29933" citStr="Bullinaria and Levy (2012)" startWordPosition="4661" endWordPosition="4664">or even larger windows. Again, di- These parameters represent an extension of the These parameters represent an extension of the mensionality reduction improves performance for mensionality reduction improves performance for experiments conducted on the GEK dataset by experiments conducted on the GEK dataset by large co-occurrence windows. For FPA and BPA, large co-occurrence windows. For FPA and BPA, Lapesa and Evert (2013). They have already been Lapesa and Evert (2013). They have already been the optimum seems to be achieved with a winthe optimum seems to be achieved with a win- applied by Bullinaria and Levy (2012) to a differapplied by Bullinaria and Levy (2012) to a differdow of 4–8 words; performance on GEK contindow of 4–8 words; performance on GEK contin- ent set of tasks, including the TOEFL multipleent set of tasks, including the TOEFL multipleues to increase up to 16 words, the largest winues to increase up to 16 words, the largest win- choice synonymy task. In particular, Bullinaria choice synonymy task. In particular, Bullinaria dow size considered in our experiments. Such patdow size considered in our experiments. Such pat- and Levy found that discarding the initial SVD diand Levy found that </context>
</contexts>
<marker>Bullinaria, Levy, 2012</marker>
<rawString>John A. Bullinaria and Joseph P. Levy. 2012. Extracting semantic representations from word cooccurrence statistics: stop-lists, stemming and svd. Behavior Research Methods, 44:890–907.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
</authors>
<title>From distributional to semantic similarity.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Institute for Communicating and Collaborative Systems, School of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="5852" citStr="Curran, 2003" startWordPosition="847" endWordPosition="848"> parameters. Section 4 introduces our model selection methodology. Section 5 presents the results of our evaluation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in </context>
</contexts>
<marker>Curran, 2003</marker>
<rawString>James Curran. 2003. From distributional to semantic similarity. Ph.D. thesis, Institute for Communicating and Collaborative Systems, School of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Edmonds</author>
<author>Graeme Hirst</author>
</authors>
<title>Nearsynonymy and lexical choice.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="5837" citStr="Edmonds and Hirst, 2002" startWordPosition="843" endWordPosition="846">k, datasets and evaluated parameters. Section 4 introduces our model selection methodology. Section 5 presents the results of our evaluation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the </context>
</contexts>
<marker>Edmonds, Hirst, 2002</marker>
<rawString>Philip Edmonds and Graeme Hirst. 2002. Nearsynonymy and lexical choice. Computational Linguistics, 28(2):105–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
<author>Ulrike Pad´o</author>
</authors>
<title>A flexible, corpus-driven model of regular and inverse selectional preferences.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<marker>Erk, Pad´o, Pad´o, 2010</marker>
<rawString>Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A flexible, corpus-driven model of regular and inverse selectional preferences. Computational Linguistics, 36(4):723–763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>Corpora and collocations.</title>
<date>2008</date>
<booktitle>In Anke L¨udeling and Merja Kyt¨o, editors, Corpus Linguistics. An International Handbook, chapter 58. Mouton de Gruyter,</booktitle>
<location>Berlin, New York.</location>
<contexts>
<context position="15674" citStr="Evert (2008)" startWordPosition="2289" endWordPosition="2290">, 50000 or 100000 dimensions, according to the criterion above. • Feature scoring (score): Co-occurrence counts are weighted using one of the following association measures: frequency, Dice coefficient, simple log-likelihood, Mutual Information, t-score, z-score or tf.idf.7 • Feature transformation (transformation): A transformation function may be applied to reduce the skewness of feature scores. Possible transformations are: none, square root, logarithmic and sigmoid. 5http://www.natcorp.ox.ac.uk/ 6Both ukWaC and WaCkypedia EN are available at: wacky.sslmit.unibo.it/doku.php?id=corpora 7See Evert (2008) for a description of these measures and details on the calculation of association scores. Note that we compute “sparse” versions of the association measures (where negative values are clamped to zero) in order to preserve the sparseness of the co-occurrence matrix. • Distance metric (metric): We apply cosine distance (i.e., angle between vectors) or Manhattan distance. • Dimensionality reduction: We apply singular value decomposition in order to project distributional vectors to a relatively small number of latent dimensions and compare the results to the unreduced runs8. For the SVD-based mo</context>
</contexts>
<marker>Evert, 2008</marker>
<rawString>Stefan Evert. 2008. Corpora and collocations. In Anke L¨udeling and Merja Kyt¨o, editors, Corpus Linguistics. An International Handbook, chapter 58. Mouton de Gruyter, Berlin, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Todd Ferretti</author>
<author>Ken McRae</author>
<author>Ann Hatherell</author>
</authors>
<title>Integrating verbs, situation schemas, and thematic role concepts.</title>
<date>2001</date>
<journal>Journal of Memory and Language,</journal>
<volume>44</volume>
<issue>4</issue>
<contexts>
<context position="11882" citStr="Ferretti et al. (2001)" startWordPosition="1733" endWordPosition="1737">ard phrasal associates (FPA): 144 triples (e.g., help–wanted); back2The dataset is available at http://spp.montana.edu/ ward phrasal associates (BPA): 89 triples (e.g., wanted–help). The second priming dataset is the Generalized Event Knowledge dataset (henceforth GEK), already evaluated in Lapesa and Evert (2013): a collection of 402 triples (target, consistent prime, inconsistent prime) from three priming studies conducted to demonstrate that event knowledge is responsible for facilitation of the processing of words that denote events and their participants. The first study was conducted by Ferretti et al. (2001), who found that verbs facilitate the processing of nouns denoting prototypical participants in the depicted event and of adjectives denoting features of prototypical participants. The study covered five thematic relations: agent (e.g., pay–customer), patient, feature of the patient, instrument, location. The second study (McRae et al., 2005) focussed on priming from nouns to verbs. It involved four relations: agent (e.g., reporter–interview), patient, instrument, location. The third study (Hare et al., 2009) investigated priming from nouns to nouns, referring to participants of the same event</context>
</contexts>
<marker>Ferretti, McRae, Hatherell, 2001</marker>
<rawString>Todd Ferretti, Ken McRae, and Ann Hatherell. 2001. Integrating verbs, situation schemas, and thematic role concepts. Journal of Memory and Language, 44(4):516–547.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Fox</author>
</authors>
<title>Effect displays in R for generalised linear models.</title>
<date>2003</date>
<journal>Journal of Statistical Software,</journal>
<volume>8</volume>
<issue>15</issue>
<contexts>
<context position="19123" citStr="Fox, 2003" startWordPosition="2845" endWordPosition="2846">lection follows the proposal of Lapesa and Evert (2013), who consider DSM parameters as predictors of model performance. We analyze the influence of individual parameters and their interactions using general linear models with performance (percent accuracy) as a dependent variable and the model parameters as independent variables, including all twoway interactions. Analysis of variance – which is straightforward for our full factorial design – is used to quantify the importance of each parameter or interaction. Robust optimal parameter settings are identified with the help of effect displays (Fox, 2003), which marginalize over all the parameters not shown in a plot and thus allow an intuitive interpretation of the effect sizes of categorical variables irrespective of the dummy coding scheme. For each dataset, a separate linear model was fitted. The results are reported and compared in section 5. Table 1 lists the global goodness-of-fit (R2) on each dataset, for the reduced and unreduced runs. Despite some variability across relations and between unreduced and reduced runs, the R2 values are always high (≥ 75%), showing that the linear model explains a large part of the observed performance d</context>
</contexts>
<marker>Fox, 2003</marker>
<rawString>John Fox. 2003. Effect displays in R for generalised linear models. Journal of Statistical Software, 8(15):1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Halko</author>
<author>Per-Gunnar Martinsson</author>
<author>Joel A Tropp</author>
</authors>
<title>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions.</title>
<date>2009</date>
<tech>Technical Report 2009-05,</tech>
<institution>ACM, California Institute of Technology.</institution>
<contexts>
<context position="17858" citStr="Halko et al., 2009" startWordPosition="2645" endWordPosition="2648">of each prime. We expect that the target will occur in a higher position among the neighbors of the consistent prime than among those of the inconsistent prime. Since this corresponds to a lower numeric rank value for the consistent prime, we can treat neighbor rank as a measure of dissimilarity. Neighbor rank is particularly interesting as an index of relatedness because, unlike a distance metric, it can capture asymmetry effects9. 4 Methodology In our evaluation study, we tested all the possible combinations of the parameters listed in section 8For efficiency reasons, we use randomized SVD (Halko et al., 2009) with a sufficiently high oversampling factor to ensure a good approximation. 9Note that our use of neighbor rank is fully consistent with the experimental design (primes are shown before targets). See Lapesa and Evert (2013) for an analysis of the performance of neighbor rank as a predictor of priming and discussion of the implications of using rank in cognitive modeling. 163 3.2, resulting in a total of 537600 different model runs (33600 in the setting without dimensionality reduction, 504000 in the dimensionality-reduced setting). The models were generated and evaluated on a large HPC clust</context>
</contexts>
<marker>Halko, Martinsson, Tropp, 2009</marker>
<rawString>Nathan Halko, Per-Gunnar Martinsson, and Joel A. Tropp. 2009. Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions. Technical Report 2009-05, ACM, California Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Hare</author>
<author>Michael Jones</author>
<author>Caroline Thomson</author>
<author>Sarah Kelly</author>
<author>Ken McRae</author>
</authors>
<title>Activating event knowledge.</title>
<date>2009</date>
<journal>Cognition,</journal>
<volume>111</volume>
<issue>2</issue>
<contexts>
<context position="12396" citStr="Hare et al., 2009" startWordPosition="1814" endWordPosition="1817">words that denote events and their participants. The first study was conducted by Ferretti et al. (2001), who found that verbs facilitate the processing of nouns denoting prototypical participants in the depicted event and of adjectives denoting features of prototypical participants. The study covered five thematic relations: agent (e.g., pay–customer), patient, feature of the patient, instrument, location. The second study (McRae et al., 2005) focussed on priming from nouns to verbs. It involved four relations: agent (e.g., reporter–interview), patient, instrument, location. The third study (Hare et al., 2009) investigated priming from nouns to nouns, referring to participants of the same event or the event itself. The dataset involves seven relations: event-people (e.g., trial–judge), eventthing, location-living, location-thing, peopleinstrument, instrument-people, instrument-thing. In the presentation of our results we group synonyms with antonyms and cohyponyms from SPP as paradigmatic relations, and the entire GEK dataset with backward and forward phrasal associates from SPP as syntagmatic relations. 3.2 Evaluated Parameters DSMs evaluated in this paper belong to the class of bag-of-words model</context>
</contexts>
<marker>Hare, Jones, Thomson, Kelly, McRae, 2009</marker>
<rawString>Mary Hare, Michael Jones, Caroline Thomson, Sarah Kelly, and Ken McRae. 2009. Activating event knowledge. Cognition, 111(2):151–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig Harris</author>
</authors>
<date>1954</date>
<journal>Distributional structure. Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="1634" citStr="Harris (1954)" startWordPosition="219" endWordPosition="220">irst-order models – we show that second-order models perform well on both paradigmatic and syntagmatic relations if their parameters are properly tuned. In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations. 1 Introduction Distributional takes on the representation and acquisition of word meaning rely on the assumption that words with similar meaning tend to occur in similar contexts: this assumption, known as distributional hypothesis, has been first proposed by Harris (1954). Distributional Semantic Models (henceforth, DSMs) are computational models that operationalize the distributional hypothesis; they produce semantic representations for words in the form of distributional vectors recording patterns of co-occurrence in large samples of language data (Sahlgren, 2006; Baroni and Lenci, 2010; Turney and Pantel, 2010). Comparison between distributional vectors allows the identification of shared contexts as an empirical correlate of the semantic similarity between the target words. As noted in Sahlgren (2008), the notion of semantic similarity applied in distribut</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zelig Harris. 1954. Distributional structure. Word, 10(23):146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amac Herda˘gdelen</author>
<author>Marco Baroni</author>
<author>Katrin Erk</author>
</authors>
<title>Measuring semantic relatedness with vector space models and random walks.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing,</booktitle>
<pages>50--53</pages>
<marker>Herda˘gdelen, Baroni, Erk, 2009</marker>
<rawString>Amac Herda˘gdelen, Marco Baroni, and Katrin Erk. 2009. Measuring semantic relatedness with vector space models and random walks. In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, pages 50–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith A Hutchison</author>
<author>David A Balota</author>
<author>James H Neely</author>
<author>Michael J Cortese</author>
<author>Emily R Cohen-Shikora</author>
<author>ChiShing Tse</author>
<author>Melvin J Yap</author>
<author>Jesse J Bengson</author>
<author>Dale Niemeyer</author>
<author>Erin Buchanan</author>
</authors>
<title>The semantic priming project.</title>
<date>2013</date>
<journal>Behavior Research Methods,</journal>
<volume>45</volume>
<issue>4</issue>
<contexts>
<context position="10466" citStr="Hutchison et al., 2013" startWordPosition="1530" endWordPosition="1533">n modeling priming effects as a comparison between prime-target pairs (McDonald and Brew, 2004; Pad´o and Lapata, 2007; Herda˘gdelen et al., 2009), we evaluate our models in a classification task. The goal is to identify the consistent prime on the basis of its distributional relatedness to the target: if a particular DSM (i.e., a certain parameter combination) is sensitive to a specific relation (or group of relations), we expect the consistent primes to be closer to the target in semantic space than the inconsistent ones. The first dataset is derived from the Semantic Priming Project (SPP) (Hutchison et al., 2013). To the best of our knowledge, our study represents the first evaluation of bag-of-words DSMs on items from this dataset. The original data consist of 1661 word triples (target, consistent prime, inconsistent prime) collected within a large-scale project aiming at characterizing English words in terms of a set of lexical and associative/semantic characteristics, along with behavioral data from visual lexical decision and naming studies2. We manually discarded all triples containing proper nouns, adverbs or inflected words. We then selected five subsets involving different semantic relations, </context>
</contexts>
<marker>Hutchison, Balota, Neely, Cortese, Cohen-Shikora, Tse, Yap, Bengson, Niemeyer, Buchanan, 2013</marker>
<rawString>Keith A. Hutchison, David A. Balota, James H. Neely, Michael J. Cortese, Emily R. Cohen-Shikora, ChiShing Tse, Melvin J. Yap, Jesse J. Bengson, Dale Niemeyer, and Erin Buchanan. 2013. The semantic priming project. Behavior Research Methods, 45(4):1099–1114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Redefining antonymy: The textual structure of a semantic relation. Literary and Linguistic Computing,</title>
<date>1992</date>
<volume>7</volume>
<issue>3</issue>
<pages>184</pages>
<contexts>
<context position="27456" citStr="Justeson and Katz (1992)" startWordPosition="4272" endWordPosition="4275">: Window, syntagmatic, unreduced Figure 7: Window, syntagmatic, unreduced Figure 8: Window, syntagmatic, reduced Figure 8: Window, syntagmatic, reduced quickly for larger windows. With 50 or 100 diseems to be more similar to the syntagmatic relaquickly for larger windows. With 50 or 100 di- seems to be more similar to the syntagmatic relamensions skipped, performance improves up to a tions than SYN and COH. This is in line with the mensions skipped, performance improves up to a tions than SYN and COH. This is in line with the 4- or 8-word window. Our interpretation is that the observations of Justeson and Katz (1992) concern4- or 8-word window. Our interpretation is that the observations of Justeson and Katz (1992) concernfirst SVD dimensions capture general domain and ing the tendency of antonyms to co-occur (e.g., in first SVD dimensions capture general domain and ing the tendency of antonyms to co-occur (e.g., in topic information dominating the co-occurrence coordinations such as short and long). Like syntopic information dominating the co-occurrence coordinations such as short and long). Like syndata; removing these dimensions reveals paradigonyms, antonyms are interchangeable in absentia; data; remo</context>
</contexts>
<marker>Justeson, Katz, 1992</marker>
<rawString>John. S. Justeson and Slava M. Katz. 1992. Redefining antonymy: The textual structure of a semantic relation. Literary and Linguistic Computing, 7(3):176– 184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriella Lapesa</author>
<author>Stefan Evert</author>
</authors>
<title>Evaluating neighbor rank and distance measures as predictors of semantic priming.</title>
<date>2013</date>
<booktitle>In Proceedings of the ACL Workshop on Cognitive Modeling and Computational Linguistics (CMCL</booktitle>
<pages>66--74</pages>
<contexts>
<context position="11575" citStr="Lapesa and Evert (2013)" startWordPosition="1687" endWordPosition="1690">g proper nouns, adverbs or inflected words. We then selected five subsets involving different semantic relations, namely: synonyms (SYN), 436 triples (example of a consistent prime and target: frigid–cold); antonyms (ANT): 135 triples (e.g., hot–cold); cohyponyms (COH): 159 triples (e.g., table–chair); forward phrasal associates (FPA): 144 triples (e.g., help–wanted); back2The dataset is available at http://spp.montana.edu/ ward phrasal associates (BPA): 89 triples (e.g., wanted–help). The second priming dataset is the Generalized Event Knowledge dataset (henceforth GEK), already evaluated in Lapesa and Evert (2013): a collection of 402 triples (target, consistent prime, inconsistent prime) from three priming studies conducted to demonstrate that event knowledge is responsible for facilitation of the processing of words that denote events and their participants. The first study was conducted by Ferretti et al. (2001), who found that verbs facilitate the processing of nouns denoting prototypical participants in the depicted event and of adjectives denoting features of prototypical participants. The study covered five thematic relations: agent (e.g., pay–customer), patient, feature of the patient, instrume</context>
<context position="14097" citStr="Lapesa and Evert (2013)" startWordPosition="2061" endWordPosition="2064">reviated as corpus in plots 1-4): We compiled DSMs from three corpora often used in DSM evaluation studies and that 3http://www.collocations.de/software.html 4http://r-forge.r-project.org/projects/wordspace/ 162 differ in both size and quality: British National Corpus5, ukWaC, and WaCkypedia EN6. • Size of the context window (win.size): As this parameter quantifies the amount of shared context involved in the computation of similarity, we expect it to be crucial in determining whether syntagmatic or paradigmatic relations are captured. We therefore use a finer granularity for window size than Lapesa and Evert (2013): 1, 2, 4, 8 and 16 words. • Directionality of the context window (win.direction): When collecting co-occurrence information from the source corpora, we use either a directed window (i.e., separate frequency counts for co-occurrences of a context term to the left and to the right of the target term) or an undirected window (i.e., no distinction between left and right context when collecting co-occurrence counts). • Context selection: From the full co-occurrence matrix collected as described above, we select dimensions (columns) according to the following parameters: – Criterion for context sel</context>
<context position="18083" citStr="Lapesa and Evert (2013)" startWordPosition="2680" endWordPosition="2683"> consistent prime, we can treat neighbor rank as a measure of dissimilarity. Neighbor rank is particularly interesting as an index of relatedness because, unlike a distance metric, it can capture asymmetry effects9. 4 Methodology In our evaluation study, we tested all the possible combinations of the parameters listed in section 8For efficiency reasons, we use randomized SVD (Halko et al., 2009) with a sufficiently high oversampling factor to ensure a good approximation. 9Note that our use of neighbor rank is fully consistent with the experimental design (primes are shown before targets). See Lapesa and Evert (2013) for an analysis of the performance of neighbor rank as a predictor of priming and discussion of the implications of using rank in cognitive modeling. 163 3.2, resulting in a total of 537600 different model runs (33600 in the setting without dimensionality reduction, 504000 in the dimensionality-reduced setting). The models were generated and evaluated on a large HPC cluster within approx. 4 weeks. Our methodology for model selection follows the proposal of Lapesa and Evert (2013), who consider DSM parameters as predictors of model performance. We analyze the influence of individual parameters</context>
<context position="29735" citStr="Lapesa and Evert (2013)" startWordPosition="4625" endWordPosition="4628">formance peaks at 8 words, and decreases only ber of skipped dimensions (figures 11 and 12). ber of skipped dimensions (figures 11 and 12). minimally for even larger windows. Again, diminimally for even larger windows. Again, di- These parameters represent an extension of the These parameters represent an extension of the mensionality reduction improves performance for mensionality reduction improves performance for experiments conducted on the GEK dataset by experiments conducted on the GEK dataset by large co-occurrence windows. For FPA and BPA, large co-occurrence windows. For FPA and BPA, Lapesa and Evert (2013). They have already been Lapesa and Evert (2013). They have already been the optimum seems to be achieved with a winthe optimum seems to be achieved with a win- applied by Bullinaria and Levy (2012) to a differapplied by Bullinaria and Levy (2012) to a differdow of 4–8 words; performance on GEK contindow of 4–8 words; performance on GEK contin- ent set of tasks, including the TOEFL multipleent set of tasks, including the TOEFL multipleues to increase up to 16 words, the largest winues to increase up to 16 words, the largest win- choice synonymy task. In particular, Bullinaria choice synonymy t</context>
</contexts>
<marker>Lapesa, Evert, 2013</marker>
<rawString>Gabriella Lapesa and Stefan Evert. 2013. Evaluating neighbor rank and distance measures as predictors of semantic priming. In Proceedings of the ACL Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2013), pages 66–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Lenci</author>
<author>Giulia Benotto</author>
</authors>
<title>Identifying hypernyms in distributional semantic spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of *SEM 2012: The First Joint Conference on Lexical and Computational Semantics –</booktitle>
<volume>1</volume>
<pages>75--79</pages>
<contexts>
<context position="5909" citStr="Lenci and Benotto, 2012" startWordPosition="854" endWordPosition="857">lection methodology. Section 5 presents the results of our evaluation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in this paper we will adopt the labels syntagmatic and parad</context>
</contexts>
<marker>Lenci, Benotto, 2012</marker>
<rawString>Alessandro Lenci and Giulia Benotto. 2012. Identifying hypernyms in distributional semantic spaces. In Proceedings of *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1, pages 75–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>John Carroll</author>
</authors>
<title>Disambiguating nouns, verbs and adjectives using automatically acquired selectional preferences.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="5974" citStr="McCarthy and Carroll, 2003" startWordPosition="862" endWordPosition="865">uation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in this paper we will adopt the labels syntagmatic and paradigmatic to characterize different types of semantic relations, an</context>
</contexts>
<marker>McCarthy, Carroll, 2003</marker>
<rawString>Diana McCarthy and John Carroll. 2003. Disambiguating nouns, verbs and adjectives using automatically acquired selectional preferences. Computational Linguistics, 29(4):639–654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott McDonald</author>
<author>Chris Brew</author>
</authors>
<title>A distributional model of semantic context effects in lexical processing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="9937" citStr="McDonald and Brew, 2004" startWordPosition="1442" endWordPosition="1445"> as the evaluation focuses either on paradigmatic relations (TOEFL multiple choice test, antonymy test) or on resources containing both types of relations (thesauri, association norms). 3 Experimental Setting 3.1 Evaluation Task and Data In this study, bag-of-words DSMs are evaluated on two datasets containing experimental items from two priming studies. Each item is a word triple (target, consistent prime, inconsistent prime) with a particular semantic relation between target and consistent prime. Following previous work on modeling priming effects as a comparison between prime-target pairs (McDonald and Brew, 2004; Pad´o and Lapata, 2007; Herda˘gdelen et al., 2009), we evaluate our models in a classification task. The goal is to identify the consistent prime on the basis of its distributional relatedness to the target: if a particular DSM (i.e., a certain parameter combination) is sensitive to a specific relation (or group of relations), we expect the consistent primes to be closer to the target in semantic space than the inconsistent ones. The first dataset is derived from the Semantic Priming Project (SPP) (Hutchison et al., 2013). To the best of our knowledge, our study represents the first evaluati</context>
</contexts>
<marker>McDonald, Brew, 2004</marker>
<rawString>Scott McDonald and Chris Brew. 2004. A distributional model of semantic context effects in lexical processing. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken McRae</author>
<author>Mary Hare</author>
<author>Jeffrey L Elman</author>
<author>Todd Ferretti</author>
</authors>
<title>A basis for generating expectancies for verbs from nouns.</title>
<date>2005</date>
<journal>Memory &amp; Cognition,</journal>
<volume>33</volume>
<issue>7</issue>
<contexts>
<context position="12226" citStr="McRae et al., 2005" startWordPosition="1788" endWordPosition="1791">arget, consistent prime, inconsistent prime) from three priming studies conducted to demonstrate that event knowledge is responsible for facilitation of the processing of words that denote events and their participants. The first study was conducted by Ferretti et al. (2001), who found that verbs facilitate the processing of nouns denoting prototypical participants in the depicted event and of adjectives denoting features of prototypical participants. The study covered five thematic relations: agent (e.g., pay–customer), patient, feature of the patient, instrument, location. The second study (McRae et al., 2005) focussed on priming from nouns to verbs. It involved four relations: agent (e.g., reporter–interview), patient, instrument, location. The third study (Hare et al., 2009) investigated priming from nouns to nouns, referring to participants of the same event or the event itself. The dataset involves seven relations: event-people (e.g., trial–judge), eventthing, location-living, location-thing, peopleinstrument, instrument-people, instrument-thing. In the presentation of our results we group synonyms with antonyms and cohyponyms from SPP as paradigmatic relations, and the entire GEK dataset with </context>
</contexts>
<marker>McRae, Hare, Elman, Ferretti, 2005</marker>
<rawString>Ken McRae, Mary Hare, Jeffrey L. Elman, and Todd Ferretti. 2005. A basis for generating expectancies for verbs from nouns. Memory &amp; Cognition, 33(7):1174–1184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Peirsman</author>
<author>Kris Heylen</author>
<author>Dirk Speelman</author>
</authors>
<title>Putting things in order. First and second order context models for the calculation of semantic similarity.</title>
<date>2008</date>
<booktitle>In JADT 2008: 9es Journ´ees internationales d’Analyse statistique des Donn´ees Textuelles.</booktitle>
<contexts>
<context position="9068" citStr="Peirsman et al. (2008)" startWordPosition="1319" endWordPosition="1322">aces privilege paradigmatic relations, based on the assumption that paradigmatically related word pairs belong to the same part of speech, while this is not necessarily the case for syntagmatically related word pairs. 1Term-document models encode first-order information because dot products between row vectors are related to cooccurrence counts of the corresponding words (within documents). More precisely, for a binary term-document matrix, cosine similarity is identical to the square root of the MI association measure. Please note that our terminology differs from that of Sch¨utze (1998) and Peirsman et al. (2008). 161 Summing up, in both Rapp (2002) and Sahlgren (2006) it is claimed that second-order models perform poorly in predicting syntagmatic relations. However, neither of those studies involves datasets containing exclusively syntagmatic relations, as the evaluation focuses either on paradigmatic relations (TOEFL multiple choice test, antonymy test) or on resources containing both types of relations (thesauri, association norms). 3 Experimental Setting 3.1 Evaluation Task and Data In this study, bag-of-words DSMs are evaluated on two datasets containing experimental items from two priming studie</context>
</contexts>
<marker>Peirsman, Heylen, Speelman, 2008</marker>
<rawString>Yves Peirsman, Kris Heylen, and Dirk Speelman. 2008. Putting things in order. First and second order context models for the calculation of semantic similarity. In JADT 2008: 9es Journ´ees internationales d’Analyse statistique des Donn´ees Textuelles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>The computation of word associations: Comparing syntagmatic and paradigmatic approaches.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics -Volume</booktitle>
<volume>1</volume>
<pages>1--7</pages>
<contexts>
<context position="849" citStr="Rapp, 2002" startWordPosition="99" endWordPosition="100">ur f¨ur Korpuslinguistik stefan.evert@fau.de Sabine Schulte im Walde3 3Universit¨at Stuttgart Institut f¨ur Maschinelle Sprachverarbeitung schulte@ims.uni-stuttgart.de Abstract This paper presents a large-scale evaluation of bag-of-words distributional models on two datasets from priming experiments involving syntagmatic and paradigmatic relations. We interpret the variation in performance achieved by different settings of the model parameters as an indication of which aspects of distributional patterns characterize these types of relations. Contrary to what has been argued in the literature (Rapp, 2002; Sahlgren, 2006) – that bag-of-words models based on secondorder statistics mainly capture paradigmatic relations and that syntagmatic relations need to be gathered from first-order models – we show that second-order models perform well on both paradigmatic and syntagmatic relations if their parameters are properly tuned. In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations. 1 Introduction Distributional takes on the representation and acquisition of word meanin</context>
<context position="3404" citStr="Rapp, 2002" startWordPosition="475" endWordPosition="476">they are also called relations in absentia (Sahlgren, 2006) because paradigmatically related words do not co-occur. Examples of paradigmatic relations are synonyms (e.g., frigid–cold) and antonyms (e.g., cold–hot). Syntagmatic relations hold between words that cooccur (relations in praesentia) and therefore exhibit a similar distribution across contexts. Typical examples of syntagmatic relations are phrasal associates (e.g., help–wanted) and syntactic collocations (e.g., dog–bark). Distributional modeling has already tackled the issue of paradigmatic and syntagmatic relations (Sahlgren, 2006; Rapp, 2002). Key contributions of the present work are the scope of its evaluation (in terms of semantic relations and model parameters) and the new perspective on paradigmatic vs. syntagmatic models provided by our results. Concerning the scope of the evaluation, this is the first study in which the comparison involves such a wide range of semantic relations (paradigmatic: synonyms, antonyms and co-hyponyms; syntagmatic: syntactic collocations, backward and forward phrasal associates). Moreover, our evaluation covers a large number of DSM parameters: source corpus, size and direction of the context wind</context>
<context position="5638" citStr="Rapp, 2002" startWordPosition="812" endWordPosition="813">ic relations, is not applicable to collocation lists. This paper is structured as follows. Section 2 summarizes previous work. Section 3 describes the experimental setup, in terms of task, datasets and evaluated parameters. Section 4 introduces our model selection methodology. Section 5 presents the results of our evaluation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context reg</context>
<context position="6871" citStr="Rapp (2002)" startWordPosition="1002" endWordPosition="1003">bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in this paper we will adopt the labels syntagmatic and paradigmatic to characterize different types of semantic relations, and we will use the labels first-order and second-order to characterize corpus-based models with respect to the kind of co-occurrence information they encode. We will refer to collocation lists and termdocument DSMs as first-order models, and to bagof-words DSMs as second-order models1. Rapp (2002) integrates first-order (cooccurrence lists) and second-order (bag-of-words DSMs) information to distinguish syntagmatic and paradigmatic relations. Under the assumption that paradigmatically related words will be found among the closest neighbors of a target word in the DSM space and that paradigmatically and syntagmatically related words will be intermingled in the list of collocates of the target word, Rapp proposes to exploit a comparison of the most salient collocates and the nearest DSM neighbors to distinguish between the two types of relations. Sahlgren (2006) compares term-context and</context>
<context position="9105" citStr="Rapp (2002)" startWordPosition="1328" endWordPosition="1329">the assumption that paradigmatically related word pairs belong to the same part of speech, while this is not necessarily the case for syntagmatically related word pairs. 1Term-document models encode first-order information because dot products between row vectors are related to cooccurrence counts of the corresponding words (within documents). More precisely, for a binary term-document matrix, cosine similarity is identical to the square root of the MI association measure. Please note that our terminology differs from that of Sch¨utze (1998) and Peirsman et al. (2008). 161 Summing up, in both Rapp (2002) and Sahlgren (2006) it is claimed that second-order models perform poorly in predicting syntagmatic relations. However, neither of those studies involves datasets containing exclusively syntagmatic relations, as the evaluation focuses either on paradigmatic relations (TOEFL multiple choice test, antonymy test) or on resources containing both types of relations (thesauri, association norms). 3 Experimental Setting 3.1 Evaluation Task and Data In this study, bag-of-words DSMs are evaluated on two datasets containing experimental items from two priming studies. Each item is a word triple (target</context>
</contexts>
<marker>Rapp, 2002</marker>
<rawString>Reinhard Rapp. 2002. The computation of word associations: Comparing syntagmatic and paradigmatic approaches. In Proceedings of the 19th International Conference on Computational Linguistics -Volume 1, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The word-space model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Stockolm.</institution>
<contexts>
<context position="866" citStr="Sahlgren, 2006" startWordPosition="101" endWordPosition="102">uslinguistik stefan.evert@fau.de Sabine Schulte im Walde3 3Universit¨at Stuttgart Institut f¨ur Maschinelle Sprachverarbeitung schulte@ims.uni-stuttgart.de Abstract This paper presents a large-scale evaluation of bag-of-words distributional models on two datasets from priming experiments involving syntagmatic and paradigmatic relations. We interpret the variation in performance achieved by different settings of the model parameters as an indication of which aspects of distributional patterns characterize these types of relations. Contrary to what has been argued in the literature (Rapp, 2002; Sahlgren, 2006) – that bag-of-words models based on secondorder statistics mainly capture paradigmatic relations and that syntagmatic relations need to be gathered from first-order models – we show that second-order models perform well on both paradigmatic and syntagmatic relations if their parameters are properly tuned. In particular, our results show that size of the context window and dimensionality reduction play a key role in differentiating DSM performance on paradigmatic vs. syntagmatic relations. 1 Introduction Distributional takes on the representation and acquisition of word meaning rely on the ass</context>
<context position="2852" citStr="Sahlgren, 2006" startWordPosition="403" endWordPosition="404">al approaches to meaning is an easy target of criticism, as it is employed to capture a wide range of semantic relations, such as synonymy, antonymy, hypernymy, up to topical relatedness. The study presented in this paper contributes to the debate concerning the nature of the semantic representations built by DSMs, and it does so by comparing the performance of several DSMs in a classification task conducted on priming data and involving paradigmatic and syntagmatic relations. Paradigmatic relations hold between words that occur in similar contexts; they are also called relations in absentia (Sahlgren, 2006) because paradigmatically related words do not co-occur. Examples of paradigmatic relations are synonyms (e.g., frigid–cold) and antonyms (e.g., cold–hot). Syntagmatic relations hold between words that cooccur (relations in praesentia) and therefore exhibit a similar distribution across contexts. Typical examples of syntagmatic relations are phrasal associates (e.g., help–wanted) and syntactic collocations (e.g., dog–bark). Distributional modeling has already tackled the issue of paradigmatic and syntagmatic relations (Sahlgren, 2006; Rapp, 2002). Key contributions of the present work are the </context>
<context position="4503" citStr="Sahlgren, 2006" startWordPosition="637" endWordPosition="638">over, our evaluation covers a large number of DSM parameters: source corpus, size and direction of the context window, criteria for feature selection, feature 160 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 160–170, Dublin, Ireland, August 23-24 2014. weighting, dimensionality reduction and index of distributional relatedness. We consider the variation in performance achieved by different parameter settings as a cue towards characteristic aspects of specific relations (or groups of relations). Our work also differs from previous studies (Sahlgren, 2006; Rapp, 2002) in its focus on second-order models. We aim to show that they are able to capture both paradigmatic and syntagmatic relations with appropriate parameter settings. In addition, this focus provides a uniform experimental design for the evaluation. For example, parameters like window size and directionality apply to bag-of-words DSMs and collocation lists but not to term-context models; dimensionality reduction, whose effect has not yet been explored systematically in the context of syntagmatic and paradigmatic relations, is not applicable to collocation lists. This paper is structu</context>
<context position="6330" citStr="Sahlgren (2006)" startWordPosition="919" endWordPosition="920">bal level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in this paper we will adopt the labels syntagmatic and paradigmatic to characterize different types of semantic relations, and we will use the labels first-order and second-order to characterize corpus-based models with respect to the kind of co-occurrence information they encode. We will refer to collocation lists and termdocument DSMs as first-order models, and to bagof-words DSMs as second-order models1. Rapp (2002) integrates first-order (cooccurrence lists) and second-ord</context>
<context position="8286" citStr="Sahlgren (2006)" startWordPosition="1202" endWordPosition="1203">gmatically related words) and neighbors in the distributional spaces is conducted. It shows that, while term-context DSMs produce both syntagmatically and paradigmatically related words, the nearest neighbors in a bag-of-words DSM mainly provide paradigmatic information. Bagof-words models also performed better than termcontext models in predicting association norms, in the TOEFL multiple-choice synonymy task and in the prediction of antonyms (although the difference in performance was less significant here). Last, word neighborhoods are analysed in terms of their part-of-speech distribution. Sahlgren (2006) observes that bag-of-words spaces contain more neighbors with the same part of speech as the target than term-context spaces. He concludes that bag-of-words spaces privilege paradigmatic relations, based on the assumption that paradigmatically related word pairs belong to the same part of speech, while this is not necessarily the case for syntagmatically related word pairs. 1Term-document models encode first-order information because dot products between row vectors are related to cooccurrence counts of the corresponding words (within documents). More precisely, for a binary term-document mat</context>
<context position="26120" citStr="Sahlgren (2006)" startWordPosition="3987" endWordPosition="3988">vely. The plots in figures 7 and 8 display its partial effect for syntagmatic relations. When no dimensionality reduction is involved, a very small context window (i.e., one word) is sufficient for all paradigmatic relations, and DSM performance decreases as soon as we enlarge the context window. The picture changes when applying dimensionality reduction: a 4-word window is a robust choice for all paradigmatic relations (although ANT show a further increase in performance with an 8-word window), even in the SYN task that is traditionally associated with very small windows of 1 or 2 words (cf. Sahlgren (2006)). A significant interaction between window size and number of skipped dimensions (not shown for reasons of space) sheds further light on this matter. Without skipping SVD dimensions, the reduced models achieve optimal performance for a 2-word window and degrade more (COH) or less (ANT) 165 ● ● 96 ● ● ● ● ● ● ● dataset ● SYN ● ANT ●COH ● ● ● ● ● ● 93 90 87 84 1 2 4 8 16 ● ● ● 90 ● ● 1 2 4 8 16 96 93 ● ● ● ● ● ● ● ● dataset ● SYN ● ANT ●COH 87 84 Figure 5: Window, paradigmatic, unreduced Figure 6: Window, paradigmatic, reduced 86 84 82 80 78 76 74 1 2 4 8 16 dataset ●GEK ● FPA ● BPA ● ● ● ● ● ●</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The word-space model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces. Ph.D. thesis, University of Stockolm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The distributional hypothesis. Rivista di Linguistica (Italian</title>
<date>2008</date>
<journal>Journal of Linguistics),</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="2178" citStr="Sahlgren (2008)" startWordPosition="297" endWordPosition="298"> as distributional hypothesis, has been first proposed by Harris (1954). Distributional Semantic Models (henceforth, DSMs) are computational models that operationalize the distributional hypothesis; they produce semantic representations for words in the form of distributional vectors recording patterns of co-occurrence in large samples of language data (Sahlgren, 2006; Baroni and Lenci, 2010; Turney and Pantel, 2010). Comparison between distributional vectors allows the identification of shared contexts as an empirical correlate of the semantic similarity between the target words. As noted in Sahlgren (2008), the notion of semantic similarity applied in distributional approaches to meaning is an easy target of criticism, as it is employed to capture a wide range of semantic relations, such as synonymy, antonymy, hypernymy, up to topical relatedness. The study presented in this paper contributes to the debate concerning the nature of the semantic representations built by DSMs, and it does so by comparing the performance of several DSMs in a classification task conducted on priming data and involving paradigmatic and syntagmatic relations. Paradigmatic relations hold between words that occur in sim</context>
</contexts>
<marker>Sahlgren, 2008</marker>
<rawString>Magnus Sahlgren. 2008. The distributional hypothesis. Rivista di Linguistica (Italian Journal of Linguistics), 20(1):33–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silke Scheible</author>
<author>Sabine Schulte im Walde</author>
<author>Sylvia Springorum</author>
</authors>
<title>Uncovering Distributional Differences between Synonyms and Antonyms in a Word Space Model.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Natural Language Processing,</booktitle>
<pages>489--497</pages>
<contexts>
<context position="42456" citStr="Scheible et al. (2013)" startWordPosition="6659" endWordPosition="6662">g experiments. The leading theme of our study is a comparison between syntagmatic and paradigmatic relations in terms of the aspects of distributional similarity that characterize them. Our results show that second-order DSMs are capable of capturing both syntagmatic and paradigmatic relations, if parameters are properly tuned. Size of the co-occurrence window as well as parameters connected to dimensionality reduction play a key role in adapting DSMs to particular relations. Even if we do not address the more specific task of distinguishing between relations (e.g., synonyms vs. antonyms; see Scheible et al. (2013) and references therein), we believe that such applications may benefit from our detailed analyses on the effects of DSM parameters. Ongoing and future work is concerned with the expansion of the evaluation setting to other classes of models (first-order models, dependency-based second-order models) and parameters (e.g., dimensionality reduction with Random Indexing). Acknowledgments We are grateful to Ken MacRae for providing us the GEK priming data and to the three reviewers. This research was funded by the DFG Collaborative Research Centre SFB 732 (Gabriella Lapesa) and the DFG Heisenberg F</context>
</contexts>
<marker>Scheible, Walde, Springorum, 2013</marker>
<rawString>Silke Scheible, Sabine Schulte im Walde, and Sylvia Springorum. 2013. Uncovering Distributional Differences between Synonyms and Antonyms in a Word Space Model. In Proceedings of the 6th International Joint Conference on Natural Language Processing, pages 489—497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>1</issue>
<pages>123</pages>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 27(1):97– 123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141</pages>
<contexts>
<context position="1983" citStr="Turney and Pantel, 2010" startWordPosition="266" endWordPosition="269">. 1 Introduction Distributional takes on the representation and acquisition of word meaning rely on the assumption that words with similar meaning tend to occur in similar contexts: this assumption, known as distributional hypothesis, has been first proposed by Harris (1954). Distributional Semantic Models (henceforth, DSMs) are computational models that operationalize the distributional hypothesis; they produce semantic representations for words in the form of distributional vectors recording patterns of co-occurrence in large samples of language data (Sahlgren, 2006; Baroni and Lenci, 2010; Turney and Pantel, 2010). Comparison between distributional vectors allows the identification of shared contexts as an empirical correlate of the semantic similarity between the target words. As noted in Sahlgren (2008), the notion of semantic similarity applied in distributional approaches to meaning is an easy target of criticism, as it is employed to capture a wide range of semantic relations, such as synonymy, antonymy, hypernymy, up to topical relatedness. The study presented in this paper contributes to the debate concerning the nature of the semantic representations built by DSMs, and it does so by comparing t</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
<author>Diana McCarthy</author>
</authors>
<title>Characterising measures of lexical distributional similarity.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference of Computational Linguistics,</booktitle>
<pages>1015--1021</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="5883" citStr="Weeds et al., 2004" startWordPosition="850" endWordPosition="853">roduces our model selection methodology. Section 5 presents the results of our evaluation study. Section 6 summarizes main findings and sketches ongoing and future work. 2 Previous Work In this section we discuss previous work relevant to the distributional modeling of paradigmatic and syntagmatic relations. For space constraints, we focus only on two studies (Rapp, 2002; Sahlgren, 2006) in which the two classes of relations are compared at a global level, and not on studies that are concerned with specific semantic relations, e.g., synonymy (Edmonds and Hirst, 2002; Curran, 2003), hypernymy (Weeds et al., 2004; Lenci and Benotto, 2012) or syntagmatic predicate preferences (McCarthy and Carroll, 2003; Erk et al., 2010), etc. In previous studies, the comparison of syntagmatic and paradigmatic relations has been implemented in terms of an opposition between different classes of corpus-based models: term-context models (words as targets, documents or context regions as features) vs. bag-of-words models (words as targets and features) in Sahlgren (2006); collocation lists vs. bag-of-words models in Rapp (2002). Given the high terminological variation in the literature, in this paper we will adopt the la</context>
</contexts>
<marker>Weeds, Weir, McCarthy, 2004</marker>
<rawString>Julie Weeds, David Weir, and Diana McCarthy. 2004. Characterising measures of lexical distributional similarity. In Proceedings of the 20th International Conference of Computational Linguistics, pages 1015–1021, Geneva, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>