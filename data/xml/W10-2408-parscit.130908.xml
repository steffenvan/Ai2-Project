<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.081923">
<title confidence="0.998118">
Language Independent Transliteration Mining System Using Finite State
Automata Framework
</title>
<author confidence="0.893945">
Sara Noeman and Amgad Madkour
</author>
<affiliation confidence="0.8394685">
Human Language Technologies Group
IBM Cairo Technology Development Center
</affiliation>
<address confidence="0.814647">
P.O.Box 166 El-Haram, Giza, Egypt
</address>
<email confidence="0.998868">
{noemans,amadkour}@eg.ibm.com
</email>
<sectionHeader confidence="0.993897" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999924083333334">
We propose a Named Entities translitera-
tion mining system using Finite State Au-
tomata (FSA). We compare the proposed
approach with a baseline system that uti-
lizes the Editex technique to measure the
length-normalized phonetic based edit dis-
tance between the two words. We sub-
mitted three standard runs in NEWS2010
shared task and ranked first for English
to Arabic (WM-EnAr) and obtained an F-
measure of 0.915, 0.903, and 0.874 re-
spectively.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999917733333333">
Named entities transliteration is a crucial task in
many domains such as cross lingual information
retrieval, machine translation, and other natural
language processing applications. In the previous
NEWS 2009 transliteration task, we introduced a
statistical approach for transliteration generation
only using the bilingual resources (about 15k par-
allel names) provided for the shared task. For
NEWS2010, the shared task focuses on acquisi-
tion of a reasonably sized, good quality names
corpus to complement the machine transliteration
task. Specifically, the task focuses on mining the
Wikipedia paired entities data (inter-wiki-links) to
produce high-quality transliteration data that may
be used for transliteration generation tasks.
</bodyText>
<sectionHeader confidence="0.999852" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999952733333334">
Finite state Automata is used to tackle many Nat-
ural Language Processing challenges. Hassan
(2008) et al. proposed the use of finite state au-
tomata for language-independent text correction.
It consists of three phases : detecting misspelled
words, generating candidate corrections for them
and ranking corrections. In detecting the mis-
pelled words, they compose the finite state au-
tomaton representation of the dictionary with the
input string. Onaizan (2002) et al. proposed
the use of probabilistic finite state machines for
machine transliteration of names in Arabic text.
They used a hybrid approach between phonetic-
based and spelling-based models. Malik (2008)
et al. proposed a Hindi Urdu machine translit-
eration system using finite state machines. They
introduced UIT (universal intermediate transcrip-
tion) on the same pair according to thier phonetic
properties as a means of representing the language
and created finite state transducers to represent
them. Sherif (2007) proposed the use of memo-
ryless stochastic transducer for extracting translit-
eration through word similarity metrics.
Other approaches for transliteration include
translation of names through mining or through
using machine translation systems resources. Has-
san (2007) et al. proposed a framework for extrac-
tion of named entity translation pairs. This is done
through searching for candidate documents pairs
through an information retrieval system and then
using a named entity matching system which re-
lies on the length-normalized phonetic based edit
distance between the two words. They also use
a phrase-based translation tables to measure simi-
larity of extracted named entities. Noeman (2009)
also used a phrase based statistical machine trans-
lation (PBSMT) approach to create a substring
based transliteration system through the generated
phrase table, thus creating a language indepen-
dent approach to transliteration. Other resources
have been used to perform transliteration. Chang
(2009) et. al proposed the use of a romanization
table in conjunction with an unsupervised con-
straint driven learning algorithm in order to iden-
tify transliteration pairs without any labelled data.
</bodyText>
<sectionHeader confidence="0.968451" genericHeader="method">
3 System architecture
</sectionHeader>
<bodyText confidence="0.9882835">
The approach consists of three main phases which
are (1) Transliteration model learning, (2) Fi-
</bodyText>
<page confidence="0.997411">
57
</page>
<note confidence="0.91291">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 57–61,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999761">
Figure 1: Transliteration table learning in PBSMT
</figureCaption>
<bodyText confidence="0.98021">
nite State machine formalization of the generated
transliteration model and (3) Generating Candi-
date transliterations. Figure (1) illustrates Translit-
eration table learning in PBSMT framework. A
detailed description of each phase is given in the
following sections.
</bodyText>
<subsectionHeader confidence="0.991721">
3.1 Transliteration model learning
</subsectionHeader>
<bodyText confidence="0.999941545454545">
The objective of NEWS2010 shared task is to de-
velop a system for mining single word translitera-
tion pairs from the standard Wikipedia paired top-
ics (Wikipedia Inter-Language Links, or WIL1),
using a seed data of only 1000 parallel names. The
aim is to learn one-to-many character sequence
mappings on both directions.
We propose the use of MOSES framework1 for
PBSMT training which was applied on the 1k par-
allel seed data. The proposed approach depends on
the formulation of the transliteration problem us-
ing the PBSMT approach used in Machine trans-
lation. Giza++ Hidden Markov Model (HMM)
aligner2 proposed by Och (1999) was also used
over the parallel character sequences. Heuristics
were used to extend substring to substring map-
pings based on character-to-character alignment.
This generated a substring to substring translation
model such as in Koehn (2003). The phrase ”sub-
string” table was filtered out to obtain all possi-
ble substrings alignment of each single character
in the language alphabet in both directions. This
means that for each character in the source lan-
guage (English) alphabet, substrings mapped to it
are filtered with a threshold. Also for each char-
acter in the target language (Arabic) alphabet, all
English substrings mapped to it are filtered with
a threshold. These two one-to-many alignments
were intersected in one ”Transliteration Arabic-to-
English mapping”. We obtained a character align-
ment table which we refer to as ”Ar2En list”. Fig-
ure(2) illustrates a sample one-to-many alignment
mapping.
</bodyText>
<footnote confidence="0.999948">
1MOSES Framework: http://www.statmt.org/moses/
2GIZA++ Aligner: http://fjoch.com/GIZA++.html
</footnote>
<figureCaption confidence="0.999977">
Figure 2: One to Many Alignment Mapping
Figure 3: Edit distance 1 FSM
</figureCaption>
<subsectionHeader confidence="0.931484">
3.2 FSM formalization of Transliteration
Model
</subsectionHeader>
<bodyText confidence="0.999780545454545">
The proposed method makes use of the finite state
automaton representation for the Ar2En character
alignment list, where the input is the source char-
acter and the output is the target character. We re-
fer to this finite state transducer (FST) as ”Ar2En
FST”. For each source word, we build a Finite
State Acceptor (FSA), such that each candidate
source word FSA is composed with the ”Ar2En
FST”. For the target words list, we build a finite
state acceptor (FSA) that contains a path for each
word in the target Wiki-Link.
</bodyText>
<subsectionHeader confidence="0.993814">
3.3 Generating Candidate transliterations
</subsectionHeader>
<bodyText confidence="0.999759333333333">
The task of generating candidate transliterations
at edit distance k from initial source candidate
transliterations using Levenshtein transducer can
be divided into two sub tasks: Generating a list of
words that have edit distance less than or equal k
to the input word, and selecting the words inter-
</bodyText>
<figure confidence="0.999671611111111">
b:b/0
a:a/0
1
b:a/0
a:b/0
&lt;epsilon&gt;:b/0
a:&lt;epsilon&gt;/0
a:b/0
b:&lt;epsilon&gt;/0
b:a/0
&lt;epsilon&gt;:a/0
4
3
b:a/0
a:b/0
2/0.25
b:b/0
a:a/0
</figure>
<page confidence="0.812748">
58
</page>
<figureCaption confidence="0.999747">
Figure 4: Edit distance 2 FSM
</figureCaption>
<bodyText confidence="0.99787">
secting with the target inter-wiki-link words. This
is similar to the spelling correction technique that
used FSM which was introduced by Hassan (2008)
et. al. In the spelling correction task , after gener-
ating the list of words within edit distance k to the
input word, the system selects a subset of those
words that exist in a large dictionary. In order to
accomplish this same scenario, we created a sin-
gle transducer (Levenshtein transducer) that when
composed with an FSM representing a word gen-
erates all words within an edit distance k from the
input word. We then compose the resulting FSM
with an FSA (finite state acceptor) of all words in
the target inter-wiki-link. The Levenshtein trans-
ducer is language independent and is built only
using the alphabet of the target language. Figure
(3) and Figure (4) illustrate the Levenshtein trans-
ducer for edit distance 1 and 2 over a limited set of
vocabulary (a, b).
</bodyText>
<sectionHeader confidence="0.982633" genericHeader="method">
4 Data and Resources Processing
</sectionHeader>
<bodyText confidence="0.99278925">
After revising the training data (inter-wiki-links)
released, we discovered that English and Arabic
words contained many stress marks and non nor-
malized characters. We therefore applied normal-
ization on Arabic and English characters to in-
crease source target matching probability, thus in-
creasing the recall of data mining. We also nor-
malized Arabic names, removing all diacritics and
kashida. Kashida is a type of justification used in
some cursive scripts such as Arabic. Also we nor-
malized Alef () with hamza and madda to go to
”bare Alef”.
</bodyText>
<figureCaption confidence="0.974203">
Figure 5: Using Levenshtein edit-1 FST
</figureCaption>
<sectionHeader confidence="0.886705" genericHeader="method">
5 Standard runs
</sectionHeader>
<bodyText confidence="0.999978125">
We submitted 6 runs derived from 3 experiments.
For each experiment, we submitted 2 runs, one
with normalized Arabic and English characters,
and the other with the stress marks and special
characters. It is important to note that we run the
mining in the Arabic to English direction, thus the
Arabic side is the source and the English side is
the target.
</bodyText>
<subsectionHeader confidence="0.99817">
5.1 Using Levenshtein edit distance 1 FST
</subsectionHeader>
<bodyText confidence="0.999461133333334">
Figure (5) illustrates the algorithm used to con-
duct the first experiment. We subjected all source
words to be composed with Levenshtein edit dis-
tance 1. For each Wiki-Link, we build a finite
state acceptor (FSA) that contains a path for each
word in the Arabic Wiki-Link. We refer to it as
FSA[@ArWords]. Similarly, for the English name
candidates we build a finite state acceptor (FSA)
that contains a path for each word in the English
Wiki-Link. We refer to it as FSA[@EnWords].
The generated @ArWords and @EnWords are the
lists of words in the Arabic and English wiki-links
respectively. The result of this experiment was re-
ported as Standard-3 ”normalized characters” and
Standard-4 ”without normalized characters”.
</bodyText>
<subsectionHeader confidence="0.9053385">
5.2 Using Levenshtein up to edit distance 2
FST
</subsectionHeader>
<bodyText confidence="0.988272">
Figure (6) illustrates the algorithm used to conduct
the second experiment. We use a threshold on the
number of characters in a word to decide whether
it will be subjected for ”composed with” edit dis-
</bodyText>
<figure confidence="0.999483787878788">
b:b/0
a:a/0
1
b:a/0
a:
b:&lt;epsilon&gt;/0
b:a/0
&lt;epsilon&gt;:a/0
&lt;epsilon&gt;:b/0
a:&lt;epsilon&gt;/0
a:b/0
4
5
b:a/0
a:b/0
2/0.25
b:b/0
a:a/0
b:a/0
a:
b:&lt;epsilon&gt;/0
b:a/0
&lt;epsilon&gt;:a/0
&lt;epsilon&gt;:b/0
a:&lt;epsilon&gt;/0
a:
6
7
b:a/0
a:b/0
b:b/0
3/0.5
a:a/0
</figure>
<page confidence="0.875291">
59
</page>
<figureCaption confidence="0.999502">
Figure 6: Using Levenshtein edit-2 FST
</figureCaption>
<bodyText confidence="0.995956153846154">
tance 0 or 1 or 2. We use a threshold of 3 for
edit distance 1 and a threshold of 7 for edit dis-
tance 2. The threshold values are set based on our
previous experience from dealing with Arabic text
and could be derived from the data we obtained.
If word length is less than or equal 3 letters, then
it is not composed with Levenshtein FSTs, and if
word length is between 4 to 7 letters, we compose
it with edit distance 1 FST. Longer words are com-
posed with edit distance 2 FST. The result of the
experiment was reported in two submitted runs:
Standard-5 ”normalized characters” and Standard-
6 ”without normalized characters”.
</bodyText>
<subsectionHeader confidence="0.992465">
5.3 Baseline
</subsectionHeader>
<bodyText confidence="0.99857575">
We use a length-normalized phonetic edit distance
to measure the phonetic similarity between the
source and target Named Entities in the inter-wiki-
links. We use the Editex technique Zobel (1996)
that makes use of the phonetic characteristics of
individual characters to estimate their similarity.
Editex measures the phonetic distance between
pairs of words by combining the properties of
edit distances with a letter grouping strategy that
groups letters with similar pronunciations. The re-
sult of this experiment was reported in two submit-
ted runs: Standard-1 ”normalized characters” and
</bodyText>
<table confidence="0.999641">
Submission F-Score Precision Recall
Standard-6 0.915 0.887 0.945
Standard-4 0.903 0.859 0.952
Standard-2 0.874 0.923 0.830
Standard-5 0.723 0.701 0.747
Standard-3 0.716 0.681 0.755
Standard-1 0.702 0.741 0.666
</table>
<tableCaption confidence="0.997093">
Table 1: Shared Task Results
</tableCaption>
<bodyText confidence="0.44113">
Standard-2 ”without normalized characters”.
</bodyText>
<sectionHeader confidence="0.999746" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.998661636363636">
Table (1) illustrates the results of the shared task
given on the runs we submitted.
Our baseline run (Standard-2) reports highest
precision of 0.923 and lowest recall of 0.830 (low-
est F-score = 0.874). The reason is that Editex
technique measures the edit distance based on let-
ter grouping strategy which groups letters with
similar pronunciations. It operates on character to
character level. Letters that are mapped to multi-
characters will suffer a large edit distance and may
exceed the matching threshold used.
The two runs Standard-4 and Standard-6 are
implemented using edit-distance FSM matching
between source and target. They cover one-to-
many character mapping. We notice that Standard-
6 run reports higher precision of 0.887 compared
to 0.859 for Standard-4 run. This reflects the ef-
fect of using variable edit-distance according to
the source word length. The Standard-6 reports
a Recall of 0.945 producing our best F-Score of
0.915. Standard-6 recall degrades only 0.7% from
Standard-4 Recall (0.952).
</bodyText>
<sectionHeader confidence="0.998374" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999954818181818">
We proposed a language independent transliter-
ation mining system that utilizes finite state au-
tomaton. We demonstrated how statistical tech-
niques could be used to build a language indepen-
dent machine transliteration system through uti-
lizing PBMT techniques. We performed 3 stan-
dard experiments each containing two submis-
sions. FSM edit distance matching outperformed
Editex in F-Score and Recall. The proposed ap-
proach obtained the highest F-Score of 0.915 and
a recall of 0.945 in the shared task.
</bodyText>
<page confidence="0.997836">
60
</page>
<sectionHeader confidence="0.995773" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999789813953489">
Ahmed Hassan, Haytham Fahmy, Hany Hassan 2007.
Improving Named Entity Translation by Exploiting
Comparable and Parallel Corpora. AMML07
Ahmed Hassan, Sara Noeman, Hany Hassan 2008.
Language Independent Text Correction using Finite
State Automata. IJCNLP08.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney 1999. Improved Alignment Models for Statisti-
cal Machine Translation. EMNLP.
Justin Zobel and Philip Dart 1996. Phonetic string
matching: Lessons from information retrieval. In
Proceedings of the Annual ACM References Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR).
M. G. Abbas Malik, Christian Boitet, Pushpak Bhat-
tacharyya 2008. Hindi Urdu Machine Transliter-
ation using Finite-state Transducers. Proceedings
of the 22nd International Conference on Computa-
tional Linguistics (Coling 2008), pages 537544
Ming-Wei Chang, Dan Goldwasser, Dan Roth,
Yuancheng Tu 2009. Unsupervised Constraint
Driven Learning For Transliteration Discovery.
Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics.
Philipp Koehn, Franz Josef Och, Daniel Marc 2003.
Statistical Phrase-Based Translation. Proc. Of the
Human Language Technology Conference, HLT-
NAACL2003, May.
Sara Noeman 2009. Language Independent Transliter-
ation system using PBSMT approach on substrings.
Proceedings of the 2009 Named Entities Workshop:
Shared Task on Transliteration.
Tarek Sherif, Grzegorz Kondrak 2007. Bootstrapping
a Stochastic Transducerfor Arabic-English Translit-
eration Extraction. Proceedings of the 45th Annual
Meeting of the Association of Computational Lin-
guistics, pages 864871
Yasser Al-Onaizan, Kevin Knight 2002. Machine
Transliteration of Names in Arabic Text. ACL
Workshop on Comp. Approaches to Semitic Lan-
guages.
</reference>
<page confidence="0.999269">
61
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.364709">
<title confidence="0.890694">Language Independent Transliteration Mining System Using Finite State Automata Framework Sara Noeman and Amgad Human Language Technologies</title>
<affiliation confidence="0.672603">IBM Cairo Technology Development</affiliation>
<address confidence="0.748327">P.O.Box 166 El-Haram, Giza,</address>
<abstract confidence="0.98911">We propose a Named Entities transliteration mining system using Finite State Automata (FSA). We compare the proposed approach with a baseline system that utilizes the Editex technique to measure the length-normalized phonetic based edit distance between the two words. We submitted three standard runs in NEWS2010 shared task and ranked first for English to Arabic (WM-EnAr) and obtained an Fmeasure of 0.915, 0.903, and 0.874 respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
</authors>
<title>Haytham Fahmy, Hany Hassan</title>
<date>2007</date>
<pages>07</pages>
<contexts>
<context position="2720" citStr="Hassan (2007)" startWordPosition="391" endWordPosition="393">ling-based models. Malik (2008) et al. proposed a Hindi Urdu machine transliteration system using finite state machines. They introduced UIT (universal intermediate transcription) on the same pair according to thier phonetic properties as a means of representing the language and created finite state transducers to represent them. Sherif (2007) proposed the use of memoryless stochastic transducer for extracting transliteration through word similarity metrics. Other approaches for transliteration include translation of names through mining or through using machine translation systems resources. Hassan (2007) et al. proposed a framework for extraction of named entity translation pairs. This is done through searching for candidate documents pairs through an information retrieval system and then using a named entity matching system which relies on the length-normalized phonetic based edit distance between the two words. They also use a phrase-based translation tables to measure similarity of extracted named entities. Noeman (2009) also used a phrase based statistical machine translation (PBSMT) approach to create a substring based transliteration system through the generated phrase table, thus creat</context>
</contexts>
<marker>Hassan, 2007</marker>
<rawString>Ahmed Hassan, Haytham Fahmy, Hany Hassan 2007. Improving Named Entity Translation by Exploiting Comparable and Parallel Corpora. AMML07</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
</authors>
<title>Sara Noeman, Hany Hassan</title>
<date>2008</date>
<contexts>
<context position="1571" citStr="Hassan (2008)" startWordPosition="224" endWordPosition="225">troduced a statistical approach for transliteration generation only using the bilingual resources (about 15k parallel names) provided for the shared task. For NEWS2010, the shared task focuses on acquisition of a reasonably sized, good quality names corpus to complement the machine transliteration task. Specifically, the task focuses on mining the Wikipedia paired entities data (inter-wiki-links) to produce high-quality transliteration data that may be used for transliteration generation tasks. 2 Related Work Finite state Automata is used to tackle many Natural Language Processing challenges. Hassan (2008) et al. proposed the use of finite state automata for language-independent text correction. It consists of three phases : detecting misspelled words, generating candidate corrections for them and ranking corrections. In detecting the mispelled words, they compose the finite state automaton representation of the dictionary with the input string. Onaizan (2002) et al. proposed the use of probabilistic finite state machines for machine transliteration of names in Arabic text. They used a hybrid approach between phoneticbased and spelling-based models. Malik (2008) et al. proposed a Hindi Urdu mac</context>
<context position="7177" citStr="Hassan (2008)" startWordPosition="1076" endWordPosition="1077">The task of generating candidate transliterations at edit distance k from initial source candidate transliterations using Levenshtein transducer can be divided into two sub tasks: Generating a list of words that have edit distance less than or equal k to the input word, and selecting the words interb:b/0 a:a/0 1 b:a/0 a:b/0 &lt;epsilon&gt;:b/0 a:&lt;epsilon&gt;/0 a:b/0 b:&lt;epsilon&gt;/0 b:a/0 &lt;epsilon&gt;:a/0 4 3 b:a/0 a:b/0 2/0.25 b:b/0 a:a/0 58 Figure 4: Edit distance 2 FSM secting with the target inter-wiki-link words. This is similar to the spelling correction technique that used FSM which was introduced by Hassan (2008) et. al. In the spelling correction task , after generating the list of words within edit distance k to the input word, the system selects a subset of those words that exist in a large dictionary. In order to accomplish this same scenario, we created a single transducer (Levenshtein transducer) that when composed with an FSM representing a word generates all words within an edit distance k from the input word. We then compose the resulting FSM with an FSA (finite state acceptor) of all words in the target inter-wiki-link. The Levenshtein transducer is language independent and is built only usi</context>
</contexts>
<marker>Hassan, 2008</marker>
<rawString>Ahmed Hassan, Sara Noeman, Hany Hassan 2008. Language Independent Text Correction using Finite State Automata. IJCNLP08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Alignment Models for Statistical Machine Translation.</title>
<date>1999</date>
<publisher>EMNLP.</publisher>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Franz Josef Och, Christoph Tillmann, and Hermann Ney 1999. Improved Alignment Models for Statistical Machine Translation. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Zobel</author>
<author>Philip Dart</author>
</authors>
<title>Phonetic string matching: Lessons from information retrieval.</title>
<date>1996</date>
<booktitle>In Proceedings of the Annual ACM References Conference on Research and Development in Information Retrieval (SIGIR).</booktitle>
<marker>Zobel, Dart, 1996</marker>
<rawString>Justin Zobel and Philip Dart 1996. Phonetic string matching: Lessons from information retrieval. In Proceedings of the Annual ACM References Conference on Research and Development in Information Retrieval (SIGIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Abbas Malik</author>
<author>Christian Boitet</author>
</authors>
<title>Pushpak Bhattacharyya</title>
<date>2008</date>
<booktitle>Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>537544</pages>
<marker>Malik, Boitet, 2008</marker>
<rawString>M. G. Abbas Malik, Christian Boitet, Pushpak Bhattacharyya 2008. Hindi Urdu Machine Transliteration using Finite-state Transducers. Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 537544</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
</authors>
<title>Unsupervised Constraint Driven Learning For Transliteration Discovery.</title>
<date>2009</date>
<booktitle>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<location>Yuancheng Tu</location>
<marker>Chang, Goldwasser, Roth, 2009</marker>
<rawString>Ming-Wei Chang, Dan Goldwasser, Dan Roth, Yuancheng Tu 2009. Unsupervised Constraint Driven Learning For Transliteration Discovery. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marc</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>Proc. Of the Human Language Technology Conference, HLTNAACL2003,</booktitle>
<marker>Koehn, Och, Marc, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, Daniel Marc 2003. Statistical Phrase-Based Translation. Proc. Of the Human Language Technology Conference, HLTNAACL2003, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Noeman</author>
</authors>
<title>Language Independent Transliteration system using PBSMT approach on substrings.</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration.</booktitle>
<contexts>
<context position="3148" citStr="Noeman (2009)" startWordPosition="458" endWordPosition="459">n through word similarity metrics. Other approaches for transliteration include translation of names through mining or through using machine translation systems resources. Hassan (2007) et al. proposed a framework for extraction of named entity translation pairs. This is done through searching for candidate documents pairs through an information retrieval system and then using a named entity matching system which relies on the length-normalized phonetic based edit distance between the two words. They also use a phrase-based translation tables to measure similarity of extracted named entities. Noeman (2009) also used a phrase based statistical machine translation (PBSMT) approach to create a substring based transliteration system through the generated phrase table, thus creating a language independent approach to transliteration. Other resources have been used to perform transliteration. Chang (2009) et. al proposed the use of a romanization table in conjunction with an unsupervised constraint driven learning algorithm in order to identify transliteration pairs without any labelled data. 3 System architecture The approach consists of three main phases which are (1) Transliteration model learning</context>
</contexts>
<marker>Noeman, 2009</marker>
<rawString>Sara Noeman 2009. Language Independent Transliteration system using PBSMT approach on substrings. Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
</authors>
<title>Grzegorz Kondrak</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>864871</pages>
<contexts>
<context position="2452" citStr="Sherif (2007)" startWordPosition="356" endWordPosition="357">finite state automaton representation of the dictionary with the input string. Onaizan (2002) et al. proposed the use of probabilistic finite state machines for machine transliteration of names in Arabic text. They used a hybrid approach between phoneticbased and spelling-based models. Malik (2008) et al. proposed a Hindi Urdu machine transliteration system using finite state machines. They introduced UIT (universal intermediate transcription) on the same pair according to thier phonetic properties as a means of representing the language and created finite state transducers to represent them. Sherif (2007) proposed the use of memoryless stochastic transducer for extracting transliteration through word similarity metrics. Other approaches for transliteration include translation of names through mining or through using machine translation systems resources. Hassan (2007) et al. proposed a framework for extraction of named entity translation pairs. This is done through searching for candidate documents pairs through an information retrieval system and then using a named entity matching system which relies on the length-normalized phonetic based edit distance between the two words. They also use a </context>
</contexts>
<marker>Sherif, 2007</marker>
<rawString>Tarek Sherif, Grzegorz Kondrak 2007. Bootstrapping a Stochastic Transducerfor Arabic-English Transliteration Extraction. Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 864871</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<date>2002</date>
<booktitle>Machine Transliteration of Names in Arabic Text. ACL Workshop on Comp. Approaches to Semitic Languages.</booktitle>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yasser Al-Onaizan, Kevin Knight 2002. Machine Transliteration of Names in Arabic Text. ACL Workshop on Comp. Approaches to Semitic Languages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>