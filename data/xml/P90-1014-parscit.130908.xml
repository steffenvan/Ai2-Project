<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.675793">
Free Indexation: Combinatorial Analysis and
A Compositional Algorithm*
</title>
<author confidence="0.382256">
Sandiway Fong
</author>
<note confidence="0.770993333333333">
545 Technology Square, Rm. NE43-810,
MIT Artificial Intelligence Laboratory,
Cambridge MA 02139
</note>
<email confidence="0.662568">
Internet: sandiwaygai.mit.edu
</email>
<sectionHeader confidence="0.912366" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999829">
The principle known as &apos;free indexation&apos; plays
an important role in the determination of the refer-
ential properties of noun phrases in the principle-
and-parameters language framework. First, by in-
vestigating the combinatorics of free indexation,
we show that the problem of enumerating all possi-
ble indexings requires exponential time. Secondly,
we exhibit a provably optimal free indexation al-
gorithm.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99988647826087">
In the principles-and-parameters model of lan-
guage, the principle known as Tree indexation&apos;
plays an important part in the process of deter-
mining the referential properties of elements such
as anaphors and pronominals. This paper ad-
dresses two issues. (1) We investigate the cornbi-
natorics of free indexation. By relating the prob-
lem to the n-set partitioning problem, we show
that free indexation must produce an exponen-
tial number of referentially distinct phrase struc-
tures given a structure with n (independent) noun
phrases. (2) We introduce an algorithm for free in-
dexation that is defined compositionally on phrase
structures. We show how the compositional na-
ture of the algorithm makes it possible to incre-
mentally interleave the computation of free index-
ation with phrase structure construction. Addi-
tionally, we prove the algorithm to be an &apos;optimal&apos;
procedure for free indexation. More precisely, by
relating the compositional structure of the formu-
lation to the combinatorial analysis, we show that
the algorithm enumerates precisely all possible in-
dexings, without duplicates.
</bodyText>
<sectionHeader confidence="0.985335" genericHeader="method">
2 Free Indexation
</sectionHeader>
<bodyText confidence="0.503688">
Consider the ambiguous sentence:
</bodyText>
<listItem confidence="0.712403">
(1) John believes Bill will identify him
</listItem>
<bodyText confidence="0.995356125">
The author would like to acknowledge Eric S. Ris-
tad, whose interaction helped to motivate much of
the analysis in this paper. Also, Robert C. Berwick,
Michael B. Kashket, and Tanveer Syeda provided
many useful comments on earlier drafts. This work
is supported by an IBM Graduate Fellowship.
In (I), the pronominal &amp;quot;him&amp;quot; can be interpreted
as being coreferential with &amp;quot;John&amp;quot;, or with some
other person not named in (1), but not with &amp;quot;Bill&amp;quot;.
We can represent these various cases by assigning
indices to all noun phrases in a sentence together
with the interpretation that two noun phrases are
coreferential if and only if they are coindexed, that
is, if they have the same index. Hence the follow-
ing indexings represent the three coreference op-
tions for pronominal &amp;quot;him&amp;quot; :1
</bodyText>
<listItem confidence="0.976918333333333">
(2) a. John&apos; believes Bill2 will identify himi
b. John&apos; believes Bill2 will identify him3
c. *John&apos; believes Bill2 will identify him2
</listItem>
<bodyText confidence="0.945624666666667">
In the principles-and-parameters framework
(Chomsky [31), once indices have been assigned,
general principles that state constraints on the lo-
cality of reference of pronominals and names (e.g.
&amp;quot;John&amp;quot; and &amp;quot;Bill&amp;quot;) will conspire to rule out the
impossible interpretation (2c) while, at the same
time, allow the other two (valid) interpretations.
The process of assigning indices to noun phrases
is known as &amp;quot;free indexation,&amp;quot; which has the fol-
lowing general form:
(4) Assign indices freely to all noun
phrases.2
In such theories, free indexation accounts for the
fact that we have coreferential ambiguities in lan-
guage. Other principles interact so as to limit the
&apos;Note that the indexing mechanism used above is
too simplistic a framework to handle binding examples
involving inclusion of reference such as:
</bodyText>
<listItem confidence="0.98882675">
(3) a. Wel think that II will win
b. Wel think that 12 will win
c. *Wei like myself,
d. John told Bill that they should leave
</listItem>
<bodyText confidence="0.996422727272727">
Richer schemes that address some of these problems,
for example, by representing indices as sets of num-
bers, have been proposed. See Lasnik [9] for a discus-
sion on the limitations of, and alternatives to, simple
indexation. Also, Higginbotham [71 has argued against
coindexation (a symmetric relation), and in favour of
directed links between elements (linking theory). In
general, there will be twice as many possible `linkings&apos;
as indexings for a given structure. However, note that
the asymptotic results of Section 3 obtained for free
indexation will also hold for linking theory.
</bodyText>
<page confidence="0.998743">
105
</page>
<bodyText confidence="0.999507125">
number of indexings generated by free indexation
to those that are semantically well-formed.
In theory, since the indices are drawn from the
set of natural numbers, there exists an infinite
number of possible indexings for any sentence.
However, we are only interested in those indexings
that are distinct with respect to semantic interpre-
tation. Since the interpretation of indices is con-
cerned only with the equality (and inequality) of
indices, there are only a finite number of seman-
tically different indexings.3 For example, &amp;quot;Johni
likes Mary2&amp;quot; and &amp;quot;John23 likes Mary: are con-
sidered to be equivalent indexings. Note that the
definition in (4) implies that &amp;quot;John believes Bill
will identify him&amp;quot; has two other indexings (in ad-
dition to those in (2)):
</bodyText>
<listItem confidence="0.7362025">
(5) a. *John&apos; believes Billi will identify himi
b. *Johni believes Bali will identify him2
</listItem>
<bodyText confidence="0.997886428571429">
In some versions of the theory, indices are only
freely assigned to those noun phrases that have
not been coindexed through a rule of movement
(Move-a). (see Chomsky [3] (pg.331)). For exam-
ple, in &amp;quot;Whoi did John see [Npi]i?&amp;quot;, the rule of
movement effectively stipulates that &amp;quot;Who&amp;quot; and
its trace noun phrase must be careferential. In
particular, this implies that free indexation must
not assign different indices to &amp;quot;who&amp;quot; and its trace
element. For the purposes of free indexation, we
can essentially &apos;collapse&apos; these two noun phrases,
and treat them as if they were only one. Hence,
this structure contains only two independent noun
phrases.4
</bodyText>
<sectionHeader confidence="0.870298" genericHeader="method">
3 The Combinatorics of
Free Indexation
</sectionHeader>
<bodyText confidence="0.997634375">
In this section, we show that free indexation gen-
erates an exponential number of indexings in the
number of independent noun phrases in a phrase
structure. We achieve this result by observing that
the problem of free indexation can be expressed in
terms of a well-known combinatorial partitioning
problem,
Consider the general problem of partitioning
a set of n elements into 771 non-empty (disjoint)
&apos;The exact form of (4) varies according to different
versions of the theory. For example, in Chorrisky [4]
(pg.59), free indexation is restricted to apply to A-
positions at the level of S-structure, and to A-positions
at the level of logical form.
sin other words, there are only a finite number of
equivalence classes on the relation &apos;same coreference
relations bold.&apos; This can easily be shown by induction
on the number of indexed elements.
4Technically, &amp;quot;who&amp;quot; and its trace are said to form
a chain. Hence, the structure in question contains two
distinct chains.
subsets, For example, a set of four elements
{so, x, j, z} can be partitioned into two subsets in
the following seven ways:
</bodyText>
<equation confidence="0.95433025">
{w,x,Y}{z} {•tv36}{Y,z}
t,z}{Y} {1/),Y}{x,z}
{tv,y,z}{x} {ro, z}{x,y}
{x,y, z){w}
</equation>
<bodyText confidence="0.999840166666667">
The number of partitions obtained thus is
usually represented using the notation 1m&apos;
(Knuth [8]). In general, the number of ways of
partitioning n elements into m sets is given by the
following formula. (See Purdom &amp; Brown [10] for
a discussion of (6).)
</bodyText>
<equation confidence="0.996203">
(6)
{n + 1
rn + = + (m +1){.: if
for ra, m &gt; 0
</equation>
<bodyText confidence="0.983651636363636">
The number of ways of partitioning n elements
into zero sets, Inol, is defined to be zero for is &gt; 0
and one when is = 0. Similarly, trn° , the number
of ways of partitioning zero elements into m sets
is zero for ns &gt; 0 and one when m = 0.
We observe that the problem of free indexa-
tion may be expressed as the problem of assign-
ing 1,2, , n distinct indices ton noun phrases
where is is the number of noun phrases in a sen-
tence. Now, the general problem of assigning m
distinct indices to is noun phrases is isomorphic
to the problem of partitioning n elements into m
non-empty disjoint subsets. The correspondence
here is that each partitioned subset represents a
set of noun phrases with the same index. Hence,
the number of indexings for a sentence with is noun
phrases is:
ntlynn}
(The quantity in (7) is commonly known as
Bell&apos;s Exponential Number Bn; see Berge [2].)
The recurrence relation in (6) has the following
solution (Abramowitz [1]):
</bodyText>
<equation confidence="0.987879">
m
{7&apos;1&apos; = m—k (M)kn
rri in!
k =0
</equation>
<bodyText confidence="0.9955575">
Using (8), we can obtain a finite summation
form for the number of indexings:
</bodyText>
<equation confidence="0.985665666666667">
(9)
Bn
m = I k0 k)! lc!kn
</equation>
<page confidence="0.955271">
106
</page>
<bodyText confidence="0.9974335">
It can also be shown (Graham [6]) that .13„ is
asymptotically equal to (10):
</bodyText>
<equation confidence="0.974411333333333">
(10)
mnnem„—n—
V17-1
</equation>
<bodyText confidence="0.983779">
where the quantity nin is given by:
</bodyText>
<equation confidence="0.661504333333333">
(11)
Tun In ran n
2
</equation>
<bodyText confidence="0.983887285714286">
That is, (10) is both an upper and lower bound
on the number of indexings. More concretely, to
provide some idea of how fast the number of pos-
sible indexings increases with the number of noun
phrases in a phrase structure, the following table
exhibits the values of (9) for the first dozen values
of n:
</bodyText>
<table confidence="0.967916428571429">
NPs Indexings NPs Indexings
1 1 7 877
2 2 8 4140
3 5 9 21147
4 15 10 115975
5 52 11 678570
6 203 12 4123597
</table>
<sectionHeader confidence="0.9950725" genericHeader="method">
4 A Compositional
Algorithm
</sectionHeader>
<bodyText confidence="0.998257550000001">
In this section, we will define a compositional algo-
rithm for free indexation that provably enumerates
all and only all the possible indexings predicted by
the analysis of the previous section.
The PO-PARSER is a parser based
on a principles-and-parameters framework with a
uniquely flexible architecture ([5]). In this parser,
linguistic principles such as free indexation may be
applied either incrementally as bottom-up phrase
structure construction proceeds, or as a separate
operation after the complete phrase structure for
a sentence is recovered. The PO-PARSER was de-
signed primarily as a toot for exploring how to
organize linguistic principles for efficient process-
ing. This freedom in principle application allows
one to experiment with a wide variety of parser
configurations.
Perhaps the most obvious algorithm for free in-
dexation is, first, to simply collect all noun phrases
occurring in a sentence into a list. Then, it is easy
to obtain all the possible indexing combinations
by taking each element in the list in turn, and
optionally coindexing it with each element follow-
ing it in the list. This simple scheme produces
each possible indexing without any duplicates and
works well in the case where free indexing applies
after structure building has been completed.
The problem with the above scheme is that it is
not flexible enough to deal with the case when free
indexing is to be interleaved with phrase structure
construction. Conceivably, one could repeatedly
apply the algorithm to avoid missing possible in-
dexings. However, this is very inefficient, that is,
it involves much duplication of effort. Moreover,
it may be necessary to introduce extra machin-
ery to keep track of each assignment of indices
in order to avoid the problem of producing du-
plicate indexings. Another alternative is to sim-
ply delay the operation until all noun phrases in
the sentence have been parsed. (This is basically
the same arrangement as in the non-interleaved
case.) Unfortunately, this effectively blocks the
interleaved application of other principles that are
logically dependent on free indexation to assign
indices. For example, this means that principles
that deal with locality restrictions on the bind-
ing of anaphors and pronorninals cannot be in-
terleaved with structure building (despite the fact
that these particular parser operations can be ef-
fectively interleaved).
An algorithm for free indexation that is defined
composationally on phrase structures can be effec-
tively interleaved. That is, free indexing should be
defined so that the indexings for a phrase is some
function of the indexings of its sub-constituents.
Then, coindexings can be computed incrementally
for all individual phrases as they are built. Of
course, a compositional algorithm can also be used
in the non-interleaved case.
Basically, the algorithm works by maintaining a
set of indices at each sub-phrase of a parse tree.5
Each index set for a phrase represents the range
of indices present in that phrase. For example,
&amp;quot;Who i did Johni see ti?&amp;quot; has the phrase structure
and index sets shown in Figure 1.
There are two separate tasks to be performed
whenever two (or more) phrases combine to form
a larger phrase.6 First, we must account for the
possibility that elements in one phrase could be
coindexed (cross-indexed) with elements from the
other phrase. This is accomplished by allowing in-
dices from one set to be (optionally) merged with
distinct indices from the other set. For example,
the phrases &amp;quot;[NpJohni]&amp;quot; and &amp;quot;[VP likes hirrii]&amp;quot;
have index sets {i} and {j}, respectively. Free
indexation must allow for the possibilities that
&amp;quot;John&amp;quot; and &amp;quot;him&amp;quot; could be coindexed or main-
tain distinct indices. Cross-indexing accounts for
this by optionally merging indices i and j. Hence,
we obtain:
</bodyText>
<listItem confidence="0.626153">
(12) a. John i likes him, i merged with j
</listItem>
<tableCaption confidence="0.588879666666667">
&apos;For expository reasons, we consider only pure in-
dices. The actual algorithm keeps track of additional
information, such as agreement features like person,
number and gender, associated with each index. For
example, irrespective of configuration, &amp;quot;Mary&amp;quot; and
&amp;quot;him&amp;quot; can never have the same index,
</tableCaption>
<page confidence="0.983793">
107
</page>
<figure confidence="0.464287">
[cP (NP who] [7, did lip [ATP Johns] [VP see [NP
{i} fi,51 fil fil
</figure>
<figureCaption confidence="0.871099">
Figure 1 Index sets for &amp;quot;Who did John see?&amp;quot;
</figureCaption>
<bodyText confidence="0.944814666666667">
b. John i likes him, i not merged with j
Secondly, we must find the index set of the ag-
gregate phrase. This is just the set union of the in-
dex sets of its sub-phrases after cross-indexation.
In the example, &amp;quot;John likes him&amp;quot;, (12a) and (12b)
have index sets {i} and {i,./}.
More precisely, let Ip be the set of all in-
dices associated with the Binding Theory-relevant
elements in phrase P. Assume, without loss
of generality, that phrase structures are binary
branching.7 Consider a phrase P = [p X Y1 with
immediate constituents X and Y. Then:
</bodyText>
<listItem confidence="0.974710142857143">
1. Cross Indexing: Let Ix represent those ele-
ments of Ix which are not also members of
ly, that is, (Ix — ly). Similarly, let ly be
Ix).8
(a) If either Ix or ly are empty sets, then
done.
(b) Let x and y be members of /x and ly,
respectively.
(c) Either merge indices x and y or do noth-
ing.
(d) Repeat from step (la) with .tx — {x} in
place of Ix . Replace ly with ly — {y} if
x and y have been merged.
2. Index Set Propagation: Ip = Ix U Iy
</listItem>
<bodyText confidence="0.998998695652174">
The nondeterminism in step (1c) of cross-
indexing will generate all and only all (i.e. with-
out duplicates) the possible indexings. We will
show this in two parts. First, we will argue that
6Some readers may realize that the algorithm must
have an additional step in cases where the larger
phrase itself may be indexed, for instance, as in
[NP,[Np John&apos;s ] mother]. In such cases, the third
step is simply to merge the singleton set consisting of
the index of the larger phrase with the result of cross-
indexing in the first step. (For the above example, the
extra step is to just merge {i) with {j}.) For exposi-
tory reasons, we will ignore such cases. Note that no
loss of generality is implied since a structure of the
form [Np,[Npi... a ...]... /3 ...] can be can always be
handled as [pi [Npi][P2[NP,• • a • ..]• 0 •
&apos;The algorithm generalizes to n-ary branching us-
ing iteration. For example, a ternary branching struc-
ture such as [p X V 2] would be handled in the same
way as [p X[p, Y Z]].
&apos;Note that Ix and iy are defined purely for no-
tational convenience. That is, the algorithm directly
operates on the elements of Ix and ly.
</bodyText>
<figure confidence="0.9683784">
Pijk
N
Pu
N Pk
Nps NA
</figure>
<figureCaption confidence="0.99903">
Figure 2 Right-branching tree
</figureCaption>
<bodyText confidence="0.85318375">
the above algorithm cannot generate duplicate in-
dexings. That is, the algorithm only generates
distinct indexings with respect to the interpreta-
tion of indices. As shown in the previous section,
the combinatorics of free-indexing indicates that
there are only Bn possible indexings. Next, we
will demonstrate that the algorithm generates ex-
actly that number of indexings. If the algorithm
satisfies both of these conditions, then we have
proved that it generates all the possible indexings
exactly once.
1. Consider the definition of cross-indexing. Ix
represents those indices in X that do not ap-
pear in Y. (Similarly for /y.) Also, whenever
two indices are merged in step (lb), they are
&apos;removed&apos; from Ix and _Ty before the next it-
eration. Thus, in each iteration, x and y from
step (1b) are &apos;new&apos; indices that have not been
merged with each other in a previous itera-
tion. By induction on tree structures, it is
easy to see that two distinct indices cannot
be merged with each other more than once.
Hence, the algorithm cannot generate dupli-
cate indexings.
2. We now demonstrate why the algorithm gen-
erates exactly the correct number of index-
ings by means of a simple example. Without
loss of generality, consider the right-branching
phrase scheme shown in Figure 2.
Now consider the decision tree shown in Fig-
ure 3 for computing the possible indexings of
the right-branching tree in a bottom-up fash-
ion.
Each node in the tree represents the index set
of the combined phrase depending on whether
the noun phrase at the same level is cross-
</bodyText>
<page confidence="0.993324">
108
</page>
<figure confidence="0.741462">
NPs Decision Tree
NP {i}
</figure>
<figureCaption confidence="0.891712">
Figure 3 Decision tree
</figureCaption>
<equation confidence="0.68394">
2 2 3
2 2 2 3 2 2 3 2 2 3 3 3 3 4
</equation>
<figureCaption confidence="0.998038">
Figure 4 Condensed decision tree
</figureCaption>
<bodyText confidence="0.999808523809524">
indexed or not. For example, {4 and
on the level corresponding to NP i are the two
possible index sets for the phrase P,. The
path from the root to an index set contains
arcs indicating what choices (either to coin-
dex or to leave free) must have been made in
order to build that index set. Next, let us
just consider the cardinality of the index sets
in the decision tree, and expand the tree one
more level (for NP1) as shown in Figure 4.
Informally speaking, observe that each deci-
sion tree node of cardinality i &apos;generates&apos; i
child nodes of cardinality i plus one child node
of cardinality i + 1. Thus, at any given level,
if the number of nodes of cardinality tra is cm,
and the number of nodes of cardinality Tri — 1
is c,71....1, then at the next level down, there
will be me, + cm_i nodes of car dinality m.
Let c(a,m) denote the number of nodes at
level a with cardinality m. Let the top level
of the decision tree be level 1. Then:
</bodyText>
<equation confidence="0.8472335">
(13)
c(n+1, m+1) =_- c(n, m)+(m.-1-1)c(n, m+1)
</equation>
<bodyText confidence="0.9997202">
Observe that this recurrence relation has the
same form as equation (6). Hence the al-
gorithm generates exactly the same number
of indexings as demanded by combinatorial
analysis.
</bodyText>
<sectionHeader confidence="0.998921" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.945482666666667">
This paper has shown that free indexation pro-
duces an exponential number of indexings per
phrase structure. This implies that all algorithms
that compute free indexation, that is, assign in-
dices, must also take at least exponential time. In
this section, we will discuss whether it is possible
for a principle-based parser to avoid the combina-
torial `blow-up&apos; predicted by analysis.
First, let us consider the question whether the
&apos;full power&apos; of the free indexing mechanism is nec-
essary for natural languages. Alternatively, would
it be possible to &apos;shortcut&apos; the enumeration pro-
cedure, that is, to get away with producing fewer
than fin indexings? After all, it is not obvious
that a sentence with a valid interpretation can be
constructed for every possible indexing. However,
it turns out (at least for small values of n; see
Figures 5 and 6 below) that language makes use
of every combination predicted by analysis. This
implies, that all parsers must be capable of pro-
ducing every indexing, or else miss valid interpre-
tations for some sentences.
There are B3 = 5 possible indexings for three
noun phrases. Figure 5 contains example sen-
tences for each possible indexing.9 Similarly,
there are fifteen possible indexings for four noun
phrases. The corresponding examples are shown
in Figure 6.
Although it may be the case that a parser must
be capable of producing every possible indexing,
it does not necessarily follow that a parser must
enumerate every indexing when parsing a particu-
lar sentence. In fact, for many cases, it is possible
to avoid exhaustively exploring the search space
of possibilities predicted by combinatorial analy-
sis. To do this, basically we must know, a priori,
what classes of indexings are impossible for a given
sentence. By factoring in knowledge about restric-
tions on the locality of reference of the items to be
indexed (i.e. binding principles), it is possible to
explore the space of indexings in a controlled fash-
ion. For example, although free indexation implies
that there are five indexings for &amp;quot;John thought is
Tom forgave himself] &amp;quot;, we can make use of the
fact that &amp;quot;himself&apos; must be coinclexed with an el-
ement within the subordinate clause to avoid gen-
gTo make the boundary cases match, just define
40,0) to be 1, and let c(0, 7n) = 0 and c(n, 0) 0 for
m &gt; 0 and a &gt; 0, respectively.
&apos;PRO is an empty (non-overt) noun phrase
element.
</bodyText>
<figure confidence="0.5115567">
NPj
= k k
=k j =
N Pk {I} {i,k} {0}
109
(111) John&apos; wanted PRO/ to forgive himself].
(112) Johni wanted PRO/ to forgive him2
(121) John/ wanted Mary2 to forgive him/
(122) John/ wanted Mary2 to forgive herself2
(123) John/ wanted Mary2 to forgive him3
</figure>
<figureCaption confidence="0.767871">
Figure 5 Example sentences for B3
</figureCaption>
<reference confidence="0.995367357142857">
(1111) John/ persuaded himself1 that hci should give himself] up
(1222) John/ persuaded Mary2 PRO2 to forgive herself2
(1112) John/ persuaded himselfl PRO/ to forgive her2
(1221) John/ persuaded Mary2 PRO2 to forgive him]
(1223) John/ persuaded Mary2 PRO2 to forgive him3
(1233) John/ wanted Bill2 to ask Mary3 PRO3 to leave
(1122) John,. wanted PRO1 to tell Mary2 about herself2
(1211) John] wanted Mary2 to tell him/ about himself].
(1121) Johnl wanted PRO/ to tell Mary2 about himself]
(1232) John&apos; wanted Bill2 to tell Mary3 about himself2
(1123) John/ wanted PRO/ to tell Mary2 about Tom3
(1213) John/ wanted Mary2 to tell him/ about Tom3
(1231) John,. wanted Mary2 to tell Tom3 about him]
(1234) John/ wanted Mary2 to tell Tom3 about Bill4
</reference>
<figureCaption confidence="0.987789">
Figure 6 Example sentences for B4
</figureCaption>
<bodyText confidence="0.999422636363636">
crating indexings in which &amp;quot;Tom&amp;quot; and &amp;quot;himself&amp;quot;
are not coindexed.1° Note that the early elimina-
tion of ill-formed indexings depends crucially on
a parser&apos;s ability to interleave binding principles
with structure building. But, as discussed in Sec-
tion 4, the interleaving of binding principles logi-
cally depends on the ability to interleave free in-
dexation with structure building. Hence the im-
portance of an formulation of free indexation, such
as the one introduced in Section 4, which can be
effectively interleaved.
</bodyText>
<sectionHeader confidence="0.998388" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999749714285714">
[1] M. Abramowitz &amp; I.A. Stegun, Handbook of
Mathematical Functions, 1965. Dover.
[2] Berge, C., Principles of Combinatorics. 1971.
Academic Press,
[3] Chomsky, N.A., Lectures on Government and
Binding: The Pisa Lectures. 1981. Foris Pub-
lications.
</reference>
<footnote confidence="0.975689166666667">
1°This leaves only two remaining indexings: (1)
where &amp;quot;John&apos; is coindexed with &amp;quot;Tom&amp;quot; and &amp;quot;himself&amp;quot;,
and (2) where &amp;quot;John&amp;quot; has a separate index. Similarly,
if we make use of the fact that &amp;quot;Toni&amp;quot; cannot be coin-
dexed with &amp;quot;John&amp;quot;, we can pare the list of indexings
down to just one (the second case).
</footnote>
<reference confidence="0.999752090909091">
[4] Chomsky, N.A., Some Concepts and Conse-
quences of of the Theory of Government and
Binding. 1982. MIT Press.
[5] Fong, S. &amp; R.C. Berwick, &amp;quot;The Compu-
tational Implementation of Principle-Based
Parsers,&amp;quot; International Workshop on Pars-
ing Technologies. Carnegie Mellon University.
1989.
[6] Graham, R.L., D.E. Knuth, Sz O. Patash-
nik, Concrete Mathematics: A Foundation
for Computer Science. 1989. Addison-Wesley.
[7] Higginbotham, J., &amp;quot;Logical Form, Binding,
and Norninals,&amp;quot; Linguistic inquiry. Summer
1983. Volume 14, Number 3.
[8] Knuth, D.E., The Art of Computer Program-
ming: Volume I Fundamental Algorithms.
2nd Edition. 1973. Addison-Wesley,
[9] Lasnik, II. &amp; J. Uriagereka, A Course in GB
Syntax: Lectures on Binding and Empty Cat-
egories. 1988. M.I.T. Press.
[10] Purdom, P.W., Jr. Si C.A. Brown, The Anal-
ysis of Algorithms. 1985. CBS Publishing.
</reference>
<page confidence="0.817094">
1W
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.501436">
<title confidence="0.982953">Free Indexation: Combinatorial Analysis and A Compositional Algorithm*</title>
<author confidence="0.944858">Sandiway Fong</author>
<address confidence="0.91302">545 Technology Square, Rm. NE43-810,</address>
<affiliation confidence="0.999751">MIT Artificial Intelligence Laboratory,</affiliation>
<address confidence="0.99999">Cambridge MA 02139</address>
<email confidence="0.998298">Internet:sandiwaygai.mit.edu</email>
<abstract confidence="0.958311">The principle known as &apos;free indexation&apos; plays an important role in the determination of the referential properties of noun phrases in the principleand-parameters language framework. First, by investigating the combinatorics of free indexation, we show that the problem of enumerating all possible indexings requires exponential time. Secondly, we exhibit a provably optimal free indexation algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>John</author>
</authors>
<title>persuaded himself1 that hci should give himself] up</title>
<marker>(1111)</marker>
<rawString>John/ persuaded himself1 that hci should give himself] up</rawString>
</citation>
<citation valid="false">
<note>John/ persuaded Mary2 PRO2 to forgive herself2</note>
<marker>(1222)</marker>
<rawString>John/ persuaded Mary2 PRO2 to forgive herself2</rawString>
</citation>
<citation valid="false">
<note>John/ persuaded himselfl PRO/ to forgive her2</note>
<marker>(1112)</marker>
<rawString>John/ persuaded himselfl PRO/ to forgive her2</rawString>
</citation>
<citation valid="false">
<note>John/ persuaded Mary2 PRO2 to forgive him</note>
<marker>(1221)</marker>
<rawString>John/ persuaded Mary2 PRO2 to forgive him]</rawString>
</citation>
<citation valid="false">
<note>John/ persuaded Mary2 PRO2 to forgive him3</note>
<marker>(1223)</marker>
<rawString>John/ persuaded Mary2 PRO2 to forgive him3</rawString>
</citation>
<citation valid="false">
<note>John/ wanted Bill2 to ask Mary3 PRO3 to leave</note>
<marker>(1233)</marker>
<rawString>John/ wanted Bill2 to ask Mary3 PRO3 to leave</rawString>
</citation>
<citation valid="false">
<authors>
<author>John</author>
</authors>
<note>wanted PRO1 to tell Mary2 about herself2</note>
<marker>(1122)</marker>
<rawString>John,. wanted PRO1 to tell Mary2 about herself2</rawString>
</citation>
<citation valid="false">
<note>John] wanted Mary2 to tell him/ about himself].</note>
<marker>(1211)</marker>
<rawString>John] wanted Mary2 to tell him/ about himself].</rawString>
</citation>
<citation valid="false">
<note>Johnl wanted PRO/ to tell Mary2 about himself</note>
<marker>(1121)</marker>
<rawString>Johnl wanted PRO/ to tell Mary2 about himself]</rawString>
</citation>
<citation valid="false">
<authors>
<author>John&apos;</author>
</authors>
<note>wanted Bill2 to tell Mary3 about himself2</note>
<marker>(1232)</marker>
<rawString>John&apos; wanted Bill2 to tell Mary3 about himself2</rawString>
</citation>
<citation valid="false">
<note>John/ wanted PRO/ to tell Mary2 about Tom3</note>
<marker>(1123)</marker>
<rawString>John/ wanted PRO/ to tell Mary2 about Tom3</rawString>
</citation>
<citation valid="false">
<note>John/ wanted Mary2 to tell him/ about Tom3</note>
<marker>(1213)</marker>
<rawString>John/ wanted Mary2 to tell him/ about Tom3</rawString>
</citation>
<citation valid="false">
<authors>
<author>John</author>
</authors>
<note>wanted Mary2 to tell Tom3 about him</note>
<marker>(1231)</marker>
<rawString>John,. wanted Mary2 to tell Tom3 about him]</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Abramowitz</author>
<author>I A Stegun</author>
</authors>
<title>Handbook of Mathematical Functions,</title>
<date>1965</date>
<journal>Addison-Wesley.</journal>
<booktitle>John/ wanted Mary2 to tell Tom3 about Bill4 [1]</booktitle>
<volume>5</volume>
<publisher>MIT Press.</publisher>
<marker>(1234)</marker>
<rawString>John/ wanted Mary2 to tell Tom3 about Bill4 [1] M. Abramowitz &amp; I.A. Stegun, Handbook of Mathematical Functions, 1965. Dover. [2] Berge, C., Principles of Combinatorics. 1971. Academic Press, [3] Chomsky, N.A., Lectures on Government and Binding: The Pisa Lectures. 1981. Foris Publications. [4] Chomsky, N.A., Some Concepts and Consequences of of the Theory of Government and Binding. 1982. MIT Press. [5] Fong, S. &amp; R.C. Berwick, &amp;quot;The Computational Implementation of Principle-Based Parsers,&amp;quot; International Workshop on Parsing Technologies. Carnegie Mellon University. 1989. [6] Graham, R.L., D.E. Knuth, Sz O. Patashnik, Concrete Mathematics: A Foundation for Computer Science. 1989. Addison-Wesley. [7] Higginbotham, J., &amp;quot;Logical Form, Binding, and Norninals,&amp;quot; Linguistic inquiry. Summer 1983. Volume 14, Number 3. [8] Knuth, D.E., The Art of Computer Programming: Volume I Fundamental Algorithms. 2nd Edition. 1973. Addison-Wesley, [9] Lasnik, II. &amp; J. Uriagereka, A Course in GB Syntax: Lectures on Binding and Empty Categories. 1988. M.I.T. Press. [10] Purdom, P.W., Jr. Si C.A. Brown, The Analysis of Algorithms. 1985. CBS Publishing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>