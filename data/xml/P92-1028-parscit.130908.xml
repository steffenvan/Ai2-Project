<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<sectionHeader confidence="0.9226815" genericHeader="abstract">
CORPUS-BASED ACQUISITION OF RELATIVE PRONOUN
DISAMBIGUATION HEURISTICS
</sectionHeader>
<author confidence="0.561123">
Claire Cardie
</author>
<affiliation confidence="0.9433625">
Department of Computer Science
University of Massachusetts
</affiliation>
<address confidence="0.631378">
Amherst, MA 01003
</address>
<email confidence="0.995468">
E-mail: cardie@cs.umass.edu
</email>
<sectionHeader confidence="0.995776" genericHeader="keywords">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999895642857143">
This paper presents a corpus-based approach for
deriving heuristics to locate the antecedents of relative
pronouns. The technique duplicates the performance
of hand-coded rules and requires human intervention
only during the training phase. Because the training
instances are built on parser output rather than word
cooccurrences, the technique requires a small number
of training examples and can be used on small to
medium-sized corpora. Our initial results suggest that
the approach may provide a general method for the
automated acquisition of a variety of disambiguation
heuristics for natural language systems, especially for
problems that require the assimilation of syntactic and
semantic knowledge.
</bodyText>
<sectionHeader confidence="0.999775" genericHeader="introduction">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999978438596491">
State-of-the-art natural language processing (NLP)
systems typically rely on heuristics to resolve many
classes of ambiguities, e.g., prepositional phrase
attachment, part of speech disambiguation, word
sense disambiguation, conjunction, pronoun
resolution, and concept activation. However, the
manual encoding of these heuristics, either as part of
a formal grammar or as a set of disambiguation rules,
is difficult because successful heuristics demand the
assimilation of complex syntactic and semantic
knowledge. Consider, for example, the problem of
prepositional phrase attachment. A number of purely
structural solutions have been proposed including the
theories of Minimal Attachment (Frazier, 1978) and
Right Association (Kimball, 1973). While these
models may suggest the existence of strong syntactic
preferences in effect during sentence understanding,
other studies provide clear evidence that purely
syntactic heuristics for prepositional phrase
attachment will not work (see (Whittemore, Ferrara,
&amp; Brunner, 1990), (Taraban, &amp; McClelland, 1988)).
However, computational linguists have found the
manual encoding of disambiguation rules —
especially those that merge syntactic and semantic
constraints — to be difficult, time-consuming, and
prone to error. In addition, hand-coded heuristics are
often incomplete and perform poorly in new domains
comprised of specialized vocabularies or a different
genre of text.
In this paper, we focus on a single ambiguity in
sentence processing: locating the antecedents of
relative pronouns. We present an implemented
corpus-based approach for the automatic acquisition of
disambiguation heuristics for that task. The technique
uses an existing hierarchical clustering system to
determine the antecedent of a relative pronoun given a
description of the clause that precedes it and requires
only minimal syntactic parsing capabilities and a very
general semantic feature set for describing nouns.
Unlike other corpus-based techniques, only a small
number of training examples is needed, making the
approach practical even for small to medium-sized on-
line corpora. For the task of relative pronoun
disambiguation, the automated approach duplicates
the performance of hand-coded rules and makes it
possible to compile heuristics tuned to a new corpus
with little human intervention. Moreover, we believe
that the technique may provide a general approach for
the automated acquisition of disambiguation
heuristics for additional problems in natural
language processing.
In the next section, we briefly describe the task of
relative pronoun disambiguation. Sections 3 and 4
give the details of the acquisition algorithm and
evaluate its performance. Problems with the
approach and extensions required for use with large
corpora of unrestricted text are discussed in Section 5.
</bodyText>
<sectionHeader confidence="0.9996255" genericHeader="method">
2 DISAMBIGUATING RELATIVE
PRONOUNS
</sectionHeader>
<bodyText confidence="0.999768909090909">
Accurate disambiguation of relative pronouns is
important for any natural language processing system
that hopes to process real world texts. It is especially
a concern for corpora where the sentences tend to be
long and information-packed. Unfortunately, to
understand a sentence containing a relative pronoun,
an NLP system must solve two difficult problems:
the system has to locate the antecedent of the relative
pronoun and then determine the antecedent&apos;s implicit
position in the embedded clause. Although finding the
gap in the embedded clause is an equally difficult
</bodyText>
<page confidence="0.998116">
216
</page>
<bodyText confidence="0.953453058823529">
problem, the work we describe here focuses on
locating the relative pronoun antecedent.1
This task may at rust seem relatively simple: the
antecedent of a relative pronoun is just the most
recent constituent that is a human. This is the case
for sentences Si-Si in Figure 1, for example.
However, this strategy assumes that the NLP system
produces a perfect syntactic and semantic parse of the
clause preceding the relative pronoun, including
prepositional phrase attachment (e.g., S3, S4, and
S7) and interpretation of conjunctions (e.g., S4, S5,
and S6) and appositives (e.g., S6). In S5, for
example, the antecedent is the entire conjunction of
phrases (i.e., &amp;quot;Jim, Terry, and Shawn&amp;quot;), not just the
most recent human (i.e., &amp;quot;Shawn&amp;quot;). In S6, either
Si. Tony saw the boy who won the award.
S2. The boy who gave me the book had red hair.
</bodyText>
<listItem confidence="0.828937727272727">
S3. Tony ate dinner with the men from Detroit who
sold computers.
S4. I spoke to the woman with the black shirt and
green hat over in the far corner of the room who
wanted a second interview.
S5. rd like to thank Jim, Terry, and Shawn, who
provided the desserts.
S6. rd like to thank our sponsors, GE and NSF, who
provide fmancial support.
S7. The woman from Philadelphia who played soccer
was my sister.
</listItem>
<bodyText confidence="0.5987068">
S8. The awards for the children who pass the test are
in the drawer.
S9. We wondered who stole the watch.
S10. We talked with the woman and the man who
danced.
</bodyText>
<figureCaption confidence="0.797201">
Figure /. Examples of Relative
</figureCaption>
<subsectionHeader confidence="0.718396">
Pronoun Antecedents
</subsectionHeader>
<bodyText confidence="0.995337538461539">
&amp;quot;our sponsors&amp;quot; or its appositive &amp;quot;GE and NSF&amp;quot; is a
semantically valid antecedent. Because pp-attachment
and interpretation of conjunctions and appositives
remain difficult for current systems, it is often
unreasonable to expect reliable parser output for
clauses containing those constructs.
Moreover, the parser must access both syntactic
and semantic knowledge in finding the antecedent of a
relative pronoun. The syntactic structure of the clause
preceding &amp;quot;who&amp;quot; in S7 and S8, for example, is
identical (NP-PP) but the antecedent in each case is
different. In S7, the antecedent is the subject, &amp;quot;the
woman:&amp;quot; in S9, it is the prepositional phrase
</bodyText>
<footnote confidence="0.804917">
1For a solution to the gap-finding problem that is
consistent with the simplified parsing strategy
presented below, see (Cardie &amp; Lehnert, 1991).
</footnote>
<bodyText confidence="0.999696333333333">
modifier, &amp;quot;the children.&amp;quot; Even if we assume a perfect
parse, there can be additional complications. In some
cases the antecedent is not the most recent
constituent, but is a modifier of that constituent (e.g.,
S8). Sometimes there is no apparent antecedent at all
(e.g., S9). Other times the antecedent is truly
ambiguous without seeing more of the surrounding
context (e.g., S10).
As a direct result of these difficulties, NLP system
builders have found the manual coding of rules that
find relative pronoun antecedents to be very hard. In
addition, the resulting heuristics are prone to errors
of omission and may not generalize to new contexts.
For example, the UMass/MUC-3 system2 began with
19 rules for finding the antecedents of relative
pronouns. These rules included both structural and
semantic knowledge and were based on approximately
50 instances of relative pronouns. As counter-
examples were identified, new rules were added
(approximately 10) and existing rules changed. Over
time, however, we became increasingly reluctant to
modify the rule set because the global effects of local
rule changes were difficult to measure. Moreover, the
original rules were based on sentences that
UMass/MUC-3 had found to contain important
information. As a result, the rules tended to work
well for relative pronoun disambiguation in sentences
of this class (93% correct for one test set of 50 texts),
but did not generalize to sentences outside of the class
(78% correct on the same test set of 50 texts).
</bodyText>
<subsectionHeader confidence="0.927297">
2.1 CURRENT APPROACHES
</subsectionHeader>
<bodyText confidence="0.998861130434782">
Although descriptions of NLP systems do not
usually include the algorithms used to find relative
pronoun antecedents, current high-coverage parsers
seem to employ one of 3 approaches for relative
pronoun disambiguation. Systems that use a formal
syntactic grammar often directly encode information
for relative pronoun disambiguation in the grammar.
Alternatively, a syntactic filter is applied to the parse
tree and any noun phrases for which coreference with
the relative pronoun is syntactically legal (or, in
some cases, illegal) are passed to a semantic
component which determines the antecedent using
inference or preference rules (see (Correa, 1988),
(Hobbs, 1986), (Ingria, &amp; Stallard, 1989), (Lappin,
&amp; McCord, 1990)). The third approach employs hand-
coded disambiguation heuristics that rely mainly on
2UMass/MUC-3 is a version of the CIRCUS parser
(Lehnert, 1990) developed for the MUC-3
performance evaluation. See (Lehnert et. al., 1991)
for a description of UMass/MUC-3. MUC-3 is the
Third Message Understanding System Evaluation and
Message Understanding Conference (Sundheim,
1991).
</bodyText>
<page confidence="0.985716">
217
</page>
<bodyText confidence="0.99988315">
semantic knowledge but also include syntactic
constraints (e.g., UMass/MUC-3).
However, there are problems with all 3 approaches
in that 1) the grammar must be designed to find
relative pronoun antecedents for all possible syntactic
contexts; 2) the grammar and/or inference rules require
tuning for new corpora; and 3) in most cases, the
approach unreasonably assumes a completely correct
parse of the clause preceding the relative pronoun. In
the remainder of the paper, we present an automated
approach for deriving relative pronoun disambiguation
rules. This approach avoids the problems associated
with the manual encoding of heuristics and grammars
and automatically tailors the disambiguation
decisions to the syntactic and semantic profile of the
corpus. Moreover, the technique requires only a very
simple parser because input to the clustering system
that creates the disambiguation heuristics presumes
neither pp-attachment nor interpretation of
conjunctions and appositives.
</bodyText>
<sectionHeader confidence="0.998788" genericHeader="method">
3 AN AUTOMATED APPROACH
</sectionHeader>
<bodyText confidence="0.811646533333333">
Our method for deriving relative pronoun
disambiguation heuristics consists of the following
steps:
1. Select from a subset of the corpus all
sentences containing a particular relative
pronoun. (For the remainder of the paper, we
will focus on the relative pronoun &amp;quot;who.&amp;quot;)
2. For each instance of the relative pronoun in
the selected sentences,
a. parse the portion of the sentence that
precedes it into low-level syntactic constituents
b. use the results of the parse to create a
training instance that represents the
disambiguation decision for this occurrence of
the relative pronoun.
</bodyText>
<listItem confidence="0.798533">
3. Provide the training instances as input to an
existing conceptual clustering system.
</listItem>
<bodyText confidence="0.999912">
During the training phase outlined above, the
clustering system creates a hierarchy of relative
pronoun disambiguation decisions that replace the
hand-coded heuristics. Then, for each new occurrence
of the wh-word encountered after training, we retrieve
the most similar disambiguation decision from the
hierarchy using a representation of the clause
preceding the wh-word as the probe. Finally, the
antecedent of the retrieved decision guides the
selection of the antecedent for the new occurrence of
the relative pronoun. Each step of the training and
testing phases will be explained further in the
sections that follow.
</bodyText>
<sectionHeader confidence="0.8104415" genericHeader="method">
3.1 SELECTING SENTENCES
FROM THE CORPUS
</sectionHeader>
<bodyText confidence="0.999901714285714">
For the relative pronoun disambiguation task, we
used the MUC-3 corpus of 1500 articles that range
from a single paragraph to over one page in length.
In theory, each article describes one or more terrorist
incidents in Latin America. In practice, however,
about half of the texts are actually irrelevant to the
MUC task. The MUC-3 articles consist of a variety
of text types including newspaper articles, TV news
reports, radio broadcasts, rebel communiques,
speeches, and interviews. The corpus is relatively
small — it contains approximately 450,000 words and
18,750 sentences. In comparison, most corpus-based
algorithms employ substantially larger corpora (e.g.,
1 million words (de Marcken, 1990), 2.5 million
words (Brent, 1991), 6 million words (Hindle, 1990),
13 million words (Hindle, &amp; Rooth, 1991)).
Relative pronoun processing is especially
important for the MUC-3 corpus because
approximately 25% of the sentences contain at least
one relative pronoun.3 In fact, the relative pronoun
&amp;quot;who&amp;quot; occurs in approximately 1 out of every 10
sentences. In the experiment described below, we use
100 texts containing 176 instances of the relative
pronoun &amp;quot;who&amp;quot; for training. To extract sentences
containing a specific relative pronoun, we simply
search the selected articles for instances of the relative
pronoun and use a preprocessor to locate sentence
boundaries.
</bodyText>
<subsectionHeader confidence="0.973204">
3.2 PARSING REQUIREMENTS
</subsectionHeader>
<bodyText confidence="0.99792915">
Next, UMass/MUC-3 parses each of the selected
sentences. Whenever the relative pronoun &amp;quot;who&amp;quot; is
recognized, the syntactic analyzer returns a list of the
low-level constituents of the preceding clause prior to
any attachment decisions (see Figure 2).
UMass/MUC-3 has a simple, deterministic, stack-
oriented syntactic analyzer based on the McEli parser
(Schank, &amp; Riesbeck, 1981). It employs lexically-
indexed local syntactic knowledge to segment
incoming text into noun phrases, prepositional
phrases, and verb phrases, ignoring all unexpected
constructs and unknown words.4 Each constituent
3There are 4707 occurrences of wh-words (i.e., who,
whom, which, whose, where, when, why) in the
approximately 18,750 sentences that comprise the
MUC-3 corpus.
4Although UMass/MUC-3 can recognize other
syntactic classes, only noun phrases, prepositional
phrases, and verb phrases become part of the training
instance.
</bodyText>
<page confidence="0.988217">
218
</page>
<note confidence="0.608371666666667">
Sources in downtown Lima report that
the police last night detained Juan
Bautista and Rogoberto Matute, who ...
</note>
<table confidence="0.9081725">
UMass/MUC-3 syntactic
analyzer
the police: [subject, human]
detained: [verb]
Juan Bautista: [np, proper-name]
Rogoberto Matute: [np, proper-name]
</table>
<figureCaption confidence="0.996724">
Figure 2. Syntactic Analyzer Output
</figureCaption>
<bodyText confidence="0.99887478125">
returned by the parser (except the verb) is tagged with
the semantic classification that best describes the
phrase&apos;s head noun. For the MUC-3 corpus, we use a
set of 7 semantic features to categorize each noun in
the lexicon: human, proper-name, location, entity,
physical-target, organization, and weapon. In
addition, clause boundaries are detected using a
method described in (Cardie, &amp; Lehnert, 1991).
It should be noted that all difficult parsing
decisions are delayed for subsequent processing
components. For the task of relative pronoun
disambiguation, this means that the conceptual
clustering system, not the parser, is responsible for
recognizing all phrases that comprise a conjunction of
antecedents and for specifying at least one of the
semantically valid antecedents in the case of
appositives. In addition, pp-attachment is more
easily postponed until after the relative pronoun
antecedent has been located. Consider the sentence &amp;quot;I
ate with the men from the restaurant in the club.&amp;quot;
Depending on the context, &amp;quot;in the club&amp;quot; modifies
either &amp;quot;ate&amp;quot; or &amp;quot;the restaurant.&amp;quot; If we know that &amp;quot;the
men&amp;quot; is the antecedent of a relative pronoun, however
(e.g., &amp;quot;I ate with the men from the restaurant in the
club, who offered me the job&amp;quot;), it is probably the case
that &amp;quot;in the club&amp;quot; modifies &amp;quot;the men.&amp;quot;
Finally, because the MUC-3 domain is sufficiently
narrow in scope, lexical disambiguation problems are
infrequent. Given this rather simplistic view of
syntax, we have found that a small set of syntactic
predictions covers the wide variety of constructs in
the MUC-3 corpus.
</bodyText>
<sectionHeader confidence="0.993422" genericHeader="method">
3.3 CREATING THE TRAINING
INSTANCES
</sectionHeader>
<bodyText confidence="0.990025875">
Output from the syntactic analyzer is used to
generate a training instance for each occurrence of the
relative pronoun in the selected sentences. A training
instance represents a single disambiguation decision
and includes one attribute-value pair for every low-
level syntactic constituent in the preceding clause.
The attributes of a training instance describe the
syntactic class of the constituent as well as its
position with respect to the relative pronoun. The
value associated with an attribute is the semantic
feature of the phrase&apos;s head noun. (For verb phrases,
we currently note only their presence or absence using
the values t and nil, respectively.)
Consider the training instances in Figure 3. In S I,
for example, &amp;quot;of the 76th district court&amp;quot; is represented
with the attribute ppl because it is a prepositional
phrase and is in the first position to the left of &amp;quot;who.&amp;quot;
Its value is &amp;quot;physical-target&amp;quot; because &amp;quot;court&amp;quot; is
classified as a physical-target in the lexicon. The
subject and verb constituents (e.g., &amp;quot;her DAS
bodyguard&amp;quot; in S3 and &amp;quot;detained&amp;quot; in S2) retain their
traditional s and v labels, however — no positional
information is included for those attributes.
[The judge] [of the 76th court] [,] who ...
</bodyText>
<construct confidence="0.565734857142857">
Training instance: /- (s human) (ppl physical-target) (v nil) (antecedent ((s))) I
S2: [The police] [detained] Uuan Bautista] [and] [Rogoberto Matute] [,] who ...
Training instance: [ (s human) (v t) (np2 proper-name) (npl proper-name)
(antecedent ((np2 npl)))
S3: [Her DASI bodyguard] [,] [Dagober to Rodriquez] [,] who...
Training instance: [(s human) (npl proper-name) (v nil)
(antecedent ((npl)(s nplys)))]
</construct>
<figureCaption confidence="0.992813">
Figure 3. Training Instances
</figureCaption>
<page confidence="0.997012">
219
</page>
<bodyText confidence="0.999963357142857">
In addition to the constituent attribute-value pairs,
a training instance contains an attribute-value pair
that represents the correct antecedent. As shown in
Figure 3, the value of the antecedent attribute is a list
of the syntactic constituents that contain the
antecedent (or (none) if the relative pronoun has no
antecedent). In Si, for example, the antecedent of
&amp;quot;who&amp;quot; is &amp;quot;the judge.&amp;quot; Because this phrase is located
in the subject position, the value of the antecedent
attribute is (s). Sometimes, however, the antecedent
is actually a conjunction of phrases. In these cases,
we represent the antecedent as a list of the
constituents associated with each element of the
conjunction. Look, for example, at the antecedent in
S2. Because &amp;quot;who&amp;quot; refers to the conjunction &amp;quot;Juan
Bautista and Rogoberto Matute,&amp;quot; and because those
phrases occur as npl and np2, the value of the
antecedent attribute is (np2 npl). S3 shows yet
another variation of the antecedent attribute-value
pair. In this example, an appositive creates three
equivalent antecedents: 1) &amp;quot;Dagoberto Rodriguez&amp;quot; —
(npl), 2) &amp;quot;her DAS bodyguard&amp;quot; — (s), and 3) &amp;quot;her
DAS bodyguard, Dagoberto Rodriguez&amp;quot; — (s npl).
UMass/MUC-3 automatically generates the
training instances as a side effect of parsing. Only
the desired antecedent is specified by a human
supervisor via a menu-driven interface that displays
the antecedent options.
</bodyText>
<sectionHeader confidence="0.999258333333333" genericHeader="method">
3.4 BUILDING THE HIERARCHY
OF DISAMBIGUATION
HEURISTICS
</sectionHeader>
<bodyText confidence="0.999715583333333">
As the training instances become available they are
input to an existing conceptual clustering system
called COBWEB (Fisher, 1987).5 COBWEB employs
an evaluation metric called category utility (Gluck,
&amp; Corter, 1985) to incrementally discover a
classification hierarchy that covers the training
instances.6 It is this hierarchy that replaces the hand-
coded disambiguation heuristics. While the details of
COBWEB are not necessary, it is important to know
that nodes in the hierarchy represent concepts that
increase in generality as they approach the root of the
tree. Given a new instance to classify, COBWEB
5 For these experiments, we used a version of
COBWEB developed by Robert Williams at the
University of Massachusetts at Amherst.
6Conceptual clustering systems typically discover
appropriate classes as well as the the concepts for
each class when given a set of examples that have
not been preclassified by a teacher. Our unorthodox
use of COBWEB to perform supervised learning is
prompted by plans to use the resulting hierarchy for
tasks other than relative pronoun disambiguation.
retrieves the most specific concept that adequately
describes the instance.
</bodyText>
<sectionHeader confidence="0.997421666666667" genericHeader="method">
3.5 USING THE
DISAMBIGUATION HEURISTICS
HIERARCHY
</sectionHeader>
<bodyText confidence="0.9997019375">
After training, the resulting hierarchy of relative
pronoun disambiguation decisions supplies the
antecedent of the wh-word in new contexts. Given a
novel sentence containing &amp;quot;who,&amp;quot; UMass/MUC-3
generates a set of attribute-value pairs that represent
the clause preceding the wh-word. This probe is just
a training instance without the antecedent attribute-
value pair. Given the probe, COBWEB retrieves
from the hierarchy the individual instance or abstract
class that is most similar and the antecedent of the
retrieved example guides selection of the antecedent
for the novel case. We currently use the following
selection heuristics to 1) choose an antecedent for the
novel sentence that is consistent with the context of
the probe; or to 2) modify the retrieved antecedent so
that it is applicable in the current context:
</bodyText>
<listItem confidence="0.992135375">
1. Choose the first option whose constituents
are all present in the probe.
2. Otherwise, choose the first option that
contains at least one constituent present in the
probe and ignore those constituents in the
retrieved antecedent that are missing from the
probe.
3. Otherwise, replace the np constituents in the
</listItem>
<bodyText confidence="0.93840785">
retrieved antecedent that are missing from the
probe with pp constituents (and vice versa),
and try! and 2 again.
In Si of Figure 4, for example, the first selection
heuristic applies. The retrieved instance specifies the
np2 constituent as the location of the antecedent and
the probe has np2 as one of its constituents.
Therefore, UMass/MUC-3 infers that the antecedent
of &amp;quot;who&amp;quot; for the current sentence is &amp;quot;the hardliners,&amp;quot;
i.e., the contents of the np2 syntactic constituent. In
S2, however, the retrieved concept specifies an
antecedent from five constituents, only two of which
are actually present in the probe. Therefore, we
ignore the missing constituents pp5, np4, and pp3,
and look to just np2 and npl for the antecedent. For
S3, selection heuristics 1 and 2 fail because the probe
contains no pp2 constituent. However, if we replace
pp2 with np2 in the retrieved antecedent, then
heuristic 1 applies and &amp;quot;a specialist&amp;quot; is chosen as the
antecedent.
</bodyText>
<page confidence="0.996554">
220
</page>
<figureCaption confidence="0.997349">
Figure 4. Using the Disambiguation Heuristics Hierarchy
</figureCaption>
<figure confidence="0.729607428571429">
Si: [It] [encourages] [the military men] [,] [and] [the hardliners] [in ARENA] who...
[(s entity) (v t) (np3 human) (np2 human) (ppl org)]
Antecedent of Retrieved Instance: ((np2))
Antecedent of Probe: (np2) = &amp;quot;the hardliners&amp;quot;
S2: [There] [are][also] [criminals] [like] [Vice President Merino] [,] [a man] who...
•.. I I /
[(s entity) (v t) (np3 human) (np2 proper-name) (npl human)]
Antecedent of Retrieved Instance: ((pp5 np4 pp3 np2 npl))
Antecedent of Probe (np2 npl) = &amp;quot;Vice President Merino, a man&amp;quot;
S3: [It] [coincided] [with the arrival] [of Smith] [,] [a specialist] [from the UN] [,] who...
\ \ I I I I
[(s entity) (v t) (pp4 entity) (pp3 proper-name) (np2 human) (ppl entity)]
Antecedent of Retrieved Instance: ((pp2))
Antecedent of Probe: (np2) = &amp;quot;a specialist&amp;quot;
</figure>
<sectionHeader confidence="0.997738" genericHeader="evaluation">
4 RESULTS
</sectionHeader>
<bodyText confidence="0.999895173076923">
As described above, we used 100 texts
(approximately 7% of the corpus) containing 176
instances of the relative pronoun &amp;quot;who&amp;quot; for training.
Six of those instances were discarded when the
U&apos;Mass/MUC-3 syntactic analyzer failed to include the
desired antecedent as part of its constituent
representation, making it impossible for the human
supervisor to specify the location of the antecedent?
After training, we tested the resulting disambiguation
hierarchy on 71 novel instances extracted from an
additional 50 texts in the corpus. Using the selection
heuristics described above, the correct antecedent was
found for 92% of the test instances. Of the 6 errors, 3
involved probes with antecedent combinations never
seen in any of the training cases. This usually
indicates that the semantic and syntactic structure of
the novel clause differs significantly from those in
the disambiguation hierarchy. This was, in fact, the
case for 2 out of 3 of the errors. The third error
involved a complex conjunction and appositive
combination. In this case, the retrieved antecedent
specified 3 out of 4 of the required constituents.
If we discount the errors involving unknown
antecedents, our algorithm correctly classifies 94%
of the novel instances (3 errors). In comparison, the
original UMass/MUC-3 system that relied on hand-
coded heuristics for relative pronoun disambiguation
fmds the correct antecedent 87% of the time (9 errors).
70ther parsing errors occurred throughout the training
set, but only those instances where the antecedent was
not recognized as a constituent (and the wh-word had
an antecedent) were discarded.
However, a simple heuristic that chooses the most
recent phrase as the antecedent succeeds 86% of the
time. (For the training sets, this heuristic works
only 75% of the time.) In cases where the antecedent
was not the most recent phrase, UMass/MUC-3 errs
67% of the time. Our automated algorithm errs 47%
of the time.
It is interesting that of the 3 errors that did not
specify previously unseen antecedents, one was caused
by parsing blunders. The remaining 2 errors involved
relative pronoun antecedents that are difficult even for
people to specify: 1) &amp;quot;... 9 rebels died at the hands of
members of the civilian militia, who resisted the
attacks&amp;quot; and 2) &amp;quot;... the government expelled a group
of foreign drug traffickers who had established
themselves in northern Chile&amp;quot;. Our algorithm chose
&amp;quot;the civilian militia&amp;quot; and &amp;quot;foreign drug traffickers&amp;quot; as
the antecedents of &amp;quot;who&amp;quot; instead of the preferred
antecedents &amp;quot;members of the civilian militia&amp;quot; and
&amp;quot;group of foreign drug traffickers.&amp;quot;8
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="conclusions">
5 CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.998756090909091">
We have described an automated approach for the
acquisition of relative pronoun disambiguation
heuristics that duplicates the performance of hand-
coded rules. Unfortunately, extending the technique
for use with unrestricted texts may be difficult. The
UMass/MUC-3 parser would clearly need additional
mechanisms to handle the ensuing part of speech and
8Interestingly, in work on the automated
classification of nouns, (Hindle, 1990) also noted
problems with &amp;quot;empty&amp;quot; words that depend on their
complements for meaning.
</bodyText>
<page confidence="0.992203">
221
</page>
<bodyText confidence="0.997884473684211">
word sense disambiguation problems. However,
recent research in these areas indicates that automated
approaches for these tasks may be feasible (see, for
example, (Brown, Della Pietra, Della Pietra, &amp;
Mercer, 1991) and (Hindle, 1983)). In addition,
although our simple semantic feature set seems
adequate for the current relative pronoun
disambiguation task, it is doubtful that a single
semantic feature set can be used across all domains
and for all disambiguation tasks.9
In related work on pronoun disambiguation, Dagan
and Itai (1991) successfully use statistical
cooccurrence patterns to choose among the
syntactically valid pronoun referents posed by the
parser. Their approach is similar in that the
statistical database depends on parser output.
However, it differs in a variety of ways. First,
human intervention is required not to specify the
correct pronoun antecedent, but to check that the
complete parse tree supplied by the parser for each
training example is correct and to rule out potential
examples that are inappropriate for their approach.
More importantly, their method requires very large
corpora of data.
Our technique, on the other hand, requires few
training examples because each training instance is
not word-based, but created from higher-level parser
output.1° Therefore, unlike other corpus-based
techniques, our approach is practical for use with
small to medium-sized corpora in relatively narrow
domains. ((Dagan &amp; Itai, 1991) mention the use of
semantic feature-based cooccurrences as one way to
make use of a smaller corpus.) In addition, because
human intervention is required only to specify the
antecedent during the training phase, creating
disambiguation heuristics for a new domain requires
little effort. Any NLP system that uses semantic
features for describing nouns and has minimal
syntactic parsing capabilities can generate the required
training instances. The parser need only recognize
noun phrases, verbs, and prepositional phrases
because the disambiguation heuristics, not the parser,
are responsible for recognizing the conjunctions and
appositives that comprise a relative pronoun
antecedent. Moreover, the success of the approach for
structurally complex antecedents suggests that the
technique may provide a general approach for the
9 In recent work on the disambiguation of
structurally, but not semantically, restricted phrases,
however, a set of 16 predefined semantic categories
sufficed (Ravin, 1990).
10Although further work is needed to determine the
optimal number of training examples, it is probably
the case that many fewer than 170 instances were
required even for the experiments described here.
automated acquisition of disambiguation rules for
other problems in natural language processing.
</bodyText>
<sectionHeader confidence="0.997283" genericHeader="acknowledgments">
6 ACKNOWLEDGMENTS
</sectionHeader>
<reference confidence="0.387667777777778">
This research was supported by the Office of Naval
Research, under a University Research Initiative
Grant, Contract No. N00014-86-K-0764 and NSF
Presidential Young Investigators Award NSFIST-
8351863 (awarded to Wendy Lehnert) and the
Advanced Research Projects Agency of the
Department of Defense monitored by the Air Force
Office of Scientific Research under Contract No.
F49620-88-C-0058.
</reference>
<sectionHeader confidence="0.975852" genericHeader="references">
7 REFERENCES
</sectionHeader>
<reference confidence="0.99888364516129">
Brent, M. (1991). Automatic acquisition of
subcategorization frames from untagged text.
Proceedings, 29th Annual Meeting of the Association
for Computational Linguists. University of
California, Berkeley. Association for Computational
Linguists.
Brown, P. F., Della Pietra, S. A., Della Pietra, V.
J., &amp; Mercer, R. L. (1991). Word-sense
disambiguation using statistical methods.
Proceedings, 29th Annual Meeting of the Association
for Computational Linguists. University of
California, Berkeley. Association for Computational
Linguists.
Cardie, C., &amp; Lehnert, W. (1991). A Cognitively
Plausible Approach to Understanding Complex
Syntax. Proceedings, Eighth National Conference on
Artificial Intelligence. Anaheim, CA. AAAI Press /
The MIT Press.
Correa, N. (1988). A Binding Rule for
Government-Binding Parsing. Proceedings, COLING
&apos;88. Budapest.
Dagan, I. and Itai, A. (1991). A Statistical Filter
for Resolving Pronoun References. In Y.A. Feldman
and A.Bruckstein (Eds.), Artificial Intelligence and
Computer Vision (pp. 125-135). North-Holland:
Elsevier.
de Marcken, C. G. (1990). Parsing the LOB
corpus. Proceedings, 28th Annual Meeting of the
Association for Computational Linguists. University
of Pittsburgh. Association for Computational
Linguists.
</reference>
<page confidence="0.967557">
222
</page>
<reference confidence="0.999750337662337">
Fisher, D. H. (1987). Knowledge Acquisition Via
Incremental Conceptual Clustering. Machine
Learning, 2, 139-172.
Frazier, L. (1978). On comprehending sentences:
Syntactic parsing strategies. Ph.D. Thesis. University
of Connecticut.
Gluck, M. A., &amp; Corter, J. E. (1985).
Information, uncertainty, and the utility of categories.
Proceedings, Seventh Annual Conference of the
Cognitive Science Society. Lawrence Erlbaum
Associates.
Hindle, D. (1983). User manual for Fidditch
(7590-142). Naval Research Laboratory.
Hindle, D. (1990). Noun classification from
predicate-argument structures. Proceedings, 28th
Annual Meeting of the Association for
Computational Linguists. University of Pittsburgh.
Association for Computational Linguists.
Hindle, D., &amp; Rooth, M. (1991). Structural
ambiguity and lexical relations. Proceedings, 29th
Annual Meeting of the Association for
Computational Linguists. University of California,
Berkeley. Association for Computational Linguists.
Hobbs, J. (1986). Resolving Pronoun References.
In B. J. Grosz, K. Sparck Jones, &amp; B. L. Webber
(Eds.), Readings in Natural Language Processing (pp.
339-352). Los Altos, CA: Morgan Kaufmann
Publishers, Inc.
Ingria, R., &amp; Stallard, D. (1989). A computational
mechanism for pronominal reference. Proceedings,
27th Annual Meeting of the Association for
Computational Linguistics. Vancouver.
Kimball, J. (1973). Seven principles of surface
structure parsing in natural language. Cognition, 2,
15-47.
Lappin, S., &amp; McCord, M. (1990). A syntactic
filter on pronominal anaphora for slot grammar.
Proceedings, 28th Annual Meeting of the Association
for Computational Linguistics. University of
Pittsburgh. Association for Computational
Linguistics.
Lehnert, W. (1990). Symbolic/Subsymbolic
Sentence Analysis: Exploiting the Best of Two
Worlds. In J. Barnden, &amp; J. Pollack (Eds.), Advances
in Connectionist and Neural Computation Theory.
Norwood, NJ: Ablex Publishers.
Lehnert, W., Cardie, C., Fisher, D., Riloff, E., &amp;
Williams, R. (1991).University of Massachusetts:
Description of the CIRCUS System as Used for
MUC-3. Proceedings, Third Message Understanding
Conference (MUC-3 ). San Diego, CA. Morgan
Kaufmann Publishers.
Ravin, Y. (1990). Disambiguating and interpreting
verb definitions. Proceedings, 28th Annual Meeting
of the Association for Computational Linguists.
University of Pittsburgh. Association for
Computational Linguists.
Schank, R., &amp; Riesbeck, C. (1981). Inside
Computer Understanding: Five Programs Plus
Miniatures. Hillsdale, NJ: Lawrence Erlbaum.
Sundheim, B. M. (May,1991). Overview of the
Third Message Understanding Evaluation and
Conference. Proceedings ,Third Message Understand-
ing Conference (MUC-3). San Diego, CA. Morgan
Kaufmann Publishers.
Taraban, R., &amp; McClelland, J. L. (1988).
Constituent attachment and thematic role assignment
in sentence processing: influences of content-based
expectations. Journal of Memory and Language, 27,
597-632.
Whittemore, G., Ferrara, K., &amp; Brunner, H.
(1990). Empirical study of predictive powers of
simple attachment schemes for post-modifier
prepositional phrases. Proceedings, 28th Annual
Meeting of the Association for Computational
Linguistics. University of Pittsburgh. Association for
Computational Linguistics.
</reference>
<page confidence="0.999169">
223
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.949334">
<title confidence="0.98758">CORPUS-BASED ACQUISITION OF RELATIVE PRONOUN DISAMBIGUATION HEURISTICS</title>
<author confidence="0.999299">Claire Cardie</author>
<affiliation confidence="0.999961">Department of Computer Science University of Massachusetts</affiliation>
<address confidence="0.999997">Amherst, MA 01003</address>
<email confidence="0.999976">E-mail:cardie@cs.umass.edu</email>
<abstract confidence="0.9982564">This paper presents a corpus-based approach for deriving heuristics to locate the antecedents of relative pronouns. The technique duplicates the performance of hand-coded rules and requires human intervention only during the training phase. Because the training instances are built on parser output rather than word cooccurrences, the technique requires a small number of training examples and can be used on small to medium-sized corpora. Our initial results suggest that the approach may provide a general method for the automated acquisition of a variety of disambiguation heuristics for natural language systems, especially for problems that require the assimilation of syntactic and semantic knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This research was supported by the Office of Naval Research, under a University Research Initiative Grant, Contract No. N00014-86-K-0764 and NSF Presidential Young Investigators Award</title>
<booktitle>NSFIST8351863 (awarded to Wendy Lehnert) and the Advanced Research Projects Agency of the Department of Defense monitored by the Air Force Office of Scientific Research under Contract No.</booktitle>
<pages>49620--88</pages>
<marker></marker>
<rawString>This research was supported by the Office of Naval Research, under a University Research Initiative Grant, Contract No. N00014-86-K-0764 and NSF Presidential Young Investigators Award NSFIST8351863 (awarded to Wendy Lehnert) and the Advanced Research Projects Agency of the Department of Defense monitored by the Air Force Office of Scientific Research under Contract No. F49620-88-C-0058.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Brent</author>
</authors>
<title>Automatic acquisition of subcategorization frames from untagged text.</title>
<date>1991</date>
<booktitle>Proceedings, 29th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</institution>
<contexts>
<context position="12326" citStr="Brent, 1991" startWordPosition="1856" endWordPosition="1857">to over one page in length. In theory, each article describes one or more terrorist incidents in Latin America. In practice, however, about half of the texts are actually irrelevant to the MUC task. The MUC-3 articles consist of a variety of text types including newspaper articles, TV news reports, radio broadcasts, rebel communiques, speeches, and interviews. The corpus is relatively small — it contains approximately 450,000 words and 18,750 sentences. In comparison, most corpus-based algorithms employ substantially larger corpora (e.g., 1 million words (de Marcken, 1990), 2.5 million words (Brent, 1991), 6 million words (Hindle, 1990), 13 million words (Hindle, &amp; Rooth, 1991)). Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25% of the sentences contain at least one relative pronoun.3 In fact, the relative pronoun &amp;quot;who&amp;quot; occurs in approximately 1 out of every 10 sentences. In the experiment described below, we use 100 texts containing 176 instances of the relative pronoun &amp;quot;who&amp;quot; for training. To extract sentences containing a specific relative pronoun, we simply search the selected articles for instances of the relative pronoun and use a preproces</context>
</contexts>
<marker>Brent, 1991</marker>
<rawString>Brent, M. (1991). Automatic acquisition of subcategorization frames from untagged text. Proceedings, 29th Annual Meeting of the Association for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>Della Pietra</author>
<author>S A</author>
<author>Della Pietra</author>
<author>V J</author>
<author>R L Mercer</author>
</authors>
<title>Word-sense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>Proceedings, 29th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</institution>
<marker>Brown, Pietra, A, Pietra, J, Mercer, 1991</marker>
<rawString>Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., &amp; Mercer, R. L. (1991). Word-sense disambiguation using statistical methods. Proceedings, 29th Annual Meeting of the Association for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cardie</author>
<author>W Lehnert</author>
</authors>
<title>A Cognitively Plausible Approach to Understanding Complex Syntax.</title>
<date>1991</date>
<booktitle>Proceedings, Eighth National Conference on Artificial Intelligence.</booktitle>
<publisher>AAAI Press / The MIT Press.</publisher>
<location>Anaheim, CA.</location>
<contexts>
<context position="6606" citStr="Cardie &amp; Lehnert, 1991" startWordPosition="990" endWordPosition="993">t for current systems, it is often unreasonable to expect reliable parser output for clauses containing those constructs. Moreover, the parser must access both syntactic and semantic knowledge in finding the antecedent of a relative pronoun. The syntactic structure of the clause preceding &amp;quot;who&amp;quot; in S7 and S8, for example, is identical (NP-PP) but the antecedent in each case is different. In S7, the antecedent is the subject, &amp;quot;the woman:&amp;quot; in S9, it is the prepositional phrase 1For a solution to the gap-finding problem that is consistent with the simplified parsing strategy presented below, see (Cardie &amp; Lehnert, 1991). modifier, &amp;quot;the children.&amp;quot; Even if we assume a perfect parse, there can be additional complications. In some cases the antecedent is not the most recent constituent, but is a modifier of that constituent (e.g., S8). Sometimes there is no apparent antecedent at all (e.g., S9). Other times the antecedent is truly ambiguous without seeing more of the surrounding context (e.g., S10). As a direct result of these difficulties, NLP system builders have found the manual coding of rules that find relative pronoun antecedents to be very hard. In addition, the resulting heuristics are prone to errors of</context>
</contexts>
<marker>Cardie, Lehnert, 1991</marker>
<rawString>Cardie, C., &amp; Lehnert, W. (1991). A Cognitively Plausible Approach to Understanding Complex Syntax. Proceedings, Eighth National Conference on Artificial Intelligence. Anaheim, CA. AAAI Press / The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Correa</author>
</authors>
<title>A Binding Rule for Government-Binding Parsing.</title>
<date>1988</date>
<booktitle>Proceedings, COLING &apos;88.</booktitle>
<location>Budapest.</location>
<contexts>
<context position="8794" citStr="Correa, 1988" startWordPosition="1332" endWordPosition="1333"> usually include the algorithms used to find relative pronoun antecedents, current high-coverage parsers seem to employ one of 3 approaches for relative pronoun disambiguation. Systems that use a formal syntactic grammar often directly encode information for relative pronoun disambiguation in the grammar. Alternatively, a syntactic filter is applied to the parse tree and any noun phrases for which coreference with the relative pronoun is syntactically legal (or, in some cases, illegal) are passed to a semantic component which determines the antecedent using inference or preference rules (see (Correa, 1988), (Hobbs, 1986), (Ingria, &amp; Stallard, 1989), (Lappin, &amp; McCord, 1990)). The third approach employs handcoded disambiguation heuristics that rely mainly on 2UMass/MUC-3 is a version of the CIRCUS parser (Lehnert, 1990) developed for the MUC-3 performance evaluation. See (Lehnert et. al., 1991) for a description of UMass/MUC-3. MUC-3 is the Third Message Understanding System Evaluation and Message Understanding Conference (Sundheim, 1991). 217 semantic knowledge but also include syntactic constraints (e.g., UMass/MUC-3). However, there are problems with all 3 approaches in that 1) the grammar mu</context>
</contexts>
<marker>Correa, 1988</marker>
<rawString>Correa, N. (1988). A Binding Rule for Government-Binding Parsing. Proceedings, COLING &apos;88. Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>A Itai</author>
</authors>
<title>A Statistical Filter for Resolving Pronoun References.</title>
<date>1991</date>
<booktitle>In Y.A. Feldman and A.Bruckstein (Eds.), Artificial Intelligence and Computer Vision</booktitle>
<pages>125--135</pages>
<publisher>North-Holland: Elsevier.</publisher>
<contexts>
<context position="26772" citStr="Dagan and Itai (1991)" startWordPosition="4085" endWordPosition="4088">ted problems with &amp;quot;empty&amp;quot; words that depend on their complements for meaning. 221 word sense disambiguation problems. However, recent research in these areas indicates that automated approaches for these tasks may be feasible (see, for example, (Brown, Della Pietra, Della Pietra, &amp; Mercer, 1991) and (Hindle, 1983)). In addition, although our simple semantic feature set seems adequate for the current relative pronoun disambiguation task, it is doubtful that a single semantic feature set can be used across all domains and for all disambiguation tasks.9 In related work on pronoun disambiguation, Dagan and Itai (1991) successfully use statistical cooccurrence patterns to choose among the syntactically valid pronoun referents posed by the parser. Their approach is similar in that the statistical database depends on parser output. However, it differs in a variety of ways. First, human intervention is required not to specify the correct pronoun antecedent, but to check that the complete parse tree supplied by the parser for each training example is correct and to rule out potential examples that are inappropriate for their approach. More importantly, their method requires very large corpora of data. Our techn</context>
<context position="27694" citStr="Dagan &amp; Itai, 1991" startWordPosition="4222" endWordPosition="4225">specify the correct pronoun antecedent, but to check that the complete parse tree supplied by the parser for each training example is correct and to rule out potential examples that are inappropriate for their approach. More importantly, their method requires very large corpora of data. Our technique, on the other hand, requires few training examples because each training instance is not word-based, but created from higher-level parser output.1° Therefore, unlike other corpus-based techniques, our approach is practical for use with small to medium-sized corpora in relatively narrow domains. ((Dagan &amp; Itai, 1991) mention the use of semantic feature-based cooccurrences as one way to make use of a smaller corpus.) In addition, because human intervention is required only to specify the antecedent during the training phase, creating disambiguation heuristics for a new domain requires little effort. Any NLP system that uses semantic features for describing nouns and has minimal syntactic parsing capabilities can generate the required training instances. The parser need only recognize noun phrases, verbs, and prepositional phrases because the disambiguation heuristics, not the parser, are responsible for re</context>
</contexts>
<marker>Dagan, Itai, 1991</marker>
<rawString>Dagan, I. and Itai, A. (1991). A Statistical Filter for Resolving Pronoun References. In Y.A. Feldman and A.Bruckstein (Eds.), Artificial Intelligence and Computer Vision (pp. 125-135). North-Holland: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C G de Marcken</author>
</authors>
<title>Parsing the LOB corpus.</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</institution>
<marker>de Marcken, 1990</marker>
<rawString>de Marcken, C. G. (1990). Parsing the LOB corpus. Proceedings, 28th Annual Meeting of the Association for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Fisher</author>
</authors>
<title>Knowledge Acquisition Via Incremental Conceptual Clustering.</title>
<date>1987</date>
<booktitle>Machine Learning,</booktitle>
<volume>2</volume>
<pages>139--172</pages>
<contexts>
<context position="19056" citStr="Fisher, 1987" startWordPosition="2883" endWordPosition="2884">ibute-value pair. In this example, an appositive creates three equivalent antecedents: 1) &amp;quot;Dagoberto Rodriguez&amp;quot; — (npl), 2) &amp;quot;her DAS bodyguard&amp;quot; — (s), and 3) &amp;quot;her DAS bodyguard, Dagoberto Rodriguez&amp;quot; — (s npl). UMass/MUC-3 automatically generates the training instances as a side effect of parsing. Only the desired antecedent is specified by a human supervisor via a menu-driven interface that displays the antecedent options. 3.4 BUILDING THE HIERARCHY OF DISAMBIGUATION HEURISTICS As the training instances become available they are input to an existing conceptual clustering system called COBWEB (Fisher, 1987).5 COBWEB employs an evaluation metric called category utility (Gluck, &amp; Corter, 1985) to incrementally discover a classification hierarchy that covers the training instances.6 It is this hierarchy that replaces the handcoded disambiguation heuristics. While the details of COBWEB are not necessary, it is important to know that nodes in the hierarchy represent concepts that increase in generality as they approach the root of the tree. Given a new instance to classify, COBWEB 5 For these experiments, we used a version of COBWEB developed by Robert Williams at the University of Massachusetts at A</context>
</contexts>
<marker>Fisher, 1987</marker>
<rawString>Fisher, D. H. (1987). Knowledge Acquisition Via Incremental Conceptual Clustering. Machine Learning, 2, 139-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
</authors>
<title>On comprehending sentences: Syntactic parsing strategies.</title>
<date>1978</date>
<tech>Ph.D. Thesis.</tech>
<institution>University of Connecticut.</institution>
<contexts>
<context position="1628" citStr="Frazier, 1978" startWordPosition="218" endWordPosition="219">esolve many classes of ambiguities, e.g., prepositional phrase attachment, part of speech disambiguation, word sense disambiguation, conjunction, pronoun resolution, and concept activation. However, the manual encoding of these heuristics, either as part of a formal grammar or as a set of disambiguation rules, is difficult because successful heuristics demand the assimilation of complex syntactic and semantic knowledge. Consider, for example, the problem of prepositional phrase attachment. A number of purely structural solutions have been proposed including the theories of Minimal Attachment (Frazier, 1978) and Right Association (Kimball, 1973). While these models may suggest the existence of strong syntactic preferences in effect during sentence understanding, other studies provide clear evidence that purely syntactic heuristics for prepositional phrase attachment will not work (see (Whittemore, Ferrara, &amp; Brunner, 1990), (Taraban, &amp; McClelland, 1988)). However, computational linguists have found the manual encoding of disambiguation rules — especially those that merge syntactic and semantic constraints — to be difficult, time-consuming, and prone to error. In addition, hand-coded heuristics ar</context>
</contexts>
<marker>Frazier, 1978</marker>
<rawString>Frazier, L. (1978). On comprehending sentences: Syntactic parsing strategies. Ph.D. Thesis. University of Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Gluck</author>
<author>J E Corter</author>
</authors>
<title>Information, uncertainty, and the utility of categories.</title>
<date>1985</date>
<booktitle>Proceedings, Seventh Annual Conference of the Cognitive Science Society. Lawrence Erlbaum Associates.</booktitle>
<marker>Gluck, Corter, 1985</marker>
<rawString>Gluck, M. A., &amp; Corter, J. E. (1985). Information, uncertainty, and the utility of categories. Proceedings, Seventh Annual Conference of the Cognitive Science Society. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>User manual for Fidditch (7590-142).</title>
<date>1983</date>
<institution>Naval Research Laboratory.</institution>
<contexts>
<context position="26466" citStr="Hindle, 1983" startWordPosition="4040" endWordPosition="4041">andcoded rules. Unfortunately, extending the technique for use with unrestricted texts may be difficult. The UMass/MUC-3 parser would clearly need additional mechanisms to handle the ensuing part of speech and 8Interestingly, in work on the automated classification of nouns, (Hindle, 1990) also noted problems with &amp;quot;empty&amp;quot; words that depend on their complements for meaning. 221 word sense disambiguation problems. However, recent research in these areas indicates that automated approaches for these tasks may be feasible (see, for example, (Brown, Della Pietra, Della Pietra, &amp; Mercer, 1991) and (Hindle, 1983)). In addition, although our simple semantic feature set seems adequate for the current relative pronoun disambiguation task, it is doubtful that a single semantic feature set can be used across all domains and for all disambiguation tasks.9 In related work on pronoun disambiguation, Dagan and Itai (1991) successfully use statistical cooccurrence patterns to choose among the syntactically valid pronoun referents posed by the parser. Their approach is similar in that the statistical database depends on parser output. However, it differs in a variety of ways. First, human intervention is require</context>
</contexts>
<marker>Hindle, 1983</marker>
<rawString>Hindle, D. (1983). User manual for Fidditch (7590-142). Naval Research Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</institution>
<contexts>
<context position="12358" citStr="Hindle, 1990" startWordPosition="1861" endWordPosition="1862">theory, each article describes one or more terrorist incidents in Latin America. In practice, however, about half of the texts are actually irrelevant to the MUC task. The MUC-3 articles consist of a variety of text types including newspaper articles, TV news reports, radio broadcasts, rebel communiques, speeches, and interviews. The corpus is relatively small — it contains approximately 450,000 words and 18,750 sentences. In comparison, most corpus-based algorithms employ substantially larger corpora (e.g., 1 million words (de Marcken, 1990), 2.5 million words (Brent, 1991), 6 million words (Hindle, 1990), 13 million words (Hindle, &amp; Rooth, 1991)). Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25% of the sentences contain at least one relative pronoun.3 In fact, the relative pronoun &amp;quot;who&amp;quot; occurs in approximately 1 out of every 10 sentences. In the experiment described below, we use 100 texts containing 176 instances of the relative pronoun &amp;quot;who&amp;quot; for training. To extract sentences containing a specific relative pronoun, we simply search the selected articles for instances of the relative pronoun and use a preprocessor to locate sentence boundarie</context>
<context position="26143" citStr="Hindle, 1990" startWordPosition="3992" endWordPosition="3993">foreign drug traffickers&amp;quot; as the antecedents of &amp;quot;who&amp;quot; instead of the preferred antecedents &amp;quot;members of the civilian militia&amp;quot; and &amp;quot;group of foreign drug traffickers.&amp;quot;8 5 CONCLUSIONS We have described an automated approach for the acquisition of relative pronoun disambiguation heuristics that duplicates the performance of handcoded rules. Unfortunately, extending the technique for use with unrestricted texts may be difficult. The UMass/MUC-3 parser would clearly need additional mechanisms to handle the ensuing part of speech and 8Interestingly, in work on the automated classification of nouns, (Hindle, 1990) also noted problems with &amp;quot;empty&amp;quot; words that depend on their complements for meaning. 221 word sense disambiguation problems. However, recent research in these areas indicates that automated approaches for these tasks may be feasible (see, for example, (Brown, Della Pietra, Della Pietra, &amp; Mercer, 1991) and (Hindle, 1983)). In addition, although our simple semantic feature set seems adequate for the current relative pronoun disambiguation task, it is doubtful that a single semantic feature set can be used across all domains and for all disambiguation tasks.9 In related work on pronoun disambig</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, D. (1990). Noun classification from predicate-argument structures. Proceedings, 28th Annual Meeting of the Association for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1991</date>
<booktitle>Proceedings, 29th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</institution>
<marker>Hindle, Rooth, 1991</marker>
<rawString>Hindle, D., &amp; Rooth, M. (1991). Structural ambiguity and lexical relations. Proceedings, 29th Annual Meeting of the Association for Computational Linguists. University of California, Berkeley. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Resolving Pronoun References. In</title>
<date>1986</date>
<booktitle>Readings in Natural Language Processing</booktitle>
<pages>339--352</pages>
<publisher>Morgan Kaufmann Publishers, Inc.</publisher>
<location>Los Altos, CA:</location>
<contexts>
<context position="8809" citStr="Hobbs, 1986" startWordPosition="1334" endWordPosition="1335"> the algorithms used to find relative pronoun antecedents, current high-coverage parsers seem to employ one of 3 approaches for relative pronoun disambiguation. Systems that use a formal syntactic grammar often directly encode information for relative pronoun disambiguation in the grammar. Alternatively, a syntactic filter is applied to the parse tree and any noun phrases for which coreference with the relative pronoun is syntactically legal (or, in some cases, illegal) are passed to a semantic component which determines the antecedent using inference or preference rules (see (Correa, 1988), (Hobbs, 1986), (Ingria, &amp; Stallard, 1989), (Lappin, &amp; McCord, 1990)). The third approach employs handcoded disambiguation heuristics that rely mainly on 2UMass/MUC-3 is a version of the CIRCUS parser (Lehnert, 1990) developed for the MUC-3 performance evaluation. See (Lehnert et. al., 1991) for a description of UMass/MUC-3. MUC-3 is the Third Message Understanding System Evaluation and Message Understanding Conference (Sundheim, 1991). 217 semantic knowledge but also include syntactic constraints (e.g., UMass/MUC-3). However, there are problems with all 3 approaches in that 1) the grammar must be designed </context>
</contexts>
<marker>Hobbs, 1986</marker>
<rawString>Hobbs, J. (1986). Resolving Pronoun References. In B. J. Grosz, K. Sparck Jones, &amp; B. L. Webber (Eds.), Readings in Natural Language Processing (pp. 339-352). Los Altos, CA: Morgan Kaufmann Publishers, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ingria</author>
<author>D Stallard</author>
</authors>
<title>A computational mechanism for pronominal reference.</title>
<date>1989</date>
<booktitle>Proceedings, 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Vancouver.</location>
<marker>Ingria, Stallard, 1989</marker>
<rawString>Ingria, R., &amp; Stallard, D. (1989). A computational mechanism for pronominal reference. Proceedings, 27th Annual Meeting of the Association for Computational Linguistics. Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kimball</author>
</authors>
<title>Seven principles of surface structure parsing in natural language.</title>
<date>1973</date>
<journal>Cognition,</journal>
<volume>2</volume>
<pages>15--47</pages>
<contexts>
<context position="1666" citStr="Kimball, 1973" startWordPosition="223" endWordPosition="224">g., prepositional phrase attachment, part of speech disambiguation, word sense disambiguation, conjunction, pronoun resolution, and concept activation. However, the manual encoding of these heuristics, either as part of a formal grammar or as a set of disambiguation rules, is difficult because successful heuristics demand the assimilation of complex syntactic and semantic knowledge. Consider, for example, the problem of prepositional phrase attachment. A number of purely structural solutions have been proposed including the theories of Minimal Attachment (Frazier, 1978) and Right Association (Kimball, 1973). While these models may suggest the existence of strong syntactic preferences in effect during sentence understanding, other studies provide clear evidence that purely syntactic heuristics for prepositional phrase attachment will not work (see (Whittemore, Ferrara, &amp; Brunner, 1990), (Taraban, &amp; McClelland, 1988)). However, computational linguists have found the manual encoding of disambiguation rules — especially those that merge syntactic and semantic constraints — to be difficult, time-consuming, and prone to error. In addition, hand-coded heuristics are often incomplete and perform poorly </context>
</contexts>
<marker>Kimball, 1973</marker>
<rawString>Kimball, J. (1973). Seven principles of surface structure parsing in natural language. Cognition, 2, 15-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>M McCord</author>
</authors>
<title>A syntactic filter on pronominal anaphora for slot grammar.</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics. University of Pittsburgh. Association for Computational Linguistics.</institution>
<marker>Lappin, McCord, 1990</marker>
<rawString>Lappin, S., &amp; McCord, M. (1990). A syntactic filter on pronominal anaphora for slot grammar. Proceedings, 28th Annual Meeting of the Association for Computational Linguistics. University of Pittsburgh. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lehnert</author>
</authors>
<title>Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two Worlds. In</title>
<date>1990</date>
<booktitle>Advances in Connectionist and Neural Computation Theory.</booktitle>
<publisher>Ablex Publishers.</publisher>
<location>Norwood, NJ:</location>
<contexts>
<context position="9011" citStr="Lehnert, 1990" startWordPosition="1364" endWordPosition="1365">mmar often directly encode information for relative pronoun disambiguation in the grammar. Alternatively, a syntactic filter is applied to the parse tree and any noun phrases for which coreference with the relative pronoun is syntactically legal (or, in some cases, illegal) are passed to a semantic component which determines the antecedent using inference or preference rules (see (Correa, 1988), (Hobbs, 1986), (Ingria, &amp; Stallard, 1989), (Lappin, &amp; McCord, 1990)). The third approach employs handcoded disambiguation heuristics that rely mainly on 2UMass/MUC-3 is a version of the CIRCUS parser (Lehnert, 1990) developed for the MUC-3 performance evaluation. See (Lehnert et. al., 1991) for a description of UMass/MUC-3. MUC-3 is the Third Message Understanding System Evaluation and Message Understanding Conference (Sundheim, 1991). 217 semantic knowledge but also include syntactic constraints (e.g., UMass/MUC-3). However, there are problems with all 3 approaches in that 1) the grammar must be designed to find relative pronoun antecedents for all possible syntactic contexts; 2) the grammar and/or inference rules require tuning for new corpora; and 3) in most cases, the approach unreasonably assumes a </context>
</contexts>
<marker>Lehnert, 1990</marker>
<rawString>Lehnert, W. (1990). Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two Worlds. In J. Barnden, &amp; J. Pollack (Eds.), Advances in Connectionist and Neural Computation Theory. Norwood, NJ: Ablex Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lehnert</author>
<author>C Cardie</author>
<author>D Fisher</author>
<author>E Riloff</author>
<author>R Williams</author>
</authors>
<date>1991</date>
<booktitle>of Massachusetts: Description of the CIRCUS System as Used for MUC-3. Proceedings, Third Message Understanding Conference (MUC-3 ).</booktitle>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Diego, CA.</location>
<marker>Lehnert, Cardie, Fisher, Riloff, Williams, 1991</marker>
<rawString>Lehnert, W., Cardie, C., Fisher, D., Riloff, E., &amp; Williams, R. (1991).University of Massachusetts: Description of the CIRCUS System as Used for MUC-3. Proceedings, Third Message Understanding Conference (MUC-3 ). San Diego, CA. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ravin</author>
</authors>
<title>Disambiguating and interpreting verb definitions.</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</institution>
<marker>Ravin, 1990</marker>
<rawString>Ravin, Y. (1990). Disambiguating and interpreting verb definitions. Proceedings, 28th Annual Meeting of the Association for Computational Linguists. University of Pittsburgh. Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>C Riesbeck</author>
</authors>
<title>Inside Computer Understanding: Five Programs Plus Miniatures.</title>
<date>1981</date>
<location>Hillsdale, NJ: Lawrence Erlbaum.</location>
<marker>Schank, Riesbeck, 1981</marker>
<rawString>Schank, R., &amp; Riesbeck, C. (1981). Inside Computer Understanding: Five Programs Plus Miniatures. Hillsdale, NJ: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B M Sundheim</author>
</authors>
<title>Overview of the Third Message Understanding Evaluation and Conference.</title>
<booktitle>Proceedings ,Third Message Understanding Conference (MUC-3).</booktitle>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Diego, CA.</location>
<marker>Sundheim, </marker>
<rawString>Sundheim, B. M. (May,1991). Overview of the Third Message Understanding Evaluation and Conference. Proceedings ,Third Message Understanding Conference (MUC-3). San Diego, CA. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Taraban</author>
<author>J L McClelland</author>
</authors>
<title>Constituent attachment and thematic role assignment in sentence processing: influences of content-based expectations.</title>
<date>1988</date>
<journal>Journal of Memory and Language,</journal>
<volume>27</volume>
<pages>597--632</pages>
<marker>Taraban, McClelland, 1988</marker>
<rawString>Taraban, R., &amp; McClelland, J. L. (1988). Constituent attachment and thematic role assignment in sentence processing: influences of content-based expectations. Journal of Memory and Language, 27, 597-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Whittemore</author>
<author>K Ferrara</author>
<author>H Brunner</author>
</authors>
<title>Empirical study of predictive powers of simple attachment schemes for post-modifier prepositional phrases.</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics. University of Pittsburgh. Association for Computational Linguistics.</institution>
<contexts>
<context position="1948" citStr="Whittemore, Ferrara, &amp; Brunner, 1990" startWordPosition="258" endWordPosition="262">uation rules, is difficult because successful heuristics demand the assimilation of complex syntactic and semantic knowledge. Consider, for example, the problem of prepositional phrase attachment. A number of purely structural solutions have been proposed including the theories of Minimal Attachment (Frazier, 1978) and Right Association (Kimball, 1973). While these models may suggest the existence of strong syntactic preferences in effect during sentence understanding, other studies provide clear evidence that purely syntactic heuristics for prepositional phrase attachment will not work (see (Whittemore, Ferrara, &amp; Brunner, 1990), (Taraban, &amp; McClelland, 1988)). However, computational linguists have found the manual encoding of disambiguation rules — especially those that merge syntactic and semantic constraints — to be difficult, time-consuming, and prone to error. In addition, hand-coded heuristics are often incomplete and perform poorly in new domains comprised of specialized vocabularies or a different genre of text. In this paper, we focus on a single ambiguity in sentence processing: locating the antecedents of relative pronouns. We present an implemented corpus-based approach for the automatic acquisition of d</context>
</contexts>
<marker>Whittemore, Ferrara, Brunner, 1990</marker>
<rawString>Whittemore, G., Ferrara, K., &amp; Brunner, H. (1990). Empirical study of predictive powers of simple attachment schemes for post-modifier prepositional phrases. Proceedings, 28th Annual Meeting of the Association for Computational Linguistics. University of Pittsburgh. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>