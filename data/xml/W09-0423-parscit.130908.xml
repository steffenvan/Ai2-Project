<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001886">
<title confidence="0.811476">
SMT and SPE Machine Translation Systems for WMT’09
</title>
<author confidence="0.808586">
Holger Schwenk and Sadaf Abdul-Rauf and Loic Barrault
</author>
<affiliation confidence="0.800349">
LIUM, University of Le Mans
</affiliation>
<address confidence="0.491661">
72085 Le Mans cedex 9, FRANCE
</address>
<email confidence="0.945045">
schwenk,abdul,barrault@lium.univ-lemans.fr
</email>
<author confidence="0.877504">
Jean Senellart
</author>
<affiliation confidence="0.434641">
SYSTRAN SA
</affiliation>
<address confidence="0.604215">
92044 Paris La D´efense cedex, FRANCE
</address>
<email confidence="0.995297">
senellart@systran.fr
</email>
<sectionHeader confidence="0.997307" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999815272727273">
This paper describes the development of
several machine translation systems for
the 2009 WMT shared task evaluation.
We only consider the translation between
French and English. We describe a sta-
tistical system based on the Moses de-
coder and a statistical post-editing sys-
tem using SYSTRAN’s rule-based system.
We also investigated techniques to auto-
matically extract additional bilingual texts
from comparable corpora.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976294117647">
This paper describes the machine translation sys-
tems developed by the Computer Science labo-
ratory at the University of Le Mans (LIUM) for
the 2009 WMT shared task evaluation. This work
was performed in cooperation with the company
SYSTRAN. We only consider the translation be-
tween French and English (in both directions).
The main differences to the previous year’s system
(Schwenk et al., 2008) are as follows: better us-
age of SYSTRAN’s bilingual dictionary in the sta-
tistical system, less bilingual training data, addi-
tional language model training data (news-train08
as distributed by the organizers), usage of com-
parable corpora to improve the translation model,
and development of a statistical post-editing sys-
tem (SPE). These different components are de-
scribed in the following.
</bodyText>
<sectionHeader confidence="0.993953" genericHeader="method">
2 Used Resources
</sectionHeader>
<bodyText confidence="0.999935">
In the frame work of the 2009 WMT shared trans-
lation task many resources were made available.
The following sections describe how they were
used to train the translation and language models
of the systems.
</bodyText>
<subsectionHeader confidence="0.990027">
2.1 Bilingual data
</subsectionHeader>
<bodyText confidence="0.999868891891891">
The latest version of the French/English Europarl
and news-commentary corpus were used. We re-
alized that the first corpus contains parts with for-
eign languages. About 1200 such lines were ex-
cluded.1 Additional bilingual corpora were avail-
able, namely the Canadian Hansard corpus (about
68M English words) and an UN corpus (about
198M English words). In several initial exper-
iments, we found no evidence that adding this
data improves the overall system and they were
not used in the final system, in order to keep
the phrase-table small. We also performed ex-
periments with the provided so-called bilingual
French/English Gigaword corpus (575M English
words in release 3). Again, we were not able
to achieve any improvement by adding this data
to the training material of the translation model.
These findings are somehow surprising since it
was eventually believed by the community that
adding large amounts of bitexts should improve
the translation model, as it is usually observed for
the language model (Brants et al., 2007).
In addition to these human generated bitexts,
we also integrated a high quality bilingual dictio-
nary from SYSTRAN. The entries of the dictio-
nary were directly added to the bitexts. This tech-
nique has the potential advantage that the dictio-
nary words could improve the alignments of these
words when they also appear in the other bitexts.
However, it is not guaranteed that multi-word ex-
pressions will be correctly aligned by GIZA++
and that only meaningful translations will actually
appear in the phrase-table. A typical example is
fire engine – camion de pompiers, for which the
individual constituent words are not good trans-
lations of each other. The use of a dictionary to
improve an SMT system was also investigated by
</bodyText>
<footnote confidence="0.981193">
1Lines 580934–581316 and 599839–600662.
</footnote>
<note confidence="0.497147">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 130–134,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.980508">
130
</page>
<figure confidence="0.9927455">
9.3M words
10.3M words
French
English
translations
Gigaword
used as queries
per day articles candidate sentence pairs sentences with parallel
extra words at ends sentences
length
comparison
+
number / table
tail
removal
removing
WER
133M words
parallel
174M words
FR
SMT
+−5 day articles
from English Gigaword
</figure>
<figureCaption confidence="0.999997">
Figure 1: Architecture of the parallel sentence extraction system (Rauf and Schwenk, 2009).
</figureCaption>
<bodyText confidence="0.968836375">
(Brown et al., 1993).
In comparison to our previous work (Schwenk
et al., 2008), we also included all verbs in the
French subjonctif and pass´e simple tense. In fact,
those tenses seem to be frequently used in news
material. In total about 10,000 verbs, 1,500 adjec-
tives/adverbs and more than 100,000 noun forms
were added.
</bodyText>
<subsectionHeader confidence="0.999617">
2.2 Use of Comparable corpora
</subsectionHeader>
<bodyText confidence="0.999971172413793">
Available human translated bitexts such as the UN
and the Hansard corpus seem to be out-of domain
for this task, as mentioned above. Therefore, we
investigated a new method to automatically extract
and align parallel sentences from comparable in-
domain corpora. In this work we used the AFP
news texts since there are available in the French
and English LDC Gigaword corpora.
The general architecture of our parallel sentence
extraction system is shown in figure 1. We first
translate 174M words from French into English
using an SMT system. These English sentences
are then used to search for translations in the En-
glish AFP texts of the Gigaword corpus using in-
formation retrieval techniques. The Lemur toolkit
(Ogilvie and Callan, 2001) was used for this pur-
pose. Search was limited to a window of ±5 days
of the date of the French news text. The retrieved
candidate sentences were then filtered using the
word error rate with respect to the automatic trans-
lations. In this study, sentences with an error rate
below 32% were kept. Sentences with a large
length difference (French versus English) or con-
taining a large fraction of numbers were also dis-
carded. By these means, about 9M words of ad-
ditional bitexts were obtained. An improved ver-
sion of this algorithm using TER instead of the
word error rate is described in detail in (Rauf and
Schwenk, 2009).
</bodyText>
<subsectionHeader confidence="0.998746">
2.3 Monolingual data
</subsectionHeader>
<bodyText confidence="0.999971166666667">
The French and English target language models
were trained on all provided monolingual data. We
realized that the news-train08 corpora contained
some foreign texts, in particular in German. We
tried to filter those lines using simple regular ex-
pressions. We also discarded lines with a large
fraction of numerical expressions. In addition,
LDC’s Gigaword collection, the Hansard corpus
and the UN corpus were used for both languages.
Finally, about 30M words crawled from the WEB
were used for the French LM. All this data pre-
dated the evaluation period.
</bodyText>
<subsectionHeader confidence="0.994215">
2.4 Development data
</subsectionHeader>
<bodyText confidence="0.999988833333333">
All development was done on news-dev2009a and
news-dev2009b was used as internal test set. The
default Moses tokenization was used. All our
models are case sensitive and include punctuation.
The BLEU scores reported in this paper were cal-
culated with the NIST tool and are case sensitive.
</bodyText>
<sectionHeader confidence="0.994305" genericHeader="method">
3 Language Modeling
</sectionHeader>
<bodyText confidence="0.9998739">
Language modeling plays an important role in
SMT systems. 4-gram back-off language models
(LM) were used in all our systems. The word list
contains all the words of the bitext used to train
the translation model and all words that appear at
least ten times in the news-train08 corpus. Sep-
arate LMs were build on each data source with
the SRI LM toolkit (Stolcke, 2002) and then lin-
early interpolated, optimizing the coefficients with
an EM procedure. The perplexities of these LMs
</bodyText>
<page confidence="0.981617">
131
</page>
<table confidence="0.998833352941177">
Corpus # Fr words Dev09a Dev09b Test09
SMT system
Eparl+NC
Eparl+NC+dict 48.5M
Eparl+NC+dict+AFP 57.8M
Eparl+NC 45.5M
Eparl+NC+AFP 54.4M
SPE system
SYSTRAN
46.5M
-
22.44 22.38 25.60
22.60 22.55 26.01
22.82 22.63* 26.18
22.84 22.59# 25.59
22.72 21.96 25.40
17.76 18.13 19.98
</table>
<tableCaption confidence="0.669577142857143">
Table 1: Case sensitive NIST BLEU scores for the French-English systems. “NC” denotes the news-
commentary bitexts, “dict” SYSTRAN’s bilingual dictionary and “AFP” the automatically aligned news
texts (*=primary, #=contrastive system)
are given in Table 2. Adding the new news-train08
monolingual data had an important impact on the
quality of the LM, even when the Gigaword data
is already included.
</tableCaption>
<table confidence="0.999590571428572">
Data French English
Vocabulary size 407k 299k
Eparl+news 248.8 416.7
+ LDC Gigaword 142.2 194.9
+ Hansard and UN 137.5 187.5
news-train08 alone 165.0 245.9
all 120.6 174.8
</table>
<tableCaption confidence="0.969917">
Table 2: Perplexities on the development data of
various language models.
</tableCaption>
<sectionHeader confidence="0.670962" genericHeader="method">
4 Architecture of the SMT system
</sectionHeader>
<bodyText confidence="0.998623571428571">
The goal of statistical machine translation (SMT)
is to produce a target sentence e from a source
sentence f. It is today common practice to use
phrases as translation units (Koehn et al., 2003;
Och and Ney, 2003) and a log linear framework in
order to introduce several models explaining the
translation process:
</bodyText>
<equation confidence="0.984379">
e* = arg max p(e|f)
�
= arg max {exp(
e
i
</equation>
<bodyText confidence="0.999957210526316">
The feature functions hi are the system models
and the Ai weights are typically optimized to max-
imize a scoring function on a development set
(Och and Ney, 2002). In our system fourteen
features functions were used, namely phrase and
lexical translation probabilities in both directions,
seven features for the lexicalized distortion model,
a word and a phrase penalty and a target language
model (LM).
The system is based on the Moses SMT toolkit
(Koehn et al., 2007) and constructed as follows.
First, word alignments in both directions are cal-
culated. We used a multi-threaded version of the
GIZA++ tool (Gao and Vogel, 2008).2 This speeds
up the process and corrects an error of GIZA++
that can appear with rare words. This previously
caused problems when adding the entries of the
bilingual dictionary to the bitexts.
Phrases and lexical reorderings are extracted us-
ing the default settings of the Moses toolkit. The
parameters of Moses are tuned on news-dev2009a,
using the cmert tool. The basic architecture of
the system is identical to the one used in the
2008 WMT evaluation (Schwenk et al., 2008),
but we did not use two pass decoding and n-best
list rescoring with a continuous space language
model.
The results of the SMT systems are summarized
in the upper part of Table 1 and 3. The dictionary
and the additional automatically produced AFP bi-
texts achieved small improvements when translat-
ing from French to English. In the opposite trans-
lation direction, the systems that include the addi-
tional AFP texts exhibit a bad generalisation be-
havior. We provide also the performance of the
different systems on the official test set, calculated
after the evaluation. In most of the cases, the ob-
served improvements carry over on the test set.
</bodyText>
<subsectionHeader confidence="0.547335">
5 Architecture of the SPE system
</subsectionHeader>
<bodyText confidence="0.99899525">
During the last years statistical post-editing sys-
tems have shown to achieve very competitive per-
formance (Simard et al., 2007; Dugast et al.,
2007). The main idea of this techniques is to use
</bodyText>
<footnote confidence="0.960076">
2The source is available at http://www.cs.cmu.
edu/˜qing/
</footnote>
<equation confidence="0.70873">
Aihi(ej))} (1)
</equation>
<page confidence="0.870078">
132
</page>
<table confidence="0.938852444444444">
Corpus # En words Dev09a Dev09b Test09
SMT system
Eparl+NC
Eparl+NC+dict
Eparl+NC+dict+AFP 51.7M
Eparl+NC 44.2M
Eparl+NC+AFP 53.3M
SPE system
SYSTRAN
41.6M
44.0M
-
21.89 21.78 23.80
22.28 22.35# 24.13
22.21 21.43 23.88
23.03 23.15 24.36
22.95 23.15* 24.62
18.68 18.84 20.29
</table>
<tableCaption confidence="0.980791">
Table 3: Case sensitive NIST BLEU scores for the English-French systems. “NC” denotes the news-
commentary bitexts, “dict” denotes SYSTRAN’s bilingual dictionary and “AFP” the automatically
aligned news texts (*=primary, #=contrastive system)
</tableCaption>
<bodyText confidence="0.999928304347826">
an SMT system to correct the errors of a rule-
based translation system. In this work, SYSTRAN
server version 6, followed by an SMT system
based on Moses were used. The post-editing sys-
tems uses exactly the same language models than
the above described stand-alone SMT systems.
The translation model was trained on the Europarl,
the news-commentary and the extracted AFP bi-
texts. The results of these SPE systems are sum-
marized in the lower part of Table 1 and 3. SYS-
TRAN’s rule-based system alone already achieves
remarkable BLEU scores although it was not op-
timized or adapted to this task. This could be sig-
nificantly improved using statistical post-editing.
The additional AFP texts were not useful when
translating form French to English, but helped to
improve the generalisation behavior for the En-
glish/French systems.
When translating from English to French (Ta-
ble 3), the SPE system is clearly better than the
carefully optimized SMT system. Consequently,
it was submitted as primary system and the SMT
system as contrastive one.
</bodyText>
<sectionHeader confidence="0.995877" genericHeader="conclusions">
6 Conclusion and discussion
</sectionHeader>
<bodyText confidence="0.999986387096774">
We described the development of two comple-
mentary machine translation systems for the 2009
WMT shared translation task: an SMT and an SPE
system. The last one is based on SYSTRAN’s
rule-based system. Interesting findings of this re-
search include the fact that the SPE system out-
performs the SMT system when translating into
French. This system has also obtained the best
scores in the human evaluation.
With respect to the SMT system, we were
not able to improve the translation model by
adding large amounts of bitexts, although different
sources were available (Canadian Hansard, UN
or WEB data). Eventually these corpora are too
noisy or out-of-domain. On the other hand, the
integration of a high quality bilingual dictionary
was helpful, as well as the automatic alignment of
news texts from comparable corpora.
Future work will concentrate on the integration
of previously successful techniques, in particu-
lar continuous space language models and lightly-
supervised training (Schwenk, 2008). We also be-
lieve that the tokenization could be improved, in
particular for the French sources texts. Numbers,
dates and other numerical expressions could be
translated by a rule-based system.
System combination has recently shown to pro-
vide important improvements of translation qual-
ity. We are currently working on a combination of
the SMT and SPE system. It may be also interest-
ing to add a third (hierarchical) MT system.
</bodyText>
<sectionHeader confidence="0.999245" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9995046">
This work has been partially funded by the French
Government under the project INSTAR (ANR
JCJC06 143038) and the by the Higher Education
Commission, Pakistan through the HEC Overseas
Scholarship 2005.
</bodyText>
<page confidence="0.9988">
133
</page>
<sectionHeader confidence="0.996403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999811962264151">
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large language mod-
els in machine translation. In EMNLP, pages 858–
867.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, Meredith J. Goldsmith, Jan Hajic,
Robert L. Mercer, and Surya Mohanty. 1993. But
dictionaries are data too. In Proceedings of the
workshop on Human Language Technology, pages
202–205, Princeton, New Jersey.
Loic Dugast, Jean Senellart, and Philipp Koehn. 2007.
Statistical post-editing on SYSTRAN’s rule-based
translation system. In Second Workshop on SMT,
pages 179–182.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natu-
ral Language Processing, pages 49–57, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrased-based machine translation.
In HLT/NACL, pages 127–133.
Philipp Koehn et al. 2007. Moses: Open source toolkit
for statistical machine translation. In ACL, demon-
stration session.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for sta-
tistical machine translation. In ACL, pages 295–302.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignement
models. Computational Linguistics, 29(1):19–51.
Paul Ogilvie and Jamie Callan. 2001. Experiments
using the Lemur toolkit. In In Proceedings of the
Tenth Text Retrieval Conference (TREC-10), pages
103–108.
Sadaf Abdul Rauf and Holger Schwenk. 2009. On the
use of comparable corpora to improve SMT perfor-
mance. In EACL, page to be published.
Holger Schwenk, Jean-Baptiste Fouet, and Jean Senel-
lart. 2008. First steps towards a general purpose
French/English statistical machine translation sys-
tem. In Third Workshop on SMT, pages 119–122.
Holger Schwenk. 2008. Investigations on large-
scale lightly-supervised training for statistical ma-
chine translation. In IWSLT, pages 182–189.
Michel Simard, Nicola Ueffing, Pierre Isabelle, and
Roland Kuhn. 2007. Rule-based translation with
statistical phrase-based post-editing. In Second
Workshop on SMT, pages 203–206.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In ICSLP, pages II: 901–
904.
</reference>
<page confidence="0.998623">
134
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.582805">
<title confidence="0.898858">SMT and SPE Machine Translation Systems for WMT’09</title>
<author confidence="0.968924">Schwenk Abdul-Rauf</author>
<affiliation confidence="0.999259">LIUM, University of Le</affiliation>
<address confidence="0.990417">72085 Le Mans cedex 9,</address>
<email confidence="0.967848">schwenk,abdul,barrault@lium.univ-lemans.fr</email>
<author confidence="0.990469">Jean</author>
<affiliation confidence="0.715739">SYSTRAN</affiliation>
<address confidence="0.982774">92044 Paris La D´efense cedex,</address>
<email confidence="0.985748">senellart@systran.fr</email>
<abstract confidence="0.9984155">This paper describes the development of several machine translation systems for the 2009 WMT shared task evaluation. We only consider the translation between French and English. We describe a statistical system based on the Moses decoder and a statistical post-editing system using SYSTRAN’s rule-based system. We also investigated techniques to automatically extract additional bilingual texts from comparable corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Ashok C Popat</author>
<author>Peng Xu</author>
<author>Franz J Och</author>
<author>Jeffrey Dean</author>
</authors>
<title>Large language models in machine translation.</title>
<date>2007</date>
<booktitle>In EMNLP,</booktitle>
<pages>858--867</pages>
<contexts>
<context position="2790" citStr="Brants et al., 2007" startWordPosition="429" endWordPosition="432"> adding this data improves the overall system and they were not used in the final system, in order to keep the phrase-table small. We also performed experiments with the provided so-called bilingual French/English Gigaword corpus (575M English words in release 3). Again, we were not able to achieve any improvement by adding this data to the training material of the translation model. These findings are somehow surprising since it was eventually believed by the community that adding large amounts of bitexts should improve the translation model, as it is usually observed for the language model (Brants et al., 2007). In addition to these human generated bitexts, we also integrated a high quality bilingual dictionary from SYSTRAN. The entries of the dictionary were directly added to the bitexts. This technique has the potential advantage that the dictionary words could improve the alignments of these words when they also appear in the other bitexts. However, it is not guaranteed that multi-word expressions will be correctly aligned by GIZA++ and that only meaningful translations will actually appear in the phrase-table. A typical example is fire engine – camion de pompiers, for which the individual consti</context>
</contexts>
<marker>Brants, Popat, Xu, Och, Dean, 2007</marker>
<rawString>Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large language models in machine translation. In EMNLP, pages 858– 867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Meredith J Goldsmith</author>
<author>Jan Hajic</author>
<author>Robert L Mercer</author>
<author>Surya Mohanty</author>
</authors>
<title>But dictionaries are data too.</title>
<date>1993</date>
<booktitle>In Proceedings of the workshop on Human Language Technology,</booktitle>
<pages>202--205</pages>
<location>Princeton, New Jersey.</location>
<contexts>
<context position="4160" citStr="Brown et al., 1993" startWordPosition="644" endWordPosition="647"> 599839–600662. Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 130–134, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 130 9.3M words 10.3M words French English translations Gigaword used as queries per day articles candidate sentence pairs sentences with parallel extra words at ends sentences length comparison + number / table tail removal removing WER 133M words parallel 174M words FR SMT +−5 day articles from English Gigaword Figure 1: Architecture of the parallel sentence extraction system (Rauf and Schwenk, 2009). (Brown et al., 1993). In comparison to our previous work (Schwenk et al., 2008), we also included all verbs in the French subjonctif and pass´e simple tense. In fact, those tenses seem to be frequently used in news material. In total about 10,000 verbs, 1,500 adjectives/adverbs and more than 100,000 noun forms were added. 2.2 Use of Comparable corpora Available human translated bitexts such as the UN and the Hansard corpus seem to be out-of domain for this task, as mentioned above. Therefore, we investigated a new method to automatically extract and align parallel sentences from comparable indomain corpora. In th</context>
</contexts>
<marker>Brown, Pietra, Pietra, Goldsmith, Hajic, Mercer, Mohanty, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, Meredith J. Goldsmith, Jan Hajic, Robert L. Mercer, and Surya Mohanty. 1993. But dictionaries are data too. In Proceedings of the workshop on Human Language Technology, pages 202–205, Princeton, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Dugast</author>
<author>Jean Senellart</author>
<author>Philipp Koehn</author>
</authors>
<title>Statistical post-editing on SYSTRAN’s rule-based translation system.</title>
<date>2007</date>
<booktitle>In Second Workshop on SMT,</booktitle>
<pages>179--182</pages>
<contexts>
<context position="10486" citStr="Dugast et al., 2007" startWordPosition="1694" endWordPosition="1697">the additional automatically produced AFP bitexts achieved small improvements when translating from French to English. In the opposite translation direction, the systems that include the additional AFP texts exhibit a bad generalisation behavior. We provide also the performance of the different systems on the official test set, calculated after the evaluation. In most of the cases, the observed improvements carry over on the test set. 5 Architecture of the SPE system During the last years statistical post-editing systems have shown to achieve very competitive performance (Simard et al., 2007; Dugast et al., 2007). The main idea of this techniques is to use 2The source is available at http://www.cs.cmu. edu/˜qing/ Aihi(ej))} (1) 132 Corpus # En words Dev09a Dev09b Test09 SMT system Eparl+NC Eparl+NC+dict Eparl+NC+dict+AFP 51.7M Eparl+NC 44.2M Eparl+NC+AFP 53.3M SPE system SYSTRAN 41.6M 44.0M - 21.89 21.78 23.80 22.28 22.35# 24.13 22.21 21.43 23.88 23.03 23.15 24.36 22.95 23.15* 24.62 18.68 18.84 20.29 Table 3: Case sensitive NIST BLEU scores for the English-French systems. “NC” denotes the newscommentary bitexts, “dict” denotes SYSTRAN’s bilingual dictionary and “AFP” the automatically aligned news tex</context>
</contexts>
<marker>Dugast, Senellart, Koehn, 2007</marker>
<rawString>Loic Dugast, Jean Senellart, and Philipp Koehn. 2007. Statistical post-editing on SYSTRAN’s rule-based translation system. In Second Workshop on SMT, pages 179–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="9181" citStr="Gao and Vogel, 2008" startWordPosition="1475" endWordPosition="1478">ure functions hi are the system models and the Ai weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002). In our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM). The system is based on the Moses SMT toolkit (Koehn et al., 2007) and constructed as follows. First, word alignments in both directions are calculated. We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008).2 This speeds up the process and corrects an error of GIZA++ that can appear with rare words. This previously caused problems when adding the entries of the bilingual dictionary to the bitexts. Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit. The parameters of Moses are tuned on news-dev2009a, using the cmert tool. The basic architecture of the system is identical to the one used in the 2008 WMT evaluation (Schwenk et al., 2008), but we did not use two pass decoding and n-best list rescoring with a continuous space language model. The results of t</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrased-based machine translation.</title>
<date>2003</date>
<booktitle>In HLT/NACL,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="8390" citStr="Koehn et al., 2003" startWordPosition="1340" endWordPosition="1343">. Adding the new news-train08 monolingual data had an important impact on the quality of the LM, even when the Gigaword data is already included. Data French English Vocabulary size 407k 299k Eparl+news 248.8 416.7 + LDC Gigaword 142.2 194.9 + Hansard and UN 137.5 187.5 news-train08 alone 165.0 245.9 all 120.6 174.8 Table 2: Perplexities on the development data of various language models. 4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e* = arg max p(e|f) � = arg max {exp( e i The feature functions hi are the system models and the Ai weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002). In our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM). The system is based on the Moses S</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrased-based machine translation. In HLT/NACL, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL, demonstration session.</booktitle>
<marker>Koehn, 2007</marker>
<rawString>Philipp Koehn et al. 2007. Moses: Open source toolkit for statistical machine translation. In ACL, demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="8714" citStr="Och and Ney, 2002" startWordPosition="1400" endWordPosition="1403">2: Perplexities on the development data of various language models. 4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e* = arg max p(e|f) � = arg max {exp( e i The feature functions hi are the system models and the Ai weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002). In our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM). The system is based on the Moses SMT toolkit (Koehn et al., 2007) and constructed as follows. First, word alignments in both directions are calculated. We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008).2 This speeds up the process and corrects an error of GIZA++ that can appear with rare words. This previously caused problems when a</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In ACL, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignement models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="8410" citStr="Och and Ney, 2003" startWordPosition="1344" endWordPosition="1347">s-train08 monolingual data had an important impact on the quality of the LM, even when the Gigaword data is already included. Data French English Vocabulary size 407k 299k Eparl+news 248.8 416.7 + LDC Gigaword 142.2 194.9 + Hansard and UN 137.5 187.5 news-train08 alone 165.0 245.9 all 120.6 174.8 Table 2: Perplexities on the development data of various language models. 4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e* = arg max p(e|f) � = arg max {exp( e i The feature functions hi are the system models and the Ai weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002). In our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM). The system is based on the Moses SMT toolkit (Koehn et</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignement models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ogilvie</author>
<author>Jamie Callan</author>
</authors>
<title>Experiments using the Lemur toolkit. In</title>
<date>2001</date>
<booktitle>In Proceedings of the Tenth Text Retrieval Conference (TREC-10),</booktitle>
<pages>103--108</pages>
<contexts>
<context position="5232" citStr="Ogilvie and Callan, 2001" startWordPosition="821" endWordPosition="824">as mentioned above. Therefore, we investigated a new method to automatically extract and align parallel sentences from comparable indomain corpora. In this work we used the AFP news texts since there are available in the French and English LDC Gigaword corpora. The general architecture of our parallel sentence extraction system is shown in figure 1. We first translate 174M words from French into English using an SMT system. These English sentences are then used to search for translations in the English AFP texts of the Gigaword corpus using information retrieval techniques. The Lemur toolkit (Ogilvie and Callan, 2001) was used for this purpose. Search was limited to a window of ±5 days of the date of the French news text. The retrieved candidate sentences were then filtered using the word error rate with respect to the automatic translations. In this study, sentences with an error rate below 32% were kept. Sentences with a large length difference (French versus English) or containing a large fraction of numbers were also discarded. By these means, about 9M words of additional bitexts were obtained. An improved version of this algorithm using TER instead of the word error rate is described in detail in (Rau</context>
</contexts>
<marker>Ogilvie, Callan, 2001</marker>
<rawString>Paul Ogilvie and Jamie Callan. 2001. Experiments using the Lemur toolkit. In In Proceedings of the Tenth Text Retrieval Conference (TREC-10), pages 103–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadaf Abdul Rauf</author>
<author>Holger Schwenk</author>
</authors>
<title>On the use of comparable corpora to improve SMT performance.</title>
<date>2009</date>
<booktitle>In EACL,</booktitle>
<pages>page</pages>
<note>to be published.</note>
<contexts>
<context position="4138" citStr="Rauf and Schwenk, 2009" startWordPosition="640" endWordPosition="643">y 1Lines 580934–581316 and 599839–600662. Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 130–134, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 130 9.3M words 10.3M words French English translations Gigaword used as queries per day articles candidate sentence pairs sentences with parallel extra words at ends sentences length comparison + number / table tail removal removing WER 133M words parallel 174M words FR SMT +−5 day articles from English Gigaword Figure 1: Architecture of the parallel sentence extraction system (Rauf and Schwenk, 2009). (Brown et al., 1993). In comparison to our previous work (Schwenk et al., 2008), we also included all verbs in the French subjonctif and pass´e simple tense. In fact, those tenses seem to be frequently used in news material. In total about 10,000 verbs, 1,500 adjectives/adverbs and more than 100,000 noun forms were added. 2.2 Use of Comparable corpora Available human translated bitexts such as the UN and the Hansard corpus seem to be out-of domain for this task, as mentioned above. Therefore, we investigated a new method to automatically extract and align parallel sentences from comparable i</context>
<context position="5852" citStr="Rauf and Schwenk, 2009" startWordPosition="932" endWordPosition="935">01) was used for this purpose. Search was limited to a window of ±5 days of the date of the French news text. The retrieved candidate sentences were then filtered using the word error rate with respect to the automatic translations. In this study, sentences with an error rate below 32% were kept. Sentences with a large length difference (French versus English) or containing a large fraction of numbers were also discarded. By these means, about 9M words of additional bitexts were obtained. An improved version of this algorithm using TER instead of the word error rate is described in detail in (Rauf and Schwenk, 2009). 2.3 Monolingual data The French and English target language models were trained on all provided monolingual data. We realized that the news-train08 corpora contained some foreign texts, in particular in German. We tried to filter those lines using simple regular expressions. We also discarded lines with a large fraction of numerical expressions. In addition, LDC’s Gigaword collection, the Hansard corpus and the UN corpus were used for both languages. Finally, about 30M words crawled from the WEB were used for the French LM. All this data predated the evaluation period. 2.4 Development data A</context>
</contexts>
<marker>Rauf, Schwenk, 2009</marker>
<rawString>Sadaf Abdul Rauf and Holger Schwenk. 2009. On the use of comparable corpora to improve SMT performance. In EACL, page to be published.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
<author>Jean-Baptiste Fouet</author>
<author>Jean Senellart</author>
</authors>
<title>First steps towards a general purpose French/English statistical machine translation system.</title>
<date>2008</date>
<booktitle>In Third Workshop on SMT,</booktitle>
<pages>119--122</pages>
<contexts>
<context position="1130" citStr="Schwenk et al., 2008" startWordPosition="164" endWordPosition="167">m based on the Moses decoder and a statistical post-editing system using SYSTRAN’s rule-based system. We also investigated techniques to automatically extract additional bilingual texts from comparable corpora. 1 Introduction This paper describes the machine translation systems developed by the Computer Science laboratory at the University of Le Mans (LIUM) for the 2009 WMT shared task evaluation. This work was performed in cooperation with the company SYSTRAN. We only consider the translation between French and English (in both directions). The main differences to the previous year’s system (Schwenk et al., 2008) are as follows: better usage of SYSTRAN’s bilingual dictionary in the statistical system, less bilingual training data, additional language model training data (news-train08 as distributed by the organizers), usage of comparable corpora to improve the translation model, and development of a statistical post-editing system (SPE). These different components are described in the following. 2 Used Resources In the frame work of the 2009 WMT shared translation task many resources were made available. The following sections describe how they were used to train the translation and language models of</context>
<context position="4219" citStr="Schwenk et al., 2008" startWordPosition="654" endWordPosition="657">tistical Machine Translation, pages 130–134, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 130 9.3M words 10.3M words French English translations Gigaword used as queries per day articles candidate sentence pairs sentences with parallel extra words at ends sentences length comparison + number / table tail removal removing WER 133M words parallel 174M words FR SMT +−5 day articles from English Gigaword Figure 1: Architecture of the parallel sentence extraction system (Rauf and Schwenk, 2009). (Brown et al., 1993). In comparison to our previous work (Schwenk et al., 2008), we also included all verbs in the French subjonctif and pass´e simple tense. In fact, those tenses seem to be frequently used in news material. In total about 10,000 verbs, 1,500 adjectives/adverbs and more than 100,000 noun forms were added. 2.2 Use of Comparable corpora Available human translated bitexts such as the UN and the Hansard corpus seem to be out-of domain for this task, as mentioned above. Therefore, we investigated a new method to automatically extract and align parallel sentences from comparable indomain corpora. In this work we used the AFP news texts since there are availabl</context>
<context position="9660" citStr="Schwenk et al., 2008" startWordPosition="1555" endWordPosition="1558">s follows. First, word alignments in both directions are calculated. We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008).2 This speeds up the process and corrects an error of GIZA++ that can appear with rare words. This previously caused problems when adding the entries of the bilingual dictionary to the bitexts. Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit. The parameters of Moses are tuned on news-dev2009a, using the cmert tool. The basic architecture of the system is identical to the one used in the 2008 WMT evaluation (Schwenk et al., 2008), but we did not use two pass decoding and n-best list rescoring with a continuous space language model. The results of the SMT systems are summarized in the upper part of Table 1 and 3. The dictionary and the additional automatically produced AFP bitexts achieved small improvements when translating from French to English. In the opposite translation direction, the systems that include the additional AFP texts exhibit a bad generalisation behavior. We provide also the performance of the different systems on the official test set, calculated after the evaluation. In most of the cases, the obser</context>
</contexts>
<marker>Schwenk, Fouet, Senellart, 2008</marker>
<rawString>Holger Schwenk, Jean-Baptiste Fouet, and Jean Senellart. 2008. First steps towards a general purpose French/English statistical machine translation system. In Third Workshop on SMT, pages 119–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
</authors>
<title>Investigations on largescale lightly-supervised training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In IWSLT,</booktitle>
<pages>182--189</pages>
<contexts>
<context position="13183" citStr="Schwenk, 2008" startWordPosition="2120" endWordPosition="2121">the human evaluation. With respect to the SMT system, we were not able to improve the translation model by adding large amounts of bitexts, although different sources were available (Canadian Hansard, UN or WEB data). Eventually these corpora are too noisy or out-of-domain. On the other hand, the integration of a high quality bilingual dictionary was helpful, as well as the automatic alignment of news texts from comparable corpora. Future work will concentrate on the integration of previously successful techniques, in particular continuous space language models and lightlysupervised training (Schwenk, 2008). We also believe that the tokenization could be improved, in particular for the French sources texts. Numbers, dates and other numerical expressions could be translated by a rule-based system. System combination has recently shown to provide important improvements of translation quality. We are currently working on a combination of the SMT and SPE system. It may be also interesting to add a third (hierarchical) MT system. 7 Acknowledgments This work has been partially funded by the French Government under the project INSTAR (ANR JCJC06 143038) and the by the Higher Education Commission, Pakis</context>
</contexts>
<marker>Schwenk, 2008</marker>
<rawString>Holger Schwenk. 2008. Investigations on largescale lightly-supervised training for statistical machine translation. In IWSLT, pages 182–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Nicola Ueffing</author>
<author>Pierre Isabelle</author>
<author>Roland Kuhn</author>
</authors>
<title>Rule-based translation with statistical phrase-based post-editing.</title>
<date>2007</date>
<booktitle>In Second Workshop on SMT,</booktitle>
<pages>203--206</pages>
<contexts>
<context position="10464" citStr="Simard et al., 2007" startWordPosition="1690" endWordPosition="1693">. The dictionary and the additional automatically produced AFP bitexts achieved small improvements when translating from French to English. In the opposite translation direction, the systems that include the additional AFP texts exhibit a bad generalisation behavior. We provide also the performance of the different systems on the official test set, calculated after the evaluation. In most of the cases, the observed improvements carry over on the test set. 5 Architecture of the SPE system During the last years statistical post-editing systems have shown to achieve very competitive performance (Simard et al., 2007; Dugast et al., 2007). The main idea of this techniques is to use 2The source is available at http://www.cs.cmu. edu/˜qing/ Aihi(ej))} (1) 132 Corpus # En words Dev09a Dev09b Test09 SMT system Eparl+NC Eparl+NC+dict Eparl+NC+dict+AFP 51.7M Eparl+NC 44.2M Eparl+NC+AFP 53.3M SPE system SYSTRAN 41.6M 44.0M - 21.89 21.78 23.80 22.28 22.35# 24.13 22.21 21.43 23.88 23.03 23.15 24.36 22.95 23.15* 24.62 18.68 18.84 20.29 Table 3: Case sensitive NIST BLEU scores for the English-French systems. “NC” denotes the newscommentary bitexts, “dict” denotes SYSTRAN’s bilingual dictionary and “AFP” the automati</context>
</contexts>
<marker>Simard, Ueffing, Isabelle, Kuhn, 2007</marker>
<rawString>Michel Simard, Nicola Ueffing, Pierre Isabelle, and Roland Kuhn. 2007. Rule-based translation with statistical phrase-based post-editing. In Second Workshop on SMT, pages 203–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In ICSLP,</booktitle>
<pages>901--904</pages>
<contexts>
<context position="7128" citStr="Stolcke, 2002" startWordPosition="1144" endWordPosition="1145"> used as internal test set. The default Moses tokenization was used. All our models are case sensitive and include punctuation. The BLEU scores reported in this paper were calculated with the NIST tool and are case sensitive. 3 Language Modeling Language modeling plays an important role in SMT systems. 4-gram back-off language models (LM) were used in all our systems. The word list contains all the words of the bitext used to train the translation model and all words that appear at least ten times in the news-train08 corpus. Separate LMs were build on each data source with the SRI LM toolkit (Stolcke, 2002) and then linearly interpolated, optimizing the coefficients with an EM procedure. The perplexities of these LMs 131 Corpus # Fr words Dev09a Dev09b Test09 SMT system Eparl+NC Eparl+NC+dict 48.5M Eparl+NC+dict+AFP 57.8M Eparl+NC 45.5M Eparl+NC+AFP 54.4M SPE system SYSTRAN 46.5M - 22.44 22.38 25.60 22.60 22.55 26.01 22.82 22.63* 26.18 22.84 22.59# 25.59 22.72 21.96 25.40 17.76 18.13 19.98 Table 1: Case sensitive NIST BLEU scores for the French-English systems. “NC” denotes the newscommentary bitexts, “dict” SYSTRAN’s bilingual dictionary and “AFP” the automatically aligned news texts (*=primary</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In ICSLP, pages II: 901– 904.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>