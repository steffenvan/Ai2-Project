<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.184927">
<title confidence="0.898843">
Methods for Amharic Part-of-Speech Tagging
</title>
<author confidence="0.992374">
Bj¨orn Gamb¨acktt Fredrik Olssont Atelach Alemu Argaw* Lars Asker*
</author>
<affiliation confidence="0.970423666666667">
†Userware Laboratory $Dpt. of Computer &amp; Information Science *Dpt. of Computer &amp; System Sciences
Swedish Institute of Computer Science Norwegian University of Science &amp; Technology Stockholm University
Kista, Sweden Trondheim, Norway Kista, Sweden
</affiliation>
<email confidence="0.97388">
{gamback,fredriko}@sics.se gamback@idi.ntnu.no {atelach,asker}@dsv.su.se
</email>
<sectionHeader confidence="0.993351" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985909090909">
The paper describes a set of experiments
involving the application of three state-of-
the-art part-of-speech taggers to Ethiopian
Amharic, using three different tagsets.
The taggers showed worse performance
than previously reported results for Eng-
lish, in particular having problems with
unknown words. The best results were
obtained using a Maximum Entropy ap-
proach, while HMM-based and SVM-
based taggers got comparable results.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996938195652174">
Many languages, especially on the African con-
tinent, are under-resourced in that they have
very few computational linguistic tools or corpora
(such as lexica, taggers, parsers or tree-banks)
available. Here, we will concentrate on the task
of developing part-of-speech taggers for Amharic,
the official working language of the government
of the Federal Democratic Republic of Ethiopia:
Ethiopia is divided into nine regions, each with
its own nationality language; however, Amharic is
the language for country-wide communication.
Amharic is spoken by about 30 million people
as a first or second language, making it the second
most spoken Semitic language in the world (after
Arabic), probably the second largest language in
Ethiopia (after Oromo), and possibly one of the
five largest languages on the African continent.
The actual size of the Amharic speaking popula-
tion must be based on estimates: Hudson (1999)
analysed the Ethiopian census from 1994 and in-
dicated that more than 40% of the population then
understood Amharic, while the current size of the
Ethiopian population is about 80 million.1
182.5 million according to CIA (2009); 76.9 according to
Ethiopian parliament projections in December 2008 based on
the preliminary reports from the census of May 2007.
In spite of the relatively large number of speak-
ers, Amharic is still a language for which very few
computational linguistic resources have been de-
veloped, and previous efforts to create language
processing tools for Amharic—e.g., Alemayehu
and Willett (2002) and Fissaha (2005)—have been
severely hampered by the lack of large-scale lin-
guistic resources for the language. In contrast, the
work detailed in the present paper has been able
to utilize the first publicly available medium-sized
tagged Amharic corpus, described in Section 5.
However, first the Amharic language as such is
introduced (in Section 2), and then the task of part-
of-speech tagging and some previous work in the
field is described (Section 3). Section 4 details the
tagging strategies used in the experiments, the re-
sults of which can be found in Section 6 together
with a short discussion. Finally, Section 7 sums up
the paper and points to ways in which we believe
that the results can be improved in the future.
</bodyText>
<sectionHeader confidence="0.99536" genericHeader="introduction">
2 Amharic
</sectionHeader>
<bodyText confidence="0.999577157894737">
Written Amharic (and Tigrinya) uses a unique
script originating from the Ge’ez alphabet (the
liturgical language of the Ethiopian Orthodox
Church). Written Ge’ez can be traced back to at
least the 4th century A.D., with the first versions
including consonants only, while the characters
in later versions represent consonant-vowel (CV)
pairs. In modern Ethiopic script each syllograph
(syllable pattern) comes in seven different forms
(called orders), reflecting the seven vowel sounds.
The first order is the basic form; the others are de-
rived from it by modifications indicating vowels.
There are 33 basic forms, giving 7*33 syllographs,
or fidels (‘fidel’, lit. ‘alphabet’ in Amharic, refers
both to the characters and the entire script). Unlike
Arabic and Hebrew, Amharic is written from left
to right. There is no agreed upon spelling standard
for compound words and the writing system uses
several ways to denote compounds
</bodyText>
<note confidence="0.949549">
Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 104–111,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.995346">
104
</page>
<table confidence="0.733279">
form pattern
root sbr CCC
perfect s¨abb¨ar CVCCVC
imperfect s¨abr CVCC
gerund s¨abr CVCC
imperative sb¨ar CCVC
causative ass¨abb¨ar as-CVCCVC
passive t¨as¨abb¨ar t¨as-CVCCVC
</table>
<tableCaption confidence="0.997923">
Table 1: Some forms of the verb sbr (‘break’)
</tableCaption>
<subsectionHeader confidence="0.972086">
2.1 Amharic morphology
</subsectionHeader>
<bodyText confidence="0.999992764705882">
A significantly large part of the vocabulary con-
sists of verbs, and like many other Semitic lan-
guages, Amharic has a rich verbal morphology
based on triconsonantal roots with vowel variants
describing modifications to, or supplementary de-
tail and variants of the root form. For example,
the root sbr, meaning ‘to break’ can have (among
others!) the forms shown in Table 1. Subject, gen-
der, number, etc., are also indicated as bound mor-
phemes on the verb, as well as objects and posses-
sion markers, mood and tense, beneficative, mal-
factive, transitive, dative, negative, etc.
Amharic nouns (and adjectives) can be inflected
for gender, number, definiteness, and case, al-
though gender is usually neutral. The definite ar-
ticle attaches to the end of a noun, as do conjunc-
tions, while prepositions are mostly prefixed.
</bodyText>
<subsectionHeader confidence="0.997818">
2.2 Processing Amharic morphology
</subsectionHeader>
<bodyText confidence="0.999960382352941">
The first effort on Amharic morphological pro-
cessing was a rule-based system for verbs (and
nouns derived from verbs) which used root pat-
terns and affixes to determine lexical and in-
flectional categories (Bayou, 2000), while Bayu
(2002) used an unsupervised learning approach
based on probabilistic models to extract stems,
prefixes, and suffixes for building a morphological
dictionary. The system was able to successfully
analyse 87% of a small testdata set of 500 words.
The first larger-scale morphological analyser
for Amharic verbs used XFST, the Xerox Finite
State Tools (Fissaha and Haller, 2003). This was
later extended to include all word categories (Am-
salu and Gibbon, 2005). Testing with 1620 words
text from an Amharic bible, 88–94% recall and
54–94% precision (depending on the word-class)
were reported. The lowest precision (54%) was
obtained for verbs; Amsalu and Demeke (2006)
thus describe ways to extend the finite-state sys-
tem to handle 6400 simple verbal stems generated
from 1300 root forms.
Alemayehu and Willett (2002) report on a stem-
mer for Information Retrieval for Amharic, and
testing on a 1221 random word sample stated
“Manual assessment of the resulting stems showed
that 95.5 percent of them were linguistically
meaningful,” but gave no evaluation of the cor-
rectness of the segmentations. Argaw and Asker
(2007) created a rule-based stemmer for a similar
task, and using 65 rules and machine readable dic-
tionaries obtained 60.0% accuracy on fictional text
(testing on 300 unique words) and 76.9% on news
articles (on 1503 words, of which 1000 unique).2
</bodyText>
<sectionHeader confidence="0.985358" genericHeader="method">
3 Part-of-Speech Tagging
</sectionHeader>
<bodyText confidence="0.9999693">
Part-of-speech (POS) tagging is normally treated
as a classification task with the goal to assign lex-
ical categories (word classes) to the words in a
text. Most work on tagging has concentrated on
English and on using supervised methods, in the
sense that the taggers have been trained on an
available, tagged corpus. Both rule-based and sta-
tistical / machine-learning based approaches have
been thoroughly investigated. The Brill Tagger
(Brill, 1995) was fundamental in using a com-
bined rule- and learning-based strategy to achieve
96.6% accuracy on tagging the Penn Treebank
version of the Wall Street Journal corpus. That
is, to a level which is just about what humans
normally achieve when hand-tagging a corpus, in
terms of interannotator agreement—even though
Voutilainen (1999) has shown that humans can get
close to the 100% agreement mark if the annota-
tors are allowed to discuss the problematic cases.
Later taggers have managed to improve Brill’s
figures a little bit, to just above 97% on the Wall
Street Journal corpus using Hidden Markov Mod-
els, HMM and Conditional Random Fields, CRF;
e.g., Collins (2002) and Toutanova et al. (2003).
However, most recent work has concentrated on
applying tagging strategies to other languages than
English, on combining taggers, and/or on using
unsupervised methods. In this section we will look
at these issues in more detail, in particular with the
relation to languages similar to Amharic.
</bodyText>
<subsectionHeader confidence="0.999862">
3.1 Tagging Semitic languages
</subsectionHeader>
<bodyText confidence="0.910446">
Diab et al. (2004) used a Support Vector Machine,
SVM-based tagger, trained on the Arabic Penn
</bodyText>
<footnote confidence="0.99548025">
2Other knowledge sources for processing Amharic in-
clude, e.g., Gasser’s verb stem finder (available from
nlp.amharic.org) and wordlists as those collected by
Gebremichael (www.cs.ru.nl/∼biniam/geez).
</footnote>
<page confidence="0.998977">
105
</page>
<bodyText confidence="0.99994315625">
Treebank 1 to tokenize, POS tag, and annotate
Arabic base phrases. With an accuracy of 95.5%
over a set of 24 tags, the data-driven tagger per-
formed on par with state-of-the-art results for En-
glish when trained on similar-sized data (168k to-
kens). Bar-Haim et al. (2008) developed a lexicon-
based HMM tagger for Hebrew. They report
89.6% accuracy using 21 tags and training on 36k
tokens of news text. Mansour (2008) ported this
tagger into Arabic by replacing the morphological
analyzer, achieving an accuracy of 96.3% over 26
tags on a 89k token corpus. His approach modifies
the analyses of sentences receiving a low proba-
bility by adding synthetically constructed analyses
proposed by a model using character information.
A first prototype POS tagger for Amharic used
a stochastic HMM to model contextual dependen-
cies (Getachew, 2001), but was trained and tested
on only one page of text. Getachew suggested a
tagset for Amharic consisting of 25 tags. More
recently, CRFs have been applied to segment and
tag Amharic words (Fissaha, 2005), giving an ac-
curacy of 84% for word segmentation, using char-
acter, morphological and lexical features. The best
result for POS-tagging was 74.8%, when adding a
dictionary and bigrams to lexical and morphologi-
cal features, and 70.0% without dictionary and bi-
grams. The data used in the experiments was also
quite small and consisted of 5 annotated news ar-
ticles (1000 words). The tagset was a reduced ver-
sion (10 tags) of the one used by Getachew (2001),
and will be further discussed in Section 5.2.
</bodyText>
<subsectionHeader confidence="0.999671">
3.2 Unsupervised tagging
</subsectionHeader>
<bodyText confidence="0.999987">
The desire to use unsupervised machine learning
approaches to tagging essentially originates from
the wish to exploit the vast amounts of unlabelled
data available when constructing taggers. The area
is particularly vivid when it comes to the treatment
of languages for which there exist few, if any, com-
putational resources, and for the case of adapting
an existing tagger to a new language domain.
Banko and Moore (2004) compared unsuper-
vised HMM and transformation-based taggers
trained on the same portions of the Penn Treebank,
and showed that the quality of the lexicon used for
training had a high impact on the tagging results.
Duh and Kirchhoff (2005) presented a minimally-
supervised approach to tagging for dialectal Ara-
bic (Colloquial Egyptian), based on a morpholog-
ical analyzer for Modern Standard Arabic and un-
labeled texts in a number of dialects. Using a tri-
gram HMM tagger, they first produced a baseline
system and then gradually improved on that in an
unsupervised manner by adding features so as to
facilitate the analysis of unknown words, and by
constraining and refining the lexicon.
Unsupervised learning is often casted as the
problem of finding (hidden) structure in unla-
beled data. Goldwater and Griffiths (2007) noted
that most recent approaches to this problem aim
to identify the set of attributes that maximizes
some target function (Maximum Likelihood Esti-
mation), and then to select the values of these at-
tributes based on the representation of the model.
They proposed a different approach, based on
Bayesian principles, which tries to directly max-
imize the probability of the attributes based on
observation in the data. This Bayesian approach
outperformed Maximum Likelihood Estimation
when training a trigram HMM tagger for English.
Toutanova and Johnson (2007) report state-of-the-
art results by extending the work on Bayesian
modelling for unsupervised learning of taggers
both in the way that prior knowledge can be incor-
porated into the model, and in the way that possi-
ble tags for a given word is explicitly modeled.
</bodyText>
<subsectionHeader confidence="0.999824">
3.3 Combining taggers
</subsectionHeader>
<bodyText confidence="0.999960652173913">
A possible way to improve on POS tagging results
is to combine the output of several different tag-
gers into a committee, forming joint decisions re-
garding the labeling of the input. Roughly, there
are three obvious ways of combining multiple pre-
dicted tags for a word: random decision, voting,
and stacking (Dietterich, 1997), with the first way
suited only for forming a baseline. Voting can
be divided into two subclasses: unweighted votes,
and weighted votes. The weights of the votes, if
any, are usually calculated based on the classifiers’
performance on some initial dataset. Stacking, fi-
nally, is a way of combining the decisions made
by individual taggers in which the predicted tags
for a given word are used as input to a subsequent
tagger which outputs a final label for the word.
Committee-based approaches to POS tagging
have been in focus the last decade: Brill and Wu
(1998) combined four different taggers for English
using unweighted voting and by exploring contex-
tual cues (essentially a variant of stacking). Aires
et al. (2000) experimented with 12 different ways
of combining the output from taggers for Brazilian
</bodyText>
<page confidence="0.991778">
106
</page>
<bodyText confidence="0.99996725">
Portuguese, and concluded that some, but not all,
combinations yielded better accuracy than the best
individual tagger. Shacham and Wintner (2007)
contrasted what they refer to as being a naive way
of combining taggers with a more elaborate, hi-
erarchical one for Hebrew. In the end, the elabo-
rated method yielded results inferior to the naive
approach. De Pauw et al. (2006) came to simi-
lar conclusions when using five different ways of
combining four data-driven taggers for Swahili.
The taggers were based on HMM, Memory-based
learning, SVM, and Maximum Entropy, with the
latter proving most accurate. Only in three of
five cases did a combination of classifiers perform
better than the Maximum Entropy-based tagger,
and simpler combination methods mostly outper-
formed more elaborate ones.
Spoustov´a et al. (2007) report on work on com-
bining a hand-written rule-based tagger with three
statistically induced taggers for Czech. As an ef-
fect of Czech being highly inflectional, the tagsets
are large: 1000–2000 unique tags. Thus the ap-
proach to combining taggers first aims at reducing
the number of plausible tags for a word by using
the rule-based tagger to discard impossible tags.
Precision is then increased by invoking one or all
of the data-driven taggers. Three different ways of
combining the taggers were explored: serial com-
bination, involving one of the statistical taggers;
so called SUBPOS pre-processing, involving two
instances of statistical taggers (possibly the same
tagger); and, parallel combination, in which an ar-
bitrary number of statistical taggers is used. The
combined tagger yielded the best results for Czech
POS tagging reported to date, and as a side-effect
also the best accuracy for English: 97.43%.3
</bodyText>
<sectionHeader confidence="0.992987" genericHeader="method">
4 The Taggers
</sectionHeader>
<bodyText confidence="0.9999805">
This section describes the three taggers used in the
experiments (which are reported on in Section 6).
</bodyText>
<subsectionHeader confidence="0.978745">
4.1 Hidden Markov Models: TnT
</subsectionHeader>
<bodyText confidence="0.998525857142857">
TnT, “Trigrams’n’Tags” (Brants, 2000) is a very
fast and easy-to-use HMM-based tagger which
painlessly can be trained on different languages
and tagsets, given a tagged corpus.4 A Markov-
based tagger aims to find a tag sequence which
maximizes P(word,,,jtag,,,) ~ P(tag,,,jtagi...,,,_i),
where the first factor is the emit (or lexical) prob-
</bodyText>
<footnote confidence="0.9997875">
3As reported on ufal.mff.cuni.cz/compost/en
4www.coli.uni-saarland.de/∼thorsten/tnt
</footnote>
<bodyText confidence="0.999811384615384">
ability, the likelihood of a word given certain tag,
and the second factor is the state transition (or con-
textual) probability, the likelihood of a tag given a
sequence of preceding tags. TnT uses the Viterbi
algorithm for finding the optimal tag sequence.
Smoothing is implemented by linear interpolation,
the respective weights are determined by deleted
interpolation. Unknown words are handled by a
suffix trie and successive abstraction.
Applying TnT to the Wall Street Journal cor-
pus, Brants (2000) reports 96.7% overall accuracy,
with 97.0% on known and 85.5% on unknown
words (with 2.9% of the words being unknown).
</bodyText>
<subsectionHeader confidence="0.98619">
4.2 Support Vector Machines: SVMTool
</subsectionHeader>
<bodyText confidence="0.999921714285714">
Support Vector Machines (SVM) is a linear learn-
ing system which builds two class classifiers. It
is a supervised learning method whereby the in-
put data are represented as vectors in a high-
dimensional space and SVM finds a hyperplane (a
decision boundary) separating the input space into
two by maximizing the margin between positive
and negative data points.
SVMTool is an open source tagger based on
SVMs.5 Comparing the accuracy of SVMTool
with TnT on the Wall Street Journal corpus,
Gim´enez and M`arquez (2004) report a better per-
formance by SVMTool: 96.9%, with 97.2% on
known words and 83.5% on unknown.
</bodyText>
<subsectionHeader confidence="0.996185">
4.3 Maximum Entropy: MALLET
</subsectionHeader>
<bodyText confidence="0.999813">
Maximum Entropy is a linear classification
method. In its basic incarnation, linear classifi-
cation combines, by addition, the pre-determined
weights used for representing the importance of
each feature to a given class. Training a Maxi-
mum Entropy classifier involves fitting the weights
of each feature value for a particular class to the
available training data. A good fit of the weights
to the data is obtained by selecting weights to max-
imize the log-likelihood of the learned classifica-
tion model. Using an Maximum Entropy approach
to POS tagging, Ratnaparkhi (1996) reports a tag-
ging accuracy of 96.6% on the Wall Street Journal.
The software of choice for the experiments re-
ported here is MALLET (McCallum, 2002), a
freely available Java implementation of a range of
machine learning methods, such as Naive Bayes,
decision trees, CRF, and Maximum Entropy.6
</bodyText>
<footnote confidence="0.9987165">
5www.lsi.upc.edu/∼nlp/SVMTool
6mallet.cs.umass.edu
</footnote>
<page confidence="0.996921">
107
</page>
<sectionHeader confidence="0.994938" genericHeader="method">
5 The Dataset
</sectionHeader>
<bodyText confidence="0.999970941176471">
The experiments of this paper utilize the first
medium-sized corpus for Amharic (available at
http://nlp.amharic.org). The corpus consists
of all 1065 news texts (210,000 words) from the
Ethiopian year 1994 (parts of the Gregorian years
2001–2002) from the Walta Information Center, a
private news service based in Addis Ababa. It has
been morphologically analysed and manually part-
of-speech tagged by staff at ELRC, the Ethiopian
Languages Research Center at Addis Ababa Uni-
versity (Demeke and Getachew, 2006).
The corpus is available both infidel and tran-
scribed into a romanized version known as SERA,
System for Ethiopic Representation in ASCII (Ya-
cob, 1997). We worked with the transliterated
form (202,671 words), to be compatible with the
machine learning tools used in the experiments.
</bodyText>
<subsectionHeader confidence="0.987045">
5.1 “Cleaning” the corpus
</subsectionHeader>
<bodyText confidence="0.999979766666667">
Unfortunately, the corpus available on the net con-
tains quite a few errors and tagging inconsisten-
cies: nine persons participated in the manual tag-
ging, writing the tags with pen on hard copies,
which were given to typists for insertion into the
electronic version of the corpus—a procedure ob-
viously introducing several possible error sources.
Before running the experiments the corpus had
to be “cleaned”: many non-tagged items have been
tagged (the human taggers have, e.g., often tagged
the headlines of the news texts as one item, end-
of-sentence punctuation), while some double tags
have been removed. Reflecting the segmentation
of the original Amharic text, all whitespaces were
removed, merging multiword units with a single
tag into one-word units. Items like ‘&amp;quot;’ and ‘/’
have been treated consistently as punctuation, and
consistent tagging has been added to word-initial
and word-final hyphens. Also, some direct tagging
errors and misspellings have been corrected.
Time expressions and numbers have not been
consistently tagged at all, but those had to be left
as they were. Finally, many words have been tran-
scribed into SERA in several versions, with only
the cases differing. However, this is also difficult
to account for (and in the experiments below we
used the case sensitive version of SERA), since
the SERA notation in general lets upper and lower
cases of the English alphabet represent different
symbols infidel (the Amharic script).
</bodyText>
<subsectionHeader confidence="0.989703">
5.2 Tagsets
</subsectionHeader>
<bodyText confidence="0.999991027027027">
For the experiments, three different tagsets were
used. Firstly, the full, original 30-tag set devel-
oped at the Ethiopian Languages Research Center
and described by Demeke and Getachew (2006).
This version of the corpus will be referred to as
‘ELRC’. It contains 200,863 words and differs
from the published corpus in way of the correc-
tions described in the previous section.
Secondly, the corpus was mapped to 11 basic
tags. This set consists of ten word classes: Noun,
Pronoun, Verb, Adjective, Preposition, Conjunc-
tion, Adverb, Numeral, Interjection, and Punctua-
tion, plus one tag for problematic words (unclear:
&lt;UNC&gt;). The main differences between the two
tagsets pertain to the treatment of prepositions and
conjunctions: in ‘ELRC’ there are specific classes
for, e.g., pronouns attached with preposition, con-
junction, and both preposition and conjunction
(similar classes occur for nouns, verbs, adjectives,
and numerals). In addition, numerals are divided
into cardinals and ordinals, verbal nouns are sepa-
rated from other nouns, while auxiliaries and rela-
tive verbs are distinguished from other verbs. The
full tagset is made up of thirty subclasses of the
basic classes, based on type of word only: the tags
contain no information on grammatical categories
(such as number, gender, tense, and aspect).
Thirdly, for comparison reasons, the full tagset
was mapped to the 10 tags used by Fissaha (2005).
These classes include one for Residual (R) which
was assumed to be equivalent to &lt;UNC&gt;. In addi-
tion, &lt;CONJ&gt; and &lt;PREP&gt; were mapped to Ad-
position (AP), and both &lt;N&gt; and &lt;PRON&gt; to N.
The other mappings were straight-forward, except
that the ‘BASIC’ tagset groups all verbs together,
while Fissaha kept Auxiliary (AUX) as its own
class. This tagset will be referred to as ‘SISAY’.
</bodyText>
<subsectionHeader confidence="0.981326">
5.3 Folds
</subsectionHeader>
<bodyText confidence="0.999970727272727">
For evaluation of the taggers, the corpus was split
into 10 folds. These folds were created by chop-
ping the corpus into 100 pieces, each of about
2000 words in sequence, while making sure that
each piece contained full sentences (rather than
cutting off the text in the middle of a sentence),
and then merging sets of 10 pieces into a fold.
Thus the folds represent even splits over the cor-
pus, to avoid tagging inconsistencies, but the se-
quences are still large enough to potentially make
knowledge sources such as n-grams useful.
</bodyText>
<page confidence="0.996193">
108
</page>
<table confidence="0.999865692307692">
Fold TOTAL KNOWN UNKNOWN
fold00 20,027 17,720 2,307
fold01 20,123 17,750 2,373
fold02 20,054 17,645 2,409
fold03 20,169 17,805 2,364
fold04 20,051 17,524 2,527
fold05 20,058 17,882 2,176
fold06 20,111 17,707 2,404
fold07 20,112 17,746 2,366
fold08 20,015 17,765 2,250
fold09 20,143 17,727 2,416
Average 20,086 17,727 2,359
Percent — 88.26 11.74
</table>
<tableCaption confidence="0.993241">
Table 2: Statistics for the 10 folds
</tableCaption>
<bodyText confidence="0.9974678">
Table 2 shows the data for each of the folds, in
terms of total number of tokens, as well as split
into known and unknown tokens, where the term
UNKNOWN refers to tokens that are not in any of
the other nine folds. The figures at the bottom
of the table show the average numbers of known
and unknown words, over all folds. Notably, the
average number of unknown words is about four
times higher than in the Wall Street Journal cor-
pus (which, however, is about six times larger).
</bodyText>
<sectionHeader confidence="0.999841" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999990846153846">
The results obtained by applying the three dif-
ferent tagging strategies to the three tagsets are
shown in Table 3, in terms of average accura-
cies after 10-fold cross validation, over all the
tokens (with standard deviation),7 as well as ac-
curacy divided between the known and unknown
words. Additionally, SVMTool and MALLET in-
clude support for automatically running 10-fold
cross validation on their own folds. Figures for
those runs are also given. The last line of the table
shows the baselines for the tagsets, given as the
number of tokens tagged as regular nouns divided
by the total number of words after correction.
</bodyText>
<subsectionHeader confidence="0.994047">
6.1 TnT
</subsectionHeader>
<bodyText confidence="0.999947222222222">
As the bold face figures indicate, TnT achieves the
best scores of all three taggers, on all three tagsets,
on known words. However, it has problems with
the unknown words—and since these are so fre-
quent in the corpus, TnT overall performs worse
than the other taggers. The problems with the un-
known words increase as the number of possible
tags increase, and thus TnT does badly on the orig-
inal tagging scheme (‘ELRC’), where it only gets
</bodyText>
<footnote confidence="0.925155">
7The standard deviation is given by V n1 Eni=1 (xi − x)2
where x is the arithmetic mean ( &apos; E 1 xi).
</footnote>
<table confidence="0.999818555555555">
ELRC BASIC SISAY
TnT 85.56 92.55 92.60
STD DEV 0.42 0.31 0.32
KNOWN 90.00 93.95 93.99
UNKNOWN 52.13 82.06 82.20
SVM 88.30 92.77 92.80
STD DEV 0.41 0.31 0.37
KNOWN 89.58 93.37 93.34
UNKNOWN 78.68 88.23 88.74
Own folds 88.69 92.97 92.99
STD DEV 0.33 0.17 0.26
MaxEnt 87.87 92.56 92.60
STD DEV 0.49 0.38 0.43
KNOWN 89.44 93.26 93.27
UNKNOWN 76.05 87.29 87.61
Own folds 90.83 94.64 94.52
STD DEV 1.37 1.11 0.69
BASELINE 35.50 58.26 59.61
</table>
<tableCaption confidence="0.999702">
Table 3: Tagging results
</tableCaption>
<bodyText confidence="0.999658625">
a bit over 50% on the unknown words (and 85.6%
overall). For the two reduced tagsets TnT does
better: overall performance goes up to a bit over
92%, with 82% on unknown words.
Table 3 shows the results on the default configu-
ration of TnT, i.e., using 3-grams and interpolated
smoothing. Changing these settings give no sub-
stantial improvement overall: what is gained at
one end (e.g., on unknown words or a particular
tagset) is lost at the other end (on known words or
other tagsets). However, per default TnT uses a
suffix trie of length 10 to handle unknown words.
Extending the suffix to 20 (the maximum value
in TnT) gave a slight performance increase on
‘ELCR’ (0.13% on unknown words, 0.01% over-
all), while having no effect on the smaller tagsets.
</bodyText>
<subsectionHeader confidence="0.997797">
6.2 SVM
</subsectionHeader>
<bodyText confidence="0.999981818181818">
The SVM-tagger outperforms TnT on unknown
words, but is a bit worse on known words. Overall,
SVM is slightly better than TnT on the two smaller
tagsets and clearly better on the large tagset, and
somewhat better than MaxEnt on all three tagsets.
These results are based on SVMTool’s default
parameters: a one-pass, left-to-right, greedy tag-
ging scheme with a window size of 5. Previous
experiments with parameter tuning and multiple
pass tagging have indicated that there is room for
performance improvements by Pt� 2%.
</bodyText>
<subsectionHeader confidence="0.998394">
6.3 Maximum Entropy
</subsectionHeader>
<bodyText confidence="0.994829">
The MaxEnt tagger gets results comparable to the
other taggers on the predefined folds. Its overall
</bodyText>
<page confidence="0.997287">
109
</page>
<table confidence="0.996271">
Wordn ; Tag of Wordn
Prefixes of Wordn, length 1-5 characters
Postfixes of Wordn, length 1-5 characters
Is Wordn capitalized?
Is Wordn all digits?
Does Wordn contain digits?
Does Wordn contain a hyphen?
Wordn−1 ; Tag of Wordn−1
Wordn−2 ; Tag of Wordn−2
Wordn+1
Wordn+2
</table>
<tableCaption confidence="0.999295">
Table 4: Features used in the MaxEnt tagger
</tableCaption>
<bodyText confidence="0.999864190476191">
performance is equivalent to TnT’s on the smaller
tagsets, but significantly better on ‘ELRC’.
As can be seen in Table 3, the MaxEnt tag-
ger clearly outperforms the other taggers on all
tagsets, when MALLET is allowed to create its
own folds: all tagsets achieved classification ac-
curacies higher than 90%, with the two smaller
tagsets over 94.5%. The dramatic increase in the
tagger’s performance on these folds is surprising,
but a clear indication of one of the problems with
n-fold cross validation: even though the results
represent averages after n runs, the choice of the
original folds to suit a particular tagging strategy
is of utmost importance for the final result.
Table 4 shows the 22 features used to represent
an instance (Wordn) in the Maximum Entropy tag-
ger. The features are calculated per token within
sentences: the starting token of a sentence is not
affected by the characteristics of the tokens ending
the previous sentence, nor the other way around.
Thus not all features are calculated for all tokens.
</bodyText>
<subsectionHeader confidence="0.750065">
6.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999983529411765">
In terms of accuracy, the MaxEnt tagger is by
far the best of the three taggers, and on all three
tagsets, when allowed to select its own folds. Still,
as Table 3 shows, the variation of the results for
each individual fold was then substantially larger.
It should also be noted that TnT is by far the
fastest of the three taggers, in all respects: in terms
of time to set up and learn to use the tagger, in
terms of tagging speed, and in particular in terms
of training time. Training TnT is a matter of sec-
onds, but a matter of hours for MALLET/MaxEnt
and SVMTool. On the practical side, it is worth
adding that TnT is robust, well-documented, and
easy to use, while MALLET and SVMTool are
substantially more demanding in terms of user ef-
fort and also appear to be more sensitive to the
quality and format of the input data.
</bodyText>
<sectionHeader confidence="0.991287" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999994681818182">
The paper has described experiments with apply-
ing three state-of-the-art part-of-speech taggers to
Amharic, using three different tagsets. All tag-
gers showed worse performance than previously
reported results for English. The best accuracy
was obtained using a Maximum Entropy approach
when allowed to create its own folds: 90.1% on a
30 tag tagset, and 94.6 resp. 94.5% on two reduced
sets (11 resp. 10 tags), outperforming an HMM-
based (TnT) and an SVM-based (SVMTool) tag-
ger. On predefined folds all taggers got compa-
rable results (92.5-92.8% on the reduced sets and
4-7% lower on the full tagset). The SVM-tagger
performs slightly better than the others overall,
since it has the best performance on unknown
words, which are four times as frequent in the
200K words Amharic corpus used than in the (six
times larger) English Wall Street Journal corpus.
TnT gave the best results for known words, but
had the worst performance on unknown words.
In order to improve tagging accuracy, we will
investigate including explicit morphological pro-
cessing to treat unknown words, and combining
taggers. Judging from previous efforts on com-
bining taggers (Section 3.3), it is far from certain
that the combination of taggers actually ends up
producing better results than the best individual
tagger. A pre-requisite for successful combination
is that the taggers are sufficiently dissimilar; they
must draw on different characteristics of the train-
ing data and make different types of mistakes.
The taggers described in this paper use no other
knowledge source than a tagged training corpus.
In addition to incorporating (partial) morpholog-
ical processing, performance could be increased
by including knowledge sources such as machine
readable dictionaries or lists of Amharic stem
forms (Section 2.2). Conversely, semi-supervised
or unsupervised learning for tagging clearly are
interesting alternatives to manually annotate and
construct corpora for training taggers. Since
there are few computational resources available
for Amharic, approaches as those briefly outlined
in Section 3.2 deserve to be explored.
</bodyText>
<sectionHeader confidence="0.996439" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.928383166666667">
The work was partially funded by Sida, the Swedish Inter-
national Development Cooperation Agency through SPIDER
(the Swedish Programme for ICT in Developing Regions).
Thanks to Dr. Girma Demeke, Mesfin Getachew, and the
ELRC staff for their efforts on tagging the corpus, and to
Thorsten Brants for providing us with the TnT tagger.
</bodyText>
<page confidence="0.997149">
110
</page>
<sectionHeader confidence="0.990085" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999940357142857">
Rachel V. Xavier Aires, Sandra M. Aluisio, Denise C. S.
Kuhn, Marcio L. B. Andreeta, and Osvaldo N. Oliveira Jr.
2000. Combining classifiers to improve part of speech
tagging: A case study for Brazilian Portuguese. In 15th
Brazilian Symposium on AI, pp. 227–236, Atibaia, Brazil.
Nega Alemayehu and Peter Willett. 2002. Stemming of
Amharic words for information retrieval. Literary and
Linguistic Computing, 17:1–17.
Saba Amsalu and Dafydd Gibbon. 2005. Finite state mor-
phology of Amharic. In 5th Recent Advances in Natural
Language Processing, pp. 47–51, Borovets, Bulgaria.
Saba Amsalu and Girma A. Demeke. 2006. Non-
concatinative finite-state morphotactics of Amharic sim-
ple verbs. ELRC Working Papers, 2:304-325.
Atelach Alemu Argaw and Lars Asker. 2007. An Amharic
stemmer: Reducing words to their citation forms. Compu-
tational Approaches to Semitic Languages, pp. 104–110,
Prague, Czech Rep.
Michele Banko and Robert C. Moore. 2004. Part of speech
tagging in context. In 20th Int. Conf. on Computational
Linguistics, pp. 556–561, Geneva, Switzerland.
Roy Bar-Haim, Khalil Simaan, and Yoad Winter. 2008. Part-
of-speech tagging of modern Hebrew text. Natural Lan-
guage Engineering, 14:223–251.
Abiyot Bayou. 2000. Design and development of word
parser for Amharic language. MSc Thesis, Addis Ababa
University, Ethiopia.
Tesfaye Bayu. 2002. Automatic morphological analyser:
An experiment using unsupervised and autosegmental ap-
proach. MSc Thesis, Addis Ababa University, Ethiopia.
Thorsten Brants. 2000. TnT — a statistical part-of-speech
tagger. In 6th Conf. Applied Natural Language Process-
ing, pp. 224–231, Seattle, Wash.
Eric Brill and Jun Wu. 1998. Classifier combination for im-
proved lexical disambiguation. In 17th Int. Conf. on Com-
putational Linguistics, pp. 191–195, Montreal, Canada.
Eric Brill. 1995. Transformation-based error-driven learning
and Natural Language Processing: A case study in part of
speech tagging. Computational Linguistics, 21:543–565.
CIA. 2009. The World Factbook — Ethiopia. The Central In-
telligence Agency, Washington, DC. [Updated 22/01/09.]
Michael Collins. 2002. Discriminative training methods for
hidden Markov models: Theory and experiments with per-
ceptron algorithms. In Empirical Methods in Natural Lan-
guage Processing, pp. 1–8, Philadelphia, Penn.
Girma A. Demeke and Mesfin Getachew. 2006. Manual an-
notation of Amharic news items with part-of-speech tags
and its challenges. ELRC Working Papers, 2:1–17.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Au-
tomatic tagging of Arabic text: From raw text to base
phrase chunks. In HLT Conf. North American ACL,
pp. 149–152, Boston, Mass.
Thomas G. Dietterich. 1997. Machine-learning research:
Four current directions. AI magazine, 18:97–136.
Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of di-
alectal Arabic: A minimally supervised approach. Com-
putational Approaches to Semitic Languages, pp. 55–62,
Ann Arbor, Mich.
Sisay Fissaha and Johann Haller. 2003. Amharic verb
lexicon in the context of machine translation. In 10th
Traitement Automatique des Langues Naturelles, vol. 2,
pp. 183–192, Batz-sur-Mer, France.
Sisay Fissaha. 2005. Part of speech tagging for Amharic us-
ing conditional random fields. Computational Approaches
to Semitic Languages, pp. 47–54, Ann Arbor, Mich.
Mesfin Getachew. 2001. Automatic part of speech tag-
ging for Amharic: An experiment using stochastic hid-
den Markov model (HMM) approach. MSc Thesis, Addis
Ababa University, Ethiopia.
Jes´us Gim´enez and Lluis M`arquez. 2004. SVMTool: A gen-
eral POS tagger generator based on support vector ma-
chines. In 4th Int. Conf. Language Resources and Eval-
uation, pp. 168–176, Lisbon, Portugal.
Sharon Goldwater and Thomas L. Griffiths. 2007. A fully
Bayesian approach to unsupervised part-of-speech tag-
ging. In 45th ACL, pp. 744–751, Prague, Czech Rep.
Grover Hudson. 1999. Linguistic analysis of the 1994
Ethiopian census. Northeast African Studies, 6:89–107.
Saib Mansour. 2008. Combining character and morpheme
based models for part-of-speech tagging of Semitic lan-
guages. MSc Thesis, Technion, Haifa, Israel.
Andrew Kachites McCallum. 2002. MALLET: A machine
learning for language toolkit. Webpage.
Guy De Pauw, Gilles-Maurice de Schryver, and Peter W.
Wagacha. 2006. Data-driven part-of-speech tagging of
Kiswahili. In 9th Int. Conf. Text, Speech and Dialogue,
pp. 197–204, Brno, Czech Rep.
Adwait Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In Empirical Methods in Natural
Language Processing, pp. 133–142, Philadelphia, Penn.
Danny Shacham and Shuly Wintner. 2007. Morphological
disambiguation of Hebrew: A case study in classifier com-
bination. In Empirical Methods in Natural Language Pro-
cessing, pp. 439–447, Prague, Czech Rep.
Drahomir´a Spoustov´a, Jan Hajiˇc, Jan Votrubec, Pavel Krbec,
and Pavel Kvˇetoˇn. 2007. The best of two worlds: Co-
operation of statistical and rule-based taggers for Czech.
Balto-Slavonic Natural Language Processing, pp. 67–74.
Prague, Czech Rep.
Kristina Toutanova and Mark Johnson. 2007. A Bayesian
LDA-based model for semi-supervised part-of-speech tag-
ging. In 21st Int. Conf. Advances in Neural Information
Processing Systems, pp. 1521–1528, Vancover, B.C.
Kristina Toutanova, Dan Klein, Christopher D. Manning, and
Yoram Singer. 2003. Feature-rich part-of-speech tagging
with a cyclic dependency network. In HLT Conf. North
American ACL, pp. 173–180, Edmonton, Alberta.
Atro Voutilainen. 1999. An experiment on the upper bound
of interjudge agreement: The case of tagging. In 9th Eu-
ropean ACL, pp. 204–208, Bergen, Norway.
Daniel Yacob. 1997. The System for Ethiopic Representa-
tion in ASCII — 1997 standard. Webpage.
</reference>
<page confidence="0.998799">
111
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.868576">
<title confidence="0.998333">Methods for Amharic Part-of-Speech Tagging</title>
<author confidence="0.9052">Alemu</author>
<affiliation confidence="0.9970565">Laboratory of Computer &amp; Information Science of Computer &amp; System Sciences Swedish Institute of Computer Science Norwegian University of Science &amp; Technology Stockholm University</affiliation>
<address confidence="0.981785">Kista, Sweden Trondheim, Norway Kista, Sweden</address>
<email confidence="0.99349">gamback@idi.ntnu.no</email>
<abstract confidence="0.99863075">The paper describes a set of experiments involving the application of three state-ofthe-art part-of-speech taggers to Ethiopian Amharic, using three different tagsets. The taggers showed worse performance than previously reported results for English, in particular having problems with unknown words. The best results were obtained using a Maximum Entropy approach, while HMM-based and SVMbased taggers got comparable results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rachel V Xavier Aires</author>
<author>Sandra M Aluisio</author>
<author>Denise C S Kuhn</author>
<author>Marcio L B Andreeta</author>
<author>Osvaldo N Oliveira Jr</author>
</authors>
<title>Combining classifiers to improve part of speech tagging: A case study for Brazilian Portuguese.</title>
<date>2000</date>
<booktitle>In 15th Brazilian Symposium on AI,</booktitle>
<pages>227--236</pages>
<location>Atibaia, Brazil.</location>
<contexts>
<context position="13452" citStr="Aires et al. (2000)" startWordPosition="2119" endWordPosition="2122">ighted votes, and weighted votes. The weights of the votes, if any, are usually calculated based on the classifiers’ performance on some initial dataset. Stacking, finally, is a way of combining the decisions made by individual taggers in which the predicted tags for a given word are used as input to a subsequent tagger which outputs a final label for the word. Committee-based approaches to POS tagging have been in focus the last decade: Brill and Wu (1998) combined four different taggers for English using unweighted voting and by exploring contextual cues (essentially a variant of stacking). Aires et al. (2000) experimented with 12 different ways of combining the output from taggers for Brazilian 106 Portuguese, and concluded that some, but not all, combinations yielded better accuracy than the best individual tagger. Shacham and Wintner (2007) contrasted what they refer to as being a naive way of combining taggers with a more elaborate, hierarchical one for Hebrew. In the end, the elaborated method yielded results inferior to the naive approach. De Pauw et al. (2006) came to similar conclusions when using five different ways of combining four data-driven taggers for Swahili. The taggers were based </context>
</contexts>
<marker>Aires, Aluisio, Kuhn, Andreeta, Jr, 2000</marker>
<rawString>Rachel V. Xavier Aires, Sandra M. Aluisio, Denise C. S. Kuhn, Marcio L. B. Andreeta, and Osvaldo N. Oliveira Jr. 2000. Combining classifiers to improve part of speech tagging: A case study for Brazilian Portuguese. In 15th Brazilian Symposium on AI, pp. 227–236, Atibaia, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nega Alemayehu</author>
<author>Peter Willett</author>
</authors>
<title>Stemming of Amharic words for information retrieval.</title>
<date>2002</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>17--1</pages>
<contexts>
<context position="2413" citStr="Alemayehu and Willett (2002)" startWordPosition="348" endWordPosition="351">son (1999) analysed the Ethiopian census from 1994 and indicated that more than 40% of the population then understood Amharic, while the current size of the Ethiopian population is about 80 million.1 182.5 million according to CIA (2009); 76.9 according to Ethiopian parliament projections in December 2008 based on the preliminary reports from the census of May 2007. In spite of the relatively large number of speakers, Amharic is still a language for which very few computational linguistic resources have been developed, and previous efforts to create language processing tools for Amharic—e.g., Alemayehu and Willett (2002) and Fissaha (2005)—have been severely hampered by the lack of large-scale linguistic resources for the language. In contrast, the work detailed in the present paper has been able to utilize the first publicly available medium-sized tagged Amharic corpus, described in Section 5. However, first the Amharic language as such is introduced (in Section 2), and then the task of partof-speech tagging and some previous work in the field is described (Section 3). Section 4 details the tagging strategies used in the experiments, the results of which can be found in Section 6 together with a short discus</context>
<context position="6416" citStr="Alemayehu and Willett (2002)" startWordPosition="982" endWordPosition="985">ssfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest precision (54%) was obtained for verbs; Amsalu and Demeke (2006) thus describe ways to extend the finite-state system to handle 6400 simple verbal stems generated from 1300 root forms. Alemayehu and Willett (2002) report on a stemmer for Information Retrieval for Amharic, and testing on a 1221 random word sample stated “Manual assessment of the resulting stems showed that 95.5 percent of them were linguistically meaningful,” but gave no evaluation of the correctness of the segmentations. Argaw and Asker (2007) created a rule-based stemmer for a similar task, and using 65 rules and machine readable dictionaries obtained 60.0% accuracy on fictional text (testing on 300 unique words) and 76.9% on news articles (on 1503 words, of which 1000 unique).2 3 Part-of-Speech Tagging Part-of-speech (POS) tagging is</context>
</contexts>
<marker>Alemayehu, Willett, 2002</marker>
<rawString>Nega Alemayehu and Peter Willett. 2002. Stemming of Amharic words for information retrieval. Literary and Linguistic Computing, 17:1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saba Amsalu</author>
<author>Dafydd Gibbon</author>
</authors>
<title>Finite state morphology of Amharic.</title>
<date>2005</date>
<booktitle>In 5th Recent Advances in Natural Language Processing,</booktitle>
<pages>47--51</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="6058" citStr="Amsalu and Gibbon, 2005" startWordPosition="925" endWordPosition="929">e-based system for verbs (and nouns derived from verbs) which used root patterns and affixes to determine lexical and inflectional categories (Bayou, 2000), while Bayu (2002) used an unsupervised learning approach based on probabilistic models to extract stems, prefixes, and suffixes for building a morphological dictionary. The system was able to successfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest precision (54%) was obtained for verbs; Amsalu and Demeke (2006) thus describe ways to extend the finite-state system to handle 6400 simple verbal stems generated from 1300 root forms. Alemayehu and Willett (2002) report on a stemmer for Information Retrieval for Amharic, and testing on a 1221 random word sample stated “Manual assessment of the resulting stems showed that 95.5 percent of them were linguistically meaningful,” but gave no evaluation of </context>
</contexts>
<marker>Amsalu, Gibbon, 2005</marker>
<rawString>Saba Amsalu and Dafydd Gibbon. 2005. Finite state morphology of Amharic. In 5th Recent Advances in Natural Language Processing, pp. 47–51, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saba Amsalu</author>
<author>Girma A Demeke</author>
</authors>
<title>Nonconcatinative finite-state morphotactics of Amharic simple verbs. ELRC Working Papers,</title>
<date>2006</date>
<pages>2--304</pages>
<contexts>
<context position="6267" citStr="Amsalu and Demeke (2006)" startWordPosition="958" endWordPosition="961">oach based on probabilistic models to extract stems, prefixes, and suffixes for building a morphological dictionary. The system was able to successfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest precision (54%) was obtained for verbs; Amsalu and Demeke (2006) thus describe ways to extend the finite-state system to handle 6400 simple verbal stems generated from 1300 root forms. Alemayehu and Willett (2002) report on a stemmer for Information Retrieval for Amharic, and testing on a 1221 random word sample stated “Manual assessment of the resulting stems showed that 95.5 percent of them were linguistically meaningful,” but gave no evaluation of the correctness of the segmentations. Argaw and Asker (2007) created a rule-based stemmer for a similar task, and using 65 rules and machine readable dictionaries obtained 60.0% accuracy on fictional text (tes</context>
</contexts>
<marker>Amsalu, Demeke, 2006</marker>
<rawString>Saba Amsalu and Girma A. Demeke. 2006. Nonconcatinative finite-state morphotactics of Amharic simple verbs. ELRC Working Papers, 2:304-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atelach Alemu Argaw</author>
<author>Lars Asker</author>
</authors>
<title>An Amharic stemmer: Reducing words to their citation forms.</title>
<date>2007</date>
<booktitle>Computational Approaches to Semitic Languages,</booktitle>
<pages>104--110</pages>
<location>Prague, Czech Rep.</location>
<contexts>
<context position="6718" citStr="Argaw and Asker (2007)" startWordPosition="1031" endWordPosition="1034"> Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest precision (54%) was obtained for verbs; Amsalu and Demeke (2006) thus describe ways to extend the finite-state system to handle 6400 simple verbal stems generated from 1300 root forms. Alemayehu and Willett (2002) report on a stemmer for Information Retrieval for Amharic, and testing on a 1221 random word sample stated “Manual assessment of the resulting stems showed that 95.5 percent of them were linguistically meaningful,” but gave no evaluation of the correctness of the segmentations. Argaw and Asker (2007) created a rule-based stemmer for a similar task, and using 65 rules and machine readable dictionaries obtained 60.0% accuracy on fictional text (testing on 300 unique words) and 76.9% on news articles (on 1503 words, of which 1000 unique).2 3 Part-of-Speech Tagging Part-of-speech (POS) tagging is normally treated as a classification task with the goal to assign lexical categories (word classes) to the words in a text. Most work on tagging has concentrated on English and on using supervised methods, in the sense that the taggers have been trained on an available, tagged corpus. Both rule-based</context>
</contexts>
<marker>Argaw, Asker, 2007</marker>
<rawString>Atelach Alemu Argaw and Lars Asker. 2007. An Amharic stemmer: Reducing words to their citation forms. Computational Approaches to Semitic Languages, pp. 104–110, Prague, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Robert C Moore</author>
</authors>
<title>Part of speech tagging in context.</title>
<date>2004</date>
<booktitle>In 20th Int. Conf. on Computational Linguistics,</booktitle>
<pages>556--561</pages>
<location>Geneva,</location>
<contexts>
<context position="10746" citStr="Banko and Moore (2004)" startWordPosition="1679" endWordPosition="1682">sisted of 5 annotated news articles (1000 words). The tagset was a reduced version (10 tags) of the one used by Getachew (2001), and will be further discussed in Section 5.2. 3.2 Unsupervised tagging The desire to use unsupervised machine learning approaches to tagging essentially originates from the wish to exploit the vast amounts of unlabelled data available when constructing taggers. The area is particularly vivid when it comes to the treatment of languages for which there exist few, if any, computational resources, and for the case of adapting an existing tagger to a new language domain. Banko and Moore (2004) compared unsupervised HMM and transformation-based taggers trained on the same portions of the Penn Treebank, and showed that the quality of the lexicon used for training had a high impact on the tagging results. Duh and Kirchhoff (2005) presented a minimallysupervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. Using a trigram HMM tagger, they first produced a baseline system and then gradually improved on that in an unsupervised manner by adding features so as to fac</context>
</contexts>
<marker>Banko, Moore, 2004</marker>
<rawString>Michele Banko and Robert C. Moore. 2004. Part of speech tagging in context. In 20th Int. Conf. on Computational Linguistics, pp. 556–561, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Khalil Simaan</author>
<author>Yoad Winter</author>
</authors>
<title>Partof-speech tagging of modern Hebrew text.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<pages>14--223</pages>
<contexts>
<context position="9027" citStr="Bar-Haim et al. (2008)" startWordPosition="1397" endWordPosition="1400">es similar to Amharic. 3.1 Tagging Semitic languages Diab et al. (2004) used a Support Vector Machine, SVM-based tagger, trained on the Arabic Penn 2Other knowledge sources for processing Amharic include, e.g., Gasser’s verb stem finder (available from nlp.amharic.org) and wordlists as those collected by Gebremichael (www.cs.ru.nl/∼biniam/geez). 105 Treebank 1 to tokenize, POS tag, and annotate Arabic base phrases. With an accuracy of 95.5% over a set of 24 tags, the data-driven tagger performed on par with state-of-the-art results for English when trained on similar-sized data (168k tokens). Bar-Haim et al. (2008) developed a lexiconbased HMM tagger for Hebrew. They report 89.6% accuracy using 21 tags and training on 36k tokens of news text. Mansour (2008) ported this tagger into Arabic by replacing the morphological analyzer, achieving an accuracy of 96.3% over 26 tags on a 89k token corpus. His approach modifies the analyses of sentences receiving a low probability by adding synthetically constructed analyses proposed by a model using character information. A first prototype POS tagger for Amharic used a stochastic HMM to model contextual dependencies (Getachew, 2001), but was trained and tested on o</context>
</contexts>
<marker>Bar-Haim, Simaan, Winter, 2008</marker>
<rawString>Roy Bar-Haim, Khalil Simaan, and Yoad Winter. 2008. Partof-speech tagging of modern Hebrew text. Natural Language Engineering, 14:223–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abiyot Bayou</author>
</authors>
<title>Design and development of word parser for Amharic language. MSc Thesis,</title>
<date>2000</date>
<institution>Addis Ababa University,</institution>
<contexts>
<context position="5589" citStr="Bayou, 2000" startWordPosition="856" endWordPosition="857"> as well as objects and possession markers, mood and tense, beneficative, malfactive, transitive, dative, negative, etc. Amharic nouns (and adjectives) can be inflected for gender, number, definiteness, and case, although gender is usually neutral. The definite article attaches to the end of a noun, as do conjunctions, while prepositions are mostly prefixed. 2.2 Processing Amharic morphology The first effort on Amharic morphological processing was a rule-based system for verbs (and nouns derived from verbs) which used root patterns and affixes to determine lexical and inflectional categories (Bayou, 2000), while Bayu (2002) used an unsupervised learning approach based on probabilistic models to extract stems, prefixes, and suffixes for building a morphological dictionary. The system was able to successfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reporte</context>
</contexts>
<marker>Bayou, 2000</marker>
<rawString>Abiyot Bayou. 2000. Design and development of word parser for Amharic language. MSc Thesis, Addis Ababa University, Ethiopia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tesfaye Bayu</author>
</authors>
<title>Automatic morphological analyser: An experiment using unsupervised and autosegmental approach. MSc Thesis,</title>
<date>2002</date>
<institution>Addis Ababa University,</institution>
<contexts>
<context position="5608" citStr="Bayu (2002)" startWordPosition="859" endWordPosition="860">and possession markers, mood and tense, beneficative, malfactive, transitive, dative, negative, etc. Amharic nouns (and adjectives) can be inflected for gender, number, definiteness, and case, although gender is usually neutral. The definite article attaches to the end of a noun, as do conjunctions, while prepositions are mostly prefixed. 2.2 Processing Amharic morphology The first effort on Amharic morphological processing was a rule-based system for verbs (and nouns derived from verbs) which used root patterns and affixes to determine lexical and inflectional categories (Bayou, 2000), while Bayu (2002) used an unsupervised learning approach based on probabilistic models to extract stems, prefixes, and suffixes for building a morphological dictionary. The system was able to successfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest preci</context>
</contexts>
<marker>Bayu, 2002</marker>
<rawString>Tesfaye Bayu. 2002. Automatic morphological analyser: An experiment using unsupervised and autosegmental approach. MSc Thesis, Addis Ababa University, Ethiopia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT — a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In 6th Conf. Applied Natural Language Processing,</booktitle>
<pages>224--231</pages>
<location>Seattle, Wash.</location>
<contexts>
<context position="15463" citStr="Brants, 2000" startWordPosition="2438" endWordPosition="2439">gers were explored: serial combination, involving one of the statistical taggers; so called SUBPOS pre-processing, involving two instances of statistical taggers (possibly the same tagger); and, parallel combination, in which an arbitrary number of statistical taggers is used. The combined tagger yielded the best results for Czech POS tagging reported to date, and as a side-effect also the best accuracy for English: 97.43%.3 4 The Taggers This section describes the three taggers used in the experiments (which are reported on in Section 6). 4.1 Hidden Markov Models: TnT TnT, “Trigrams’n’Tags” (Brants, 2000) is a very fast and easy-to-use HMM-based tagger which painlessly can be trained on different languages and tagsets, given a tagged corpus.4 A Markovbased tagger aims to find a tag sequence which maximizes P(word,,,jtag,,,) ~ P(tag,,,jtagi...,,,_i), where the first factor is the emit (or lexical) prob3As reported on ufal.mff.cuni.cz/compost/en 4www.coli.uni-saarland.de/∼thorsten/tnt ability, the likelihood of a word given certain tag, and the second factor is the state transition (or contextual) probability, the likelihood of a tag given a sequence of preceding tags. TnT uses the Viterbi algor</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT — a statistical part-of-speech tagger. In 6th Conf. Applied Natural Language Processing, pp. 224–231, Seattle, Wash.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Jun Wu</author>
</authors>
<title>Classifier combination for improved lexical disambiguation.</title>
<date>1998</date>
<booktitle>In 17th Int. Conf. on Computational Linguistics,</booktitle>
<pages>191--195</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="13294" citStr="Brill and Wu (1998)" startWordPosition="2095" endWordPosition="2098">ndom decision, voting, and stacking (Dietterich, 1997), with the first way suited only for forming a baseline. Voting can be divided into two subclasses: unweighted votes, and weighted votes. The weights of the votes, if any, are usually calculated based on the classifiers’ performance on some initial dataset. Stacking, finally, is a way of combining the decisions made by individual taggers in which the predicted tags for a given word are used as input to a subsequent tagger which outputs a final label for the word. Committee-based approaches to POS tagging have been in focus the last decade: Brill and Wu (1998) combined four different taggers for English using unweighted voting and by exploring contextual cues (essentially a variant of stacking). Aires et al. (2000) experimented with 12 different ways of combining the output from taggers for Brazilian 106 Portuguese, and concluded that some, but not all, combinations yielded better accuracy than the best individual tagger. Shacham and Wintner (2007) contrasted what they refer to as being a naive way of combining taggers with a more elaborate, hierarchical one for Hebrew. In the end, the elaborated method yielded results inferior to the naive approac</context>
</contexts>
<marker>Brill, Wu, 1998</marker>
<rawString>Eric Brill and Jun Wu. 1998. Classifier combination for improved lexical disambiguation. In 17th Int. Conf. on Computational Linguistics, pp. 191–195, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and Natural Language Processing: A case study in part of speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--543</pages>
<contexts>
<context position="7436" citStr="Brill, 1995" startWordPosition="1147" endWordPosition="1148">ained 60.0% accuracy on fictional text (testing on 300 unique words) and 76.9% on news articles (on 1503 words, of which 1000 unique).2 3 Part-of-Speech Tagging Part-of-speech (POS) tagging is normally treated as a classification task with the goal to assign lexical categories (word classes) to the words in a text. Most work on tagging has concentrated on English and on using supervised methods, in the sense that the taggers have been trained on an available, tagged corpus. Both rule-based and statistical / machine-learning based approaches have been thoroughly investigated. The Brill Tagger (Brill, 1995) was fundamental in using a combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the Penn Treebank version of the Wall Street Journal corpus. That is, to a level which is just about what humans normally achieve when hand-tagging a corpus, in terms of interannotator agreement—even though Voutilainen (1999) has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases. Later taggers have managed to improve Brill’s figures a little bit, to just above 97% on the Wall Street Journal corpus using Hidden Markov</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and Natural Language Processing: A case study in part of speech tagging. Computational Linguistics, 21:543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CIA</author>
</authors>
<title>The World Factbook — Ethiopia. The Central Intelligence Agency,</title>
<date>2009</date>
<location>Washington, DC.</location>
<note>[Updated 22/01/09.]</note>
<contexts>
<context position="2022" citStr="CIA (2009)" startWordPosition="290" endWordPosition="291">mharic is spoken by about 30 million people as a first or second language, making it the second most spoken Semitic language in the world (after Arabic), probably the second largest language in Ethiopia (after Oromo), and possibly one of the five largest languages on the African continent. The actual size of the Amharic speaking population must be based on estimates: Hudson (1999) analysed the Ethiopian census from 1994 and indicated that more than 40% of the population then understood Amharic, while the current size of the Ethiopian population is about 80 million.1 182.5 million according to CIA (2009); 76.9 according to Ethiopian parliament projections in December 2008 based on the preliminary reports from the census of May 2007. In spite of the relatively large number of speakers, Amharic is still a language for which very few computational linguistic resources have been developed, and previous efforts to create language processing tools for Amharic—e.g., Alemayehu and Willett (2002) and Fissaha (2005)—have been severely hampered by the lack of large-scale linguistic resources for the language. In contrast, the work detailed in the present paper has been able to utilize the first publicly</context>
</contexts>
<marker>CIA, 2009</marker>
<rawString>CIA. 2009. The World Factbook — Ethiopia. The Central Intelligence Agency, Washington, DC. [Updated 22/01/09.]</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--8</pages>
<location>Philadelphia, Penn.</location>
<contexts>
<context position="8105" citStr="Collins (2002)" startWordPosition="1257" endWordPosition="1258">-based strategy to achieve 96.6% accuracy on tagging the Penn Treebank version of the Wall Street Journal corpus. That is, to a level which is just about what humans normally achieve when hand-tagging a corpus, in terms of interannotator agreement—even though Voutilainen (1999) has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases. Later taggers have managed to improve Brill’s figures a little bit, to just above 97% on the Wall Street Journal corpus using Hidden Markov Models, HMM and Conditional Random Fields, CRF; e.g., Collins (2002) and Toutanova et al. (2003). However, most recent work has concentrated on applying tagging strategies to other languages than English, on combining taggers, and/or on using unsupervised methods. In this section we will look at these issues in more detail, in particular with the relation to languages similar to Amharic. 3.1 Tagging Semitic languages Diab et al. (2004) used a Support Vector Machine, SVM-based tagger, trained on the Arabic Penn 2Other knowledge sources for processing Amharic include, e.g., Gasser’s verb stem finder (available from nlp.amharic.org) and wordlists as those collect</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Empirical Methods in Natural Language Processing, pp. 1–8, Philadelphia, Penn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Girma A Demeke</author>
<author>Mesfin Getachew</author>
</authors>
<title>Manual annotation of Amharic news items with part-of-speech tags and its challenges. ELRC Working Papers,</title>
<date>2006</date>
<pages>2--1</pages>
<contexts>
<context position="18590" citStr="Demeke and Getachew, 2006" startWordPosition="2919" endWordPosition="2922">es, decision trees, CRF, and Maximum Entropy.6 5www.lsi.upc.edu/∼nlp/SVMTool 6mallet.cs.umass.edu 107 5 The Dataset The experiments of this paper utilize the first medium-sized corpus for Amharic (available at http://nlp.amharic.org). The corpus consists of all 1065 news texts (210,000 words) from the Ethiopian year 1994 (parts of the Gregorian years 2001–2002) from the Walta Information Center, a private news service based in Addis Ababa. It has been morphologically analysed and manually partof-speech tagged by staff at ELRC, the Ethiopian Languages Research Center at Addis Ababa University (Demeke and Getachew, 2006). The corpus is available both infidel and transcribed into a romanized version known as SERA, System for Ethiopic Representation in ASCII (Yacob, 1997). We worked with the transliterated form (202,671 words), to be compatible with the machine learning tools used in the experiments. 5.1 “Cleaning” the corpus Unfortunately, the corpus available on the net contains quite a few errors and tagging inconsistencies: nine persons participated in the manual tagging, writing the tags with pen on hard copies, which were given to typists for insertion into the electronic version of the corpus—a procedure</context>
<context position="20560" citStr="Demeke and Getachew (2006)" startWordPosition="3230" endWordPosition="3233">agged at all, but those had to be left as they were. Finally, many words have been transcribed into SERA in several versions, with only the cases differing. However, this is also difficult to account for (and in the experiments below we used the case sensitive version of SERA), since the SERA notation in general lets upper and lower cases of the English alphabet represent different symbols infidel (the Amharic script). 5.2 Tagsets For the experiments, three different tagsets were used. Firstly, the full, original 30-tag set developed at the Ethiopian Languages Research Center and described by Demeke and Getachew (2006). This version of the corpus will be referred to as ‘ELRC’. It contains 200,863 words and differs from the published corpus in way of the corrections described in the previous section. Secondly, the corpus was mapped to 11 basic tags. This set consists of ten word classes: Noun, Pronoun, Verb, Adjective, Preposition, Conjunction, Adverb, Numeral, Interjection, and Punctuation, plus one tag for problematic words (unclear: &lt;UNC&gt;). The main differences between the two tagsets pertain to the treatment of prepositions and conjunctions: in ‘ELRC’ there are specific classes for, e.g., pronouns attach</context>
</contexts>
<marker>Demeke, Getachew, 2006</marker>
<rawString>Girma A. Demeke and Mesfin Getachew. 2006. Manual annotation of Amharic news items with part-of-speech tags and its challenges. ELRC Working Papers, 2:1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of Arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In HLT Conf. North American ACL,</booktitle>
<pages>149--152</pages>
<location>Boston, Mass.</location>
<contexts>
<context position="8476" citStr="Diab et al. (2004)" startWordPosition="1313" endWordPosition="1316">owed to discuss the problematic cases. Later taggers have managed to improve Brill’s figures a little bit, to just above 97% on the Wall Street Journal corpus using Hidden Markov Models, HMM and Conditional Random Fields, CRF; e.g., Collins (2002) and Toutanova et al. (2003). However, most recent work has concentrated on applying tagging strategies to other languages than English, on combining taggers, and/or on using unsupervised methods. In this section we will look at these issues in more detail, in particular with the relation to languages similar to Amharic. 3.1 Tagging Semitic languages Diab et al. (2004) used a Support Vector Machine, SVM-based tagger, trained on the Arabic Penn 2Other knowledge sources for processing Amharic include, e.g., Gasser’s verb stem finder (available from nlp.amharic.org) and wordlists as those collected by Gebremichael (www.cs.ru.nl/∼biniam/geez). 105 Treebank 1 to tokenize, POS tag, and annotate Arabic base phrases. With an accuracy of 95.5% over a set of 24 tags, the data-driven tagger performed on par with state-of-the-art results for English when trained on similar-sized data (168k tokens). Bar-Haim et al. (2008) developed a lexiconbased HMM tagger for Hebrew. </context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In HLT Conf. North American ACL, pp. 149–152, Boston, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Machine-learning research: Four current directions. AI magazine,</title>
<date>1997</date>
<pages>18--97</pages>
<contexts>
<context position="12729" citStr="Dietterich, 1997" startWordPosition="2001" endWordPosition="2002">son (2007) report state-of-theart results by extending the work on Bayesian modelling for unsupervised learning of taggers both in the way that prior knowledge can be incorporated into the model, and in the way that possible tags for a given word is explicitly modeled. 3.3 Combining taggers A possible way to improve on POS tagging results is to combine the output of several different taggers into a committee, forming joint decisions regarding the labeling of the input. Roughly, there are three obvious ways of combining multiple predicted tags for a word: random decision, voting, and stacking (Dietterich, 1997), with the first way suited only for forming a baseline. Voting can be divided into two subclasses: unweighted votes, and weighted votes. The weights of the votes, if any, are usually calculated based on the classifiers’ performance on some initial dataset. Stacking, finally, is a way of combining the decisions made by individual taggers in which the predicted tags for a given word are used as input to a subsequent tagger which outputs a final label for the word. Committee-based approaches to POS tagging have been in focus the last decade: Brill and Wu (1998) combined four different taggers fo</context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>Thomas G. Dietterich. 1997. Machine-learning research: Four current directions. AI magazine, 18:97–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>POS tagging of dialectal Arabic: A minimally supervised approach.</title>
<date>2005</date>
<booktitle>Computational Approaches to Semitic Languages,</booktitle>
<pages>55--62</pages>
<location>Ann Arbor, Mich.</location>
<contexts>
<context position="10984" citStr="Duh and Kirchhoff (2005)" startWordPosition="1718" endWordPosition="1721">ne learning approaches to tagging essentially originates from the wish to exploit the vast amounts of unlabelled data available when constructing taggers. The area is particularly vivid when it comes to the treatment of languages for which there exist few, if any, computational resources, and for the case of adapting an existing tagger to a new language domain. Banko and Moore (2004) compared unsupervised HMM and transformation-based taggers trained on the same portions of the Penn Treebank, and showed that the quality of the lexicon used for training had a high impact on the tagging results. Duh and Kirchhoff (2005) presented a minimallysupervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. Using a trigram HMM tagger, they first produced a baseline system and then gradually improved on that in an unsupervised manner by adding features so as to facilitate the analysis of unknown words, and by constraining and refining the lexicon. Unsupervised learning is often casted as the problem of finding (hidden) structure in unlabeled data. Goldwater and Griffiths (2007) noted that most rece</context>
</contexts>
<marker>Duh, Kirchhoff, 2005</marker>
<rawString>Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of dialectal Arabic: A minimally supervised approach. Computational Approaches to Semitic Languages, pp. 55–62, Ann Arbor, Mich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sisay Fissaha</author>
<author>Johann Haller</author>
</authors>
<title>Amharic verb lexicon in the context of machine translation.</title>
<date>2003</date>
<booktitle>In 10th Traitement Automatique des Langues Naturelles,</booktitle>
<volume>2</volume>
<pages>183--192</pages>
<location>Batz-sur-Mer, France.</location>
<contexts>
<context position="5976" citStr="Fissaha and Haller, 2003" startWordPosition="912" endWordPosition="915">g Amharic morphology The first effort on Amharic morphological processing was a rule-based system for verbs (and nouns derived from verbs) which used root patterns and affixes to determine lexical and inflectional categories (Bayou, 2000), while Bayu (2002) used an unsupervised learning approach based on probabilistic models to extract stems, prefixes, and suffixes for building a morphological dictionary. The system was able to successfully analyse 87% of a small testdata set of 500 words. The first larger-scale morphological analyser for Amharic verbs used XFST, the Xerox Finite State Tools (Fissaha and Haller, 2003). This was later extended to include all word categories (Amsalu and Gibbon, 2005). Testing with 1620 words text from an Amharic bible, 88–94% recall and 54–94% precision (depending on the word-class) were reported. The lowest precision (54%) was obtained for verbs; Amsalu and Demeke (2006) thus describe ways to extend the finite-state system to handle 6400 simple verbal stems generated from 1300 root forms. Alemayehu and Willett (2002) report on a stemmer for Information Retrieval for Amharic, and testing on a 1221 random word sample stated “Manual assessment of the resulting stems showed tha</context>
</contexts>
<marker>Fissaha, Haller, 2003</marker>
<rawString>Sisay Fissaha and Johann Haller. 2003. Amharic verb lexicon in the context of machine translation. In 10th Traitement Automatique des Langues Naturelles, vol. 2, pp. 183–192, Batz-sur-Mer, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sisay Fissaha</author>
</authors>
<title>Part of speech tagging for Amharic using conditional random fields.</title>
<date>2005</date>
<booktitle>Computational Approaches to Semitic Languages,</booktitle>
<pages>47--54</pages>
<location>Ann Arbor, Mich.</location>
<contexts>
<context position="2432" citStr="Fissaha (2005)" startWordPosition="353" endWordPosition="354"> census from 1994 and indicated that more than 40% of the population then understood Amharic, while the current size of the Ethiopian population is about 80 million.1 182.5 million according to CIA (2009); 76.9 according to Ethiopian parliament projections in December 2008 based on the preliminary reports from the census of May 2007. In spite of the relatively large number of speakers, Amharic is still a language for which very few computational linguistic resources have been developed, and previous efforts to create language processing tools for Amharic—e.g., Alemayehu and Willett (2002) and Fissaha (2005)—have been severely hampered by the lack of large-scale linguistic resources for the language. In contrast, the work detailed in the present paper has been able to utilize the first publicly available medium-sized tagged Amharic corpus, described in Section 5. However, first the Amharic language as such is introduced (in Section 2), and then the task of partof-speech tagging and some previous work in the field is described (Section 3). Section 4 details the tagging strategies used in the experiments, the results of which can be found in Section 6 together with a short discussion. Finally, Sect</context>
<context position="9798" citStr="Fissaha, 2005" startWordPosition="1524" endWordPosition="1525"> tagger into Arabic by replacing the morphological analyzer, achieving an accuracy of 96.3% over 26 tags on a 89k token corpus. His approach modifies the analyses of sentences receiving a low probability by adding synthetically constructed analyses proposed by a model using character information. A first prototype POS tagger for Amharic used a stochastic HMM to model contextual dependencies (Getachew, 2001), but was trained and tested on only one page of text. Getachew suggested a tagset for Amharic consisting of 25 tags. More recently, CRFs have been applied to segment and tag Amharic words (Fissaha, 2005), giving an accuracy of 84% for word segmentation, using character, morphological and lexical features. The best result for POS-tagging was 74.8%, when adding a dictionary and bigrams to lexical and morphological features, and 70.0% without dictionary and bigrams. The data used in the experiments was also quite small and consisted of 5 annotated news articles (1000 words). The tagset was a reduced version (10 tags) of the one used by Getachew (2001), and will be further discussed in Section 5.2. 3.2 Unsupervised tagging The desire to use unsupervised machine learning approaches to tagging esse</context>
<context position="21778" citStr="Fissaha (2005)" startWordPosition="3423" endWordPosition="3424">ith preposition, conjunction, and both preposition and conjunction (similar classes occur for nouns, verbs, adjectives, and numerals). In addition, numerals are divided into cardinals and ordinals, verbal nouns are separated from other nouns, while auxiliaries and relative verbs are distinguished from other verbs. The full tagset is made up of thirty subclasses of the basic classes, based on type of word only: the tags contain no information on grammatical categories (such as number, gender, tense, and aspect). Thirdly, for comparison reasons, the full tagset was mapped to the 10 tags used by Fissaha (2005). These classes include one for Residual (R) which was assumed to be equivalent to &lt;UNC&gt;. In addition, &lt;CONJ&gt; and &lt;PREP&gt; were mapped to Adposition (AP), and both &lt;N&gt; and &lt;PRON&gt; to N. The other mappings were straight-forward, except that the ‘BASIC’ tagset groups all verbs together, while Fissaha kept Auxiliary (AUX) as its own class. This tagset will be referred to as ‘SISAY’. 5.3 Folds For evaluation of the taggers, the corpus was split into 10 folds. These folds were created by chopping the corpus into 100 pieces, each of about 2000 words in sequence, while making sure that each piece contai</context>
</contexts>
<marker>Fissaha, 2005</marker>
<rawString>Sisay Fissaha. 2005. Part of speech tagging for Amharic using conditional random fields. Computational Approaches to Semitic Languages, pp. 47–54, Ann Arbor, Mich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mesfin Getachew</author>
</authors>
<title>Automatic part of speech tagging for Amharic: An experiment using stochastic hidden Markov model (HMM) approach. MSc Thesis,</title>
<date>2001</date>
<institution>Addis Ababa University,</institution>
<contexts>
<context position="9594" citStr="Getachew, 2001" startWordPosition="1489" endWordPosition="1490">sized data (168k tokens). Bar-Haim et al. (2008) developed a lexiconbased HMM tagger for Hebrew. They report 89.6% accuracy using 21 tags and training on 36k tokens of news text. Mansour (2008) ported this tagger into Arabic by replacing the morphological analyzer, achieving an accuracy of 96.3% over 26 tags on a 89k token corpus. His approach modifies the analyses of sentences receiving a low probability by adding synthetically constructed analyses proposed by a model using character information. A first prototype POS tagger for Amharic used a stochastic HMM to model contextual dependencies (Getachew, 2001), but was trained and tested on only one page of text. Getachew suggested a tagset for Amharic consisting of 25 tags. More recently, CRFs have been applied to segment and tag Amharic words (Fissaha, 2005), giving an accuracy of 84% for word segmentation, using character, morphological and lexical features. The best result for POS-tagging was 74.8%, when adding a dictionary and bigrams to lexical and morphological features, and 70.0% without dictionary and bigrams. The data used in the experiments was also quite small and consisted of 5 annotated news articles (1000 words). The tagset was a red</context>
</contexts>
<marker>Getachew, 2001</marker>
<rawString>Mesfin Getachew. 2001. Automatic part of speech tagging for Amharic: An experiment using stochastic hidden Markov model (HMM) approach. MSc Thesis, Addis Ababa University, Ethiopia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gim´enez</author>
<author>Lluis M`arquez</author>
</authors>
<title>SVMTool: A general POS tagger generator based on support vector machines.</title>
<date>2004</date>
<booktitle>In 4th Int. Conf. Language Resources and Evaluation,</booktitle>
<pages>168--176</pages>
<location>Lisbon,</location>
<marker>Gim´enez, M`arquez, 2004</marker>
<rawString>Jes´us Gim´enez and Lluis M`arquez. 2004. SVMTool: A general POS tagger generator based on support vector machines. In 4th Int. Conf. Language Resources and Evaluation, pp. 168–176, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas L Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In 45th ACL,</booktitle>
<pages>744--751</pages>
<location>Prague, Czech Rep.</location>
<contexts>
<context position="11563" citStr="Goldwater and Griffiths (2007)" startWordPosition="1811" endWordPosition="1814">ct on the tagging results. Duh and Kirchhoff (2005) presented a minimallysupervised approach to tagging for dialectal Arabic (Colloquial Egyptian), based on a morphological analyzer for Modern Standard Arabic and unlabeled texts in a number of dialects. Using a trigram HMM tagger, they first produced a baseline system and then gradually improved on that in an unsupervised manner by adding features so as to facilitate the analysis of unknown words, and by constraining and refining the lexicon. Unsupervised learning is often casted as the problem of finding (hidden) structure in unlabeled data. Goldwater and Griffiths (2007) noted that most recent approaches to this problem aim to identify the set of attributes that maximizes some target function (Maximum Likelihood Estimation), and then to select the values of these attributes based on the representation of the model. They proposed a different approach, based on Bayesian principles, which tries to directly maximize the probability of the attributes based on observation in the data. This Bayesian approach outperformed Maximum Likelihood Estimation when training a trigram HMM tagger for English. Toutanova and Johnson (2007) report state-of-theart results by extend</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Thomas L. Griffiths. 2007. A fully Bayesian approach to unsupervised part-of-speech tagging. In 45th ACL, pp. 744–751, Prague, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grover Hudson</author>
</authors>
<date>1999</date>
<booktitle>Linguistic analysis of the 1994 Ethiopian census. Northeast African Studies,</booktitle>
<pages>6--89</pages>
<contexts>
<context position="1795" citStr="Hudson (1999)" startWordPosition="253" endWordPosition="254">l working language of the government of the Federal Democratic Republic of Ethiopia: Ethiopia is divided into nine regions, each with its own nationality language; however, Amharic is the language for country-wide communication. Amharic is spoken by about 30 million people as a first or second language, making it the second most spoken Semitic language in the world (after Arabic), probably the second largest language in Ethiopia (after Oromo), and possibly one of the five largest languages on the African continent. The actual size of the Amharic speaking population must be based on estimates: Hudson (1999) analysed the Ethiopian census from 1994 and indicated that more than 40% of the population then understood Amharic, while the current size of the Ethiopian population is about 80 million.1 182.5 million according to CIA (2009); 76.9 according to Ethiopian parliament projections in December 2008 based on the preliminary reports from the census of May 2007. In spite of the relatively large number of speakers, Amharic is still a language for which very few computational linguistic resources have been developed, and previous efforts to create language processing tools for Amharic—e.g., Alemayehu </context>
</contexts>
<marker>Hudson, 1999</marker>
<rawString>Grover Hudson. 1999. Linguistic analysis of the 1994 Ethiopian census. Northeast African Studies, 6:89–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saib Mansour</author>
</authors>
<title>Combining character and morpheme based models for part-of-speech tagging of Semitic languages. MSc Thesis,</title>
<date>2008</date>
<location>Technion, Haifa, Israel.</location>
<contexts>
<context position="9172" citStr="Mansour (2008)" startWordPosition="1424" endWordPosition="1425">r knowledge sources for processing Amharic include, e.g., Gasser’s verb stem finder (available from nlp.amharic.org) and wordlists as those collected by Gebremichael (www.cs.ru.nl/∼biniam/geez). 105 Treebank 1 to tokenize, POS tag, and annotate Arabic base phrases. With an accuracy of 95.5% over a set of 24 tags, the data-driven tagger performed on par with state-of-the-art results for English when trained on similar-sized data (168k tokens). Bar-Haim et al. (2008) developed a lexiconbased HMM tagger for Hebrew. They report 89.6% accuracy using 21 tags and training on 36k tokens of news text. Mansour (2008) ported this tagger into Arabic by replacing the morphological analyzer, achieving an accuracy of 96.3% over 26 tags on a 89k token corpus. His approach modifies the analyses of sentences receiving a low probability by adding synthetically constructed analyses proposed by a model using character information. A first prototype POS tagger for Amharic used a stochastic HMM to model contextual dependencies (Getachew, 2001), but was trained and tested on only one page of text. Getachew suggested a tagset for Amharic consisting of 25 tags. More recently, CRFs have been applied to segment and tag Amh</context>
</contexts>
<marker>Mansour, 2008</marker>
<rawString>Saib Mansour. 2008. Combining character and morpheme based models for part-of-speech tagging of Semitic languages. MSc Thesis, Technion, Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>MALLET: A machine learning for language toolkit.</title>
<date>2002</date>
<journal>Webpage.</journal>
<contexts>
<context position="17866" citStr="McCallum, 2002" startWordPosition="2816" endWordPosition="2817">nes, by addition, the pre-determined weights used for representing the importance of each feature to a given class. Training a Maximum Entropy classifier involves fitting the weights of each feature value for a particular class to the available training data. A good fit of the weights to the data is obtained by selecting weights to maximize the log-likelihood of the learned classification model. Using an Maximum Entropy approach to POS tagging, Ratnaparkhi (1996) reports a tagging accuracy of 96.6% on the Wall Street Journal. The software of choice for the experiments reported here is MALLET (McCallum, 2002), a freely available Java implementation of a range of machine learning methods, such as Naive Bayes, decision trees, CRF, and Maximum Entropy.6 5www.lsi.upc.edu/∼nlp/SVMTool 6mallet.cs.umass.edu 107 5 The Dataset The experiments of this paper utilize the first medium-sized corpus for Amharic (available at http://nlp.amharic.org). The corpus consists of all 1065 news texts (210,000 words) from the Ethiopian year 1994 (parts of the Gregorian years 2001–2002) from the Walta Information Center, a private news service based in Addis Ababa. It has been morphologically analysed and manually partof-s</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. MALLET: A machine learning for language toolkit. Webpage.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy De Pauw</author>
<author>Gilles-Maurice de Schryver</author>
<author>Peter W Wagacha</author>
</authors>
<title>Data-driven part-of-speech tagging of Kiswahili.</title>
<date>2006</date>
<booktitle>In 9th Int. Conf. Text, Speech and Dialogue,</booktitle>
<pages>197--204</pages>
<location>Brno, Czech Rep.</location>
<marker>De Pauw, de Schryver, Wagacha, 2006</marker>
<rawString>Guy De Pauw, Gilles-Maurice de Schryver, and Peter W. Wagacha. 2006. Data-driven part-of-speech tagging of Kiswahili. In 9th Int. Conf. Text, Speech and Dialogue, pp. 197–204, Brno, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Empirical Methods in Natural Language Processing,</booktitle>
<pages>133--142</pages>
<location>Philadelphia, Penn.</location>
<contexts>
<context position="17718" citStr="Ratnaparkhi (1996)" startWordPosition="2790" endWordPosition="2791"> 83.5% on unknown. 4.3 Maximum Entropy: MALLET Maximum Entropy is a linear classification method. In its basic incarnation, linear classification combines, by addition, the pre-determined weights used for representing the importance of each feature to a given class. Training a Maximum Entropy classifier involves fitting the weights of each feature value for a particular class to the available training data. A good fit of the weights to the data is obtained by selecting weights to maximize the log-likelihood of the learned classification model. Using an Maximum Entropy approach to POS tagging, Ratnaparkhi (1996) reports a tagging accuracy of 96.6% on the Wall Street Journal. The software of choice for the experiments reported here is MALLET (McCallum, 2002), a freely available Java implementation of a range of machine learning methods, such as Naive Bayes, decision trees, CRF, and Maximum Entropy.6 5www.lsi.upc.edu/∼nlp/SVMTool 6mallet.cs.umass.edu 107 5 The Dataset The experiments of this paper utilize the first medium-sized corpus for Amharic (available at http://nlp.amharic.org). The corpus consists of all 1065 news texts (210,000 words) from the Ethiopian year 1994 (parts of the Gregorian years 2</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Empirical Methods in Natural Language Processing, pp. 133–142, Philadelphia, Penn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danny Shacham</author>
<author>Shuly Wintner</author>
</authors>
<title>Morphological disambiguation of Hebrew: A case study in classifier combination.</title>
<date>2007</date>
<booktitle>In Empirical Methods in Natural Language Processing,</booktitle>
<pages>439--447</pages>
<location>Prague, Czech Rep.</location>
<contexts>
<context position="13690" citStr="Shacham and Wintner (2007)" startWordPosition="2154" endWordPosition="2157">gers in which the predicted tags for a given word are used as input to a subsequent tagger which outputs a final label for the word. Committee-based approaches to POS tagging have been in focus the last decade: Brill and Wu (1998) combined four different taggers for English using unweighted voting and by exploring contextual cues (essentially a variant of stacking). Aires et al. (2000) experimented with 12 different ways of combining the output from taggers for Brazilian 106 Portuguese, and concluded that some, but not all, combinations yielded better accuracy than the best individual tagger. Shacham and Wintner (2007) contrasted what they refer to as being a naive way of combining taggers with a more elaborate, hierarchical one for Hebrew. In the end, the elaborated method yielded results inferior to the naive approach. De Pauw et al. (2006) came to similar conclusions when using five different ways of combining four data-driven taggers for Swahili. The taggers were based on HMM, Memory-based learning, SVM, and Maximum Entropy, with the latter proving most accurate. Only in three of five cases did a combination of classifiers perform better than the Maximum Entropy-based tagger, and simpler combination met</context>
</contexts>
<marker>Shacham, Wintner, 2007</marker>
<rawString>Danny Shacham and Shuly Wintner. 2007. Morphological disambiguation of Hebrew: A case study in classifier combination. In Empirical Methods in Natural Language Processing, pp. 439–447, Prague, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Drahomir´a Spoustov´a</author>
<author>Jan Hajiˇc</author>
<author>Jan Votrubec</author>
<author>Pavel Krbec</author>
<author>Pavel Kvˇetoˇn</author>
</authors>
<title>The best of two worlds: Cooperation of statistical and rule-based taggers for Czech. Balto-Slavonic Natural Language Processing,</title>
<date>2007</date>
<pages>67--74</pages>
<location>Prague, Czech Rep.</location>
<marker>Spoustov´a, Hajiˇc, Votrubec, Krbec, Kvˇetoˇn, 2007</marker>
<rawString>Drahomir´a Spoustov´a, Jan Hajiˇc, Jan Votrubec, Pavel Krbec, and Pavel Kvˇetoˇn. 2007. The best of two worlds: Cooperation of statistical and rule-based taggers for Czech. Balto-Slavonic Natural Language Processing, pp. 67–74. Prague, Czech Rep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Mark Johnson</author>
</authors>
<title>A Bayesian LDA-based model for semi-supervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In 21st Int. Conf. Advances in Neural Information Processing Systems,</booktitle>
<pages>1521--1528</pages>
<location>Vancover, B.C.</location>
<contexts>
<context position="12122" citStr="Toutanova and Johnson (2007)" startWordPosition="1897" endWordPosition="1900"> (hidden) structure in unlabeled data. Goldwater and Griffiths (2007) noted that most recent approaches to this problem aim to identify the set of attributes that maximizes some target function (Maximum Likelihood Estimation), and then to select the values of these attributes based on the representation of the model. They proposed a different approach, based on Bayesian principles, which tries to directly maximize the probability of the attributes based on observation in the data. This Bayesian approach outperformed Maximum Likelihood Estimation when training a trigram HMM tagger for English. Toutanova and Johnson (2007) report state-of-theart results by extending the work on Bayesian modelling for unsupervised learning of taggers both in the way that prior knowledge can be incorporated into the model, and in the way that possible tags for a given word is explicitly modeled. 3.3 Combining taggers A possible way to improve on POS tagging results is to combine the output of several different taggers into a committee, forming joint decisions regarding the labeling of the input. Roughly, there are three obvious ways of combining multiple predicted tags for a word: random decision, voting, and stacking (Dietterich</context>
</contexts>
<marker>Toutanova, Johnson, 2007</marker>
<rawString>Kristina Toutanova and Mark Johnson. 2007. A Bayesian LDA-based model for semi-supervised part-of-speech tagging. In 21st Int. Conf. Advances in Neural Information Processing Systems, pp. 1521–1528, Vancover, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In HLT Conf. North American ACL,</booktitle>
<pages>173--180</pages>
<location>Edmonton, Alberta.</location>
<contexts>
<context position="8133" citStr="Toutanova et al. (2003)" startWordPosition="1260" endWordPosition="1263">achieve 96.6% accuracy on tagging the Penn Treebank version of the Wall Street Journal corpus. That is, to a level which is just about what humans normally achieve when hand-tagging a corpus, in terms of interannotator agreement—even though Voutilainen (1999) has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases. Later taggers have managed to improve Brill’s figures a little bit, to just above 97% on the Wall Street Journal corpus using Hidden Markov Models, HMM and Conditional Random Fields, CRF; e.g., Collins (2002) and Toutanova et al. (2003). However, most recent work has concentrated on applying tagging strategies to other languages than English, on combining taggers, and/or on using unsupervised methods. In this section we will look at these issues in more detail, in particular with the relation to languages similar to Amharic. 3.1 Tagging Semitic languages Diab et al. (2004) used a Support Vector Machine, SVM-based tagger, trained on the Arabic Penn 2Other knowledge sources for processing Amharic include, e.g., Gasser’s verb stem finder (available from nlp.amharic.org) and wordlists as those collected by Gebremichael (www.cs.r</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In HLT Conf. North American ACL, pp. 173–180, Edmonton, Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
</authors>
<title>An experiment on the upper bound of interjudge agreement: The case of tagging.</title>
<date>1999</date>
<booktitle>In 9th European ACL,</booktitle>
<pages>204--208</pages>
<location>Bergen,</location>
<contexts>
<context position="7769" citStr="Voutilainen (1999)" startWordPosition="1199" endWordPosition="1200">on tagging has concentrated on English and on using supervised methods, in the sense that the taggers have been trained on an available, tagged corpus. Both rule-based and statistical / machine-learning based approaches have been thoroughly investigated. The Brill Tagger (Brill, 1995) was fundamental in using a combined rule- and learning-based strategy to achieve 96.6% accuracy on tagging the Penn Treebank version of the Wall Street Journal corpus. That is, to a level which is just about what humans normally achieve when hand-tagging a corpus, in terms of interannotator agreement—even though Voutilainen (1999) has shown that humans can get close to the 100% agreement mark if the annotators are allowed to discuss the problematic cases. Later taggers have managed to improve Brill’s figures a little bit, to just above 97% on the Wall Street Journal corpus using Hidden Markov Models, HMM and Conditional Random Fields, CRF; e.g., Collins (2002) and Toutanova et al. (2003). However, most recent work has concentrated on applying tagging strategies to other languages than English, on combining taggers, and/or on using unsupervised methods. In this section we will look at these issues in more detail, in par</context>
</contexts>
<marker>Voutilainen, 1999</marker>
<rawString>Atro Voutilainen. 1999. An experiment on the upper bound of interjudge agreement: The case of tagging. In 9th European ACL, pp. 204–208, Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Yacob</author>
</authors>
<title>The System for Ethiopic Representation in ASCII —</title>
<date>1997</date>
<note>standard. Webpage.</note>
<contexts>
<context position="18742" citStr="Yacob, 1997" startWordPosition="2945" endWordPosition="2947">dium-sized corpus for Amharic (available at http://nlp.amharic.org). The corpus consists of all 1065 news texts (210,000 words) from the Ethiopian year 1994 (parts of the Gregorian years 2001–2002) from the Walta Information Center, a private news service based in Addis Ababa. It has been morphologically analysed and manually partof-speech tagged by staff at ELRC, the Ethiopian Languages Research Center at Addis Ababa University (Demeke and Getachew, 2006). The corpus is available both infidel and transcribed into a romanized version known as SERA, System for Ethiopic Representation in ASCII (Yacob, 1997). We worked with the transliterated form (202,671 words), to be compatible with the machine learning tools used in the experiments. 5.1 “Cleaning” the corpus Unfortunately, the corpus available on the net contains quite a few errors and tagging inconsistencies: nine persons participated in the manual tagging, writing the tags with pen on hard copies, which were given to typists for insertion into the electronic version of the corpus—a procedure obviously introducing several possible error sources. Before running the experiments the corpus had to be “cleaned”: many non-tagged items have been ta</context>
</contexts>
<marker>Yacob, 1997</marker>
<rawString>Daniel Yacob. 1997. The System for Ethiopic Representation in ASCII — 1997 standard. Webpage.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>