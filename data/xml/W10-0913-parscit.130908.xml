<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000365">
<title confidence="0.9992985">
A Hybrid Approach to Unsupervised Relation Discovery Based on
Linguistic Analysis and Semantic Typing
</title>
<author confidence="0.992195">
Zareen Syed Evelyne Viegas
</author>
<affiliation confidence="0.585404666666667">
University of Maryland Baltimore County Microsoft Research
1000 Hilltop Circle One Microsoft Way
Baltimore, MD 21229, USA Redmond, WA 98052, USA
</affiliation>
<sectionHeader confidence="0.954276" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996964">
This paper describes a hybrid approach for
unsupervised and unrestricted relation discov-
ery between entities using output from linguis-
tic analysis and semantic typing information
from a knowledge base. We use Factz (en-
coded as subject, predicate and object triples)
produced by Powerset as a result of linguistic
analysis. A particular relation may be ex-
pressed in a variety of ways in text and hence
have multiple facts associated with it. We
present an unsupervised approach for collaps-
ing multiple facts which represent the same
kind of semantic relation between entities.
Then a label is selected for the relation based
on the input facts and entropy based label
ranking of context words. Finally, we demon-
strate relation discovery between entities at
different levels of abstraction by leveraging
semantic typing information from a know-
ledge base.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999813476190476">
There are a number of challenges involved when
using facts extracted from text to enrich a know-
ledge base (KB) with semantic relations between
entities: co-reference resolution as there are
many co-referent objects; entity resolution in
order to link the entities mentioned in text to the
right entities in the KB; handling co-referent re-
lations, as a particular semantic relation between
entities can be expressed in a variety of ways in
the text and therefore have multiple facts asso-
ciated between the entities. In addition, the facts
extracted from linguistic analysis are usually noi-
sy and sparse.
Our work focuses on a recent line of explora-
tory work in the direction of Unrestricted Rela-
tion Discovery which is defined as: the automatic
identification of different relations in text with-
out specifying a relation or set of relations in ad-
vance (Shinyama and Sekine, 2006). We use the
facts which are the output of linguistic analysis
from Powerset (www.Powerset.com). Powerset
</bodyText>
<page confidence="0.997289">
105
</page>
<bodyText confidence="0.9994623125">
is an online search engine for querying Wikipe-
dia using Natural Language Queries. Powerset
performs a linguistic analysis of the sentences
within Wikipedia and outputs facts in the form of
subject, predicate and object triples which can be
queried through the online interface. For most
entities like persons, places and things, Powerset
shows a summary of facts from across Wikipedia
(figure 1). In our approach we use the readily
available “Factz” from Powerset as input to our
system. Powerset is Wikipedia independent and
can run on any corpus with well-formed sen-
tences and hence our approach is also not limited
to Wikipedia. The Factz output from Powerset
may represent relations between named entities
or just nouns for example,
</bodyText>
<subsectionHeader confidence="0.602382333333333">
Bank of America &lt;acquired&gt; bank
Bank of America &lt;acquired&gt; Merrill Lynch
Bank of America &lt;owned&gt; building
</subsectionHeader>
<bodyText confidence="0.99475025">
Linguistic analysis has been recently de-
scribed as an effective technique for relation ex-
traction (Yan et al., 2009; Kambhatla, 2004;
Nguyen et al., 2007). Following that trend, we
incorporate Factz, that are the output of linguistic
analysis done by Powerset, to discover semantic
relations between entities.
Information from existing knowledge re-
</bodyText>
<figureCaption confidence="0.947008">
Figure 1. Demonstration of Powerset Factz available
online
</figureCaption>
<note confidence="0.9808025">
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 105–113,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9966346">
sources can help in tasks like named entity dis-
ambiguation by providing additional context in
the form of linked entities in the KB and aid in
linking the entities mentioned in the text to the
entities in the KB. The KB can also provide in-
formation about the entity types which can in
turn be used to discover relations between entity
types at different levels of abstraction and help in
enriching the KB itself. This could allow ontolo-
gy engineers to explore the kind of relations ex-
isting between different entity types in a corpus
and then design an ontology which is representa-
tive of the entities and relations evident in the
corpus.
Our overall approach to automatic relation
discovery consists in a hybrid approach based
on Powerset Factz that are the output of linguis-
tic analysis, and serve as input to our system;
Text based label ranking by directly considering
the context words in the sentences; and, Seman-
tic Typing information from existing knowledge
resources to discover relations between Entity
types at different levels of abstraction.
The paper is organized as follows. We discuss
the related work in the next section. In section 3
we propose our approach and give the details of
different components in our system. In section 4,
we discuss preliminary experiments and results.
In the last section we conclude our work and
give future work directions.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999952535211268">
Hasegawa et al. (2004) developed an approach
for unsupervised relation discovery by clustering
pairs of entities based on intervening words
represented as context vectors. They used the
most frequent common word to label the cluster
and hence the relation represented by the cluster.
Shinyama and Sekine (2006) developed an
approach to preemptively discover relations in a
corpus and present them as tables with all the
entity pairs in the table having the same relations
between them. For pairs of entities they generate
basic patterns that are parts of text syntactically
connected to the Entity and use the predicate ar-
gument structure to make the basic patterns more
generalized. They generate a basic cluster from
articles based on having similar basic patterns to
represent the same event and then they cluster
the basic clusters to get a set of events having the
same relation.
Davidov et al. (2007) developed a web mining
approach for discovering relations in which a
specified concept participates based on clustering
patterns in which the concept words and other
words appear. Their system is based on the initial
seed of two or more words representing the type
of concept one is interested in.
Linguistic analysis has been reported as an ef-
fective technique for semantic relation extrac-
tion. Harabagiu et al. (2005) used shallow se-
mantic parsers to enhance dependency tree ker-
nels and to build semantic dependency structures
to improve relation extraction, they reported that
their method improved the quality of the ex-
tracted relations as compared to kernel-based
models that used semantic class information on-
ly.
Nguyen et al. (2007) presented an approach
for relation extraction from Wikipedia by ex-
tracting features from subtrees mined from the
syntactic structure of text. Kambhatla (2004) de-
veloped a method for extracting relations by ap-
plying Maximum Entropy models to combine
lexical, syntactic and semantic features and re-
port that they obtain improvement in results
when they combine variety of features. Most of
the existing approaches have used linguistic
analysis to generate features for supervised or
semi-supervised relation extraction.
Recently, Yan et al. (2009) have developed an
approach for unsupervised relation discovery by
integrating linguistic analysis done on Wikipedia
with context generated from the Web. They de-
velop a clustering approach based on dependency
patterns from dependency analysis of Wikipedia
and surface patterns by querying the web to in-
troduce redundancy. They report that dependen-
cy patterns improve the precision whereas, the
surface patterns improved the coverage.
Banko et al. (2008) introduce the TextRunner
system which takes a small corpus sample as
input and uses a linguistic parser to generate
training data which they use to train the extractor
which can run at web scale. However, Kok and
Domingos (2008) have reported that the triples
output from the TextRunner system are noisy,
sparse and contain many co-referent objects and
relations which is also the case with Powerset.
Their system uses the output from the TextRun-
ner system and uses Multiple Relational Cluster-
ing model to get object clusters and relation clus-
ters.
</bodyText>
<page confidence="0.998426">
106
</page>
<figureCaption confidence="0.986070666666667">
Figure 2. The Knowledge Discovery approach uses Powerset Factz which are the output from linguistic analy-
sis, article text for entropy based label ranking and existing knowledge resources for discovering relations at
different levels of abstraction and hence aiding in enriching the existing knowledge resources.
</figureCaption>
<sectionHeader confidence="0.992326" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999737">
In this section we describe in detail the different
steps in our approach involving querying Factz
from Powerset, collapsing facts expressing same
type of relation, Label Selection and introducing
Semantic Typing information. Figure 2 gives an
overview of our approach and Figure 3 shows the
different components in our system. We discuss
each component in detail below.
</bodyText>
<subsectionHeader confidence="0.997193">
3.1 Querying Powerset and Retrieving
Factz
</subsectionHeader>
<bodyText confidence="0.9961502">
In the first step we query Powerset API by giving
as input a list of entities or list of entity pairs and
retrieve all the Factz and sentences that are asso-
ciated with the entities or entity pairs from the
Powerset API output.
</bodyText>
<subsectionHeader confidence="0.999971">
3.2 Collapsing Similar Relations
</subsectionHeader>
<bodyText confidence="0.999962153846154">
A particular semantic relationship can be ex-
pressed in different ways in sentences. For ex-
ample words like “purchase”, “buy” and “ac-
quire” may represent the same semantic relation
between the subject and the object. Sometimes
the words might be direct synonyms in which
case resources like WordNet (Miller et al., 1990)
can help in identifying the same relation whereas
in other cases the words might not be synonyms
at all but may still imply the same semantic rela-
tion between the subject and the object. For ex-
ample, we queried Powerset to get a sample of
relations between companies and products. We
got relations like introduce, produce, sell, manu-
facture and make. It is often the case that compa-
nies introduce and sell the products that they
manufacture, make or produce. However, all of
these words are not synonyms of each other and
it may not be feasible to express the relation be-
tween a company and a product in all these dif-
ferent ways in a KB.
We have developed an approach for collaps-
ing relations expressed using different words in
the facts and represent it using the dominating
relation between the pair of entities. We explain
the different steps in our approach below.
</bodyText>
<subsubsectionHeader confidence="0.585779">
3.2.1 Relation Clustering
</subsubsectionHeader>
<bodyText confidence="0.999824333333333">
We consider relations to be similar if they appear
between the same subjects and the objects. We
take the set of Factz that we got by querying Po-
</bodyText>
<figureCaption confidence="0.989239">
Figure 3. System Framework
</figureCaption>
<page confidence="0.991865">
107
</page>
<bodyText confidence="0.998834545454546">
werset in the previous step and based on those
Factz we construct a similarity matrix to
represent similarity between all pairs of relations
in the data set. Each entry in the similarity matrix
represents the number of times the pair of rela-
tions had the same subject and object in the Factz
data set. For example, in the sample dataset in
table 1, the similarity matrix entry for the pair
acquired and purchased would be 3. We use that
similarity matrix as input and apply average link
agglomerative clustering algorithm over it.
</bodyText>
<table confidence="0.968607428571428">
Subject Predicate Object
Bank of America acquired Merrill Lynch
Bank of America acquired MBNA
Bank of America acquired FleetBoston
Bank of America purchased FleetBoston
Bank of America purchased Merrill Lynch
Bank of America purchased MBNA
</table>
<tableCaption confidence="0.9683065">
Table 1. Relations between same subjects and objects
in Powerset
</tableCaption>
<subsectionHeader confidence="0.962121">
3.2.2 Filtering Ambiguous Relations
</subsectionHeader>
<bodyText confidence="0.999908888888889">
After the clustering step we have a step for filter-
ing ambiguous relations from the clusters. We
explain the filtering procedure using an example
from one of the experiments in which two clus-
ters were produced. First cluster had acquire,
purchase, buy and own relations and the second
cluster had introduce, produce, make and say
about relations. After clustering the relations we
have the following steps:
</bodyText>
<listItem confidence="0.687002">
1. We take each pair of entities and get the
set of relations between the pair of entities. For
example, the set of relation between “Bank of
America” and “Merrill Lynch” are acquire, pur-
chase and say about (figure 4).
2. By considering the set of relations be-
tween each pair of entities we assign it to a clus-
</listItem>
<bodyText confidence="0.974631428571429">
ter based on the maximum number of overlap-
ping relations between the set and the cluster
members. In our example clusters, we assign it to
cluster one with which there is an overlap of two
relations i.e. acquire and buy instead of assigning
it to cluster two with which it has an overlap of
one relation i.e. say about (figure 4).
3. Once an entity pair is assigned to a clus-
ter, we consider other relations in the set of rela-
tions present between that entity pair and if any
of those relations exists as a member of another
cluster we filter out that relation from that clus-
ter. For example, one of the relations present be-
tween “Bank of America” and “Merill Lynch” is
</bodyText>
<figureCaption confidence="0.907003">
Figure 4. Filtering ambiguous relations from exist-
ing clusters
</figureCaption>
<bodyText confidence="0.999971">
say about, and this relation is actually a member
of cluster two whereas, this pair is assigned to
cluster one and therefore, we filter out say about
from cluster two. After cluster filtering, the label
for the cluster is selected as the label that is the
most frequent relation found in the set of entity
pairs being assigned to the cluster.
</bodyText>
<subsectionHeader confidence="0.998773">
3.3 Relation Label Selection
</subsectionHeader>
<bodyText confidence="0.999975136363636">
A pair of entities might have more than one fact
associated with them. We select a representative
label based on a hybrid approach by combining
the output from entropy based label ranking
(Chen et al., 2005) and clusters of similar rela-
tions found by relational clustering. We select
the relation label as the cluster label of the clus-
ter which has the maximum member overlap
with the predicates in the set of facts between a
pair of entities. In case there is an overlap of just
one relation, we select the label that is ranked
highest through entropy based label ranking ap-
proach (Chen et al., 2005). According to their
algorithm, the importance of terms can be as-
sessed using the entropy criterion, which is based
on the assumption that a term is irrelevant if its
presence obscures the separability of the dataset.
There may be cases where there are multiple re-
lations existing between a given pair of entities,
however, in our approach we select the relation
label that is evident in the majority of the facts
associated with the pair.
</bodyText>
<subsectionHeader confidence="0.989819">
3.4 Semantic Typing
</subsectionHeader>
<bodyText confidence="0.99978525">
For certain applications there might be the need
of discovering relations between specific types of
entities rather than instances of entities. For ex-
ample, for ontology engineering, the ontology
</bodyText>
<page confidence="0.996488">
108
</page>
<bodyText confidence="0.99997496875">
engineer might want to explore the kind of rela-
tions that exist between different entity types
based on the data set and then develop an ontol-
ogy representing those relations. Therefore, we
have a component in our system that incorpo-
rates semantic type information into the Factz
before collapsing the relations present in the
facts. The semantic type module queries a know-
ledge base for the entity type and replaces the
entity instance names with entity types in the
Factz data set. We have used the Freebase (Me-
taweb Technologies, 2009) Knowledge base to
associate the entity types for the entities that we
experimented with. When this modified version
of the Factz dataset is given as input to the next
component of the system i.e. Collapse Relations,
the similarity between relations is computed
based on having the same subject and object enti-
ty types rather than entity instances. Following
the Semantic Typing path in the system would
output the relations discovered between types of
entities. Introducing Semantic Typing informa-
tion can also help in creating redundancy in the
dataset and overcome the data sparseness prob-
lem. For example in case of relations such as ac-
quire and purchase if we cannot get evidence of
overlap in the subject and object in the Factz da-
taset then we cannot assign them any similarity
score in the similarity matrix however, if we re-
place the instance names with instance types and
consider the overlap between the instance types
we can get more evidence about their similarity.
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.99991875">
In this section, we present the preliminary expe-
riments we conducted to evaluate the approach.
We start by an initial evaluation of Powerset
Factz by comparing them with ground truth and
text based label ranking (Chen et al., 2005). We
then use our approach to discover relations be-
tween different entity types. The details of the
experiments and results are discussed below.
</bodyText>
<subsectionHeader confidence="0.933223">
4.1 Preliminary Evaluation of Powerset
Factz
</subsectionHeader>
<bodyText confidence="0.9998765">
Our first experiment was targeted towards a pre-
liminary evaluation of the accuracy of Powerset
Factz themselves and their performance when
compared with ground truth and with Entropy
based label ranking approach which does not use
any linguistic analysis. To achieve this we took
the “acquisitions” table from Freebase. The “ac-
quisitions” table has a list of companies and their
</bodyText>
<table confidence="0.999256333333333">
Approach Accuracy
Powerset Factz based approach 85%
Entropy based Label ranking 72%
</table>
<tableCaption confidence="0.987886">
Table 2. Comparison of Powerset Factz based
approach and Entropy based label ranking
</tableCaption>
<bodyText confidence="0.999978026315789">
acquisitions. We considered the acquisitions
table as ground truth as this information is either
entered manually by contributors or imported
from Wikipedia via DBpedia. We queried Po-
werset by giving the entity pairs as input and
were able to retrieve Factz for 170 pairs out of
1107 entity pairs present in Freebase table. The
number of pairs for which Powerset returned
Factz is low because Powerset currently extracts
Factz from well formed sentences and not semi-
structured or structured information such as
tables or info-boxes in Wikipedia and the acqui-
sition relation is mostly expressed in the form of
tables or lists in Wikipedia articles. We applied
relational clustering and stopped clustering when
the similarity between the clusters was less than
4. We identified one cluster (acquire, purchase,
buy) having more than one member and got 146
relations labeled accurately i.e. 85% accuracy
through our approach. We repeated the experi-
ment using Entropy based label ranking approach
(Chen et al., 2005). We were mainly focusing on
relations that were expressed by verbs. We took
all sentences between a pair of entities from
which Powerset had extracted Factz. We ex-
tracted verbs from those sentences and ranked
those verbs based on the entropy based label
ranking approach and considered any of the la-
bels matching with the cluster members (acquire,
purchase, buy) as correct prediction. We com-
pared the results with the ground truth and got
the accuracy of 72% (table 2). Our preliminary
experiment on the sample dataset demonstrated
that the relation labels assigned by Powerset
have reasonably high accuracy when compared
with ground truth i.e. 85% and also give higher
accuracy as compared to the entropy based label
ranking approach for the sample data set.
</bodyText>
<subsectionHeader confidence="0.9996685">
4.2 Discovering Relations between Different
Types of Entity Pairs
</subsectionHeader>
<bodyText confidence="0.999969">
In this experiment we wanted to explore if our
approach was successful in discovering relations
existing between different types of entity pairs
and clusters the pairs into separate clusters.
We constructed two datasets using Wikipedia
page links between articles on entities namely
Persons and Organizations. Using “person” type
and “organization” type specified in Freebase,
</bodyText>
<page confidence="0.998374">
109
</page>
<bodyText confidence="0.998303208333333">
we were able to construct a list of Wikipedia ar-
ticles that were on Persons and Organizations.
The Wikipedia article links served the purpose of
finding out which organizations are related to
which other organizations and which persons are
related to which organizations. The first dataset
represented relations between Organizations
whereas the second dataset represented relations
between Persons and Organizations. We applied
relational clustering for collapsing similar rela-
tions and evaluated the output clusters at differ-
ent thresholds to see if they represented relations
between different types of entities. At stopping
with a threshold of 2 we found the following two
clusters having more than one member: one of
the clusters represented the relations present be-
tween a pair of Organizations (acquire, pur-
chase, buy, own, say about, take over) and the
other cluster represented the relations between
Persons and Organizations (formed, found, lead)
(table 3). The experiment confirmed the effec-
tiveness of clustering approach as it clusters rela-
tions between different kinds of entity pairs into
different clusters.
</bodyText>
<table confidence="0.98010525">
Relations Clusters
Org-Org Cluster 1: acquire, purchase, buy, own, say
about, take over over
Pers-Org Cluster 2: found, lead, form
</table>
<tableCaption confidence="0.996273">
Table 3. Relations between different types of entity
pairs are clustered into different clusters
</tableCaption>
<subsectionHeader confidence="0.999619">
4.3 Improving Recall
</subsectionHeader>
<bodyText confidence="0.999941097560976">
In this experiment we were interested in finding
if Factz from Powerset can help in discovering
relations between entities that are not present in
resources like DBpedia and Freebase. We took a
list of organization (with &gt; 28,000 organization
names from Freebase and an internal Knowledge
Base) and retrieved Powerset Factz having those
organizations as subjects. We performed relation
clustering and output clusters at different thre-
sholds. We selected the minimum threshold for
which there were at least two clusters with more
than one member. From the two clusters, one
cluster had manufacture, produce and make rela-
tions and the second had acquire, purchase, own,
operate and buy relations (table 4). Our intuition
was that the first cluster represented relations
between organizations and products. Therefore,
we took the “company-products” table from
Freebase and compared it with our dataset. How-
ever, we could only find an overlap of 3 subject
object pairs. The second cluster had relations that
we earlier found to exist between organizations
having the acquisition relation between them,
therefore, we took the “acquisitions” table from
Freebase and compared it against our dataset.
Comparing the pairs with our list of organiza-
tions, we found 104 pairs that had an organiza-
tion as a subject and an object. Out of those 104
pairs 97 pairs were assigned to cluster 2 and 7
pairs were assigned to cluster 1. When we com-
pared those 97 pairs with Freebase “acquisition”
table (which had 73 pairs of organizations that
overlapped with our dataset) we found that 66
existed in the set and were therefore predicted
correctly. We then inspected the rest of the pairs
manually and found that there were 16 additional
pairs that were predicted to have the acquire re-
lation and which were not present in the Freebase
table. Therefore, this approach helped in identi-
fying 16 additional organization pairs having
acquisition relation between them correctly.
</bodyText>
<table confidence="0.978396666666667">
Cluster Cluster Members
1 manufacture, produce, make
2 acquire, purchase, own, operate, buy
</table>
<tableCaption confidence="0.9895135">
Table 4. Clustering results for Relations having Or-
ganizations as subjects
</tableCaption>
<table confidence="0.997861166666667">
Statistics
No. of pairs in Freebase table 73
No. of discovered pairs matching Freebase 66
No. of additional pairs discovered 16
Total no. of correctly discovered pairs 82/104
Accurate Predictions %age 78%
</table>
<tableCaption confidence="0.844003333333333">
Table 5. Evaluation results for improving recall by
discovering additional entity pairs having the acquisi-
tion relation
</tableCaption>
<bodyText confidence="0.999588125">
Another observation worth mentioning is that the
acquisition relation is represented mostly in the
form of tables in Wikipedia whereas Powerset
only processes information that is present in sen-
tences. In spite of that, our approach was able to
find new entity pairs from text that did not al-
ready exist in information extracted by other
sources (table 5).
</bodyText>
<subsectionHeader confidence="0.999492">
4.4 Discovering Relations at Different Le-
vels of Abstraction
</subsectionHeader>
<bodyText confidence="0.999819125">
In this experiment we introduced Semantic Type
information in the Factz data set to discover rela-
tions at different levels of abstraction i.e. be-
tween Entity Types at different levels (For ex-
ample School or Organization, where School is a
type of Organization).
We took a list of 13000 organizations for
which we had their Organization Types available
</bodyText>
<page confidence="0.994754">
110
</page>
<bodyText confidence="0.999835620689655">
from an internal KB and queried Powerset for
Factz between all pairs of organizations and were
able to retrieve more than 88,000 Factz. We
passed on the Factz to the Semantic Typing
module to replace the Organization names with
their types. The Factz dataset with Semantic
Type information was given as input for collaps-
ing relations, where the similarity matrix was
constructed based on the same subject and object
types (rather than same subject and object in-
stances), after which the clustering was per-
formed. We evaluated the clusters at different
stopping thresholds but the system did not gener-
ate any meaningful clusters. We then looked into
the dataset and realized that a lot of noise was
introduced into the system due to various organi-
zation names which were very ambiguous and
replacing the ambiguous organization names
with organization types had magnified the noise.
For example, in our organizations list there is an
organization with the name “Systems” which is
of type “Medical Instrument Supplies”. It had the
following fact related to it: &lt;3d systems&gt; &lt;man-
ufacture&gt; &lt;systems&gt;. Replacing the organization
name with the type resulted in the following fact
i.e., &lt;multimedia graphics software&gt; &lt;manufac-
ture&gt; &lt;medical instruments supplies&gt;. Such am-
biguous names when replaced with wrong types
further magnified the noise.
</bodyText>
<subsectionHeader confidence="0.773418">
4.4.1 Resolving Ambiguity
</subsectionHeader>
<bodyText confidence="0.999995375">
As discussed, ambiguous organization names
introduced noise and replacing them with organi-
zation types magnified the noise. Therefore, it
was important to resolve the ambiguity in the
names of entities before applying Semantic Typ-
ing. There are different approaches than can be
used to recognize and disambiguate Named Enti-
ties, which we discuss below.
</bodyText>
<subsectionHeader confidence="0.778982">
4.4.1.1 Named Entity Recognition
</subsectionHeader>
<bodyText confidence="0.999831358974359">
Powerset has Factz that are extracted from
sentences. The Factz may be present between
Named Entities or even just words in sentences.
For example “Accord” is a name of a trade union
and is also a word. Running Named Entity Rec-
ognition systems over the sentences from which
the Factz have been extracted can help in identi-
fying named entities and in eliminating such
factz which are not between named entities. In
general, the relation extraction systems have an
initial step where they identify entities in sen-
tences through NER systems and then discover
relations between those entities.
Most of Named Entity Recognition and Dis-
ambiguation systems use the contextual informa-
tion to disambiguate between entities. The con-
textual information could be words in the sen-
tences or other entities in the sentences where the
entity is mentioned. Having some evidence that
two entities are related in some way can also
help in eliminating much of the ambiguity. In
general, the relation extraction systems have an
initial step where they find related entity pairs
based on Co-occurrences and then discover rela-
tions between those pairs of entities which fre-
quently co-occur with each other in sentences.
We followed the approach of getting addition-
al context by using entity pairs for querying Po-
werset for which we have background know-
ledge that the pairs are related through some rela-
tion and only retrieved the Factz that were be-
tween those entity pairs. We repeated the same
experiment. However, this time we gave as input
pairs of entity names for which we have evidence
that the entities are related and then ran the expe-
riment with and without semantic typing infor-
mation to validate if introducing semantic typing
can give us some additional advantage. We dis-
cuss the details of our experiment below.
</bodyText>
<table confidence="0.981485">
Relations between Entity Types Freebase Source
person - organization PersonEmployment table
person- school Education table
organization-organization Acquisitions table
</table>
<tableCaption confidence="0.978338">
Table 6. Data Set with relations between different
types of entities extracted from Freebase tables
</tableCaption>
<bodyText confidence="0.999629">
Using Freebase tables we extracted datasets
for relations present between three different
kinds of entity pairs i.e persons and organizations
(e.g. Person-join-Organization), persons and
school (e.g. Person-attend-School) and Organiza-
tions and Organizations (e.g. Organization- ac-
quire-Organization) (table 6). We used the pairs
of entities (Persons - Organizations, Persons -
Schools and Organizations - Organizations) to
query Powerset and extracted the Factz that cor-
responded to those pairs. Table 7 gives an exam-
ple of the predicates in the Factz found between
the different types of entity pairs.
After clustering we evaluated the clusters and
were expecting to get the relations between three
different kinds of entity pairs namely Person -
Organization, Person - School, Organization -
Organization into three separate clusters. We
evaluated the output clusters at different stopping
thresholds but were not able to get three clusters
using any threshold. Table 8 shows the clusters
</bodyText>
<page confidence="0.996202">
111
</page>
<bodyText confidence="0.999517296296296">
found at threshold of 2. There were two possible
reasons for this outcome, one reason was that we
did not have enough redundancy in the data set
to get meaningful clusters and secondly,
“school” is a type of “organization” which could
have introduced ambiguity. In order to introduce
redundancy we replaced all the entity names with
their types (i.e., Person, Organization, School) in
the Factz and repeated the experiment with Enti-
ty Type information rather than Entity names.
We evaluated the clusters at different thresholds
and were able to separate the relation sets into
three clusters with greater than one member. Ta-
ble 9 gives the results of clustering where we got
three clusters with more than one member at
minimum threshold.
The clusters represented the relations present
between the three different types of entity pairs
i.e., person and school, organization and organi-
zation and person and organization (table 9).
Wikipedia is a very non-redundant resource
and redundancy helps in getting more evidence
about the similarity between relations. Other
approaches (Yan et al., 2009) have used the web
for getting redundant information and improving
recall. In addition, there are many sentences in
Wikipedia for which Powerset has no corres-
</bodyText>
<table confidence="0.9927044">
Relation Example of Powerset Factz Predicates
Person- Organization join, leave, found, form, start, create
Person – School attend, enter, return to, enroll at, study at
Organization - Or- acquire, purchase, buy, own
ganization
</table>
<tableCaption confidence="0.883988333333333">
Table 7. Example of Predicates in Powerset Factz
representing relations between different types of entity
pairs
</tableCaption>
<table confidence="0.9996368">
No. Cluster Members Semantic Types
1 enroll at, return to Person-School
2 found, purchase, buy, acquire, Organization- Organi-
create, say about, own zation,
Person-Organization
</table>
<tableCaption confidence="0.9473915">
Table 8. Results of Clustering Relations between Enti-
ty Pairs without using Semantic Typing
</tableCaption>
<table confidence="0.328643363636364">
No. Cluster Members Semantic Relation
1 lead, prep at, play for, enter, Person- School
study, play, graduate, transfer
to, play at, enroll in, go to,
remain at, enroll at, teach at,
move to, attend, join, leave,
teach, study at, return to, work
at
2 acquire, purchase, buy, own, Organization - Organi-
say about zation
3 found, create Person - Organization
</table>
<tableCaption confidence="0.989551">
Table 9. Results of Clustering Relations with Semantic
</tableCaption>
<subsectionHeader confidence="0.598857">
Typing
</subsectionHeader>
<bodyText confidence="0.999965727272727">
ponding Factz associated (it might be due to
some strong filtering heuristics). Using semantic
typing helped in introducing redundancy, without
which we were not able to cluster the relations
between different types of entity pairs into sepa-
rate clusters. Semantic Typing also helped in
identifying the relations present between entities
at different levels of abstraction. This can help in
suggesting relations between different entity
types evident in the corpus during the Ontology
engineering process.
</bodyText>
<sectionHeader confidence="0.999658" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999986">
We have developed a hybrid approach for unsu-
pervised and unrestricted relation discovery be-
tween entities using linguistic analysis via Po-
werset, entropy based label ranking and semantic
typing information from a Knowledge base. We
initially compared the accuracy of Powerset
Factz with ground truth and with entropy based
label ranking approach on a sample dataset and
observed that the relations discovered through
Powerset Factz gave higher accuracy than the
entropy based approach for the sample dataset.
We also developed an approach to collapse a set
of relations represented in facts as a single domi-
nating relation and introduced a hybrid approach
for label selection based on relation clustering
and entropy based label ranking. Our experi-
ments showed that the relational clustering ap-
proach was able to cluster different kinds of enti-
ty pairs into different clusters. For the case where
the kinds of entity pairs were at different levels
of abstraction, introducing Semantic Typing in-
formation helped in introducing redundancy and
also in clustering relations between different
kinds of entity pairs whereas, the direct approach
was not able to identify meaningful clusters. We
plan to further test our approach on a greater va-
riety of relations and on a larger scale.
</bodyText>
<page confidence="0.997582">
112
</page>
<sectionHeader confidence="0.995876" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998451653061225">
Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishi-
zuka. 2007. Subtree mining for relation extraction
from Wikipedia. In Proc. of NAACL ’07: pages
125–128.
Dmitry Davidov, Ari Rappoport and Moshe Koppel.
2007. Fully unsupervised discovery of concept-
specific relationships by Web mining. Proceedings
of the 45th Annual Meeting of the Association of
Computational Linguistics, pp. 232–239.
George A. Miller , Richard Beckwith , Christiane
Fellbaum , Derek Gross , Katherine Miller. 1990.
Wordnet: An on-line lexical database. International
Journal of Lexicography, 3(4):235-312.
Jinxiu Chen, Donghong Ji, Chew Lim Tan and Zhen-
gyu Niu. Unsupervised Feature Selection for Rela-
tion Extraction. In Proc. of IJCNLP-2005.
Metaweb Technologies, Freebase Data Dumps,
http://download.freebase.com/datadumps/ July,
2009
Michele Banko , Michael J Cafarella , Stephen So-
derl , Matt Broadhead , Oren Etzioni. 2008. Open
information extraction from the web. Commun.
ACM 51, 12 (Dec. 2008), 68-74.
Nanda Kambhatla. 2004. Combining lexical, syntactic
and semantic features with maximum entropy
models. In Proceedings of the ACL 2004 on Inter-
active poster and demonstration sessions.
Sanda Harabagiu, Cosmin Andrian Bejan, and Paul
Morarescu. 2005. Shallow semantics for relation
extraction. In Proc. of IJCAI 2005.
Soren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. Dbpedia: A nucleus for a web of open data.
In Proc. of ISWC 2007.
Stanley Kok and Pedro Domingos. 2008. Extracting
Semantic Networks from Text Via Relational Clus-
tering. In Proc. of the ECML-2008.
Takaaki Hasegawa, Satoshi Sekine and Ralph Grish-
man. 2004. Discovering Relations among Named
Entities from Large Corpora. In Proc. of ACL-04.
Powerset. www.Powerset.com
Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu
Yang, and Mitsuru Ishizuka. 2009. Unsupervised
relation extraction by mining Wikipedia texts using
information from the web. In ACL-IJCNLP ’09:
Volume 2, pages 1021–1029.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted rela-
tion discovery. In HLT/NAACL-2006.
</reference>
<page confidence="0.999313">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929169">
<title confidence="0.9984405">A Hybrid Approach to Unsupervised Relation Discovery Based Linguistic Analysis and Semantic Typing</title>
<author confidence="0.990322">Zareen Syed Evelyne Viegas</author>
<affiliation confidence="0.999833">University of Maryland Baltimore County Microsoft Research</affiliation>
<address confidence="0.999716">1000 Hilltop Circle One Microsoft Way Baltimore, MD 21229, USA Redmond, WA 98052, USA</address>
<abstract confidence="0.997213333333333">This paper describes a hybrid approach for unsupervised and unrestricted relation discovery between entities using output from linguistic analysis and semantic typing information from a knowledge base. We use Factz (encoded as subject, predicate and object triples) produced by Powerset as a result of linguistic analysis. A particular relation may be expressed in a variety of ways in text and hence have multiple facts associated with it. We present an unsupervised approach for collapsing multiple facts which represent the same kind of semantic relation between entities. Then a label is selected for the relation based on the input facts and entropy based label ranking of context words. Finally, we demonstrate relation discovery between entities at different levels of abstraction by leveraging semantic typing information from a knowledge base.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dat P T Nguyen</author>
<author>Yutaka Matsuo</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Subtree mining for relation extraction from Wikipedia.</title>
<date>2007</date>
<booktitle>In Proc. of NAACL ’07:</booktitle>
<pages>125--128</pages>
<contexts>
<context position="3136" citStr="Nguyen et al., 2007" startWordPosition="492" endWordPosition="495">kipedia (figure 1). In our approach we use the readily available “Factz” from Powerset as input to our system. Powerset is Wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to Wikipedia. The Factz output from Powerset may represent relations between named entities or just nouns for example, Bank of America &lt;acquired&gt; bank Bank of America &lt;acquired&gt; Merrill Lynch Bank of America &lt;owned&gt; building Linguistic analysis has been recently described as an effective technique for relation extraction (Yan et al., 2009; Kambhatla, 2004; Nguyen et al., 2007). Following that trend, we incorporate Factz, that are the output of linguistic analysis done by Powerset, to discover semantic relations between entities. Information from existing knowledge reFigure 1. Demonstration of Powerset Factz available online Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 105–113, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics sources can help in tasks like named entity disambiguation by providing additional context in the form of linked entities in the </context>
<context position="6640" citStr="Nguyen et al. (2007)" startWordPosition="1055" endWordPosition="1058"> patterns in which the concept words and other words appear. Their system is based on the initial seed of two or more words representing the type of concept one is interested in. Linguistic analysis has been reported as an effective technique for semantic relation extraction. Harabagiu et al. (2005) used shallow semantic parsers to enhance dependency tree kernels and to build semantic dependency structures to improve relation extraction, they reported that their method improved the quality of the extracted relations as compared to kernel-based models that used semantic class information only. Nguyen et al. (2007) presented an approach for relation extraction from Wikipedia by extracting features from subtrees mined from the syntactic structure of text. Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. Most of the existing approaches have used linguistic analysis to generate features for supervised or semi-supervised relation extraction. Recently, Yan et al. (2009) have developed an approach for unsupervised relation </context>
</contexts>
<marker>Nguyen, Matsuo, Ishizuka, 2007</marker>
<rawString>Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishizuka. 2007. Subtree mining for relation extraction from Wikipedia. In Proc. of NAACL ’07: pages 125–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
<author>Moshe Koppel</author>
</authors>
<title>Fully unsupervised discovery of conceptspecific relationships by Web mining.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>232--239</pages>
<contexts>
<context position="5900" citStr="Davidov et al. (2007)" startWordPosition="937" endWordPosition="940">hinyama and Sekine (2006) developed an approach to preemptively discover relations in a corpus and present them as tables with all the entity pairs in the table having the same relations between them. For pairs of entities they generate basic patterns that are parts of text syntactically connected to the Entity and use the predicate argument structure to make the basic patterns more generalized. They generate a basic cluster from articles based on having similar basic patterns to represent the same event and then they cluster the basic clusters to get a set of events having the same relation. Davidov et al. (2007) developed a web mining approach for discovering relations in which a specified concept participates based on clustering patterns in which the concept words and other words appear. Their system is based on the initial seed of two or more words representing the type of concept one is interested in. Linguistic analysis has been reported as an effective technique for semantic relation extraction. Harabagiu et al. (2005) used shallow semantic parsers to enhance dependency tree kernels and to build semantic dependency structures to improve relation extraction, they reported that their method improv</context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Dmitry Davidov, Ari Rappoport and Moshe Koppel. 2007. Fully unsupervised discovery of conceptspecific relationships by Web mining. Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pp. 232–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>Wordnet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<marker>Fellbaum, 1990</marker>
<rawString>George A. Miller , Richard Beckwith , Christiane Fellbaum , Derek Gross , Katherine Miller. 1990. Wordnet: An on-line lexical database. International Journal of Lexicography, 3(4):235-312.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jinxiu Chen</author>
</authors>
<title>Donghong Ji, Chew Lim Tan and Zhengyu Niu. Unsupervised Feature Selection for Relation Extraction.</title>
<booktitle>In Proc. of IJCNLP-2005.</booktitle>
<marker>Chen, </marker>
<rawString>Jinxiu Chen, Donghong Ji, Chew Lim Tan and Zhengyu Niu. Unsupervised Feature Selection for Relation Extraction. In Proc. of IJCNLP-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Metaweb Technologies</author>
</authors>
<title>Freebase Data Dumps,</title>
<date>2009</date>
<location>http://download.freebase.com/datadumps/</location>
<contexts>
<context position="15075" citStr="Technologies, 2009" startWordPosition="2467" endWordPosition="2468">n instances of entities. For example, for ontology engineering, the ontology 108 engineer might want to explore the kind of relations that exist between different entity types based on the data set and then develop an ontology representing those relations. Therefore, we have a component in our system that incorporates semantic type information into the Factz before collapsing the relations present in the facts. The semantic type module queries a knowledge base for the entity type and replaces the entity instance names with entity types in the Factz data set. We have used the Freebase (Metaweb Technologies, 2009) Knowledge base to associate the entity types for the entities that we experimented with. When this modified version of the Factz dataset is given as input to the next component of the system i.e. Collapse Relations, the similarity between relations is computed based on having the same subject and object entity types rather than entity instances. Following the Semantic Typing path in the system would output the relations discovered between types of entities. Introducing Semantic Typing information can also help in creating redundancy in the dataset and overcome the data sparseness problem. For</context>
</contexts>
<marker>Technologies, 2009</marker>
<rawString>Metaweb Technologies, Freebase Data Dumps, http://download.freebase.com/datadumps/ July, 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Soderl</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2008</date>
<journal>Commun. ACM</journal>
<volume>51</volume>
<pages>12</pages>
<marker>Soderl, 2008</marker>
<rawString>Michele Banko , Michael J Cafarella , Stephen Soderl , Matt Broadhead , Oren Etzioni. 2008. Open information extraction from the web. Commun. ACM 51, 12 (Dec. 2008), 68-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanda Kambhatla</author>
</authors>
<title>Combining lexical, syntactic and semantic features with maximum entropy models.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL</booktitle>
<contexts>
<context position="3114" citStr="Kambhatla, 2004" startWordPosition="490" endWordPosition="491">ts from across Wikipedia (figure 1). In our approach we use the readily available “Factz” from Powerset as input to our system. Powerset is Wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to Wikipedia. The Factz output from Powerset may represent relations between named entities or just nouns for example, Bank of America &lt;acquired&gt; bank Bank of America &lt;acquired&gt; Merrill Lynch Bank of America &lt;owned&gt; building Linguistic analysis has been recently described as an effective technique for relation extraction (Yan et al., 2009; Kambhatla, 2004; Nguyen et al., 2007). Following that trend, we incorporate Factz, that are the output of linguistic analysis done by Powerset, to discover semantic relations between entities. Information from existing knowledge reFigure 1. Demonstration of Powerset Factz available online Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 105–113, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics sources can help in tasks like named entity disambiguation by providing additional context in the form of l</context>
<context position="6799" citStr="Kambhatla (2004)" startWordPosition="1080" endWordPosition="1081"> interested in. Linguistic analysis has been reported as an effective technique for semantic relation extraction. Harabagiu et al. (2005) used shallow semantic parsers to enhance dependency tree kernels and to build semantic dependency structures to improve relation extraction, they reported that their method improved the quality of the extracted relations as compared to kernel-based models that used semantic class information only. Nguyen et al. (2007) presented an approach for relation extraction from Wikipedia by extracting features from subtrees mined from the syntactic structure of text. Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. Most of the existing approaches have used linguistic analysis to generate features for supervised or semi-supervised relation extraction. Recently, Yan et al. (2009) have developed an approach for unsupervised relation discovery by integrating linguistic analysis done on Wikipedia with context generated from the Web. They develop a clustering approach based on dependency patt</context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>Nanda Kambhatla. 2004. Combining lexical, syntactic and semantic features with maximum entropy models. In Proceedings of the ACL 2004 on Interactive poster and demonstration sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Cosmin Andrian Bejan</author>
<author>Paul Morarescu</author>
</authors>
<title>Shallow semantics for relation extraction.</title>
<date>2005</date>
<booktitle>In Proc. of IJCAI</booktitle>
<contexts>
<context position="6320" citStr="Harabagiu et al. (2005)" startWordPosition="1005" endWordPosition="1008">ic cluster from articles based on having similar basic patterns to represent the same event and then they cluster the basic clusters to get a set of events having the same relation. Davidov et al. (2007) developed a web mining approach for discovering relations in which a specified concept participates based on clustering patterns in which the concept words and other words appear. Their system is based on the initial seed of two or more words representing the type of concept one is interested in. Linguistic analysis has been reported as an effective technique for semantic relation extraction. Harabagiu et al. (2005) used shallow semantic parsers to enhance dependency tree kernels and to build semantic dependency structures to improve relation extraction, they reported that their method improved the quality of the extracted relations as compared to kernel-based models that used semantic class information only. Nguyen et al. (2007) presented an approach for relation extraction from Wikipedia by extracting features from subtrees mined from the syntactic structure of text. Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semanti</context>
</contexts>
<marker>Harabagiu, Bejan, Morarescu, 2005</marker>
<rawString>Sanda Harabagiu, Cosmin Andrian Bejan, and Paul Morarescu. 2005. Shallow semantics for relation extraction. In Proc. of IJCAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In Proc. of ISWC</booktitle>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>Soren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In Proc. of ISWC 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Pedro Domingos</author>
</authors>
<title>Extracting Semantic Networks from Text Via Relational Clustering.</title>
<date>2008</date>
<booktitle>In Proc. of the ECML-2008.</booktitle>
<contexts>
<context position="7868" citStr="Kok and Domingos (2008)" startWordPosition="1242" endWordPosition="1245">very by integrating linguistic analysis done on Wikipedia with context generated from the Web. They develop a clustering approach based on dependency patterns from dependency analysis of Wikipedia and surface patterns by querying the web to introduce redundancy. They report that dependency patterns improve the precision whereas, the surface patterns improved the coverage. Banko et al. (2008) introduce the TextRunner system which takes a small corpus sample as input and uses a linguistic parser to generate training data which they use to train the extractor which can run at web scale. However, Kok and Domingos (2008) have reported that the triples output from the TextRunner system are noisy, sparse and contain many co-referent objects and relations which is also the case with Powerset. Their system uses the output from the TextRunner system and uses Multiple Relational Clustering model to get object clusters and relation clusters. 106 Figure 2. The Knowledge Discovery approach uses Powerset Factz which are the output from linguistic analysis, article text for entropy based label ranking and existing knowledge resources for discovering relations at different levels of abstraction and hence aiding in enrich</context>
</contexts>
<marker>Kok, Domingos, 2008</marker>
<rawString>Stanley Kok and Pedro Domingos. 2008. Extracting Semantic Networks from Text Via Relational Clustering. In Proc. of the ECML-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hasegawa</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Discovering Relations among Named Entities from Large Corpora.</title>
<date>2004</date>
<booktitle>In Proc. of ACL-04.</booktitle>
<contexts>
<context position="5016" citStr="Hasegawa et al. (2004)" startWordPosition="794" endWordPosition="797">s, and serve as input to our system; Text based label ranking by directly considering the context words in the sentences; and, Semantic Typing information from existing knowledge resources to discover relations between Entity types at different levels of abstraction. The paper is organized as follows. We discuss the related work in the next section. In section 3 we propose our approach and give the details of different components in our system. In section 4, we discuss preliminary experiments and results. In the last section we conclude our work and give future work directions. 2 Related Work Hasegawa et al. (2004) developed an approach for unsupervised relation discovery by clustering pairs of entities based on intervening words represented as context vectors. They used the most frequent common word to label the cluster and hence the relation represented by the cluster. Shinyama and Sekine (2006) developed an approach to preemptively discover relations in a corpus and present them as tables with all the entity pairs in the table having the same relations between them. For pairs of entities they generate basic patterns that are parts of text syntactically connected to the Entity and use the predicate ar</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Takaaki Hasegawa, Satoshi Sekine and Ralph Grishman. 2004. Discovering Relations among Named Entities from Large Corpora. In Proc. of ACL-04.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Powerset</author>
</authors>
<note>www.Powerset.com</note>
<marker>Powerset, </marker>
<rawString>Powerset. www.Powerset.com</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan Yan</author>
<author>Naoaki Okazaki</author>
<author>Yutaka Matsuo</author>
<author>Zhenglu Yang</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Unsupervised relation extraction by mining Wikipedia texts using information from the web.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP ’09:</booktitle>
<volume>2</volume>
<pages>1021--1029</pages>
<contexts>
<context position="3097" citStr="Yan et al., 2009" startWordPosition="486" endWordPosition="489">s a summary of facts from across Wikipedia (figure 1). In our approach we use the readily available “Factz” from Powerset as input to our system. Powerset is Wikipedia independent and can run on any corpus with well-formed sentences and hence our approach is also not limited to Wikipedia. The Factz output from Powerset may represent relations between named entities or just nouns for example, Bank of America &lt;acquired&gt; bank Bank of America &lt;acquired&gt; Merrill Lynch Bank of America &lt;owned&gt; building Linguistic analysis has been recently described as an effective technique for relation extraction (Yan et al., 2009; Kambhatla, 2004; Nguyen et al., 2007). Following that trend, we incorporate Factz, that are the output of linguistic analysis done by Powerset, to discover semantic relations between entities. Information from existing knowledge reFigure 1. Demonstration of Powerset Factz available online Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 105–113, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics sources can help in tasks like named entity disambiguation by providing additional context</context>
<context position="7186" citStr="Yan et al. (2009)" startWordPosition="1136" endWordPosition="1139"> models that used semantic class information only. Nguyen et al. (2007) presented an approach for relation extraction from Wikipedia by extracting features from subtrees mined from the syntactic structure of text. Kambhatla (2004) developed a method for extracting relations by applying Maximum Entropy models to combine lexical, syntactic and semantic features and report that they obtain improvement in results when they combine variety of features. Most of the existing approaches have used linguistic analysis to generate features for supervised or semi-supervised relation extraction. Recently, Yan et al. (2009) have developed an approach for unsupervised relation discovery by integrating linguistic analysis done on Wikipedia with context generated from the Web. They develop a clustering approach based on dependency patterns from dependency analysis of Wikipedia and surface patterns by querying the web to introduce redundancy. They report that dependency patterns improve the precision whereas, the surface patterns improved the coverage. Banko et al. (2008) introduce the TextRunner system which takes a small corpus sample as input and uses a linguistic parser to generate training data which they use t</context>
<context position="29769" citStr="Yan et al., 2009" startWordPosition="4784" endWordPosition="4787">. We evaluated the clusters at different thresholds and were able to separate the relation sets into three clusters with greater than one member. Table 9 gives the results of clustering where we got three clusters with more than one member at minimum threshold. The clusters represented the relations present between the three different types of entity pairs i.e., person and school, organization and organization and person and organization (table 9). Wikipedia is a very non-redundant resource and redundancy helps in getting more evidence about the similarity between relations. Other approaches (Yan et al., 2009) have used the web for getting redundant information and improving recall. In addition, there are many sentences in Wikipedia for which Powerset has no corresRelation Example of Powerset Factz Predicates Person- Organization join, leave, found, form, start, create Person – School attend, enter, return to, enroll at, study at Organization - Or- acquire, purchase, buy, own ganization Table 7. Example of Predicates in Powerset Factz representing relations between different types of entity pairs No. Cluster Members Semantic Types 1 enroll at, return to Person-School 2 found, purchase, buy, acquire</context>
</contexts>
<marker>Yan, Okazaki, Matsuo, Yang, Ishizuka, 2009</marker>
<rawString>Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu Yang, and Mitsuru Ishizuka. 2009. Unsupervised relation extraction by mining Wikipedia texts using information from the web. In ACL-IJCNLP ’09: Volume 2, pages 1021–1029.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In HLT/NAACL-2006.</booktitle>
<contexts>
<context position="2029" citStr="Shinyama and Sekine, 2006" startWordPosition="317" endWordPosition="320">he entities mentioned in text to the right entities in the KB; handling co-referent relations, as a particular semantic relation between entities can be expressed in a variety of ways in the text and therefore have multiple facts associated between the entities. In addition, the facts extracted from linguistic analysis are usually noisy and sparse. Our work focuses on a recent line of exploratory work in the direction of Unrestricted Relation Discovery which is defined as: the automatic identification of different relations in text without specifying a relation or set of relations in advance (Shinyama and Sekine, 2006). We use the facts which are the output of linguistic analysis from Powerset (www.Powerset.com). Powerset 105 is an online search engine for querying Wikipedia using Natural Language Queries. Powerset performs a linguistic analysis of the sentences within Wikipedia and outputs facts in the form of subject, predicate and object triples which can be queried through the online interface. For most entities like persons, places and things, Powerset shows a summary of facts from across Wikipedia (figure 1). In our approach we use the readily available “Factz” from Powerset as input to our system. Po</context>
<context position="5304" citStr="Shinyama and Sekine (2006)" startWordPosition="837" endWordPosition="840">anized as follows. We discuss the related work in the next section. In section 3 we propose our approach and give the details of different components in our system. In section 4, we discuss preliminary experiments and results. In the last section we conclude our work and give future work directions. 2 Related Work Hasegawa et al. (2004) developed an approach for unsupervised relation discovery by clustering pairs of entities based on intervening words represented as context vectors. They used the most frequent common word to label the cluster and hence the relation represented by the cluster. Shinyama and Sekine (2006) developed an approach to preemptively discover relations in a corpus and present them as tables with all the entity pairs in the table having the same relations between them. For pairs of entities they generate basic patterns that are parts of text syntactically connected to the Entity and use the predicate argument structure to make the basic patterns more generalized. They generate a basic cluster from articles based on having similar basic patterns to represent the same event and then they cluster the basic clusters to get a set of events having the same relation. Davidov et al. (2007) dev</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In HLT/NAACL-2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>