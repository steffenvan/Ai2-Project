<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000741">
<title confidence="0.9736395">
Improved Natural Language Learning via
Variance-Regularization Support Vector Machines
</title>
<author confidence="0.9977">
Shane Bergsma Dekang Lin Dale Schuurmans
</author>
<affiliation confidence="0.998442">
University of Alberta Google, Inc. University of Alberta
</affiliation>
<email confidence="0.978963">
sbergsma@ualberta.ca lindek@google.com dale@cs.ualberta.ca
</email>
<sectionHeader confidence="0.994417" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988175">
We present a simple technique for learn-
ing better SVMs using fewer training ex-
amples. Rather than using the standard
SVM regularization, we regularize toward
low weight-variance. Our new SVM ob-
jective remains a convex quadratic func-
tion of the weights, and is therefore com-
putationally no harder to optimize than a
standard SVM. Variance regularization is
shown to enable dramatic improvements
in the learning rates of SVMs on three lex-
ical disambiguation tasks.
</bodyText>
<sectionHeader confidence="0.998422" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999884256410256">
Discriminative training is commonly used in NLP
and speech to scale the contribution of different
models or systems in a combined predictor. For
example, discriminative training can be used to
scale the contribution of the language model and
translation model in machine translation (Och and
Ney, 2002). Without training data, it is often rea-
sonable to weight the different models equally. We
propose a simple technique that exploits this intu-
ition for better learning with fewer training exam-
ples. We regularize the feature weights in a Sup-
port Vector Machine (Cortes and Vapnik, 1995) to-
ward a low-variance solution. Since the new SVM
quadratic program is convex, it is no harder to op-
timize than the standard SVM objective.
When training data is generated through hu-
man effort, faster learning saves time and money.
When examples are labeled automatically, through
user feedback (Joachims, 2002) or from tex-
tual pseudo-examples (Smith and Eisner, 2005;
Okanohara and Tsujii, 2007), faster learning can
reduce the lag before a new system is useful.
We demonstrate faster learning on lexical dis-
ambiguation tasks. For these tasks, a system pre-
dicts a label for a word in text, based on the
word’s context. Possible labels include part-of-
speech tags, named-entity types, and word senses.
A number of disambiguation systems make pre-
dictions with the help of N-gram counts from a
web-scale auxiliary corpus, typically via a search-
engine (Lapata and Keller, 2005) or N-gram cor-
pus (Bergsma et al., 2009). When discriminative
training is used to weigh the counts for classifi-
cation, many of the learned feature weights have
similar values. Good weights have low variance.
For example, consider the task of preposition
selection. A system selects the most likely prepo-
sition given the context, and flags a possible error
if it disagrees with the user’s choice:
</bodyText>
<listItem confidence="0.998607">
• I worked in Russia from 1997 to 2001.
• I worked in Russia *during 1997 to 2001.
</listItem>
<bodyText confidence="0.999928173913044">
Bergsma et al. (2009) use a variety of web counts
to predict the correct preposition. They have fea-
tures for COUNT(in Russia from), COUNT(Russia
from 1997), COUNT(from 1997 to), etc. If these are
high, from is predicted. Similarly, they have fea-
tures for COUNT(in Russia during), COUNT(Russia
during 1997), COUNT(during 1997 to). These fea-
tures predict during. All counts are in the log
domain. The task has thirty-four different prepo-
sitions to choose from. A 34-way classifier is
trained on examples of correct preposition usage;
it learns which context positions and sizes are most
reliable and assigns feature weights accordingly.
A very strong unsupervised baseline, however,
is to simply weight all the count features equally.
In fact, in Bergsma et al. (2009), the supervised
approach requires over 30,000 training examples
before it outperforms this baseline. In contrast,
we show that by regularizing a classifier toward
equal weights, a supervised predictor outperforms
the unsupervised approach after only ten exam-
ples, and does as well with 1000 examples as the
standard classifier does with 100,000.
</bodyText>
<page confidence="0.964048">
172
</page>
<note confidence="0.9554775">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 172–181,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99996503030303">
Section 2 first describes a general multi-class
SVM. We call the base vector of information
used by the SVM the attributes. A standard
multi-class SVM creates features for the cross-
product of attributes and classes. E.g., the attribute
COUNT(Russia during 1997) is not only a feature
for predicting the preposition during, but also for
predicting the 33 other prepositions. The SVM
must therefore learn to disregard many irrelevant
features. We observe that this is not necessary,
and develop an SVM that only uses the relevant
attributes in the score for each class. Building on
this efficient framework, we incorporate variance
regularization into the SVM’s quadratic program.
We apply our algorithms to three tasks: prepo-
sition selection, context-sensitive spelling correc-
tion, and non-referential pronoun detection (Sec-
tion 4). We reproduce Bergsma et al. (2009)’s
results using a multi-class SVM. Our new mod-
els achieve much better accuracy with fewer train-
ing examples. We also exceed the accuracy of a
reasonable alternative technique for increasing the
learning rate: including the output of the unsuper-
vised system as a feature in the SVM.
Variance regularization is an elegant addition to
the suite of methods in NLP that improve perfor-
mance when access to labeled data is limited. Sec-
tion 5 discusses some related approaches. While
we motivate our algorithm as a way to learn better
weights when the features are counts from an aux-
iliary corpus, there are other potential uses of our
method. We outline some of these in Section 6,
and note other directions for future research.
</bodyText>
<sectionHeader confidence="0.966372" genericHeader="introduction">
2 Three Multi-Class SVM Models
</sectionHeader>
<bodyText confidence="0.9999422">
We describe three max-margin multi-class classi-
fiers and their corresponding quadratic programs.
Although we describe linear SVMs, they can be
extended to nonlinear cases in the standard way
by writing the optimal function as a linear combi-
nation of kernel functions over the input examples.
In each case, after providing the general tech-
nique, we relate the approach to our motivating
application: learning weights for count features in
a discriminative web-scale N-gram model.
</bodyText>
<subsectionHeader confidence="0.996878">
2.1 Standard Multi-Class SVM
</subsectionHeader>
<bodyText confidence="0.998492625">
We define a K-class SVM following Crammer and
Singer (2001). This is a generalization of binary
SVMs (Cortes and Vapnik, 1995). We have a set
{(x1, y1), ..., (xm, ym)} of M training examples.
Each x� is an N-dimensional attribute vector, and
y ∈ {1, ..., K} are classes. A classifier, H, maps
an attribute vector, x, to a class, y. H is parame-
terized by a K-by-N matrix of weights, W:
</bodyText>
<equation confidence="0.999534666666667">
HW(x) = argmax
K { Wr · 4 (1)
r=1
</equation>
<bodyText confidence="0.999878166666667">
where Wr is the rth row of W. That is, the pre-
dicted label is the index of the row of W that has
the highest inner-product with the attributes, x.
We seek weights such that the classifier makes
few errors on training data and generalizes well
to unseen data. There are KN weights to learn,
for the cross-product of attributes and classes.
The most common approach is to train K sep-
arate one-versus-all binary SVMs, one for each
class. The weights learned for the rth SVM pro-
vide the weights Wr in (1). We call this approach
OvA-SVM. Note in some settings various one-
versus-one strategies may be more effective than
one-versus-all (Hsu and Lin, 2002).
The weights can also be found using a single
constrained optimization (Vapnik, 1998; Weston
and Watkins, 1998). Following the soft-margin
version in Crammer and Singer (2001):
</bodyText>
<equation confidence="0.95168225">
mint 1 K  ||�Wi||2 + C M ξi
W IV I... Ib m 2 i=1 i=1
subject to � ξi ≥0
∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2)
</equation>
<bodyText confidence="0.999905">
The constraints require the correct class to be
scored higher than other classes by a certain mar-
gin, with slack for non-separable cases. Minimiz-
ing the weights is a form of regularization. Tuning
the C-parameter controls the emphasis on regular-
ization versus separation of training examples.
We call this the K-SVM. The K-SVM out-
performed the OvA-SVM in Crammer and Singer
(2001), but see Rifkin and Klautau (2004). The
popularity of K-SVM is partly due to convenience;
it is included in popular SVM software like SVM-
multiclass1 and LIBLINEAR (Fan et al., 2008).
Note that with two classes, K-SVM is less effi-
cient than a standard binary SVM. A binary classi-
fier outputs class 1 if (w� · x� &gt; 0) and class 2 other-
wise. The K-SVM encodes a binary classifier using
</bodyText>
<equation confidence="0.718632">
� �
W1 = w� and W2 = − w, therefore requiring twice
</equation>
<bodyText confidence="0.995307333333333">
the memory of a binary SVM. However, both bi-
nary and 2-class formulations have the same solu-
tion (Weston and Watkins, 1998).
</bodyText>
<footnote confidence="0.999098">
1http://svmlight.joachims.org/svm multiclass.html
</footnote>
<page confidence="0.996787">
173
</page>
<subsectionHeader confidence="0.785483">
2.1.1 Web-Scale N-gram K-SVM
</subsectionHeader>
<bodyText confidence="0.999846814814815">
K-SVM was used with N-gram models in Bergsma
et al. (2009). For preposition selection, attributes
were web counts of patterns filled with 34 preposi-
tions, corresponding to the 34 classes. Each prepo-
sition serves as the filler of each context pattern.
Fourteen patterns were used for each filler: all five
5-grams, four 4-grams, three 3-grams, and two 2-
grams spanning the position to be predicted. There
are N = 14*34 = 476 total attributes, and therefore
KN = 476 * 34 = 16184 weights in W.
This K-SVM classifier can potentially exploit
very subtle information. Let Win and Wbefore
be weights for the classes in and before. Notice
some of the attributes weighted in the inner prod-
ucts Wbefore · x and Win · x� will be for counts of
the preposition after. Relatively high counts for a
context with after should deter us from choosing
in more than from choosing before. These cor-
relations can be encoded in the classifier via the
corresponding weights on after-counts in Win and
Wbefore. How useful are these correlations and
how much training data is needed before they can
be learned and exploited effectively?
We next develop a model that, for each class,
only scores those attributes deemed to be directly
relevant to the class. Our experiments thus empir-
ically address these questions for different tasks.
</bodyText>
<subsectionHeader confidence="0.999595">
2.2 SVM with Class-Specific Attributes
</subsectionHeader>
<bodyText confidence="0.993116625">
Suppose we can partition our attribute vectors into
sub-vectors that only include attributes that we de-
clare as relevant to the corresponding class: x� =
(x1, ..., xK). We develop a classifier that only
uses the class-specific attributes in the score for
each class. The classifier uses an N-dimensional
weight vector, w, which follows the attribute par-
tition, w� = ( 17V1, ..., WK). The classifier is:
</bodyText>
<equation confidence="0.998972333333333">
H¯w(x) = argmax
K {�wr · xr} (3)
r=1
</equation>
<bodyText confidence="0.902929066666667">
We call this classifier the CS-SVM (an SVM with
Class-Specific attributes).
The weights can be determined using the follow
(soft-margin) optimization:
min 1 UV w� + C �m ξi
¯w,ξ�,...,ξm 2 i=1
subject to :ξi &gt;0
br =� yi, wyi · xyi − wr · xr &gt;1 − ξi (4)
There are several advantages to this formula-
tion. Foremost, rather than having KN weights,
it can have only N. For linear classifiers, the
number of examples needed to reach optimum
performance is at most linear in the number of
weights (Vapnik, 1998; Ng and Jordan, 2002). In
fact, both the total number and number of active
features per example decrease by K. Thus this re-
duction saves far more memory than what could
be obtained by an equal reduction in dimensional-
ity via pruning infrequent attributes.
Also, note that unlike the K-SVM (Section 2.1),
in the binary case the CS-SVM is completely equiv-
alent (thus equally efficient) to a standard SVM.
We will not always a priori know the class as-
sociated with each attribute. Also, some attributes
may be predictive of multiple classes. In such
cases, we can include ambiguous attributes in ev-
ery sub-vector (needing N+D(K-1) total weights
if D attributes are duplicated). In the degenerate
case where every attribute is duplicated, CS-SVM
is equivalent to K-SVM; both have KN weights.
</bodyText>
<subsectionHeader confidence="0.493126">
2.2.1 Optimization as a Binary SVM
</subsectionHeader>
<bodyText confidence="0.99998024">
We could solve the optimization problem in (4)
directly using a quadratic programming solver.
However, through an equivalent transformation
into a binary SVM, we can take advantage of effi-
cient, custom SVM optimization algorithms.
We follow Har-Peled et al. (2003) in transform-
ing a multi-class example into a set of binary
examples, each specifying a constraint from (4).
We extend the attribute sub-vector corresponding
to each class to be N-dimensional. We do this
by substituting zero-vectors for all the other sub-
vectors in the partition. The attribute vector for the
rth class is then zr = (0, ..., 0, xr, 0, ..., 0). This is
known as Kesler’s Construction and has a long his-
tory in classification (Duda and Hart, 1973; Cram-
mer and Singer, 2003). We then create binary rank
constraints for a ranking SVM (Joachims, 2002)
(ranking SVMs reduce to standard binary SVMs).
We create K instances for each multi-class exam-
ple (V, yi), with the transformed vector of the true
class, zyi, assigned a higher-rank than all the other,
equally-ranked classes, 2{r�yi}. Training a rank-
ing SVM using these constraints gives the same
weights as solving (4), but allows us to use effi-
cient, custom SVM software.2 Note the K-SVM
</bodyText>
<footnote confidence="0.997845666666667">
2One subtlety is whether to use a single slack, �i, for all
K-1 constraints per example i (Crammer and Singer, 2001),
or a different slack for each constraint (Joachims, 2002). Us-
</footnote>
<page confidence="0.996983">
174
</page>
<bodyText confidence="0.9831535">
can also be trained this way, by including every
attribute in every sub-vector, as described earlier.
</bodyText>
<subsectionHeader confidence="0.560264">
2.2.2 Web-Scale N-gram CS-SVM
</subsectionHeader>
<bodyText confidence="0.999816076923077">
Returning to our preposition selection example, an
obvious attribute partition for the CS-SVM is to
include as attributes for predicting preposition r
only those counts for patterns filled with preposi-
tion r. Thus xin will only include counts for con-
text patterns filled with in and �xbefore will only
include counts for context patterns filled with be-
fore. With 34 sub-vectors and 14 attributes in each,
there are only 14 * 34 = 476 total weights. In con-
trast, K-SVM had 16184 weights to learn.
It is instructive to compare the CS-SVM in (3) to
the unsupervised SUMLM approach in Bergsma et
al. (2009). That approach can be written as:
</bodyText>
<equation confidence="0.998455">
K 11 xr} (5)
H(x) = argmax
r=1
</equation>
<bodyText confidence="0.999983">
where 1 is an N-dimensional vector of ones. This
is CS-SVM with all weights set to unity. The
counts for each preposition are simply summed,
and whichever one scores the highest is taken as
the output (actually only a subset of the counts are
used, see Section 4.1). As mentioned earlier, this
system performs remarkably well on several tasks.
</bodyText>
<subsectionHeader confidence="0.999005">
2.3 Variance Regularization SVMs
</subsectionHeader>
<bodyText confidence="0.999937861111111">
Suppose we choose our attribute partition well and
train the CS-SVM on a sufficient number of exam-
ples to achieve good performance. It is a reason-
able hypothesis that the learned weights will be
predominantly positive. This is because each sub-
vector xr was chosen to only include attributes
that are predictive of class r. Unlike the classifier
in (1) which weighs positive and negative evidence
together for each class, in CS-SVM, negative evi-
dence only plays a roll as it contributes to the score
of competing classes.
If all the attributes are equally important, the
weights should be equal, as in the unsupervised
approach in (5). If some are more important than
others, the training examples should reflect this
and the learner can adjust the weights accord-
ingly.3 In the absence of this training evidence, it
is reasonable to bias the classifier toward an equal-
weight solution.
ing the former may be better as it results in a tighter bound
on empirical risk (Tsochantaridis et al., 2005).
3E.g., the true preposition might be better predicted by the
counts of patterns that tend to include the preposition’s gram-
matical object, i.e., patterns that include more right-context.
Rather than the standard SVM regularization
that minimizes the norm of the weights as in (4),
we therefore regularize toward weights that have
low variance. More formally, we can regard the
set of weights, w1, ..., wN, as the distribution of a
discrete random variable, W. We can calculate the
mean and variance of this variable from its distri-
bution. We seek a variable that has low variance.
We begin with a more general objective and
then explain how a specific choice of covariance
matrix, C, minimizes the variance of the weights.
We propose the regularizer:
</bodyText>
<equation confidence="0.86731675">
min 1 wTC w�+ C m ξi
w,ξ1,...,ξm 2 i=1
subject to � ξi &gt;0
br =� yi, wyz xiyz − wr xir &gt;1 − ξi (6)
</equation>
<bodyText confidence="0.999704615384615">
where C is a normalized covariance matrix such
that Ei,j Ci,j = 0. This ensures uniform weight
vectors receive zero regularization penalty. Since
all covariance matrices are positive semi-definite,
the quadratic program (QP) remains convex in w,
and thus amenable to general purpose QP-solvers.
Since the unsupervised system in (5) has zero
weight variance, the SVM learned in (6) should do
as least as well as (5) as we tune the C-parameter
on development data. That is, as C approaches
zero, variance minimization becomes the sole ob-
jective of (6), and uniform weights are produced.
We use covariance matrices of the form:
</bodyText>
<equation confidence="0.993012">
C = diag(p) − ppT (7)
</equation>
<bodyText confidence="0.999415909090909">
where diag(p) is the matrix constructed by putting
p� on the main diagonal. Here, p� is an arbitrary
N-dimensional weighting vector, such that p &gt;
0 and Ei pi = 1. p� dictates the contribution of
each wi to the mean and variance of the weights
in w. It is easy to see that Ei,j Ci,j = Ei pi −
Ei Ej pipj = 0.
We now show that wT (diag(p) − ppT ) w� ex-
presses the variance of the weights in w� with re-
spect to the probability weighting p. The variance
of a random variable with mean E[W] = µ is:
</bodyText>
<equation confidence="0.992649">
Var[W] = E[(W − µ)2] = E[W2] − E[W]2
</equation>
<bodyText confidence="0.880759666666667">
The mean of the weights using probability weight-
ing p� is E[W] = wTp� = p�w. Also, E[W2] =
UV diag(p) w. Thus:
</bodyText>
<equation confidence="0.992814">
Var[W] = wT diag(p) w� − ( wT p)(p w)
UV (diag(p) − pp) w�
</equation>
<page confidence="0.972571">
175
</page>
<bodyText confidence="0.9957375">
In our experiments, we deem each weight to be
equally important to the variance calculation, and
</bodyText>
<equation confidence="0.8654125">
1
set pi = N, ∀i = 1,... , N.
</equation>
<bodyText confidence="0.999978138888889">
The goal of the regularization in (6) using C
from (7) can be regarded as directing the SVM to-
ward a good unsupervised system, regardless of
the constraints (training examples). In some un-
supervised systems, however, only a subset of the
attributes are used. In other cases, distinct subsets
of weights should have low variance, rather than
minimizing the variance across all weights. There
are examples of these situations in Section 4.
We can account for these cases in our QP. We
provide separate terms in our quadratic function
for the subsets of w that should have low vari-
ance. Suppose we create L subsets of w: cav1, ...�WL,
where Cvj is w with elements set to zero that are not
in subset j. We then minimize 12(�Wi C1(D1 + ... +
�WLCL(DL). If the terms in subset j have low vari-
ance, Cj = C from (7) is used. If the subset corre-
sponds to attributes that are not a priori known to
be useful, an identity matrix can instead be used,
Cj = I, and these weights will be regularized to-
ward zero as in a standard SVM.4
Variance regularization therefore exploits extra
knowledge by the system designer. The designer
decides which weights should have similar values,
and the SVM is biased to prefer this solution.
One consequence of being able to regularize
different subsets of weights is that we can also ap-
ply variance regularization to the standard multi-
class SVM (Section 2.1). We can use an identity
Ci matrix for all irrelevant weights, i.e., weights
that correspond to class-attribute pairs where the
attribute is not directly relevant to the class. In our
experiments, however, we apply variance regular-
ization to the more efficient CS-SVM.
We refer to a CS-SVM trained using the variance
minimization quadratic program as the VAR-SVM.
</bodyText>
<subsectionHeader confidence="0.797126">
2.3.1 Web-Scale N-gram VAR-SVM
</subsectionHeader>
<bodyText confidence="0.999902">
If variance regularization is applied to all weights,
attributes COUNT(in Russia during), COUNT(Russia
during 1997), and COUNT(during 1997 to) will be
encouraged to have similar weights in the score for
class during. Furthermore, these will be weighted
similarly to other patterns, filled with other prepo-
sitions, used in the scores for other classes.
</bodyText>
<footnote confidence="0.434606">
4Weights must appear in &gt;1 subsets (possibly only in the
C; = I subset). Each occurs in at most one in our experi-
ments. Note it is straightforward to express this as a single
covariance matrix regularizer over w; we omit the details.
</footnote>
<bodyText confidence="0.99995175">
Alternatively, we could minimize the variance
separately over all 5-gram patterns, then over all
4-gram patterns, etc., or over all patterns with a
filler in the same position. In our experiments, we
took a very simple approach: we minimized the
variance of all attributes that are weighted equally
in the unsupervised baselines. If a feature is not in-
cluded in a baseline, it is regularized toward zero.
</bodyText>
<sectionHeader confidence="0.998404" genericHeader="method">
3 Experimental Details
</sectionHeader>
<bodyText confidence="0.999858848484849">
We use the data sets from Bergsma et al. (2009).
These are the three tasks where web-scale N-gram
counts were previously used as features in a stan-
dard K-SVM. In each case a classifier makes a de-
cision for a particular word based on the word’s
surrounding context. The attributes of the classi-
fier are the log counts of different fillers occurring
in the context patterns. We retrieve counts from
the web-scale Google Web 5-gram Corpus (Brants
and Franz, 2006), which includes N-grams of
length one to five. We apply add-one smoothing
to all counts. Every classifier also has bias fea-
tures (for every class). We simply include, where
appropriate, attributes that are always unity.
We use LIBLINEAR (Fan et al., 2008) to train
K-SVM and OvA-SVM, and SVMrank (Joachims,
2006) to train CS-SVM. For VAR-SVM, we solve
the primal form of the quadratic program directly
in CPLEX (2005), a general optimization package.
We vary the number of training examples for
each classifier. The C-parameters of all SVMs are
tuned on development data. We evaluate using ac-
curacy: the percentage of test examples that are
classified correctly. We also provide the accuracy
of the majority-class baseline and best unsuper-
vised system, as defined in Bergsma et al. (2009).
As an alternative way to increase the learning
rate, we augment a classifier’s features using the
output of the unsupervised system: For each class,
we include one feature for the sum of all counts (in
the unsupervised system) that predict that class.
We denote these augmented systems with a + as
in K-SVM+ and CS-SVM+.
</bodyText>
<sectionHeader confidence="0.999616" genericHeader="method">
4 Applications
</sectionHeader>
<subsectionHeader confidence="0.999462">
4.1 Preposition Selection
</subsectionHeader>
<bodyText confidence="0.99974325">
Preposition errors are common among new En-
glish speakers (Chodorow et al., 2007). Systems
that can reliably identify these errors are needed
in word processing and educational software.
</bodyText>
<page confidence="0.996612">
176
</page>
<table confidence="0.999767625">
Training Examples
System 10 100 1K 10K 100K
OvA-SVM 16.0 50.6 66.1 71.1 73.5
K-SVM 13.7 50.0 65.8 72.0 74.7
K-SVM+ 22.2 56.8 70.5 73.7 75.2
CS-SVM 27.1 58.8 69.0 73.5 74.2
CS-SVM+ 39.6 64.8 71.5 74.0 74.4
VAR-SVM 73.8 74.2 74.7 74.9 74.9
</table>
<tableCaption confidence="0.933743">
Table 1: Accuracy (%) of preposition-selection
SVMs. Unsupervised accuracy is 73.7%.
</tableCaption>
<bodyText confidence="0.999416666666667">
In our experiments, a classifier must choose the
correct preposition among 34 candidates, using
counts for filled 2-to-5-gram patterns. We use
100K training, 10K development, and 10K test
examples. The unsupervised approach sums the
counts of all 3-to-5-gram patterns for each prepo-
sition. We therefore regularize the variance of the
3-to-5-gram weights in VAR-SVM, and simultane-
ously minimize the norm of the 2-gram weights.
</bodyText>
<sectionHeader confidence="0.933442" genericHeader="method">
4.1.1 Results
</sectionHeader>
<bodyText confidence="0.987853148148148">
The majority-class is the preposition of; it occurs
in 20.3% of test examples. The unsupervised sys-
tem scores 73.7%. For further perspective on these
results, note Chodorow et al. (2007) achieved 69%
with 7M training examples, while Tetreault and
Chodorow (2008) found the human performance
was around 75%. However, these results are not
directly comparable as they are on different data.
Table 1 gives the accuracy for different amounts
of training data. Here, as in the other tasks, K-SVM
mirrors the learning rate in Bergsma et al. (2009).
There are several distinct phases among the rela-
tive ranking of the systems. For smaller amounts
of training data (≤1000 examples) K-SVM per-
forms worst, while VAR-SVM is statistically sig-
nificantly better than all other systems, and al-
ways exceeds the performance of the unsupervised
approach.5 Augmenting the attributes with sum
counts (the + systems) strongly helps with fewer
examples, especially in conjunction with the more
efficient CS-SVM. However, VAR-SVM clearly
helps more. We noted earlier that VAR-SVM is
guaranteed to do as well as the unsupervised sys-
tem on the development data, but here we confirm
that it can also exploit even small amounts of train-
ing data to further improve accuracy.
CS-SVM outperforms K-SVM except with 100K
</bodyText>
<footnote confidence="0.9908585">
5Significance is calculated using a x2 test over the test set
correct/incorrect contingency table.
</footnote>
<table confidence="0.9996998">
Training Examples
System 10 100 1K 10K 100K
CS-SVM 86.0 93.5 95.1 95.7 95.7
CS-SVM+ 91.0 94.9 95.3 95.7 95.7
VAR-SVM 94.9 95.3 95.6 95.7 95.8
</table>
<tableCaption confidence="0.935389">
Table 2: Accuracy (%) of spell-correction SVMs.
Unsupervised accuracy is 94.8%.
</tableCaption>
<bodyText confidence="0.998817714285714">
examples, while OvA-SVM is better than K-SVM
for small amounts of data.6 K-SVM performs best
with all the data; it uses the most expressive repre-
sentation, but needs 100K examples to make use
of it. On the other hand, feature augmentation
and variance regularization provide diminishing
returns as the amount of training data increases.
</bodyText>
<subsectionHeader confidence="0.997194">
4.2 Context-Sensitive Spelling Correction
</subsectionHeader>
<bodyText confidence="0.999971736842105">
Context-sensitive spelling correction, or real-word
error/malapropism detection (Golding and Roth,
1999; Hirst and Budanitsky, 2005), is the task of
identifying errors when a misspelling results in a
real word in the lexicon, e.g., using site when sight
or cite was intended. Contextual spell checkers are
among the most widely-used NLP technology, as
they are included in commercial word processing
software (Church et al., 2007).
For every occurrence of a word in a pre-defined
confusion set (e.g. {cite, sight, cite}), the clas-
sifier selects the most likely word from the set.
We use the five confusion sets from Bergsma et al.
(2009); four are binary and one is a 3-way classi-
fication. We use 100K training, 10K development,
and 10K test examples for each, and average ac-
curacy across the sets. All 2-to-5 gram counts are
used in the unsupervised system, so the variance
of all weights is regularized in VAR-SVM.
</bodyText>
<sectionHeader confidence="0.875441" genericHeader="method">
4.2.1 Results
</sectionHeader>
<bodyText confidence="0.949956153846154">
On this task, the majority-class baseline is much
higher, 66.9%, and so is the accuracy of the top un-
supervised system: 94.8%. Since four of the five
sets are binary classifications, where K-SVM and
CS-SVM are equivalent, we only give the accuracy
of the CS-SVM (it does perform better on the one
3-way set). VAR-SVM again exceeds the unsuper-
vised accuracy for all training sizes, and generally
6Rifkin and Klautau (2004) argue OvA-SVM is as good
as K-SVM, but this is “predicated on the assumption that the
classes are ‘independent’,” i.e., that examples from class 0
are no closer to class 1 than to class 2. This is not true of this
task (e.g. xbefore is closer to xafter than -tin, etc.).
</bodyText>
<page confidence="0.990219">
177
</page>
<table confidence="0.999750166666667">
Training Examples
System 10 100 1K
CS-SVM 59.0 71.0 84.3
CS-SVM+ 59.4 74.9 84.5
VAR-SVM 70.2 76.2 84.5
VAR-SVM+FreeB 64.2 80.3 84.5
</table>
<tableCaption confidence="0.9415645">
Table 3: Accuracy (%) of non-referential detection
SVMs. Unsupervised accuracy is 80.1%.
</tableCaption>
<bodyText confidence="0.997133666666667">
performs as well as the augmented CS-SVM+ us-
ing an order of magnitude less training data (Ta-
ble 2). Differences from &lt;1K are significant.
</bodyText>
<subsectionHeader confidence="0.997724">
4.3 Non-Referential Pronoun Detection
</subsectionHeader>
<bodyText confidence="0.9999835">
Non-referential detection predicts whether the En-
glish pronoun it refers to a preceding noun (“it
lost money”) or is used as a grammatical place-
holder (“it is important to...”). This binary clas-
sification is a necessary but often neglected step
for noun phrase coreference resolution (Paice and
Husk, 1987; Bergsma et al., 2008; Ng, 2009).
Bergsma et al. (2008) use features for the counts
of various fillers in the pronoun’s context patterns.
If it is the most common filler, the pronoun is
likely non-referential. If other fillers are common
(like they or he), it is likely a referential instance.
For example, “he lost money” is common on the
web, but “he is important to” is not. We use the
same fillers as in previous work, and preprocess
the N-gram corpus in the same way.
The unsupervised system picks non-referential
if the difference between the summed count of
it fillers and the summed count of they fillers is
above a threshold (note this no longer fits (5),
with consequences discussed below). We thus
separately minimize the variance of the it pattern
weights and the they pattern weights. We use 1K
training, 533 development, and 534 test examples.
</bodyText>
<sectionHeader confidence="0.771051" genericHeader="evaluation">
4.3.1 Results
</sectionHeader>
<bodyText confidence="0.999981457142857">
The most common class is referential, occurring
in 59.4% of test examples. The unsupervised sys-
tem again does much better, at 80.1%.
Annotated training examples are much harder
to obtain for this task and we experiment with a
smaller range of training sizes (Table 3). The per-
formance of VAR-SVM exceeds the performance
of K-SVM across all training sizes (bold accura-
cies are significantly better than either CS-SVM for
&lt;100 examples). However, the gains were not
as large as we had hoped, and accuracy remains
worse than the unsupervised system when not us-
ing all the training data. When using all the data,
a fairly large C-parameter performs best on devel-
opment data, so regularization plays less of a role.
After development experiments, we speculated
that the poor performance relative to the unsuper-
vised approach was related to class bias. In the
other tasks, the unsupervised system chooses the
highest summed score. Here, the difference in it
and they counts is compared to a threshold. Since
the bias feature is regularized toward zero, then,
unlike the other tasks, using a low C-parameter
does not produce the unsupervised system, so per-
formance can begin below the unsupervised level.
Since we wanted the system to learn this thresh-
old, even when highly regularized, we removed
the regularization penalty from the bias weight,
letting the optimization freely set the weight to
minimize training error. With more freedom, the
new classifier (VAR-SVM+FreeB) performs worse
with 10 examples, but exceeds the unsupervised
approach with 100 training points. Although
this was somewhat successful, developing better
strategies for bias remains useful future work.
</bodyText>
<sectionHeader confidence="0.999819" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99961184">
There is a large body of work on regularization in
machine learning, including work that uses posi-
tive semi-definite matrices in the SVM quadratic
program. The graph Laplacian has been used to
encourage geometrically-similar feature vectors to
be classified similarly (Belkin et al., 2006). An ap-
pealing property of these approaches is that they
incorporate information from unlabeled examples.
Wang et al. (2006) use Laplacian regularization
for the task of dependency parsing. They regular-
ize such that features for distributionally-similar
words have similar weights. Rather than penal-
ize pairwise differences proportional to a similar-
ity function, we simply penalize weight variance.
In the field of computer vision, Tefas et al.
(2001) (binary) and Kotsia et al. (2009) (multi-
class) also regularize weights with respect to a co-
variance matrix. They use labeled data to find the
sum of the sample covariance matrices from each
class, similar to linear discriminant analysis. We
propose the idea in general, and instantiate with
a different C matrix: a variance regularizer over
w. Most importantly, our instantiated covariance
matrix does not require labeled data to generate.
In a Bayesian setting, Raina et al. (2006) model
</bodyText>
<page confidence="0.996216">
178
</page>
<bodyText confidence="0.9999640625">
feature correlations in a logistic regression clas-
sifier. They propose a method to construct a co-
variance matrix for a multivariate Gaussian prior
on the classifier’s weights. Labeled data for other,
related tasks is used to infer potentially correlated
features on the target task. Like in our results, they
found that the gains from modeling dependencies
diminish as more training data is available.
We also mention two related online learning ap-
proaches. Similar to our goal of regularizing to-
ward a good unsupervised system, Crammer et al.
(2006) regularize w� toward a (different) target vec-
tor at each update, rather than strictly minimizing
 ||�w||2. The target vector is the vector learned from
the cumulative effect of previous updates. Dredze
et al. (2008) maintain the variance of each weight
and use this to guide the online updates. However,
covariance between weights is not considered.
We believe new SVM regularizations in gen-
eral, and variance regularization in particular, will
increasingly be used in combination with related
NLP strategies that learn better when labeled data
is scarce. These may include: using more-general
features, e.g. ones generated from raw text (Miller
et al., 2004; Koo et al., 2008), leveraging out-of-
domain examples to improve in-domain classifi-
cation (Blitzer et al., 2007; Daum´e III, 2007), ac-
tive learning (Cohn et al., 1994; Tong and Koller,
2002), and approaches that treat unlabeled data as
labeled, such as bootstrapping (Yarowsky, 1995),
co-training (Blum and Mitchell, 1998), and self-
training (McClosky et al., 2006).
</bodyText>
<sectionHeader confidence="0.999731" genericHeader="discussions">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999906">
The primary direction of future research will be
to apply the VAR-SVM to new problems and tasks.
There are many situations where a system designer
has an intuition about the role a feature will play in
prediction; the feature was perhaps added with this
role in mind. By biasing the SVM to use features
as intended, VAR-SVM may learn better with fewer
training examples. The relationship between at-
tributes and classes may be explicit when, e.g.,
a rule-based system is optimized via discrimina-
tive learning, or annotators justify their decisions
by indicating the relevant attributes (Zaidan et al.,
2007). Also, if features are a priori thought to
have different predictive worth, the attribute val-
ues could be scaled such that variance regulariza-
tion, as we formulated it, has the desired effect.
Other avenues of future work will be to extend
the VAR-SVM in three directions: efficiency, rep-
resentational power, and problem domain.
While we optimized the VAR-SVM objective in
CPLEX, general purpose QP-solvers “do not ex-
ploit the special structure of [the SVM optimiza-
tion] problem,” and consequently often train in
time super-linear with the number of training ex-
amples (Joachims et al., 2009). It would be useful
to fit our optimization problem to efficient SVM
training methods, especially for linear classifiers.
VAR-SVM’s representational power could be ex-
tended by using non-linear SVMs. Kernels can
be used with a covariance regularizer (Kotsia et
al., 2009). Since C is positive semi-definite, the
square root of its inverse is defined. We can there-
fore map the input examples using (C−21x), and
write an equivalent objective function in terms of
kernel functions over the transformed examples.
Also, since structured-prediction SVMs build
on the multi-class framework (Tsochantaridis et
al., 2005), variance regularization can be incor-
porated naturally into more complex prediction
tasks, such as parsers, taggers, and aligners.
VAR-SVM may also help in new domains where
annotated data is lacking. VAR-SVM should be
stronger cross-domain than K-SVM; regulariza-
tion with domain-neutral prior-knowledge can off-
set domain-specific biases. Learned weight vec-
tors from other domains may also provide cross-
domain regularization guidance.
</bodyText>
<sectionHeader confidence="0.998451" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999963631578947">
We presented variance-regularization SVMs, an
approach to learning that creates better classi-
fiers using fewer training examples. Variance reg-
ularization incorporates a bias for known good
weights into the SVM’s quadratic program. The
VAR-SVM can therefore exploit extra knowledge
by the system designer. Since the objective re-
mains a convex quadratic function of the weights,
the program is computationally no harder to opti-
mize than a standard SVM. We also demonstrated
how to design multi-class SVMs using only class-
specific attributes, and compared the performance
of this approach to standard multi-class SVMs on
the task of preposition selection.
While variance regularization is most helpful on
tasks with many classes and features, like prepo-
sition selection, it achieved gains on all our tasks
when training with smaller sample sizes. It should
be useful on a variety of other NLP problems.
</bodyText>
<page confidence="0.998303">
179
</page>
<sectionHeader confidence="0.983698" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99992272">
Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani.
2006. Manifold regularization: A geometric frame-
work for learning from labeled and unlabeled exam-
ples. JMLR, 7:2399–2434.
Shane Bergsma, Dekang Lin, and Randy Goebel.
2008. Distributional identification of non-referential
pronouns. In ACL-08: HLT.
Shane Bergsma, Dekang Lin, and Randy Goebel.
2009. Web-scale N-gram models for lexical disam-
biguation. In IJCAI.
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In ACL.
Avrim Blum and Tom Mitchell. 1998. Combining la-
beled and unlabeled data with co-training. In COLT.
Thorsten Brants and Alex Franz. 2006. The Google
Web 1T 5-gram Corpus Version 1.1. LDC2006T13.
Martin Chodorow, Joel R. Tetreault, and Na-Rae Han.
2007. Detection of grammatical errors involving
prepositions. In ACL-SIGSEM Workshop on Prepo-
sitions.
Kenneth Church, Ted Hart, and Jianfeng Gao. 2007.
Compressing trigram language models with Golomb
coding. In EMNLP-CoNLL.
David Cohn, Les Atlas, and Richard Ladner. 1994. Im-
proving generalization with active learning. Mach.
Learn., 15(2):201–221.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Mach. Learn., 20(3):273–297.
CPLEX. 2005. IBM ILOG CPLEX 9.1. www.ilog.
com/products/cplex/.
Koby Crammer and Yoram Singer. 2001. On the algo-
rithmic implementation of multiclass kernel-based
vector machines. JMLR, 2:265–292.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
JMLR, 3:951–991.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. JMLR, 7:551–585.
Hal Daum´e III. 2007. Frustratingly easy domain adap-
tation. In ACL.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
ICML.
Richard O. Duda and Peter E. Hart. 1973. Pattern
Classification and Scene Analysis. John Wiley &amp;
Sons.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLIN-
EAR: A library for large linear classification. JMLR,
9:1871–1874.
Andrew R. Golding and Dan Roth. 1999. A Winnow-
based approach to context-sensitive spelling correc-
tion. Mach. Learn., 34(1-3):107–130.
Sariel Har-Peled, Dan Roth, and Dav Zimak. 2003.
Constraint classification for multiclass classification
and ranking. In NIPS.
Graeme Hirst and Alexander Budanitsky. 2005. Cor-
recting real-word spelling errors by restoring lexical
cohesion. Nat. Lang. Eng., 11(1):87–111.
Chih-Wei Hsu and Chih-Jen Lin. 2002. A comparison
of methods for multiclass support vector machines.
IEEE Trans. Neur. Networks, 13(2):415–425.
Thorsten Joachims, Thomas Finley, and Chun-
Nam John Yu. 2009. Cutting-plane training of
structural SVMs. Mach. Learn., 77(1):27–59.
Thorsten Joachims. 2002. Optimizing search engines
using clickthrough data. In KDD.
Thorsten Joachims. 2006. Training linear SVMs in
linear time. In KDD.
Terry Koo, Xavier Carreras, and Michael Collins.
2008. Simple semi-supervised dependency parsing.
In ACL-08: HLT.
Irene Kotsia, Stefanos Zafeiriou, and Ioannis Pitas.
2009. Novel multiclass classifiers based on the min-
imization of the within-class variance. IEEE Trans.
Neur. Networks, 20(1):14–34.
Mirella Lapata and Frank Keller. 2005. Web-based
models for natural language processing. ACM
Trans. Speech and Language Processing, 2(1):1–31.
David McClosky, Eugene Charniak, and Mark John-
son. 2006. Effective self-training for parsing. In
HLT-NAACL.
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name tagging with word clusters and discrim-
inative training. In HLT-NAACL.
Andrew Y. Ng and Michael I. Jordan. 2002. Discrim-
inative vs. generative classifiers: A comparison of
logistic regression and naive bayes. In NIPS.
Vincent Ng. 2009. Graph-cut-based anaphoricity de-
termination for coreference resolution. In NAACL-
HLT.
Franz J. Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statistical
machine translation. In ACL.
Daisuke Okanohara and Jun’ichi Tsujii. 2007. A dis-
criminative language model with pseudo-negative
samples. In ACL.
</reference>
<page confidence="0.973269">
180
</page>
<reference confidence="0.998072720930233">
Chris D. Paice and Gareth D. Husk. 1987. Towards the
automatic recognition of anaphoric features in En-
glish text: the impersonal pronoun “it”. Computer
Speech and Language, 2:109–132.
Rajat Raina, Andrew Y. Ng, and Daphne Koller. 2006.
Constructing informative priors using transfer learn-
ing. In ICML.
Ryan Rifkin and Aldebaro Klautau. 2004. In defense
of one-vs-all classification. JMLR, 5:101–141.
Noah A. Smith and Jason Eisner. 2005. Contrastive
estimation: training log-linear models on unlabeled
data. In ACL.
Anastasios Tefas, Constantine Kotropoulos, and Ioan-
nis Pitas. 2001. Using support vector machines to
enhance the performance of elastic graph matching
for frontal face authentication. IEEE Trans. Pattern
Anal. Machine Intell., 23:735–746.
Joel R. Tetreault and Martin Chodorow. 2008. The
ups and downs of preposition error detection in ESL
writing. In COLING.
Simon Tong and Daphne Koller. 2002. Support vec-
tor machine active learning with applications to text
classification. JMLR, 2:45–66.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas
Hofmann, and Yasemin Altun. 2005. Large mar-
gin methods for structured and interdependent out-
put variables. JMLR, 6:1453–1484.
Vladimir N. Vapnik. 1998. Statistical Learning The-
ory. John Wiley &amp; Sons.
Qin Iris Wang, Colin Cherry, Dan Lizotte, and Dale
Schuurmans. 2006. Improved large margin depen-
dency parsing via local constraints and Laplacian
regularization. In CoNLL.
Jason Weston and Chris Watkins. 1998. Multi-class
support vector machines. Technical Report CSD-
TR-98-04, Department of Computer Science, Royal
Holloway, University of London.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In ACL.
Omar Zaidan, Jason Eisner, and Christine Piatko.
2007. Using “annotator rationales” to improve ma-
chine learning for text categorization. In NAACL-
HLT.
</reference>
<page confidence="0.998346">
181
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.943751">
<title confidence="0.9980175">Improved Natural Language Learning Variance-Regularization Support Vector Machines</title>
<author confidence="0.999927">Shane Bergsma Dekang Lin Dale Schuurmans</author>
<affiliation confidence="0.999641">University of Alberta Google, Inc. University of Alberta</affiliation>
<email confidence="0.962087">sbergsma@ualberta.calindek@google.comdale@cs.ualberta.ca</email>
<abstract confidence="0.998837692307692">We present a simple technique for learning better SVMs using fewer training examples. Rather than using the standard SVM regularization, we regularize toward low weight-variance. Our new SVM objective remains a convex quadratic function of the weights, and is therefore computationally no harder to optimize than a standard SVM. Variance regularization is shown to enable dramatic improvements in the learning rates of SVMs on three lexical disambiguation tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mikhail Belkin</author>
<author>Partha Niyogi</author>
<author>Vikas Sindhwani</author>
</authors>
<title>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--2399</pages>
<contexts>
<context position="30017" citStr="Belkin et al., 2006" startWordPosition="5016" endWordPosition="5019">imization freely set the weight to minimize training error. With more freedom, the new classifier (VAR-SVM+FreeB) performs worse with 10 examples, but exceeds the unsupervised approach with 100 training points. Although this was somewhat successful, developing better strategies for bias remains useful future work. 5 Related Work There is a large body of work on regularization in machine learning, including work that uses positive semi-definite matrices in the SVM quadratic program. The graph Laplacian has been used to encourage geometrically-similar feature vectors to be classified similarly (Belkin et al., 2006). An appealing property of these approaches is that they incorporate information from unlabeled examples. Wang et al. (2006) use Laplacian regularization for the task of dependency parsing. They regularize such that features for distributionally-similar words have similar weights. Rather than penalize pairwise differences proportional to a similarity function, we simply penalize weight variance. In the field of computer vision, Tefas et al. (2001) (binary) and Kotsia et al. (2009) (multiclass) also regularize weights with respect to a covariance matrix. They use labeled data to find the sum of</context>
</contexts>
<marker>Belkin, Niyogi, Sindhwani, 2006</marker>
<rawString>Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani. 2006. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. JMLR, 7:2399–2434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Distributional identification of non-referential pronouns.</title>
<date>2008</date>
<booktitle>In ACL-08: HLT.</booktitle>
<contexts>
<context position="27191" citStr="Bergsma et al., 2008" startWordPosition="4558" endWordPosition="4561">AR-SVM+FreeB 64.2 80.3 84.5 Table 3: Accuracy (%) of non-referential detection SVMs. Unsupervised accuracy is 80.1%. performs as well as the augmented CS-SVM+ using an order of magnitude less training data (Table 2). Differences from &lt;1K are significant. 4.3 Non-Referential Pronoun Detection Non-referential detection predicts whether the English pronoun it refers to a preceding noun (“it lost money”) or is used as a grammatical placeholder (“it is important to...”). This binary classification is a necessary but often neglected step for noun phrase coreference resolution (Paice and Husk, 1987; Bergsma et al., 2008; Ng, 2009). Bergsma et al. (2008) use features for the counts of various fillers in the pronoun’s context patterns. If it is the most common filler, the pronoun is likely non-referential. If other fillers are common (like they or he), it is likely a referential instance. For example, “he lost money” is common on the web, but “he is important to” is not. We use the same fillers as in previous work, and preprocess the N-gram corpus in the same way. The unsupervised system picks non-referential if the difference between the summed count of it fillers and the summed count of they fillers is above</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Distributional identification of non-referential pronouns. In ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Web-scale N-gram models for lexical disambiguation.</title>
<date>2009</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="2231" citStr="Bergsma et al., 2009" startWordPosition="343" endWordPosition="346">ck (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on the word’s context. Possible labels include part-ofspeech tags, named-entity types, and word senses. A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine (Lapata and Keller, 2005) or N-gram corpus (Bergsma et al., 2009). When discriminative training is used to weigh the counts for classification, many of the learned feature weights have similar values. Good weights have low variance. For example, consider the task of preposition selection. A system selects the most likely preposition given the context, and flags a possible error if it disagrees with the user’s choice: • I worked in Russia from 1997 to 2001. • I worked in Russia *during 1997 to 2001. Bergsma et al. (2009) use a variety of web counts to predict the correct preposition. They have features for COUNT(in Russia from), COUNT(Russia from 1997), COUN</context>
<context position="4836" citStr="Bergsma et al. (2009)" startWordPosition="747" endWordPosition="750">sia during 1997) is not only a feature for predicting the preposition during, but also for predicting the 33 other prepositions. The SVM must therefore learn to disregard many irrelevant features. We observe that this is not necessary, and develop an SVM that only uses the relevant attributes in the score for each class. Building on this efficient framework, we incorporate variance regularization into the SVM’s quadratic program. We apply our algorithms to three tasks: preposition selection, context-sensitive spelling correction, and non-referential pronoun detection (Section 4). We reproduce Bergsma et al. (2009)’s results using a multi-class SVM. Our new models achieve much better accuracy with fewer training examples. We also exceed the accuracy of a reasonable alternative technique for increasing the learning rate: including the output of the unsupervised system as a feature in the SVM. Variance regularization is an elegant addition to the suite of methods in NLP that improve performance when access to labeled data is limited. Section 5 discusses some related approaches. While we motivate our algorithm as a way to learn better weights when the features are counts from an auxiliary corpus, there are</context>
<context position="8536" citStr="Bergsma et al. (2009)" startWordPosition="1398" endWordPosition="1401">venience; it is included in popular SVM software like SVMmulticlass1 and LIBLINEAR (Fan et al., 2008). Note that with two classes, K-SVM is less efficient than a standard binary SVM. A binary classifier outputs class 1 if (w� · x� &gt; 0) and class 2 otherwise. The K-SVM encodes a binary classifier using � � W1 = w� and W2 = − w, therefore requiring twice the memory of a binary SVM. However, both binary and 2-class formulations have the same solution (Weston and Watkins, 1998). 1http://svmlight.joachims.org/svm multiclass.html 173 2.1.1 Web-Scale N-gram K-SVM K-SVM was used with N-gram models in Bergsma et al. (2009). For preposition selection, attributes were web counts of patterns filled with 34 prepositions, corresponding to the 34 classes. Each preposition serves as the filler of each context pattern. Fourteen patterns were used for each filler: all five 5-grams, four 4-grams, three 3-grams, and two 2- grams spanning the position to be predicted. There are N = 14*34 = 476 total attributes, and therefore KN = 476 * 34 = 16184 weights in W. This K-SVM classifier can potentially exploit very subtle information. Let Win and Wbefore be weights for the classes in and before. Notice some of the attributes we</context>
<context position="13728" citStr="Bergsma et al. (2009)" startWordPosition="2279" endWordPosition="2282">cale N-gram CS-SVM Returning to our preposition selection example, an obvious attribute partition for the CS-SVM is to include as attributes for predicting preposition r only those counts for patterns filled with preposition r. Thus xin will only include counts for context patterns filled with in and �xbefore will only include counts for context patterns filled with before. With 34 sub-vectors and 14 attributes in each, there are only 14 * 34 = 476 total weights. In contrast, K-SVM had 16184 weights to learn. It is instructive to compare the CS-SVM in (3) to the unsupervised SUMLM approach in Bergsma et al. (2009). That approach can be written as: K 11 xr} (5) H(x) = argmax r=1 where 1 is an N-dimensional vector of ones. This is CS-SVM with all weights set to unity. The counts for each preposition are simply summed, and whichever one scores the highest is taken as the output (actually only a subset of the counts are used, see Section 4.1). As mentioned earlier, this system performs remarkably well on several tasks. 2.3 Variance Regularization SVMs Suppose we choose our attribute partition well and train the CS-SVM on a sufficient number of examples to achieve good performance. It is a reasonable hypoth</context>
<context position="20331" citStr="Bergsma et al. (2009)" startWordPosition="3444" endWordPosition="3447">at most one in our experiments. Note it is straightforward to express this as a single covariance matrix regularizer over w; we omit the details. Alternatively, we could minimize the variance separately over all 5-gram patterns, then over all 4-gram patterns, etc., or over all patterns with a filler in the same position. In our experiments, we took a very simple approach: we minimized the variance of all attributes that are weighted equally in the unsupervised baselines. If a feature is not included in a baseline, it is regularized toward zero. 3 Experimental Details We use the data sets from Bergsma et al. (2009). These are the three tasks where web-scale N-gram counts were previously used as features in a standard K-SVM. In each case a classifier makes a decision for a particular word based on the word’s surrounding context. The attributes of the classifier are the log counts of different fillers occurring in the context patterns. We retrieve counts from the web-scale Google Web 5-gram Corpus (Brants and Franz, 2006), which includes N-grams of length one to five. We apply add-one smoothing to all counts. Every classifier also has bias features (for every class). We simply include, where appropriate, </context>
<context position="23391" citStr="Bergsma et al. (2009)" startWordPosition="3940" endWordPosition="3943">-SVM, and simultaneously minimize the norm of the 2-gram weights. 4.1.1 Results The majority-class is the preposition of; it occurs in 20.3% of test examples. The unsupervised system scores 73.7%. For further perspective on these results, note Chodorow et al. (2007) achieved 69% with 7M training examples, while Tetreault and Chodorow (2008) found the human performance was around 75%. However, these results are not directly comparable as they are on different data. Table 1 gives the accuracy for different amounts of training data. Here, as in the other tasks, K-SVM mirrors the learning rate in Bergsma et al. (2009). There are several distinct phases among the relative ranking of the systems. For smaller amounts of training data (≤1000 examples) K-SVM performs worst, while VAR-SVM is statistically significantly better than all other systems, and always exceeds the performance of the unsupervised approach.5 Augmenting the attributes with sum counts (the + systems) strongly helps with fewer examples, especially in conjunction with the more efficient CS-SVM. However, VAR-SVM clearly helps more. We noted earlier that VAR-SVM is guaranteed to do as well as the unsupervised system on the development data, but </context>
<context position="25476" citStr="Bergsma et al. (2009)" startWordPosition="4269" endWordPosition="4272">e spelling correction, or real-word error/malapropism detection (Golding and Roth, 1999; Hirst and Budanitsky, 2005), is the task of identifying errors when a misspelling results in a real word in the lexicon, e.g., using site when sight or cite was intended. Contextual spell checkers are among the most widely-used NLP technology, as they are included in commercial word processing software (Church et al., 2007). For every occurrence of a word in a pre-defined confusion set (e.g. {cite, sight, cite}), the classifier selects the most likely word from the set. We use the five confusion sets from Bergsma et al. (2009); four are binary and one is a 3-way classification. We use 100K training, 10K development, and 10K test examples for each, and average accuracy across the sets. All 2-to-5 gram counts are used in the unsupervised system, so the variance of all weights is regularized in VAR-SVM. 4.2.1 Results On this task, the majority-class baseline is much higher, 66.9%, and so is the accuracy of the top unsupervised system: 94.8%. Since four of the five sets are binary classifications, where K-SVM and CS-SVM are equivalent, we only give the accuracy of the CS-SVM (it does perform better on the one 3-way set</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2009</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2009. Web-scale N-gram models for lexical disambiguation. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32281" citStr="Blitzer et al., 2007" startWordPosition="5370" endWordPosition="5373">om the cumulative effect of previous updates. Dredze et al. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may lea</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="32492" citStr="Blum and Mitchell, 1998" startWordPosition="5402" endWordPosition="5405">ieve new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationship between attributes and classes may be explicit when, e.g., a rule-based system is optimized via discriminative learning, or annotators justify their decis</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<booktitle>The Google Web 1T 5-gram Corpus Version</booktitle>
<volume>1</volume>
<pages>2006--13</pages>
<contexts>
<context position="20744" citStr="Brants and Franz, 2006" startWordPosition="3514" endWordPosition="3517">ributes that are weighted equally in the unsupervised baselines. If a feature is not included in a baseline, it is regularized toward zero. 3 Experimental Details We use the data sets from Bergsma et al. (2009). These are the three tasks where web-scale N-gram counts were previously used as features in a standard K-SVM. In each case a classifier makes a decision for a particular word based on the word’s surrounding context. The attributes of the classifier are the log counts of different fillers occurring in the context patterns. We retrieve counts from the web-scale Google Web 5-gram Corpus (Brants and Franz, 2006), which includes N-grams of length one to five. We apply add-one smoothing to all counts. Every classifier also has bias features (for every class). We simply include, where appropriate, attributes that are always unity. We use LIBLINEAR (Fan et al., 2008) to train K-SVM and OvA-SVM, and SVMrank (Joachims, 2006) to train CS-SVM. For VAR-SVM, we solve the primal form of the quadratic program directly in CPLEX (2005), a general optimization package. We vary the number of training examples for each classifier. The C-parameters of all SVMs are tuned on development data. We evaluate using accuracy:</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. The Google Web 1T 5-gram Corpus Version 1.1. LDC2006T13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Joel R Tetreault</author>
<author>Na-Rae Han</author>
</authors>
<title>Detection of grammatical errors involving prepositions.</title>
<date>2007</date>
<booktitle>In ACL-SIGSEM Workshop on Prepositions.</booktitle>
<contexts>
<context position="21977" citStr="Chodorow et al., 2007" startWordPosition="3715" endWordPosition="3718">tage of test examples that are classified correctly. We also provide the accuracy of the majority-class baseline and best unsupervised system, as defined in Bergsma et al. (2009). As an alternative way to increase the learning rate, we augment a classifier’s features using the output of the unsupervised system: For each class, we include one feature for the sum of all counts (in the unsupervised system) that predict that class. We denote these augmented systems with a + as in K-SVM+ and CS-SVM+. 4 Applications 4.1 Preposition Selection Preposition errors are common among new English speakers (Chodorow et al., 2007). Systems that can reliably identify these errors are needed in word processing and educational software. 176 Training Examples System 10 100 1K 10K 100K OvA-SVM 16.0 50.6 66.1 71.1 73.5 K-SVM 13.7 50.0 65.8 72.0 74.7 K-SVM+ 22.2 56.8 70.5 73.7 75.2 CS-SVM 27.1 58.8 69.0 73.5 74.2 CS-SVM+ 39.6 64.8 71.5 74.0 74.4 VAR-SVM 73.8 74.2 74.7 74.9 74.9 Table 1: Accuracy (%) of preposition-selection SVMs. Unsupervised accuracy is 73.7%. In our experiments, a classifier must choose the correct preposition among 34 candidates, using counts for filled 2-to-5-gram patterns. We use 100K training, 10K devel</context>
</contexts>
<marker>Chodorow, Tetreault, Han, 2007</marker>
<rawString>Martin Chodorow, Joel R. Tetreault, and Na-Rae Han. 2007. Detection of grammatical errors involving prepositions. In ACL-SIGSEM Workshop on Prepositions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Ted Hart</author>
<author>Jianfeng Gao</author>
</authors>
<title>Compressing trigram language models with Golomb coding.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="25269" citStr="Church et al., 2007" startWordPosition="4232" endWordPosition="4235">se of it. On the other hand, feature augmentation and variance regularization provide diminishing returns as the amount of training data increases. 4.2 Context-Sensitive Spelling Correction Context-sensitive spelling correction, or real-word error/malapropism detection (Golding and Roth, 1999; Hirst and Budanitsky, 2005), is the task of identifying errors when a misspelling results in a real word in the lexicon, e.g., using site when sight or cite was intended. Contextual spell checkers are among the most widely-used NLP technology, as they are included in commercial word processing software (Church et al., 2007). For every occurrence of a word in a pre-defined confusion set (e.g. {cite, sight, cite}), the classifier selects the most likely word from the set. We use the five confusion sets from Bergsma et al. (2009); four are binary and one is a 3-way classification. We use 100K training, 10K development, and 10K test examples for each, and average accuracy across the sets. All 2-to-5 gram counts are used in the unsupervised system, so the variance of all weights is regularized in VAR-SVM. 4.2.1 Results On this task, the majority-class baseline is much higher, 66.9%, and so is the accuracy of the top </context>
</contexts>
<marker>Church, Hart, Gao, 2007</marker>
<rawString>Kenneth Church, Ted Hart, and Jianfeng Gao. 2007. Compressing trigram language models with Golomb coding. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Cohn</author>
<author>Les Atlas</author>
<author>Richard Ladner</author>
</authors>
<title>Improving generalization with active learning.</title>
<date>1994</date>
<location>Mach. Learn.,</location>
<contexts>
<context position="32336" citStr="Cohn et al., 1994" startWordPosition="5380" endWordPosition="5383">. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationshi</context>
</contexts>
<marker>Cohn, Atlas, Ladner, 1994</marker>
<rawString>David Cohn, Les Atlas, and Richard Ladner. 1994. Improving generalization with active learning. Mach. Learn., 15(2):201–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<location>Mach. Learn.,</location>
<contexts>
<context position="1317" citStr="Cortes and Vapnik, 1995" startWordPosition="193" endWordPosition="196"> disambiguation tasks. 1 Introduction Discriminative training is commonly used in NLP and speech to scale the contribution of different models or systems in a combined predictor. For example, discriminative training can be used to scale the contribution of the language model and translation model in machine translation (Och and Ney, 2002). Without training data, it is often reasonable to weight the different models equally. We propose a simple technique that exploits this intuition for better learning with fewer training examples. We regularize the feature weights in a Support Vector Machine (Cortes and Vapnik, 1995) toward a low-variance solution. Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective. When training data is generated through human effort, faster learning saves time and money. When examples are labeled automatically, through user feedback (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on</context>
<context position="6224" citStr="Cortes and Vapnik, 1995" startWordPosition="973" endWordPosition="976">e three max-margin multi-class classifiers and their corresponding quadratic programs. Although we describe linear SVMs, they can be extended to nonlinear cases in the standard way by writing the optimal function as a linear combination of kernel functions over the input examples. In each case, after providing the general technique, we relate the approach to our motivating application: learning weights for count features in a discriminative web-scale N-gram model. 2.1 Standard Multi-Class SVM We define a K-class SVM following Crammer and Singer (2001). This is a generalization of binary SVMs (Cortes and Vapnik, 1995). We have a set {(x1, y1), ..., (xm, ym)} of M training examples. Each x� is an N-dimensional attribute vector, and y ∈ {1, ..., K} are classes. A classifier, H, maps an attribute vector, x, to a class, y. H is parameterized by a K-by-N matrix of weights, W: HW(x) = argmax K { Wr · 4 (1) r=1 where Wr is the rth row of W. That is, the predicted label is the index of the row of W that has the highest inner-product with the attributes, x. We seek weights such that the classifier makes few errors on training data and generalizes well to unseen data. There are KN weights to learn, for the cross-pro</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Mach. Learn., 20(3):273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CPLEX</author>
</authors>
<date>2005</date>
<journal>IBM ILOG CPLEX</journal>
<volume>9</volume>
<note>www.ilog. com/products/cplex/.</note>
<contexts>
<context position="21162" citStr="CPLEX (2005)" startWordPosition="3585" endWordPosition="3586">he attributes of the classifier are the log counts of different fillers occurring in the context patterns. We retrieve counts from the web-scale Google Web 5-gram Corpus (Brants and Franz, 2006), which includes N-grams of length one to five. We apply add-one smoothing to all counts. Every classifier also has bias features (for every class). We simply include, where appropriate, attributes that are always unity. We use LIBLINEAR (Fan et al., 2008) to train K-SVM and OvA-SVM, and SVMrank (Joachims, 2006) to train CS-SVM. For VAR-SVM, we solve the primal form of the quadratic program directly in CPLEX (2005), a general optimization package. We vary the number of training examples for each classifier. The C-parameters of all SVMs are tuned on development data. We evaluate using accuracy: the percentage of test examples that are classified correctly. We also provide the accuracy of the majority-class baseline and best unsupervised system, as defined in Bergsma et al. (2009). As an alternative way to increase the learning rate, we augment a classifier’s features using the output of the unsupervised system: For each class, we include one feature for the sum of all counts (in the unsupervised system) </context>
</contexts>
<marker>CPLEX, 2005</marker>
<rawString>CPLEX. 2005. IBM ILOG CPLEX 9.1. www.ilog. com/products/cplex/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>On the algorithmic implementation of multiclass kernel-based vector machines.</title>
<date>2001</date>
<journal>JMLR,</journal>
<pages>2--265</pages>
<contexts>
<context position="6157" citStr="Crammer and Singer (2001)" startWordPosition="962" endWordPosition="965">tions for future research. 2 Three Multi-Class SVM Models We describe three max-margin multi-class classifiers and their corresponding quadratic programs. Although we describe linear SVMs, they can be extended to nonlinear cases in the standard way by writing the optimal function as a linear combination of kernel functions over the input examples. In each case, after providing the general technique, we relate the approach to our motivating application: learning weights for count features in a discriminative web-scale N-gram model. 2.1 Standard Multi-Class SVM We define a K-class SVM following Crammer and Singer (2001). This is a generalization of binary SVMs (Cortes and Vapnik, 1995). We have a set {(x1, y1), ..., (xm, ym)} of M training examples. Each x� is an N-dimensional attribute vector, and y ∈ {1, ..., K} are classes. A classifier, H, maps an attribute vector, x, to a class, y. H is parameterized by a K-by-N matrix of weights, W: HW(x) = argmax K { Wr · 4 (1) r=1 where Wr is the rth row of W. That is, the predicted label is the index of the row of W that has the highest inner-product with the attributes, x. We seek weights such that the classifier makes few errors on training data and generalizes we</context>
<context position="7834" citStr="Crammer and Singer (2001)" startWordPosition="1274" endWordPosition="1277">gle constrained optimization (Vapnik, 1998; Weston and Watkins, 1998). Following the soft-margin version in Crammer and Singer (2001): mint 1 K ||�Wi||2 + C M ξi W IV I... Ib m 2 i=1 i=1 subject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-SVM. The K-SVM outperformed the OvA-SVM in Crammer and Singer (2001), but see Rifkin and Klautau (2004). The popularity of K-SVM is partly due to convenience; it is included in popular SVM software like SVMmulticlass1 and LIBLINEAR (Fan et al., 2008). Note that with two classes, K-SVM is less efficient than a standard binary SVM. A binary classifier outputs class 1 if (w� · x� &gt; 0) and class 2 otherwise. The K-SVM encodes a binary classifier using � � W1 = w� and W2 = − w, therefore requiring twice the memory of a binary SVM. However, both binary and 2-class formulations have the same solution (Weston and Watkins, 1998). 1http://svmlight.joachims.org/svm multi</context>
<context position="12927" citStr="Crammer and Singer, 2001" startWordPosition="2144" endWordPosition="2147">a and Hart, 1973; Crammer and Singer, 2003). We then create binary rank constraints for a ranking SVM (Joachims, 2002) (ranking SVMs reduce to standard binary SVMs). We create K instances for each multi-class example (V, yi), with the transformed vector of the true class, zyi, assigned a higher-rank than all the other, equally-ranked classes, 2{r�yi}. Training a ranking SVM using these constraints gives the same weights as solving (4), but allows us to use efficient, custom SVM software.2 Note the K-SVM 2One subtlety is whether to use a single slack, �i, for all K-1 constraints per example i (Crammer and Singer, 2001), or a different slack for each constraint (Joachims, 2002). Us174 can also be trained this way, by including every attribute in every sub-vector, as described earlier. 2.2.2 Web-Scale N-gram CS-SVM Returning to our preposition selection example, an obvious attribute partition for the CS-SVM is to include as attributes for predicting preposition r only those counts for patterns filled with preposition r. Thus xin will only include counts for context patterns filled with in and �xbefore will only include counts for context patterns filled with before. With 34 sub-vectors and 14 attributes in ea</context>
</contexts>
<marker>Crammer, Singer, 2001</marker>
<rawString>Koby Crammer and Yoram Singer. 2001. On the algorithmic implementation of multiclass kernel-based vector machines. JMLR, 2:265–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>JMLR,</journal>
<pages>3--951</pages>
<contexts>
<context position="12345" citStr="Crammer and Singer, 2003" startWordPosition="2045" endWordPosition="2049">ransformation into a binary SVM, we can take advantage of efficient, custom SVM optimization algorithms. We follow Har-Peled et al. (2003) in transforming a multi-class example into a set of binary examples, each specifying a constraint from (4). We extend the attribute sub-vector corresponding to each class to be N-dimensional. We do this by substituting zero-vectors for all the other subvectors in the partition. The attribute vector for the rth class is then zr = (0, ..., 0, xr, 0, ..., 0). This is known as Kesler’s Construction and has a long history in classification (Duda and Hart, 1973; Crammer and Singer, 2003). We then create binary rank constraints for a ranking SVM (Joachims, 2002) (ranking SVMs reduce to standard binary SVMs). We create K instances for each multi-class example (V, yi), with the transformed vector of the true class, zyi, assigned a higher-rank than all the other, equally-ranked classes, 2{r�yi}. Training a ranking SVM using these constraints gives the same weights as solving (4), but allows us to use efficient, custom SVM software.2 Note the K-SVM 2One subtlety is whether to use a single slack, �i, for all K-1 constraints per example i (Crammer and Singer, 2001), or a different s</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. JMLR, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--551</pages>
<contexts>
<context position="31512" citStr="Crammer et al. (2006)" startWordPosition="5251" endWordPosition="5254">data to generate. In a Bayesian setting, Raina et al. (2006) model 178 feature correlations in a logistic regression classifier. They propose a method to construct a covariance matrix for a multivariate Gaussian prior on the classifier’s weights. Labeled data for other, related tasks is used to infer potentially correlated features on the target task. Like in our results, they found that the gains from modeling dependencies diminish as more training data is available. We also mention two related online learning approaches. Similar to our goal of regularizing toward a good unsupervised system, Crammer et al. (2006) regularize w� toward a (different) target vector at each update, rather than strictly minimizing ||�w||2. The target vector is the vector learned from the cumulative effect of previous updates. Dredze et al. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general featur</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly easy domain adaptation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="31727" citStr="Dredze et al. (2008)" startWordPosition="5285" endWordPosition="5288">r on the classifier’s weights. Labeled data for other, related tasks is used to infer potentially correlated features on the target task. Like in our results, they found that the gains from modeling dependencies diminish as more training data is available. We also mention two related online learning approaches. Similar to our goal of regularizing toward a good unsupervised system, Crammer et al. (2006) regularize w� toward a (different) target vector at each update, rather than strictly minimizing ||�w||2. The target vector is the vector learned from the cumulative effect of previous updates. Dredze et al. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et </context>
</contexts>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard O Duda</author>
<author>Peter E Hart</author>
</authors>
<title>Pattern Classification and Scene Analysis.</title>
<date>1973</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="12318" citStr="Duda and Hart, 1973" startWordPosition="2041" endWordPosition="2044">rough an equivalent transformation into a binary SVM, we can take advantage of efficient, custom SVM optimization algorithms. We follow Har-Peled et al. (2003) in transforming a multi-class example into a set of binary examples, each specifying a constraint from (4). We extend the attribute sub-vector corresponding to each class to be N-dimensional. We do this by substituting zero-vectors for all the other subvectors in the partition. The attribute vector for the rth class is then zr = (0, ..., 0, xr, 0, ..., 0). This is known as Kesler’s Construction and has a long history in classification (Duda and Hart, 1973; Crammer and Singer, 2003). We then create binary rank constraints for a ranking SVM (Joachims, 2002) (ranking SVMs reduce to standard binary SVMs). We create K instances for each multi-class example (V, yi), with the transformed vector of the true class, zyi, assigned a higher-rank than all the other, equally-ranked classes, 2{r�yi}. Training a ranking SVM using these constraints gives the same weights as solving (4), but allows us to use efficient, custom SVM software.2 Note the K-SVM 2One subtlety is whether to use a single slack, �i, for all K-1 constraints per example i (Crammer and Sing</context>
</contexts>
<marker>Duda, Hart, 1973</marker>
<rawString>Richard O. Duda and Peter E. Hart. 1973. Pattern Classification and Scene Analysis. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>JMLR,</journal>
<pages>9--1871</pages>
<contexts>
<context position="8016" citStr="Fan et al., 2008" startWordPosition="1305" endWordPosition="1308">ject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-SVM. The K-SVM outperformed the OvA-SVM in Crammer and Singer (2001), but see Rifkin and Klautau (2004). The popularity of K-SVM is partly due to convenience; it is included in popular SVM software like SVMmulticlass1 and LIBLINEAR (Fan et al., 2008). Note that with two classes, K-SVM is less efficient than a standard binary SVM. A binary classifier outputs class 1 if (w� · x� &gt; 0) and class 2 otherwise. The K-SVM encodes a binary classifier using � � W1 = w� and W2 = − w, therefore requiring twice the memory of a binary SVM. However, both binary and 2-class formulations have the same solution (Weston and Watkins, 1998). 1http://svmlight.joachims.org/svm multiclass.html 173 2.1.1 Web-Scale N-gram K-SVM K-SVM was used with N-gram models in Bergsma et al. (2009). For preposition selection, attributes were web counts of patterns filled with </context>
<context position="21000" citStr="Fan et al., 2008" startWordPosition="3556" endWordPosition="3559">ounts were previously used as features in a standard K-SVM. In each case a classifier makes a decision for a particular word based on the word’s surrounding context. The attributes of the classifier are the log counts of different fillers occurring in the context patterns. We retrieve counts from the web-scale Google Web 5-gram Corpus (Brants and Franz, 2006), which includes N-grams of length one to five. We apply add-one smoothing to all counts. Every classifier also has bias features (for every class). We simply include, where appropriate, attributes that are always unity. We use LIBLINEAR (Fan et al., 2008) to train K-SVM and OvA-SVM, and SVMrank (Joachims, 2006) to train CS-SVM. For VAR-SVM, we solve the primal form of the quadratic program directly in CPLEX (2005), a general optimization package. We vary the number of training examples for each classifier. The C-parameters of all SVMs are tuned on development data. We evaluate using accuracy: the percentage of test examples that are classified correctly. We also provide the accuracy of the majority-class baseline and best unsupervised system, as defined in Bergsma et al. (2009). As an alternative way to increase the learning rate, we augment a</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. JMLR, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>A Winnowbased approach to context-sensitive spelling correction.</title>
<date>1999</date>
<pages>34--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="24942" citStr="Golding and Roth, 1999" startWordPosition="4179" endWordPosition="4182">+ 91.0 94.9 95.3 95.7 95.7 VAR-SVM 94.9 95.3 95.6 95.7 95.8 Table 2: Accuracy (%) of spell-correction SVMs. Unsupervised accuracy is 94.8%. examples, while OvA-SVM is better than K-SVM for small amounts of data.6 K-SVM performs best with all the data; it uses the most expressive representation, but needs 100K examples to make use of it. On the other hand, feature augmentation and variance regularization provide diminishing returns as the amount of training data increases. 4.2 Context-Sensitive Spelling Correction Context-sensitive spelling correction, or real-word error/malapropism detection (Golding and Roth, 1999; Hirst and Budanitsky, 2005), is the task of identifying errors when a misspelling results in a real word in the lexicon, e.g., using site when sight or cite was intended. Contextual spell checkers are among the most widely-used NLP technology, as they are included in commercial word processing software (Church et al., 2007). For every occurrence of a word in a pre-defined confusion set (e.g. {cite, sight, cite}), the classifier selects the most likely word from the set. We use the five confusion sets from Bergsma et al. (2009); four are binary and one is a 3-way classification. We use 100K t</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>Andrew R. Golding and Dan Roth. 1999. A Winnowbased approach to context-sensitive spelling correction. Mach. Learn., 34(1-3):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sariel Har-Peled</author>
<author>Dan Roth</author>
<author>Dav Zimak</author>
</authors>
<title>Constraint classification for multiclass classification and ranking.</title>
<date>2003</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="11858" citStr="Har-Peled et al. (2003)" startWordPosition="1960" endWordPosition="1963">ch attribute. Also, some attributes may be predictive of multiple classes. In such cases, we can include ambiguous attributes in every sub-vector (needing N+D(K-1) total weights if D attributes are duplicated). In the degenerate case where every attribute is duplicated, CS-SVM is equivalent to K-SVM; both have KN weights. 2.2.1 Optimization as a Binary SVM We could solve the optimization problem in (4) directly using a quadratic programming solver. However, through an equivalent transformation into a binary SVM, we can take advantage of efficient, custom SVM optimization algorithms. We follow Har-Peled et al. (2003) in transforming a multi-class example into a set of binary examples, each specifying a constraint from (4). We extend the attribute sub-vector corresponding to each class to be N-dimensional. We do this by substituting zero-vectors for all the other subvectors in the partition. The attribute vector for the rth class is then zr = (0, ..., 0, xr, 0, ..., 0). This is known as Kesler’s Construction and has a long history in classification (Duda and Hart, 1973; Crammer and Singer, 2003). We then create binary rank constraints for a ranking SVM (Joachims, 2002) (ranking SVMs reduce to standard bina</context>
</contexts>
<marker>Har-Peled, Roth, Zimak, 2003</marker>
<rawString>Sariel Har-Peled, Dan Roth, and Dav Zimak. 2003. Constraint classification for multiclass classification and ranking. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>Alexander Budanitsky</author>
</authors>
<title>Correcting real-word spelling errors by restoring lexical cohesion.</title>
<date>2005</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="24971" citStr="Hirst and Budanitsky, 2005" startWordPosition="4183" endWordPosition="4186">.7 VAR-SVM 94.9 95.3 95.6 95.7 95.8 Table 2: Accuracy (%) of spell-correction SVMs. Unsupervised accuracy is 94.8%. examples, while OvA-SVM is better than K-SVM for small amounts of data.6 K-SVM performs best with all the data; it uses the most expressive representation, but needs 100K examples to make use of it. On the other hand, feature augmentation and variance regularization provide diminishing returns as the amount of training data increases. 4.2 Context-Sensitive Spelling Correction Context-sensitive spelling correction, or real-word error/malapropism detection (Golding and Roth, 1999; Hirst and Budanitsky, 2005), is the task of identifying errors when a misspelling results in a real word in the lexicon, e.g., using site when sight or cite was intended. Contextual spell checkers are among the most widely-used NLP technology, as they are included in commercial word processing software (Church et al., 2007). For every occurrence of a word in a pre-defined confusion set (e.g. {cite, sight, cite}), the classifier selects the most likely word from the set. We use the five confusion sets from Bergsma et al. (2009); four are binary and one is a 3-way classification. We use 100K training, 10K development, and</context>
</contexts>
<marker>Hirst, Budanitsky, 2005</marker>
<rawString>Graeme Hirst and Alexander Budanitsky. 2005. Correcting real-word spelling errors by restoring lexical cohesion. Nat. Lang. Eng., 11(1):87–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Wei Hsu</author>
<author>Chih-Jen Lin</author>
</authors>
<title>A comparison of methods for multiclass support vector machines.</title>
<date>2002</date>
<journal>IEEE Trans. Neur. Networks,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="7166" citStr="Hsu and Lin, 2002" startWordPosition="1151" endWordPosition="1154">hat is, the predicted label is the index of the row of W that has the highest inner-product with the attributes, x. We seek weights such that the classifier makes few errors on training data and generalizes well to unseen data. There are KN weights to learn, for the cross-product of attributes and classes. The most common approach is to train K separate one-versus-all binary SVMs, one for each class. The weights learned for the rth SVM provide the weights Wr in (1). We call this approach OvA-SVM. Note in some settings various oneversus-one strategies may be more effective than one-versus-all (Hsu and Lin, 2002). The weights can also be found using a single constrained optimization (Vapnik, 1998; Weston and Watkins, 1998). Following the soft-margin version in Crammer and Singer (2001): mint 1 K ||�Wi||2 + C M ξi W IV I... Ib m 2 i=1 i=1 subject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-</context>
</contexts>
<marker>Hsu, Lin, 2002</marker>
<rawString>Chih-Wei Hsu and Chih-Jen Lin. 2002. A comparison of methods for multiclass support vector machines. IEEE Trans. Neur. Networks, 13(2):415–425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
<author>Thomas Finley</author>
<author>ChunNam John Yu</author>
</authors>
<title>Cutting-plane training of structural SVMs.</title>
<date>2009</date>
<journal>Mach. Learn.,</journal>
<volume>77</volume>
<issue>1</issue>
<contexts>
<context position="33748" citStr="Joachims et al., 2009" startWordPosition="5606" endWordPosition="5609">tributes (Zaidan et al., 2007). Also, if features are a priori thought to have different predictive worth, the attribute values could be scaled such that variance regularization, as we formulated it, has the desired effect. Other avenues of future work will be to extend the VAR-SVM in three directions: efficiency, representational power, and problem domain. While we optimized the VAR-SVM objective in CPLEX, general purpose QP-solvers “do not exploit the special structure of [the SVM optimization] problem,” and consequently often train in time super-linear with the number of training examples (Joachims et al., 2009). It would be useful to fit our optimization problem to efficient SVM training methods, especially for linear classifiers. VAR-SVM’s representational power could be extended by using non-linear SVMs. Kernels can be used with a covariance regularizer (Kotsia et al., 2009). Since C is positive semi-definite, the square root of its inverse is defined. We can therefore map the input examples using (C−21x), and write an equivalent objective function in terms of kernel functions over the transformed examples. Also, since structured-prediction SVMs build on the multi-class framework (Tsochantaridis e</context>
</contexts>
<marker>Joachims, Finley, Yu, 2009</marker>
<rawString>Thorsten Joachims, Thomas Finley, and ChunNam John Yu. 2009. Cutting-plane training of structural SVMs. Mach. Learn., 77(1):27–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="1629" citStr="Joachims, 2002" startWordPosition="245" endWordPosition="246">(Och and Ney, 2002). Without training data, it is often reasonable to weight the different models equally. We propose a simple technique that exploits this intuition for better learning with fewer training examples. We regularize the feature weights in a Support Vector Machine (Cortes and Vapnik, 1995) toward a low-variance solution. Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective. When training data is generated through human effort, faster learning saves time and money. When examples are labeled automatically, through user feedback (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on the word’s context. Possible labels include part-ofspeech tags, named-entity types, and word senses. A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine (Lapata and Keller, 2005) or N-gram corpus (Bergsma et al., 200</context>
<context position="12420" citStr="Joachims, 2002" startWordPosition="2060" endWordPosition="2061">ization algorithms. We follow Har-Peled et al. (2003) in transforming a multi-class example into a set of binary examples, each specifying a constraint from (4). We extend the attribute sub-vector corresponding to each class to be N-dimensional. We do this by substituting zero-vectors for all the other subvectors in the partition. The attribute vector for the rth class is then zr = (0, ..., 0, xr, 0, ..., 0). This is known as Kesler’s Construction and has a long history in classification (Duda and Hart, 1973; Crammer and Singer, 2003). We then create binary rank constraints for a ranking SVM (Joachims, 2002) (ranking SVMs reduce to standard binary SVMs). We create K instances for each multi-class example (V, yi), with the transformed vector of the true class, zyi, assigned a higher-rank than all the other, equally-ranked classes, 2{r�yi}. Training a ranking SVM using these constraints gives the same weights as solving (4), but allows us to use efficient, custom SVM software.2 Note the K-SVM 2One subtlety is whether to use a single slack, �i, for all K-1 constraints per example i (Crammer and Singer, 2001), or a different slack for each constraint (Joachims, 2002). Us174 can also be trained this w</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear SVMs in linear time.</title>
<date>2006</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="21057" citStr="Joachims, 2006" startWordPosition="3567" endWordPosition="3568"> In each case a classifier makes a decision for a particular word based on the word’s surrounding context. The attributes of the classifier are the log counts of different fillers occurring in the context patterns. We retrieve counts from the web-scale Google Web 5-gram Corpus (Brants and Franz, 2006), which includes N-grams of length one to five. We apply add-one smoothing to all counts. Every classifier also has bias features (for every class). We simply include, where appropriate, attributes that are always unity. We use LIBLINEAR (Fan et al., 2008) to train K-SVM and OvA-SVM, and SVMrank (Joachims, 2006) to train CS-SVM. For VAR-SVM, we solve the primal form of the quadratic program directly in CPLEX (2005), a general optimization package. We vary the number of training examples for each classifier. The C-parameters of all SVMs are tuned on development data. We evaluate using accuracy: the percentage of test examples that are classified correctly. We also provide the accuracy of the majority-class baseline and best unsupervised system, as defined in Bergsma et al. (2009). As an alternative way to increase the learning rate, we augment a classifier’s features using the output of the unsupervis</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear SVMs in linear time. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In ACL-08: HLT.</booktitle>
<contexts>
<context position="32189" citStr="Koo et al., 2008" startWordPosition="5357" endWordPosition="5360">date, rather than strictly minimizing ||�w||2. The target vector is the vector learned from the cumulative effect of previous updates. Dredze et al. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps a</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Kotsia</author>
<author>Stefanos Zafeiriou</author>
<author>Ioannis Pitas</author>
</authors>
<title>Novel multiclass classifiers based on the minimization of the within-class variance.</title>
<date>2009</date>
<journal>IEEE Trans. Neur. Networks,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="30502" citStr="Kotsia et al. (2009)" startWordPosition="5089" endWordPosition="5092">. The graph Laplacian has been used to encourage geometrically-similar feature vectors to be classified similarly (Belkin et al., 2006). An appealing property of these approaches is that they incorporate information from unlabeled examples. Wang et al. (2006) use Laplacian regularization for the task of dependency parsing. They regularize such that features for distributionally-similar words have similar weights. Rather than penalize pairwise differences proportional to a similarity function, we simply penalize weight variance. In the field of computer vision, Tefas et al. (2001) (binary) and Kotsia et al. (2009) (multiclass) also regularize weights with respect to a covariance matrix. They use labeled data to find the sum of the sample covariance matrices from each class, similar to linear discriminant analysis. We propose the idea in general, and instantiate with a different C matrix: a variance regularizer over w. Most importantly, our instantiated covariance matrix does not require labeled data to generate. In a Bayesian setting, Raina et al. (2006) model 178 feature correlations in a logistic regression classifier. They propose a method to construct a covariance matrix for a multivariate Gaussian</context>
<context position="34019" citStr="Kotsia et al., 2009" startWordPosition="5647" endWordPosition="5650">e VAR-SVM in three directions: efficiency, representational power, and problem domain. While we optimized the VAR-SVM objective in CPLEX, general purpose QP-solvers “do not exploit the special structure of [the SVM optimization] problem,” and consequently often train in time super-linear with the number of training examples (Joachims et al., 2009). It would be useful to fit our optimization problem to efficient SVM training methods, especially for linear classifiers. VAR-SVM’s representational power could be extended by using non-linear SVMs. Kernels can be used with a covariance regularizer (Kotsia et al., 2009). Since C is positive semi-definite, the square root of its inverse is defined. We can therefore map the input examples using (C−21x), and write an equivalent objective function in terms of kernel functions over the transformed examples. Also, since structured-prediction SVMs build on the multi-class framework (Tsochantaridis et al., 2005), variance regularization can be incorporated naturally into more complex prediction tasks, such as parsers, taggers, and aligners. VAR-SVM may also help in new domains where annotated data is lacking. VAR-SVM should be stronger cross-domain than K-SVM; regul</context>
</contexts>
<marker>Kotsia, Zafeiriou, Pitas, 2009</marker>
<rawString>Irene Kotsia, Stefanos Zafeiriou, and Ioannis Pitas. 2009. Novel multiclass classifiers based on the minimization of the within-class variance. IEEE Trans. Neur. Networks, 20(1):14–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Frank Keller</author>
</authors>
<title>Web-based models for natural language processing.</title>
<date>2005</date>
<journal>ACM Trans. Speech and Language Processing,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="2191" citStr="Lapata and Keller, 2005" startWordPosition="335" endWordPosition="338"> labeled automatically, through user feedback (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on the word’s context. Possible labels include part-ofspeech tags, named-entity types, and word senses. A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine (Lapata and Keller, 2005) or N-gram corpus (Bergsma et al., 2009). When discriminative training is used to weigh the counts for classification, many of the learned feature weights have similar values. Good weights have low variance. For example, consider the task of preposition selection. A system selects the most likely preposition given the context, and flags a possible error if it disagrees with the user’s choice: • I worked in Russia from 1997 to 2001. • I worked in Russia *during 1997 to 2001. Bergsma et al. (2009) use a variety of web counts to predict the correct preposition. They have features for COUNT(in Rus</context>
</contexts>
<marker>Lapata, Keller, 2005</marker>
<rawString>Mirella Lapata and Frank Keller. 2005. Web-based models for natural language processing. ACM Trans. Speech and Language Processing, 2(1):1–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="32534" citStr="McClosky et al., 2006" startWordPosition="5409" endWordPosition="5412"> variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationship between attributes and classes may be explicit when, e.g., a rule-based system is optimized via discriminative learning, or annotators justify their decisions by indicating the relevant attributes</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="32170" citStr="Miller et al., 2004" startWordPosition="5353" endWordPosition="5356">get vector at each update, rather than strictly minimizing ||�w||2. The target vector is the vector learned from the cumulative effect of previous updates. Dredze et al. (2008) maintain the variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the fe</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes.</title>
<date>2002</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="10792" citStr="Ng and Jordan, 2002" startWordPosition="1787" endWordPosition="1790">ibute partition, w� = ( 17V1, ..., WK). The classifier is: H¯w(x) = argmax K {�wr · xr} (3) r=1 We call this classifier the CS-SVM (an SVM with Class-Specific attributes). The weights can be determined using the follow (soft-margin) optimization: min 1 UV w� + C �m ξi ¯w,ξ�,...,ξm 2 i=1 subject to :ξi &gt;0 br =� yi, wyi · xyi − wr · xr &gt;1 − ξi (4) There are several advantages to this formulation. Foremost, rather than having KN weights, it can have only N. For linear classifiers, the number of examples needed to reach optimum performance is at most linear in the number of weights (Vapnik, 1998; Ng and Jordan, 2002). In fact, both the total number and number of active features per example decrease by K. Thus this reduction saves far more memory than what could be obtained by an equal reduction in dimensionality via pruning infrequent attributes. Also, note that unlike the K-SVM (Section 2.1), in the binary case the CS-SVM is completely equivalent (thus equally efficient) to a standard SVM. We will not always a priori know the class associated with each attribute. Also, some attributes may be predictive of multiple classes. In such cases, we can include ambiguous attributes in every sub-vector (needing N+</context>
</contexts>
<marker>Ng, Jordan, 2002</marker>
<rawString>Andrew Y. Ng and Michael I. Jordan. 2002. Discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Graph-cut-based anaphoricity determination for coreference resolution.</title>
<date>2009</date>
<booktitle>In NAACLHLT.</booktitle>
<contexts>
<context position="27202" citStr="Ng, 2009" startWordPosition="4562" endWordPosition="4563"> 84.5 Table 3: Accuracy (%) of non-referential detection SVMs. Unsupervised accuracy is 80.1%. performs as well as the augmented CS-SVM+ using an order of magnitude less training data (Table 2). Differences from &lt;1K are significant. 4.3 Non-Referential Pronoun Detection Non-referential detection predicts whether the English pronoun it refers to a preceding noun (“it lost money”) or is used as a grammatical placeholder (“it is important to...”). This binary classification is a necessary but often neglected step for noun phrase coreference resolution (Paice and Husk, 1987; Bergsma et al., 2008; Ng, 2009). Bergsma et al. (2008) use features for the counts of various fillers in the pronoun’s context patterns. If it is the most common filler, the pronoun is likely non-referential. If other fillers are common (like they or he), it is likely a referential instance. For example, “he lost money” is common on the web, but “he is important to” is not. We use the same fillers as in previous work, and preprocess the N-gram corpus in the same way. The unsupervised system picks non-referential if the difference between the summed count of it fillers and the summed count of they fillers is above a threshol</context>
</contexts>
<marker>Ng, 2009</marker>
<rawString>Vincent Ng. 2009. Graph-cut-based anaphoricity determination for coreference resolution. In NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1033" citStr="Och and Ney, 2002" startWordPosition="146" endWordPosition="149">weight-variance. Our new SVM objective remains a convex quadratic function of the weights, and is therefore computationally no harder to optimize than a standard SVM. Variance regularization is shown to enable dramatic improvements in the learning rates of SVMs on three lexical disambiguation tasks. 1 Introduction Discriminative training is commonly used in NLP and speech to scale the contribution of different models or systems in a combined predictor. For example, discriminative training can be used to scale the contribution of the language model and translation model in machine translation (Och and Ney, 2002). Without training data, it is often reasonable to weight the different models equally. We propose a simple technique that exploits this intuition for better learning with fewer training examples. We regularize the feature weights in a Support Vector Machine (Cortes and Vapnik, 1995) toward a low-variance solution. Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective. When training data is generated through human effort, faster learning saves time and money. When examples are labeled automatically, through user feedback (Joachims, 2002) or </context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz J. Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Okanohara</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>A discriminative language model with pseudo-negative samples.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1714" citStr="Okanohara and Tsujii, 2007" startWordPosition="256" endWordPosition="259">ght the different models equally. We propose a simple technique that exploits this intuition for better learning with fewer training examples. We regularize the feature weights in a Support Vector Machine (Cortes and Vapnik, 1995) toward a low-variance solution. Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective. When training data is generated through human effort, faster learning saves time and money. When examples are labeled automatically, through user feedback (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on the word’s context. Possible labels include part-ofspeech tags, named-entity types, and word senses. A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine (Lapata and Keller, 2005) or N-gram corpus (Bergsma et al., 2009). When discriminative training is used to weigh the counts for classification, many</context>
</contexts>
<marker>Okanohara, Tsujii, 2007</marker>
<rawString>Daisuke Okanohara and Jun’ichi Tsujii. 2007. A discriminative language model with pseudo-negative samples. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris D Paice</author>
<author>Gareth D Husk</author>
</authors>
<title>Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun “it”. Computer Speech and Language,</title>
<date>1987</date>
<pages>2--109</pages>
<contexts>
<context position="27169" citStr="Paice and Husk, 1987" startWordPosition="4554" endWordPosition="4557">R-SVM 70.2 76.2 84.5 VAR-SVM+FreeB 64.2 80.3 84.5 Table 3: Accuracy (%) of non-referential detection SVMs. Unsupervised accuracy is 80.1%. performs as well as the augmented CS-SVM+ using an order of magnitude less training data (Table 2). Differences from &lt;1K are significant. 4.3 Non-Referential Pronoun Detection Non-referential detection predicts whether the English pronoun it refers to a preceding noun (“it lost money”) or is used as a grammatical placeholder (“it is important to...”). This binary classification is a necessary but often neglected step for noun phrase coreference resolution (Paice and Husk, 1987; Bergsma et al., 2008; Ng, 2009). Bergsma et al. (2008) use features for the counts of various fillers in the pronoun’s context patterns. If it is the most common filler, the pronoun is likely non-referential. If other fillers are common (like they or he), it is likely a referential instance. For example, “he lost money” is common on the web, but “he is important to” is not. We use the same fillers as in previous work, and preprocess the N-gram corpus in the same way. The unsupervised system picks non-referential if the difference between the summed count of it fillers and the summed count of</context>
</contexts>
<marker>Paice, Husk, 1987</marker>
<rawString>Chris D. Paice and Gareth D. Husk. 1987. Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun “it”. Computer Speech and Language, 2:109–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajat Raina</author>
<author>Andrew Y Ng</author>
<author>Daphne Koller</author>
</authors>
<title>Constructing informative priors using transfer learning.</title>
<date>2006</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="30951" citStr="Raina et al. (2006)" startWordPosition="5161" endWordPosition="5164">ferences proportional to a similarity function, we simply penalize weight variance. In the field of computer vision, Tefas et al. (2001) (binary) and Kotsia et al. (2009) (multiclass) also regularize weights with respect to a covariance matrix. They use labeled data to find the sum of the sample covariance matrices from each class, similar to linear discriminant analysis. We propose the idea in general, and instantiate with a different C matrix: a variance regularizer over w. Most importantly, our instantiated covariance matrix does not require labeled data to generate. In a Bayesian setting, Raina et al. (2006) model 178 feature correlations in a logistic regression classifier. They propose a method to construct a covariance matrix for a multivariate Gaussian prior on the classifier’s weights. Labeled data for other, related tasks is used to infer potentially correlated features on the target task. Like in our results, they found that the gains from modeling dependencies diminish as more training data is available. We also mention two related online learning approaches. Similar to our goal of regularizing toward a good unsupervised system, Crammer et al. (2006) regularize w� toward a (different) tar</context>
</contexts>
<marker>Raina, Ng, Koller, 2006</marker>
<rawString>Rajat Raina, Andrew Y. Ng, and Daphne Koller. 2006. Constructing informative priors using transfer learning. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Rifkin</author>
<author>Aldebaro Klautau</author>
</authors>
<date>2004</date>
<booktitle>In defense of one-vs-all classification. JMLR,</booktitle>
<pages>5--101</pages>
<contexts>
<context position="7869" citStr="Rifkin and Klautau (2004)" startWordPosition="1280" endWordPosition="1283">k, 1998; Weston and Watkins, 1998). Following the soft-margin version in Crammer and Singer (2001): mint 1 K ||�Wi||2 + C M ξi W IV I... Ib m 2 i=1 i=1 subject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-SVM. The K-SVM outperformed the OvA-SVM in Crammer and Singer (2001), but see Rifkin and Klautau (2004). The popularity of K-SVM is partly due to convenience; it is included in popular SVM software like SVMmulticlass1 and LIBLINEAR (Fan et al., 2008). Note that with two classes, K-SVM is less efficient than a standard binary SVM. A binary classifier outputs class 1 if (w� · x� &gt; 0) and class 2 otherwise. The K-SVM encodes a binary classifier using � � W1 = w� and W2 = − w, therefore requiring twice the memory of a binary SVM. However, both binary and 2-class formulations have the same solution (Weston and Watkins, 1998). 1http://svmlight.joachims.org/svm multiclass.html 173 2.1.1 Web-Scale N-gr</context>
<context position="26191" citStr="Rifkin and Klautau (2004)" startWordPosition="4391" endWordPosition="4394">, and 10K test examples for each, and average accuracy across the sets. All 2-to-5 gram counts are used in the unsupervised system, so the variance of all weights is regularized in VAR-SVM. 4.2.1 Results On this task, the majority-class baseline is much higher, 66.9%, and so is the accuracy of the top unsupervised system: 94.8%. Since four of the five sets are binary classifications, where K-SVM and CS-SVM are equivalent, we only give the accuracy of the CS-SVM (it does perform better on the one 3-way set). VAR-SVM again exceeds the unsupervised accuracy for all training sizes, and generally 6Rifkin and Klautau (2004) argue OvA-SVM is as good as K-SVM, but this is “predicated on the assumption that the classes are ‘independent’,” i.e., that examples from class 0 are no closer to class 1 than to class 2. This is not true of this task (e.g. xbefore is closer to xafter than -tin, etc.). 177 Training Examples System 10 100 1K CS-SVM 59.0 71.0 84.3 CS-SVM+ 59.4 74.9 84.5 VAR-SVM 70.2 76.2 84.5 VAR-SVM+FreeB 64.2 80.3 84.5 Table 3: Accuracy (%) of non-referential detection SVMs. Unsupervised accuracy is 80.1%. performs as well as the augmented CS-SVM+ using an order of magnitude less training data (Table 2). Dif</context>
</contexts>
<marker>Rifkin, Klautau, 2004</marker>
<rawString>Ryan Rifkin and Aldebaro Klautau. 2004. In defense of one-vs-all classification. JMLR, 5:101–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1685" citStr="Smith and Eisner, 2005" startWordPosition="252" endWordPosition="255"> often reasonable to weight the different models equally. We propose a simple technique that exploits this intuition for better learning with fewer training examples. We regularize the feature weights in a Support Vector Machine (Cortes and Vapnik, 1995) toward a low-variance solution. Since the new SVM quadratic program is convex, it is no harder to optimize than the standard SVM objective. When training data is generated through human effort, faster learning saves time and money. When examples are labeled automatically, through user feedback (Joachims, 2002) or from textual pseudo-examples (Smith and Eisner, 2005; Okanohara and Tsujii, 2007), faster learning can reduce the lag before a new system is useful. We demonstrate faster learning on lexical disambiguation tasks. For these tasks, a system predicts a label for a word in text, based on the word’s context. Possible labels include part-ofspeech tags, named-entity types, and word senses. A number of disambiguation systems make predictions with the help of N-gram counts from a web-scale auxiliary corpus, typically via a searchengine (Lapata and Keller, 2005) or N-gram corpus (Bergsma et al., 2009). When discriminative training is used to weigh the co</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A. Smith and Jason Eisner. 2005. Contrastive estimation: training log-linear models on unlabeled data. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anastasios Tefas</author>
<author>Constantine Kotropoulos</author>
<author>Ioannis Pitas</author>
</authors>
<title>Using support vector machines to enhance the performance of elastic graph matching for frontal face authentication.</title>
<date>2001</date>
<journal>IEEE Trans. Pattern Anal. Machine Intell.,</journal>
<pages>23--735</pages>
<contexts>
<context position="30468" citStr="Tefas et al. (2001)" startWordPosition="5083" endWordPosition="5086">ices in the SVM quadratic program. The graph Laplacian has been used to encourage geometrically-similar feature vectors to be classified similarly (Belkin et al., 2006). An appealing property of these approaches is that they incorporate information from unlabeled examples. Wang et al. (2006) use Laplacian regularization for the task of dependency parsing. They regularize such that features for distributionally-similar words have similar weights. Rather than penalize pairwise differences proportional to a similarity function, we simply penalize weight variance. In the field of computer vision, Tefas et al. (2001) (binary) and Kotsia et al. (2009) (multiclass) also regularize weights with respect to a covariance matrix. They use labeled data to find the sum of the sample covariance matrices from each class, similar to linear discriminant analysis. We propose the idea in general, and instantiate with a different C matrix: a variance regularizer over w. Most importantly, our instantiated covariance matrix does not require labeled data to generate. In a Bayesian setting, Raina et al. (2006) model 178 feature correlations in a logistic regression classifier. They propose a method to construct a covariance </context>
</contexts>
<marker>Tefas, Kotropoulos, Pitas, 2001</marker>
<rawString>Anastasios Tefas, Constantine Kotropoulos, and Ioannis Pitas. 2001. Using support vector machines to enhance the performance of elastic graph matching for frontal face authentication. IEEE Trans. Pattern Anal. Machine Intell., 23:735–746.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel R Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>The ups and downs of preposition error detection in ESL writing.</title>
<date>2008</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="23112" citStr="Tetreault and Chodorow (2008)" startWordPosition="3893" endWordPosition="3896">g 34 candidates, using counts for filled 2-to-5-gram patterns. We use 100K training, 10K development, and 10K test examples. The unsupervised approach sums the counts of all 3-to-5-gram patterns for each preposition. We therefore regularize the variance of the 3-to-5-gram weights in VAR-SVM, and simultaneously minimize the norm of the 2-gram weights. 4.1.1 Results The majority-class is the preposition of; it occurs in 20.3% of test examples. The unsupervised system scores 73.7%. For further perspective on these results, note Chodorow et al. (2007) achieved 69% with 7M training examples, while Tetreault and Chodorow (2008) found the human performance was around 75%. However, these results are not directly comparable as they are on different data. Table 1 gives the accuracy for different amounts of training data. Here, as in the other tasks, K-SVM mirrors the learning rate in Bergsma et al. (2009). There are several distinct phases among the relative ranking of the systems. For smaller amounts of training data (≤1000 examples) K-SVM performs worst, while VAR-SVM is statistically significantly better than all other systems, and always exceeds the performance of the unsupervised approach.5 Augmenting the attribute</context>
</contexts>
<marker>Tetreault, Chodorow, 2008</marker>
<rawString>Joel R. Tetreault and Martin Chodorow. 2008. The ups and downs of preposition error detection in ESL writing. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Tong</author>
<author>Daphne Koller</author>
</authors>
<title>Support vector machine active learning with applications to text classification.</title>
<date>2002</date>
<journal>JMLR,</journal>
<pages>2--45</pages>
<contexts>
<context position="32360" citStr="Tong and Koller, 2002" startWordPosition="5384" endWordPosition="5387">he variance of each weight and use this to guide the online updates. However, covariance between weights is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationship between attributes and</context>
</contexts>
<marker>Tong, Koller, 2002</marker>
<rawString>Simon Tong and Daphne Koller. 2002. Support vector machine active learning with applications to text classification. JMLR, 2:45–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thorsten Joachims</author>
<author>Thomas Hofmann</author>
<author>Yasemin Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>JMLR,</journal>
<pages>6--1453</pages>
<contexts>
<context position="15164" citStr="Tsochantaridis et al., 2005" startWordPosition="2524" endWordPosition="2527">positive and negative evidence together for each class, in CS-SVM, negative evidence only plays a roll as it contributes to the score of competing classes. If all the attributes are equally important, the weights should be equal, as in the unsupervised approach in (5). If some are more important than others, the training examples should reflect this and the learner can adjust the weights accordingly.3 In the absence of this training evidence, it is reasonable to bias the classifier toward an equalweight solution. ing the former may be better as it results in a tighter bound on empirical risk (Tsochantaridis et al., 2005). 3E.g., the true preposition might be better predicted by the counts of patterns that tend to include the preposition’s grammatical object, i.e., patterns that include more right-context. Rather than the standard SVM regularization that minimizes the norm of the weights as in (4), we therefore regularize toward weights that have low variance. More formally, we can regard the set of weights, w1, ..., wN, as the distribution of a discrete random variable, W. We can calculate the mean and variance of this variable from its distribution. We seek a variable that has low variance. We begin with a m</context>
<context position="34360" citStr="Tsochantaridis et al., 2005" startWordPosition="5698" endWordPosition="5701">ms et al., 2009). It would be useful to fit our optimization problem to efficient SVM training methods, especially for linear classifiers. VAR-SVM’s representational power could be extended by using non-linear SVMs. Kernels can be used with a covariance regularizer (Kotsia et al., 2009). Since C is positive semi-definite, the square root of its inverse is defined. We can therefore map the input examples using (C−21x), and write an equivalent objective function in terms of kernel functions over the transformed examples. Also, since structured-prediction SVMs build on the multi-class framework (Tsochantaridis et al., 2005), variance regularization can be incorporated naturally into more complex prediction tasks, such as parsers, taggers, and aligners. VAR-SVM may also help in new domains where annotated data is lacking. VAR-SVM should be stronger cross-domain than K-SVM; regularization with domain-neutral prior-knowledge can offset domain-specific biases. Learned weight vectors from other domains may also provide crossdomain regularization guidance. 7 Conclusion We presented variance-regularization SVMs, an approach to learning that creates better classifiers using fewer training examples. Variance regularizati</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. 2005. Large margin methods for structured and interdependent output variables. JMLR, 6:1453–1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="7251" citStr="Vapnik, 1998" startWordPosition="1166" endWordPosition="1167"> with the attributes, x. We seek weights such that the classifier makes few errors on training data and generalizes well to unseen data. There are KN weights to learn, for the cross-product of attributes and classes. The most common approach is to train K separate one-versus-all binary SVMs, one for each class. The weights learned for the rth SVM provide the weights Wr in (1). We call this approach OvA-SVM. Note in some settings various oneversus-one strategies may be more effective than one-versus-all (Hsu and Lin, 2002). The weights can also be found using a single constrained optimization (Vapnik, 1998; Weston and Watkins, 1998). Following the soft-margin version in Crammer and Singer (2001): mint 1 K ||�Wi||2 + C M ξi W IV I... Ib m 2 i=1 i=1 subject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-SVM. The K-SVM outperformed the OvA-SVM in Crammer and Singer (2001), but see Rifkin </context>
<context position="10770" citStr="Vapnik, 1998" startWordPosition="1785" endWordPosition="1786">llows the attribute partition, w� = ( 17V1, ..., WK). The classifier is: H¯w(x) = argmax K {�wr · xr} (3) r=1 We call this classifier the CS-SVM (an SVM with Class-Specific attributes). The weights can be determined using the follow (soft-margin) optimization: min 1 UV w� + C �m ξi ¯w,ξ�,...,ξm 2 i=1 subject to :ξi &gt;0 br =� yi, wyi · xyi − wr · xr &gt;1 − ξi (4) There are several advantages to this formulation. Foremost, rather than having KN weights, it can have only N. For linear classifiers, the number of examples needed to reach optimum performance is at most linear in the number of weights (Vapnik, 1998; Ng and Jordan, 2002). In fact, both the total number and number of active features per example decrease by K. Thus this reduction saves far more memory than what could be obtained by an equal reduction in dimensionality via pruning infrequent attributes. Also, note that unlike the K-SVM (Section 2.1), in the binary case the CS-SVM is completely equivalent (thus equally efficient) to a standard SVM. We will not always a priori know the class associated with each attribute. Also, some attributes may be predictive of multiple classes. In such cases, we can include ambiguous attributes in every </context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Iris Wang</author>
<author>Colin Cherry</author>
<author>Dan Lizotte</author>
<author>Dale Schuurmans</author>
</authors>
<title>Improved large margin dependency parsing via local constraints and Laplacian regularization.</title>
<date>2006</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="30141" citStr="Wang et al. (2006)" startWordPosition="5035" endWordPosition="5038">se with 10 examples, but exceeds the unsupervised approach with 100 training points. Although this was somewhat successful, developing better strategies for bias remains useful future work. 5 Related Work There is a large body of work on regularization in machine learning, including work that uses positive semi-definite matrices in the SVM quadratic program. The graph Laplacian has been used to encourage geometrically-similar feature vectors to be classified similarly (Belkin et al., 2006). An appealing property of these approaches is that they incorporate information from unlabeled examples. Wang et al. (2006) use Laplacian regularization for the task of dependency parsing. They regularize such that features for distributionally-similar words have similar weights. Rather than penalize pairwise differences proportional to a similarity function, we simply penalize weight variance. In the field of computer vision, Tefas et al. (2001) (binary) and Kotsia et al. (2009) (multiclass) also regularize weights with respect to a covariance matrix. They use labeled data to find the sum of the sample covariance matrices from each class, similar to linear discriminant analysis. We propose the idea in general, an</context>
</contexts>
<marker>Wang, Cherry, Lizotte, Schuurmans, 2006</marker>
<rawString>Qin Iris Wang, Colin Cherry, Dan Lizotte, and Dale Schuurmans. 2006. Improved large margin dependency parsing via local constraints and Laplacian regularization. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Chris Watkins</author>
</authors>
<title>Multi-class support vector machines.</title>
<date>1998</date>
<tech>Technical Report CSDTR-98-04,</tech>
<institution>Department of Computer Science, Royal Holloway, University of London.</institution>
<contexts>
<context position="7278" citStr="Weston and Watkins, 1998" startWordPosition="1168" endWordPosition="1171">ibutes, x. We seek weights such that the classifier makes few errors on training data and generalizes well to unseen data. There are KN weights to learn, for the cross-product of attributes and classes. The most common approach is to train K separate one-versus-all binary SVMs, one for each class. The weights learned for the rth SVM provide the weights Wr in (1). We call this approach OvA-SVM. Note in some settings various oneversus-one strategies may be more effective than one-versus-all (Hsu and Lin, 2002). The weights can also be found using a single constrained optimization (Vapnik, 1998; Weston and Watkins, 1998). Following the soft-margin version in Crammer and Singer (2001): mint 1 K ||�Wi||2 + C M ξi W IV I... Ib m 2 i=1 i=1 subject to � ξi ≥0 ∀r =6 yi, Wyz · V − Wr · V ≥1 − ξi (2) The constraints require the correct class to be scored higher than other classes by a certain margin, with slack for non-separable cases. Minimizing the weights is a form of regularization. Tuning the C-parameter controls the emphasis on regularization versus separation of training examples. We call this the K-SVM. The K-SVM outperformed the OvA-SVM in Crammer and Singer (2001), but see Rifkin and Klautau (2004). The pop</context>
</contexts>
<marker>Weston, Watkins, 1998</marker>
<rawString>Jason Weston and Chris Watkins. 1998. Multi-class support vector machines. Technical Report CSDTR-98-04, Department of Computer Science, Royal Holloway, University of London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32453" citStr="Yarowsky, 1995" startWordPosition="5399" endWordPosition="5400">ghts is not considered. We believe new SVM regularizations in general, and variance regularization in particular, will increasingly be used in combination with related NLP strategies that learn better when labeled data is scarce. These may include: using more-general features, e.g. ones generated from raw text (Miller et al., 2004; Koo et al., 2008), leveraging out-ofdomain examples to improve in-domain classification (Blitzer et al., 2007; Daum´e III, 2007), active learning (Cohn et al., 1994; Tong and Koller, 2002), and approaches that treat unlabeled data as labeled, such as bootstrapping (Yarowsky, 1995), co-training (Blum and Mitchell, 1998), and selftraining (McClosky et al., 2006). 6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationship between attributes and classes may be explicit when, e.g., a rule-based system is optimized via discriminative lear</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar Zaidan</author>
<author>Jason Eisner</author>
<author>Christine Piatko</author>
</authors>
<title>Using “annotator rationales” to improve machine learning for text categorization.</title>
<date>2007</date>
<booktitle>In NAACLHLT.</booktitle>
<contexts>
<context position="33156" citStr="Zaidan et al., 2007" startWordPosition="5511" endWordPosition="5514">6 Future Work The primary direction of future research will be to apply the VAR-SVM to new problems and tasks. There are many situations where a system designer has an intuition about the role a feature will play in prediction; the feature was perhaps added with this role in mind. By biasing the SVM to use features as intended, VAR-SVM may learn better with fewer training examples. The relationship between attributes and classes may be explicit when, e.g., a rule-based system is optimized via discriminative learning, or annotators justify their decisions by indicating the relevant attributes (Zaidan et al., 2007). Also, if features are a priori thought to have different predictive worth, the attribute values could be scaled such that variance regularization, as we formulated it, has the desired effect. Other avenues of future work will be to extend the VAR-SVM in three directions: efficiency, representational power, and problem domain. While we optimized the VAR-SVM objective in CPLEX, general purpose QP-solvers “do not exploit the special structure of [the SVM optimization] problem,” and consequently often train in time super-linear with the number of training examples (Joachims et al., 2009). It wou</context>
</contexts>
<marker>Zaidan, Eisner, Piatko, 2007</marker>
<rawString>Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve machine learning for text categorization. In NAACLHLT.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>