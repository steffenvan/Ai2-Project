<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002436">
<title confidence="0.916624">
Identifying Word Translations in Non-Parallel Texts
</title>
<author confidence="0.411902">
Reinhard Rapp
</author>
<note confidence="0.796081">
ISSCO, Universite de Geneve
54 route des Acacias
</note>
<sectionHeader confidence="0.382673" genericHeader="abstract">
Geneve, Switzerland
</sectionHeader>
<email confidence="0.882935">
rapp@divsun.unige.ch
</email>
<sectionHeader confidence="0.996323" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.9987238">
Common algorithms for sentence and
word-alignment allow the automatic iden-
tification of word translations from parallel
texts. This study suggests that the identi-
fication of word translations should also be
possible with non-parallel and even unre-
lated texts. The method proposed is based
on the assumption that there is a corre-
lation between the patterns of word co-
occurrences in texts of different languages.
</bodyText>
<sectionHeader confidence="0.999398" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99943168">
In a number of recent studies it has been shown that
word translations can be automatically derived from
the statistical distribution of words in bilingual par-
allel texts (e. g. Catizone, Russell &amp; Warwick, 1989;
Brown et al., 1990; Dagan, Church &amp; Gale, 1993;
Kay &amp; ROscheisen, 1993). Most of the proposed
algorithms first conduct an alignment of sentences,
i. e. those pairs of sentences are located that are
translations of each other. In a second step a word
alignment is performed by analyzing the correspon-
dences of words in each pair of sentences.
The results achieved with these algorithms have
been found useful for the compilation of dictionaries,
for checking the consistency of terminological usage
in translations, and for assisting the terminological
work of translators and interpreters.
However, despite serious efforts in the compilation
of corpora (Church &amp; Mercer, 1993; Armstrong &amp;
Thompson, 1995) the availability of a large enough
parallel corpus in a specific field and for a given pair
of languages will always be the exception, not the
rule. Since the acquisition of non-parallel texts is
usually much easier, it would be desirable to have
a program that can determine the translations of
words from comparable or even unrelated texts.
</bodyText>
<sectionHeader confidence="0.992659" genericHeader="method">
2 Approach
</sectionHeader>
<bodyText confidence="0.999934862068966">
It is assumed that there is a correlation between
the co-occurrences of words which are translations
of each other. If — for example — in a text of one
language two words A and B co-occur more often
than expected from chance, then in a text of an-
other language those words which are translations of
A and B should also co-occur more frequently than
expected. This assumption is reasonable for parallel
texts. However, in this paper it is further assumed
that the co-occurrence patterns in original texts are
not fundamentally different from those in translated
texts.
Starting from an English vocabulary of six words
and the corresponding German translations, table la
and b show an English and a German co-occurrence
matrix. In these matrices the entries belonging to
those pairs of words that in texts co-occur more fre-
quently than expected have been marked with a dot.
In general, word order in the lines and columns of a
co-occurrence matrix is independent of each other,
but for the purpose of this paper can always be as-
sumed to be equal without loss of generality.
If now the word order of the English matrix is per-
muted until the resulting pattern of dots is most sim-
ilar to that of the German matrix (see table lc), then
this increases the likelihood that the English and
German words are in corresponding order. Word a
in the English matrix is then the translation of word
a in the German matrix.
</bodyText>
<sectionHeader confidence="0.993539" genericHeader="method">
3 Simulation
</sectionHeader>
<bodyText confidence="0.999943857142857">
A simulation experiment was conducted in order to
see whether the above assumptions concerning the
similarity of co-occurrence patterns actually hold.
In this experiment, for an equivalent English and
German vocabulary two co-occurrence matrices were
computed and then compared. As the English vo-
cabulary a list of 100 words was used, which had
been suggested by Kent &amp; Rosanoff (1910) for asso-
ciation experiments. The German vocabulary con-
sisted of one by one translations of these words as
chosen by Russell (1970).
The word co-occurrences were computed on the
basis of an English corpus of 33 and a German corpus
of 46 million words. The English corpus consists of
</bodyText>
<page confidence="0.998189">
320
</page>
<tableCaption confidence="0.827806">
Table 1: When the word orders of the English and
the German matrix correspond, the dot patterns of
the two matrices are identical.
</tableCaption>
<construct confidence="0.935491857142857">
1 2 3 4 5 6
blue 1 • •
green 2 • •
plant 3 •
school 4 •
sky 5 •
teacher 6 •
1 2 3 4 5 6
blau 1 • •
grfin 2 • •
Himmel 3 •
Lehrer 4 •
Pflanze 5 •
Schule 6 •
1 2 5 6 3 4
blue 1 • •
green 2 • •
sky 5 •
teacher 6 •
plant 3 •
school 4 •
</construct>
<bodyText confidence="0.989248">
the Brown Corpus, texts from the Wall Street Jour-
nal, Grolier &apos;s Electronic Encyclopedia and scientific
abstracts from different fields. The German cor-
pus is a compilation of mainly newspaper texts from
Frankfurter Rundschau, Die Zeit and Mannheimer
Morgen. To the knowledge of the author, the English
and German corpora contain no parallel passages.
For each pair of words in the English vocabulary
its frequency of common occurrence in the English
corpus was counted. The common occurrence of two
words was defined as both words being separated
by at most 11 other words. The co-occurrence fre-
quencies obtained in this way were used to build
up the English matrix. Equivalently, the German
co-occurrence matrix was created by counting the
co-occurrences of German word pairs in the German
corpus. As a starting point, word order in the two
matrices was chosen such that word n in the German
matrix was the translation of word n in the English
matrix.
Co-occurrence studies like that conducted by
Wettler St Rapp (1993) have shown that for many
purposes it is desirable to reduce the influence of
word frequency on the co-occurrence counts. For
the prediction of word associations they achieved
best results when modifying each entry in the co-
occurrence matrix using the following formula:
</bodyText>
<equation confidence="0.7246635">
(f(i&amp;.-7))2
f(i) • 1(i)
</equation>
<bodyText confidence="0.998532142857143">
Hereby f(i&amp;j) is the frequency of common occur-
rence of the two words i and j, and f(i) is the corpus
frequency of word i. However, for comparison, the
simulations described below were also conducted us-
ing the original co-occurrence matrices (formula 2)
and a measure similar to mutual information (for-
mula 3).1
</bodyText>
<equation confidence="0.9070485">
= f(i&amp;j) (2)
f(i&amp;j)
</equation>
<bodyText confidence="0.999812625">
Regardless of the formula applied, the English and
the German matrix where both normalized.2 Start-
ing from the normalized English and German matri-
ces, the aim was to determine how far the similarity
of the two matrices depends on the correspondence
of word order. As a measure for matrix similarity
the sum of the absolute differences of the values at
corresponding matrix positions was used.
</bodyText>
<equation confidence="0.975424">
N N
(4)
i=1. 1=1
</equation>
<bodyText confidence="0.999711">
This similarity measure leads to a value of zero for
identical matrices, and to a value of 20 000 in the
case that a non-zero entry in one of the 100 * 100
matrices always corresponds to a zero-value in the
other.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.975692681818182">
The simulation was conducted by randomly permut-
ing the word order of the German matrix and then
computing the similarity s to the English matrix.
For each permutation it was determined how many
words c had been shifted to positions different from
those in the original German matrix. The simulation
was continued until for each value of c a set of 1000
similarity values was available.&apos; Figure 1 shows for
the three formulas how the average similarity a be-
tween the English and the German matrix depends
on the number of non-corresponding word positions
c. Each of the curves increases monotonically, with
formula 1 having the steepest, i. e. best discriminat-
ing characteristic. The dotted curves in figure 1 are
the minimum and maximum values in each set of
1000 similarity values for formula 1.
&apos;The logarithm has been removed from the mutual
information measure since it is not defined for zero co-
occurrences.
2 Normalization was conducted in such a way that the
sum of all matrix entries adds up to the number of fields
in the matrix.
</bodyText>
<equation confidence="0.884379">
C = 1 is not possible and was not taken into account.
(1)
(3)
</equation>
<page confidence="0.985453">
321
</page>
<figureCaption confidence="0.986811">
Figure 1: Dependency between the mean similarity i
</figureCaption>
<bodyText confidence="0.883899">
of the English and the German matrix and the num-
ber of non-corresponding word positions c for 3 for-
mulas. The dotted lines are the minimum and max-
imum values of each sample of 1000 for formula 1.
</bodyText>
<sectionHeader confidence="0.959004" genericHeader="conclusions">
5 Discussion and prospects
</sectionHeader>
<bodyText confidence="0.960785071428571">
It could be shown that even for unrelated Eng-
lish and German texts the patterns of word co-
occurrences strongly correlate. The monotonically
increasing character of the curves in figure 1 indi-
cates that in principle it should be possible to find
word correspondences in two matrices of different
languages by randomly permuting one of the ma-
trices until the similarity function s reaches a mini-
mum and thus indicates maximum similarity. How-
ever, the minimum-curve in figure 1 suggests that
there are some deep minima of the similarity func-
tion even in cases when many word correspondences
are incorrect. An algorithm currently under con-
struction therefore searches for many local minima,
and tries to find out what word correspondences are
the most reliable ones. In order to limit the search
space, translations that are known beforehand can
be used as anchor points.
Future work will deal with the following as yet
unresolved problems:
• Computational limitations require the vocabu-
laries to be limited to subsets of all word types
in large corpora. With criteria like the corpus
frequency of a word, its specificity for a given
domain, and the salience of its co-occurrence
patterns, it should be possible to make a selec-
tion of corresponding vocabularies in the two
languages. If morphological tools and disam-
biguators are available, preliminary lemmatiza-
tion of the corpora would be desirable.
• Ambiguities in word translations can be taken
into account by working with continuous prob-
abilities to judge whether a word translation
is correct instead of making a binary decision.
Thereby, different sizes of the two matrices
could be allowed for.
It can be expected that with such a method the qual-
ity of the results depends on the thematic compara-
bility of the corpora, but not on their degree of par-
allelism. As a further step, even with non parallel
corpora it should be possible to locate comparable
passages of text.
</bodyText>
<sectionHeader confidence="0.990268" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998051">
I thank Susan Armstrong and Manfred Wettler for
their support of this project. Thanks also to Graham
Russell and three anonymous reviewers for valuable
comments on the manuscript.
</bodyText>
<sectionHeader confidence="0.998526" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99938945">
Armstrong, Susan; Thompson, Henry (1995). A
presentation of MLCC: Multilingual Corpora
for Cooperation. Linguistic Database Workshop,
Groningen.
Brown, Peter; Cocke, John; Della Pietra, Stephen
A.; Della Pietra, Vincent J.; Jelinek, Fredrick;
Lafferty, John D.; Mercer, Robert L.; Rossin, Paul
S. (1990). A statistical approach to machine trans-
lation. Computational Linguistics, 16(2), 79-85.
Catizone, Roberta; Russell, Graham; Warwick, Su-
san (1989). Deriving translation data from bilin-
gual texts. In: U. Zernik (ed.): Proceedings of the
First International Lexical Acquisition Workshop,
Detroit.
Church, Kenneth W.; Mercer, Robert L. (1993).
Introduction to the special issue on Computa-
tional Linguistics using large corpora. Computa-
tional Linguistics, 19(1), 1-24.
Dagan, Ido; Church, Kenneth W.; Gale, William A.
(1993). Robust bilingual word alignment for ma-
chine aided translation. Proceedings of the Work-
shop on Very Large Corpora: Academic and In-
dustrial Perspectives. Columbus, Ohio, 1-8.
Kay, Martin; ROscheisen, Martin (1993). Text—
Translation Alignment. Computational Linguis-
tics, 19(1), 121-142.
Kent, G.H.; Rosanoff, Al. (1910). A study of asso-
ciation in insanity. American Journal of Insanity,
67, 37-96, 317-390.
Russell, Wallace A. (1970). The complete German
language norms for responses to 100 words from
the Kent-Rosanoff word association test. In: L.
Postman, G. Keppel (eds.): Norms of Word As-
sociation. New York: Academic Press, 53-94.
Wettler, Manfred; Rapp, Reinhard (1993). Com-
putation of word associations based on the co-
occurrences of words in large corpora. In: Pro-
ceedings of the Workshop on Very Large Corpora:
Academic and Industrial Perspectives, Columbus,
Ohio, 84-93.
</reference>
<figure confidence="0.999698454545455">
0 10 20 30 40 50 60 70 80 90 100
0000
20 (1)
&amp;quot; (3)
(2)
16
14 .
12 .
10
18
i••••
</figure>
<page confidence="0.960399">
322
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912020">
<title confidence="0.999895">Identifying Word Translations in Non-Parallel Texts</title>
<author confidence="0.999905">Reinhard Rapp</author>
<affiliation confidence="0.998511">ISSCO, Universite de Geneve</affiliation>
<address confidence="0.974647">54 route des Acacias Geneve, Switzerland</address>
<email confidence="0.987324">rapp@divsun.unige.ch</email>
<abstract confidence="0.997461">Common algorithms for sentence and word-alignment allow the automatic identification of word translations from parallel texts. This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts. The method proposed is based on the assumption that there is a correlation between the patterns of word cooccurrences in texts of different languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susan Armstrong</author>
<author>Henry Thompson</author>
</authors>
<title>A presentation of MLCC: Multilingual Corpora for Cooperation. Linguistic Database Workshop,</title>
<date>1995</date>
<location>Groningen.</location>
<contexts>
<context position="1508" citStr="Armstrong &amp; Thompson, 1995" startWordPosition="227" endWordPosition="230"> of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other. In a second step a word alignment is performed by analyzing the correspondences of words in each pair of sentences. The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters. However, despite serious efforts in the compilation of corpora (Church &amp; Mercer, 1993; Armstrong &amp; Thompson, 1995) the availability of a large enough parallel corpus in a specific field and for a given pair of languages will always be the exception, not the rule. Since the acquisition of non-parallel texts is usually much easier, it would be desirable to have a program that can determine the translations of words from comparable or even unrelated texts. 2 Approach It is assumed that there is a correlation between the co-occurrences of words which are translations of each other. If — for example — in a text of one language two words A and B co-occur more often than expected from chance, then in a text of a</context>
</contexts>
<marker>Armstrong, Thompson, 1995</marker>
<rawString>Armstrong, Susan; Thompson, Henry (1995). A presentation of MLCC: Multilingual Corpora for Cooperation. Linguistic Database Workshop, Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>John Cocke</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Rossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<pages>79--85</pages>
<contexts>
<context position="822" citStr="Brown et al., 1990" startWordPosition="121" endWordPosition="124">-alignment allow the automatic identification of word translations from parallel texts. This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts. The method proposed is based on the assumption that there is a correlation between the patterns of word cooccurrences in texts of different languages. 1 Introduction In a number of recent studies it has been shown that word translations can be automatically derived from the statistical distribution of words in bilingual parallel texts (e. g. Catizone, Russell &amp; Warwick, 1989; Brown et al., 1990; Dagan, Church &amp; Gale, 1993; Kay &amp; ROscheisen, 1993). Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other. In a second step a word alignment is performed by analyzing the correspondences of words in each pair of sentences. The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters. However, despite serious eff</context>
</contexts>
<marker>Brown, Cocke, Pietra, Stephen, Pietra, Vincent, Jelinek, Lafferty, Mercer, Rossin, 1990</marker>
<rawString>Brown, Peter; Cocke, John; Della Pietra, Stephen A.; Della Pietra, Vincent J.; Jelinek, Fredrick; Lafferty, John D.; Mercer, Robert L.; Rossin, Paul S. (1990). A statistical approach to machine translation. Computational Linguistics, 16(2), 79-85.</rawString>
</citation>
<citation valid="true">
<title>Deriving translation data from bilingual texts. In:</title>
<date>1989</date>
<booktitle>Proceedings of the First International Lexical Acquisition Workshop,</booktitle>
<editor>Catizone, Roberta; Russell, Graham; Warwick,</editor>
<location>Susan</location>
<marker>1989</marker>
<rawString>Catizone, Roberta; Russell, Graham; Warwick, Susan (1989). Deriving translation data from bilingual texts. In: U. Zernik (ed.): Proceedings of the First International Lexical Acquisition Workshop, Detroit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Robert L Mercer</author>
</authors>
<title>Introduction to the special issue on Computational Linguistics using large corpora.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>1--24</pages>
<contexts>
<context position="1479" citStr="Church &amp; Mercer, 1993" startWordPosition="223" endWordPosition="226">ROscheisen, 1993). Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other. In a second step a word alignment is performed by analyzing the correspondences of words in each pair of sentences. The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters. However, despite serious efforts in the compilation of corpora (Church &amp; Mercer, 1993; Armstrong &amp; Thompson, 1995) the availability of a large enough parallel corpus in a specific field and for a given pair of languages will always be the exception, not the rule. Since the acquisition of non-parallel texts is usually much easier, it would be desirable to have a program that can determine the translations of words from comparable or even unrelated texts. 2 Approach It is assumed that there is a correlation between the co-occurrences of words which are translations of each other. If — for example — in a text of one language two words A and B co-occur more often than expected fro</context>
</contexts>
<marker>Church, Mercer, 1993</marker>
<rawString>Church, Kenneth W.; Mercer, Robert L. (1993). Introduction to the special issue on Computational Linguistics using large corpora. Computational Linguistics, 19(1), 1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Robust bilingual word alignment for machine aided translation.</title>
<date>1993</date>
<booktitle>Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives.</booktitle>
<pages>1--8</pages>
<location>Columbus, Ohio,</location>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Dagan, Ido; Church, Kenneth W.; Gale, William A. (1993). Robust bilingual word alignment for machine aided translation. Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives. Columbus, Ohio, 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
<author>Martin ROscheisen</author>
</authors>
<date>1993</date>
<journal>Text— Translation Alignment. Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>121--142</pages>
<contexts>
<context position="875" citStr="Kay &amp; ROscheisen, 1993" startWordPosition="130" endWordPosition="133"> word translations from parallel texts. This study suggests that the identification of word translations should also be possible with non-parallel and even unrelated texts. The method proposed is based on the assumption that there is a correlation between the patterns of word cooccurrences in texts of different languages. 1 Introduction In a number of recent studies it has been shown that word translations can be automatically derived from the statistical distribution of words in bilingual parallel texts (e. g. Catizone, Russell &amp; Warwick, 1989; Brown et al., 1990; Dagan, Church &amp; Gale, 1993; Kay &amp; ROscheisen, 1993). Most of the proposed algorithms first conduct an alignment of sentences, i. e. those pairs of sentences are located that are translations of each other. In a second step a word alignment is performed by analyzing the correspondences of words in each pair of sentences. The results achieved with these algorithms have been found useful for the compilation of dictionaries, for checking the consistency of terminological usage in translations, and for assisting the terminological work of translators and interpreters. However, despite serious efforts in the compilation of corpora (Church &amp; Mercer, </context>
</contexts>
<marker>Kay, ROscheisen, 1993</marker>
<rawString>Kay, Martin; ROscheisen, Martin (1993). Text— Translation Alignment. Computational Linguistics, 19(1), 121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Kent</author>
<author>Al Rosanoff</author>
</authors>
<title>A study of association in insanity.</title>
<date>1910</date>
<journal>American Journal of Insanity,</journal>
<volume>67</volume>
<pages>37--96</pages>
<contexts>
<context position="3668" citStr="Kent &amp; Rosanoff (1910)" startWordPosition="597" endWordPosition="600">that of the German matrix (see table lc), then this increases the likelihood that the English and German words are in corresponding order. Word a in the English matrix is then the translation of word a in the German matrix. 3 Simulation A simulation experiment was conducted in order to see whether the above assumptions concerning the similarity of co-occurrence patterns actually hold. In this experiment, for an equivalent English and German vocabulary two co-occurrence matrices were computed and then compared. As the English vocabulary a list of 100 words was used, which had been suggested by Kent &amp; Rosanoff (1910) for association experiments. The German vocabulary consisted of one by one translations of these words as chosen by Russell (1970). The word co-occurrences were computed on the basis of an English corpus of 33 and a German corpus of 46 million words. The English corpus consists of 320 Table 1: When the word orders of the English and the German matrix correspond, the dot patterns of the two matrices are identical. 1 2 3 4 5 6 blue 1 • • green 2 • • plant 3 • school 4 • sky 5 • teacher 6 • 1 2 3 4 5 6 blau 1 • • grfin 2 • • Himmel 3 • Lehrer 4 • Pflanze 5 • Schule 6 • 1 2 5 6 3 4 blue 1 • • gre</context>
</contexts>
<marker>Kent, Rosanoff, 1910</marker>
<rawString>Kent, G.H.; Rosanoff, Al. (1910). A study of association in insanity. American Journal of Insanity, 67, 37-96, 317-390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wallace A Russell</author>
</authors>
<title>The complete German language norms for responses to 100 words from the Kent-Rosanoff word association test.</title>
<date>1970</date>
<booktitle>Norms of Word Association.</booktitle>
<pages>53--94</pages>
<editor>In: L. Postman, G. Keppel (eds.):</editor>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="3799" citStr="Russell (1970)" startWordPosition="621" endWordPosition="622">Word a in the English matrix is then the translation of word a in the German matrix. 3 Simulation A simulation experiment was conducted in order to see whether the above assumptions concerning the similarity of co-occurrence patterns actually hold. In this experiment, for an equivalent English and German vocabulary two co-occurrence matrices were computed and then compared. As the English vocabulary a list of 100 words was used, which had been suggested by Kent &amp; Rosanoff (1910) for association experiments. The German vocabulary consisted of one by one translations of these words as chosen by Russell (1970). The word co-occurrences were computed on the basis of an English corpus of 33 and a German corpus of 46 million words. The English corpus consists of 320 Table 1: When the word orders of the English and the German matrix correspond, the dot patterns of the two matrices are identical. 1 2 3 4 5 6 blue 1 • • green 2 • • plant 3 • school 4 • sky 5 • teacher 6 • 1 2 3 4 5 6 blau 1 • • grfin 2 • • Himmel 3 • Lehrer 4 • Pflanze 5 • Schule 6 • 1 2 5 6 3 4 blue 1 • • green 2 • • sky 5 • teacher 6 • plant 3 • school 4 • the Brown Corpus, texts from the Wall Street Journal, Grolier &apos;s Electronic Encyc</context>
</contexts>
<marker>Russell, 1970</marker>
<rawString>Russell, Wallace A. (1970). The complete German language norms for responses to 100 words from the Kent-Rosanoff word association test. In: L. Postman, G. Keppel (eds.): Norms of Word Association. New York: Academic Press, 53-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Wettler</author>
<author>Reinhard Rapp</author>
</authors>
<title>Computation of word associations based on the cooccurrences of words in large corpora. In:</title>
<date>1993</date>
<booktitle>Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<pages>84--93</pages>
<location>Columbus, Ohio,</location>
<marker>Wettler, Rapp, 1993</marker>
<rawString>Wettler, Manfred; Rapp, Reinhard (1993). Computation of word associations based on the cooccurrences of words in large corpora. In: Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, Columbus, Ohio, 84-93.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>