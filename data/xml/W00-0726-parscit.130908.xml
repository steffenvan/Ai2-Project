<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005548">
<note confidence="0.820183">
In: Proceedings of CoNLL-2000 and LLL-2000, pages 127-132, Lisbon, Portugal, 2000.
</note>
<title confidence="0.935161">
Introduction to the CoNLL-2000 Shared Task: Chunking
</title>
<author confidence="0.872685">
Erik F. Tjong Kim Sang Sabine Buchholz
</author>
<affiliation confidence="0.8514155">
CNTS - Language Technology Group ILK, Computational Linguistics
University of Antwerp Tilburg University
</affiliation>
<email confidence="0.987995">
erikt@uia.ua.ac.be s.buchholz@kub.n1
</email>
<sectionHeader confidence="0.986908" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982714285714">
We describe the CoNLL-2000 shared task:
dividing text into syntactically related non-
overlapping groups of words, so-called text
chunking. We give background information on
the data sets, present a general overview of the
systems that have taken part in the shared task
and briefly discuss their performance.
</bodyText>
<sectionHeader confidence="0.993706" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999840875">
Text chunking is a useful preprocessing step
for parsing. There has been a large inter-
est in recognizing non-overlapping noun phrases
(Ramshaw and Marcus (1995) and follow-up pa-
pers) but relatively little has been written about
identifying phrases of other syntactic categories.
The CoNLL-2000 shared task attempts to fill
this gap.
</bodyText>
<sectionHeader confidence="0.756043" genericHeader="method">
2 Task description
</sectionHeader>
<bodyText confidence="0.998392521739131">
Text chunking consists of dividing a text into
phrases in such a way that syntactically re-
lated words become member of the same phrase.
These phrases are non-overlapping which means
that one word can only be a member of one
chunk Here is an example sentence:
[NP He ] [vp reckons ] [NP the current
account deficit] [vp will narrow]
[pp to [NP only 1.8 billion]
[pp in] [NP September] .
Chunks have been represented as groups of
words between square brackets. A tag next to
the open bracket denotes the type of the chunk.
As far as we know, there are no annotated cor-
pora available which contain specific informa-
tion about dividing sentences into chunks of
words of arbitrary types. We have chosen to
work with a corpus with parse information, the
Wall Street Journal WSJ part of the Penn Tree-
bank II corpus (Marcus et al., 1993), and to ex-
tract chunk information from the parse trees in
this corpus. We will give a global description of
the various chunk types in the next section.
</bodyText>
<sectionHeader confidence="0.99161" genericHeader="method">
3 Chunk Types
</sectionHeader>
<bodyText confidence="0.999974678571429">
The chunk types are based on the syntactic cat-
egory part (i.e. without function tag) of the
bracket label in the Treebank (cf. Bies (1995)
p.35). Roughly, a chunk contains everything to
the left of and including the syntactic head of
the constituent of the same name. Some Tree-
bank constituents do not have related chunks.
The head of S (simple declarative clause) for ex-
ample is normally thought to be the verb, but
as the verb is already part of the VP chunk, no
S chunk exists in our example sentence.
Besides the head, a chunk also contains pre-
modifiers (like determiners and adjectives in
NPs), but no postmodifiers or arguments. This
is why the PP chunk only contains the preposi-
tion, and not the argument NP, and the SBAR
chunk consists of only the complementizer.
There are several difficulties when converting
trees into chunks. In the most simple case, a
chunk is just a syntactic constituent without
any further embedded constituents, like the NPs
in our examples. In some cases, the chunk con-
tains only what is left after other chunks have
been removed from the constituent, cf. &amp;quot;(VP
loves (NP Mary))&amp;quot; above, or ADJPs and PPs
below. We will discuss some special cases dur-
ing the following description of the individual
chunk types.
</bodyText>
<subsectionHeader confidence="0.986236">
3.1 NP
</subsectionHeader>
<bodyText confidence="0.9906398">
Our NP chunks are very similar to the ones of
Ramshaw and Marcus (1995). Specifically, pos-
sessive NP constructions are split in front of
the possessive marker (e.g. [NP Eastern Air-
lines] [NP creditors]) and the handling of co-
</bodyText>
<page confidence="0.995947">
127
</page>
<bodyText confidence="0.996181666666667">
ordinated NPs follows the Treebank annotators.
However, as Ramshaw and Marcus do not de-
scribe the details of their conversion algorithm,
results may differ in difficult cases, e.g. involv-
ing NAC and NX.1
An ADJP constituent inside an NP con-
stituent becomes part of the NP chunk:
(NP The (ADJP most volatile) form)
[NP the most volatile form]
</bodyText>
<subsectionHeader confidence="0.997305">
3.2 VP
</subsectionHeader>
<bodyText confidence="0.987553482758621">
In the Treebank, verb phrases are highly embed-
ded; see e.g. the following sentence which con-
tains four VP constituents. Following Ramshaw
and Marcus&apos; V-type chunks, this sentence will
only contain one VP chunk:
((S (NP-SBJ-3 Mr. Icahn) (VP may
not (VP want (S (NP-SBJ *-3) (VP to
(VP sell ...))))) . ))
[NP Mr. Icahn] [vp may not want
to sell]
It is still possible however to have one VP chunk
directly follow another: [NP The impression
[NP I] [vp have got] [vp is] [NP they] [vp &apos;d
love to do] [PRT away] [pp with] [NP it]. In this
case the two VP constituents did not overlap in
the Treebank.
Adverbs/adverbial phrases become part of
the VP chunk (as long as they are in front of
the main verb):
(VP could (ADVP very well) (VP
show ... ))
[vp could very well show]
In contrast to Ramshaw and Marcus (1995),
predicative adjectives of the verb are not part
of the VP chunk, e.g. in &amp;quot;[NP they [vp are 1
[paw unhappy ]&amp;quot;.
In inverted sentences, the auxiliary verb is not
part of any verb phrase in the Treebank. Con-
sequently it does not belong to any VP chunk:
</bodyText>
<footnote confidence="0.8336815">
((S (SINV (CONJP Not only) does
(NP-SBJ-1 your product) (VP have (S
1E.g. (NP-SBJ (NP Robin Leigh-Pemberton) , (NP
(NAC Bank (PP of (NP England))) governor) ,) which
we convert to [NP Robin Leigh-Pemberton ] , Bank
[pp of] [Np England] [NP governor] whereas Ramshaw
and Marcus state that C &amp;quot;governor&amp;quot; is not included in
any baseNP chunk&apos;.
</footnote>
<bodyText confidence="0.8614774">
(NP-SBJ *-1) (VP to (VP be (ADJP-
PRD excellent)))))) , but ...
[CONJP Not only ] does [NP your
product [vp have to be [ADJP ex-
cellent , but ...
</bodyText>
<subsectionHeader confidence="0.998802">
3.3 ADVP and ADJP
</subsectionHeader>
<bodyText confidence="0.933768058823529">
ADVP chunks mostly correspond to ADVP con-
stituents in the Treebank. However, ADVPs in-
side ADJPs or inside VPs if in front of the main
verb are assimilated into the ADJP respectively
VP chunk. On the other hand, ADVPs that
contain an NP make two chunks:
(ADVP-TMP (NP a year) earlier)
[NP a year] [ADVP earlier]
ADJPs inside NPs are assimilated into the NP.
And parallel to ADVPs, ADJPs that contain an
NP make two chunks:
(ADJP-PRD (NP 68 years) old)
[NP 68 years] [ADJP old]
It would be interesting to see how chang-
ing these decisions (as can be done in the
Treebank-to-chunk conversion script2) influ-
ences the chunking task.
</bodyText>
<subsectionHeader confidence="0.981717">
3.4 PP and SBAR
</subsectionHeader>
<bodyText confidence="0.9999697">
Most PP chunks just consist of one word (the
preposition) with the part-of-speech tag IN.
This does not mean, though, that finding PP
chunks is completely trivial. INs can also con-
stitute an SBAR chunk (see below) and some
PP chunks contain more than one word. This
is the case with fixed multi-word prepositions
such as such as, because of, due to, with prepo-
sitions preceded by a modifier: well above, just
after, even in, particularly among or with coor-
dinated prepositions: inside and outside. We
think that PPs behave sufficiently differently
from NPs in a sentence for not wanting to group
them into one class (as Ramshaw and Marcus
did in their N-type chunks), and that on the
other hand tagging all NP chunks inside a PP
as I-PP would only confuse the chunker. We
therefore chose not to handle the recognition of
true PPs (prep.+NP) during this first chunking
step.
</bodyText>
<footnote confidence="0.999518">
2The Treebank-to-chunk conversion script is available
from http://ilk.kub.n1/-sabine/chunklink/
</footnote>
<page confidence="0.994472">
128
</page>
<bodyText confidence="0.9995378">
SBAR chunks mostly consist of one word (the
complementizer) with the part-of-speech tag IN,
but like multi-word prepositions, there are also
multi-word complementizers: even though, so
that, just as, even if, as if, only if.
</bodyText>
<subsectionHeader confidence="0.832812">
3.5 CONJP, PRT, INTJ, LST, UCP
</subsectionHeader>
<bodyText confidence="0.998404576923077">
Conjunctions can consist of more than one word
as well: as well as, instead of, rather than, not
only, but also. One-word conjunctions (like and,
or) are not annotated as CONJP in the Tree-
bank, and are consequently no CONJP chunks
in our data.
The Treebank uses the PRT constituent to
annotate verb particles, and our PRT chunk
does the same. The only multi-word particle
is on and off This chunk type should be easy
to recognize as it should coincide with the part-
of-speech tag RP, but through tagging errors it
is sometimes also assigned IN (preposition) or
RB (adverb).
INTJ is an interjection phrase/chunk like no,
oh, hello, alas, good grief!. It is quite rare.
The list marker LST is even rarer. Examples
are 1., 2., 3., first, second, a, b, c. It might con-
sist of two words: the number and the period.
The UCP chunk is reminiscent of the UCP
(unlike coordinated phrase) constituent in the
Treebank. Arguably, the conjunction is the
head of the UCP, so most UCP chunks consist
of conjunctions like and and or. UCPs are the
rarest chunks and are probably not very useful
for other NLP tasks.
</bodyText>
<subsectionHeader confidence="0.997835">
3.6 Tokens outside
</subsectionHeader>
<bodyText confidence="0.99889675">
Tokens outside any chunk are mostly punctua-
tion signs and the conjunctions in ordinary coor-
dinated phrases. The word not may also be out-
side of any chunk. This happens in two cases:
Either not is not inside the VP constituent in
the Treebank annotation e.g. in
... (VP have (VP told (NP-1 clients)
(S (NP-SBJ *-1) not (VP to (VP ship
(NP anything))))))
or not is not followed by another verb (because
the main verb is a form of to be). As the right
chunk boundary is defined by the chunk&apos;s head,
i.e. the main verb in this case, not is then in fact
a postmodifier and as such not included in the
chunk: &amp;quot;... [SBAR that ] [NP there ] [vp were ]
n&apos;t [NP any major problems] .&amp;quot;
</bodyText>
<subsectionHeader confidence="0.980867">
3.7 Problems
</subsectionHeader>
<bodyText confidence="0.999927210526316">
All chunks were automatically extracted from
the parsed version of the Treebank, guided by
the tree structure, the syntactic constituent la-
bels, the part-of-speech tags and by knowledge
about which tags can be heads of which con-
stituents. However, some trees are very complex
and some annotations are inconsistent. What
to think about a VP in which the main verb is
tagged as NN (common noun)? Either we al-
low NNs as heads of VPs (not very elegant but
which is what we did) or we have a VP without
a head. The first solution might also introduce
errors elsewhere... As Ramshaw and Marcus
(1995) already noted: &amp;quot;While this automatic
derivation process introduced a small percent-
age of errors on its own, it was the only practi-
cal way both to provide the amount of training
data required and to allow for fully-automatic
testing.&amp;quot;
</bodyText>
<sectionHeader confidence="0.922369" genericHeader="method">
4 Data and Evaluation
</sectionHeader>
<bodyText confidence="0.99994192">
For the CoNLL shared task, we have chosen
to work with the same sections of the Penn
Treebank as the widely used data set for base
noun phrase recognition (Ramshaw and Mar-
cus, 1995): WSJ sections 15-18 of the Penn
Treebank as training material and section 20
as test materia13. The chunks in the data
were selected to match the descriptions in the
previous section. An overview of the chunk
types in the training data can be found in ta-
ble 1. De data sets contain tokens (words and
punctuation marks), information about the lo-
cation of sentence boundaries and information
about chunk boundaries. Additionally, a part-
of-speech (POS) tag was assigned to each token
by a standard POS tagger (Brill (1994) trained
on the Penn Treebank). We used these POS
tags rather than the Treebank ones in order to
make sure that the performance rates obtained
for this data are realistic estimates for data for
which no treebank POS tags are available.
In our example sentence in section 2, we have
used brackets for encoding text chunks. In the
data sets we have represented chunks with three
types of tags:
</bodyText>
<footnote confidence="0.9998515">
3The text chunking data set is available at http://lcg-
www.uia.ac.be/con112000/chunking/
</footnote>
<page confidence="0.981236">
129
</page>
<table confidence="0.999769333333333">
count % type
55081 51% NP (noun phrase)
21467 20% VP (verb phrase)
21281 20% PP (prepositional phrase)
4227 4% ADVP (adverb phrase)
2207 2% SBAR (subordinated clause)
2060 2% ADJP (adjective phrase)
556 1% PRT (particles)
56 0% CONJP (conjunction phrase)
31 0% INTJ (interjection)
10 0% LST (list marker)
2 0% UCP (unlike coordinated phrase)
</table>
<tableCaption confidence="0.705667666666667">
Table 1: Number of chunks per phrase type
in the training data (211727 tokens, 106978
chunks).
</tableCaption>
<bodyText confidence="0.993482916666667">
B-X first word of a chunk of type X
I-X non-initial word in an X chunk
0 word outside of any chunk
This representation type is based on a repre-
sentation proposed by Ramshaw and Marcus
(1995) for noun phrase chunks. The three tag
groups are sufficient for encoding the chunks in
the data since these are non-overlapping. Using
these chunk tags makes it possible to approach
the chunking task as a word classification task.
We can use chunk tags for representing our ex-
ample sentence in the following way:
</bodyText>
<equation confidence="0.989662166666667">
He/B-NP reckons/B-VP the/B-NP
current/I-NP account/I-NP
deficit/I-NP will/B-VP narrow/I-VP
to/B-PP only/B-NP #/I-NP
1.8/I-NP billion/B-NP in/B-PP
September/B-NP ./0
</equation>
<bodyText confidence="0.999767">
The output of a chunk recognizer may contain
inconsistencies in the chunk tags in case a word
tagged I-X follows a word tagged 0 or I-Y, with
X and Y being different. These inconsistencies
can be resolved by assuming that such I-X tags
start a new chunk.
The performance on this task is measured
with three rates. First, the percentage of
detected phrases that are correct (precision).
Second, the percentage of phrases in the
data that were found by the chunker (recall).
And third, the Fo=1 rate which is equal to
(132+1)*precision*recall / (02*precision+recall)
with 0.1 (van Rijsbergen, 1975). The lat-
ter rate has been used as the target for
optimization4.
</bodyText>
<sectionHeader confidence="0.999291" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.995463666666667">
The eleven systems that have been applied to
the CoNLL-2000 shared task can be divided in
four groups:
</bodyText>
<listItem confidence="0.99901675">
1. Rule-based systems: Villain and Day; Jo-
hansson; Dejean.
2. Memory-based systems: Veenstra and Van
den Bosch.
3. Statistical systems: Pla, Molina and Pri-
eto; Osborne; Koeling; Zhou, Tey and Su.
4. Combined systems: Tjong Kim Sang; Van
Halteren; Kudoh and Matsumoto.
</listItem>
<bodyText confidence="0.999765">
Vilain and Day (2000) approached the shared
task in three different ways. The most success-
ful was an application of the Alembic parser
which uses transformation-based rules. Johans-
son (2000) uses context-sensitive and context-
free rules for transforming part-of-speech (POS)
tag sequences to chunk tag sequences. Dejean
(2000) has applied the theory refinement sys-
tem ALLiS to the shared task. In order to ob-
tain a system which could process XML format-
ted data while using context information, he
has used three extra tools. Veenstra and Van
den Bosch (2000) examined different parame-
ter settings of a memory-based learning algo-
rithm. They found that modified value differ-
ence metric applied to POS information only
worked best.
A large number of the systems applied to
the CoNLL-2000 shared task uses statistical
methods. Pla, Molina and Prieto (2000) use
a finite-state version of Markov Models. They
started with using POS information only and
obtained a better performance when lexical
information was used. Zhou, Tey and Su
(2000) implemented a chunk tagger based on
HMMs. The initial performance of the tag-
ger was improved by a post-process correction
method based on error driven learning and by
</bodyText>
<footnote confidence="0.9973944">
41n the literature about related tasks sometimes the
tagging accuracy is mentioned as well. However, since
the relation between tag accuracy and chunk precision
and recall is not very strict, tagging accuracy is not a
good evaluation measure for this task.
</footnote>
<page confidence="0.984139">
130
</page>
<table confidence="0.999946461538462">
test data precision recall Fo=i
Kudoh and Matsumoto 93.45% 93.51% 93.48
Van Halteren 93.13% 93.51% 93.32
Tjong Kim Sang 94.04% 91.00% 92.50
Zhou, Tey and Su 91.99% 92.25% 92.12
Dejean 91.87% 91.31% 92.09
Koeling 92.08% 91.86% 91.97
Osborne 91.65% 92.23% 91.94
Veenstra and Van den Bosch 91.05% 92.03% 91.54
Pla, Molina and Prieto 90.63% 89.65% 90.14
Johansson 86.24% 88.25% 87.23
Vilain and Day 88.82% 82.91% 85.76
baseline 72.58% 82.14% 77.07
</table>
<tableCaption confidence="0.89161">
Table 2: Performance of the eleven systems on the test data. The baseline results have been
obtained by selecting the most frequent chunk tag for each part-of-speech tag.
</tableCaption>
<bodyText confidence="0.997849756756757">
incorporating chunk probabilities generated by
a memory-based learning process. The two
other statistical systems use maximum-entropy
based methods. Osborne (2000) trained Ratna-
parkhi&apos;s maximum-entropy POS tagger to out-
put chunk tags. Koeling (2000) used a stan-
dard maximum-entropy learner for generating
chunk tags from words and POS tags. Both
have tested different feature combinations be-
fore finding an optimal one and their final re-
sults are close to each other.
Three systems use system combination.
Tjong Kim Sang (2000) trained and tested five
memory-based learning systems to produce dif-
ferent representations of the chunk tags. A
combination of the five by majority voting per-
formed better than the individual parts. Van
Halteren (2000) used Weighted Probability Dis-
tribution Voting (WPDV) for combining the
results of four WPDV chunk taggers and a
memory-based chunk tagger. Again the com-
bination outperformed the individual systems.
Kudoh and Matsumoto (2000) created 231 sup-
port vector machine classifiers to predict the
unique pairs of chunk tags. The results of the
classifiers were combined by a dynamic pro-
gramming algorithm.
The performance of the systems can be found
in Table 2. A baseline performance was ob-
tained by selecting the chunk tag most fre-
quently associated with a POS tag. All systems
outperform the baseline. The majority of the
systems reached an Fo=1 score between 91.50
and 92.50. Two approaches performed a lot
better: the combination system WPDV used by
Van Halteren and the Support Vector Machines
used by Kudoh and Matsumoto.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.98880344">
In the early nineties, Abney (1991) proposed
to approach parsing by starting with finding
related chunks of words. By then, Church
(1988) had already reported on recognition
of base noun phrases with statistical meth-
ods. Ramshaw and Marcus (1995) approached
chunking by using a machine learning method.
Their work has inspired many others to study
the application of learning methods to noun
phrase chunking5. Other chunk types have not
received the same attention as NP chunks. The
most complete work is Buchholz et al. (1999),
which presents results for NP, VP, PP, ADJP
and ADVP chunks. Veenstra (1999) works with
NP, VP and PP chunks. Both he and Buchholz
et al. use data generated by the script that pro-
duced the CoNLL-2000 shared task data sets.
Ratnaparkhi (1998) has recognized arbitrary
chunks as part of a parsing task but did not re-
port on the chunking performance. Part of the
Sparkle project has concentrated on finding var-
ious sorts of chunks for the different languages
&apos;An elaborate overview of the work done on noun
phrase chunking can be found on http://lcg-www.uia.
ac.bererikt/research/np-chunking.html
</bodyText>
<page confidence="0.994318">
131
</page>
<bodyText confidence="0.594874">
(Carroll et al., 1997).
</bodyText>
<sectionHeader confidence="0.978591" genericHeader="conclusions">
7 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.9999906">
We have presented an introduction to the
CoNLL-2000 shared task: dividing text into
syntactically related non-overlapping groups of
words, so-called text chunking. For this task we
have generated training and test data from the
Penn Treebank. This data has been processed
by eleven systems. The best performing system
was a combination of Support Vector Machines
submitted by Taku Kudoh and Yuji Matsumoto.
It obtained an Fo=1 score of 93.48 on this task.
</bodyText>
<sectionHeader confidence="0.997987" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998999444444444">
We would like to thank the members of
the CNTS - Language Technology Group in
Antwerp, Belgium and the members of the ILK
group in Tilburg, The Netherlands for valuable
discussions and comments. Tjong Kim Sang is
funded by the European TMR network Learn-
ing Computational Grammars. Buchholz is sup-
ported by the Netherlands Organization for Sci-
entific Research (NWO).
</bodyText>
<sectionHeader confidence="0.998469" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999768313253012">
Steven Abney. 1991. Parsing by chunks. In
Principle-Based Parsing. Kluwer Academic Pub-
lishers.
Ann Bies, Mark Ferguson, Karen Katz, and Robert
MacIntyre. 1995. Bracket Guidelines for Tree-
bank II Style Penn Treebank Project. Penn Tree-
bank II cdrom.
Eric Brill. 1994. Some advances in rule-based
part of speech tagging. In Proceedings of the
Twelfth National Conference on Artificial Intel-
ligence (AAAI-94). Seattle, Washington.
Sabine Buchholz, Jorn Veenstra, and Walter Daele-
mans. 1999. Cascaded grammatical relation as-
signment. In Proceedings of EMNLP/VLC-99.
Association for Computational Linguistics.
John Carroll, Ted Briscoe, Glenn Carroll, Marc
Light, Dethleff Prescher, Mats Rooth, Stefano
Federici, Simonetta Montemagni, Vito Pirrelli,
Irina Prodanof, and Massimo Vanocchi. 1997.
Phrasal Parsing Software. Sparkle Work Package
3, Deliverable D3.2.
Kenneth Ward Church. 1988. A stochastic parts
program and noun phrase parser for unrestricted
text. In Second Conference on Applied Natural
Language Processing. Austin, Texas.
Herve Dejean. 2000. Learning syntactic structures
with xml. In Proceedings of CoNLL-2000 and
LLL-2000. Lisbon, Portugal.
Christer Johansson. 2000. A context sensitive max-
imum likelihood approach to chunking. In Pro-
ceedings of CoNLL-2000 and LLL-2000. Lisbon,
Portugal.
Rob Koeling. 2000. Chunking with maximum en-
tropy models. In Proceedings of CoNLL-2000 and
LLL-2000. Lisbon, Portugal.
Taku Kudoh and Yuji Matsumoto. 2000. Use of sup-
port vector learning for chunk identification. In
Proceedings of CoNLL-2000 and LLL-2000. Lis-
bon, Portugal.
Mitchell P. Marcus, Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building a large
annotated corpus of english: the penn treebank.
Computational Linguistics, 19(2).
Miles Osborne. 2000. Shallow parsing as part-of-
speech tagging. In Proceedings of CoNLL-2000
and LLL-2000. Lisbon, Portugal.
Ferran Pla, Antonio Molina, and Natividad Pri-
eto. 2000. Improving chunking by means of
lexical-contextual information in statistical lan-
guage models. In Proceedings of CoNLL-2000 and
LLL-2000. Lisbon, Portugal.
Lance A. Ramshaw and Mitchell P. Marcus. 1995.
Text chunking using transformation-based learn-
ing. In Proceedings of the Third ACL Workshop
on Very Large Corpora. Association for Compu-
tational Linguistics.
Adwait Ratnaparkhi. 1998. Maximum Entropy
Models for Natural Language Ambiguity Resolu-
tion. PhD thesis Computer and Information Sci-
ence, University of Pennsylvania.
Erik F. Tjong Kim Sang. 2000. Text chunking by
system combination. In Proceedings of CoNLL-
2000 and LLL-2000. Lisbon, Portugal.
Hans van Halteren. 2000. Chunking with wpdv
models. In Proceedings of CoNLL-2000 and LLL-
2000. Lisbon, Portugal.
C.J. van Rijsbergen. 1975. Information Retrieval.
Buttersworth.
Jorn Veenstra and Antal van den Bosch. 2000.
Single-classifier memory-based phrase chunking.
In Proceedings of CoNLL-2000 and LLL-2000.
Lisbon, Portugal.
Jorn Veenstra. 1999. Memory-based text chunking.
In Nikos Fakotakis, editor, Machine learning in
human language technology, workshop at ACAI
99.
Marc Vilain and David Day. 2000. Phrase parsing
with rule sequence processors: an application to
the shared conll task. In Proceedings of CoNLL-
2000 and LLL-2000. Lisbon, Portugal.
GuoDong Zhou, Jian Su, and TongGuan Tey. 2000.
Hybrid text chunking. In Proceedings of CoNLL-
2000 and LLL-2000. Lisbon, Portugal.
</reference>
<page confidence="0.997721">
132
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.991544">
<note confidence="0.991544">of CoNLL-2000 and LLL-2000, 127-132, Lisbon, Portugal, 2000.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Parsing by chunks. In Principle-Based Parsing.</title>
<date>1991</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="16940" citStr="Abney (1991)" startWordPosition="2871" endWordPosition="2872">ne classifiers to predict the unique pairs of chunk tags. The results of the classifiers were combined by a dynamic programming algorithm. The performance of the systems can be found in Table 2. A baseline performance was obtained by selecting the chunk tag most frequently associated with a POS tag. All systems outperform the baseline. The majority of the systems reached an Fo=1 score between 91.50 and 92.50. Two approaches performed a lot better: the combination system WPDV used by Van Halteren and the Support Vector Machines used by Kudoh and Matsumoto. 6 Related Work In the early nineties, Abney (1991) proposed to approach parsing by starting with finding related chunks of words. By then, Church (1988) had already reported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chun</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Steven Abney. 1991. Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Robert MacIntyre</author>
</authors>
<title>Bracket Guidelines for Treebank II Style Penn Treebank Project. Penn Treebank II cdrom.</title>
<date>1995</date>
<marker>Bies, Ferguson, Katz, MacIntyre, 1995</marker>
<rawString>Ann Bies, Mark Ferguson, Karen Katz, and Robert MacIntyre. 1995. Bracket Guidelines for Treebank II Style Penn Treebank Project. Penn Treebank II cdrom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some advances in rule-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94).</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="10614" citStr="Brill (1994)" startWordPosition="1851" endWordPosition="1852">bank as the widely used data set for base noun phrase recognition (Ramshaw and Marcus, 1995): WSJ sections 15-18 of the Penn Treebank as training material and section 20 as test materia13. The chunks in the data were selected to match the descriptions in the previous section. An overview of the chunk types in the training data can be found in table 1. De data sets contain tokens (words and punctuation marks), information about the location of sentence boundaries and information about chunk boundaries. Additionally, a partof-speech (POS) tag was assigned to each token by a standard POS tagger (Brill (1994) trained on the Penn Treebank). We used these POS tags rather than the Treebank ones in order to make sure that the performance rates obtained for this data are realistic estimates for data for which no treebank POS tags are available. In our example sentence in section 2, we have used brackets for encoding text chunks. In the data sets we have represented chunks with three types of tags: 3The text chunking data set is available at http://lcgwww.uia.ac.be/con112000/chunking/ 129 count % type 55081 51% NP (noun phrase) 21467 20% VP (verb phrase) 21281 20% PP (prepositional phrase) 4227 4% ADVP </context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Eric Brill. 1994. Some advances in rule-based part of speech tagging. In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94). Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Jorn Veenstra</author>
<author>Walter Daelemans</author>
</authors>
<title>Cascaded grammatical relation assignment.</title>
<date>1999</date>
<booktitle>In Proceedings of EMNLP/VLC-99. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="17432" citStr="Buchholz et al. (1999)" startWordPosition="2948" endWordPosition="2951">ed by Van Halteren and the Support Vector Machines used by Kudoh and Matsumoto. 6 Related Work In the early nineties, Abney (1991) proposed to approach parsing by starting with finding related chunks of words. By then, Church (1988) had already reported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary chunks as part of a parsing task but did not report on the chunking performance. Part of the Sparkle project has concentrated on finding various sorts of chunks for the different languages &apos;An elaborate overview of the work done on noun phrase chunking can be found on http://lcg-www.uia. ac.bererikt/research/np-chunking.html 131 </context>
</contexts>
<marker>Buchholz, Veenstra, Daelemans, 1999</marker>
<rawString>Sabine Buchholz, Jorn Veenstra, and Walter Daelemans. 1999. Cascaded grammatical relation assignment. In Proceedings of EMNLP/VLC-99. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
<author>Glenn Carroll</author>
<author>Marc Light</author>
<author>Dethleff Prescher</author>
<author>Mats Rooth</author>
<author>Stefano Federici</author>
<author>Simonetta Montemagni</author>
<author>Vito Pirrelli</author>
<author>Irina Prodanof</author>
<author>Massimo Vanocchi</author>
</authors>
<title>Phrasal Parsing Software. Sparkle Work Package 3, Deliverable D3.2.</title>
<date>1997</date>
<contexts>
<context position="18054" citStr="Carroll et al., 1997" startWordPosition="3050" endWordPosition="3053"> which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary chunks as part of a parsing task but did not report on the chunking performance. Part of the Sparkle project has concentrated on finding various sorts of chunks for the different languages &apos;An elaborate overview of the work done on noun phrase chunking can be found on http://lcg-www.uia. ac.bererikt/research/np-chunking.html 131 (Carroll et al., 1997). 7 Concluding Remarks We have presented an introduction to the CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking. For this task we have generated training and test data from the Penn Treebank. This data has been processed by eleven systems. The best performing system was a combination of Support Vector Machines submitted by Taku Kudoh and Yuji Matsumoto. It obtained an Fo=1 score of 93.48 on this task. Acknowledgements We would like to thank the members of the CNTS - Language Technology Group in Antwerp, Belgium and the m</context>
</contexts>
<marker>Carroll, Briscoe, Carroll, Light, Prescher, Rooth, Federici, Montemagni, Pirrelli, Prodanof, Vanocchi, 1997</marker>
<rawString>John Carroll, Ted Briscoe, Glenn Carroll, Marc Light, Dethleff Prescher, Mats Rooth, Stefano Federici, Simonetta Montemagni, Vito Pirrelli, Irina Prodanof, and Massimo Vanocchi. 1997. Phrasal Parsing Software. Sparkle Work Package 3, Deliverable D3.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In Second Conference on Applied Natural Language Processing.</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="17042" citStr="Church (1988)" startWordPosition="2887" endWordPosition="2888">d by a dynamic programming algorithm. The performance of the systems can be found in Table 2. A baseline performance was obtained by selecting the chunk tag most frequently associated with a POS tag. All systems outperform the baseline. The majority of the systems reached an Fo=1 score between 91.50 and 92.50. Two approaches performed a lot better: the combination system WPDV used by Van Halteren and the Support Vector Machines used by Kudoh and Matsumoto. 6 Related Work In the early nineties, Abney (1991) proposed to approach parsing by starting with finding related chunks of words. By then, Church (1988) had already reported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared t</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Kenneth Ward Church. 1988. A stochastic parts program and noun phrase parser for unrestricted text. In Second Conference on Applied Natural Language Processing. Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herve Dejean</author>
</authors>
<title>Learning syntactic structures with xml.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="13571" citStr="Dejean (2000)" startWordPosition="2331" endWordPosition="2332">ded in four groups: 1. Rule-based systems: Villain and Day; Johansson; Dejean. 2. Memory-based systems: Veenstra and Van den Bosch. 3. Statistical systems: Pla, Molina and Prieto; Osborne; Koeling; Zhou, Tey and Su. 4. Combined systems: Tjong Kim Sang; Van Halteren; Kudoh and Matsumoto. Vilain and Day (2000) approached the shared task in three different ways. The most successful was an application of the Alembic parser which uses transformation-based rules. Johansson (2000) uses context-sensitive and contextfree rules for transforming part-of-speech (POS) tag sequences to chunk tag sequences. Dejean (2000) has applied the theory refinement system ALLiS to the shared task. In order to obtain a system which could process XML formatted data while using context information, he has used three extra tools. Veenstra and Van den Bosch (2000) examined different parameter settings of a memory-based learning algorithm. They found that modified value difference metric applied to POS information only worked best. A large number of the systems applied to the CoNLL-2000 shared task uses statistical methods. Pla, Molina and Prieto (2000) use a finite-state version of Markov Models. They started with using POS </context>
</contexts>
<marker>Dejean, 2000</marker>
<rawString>Herve Dejean. 2000. Learning syntactic structures with xml. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christer Johansson</author>
</authors>
<title>A context sensitive maximum likelihood approach to chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="13436" citStr="Johansson (2000)" startWordPosition="2312" endWordPosition="2314">s been used as the target for optimization4. 5 Results The eleven systems that have been applied to the CoNLL-2000 shared task can be divided in four groups: 1. Rule-based systems: Villain and Day; Johansson; Dejean. 2. Memory-based systems: Veenstra and Van den Bosch. 3. Statistical systems: Pla, Molina and Prieto; Osborne; Koeling; Zhou, Tey and Su. 4. Combined systems: Tjong Kim Sang; Van Halteren; Kudoh and Matsumoto. Vilain and Day (2000) approached the shared task in three different ways. The most successful was an application of the Alembic parser which uses transformation-based rules. Johansson (2000) uses context-sensitive and contextfree rules for transforming part-of-speech (POS) tag sequences to chunk tag sequences. Dejean (2000) has applied the theory refinement system ALLiS to the shared task. In order to obtain a system which could process XML formatted data while using context information, he has used three extra tools. Veenstra and Van den Bosch (2000) examined different parameter settings of a memory-based learning algorithm. They found that modified value difference metric applied to POS information only worked best. A large number of the systems applied to the CoNLL-2000 shared</context>
</contexts>
<marker>Johansson, 2000</marker>
<rawString>Christer Johansson. 2000. A context sensitive maximum likelihood approach to chunking. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Koeling</author>
</authors>
<title>Chunking with maximum entropy models.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15573" citStr="Koeling (2000)" startWordPosition="2649" endWordPosition="2650">23% 91.94 Veenstra and Van den Bosch 91.05% 92.03% 91.54 Pla, Molina and Prieto 90.63% 89.65% 90.14 Johansson 86.24% 88.25% 87.23 Vilain and Day 88.82% 82.91% 85.76 baseline 72.58% 82.14% 77.07 Table 2: Performance of the eleven systems on the test data. The baseline results have been obtained by selecting the most frequent chunk tag for each part-of-speech tag. incorporating chunk probabilities generated by a memory-based learning process. The two other statistical systems use maximum-entropy based methods. Osborne (2000) trained Ratnaparkhi&apos;s maximum-entropy POS tagger to output chunk tags. Koeling (2000) used a standard maximum-entropy learner for generating chunk tags from words and POS tags. Both have tested different feature combinations before finding an optimal one and their final results are close to each other. Three systems use system combination. Tjong Kim Sang (2000) trained and tested five memory-based learning systems to produce different representations of the chunk tags. A combination of the five by majority voting performed better than the individual parts. Van Halteren (2000) used Weighted Probability Distribution Voting (WPDV) for combining the results of four WPDV chunk tagg</context>
</contexts>
<marker>Koeling, 2000</marker>
<rawString>Rob Koeling. 2000. Chunking with maximum entropy models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudoh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of support vector learning for chunk identification.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="16295" citStr="Kudoh and Matsumoto (2000)" startWordPosition="2760" endWordPosition="2763"> have tested different feature combinations before finding an optimal one and their final results are close to each other. Three systems use system combination. Tjong Kim Sang (2000) trained and tested five memory-based learning systems to produce different representations of the chunk tags. A combination of the five by majority voting performed better than the individual parts. Van Halteren (2000) used Weighted Probability Distribution Voting (WPDV) for combining the results of four WPDV chunk taggers and a memory-based chunk tagger. Again the combination outperformed the individual systems. Kudoh and Matsumoto (2000) created 231 support vector machine classifiers to predict the unique pairs of chunk tags. The results of the classifiers were combined by a dynamic programming algorithm. The performance of the systems can be found in Table 2. A baseline performance was obtained by selecting the chunk tag most frequently associated with a POS tag. All systems outperform the baseline. The majority of the systems reached an Fo=1 score between 91.50 and 92.50. Two approaches performed a lot better: the combination system WPDV used by Van Halteren and the Support Vector Machines used by Kudoh and Matsumoto. 6 Rel</context>
</contexts>
<marker>Kudoh, Matsumoto, 2000</marker>
<rawString>Taku Kudoh and Yuji Matsumoto. 2000. Use of support vector learning for chunk identification. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: the penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1829" citStr="Marcus et al., 1993" startWordPosition="290" endWordPosition="293">a member of one chunk Here is an example sentence: [NP He ] [vp reckons ] [NP the current account deficit] [vp will narrow] [pp to [NP only 1.8 billion] [pp in] [NP September] . Chunks have been represented as groups of words between square brackets. A tag next to the open bracket denotes the type of the chunk. As far as we know, there are no annotated corpora available which contain specific information about dividing sentences into chunks of words of arbitrary types. We have chosen to work with a corpus with parse information, the Wall Street Journal WSJ part of the Penn Treebank II corpus (Marcus et al., 1993), and to extract chunk information from the parse trees in this corpus. We will give a global description of the various chunk types in the next section. 3 Chunk Types The chunk types are based on the syntactic category part (i.e. without function tag) of the bracket label in the Treebank (cf. Bies (1995) p.35). Roughly, a chunk contains everything to the left of and including the syntactic head of the constituent of the same name. Some Treebank constituents do not have related chunks. The head of S (simple declarative clause) for example is normally thought to be the verb, but as the verb is </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: the penn treebank. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miles Osborne</author>
</authors>
<title>Shallow parsing as part-ofspeech tagging.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15487" citStr="Osborne (2000)" startWordPosition="2636" endWordPosition="2637">92.25% 92.12 Dejean 91.87% 91.31% 92.09 Koeling 92.08% 91.86% 91.97 Osborne 91.65% 92.23% 91.94 Veenstra and Van den Bosch 91.05% 92.03% 91.54 Pla, Molina and Prieto 90.63% 89.65% 90.14 Johansson 86.24% 88.25% 87.23 Vilain and Day 88.82% 82.91% 85.76 baseline 72.58% 82.14% 77.07 Table 2: Performance of the eleven systems on the test data. The baseline results have been obtained by selecting the most frequent chunk tag for each part-of-speech tag. incorporating chunk probabilities generated by a memory-based learning process. The two other statistical systems use maximum-entropy based methods. Osborne (2000) trained Ratnaparkhi&apos;s maximum-entropy POS tagger to output chunk tags. Koeling (2000) used a standard maximum-entropy learner for generating chunk tags from words and POS tags. Both have tested different feature combinations before finding an optimal one and their final results are close to each other. Three systems use system combination. Tjong Kim Sang (2000) trained and tested five memory-based learning systems to produce different representations of the chunk tags. A combination of the five by majority voting performed better than the individual parts. Van Halteren (2000) used Weighted Pr</context>
</contexts>
<marker>Osborne, 2000</marker>
<rawString>Miles Osborne. 2000. Shallow parsing as part-ofspeech tagging. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferran Pla</author>
<author>Antonio Molina</author>
<author>Natividad Prieto</author>
</authors>
<title>Improving chunking by means of lexical-contextual information in statistical language models.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Pla, Molina, Prieto, 2000</marker>
<rawString>Ferran Pla, Antonio Molina, and Natividad Prieto. 2000. Improving chunking by means of lexical-contextual information in statistical language models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third ACL Workshop on Very Large Corpora. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="809" citStr="Ramshaw and Marcus (1995)" startWordPosition="111" endWordPosition="114">nguage Technology Group ILK, Computational Linguistics University of Antwerp Tilburg University erikt@uia.ua.ac.be s.buchholz@kub.n1 Abstract We describe the CoNLL-2000 shared task: dividing text into syntactically related nonoverlapping groups of words, so-called text chunking. We give background information on the data sets, present a general overview of the systems that have taken part in the shared task and briefly discuss their performance. 1 Introduction Text chunking is a useful preprocessing step for parsing. There has been a large interest in recognizing non-overlapping noun phrases (Ramshaw and Marcus (1995) and follow-up papers) but relatively little has been written about identifying phrases of other syntactic categories. The CoNLL-2000 shared task attempts to fill this gap. 2 Task description Text chunking consists of dividing a text into phrases in such a way that syntactically related words become member of the same phrase. These phrases are non-overlapping which means that one word can only be a member of one chunk Here is an example sentence: [NP He ] [vp reckons ] [NP the current account deficit] [vp will narrow] [pp to [NP only 1.8 billion] [pp in] [NP September] . Chunks have been repre</context>
<context position="3319" citStr="Ramshaw and Marcus (1995)" startWordPosition="553" endWordPosition="556">t the argument NP, and the SBAR chunk consists of only the complementizer. There are several difficulties when converting trees into chunks. In the most simple case, a chunk is just a syntactic constituent without any further embedded constituents, like the NPs in our examples. In some cases, the chunk contains only what is left after other chunks have been removed from the constituent, cf. &amp;quot;(VP loves (NP Mary))&amp;quot; above, or ADJPs and PPs below. We will discuss some special cases during the following description of the individual chunk types. 3.1 NP Our NP chunks are very similar to the ones of Ramshaw and Marcus (1995). Specifically, possessive NP constructions are split in front of the possessive marker (e.g. [NP Eastern Airlines] [NP creditors]) and the handling of co127 ordinated NPs follows the Treebank annotators. However, as Ramshaw and Marcus do not describe the details of their conversion algorithm, results may differ in difficult cases, e.g. involving NAC and NX.1 An ADJP constituent inside an NP constituent becomes part of the NP chunk: (NP The (ADJP most volatile) form) [NP the most volatile form] 3.2 VP In the Treebank, verb phrases are highly embedded; see e.g. the following sentence which cont</context>
<context position="4634" citStr="Ramshaw and Marcus (1995)" startWordPosition="790" endWordPosition="793"> only contain one VP chunk: ((S (NP-SBJ-3 Mr. Icahn) (VP may not (VP want (S (NP-SBJ *-3) (VP to (VP sell ...))))) . )) [NP Mr. Icahn] [vp may not want to sell] It is still possible however to have one VP chunk directly follow another: [NP The impression [NP I] [vp have got] [vp is] [NP they] [vp &apos;d love to do] [PRT away] [pp with] [NP it]. In this case the two VP constituents did not overlap in the Treebank. Adverbs/adverbial phrases become part of the VP chunk (as long as they are in front of the main verb): (VP could (ADVP very well) (VP show ... )) [vp could very well show] In contrast to Ramshaw and Marcus (1995), predicative adjectives of the verb are not part of the VP chunk, e.g. in &amp;quot;[NP they [vp are 1 [paw unhappy ]&amp;quot;. In inverted sentences, the auxiliary verb is not part of any verb phrase in the Treebank. Consequently it does not belong to any VP chunk: ((S (SINV (CONJP Not only) does (NP-SBJ-1 your product) (VP have (S 1E.g. (NP-SBJ (NP Robin Leigh-Pemberton) , (NP (NAC Bank (PP of (NP England))) governor) ,) which we convert to [NP Robin Leigh-Pemberton ] , Bank [pp of] [Np England] [NP governor] whereas Ramshaw and Marcus state that C &amp;quot;governor&amp;quot; is not included in any baseNP chunk&apos;. (NP-SBJ *-</context>
<context position="9656" citStr="Ramshaw and Marcus (1995)" startWordPosition="1684" endWordPosition="1687">ajor problems] .&amp;quot; 3.7 Problems All chunks were automatically extracted from the parsed version of the Treebank, guided by the tree structure, the syntactic constituent labels, the part-of-speech tags and by knowledge about which tags can be heads of which constituents. However, some trees are very complex and some annotations are inconsistent. What to think about a VP in which the main verb is tagged as NN (common noun)? Either we allow NNs as heads of VPs (not very elegant but which is what we did) or we have a VP without a head. The first solution might also introduce errors elsewhere... As Ramshaw and Marcus (1995) already noted: &amp;quot;While this automatic derivation process introduced a small percentage of errors on its own, it was the only practical way both to provide the amount of training data required and to allow for fully-automatic testing.&amp;quot; 4 Data and Evaluation For the CoNLL shared task, we have chosen to work with the same sections of the Penn Treebank as the widely used data set for base noun phrase recognition (Ramshaw and Marcus, 1995): WSJ sections 15-18 of the Penn Treebank as training material and section 20 as test materia13. The chunks in the data were selected to match the descriptions in</context>
<context position="11725" citStr="Ramshaw and Marcus (1995)" startWordPosition="2039" endWordPosition="2042">unt % type 55081 51% NP (noun phrase) 21467 20% VP (verb phrase) 21281 20% PP (prepositional phrase) 4227 4% ADVP (adverb phrase) 2207 2% SBAR (subordinated clause) 2060 2% ADJP (adjective phrase) 556 1% PRT (particles) 56 0% CONJP (conjunction phrase) 31 0% INTJ (interjection) 10 0% LST (list marker) 2 0% UCP (unlike coordinated phrase) Table 1: Number of chunks per phrase type in the training data (211727 tokens, 106978 chunks). B-X first word of a chunk of type X I-X non-initial word in an X chunk 0 word outside of any chunk This representation type is based on a representation proposed by Ramshaw and Marcus (1995) for noun phrase chunks. The three tag groups are sufficient for encoding the chunks in the data since these are non-overlapping. Using these chunk tags makes it possible to approach the chunking task as a word classification task. We can use chunk tags for representing our example sentence in the following way: He/B-NP reckons/B-VP the/B-NP current/I-NP account/I-NP deficit/I-NP will/B-VP narrow/I-VP to/B-PP only/B-NP #/I-NP 1.8/I-NP billion/B-NP in/B-PP September/B-NP ./0 The output of a chunk recognizer may contain inconsistencies in the chunk tags in case a word tagged I-X follows a word t</context>
<context position="17151" citStr="Ramshaw and Marcus (1995)" startWordPosition="2902" endWordPosition="2905">aseline performance was obtained by selecting the chunk tag most frequently associated with a POS tag. All systems outperform the baseline. The majority of the systems reached an Fo=1 score between 91.50 and 92.50. Two approaches performed a lot better: the combination system WPDV used by Van Halteren and the Support Vector Machines used by Kudoh and Matsumoto. 6 Related Work In the early nineties, Abney (1991) proposed to approach parsing by starting with finding related chunks of words. By then, Church (1988) had already reported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary chunks as part of a parsing task but did not repor</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the Third ACL Workshop on Very Large Corpora. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Maximum Entropy Models for Natural Language Ambiguity Resolution.</title>
<date>1998</date>
<tech>PhD thesis</tech>
<institution>Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="17675" citStr="Ratnaparkhi (1998)" startWordPosition="2993" endWordPosition="2994">ported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary chunks as part of a parsing task but did not report on the chunking performance. Part of the Sparkle project has concentrated on finding various sorts of chunks for the different languages &apos;An elaborate overview of the work done on noun phrase chunking can be found on http://lcg-www.uia. ac.bererikt/research/np-chunking.html 131 (Carroll et al., 1997). 7 Concluding Remarks We have presented an introduction to the CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking. For this task we have generated tr</context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Adwait Ratnaparkhi. 1998. Maximum Entropy Models for Natural Language Ambiguity Resolution. PhD thesis Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
</authors>
<title>Text chunking by system combination.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15851" citStr="Sang (2000)" startWordPosition="2695" endWordPosition="2696">been obtained by selecting the most frequent chunk tag for each part-of-speech tag. incorporating chunk probabilities generated by a memory-based learning process. The two other statistical systems use maximum-entropy based methods. Osborne (2000) trained Ratnaparkhi&apos;s maximum-entropy POS tagger to output chunk tags. Koeling (2000) used a standard maximum-entropy learner for generating chunk tags from words and POS tags. Both have tested different feature combinations before finding an optimal one and their final results are close to each other. Three systems use system combination. Tjong Kim Sang (2000) trained and tested five memory-based learning systems to produce different representations of the chunk tags. A combination of the five by majority voting performed better than the individual parts. Van Halteren (2000) used Weighted Probability Distribution Voting (WPDV) for combining the results of four WPDV chunk taggers and a memory-based chunk tagger. Again the combination outperformed the individual systems. Kudoh and Matsumoto (2000) created 231 support vector machine classifiers to predict the unique pairs of chunk tags. The results of the classifiers were combined by a dynamic program</context>
</contexts>
<marker>Sang, 2000</marker>
<rawString>Erik F. Tjong Kim Sang. 2000. Text chunking by system combination. In Proceedings of CoNLL2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans van Halteren</author>
</authors>
<title>Chunking with wpdv models.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL2000.</booktitle>
<location>Lisbon, Portugal.</location>
<marker>van Halteren, 2000</marker>
<rawString>Hans van Halteren. 2000. Chunking with wpdv models. In Proceedings of CoNLL-2000 and LLL2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<date>1975</date>
<journal>Information Retrieval. Buttersworth.</journal>
<marker>van Rijsbergen, 1975</marker>
<rawString>C.J. van Rijsbergen. 1975. Information Retrieval. Buttersworth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorn Veenstra</author>
<author>Antal van den Bosch</author>
</authors>
<title>Single-classifier memory-based phrase chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Veenstra, van den Bosch, 2000</marker>
<rawString>Jorn Veenstra and Antal van den Bosch. 2000. Single-classifier memory-based phrase chunking. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorn Veenstra</author>
</authors>
<title>Memory-based text chunking.</title>
<date>1999</date>
<booktitle>Machine learning in human language technology, workshop at ACAI 99.</booktitle>
<editor>In Nikos Fakotakis, editor,</editor>
<contexts>
<context position="17510" citStr="Veenstra (1999)" startWordPosition="2963" endWordPosition="2964">ated Work In the early nineties, Abney (1991) proposed to approach parsing by starting with finding related chunks of words. By then, Church (1988) had already reported on recognition of base noun phrases with statistical methods. Ramshaw and Marcus (1995) approached chunking by using a machine learning method. Their work has inspired many others to study the application of learning methods to noun phrase chunking5. Other chunk types have not received the same attention as NP chunks. The most complete work is Buchholz et al. (1999), which presents results for NP, VP, PP, ADJP and ADVP chunks. Veenstra (1999) works with NP, VP and PP chunks. Both he and Buchholz et al. use data generated by the script that produced the CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary chunks as part of a parsing task but did not report on the chunking performance. Part of the Sparkle project has concentrated on finding various sorts of chunks for the different languages &apos;An elaborate overview of the work done on noun phrase chunking can be found on http://lcg-www.uia. ac.bererikt/research/np-chunking.html 131 (Carroll et al., 1997). 7 Concluding Remarks We have presented an introduction</context>
</contexts>
<marker>Veenstra, 1999</marker>
<rawString>Jorn Veenstra. 1999. Memory-based text chunking. In Nikos Fakotakis, editor, Machine learning in human language technology, workshop at ACAI 99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>David Day</author>
</authors>
<title>Phrase parsing with rule sequence processors: an application to the shared conll task.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="13267" citStr="Vilain and Day (2000)" startWordPosition="2285" endWordPosition="2288">found by the chunker (recall). And third, the Fo=1 rate which is equal to (132+1)*precision*recall / (02*precision+recall) with 0.1 (van Rijsbergen, 1975). The latter rate has been used as the target for optimization4. 5 Results The eleven systems that have been applied to the CoNLL-2000 shared task can be divided in four groups: 1. Rule-based systems: Villain and Day; Johansson; Dejean. 2. Memory-based systems: Veenstra and Van den Bosch. 3. Statistical systems: Pla, Molina and Prieto; Osborne; Koeling; Zhou, Tey and Su. 4. Combined systems: Tjong Kim Sang; Van Halteren; Kudoh and Matsumoto. Vilain and Day (2000) approached the shared task in three different ways. The most successful was an application of the Alembic parser which uses transformation-based rules. Johansson (2000) uses context-sensitive and contextfree rules for transforming part-of-speech (POS) tag sequences to chunk tag sequences. Dejean (2000) has applied the theory refinement system ALLiS to the shared task. In order to obtain a system which could process XML formatted data while using context information, he has used three extra tools. Veenstra and Van den Bosch (2000) examined different parameter settings of a memory-based learnin</context>
</contexts>
<marker>Vilain, Day, 2000</marker>
<rawString>Marc Vilain and David Day. 2000. Phrase parsing with rule sequence processors: an application to the shared conll task. In Proceedings of CoNLL2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
<author>TongGuan Tey</author>
</authors>
<title>Hybrid text chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL2000 and LLL-2000.</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Zhou, Su, Tey, 2000</marker>
<rawString>GuoDong Zhou, Jian Su, and TongGuan Tey. 2000. Hybrid text chunking. In Proceedings of CoNLL2000 and LLL-2000. Lisbon, Portugal.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>