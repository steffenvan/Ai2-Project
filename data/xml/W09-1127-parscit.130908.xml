<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.066370">
<title confidence="0.995786">
New Features for FrameNet – WordNet Mapping
</title>
<author confidence="0.942767">
Sara Tonelli and Daniele Pighin
</author>
<affiliation confidence="0.725164">
FBK-Irst, Human Language Technologies
</affiliation>
<address confidence="0.930068">
Via di Sommarive, 18 I-38100 Povo (TN) Italy
</address>
<email confidence="0.998456">
{satonelli,pighin}@fbk.eu
</email>
<sectionHeader confidence="0.995609" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999780366666667">
Many applications in the context of natural
language processing or information retrieval
may be largely improved if they were able to
fully exploit the rich semantic information an-
notated in high-quality, publicly available re-
sources such as the FrameNet and the Word-
Net databases. Nevertheless, the practical use
of similar resources is often biased by the
limited coverage of semantic phenomena that
they provide.
A natural solution to this problem would be to
automatically establish anchors between these
resources that would allow us 1) to jointly use
the encoded information, thus possibly over-
coming limitations of the individual corpora,
and 2) to extend each resource coverage by ex-
ploiting the information encoded in the others.
In this paper, we present a supervised learn-
ing framework for the mapping of FrameNet
lexical units onto WordNet synsets based on
a reduced set of novel and semantically rich
features. The automatically learnt mapping,
which we call MapNet, can be used 1) to ex-
tend frame sets in the English FrameNet, 2)
to populate frame sets in the Italian FrameNet
via MultiWordNet and 3) to add frame labels
to the MultiSemCor corpus. Our evaluation on
these tasks shows that the proposed approach
is viable and can result in accurate automatic
annotations.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918333333333">
In recent years, the integration of manually-built
lexical resources into NLP systems has received
growing interest. In particular, resources annotated
with the surface realization of semantic roles, like
FrameNet (Baker et al., 1998) or PropBank (Palmer
et al., 2005) have shown to convey an improve-
ment in several NLP tasks, from question answer-
ing (Shen and Lapata, 2007) to textual entailment
(Burchardt et al., 2007) and shallow semantic pars-
ing (Giuglea and Moschitti, 2006). Nonetheless, the
main limitation of such resources is their poor cov-
erage, particularly as regards FrameNet. Indeed, the
latest FrameNet release (v. 1.3) contains 10,195 lex-
ical units (LUs), 3,380 of which are described only
by a lexicographic definition without any example
sentence. In order to cope with this lack of data, it
would be useful to map frame information onto other
lexical resources with a broader coverage. We be-
lieve that WordNet (Fellbaum, 1998), with 210,000
entries in version 3.0, can represent a suitable re-
source for this task. In fact, both FrameNet and
WordNet group together semantically similar words,
and provide a hierarchical representation of the lex-
ical knowledge (in WordNet the relations between
synsets, in FrameNet between frames, see Ruppen-
hofer et al. (2006)). On the other hand, WordNet
provides a more extensive coverage particularly for
adjectives and nouns denoting artifacts and natural
kinds, that are mostly neglected in FrameNet.
In this paper, we present an approach using Sup-
port Vector Machines (SVM) to map FrameNet lex-
ical units to WordNet synsets. The proposed ap-
proach addresses some of the limitations of previous
works on the same task (see for example De Cao
et al. (2008) and Johansson and Nugues (2007)).
Most notably, as we do not train the SVM on a per-
</bodyText>
<page confidence="0.987612">
219
</page>
<note confidence="0.9899">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 219–227,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99994028">
frame basis, our model is able to cope also with
those frames that have little or no annotated sen-
tences to support the frame description. After learn-
ing a very fast model on a small set of annotated
lexical unit-synset pairs, we can automatically es-
tablish new mappings in never-seen-before pairs and
use them for our applications. We will evaluate the
effect of the induced mappings on two tasks: the au-
tomatic enrichment of lexical unit sets in the English
and Italian FrameNet via MultiWordNet (Pianta et
al., 2002), and the annotation of the MultiSemCor
corpus (Bentivogli and Pianta, 2005) with frame la-
bels.
The discussion is structured as follows: in
Section 2 we review the main characteristics of
FrameNet and WordNet; in Section 3 we discuss
previous attempts to establish a mapping between
them; in Section 4 we describe our supervised ap-
proach to map lexical units onto synsets; Section 5
details the dataset that we employed for our experi-
ments; Section 6 describes the novel features that we
used to characterize the mapping; Section 7 details
the results of our experiments; in Section 8 we ap-
ply the mapping to three resource annotation tasks;
finally, in Section 9 we draw our conclusions.
</bodyText>
<sectionHeader confidence="0.946529" genericHeader="introduction">
2 FrameNet and WordNet
</sectionHeader>
<bodyText confidence="0.9999408">
The FrameNet database (Baker et al. (1998), Fill-
more et al. (2003)) is an English lexical resource
based on the description of some prototypical sit-
uations, the frames, and the frame-evoking words
or expressions associated to them, the lexical units
(LU). Every frame corresponds to a scenario involv-
ing a set of participants, the frame elements (FEs),
that are typically the semantic arguments shared by
all LUs in a frame.
We report in Table 1 the information recorded
in FrameNet for the CAUSE TO WAKE frame. In
the first row there is the frame definition with the
relevant frame elements, namely AGENT, CAUSE,
SLEEPER and SLEEP STATE. Then there is the list
of all lexical units evoking the frame and the corre-
sponding part of speech. Note that, differently from
WordNet synsets, a frame can contain LUs with dif-
ferent PoS as well as antonymous words. In the
last row, an example for each frame element is re-
ported. The lexical unit is underlined, while the con-
</bodyText>
<table confidence="0.987166307692308">
Frame: CAUSE TO WAKE
Def. An AGENT or CAUSE causes a SLEEPER to
transition from the SLEEP STATE to wakeful
consciousness.
LUs awaken.v, get up.v, rouse.v, wake.v, wake up.v
singe.v, sizzle.v, stew.v
FEs AGENT We tried to rouse Peter.
CAUSE
SLEEPER
SL STATE
The rain woke the children.
Neighbors were awakened by screams.
He woke Constance from her doze.
</table>
<tableCaption confidence="0.999926">
Table 1: Frame CAUSE TO WAKE
</tableCaption>
<bodyText confidence="0.997475085714286">
stituent bearing the FE label is written in italics. The
FrameNet resource is corpus-based, i.e. every lexi-
cal unit should be instantiated by at least one ex-
ample sentence. Besides, every lexical unit comes
with a manual lexicographic definition. The latest
database release contains 795 frame definitions and
10,195 lexical units, instantiated through approxi-
mately 140.000 example sentences. Despite this, the
database shows coverage problems when exploited
for NLP tasks, and is still being extended by the
Berkeley group at ICSI.
WordNet (Fellbaum, 1998) is a lexical resource
for English based on psycholinguistics principles
and developed at Princeton University. It has been
conceived as a computational resource aimed at im-
proving some drawbacks of traditional dictionaries
such as the circularity of definitions and the ambigu-
ity of sense references. At present, it covers the ma-
jority of nouns, verbs, adjectives and adverbs in the
English language, organized in synonym sets called
synsets, which correspond to concepts. WordNet
also includes a rich set of semantic relations across
concepts, such as hyponymy, entailment, antonymy,
similar-to, etc. Each synset is encoded as a set of
synomyms having the same part of speech and de-
scribed by a definition or gloss. In some cases, one
or more example sentences may also be reported.
The Princeton English WordNet has also been aug-
mented with domain labels (Magnini and Cavagli`a,
2000) that group synsets into homogeneous clusters
in order to reduce polysemy in the database.
We believe that mapping FrameNet LUs to Word-
Net synsets would have at least three different ad-
vantages: 1) for the English FrameNet, it would au-
tomatically increase the number of LUs for frame by
</bodyText>
<page confidence="0.990808">
220
</page>
<bodyText confidence="0.999964590909091">
importing all synonyms from the mapped synset(s),
and would allow to exploit the semantic and lex-
ical relations in WordNet to enrich the informa-
tion encoded in FrameNet. This would help cop-
ing with coverage problems and disambiguating the
LU senses. 2) For WordNet, it would be possible
to add a semantic layer between the synset level
and the domain level represented by frame rela-
tions, and to enrich the synsets with a computa-
tional description of the situation they refer to to-
gether with the semantic roles involved. 3) Since
frames are mostly defined at conceptual level, the
FrameNet model is particularly suitable for cross-
lingual induction (Boas, 2005). In this framework,
the FrameNet-WordNet mapping could help mod-
elling frame-based resources for new languages us-
ing minimal supervision. In fact, the availability of
multilingual resources like MultiWordNet (Pianta et
al., 2002) and EuroWordNet (Vossen, 1998) allows
to easily populate frame sets for new languages with
reduced human effort and near-manual quality by
importing all lemmas from the mapped synsets.
</bodyText>
<sectionHeader confidence="0.999951" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.999951150943396">
Several experiments have been carried out to de-
velop a FrameNet-WordNet mapping and test its
applications. Shi and Mihalcea (2005) described
a semi-automatic approach to exploit VerbNet as a
bridge between FrameNet and WordNet for verbs,
using synonym and hyponym relations and simi-
larity between Levin’s verb classes and FrameNet
frames. Their mapping was used to develop a rule-
based semantic parser (Shi and Mihalcea, 2004) as
well as to detect target words and assign frames for
verbs in an open text (Honnibal and Hawker, 2005).
Burchardt et al. (2005) presented a rule-based
system for the assignment of FrameNet frames by
way of a “detour via WordNet”. They applied
a WordNet-based WSD system to annotate lexical
units in unseen texts with their contextually de-
termined WordNet synsets and then exploited syn-
onyms and hypernyms information to assign the best
frame to the lexical units. The system was inte-
grated into the SALSA RTE system for textual en-
tailment (Burchardt et al., 2007) to cope with sparse-
data problems in the automatic assignment of frame
labels.
Johansson and Nugues (2007) created a feature
representation for every WordNet lemma and used
it to train an SVM classifier for each frame that tells
whether a lemma belongs to the frame or not. The
best-performing feature representation was built us-
ing the sequence of unique identifiers for each synset
in its hypernym tree and weigthing the synsets ac-
cording to their relative frequency in the SemCor
corpus. They used the mapping in the Semeval-2007
task on frame-semantic structure extraction (Baker
et al., 2007) in order to find target words in open
text and assign frames.
Crespo and Buitelaar (2008) carried out an auto-
matic mapping of medical-oriented frames to Word-
Net synsets applying a Statistical Hypothesis Test-
ing to select synsets attached to a lexical unit that
were statistically significant using a given refer-
ence corpus. The mapping obtained was used
to expand Spanish FrameNet using EuroWordNet
(Vossen, 1998) and evaluation was carried out on the
Spanish lexical units obtained after mapping.
Given a set of lexical units, De Cao et al. (2008)
propose a method to detect the set of suitable Word-
Net senses able to evoke a frame by applying a simi-
larity function that exploits different WordNet infor-
mation, namely conceptual density for nouns, syn-
onymy and co-hyponymy for verbs and synonymy
for adjectives. The mapping approach was applied
also to LU induction for the English FrameNet and
for Italian frames via MultiWordNet.
</bodyText>
<sectionHeader confidence="0.985746" genericHeader="method">
4 Problem formulation
</sectionHeader>
<bodyText confidence="0.999045357142857">
Our objective is to be able to assign to every lex-
ical unit l, belonging to a frame Fi defined in the
FrameNet database, one or more WordNet senses
that best express the meaning of l. More specifically,
for every l ∈ Fi, we consider the set of all WordNet
senses where l appears, CandSet, and then find the
best WordNet sense(s) bests ⊂ CandSet that express
the meaning of l.
For example, the lexical unit rouse.v belonging to
the CAUSE TO WAKE frame, is defined in FrameNet
as “bring out of sleep; awaken”. Its CandSet com-
prises 4 senses1: 1# bestir, rouse (become active);
2# rout out, drive out, force out, rouse (force or
drive out); #3 agitate, rouse, turn on, charge, com-
</bodyText>
<footnote confidence="0.991746">
1The gloss is reported between parenthesis
</footnote>
<page confidence="0.997298">
221
</page>
<bodyText confidence="0.999844229166667">
move, excite, charge up (cause to be agitated, ex-
cited or roused); #4 awaken, wake, waken, rouse,
wake up, arouse (cause to become awake or con-
scious). In this example, bests = {#4} for rouse.v
in CAUSE TO WAKE.
We aim at creating a mapping system that
can achieve a good accuracy also with poorly-
documented lexical units and frames. In fact, we be-
lieve that under real-usage conditions, the automatic
induction of LUs is typically required for frames
with a smaller LU set, especially for those with only
one element. In the FrameNet database (v. 1.3), 33
frames out of 720 are described only by one lex-
ical unit, and 63 are described by two. Further-
more, more than 3,000 lexical units are character-
ized only by the lexicographic definition and are
not provided with example sentences. For this rea-
son, we suggest an approach that makes also use
of usually unexploited information in the FrameNet
database, namely the definition associated to every
lexical unit, and disregards example sentences.
This is the main point of difference between
our and some previous works, e.g. Johansson and
Nugues (2007) and De Cao et al. (2008), where un-
supervised approaches are proposed which strongly
rely either on the number of lexical units in a frame
or on the example sentences available for l in the
FrameNet corpus. We claim that the relative short
time necessary to annotate a small dataset of frame-
synset pairs will result in a more reliable mapping
system and, as a consequence, in consistent time
savings when we actually try to use the mappings
for some tasks. The ability to cope with different
cases while retaining a good accuracy will allow to
bootstrap the mapping process in many cases where
other approaches would have failed due to lack of
training data.
To this end, we can train a binary classifier
that, given l and CandSet, for each pair (l,s),
s E CandSet, delivers a positive answer if s E
bests, and a negative one otherwise. To follow on
the previous example, for rouse.v we would have
4 classifier examples, i.e. the pairs (rouse.v,#1),
(rouse.v,#2), (rouse.v,#3) and (rouse.v,#4). Of
these, only the last would be considered a positive
instance. As a learning framework, we decided to
use SVMs due to their classification accuracy and
robustness to noisy data (Vapnik, 1998).
</bodyText>
<sectionHeader confidence="0.978701" genericHeader="method">
5 Dataset description
</sectionHeader>
<bodyText confidence="0.999946">
In order to train and test the classifier, we created
a gold standard by manually annotating 2,158 LU-
synset pairs as positive or negative examples. We
don’t have data about inter-annotator agreement be-
cause the dataset was developed only by one annota-
tor, but De Cao et al. (2008) report 0.90 as Cohen’s
Kappa computed over 192 LU-synset pairs for the
same mapping task. This confirms that senses and
lexical units are highly correlated and that the map-
ping is semantically motivated.
The annotation process can be carried out in rea-
sonable time. It took approximately two work days
to an expert annotator to manually annotate the
2,158 pairs that make up our gold standard. The lexi-
cal units were randomly selected from the FrameNet
database regardless of their part of speech or amount
of annotated data in the FrameNet database. For
each lexical unit, we extracted from WordNet the
synsets where the LU appears, and for each of them
we assigned a positive label in case the LU-synset
pairs share the same meaning, and a negative label
otherwise. Statistics about the dataset are reported
in Table 2.
</bodyText>
<table confidence="0.999406833333333">
N. of LU-synset pairs 2,158
N. of lexical units 617
Verbal lexical units 39%
Nominal lexical units 51%
Adjectival lexical units 9%
Adverbial lexical units &lt;1%
Targeted frames 386
Pairs annotated as positive 32%
Pairs annotated as negative 68%
Average polysemy 3.49
LUs with one candidate synset 204
LUs with 10 or more cand. synsets 32
</table>
<tableCaption confidence="0.999705">
Table 2: Statistics on the dataset
</tableCaption>
<bodyText confidence="0.999923857142857">
The 386 frames that are present in the dataset rep-
resent about one half of all lexicalized frames in
the FrameNet database. This proves that, despite
the limited size of the dataset, it is well representa-
tive of FrameNet characteristics. This is confirmed
by the distribution of the part of speech. In fact,
in the FrameNet database about 41% of the LUs
</bodyText>
<page confidence="0.98739">
222
</page>
<bodyText confidence="0.9998956">
are nouns, 40% are verbs, 17% are adjectives and
&lt;1% are adverbs (the rest are prepositions, which
are not included in our experiment because they are
not present in WordNet). In our dataset, the per-
centage of nouns is higher, but the PoS ranking by
frequency is the same, with nouns being the most
frequent PoS and adverbs the less represented. The
average polysemy corresponds to the average num-
ber of candidate synsets for every LU in the dataset.
Note that the high number of lexical units with only
one candidate does not imply a more straightforward
mapping, because in some cases the only candidate
represents a negative example. In fact, a LU could
be encoded in a frame that does not correspond to
the sense expressed by the synset.
</bodyText>
<sectionHeader confidence="0.996376" genericHeader="method">
6 Feature description
</sectionHeader>
<bodyText confidence="0.999837289473685">
For every LU-synset pair in the gold standard, we
extracted a set of features that characterize different
aspects of the mapping. In the remainder, we detail
the meaning as well as the feature extraction proce-
dure of each of them.
Stem overlap Both WordNet glosses and LU def-
initions in FrameNet are manually written by lex-
icographers. We noticed that when they share the
same sense, they show high similarity, and some-
times are even identical. For example, the defini-
tion of thicken in the Change of consistency frame
is “become thick or thicker”, which is identical to
the WordNet gloss of synset n. v#00300319. The
thicken lemma occurs in three WordNet synsets, and
in each of them it is the only lemma available, so no
other information could be exploited for the sense
disambiguation.
We believe that this information could help in the
choice of the best candidate synset, so we stemmed
all the words in the synset gloss and in the lexical
unit definition and measured their overlap. As fea-
tures, we use the ratio between the number of over-
lapping words and the number of words in the defi-
nition, both for the gloss and the LU description.
Prevalent Domain and Synset Since a frame rep-
resents a prototypical situation evoked by the set
of its lexical units, our intuition is that it should
be possible to assign it to a WordNet domain, that
groups homogeneous clusters of semantically simi-
lar synsets (see Section 2).
Given the LU-synset pair (l, s), l E Fi, s E
CandSet, we extract all the lexical units in Fi and
then build a set AllCandSet of pairs (sj, cj), where
sj is a synset in which at least one li E Fi appears,
and cj is the count of lexical units that are found in
sj.
We exploit the information conveyed by AllCan-
dSet in two ways: i) if there is a prevalent Word-
Net domain that characterizes the majority of the
synsets in AllCandSet, and s E CandSet belongs
to that same domain, we add a boolean feature to
the feature vector representing (l, s); ii) if s is the
synset with the highest count in AllCandSet, i.e. if
s = sj and cj &gt; cib(sj, cj) E AllCandSet, i =� j,
then we add another boolean feature to encode this
information.
Cross-lingual parallelism Our idea is that, if an
English lexical unit and its Italian translation belong
to the same frame, they are likely to appear also in
the same MultiWordNet synset, and the latter would
be a good candidate for mapping. In fact, in Multi-
WordNet the Italian WordNet is strictly aligned with
the Princeton WordNet 1.6, with synsets having the
same id for both languages, and also semantic re-
lations are preserved in the multilingual hierarchy.
Since no Italian FrameNet is available yet, we ex-
tended the parallel English-Italian corpus annotated
on both sides with frame information described in
Tonelli and Pianta (2008) by adding and annotating
400 new parallel sentences. The final corpus con-
tains about 1,000 pairs of parallel sentences where
the English and the Italian lexical unit belong to the
same frame.
Given a pair (l, s), we check if l appears also in
the corpus with the frame label Fi and extract its
Italian translation lit. If lit appears also in the Italian
version of synset s in MultiWordNet, we consider s
as a good candidate for the mapping of l and encode
this information as a binary feature.
Simple synset-frame overlap Intuitively, the
more lemmas a frame and a synset have in common,
the more semantically similar they are. In order to
take into account this similarity in our feature vec-
tor, given the pair (l, s), l E Fi, we extract all lexical
units in Fi and all lemmas in s and we compute the
number of overlapping elements. Then we divide
</bodyText>
<page confidence="0.99716">
223
</page>
<bodyText confidence="0.99996892">
the value by the number of synsets where the same
overlapping element(s) occur.
As an example, the words tank and tank car in
the Vehicle frame, occur together only in the fourth
synset related to tank, which therefore will have a
higher value for this feature.
Extended synset-frame overlap This feature is a
generalization of overlapping value described above.
In fact, we noticed that the hypernym information
in WordNet can help disambiguating the synsets.
Therefore, we take into account not only the over-
laps according to the previous criterion, but also the
number of overlapping words between the lexical
units in a frame and the hypernyms of a synset. For
example, the party.n lexical unit in the AGGREGATE
frame has 5 senses in WordNet. According to the
previous criterion, there is no overlap between the
LUs in the frame and the lemmas in any of the five
synsets. Instead, if we look at the direct hypernym
relation of party, we find that sense #3 is also de-
scribed as set, circle, band, that are also lexical units
of AGGREGATE.
In those cases where the hypernym relation is not
defined, e.g. adjectives, we used the similar-to rela-
tion.
</bodyText>
<sectionHeader confidence="0.968084" genericHeader="method">
7 Experimental setup and evaluation
</sectionHeader>
<bodyText confidence="0.999911368421053">
To evaluate our methodology we carried out a 10-
fold cross validation using the available data, split-
ting them in 10 non-overlapping sets. For each itera-
tion, 70% of the data was used for training, 30% for
testing. All the splits were generated so as to main-
tain a balance between positive and negative exam-
ples in the training and test sets.
We used the SVM optimizer SVM-
Light2 (Joachims, 1999), and applied polynomial
kernels (poly) of different degrees (i.e. 1 through
4) in order to select the configuration with the best
generalization capabilities. The accuracy is mea-
sured in terms of Precision, Recall and F1 measure,
i.e. the harmonic average between Precision and
Recall. For the sake of annotation, it is important
that an automatic system be very precise, thus not
producing wrong annotations. On the other hand,
the higher the recall, the larger the amount of data
that the system will be able to annotate.
</bodyText>
<footnote confidence="0.99087">
2Available at http://svmlight.joachims.org/
</footnote>
<bodyText confidence="0.999867458333333">
The macro-average of the classifier accuracy for
the different configurations is shown in Table 3. We
report results for linear kernel (i.e. poly 1), maxi-
mizing recall and f-measure, and for polynomial ker-
nel of degree 2 (i.e. poly 2), scoring the highest pre-
cision. In general , we notice that all our models
have a higher precision than recall, but overall are
quite balanced. Different polynomial kernels (i.e.
conjunction of features) do not produce very rele-
vant differences in the results, suggesting that the
features that we employed encode significant infor-
mation and have a relevance if considered indepen-
dently.
As a comparison, we also carried out the same
evaluation by setting a manual threshold and con-
sidering a LU-synset pair as a positive example if
the sum of the feature values was above the thresh-
old. We chose two different threshold values, the
first (Row 1 in Table 3) selected so as to have com-
parable precision with the most precise SVM model
(i.e. poly2), the second (Row 2) selected to have
recall comparable with poly1, i.e. the SVM model
with highest recall. In the former case, the model has
a recall that is less than half than poly2, i.e. 0.214
vs. 0.569, meaning that such model would establish
a half of the mappings while making the same per-
centage of mistakes. In the latter, the precision of
the SVM classifier is 0.114 points higher, i.e. 0.794
vs. 0.680, meaning the SVM can retrieve as many
mappings but making 15% less errors.
In order to investigate the impact of different fea-
tures on the classifier performance, we also consid-
ered three different groups of features separately:
the ones based on stem overlap, those computed
for prevalent domain and synset, and the features
for simple and extended frame – synset overlap.
We did not take into account cross-lingual paral-
lelism because it is one single feature whose cover-
age strongly relies on the parallel corpus available.
As a consequence, it is not possible to test the fea-
ture in isolation due to data sparseness.
Results are shown in Table 3, in the second group
of rows. Also in this case, we carried out a 10-
fold cross validation using a polynomial kernel of
degree 2. The stem overlap features, which to our
best knowledge are an original contribution of our
approach, score the highest recall among the three
groups. This confirms our intuition that LU defini-
</bodyText>
<page confidence="0.995519">
224
</page>
<bodyText confidence="0.989270944444444">
tions and WordNet glosses can help extending the
number of mapped LUs, including those that are
poorly annotated. For instance, if we consider the
KNOT CREATION frame, having only tie.v as LU,
the features about prevalent domain &amp; synset and
about synset-frame overlap would hardly be infor-
mative, while stem overlap generally achieves a con-
sistent performance regardless of the LU set. In
fact, tie.v is correctly mapped to synset v#00095054
based on their similar definition (respectively “to
form a knot” and “form a knot or bow in”). Best
precision was scored by the feature group consider-
ing prevalent domain &amp; synset, which are also new
features introduced by our approach. The positive
effect of combining all features is clearly shown by
comparing the results obtained with individual fea-
ture groups against the figures in the row labeled
poly2.
</bodyText>
<table confidence="0.999621">
Prec. Recall F1
Man. thresh. (P) 0.789 0.214 0.337
Man. thresh. (F1) 0.680 0.662 0.671
Stem Overlap 0.679 0.487 0.567
Prev.Dom.&amp; Syn. 0.756 0.434 0.551
Syn.- Frame Overlap 0.717 0.388 0.504
poly1 0.761 0.613 0.679
poly2 0.794 0.569 0.663
</table>
<tableCaption confidence="0.999681">
Table 3: Mapping evaluation
</tableCaption>
<sectionHeader confidence="0.625298" genericHeader="evaluation">
8 MapNet and its applications
</sectionHeader>
<bodyText confidence="0.990990642857143">
Since we aim at assigning at least one synset to ev-
ery lexical unit in FrameNet, we considered all the
frames and for every LU in the database we created
a list of LU-synset pairs. We re-trained the clas-
sifier using the whole annotated gold standard and
classified all the candidate pairs. The mapping pro-
duced between the two resources, that we call Map-
Net, comprises 5,162 pairs. Statistics on MapNet are
reported in table 4.
About one thousand lexical units in FrameNet
have no candidate synsets because the lemma is not
present in WordNet. The remaining LUs have 3.69
candidate synsets each on average, similarly to the
average polysemy reported for the gold standard (see
</bodyText>
<tableCaption confidence="0.941728">
Table 2). This confirms our hypothesis that the data
used for training are well representative of the char-
</tableCaption>
<table confidence="0.998697">
N. of LUs in FrameNet 10,100
N. of LUs with at least one syn.cand. 9,120
N. of LU-synset candidate pairs 33,698
N. of mapped pairs 5,162
</table>
<tableCaption confidence="0.999792">
Table 4: Statistics on the mapping
</tableCaption>
<bodyText confidence="0.997024333333333">
acteristics of the whole resource. We expect about
80% of these mappings to be correct, i.e. in line
with the precision of the classifier.
</bodyText>
<subsectionHeader confidence="0.997615">
8.1 Automatic FrameNet extension
</subsectionHeader>
<bodyText confidence="0.999937454545455">
MapNet can be easily exploited to automatically ex-
tend FrameNet coverage, in particular to extend the
set of lexical units for each frame. In fact, we can
assume that all lemmas in the mapped synsets have
the same meaning of the LUs in the corresponding
frames. We use MapNet to extract from WordNet
the lemmas in the mapped synsets and add them to
the frames.
For English FrameNet, we can acquire 4,265 new
lexical units for 521 frames. In this way, we would
extend FrameNet size by almost 42%. In the ran-
dom evaluation of 100 newly acquired LUs belong-
ing to 100 different frames, we assessed a precision
of 78%. For the Italian side, we extract 6,429 lexi-
cal units for 561 frames. Since no Italian FrameNet
has been developed yet, this would represent a first
attempt to create this resource by automatically pop-
ulating the frames. We evaluate the content of 15
complete frames containing 191 Italian LUs. The
assigned LUs are correct in 88% of the considered
cases, which represent a promising result w.r.t. the
unsupervised creation of Italian FrameNet.
The difference in the evaluation for the two lan-
guages most likely lies in the smaller number of
synsets on the Italian side of MultiWordNet if com-
pared to the English, which results in less ambigu-
ity. Furthermore, we should consider that the task
for Italian is easier than for English, since in the for-
mer case we are building a resource from scratch,
while in the latter we are extending an already exist-
ing resource with lexical units which are most likely
peripheral with respect to those already present in
the database.
</bodyText>
<page confidence="0.995575">
225
</page>
<note confidence="0.5314725">
8.2 Frame annotation of MultiSemCor of COOKING CREATION and ATTACHING instead
of INCHOATIVE ATTACHING.
</note>
<bodyText confidence="0.999896086956522">
MultiSemCor (Bentivogli and Pianta, 2005) is an
English/Italian parallel corpus, aligned at word
level and annotated with PoS, lemma and Word-
Net synsets. The parallel corpus was created start-
ing from the SemCor corpus, which is a subset of
the English Brown corpus containing about 700,000
running words. The corpus was first manually trans-
lated into Italian. Then, the procedure of transferring
word sense annotations from English to Italian was
carried out automatically.
We apply MapNet to enrich the corpus with frame
information. We believe that this procedure would
be interesting from different point of views. Not
only we would enrich the resource with a new anno-
tation layer, but we would also automatically acquire
a large set of English and Italian sentences having a
lexical unit with a frame label. For the English side,
it is a good solution to automatically extract a dataset
with frame information and train, for example, a ma-
chine learning system for frame identification. For
the Italian side, it represents a good starting point for
the creation of a large annotated corpus with frame
information, the base for a future Italian FrameNet.
MultiSemCor contains 12,843 parallel sentences.
If we apply MapNet to the corpus, we produce
27,793 annotated instances in English and 23,872 in
Italian, i.e. about two lexical units per sentence. The
different amount of annotated sentences depends on
the fact that in MultiSemCor some synset annota-
tions have not been transferred from English to Ital-
ian. From both sides of the resulting corpus, we
randomly selected 200 sentences labeled with 200
different frames, and evaluated the annotation qual-
ity. As for the English corpus, 75% of the sen-
tences was annotated with the correct frame label,
while on the Italian side they were 70%. This re-
sult is in line with the expectations, since Map-
Net was developed with 0.79 precision. Besides,
synset annotation on the English side of MultiSem-
Cor was carried out by hand, while annotation in
Italian was automatically acquired by transferring
the information from the English corpus (precision
0.86). This explains why the resulting annotation
for English is slightly better than for Italian. In some
cases, the wrongly annotated frame was strictly con-
nected to the right one, i.e. APPLY HEAT instead
</bodyText>
<sectionHeader confidence="0.996142" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999986709677419">
We proposed a new method to map FrameNet LUs
to WordNet synsets using SVM with minimal super-
vision effort.
To our best knowledge, this is the only approach
to the task that exploits features based on stem over-
lap between LU definition and synset gloss and
that makes use of information about WordNet do-
mains. Differently from other models, the SVM
is not trained on a per-frame basis and we do not
rely on the number of the annotated sentences for a
LU in the FrameNet corpus, thus our mapping al-
gorithm performs well also with poorly-annotated
LUs. After creating MapNet, the mapping be-
tween FrameNet and WordNet, we applied it to three
tasks: the automatic induction of new LUs for En-
glish FrameNet, the population of frames for Italian
FrameNet and the annotation of the MultiSemCor
corpus with frame information. A preliminary eval-
uation shows that the mapping can significantly re-
duce the manual effort for the development and the
extension of FrameNet-like resources, both in the
phase of corpus annotation and of frame population.
In the future, we plan to improve the algorithm
by introducing syntactic features for assessing simi-
larity between LU definitions and WordNet glosses.
We also want to merge all information extracted and
collected for Italian FrameNet and deliver a seed
version of the resource to be validated. Finally, we
plan to extend the mapping to all languages included
in MultiWordNet, i.e. Spanish, Portuguese, Hebrew
and Romanian.
</bodyText>
<sectionHeader confidence="0.994957" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998345333333333">
We thank Roberto Basili and Diego De Cao for shar-
ing with us their gold standard of frame – synset
mappings.
</bodyText>
<page confidence="0.997564">
226
</page>
<sectionHeader confidence="0.995891" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99983153125">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of the 36th ACL Meeting and 17th ICCL Confer-
ence. Morgan Kaufmann.
Collin F. Baker, Michael Ellsworth, and Katrin Erk.
2007. SemEval-2007 Task 10: Frame Semantic Struc-
ture Extraction. In Proceedings of the Fourth Interna-
tional Workshop on Semantic Evaluations (SemEval-
2007), pages 99–104, Prague, CZ, June.
Luisa Bentivogli and Emanuele Pianta. 2005. Exploiting
Parallel Texts in the Creation of Multilingual Seman-
tically Annotated Resources: The MultiSemCor Cor-
pus. Natural Language Engineering, Special Issue on
Parallel Texts, 11(03):247–261, September.
Hans C. Boas. 2005. Semantic frames as interlingual
representations for multilingual lexical databases. In-
ternational Journal of Lexicography, 18(4):445–478.
Aljoscha Burchardt, Katrin Erk, and Annette Frank.
2005. A WordNet detour to FrameNet. In B. Fis-
seni, H. Schmitz, B. Schr¨oder, and P. Wagner, editors,
Sprachtechnologie, mobile Kommunikation und lingis-
tische Resourcen, Frankfurt am Main, Germany. Peter
Lang.
Aljoscha Burchardt, Nils Reiter, Stefan Thater, and An-
nette Frank. 2007. A semantic approach to textual
entailment: System evaluation and task analysis. In
Proceedings of Pascal RTE-3 Challenge, Prague, CZ.
Diego De Cao, Danilo Croce, Marco Pennacchiotti, and
Roberto Basili. 2008. Combining Word Sense and
Usage for modeling Frame Semantics. In Proceedings
of STEP 2008, Venice, Italy.
Mario Crespo and Paul Buitelaar. 2008. Domain-specific
English-to-Spanish Translation of FrameNet. In Proc.
of LREC 2008, Marrakech.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
C.J. Fillmore, C.R. Johnson, and M. R. L. Petruck. 2003.
Background to FrameNet. International Journal of
Lexicography, 16:235–250, September.
Ana-Maria Giuglea and Alessandro Moschitti. 2006. Se-
mantic role labeling via FrameNet, VerbNet and Prop-
Bank. In Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th an-
nual ACL meeting, pages 929–936, Morristown, NJ,
US. Association for Computational Linguistics.
Matthew Honnibal and Tobias Hawker. 2005. Identify-
ing FrameNet frames for verbs from a real-text corpus.
In Proceedings of Australasian Language Technology
Workshop 2005.
Thorsten Joachims. 1999. Making large-scale sup-
port vector machine learning practical. In Bernhard
Sch¨olkopf, Christopher J. C. Burges, and Alexander J
Smola, editors, Advances in kernel methods: support
vector learning, pages 169–184. MIT Press, Cam-
bridge, MA, USA.
R. Johansson and P. Nugues. 2007. Using WordNet to
extend FrameNet coverage. In Proc. of the Workshop
on Building Frame-semantic Resources for Scandina-
vian and Baltic Languages, at NODALIDA, Tartu.
Bernardo Magnini and Gabriela Cavagli`a. 2000. Inte-
grating Subject Field Codes into WordNet. In Pro-
ceedings of LREC 2000, pages 1413–1418, Athens,
Greece.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Corpus
of Semantic Roles. Computational Linguistics, 31.
Emanuele Pianta, Luisa Bentivogli, and Christian Gi-
rardi. 2002. MultiWordNet: developing an aligned
multilingual database. In First International Confer-
ence on Global WordNet, pages 292–302, Mysore, In-
dia.
Josef Ruppenhofer, Michael Ellsworth, Miriam R.L.
Petruck, Christopher R. Johnson, and Jan
Scheffczyk. 2006. FrameNet II: Ex-
tended Theory and Practice. Available at
http://framenet.icsi.berkeley.edu/book/book.html.
Dan Shen and Mirella Lapata. 2007. Using Semantic
Roles to Improve Question Answering. In Proceed-
ings of EMNLP and CONLL, pages 12–21, Prague,
CZ.
Lei Shi and Rada Mihalcea. 2004. Open Text Semantic
Parsing Using FrameNet and WordNet. In Proceed-
ings of HLT-NAACL 2004.
Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
gether: Combining FrameNet, VerbNet and WordNet
for Robust Semantic Parsing. In Proceedings of CI-
CLing 2005, pages 100–111. Springer.
Sara Tonelli and Emanuele Pianta. 2008. Frame Infor-
mation Transfer from English to Italian. In European
Language Resources Association (ELRA), editor, Pro-
ceedings of LREC 2008, Marrakech, Morocco.
Vladimir N. Vapnik. 1998. Statistical Learning Theory.
Wiley-Interscience.
Piek Vossen, editor. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Springer,
October.
</reference>
<page confidence="0.997847">
227
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.405364">
<title confidence="0.999467">New Features for FrameNet – WordNet Mapping</title>
<author confidence="0.917066">Sara Tonelli</author>
<author confidence="0.917066">Daniele</author>
<title confidence="0.55239">FBK-Irst, Human Language Technologies</title>
<author confidence="0.606664">Via di_Sommarive</author>
<author confidence="0.606664">I- Povo</author>
<abstract confidence="0.998827322580645">Many applications in the context of natural language processing or information retrieval may be largely improved if they were able to fully exploit the rich semantic information annotated in high-quality, publicly available resources such as the FrameNet and the Word- Net databases. Nevertheless, the practical use of similar resources is often biased by the limited coverage of semantic phenomena that they provide. A natural solution to this problem would be to automatically establish anchors between these resources that would allow us 1) to jointly use the encoded information, thus possibly overcoming limitations of the individual corpora, and 2) to extend each resource coverage by exploiting the information encoded in the others. In this paper, we present a supervised learning framework for the mapping of FrameNet lexical units onto WordNet synsets based on a reduced set of novel and semantically rich features. The automatically learnt mapping, we call can be used 1) to extend frame sets in the English FrameNet, 2) to populate frame sets in the Italian FrameNet via MultiWordNet and 3) to add frame labels to the MultiSemCor corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th ACL Meeting and 17th ICCL Conference.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="1728" citStr="Baker et al., 1998" startWordPosition="264" endWordPosition="267">eatures. The automatically learnt mapping, which we call MapNet, can be used 1) to extend frame sets in the English FrameNet, 2) to populate frame sets in the Italian FrameNet via MultiWordNet and 3) to add frame labels to the MultiSemCor corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations. 1 Introduction In recent years, the integration of manually-built lexical resources into NLP systems has received growing interest. In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al., 1998) or PropBank (Palmer et al., 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al., 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). Nonetheless, the main limitation of such resources is their poor coverage, particularly as regards FrameNet. Indeed, the latest FrameNet release (v. 1.3) contains 10,195 lexical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map </context>
<context position="4753" citStr="Baker et al. (1998)" startWordPosition="759" endWordPosition="762">: in Section 2 we review the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the mapping to three resource annotation tasks; finally, in Section 9 we draw our conclusions. 2 FrameNet and WordNet The FrameNet database (Baker et al. (1998), Fillmore et al. (2003)) is an English lexical resource based on the description of some prototypical situations, the frames, and the frame-evoking words or expressions associated to them, the lexical units (LU). Every frame corresponds to a scenario involving a set of participants, the frame elements (FEs), that are typically the semantic arguments shared by all LUs in a frame. We report in Table 1 the information recorded in FrameNet for the CAUSE TO WAKE frame. In the first row there is the frame definition with the relevant frame elements, namely AGENT, CAUSE, SLEEPER and SLEEP STATE. The</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 36th ACL Meeting and 17th ICCL Conference. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Michael Ellsworth</author>
<author>Katrin Erk</author>
</authors>
<title>SemEval-2007 Task 10: Frame Semantic Structure Extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval2007),</booktitle>
<pages>99--104</pages>
<location>Prague, CZ,</location>
<contexts>
<context position="10475" citStr="Baker et al., 2007" startWordPosition="1691" endWordPosition="1694">urchardt et al., 2007) to cope with sparsedata problems in the automatic assignment of frame labels. Johansson and Nugues (2007) created a feature representation for every WordNet lemma and used it to train an SVM classifier for each frame that tells whether a lemma belongs to the frame or not. The best-performing feature representation was built using the sequence of unique identifiers for each synset in its hypernym tree and weigthing the synsets according to their relative frequency in the SemCor corpus. They used the mapping in the Semeval-2007 task on frame-semantic structure extraction (Baker et al., 2007) in order to find target words in open text and assign frames. Crespo and Buitelaar (2008) carried out an automatic mapping of medical-oriented frames to WordNet synsets applying a Statistical Hypothesis Testing to select synsets attached to a lexical unit that were statistically significant using a given reference corpus. The mapping obtained was used to expand Spanish FrameNet using EuroWordNet (Vossen, 1998) and evaluation was carried out on the Spanish lexical units obtained after mapping. Given a set of lexical units, De Cao et al. (2008) propose a method to detect the set of suitable Wor</context>
</contexts>
<marker>Baker, Ellsworth, Erk, 2007</marker>
<rawString>Collin F. Baker, Michael Ellsworth, and Katrin Erk. 2007. SemEval-2007 Task 10: Frame Semantic Structure Extraction. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval2007), pages 99–104, Prague, CZ, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Emanuele Pianta</author>
</authors>
<title>Exploiting Parallel Texts in the Creation of Multilingual Semantically Annotated Resources: The MultiSemCor Corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering, Special Issue on Parallel Texts,</journal>
<volume>11</volume>
<issue>03</issue>
<contexts>
<context position="4075" citStr="Bentivogli and Pianta, 2005" startWordPosition="644" endWordPosition="647">on for Computational Linguistics frame basis, our model is able to cope also with those frames that have little or no annotated sentences to support the frame description. After learning a very fast model on a small set of annotated lexical unit-synset pairs, we can automatically establish new mappings in never-seen-before pairs and use them for our applications. We will evaluate the effect of the induced mappings on two tasks: the automatic enrichment of lexical unit sets in the English and Italian FrameNet via MultiWordNet (Pianta et al., 2002), and the annotation of the MultiSemCor corpus (Bentivogli and Pianta, 2005) with frame labels. The discussion is structured as follows: in Section 2 we review the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the mapping to three resource annotation tasks; finally, in Section 9 we draw our </context>
<context position="29246" citStr="Bentivogli and Pianta, 2005" startWordPosition="4917" endWordPosition="4920">nguages most likely lies in the smaller number of synsets on the Italian side of MultiWordNet if compared to the English, which results in less ambiguity. Furthermore, we should consider that the task for Italian is easier than for English, since in the former case we are building a resource from scratch, while in the latter we are extending an already existing resource with lexical units which are most likely peripheral with respect to those already present in the database. 225 8.2 Frame annotation of MultiSemCor of COOKING CREATION and ATTACHING instead of INCHOATIVE ATTACHING. MultiSemCor (Bentivogli and Pianta, 2005) is an English/Italian parallel corpus, aligned at word level and annotated with PoS, lemma and WordNet synsets. The parallel corpus was created starting from the SemCor corpus, which is a subset of the English Brown corpus containing about 700,000 running words. The corpus was first manually translated into Italian. Then, the procedure of transferring word sense annotations from English to Italian was carried out automatically. We apply MapNet to enrich the corpus with frame information. We believe that this procedure would be interesting from different point of views. Not only we would enric</context>
</contexts>
<marker>Bentivogli, Pianta, 2005</marker>
<rawString>Luisa Bentivogli and Emanuele Pianta. 2005. Exploiting Parallel Texts in the Creation of Multilingual Semantically Annotated Resources: The MultiSemCor Corpus. Natural Language Engineering, Special Issue on Parallel Texts, 11(03):247–261, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans C Boas</author>
</authors>
<title>Semantic frames as interlingual representations for multilingual lexical databases.</title>
<date>2005</date>
<journal>International Journal of Lexicography,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="8456" citStr="Boas, 2005" startWordPosition="1371" endWordPosition="1372">and would allow to exploit the semantic and lexical relations in WordNet to enrich the information encoded in FrameNet. This would help coping with coverage problems and disambiguating the LU senses. 2) For WordNet, it would be possible to add a semantic layer between the synset level and the domain level represented by frame relations, and to enrich the synsets with a computational description of the situation they refer to together with the semantic roles involved. 3) Since frames are mostly defined at conceptual level, the FrameNet model is particularly suitable for crosslingual induction (Boas, 2005). In this framework, the FrameNet-WordNet mapping could help modelling frame-based resources for new languages using minimal supervision. In fact, the availability of multilingual resources like MultiWordNet (Pianta et al., 2002) and EuroWordNet (Vossen, 1998) allows to easily populate frame sets for new languages with reduced human effort and near-manual quality by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to </context>
</contexts>
<marker>Boas, 2005</marker>
<rawString>Hans C. Boas. 2005. Semantic frames as interlingual representations for multilingual lexical databases. International Journal of Lexicography, 18(4):445–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Annette Frank</author>
</authors>
<title>A WordNet detour to FrameNet. In</title>
<date>2005</date>
<booktitle>Sprachtechnologie, mobile Kommunikation und lingistische Resourcen,</booktitle>
<editor>B. Fisseni, H. Schmitz, B. Schr¨oder, and P. Wagner, editors,</editor>
<location>Frankfurt</location>
<contexts>
<context position="9442" citStr="Burchardt et al. (2005)" startWordPosition="1522" endWordPosition="1525">ty by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to exploit VerbNet as a bridge between FrameNet and WordNet for verbs, using synonym and hyponym relations and similarity between Levin’s verb classes and FrameNet frames. Their mapping was used to develop a rulebased semantic parser (Shi and Mihalcea, 2004) as well as to detect target words and assign frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in unseen texts with their contextually determined WordNet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units. The system was integrated into the SALSA RTE system for textual entailment (Burchardt et al., 2007) to cope with sparsedata problems in the automatic assignment of frame labels. Johansson and Nugues (2007) created a feature representation for every WordNet lemma </context>
</contexts>
<marker>Burchardt, Erk, Frank, 2005</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, and Annette Frank. 2005. A WordNet detour to FrameNet. In B. Fisseni, H. Schmitz, B. Schr¨oder, and P. Wagner, editors, Sprachtechnologie, mobile Kommunikation und lingistische Resourcen, Frankfurt am Main, Germany. Peter Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Nils Reiter</author>
<author>Stefan Thater</author>
<author>Annette Frank</author>
</authors>
<title>A semantic approach to textual entailment: System evaluation and task analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of Pascal RTE-3 Challenge,</booktitle>
<location>Prague, CZ.</location>
<contexts>
<context position="1915" citStr="Burchardt et al., 2007" startWordPosition="296" endWordPosition="299">tiWordNet and 3) to add frame labels to the MultiSemCor corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations. 1 Introduction In recent years, the integration of manually-built lexical resources into NLP systems has received growing interest. In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al., 1998) or PropBank (Palmer et al., 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al., 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). Nonetheless, the main limitation of such resources is their poor coverage, particularly as regards FrameNet. Indeed, the latest FrameNet release (v. 1.3) contains 10,195 lexical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with a broader coverage. We believe that WordNet (Fellbaum, 1998), with 210,000 entries in version 3.0, can represent a suitable resource fo</context>
<context position="9878" citStr="Burchardt et al., 2007" startWordPosition="1594" endWordPosition="1597">lop a rulebased semantic parser (Shi and Mihalcea, 2004) as well as to detect target words and assign frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in unseen texts with their contextually determined WordNet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units. The system was integrated into the SALSA RTE system for textual entailment (Burchardt et al., 2007) to cope with sparsedata problems in the automatic assignment of frame labels. Johansson and Nugues (2007) created a feature representation for every WordNet lemma and used it to train an SVM classifier for each frame that tells whether a lemma belongs to the frame or not. The best-performing feature representation was built using the sequence of unique identifiers for each synset in its hypernym tree and weigthing the synsets according to their relative frequency in the SemCor corpus. They used the mapping in the Semeval-2007 task on frame-semantic structure extraction (Baker et al., 2007) in</context>
</contexts>
<marker>Burchardt, Reiter, Thater, Frank, 2007</marker>
<rawString>Aljoscha Burchardt, Nils Reiter, Stefan Thater, and Annette Frank. 2007. A semantic approach to textual entailment: System evaluation and task analysis. In Proceedings of Pascal RTE-3 Challenge, Prague, CZ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego De Cao</author>
<author>Danilo Croce</author>
<author>Marco Pennacchiotti</author>
<author>Roberto Basili</author>
</authors>
<title>Combining Word Sense and Usage for modeling Frame Semantics.</title>
<date>2008</date>
<booktitle>In Proceedings of STEP 2008,</booktitle>
<location>Venice, Italy.</location>
<marker>De Cao, Croce, Pennacchiotti, Basili, 2008</marker>
<rawString>Diego De Cao, Danilo Croce, Marco Pennacchiotti, and Roberto Basili. 2008. Combining Word Sense and Usage for modeling Frame Semantics. In Proceedings of STEP 2008, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Crespo</author>
<author>Paul Buitelaar</author>
</authors>
<title>Domain-specific English-to-Spanish Translation of FrameNet.</title>
<date>2008</date>
<booktitle>In Proc. of LREC 2008,</booktitle>
<location>Marrakech.</location>
<contexts>
<context position="10565" citStr="Crespo and Buitelaar (2008)" startWordPosition="1707" endWordPosition="1710">t of frame labels. Johansson and Nugues (2007) created a feature representation for every WordNet lemma and used it to train an SVM classifier for each frame that tells whether a lemma belongs to the frame or not. The best-performing feature representation was built using the sequence of unique identifiers for each synset in its hypernym tree and weigthing the synsets according to their relative frequency in the SemCor corpus. They used the mapping in the Semeval-2007 task on frame-semantic structure extraction (Baker et al., 2007) in order to find target words in open text and assign frames. Crespo and Buitelaar (2008) carried out an automatic mapping of medical-oriented frames to WordNet synsets applying a Statistical Hypothesis Testing to select synsets attached to a lexical unit that were statistically significant using a given reference corpus. The mapping obtained was used to expand Spanish FrameNet using EuroWordNet (Vossen, 1998) and evaluation was carried out on the Spanish lexical units obtained after mapping. Given a set of lexical units, De Cao et al. (2008) propose a method to detect the set of suitable WordNet senses able to evoke a frame by applying a similarity function that exploits differen</context>
</contexts>
<marker>Crespo, Buitelaar, 2008</marker>
<rawString>Mario Crespo and Paul Buitelaar. 2008. Domain-specific English-to-Spanish Translation of FrameNet. In Proc. of LREC 2008, Marrakech.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4753" citStr="(1998)" startWordPosition="762" endWordPosition="762">2 we review the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the mapping to three resource annotation tasks; finally, in Section 9 we draw our conclusions. 2 FrameNet and WordNet The FrameNet database (Baker et al. (1998), Fillmore et al. (2003)) is an English lexical resource based on the description of some prototypical situations, the frames, and the frame-evoking words or expressions associated to them, the lexical units (LU). Every frame corresponds to a scenario involving a set of participants, the frame elements (FEs), that are typically the semantic arguments shared by all LUs in a frame. We report in Table 1 the information recorded in FrameNet for the CAUSE TO WAKE frame. In the first row there is the frame definition with the relevant frame elements, namely AGENT, CAUSE, SLEEPER and SLEEP STATE. The</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>C R Johnson</author>
<author>M R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<contexts>
<context position="4777" citStr="Fillmore et al. (2003)" startWordPosition="763" endWordPosition="767">iew the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the mapping to three resource annotation tasks; finally, in Section 9 we draw our conclusions. 2 FrameNet and WordNet The FrameNet database (Baker et al. (1998), Fillmore et al. (2003)) is an English lexical resource based on the description of some prototypical situations, the frames, and the frame-evoking words or expressions associated to them, the lexical units (LU). Every frame corresponds to a scenario involving a set of participants, the frame elements (FEs), that are typically the semantic arguments shared by all LUs in a frame. We report in Table 1 the information recorded in FrameNet for the CAUSE TO WAKE frame. In the first row there is the frame definition with the relevant frame elements, namely AGENT, CAUSE, SLEEPER and SLEEP STATE. Then there is the list of a</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>C.J. Fillmore, C.R. Johnson, and M. R. L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Giuglea</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Semantic role labeling via FrameNet, VerbNet and PropBank.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual ACL meeting,</booktitle>
<pages>929--936</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, US.</location>
<contexts>
<context position="1974" citStr="Giuglea and Moschitti, 2006" startWordPosition="305" endWordPosition="308">r corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations. 1 Introduction In recent years, the integration of manually-built lexical resources into NLP systems has received growing interest. In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al., 1998) or PropBank (Palmer et al., 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al., 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). Nonetheless, the main limitation of such resources is their poor coverage, particularly as regards FrameNet. Indeed, the latest FrameNet release (v. 1.3) contains 10,195 lexical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with a broader coverage. We believe that WordNet (Fellbaum, 1998), with 210,000 entries in version 3.0, can represent a suitable resource for this task. In fact, both FrameNet and WordNet group toget</context>
</contexts>
<marker>Giuglea, Moschitti, 2006</marker>
<rawString>Ana-Maria Giuglea and Alessandro Moschitti. 2006. Semantic role labeling via FrameNet, VerbNet and PropBank. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual ACL meeting, pages 929–936, Morristown, NJ, US. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
<author>Tobias Hawker</author>
</authors>
<title>Identifying FrameNet frames for verbs from a real-text corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of Australasian Language Technology Workshop</booktitle>
<contexts>
<context position="9417" citStr="Honnibal and Hawker, 2005" startWordPosition="1518" endWordPosition="1521">effort and near-manual quality by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to exploit VerbNet as a bridge between FrameNet and WordNet for verbs, using synonym and hyponym relations and similarity between Levin’s verb classes and FrameNet frames. Their mapping was used to develop a rulebased semantic parser (Shi and Mihalcea, 2004) as well as to detect target words and assign frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in unseen texts with their contextually determined WordNet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units. The system was integrated into the SALSA RTE system for textual entailment (Burchardt et al., 2007) to cope with sparsedata problems in the automatic assignment of frame labels. Johansson and Nugues (2007) created a feature representation</context>
</contexts>
<marker>Honnibal, Hawker, 2005</marker>
<rawString>Matthew Honnibal and Tobias Hawker. 2005. Identifying FrameNet frames for verbs from a real-text corpus. In Proceedings of Australasian Language Technology Workshop 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale support vector machine learning practical.</title>
<date>1999</date>
<booktitle>Advances in kernel methods: support vector learning,</booktitle>
<pages>169--184</pages>
<editor>In Bernhard Sch¨olkopf, Christopher J. C. Burges, and Alexander J Smola, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="22296" citStr="Joachims, 1999" startWordPosition="3745" endWordPosition="3746">described as set, circle, band, that are also lexical units of AGGREGATE. In those cases where the hypernym relation is not defined, e.g. adjectives, we used the similar-to relation. 7 Experimental setup and evaluation To evaluate our methodology we carried out a 10- fold cross validation using the available data, splitting them in 10 non-overlapping sets. For each iteration, 70% of the data was used for training, 30% for testing. All the splits were generated so as to maintain a balance between positive and negative examples in the training and test sets. We used the SVM optimizer SVMLight2 (Joachims, 1999), and applied polynomial kernels (poly) of different degrees (i.e. 1 through 4) in order to select the configuration with the best generalization capabilities. The accuracy is measured in terms of Precision, Recall and F1 measure, i.e. the harmonic average between Precision and Recall. For the sake of annotation, it is important that an automatic system be very precise, thus not producing wrong annotations. On the other hand, the higher the recall, the larger the amount of data that the system will be able to annotate. 2Available at http://svmlight.joachims.org/ The macro-average of the classi</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale support vector machine learning practical. In Bernhard Sch¨olkopf, Christopher J. C. Burges, and Alexander J Smola, editors, Advances in kernel methods: support vector learning, pages 169–184. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johansson</author>
<author>P Nugues</author>
</authors>
<title>Using WordNet to extend FrameNet coverage.</title>
<date>2007</date>
<booktitle>In Proc. of the Workshop on Building Frame-semantic Resources for Scandinavian and Baltic Languages, at NODALIDA,</booktitle>
<location>Tartu.</location>
<contexts>
<context position="3237" citStr="Johansson and Nugues (2007)" startWordPosition="509" endWordPosition="512">provide a hierarchical representation of the lexical knowledge (in WordNet the relations between synsets, in FrameNet between frames, see Ruppenhofer et al. (2006)). On the other hand, WordNet provides a more extensive coverage particularly for adjectives and nouns denoting artifacts and natural kinds, that are mostly neglected in FrameNet. In this paper, we present an approach using Support Vector Machines (SVM) to map FrameNet lexical units to WordNet synsets. The proposed approach addresses some of the limitations of previous works on the same task (see for example De Cao et al. (2008) and Johansson and Nugues (2007)). Most notably, as we do not train the SVM on a per219 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 219–227, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics frame basis, our model is able to cope also with those frames that have little or no annotated sentences to support the frame description. After learning a very fast model on a small set of annotated lexical unit-synset pairs, we can automatically establish new mappings in never-seen-before pairs and use them for our applications. We will evaluate the eff</context>
<context position="9984" citStr="Johansson and Nugues (2007)" startWordPosition="1611" endWordPosition="1614">frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in unseen texts with their contextually determined WordNet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units. The system was integrated into the SALSA RTE system for textual entailment (Burchardt et al., 2007) to cope with sparsedata problems in the automatic assignment of frame labels. Johansson and Nugues (2007) created a feature representation for every WordNet lemma and used it to train an SVM classifier for each frame that tells whether a lemma belongs to the frame or not. The best-performing feature representation was built using the sequence of unique identifiers for each synset in its hypernym tree and weigthing the synsets according to their relative frequency in the SemCor corpus. They used the mapping in the Semeval-2007 task on frame-semantic structure extraction (Baker et al., 2007) in order to find target words in open text and assign frames. Crespo and Buitelaar (2008) carried out an aut</context>
<context position="13259" citStr="Johansson and Nugues (2007)" startWordPosition="2166" endWordPosition="2169">pecially for those with only one element. In the FrameNet database (v. 1.3), 33 frames out of 720 are described only by one lexical unit, and 63 are described by two. Furthermore, more than 3,000 lexical units are characterized only by the lexicographic definition and are not provided with example sentences. For this reason, we suggest an approach that makes also use of usually unexploited information in the FrameNet database, namely the definition associated to every lexical unit, and disregards example sentences. This is the main point of difference between our and some previous works, e.g. Johansson and Nugues (2007) and De Cao et al. (2008), where unsupervised approaches are proposed which strongly rely either on the number of lexical units in a frame or on the example sentences available for l in the FrameNet corpus. We claim that the relative short time necessary to annotate a small dataset of framesynset pairs will result in a more reliable mapping system and, as a consequence, in consistent time savings when we actually try to use the mappings for some tasks. The ability to cope with different cases while retaining a good accuracy will allow to bootstrap the mapping process in many cases where other </context>
</contexts>
<marker>Johansson, Nugues, 2007</marker>
<rawString>R. Johansson and P. Nugues. 2007. Using WordNet to extend FrameNet coverage. In Proc. of the Workshop on Building Frame-semantic Resources for Scandinavian and Baltic Languages, at NODALIDA, Tartu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Gabriela Cavagli`a</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC 2000,</booktitle>
<pages>1413--1418</pages>
<location>Athens, Greece.</location>
<marker>Magnini, Cavagli`a, 2000</marker>
<rawString>Bernardo Magnini and Gabriela Cavagli`a. 2000. Integrating Subject Field Codes into WordNet. In Proceedings of LREC 2000, pages 1413–1418, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<contexts>
<context position="1762" citStr="Palmer et al., 2005" startWordPosition="270" endWordPosition="273"> mapping, which we call MapNet, can be used 1) to extend frame sets in the English FrameNet, 2) to populate frame sets in the Italian FrameNet via MultiWordNet and 3) to add frame labels to the MultiSemCor corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations. 1 Introduction In recent years, the integration of manually-built lexical resources into NLP systems has received growing interest. In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al., 1998) or PropBank (Palmer et al., 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al., 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). Nonetheless, the main limitation of such resources is their poor coverage, particularly as regards FrameNet. Indeed, the latest FrameNet release (v. 1.3) contains 10,195 lexical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map frame information onto other lexic</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuele Pianta</author>
<author>Luisa Bentivogli</author>
<author>Christian Girardi</author>
</authors>
<title>MultiWordNet: developing an aligned multilingual database.</title>
<date>2002</date>
<booktitle>In First International Conference on Global WordNet,</booktitle>
<pages>292--302</pages>
<location>Mysore, India.</location>
<contexts>
<context position="3999" citStr="Pianta et al., 2002" startWordPosition="633" endWordPosition="636">oNLL), pages 219–227, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics frame basis, our model is able to cope also with those frames that have little or no annotated sentences to support the frame description. After learning a very fast model on a small set of annotated lexical unit-synset pairs, we can automatically establish new mappings in never-seen-before pairs and use them for our applications. We will evaluate the effect of the induced mappings on two tasks: the automatic enrichment of lexical unit sets in the English and Italian FrameNet via MultiWordNet (Pianta et al., 2002), and the annotation of the MultiSemCor corpus (Bentivogli and Pianta, 2005) with frame labels. The discussion is structured as follows: in Section 2 we review the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the ma</context>
<context position="8685" citStr="Pianta et al., 2002" startWordPosition="1401" endWordPosition="1404">ould be possible to add a semantic layer between the synset level and the domain level represented by frame relations, and to enrich the synsets with a computational description of the situation they refer to together with the semantic roles involved. 3) Since frames are mostly defined at conceptual level, the FrameNet model is particularly suitable for crosslingual induction (Boas, 2005). In this framework, the FrameNet-WordNet mapping could help modelling frame-based resources for new languages using minimal supervision. In fact, the availability of multilingual resources like MultiWordNet (Pianta et al., 2002) and EuroWordNet (Vossen, 1998) allows to easily populate frame sets for new languages with reduced human effort and near-manual quality by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to exploit VerbNet as a bridge between FrameNet and WordNet for verbs, using synonym and hyponym relations and similarity between Levin’s verb classes and FrameNet frames. Their mapping was used to develop a rulebased semantic parse</context>
</contexts>
<marker>Pianta, Bentivogli, Girardi, 2002</marker>
<rawString>Emanuele Pianta, Luisa Bentivogli, and Christian Girardi. 2002. MultiWordNet: developing an aligned multilingual database. In First International Conference on Global WordNet, pages 292–302, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Michael Ellsworth</author>
<author>Miriam R L Petruck</author>
<author>Christopher R Johnson</author>
<author>Jan Scheffczyk</author>
</authors>
<title>FrameNet II: Extended Theory and Practice. Available at http://framenet.icsi.berkeley.edu/book/book.html.</title>
<date>2006</date>
<contexts>
<context position="2773" citStr="Ruppenhofer et al. (2006)" startWordPosition="431" endWordPosition="435">xical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with a broader coverage. We believe that WordNet (Fellbaum, 1998), with 210,000 entries in version 3.0, can represent a suitable resource for this task. In fact, both FrameNet and WordNet group together semantically similar words, and provide a hierarchical representation of the lexical knowledge (in WordNet the relations between synsets, in FrameNet between frames, see Ruppenhofer et al. (2006)). On the other hand, WordNet provides a more extensive coverage particularly for adjectives and nouns denoting artifacts and natural kinds, that are mostly neglected in FrameNet. In this paper, we present an approach using Support Vector Machines (SVM) to map FrameNet lexical units to WordNet synsets. The proposed approach addresses some of the limitations of previous works on the same task (see for example De Cao et al. (2008) and Johansson and Nugues (2007)). Most notably, as we do not train the SVM on a per219 Proceedings of the Thirteenth Conference on Computational Natural Language Learn</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, Scheffczyk, 2006</marker>
<rawString>Josef Ruppenhofer, Michael Ellsworth, Miriam R.L. Petruck, Christopher R. Johnson, and Jan Scheffczyk. 2006. FrameNet II: Extended Theory and Practice. Available at http://framenet.icsi.berkeley.edu/book/book.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Mirella Lapata</author>
</authors>
<title>Using Semantic Roles to Improve Question Answering.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP and CONLL,</booktitle>
<pages>12--21</pages>
<location>Prague, CZ.</location>
<contexts>
<context position="1868" citStr="Shen and Lapata, 2007" startWordPosition="289" endWordPosition="292">ate frame sets in the Italian FrameNet via MultiWordNet and 3) to add frame labels to the MultiSemCor corpus. Our evaluation on these tasks shows that the proposed approach is viable and can result in accurate automatic annotations. 1 Introduction In recent years, the integration of manually-built lexical resources into NLP systems has received growing interest. In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al., 1998) or PropBank (Palmer et al., 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al., 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006). Nonetheless, the main limitation of such resources is their poor coverage, particularly as regards FrameNet. Indeed, the latest FrameNet release (v. 1.3) contains 10,195 lexical units (LUs), 3,380 of which are described only by a lexicographic definition without any example sentence. In order to cope with this lack of data, it would be useful to map frame information onto other lexical resources with a broader coverage. We believe that WordNet (Fellbaum, 1998), with 210,000 entries in ve</context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>Dan Shen and Mirella Lapata. 2007. Using Semantic Roles to Improve Question Answering. In Proceedings of EMNLP and CONLL, pages 12–21, Prague, CZ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Open Text Semantic Parsing Using FrameNet and WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<contexts>
<context position="9311" citStr="Shi and Mihalcea, 2004" startWordPosition="1498" endWordPosition="1501">d EuroWordNet (Vossen, 1998) allows to easily populate frame sets for new languages with reduced human effort and near-manual quality by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to exploit VerbNet as a bridge between FrameNet and WordNet for verbs, using synonym and hyponym relations and similarity between Levin’s verb classes and FrameNet frames. Their mapping was used to develop a rulebased semantic parser (Shi and Mihalcea, 2004) as well as to detect target words and assign frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in unseen texts with their contextually determined WordNet synsets and then exploited synonyms and hypernyms information to assign the best frame to the lexical units. The system was integrated into the SALSA RTE system for textual entailment (Burchardt et al., 2007) to cope with sparsedata problems</context>
</contexts>
<marker>Shi, Mihalcea, 2004</marker>
<rawString>Lei Shi and Rada Mihalcea. 2004. Open Text Semantic Parsing Using FrameNet and WordNet. In Proceedings of HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting Pieces Together: Combining FrameNet, VerbNet and WordNet for Robust Semantic Parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of CICLing</booktitle>
<pages>100--111</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="9016" citStr="Shi and Mihalcea (2005)" startWordPosition="1452" endWordPosition="1455">s particularly suitable for crosslingual induction (Boas, 2005). In this framework, the FrameNet-WordNet mapping could help modelling frame-based resources for new languages using minimal supervision. In fact, the availability of multilingual resources like MultiWordNet (Pianta et al., 2002) and EuroWordNet (Vossen, 1998) allows to easily populate frame sets for new languages with reduced human effort and near-manual quality by importing all lemmas from the mapped synsets. 3 Related work Several experiments have been carried out to develop a FrameNet-WordNet mapping and test its applications. Shi and Mihalcea (2005) described a semi-automatic approach to exploit VerbNet as a bridge between FrameNet and WordNet for verbs, using synonym and hyponym relations and similarity between Levin’s verb classes and FrameNet frames. Their mapping was used to develop a rulebased semantic parser (Shi and Mihalcea, 2004) as well as to detect target words and assign frames for verbs in an open text (Honnibal and Hawker, 2005). Burchardt et al. (2005) presented a rule-based system for the assignment of FrameNet frames by way of a “detour via WordNet”. They applied a WordNet-based WSD system to annotate lexical units in un</context>
</contexts>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. 2005. Putting Pieces Together: Combining FrameNet, VerbNet and WordNet for Robust Semantic Parsing. In Proceedings of CICLing 2005, pages 100–111. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Emanuele Pianta</author>
</authors>
<title>Frame Information Transfer from English to Italian.</title>
<date>2008</date>
<booktitle>In European Language Resources Association (ELRA), editor, Proceedings of LREC 2008,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="19858" citStr="Tonelli and Pianta (2008)" startWordPosition="3314" endWordPosition="3317">allelism Our idea is that, if an English lexical unit and its Italian translation belong to the same frame, they are likely to appear also in the same MultiWordNet synset, and the latter would be a good candidate for mapping. In fact, in MultiWordNet the Italian WordNet is strictly aligned with the Princeton WordNet 1.6, with synsets having the same id for both languages, and also semantic relations are preserved in the multilingual hierarchy. Since no Italian FrameNet is available yet, we extended the parallel English-Italian corpus annotated on both sides with frame information described in Tonelli and Pianta (2008) by adding and annotating 400 new parallel sentences. The final corpus contains about 1,000 pairs of parallel sentences where the English and the Italian lexical unit belong to the same frame. Given a pair (l, s), we check if l appears also in the corpus with the frame label Fi and extract its Italian translation lit. If lit appears also in the Italian version of synset s in MultiWordNet, we consider s as a good candidate for the mapping of l and encode this information as a binary feature. Simple synset-frame overlap Intuitively, the more lemmas a frame and a synset have in common, the more s</context>
</contexts>
<marker>Tonelli, Pianta, 2008</marker>
<rawString>Sara Tonelli and Emanuele Pianta. 2008. Frame Information Transfer from English to Italian. In European Language Resources Association (ELRA), editor, Proceedings of LREC 2008, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley-Interscience.</publisher>
<contexts>
<context position="14447" citStr="Vapnik, 1998" startWordPosition="2371" endWordPosition="2372">n many cases where other approaches would have failed due to lack of training data. To this end, we can train a binary classifier that, given l and CandSet, for each pair (l,s), s E CandSet, delivers a positive answer if s E bests, and a negative one otherwise. To follow on the previous example, for rouse.v we would have 4 classifier examples, i.e. the pairs (rouse.v,#1), (rouse.v,#2), (rouse.v,#3) and (rouse.v,#4). Of these, only the last would be considered a positive instance. As a learning framework, we decided to use SVMs due to their classification accuracy and robustness to noisy data (Vapnik, 1998). 5 Dataset description In order to train and test the classifier, we created a gold standard by manually annotating 2,158 LUsynset pairs as positive or negative examples. We don’t have data about inter-annotator agreement because the dataset was developed only by one annotator, but De Cao et al. (2008) report 0.90 as Cohen’s Kappa computed over 192 LU-synset pairs for the same mapping task. This confirms that senses and lexical units are highly correlated and that the mapping is semantically motivated. The annotation process can be carried out in reasonable time. It took approximately two wor</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. Wiley-Interscience.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</booktitle>
<editor>Piek Vossen, editor.</editor>
<publisher>Springer,</publisher>
<contexts>
<context position="4753" citStr="(1998)" startWordPosition="762" endWordPosition="762">2 we review the main characteristics of FrameNet and WordNet; in Section 3 we discuss previous attempts to establish a mapping between them; in Section 4 we describe our supervised approach to map lexical units onto synsets; Section 5 details the dataset that we employed for our experiments; Section 6 describes the novel features that we used to characterize the mapping; Section 7 details the results of our experiments; in Section 8 we apply the mapping to three resource annotation tasks; finally, in Section 9 we draw our conclusions. 2 FrameNet and WordNet The FrameNet database (Baker et al. (1998), Fillmore et al. (2003)) is an English lexical resource based on the description of some prototypical situations, the frames, and the frame-evoking words or expressions associated to them, the lexical units (LU). Every frame corresponds to a scenario involving a set of participants, the frame elements (FEs), that are typically the semantic arguments shared by all LUs in a frame. We report in Table 1 the information recorded in FrameNet for the CAUSE TO WAKE frame. In the first row there is the frame definition with the relevant frame elements, namely AGENT, CAUSE, SLEEPER and SLEEP STATE. The</context>
</contexts>
<marker>1998</marker>
<rawString>Piek Vossen, editor. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Springer, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>