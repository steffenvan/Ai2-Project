<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004228">
<title confidence="0.987573">
An Unsupervised Model for Statistically Determining Coordinate
Phrase Attachment
</title>
<author confidence="0.898359">
Miriam Goldberg
</author>
<affiliation confidence="0.793965">
Central High School &amp;
Dept. of Computer and Information Science
</affiliation>
<address confidence="0.580063">
200 South 33rd Street
Philadelphia, PA 19104-6389
</address>
<affiliation confidence="0.854908">
University of Pennsylvania
</affiliation>
<email confidence="0.852784">
miriamOunagi.cis.upenn.edu
</email>
<sectionHeader confidence="0.97453" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999817545454545">
This paper examines the use of an unsuper-
vised statistical model for determining the at-
tachment of ambiguous coordinate phrases (CP)
of the form n1 p n2 cc n3. The model pre-
sented here is based on [AR98], an unsupervised
model for determining prepositional phrase at-
tachment. After training on unannotated 1988
Wall Street Journal text, the model performs
at 72% accuracy on a development set from
sections 14 through 19 of the WSJ TreeBank
[MSM93).
</bodyText>
<sectionHeader confidence="0.993769" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.982829425">
The coordinate phrase (CP) is a source of struc-
tural ambiguity in natural language. For exam-
ple, take the phrase:
box of chocolates and roses
&apos;Roses&apos; attaches either high to &apos;box&apos; or low to
&apos;chocolates&apos;. In this case, attachment is high,
yielding:
H-attach: ((box (of chocolates)) (and roses))
Consider, then, the phrase:
salad of lettuce and tomatoes
&apos;Lettuce&apos; attaches low to &apos;tomatoes&apos;, giving:
L-attach: (salad (of ((lettuce) and
(tomatoes)))
Previous work has used corpus-based ap-
proaches to solve the similar problem of prepo-
sitional phrase attachment. These have in-
cluded backed-off [CB 95], maximum entropy
[RRR94], rule-based [HR941, and unsupervised
[AR98] models. In addition to these, a corpus-
based model for PP-attachment [SN971 has been
reported that uses information from a semantic
dictionary.
Sparse data can be a major concern in corpus-
based disambiguation. Supervised models are
limited by the amount of annotated data avail-
able for training. Such a model is useful only
for languages in which annotated corpora are
available. Because an unsupervised model does
not rely on such corpora it may be modified for
use in multiple languages as in [AR98].
The unsupervised model presented here
trains from an unannotated version of the 1988
Wall Street Journal. After tagging and chunk-
ing the text, a rough heuristic is then employed
to pick out training examples. This results in
a training set that is less accurate, but much
larger, than currently existing annotated cor-
pora. It is the goal, then, of unsupervised train-
ing data to be abundant in order to offset its
noisiness.
</bodyText>
<sectionHeader confidence="0.945441" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.955911692307692">
The statistical model must determine the prob-
ability of a given CP attaching either high (H)
or low (L), p(attachment I phrase). Results
shown come from a development corpus of 500
phrases of extracted head word tuples from the
WSJ TreeBank [MSM93]. 64% of these phrases
attach low and 36% attach high. After further
development, final testing will be done on a sep-
arate corpus.
The phrase:
(busloads (of ((executives) and (their wives)))
gives the 6-tuple:
L busloads of executives and wives
</bodyText>
<page confidence="0.995531">
610
</page>
<bodyText confidence="0.99110975">
where, a = L, n1 = busloads, p = of, n2 =
executives, cc = and, n3 = wives. The CP at-
tachment model must determine a for all (n1
p n2 cc n3) sets. The attachment decision is
correct if it is the same as the corresponding
decision in the TreeBank set.
The probability of a CP attaching high is
conditional on the 5-tuple. The algorithm pre-
sented in this paper estimates the probability:
= (a I nl,p, n2, cc, n3)
The parts of the CP are analogous to those
of the prepositional phrase (PP) such that
{nl,n2} {n, v} and n3 p. [AR98] de-
termines the probability p(v, n, p, a). To be
consistent, here we determine the probability
p(nl, n2, n3, a).
</bodyText>
<sectionHeader confidence="0.969376" genericHeader="method">
3 Training Data Extraction
</sectionHeader>
<bodyText confidence="0.995518852941176">
A statistical learning model must train from un-
ambiguous data. In annotated corpora ambigu-
ous data are made unambiguous through classi-
fications made by human annotators. In unan-
notated corpora the data themselves must be
unambiguous. Therefore, while this model dis-
ambiguates CPs of the form (n1 p n2 cc n3), it
trains from implicitly unambiguous CPs of the
form (n cc n). For example:
dog and cat
Because there are only two nouns in the un-
ambiguous CP, we must redefine its compo-
nents. The first noun will be referred to as nl.
It is analogous to n1 and n2 in the ambiguous
CP. The second, terminal noun will be referred
to as n3. It is analogous to the third noun in
the ambiguous CP. Hence n1 = dog, cc = and,
n3 = cat. In addition to the unambiguous CPs,
the model also uses any noun that follows a cc.
Such nouns are classified, n„.
We extracted 119629 unambiguous CPs and
325261 ns from the unannotated 1988 Wall
Street Journal. First the raw text was fed into
the part-of-speech tagger described in [AR96]1.
This was then passed to a simple chunker as
used in [AR98), implemented with two small
&apos;Because this tagger trained on annotated data, one
may argue that the model presented here is not purely
unsupervised.
regular expressions that replace noun and quan-
tifier phrases with their head words. These head
words were then passed through a set of heuris-
tics to extract the unambiguous phrases. The
heuristics to find an unambiguous CP are:
</bodyText>
<listItem confidence="0.995281714285714">
• on, is a coordinating conjunction (cc) if it
is tagged cc.
• on_x is the leftmost noun (n1) if:
— _is the first noun to occur within
4 words to the left of cc.
— no preposition occurs between this
noun and cc.
— no preposition occurs within 4 words
to the left of this noun.
• wn+x is the rightmost noun (n2) if:
— it is the first noun to occur within 4
words to the right of cc.
— No preposition occurs between cc and
this noun.
</listItem>
<bodyText confidence="0.999909444444445">
The first noun to occur within 4 words to the
right of cc is always extracted. This is nec. Such
nouns are also used in the statistical model. For
example, the we process the sentence below as
follows:
Several firms have also launched busi-
ness subsidiaries and consulting arms
specializing in trade, lobbying and
other areas.
</bodyText>
<equation confidence="0.884288428571429">
First it is annotated with parts of speech:
Several_JJ firms_NNS have_VBP
also_RB launched_VBN business_NN
subsidiaries_NNS and_CC consult-
ing_VBG arms_NNS specializing_VBG
in_IN trade_NN lobbying_NN
and_CC other_JJ areas_NNS
From there, it is passed to the chunker yield-
ing:
firms_NNS have_VBP also_RB
launched_VBN subsidiaries_NNS
and_CC consulting_VBG arms_NNS
specializing_VBG in_IN trade_NN
lobbying_NN and_CC areas_NNS
</equation>
<page confidence="0.960353">
611
</page>
<bodyText confidence="0.9990688">
Noun phrase heads of ambiguous and unam-
biguous CPs are then extracted according to the
heuristic, giving:
subsidiaries and arms
and areas
where the extracted unambiguous CP is
= subsidiaries, cc = and, n3 = arms} and
areas is extracted as a nc, because, although
it is not part of an unambiguous CP, it occurs
within four words after a conjunction.
</bodyText>
<sectionHeader confidence="0.997419" genericHeader="method">
4 The Statistical Model
</sectionHeader>
<bodyText confidence="0.93394865">
First, we can factor p(a, nl, n2, n3) as follows:
p(a, nl, n2, n3) = p(nl)p(n2)
p(a nl,n2)
p(n3 I a, nl, n2)
The terms p(n1) and p(n2) are independent
of the attachment and need not be computed.
The other two terms are more problematic. Be-
cause the training phrases are unambiguous and
of the form (n1 cc n2), n1 and n2 of the CP
in question never appear together in the train-
ing data. To compensate we use the following
heuristic as in [AR98]. Let the random variable
0 range over {true, false} and let it denote the
presence or absence of any n3 that unambigu-
ously attaches to the n1 or n2 in question. If
= true when any n3 unambiguously attaches
to ni, then p(0 = true I n1) is the conditional
probability that a particular n1 occurs with an
unambiguously attached n3. Now p(a nl, n2)
can be approximated as:
</bodyText>
<equation confidence="0.9975925">
p(true I n1)
p(a = H I nl,n2)
Z(nl, n2)
p(true I n2)
p(a = Lj nl,n2)
Z(nl, n2)
</equation>
<bodyText confidence="0.998810857142857">
where the normalization factor, Z(nl,n2) =
p(true I n1) + p(true I n2). The reasoning be-
hind this approximation is that the tendency of
a CP to attach high (low) is related to the ten-
dency of the n1 (n2) in question to appear in
an unambiguous CP in the training data.
We approximate p(n3 I a, nl, n2) as follows:
</bodyText>
<equation confidence="0.6740315">
p(n3 I a = H, nl, n2). p(n3 I true, n1)
p(n3 I a = L, nl, n2) p(n3 I true, n2)
</equation>
<bodyText confidence="0.999941285714286">
The reasoning behind this approximation is
that when generating n3 given high (low) at-
tachment, the only counts from the training
data that matter are those which unambigu-
ously attach to n1 (n2), i.e., 0 = true. Word
statistics from the extracted CPs are used to
formulate these probabilities.
</bodyText>
<subsectionHeader confidence="0.83622">
4.1 Generate 4)
</subsectionHeader>
<bodyText confidence="0.9999635">
The conditional probabilities p(true I n1) and
p(true I n2) denote the probability of whether
a noun will appear attached unambiguously to
some n3. These probabilities are estimated as:
</bodyText>
<equation confidence="0.997315833333333">
p(true I n1) = .5 otherwise
f (n1 ,true)
f(n1) if f (nl, true) &gt;0
f(n2,true)
f (n2) if f (n2, true) &gt; 0
p(true I n2) = .5 otherwise
</equation>
<bodyText confidence="0.9998682">
where f (n2, true) is the number of times n2
appears in an unambiguously attached CP in
the training data and f (n2) is the number of
times this noun has appeared as either nl, n3,
or n„ in the training data.
</bodyText>
<subsectionHeader confidence="0.979987">
4.2 Generate n3
</subsectionHeader>
<bodyText confidence="0.999788">
The terms p(n3 j nl, true) and p(n3 I n2, true)
denote the probabilies that the noun n3 appears
attached unambiguously to n1 and n2 respec-
tively. Bigram counts are used to compute these
as follows:
</bodyText>
<equation confidence="0.99547425">
f (nl,n3,true)
p(n3 I true, n1) = if(nl,true)
{ f (n2,n3,true)
p(n3 I true, n2) = if(n2,true)
</equation>
<bodyText confidence="0.9997925">
where N is the set of all n3s and ns that
occur in the training data.
</bodyText>
<sectionHeader confidence="0.999611" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.991964333333333">
Decisions were deemed correct if they agreed
with the decision in the corresponding Tree-
Bank data. The correct attachment was chosen
</bodyText>
<figure confidence="0.7981315">
if f (n1 ,n3,true)&gt;0
otherwise
if f (n2,n3,true)&gt;0
otherwise
</figure>
<page confidence="0.991097">
612
</page>
<bodyText confidence="0.999939277777777">
72% of the time on the 500-phrase development
corpus from the WSJ TreeBank. Because it is
a forced binary decision, there are no measure-
ments for recall or precision. If low attachment
is always chosen, the accuracy is 64%. After fur-
ther development the model will be tested on a
testing corpus.
When evaluating the effectiveness of an un-
supervised model, it is helpful to compare its
performance to that of an analogous supervised
model. The smaller the error reduction when
going from unsupervised to supervised models,
the more comparable the unsupervised model
is to its supervised counterpart. To our knowl-
edge there has been very little if any work in the
area of ambiguous CPs. In addition to develop-
ing an unsupervised CP disambiguation model,
In [MG, in prep] we have developed two super-
vised models (one backed-off and one maximum
entropy) for determining CP attachment. The
backed-off model, closely based on [CB95] per-
forms at 75.6% accuracy. The reduction error
from the unsupervised model presented here to
the backed-off model is 13%. This is compa-
rable to the 14.3% error reduction found when
going from [AR98] to [CB95].
It is interesting to note that after reducing
the volume of training data by half there was
no drop in accuracy. In fact, accuracy remained
exactly the same as the volume of data was in-
creased from half to full. The backed-off model
in [MG, in prep] trained on only 1380 train-
ing phrases. The training corpus used in the
study presented here consisted of 119629 train-
ing phrases. Reducing this figure by half is not
overly significant.
</bodyText>
<sectionHeader confidence="0.99976" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999992461538461">
In an effort to make the heuristic concise and
portable, we may have oversimplified it thereby
negatively affecting the performance of the
model. For example, when the heuristic came
upon a noun phrase consisting of more than one
consecutive noun the noun closest to the cc was
extracted. In a phrase like coffee and rhubarb
apple pie the heuristic would chose rhubarb as
the n3 when clearly pie should have been cho-
sen. Also, the heuristic did not check if a prepo-
sition occurred between either n1 and cc or cc
and n3. Such cases make the CP ambiguous
thereby invalidating it as an unambiguous train-
ing example. By including annotated training
data from the TreeBank set, this model could
be modified to become a partially-unsupervised
classifier.
Because the model presented here is basically
a straight reimplementation of [AR98] it fails to
take into account attributes that are specific to
the CP. For example, whereas (n1 cc n3) (n3
cc n1), (v p n) (n p v). In other words. there
is no reason to make the distinction between
&amp;quot;dog and cat&amp;quot; and &amp;quot;cat and dog.&amp;quot; Modifying
the model accordingly may greatly increase the
usefulness of the training data.
</bodyText>
<sectionHeader confidence="0.999146" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99994475">
We thank Mitch Marcus and Dennis Erlick for
making this research possible, Mike Collins for
his guidance, and Adwait Ratnaparkhi and Ja-
son Eisner for their helpful insights.
</bodyText>
<sectionHeader confidence="0.999115" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909166666667">
ICB95] M. Collins, J. Brooks. 1995. Preposi-
tional Phrase Attachment through a Backed-
Off Model, A CL 3rd Workshop on Very Large
Corpora, Pages 27-38, Cambridge, Mas-
sachusetts, June.
[MG, in prep] M. Goldberg. in preparation.
Three Models for Statistically Determining
Coordinate Phrase Attachment.
[HR93] D. Hindle, M. Rooth. 1993. Structural
Ambiguity and Lexical Relations. Computa-
tional Linguistics, 19(1):103-120.
[MSM93] M. Marcus, B. Santorini and M.
Marcinkiewicz. 1993. Building a Large Anno-
tated Corpus of English: the Penn Treebank,
Computational Linguistics, 19(2):313-330.
[RRR94] A. Ratnaparkhi, J. Reynar and S.
Roukos. 1994. A Maximum Entropy Model
for Prepositional Phrase Attachment, In Pro-
ceedings of the ARPA Workshop on Human
Language Technology, 1994.
[AR96] A. Ratnaparkhi. 1996. A Maximum En-
tropy Part-Of-Speech Tagger, In Proceedings
of the Empirical Methods in Natural Lan-
guage Processing Conference, May 17-18.
[AR98] A. Ratnaparkhi. 1998. Unsupervised
Statistical Models for Prepositional Phrase
Attachment, In Proceedings of the Seven-
teenth International Conference on Compu-
tational Linguistics, Aug. 10-14, Montreal,
Canada.
</reference>
<page confidence="0.988231">
613
</page>
<reference confidence="0.998865333333333">
[SN97] J. Stetina, M. Nagao. 1997. Corpus
Based PP Attachment Ambiguity Resolution
with a Semantic Dictionary. In Jou Shou and
Kenneth Church, editors, Proceedings of the
Fifth Workshop on Very Large Corpora, pages
66-80, Beijing and Hong Kong, Aug. 18-20.
</reference>
<page confidence="0.99815">
614
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.344719">
<title confidence="0.9932775">An Unsupervised Model for Statistically Determining Coordinate Phrase Attachment</title>
<author confidence="0.999886">Miriam Goldberg</author>
<affiliation confidence="0.9830755">Central High School &amp; Dept. of Computer and Information Science</affiliation>
<address confidence="0.9982365">200 South 33rd Street Philadelphia, PA 19104-6389</address>
<affiliation confidence="0.999436">University of Pennsylvania</affiliation>
<email confidence="0.999839">miriamOunagi.cis.upenn.edu</email>
<abstract confidence="0.933295416666667">This paper examines the use of an unsupervised statistical model for determining the attachment of ambiguous coordinate phrases (CP) the form n1 The model presented here is based on [AR98], an unsupervised model for determining prepositional phrase attachment. After training on unannotated 1988 Wall Street Journal text, the model performs at 72% accuracy on a development set from sections 14 through 19 of the WSJ TreeBank [MSM93).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>J Brooks</author>
</authors>
<title>Prepositional Phrase Attachment through a BackedOff Model,</title>
<date>1995</date>
<booktitle>A CL 3rd Workshop on Very Large Corpora,</booktitle>
<pages>27--38</pages>
<location>Cambridge, Massachusetts,</location>
<marker>Collins, Brooks, 1995</marker>
<rawString> ICB95] M. Collins, J. Brooks. 1995. Prepositional Phrase Attachment through a BackedOff Model, A CL 3rd Workshop on Very Large Corpora, Pages 27-38, Cambridge, Massachusetts, June.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Goldberg</author>
</authors>
<title>in preparation. Three Models for Statistically Determining Coordinate Phrase Attachment.</title>
<marker>[MG, in prep]</marker>
<rawString>M. Goldberg. in preparation. Three Models for Statistically Determining Coordinate Phrase Attachment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<date>1993</date>
<booktitle>Structural Ambiguity and Lexical Relations. Computational Linguistics,</booktitle>
<pages>19--1</pages>
<marker>[HR93]</marker>
<rawString>D. Hindle, M. Rooth. 1993. Structural Ambiguity and Lexical Relations. Computational Linguistics, 19(1):103-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: the Penn Treebank,</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="2593" citStr="[MSM93]" startWordPosition="410" endWordPosition="410">e 1988 Wall Street Journal. After tagging and chunking the text, a rough heuristic is then employed to pick out training examples. This results in a training set that is less accurate, but much larger, than currently existing annotated corpora. It is the goal, then, of unsupervised training data to be abundant in order to offset its noisiness. 2 Background The statistical model must determine the probability of a given CP attaching either high (H) or low (L), p(attachment I phrase). Results shown come from a development corpus of 500 phrases of extracted head word tuples from the WSJ TreeBank [MSM93]. 64% of these phrases attach low and 36% attach high. After further development, final testing will be done on a separate corpus. The phrase: (busloads (of ((executives) and (their wives))) gives the 6-tuple: L busloads of executives and wives 610 where, a = L, n1 = busloads, p = of, n2 = executives, cc = and, n3 = wives. The CP attachment model must determine a for all (n1 p n2 cc n3) sets. The attachment decision is correct if it is the same as the corresponding decision in the TreeBank set. The probability of a CP attaching high is conditional on the 5-tuple. The algorithm presented in thi</context>
</contexts>
<marker>[MSM93]</marker>
<rawString>M. Marcus, B. Santorini and M. Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: the Penn Treebank, Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
<author>J Reynar</author>
<author>S Roukos</author>
</authors>
<title>A Maximum Entropy Model for Prepositional Phrase Attachment,</title>
<date>1994</date>
<booktitle>In Proceedings of the ARPA Workshop on Human Language Technology,</booktitle>
<contexts>
<context position="1361" citStr="[RRR94]" startWordPosition="206" endWordPosition="206">phrase (CP) is a source of structural ambiguity in natural language. For example, take the phrase: box of chocolates and roses &apos;Roses&apos; attaches either high to &apos;box&apos; or low to &apos;chocolates&apos;. In this case, attachment is high, yielding: H-attach: ((box (of chocolates)) (and roses)) Consider, then, the phrase: salad of lettuce and tomatoes &apos;Lettuce&apos; attaches low to &apos;tomatoes&apos;, giving: L-attach: (salad (of ((lettuce) and (tomatoes))) Previous work has used corpus-based approaches to solve the similar problem of prepositional phrase attachment. These have included backed-off [CB 95], maximum entropy [RRR94], rule-based [HR941, and unsupervised [AR98] models. In addition to these, a corpusbased model for PP-attachment [SN971 has been reported that uses information from a semantic dictionary. Sparse data can be a major concern in corpusbased disambiguation. Supervised models are limited by the amount of annotated data available for training. Such a model is useful only for languages in which annotated corpora are available. Because an unsupervised model does not rely on such corpora it may be modified for use in multiple languages as in [AR98]. The unsupervised model presented here trains from an </context>
</contexts>
<marker>[RRR94]</marker>
<rawString>A. Ratnaparkhi, J. Reynar and S. Roukos. 1994. A Maximum Entropy Model for Prepositional Phrase Attachment, In Proceedings of the ARPA Workshop on Human Language Technology, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Part-Of-Speech Tagger,</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference,</booktitle>
<contexts>
<context position="4522" citStr="[AR96]" startWordPosition="765" endWordPosition="765">there are only two nouns in the unambiguous CP, we must redefine its components. The first noun will be referred to as nl. It is analogous to n1 and n2 in the ambiguous CP. The second, terminal noun will be referred to as n3. It is analogous to the third noun in the ambiguous CP. Hence n1 = dog, cc = and, n3 = cat. In addition to the unambiguous CPs, the model also uses any noun that follows a cc. Such nouns are classified, n„. We extracted 119629 unambiguous CPs and 325261 ns from the unannotated 1988 Wall Street Journal. First the raw text was fed into the part-of-speech tagger described in [AR96]1. This was then passed to a simple chunker as used in [AR98), implemented with two small &apos;Because this tagger trained on annotated data, one may argue that the model presented here is not purely unsupervised. regular expressions that replace noun and quantifier phrases with their head words. These head words were then passed through a set of heuristics to extract the unambiguous phrases. The heuristics to find an unambiguous CP are: • on, is a coordinating conjunction (cc) if it is tagged cc. • on_x is the leftmost noun (n1) if: — _is the first noun to occur within 4 words to the left of cc. </context>
</contexts>
<marker>[AR96]</marker>
<rawString>A. Ratnaparkhi. 1996. A Maximum Entropy Part-Of-Speech Tagger, In Proceedings of the Empirical Methods in Natural Language Processing Conference, May 17-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Unsupervised Statistical Models for Prepositional Phrase Attachment,</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Computational Linguistics,</booktitle>
<pages>10--14</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1405" citStr="[AR98]" startWordPosition="211" endWordPosition="211">ty in natural language. For example, take the phrase: box of chocolates and roses &apos;Roses&apos; attaches either high to &apos;box&apos; or low to &apos;chocolates&apos;. In this case, attachment is high, yielding: H-attach: ((box (of chocolates)) (and roses)) Consider, then, the phrase: salad of lettuce and tomatoes &apos;Lettuce&apos; attaches low to &apos;tomatoes&apos;, giving: L-attach: (salad (of ((lettuce) and (tomatoes))) Previous work has used corpus-based approaches to solve the similar problem of prepositional phrase attachment. These have included backed-off [CB 95], maximum entropy [RRR94], rule-based [HR941, and unsupervised [AR98] models. In addition to these, a corpusbased model for PP-attachment [SN971 has been reported that uses information from a semantic dictionary. Sparse data can be a major concern in corpusbased disambiguation. Supervised models are limited by the amount of annotated data available for training. Such a model is useful only for languages in which annotated corpora are available. Because an unsupervised model does not rely on such corpora it may be modified for use in multiple languages as in [AR98]. The unsupervised model presented here trains from an unannotated version of the 1988 Wall Street </context>
<context position="3370" citStr="[AR98]" startWordPosition="556" endWordPosition="556">and (their wives))) gives the 6-tuple: L busloads of executives and wives 610 where, a = L, n1 = busloads, p = of, n2 = executives, cc = and, n3 = wives. The CP attachment model must determine a for all (n1 p n2 cc n3) sets. The attachment decision is correct if it is the same as the corresponding decision in the TreeBank set. The probability of a CP attaching high is conditional on the 5-tuple. The algorithm presented in this paper estimates the probability: = (a I nl,p, n2, cc, n3) The parts of the CP are analogous to those of the prepositional phrase (PP) such that {nl,n2} {n, v} and n3 p. [AR98] determines the probability p(v, n, p, a). To be consistent, here we determine the probability p(nl, n2, n3, a). 3 Training Data Extraction A statistical learning model must train from unambiguous data. In annotated corpora ambiguous data are made unambiguous through classifications made by human annotators. In unannotated corpora the data themselves must be unambiguous. Therefore, while this model disambiguates CPs of the form (n1 p n2 cc n3), it trains from implicitly unambiguous CPs of the form (n cc n). For example: dog and cat Because there are only two nouns in the unambiguous CP, we mus</context>
<context position="6962" citStr="[AR98]" startWordPosition="1185" endWordPosition="1185">s} and areas is extracted as a nc, because, although it is not part of an unambiguous CP, it occurs within four words after a conjunction. 4 The Statistical Model First, we can factor p(a, nl, n2, n3) as follows: p(a, nl, n2, n3) = p(nl)p(n2) p(a nl,n2) p(n3 I a, nl, n2) The terms p(n1) and p(n2) are independent of the attachment and need not be computed. The other two terms are more problematic. Because the training phrases are unambiguous and of the form (n1 cc n2), n1 and n2 of the CP in question never appear together in the training data. To compensate we use the following heuristic as in [AR98]. Let the random variable 0 range over {true, false} and let it denote the presence or absence of any n3 that unambiguously attaches to the n1 or n2 in question. If = true when any n3 unambiguously attaches to ni, then p(0 = true I n1) is the conditional probability that a particular n1 occurs with an unambiguously attached n3. Now p(a nl, n2) can be approximated as: p(true I n1) p(a = H I nl,n2) Z(nl, n2) p(true I n2) p(a = Lj nl,n2) Z(nl, n2) where the normalization factor, Z(nl,n2) = p(true I n1) + p(true I n2). The reasoning behind this approximation is that the tendency of a CP to attach </context>
<context position="10353" citStr="[AR98]" startWordPosition="1802" endWordPosition="1802">, the more comparable the unsupervised model is to its supervised counterpart. To our knowledge there has been very little if any work in the area of ambiguous CPs. In addition to developing an unsupervised CP disambiguation model, In [MG, in prep] we have developed two supervised models (one backed-off and one maximum entropy) for determining CP attachment. The backed-off model, closely based on [CB95] performs at 75.6% accuracy. The reduction error from the unsupervised model presented here to the backed-off model is 13%. This is comparable to the 14.3% error reduction found when going from [AR98] to [CB95]. It is interesting to note that after reducing the volume of training data by half there was no drop in accuracy. In fact, accuracy remained exactly the same as the volume of data was increased from half to full. The backed-off model in [MG, in prep] trained on only 1380 training phrases. The training corpus used in the study presented here consisted of 119629 training phrases. Reducing this figure by half is not overly significant. 6 Discussion In an effort to make the heuristic concise and portable, we may have oversimplified it thereby negatively affecting the performance of the </context>
</contexts>
<marker>[AR98]</marker>
<rawString>A. Ratnaparkhi. 1998. Unsupervised Statistical Models for Prepositional Phrase Attachment, In Proceedings of the Seventeenth International Conference on Computational Linguistics, Aug. 10-14, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Stetina</author>
<author>M Nagao</author>
</authors>
<title>Corpus Based PP Attachment Ambiguity Resolution with a Semantic Dictionary.</title>
<date>1997</date>
<booktitle>In Jou Shou and Kenneth Church, editors, Proceedings of the Fifth Workshop on Very Large Corpora,</booktitle>
<pages>66--80</pages>
<editor>and Hong Kong,</editor>
<location>Beijing</location>
<marker>[SN97]</marker>
<rawString>J. Stetina, M. Nagao. 1997. Corpus Based PP Attachment Ambiguity Resolution with a Semantic Dictionary. In Jou Shou and Kenneth Church, editors, Proceedings of the Fifth Workshop on Very Large Corpora, pages 66-80, Beijing and Hong Kong, Aug. 18-20.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>