<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.989139">
Generating Peripheral Rhetorical Devices by Consulting a User Model
</title>
<author confidence="0.995758">
Ingrid Zukerman
</author>
<affiliation confidence="0.964128">
Department of Computer Science
Monash University
</affiliation>
<keyword confidence="0.204401">
Clayton, VICTORIA 3168
AUSTRALIA
</keyword>
<sectionHeader confidence="0.958079" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999130461538462">
In the process of generating text, competent speakers take
into consideration the effect their utterances are likely to
have on their listeners. In particular, they try to anticipate
and prevent possible comprehension problems. In this
paper, we propose a mechanism which emulates this
behaviour for the generation of Peripheral Rhetorical
Devices, such as Motivations, Contradictions and Revi-
sions. Our mechanism anticipates the effect of a given
message on a model of a listener&apos;s beliefs, and proposes
these rhetorical devices to preclude possible adverse
effects. As a testbed for these ideas, a discourse planner
called WISHFUL is being implemented in the domain of
high-school algebra.
</bodyText>
<sectionHeader confidence="0.959692" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999965448275862">
In the process of generating text, competent
speakers/writers try to generate utterances which are best
suited to attain their communicative goals with respect
to a particular audience [Hovy 1987]. In particular,
speakers often anticipate the effect an intended message
is likely to have on their listener/readers&apos;, and if this
effect is adverse in some respect, the intended message
is either withdrawn or complemented with rhetorical
devices which counteract the effect. Although it is often
the case that speakers use stereotypical information
about their audience to accomplish this task, this infor-
mation is usually sufficient to allow them to generate
competent discourse.
Computational models for discourse generation
presented to date fall into a broad spectrum, where at
one end we find the plan-based approach [Appelt 19821,
and at the other the schema-based approach [McKeown
1985, Kukich 1983, Paris 1988]. In the plan-based
approach, a text plan which achieves a communicative
goal is produced by reasoning about the effect of vari-
ous speech acts on a listener&apos;s beliefs. In the schema-
based approach, standard patterns of discourse are
encoded using rhetorical predicates. Hybrid approaches
which combine both strategies have been proposed by
[Hovy 1988] and [Moore and Swartout 1989]. In partic-
ular, Moore and Swartout expand the capabilities of a
discourse planner to enable it to generate clarifying
explanations in a dialogue. However, both types of
discourse generation strategies are based on the implicit
</bodyText>
<footnote confidence="0.6602505">
1 The terms speaker/writer and listener/reader are used
interchangeably in this paper.
</footnote>
<bodyText confidence="0.999819333333333">
assumption that once an information item is understood,
the only modifications that will take place in a listener&apos;s
beliefs result directly from this item, and hence the
listener will immediately acquire the presented informa-
tion. That is, these strategies do not take into considera-
tion the effect of indirect inferences drawn from the
presented information on a listener&apos;s beliefs or the
indirect effect of his/her existing beliefs on the acquisi-
tion of this information. Therefore, they fail to account
for rhetorical devices which address beliefs that are
indirectly related to a speaker&apos;s communicative goal. For
instance, in the sample text in Figure 1 (shortened ver-
sion from [Lynch et al. 1979]) the communicative goal
is for the listener to know the distributive law, however,
the discourse which accomplishes this goal is preceded
by a Contradiction to the applicability of bracket sim-
plification to algebraic terms and a Revision of the
application of bracket simplification to numbers.
</bodyText>
<figureCaption confidence="0.970196">
Fig. 1: Distributive Law Sample Text
</figureCaption>
<bodyText confidence="0.956446666666667">
In this paper, we present a discourse planning
mechanism which emulates a speaker&apos;s behaviour in a
knowledge acquisition setting2 in order to generate a
class of rhetorical devices (RDs), denoted Peripheral
RDs, which comprises Contradictions, Revisions and
Motivations. Given a communicative goal to convey an
Intended Message (IM) to a listener, these rhetorical
2 The term knowledge acquisition setting describes a situation
where one agent transfers an intended message to another
agent with the communicative goal that second agent learn the
transferred information. Hence, in such a setting, intended
messages are not withdrawn.
</bodyText>
<figure confidence="0.991465714285715">
1 &amp;quot;In arithmetic, brackets must
2 always be calculated first, e.g.,
t. 3 2(5+3)/4 = 2x8/4 = 4
4 However, in algebra, the brackets
5 cannot always be simplified.
&apos; 6 For instance, in 2(x+y), the
7 x+y cannot be simplified.
8 So, can anything be done to
9 remove the brackets ?&amp;quot;
I. (Presentation of Distributive Law)
Revision
Contradiction
Intended
Message
</figure>
<page confidence="0.997294">
156
</page>
<bodyText confidence="0.998799631578948">
devices address beliefs presumably entertained by the
listener which may affect the acquisition of the IM, but,
unlike the beliefs addressed by Instantiations and
Descriptions, are not directly instrumental to its
comprehension [Zukerman 1990b]. Our mechanism is
based on ideas introduced in [Zukerman and Cheong
19881, and it follows the tenet that Peripheral RDs are
generated to invalidate anticipated impainnents to a
listener&apos;s comprehension process. To this effect, our
mechanism departs from the existing discourse genera-
tion strategies, and adopts a predictive approach,
whereby the effect of a message is simulated on a shal-
low model of a listener&apos;s beliefs. If an impairment to the
comprehension process is anticipated by this model, the
generation of a remedial rhetorical device is called for.
In the following section, we briefly consider a model
of a listener&apos;s beliefs capable of predicting commonly
drawn inferences. We then describe our mechanism for
the generation of Peripheral RDs.
</bodyText>
<subsectionHeader confidence="0.954637">
Model of a Listener&apos;s Beliefs
</subsectionHeader>
<bodyText confidence="0.999949976744186">
In order to address beliefs presumably entertained by a
particular listener, we maintain an epistemological
model which represents a listener&apos;s beliefs as a function
of the presented material. This function accounts both
for direct and indirect inferences drawn from presented
messages [Zukerman 1990a].
We represent a listener&apos;s beliefs by means of a net-
work whose nodes contain individual information items
and whose links contain the relationships between the
nodes (see Figure 2). The information in the network is
represented at a level of detail which is consistent with
the level of expertise required to learn the subject at
hand, e.g., for a high-school student learning algebra,
well-known concepts, such as numerical addition and
subtraction, are primitive, whereas relatively new or
complex concepts, such as bracket simplification, are
represented in terms of more primitive concepts. The
links in the network are labeled according to the manner
in which they were acquired, i.e., they can either be
Inferred, Told or previously Known, where Inferred
links are generated by means of generally applicable
Common-sense Inference Rules. In addition, each link is
accompanied by a Measure of Belief (MB) between -1
and 1, akin to Certainty Factors [Buchanan and Short-
liffe 19851, which represents a user&apos;s level of expertise.
The nodes are labeled according to their complexity, p
for primitive concepts and c for complex ones. Like
links, nodes may be Inferred, Told or previously
Known, and each node has a Degree of Expertise (DE)
between 0 and 1. The DE of a c-node is a function of
the DEs and MBs of its constituent nodes and links,
respectively.
In this paper, we focus on technical domains, where
the transmitted information typically pertains to pro-
cedures, objects and goals. We define a context as a tri-
ple composed of a procedure, an object to which it is
applied, and the goal accomplished by this procedure
when applied to this object (labeled cl-c4 in Figure 2),
to reflect the fact that one procedure may achieve dif-
ferent goals when applied to different objects. For exam-
ple, factoring out a common factor will only partially
factorize a quadratic trinomial such as 3x2+5x â€”2, while
it will completely factorize a binomial such as 3x2+5x.
</bodyText>
<equation confidence="0.959515333333333">
(AT) Algebraic
erms (pT
apply-too) apply4o(1)
</equation>
<sectionHeader confidence="0.328215" genericHeader="method">
Newly Inferred Links
</sectionHeader>
<subsectionHeader confidence="0.54855">
Nodes and Links to be added
Fig. 2: Network Model of a Listener&apos;s Beliefs in
High-School Algebra3
</subsectionHeader>
<bodyText confidence="0.986734095238095">
Our inference mechanism generates plausible infer-
ences from links in the network by means of generally
applicable Common-sense Inference Rules which portray
reasoning activities such as generalization, specialization
and similarity-based inference (see Figure 3). These
rules are inspired by rule adaptations commonly per-
formed by students which were studied by Matz (1982),
Brown and Van Lehn (1980), Van Lehn (1983) and
Sleeman (1984). In order to account for the deductive
abilities of a particular type of listener, we annotate each
rule with a measure of uncertainty, denoted p, which
represents a listener&apos;s belief in the validity of a conclu-
sion given that the evidence is certain. This measure
resembles the rule strength used in ACT* [Anderson
19831. The application of the similarity-based rule in
Figure 3 to the context cl and the link [Numbers simile
AT] in Figure 2 yields the erroneous context c3.
/ In the actual network each link may have a counterpart
representing the inverse relationship. However, for clarity of
presentation, only links which are relevant to our discussion
are shown here.
</bodyText>
<equation confidence="0.6910052">
Numbers
(pK)
simile(I)
simile(T)
super-otass(k)
apply-to(T) c3 \
c 4
iappiy-to(1)\apply-to(l)&apos;s-
labbly-to(l)
super-class(K)
</equation>
<figure confidence="0.983311352941176">
aPPY40
(UT) Unlike
Terms (pT)
apply-to(K)
cl
apply-to(K
(LT) Like
Terms (pT)
(BrE) Bracket
Elimination
(pT)
has-goaim
C
use-1(T) (BrS) Bracket
4 Simplification
(cT)
(pK)
</figure>
<page confidence="0.616772">
157
</page>
<sectionHeader confidence="0.392618" genericHeader="method">
R2 (Similarity-based Inference)
</sectionHeader>
<bodyText confidence="0.8767377">
; If two objects are identified as similar, the
; applicability of a procedure to one of the objects
; can be inferred from its applicability to the other,
; accomplishing the same goal
IF { 3 a link [OBJâ€ž, simile OBJâ€ž] (MB = kâ€žâ€ž,)
AND
3 a context [PROC.â€”OBJmâ€”GOALI]
With links [PROC. apply-to OM.] (MB = kam)
and [PROCa has-goal GOALI] (MB = &apos;gam) I
THEN (with certainty p2)
</bodyText>
<subsectionHeader confidence="0.648643">
Add a context [PR000-0114â€”GOALd
</subsectionHeader>
<bodyText confidence="0.993024">
with links [PROC. apply-to ORM of type I
</bodyText>
<equation confidence="0.984358">
(MB = kaâ€ž = p24ka,â€ž)
</equation>
<bodyText confidence="0.920318">
and [PROC. has-goal GOAL,] of type I
</bodyText>
<equation confidence="0.978562">
(MB = k =
</equation>
<sectionHeader confidence="0.7010805" genericHeader="method">
Fig. 3: Similarity-based
Common-sense Inference Rule
</sectionHeader>
<subsectionHeader confidence="0.990483">
Generating Peripheral Rhetorical Devices
</subsectionHeader>
<bodyText confidence="0.999970833333333">
The generation of Peripheral RDs is performed by
applying a procedure called Impairment-Invalidate. This
procedure simulates the effect of an IM on our network
model to anticipate possible impairments which may
inhibit a listener&apos;s acquisition of this IM, and then pro-
poses Peripheral RDs, such as Contradictions, Revisions
and Motivations, to invalidate these impairments. To
this effect, it activates three mechanisms: (1) Propaga-
tion of the effect of a message, (2) Recognition of
impairments, and (3) Selection of Peripheral RDs. In the
following subsections, we describe these mechanisms
and then discuss procedure Impairment-Invalidate.
</bodyText>
<subsectionHeader confidence="0.95336">
Propagation of a Message
</subsectionHeader>
<bodyText confidence="0.9999934">
Propagation simulates the alterations taking effect in a
network representing a listener&apos;s beliefs due to infer-
ences drawn from a message. These inferences, which
are drawn by activating applicable Common-sense Infer-
ence Rules, result in changes in the MBs of existing
links or addition of new links and nodes to the network.
For instance, a Contradiction such as &amp;quot;You cannot
always simplify inside the brackets of algebraic terms,&amp;quot;
presented to weaken a listener&apos;s belief in the applicabil-
ity of bracket simplification to Algebraic Terms, may
cause the listener to weaken his/her correct belief in the
applicability of bracket simplification to Like Algebraic
Terms or even to Numbers, and also to weaken his/her
incorrect belief in the applicability of bracket simplifica-
tion to Unlike Algebraic Terms and in the applicability
of addition and subtraction to Algebraic Terms. This
effect is simulated by the propagation of the Contradic-
tion [BrS â€“apply-to AT] in the sample network in Figure
2, which produces the inferences [BrS â€“apply-to LT] and
[BrS â€“apply-to UT] through the application of a
specialization rule, [BrS -,apply-to Numbers] through the
application of the similarity-based rule R2 (see Figure
3), and [+/â€“ â€“apply-to AT] through the application of a
deductive inference rule. These inferences contradict the
beliefs represented by existing links, thereby lowering
the MBs associated with these links. However, their
effect ultimately depends on the strength of the rules in
question and on the MBs of the links, i.e., the impact of
an inference on a wealdy believed link is more pro-
nounced than for a strongly believed one.
</bodyText>
<subsectionHeader confidence="0.970037">
Recognition of Impairments
</subsectionHeader>
<bodyText confidence="0.999962459459459">
The Recognition mechanism anticipates possible impair-
ments to a listener&apos;s comprehension process by examin-
ing changes in a network representing the listener&apos;s
beliefs due to a message or an inference. It does not
guarantee that a certain impairment will occur, rather, it
conjectures that an impairment is likely to affect a par-
ticular link, denoted a culprit link.
We have characterized in terms of our network model
two main types of impairments which lead to undesir-
able effects commonly encountered in a knowledge
acquisition setting: (1) Affect-related impairments which
elicit negative affective responses such as Confusion and
Loss of Interest, and are caused by a conflict between a
message or inference and a belief held by a listener; and
(2) Belief-related impairments such as Mislearning,
Insufficient Learning or Insignificant Change in a
listener&apos;s knowledge status, which are caused by a
discrepancy between a listener&apos;s belief in a proposition
(possibly as a result of an inference) and the belief the
speaker intends him/her to have in this proposition. Let
us first consider the Affect-related impairments.
Confusion occurs when an inference decreases signifi-
cantly a listener&apos;s confidence in a previous belief, caus-
ing a discomforting transition from a self-perception of
possessing knowledge to one of increased uncertainty. In
terms of our network model, Confusion takes place
when the absolute value of an Anticipated Measure of
Belief (AMB), obtained by combining the MB of a link
with the MB of an inference regarding this link, is signi-
ficantly lower than the absolute value of the original
MB of this link. For instance, the statement &amp;quot;One can-
not always add algebraic terms,&amp;quot; which yields a nega-
tive value for the MB of the link [+/â€“ apply-to AT] in
Figure 2, may trigger the erroneous inference [+1-
-apply-to LT], which contradicts the link [+/â€“ apply-to
LT], thereby lowering its MB. The Strength of this
impairment for a link L is defmed as follows:
</bodyText>
<equation confidence="0.850597">
Strength (Confusion ,L) =
max{(I MB (L)I â€“I AMB (L)I ),0)
</equation>
<bodyText confidence="0.999221714285714">
Loss of Interest occurs when a listener who is initially
motivated to acquire knowledge is presented with an IM
s/he considers redundant In terms of our model, this
takes place if there exists a node B which subsumes a
new node A, i.e., new distinguishing links incident upon
A are connected to the same nodes and have MBs of
compatible magnitude and sign as the corresponding
</bodyText>
<page confidence="0.993121">
158
</page>
<bodyText confidence="0.998064277777778">
links incident upon B. For this type of impairment, a
culprit link is an erroneous link incident upon B
representing belief, whose reversal into disbelief results
in B no longer subsuming A. This situation is illustrated
in Figure 2, where we try to add the node DL, represent-
ing distributive law, and the links [DL apply-to AT] and
[DL has-goal BrE] to the network representing a
listener&apos;s beliefs. However, the existence of the culprit
link [BrS apply-to AT] supports the erroneous belief that
bracket simplification is equivalent to distributive law,
thereby rendering the new procedure redundant. If all
the existing links participating in an impairment due to
Loss of Interest are correct, no culprit link is identified.
A characterization of Belief-related impairments must
take into consideration the difference between a
listener&apos;s level of expertise and a level of expertise con-
sidered satisfactory. To this effect we define the
Strength of an impairment / in link L as follows:
</bodyText>
<equation confidence="0.84141175">
max{(SMB (L)â€”AMB (L)),0)
if SMB (L)&gt;0
min{(SMB (L)â€”AMB (L)),0)
if SMB (L)&lt;0
</equation>
<bodyText confidence="0.999057235294118">
where SMB is a Satisfactory Measure of Belief represen-
tative of an adequate level of expertise with respect to a
link. Its value may be obtained from a network which
represents the speaker&apos;s beliefs. The relative position of
Belief-related impairments and Confusion in a listener&apos;s
belief space is graphically represented in Figure 4 which
depicts these impairments as a function of the AMB and
the previous MB of a link with SMB &gt;O. The diagram
for a link with SMB &lt;0 is symmetric to the one in Fig-
ure 4.
Mislearning takes place when an erroneous belief
with a relatively high degree of certainty is produced by
an incorrect inference drawn by a listener. In terms of
our network model, this takes place when the AMB of a
link represents a substantial incorrect belief, and if this
link existed previously, the strength of the impairment
has increased, i.e., the AMB of this link is farther than
its previous MB from its SMB. If the absolute value of
the AMB of the link in question is higher than the abso-
lute value of its previous MB, the listener will falsely
perceive him/herself as being more proficient.
Insufficient Learning occurs when a correct inference
yields a correct belief with a relatively high degree of
certainty, but which still falls short of a desired degree
of certainty representative of proficiency. In terms of
our network model, this occurs when the AMB of a link
represents a substantial correct belief, and if this link
existed previously, the strength of the impairment has
decreased, i.e., the AMB of this link is closer than its
previous MB to its SMB.
Finally, an Insignificant Change in a listener&apos;s
knowledge status occurs when an inference accom-
plishes a rather inconsequential change with respect to a
previously non-existent link or with respect to a link
</bodyText>
<figure confidence="0.800736333333333">
No impairment (NI) 0 Confusion (C)
Misleaming (ML) 0 Insufficient Learning (IL)
0 Insignificant Change (IC)
</figure>
<figureCaption confidence="0.995084">
Fig. 4: Characterization of Impairments for
a Link with SMB&gt;0
</figureCaption>
<bodyText confidence="0.9953562">
with an MB representative of insufficient proficiency.
This MB may represent either a correct belief or an
incorrect belief.
The immediate invalidation of Affect-related impair-
ments is essential for the smooth continuation of the
knowledge acquisition process, since their persistence
diverts a listener&apos;s mental resources from the task of
acquiring knowledge. On the other hand, the invalidation
of Belief-related impairments with respect to links which
are not currently in focus may be temporarily postponed
due to didactic or stylistic considerations. Therefore,
although Confusion may take place in conjunction with
a Belief-related impairment, the recognition and subse-
quent invalidation of Confusion takes precedence over
the detection of this impairment (see Figure 4).
</bodyText>
<subsectionHeader confidence="0.996086">
Selection of Rhetorical Devices
</subsectionHeader>
<bodyText confidence="0.999638">
The Selection mechanism proposes a Peripheral RD to
address a recognized impairment. The type of this rhe-
torical device, its wording, and its position in the final
message sequence depend on the type of the impairment,
the correctness and magnitude of the previous MB of
the culprit link, and the SMB of this link (see Table 1).
The strength of an impairment affects the need for addi-
tional explanations, such as Causal explanations and
Instantiations, to convey a Peripheral RD.
</bodyText>
<equation confidence="0.79346">
Strength (I L) =
</equation>
<page confidence="0.997735">
159
</page>
<tableCaption confidence="0.931488">
Table 1: Peripheral RDs as a Function of
Impairment Types and Link Values
</tableCaption>
<table confidence="0.997742076923077">
Impairment Link Value Peripheral RD
Type
Loss of Correct Motivate (add links)
Interest Incorrect Contradict link
Confusion Correct Revise link
Incorrect Contradict link
Mislearning â€” Contradict inference
Inseicient â€” Revise inference
Learning
Insignificant High MB (Correct) Revise link
Change High MB (Incorrect) Contradict link
Low MB (SMB &gt;0) Revise information
Low MB (SMB &lt;0) â€”
</table>
<bodyText confidence="0.999519949152542">
The Link Value column in Table 1 contains informa-
tion pertaining to the previous MB and the SMB of the
culprit link. This information is unnecessary when
addressing Mislearning and Insufficient Learning, since
these impairments are completely characterized by their
type. However, for the rest of the impairments, the
correctness of the previous MB is the main factor in the
determination of the type of a Peripheral RD. Loss of
Interest is invalidated by a Contradiction of a culprit
link, if such a link is identified; otherwise, a Motivation
has to generated by adding nodes and links which render
the new information non-redundant, e.g., &amp;quot;You already
know how to solve quadratic equations by completion to
square. A faster method is ... &amp;quot; (details regarding the
types of Motivations which are suitable for different
situations and users appear in [Zukerman 1987]). The
invalidation of an Insignificant Change in a link with an
MB representative of lack of expertise, i.e., an MB
whose absolute value is close to 0, is performed in a
manner similar to the correction of complete ignorance.
That is, if the SMB of this link is positive, this impair-
ment is invalidated by a Revision of the relevant infor-
mation, whereas if it is negative, i.e., representative of
disbelief, no Peripheral RD is proposed, since it may be
superfluous to induce disbelief with respect to a proposi-
tion which is hardly entertained by a listener.
As seen in Table 1, we distinguish between two types
of Peripheral RDs according to the source of the belief
being addressed, namely Peripheral RDs which address
previously existing links and Peripheral RDs which
address current inferences. This distinction is not always
reflected in the English realization of a rhetorical device,
rather, it may affect the Meta Comments which accom-
pany it and its position in the fmal message sequence.
For instance, the propagation of the Contradiction [BrS
-apply-to AT] may yield the erroneous inference [BrS
--apply-to LT] which in turn may cause an impairment in
the link [BrS apply-to LT]. If the anticipated impairment
is Confusion, it will be invalidated by a Revision of this
link, whereas if it is Mislearning, it will be invalidated
by a Contradiction of the erroneous inference. The most
succinct realization of both Peripheral RDs is the
sentence &amp;quot;You can always simplify bracketed Like
Terms.&amp;quot; However, the Revision of the previous belief
may appear either before or after the above Contradic-
tion and include a Meta Comment which states the
source of this belief, e.g., &amp;quot;As we saw in Section 7, you
can always simplify bracketed Like Terms&amp;quot;; while the
Contradiction of the erroneous inference would usually
appear after the above Contradiction and would be
accompanied by a Meta Comment which indicates a vio-
lation of an expectation established by the inference,
e.g., &amp;quot;Bracket simplification does not always apply to
algebraic terms, but it always applies to Like Terms.&amp;quot;
The Peripheral RDs proposed by our Selection mechan-
ism contain sufficient information to support the genera-
tion of these types of Meta Comments by means of
mechanisms such as the ones presented in [Zukerman
and Pearl 1986] and [Zukerman 1989].
</bodyText>
<subsectionHeader confidence="0.673841">
Procedure Impairment-Invalidate
</subsectionHeader>
<bodyText confidence="0.997851">
Impairment-Invalidate is activated with one argument
which contains an FM. It returns a Message-List com-
posed of the IM and the Peripheral RDs which were
proposed to invalidate the impairments anticipated as a
result of this message.
</bodyText>
<figure confidence="0.983971366666667">
Procedure Impairment-Invalidate(Message)
1 Message-List &lt;- Message
2 Peripheral -RDs Inferences &lt;- nil
3 FirstImp &lt;- (Message ,TM ,LM),
where (TM ,Sm LM) Recognize (Message)
4 If FirstImp Then
Message -List 4--
Append (Message-List ,Select(FirstImp))
5 For each m E Message-List do
6 Inferences &lt;- Merge (Inferences ,Propagate (m))
7 endfor
8 Impairments +- ,Ti ,S ) I (i E Inferences) A
Li)(-Recognize (i)))
9 While Impairments do
10 Maxlmp +- (I ,T1 4),
where AI ,T1 ,SI,Li)E Impairments A
Ranking (I ,T LI) =
max (Ranldng (j ,T; ,S ,L1)))
(j,TioSi,LI)elinpainrsenu
11 Impairments +- Impairments - MaxImp
12 RDmâ€ž,dâ€ž,r, fâ€” Select (Maxlmp)
13 Peripheral -RDs +-
Append (Peripheral -RDs ,RDmaximp)
14 Secondary-Inferences &lt;- Propagate (RD M,)
15 Secondary -Effects Secondary-Inferences n
0 1(j ,T ,S1 ,L )E Impairments)
16 Impairments &lt;- (Impairments
E Secondary -Effects Du
[(i ,T1 ,S; ,Li)1(i E Secondary-Inferences) A
((Ti,Si,Li)+-Recognize (i)))
</figure>
<footnote confidence="0.515915333333333">
17 endwhile
18 Message-List &lt;-
Append (Message -List ,Peripheral-RDs)
</footnote>
<page confidence="0.920872">
160
</page>
<tableCaption confidence="0.503058">
Table 2: Inferences and Possible Impairments after Propagation
</tableCaption>
<table confidence="0.998151444444444">
of the IM and the Contradiction in the Sample Network
Message Rule Inference 1 Possible Impairment
1M [DL apply-to Similarity [DL apply-to Numbers has-goal BrE]l
AT has-goal BrE] Specialization [DL apply-to LT has-goal BrE] } Insufficient Learning
Specialization [DL apply-to UT has-goal BrE] J
Contradiction Similarity [BrS -apply-to Numbers] 1 ConfusionlMislearningl
[BrS -apply-to AT] Specialization [BrS -apply-to LT] 1 Insignificant Change
Specialization [BrS -apply-to UT] 1 ConfusionlIns41 Learningl
Deduction [+/- -apply-to AT] J Insignificant Change
</table>
<bodyText confidence="0.995852253012048">
We distinguish between two main stages of this pro-
cedure: (1) The preliminary stage (lines 1-4) which
determines the need for a Peripheral RD related to the
input message, and (2) The iterative stage (lines 5-17)
which ascertains the need for Peripheral RDs pertaining
to subsequent inferences.
In the preliminary stage, procedure Recognize is
applied in order to determine whether the IM is likely to
cause an impairment. If this is the case, Recognition
returns a triple (T ,S ,L), where T contains the Type of
the impairment, S its Strength, and L indicates whether
the belief represented by the link in question is correct
or incorrect. Otherwise, it returns nil and no impairment
is predicted. If an impairment was anticipated, procedure
Select is activated to propose a Peripheral RD. In our
example, the Selection mechanism invalidates the
impairment responsible for the Loss of Interest by
means of the Contradiction [BrS -apply-to AT] which
induces disbelief in the link [BrS apply-to AT]. Upon
completion of the preliminary stage, the proposed Peri-
pheral RD together with the IM form the Message-List,
which constitutes the input to the next phase of the
impairment invalidation procedure.
Both the IM and the proposed Peripheral RD cause
modifications in a listener&apos;s degree of belief in the
addressed links. These modifications in turn may lead to
changes in his/her beliefs in other links. Hence, in order
to prevent impairments due to inferences drawn from
these messages, additional Peripheral RDs may be called
for. Furthermore, Peripheral RDs may be required in
order to invalidate an Insignificant Change in links
related to the IM which have MBs representative of
insufficient proficiency, i.e., to attain a satisfactory
degree of expertise with respect to these links. To deter-
mine the need for additional Peripheral RDs, Propagate
produces inferences from each message in Message-List.
During this process, inferences from different messages
which affect the same link are merged into one inference
with a combined effect (lines 5-7). Recognition then
ascertains the attributes of the impairments which are
likely to be caused by these inferences (line 8). For
instance, the Propagation of the input message [DL
apply-to AT has-goal BrE] and the Contradiction [BrS
-apply-to AT] in the sample network in Figure 2 may
yield the inferences in Table 2. In principle, each of
these inferences may be responsible for an impairment.
However, as stated above, the effect of these inferences
ultimately depends on the p-s of the rules applied in the
propagation process and on the MBs of the affected
links. In our present discussion, we assume that Confu-
sion was recognized in the links [BrS apply-to LT] and
[BrS apply-to Numbers].
Based on Gricean maxims of cooperative conversation
(Grice 1975), we propose to generate a minimal number
of rhetorical devices to invalidate impairments occurring
concurrently in a number of links. To this end, we
iterate over the set of impairments, selecting at each
stage the culprit link with the highest ranking impair-
ment (line 10). The impairments are ranked according to
their type and strength, where impairments causing Con-
fusion are ranked higher than Belief-related impairments.
A Peripheral RD is then proposed to invalidate the
impairment in the selected link, and its effect is pro-
pagated (lines 12-14). Once a Peripheral RD has been
generated to address a particular link, further inferences
drawn during the same activation of Impairment-
Invalidate no longer affect this link. For each iteration,
the set of impairments is updated by merging the infer-
ences responsible for the previously recognized impair-
ments with the inferences resulting from the most recent
propagation, and reapplying the Recognition process
(lines 15-16). In this manner, a low-ranking impairment
in a given link may be spontaneously invalidated by an
inference resulting from a Peripheral RD generated to
invalidate an impairment in another link. For example,
if the impairment in the link [BrS apply-to Numbers]
ranks higher than the impairment in the link [BrS apply-
to LT], a Revision is generated to invalidate the impair-
ment in the former link. The propagation of this Revi-
sion may invalidate the Confusion with respect to the
latter link. If this Revision does not cause further
impairments, the procedure terminates returning the fol-
lowing messages:
</bodyText>
<sectionHeader confidence="0.592706666666667" genericHeader="method">
IM [DL apply-to AT has-goal BrE]
Contradiction [BrS -apply-to AT]
Revision [BrS apply-to Numbers has-goal BrE]
</sectionHeader>
<bodyText confidence="0.9750982">
The generation of belief Revisions tends to inhibit
further impairments, since they reinforce beliefs which
are likely to be consistent with the rest of a listener&apos;s
beliefs, while the generation of belief Contradictions
tends to foster impairments, since they disagree with
</bodyText>
<page confidence="0.994724">
161
</page>
<bodyText confidence="0.999791555555556">
existing beliefs. However, in a knowledge acquisition
setting, misconceptions are generally not allowed to pile
up, hence Contradictions to existing beliefs are expected
only during the initial stages of the propagation process.
Therefore, although in principle our algorithm may
iterate indefinitely, in practice, impairments should no
longer be detected after a few iterations, and the process
should halt after proposing a few Peripheral RDs. This
expectation is confirmed by tests run with our sample
network (see next section). However, this network is
rather small, and there may be situations in which the
number of Peripheral RDs proposed by our mechanism
will have to be restricted due to stylistic or pedagogical
considerations. In such cases, our mechanism will have
to be adjusted to invalidate only a subset of the recog-
nized impairments such as the highest ranking impair-
ments or impairments in links which are closest to the
IM.
</bodyText>
<sectionHeader confidence="0.774065" genericHeader="evaluation">
Evaluation
</sectionHeader>
<bodyText confidence="0.999452975609756">
Procedure Impairment-Invalidate has been implemented
in a system called WISHFUL, which was run on several
instances of the network in Figure 2. These instances
featured MBs which represented three types of students:
(1) Competent â€” with high MBs associated with correct
beliefs, (2) Average â€” containing some incorrect beliefs
and medium-range MBs associated with correct beliefs,
and (3) Mediocre â€” with very low MBs associated with
most beliefs. The initial values assigned to the MBs of
the links and the p-s of the Common-sense Inference
Rules yielded Peripheral RDs which were compatible
with rhetorical devices people would generate under
similar circumstances, and the response time was instan-
taneous for these rather small networks. As expected,
changes in the p-s of the Common-sense Inference
Rules resulted in variations in the generated RDs, with
additional Contradictions due to Misleaming being gen-
erated as the p-s of unsound rules increased, and addi-
tional Revisions due to Insufficient Learning as the p-s
of sound rules decreased. In addition, the number and
strength of the recognized impairments increased as the
ability of the students being represented in a network
decreased, indicating that additional explanations would
be required to convey a message to the poorer students.
In particular, for the networks representing competent
students, either Revisions of inferences due to Insuffi-
cient Learning or no Peripheral RDs were proposed
(depending on the p-s of the Common-sense Inference
Rules); for the networks representing average students,
Contradictions and Revisions were proposed in a manner
similar to the explanations in this paper, and for the net-
works representing mediocre students most of the pro-
posed Peripheral RDs were Revisions of information.
Our mechanism has also proven successful as an
analytical tool. It accounts for the presence of Peripheral
RDs in over twenty texts in a variety of domains, rang-
ing from expert domains (Telecommunications, Cogni-
tive Science and Linguistics) through intennediate ones
(high-school Algebra, Data Structures, Lisp and intro-
ductory Chess) to novice domains (Childcraft Encyclo-
pedia and Dr. Speck&apos;s Baby and Child Care).
</bodyText>
<subsectionHeader confidence="0.860947">
Limitations and Future Research
</subsectionHeader>
<bodyText confidence="0.99994796969697">
Our mechanism proposes rhetorical devices under the
assumption that after it has done &amp;quot;its best,&amp;quot; the
listener&apos;s beliefs addressed by the discourse will be
modified in the desired direction, although not neces-
sarily to the desired extent. This is a valid assumption
for discourse generation, since one can not say more
than one knows. However, for this mechanism to gen-
erate effective discourse on a continued basis, the model
of the listener&apos;s beliefs must be updated by an indepen-
dent assessment of the his/her understanding.
In addition, our mechanism must be implemented on
different domains and larger networks to test both its
response time and the adequacy and number of the pro-
posed rhetorical devices. As stated above, this may
reveal the need to adjust procedure Impairment-
Invalidate to enable it to control the number of the pro-
posed Peripheral RDs.
At present, research is in progress to extend the
impairment invalidation paradigm to the generation of
other types of rhetorical devices, such as Descriptions,
Instantiations and Causal explanations, and to devise an
algorithm to sort the generated messages according to
rhetorical considerations (Zukerman 1990b). In addition,
an alternative representation for MBs which keeps track
of the sources of an inference is being considered.
Further research is required to recognize and rectify pos-
sible misconceptions in the Common-sense Inference
Rules, and to characterize conditions for the generation
of rhetorical devices which satisfy a number of com-
municative goals. Finally, the effect of the knowledge
representation and the rules of inference on the types of
the proposed rhetorical devices needs to be further
investigated.
</bodyText>
<sectionHeader confidence="0.916182" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999973">
This paper offers a text planning mechanism which sup-
ports the generation of explanations tailored to particular
types of users. Our mechanism generates Peripheral RDs
which help convey an intended message by anticipating
and preventing potential impainnents to a listener&apos;s
comprehension process. To this effect, it characterizes
these impairments in terms of a model of a listener&apos;s
beliefs and inferences, and simulates a listener&apos;s
comprehension process on this model. Clearly, this pro-
cess does not dispense with the need to interact with a
listener, but it addresses commonly occurring impair-
ments, thereby focusing the interaction. Furthermore, it
is envisioned that the impairment invalidation mechan-
ism will become a useful tool to guide the generation of
cogent responses to user follow-up queries, as it can
point to issues which are potentially troublesome.
</bodyText>
<page confidence="0.99698">
162
</page>
<sectionHeader confidence="0.995887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999611093023256">
[Anderson, 19831 J.R. Anderson. The Architecture of
Cognition, Harvard University Press, Cambridge,
Massachusetts.
[Appelt, 1982] D.E. Appelt. Planning Natural Language
Utterances to Satisfy Multiple Goals. Technical Note
259, SRI International, March 1982.
[Brown and Van Lehn, 1980] J.S. Brown and K. Van
Lehn. Repair Theory: A Generative Theory of Bugs
in Procedural Skills. In Cognitive Science 4, pp. 379-
426.
[Buchanan and Shortliffe, 1985] B.G. Buchanan and
E.H. Shortliffe. Rule-Based Expert Systems â€” The
MYCIN Experiments of the Stanford Heuristic Pro-
gramming Project, Addison-Wesley Publishing Com-
pany.
[Grice, 1975] H.P. Grice. Logic and Conversation. In
P.J. Cole and J.L. Morgan (Eds.), Syntax and Seman-
tics, Volume 3: Speech Acts, Academic Press, pp. 41-
58.
[Hovy, 1987] E.H. Hovy. Generating Natural Language
under Pragmatic Constraints. Doctoral Dissertation,
Computer Science Department, Yale University, New
Haven, Connecticut.
[Hovy, 1988] E.H. Hovy. Planning Coherent Multisen-
tential Text. In Proceedings of the Twenty-Sixth
Annual Meeting of the Association for Computational
Linguistics, State University of New York, Buffalo,
New York.
[Kuldch, 1983] K. Kuldch. Knowledge-Based Report
Generation: A Knowledge-Engineering Approach to
Natural Language Report Generation. Doctoral
Dissertation, The Interdisciplinary Department of
Information Science, University of Pittsburgh,
Pennsylvania.
[Lynch et al., 1979] B.J. Lynch, R.E. Parr and H.M.
Keating. Maths 8, Sorrett Publishing.
[Matz, 1982] M. Matz. Towards a Process Model for
High School Algebra Errors. In D. Sleeman and J.S.
Brown (Eds.), Intelligent Tutoring Systems, London:
Academic Press, 1982, pp. 25-50.
[McKeown, 1985] K.R. McKeown. Discourse Strategies
for Generating Natural Language Text In Artificial
Intelligence 27, pp. 1-41.
[Moore and Swartout, 1989] J.D. Moore and W.R.
Swartout. A Reactive Approach to Explanation. In
IJCAI-11 Proceedings, International Joint Conference
on Artificial Intelligence, pp. 1504-1510.
[Paris, 1988] C.L. Paris. Tailoring Object Descriptions
to a User&apos;s Level of Expertise. In Computational
Linguistics, Volume 14, Number 3, September 1988,
pp. 64-78.
[Sleeman, 1984] D. Sleeman. Mis-Generalization: An
Explanation of Observed Mal-rules. In Proceedings of
the Sixth Annual Conference of the Cognitive Science
Society, pp. 51-56.
[Van Lehn, 1983] K. Van Lehn. Human Procedural Skill
Acquisition: Theory, Model and Psychological Valida-
tion. In AAAI-83 Proceedings, American Association
for Artificial Intelligence, August 1983, pp. 420-423.
[Zukerman and Pearl, 1986] I. Zukerman and J. Pearl.
Comprehension-Driven Generation of Meta-technical
Utterances in Math Tutoring. In AAAI-86 Proceed-
ings, American Association for Artificial Intelligence,
pp. 606-611.
[Zukerman, 1987] I. Zukerman, Goal-based Generation
of Motivational Expressions in a Learning Environ-
ment In AAAI-87 Proceedings, American Association
for Artificial Intelligence, July 1987, pp. 327-331.
[Zukerman and Cheong, 1988] I. Zukerman and Y.H.
Cheong. Impairment Invalidation: A Computational
Model for the Generation of Rhetorical Devices. In
Proceedings of the International Computer Science
Conference &apos;88: Artificial Intelligence, Theory and
Applications, pp. 294-300.
[Zukerman, 1989] I. Zukerman. Expectation Verifica-
tion: A Mechanism for the Generation of Meta Com-
ments. In Proceedings of the 11th Conference of the
Cognitive Science Society, Ann Arbor, Michigan, pp.
498-505.
[Zukerman, 1990a] I. Zukerman. A Predictive Approach
to the Generation of Rhetorical Devices. To appear in
Computational Intelligence, Vol 6, No. 1.
[Zukerman, 1990b] I. Zukerman. Anticipating a
Listener&apos;s Response in Text Planning. To appear in
Advances in Artificial Intelligence, Natural Language
and Knowledge-based Systems, Springer Verlag.
</reference>
<page confidence="0.999107">
163
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.557347">
<title confidence="0.997554">Generating Peripheral Rhetorical Devices by Consulting a User Model</title>
<author confidence="0.889052">Ingrid</author>
<affiliation confidence="0.875302">Department of Computer Monash</affiliation>
<address confidence="0.9157585">Clayton, VICTORIA AUSTRALIA</address>
<abstract confidence="0.998382214285714">In the process of generating text, competent speakers take into consideration the effect their utterances are likely to have on their listeners. In particular, they try to anticipate and prevent possible comprehension problems. In this paper, we propose a mechanism which emulates this behaviour for the generation of Peripheral Rhetorical Devices, such as Motivations, Contradictions and Revi- Our mechanism anticipates the effect of message on a model of a listener&apos;s beliefs, and proposes these rhetorical devices to preclude possible adverse effects. As a testbed for these ideas, a discourse planner called WISHFUL is being implemented in the domain of high-school algebra.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>The Architecture of Cognition,</title>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker></marker>
<rawString> [Anderson, 19831 J.R. Anderson. The Architecture of Cognition, Harvard University Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Appelt</author>
</authors>
<title>Planning Natural Language Utterances to Satisfy Multiple Goals.</title>
<date>1982</date>
<tech>Technical Note 259,</tech>
<institution>SRI International,</institution>
<marker>[Appelt, 1982]</marker>
<rawString>D.E. Appelt. Planning Natural Language Utterances to Satisfy Multiple Goals. Technical Note 259, SRI International, March 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J S Brown</author>
<author>K Van Lehn</author>
</authors>
<title>Repair Theory: A Generative Theory of Bugs in Procedural Skills.</title>
<journal>In Cognitive Science</journal>
<volume>4</volume>
<pages>379--426</pages>
<marker>[Brown and Van Lehn, 1980]</marker>
<rawString>J.S. Brown and K. Van Lehn. Repair Theory: A Generative Theory of Bugs in Procedural Skills. In Cognitive Science 4, pp. 379-426.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B G Buchanan</author>
<author>E H Shortliffe</author>
</authors>
<title>Rule-Based Expert Systems â€” The MYCIN Experiments of the Stanford Heuristic Programming Project,</title>
<publisher>Addison-Wesley Publishing Company.</publisher>
<marker>[Buchanan and Shortliffe, 1985]</marker>
<rawString>B.G. Buchanan and E.H. Shortliffe. Rule-Based Expert Systems â€” The MYCIN Experiments of the Stanford Heuristic Programming Project, Addison-Wesley Publishing Company.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic and Conversation. In</title>
<pages>41--58</pages>
<publisher>Academic Press,</publisher>
<marker>[Grice, 1975]</marker>
<rawString>H.P. Grice. Logic and Conversation. In P.J. Cole and J.L. Morgan (Eds.), Syntax and Semantics, Volume 3: Speech Acts, Academic Press, pp. 41-58.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E H Hovy</author>
</authors>
<title>Generating Natural Language under Pragmatic Constraints.</title>
<institution>Doctoral Dissertation, Computer Science Department, Yale University,</institution>
<location>New Haven, Connecticut.</location>
<marker>[Hovy, 1987]</marker>
<rawString>E.H. Hovy. Generating Natural Language under Pragmatic Constraints. Doctoral Dissertation, Computer Science Department, Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E H Hovy</author>
</authors>
<title>Planning Coherent Multisentential Text.</title>
<booktitle>In Proceedings of the Twenty-Sixth Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics, State University of</institution>
<location>New York, Buffalo, New York.</location>
<marker>[Hovy, 1988]</marker>
<rawString>E.H. Hovy. Planning Coherent Multisentential Text. In Proceedings of the Twenty-Sixth Annual Meeting of the Association for Computational Linguistics, State University of New York, Buffalo, New York.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K Kuldch</author>
</authors>
<title>Knowledge-Based Report Generation: A Knowledge-Engineering Approach to Natural Language Report Generation.</title>
<institution>Doctoral Dissertation, The Interdisciplinary Department of Information Science, University of Pittsburgh,</institution>
<location>Pennsylvania.</location>
<marker>[Kuldch, 1983]</marker>
<rawString>K. Kuldch. Knowledge-Based Report Generation: A Knowledge-Engineering Approach to Natural Language Report Generation. Doctoral Dissertation, The Interdisciplinary Department of Information Science, University of Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B J Lynch</author>
<author>R E Parr</author>
<author>H M Keating</author>
</authors>
<tech>Maths 8,</tech>
<institution>Sorrett Publishing.</institution>
<marker>[Lynch et al., 1979]</marker>
<rawString>B.J. Lynch, R.E. Parr and H.M. Keating. Maths 8, Sorrett Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Matz</author>
</authors>
<title>Towards a Process Model for High School Algebra Errors. In</title>
<date>1982</date>
<pages>25--50</pages>
<publisher>Academic Press,</publisher>
<location>London:</location>
<marker>[Matz, 1982]</marker>
<rawString>M. Matz. Towards a Process Model for High School Algebra Errors. In D. Sleeman and J.S. Brown (Eds.), Intelligent Tutoring Systems, London: Academic Press, 1982, pp. 25-50.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K R McKeown</author>
</authors>
<title>Discourse Strategies for Generating Natural Language Text In</title>
<journal>Artificial Intelligence</journal>
<volume>27</volume>
<pages>1--41</pages>
<marker>[McKeown, 1985]</marker>
<rawString>K.R. McKeown. Discourse Strategies for Generating Natural Language Text In Artificial Intelligence 27, pp. 1-41.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J D Moore</author>
<author>W R Swartout</author>
</authors>
<title>A Reactive Approach to Explanation. In</title>
<booktitle>IJCAI-11 Proceedings, International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1504--1510</pages>
<marker>[Moore and Swartout, 1989]</marker>
<rawString>J.D. Moore and W.R. Swartout. A Reactive Approach to Explanation. In IJCAI-11 Proceedings, International Joint Conference on Artificial Intelligence, pp. 1504-1510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Paris</author>
</authors>
<title>Tailoring Object Descriptions to a User&apos;s Level of Expertise.</title>
<date>1988</date>
<booktitle>In Computational Linguistics, Volume 14, Number 3,</booktitle>
<pages>64--78</pages>
<marker>[Paris, 1988]</marker>
<rawString>C.L. Paris. Tailoring Object Descriptions to a User&apos;s Level of Expertise. In Computational Linguistics, Volume 14, Number 3, September 1988, pp. 64-78.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Sleeman</author>
</authors>
<title>Mis-Generalization: An Explanation of Observed Mal-rules.</title>
<booktitle>In Proceedings of the Sixth Annual Conference of the Cognitive Science Society,</booktitle>
<pages>51--56</pages>
<marker>[Sleeman, 1984]</marker>
<rawString>D. Sleeman. Mis-Generalization: An Explanation of Observed Mal-rules. In Proceedings of the Sixth Annual Conference of the Cognitive Science Society, pp. 51-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Van Lehn</author>
</authors>
<title>Human Procedural Skill Acquisition: Theory, Model and Psychological Validation.</title>
<date>1983</date>
<booktitle>In AAAI-83 Proceedings, American Association for Artificial Intelligence,</booktitle>
<pages>420--423</pages>
<marker>[Van Lehn, 1983]</marker>
<rawString>K. Van Lehn. Human Procedural Skill Acquisition: Theory, Model and Psychological Validation. In AAAI-83 Proceedings, American Association for Artificial Intelligence, August 1983, pp. 420-423.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Zukerman</author>
<author>J Pearl</author>
</authors>
<title>Comprehension-Driven Generation of Meta-technical Utterances in Math Tutoring.</title>
<booktitle>In AAAI-86 Proceedings, American Association for Artificial Intelligence,</booktitle>
<pages>606--611</pages>
<marker>[Zukerman and Pearl, 1986]</marker>
<rawString>I. Zukerman and J. Pearl. Comprehension-Driven Generation of Meta-technical Utterances in Math Tutoring. In AAAI-86 Proceedings, American Association for Artificial Intelligence, pp. 606-611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
</authors>
<title>Goal-based Generation of Motivational Expressions in a Learning Environment In</title>
<date>1987</date>
<booktitle>AAAI-87 Proceedings, American Association for Artificial Intelligence,</booktitle>
<pages>327--331</pages>
<marker>[Zukerman, 1987]</marker>
<rawString>I. Zukerman, Goal-based Generation of Motivational Expressions in a Learning Environment In AAAI-87 Proceedings, American Association for Artificial Intelligence, July 1987, pp. 327-331.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Zukerman</author>
<author>Y H Cheong</author>
</authors>
<title>Impairment Invalidation: A Computational Model for the Generation of Rhetorical Devices.</title>
<booktitle>In Proceedings of the International Computer Science Conference &apos;88: Artificial Intelligence, Theory and Applications,</booktitle>
<pages>294--300</pages>
<marker>[Zukerman and Cheong, 1988]</marker>
<rawString>I. Zukerman and Y.H. Cheong. Impairment Invalidation: A Computational Model for the Generation of Rhetorical Devices. In Proceedings of the International Computer Science Conference &apos;88: Artificial Intelligence, Theory and Applications, pp. 294-300.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Zukerman</author>
</authors>
<title>Expectation Verification: A Mechanism for the Generation of Meta Comments.</title>
<booktitle>In Proceedings of the 11th Conference of the Cognitive Science Society,</booktitle>
<pages>498--505</pages>
<location>Ann Arbor, Michigan,</location>
<marker>[Zukerman, 1989]</marker>
<rawString>I. Zukerman. Expectation Verification: A Mechanism for the Generation of Meta Comments. In Proceedings of the 11th Conference of the Cognitive Science Society, Ann Arbor, Michigan, pp. 498-505.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Zukerman</author>
</authors>
<title>A Predictive Approach to the Generation of Rhetorical Devices.</title>
<journal>Computational Intelligence,</journal>
<volume>6</volume>
<note>To appear in</note>
<marker>[Zukerman, 1990a]</marker>
<rawString>I. Zukerman. A Predictive Approach to the Generation of Rhetorical Devices. To appear in Computational Intelligence, Vol 6, No. 1.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Zukerman</author>
</authors>
<title>Anticipating a Listener&apos;s Response in Text Planning.</title>
<booktitle>Advances in Artificial Intelligence, Natural Language and Knowledge-based Systems,</booktitle>
<publisher>Springer Verlag.</publisher>
<note>To appear in</note>
<marker>[Zukerman, 1990b]</marker>
<rawString>I. Zukerman. Anticipating a Listener&apos;s Response in Text Planning. To appear in Advances in Artificial Intelligence, Natural Language and Knowledge-based Systems, Springer Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>