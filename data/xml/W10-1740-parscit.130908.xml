<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001579">
<title confidence="0.996399">
Adaptive Model Weighting and Transductive Regression for
Predicting Best System Combinations
</title>
<author confidence="0.982699">
Ergun Bigici
</author>
<affiliation confidence="0.941483">
KoC University
</affiliation>
<address confidence="0.647659">
34450 Sariyer, Istanbul, Turkey
</address>
<email confidence="0.996629">
ebicici@ku.edu.tr
</email>
<author confidence="0.770482">
S. Serdar Kozat
</author>
<affiliation confidence="0.740839">
KoC University
</affiliation>
<address confidence="0.532616">
34450 Sariyer, Istanbul, Turkey
</address>
<email confidence="0.989231">
skozat@ku.edu.tr
</email>
<sectionHeader confidence="0.979369" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982227272728">
We analyze adaptive model weight-
ing techniques for reranking using in-
stance scores obtained by Li regular-
ized transductive regression. Compet-
itive statistical machine translation is
an on-line learning technique for se-
quential translation tasks where we
try to select the best among com-
peting statistical machine translators.
The competitive predictor assigns a
probability per model weighted by
the sequential performance. We de-
fine additive, multiplicative, and loss-
based weight updates with exponential
loss functions for competitive statisti-
cal machine translation. Without any
pre-knowledge of the performance of
the translation models, we succeed in
achieving the performance of the best
model in all systems and surpass their
performance in most of the language
pairs we considered.
</bodyText>
<sectionHeader confidence="0.997334" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977833333334">
When seen as independent instances, system
combination task can be solved with a sequen-
tial learning algorithm. Online learning algo-
rithms enable us to benefit from previous good
model choices to estimate the next best model.
We use transductive regression based machine
translation model to estimate the scores for
each sentence.
We analyze adaptive model weighting tech-
niques for system combination when the com-
peting translators are SMT models. We use
separate model weights weighted by the se-
quential performance. We use additive, mul-
tiplicative, or loss based weight updates to
update model weights. Without any pre-
knowledge of the performance of the transla-
tion models, we are able to achieve the per-
formance of the best model in all systems and
we can surpass its performance as well as the
regression based machine translation’s perfor-
mance.
The next section reviews the transductive
regression approach for machine translation,
which we use to obtain instance scores. In sec-
tion 3 we present competitive statistical ma-
chine translation model for solving sequential
translation tasks with competing translation
models. Section 4 presents our results and ex-
periments and the last section gives a sum-
mary of our contributions.
</bodyText>
<sectionHeader confidence="0.9146335" genericHeader="introduction">
2 Transductive Regression Based
Machine Translation
</sectionHeader>
<bodyText confidence="0.99974">
Transduction uses test instances, which can
sometimes be accessible at training time, to
learn specific models tailored towards the test
set. Transduction has computational advan-
tages since we are not using the full train-
ing set and a smaller set of constraints exist
to satisfy. Transductive regression based ma-
chine translation (TRegMT) aims to reduce
the computational burden of the regression ap-
proach by reducing the dimensionality of the
training set and the feature set and also im-
prove the translation quality by using trans-
duction.
</bodyText>
<sectionHeader confidence="0.663736" genericHeader="method">
Regression Based Machine Translation:
</sectionHeader>
<bodyText confidence="0.999792375">
Let n training instances be represented as
(x1, y1), &amp;quot;&apos; , (xn,yn) E X*xY *, where (xi, yi)
corresponds to a pair of source and target lan-
guage token sequences. Our goal is to find
a mapping f : X* —* Y * that can convert a
given set of source tokens to a set of target to-
kens that share the same meaning in the target
language.
</bodyText>
<page confidence="0.974062">
276
</page>
<note confidence="0.4531385">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 276–281,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.87389675">
We use feature mappers 4&apos;X : X* →
FX = RNX and 4bY : Y * → FY =
RNY to represent the training set. Then,
MX ∈ RNXxn and MY ∈ RNY xn such that
</bodyText>
<equation confidence="0.9786734">
MX = [4bX(x1), ... , 4bX(xn)] and MY =
[4bY (y1), . . . , `bY (yn)]. The ridge regression
solution using L2 regularization is found as:
HL2 = arg min kMY −HMX k2F +AkHk2F . (1)
HERNY xNX
</equation>
<bodyText confidence="0.9999205">
Two main challenges of the regression based
machine translation (RegMT) approach are
learning the regression function, g : X* →
FY , and solving the pre-image problem, which,
given the features of the estimated target
string sequence, g(x) = -bY (y), attempts to
find y ∈ Y *: f(x) = arg minyEY * ||g(x) −
.bY (y)||2. Pre-image calculation involves a
search over possible translations minimizing
the cost function:
</bodyText>
<equation confidence="0.9995625">
f(x) = arg min
yEY * k-bY (y) − H-bX(x)k2 . (2)
</equation>
<bodyText confidence="0.95358625">
We use n-spectrum weighted word feature
mappers (Taylor and Cristianini, 2004) which
consider all word sequences up to order n.
L1 Regularized Regression for Learning:
HL2 is not a sparse solution as most of the co-
efficients remain non-zero. L1 norm behaves
both as a feature selection technique and a
method for reducing coefficient values.
</bodyText>
<equation confidence="0.6988645">
HL, = arg min kMY −HMX k2F +AkHk1 .(3)
HERNY xNX
</equation>
<bodyText confidence="0.999710777777778">
Equation 3 presents the lasso (least absolute
shrinkage and selection operator) (Tibshirani,
1996) solution where the regularization term
is defined as kHk1= Ei,j |Hi,j|. We use for-
ward stagewise regression (FSR) (Hastie et
al., 2006) and quadratic programming (QP) to
find HL,. The details of the TRegMT model
can be read in a separate submission to the
translation task (Bicici and Yuret, 2010).
</bodyText>
<sectionHeader confidence="0.9881015" genericHeader="method">
3 Competitive Statistical Machine
Translation
</sectionHeader>
<bodyText confidence="0.999971">
We develop the Competitive Statistical Ma-
chine Translation (CSMT) framework for se-
quential translation tasks when the compet-
ing models are statistical machine translators.
CSMT uses the output of different translation
models to achieve a translation performance
that surpasses the translation performance of
all of the component models or achieves the
performance of the best.
CSMT uses online learning to update the
weights used for estimating the best perform-
ing translation model. Competitive predictor
assigns a weight per model estimated by their
sequential performance. At each step, m com-
ponent translation models are executed in par-
allel over the input source sentence sequence
and the loss lp[n] of model p at observation
n is calculated by comparing the desired data
y[n] with the output of model p, yp[n]. CSMT
model selects a model based on the weights
and the performance of the selected model as
well as the remaining models to adaptively up-
date the weights given for each model. This
corresponds to learning in full information set-
ting where we have access to the loss for each
action (Blum and Mansour, 2007). CSMT
learning involves two main steps: estimation
and weight update:
</bodyText>
<equation confidence="0.966237">
yc[n] = E(w[n], x[n]), (estimation)
lp[n] = y[n] − yp[n], (instance loss)
Lp[n] = n i=1 lp[a]2, (cumulative loss)
w[n + 1] = U(w[n], yc[n],L[n]), (update)
(4)
</equation>
<bodyText confidence="0.998938619047619">
where w[n] = (w1[n], ... , wm[n]) for m mod-
els, Lp is the cumulative squared loss of model
p, L[n] stores cumulative and instance losses,
and yc[n] is the competitive model estimated
for instance n. The learning problem is finding
an adaptive w that minimizes the cumulative
squared error with appropriate estimation and
update methods.
Related Work: Multistage adaptive filter-
ing (Kozat and Singer, 2002) combines the
output of multiple adaptive filters to outper-
form the best among them where the first
stage executes models in parallel and the sec-
ond stage updates parameters using the per-
formance of the combined prediction, yc[n].
Macherey and Och (2007) investigate different
approaches for system combination including
candidate selection that maximize a weighted
combination of BLEU scores among different
system outputs. Their system uses a fixed
weight vector trained on the development set
</bodyText>
<page confidence="0.976616">
277
</page>
<bodyText confidence="0.964723">
to be multiplied with instance BLEU scores.
</bodyText>
<subsectionHeader confidence="0.9975055">
3.1 Estimating the Best Performing
Translation Model
</subsectionHeader>
<bodyText confidence="0.9999669">
We use additive, multiplicative, or loss based
updates to estimate model weights. We
measure instance loss with trLoss(y[i], yp[i]),
which is a function that returns the transla-
tion performance of the output translation of
model p with respect to the reference transla-
tion at instance i. 1-BLEU (Papineni et al.,
2001) is one such function with outputs in the
range [0, 1]. Cumulative squared loss of the
p-th translation model is defined as:
</bodyText>
<equation confidence="0.987233">
n
Gp[n] = trLoss(y[i], yp[i])2. (5)
i=1
</equation>
<bodyText confidence="0.999723666666667">
We use exponentially re-weighted prediction to
estimate model performances, which uses ex-
ponentially re-weighted losses based on the
outputs of the m different translation models.
We define the additive exponential weight
update as follows:
</bodyText>
<equation confidence="0.930822">
, (6)
</equation>
<bodyText confidence="0.972183761904762">
where η &gt; 0 is the learning rate and the de-
nominator is used for normalization. The up-
date amount, e−η lp[n] is 1 when lp[n] = 0 and it
approaches zero with increasing instance loss.
Perceptrons, gradient descent, and Widrow-
Huff learning have additive weight updates.
We define the multiplicative exponential
weight update as follows:
� wk[n] e−η lk[n]2
k=1
where we use the squared instance loss. Equa-
tion 7 is similar to the update of Weighted Ma-
jority Algorithm (Littlestone and Warmuth,
1992) where the weights of the models that
make a mistake are multiplied by a fixed β
such that 0 &lt; β &lt; 1.
We use Bayesian Information Criterion
(BIC) as a loss based re-weighting technique.
Assuming that instance losses are normally
distributed with variance σ2, BIC score is ob-
tained as (Hastie et al., 2009):
</bodyText>
<equation confidence="0.9618235">
Gp[n]
BICp[n] = σ2 + dp log(n),
</equation>
<bodyText confidence="0.999949555555555">
where σ2 is estimated by the average of model
sample variances of squared instance loss and
dp is the number of parameters used in model p
which we assume to be the same for all models;
therefore we can discard the second term. The
model with the minimum BIC value becomes
the one with the highest posterior probability
where the posterior probability of model p can
be estimated as (Hastie et al., 2009):
</bodyText>
<equation confidence="0.994957">
e
wp[n + 1] =
2BICk[n]
1
</equation>
<bodyText confidence="0.9998355">
The posterior probabilities become model
weights and we basically forget about the pre-
vious weights, whose information is presum-
ably contained in the cumulative loss, Gp. We
define multiplicative re-weighting with BIC
scores as follows:
</bodyText>
<equation confidence="0.858052">
. (10)
</equation>
<bodyText confidence="0.99912575">
Model selection: We use stochastic or de-
terministic selection to choose the competitive
model for each instance. Deterministic choice
randomly selects among the maximum scor-
ing models with minimum translation length
whereas stochastic choice draws model p with
probability proportional to wp[n]. Random-
ization with the stochastic model selection
decreases expected mistake bounds in the
weighted majority algorithm (Littlestone and
Warmuth, 1992; Blum, 1996).
Auer et al. (2002) show that optimal fixed
learning rate for the weighted majority algo-
rithm is found as η[n] = V/m/G*[n] where
G*[n] = min1&lt;i&lt;m Gi[n], which requires prior
knowledge of the cumulative losses. We use
</bodyText>
<equation confidence="0.5262955">
�
η = m/(0.05n) for constant η.
</equation>
<sectionHeader confidence="0.988136" genericHeader="evaluation">
4 Experiments and Discussion
</sectionHeader>
<bodyText confidence="0.997892">
We perform experiments on the system com-
bination task for the English-German (en-
de), German-English (de-en), English-French
</bodyText>
<equation confidence="0.99742904">
e
wp[n + 1] = wp[n] x
−η lp[n]2
, (7)
m
wp[n + 1] = m wp[n] + e−η lp[n]
� (wk[n] + e−η lk[n]/
k=1
(8)
2BICp[n]
1
e−
�m
k=1
. (9)
wk[n] e−2BICk
1
�
k=1
−
e
wp[n + 1] = wp[n] x
2BICp
1
m
</equation>
<page confidence="0.992">
278
</page>
<bodyText confidence="0.999938636363636">
(en-�r), English-Spanish (en-es), and English-
Czech (en-cz) language pairs using the trans-
lation outputs for all the competing systems
provided in WMT10. We experiment in a sim-
ulated online learning setting where only the
scores obtained from the TRegMT system are
used during both tuning and testing. We do
not use reference translations in measuring in-
stance performance in this simulated setting
for the results we obtain be in line with sys-
tem combination challenge’s goals.
</bodyText>
<subsectionHeader confidence="0.917582">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.9999702">
We use the training set provided in WMT10 to
index and select transductive instances from.
The challenge split the test set for the transla-
tion task of 2489 sentences into a tuning set of
455 sentences and a test set with the remain-
ing 2034 sentences. Translation outputs for
each system is given in a separate file and the
number of system outputs per translation pair
varies. We have tokenized and lowercased each
of the system outputs and combined these in
a single N-best file per language pair. We use
BLEU (Papineni et al., 2001) and NIST (Dod-
dington, 2002) evaluation metrics for measur-
ing the performance of translations automati-
cally.
</bodyText>
<subsectionHeader confidence="0.994109">
4.2 Reranking Scores
</subsectionHeader>
<bodyText confidence="0.9998758">
The problem we are solving is online learn-
ing with prior information, which comes from
the comparative BLEU scores, LM scores, and
TRegMT scores at each step n. The scoring
functions are explained below:
</bodyText>
<listItem confidence="0.988309461538462">
1. TRegMT: Transductive regression based
machine translation scores as found by
Equation 2. We use the TRegMT scores
obtained by the FSR model.
2. CBLEU: Comparative BLEU scores we
obtain by measuring the average BLEU
performance of each translation relative
to the other systems’ translations in the
N-best list.
3. LM: We calculate 5-gram language model
scores for each translation using the lan-
guage model trained over the target cor-
pus provided in the translation task.
</listItem>
<bodyText confidence="0.998691739130435">
To make things simpler, we use a single prior
TRegMT system score linearly combining the
three scores mentioned with weights learned
on the tuning set. The overall TRegMT sys-
tem score for instance n, model i is referred as
TRegScorez[n].
Since we do not have access to the refer-
ence translations nor to the translation model
scores each system obtained for each sentence,
we estimate translation model performance by
measuring the average BLEU performance of
each translation relative to other translations
in the N-best list. Thus, each possible transla-
tion in the N-best list is BLEU scored against
other translations and the average of these
scores is selected as the CBLEU score for the
sentence. Sentence level BLEU score calcula-
tion avoids singularities in n-gram precisions
by taking the maximum of the match count
and 1
2|�� |for sz denoting the length of the
source sentence sz as used in (Macherey and
Och, 2007).
</bodyText>
<subsectionHeader confidence="0.976639">
4.3 Adaptive Model Weighting
</subsectionHeader>
<bodyText confidence="0.99996124137931">
We initialize model weights to 1/m for all
models, which are updated after each instance
according to the losses based on the TRegMT
model. Table 1 presents the performance
of the algorithms on the en-de development
set. We have measured their performances
with stochastic (stoc.) or deterministic (det.)
model selection when using only the weights or
mixture weights obtained when instance scores
are also considered. Mixture weights are ob-
tained as: wz[n] = wz[n] TRegScorez[n], for
instance n, model i.
Baseline performance obtained with random
selection has .1407 BLEU and 4.9832 NIST
scores. TRegMT model obtains a performance
of .1661 BLEU and 5.3283 NIST with rerank-
ing. The best model performance among the
12 en-de translation models has .1644 BLEU
and 5.2647 NIST scores. Therefore, by using
TRegMT score, we are able to achieve better
scores.
Not all of the settings are meaningful. For
instance, stochastic model selection is used for
algorithms having multiplicative weight up-
dates. This is reflected in the Table 1 by low
performance on the additive and BIC models.
Similarly, using mixture weights may not re-
sult in better scores for algorithms with multi-
plicative updates, which resulted in decreased
</bodyText>
<page confidence="0.994837">
279
</page>
<table confidence="0.999811166666667">
Additive Multiplicative BIC BIC Weighting
Setting BLEU NIST BLEU NIST BLEU NIST BLEU NIST
Stoc., W .1419 5.0016 ±.003 .1528 5.1710 ±.001 .1442 5.0468 .1568 ±.001 5.2052 ±.005
Stoc., M .1415 5.0001 .1525 5.1601 ±.001 .1459 5.0619 ±.004 .1566 ±.001 5.2030 ±.006
Det., W .1644 5.3208 .1638 5.2571 .1638 5.2542 .1646 5.2535
Det., M .1643 5.3173 .1536 5.1756 .1530 5.1871 .1507 5.1973
</table>
<tableCaption confidence="0.9894015">
Table 1: Performances of the algorithms on the development set over 100 repetitions. W:
Weights, M: Mixture.
</tableCaption>
<bodyText confidence="0.996913470588235">
performance in Table 1. Decreased perfor-
mance with BIC hints that we may use other
techniques for mixture weights.
Table 2 presents reranking results on all of
the language pairs we considered with the ran-
dom, TRegMT, and CSMT models. Random
model score lists the random model perfor-
mance selected among the competing trans-
lations randomly and it can be used as a
baseline. Best model score lists the perfor-
mance of the best model performance. CSMT
models are named with the weighting model
used (Add for additive, Mul for multiplicative,
BICW for BIC weighting), model selection
technique (S for stochastic, D for determinis-
tic), and mixtures model (W for using only
weights, M for using mixture weights) with
hyphens in between. Our challenge submis-
sion is given in the last row of Table 2 where
we used multiplicative exponential weight up-
dates, deterministic model selection, and only
the weights during model selection. For the
challenge results, we initialized the weights to
the weights obtained in the development set.
We have presented scores that are better
than or close to the best model in bold. We
observe that the additive model performs the
best by achieving the performance of the best
competing translation model and performing
better than the best in most of the language
pairs. For the en-de language pair, addi-
tive model score achieves even better than the
TRegMT model, which is used for evaluating
instance scores.
</bodyText>
<sectionHeader confidence="0.998279" genericHeader="conclusions">
5 Contributions
</sectionHeader>
<bodyText confidence="0.999849578947369">
We have analyzed adaptive model weighting
techniques for system combination when the
competing translators are statistical machine
translation models. We defined additive, mul-
tiplicative, and loss-based weight updates with
exponential loss functions for the competitive
statistical machine translation framework.
Competitive SMT via adaptive weighting of
various translators is shown to be a powerful
technique for sequential translation tasks. We
have demonstrated its use in the system com-
bination task by using the instance scores ob-
tained by the TRegMT model. Without any
pre-knowledge of the performance of the trans-
lation models, we have been able to achieve the
performance of the best model in all systems
and we are able to surpass its performance as
well as TRegMT&apos;s performance with the addi-
tive model.
</bodyText>
<sectionHeader confidence="0.994592" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999971833333333">
The research reported here was supported in
part by the Scientific and Technological Re-
search Council of Turkey (TUBITAK). The
first author would like to thank Deniz Yuret
for helpful discussions and for guidance and
support during the term of this research.
</bodyText>
<sectionHeader confidence="0.996932" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994786952380952">
Auer, Cesa-Bianchi, and Gentile. 2002. Adaptive
and self-confident on-line learning algorithms.
JCSS: Journal of Computer and System Sci-
ences, 64.
Ergun Bicici and Deniz Yuret. 2010. Ll regular-
ized regression for reranking and system combi-
nation in machine translation. In Proceedings of
the ACL 2010 Joint Fifth Workshop on Statis-
tical Machine Translation and Metrics MATR,
Uppsala, Sweden, July. Association for Compu-
tational Linguistics.
Avrim Blum and Yishay Mansour. 2007. Learn-
ing, regret minimization and equilibria. In
Noam Nisan, Tim Roughgarden, Eva Tar-
dos, and Vijay V. Vazirani, editors, Algorith-
mic Game Theory (Cambridge University Press,
2007).
Avrim Blum. 1996. On-line algorithms in machine
learning. In In Proceedings of the Workshop on
On-Line Algorithms, Dagstuhl, pages 306–325.
Springer.
</reference>
<page confidence="0.993876">
280
</page>
<table confidence="0.998501">
Model en -de de -en en -fr en -es en -cz
BLEU NIST BLEU NIST BLEU NIST BLEU NIST BLEU NIST
Random .1490 5.6555 .2088 6.4886 .2415 6.8948 .2648 7.2563 .1283 4.9238
Best model .1658 5.9610 .2408 6.9861 .2864 7.5272 .3047 7.7559 .1576 5.4480
TRegMT .1689 5.9638 .2357 6.9254 .2947 7.7107 .3049 7.8156 .1657 5.5632
Add-D-W .1697 5.9821 .2354 6.9175 .2948 7.7094 .3043 7.8093 .1642 5.5463
Add-D-M .1698 5.9824 .2353 6.9152 .2949 7.7103 .3044 7.8091 .1642 5.5461
Mul-S-W .1574 5.7564 .2161 6.5950 .2805 7.4599 .2961 .7.6870 .1572 5.4394
Mul-D-W .1618 5.8912 .2408 6.9854 .2847 7.5085 .2785 7.4133 .1612 5.5119
BIC-D-W .1614 5.8852 .2408 6.9853 .2842 7.5022 .2785 7.4132 .1623 5.5236
BIC-D-M .1580 5.7614 .2141 6.5597 .2791 7.4309 .2876 7.5138 .1577 5.4488
BICW-S-W .1621 5.8795 .2274 6.8142 .2802 7.4873 .2892 7.5569 .1565 5.4126
BICW-S-M .1618 5.8730 .2196 6.6493 .2806 7.4948 .2849 7.4845 .1561 5.4099
BICW-D-W .1648 5.9298 .2355 6.9112 .2807 7.4648 .2785 7.4134 .1534 5.3458
Challenge .1567 5.73 .2394 6.9627 .2758 7.4333 .3047 7.7559 .1641 5.5435
</table>
<tableCaption confidence="0.9862635">
Table 2: CSMT results where bold corresponds to scores better than or close to the best model.
Underlined scores are better than both the TregMT model and the best model.
</tableCaption>
<reference confidence="0.999720352941177">
George Doddington. 2002. Automatic evaluation
of machine translation quality using n-gram co-
occurrence statistics. In Human Language Tech-
nology Research, pages 138–145.
Trevor Hastie, Jonathan Taylor, Robert Tibshi-
rani, and Guenther Walther. 2006. Forward
stagewise regression and the monotone lasso.
Electronic Journal of Statistics, 1.
Trevor Hastie, Robert Tibshirani, and Jerome
Friedman. 2009. The Elements of Statistical
Learning: Data Mining, Inference and Predic-
tion. Springer-Verlag, 2nd edition.
S.S. Kozat and A.C. Singer. 2002. Further re-
sults in multistage adaptive filtering. ICASSP,
2:1329–1332.
Nick Littlestone and Manfred K. Warmuth. 1992.
The Weighted Majority Algorithm. Technical
Report UCSC-CRL-91-28, University of Califor-
nia, Santa Cruz, Jack Baskin School of Engi-
neering, October 26,.
Wolfgang Macherey and Franz J. Och. 2007. An
empirical study on computing consensus transla-
tions from multiple machine translation systems.
In EMNLP-CoNLL, pages 986–995.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2001. Bleu: a method for au-
tomatic evaluation of machine translation. In
ACL, pages 311–318. ACL.
J. Shawe Taylor and N. Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge
University Press.
Robert J. Tibshirani. 1996. Regression shrinkage
and selection via the lasso. Journal of the Royal
Statistical Society, Series B, 58(1):267–288.
</reference>
<page confidence="0.997915">
281
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.201066">
<title confidence="0.9982925">Adaptive Model Weighting and Transductive Regression Predicting Best System Combinations</title>
<author confidence="0.587292">Ergun</author>
<address confidence="0.8268965">KoC 34450 Sariyer, Istanbul,</address>
<email confidence="0.992379">ebicici@ku.edu.tr</email>
<author confidence="0.898831">S Serdar</author>
<address confidence="0.8473735">KoC 34450 Sariyer, Istanbul,</address>
<email confidence="0.997908">skozat@ku.edu.tr</email>
<abstract confidence="0.999649">We analyze adaptive model weighting techniques for reranking using inscores obtained by regularized transductive regression. Competitive statistical machine translation is an on-line learning technique for sequential translation tasks where we try to select the best among competing statistical machine translators. The competitive predictor assigns a probability per model weighted by the sequential performance. We define additive, multiplicative, and lossbased weight updates with exponential loss functions for competitive statistical machine translation. Without any pre-knowledge of the performance of the translation models, we succeed in achieving the performance of the best model in all systems and surpass their performance in most of the language pairs we considered.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cesa-Bianchi Auer</author>
<author>Gentile</author>
</authors>
<title>Adaptive and self-confident on-line learning algorithms.</title>
<date>2002</date>
<journal>JCSS: Journal of Computer and System Sciences,</journal>
<volume>64</volume>
<marker>Auer, Gentile, 2002</marker>
<rawString>Auer, Cesa-Bianchi, and Gentile. 2002. Adaptive and self-confident on-line learning algorithms. JCSS: Journal of Computer and System Sciences, 64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ergun Bicici</author>
<author>Deniz Yuret</author>
</authors>
<title>Ll regularized regression for reranking and system combination in machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="5028" citStr="Bicici and Yuret, 2010" startWordPosition="814" endWordPosition="817">ng: HL2 is not a sparse solution as most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL, = arg min kMY −HMX k2F +AkHk1 .(3) HERNY xNX Equation 3 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is defined as kHk1= Ei,j |Hi,j|. We use forward stagewise regression (FSR) (Hastie et al., 2006) and quadratic programming (QP) to find HL,. The details of the TRegMT model can be read in a separate submission to the translation task (Bicici and Yuret, 2010). 3 Competitive Statistical Machine Translation We develop the Competitive Statistical Machine Translation (CSMT) framework for sequential translation tasks when the competing models are statistical machine translators. CSMT uses the output of different translation models to achieve a translation performance that surpasses the translation performance of all of the component models or achieves the performance of the best. CSMT uses online learning to update the weights used for estimating the best performing translation model. Competitive predictor assigns a weight per model estimated by their </context>
</contexts>
<marker>Bicici, Yuret, 2010</marker>
<rawString>Ergun Bicici and Deniz Yuret. 2010. Ll regularized regression for reranking and system combination in machine translation. In Proceedings of the ACL 2010 Joint Fifth Workshop on Statistical Machine Translation and Metrics MATR, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Yishay Mansour</author>
</authors>
<title>Learning, regret minimization and equilibria.</title>
<date>2007</date>
<booktitle>Algorithmic Game Theory</booktitle>
<editor>In Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="6200" citStr="Blum and Mansour, 2007" startWordPosition="1002" endWordPosition="1005">ctor assigns a weight per model estimated by their sequential performance. At each step, m component translation models are executed in parallel over the input source sentence sequence and the loss lp[n] of model p at observation n is calculated by comparing the desired data y[n] with the output of model p, yp[n]. CSMT model selects a model based on the weights and the performance of the selected model as well as the remaining models to adaptively update the weights given for each model. This corresponds to learning in full information setting where we have access to the loss for each action (Blum and Mansour, 2007). CSMT learning involves two main steps: estimation and weight update: yc[n] = E(w[n], x[n]), (estimation) lp[n] = y[n] − yp[n], (instance loss) Lp[n] = n i=1 lp[a]2, (cumulative loss) w[n + 1] = U(w[n], yc[n],L[n]), (update) (4) where w[n] = (w1[n], ... , wm[n]) for m models, Lp is the cumulative squared loss of model p, L[n] stores cumulative and instance losses, and yc[n] is the competitive model estimated for instance n. The learning problem is finding an adaptive w that minimizes the cumulative squared error with appropriate estimation and update methods. Related Work: Multistage adaptive</context>
</contexts>
<marker>Blum, Mansour, 2007</marker>
<rawString>Avrim Blum and Yishay Mansour. 2007. Learning, regret minimization and equilibria. In Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani, editors, Algorithmic Game Theory (Cambridge University Press, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
</authors>
<title>On-line algorithms in machine learning. In</title>
<date>1996</date>
<booktitle>In Proceedings of the Workshop on On-Line Algorithms, Dagstuhl,</booktitle>
<pages>306--325</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="10130" citStr="Blum, 1996" startWordPosition="1641" endWordPosition="1642"> weights, whose information is presumably contained in the cumulative loss, Gp. We define multiplicative re-weighting with BIC scores as follows: . (10) Model selection: We use stochastic or deterministic selection to choose the competitive model for each instance. Deterministic choice randomly selects among the maximum scoring models with minimum translation length whereas stochastic choice draws model p with probability proportional to wp[n]. Randomization with the stochastic model selection decreases expected mistake bounds in the weighted majority algorithm (Littlestone and Warmuth, 1992; Blum, 1996). Auer et al. (2002) show that optimal fixed learning rate for the weighted majority algorithm is found as η[n] = V/m/G*[n] where G*[n] = min1&lt;i&lt;m Gi[n], which requires prior knowledge of the cumulative losses. We use � η = m/(0.05n) for constant η. 4 Experiments and Discussion We perform experiments on the system combination task for the English-German (ende), German-English (de-en), English-French e wp[n + 1] = wp[n] x −η lp[n]2 , (7) m wp[n + 1] = m wp[n] + e−η lp[n] � (wk[n] + e−η lk[n]/ k=1 (8) 2BICp[n] 1 e− �m k=1 . (9) wk[n] e−2BICk 1 � k=1 − e wp[n + 1] = wp[n] x 2BICp 1 m 278 (en-�r),</context>
</contexts>
<marker>Blum, 1996</marker>
<rawString>Avrim Blum. 1996. On-line algorithms in machine learning. In In Proceedings of the Workshop on On-Line Algorithms, Dagstuhl, pages 306–325. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Human Language Technology Research,</booktitle>
<pages>138--145</pages>
<contexts>
<context position="11776" citStr="Doddington, 2002" startWordPosition="1935" endWordPosition="1937">th system combination challenge’s goals. 4.1 Datasets We use the training set provided in WMT10 to index and select transductive instances from. The challenge split the test set for the translation task of 2489 sentences into a tuning set of 455 sentences and a test set with the remaining 2034 sentences. Translation outputs for each system is given in a separate file and the number of system outputs per translation pair varies. We have tokenized and lowercased each of the system outputs and combined these in a single N-best file per language pair. We use BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) evaluation metrics for measuring the performance of translations automatically. 4.2 Reranking Scores The problem we are solving is online learning with prior information, which comes from the comparative BLEU scores, LM scores, and TRegMT scores at each step n. The scoring functions are explained below: 1. TRegMT: Transductive regression based machine translation scores as found by Equation 2. We use the TRegMT scores obtained by the FSR model. 2. CBLEU: Comparative BLEU scores we obtain by measuring the average BLEU performance of each translation relative to the other systems’ translations </context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Human Language Technology Research, pages 138–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Jonathan Taylor</author>
<author>Robert Tibshirani</author>
<author>Guenther Walther</author>
</authors>
<title>Forward stagewise regression and the monotone lasso.</title>
<date>2006</date>
<journal>Electronic Journal of Statistics,</journal>
<volume>1</volume>
<contexts>
<context position="4866" citStr="Hastie et al., 2006" startWordPosition="786" endWordPosition="789">e n-spectrum weighted word feature mappers (Taylor and Cristianini, 2004) which consider all word sequences up to order n. L1 Regularized Regression for Learning: HL2 is not a sparse solution as most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL, = arg min kMY −HMX k2F +AkHk1 .(3) HERNY xNX Equation 3 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is defined as kHk1= Ei,j |Hi,j|. We use forward stagewise regression (FSR) (Hastie et al., 2006) and quadratic programming (QP) to find HL,. The details of the TRegMT model can be read in a separate submission to the translation task (Bicici and Yuret, 2010). 3 Competitive Statistical Machine Translation We develop the Competitive Statistical Machine Translation (CSMT) framework for sequential translation tasks when the competing models are statistical machine translators. CSMT uses the output of different translation models to achieve a translation performance that surpasses the translation performance of all of the component models or achieves the performance of the best. CSMT uses onl</context>
</contexts>
<marker>Hastie, Taylor, Tibshirani, Walther, 2006</marker>
<rawString>Trevor Hastie, Jonathan Taylor, Robert Tibshirani, and Guenther Walther. 2006. Forward stagewise regression and the monotone lasso. Electronic Journal of Statistics, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Robert Tibshirani</author>
<author>Jerome Friedman</author>
</authors>
<date>2009</date>
<booktitle>The Elements of Statistical Learning: Data Mining, Inference and Prediction.</booktitle>
<publisher>Springer-Verlag,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="8963" citStr="Hastie et al., 2009" startWordPosition="1451" endWordPosition="1454">. Perceptrons, gradient descent, and WidrowHuff learning have additive weight updates. We define the multiplicative exponential weight update as follows: � wk[n] e−η lk[n]2 k=1 where we use the squared instance loss. Equation 7 is similar to the update of Weighted Majority Algorithm (Littlestone and Warmuth, 1992) where the weights of the models that make a mistake are multiplied by a fixed β such that 0 &lt; β &lt; 1. We use Bayesian Information Criterion (BIC) as a loss based re-weighting technique. Assuming that instance losses are normally distributed with variance σ2, BIC score is obtained as (Hastie et al., 2009): Gp[n] BICp[n] = σ2 + dp log(n), where σ2 is estimated by the average of model sample variances of squared instance loss and dp is the number of parameters used in model p which we assume to be the same for all models; therefore we can discard the second term. The model with the minimum BIC value becomes the one with the highest posterior probability where the posterior probability of model p can be estimated as (Hastie et al., 2009): e wp[n + 1] = 2BICk[n] 1 The posterior probabilities become model weights and we basically forget about the previous weights, whose information is presumably co</context>
</contexts>
<marker>Hastie, Tibshirani, Friedman, 2009</marker>
<rawString>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference and Prediction. Springer-Verlag, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Kozat</author>
<author>A C Singer</author>
</authors>
<title>Further results in multistage adaptive filtering.</title>
<date>2002</date>
<journal>ICASSP,</journal>
<pages>2--1329</pages>
<contexts>
<context position="6835" citStr="Kozat and Singer, 2002" startWordPosition="1105" endWordPosition="1108">ing involves two main steps: estimation and weight update: yc[n] = E(w[n], x[n]), (estimation) lp[n] = y[n] − yp[n], (instance loss) Lp[n] = n i=1 lp[a]2, (cumulative loss) w[n + 1] = U(w[n], yc[n],L[n]), (update) (4) where w[n] = (w1[n], ... , wm[n]) for m models, Lp is the cumulative squared loss of model p, L[n] stores cumulative and instance losses, and yc[n] is the competitive model estimated for instance n. The learning problem is finding an adaptive w that minimizes the cumulative squared error with appropriate estimation and update methods. Related Work: Multistage adaptive filtering (Kozat and Singer, 2002) combines the output of multiple adaptive filters to outperform the best among them where the first stage executes models in parallel and the second stage updates parameters using the performance of the combined prediction, yc[n]. Macherey and Och (2007) investigate different approaches for system combination including candidate selection that maximize a weighted combination of BLEU scores among different system outputs. Their system uses a fixed weight vector trained on the development set 277 to be multiplied with instance BLEU scores. 3.1 Estimating the Best Performing Translation Model We </context>
</contexts>
<marker>Kozat, Singer, 2002</marker>
<rawString>S.S. Kozat and A.C. Singer. 2002. Further results in multistage adaptive filtering. ICASSP, 2:1329–1332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Littlestone</author>
<author>Manfred K Warmuth</author>
</authors>
<title>The Weighted Majority Algorithm.</title>
<date>1992</date>
<tech>Technical Report UCSC-CRL-91-28,</tech>
<institution>University of California, Santa Cruz, Jack Baskin School of Engineering,</institution>
<contexts>
<context position="8658" citStr="Littlestone and Warmuth, 1992" startWordPosition="1396" endWordPosition="1399">losses based on the outputs of the m different translation models. We define the additive exponential weight update as follows: , (6) where η &gt; 0 is the learning rate and the denominator is used for normalization. The update amount, e−η lp[n] is 1 when lp[n] = 0 and it approaches zero with increasing instance loss. Perceptrons, gradient descent, and WidrowHuff learning have additive weight updates. We define the multiplicative exponential weight update as follows: � wk[n] e−η lk[n]2 k=1 where we use the squared instance loss. Equation 7 is similar to the update of Weighted Majority Algorithm (Littlestone and Warmuth, 1992) where the weights of the models that make a mistake are multiplied by a fixed β such that 0 &lt; β &lt; 1. We use Bayesian Information Criterion (BIC) as a loss based re-weighting technique. Assuming that instance losses are normally distributed with variance σ2, BIC score is obtained as (Hastie et al., 2009): Gp[n] BICp[n] = σ2 + dp log(n), where σ2 is estimated by the average of model sample variances of squared instance loss and dp is the number of parameters used in model p which we assume to be the same for all models; therefore we can discard the second term. The model with the minimum BIC va</context>
<context position="10117" citStr="Littlestone and Warmuth, 1992" startWordPosition="1637" endWordPosition="1640">cally forget about the previous weights, whose information is presumably contained in the cumulative loss, Gp. We define multiplicative re-weighting with BIC scores as follows: . (10) Model selection: We use stochastic or deterministic selection to choose the competitive model for each instance. Deterministic choice randomly selects among the maximum scoring models with minimum translation length whereas stochastic choice draws model p with probability proportional to wp[n]. Randomization with the stochastic model selection decreases expected mistake bounds in the weighted majority algorithm (Littlestone and Warmuth, 1992; Blum, 1996). Auer et al. (2002) show that optimal fixed learning rate for the weighted majority algorithm is found as η[n] = V/m/G*[n] where G*[n] = min1&lt;i&lt;m Gi[n], which requires prior knowledge of the cumulative losses. We use � η = m/(0.05n) for constant η. 4 Experiments and Discussion We perform experiments on the system combination task for the English-German (ende), German-English (de-en), English-French e wp[n + 1] = wp[n] x −η lp[n]2 , (7) m wp[n + 1] = m wp[n] + e−η lp[n] � (wk[n] + e−η lk[n]/ k=1 (8) 2BICp[n] 1 e− �m k=1 . (9) wk[n] e−2BICk 1 � k=1 − e wp[n + 1] = wp[n] x 2BICp 1 m</context>
</contexts>
<marker>Littlestone, Warmuth, 1992</marker>
<rawString>Nick Littlestone and Manfred K. Warmuth. 1992. The Weighted Majority Algorithm. Technical Report UCSC-CRL-91-28, University of California, Santa Cruz, Jack Baskin School of Engineering, October 26,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz J Och</author>
</authors>
<title>An empirical study on computing consensus translations from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>986--995</pages>
<contexts>
<context position="7089" citStr="Macherey and Och (2007)" startWordPosition="1147" endWordPosition="1150">r m models, Lp is the cumulative squared loss of model p, L[n] stores cumulative and instance losses, and yc[n] is the competitive model estimated for instance n. The learning problem is finding an adaptive w that minimizes the cumulative squared error with appropriate estimation and update methods. Related Work: Multistage adaptive filtering (Kozat and Singer, 2002) combines the output of multiple adaptive filters to outperform the best among them where the first stage executes models in parallel and the second stage updates parameters using the performance of the combined prediction, yc[n]. Macherey and Och (2007) investigate different approaches for system combination including candidate selection that maximize a weighted combination of BLEU scores among different system outputs. Their system uses a fixed weight vector trained on the development set 277 to be multiplied with instance BLEU scores. 3.1 Estimating the Best Performing Translation Model We use additive, multiplicative, or loss based updates to estimate model weights. We measure instance loss with trLoss(y[i], yp[i]), which is a function that returns the translation performance of the output translation of model p with respect to the refere</context>
<context position="13478" citStr="Macherey and Och, 2007" startWordPosition="2212" endWordPosition="2215"> to the translation model scores each system obtained for each sentence, we estimate translation model performance by measuring the average BLEU performance of each translation relative to other translations in the N-best list. Thus, each possible translation in the N-best list is BLEU scored against other translations and the average of these scores is selected as the CBLEU score for the sentence. Sentence level BLEU score calculation avoids singularities in n-gram precisions by taking the maximum of the match count and 1 2|�� |for sz denoting the length of the source sentence sz as used in (Macherey and Och, 2007). 4.3 Adaptive Model Weighting We initialize model weights to 1/m for all models, which are updated after each instance according to the losses based on the TRegMT model. Table 1 presents the performance of the algorithms on the en-de development set. We have measured their performances with stochastic (stoc.) or deterministic (det.) model selection when using only the weights or mixture weights obtained when instance scores are also considered. Mixture weights are obtained as: wz[n] = wz[n] TRegScorez[n], for instance n, model i. Baseline performance obtained with random selection has .1407 B</context>
</contexts>
<marker>Macherey, Och, 2007</marker>
<rawString>Wolfgang Macherey and Franz J. Och. 2007. An empirical study on computing consensus translations from multiple machine translation systems. In EMNLP-CoNLL, pages 986–995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In ACL,</booktitle>
<pages>311--318</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7750" citStr="Papineni et al., 2001" startWordPosition="1246" endWordPosition="1249">ystem combination including candidate selection that maximize a weighted combination of BLEU scores among different system outputs. Their system uses a fixed weight vector trained on the development set 277 to be multiplied with instance BLEU scores. 3.1 Estimating the Best Performing Translation Model We use additive, multiplicative, or loss based updates to estimate model weights. We measure instance loss with trLoss(y[i], yp[i]), which is a function that returns the translation performance of the output translation of model p with respect to the reference translation at instance i. 1-BLEU (Papineni et al., 2001) is one such function with outputs in the range [0, 1]. Cumulative squared loss of the p-th translation model is defined as: n Gp[n] = trLoss(y[i], yp[i])2. (5) i=1 We use exponentially re-weighted prediction to estimate model performances, which uses exponentially re-weighted losses based on the outputs of the m different translation models. We define the additive exponential weight update as follows: , (6) where η &gt; 0 is the learning rate and the denominator is used for normalization. The update amount, e−η lp[n] is 1 when lp[n] = 0 and it approaches zero with increasing instance loss. Perce</context>
<context position="11748" citStr="Papineni et al., 2001" startWordPosition="1929" endWordPosition="1932">e results we obtain be in line with system combination challenge’s goals. 4.1 Datasets We use the training set provided in WMT10 to index and select transductive instances from. The challenge split the test set for the translation task of 2489 sentences into a tuning set of 455 sentences and a test set with the remaining 2034 sentences. Translation outputs for each system is given in a separate file and the number of system outputs per translation pair varies. We have tokenized and lowercased each of the system outputs and combined these in a single N-best file per language pair. We use BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) evaluation metrics for measuring the performance of translations automatically. 4.2 Reranking Scores The problem we are solving is online learning with prior information, which comes from the comparative BLEU scores, LM scores, and TRegMT scores at each step n. The scoring functions are explained below: 1. TRegMT: Transductive regression based machine translation scores as found by Equation 2. We use the TRegMT scores obtained by the FSR model. 2. CBLEU: Comparative BLEU scores we obtain by measuring the average BLEU performance of each translation relative to the </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. In ACL, pages 311–318. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Shawe Taylor</author>
<author>N Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4319" citStr="Taylor and Cristianini, 2004" startWordPosition="696" endWordPosition="699">using L2 regularization is found as: HL2 = arg min kMY −HMX k2F +AkHk2F . (1) HERNY xNX Two main challenges of the regression based machine translation (RegMT) approach are learning the regression function, g : X* → FY , and solving the pre-image problem, which, given the features of the estimated target string sequence, g(x) = -bY (y), attempts to find y ∈ Y *: f(x) = arg minyEY * ||g(x) − .bY (y)||2. Pre-image calculation involves a search over possible translations minimizing the cost function: f(x) = arg min yEY * k-bY (y) − H-bX(x)k2 . (2) We use n-spectrum weighted word feature mappers (Taylor and Cristianini, 2004) which consider all word sequences up to order n. L1 Regularized Regression for Learning: HL2 is not a sparse solution as most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL, = arg min kMY −HMX k2F +AkHk1 .(3) HERNY xNX Equation 3 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is defined as kHk1= Ei,j |Hi,j|. We use forward stagewise regression (FSR) (Hastie et al., 2006) and quadratic programming (QP) to find HL,. The deta</context>
</contexts>
<marker>Taylor, Cristianini, 2004</marker>
<rawString>J. Shawe Taylor and N. Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J Tibshirani</author>
</authors>
<title>Regression shrinkage and selection via the lasso.</title>
<date>1996</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>58</volume>
<issue>1</issue>
<contexts>
<context position="4730" citStr="Tibshirani, 1996" startWordPosition="766" endWordPosition="767">tion involves a search over possible translations minimizing the cost function: f(x) = arg min yEY * k-bY (y) − H-bX(x)k2 . (2) We use n-spectrum weighted word feature mappers (Taylor and Cristianini, 2004) which consider all word sequences up to order n. L1 Regularized Regression for Learning: HL2 is not a sparse solution as most of the coefficients remain non-zero. L1 norm behaves both as a feature selection technique and a method for reducing coefficient values. HL, = arg min kMY −HMX k2F +AkHk1 .(3) HERNY xNX Equation 3 presents the lasso (least absolute shrinkage and selection operator) (Tibshirani, 1996) solution where the regularization term is defined as kHk1= Ei,j |Hi,j|. We use forward stagewise regression (FSR) (Hastie et al., 2006) and quadratic programming (QP) to find HL,. The details of the TRegMT model can be read in a separate submission to the translation task (Bicici and Yuret, 2010). 3 Competitive Statistical Machine Translation We develop the Competitive Statistical Machine Translation (CSMT) framework for sequential translation tasks when the competing models are statistical machine translators. CSMT uses the output of different translation models to achieve a translation perf</context>
</contexts>
<marker>Tibshirani, 1996</marker>
<rawString>Robert J. Tibshirani. 1996. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B, 58(1):267–288.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>