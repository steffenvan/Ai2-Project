<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.497675">
<title confidence="0.991285">
Modeling word learning as communicative inference
</title>
<author confidence="0.998328">
Michael C. Frank
</author>
<affiliation confidence="0.998552">
Department of Brain and Cognitive Sciences
Massachusetts Institute of Technology
</affiliation>
<address confidence="0.952138">
Cambridge, MA 02139
</address>
<email confidence="0.999605">
mcfrank@mit.edu
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9989095">
How do children learn their first words? I
describe a model that makes joint inferences
about what speakers are trying to talk about
and the meanings of the words they use. This
model provides a principled framework for in-
tegrating a wide variety of non-linguistic in-
formation sources into the process of word
learning.
</bodyText>
<subsectionHeader confidence="0.896946">
Talk Pr´ecis
</subsectionHeader>
<bodyText confidence="0.999982513513514">
How do children learn their first words? Much
work in this field has focused on the social as-
pects of word learning: that children make use of
speakers’ intentions—as signaled by a wide range
of non-linguistic cues such as their eye-gaze, what
they are pointing at, or even what referents are new
to them—to infer the meanings of words (Bloom,
2002). However, recent evidence has suggested that
adults and children are able to learn words simply
from the consistent co-occurrence of words and their
referents, even across otherwise ambiguous situa-
tions and without explicit social cues as to which ref-
erent is being talked about (Yu &amp; Smith 2007; Smith
&amp; Yu, 2008).
In this talk I describe work aiming to combine
these two sets of evidence within a single probab-
listic framework (Frank, Goodman, &amp; Tenenbaum,
2009). We propose a model in which learners at-
tempt to infer speakers’ moment-to-moment com-
municative intentions jointly with the meanings of
the words they have used to express these intentions.
This process of joint inference allows our model to
explain away two major sources of noise in sim-
pler statistical word learning proposals: the fact that
speakers do not talk about every referent and that not
all words that speakers utter are referential.
We find that our model outperforms associative
models in learning words accurately from natural
corpus data and is able to fit children’s behavior in
a number of experimental results from developmen-
tal psychology. In addition, we have used this basic
framework to begin investigating how learners use
the rich variety of non-linguistic information signal-
ing speakers’ intentions in service of word learning.
As an example of this work, I will describe an ex-
tension of the model to use discourse continuity as a
cue for speakers’ intentions.
</bodyText>
<sectionHeader confidence="0.987453" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.983917666666667">
This work supported by a Jacob Javits Graduate Fel-
lowship and NSF Doctoral Dissertation Research
Improvement Grant #0746251.
</bodyText>
<sectionHeader confidence="0.998604" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.947072266666667">
Paul Bloom. 2002. How Children Learn the Meanings of
Words. Cambridge, MA: MIT Press.
Michael C. Frank, Noah D. Goodman, and Joshua B.
Tenenbaum. 2009. Using speakers’ referential inten-
tions to model early cross-situational word learning.
Psychological Science.
Linda Smith and Chen Yu. 2008. Infants rapidly learn
word-referent mappings via cross-situational statistics.
Cognition, 106, 1558-1568.
Chen Yu and Linda Smith. 2007. Rapid word learning
under uncertainty via cross-situational statistics. Psy-
chological Science, 18, 414-420.
2
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), page 2,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.285093">
<title confidence="0.999755">Modeling word learning as communicative inference</title>
<author confidence="0.999985">C Michael</author>
<affiliation confidence="0.9979825">Department of Brain and Cognitive Massachusetts Institute of</affiliation>
<address confidence="0.91182">Cambridge, MA</address>
<email confidence="0.999497">mcfrank@mit.edu</email>
<abstract confidence="0.998993170212766">How do children learn their first words? I describe a model that makes joint inferences about what speakers are trying to talk about and the meanings of the words they use. This model provides a principled framework for integrating a wide variety of non-linguistic information sources into the process of word learning. Talk Pr´ecis How do children learn their first words? Much work in this field has focused on the social aspects of word learning: that children make use of speakers’ intentions—as signaled by a wide range of non-linguistic cues such as their eye-gaze, what they are pointing at, or even what referents are new to them—to infer the meanings of words (Bloom, 2002). However, recent evidence has suggested that adults and children are able to learn words simply from the consistent co-occurrence of words and their referents, even across otherwise ambiguous situations and without explicit social cues as to which referent is being talked about (Yu &amp; Smith 2007; Smith &amp; Yu, 2008). In this talk I describe work aiming to combine these two sets of evidence within a single probablistic framework (Frank, Goodman, &amp; Tenenbaum, 2009). We propose a model in which learners attempt to infer speakers’ moment-to-moment communicative intentions jointly with the meanings of the words they have used to express these intentions. This process of joint inference allows our model to explain away two major sources of noise in simpler statistical word learning proposals: the fact that speakers do not talk about every referent and that not all words that speakers utter are referential. We find that our model outperforms associative models in learning words accurately from natural corpus data and is able to fit children’s behavior in a number of experimental results from developmental psychology. In addition, we have used this basic framework to begin investigating how learners use the rich variety of non-linguistic information signaling speakers’ intentions in service of word learning. As an example of this work, I will describe an extension of the model to use discourse continuity as a cue for speakers’ intentions.</abstract>
<note confidence="0.868562157894737">Acknowledgments This work supported by a Jacob Javits Graduate Fellowship and NSF Doctoral Dissertation Research Improvement Grant #0746251. References Bloom. 2002. Children Learn the Meanings of Cambridge, MA: MIT Press. Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum. 2009. Using speakers’ referential intentions to model early cross-situational word learning. Linda Smith and Chen Yu. 2008. Infants rapidly learn word-referent mappings via cross-situational statistics. 106, 1558-1568. Chen Yu and Linda Smith. 2007. Rapid word learning uncertainty via cross-situational statistics. Psy- 18, 414-420. 2 of the Thirteenth Conference on Computational Natural Language Learning page 2, Colorado, June 2009. Association for Computational Linguistics</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Paul Bloom</author>
</authors>
<title>How Children Learn the Meanings of Words.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="875" citStr="Bloom, 2002" startWordPosition="139" endWordPosition="140"> joint inferences about what speakers are trying to talk about and the meanings of the words they use. This model provides a principled framework for integrating a wide variety of non-linguistic information sources into the process of word learning. Talk Pr´ecis How do children learn their first words? Much work in this field has focused on the social aspects of word learning: that children make use of speakers’ intentions—as signaled by a wide range of non-linguistic cues such as their eye-gaze, what they are pointing at, or even what referents are new to them—to infer the meanings of words (Bloom, 2002). However, recent evidence has suggested that adults and children are able to learn words simply from the consistent co-occurrence of words and their referents, even across otherwise ambiguous situations and without explicit social cues as to which referent is being talked about (Yu &amp; Smith 2007; Smith &amp; Yu, 2008). In this talk I describe work aiming to combine these two sets of evidence within a single probablistic framework (Frank, Goodman, &amp; Tenenbaum, 2009). We propose a model in which learners attempt to infer speakers’ moment-to-moment communicative intentions jointly with the meanings o</context>
</contexts>
<marker>Bloom, 2002</marker>
<rawString>Paul Bloom. 2002. How Children Learn the Meanings of Words. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Frank</author>
<author>Noah D Goodman</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Using speakers’ referential intentions to model early cross-situational word learning.</title>
<date>2009</date>
<publisher>Psychological Science.</publisher>
<contexts>
<context position="1339" citStr="Frank, Goodman, &amp; Tenenbaum, 2009" startWordPosition="213" endWordPosition="217"> wide range of non-linguistic cues such as their eye-gaze, what they are pointing at, or even what referents are new to them—to infer the meanings of words (Bloom, 2002). However, recent evidence has suggested that adults and children are able to learn words simply from the consistent co-occurrence of words and their referents, even across otherwise ambiguous situations and without explicit social cues as to which referent is being talked about (Yu &amp; Smith 2007; Smith &amp; Yu, 2008). In this talk I describe work aiming to combine these two sets of evidence within a single probablistic framework (Frank, Goodman, &amp; Tenenbaum, 2009). We propose a model in which learners attempt to infer speakers’ moment-to-moment communicative intentions jointly with the meanings of the words they have used to express these intentions. This process of joint inference allows our model to explain away two major sources of noise in simpler statistical word learning proposals: the fact that speakers do not talk about every referent and that not all words that speakers utter are referential. We find that our model outperforms associative models in learning words accurately from natural corpus data and is able to fit children’s behavior in a </context>
</contexts>
<marker>Frank, Goodman, Tenenbaum, 2009</marker>
<rawString>Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum. 2009. Using speakers’ referential intentions to model early cross-situational word learning. Psychological Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda Smith</author>
<author>Chen Yu</author>
</authors>
<title>Infants rapidly learn word-referent mappings via cross-situational statistics.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>106</volume>
<pages>1558--1568</pages>
<contexts>
<context position="1190" citStr="Smith &amp; Yu, 2008" startWordPosition="189" endWordPosition="192">ork in this field has focused on the social aspects of word learning: that children make use of speakers’ intentions—as signaled by a wide range of non-linguistic cues such as their eye-gaze, what they are pointing at, or even what referents are new to them—to infer the meanings of words (Bloom, 2002). However, recent evidence has suggested that adults and children are able to learn words simply from the consistent co-occurrence of words and their referents, even across otherwise ambiguous situations and without explicit social cues as to which referent is being talked about (Yu &amp; Smith 2007; Smith &amp; Yu, 2008). In this talk I describe work aiming to combine these two sets of evidence within a single probablistic framework (Frank, Goodman, &amp; Tenenbaum, 2009). We propose a model in which learners attempt to infer speakers’ moment-to-moment communicative intentions jointly with the meanings of the words they have used to express these intentions. This process of joint inference allows our model to explain away two major sources of noise in simpler statistical word learning proposals: the fact that speakers do not talk about every referent and that not all words that speakers utter are referential. We </context>
</contexts>
<marker>Smith, Yu, 2008</marker>
<rawString>Linda Smith and Chen Yu. 2008. Infants rapidly learn word-referent mappings via cross-situational statistics. Cognition, 106, 1558-1568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Linda Smith</author>
</authors>
<title>Rapid word learning under uncertainty via cross-situational statistics.</title>
<date>2007</date>
<journal>Psychological Science,</journal>
<booktitle>Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<volume>18</volume>
<pages>414--420</pages>
<contexts>
<context position="1171" citStr="Yu &amp; Smith 2007" startWordPosition="185" endWordPosition="188">rst words? Much work in this field has focused on the social aspects of word learning: that children make use of speakers’ intentions—as signaled by a wide range of non-linguistic cues such as their eye-gaze, what they are pointing at, or even what referents are new to them—to infer the meanings of words (Bloom, 2002). However, recent evidence has suggested that adults and children are able to learn words simply from the consistent co-occurrence of words and their referents, even across otherwise ambiguous situations and without explicit social cues as to which referent is being talked about (Yu &amp; Smith 2007; Smith &amp; Yu, 2008). In this talk I describe work aiming to combine these two sets of evidence within a single probablistic framework (Frank, Goodman, &amp; Tenenbaum, 2009). We propose a model in which learners attempt to infer speakers’ moment-to-moment communicative intentions jointly with the meanings of the words they have used to express these intentions. This process of joint inference allows our model to explain away two major sources of noise in simpler statistical word learning proposals: the fact that speakers do not talk about every referent and that not all words that speakers utter a</context>
</contexts>
<marker>Yu, Smith, 2007</marker>
<rawString>Chen Yu and Linda Smith. 2007. Rapid word learning under uncertainty via cross-situational statistics. Psychological Science, 18, 414-420. Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), page 2,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colorado Boulder</author>
</authors>
<date>2009</date>
<booktitle>c�2009 Association for Computational Linguistics</booktitle>
<marker>Boulder, 2009</marker>
<rawString>Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>