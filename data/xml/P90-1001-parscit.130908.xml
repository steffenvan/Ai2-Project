<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.9319245">
POLYNOMIAL TIME PARSING OF COMBINATORY CATEGORIAL
GRAMMARS*
</note>
<author confidence="0.614941">
K. Vijay-Shanker
</author>
<affiliation confidence="0.780962">
Department of CIS
University of Delaware
</affiliation>
<address confidence="0.375011">
Delaware, DE 19716
</address>
<author confidence="0.489514">
David J. Weir
</author>
<affiliation confidence="0.960973">
Department of EECS
Northwestern University
</affiliation>
<keyword confidence="0.252679">
Evanston, IL 60208
</keyword>
<sectionHeader confidence="0.955942" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99909225">
In this paper we present a polynomial time pars-
ing algorithm for Combinatory Categorial Grammar.
The recognition phase extends the CKY algorithm for
CFG. The process of generating a representation of
the parse trees has two phases. Initially, a shared for-
est is build that encodes the set of all derivation trees
for the input string. This shared forest is then pruned
to remove all spurious ambiguity.
</bodyText>
<sectionHeader confidence="0.998379" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999077181818182">
Combinatory Categorial Grammar (CCG) [7, 5] is an
extension of Classical Categorial Grammar in which
both function composition and function application
are allowed. In addition, forward and backward
slashes are used to place conditions on the relative
ordering of acliacent categories that are to be com-
bined. There has been considerable interest in pars-
ing strategies for CCG&apos; [4, 11, 8, 2]. One of the major
problems that must be addressed is that of spurious
ambiguity. This refers to the possibility that a CCG
can generate a large number of (exponentially many)
derivation trees that assign the same function argu-
ment structure to a string. In [9] we noted that a CCG
can also generate exponentially many genuinely am-
biguous (non-spurious) derivations. This constitutes
a problem for the approaches cited above since it re-
sults in their respective algorithms taking exponential
time in the worst case. The algorithm we present is
the first known polynomial time parser for CCG.
The parsing process has three phases. Once the
recognizer decides (in the first phase) that an input
can be generated by the given CCG the set of parse
</bodyText>
<listItem confidence="0.587592333333333">
• This work was partially supported by NSF grant IRI-
8909810. We are very grateful to Aravind Joshi, Michael Niv,
Mark Steedman and Kent Wittenbttrg for helpful discussions.
</listItem>
<bodyText confidence="0.999266666666667">
trees can be extracted in the second phase. Rather
than enumerating all parses, in Section 3, we describe
how they can be encoded by means of a shared forest
(represented as a grammar) with which an exponen-
tial number of parses are encoded using a poIynoini-
ally bounded structure. This shared forest encodes
all derivations including those that are spuriously am-
biguous. In Section 4.1, we show that it is possible to
modify the shared forest so that it contains no spuri-
ous ambiguity. This is done (in the third phase) by
traversing the forest, examining two levels of nodes at
each stage, detecting spurious ambiguity locally. The
three stage process of recognition, building the shared
forest, and eliminating spurious ambiguity takes poly-
nomial time.
</bodyText>
<subsectionHeader confidence="0.999057">
1.1 Definition of CCG
</subsectionHeader>
<bodyText confidence="0.996641125">
A CCG, G , is denoted by (VT ,VN , S,f, R) where VT is
a finite set of terminals (lexical items), VN is a finite
set of nonterminals (atomic categories), S is a dis-
tinguished member of ITN, f is a function that maps
elements of VT to finite sets of categories, R is a fi-
nite set of combinatory rules. Combinatory rules have
the following form. In each of the rules x, y, z1, ... are
variables and Ii E
</bodyText>
<listItem confidence="0.983068333333333">
1. Forward application: x/y x
2. Backward application: y z
3. Forward composition (for n &gt; 1):
x/ii Ylizi.12• • • kr,. xliziI2• • • In Zn
4. Backward composition (for n &gt; 1):
-Inzn x\Y
</listItem>
<bodyText confidence="0.995711">
In the above rules, x I y is the primary category
and the other left-hand-side category is the secondary
category. Also, we refer to the leftmost nonterminal
</bodyText>
<page confidence="0.975428">
1
</page>
<bodyText confidence="0.987830142857143">
of a category as the target of the category. We assume
that categories are parenthesis-free. The results pre-
sented here, however, generalize to the case of fully
parenthesized categories. The version of CCG used
in [7, 51 allows for the possibility that the use of these
combinatory rules can be restricted. Such restrictions
limit the possible categories that can instantiate the
variables. We do not consider this possibility here,
though the results we present can be extended to han-
dle these restrictions.
Derivations in a CCG involve the use of the com-
binatory rules in R. Let be defined as follows,
where T1 and T2 are strings of categories and termi-
nals and c, el, ca are categories.
</bodyText>
<listItem confidence="0.913644">
• If c1e2 —+ c is an instance of a rule in R then
T1cT2 T1cic2T2.
• If c E f(a) for some a E VT and category c then
T1cT2 TiaTz.
</listItem>
<bodyText confidence="0.9469635">
The string language generated is defined as
L(G)=--{wIS
</bodyText>
<subsectionHeader confidence="0.982464">
1.2 Context-Free Paths
</subsectionHeader>
<bodyText confidence="0.9882463125">
In Section 2 we describe a recognition algorithm that
involves extending the CICY algorithm for CFG. The
differences between the CKY algorithm and the one
presented here result from the fact that the derivation
tree sets of CCG have more complicated path sets than
the (regular) path sets of CFG tree sets. Consider
the set of CCG derivation trees of the form shown in
Figure 1 for the language { ww I w E {a, b}*}.
Due to the nature of the combinatory rules, cate-
gories behave rather like stacks since their arguments
are manipulated in a last-in-first-out fashion. This has
the effect that the paths can exhibit nested dependen-
cies as shown in Figure 1. Informally, we say that CCG
tree sets have context-free paths. Note that the tree
sets of CFG have regular paths and cannot produce
such tree sets.
</bodyText>
<sectionHeader confidence="0.589202" genericHeader="method">
2 Recognition of CCG
</sectionHeader>
<bodyText confidence="0.9941425">
The recognition algorithm uses a 4 dimensional ar-
ray L for the input al ...an. In entries of the ar-
ray L we cannot store complete categories since ex-
ponentially many categories can derive the substring
</bodyText>
<figure confidence="0.999549">
A SIA
I...&amp;quot;.&amp;quot;%&amp;quot;.■
a B SIA IS
b B SIA1B1B
I ..--■■■
b SIAIBIS SIB
I
SlAIS SIBIS b
I
</figure>
<figureCaption confidence="0.999945">
Figure 1: Trees with context-free paths
</figureCaption>
<bodyText confidence="0.99778624">
...aj1 it is necessary to store categories carefully
It is possible, however, to share parts of categories be
tween different entries in L. This follows from the fac&apos;
that the use of a combinatory rule depends only on
(1) the target category of the primary category of tht
rule; (2) the first argument (suffix of length 1) of tht
primary category of the rule;(3) the entire (bounded
secondary category. Therefore, we need only find thi
(bounded) information in each array entry in crde
to determine whether a rule can be used. Entries o
the form ((A, a), T) are stored in L[i,j][p,q]. This en
codes all categories whose target is A, suffix a, an
that derive the ai ...aj. The tail T and the indices I
and q are used to locate the remaining part of them
categories. Before describing precisely the informatior
that is stored in L we give some definitions.
If a E (1\,/)VN)n then lal = n. Given a CCG,
G = (VT, VN, S f, R) let k1 be the largest n such
that R contains a rule whose secondary category is
Inzn and let k2 be the maximum of k1 and
all n where there is some c E f(a) such that c = Aa
and la&apos; = n.
In considering how categories that are derived in
the course of a derivation should be stored we have
two Cases.
</bodyText>
<footnote confidence="0.9548035">
1. Categories that are either introduced by lexical
1This is possible since the length of the category can be linear
with respect to j — i. Since previous approaches to CCG parsing
store entire categories they can take exponential time.
</footnote>
<page confidence="0.995633">
2
</page>
<bodyText confidence="0.914875">
items appearing in the input string or whose length
is less that k1 and could therefore be secondary cat-
egories of a rule. Thus all categories whose length is
bound by k2 are encoded in their entirety within a sin-
gle array entry.
2. All other categories are encoded with a sharing
mechanism in which we store up to k1 arguments lo-
cally together with an indication of where the remain-
ing arguments can be found.
Next, we give a proposition that characterizes when
an entry is included in the array by the algorithm.
An entry (A, a), T) E j][p,q) where A E VN and
E ({/, /}VN)* when one of the following holds.
If T 7 then 7 E {\,/}VN, 1 &lt; 101 &lt; 1:1, and for
</bodyText>
<listItem confidence="0.967126">
some a&apos; E ({\ 1}11N)* the following hold
(1) Acx&apos;a a ...ap...iAa&apos;7aq+1 ...aj.
(2) Ac . . ag.
(3) Informally, the category Aa&apos;7 in (1) above is &amp;quot;de-
rived&amp;quot; from Aa&apos;a such that there is no intervening
point in the derivation before reaching Aa7 at which
the all of the suffix a of Aa&apos;a has been &amp;quot;popped&amp;quot;.
</listItem>
<bodyText confidence="0.970811777777778">
Alternatively, if T = — then 0 &lt; lai &lt; k + k2,
(p, q) ----- (0,0) and Aa ...aj, Note that we
have !al &lt; ki k2 rather than 1a&lt; k2 (as might
have been expected from the discussion above). This
is the case because a category whose length is strictly
less than k2, can, as a result of function composition,
result in a category of length &lt; ki + k2. Given the
way that we have designed the algorithm below, the
latter category is stored in this (non-sharing) form.
</bodyText>
<subsectionHeader confidence="0.989848">
2.1 Algorithm
</subsectionHeader>
<bodyText confidence="0.978901833333333">
If c E f(a) for some category c, such that c Aa,
then include the tuple a), —) in Lfi, 110, 0].
For some i and j, I. &lt;i &lt; j &lt; n consider each rule
x/Y
For some k, i &lt;k &lt;j, we look for some ((.8,13),—) E
L[k + 1, [0, 0], where 10u = m, (corresponding to
the secondary category of the rule) and we look for
((A,a1 13), T) E L[i, k][p,qj for some a, T, p and q
(corresponding to the primary category of the rule).
From these entries in L we know that for some
Ary&apos;a/B =ai ak and BO
Backward composition and application are treated in the
same way as this rule, except that all occurrences below of
and k are swapped with occurrences of k+1 and respectively.
Thus, by the combinatory rule given above we have
Arri and we should store and encod-
ing of the category Aa&apos;a0 jj. This encoding
depends on a&apos;, a, 3, and T
</bodyText>
<listItem confidence="0.98952925">
• T = —
If Fafil &lt; k1 + k2 then (case la) add ((A, a —) to
• j] (0, 0). Otherwise, (case lb) add ((A, 8)/B) to
• T — and in &gt; 1
</listItem>
<bodyText confidence="0.891042">
The new category is longer than the one found in
</bodyText>
<listItem confidence="0.988219">
• klip,q]. If a 0 c then (case 2a) add ((A, 0),/B)
</listItem>
<bodyText confidence="0.694687">
to kl, otherwise (case 2b) add ((A, 13),T) to
LCI, jIIp, q).
</bodyText>
<listItem confidence="0.989819">
• T — and m 1 (case 3)
</listItem>
<bodyText confidence="0.982278085714286">
The new category has the same length as the one found
in Lti, kiln, gl. Add ((A, a(3), T) to
•Tea &amp;quot;ir — andm=0
The new category has the a length one less than the
one found in L(i,k][p,q). If a 0 c then (case 4a)
add ((A, a), T) to. Ly, ji[p, q]. Otherwise, (case 4b)
since a = c we have to look for part of the category
that is not stored locally in L[i, ;dip, q). This may be
found by looking in each entry 1,[1 2 , , sl for each
((A, 0&apos;7), T&apos;). We know that either r — or p, c
and add ((A, 13&apos;),T1) to L[i, ji[r, sl, Note that for some
a&amp;quot;, Aa&amp;quot;0&amp;quot;7 ... Aa&amp;quot; I B ai • • • ak
and thus by the combinatory rule above Act&amp;quot;0&apos;
ai aj.
As in the case of CKY algorithm we should have
loop statements that allow i, j to range from 1 through
• such that the length of the spanned substring starts
from 1 (1 = j) and increases to n (i =, 1 and j = n).
When we consider placing entries in L[i, j] (i.e., to
detect whether a category derives ai ...aj) we have
to consider whether there are two subconstituents (to
simplify the discussion let us consider only forward
combinations) which span the substrings cii ak and
ak+1 ...aj. Therefore we need to consider all values
for k between i through j — 1 and consider the entries
in Lii, klip,q) and L[k + 1, AO, Oj where i&lt;p&lt;q&lt;k
or p = q = 0.
The above algorithm can be shown to run in time
Q(n7) where n is the length of the input. In case Lib.
we have to consider all possible values for r, s between
p and q. The complexity of this case dominates the
complexity of the algorithm since the other cases do
involve fewer variables (i.e., r and .s are not involved).
Case 4b takes time 0((q p)2) and with the loops for
j, k, p,q ranging from I through n the time complex-
</bodyText>
<page confidence="0.994933">
3
</page>
<bodyText confidence="0.987108928571429">
ity of the algorithm is 0(n7).
However, this algorithm can be improved to obtain
a time complexity of 0(n6) by using the same method
employed in [91. This improvement is achieved by
moving part of case 4b outside of the k loop, since
looking for ((A, 131/791 T&apos;) in Lip, s] need not be
done within the k loop. The details of the improved
method may be found in [9] where parsing of Linear
Indexed Grammar (LIG) was considered. Note that
0(n6) (which we achieve with the improved method)
is the best known result for parsing Tree Adjoining
Grammars, which generates the same class of lan-
guages generated by CCG and LIG.
A[.-cr] rail ... Ai, [ai—i I A,(..fil A‘4.1as+11 . . Anta.1
</bodyText>
<subsectionHeader confidence="0.751823">
il[ce] a
</subsectionHeader>
<bodyText confidence="0.999973">
The first form of production is interpreted as: if a
nonterminal A is associated with some stack with the
sequence a on top (denoted [--a]), it can be rewritten
such that the Vh child inherits this stack with ,3 re-
placing a. The remaining children inherit the bounded
stacks given in the production.
The second form of production indicates that if a non-
terminal A has a stack containing a sequence a then
it can be rewritten to a terminal symbol a.
The language generated by a LIG is the set of strings
derived from the start symbol with an empty stack.
</bodyText>
<sectionHeader confidence="0.979549" genericHeader="method">
3 Recovering Al! Parses
</sectionHeader>
<bodyText confidence="0.999725571428572">
At this stage, rather than enumerating all the parses,
we will encode these parses by means of a shared forest
structure. The encoding of the set of all parses must be
concise enough so that even an exponential number of
parses can be represented by a polynomial sized shared
forest. Note that this is not achieved by any previously
presented shared forest presentation for CCG [8].
</bodyText>
<subsectionHeader confidence="0.999438">
3.1 Representing the Shared Forest
</subsectionHeader>
<bodyText confidence="0.975045363636364">
Recently, there has been considerable interest in the
use of shared forests to represent ambiguous parses
in natural language processing [I, 8]. Following 811-
lot and Lang [1], we use grammars as a representa-
tion scheme for shared forests. In our case, the gram-
mars we produce may also be viewed as acyclic and-or
graphs which is the more standard representation used
for shared forests.
The grammatical formalism we use for the repre-
sentation of shared forest is Linear Indexed Grammar
(LIG)3. Like Indexed Grammars (IG), in a LIG stacks
containing indices are associated with nontermina.ls,
with the top of the stack being used to determine the
set of productions that can be applied. Briefly, we
define LIG as follows.
If a is a sequence of indices and 7 is an index, we
use the notation A[a] to represent the case where a
stack is associated with a nonterminal A having 7 on
top with the remaining stack being the a. We use the
following forms of productions.
3It has been shown in [10, 3] that LIG and CCG generate
the same class of languages.
</bodyText>
<subsectionHeader confidence="0.999595">
3.2 Building the Shared Forest
</subsectionHeader>
<bodyText confidence="0.992447484848485">
We start building the shared forest after the recognizer
has completed the array L and decided that a given
input Si . . a, is well-formed. In recovering the parses,
having established that some a is in an element of L,
we search other elements of L to find two categories
that combine to give a. Since categories behave like
stacks the use of CFG for the representation of the set
of parse trees is not suitable. For our purposes the LIG
formalism is appropriate since it involves stacks and
production describing how a stack can be decomposed
based on only its top and bottom elements.
We refer to the LIG representing the shared forest
as G11. The set of indices used in Gsf have the form
(A,a,i, j). The terminals used in G,.0. are names for
the combinatory rule or the lexical assignment used
(thus derived terminal strings encode derivations in
G). For example, the terminal Fm indicates the use
of the forward composition rule ziy Ylizi 12 • - • Ifezin
and (c, a) indicates the lexical assignment, c to the
symbol a. We use one nonterminal, P.
An input al ... an is accepted if it is the case that
((S, e), —) E L[1, n][0, 0]. We start by marking this
entry. By marking an entry ((A, a), T) E j][p, q]
we are predicting that there is some derivation tree,
rooted with the category S and spanning the input
al ...an, in which a category represented by this en-
try will participate. Therefore at some point we will
have to consider this entry and build a shared forest
to represent all derivations from this category.
Since we start from ((5, €), —) E L[1, n][1:1, 0] and
proceed to build a (representation of) derivation trees
in a top down fashion we will have loop statements
that vary the substring spanned (ai ai) from the
</bodyText>
<page confidence="0.989173">
4
</page>
<bodyText confidence="0.9998765">
largest possible (i.e., i = 1 and j = n) to the smallest
(i.e., i = j). Within these loop statements the algo-
rithm (with some particular values for i and j) will
consider marked entries, say ((A, a), T) E j]tp, q]
(where i&lt;p&lt;q&lt;j or p = q = 0), and will build
representations of all derivations from the category
(specified by the marked entry) such that the input
spanned is ai Since ((A, a), T) is a representa-
tion of possibly more than one category, several cases
arise depending on a and T. All these cases try to un-
cover the reasons why the recognizer placed this entry
in jilp, q]. Hence the cases considered here are in-
verses of the cases considered in the recognition phase
(and noted in the algorithm given below).
</bodyText>
<equation confidence="0.280005">
Mark ((S, e), —) in L(1, n][0, 0].
</equation>
<bodyText confidence="0.833524333333333">
By varying i from I to n, j from n to i and for all ap-
propriate values alp and q if there is a marked entry,
say ((A, a), T) E Lfi, j][p,q] then do the following.
</bodyText>
<listItem confidence="0.846268">
• Type .1 Production (inverse of la, 3, and 4a)
</listItem>
<bodyText confidence="0.789117571428571">
If for some k such that .1 &lt; k &lt; j, same a8 such
that a&apos; = a(3, and B E VN we have ((A, a 1 B), T) E
Lii,k][p,q1 and ((B, 13), —) E LR + 1, j][0, 01 then let
p be the production
P[.&apos;(A, a&apos; j)] F,,, P[.-(A, al , k)] P[(B, 11, k 1,j)]
where m = 101. lip is not already present in G„1 then
add p and mark ((A, al B),T) E kllp, ql as well as
</bodyText>
<equation confidence="0.462082">
((a, —) E LR + I, j1( 0 , 0].
</equation>
<listItem confidence="0.585791">
• Type 2 Production (inverse of lb and 2a)
If for some k such that i &lt; k &lt; j, and a, B,T&apos; r, s, k
we have ((A, al B), E klir, s1 where (p, q) =
</listItem>
<bodyText confidence="0.969320625">
(i, k), ((B , —) L[k + 1, ob T = B, and the
lengths of a and a&apos; meet the requirements on the cor-
responding strings in case lb and 2a of the recognition
algorithm then then let p be the production
P[..(A, a / B, i, k)(A, a&apos;, 1, j)]
where m =kr&apos; I. If p is not already present in Gall
then add p and mark ((A, a 1 B),T1) E L(i, kl[r, s] and
((B , a&apos;), —) Lik + 1, go, ()I.
</bodyText>
<listItem confidence="0.894405">
• Type 3 Production (inverse of 2b)
</listItem>
<bodyText confidence="0.866650571428571">
If for some k such that i &lt; k &lt; j, and some B
it is the case that ((A, / B),T) E L[i,kiip,q) and
(0, —) E LR + 1, AN, 0) where )a&apos;) &gt; 1 then then
let p be the production
I&apos;m PHA, I B, k)j PRB, a&apos; , k + 1,j)J
where m = ten If p is not already present in Gsf
then add p and mark ((A, 1 B), T) E kllp, q] and
</bodyText>
<figure confidence="0.815473666666667">
((Dia% —) E + 1, j](0,0].
• Type 4 Production (inverse of 4b)
If for some k such that i &lt; k &lt; j, and some
B,71,r,s,k, we find ((A, 1 B ,), E
((A, a&apos;71), T) E L[r, sllp, q], and ((B, e), —) E
L[le + 1, AO, 01 then then let p be the production
FoP(..(4,cr&apos;7&apos;,r,.)(A,/B,i,k))P((B,r,k+1,jfl
If p is not already present in G,1 then add p and
mark ((A, 1 B),7&apos;) E gi,k][r, s] and ((B , e), —) E
LR 1, illo,
• Type 5 Production
1.1 j = 1, then it must be the case that T — and there
</figure>
<figureCaption confidence="0.587423333333333">
is a. lexical assignment assigning the category Aa&apos; to
the input symbol given by ai. Therefore, if it has not
already been included, output the production
</figureCaption>
<bodyText confidence="0.996937055555555">
PRA, a&apos;, 11 1)1 (Act, ai)
The number of terminals and nonterminais in the
grammar is bounded by a constant. The number of in-
dices and the number of productions in G f are 0(n5).
Hence the shared forest representation we build is
polynomial with respect to the length of the input, n,
despite the fact that the number of derivations trees
could be exponential.
We will now informally argue that G1 can be built
in time 0(117). Suppose an entry ((A, al), T) is in
ji[), q] indicating that for some the category
Afia&apos; dominates the substring a ...cr.&apos;. The method
outlined above will build a shared forest structure to
represent all such derivations. In particular, we will
start by considering a production whose left hand side
is given by P[..(A, a&apos;, i, j)]. It is clear that an intro-
duction of production of type 4 dominates the time
complexity since this case involves three other vari-
ables (over input positions), i.e., re, k; whereas the
introduction of other types of production involve only
one new variable k. Since we have to consider all pos-
sible values for r, 8, k within the range i through j, this
step will take OW — ir) time. With the outer loops
for P, and q allowing these indices to range from 1
through n, the time taken by the algorithm is 0(717).
Since the algorithm given here for building the
shared forest simply finds the inverses of moves made
in the recognition phase we could have modified the
recognition algorithm so as to output appropriate G,
productions
productions during the process of recognition without
altering the asymptotic complexity of the recognizer.
However this will cause the introduction of useless pro-
ductions, i.e., those that describe subderivations which
do not partake in any derivation from the category S
spanning the entire input string ai • • am.
</bodyText>
<page confidence="0.994458">
5
</page>
<sectionHeader confidence="0.930453" genericHeader="method">
4 Spurious Ambiguity
</sectionHeader>
<bodyText confidence="0.9998334">
We say that a given CCG, G, exhibits spurious am-
biguity if there are two distinct derivation trees for
a string w that assign the same function argument
structure. Two well-known sources of such ambiguity
in CCG result from type raising and the associativity
of composition. Much attention has been given to the
latter form of spurious ambiguity and this is the one
that we will focus on in this paper.
To illustrate the problem, consider the following
string of categories.
</bodyText>
<figure confidence="0.980918714285714">
At I A2 A21 A3 . . An-11 An
Aaaa
1 1 2 3
A a /A A a /A Aa
1 1 2 2 2 3 3 3
a a a a a a
ii 1 12 j2 13 j3
</figure>
<bodyText confidence="0.990384166666667">
Any pair of adjacent categories can be combined using
a composition rule. The number of such derivations
is given by the Catalan series and is therefore expo-
nential in n. We return a single representative of the
class of equivalent derivation trees (arbitrarily chosen
to be the right branching tree in the later discussion).
</bodyText>
<subsectionHeader confidence="0.999942">
4.1 Dealing with Spurious Ambiguity
</subsectionHeader>
<bodyText confidence="0.988422423076923">
We have discussed how the shared forest representa-
tion, C51, is built from the contents of array L. The
recognition algorithm does not consider whether some
of the derivations built are spuriously equivalent and
this is reflected in G31. We show how productions of
G31 can be marked to eliminate spuriously ambigu-
ous derivations. Let us call this new grammar Ga..
As stated earlier, we are only interested in detecting
spuriously equivalent derivations arising from the as-
sociativity of composition. Consider the example in-
volving spurious ambiguity shown in Figure 2. This
example illustrates the general form of spurious am-
biguity (due to associativity of composition) in the
derivation of a string made up of contiguous substrings
ai, (11,, and aia ...ai3 resulting in a cat-
egory A1aia2a3. For the sake of simplicity we assume
that each combination indicated is a forward combi-
nation and hence i2 = j1 + 1 and i5 = j2 + 1.
Each of the 4 combinations that occur in the above
figure arises due to the use of a combinatory rule, and
hence will be specified in G1 by a production. For
example, it is possible for combination 1 to be repre-
sented by the following type 1 production.
P[••(A.1, asa2/A3., , j2 )1]
F,, P[.•(Ai, aVA2,11,ii)] P[(A2, ce3, i2,f2)]
where i2 = j1 + 1, a&apos; is a suffix of al of length less than
</bodyText>
<figure confidence="0.995214333333333">
A aaa
1 1 2 3
A a a
2 2 3
3
A a /A Aa
2 2 3 33
a a a a
12 12 13 J3
</figure>
<figureCaption confidence="0.999954">
Figure 2: Example of spurious ambiguity
</figureCaption>
<bodyText confidence="0.943979428571429">
la2I. Since Ai cti/A3
, and m = and A3a3 are used
as secondary categories, their lengths are bounded by
k1 + 1. Hence these categories will appear in their en-
tirety in their representations in the G31 productions.
The four combinations4 will hence be represented in
G31 by the productions:
</bodyText>
<table confidence="0.920360571428571">
Combination 1: P[..(Ai, a`a 2 ifts, .13)1 —
F,,, P[(441, a&apos;/A3, it, it)] PRA7, ct2/443, ii + 1, j2)1
Combination 2: P(..(Ai, a&apos;a2a3, i3)]
111..(4i,a&apos;a2/42, ,./2)] P((A3 cv3i 1,j))
Combination 3: Pt..(A2, az as, ji + 1,j3)1
F,&amp;quot; P[..(A2,a21A3, ji +1, 22)] P[(Aa, as, j2 +1,j3)]
Combination 4: P(..(iit, ata2a3,
</table>
<footnote confidence="0.55161175">
PI&amp;quot;(.41, cr&apos;/A2, ctzois, + 1, j)]
where n1 =• ict2/A.31, n2 = Iasi, and n3 = let2asi.
4We consider the case where each combination is represented
by a Type 1 production.
</footnote>
<page confidence="0.99871">
6
</page>
<bodyText confidence="0.999916888888889">
These productions give us sufficient information to de-
tect spurious ambiguity locally, i.e., the local left and
right branching derivations. Suppose we choose to re-
tain the right branching derivations only. We are no
longer interested in combination 2. Therefore we mark
the production corresponding to this combination.
This production is not discarded at this stage be-
cause although it is marked it might still be useful in
detecting more spurious ambiguity. Notice in Figure 3
</bodyText>
<figure confidence="0.982980714285714">
A ct a a a
1 2 3
Aaaa/A
2 3
A a a /A
s 1 2 3
VN
</figure>
<figureCaption confidence="0.999061">
Figure 3: Reconsidering a marked production
</figureCaption>
<bodyText confidence="0.999990583333333">
that the subtree obtained from considering combina-
tion 5 and combination 1 is right branching whereas
the entire derivation is not. Since we are looking for
the presence of spurious ambiguity locally (i.e., by con-
sidering two step derivations) in order to mark this
derivation we can only compare it with the derivation
where combination 7 combines Aa I Ai with AI cricr2ois
(the result of combination 2)5. Notice we would have
already marked the production corresponding to com-
bination 2. If this production had been discarded then
the required comparison could not have been made
and the production due to combination 6 can not have
been marked. At the end of the marking process all
marked productions can be discarded6
In the procedure to build the grammar Gnz we start
with the productions for lexical assignments (type 5).
By varying i1 from n to 1, ,j3 from i + 2 to n, i2 from
js to i1 + 1, and is from i2 + 1 to js we look for a
group of four productions (as discussed above) that
locally indicates the the presence of spurious ambigu-
ity. Productions involved in derivations that are not
right branching are marked.
It can be shown that this local marking of spuri-
ous derivations will eliminate all and only the spuri-
ously ambiguous derivations. That is, enumerating all
derivations using unmarked productions, will give all
and only genuine derivations. If there are two deriva-
tions that are spuriously ambiguous (due to the as-
sociativity of composition) then in these derivations
there must be at least one occurrence of sub deriva-
tions of the nature depicted in Figure 3. This will
result in the marking of appropriate productions and
hence the spurious ambiguity will be detected. By
induction it is also possible to show that only the spu-
riously ambiguous derivations will be detected by the
marking process outlined above.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.988998066666667">
Several parsing strategies for CCG have been given
recently (e.g., [4, 11, 2, 8]). These approaches have
concentrated on coping with ambiguity in CCG deriva-
tions. Unfortunately these parsers can take exponen-
tial time. They do not take into account the fact that
categories spanning a substring of the input could be
of a length that is linearly proportional to the length
of the input spanned and hence exponential in num-
ber. We adopt a new strategy that runs in polynomial
time. We take advantage of the fact that regardless
of the length of the category only a bounded amount
of information (at the beginning and end of the cate-
sAlthough this category is also the result of combination 4,
the tree with combinations 5 and 6 can not he compared with
the tree having the combinations 7 and 4.
</bodyText>
<footnote confidence="0.904509333333333">
6Steedrnan [6] has noted that although all multiple deriva-
tions arising due to the so-called spurious amb:guity yield the
same &amp;quot;semantics&amp;quot; they need not be considered useless.
</footnote>
<figure confidence="0.998757807692308">
A a / A A ct / A
I I 2
a a a a
10 JO 11 j1
A a/A
2 2 3
a a
i2 12
A3 al
Zs
a a
13 j3
Aaaaa
1 2 3
Aacta
t 1 2 3
2
A a / A A a a /A
It 3
a a all all
10 10
Aa
3 3
ab
a a
13 13
</figure>
<page confidence="0.996917">
7
</page>
<bodyText confidence="0.999915311111111">
gory) is used in determining when a combinatory rule
can apply.
We have also given an algorithm that builds a
shared forest encoding the set of all derivations for
a given input. Previous work on the use of shared
forest structures [1] has focussed on those appropri-
ate for context-free grammars (whose derivation trees
have regular path sets). Due to the nature of the CCG
derivation process and the degree of ambiguity possi-
ble this form of shared forest structures is not appro-
priate for CCG. We have proposed a shared forest
representation that is useful for CCG and other for-
malisrn.s (such as Tree Adjoining Grammars) used in
computational linguistics that share the property of
producing trees with context free paths.
Finally, we show the shared forest can be marked
so that during the process of enumerating all parses
we do not list two derivations that are spuriously am-
biguous. In order to be able to eliminate spurious
ambiguity problem in polynomial time, we examine
two step derivations to locally identify when they are
equivalent rather than looking at the entire derivation
trees. This method was first considered by [2] where
this strategy was applied in the recognition phase.
The present algorithm removes spurious ambiguity
in a separate phase after recognition has been com-
pleted. This is a reasonable approach when a CKY-
style recognition algorithm is being used (since the de-
gree of ambiguity has no effect on recognition time).
However, if a predictive (e.g., Earley-style) parser were
employed then it would be advantageous to detect
spurious ambiguity during the recognition phase. In
a predictive parser the performance on an ambigu-
ous input may be inferior to that on an unambiguous
one. Due to the spurious ambiguity problem in CCG,
even without genuine ambiguity, the parser&apos;s perfor-
mance be poor if spurious ambiguity was not detected
during recognition. CKY-style parsers are closely re-
lated to predictive parsers such as Earley&apos;s. There-
fore, we believe that the techniques presented here,
i.e., (1) the sharing of stacks used in recognition and in
the shared forest representation and (2) the local iden-
tification of spurious ambiguity (first proposed by [2])
can be adapted for use in more practical predictive
algorithms.
</bodyText>
<sectionHeader confidence="0.998923" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999966756097561">
[1] S. Billot and B. Lang. The structure of shared
forests in ambiguous parsing. In 27 meeting As-
soc. Cornput. Ling., 1989.
[2] M. Hepple and G. Morrill. Parsing and deriva-
tional equivalence. In European Assoc. Corn put
Ling., 1089.
[3] A. K. Joshi, K. Vijay-Shanker, and D. J.
Weir. The convergence of mildly context-sensitive
grammar formalisms. In T. Wasow and P. Sells,
editors, The Processing of Linguistic Structure.
MIT Press, 1989.
[4] R. Pareschi and M. J. Steedman. A lazy way
to chart-parse with categorial grammars. In 25&apos;h
meeting Assoc. Comput. Ling., 1987.
[5] M. Steedman. Combinators and grammars. In
R.. Oehrle, E. Bach, and D. Wheeler, editors, Cat-
egorial Grammars and Natural Language Struc-
tures. Foris, Dordrecht, 1986.
[6] M. Steedman. Parsing spoken language using
combinatory grammars. In International Work-
shop of Parsing Technologies, Pittsburgh, PA,
1989.
[7] M. J. Steedman. Dependency and coordination
in the grammar of Dutch and English. Language,
61:523-568, 1985.
[8] M. Tornita. Graph-structured stack and natural
language parsing. In 26&amp;quot; meeting Assoc. Corn-
put. Ling., 1988.
[91 K. Vijay-Shanker and D. J. Weir. The recognition
of Combinatory Categorial Grammars, Linear In-
dexed Grammars, and Tree Adjoining Grammars.
In International Workshop of Parsing Technolo-
gies, Pittsburgh, PA, 1989.
[10] D. J. Weir and A. K. Joshi. Combinatory cate-
gorial grammars: Generative power and relation-
ship to linear context-free rewriting systems. In
261h meeting Assoc. Comput Ling., 1988.
[11] K. B. Wittenburg. Predictive combinators: a
method for efficient processing of combinatory
categorial grammar. In 25211 meeting Assoc. Coin-
put. Ling., 1987.
</reference>
<page confidence="0.998496">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946894">
<title confidence="0.9940175">POLYNOMIAL TIME PARSING OF COMBINATORY CATEGORIAL GRAMMARS*</title>
<author confidence="0.999712">K Vijay-Shanker</author>
<affiliation confidence="0.999963">Department of CIS University of Delaware</affiliation>
<address confidence="0.988538">Delaware, DE 19716</address>
<author confidence="0.999992">David J Weir</author>
<affiliation confidence="0.999954">Department of EECS Northwestern University</affiliation>
<address confidence="0.997928">Evanston, IL 60208</address>
<abstract confidence="0.996518333333333">In this paper we present a polynomial time parsing algorithm for Combinatory Categorial Grammar. The recognition phase extends the CKY algorithm for CFG. The process of generating a representation of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The structure of shared forests in ambiguous parsing.</title>
<date>1989</date>
<booktitle>In 27 meeting Assoc. Cornput. Ling.,</booktitle>
<contexts>
<context position="13097" citStr="[1]" startWordPosition="2438" endWordPosition="2438">! Parses At this stage, rather than enumerating all the parses, we will encode these parses by means of a shared forest structure. The encoding of the set of all parses must be concise enough so that even an exponential number of parses can be represented by a polynomial sized shared forest. Note that this is not achieved by any previously presented shared forest presentation for CCG [8]. 3.1 Representing the Shared Forest Recently, there has been considerable interest in the use of shared forests to represent ambiguous parses in natural language processing [I, 8]. Following 811- lot and Lang [1], we use grammars as a representation scheme for shared forests. In our case, the grammars we produce may also be viewed as acyclic and-or graphs which is the more standard representation used for shared forests. The grammatical formalism we use for the representation of shared forest is Linear Indexed Grammar (LIG)3. Like Indexed Grammars (IG), in a LIG stacks containing indices are associated with nontermina.ls, with the top of the stack being used to determine the set of productions that can be applied. Briefly, we define LIG as follows. If a is a sequence of indices and 7 is an index, we u</context>
<context position="15128" citStr="[1, n]" startWordPosition="2808" endWordPosition="2809"> stack can be decomposed based on only its top and bottom elements. We refer to the LIG representing the shared forest as G11. The set of indices used in Gsf have the form (A,a,i, j). The terminals used in G,.0. are names for the combinatory rule or the lexical assignment used (thus derived terminal strings encode derivations in G). For example, the terminal Fm indicates the use of the forward composition rule ziy Ylizi 12 • - • Ifezin and (c, a) indicates the lexical assignment, c to the symbol a. We use one nonterminal, P. An input al ... an is accepted if it is the case that ((S, e), —) E L[1, n][0, 0]. We start by marking this entry. By marking an entry ((A, a), T) E j][p, q] we are predicting that there is some derivation tree, rooted with the category S and spanning the input al ...an, in which a category represented by this entry will participate. Therefore at some point we will have to consider this entry and build a shared forest to represent all derivations from this category. Since we start from ((5, €), —) E L[1, n][1:1, 0] and proceed to build a (representation of) derivation trees in a top down fashion we will have loop statements that vary the substring spanned (ai ai) fro</context>
<context position="27321" citStr="[1]" startWordPosition="5150" endWordPosition="5150">inations 7 and 4. 6Steedrnan [6] has noted that although all multiple derivations arising due to the so-called spurious amb:guity yield the same &amp;quot;semantics&amp;quot; they need not be considered useless. A a / A A ct / A I I 2 a a a a 10 JO 11 j1 A a/A 2 2 3 a a i2 12 A3 al Zs a a 13 j3 Aaaaa 1 2 3 Aacta t 1 2 3 2 A a / A A a a /A It 3 a a all all 10 10 Aa 3 3 ab a a 13 13 7 gory) is used in determining when a combinatory rule can apply. We have also given an algorithm that builds a shared forest encoding the set of all derivations for a given input. Previous work on the use of shared forest structures [1] has focussed on those appropriate for context-free grammars (whose derivation trees have regular path sets). Due to the nature of the CCG derivation process and the degree of ambiguity possible this form of shared forest structures is not appropriate for CCG. We have proposed a shared forest representation that is useful for CCG and other formalisrn.s (such as Tree Adjoining Grammars) used in computational linguistics that share the property of producing trees with context free paths. Finally, we show the shared forest can be marked so that during the process of enumerating all parses we do n</context>
</contexts>
<marker>[1]</marker>
<rawString>S. Billot and B. Lang. The structure of shared forests in ambiguous parsing. In 27 meeting Assoc. Cornput. Ling., 1989.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Hepple</author>
<author>G Morrill</author>
</authors>
<title>Parsing and derivational equivalence.</title>
<booktitle>In European Assoc. Corn put Ling.,</booktitle>
<pages>1089</pages>
<contexts>
<context position="1031" citStr="[4, 11, 8, 2]" startWordPosition="157" endWordPosition="160"> of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a string. In [9] we noted that a CCG can also generate exponentially many genuinely ambiguous (non-spurious) derivations. This constitutes a problem for the approaches cited above since it results in their respective algorithms taking exponential time in the worst case. The algorithm we present is the first known polynomial time parser for CCG. The pars</context>
<context position="26023" citStr="[4, 11, 2, 8]" startWordPosition="4882" endWordPosition="4885"> will give all and only genuine derivations. If there are two derivations that are spuriously ambiguous (due to the associativity of composition) then in these derivations there must be at least one occurrence of sub derivations of the nature depicted in Figure 3. This will result in the marking of appropriate productions and hence the spurious ambiguity will be detected. By induction it is also possible to show that only the spuriously ambiguous derivations will be detected by the marking process outlined above. 5 Conclusions Several parsing strategies for CCG have been given recently (e.g., [4, 11, 2, 8]). These approaches have concentrated on coping with ambiguity in CCG derivations. Unfortunately these parsers can take exponential time. They do not take into account the fact that categories spanning a substring of the input could be of a length that is linearly proportional to the length of the input spanned and hence exponential in number. We adopt a new strategy that runs in polynomial time. We take advantage of the fact that regardless of the length of the category only a bounded amount of information (at the beginning and end of the catesAlthough this category is also the result of comb</context>
<context position="28224" citStr="[2]" startWordPosition="5299" endWordPosition="5299">entation that is useful for CCG and other formalisrn.s (such as Tree Adjoining Grammars) used in computational linguistics that share the property of producing trees with context free paths. Finally, we show the shared forest can be marked so that during the process of enumerating all parses we do not list two derivations that are spuriously ambiguous. In order to be able to eliminate spurious ambiguity problem in polynomial time, we examine two step derivations to locally identify when they are equivalent rather than looking at the entire derivation trees. This method was first considered by [2] where this strategy was applied in the recognition phase. The present algorithm removes spurious ambiguity in a separate phase after recognition has been completed. This is a reasonable approach when a CKYstyle recognition algorithm is being used (since the degree of ambiguity has no effect on recognition time). However, if a predictive (e.g., Earley-style) parser were employed then it would be advantageous to detect spurious ambiguity during the recognition phase. In a predictive parser the performance on an ambiguous input may be inferior to that on an unambiguous one. Due to the spurious a</context>
</contexts>
<marker>[2]</marker>
<rawString>M. Hepple and G. Morrill. Parsing and derivational equivalence. In European Assoc. Corn put Ling., 1089.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
</authors>
<title>The convergence of mildly context-sensitive grammar formalisms.</title>
<date>1989</date>
<booktitle>The Processing of Linguistic Structure.</booktitle>
<editor>In T. Wasow and P. Sells, editors,</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="13915" citStr="[10, 3]" startWordPosition="2584" endWordPosition="2585">. The grammatical formalism we use for the representation of shared forest is Linear Indexed Grammar (LIG)3. Like Indexed Grammars (IG), in a LIG stacks containing indices are associated with nontermina.ls, with the top of the stack being used to determine the set of productions that can be applied. Briefly, we define LIG as follows. If a is a sequence of indices and 7 is an index, we use the notation A[a] to represent the case where a stack is associated with a nonterminal A having 7 on top with the remaining stack being the a. We use the following forms of productions. 3It has been shown in [10, 3] that LIG and CCG generate the same class of languages. 3.2 Building the Shared Forest We start building the shared forest after the recognizer has completed the array L and decided that a given input Si . . a, is well-formed. In recovering the parses, having established that some a is in an element of L, we search other elements of L to find two categories that combine to give a. Since categories behave like stacks the use of CFG for the representation of the set of parse trees is not suitable. For our purposes the LIG formalism is appropriate since it involves stacks and production describin</context>
</contexts>
<marker>[3]</marker>
<rawString>A. K. Joshi, K. Vijay-Shanker, and D. J. Weir. The convergence of mildly context-sensitive grammar formalisms. In T. Wasow and P. Sells, editors, The Processing of Linguistic Structure. MIT Press, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pareschi</author>
<author>M J Steedman</author>
</authors>
<title>A lazy way to chart-parse with categorial grammars.</title>
<date>1987</date>
<booktitle>In 25&apos;h meeting Assoc. Comput. Ling.,</booktitle>
<contexts>
<context position="1031" citStr="[4, 11, 8, 2]" startWordPosition="157" endWordPosition="160"> of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a string. In [9] we noted that a CCG can also generate exponentially many genuinely ambiguous (non-spurious) derivations. This constitutes a problem for the approaches cited above since it results in their respective algorithms taking exponential time in the worst case. The algorithm we present is the first known polynomial time parser for CCG. The pars</context>
<context position="26023" citStr="[4, 11, 2, 8]" startWordPosition="4882" endWordPosition="4885"> will give all and only genuine derivations. If there are two derivations that are spuriously ambiguous (due to the associativity of composition) then in these derivations there must be at least one occurrence of sub derivations of the nature depicted in Figure 3. This will result in the marking of appropriate productions and hence the spurious ambiguity will be detected. By induction it is also possible to show that only the spuriously ambiguous derivations will be detected by the marking process outlined above. 5 Conclusions Several parsing strategies for CCG have been given recently (e.g., [4, 11, 2, 8]). These approaches have concentrated on coping with ambiguity in CCG derivations. Unfortunately these parsers can take exponential time. They do not take into account the fact that categories spanning a substring of the input could be of a length that is linearly proportional to the length of the input spanned and hence exponential in number. We adopt a new strategy that runs in polynomial time. We take advantage of the fact that regardless of the length of the category only a bounded amount of information (at the beginning and end of the catesAlthough this category is also the result of comb</context>
</contexts>
<marker>[4]</marker>
<rawString>R. Pareschi and M. J. Steedman. A lazy way to chart-parse with categorial grammars. In 25&apos;h meeting Assoc. Comput. Ling., 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinators and grammars. In</title>
<date>1986</date>
<booktitle>Categorial Grammars and Natural Language Structures. Foris,</booktitle>
<editor>R.. Oehrle, E. Bach, and D. Wheeler, editors,</editor>
<location>Dordrecht,</location>
<contexts>
<context position="683" citStr="[7, 5]" startWordPosition="103" endWordPosition="104">Department of CIS University of Delaware Delaware, DE 19716 David J. Weir Department of EECS Northwestern University Evanston, IL 60208 Abstract In this paper we present a polynomial time parsing algorithm for Combinatory Categorial Grammar. The recognition phase extends the CKY algorithm for CFG. The process of generating a representation of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a strin</context>
</contexts>
<marker>[5]</marker>
<rawString>M. Steedman. Combinators and grammars. In R.. Oehrle, E. Bach, and D. Wheeler, editors, Categorial Grammars and Natural Language Structures. Foris, Dordrecht, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Parsing spoken language using combinatory grammars.</title>
<date>1989</date>
<booktitle>In International Workshop of Parsing Technologies,</booktitle>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="26750" citStr="[6]" startWordPosition="5013" endWordPosition="5013">nential time. They do not take into account the fact that categories spanning a substring of the input could be of a length that is linearly proportional to the length of the input spanned and hence exponential in number. We adopt a new strategy that runs in polynomial time. We take advantage of the fact that regardless of the length of the category only a bounded amount of information (at the beginning and end of the catesAlthough this category is also the result of combination 4, the tree with combinations 5 and 6 can not he compared with the tree having the combinations 7 and 4. 6Steedrnan [6] has noted that although all multiple derivations arising due to the so-called spurious amb:guity yield the same &amp;quot;semantics&amp;quot; they need not be considered useless. A a / A A ct / A I I 2 a a a a 10 JO 11 j1 A a/A 2 2 3 a a i2 12 A3 al Zs a a 13 j3 Aaaaa 1 2 3 Aacta t 1 2 3 2 A a / A A a a /A It 3 a a all all 10 10 Aa 3 3 ab a a 13 13 7 gory) is used in determining when a combinatory rule can apply. We have also given an algorithm that builds a shared forest encoding the set of all derivations for a given input. Previous work on the use of shared forest structures [1] has focussed on those approp</context>
</contexts>
<marker>[6]</marker>
<rawString>M. Steedman. Parsing spoken language using combinatory grammars. In International Workshop of Parsing Technologies, Pittsburgh, PA, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Steedman</author>
</authors>
<title>Dependency and coordination in the grammar of Dutch</title>
<date>1985</date>
<pages>61--523</pages>
<contexts>
<context position="683" citStr="[7, 5]" startWordPosition="103" endWordPosition="104">Department of CIS University of Delaware Delaware, DE 19716 David J. Weir Department of EECS Northwestern University Evanston, IL 60208 Abstract In this paper we present a polynomial time parsing algorithm for Combinatory Categorial Grammar. The recognition phase extends the CKY algorithm for CFG. The process of generating a representation of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a strin</context>
</contexts>
<marker>[7]</marker>
<rawString>M. J. Steedman. Dependency and coordination in the grammar of Dutch and English. Language, 61:523-568, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tornita</author>
</authors>
<title>Graph-structured stack and natural language parsing. In 26&amp;quot; meeting</title>
<date>1988</date>
<booktitle>In International Workshop of Parsing Technologies,</booktitle>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="1031" citStr="[4, 11, 8, 2]" startWordPosition="157" endWordPosition="160"> of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a string. In [9] we noted that a CCG can also generate exponentially many genuinely ambiguous (non-spurious) derivations. This constitutes a problem for the approaches cited above since it results in their respective algorithms taking exponential time in the worst case. The algorithm we present is the first known polynomial time parser for CCG. The pars</context>
<context position="12884" citStr="[8]" startWordPosition="2405" endWordPosition="2405">minal A has a stack containing a sequence a then it can be rewritten to a terminal symbol a. The language generated by a LIG is the set of strings derived from the start symbol with an empty stack. 3 Recovering Al! Parses At this stage, rather than enumerating all the parses, we will encode these parses by means of a shared forest structure. The encoding of the set of all parses must be concise enough so that even an exponential number of parses can be represented by a polynomial sized shared forest. Note that this is not achieved by any previously presented shared forest presentation for CCG [8]. 3.1 Representing the Shared Forest Recently, there has been considerable interest in the use of shared forests to represent ambiguous parses in natural language processing [I, 8]. Following 811- lot and Lang [1], we use grammars as a representation scheme for shared forests. In our case, the grammars we produce may also be viewed as acyclic and-or graphs which is the more standard representation used for shared forests. The grammatical formalism we use for the representation of shared forest is Linear Indexed Grammar (LIG)3. Like Indexed Grammars (IG), in a LIG stacks containing indices are </context>
<context position="26023" citStr="[4, 11, 2, 8]" startWordPosition="4882" endWordPosition="4885"> will give all and only genuine derivations. If there are two derivations that are spuriously ambiguous (due to the associativity of composition) then in these derivations there must be at least one occurrence of sub derivations of the nature depicted in Figure 3. This will result in the marking of appropriate productions and hence the spurious ambiguity will be detected. By induction it is also possible to show that only the spuriously ambiguous derivations will be detected by the marking process outlined above. 5 Conclusions Several parsing strategies for CCG have been given recently (e.g., [4, 11, 2, 8]). These approaches have concentrated on coping with ambiguity in CCG derivations. Unfortunately these parsers can take exponential time. They do not take into account the fact that categories spanning a substring of the input could be of a length that is linearly proportional to the length of the input spanned and hence exponential in number. We adopt a new strategy that runs in polynomial time. We take advantage of the fact that regardless of the length of the category only a bounded amount of information (at the beginning and end of the catesAlthough this category is also the result of comb</context>
</contexts>
<marker>[8]</marker>
<rawString>M. Tornita. Graph-structured stack and natural language parsing. In 26&amp;quot; meeting Assoc. Cornput. Ling., 1988. [91 K. Vijay-Shanker and D. J. Weir. The recognition of Combinatory Categorial Grammars, Linear Indexed Grammars, and Tree Adjoining Grammars. In International Workshop of Parsing Technologies, Pittsburgh, PA, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Weir</author>
<author>A K Joshi</author>
</authors>
<title>Combinatory categorial grammars: Generative power and relationship to linear context-free rewriting systems.</title>
<date>1988</date>
<booktitle>In 261h meeting Assoc. Comput Ling.,</booktitle>
<contexts>
<context position="13915" citStr="[10, 3]" startWordPosition="2584" endWordPosition="2585">. The grammatical formalism we use for the representation of shared forest is Linear Indexed Grammar (LIG)3. Like Indexed Grammars (IG), in a LIG stacks containing indices are associated with nontermina.ls, with the top of the stack being used to determine the set of productions that can be applied. Briefly, we define LIG as follows. If a is a sequence of indices and 7 is an index, we use the notation A[a] to represent the case where a stack is associated with a nonterminal A having 7 on top with the remaining stack being the a. We use the following forms of productions. 3It has been shown in [10, 3] that LIG and CCG generate the same class of languages. 3.2 Building the Shared Forest We start building the shared forest after the recognizer has completed the array L and decided that a given input Si . . a, is well-formed. In recovering the parses, having established that some a is in an element of L, we search other elements of L to find two categories that combine to give a. Since categories behave like stacks the use of CFG for the representation of the set of parse trees is not suitable. For our purposes the LIG formalism is appropriate since it involves stacks and production describin</context>
</contexts>
<marker>[10]</marker>
<rawString>D. J. Weir and A. K. Joshi. Combinatory categorial grammars: Generative power and relationship to linear context-free rewriting systems. In 261h meeting Assoc. Comput Ling., 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K B Wittenburg</author>
</authors>
<title>Predictive combinators: a method for efficient processing of combinatory categorial grammar.</title>
<date>1987</date>
<booktitle>In 25211 meeting Assoc. Coinput. Ling.,</booktitle>
<contexts>
<context position="1031" citStr="[4, 11, 8, 2]" startWordPosition="157" endWordPosition="160"> of the parse trees has two phases. Initially, a shared forest is build that encodes the set of all derivation trees for the input string. This shared forest is then pruned to remove all spurious ambiguity. 1 Introduction Combinatory Categorial Grammar (CCG) [7, 5] is an extension of Classical Categorial Grammar in which both function composition and function application are allowed. In addition, forward and backward slashes are used to place conditions on the relative ordering of acliacent categories that are to be combined. There has been considerable interest in parsing strategies for CCG&apos; [4, 11, 8, 2]. One of the major problems that must be addressed is that of spurious ambiguity. This refers to the possibility that a CCG can generate a large number of (exponentially many) derivation trees that assign the same function argument structure to a string. In [9] we noted that a CCG can also generate exponentially many genuinely ambiguous (non-spurious) derivations. This constitutes a problem for the approaches cited above since it results in their respective algorithms taking exponential time in the worst case. The algorithm we present is the first known polynomial time parser for CCG. The pars</context>
<context position="26023" citStr="[4, 11, 2, 8]" startWordPosition="4882" endWordPosition="4885"> will give all and only genuine derivations. If there are two derivations that are spuriously ambiguous (due to the associativity of composition) then in these derivations there must be at least one occurrence of sub derivations of the nature depicted in Figure 3. This will result in the marking of appropriate productions and hence the spurious ambiguity will be detected. By induction it is also possible to show that only the spuriously ambiguous derivations will be detected by the marking process outlined above. 5 Conclusions Several parsing strategies for CCG have been given recently (e.g., [4, 11, 2, 8]). These approaches have concentrated on coping with ambiguity in CCG derivations. Unfortunately these parsers can take exponential time. They do not take into account the fact that categories spanning a substring of the input could be of a length that is linearly proportional to the length of the input spanned and hence exponential in number. We adopt a new strategy that runs in polynomial time. We take advantage of the fact that regardless of the length of the category only a bounded amount of information (at the beginning and end of the catesAlthough this category is also the result of comb</context>
</contexts>
<marker>[11]</marker>
<rawString>K. B. Wittenburg. Predictive combinators: a method for efficient processing of combinatory categorial grammar. In 25211 meeting Assoc. Coinput. Ling., 1987.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>