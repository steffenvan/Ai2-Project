<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000282">
<title confidence="0.997728">
Gathering Knowledge for a Question Answering System from
Heterogeneous Information Sources
</title>
<author confidence="0.911538">
Boris Katz and Jimmy Lin and Sue Felshin
</author>
<affiliation confidence="0.81692">
MIT Artificial Intelligence Laboratory
</affiliation>
<address confidence="0.7094315">
200 Technology Square
Cambridge, MA 02139
</address>
<email confidence="0.993136">
{boris, jimmylin, sfelshin}@ai.mit.edu
</email>
<sectionHeader confidence="0.979973" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99979215">
Although vast amounts of information
are available electronically today, no ef-
fective information access mechanism ex-
ists to provide humans with convenient
information access. A general, open-
domain question answering system is a
solution to this problem. We propose an
architecture for a collaborative question
answering system that contains four pri-
mary components: an annotations sys-
tem for storing knowledge, a ternary ex-
pression representation of language, a
transformational rule system for han-
dling some complexities of language, and
a collaborative mechanism by which or-
dinary users can contribute new knowl-
edge by teaching the system new infor-
mation. We have developed a initial pro-
totype, called Webnotator, with which to
test these ideas.
</bodyText>
<sectionHeader confidence="0.997339" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996140176470588">
A tremendous amount of heterogenous informa-
tion exists in electronic format (the most promi-
nent example being the World Wide Web), but the
potential of this large body of knowledge remains
unrealized due to the lack of an effective informa-
tion access method. Because natural language is
the most convenient and most intuitive method
of accessing this information, people should be
able to access information using a system capa-
ble of understanding and answering natural lan-
guage questions in short, a system that com-
bines human-level understanding with the infal-
lible memory of a computer.
Natural language processing has had its suc-
cesses and failures over the past decades; while the
successes are significant, computers will not soon
be able to fully process and understand language.
In addition to the traditional difficulties associ-
ated with syntactic analysis, there remains many
other problems to be solved, e.g., semantic inter-
pretation, ambiguity resolution, discourse model-
ing, inferencing, common sense, etc. Furthermore,
not all information on the Web is textual some
is sound, pictures, video, etc. While natural lan-
guage processing is advanced enough to under-
stand typical interactive questions about knowl-
edge (interactive questions are typically fairly sim-
ple in structure), it cannot understand the knowl-
edge itself. For the time being, therefore, the
only way for computers to access their own knowl-
edge is for humans to tell the computers what the
knowledge means in a language that the comput-
ers can understand but still in a language that
humans can produce. A good way to accomplish
this is with the use of natural language annota-
tions, sentences which are simple enough for a
computer to analyze, yet which are in natural hu-
man language. Once knowledge is so annotated,
and indexed in a knowledge repository, a question
answering system can retrieve it.
The START (SynTactic Analysis using Re-
versible Transformations) Natural Language Sys-
tem (Katz, 1990; Katz, 1997) is an example of a
question answering system that uses natural lan-
guage annotations. START is a natural language
question answering system that has been available
to users on the World Wide Web&apos; since Decem-
ber, 1993. During this time, it has engaged in
millions of exchanges with hundreds of thousands
of people all over the world, supplying users with
knowledge regarding geography, weather, movies,
corporations, and many many other areas. De-
spite the success of START in serving real users,
its domain of expertise is relatively small and ex-
panding its knowledge base is a time-consuming
task that requires trained individuals.
We believe that the popularity of the Web may
offer a solution to this knowledge acquisition prob-
lem by providing collaborative mechanisms on a
scale that has not existed before. We can poten-
tially leverage millions of users on the World Wide
&apos;http://www.ai.mit.edu/projects/infolab
Web to construct and annotate a knowledge base
for question answering. In fact, we had proposed
a distributed mechanism for gathering knowledge
from the World Wide Web in 1997 (Katz, 1997),
but only recently have we attempted to implement
this idea.
An advantage of natural language annotations
is that it paves a smooth path of transition as nat-
ural language processing technology improves. As
natural language analysis techniques advance, the
annotations may become more and more complex.
Eventually, a textual information segment could
be its own annotation; someday, through other
technologies such as speech and image recognition,
etc., annotations could even be automatically con-
structed for non-textual information.
A further advantage is that natural language
annotations can be processed via techniques that
only partially understand them via IR engines,
or less-than-ideal natural language systems yet
they retain their more complex content and can be
reanalyzed at a later date by more sophisticated
systems.
</bodyText>
<sectionHeader confidence="0.964712" genericHeader="introduction">
2 Overview
</sectionHeader>
<bodyText confidence="0.993398">
We propose a collaborative question answering ar-
chitecture composed of the four following compo-
nents:
</bodyText>
<listItem confidence="0.998854954545455">
1. Natural Language Annotation is a tech-
nique of describing the content of informa-
tion segments in machine parsable natural
language sentences and phrases.
2. Ternary Expressions are subject-relation-
object triples that are expressive enough
to represent natural language, and also
amenable to rapid, large-scale indexing.
3. Transformational Rules handle the prob-
lem of linguistic variation (the phenomenon
in which sentences with different surface
structures share the same semantic content)
by explicitly equating representational struc-
tures (derived from different surface forms)
that have approximately the same meaning.
4. Collaborative Knowledge Gathering is a
technique by which the World Wide Web may
be viewed not only as a knowledge resource,
but also a human resource. The knowledge
base of a question answering system could be
constructed by enlisting the help of millions
of ordinary users all over the Web.
</listItem>
<sectionHeader confidence="0.930292" genericHeader="method">
3 Annotations
</sectionHeader>
<bodyText confidence="0.998278396551724">
Natural language annotations are machine-
parsable sentences or phrases that describe the
content of various information segments. They de-
scribe the questions that a particular segment of
information is capable of answering. For example,
the following paragraph about polar bears:
Most polar bears live along the northern
coasts of Canada, Greenland, and Russia,
and on islands of the Arctic Ocean...
may be annotated with one or more of the follow-
ing:
Polar bears live in the Arctic.
Where do polar bears live?
habitat of polar bears
A question answering system would parse these
annotations and store the parsed structures with
pointers back to the original information segment
that they described. To answer a question, the
user query would be compared against the anno-
tations stored in the knowledge base. Because this
match occurs at the level of ternary expressions,
structural relations and transformation (to be dis-
cussed in Section 5) can equate queries and anno-
tations even if their surface forms were different.
Furthermore, linguistically sophisticated machin-
ery such as synonymy/hyponymy, ontologies, can
be brought to bear on the matching process. If a
match were found, the segment corresponding to
the annotation would be returned to the user as
the answer.
The annotation mechanism we have outlined
serves as a good basis for constructing a question
answering system because annotating information
segments with natural language is simple and intu-
itive. The only requirement is that annotations be
machine parsable, and thus the sophistication of
annotations depends on the parser itself. As natu-
ral language understanding technology improves,
we can use more and more sophisticated annota-
tions.
In addition, annotations can be written to de-
scribe any type of information, e.g., text, im-
ages, sound clips, videos, and even multimedia.
This allows integration of heterogenous informa-
tion sources into a single framework.
Due to the vast size of the World Wide Web,
trying to catalog all knowledge on the World Wide
Web is a daunting task. Instead, focusing on
meta-knowledge is a more promising approach to
building a knowledge base that spans more than a
tiny fraction of the Web. Consider that reference
librarians at large libraries obviously don&apos;t know
all the knowledge stored in the reference books,
but they are nevertheless helpful in finding infor-
mation, precisely because they have a lot of knowl-
edge about the knowledge. Natural language anno-
tations can assist in creating a smart &amp;quot;reference
librarian&amp;quot; for the World Wide Web.
</bodyText>
<sectionHeader confidence="0.936894" genericHeader="method">
4 Representing Natural Language
</sectionHeader>
<bodyText confidence="0.9863112">
A good representational structure for natural lan-
guage is ternary expressions.&apos; They may be in-
tuitively viewed as subject-relation-object triples,
and can express most types of syntactic relations
between various entities within a sentence. We be-
lieve that the expressiveness of ternary relations
is adequate for capturing the information need of
users and the meaning of annotations. For ex-
ample, &amp;quot;What is the population of Zimbabwe?&amp;quot;
would be represented as two ternary expressions:
[what is population]
[population of Zimbabwe]
Ternary expressions can capture many rela-
tionships between entities within a sentence.
Such a representational structure is better than
a keyword-based scheme which equates a doc-
ument&apos;s keyword statistics with its semantic
content. Consider the following sets of sen-
tences/phrases that have similar word content,
but (dramatically) different meanings:3
</bodyText>
<listItem confidence="0.905906">
(1) The bird ate the young snake.
(1&apos;) The snake ate the young bird.
(2) The meaning of life
(2&apos;) A meaningful life
(3) The bank of the river
(3&apos;) The bank near the river
</listItem>
<bodyText confidence="0.999730384615385">
Ternary expressions abstract away the linear or-
der of words in a sentence into a structure that is
closer to meaning, and therefore a relations-based
information access system will produce much more
precise results.
We have conducted some initial information re-
trieval experiments comparing a keyword-based
approach with one that performs matching based
on relations4. Using Minipar (Lin, 1999), we
parsed the entire contents of the Worldbook En-
cyclopedia and extracted salient relations from
it (e.g., subject-verb-object, possessives, prepo-
sitional phrase, etc.) We found that precision
</bodyText>
<footnote confidence="0.86569325">
2See (Katz, 1990; Katz, 1997) for details about
such representation in START.
3Examples taken from (Loper, 2000)
Oto be published
</footnote>
<bodyText confidence="0.762082">
for relations-based retrieval was much higher than
for keyword-based retrieval. In one test, retrieval
based on relations returned the database&apos;s three
correct entries:
Question: What do frogs eat?
Answer:
(R1) Adult frogs eat mainly insects and
other small animals, including earthworms,
minnows, and spiders.
(R4) One group of South American frogs
feeds mainly on other frogs.
(R6) Frogs eat many other animals, includ-
ing spiders, flies, and worms.
compared to 33 results containing the keywords
frog and eat which were returned by the keyword-
based system the additional results all answer a
different question (&amp;quot;What eats frogs?&amp;quot;) or other-
wise coincidentally contain those two terms.
Question: What do frogs eat?
Answer:
. . .
</bodyText>
<listItem confidence="0.9876234375">
(R7) Adult frogs eat mainly insects and
other small animals, including earthworms,
minnows, and spiders.
(R8) Bowfins eat mainly other fish, frogs,
and crayfish.
(R9) Most cobras eat many kinds of animals,
such as frogs, fishes, birds, and various small
mammals.
(R10) One group of South American frogs
feeds mainly on other frogs.
(R11) Cranes eat a variety of foods, includ-
ing frogs, fishes, birds, and various small
mammals.
(R12) Frogs eat many other animals, includ-
ing spiders, flies, and worms.
(R13) ...
</listItem>
<bodyText confidence="0.999357333333334">
Another advantage of ternary expressions is
that it becomes easier to write explicit transfor-
mational rules that encode specific linguistic vari-
ations. These rules are capable of equating struc-
tures derived from different sentences with the
same meaning (to be discussed in detail later).
In addition to being adequately expressive for
our purposes, ternary expressions are also highly
amenable to rapid large-scale indexing and re-
trieval. This is an important quality because
a large question answering system could poten-
tially contain answers to millions of questions.
Thus, compactness of representation and effi-
ciency of retrieval become an important consid-
eration. Ternary expressions may be indexed and
retrieved efficiently because they may be viewed
using a relational model of data and manipulated
using relational databases.
</bodyText>
<sectionHeader confidence="0.859262" genericHeader="method">
5 Handling Linguistic Variation
</sectionHeader>
<bodyText confidence="0.978236">
Linguistic variation is the phenomenon in which
the same meaning can be expressed in a variety
of different ways. Consider these questions, which
ask for exactly the same item of information:
</bodyText>
<listItem confidence="0.999073666666667">
(4) What is the capital of Taiwan?
(5) What&apos;s the capital city of Taiwan?
(6) What is Taiwan&apos;s capital?
</listItem>
<bodyText confidence="0.987895333333333">
Linguistic variations can occur at all levels of
language; the examples above demonstrate lexical,
morphological and syntactic variations. Linguistic
variations may sometimes be quite complicated,
as in the following example, which demonstrates
verb argument alternation.5
</bodyText>
<listItem confidence="0.99086875">
(7) Whose declaration of guilt shocked the
country?
(8) Who shocked the country with his dec-
laration of guilt?
</listItem>
<bodyText confidence="0.999399285714286">
Transformational rules provide a mechanism to
explicitly equate alternate realizations of the same
meaning at the level of ternary expressions.
As an example, Figure 1 shows a sample trans-
formational rule for (7) and (8).6 Thus, through
application of this rule, question (7) can be
equated with question (8).
</bodyText>
<equation confidence="0.769534">
[n1 shock na] [n3 shock na]
[shock with n3] H
[n3 related-to n1] [n3 related-to n1]
</equation>
<bodyText confidence="0.670633">
where n E Nouns where n E Nouns
</bodyText>
<figureCaption confidence="0.999027">
Figure 1: Sample Transformational Rule
</figureCaption>
<bodyText confidence="0.999751111111111">
Transformational rules may be generalized by
associating arbitrary conditions with them; e.g.,
verb E shock, surprise, excite . . .
A general observation about English verbs is
that they divide into &amp;quot;classes,&amp;quot; where verbs in
the same class undergo the same alternations.
For example, the verbs `shock&apos;, `surprise&apos;, `excite&apos;,
etc., participate in the alternation shown in Sen-
tence (7) and (8) not by coincidence, but because
</bodyText>
<footnote confidence="0.992518285714286">
513eth Levin (Levin, 1993) offers an excellent treat-
ment on English verb classes and verb argument al-
ternations.
6This rule is bidirectional in the sense that each
side of the rule implies the other side. The rule is
actually used in only one direction, so that we canon-
icalize the representation.
</footnote>
<bodyText confidence="0.997232777777778">
they share certain semantic qualities. Although
the transformational rule required to handle this
alternation is very specific (in that it applies to a
very specific pattern of ternary expression struc-
ture), the rule can nevertheless be generalized over
all verbs in the same class by associating with the
rule conditions that must be met for the rule to
fire, i.e., verb E emotional-reaction-verbs; see Fig-
ure 2.
</bodyText>
<equation confidence="0.877060666666667">
[n1 v1 na] [n3 v1 na]
[v1 with n3] H
[n3 related-to n1] [n3 related-to n1]
</equation>
<bodyText confidence="0.45486">
where n E Nouns and v E emotional-reaction-verbs
</bodyText>
<figureCaption confidence="0.996824">
Figure 2: Sample Transformational Rule
</figureCaption>
<bodyText confidence="0.999905090909091">
Note that transformational rules can also en-
code semantic knowledge and even elements of
common sense. For example, a rule can be written
that equates a selling action with a buying action
(with verb arguments in different positions). Or
as another example, rules can even encode impli-
catures, e.g., A murdered B implies that B is dead.
Transformational rules can apply at the syntac-
tic, semantic, or even pragmatic levels, and offer
a convenient, powerful, and expressive framework
for handling linguistic variations.
In order for a question answering system to be
successful and have adequate linguistic coverage,
it must have a large number of these rules. A lexi-
con which classified verbs by argument alternation
patterns would be a good start, but this is another
resource lacking in the world today. Rules gener-
ally may be quite complex, and it would be diffi-
cult to gather such knowledge from average Web
users with little linguistic background. Requesting
that users describe segments with multiple anno-
tations (each representing a different phrasing of
the description), might serve as a preliminary so-
lution to the linguistic variation problem. Another
possible solution will involve learning transforma-
tional rules from a corpus. The difficulty in cre-
ating transformational rules is a serious problem
and unless and until this problem is solved, an
NL-based QA system would have to be restricted
to a limited domain where a small number of ex-
perts could provide enough transformational rule
coverage, or would require a large commitment of
resources to attain sufficient coverage.
</bodyText>
<page confidence="0.450369">
6 Collaboration on the Web
</page>
<bodyText confidence="0.999301236363636">
A critical component of a successful natural lan-
guage question answering system is the knowledge
base itself. Although the annotation mechanism
simplifies the task of building a knowledge base,
the accumulation of knowledge is nevertheless a
time consuming and labor intensive task. How-
ever, due to the simplicity of natural language an-
notations (i.e., describing knowledge in everyday
English), ordinary users with no technical skills
may contribute to a knowledge base. Thus, by
providing a general framework in which people on
the World Wide Web can enter additional knowl-
edge, we can engage millions of potential users all
over the world to collaboratively construct a ques-
tion answering system. We can distribute the ef-
fort of building a knowledge base across many or-
dinary users by allowing them to teach the system
new knowledge.
The idea of using the Internet as a tool for
collaboration across geographically distributed re-
gions is not a new idea. The Open Source move-
ment first demonstrated the effectiveness and sus-
tainability of programming computer systems in
a distributed manner. Made possible in part by
the World Wide Web, the Open Source move-
ment promotes software development by nurtur-
ing a community of individual contributors work-
ing on freely distributed source code. Under this
development model, software reliability and qual-
ity is ensured through independent peer review by
a large number of programmers. Successful Open
Source projects include Linux, a popular Unix-like
operating system; Apache, the most popular Web
server in the World; SendMail, an utility on vir-
tually every Unix machine; and dmoz, the Open
Directory Project, whose goal is to produce the
most comprehensive directory of the Web by rely-
ing on volunteer editors.?
Another example of Web-based collaboration
is the Open Mind Initiative (Stork, 1999; Stork,
2000), which is a recent effort to organize ordi-
nary users on the World Wide Web (netizens) to
assist in developing intelligent software. Based on
the observation that many tasks such as speech
recognition and character recognition require vast
quantities of training data, the initiative attempts
to provide a collaborate framework for collecting
data from the World Wide Web. The three pri-
mary contributors within such a framework are
domain experts, who provide fundamental algo-
rithms, tool/infrastructure developers, who de-
velop the framework for capturing data, and non-
expert netizens, who supply the raw training data.
Open Mind Commonsense8 is an attempt at
constructing a large common sense database by
</bodyText>
<footnote confidence="0.9979045">
7http://www.dmoz.org
8http://openmind.media.mit.edu
</footnote>
<bodyText confidence="0.99961855319149">
collecting assertions from users all over the Web.9
Other projects have demonstrated the viabil-
ity of Web-enabled collaborative problem-solving
by harnessing the computational power of idle
processors connected to the Web.10 The SETI
(Search for Extraterrestrial Intelligence) Institute
was founded after NASA canceled its High Resolu-
tion Microwave Survey project. The institute or-
ganizes thousands of individuals who donate their
idle processor cycles to search small segments of
radio telescope logs for signs of extraterrestrial
intelligence.11 Other similar projects that orga-
nize the usage of idle processor time on personal
computers include the Internet Mersenne Prime
Search,12 and the RC5 Challenge.13
Recent technical, social, and economic devel-
opments have made the abovementioned models
of collaboration possible. Furthermore, numerous
successful projects have already demonstrated the
effectiveness of these collaborative models. Thus,
it is time to capitalize on these emerging trends
to create the first collaborative question answer-
ing system on the World Wide Web.
Even with the components such as those de-
scribed above, there still remains a major hurdle
in jumpstarting the construction of a collaborative
question answering system. We are faced with a
classic chicken-and-egg problem: in order to at-
tract users to contribute knowledge, the system
must serve a real information need (i.e., actually
provide users with answers). However, in order
to serve user information needs, the system needs
knowledge, which must be contributed by users.
In the initial stages of building a question an-
swering system, the knowledge base will be too
sparse to be useful. Furthermore, the system may
be very brittle, and might not retrieve the correct
information segment, even if it did exist within
the knowledge base (e.g., due to a missing trans-
formational rule).
It may be possible to address this dilemma with
an incremental approach. The system can first
be restricted to a very limited domain (e.g., &amp;quot;an-
imals&amp;quot; or &amp;quot;geography&amp;quot;). Users&apos; expectations will
be carefully managed so that they realize the sys-
tem is highly experimental and has a very lim-
ited range of knowledge. In effect, the users will
</bodyText>
<footnote confidence="0.868896222222222">
9A non-collaborative approach to building a com-
mon sense knowledge base is taken by Lenat whose
Cyc project (Lenat, 1995) is an attempt to build a
common sense knowledge base through a small team
of dedicated and highly trained specialists.
10http://www.distributed.org
11http://setiathome.ssl.berkeley.edu
12http://www.mersenne.org
13http://www.distributed.org/rc5/
</footnote>
<bodyText confidence="0.9990469">
be populating a domain-specific knowledge base.
Over time, the system will be able to answer more
and more questions in that domain, and hence be-
gin to offer interesting answers to real users. After
this, a critical mass will form so that users are not
only teaching the system new knowledge, but also
receiving high quality answers to their questions.
At that point, a decision can be made to increase
the domain coverage of the system.
In order to initialize this process, we can boot-
strap off the curiosity and altruism of individual
users. As an example, the Openmind Common
Sense project has accumulated over 280 thousand
items of information by over six thousand users
based on a data collection model that does not
supply the user with any useful service. The
dream of building &amp;quot;smart&amp;quot; systems has always
been a fascination in our culture (e.g., HAL from
2001: A Space Odyssey); we believe that this will
serve to attract first-time users.
</bodyText>
<sectionHeader confidence="0.837142" genericHeader="method">
7 Evolving the System
</sectionHeader>
<bodyText confidence="0.999977815789474">
While the collaborative information gathering
task proceeds, we are then faced with the prob-
lem of maintaining the system and ensuring that
it will provide users with useful information. Two
immediate issues arise: quality control and lin-
guistic variation.
How can we insure the quality of the contributed
material? In general, any system that solicits in-
formation from the World Wide Web faces a prob-
lem of quality control and moderation. Although
most Web users are well-meaning, a small frac-
tion of Web users may have malicious intentions.
Therefore, some filtering mechanisms must be im-
plemented to exclude inappropriate content (e.g.,
pornography or commercial advertisement) from
being inserted into the knowledge base. More
troublesome is the possibility of well-meant but
incorrect information which is probably more com-
mon and definitely harder to detect.
How can we handle linguistic variation? There
are often different ways of asking the same ques-
tion; the annotation of a particular segment might
not match the user query, and hence the correct
answer may not be returned as a result. Transfor-
mational rules may be a solution to the problem,
but writing and compiling these rules remain a
difficult problem.
We propose a variety of solutions for the main-
tenance of a collaborative question answering sys-
tem, depending on the level of human intervention
and supervision.
At one end of the spectrum, an unsupervised
approach to quality control can be implemented
through a distributed system of moderation with
different trust levels. The scheme essentially calls
for self-management of the knowledge repository
by the users themselves (i.e., the users with high
trust levels). Different trust levels will allow users
various levels of access to the knowledge base, e.g.,
the ability to modify or delete information seg-
ments and their associated annotations or to mod-
ify other users&apos; trust levels. To initiate the process,
only a small group of core editors is required.
In such an unsupervised system, the problem of
linguistic variation could be addressed by prompt-
ing users to give multiple annotations, each de-
scribing the information content of a particular
segment in a different way. With a sufficiently
large user base, wide coverage might still be
achieved in the absence of broad-coverage trans-
formational rules.
At the other end of the spectrum, a large or-
ganization may commit significant amounts of re-
sources to maintaining a supervised collaborative
knowledge base. For example, an organization
may be willing to commit resources to preserve
its organizational memory in the form of an &amp;quot;in-
telligent FAQ&amp;quot; supported by natural language an-
notations. Computers can be effectively utilized
to augment the memory of an organization (Allen,
1977), and have been successfully deployed in real-
world environments with relative success (Acker-
man, 1998).
If an organization were willing to commit signifi-
cant resources to a collaborative knowledge reposi-
tory, then transformational rules can be written by
experts with linguistic background. Such experts
could constantly review the annotations entered
by ordinary users and formulate transformational
rules to capture generalizations.
Supervised use of natural language annotation
falls short of the grandiose goal of accessing the
entire World Wide Web, but is the practical and
useful way to apply NL annotation until the trans-
formational rule problem can be solved for unlim-
ited domains.
</bodyText>
<sectionHeader confidence="0.992513" genericHeader="method">
8 Initial Prototype
</sectionHeader>
<bodyText confidence="0.999982672413793">
Webnotator is a prototype test-bed to evaluate
the practicality of NL-based annotation and re-
trieval through Web-based collaboration. It pro-
vides efficient facilities for retrieving answers al-
ready stored within the knowledge base and a scal-
able framework for ordinary users to contribute
knowledge.
The system analyzes natural language annota-
tions to produce ternary expressions by postpro-
cessing the results of Minipar (Lin, 1993; Lin,
1994), a fast and robust functional dependency
parser that is freely available for non-commercial
purposes. The quality of the representational
structures depends ultimately on the quality of
whatever parser Webnotator is made to access. In
the current implementation, ternary expressions
are not embedded, elements of ternary expres-
sions are not indexed, and coreference is not de-
tected. Words are stemmed to their root form and
morphological information is discarded. The sys-
tem also implements a version of transformational
rules described above as a simple forward-chaining
rule-based system.
Using a relational database, Webnotator imple-
ments a knowledge base that stores ternary ex-
pressions derived from annotations and their asso-
ciated information segments. Ternary expressions
fit neatly into a relational model of data, and thus
manipulation of the knowledge (including answer-
ing queries and inserting new knowledge) can be
formulated as SQL queries. This vastly simplifies
development efforts while maintaining robustness
and performance.
Webnotator provides an interface through
which users may teach the system new knowl-
edge by supplying new information segments and
adding new annotations. Essentially, the user en-
ters, in a CGI form, an information segment and
annotations that describe the knowledge. Since
the segment of information can contain any valid
HTML, images, tables, and even multimedia con-
tent may be included. Alternatively, the user may
simply provide a URL to annotate, and Webnota-
tor will automatically create a link to the URL in
its knowledge base.
Currently, Webnotator is a prototype that has
been released to a small community of developers
and testers within the MIT Artificial Intelligence
Laboratory. We plan on releasing the system to
the general public in the near future. By col-
lecting knowledge from the general public and by
varying the representations and transformations
applied by Webnotator, it should be possible to
discover which features are most important for
a natural-language-based annotation system and
whether the state of the art is indeed sufficiently
advanced to make such a system practical and ef-
fective.
</bodyText>
<sectionHeader confidence="0.999091" genericHeader="related work">
9 Related Work
</sectionHeader>
<bodyText confidence="0.999995029850746">
A variety of research has been conducted on bet-
ter information access methods on the World
Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (Berners-
Lee, 1999)). However, most of these approaches
have concentrated on methods of annotating exist-
ing web pages with metadata such as XML/RDF
(Resource Description Framework) (Staab et al.,
2000), extensions to HTML (Luke et al., 1997;
Heflin et al., 1999; Staab et al., 2000), special-
ized descriptions (W. Dalitz and Lugger, 1997),
or even conceptual graphs (Martin and Eklund,
1999).
The common thread among previous work is the
embedding of metadata directly into Web docu-
ments, which are then gathered via crawling or
spidering. This approach only works if the target
community of the system is well-defined; adop-
tion of various metadata techniques are presently
limited, and thus it would be pointless to crawl
the entire web to search for metadata. A model
in which distributed metadata are gathered by a
spider will not work with a constantly changing
community that is ill-defined. In principle, there
is no reason why our natural language annotations
cannot be embedded into Web documents also; the
issue is strictly a practical concern.
Another common theme in previous work is
the organization of knowledge in accordance with
some pre-established ontology. This presents sev-
eral challenges for building a general system for
gathering knowledge. Ontologies are often ei-
ther too specific to be of general use (e.g., Ri-
boWeb&apos;s ontology for ribosome data (Altmann et
al., 1999)), or too weak to provide much structure
(e.g., Yahoo). Since the ontology is static and
must be agreed upon prior to any knowledge base
development, it may be too constricting and too
inconvenient for the expression of new or unantic-
ipated concepts. Although systems do allow for
arbitrary extension of the ontology (Heflin et al.,
1999; Staab et al., 2000), such extensions defeat
the purpose of a structure-imposing ontology. Our
proposed alternative to a ontological hierarchy is
to take advantage of the expressiveness of natu-
ral language, and use linguistic devices to relate
concepts. The combination of lexical resources
(e.g., synonyms and meronyms in WordNet) and
transformational rules provide a natural, extensi-
ble way to relate and structure different concepts.
A compelling argument for natural language an-
notations is their expressiveness and compactness.
Martin and Eklund (Martin and Eklund, 1999) ar-
gue against an XML-based system of metadata be-
cause XML was primarily intended to be machine
readable, not human readable. In their paper,
they started with an English phrase, and then pro-
ceeded to demonstrate the encoding of that sen-
tence in various formalisms. A constraint graph
encoding was simpler than a KIF (Knowledge In-
terchange Format) encoding, which was in turn
shorter than a RDF format. Of course, this begs
the question: why not just annotate the document
with the original English phrase? Current NLP
technology can handle a large variety of English
sentences and phrases, which may serve as the
annotations directly. Such is system is not only
simpler, more intuitive, but also more compact.
</bodyText>
<sectionHeader confidence="0.994348" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.9999241875">
Recent social, technical, and economic develop-
ments have made possible a new paradigm of soft-
ware development and problem solving through
loosely-organized collaboration of individuals on
the World Wide Web. Many successful prece-
dents have already proven the viability of this ap-
proach. By leveraging this trend with existing an-
notation and natural language technology, we can
provide a flexible framework for a question an-
swering system that grows and &amp;quot;evolves&amp;quot; as each
user contributes to the knowledge base, with only
minimal outside supervision. Testing will reveal
whether such a system can help users realize some
of the untapped potential of the World Wide Web
and other sources of digital information as a vast
repository of human knowledge.
</bodyText>
<sectionHeader confidence="0.998082" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999650202702703">
Mark S. Ackerman. 1998. Augmenting organi-
zational memory: A field study of answer gar-
den. ACM Transactions on Information Sys-
tems, 16(3):203-224, July.
Thomas Allen. 1977. Managing the Flow of Tech-
nology. MIT Press.
R. Altmann, M. Bada, X. Chai, M. W. Car-
illo, R. Chen, and N. Abernethy. 1999. Ri-
boWeb: An ontology-based system for collabo-
rative molecular biology. IEEE Intelligent Sys-
tems, 14(5):68-76.
T. Berners-Lee. 1999. Weaving the Web. Harper,
New York.
Jeff Heflin, James Hendler, and Sean Luke. 1999.
SHOE: A knowledge representation language
for internet applications. Technical Report
CS-TR-4078, Institute of Advanced Computer
Studies, University of Maryland, College Park.
Boris Katz. 1990. Using English for indexing and
retrieving. In P.H. Winston and S.A. Shellard,
editors, Artificial Intelligence at MIT: Expand-
ing Frontiers, volume 1. MIT Press.
Boris Katz. 1997. Annotating the World Wide
Web using natural language. In Proceedings of
the 5th RIAO Conference on Computer Assisted
Information Searching on the Internet (RIAO
&apos;97).
Doug Lenat. 1995. CYC: A large-scale investment
in knowledge infrastructure. Communications
of the ACM, 38(11):33-38.
Beth Levin. 1993. English Verb Classes and Al-
ternations: A Preliminary Investigation. Uni-
versity of Chicago Press.
Dekang Lin. 1993. Principled-based parsing with-
out overgeneration. In Proceedings of the 31th
Annual Meeting of the Association for Compu-
tational Linguistics (ACL&apos;93).
Dekang Lin. 1994. PRINCIPAR An efficient,
broad-coverage, principle-based parser. In Pro-
ceedings of the 15th International Conference on
Computational Linguistics (COLING &apos;94).
Dekang Lin. 1999. Minipar a minimalist parser.
In Maryland Linguistics Colloquium, University
of Maryland, College Park, March 12,.
Edward Loper. 2000. Applying semantic relation
extraction to information retrieval. Master&apos;s
thesis, Massachusetts Institute of Technology.
S. Luke, L. Spector, D. Rager, and J. Hendler.
1997. Ontology-based web agents. In Proceed-
ings of the First International Conference on
Autonomous Agents.
Philippe Martin and Peter Eklund. 1999. Em-
bedding knowledge in web documents. In Pro-
ceedings of the Eighth International World Wide
Web Conference.
S. Staab, J. Angele, S. Decker, M. Erd-
mann, A. Hotho, A. Maedche, H.-P. Schnurr,
R. Studer, and Y. Sure. 2000. Semantic com-
munity web portals. In Proceedings of the Ninth
International World Wide Web Conference.
David G. Stork. 1999. Character and document
research in the open mind initiative. In Pro-
ceedings of the Fifth International Conference
on Document Analysis and Recognition.
David G. Stork. 2000. Open data collection for
training intelligent software in the open mind
initiative. In Proceedings of the Engineering In-
telligent Systems Symposium (EIS &apos;2000).
M. Grotschel W. Dalitz and J. Lugger. 1997.
Information services for mathematics and the
internet. In A. Sydow, editor, Proceedings of
the 15th IMACS World Congress on Scientific
Computation: Modelling and Applied Mathe-
matics. Wissenschaft und Technik Verlag.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916231">
<title confidence="0.9997285">Gathering Knowledge for a Question Answering System Heterogeneous Information Sources</title>
<author confidence="0.999895">Katz Lin</author>
<affiliation confidence="0.980087">MIT Artificial Intelligence</affiliation>
<address confidence="0.9780195">200 Technology Cambridge, MA</address>
<email confidence="0.980486">jimmylin,</email>
<abstract confidence="0.999747428571429">Although vast amounts of information are available electronically today, no effective information access mechanism exists to provide humans with convenient information access. A general, opendomain question answering system is a solution to this problem. We propose an architecture for a collaborative question answering system that contains four primary components: an annotations system for storing knowledge, a ternary expression representation of language, a transformational rule system for handling some complexities of language, and a collaborative mechanism by which ordinary users can contribute new knowledge by teaching the system new information. We have developed a initial prototype, called Webnotator, with which to test these ideas.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mark S Ackerman</author>
</authors>
<title>Augmenting organizational memory: A field study of answer garden.</title>
<date>1998</date>
<journal>ACM Transactions on Information Systems,</journal>
<pages>16--3</pages>
<contexts>
<context position="25553" citStr="Ackerman, 1998" startWordPosition="3984" endWordPosition="3986">e might still be achieved in the absence of broad-coverage transformational rules. At the other end of the spectrum, a large organization may commit significant amounts of resources to maintaining a supervised collaborative knowledge base. For example, an organization may be willing to commit resources to preserve its organizational memory in the form of an &amp;quot;intelligent FAQ&amp;quot; supported by natural language annotations. Computers can be effectively utilized to augment the memory of an organization (Allen, 1977), and have been successfully deployed in realworld environments with relative success (Ackerman, 1998). If an organization were willing to commit significant resources to a collaborative knowledge repository, then transformational rules can be written by experts with linguistic background. Such experts could constantly review the annotations entered by ordinary users and formulate transformational rules to capture generalizations. Supervised use of natural language annotation falls short of the grandiose goal of accessing the entire World Wide Web, but is the practical and useful way to apply NL annotation until the transformational rule problem can be solved for unlimited domains. 8 Initial P</context>
</contexts>
<marker>Ackerman, 1998</marker>
<rawString>Mark S. Ackerman. 1998. Augmenting organizational memory: A field study of answer garden. ACM Transactions on Information Systems, 16(3):203-224, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Allen</author>
</authors>
<title>Managing the Flow of Technology.</title>
<date>1977</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="25451" citStr="Allen, 1977" startWordPosition="3970" endWordPosition="3971">ntent of a particular segment in a different way. With a sufficiently large user base, wide coverage might still be achieved in the absence of broad-coverage transformational rules. At the other end of the spectrum, a large organization may commit significant amounts of resources to maintaining a supervised collaborative knowledge base. For example, an organization may be willing to commit resources to preserve its organizational memory in the form of an &amp;quot;intelligent FAQ&amp;quot; supported by natural language annotations. Computers can be effectively utilized to augment the memory of an organization (Allen, 1977), and have been successfully deployed in realworld environments with relative success (Ackerman, 1998). If an organization were willing to commit significant resources to a collaborative knowledge repository, then transformational rules can be written by experts with linguistic background. Such experts could constantly review the annotations entered by ordinary users and formulate transformational rules to capture generalizations. Supervised use of natural language annotation falls short of the grandiose goal of accessing the entire World Wide Web, but is the practical and useful way to apply </context>
</contexts>
<marker>Allen, 1977</marker>
<rawString>Thomas Allen. 1977. Managing the Flow of Technology. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Altmann</author>
<author>M Bada</author>
<author>X Chai</author>
<author>M W Carillo</author>
<author>R Chen</author>
<author>N Abernethy</author>
</authors>
<title>RiboWeb: An ontology-based system for collaborative molecular biology.</title>
<date>1999</date>
<journal>IEEE Intelligent Systems,</journal>
<pages>14--5</pages>
<contexts>
<context position="30297" citStr="Altmann et al., 1999" startWordPosition="4714" endWordPosition="4717">in which distributed metadata are gathered by a spider will not work with a constantly changing community that is ill-defined. In principle, there is no reason why our natural language annotations cannot be embedded into Web documents also; the issue is strictly a practical concern. Another common theme in previous work is the organization of knowledge in accordance with some pre-established ontology. This presents several challenges for building a general system for gathering knowledge. Ontologies are often either too specific to be of general use (e.g., RiboWeb&apos;s ontology for ribosome data (Altmann et al., 1999)), or too weak to provide much structure (e.g., Yahoo). Since the ontology is static and must be agreed upon prior to any knowledge base development, it may be too constricting and too inconvenient for the expression of new or unanticipated concepts. Although systems do allow for arbitrary extension of the ontology (Heflin et al., 1999; Staab et al., 2000), such extensions defeat the purpose of a structure-imposing ontology. Our proposed alternative to a ontological hierarchy is to take advantage of the expressiveness of natural language, and use linguistic devices to relate concepts. The comb</context>
</contexts>
<marker>Altmann, Bada, Chai, Carillo, Chen, Abernethy, 1999</marker>
<rawString>R. Altmann, M. Bada, X. Chai, M. W. Carillo, R. Chen, and N. Abernethy. 1999. RiboWeb: An ontology-based system for collaborative molecular biology. IEEE Intelligent Systems, 14(5):68-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Berners-Lee</author>
</authors>
<title>Weaving the Web.</title>
<date>1999</date>
<publisher>Harper,</publisher>
<location>New York.</location>
<marker>Berners-Lee, 1999</marker>
<rawString>T. Berners-Lee. 1999. Weaving the Web. Harper, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Heflin</author>
<author>James Hendler</author>
<author>Sean Luke</author>
</authors>
<title>SHOE: A knowledge representation language for internet applications.</title>
<date>1999</date>
<tech>Technical Report CS-TR-4078,</tech>
<institution>Institute of Advanced Computer Studies, University of Maryland, College Park.</institution>
<contexts>
<context position="29168" citStr="Heflin et al., 1999" startWordPosition="4533" endWordPosition="4536"> be possible to discover which features are most important for a natural-language-based annotation system and whether the state of the art is indeed sufficiently advanced to make such a system practical and effective. 9 Related Work A variety of research has been conducted on better information access methods on the World Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (BernersLee, 1999)). However, most of these approaches have concentrated on methods of annotating existing web pages with metadata such as XML/RDF (Resource Description Framework) (Staab et al., 2000), extensions to HTML (Luke et al., 1997; Heflin et al., 1999; Staab et al., 2000), specialized descriptions (W. Dalitz and Lugger, 1997), or even conceptual graphs (Martin and Eklund, 1999). The common thread among previous work is the embedding of metadata directly into Web documents, which are then gathered via crawling or spidering. This approach only works if the target community of the system is well-defined; adoption of various metadata techniques are presently limited, and thus it would be pointless to crawl the entire web to search for metadata. A model in which distributed metadata are gathered by a spider will not work with a constantly chang</context>
<context position="30634" citStr="Heflin et al., 1999" startWordPosition="4770" endWordPosition="4773">on of knowledge in accordance with some pre-established ontology. This presents several challenges for building a general system for gathering knowledge. Ontologies are often either too specific to be of general use (e.g., RiboWeb&apos;s ontology for ribosome data (Altmann et al., 1999)), or too weak to provide much structure (e.g., Yahoo). Since the ontology is static and must be agreed upon prior to any knowledge base development, it may be too constricting and too inconvenient for the expression of new or unanticipated concepts. Although systems do allow for arbitrary extension of the ontology (Heflin et al., 1999; Staab et al., 2000), such extensions defeat the purpose of a structure-imposing ontology. Our proposed alternative to a ontological hierarchy is to take advantage of the expressiveness of natural language, and use linguistic devices to relate concepts. The combination of lexical resources (e.g., synonyms and meronyms in WordNet) and transformational rules provide a natural, extensible way to relate and structure different concepts. A compelling argument for natural language annotations is their expressiveness and compactness. Martin and Eklund (Martin and Eklund, 1999) argue against an XML-b</context>
</contexts>
<marker>Heflin, Hendler, Luke, 1999</marker>
<rawString>Jeff Heflin, James Hendler, and Sean Luke. 1999. SHOE: A knowledge representation language for internet applications. Technical Report CS-TR-4078, Institute of Advanced Computer Studies, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
</authors>
<title>Using English for indexing and retrieving.</title>
<date>1990</date>
<booktitle>Artificial Intelligence at MIT: Expanding Frontiers,</booktitle>
<volume>1</volume>
<editor>In P.H. Winston and S.A. Shellard, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3001" citStr="Katz, 1990" startWordPosition="463" endWordPosition="464">he only way for computers to access their own knowledge is for humans to tell the computers what the knowledge means in a language that the computers can understand but still in a language that humans can produce. A good way to accomplish this is with the use of natural language annotations, sentences which are simple enough for a computer to analyze, yet which are in natural human language. Once knowledge is so annotated, and indexed in a knowledge repository, a question answering system can retrieve it. The START (SynTactic Analysis using Reversible Transformations) Natural Language System (Katz, 1990; Katz, 1997) is an example of a question answering system that uses natural language annotations. START is a natural language question answering system that has been available to users on the World Wide Web&apos; since December, 1993. During this time, it has engaged in millions of exchanges with hundreds of thousands of people all over the world, supplying users with knowledge regarding geography, weather, movies, corporations, and many many other areas. Despite the success of START in serving real users, its domain of expertise is relatively small and expanding its knowledge base is a time-consu</context>
<context position="10241" citStr="Katz, 1990" startWordPosition="1581" endWordPosition="1582">iver Ternary expressions abstract away the linear order of words in a sentence into a structure that is closer to meaning, and therefore a relations-based information access system will produce much more precise results. We have conducted some initial information retrieval experiments comparing a keyword-based approach with one that performs matching based on relations4. Using Minipar (Lin, 1999), we parsed the entire contents of the Worldbook Encyclopedia and extracted salient relations from it (e.g., subject-verb-object, possessives, prepositional phrase, etc.) We found that precision 2See (Katz, 1990; Katz, 1997) for details about such representation in START. 3Examples taken from (Loper, 2000) Oto be published for relations-based retrieval was much higher than for keyword-based retrieval. In one test, retrieval based on relations returned the database&apos;s three correct entries: Question: What do frogs eat? Answer: (R1) Adult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders. (R4) One group of South American frogs feeds mainly on other frogs. (R6) Frogs eat many other animals, including spiders, flies, and worms. compared to 33 results containing t</context>
</contexts>
<marker>Katz, 1990</marker>
<rawString>Boris Katz. 1990. Using English for indexing and retrieving. In P.H. Winston and S.A. Shellard, editors, Artificial Intelligence at MIT: Expanding Frontiers, volume 1. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
</authors>
<title>Annotating the World Wide Web using natural language.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th RIAO Conference on Computer Assisted Information Searching on the Internet (RIAO &apos;97).</booktitle>
<contexts>
<context position="3014" citStr="Katz, 1997" startWordPosition="465" endWordPosition="466">for computers to access their own knowledge is for humans to tell the computers what the knowledge means in a language that the computers can understand but still in a language that humans can produce. A good way to accomplish this is with the use of natural language annotations, sentences which are simple enough for a computer to analyze, yet which are in natural human language. Once knowledge is so annotated, and indexed in a knowledge repository, a question answering system can retrieve it. The START (SynTactic Analysis using Reversible Transformations) Natural Language System (Katz, 1990; Katz, 1997) is an example of a question answering system that uses natural language annotations. START is a natural language question answering system that has been available to users on the World Wide Web&apos; since December, 1993. During this time, it has engaged in millions of exchanges with hundreds of thousands of people all over the world, supplying users with knowledge regarding geography, weather, movies, corporations, and many many other areas. Despite the success of START in serving real users, its domain of expertise is relatively small and expanding its knowledge base is a time-consuming task tha</context>
<context position="10254" citStr="Katz, 1997" startWordPosition="1583" endWordPosition="1584"> expressions abstract away the linear order of words in a sentence into a structure that is closer to meaning, and therefore a relations-based information access system will produce much more precise results. We have conducted some initial information retrieval experiments comparing a keyword-based approach with one that performs matching based on relations4. Using Minipar (Lin, 1999), we parsed the entire contents of the Worldbook Encyclopedia and extracted salient relations from it (e.g., subject-verb-object, possessives, prepositional phrase, etc.) We found that precision 2See (Katz, 1990; Katz, 1997) for details about such representation in START. 3Examples taken from (Loper, 2000) Oto be published for relations-based retrieval was much higher than for keyword-based retrieval. In one test, retrieval based on relations returned the database&apos;s three correct entries: Question: What do frogs eat? Answer: (R1) Adult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders. (R4) One group of South American frogs feeds mainly on other frogs. (R6) Frogs eat many other animals, including spiders, flies, and worms. compared to 33 results containing the keywords f</context>
</contexts>
<marker>Katz, 1997</marker>
<rawString>Boris Katz. 1997. Annotating the World Wide Web using natural language. In Proceedings of the 5th RIAO Conference on Computer Assisted Information Searching on the Internet (RIAO &apos;97).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Lenat</author>
</authors>
<title>CYC: A large-scale investment in knowledge infrastructure.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<pages>38--11</pages>
<contexts>
<context position="21472" citStr="Lenat, 1995" startWordPosition="3342" endWordPosition="3343">e, and might not retrieve the correct information segment, even if it did exist within the knowledge base (e.g., due to a missing transformational rule). It may be possible to address this dilemma with an incremental approach. The system can first be restricted to a very limited domain (e.g., &amp;quot;animals&amp;quot; or &amp;quot;geography&amp;quot;). Users&apos; expectations will be carefully managed so that they realize the system is highly experimental and has a very limited range of knowledge. In effect, the users will 9A non-collaborative approach to building a common sense knowledge base is taken by Lenat whose Cyc project (Lenat, 1995) is an attempt to build a common sense knowledge base through a small team of dedicated and highly trained specialists. 10http://www.distributed.org 11http://setiathome.ssl.berkeley.edu 12http://www.mersenne.org 13http://www.distributed.org/rc5/ be populating a domain-specific knowledge base. Over time, the system will be able to answer more and more questions in that domain, and hence begin to offer interesting answers to real users. After this, a critical mass will form so that users are not only teaching the system new knowledge, but also receiving high quality answers to their questions. A</context>
</contexts>
<marker>Lenat, 1995</marker>
<rawString>Doug Lenat. 1995. CYC: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38(11):33-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="14058" citStr="Levin, 1993" startWordPosition="2175" endWordPosition="2176">n (8). [n1 shock na] [n3 shock na] [shock with n3] H [n3 related-to n1] [n3 related-to n1] where n E Nouns where n E Nouns Figure 1: Sample Transformational Rule Transformational rules may be generalized by associating arbitrary conditions with them; e.g., verb E shock, surprise, excite . . . A general observation about English verbs is that they divide into &amp;quot;classes,&amp;quot; where verbs in the same class undergo the same alternations. For example, the verbs `shock&apos;, `surprise&apos;, `excite&apos;, etc., participate in the alternation shown in Sentence (7) and (8) not by coincidence, but because 513eth Levin (Levin, 1993) offers an excellent treatment on English verb classes and verb argument alternations. 6This rule is bidirectional in the sense that each side of the rule implies the other side. The rule is actually used in only one direction, so that we canonicalize the representation. they share certain semantic qualities. Although the transformational rule required to handle this alternation is very specific (in that it applies to a very specific pattern of ternary expression structure), the rule can nevertheless be generalized over all verbs in the same class by associating with the rule conditions that m</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Principled-based parsing without overgeneration.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics (ACL&apos;93).</booktitle>
<contexts>
<context position="26593" citStr="Lin, 1993" startWordPosition="4140" endWordPosition="4141">ntire World Wide Web, but is the practical and useful way to apply NL annotation until the transformational rule problem can be solved for unlimited domains. 8 Initial Prototype Webnotator is a prototype test-bed to evaluate the practicality of NL-based annotation and retrieval through Web-based collaboration. It provides efficient facilities for retrieving answers already stored within the knowledge base and a scalable framework for ordinary users to contribute knowledge. The system analyzes natural language annotations to produce ternary expressions by postprocessing the results of Minipar (Lin, 1993; Lin, 1994), a fast and robust functional dependency parser that is freely available for non-commercial purposes. The quality of the representational structures depends ultimately on the quality of whatever parser Webnotator is made to access. In the current implementation, ternary expressions are not embedded, elements of ternary expressions are not indexed, and coreference is not detected. Words are stemmed to their root form and morphological information is discarded. The system also implements a version of transformational rules described above as a simple forward-chaining rule-based syst</context>
</contexts>
<marker>Lin, 1993</marker>
<rawString>Dekang Lin. 1993. Principled-based parsing without overgeneration. In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics (ACL&apos;93).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>PRINCIPAR An efficient, broad-coverage, principle-based parser.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94).</booktitle>
<contexts>
<context position="26605" citStr="Lin, 1994" startWordPosition="4142" endWordPosition="4143"> Wide Web, but is the practical and useful way to apply NL annotation until the transformational rule problem can be solved for unlimited domains. 8 Initial Prototype Webnotator is a prototype test-bed to evaluate the practicality of NL-based annotation and retrieval through Web-based collaboration. It provides efficient facilities for retrieving answers already stored within the knowledge base and a scalable framework for ordinary users to contribute knowledge. The system analyzes natural language annotations to produce ternary expressions by postprocessing the results of Minipar (Lin, 1993; Lin, 1994), a fast and robust functional dependency parser that is freely available for non-commercial purposes. The quality of the representational structures depends ultimately on the quality of whatever parser Webnotator is made to access. In the current implementation, ternary expressions are not embedded, elements of ternary expressions are not indexed, and coreference is not detected. Words are stemmed to their root form and morphological information is discarded. The system also implements a version of transformational rules described above as a simple forward-chaining rule-based system. Using a </context>
</contexts>
<marker>Lin, 1994</marker>
<rawString>Dekang Lin. 1994. PRINCIPAR An efficient, broad-coverage, principle-based parser. In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Minipar a minimalist parser. In</title>
<date>1999</date>
<institution>Maryland Linguistics Colloquium, University of Maryland, College Park,</institution>
<contexts>
<context position="10030" citStr="Lin, 1999" startWordPosition="1551" endWordPosition="1552">ent, but (dramatically) different meanings:3 (1) The bird ate the young snake. (1&apos;) The snake ate the young bird. (2) The meaning of life (2&apos;) A meaningful life (3) The bank of the river (3&apos;) The bank near the river Ternary expressions abstract away the linear order of words in a sentence into a structure that is closer to meaning, and therefore a relations-based information access system will produce much more precise results. We have conducted some initial information retrieval experiments comparing a keyword-based approach with one that performs matching based on relations4. Using Minipar (Lin, 1999), we parsed the entire contents of the Worldbook Encyclopedia and extracted salient relations from it (e.g., subject-verb-object, possessives, prepositional phrase, etc.) We found that precision 2See (Katz, 1990; Katz, 1997) for details about such representation in START. 3Examples taken from (Loper, 2000) Oto be published for relations-based retrieval was much higher than for keyword-based retrieval. In one test, retrieval based on relations returned the database&apos;s three correct entries: Question: What do frogs eat? Answer: (R1) Adult frogs eat mainly insects and other small animals, includin</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Minipar a minimalist parser. In Maryland Linguistics Colloquium, University of Maryland, College Park, March 12,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
</authors>
<title>Applying semantic relation extraction to information retrieval. Master&apos;s thesis,</title>
<date>2000</date>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="10337" citStr="Loper, 2000" startWordPosition="1595" endWordPosition="1596">e that is closer to meaning, and therefore a relations-based information access system will produce much more precise results. We have conducted some initial information retrieval experiments comparing a keyword-based approach with one that performs matching based on relations4. Using Minipar (Lin, 1999), we parsed the entire contents of the Worldbook Encyclopedia and extracted salient relations from it (e.g., subject-verb-object, possessives, prepositional phrase, etc.) We found that precision 2See (Katz, 1990; Katz, 1997) for details about such representation in START. 3Examples taken from (Loper, 2000) Oto be published for relations-based retrieval was much higher than for keyword-based retrieval. In one test, retrieval based on relations returned the database&apos;s three correct entries: Question: What do frogs eat? Answer: (R1) Adult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders. (R4) One group of South American frogs feeds mainly on other frogs. (R6) Frogs eat many other animals, including spiders, flies, and worms. compared to 33 results containing the keywords frog and eat which were returned by the keywordbased system the additional results a</context>
</contexts>
<marker>Loper, 2000</marker>
<rawString>Edward Loper. 2000. Applying semantic relation extraction to information retrieval. Master&apos;s thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Luke</author>
<author>L Spector</author>
<author>D Rager</author>
<author>J Hendler</author>
</authors>
<title>Ontology-based web agents.</title>
<date>1997</date>
<booktitle>In Proceedings of the First International Conference on Autonomous Agents.</booktitle>
<contexts>
<context position="29147" citStr="Luke et al., 1997" startWordPosition="4529" endWordPosition="4532">bnotator, it should be possible to discover which features are most important for a natural-language-based annotation system and whether the state of the art is indeed sufficiently advanced to make such a system practical and effective. 9 Related Work A variety of research has been conducted on better information access methods on the World Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (BernersLee, 1999)). However, most of these approaches have concentrated on methods of annotating existing web pages with metadata such as XML/RDF (Resource Description Framework) (Staab et al., 2000), extensions to HTML (Luke et al., 1997; Heflin et al., 1999; Staab et al., 2000), specialized descriptions (W. Dalitz and Lugger, 1997), or even conceptual graphs (Martin and Eklund, 1999). The common thread among previous work is the embedding of metadata directly into Web documents, which are then gathered via crawling or spidering. This approach only works if the target community of the system is well-defined; adoption of various metadata techniques are presently limited, and thus it would be pointless to crawl the entire web to search for metadata. A model in which distributed metadata are gathered by a spider will not work wi</context>
</contexts>
<marker>Luke, Spector, Rager, Hendler, 1997</marker>
<rawString>S. Luke, L. Spector, D. Rager, and J. Hendler. 1997. Ontology-based web agents. In Proceedings of the First International Conference on Autonomous Agents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Martin</author>
<author>Peter Eklund</author>
</authors>
<title>Embedding knowledge in web documents.</title>
<date>1999</date>
<booktitle>In Proceedings of the Eighth International World Wide Web Conference.</booktitle>
<contexts>
<context position="29297" citStr="Martin and Eklund, 1999" startWordPosition="4553" endWordPosition="4556">ate of the art is indeed sufficiently advanced to make such a system practical and effective. 9 Related Work A variety of research has been conducted on better information access methods on the World Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (BernersLee, 1999)). However, most of these approaches have concentrated on methods of annotating existing web pages with metadata such as XML/RDF (Resource Description Framework) (Staab et al., 2000), extensions to HTML (Luke et al., 1997; Heflin et al., 1999; Staab et al., 2000), specialized descriptions (W. Dalitz and Lugger, 1997), or even conceptual graphs (Martin and Eklund, 1999). The common thread among previous work is the embedding of metadata directly into Web documents, which are then gathered via crawling or spidering. This approach only works if the target community of the system is well-defined; adoption of various metadata techniques are presently limited, and thus it would be pointless to crawl the entire web to search for metadata. A model in which distributed metadata are gathered by a spider will not work with a constantly changing community that is ill-defined. In principle, there is no reason why our natural language annotations cannot be embedded into </context>
<context position="31211" citStr="Martin and Eklund, 1999" startWordPosition="4854" endWordPosition="4857"> extension of the ontology (Heflin et al., 1999; Staab et al., 2000), such extensions defeat the purpose of a structure-imposing ontology. Our proposed alternative to a ontological hierarchy is to take advantage of the expressiveness of natural language, and use linguistic devices to relate concepts. The combination of lexical resources (e.g., synonyms and meronyms in WordNet) and transformational rules provide a natural, extensible way to relate and structure different concepts. A compelling argument for natural language annotations is their expressiveness and compactness. Martin and Eklund (Martin and Eklund, 1999) argue against an XML-based system of metadata because XML was primarily intended to be machine readable, not human readable. In their paper, they started with an English phrase, and then proceeded to demonstrate the encoding of that sentence in various formalisms. A constraint graph encoding was simpler than a KIF (Knowledge Interchange Format) encoding, which was in turn shorter than a RDF format. Of course, this begs the question: why not just annotate the document with the original English phrase? Current NLP technology can handle a large variety of English sentences and phrases, which may</context>
</contexts>
<marker>Martin, Eklund, 1999</marker>
<rawString>Philippe Martin and Peter Eklund. 1999. Embedding knowledge in web documents. In Proceedings of the Eighth International World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Staab</author>
<author>J Angele</author>
<author>S Decker</author>
<author>M Erdmann</author>
<author>A Hotho</author>
<author>A Maedche</author>
<author>H-P Schnurr</author>
<author>R Studer</author>
<author>Y Sure</author>
</authors>
<title>Semantic community web portals.</title>
<date>2000</date>
<booktitle>In Proceedings of the Ninth International World Wide Web Conference.</booktitle>
<contexts>
<context position="29108" citStr="Staab et al., 2000" startWordPosition="4522" endWordPosition="4525">tations and transformations applied by Webnotator, it should be possible to discover which features are most important for a natural-language-based annotation system and whether the state of the art is indeed sufficiently advanced to make such a system practical and effective. 9 Related Work A variety of research has been conducted on better information access methods on the World Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (BernersLee, 1999)). However, most of these approaches have concentrated on methods of annotating existing web pages with metadata such as XML/RDF (Resource Description Framework) (Staab et al., 2000), extensions to HTML (Luke et al., 1997; Heflin et al., 1999; Staab et al., 2000), specialized descriptions (W. Dalitz and Lugger, 1997), or even conceptual graphs (Martin and Eklund, 1999). The common thread among previous work is the embedding of metadata directly into Web documents, which are then gathered via crawling or spidering. This approach only works if the target community of the system is well-defined; adoption of various metadata techniques are presently limited, and thus it would be pointless to crawl the entire web to search for metadata. A model in which distributed metadata ar</context>
<context position="30655" citStr="Staab et al., 2000" startWordPosition="4774" endWordPosition="4777">cordance with some pre-established ontology. This presents several challenges for building a general system for gathering knowledge. Ontologies are often either too specific to be of general use (e.g., RiboWeb&apos;s ontology for ribosome data (Altmann et al., 1999)), or too weak to provide much structure (e.g., Yahoo). Since the ontology is static and must be agreed upon prior to any knowledge base development, it may be too constricting and too inconvenient for the expression of new or unanticipated concepts. Although systems do allow for arbitrary extension of the ontology (Heflin et al., 1999; Staab et al., 2000), such extensions defeat the purpose of a structure-imposing ontology. Our proposed alternative to a ontological hierarchy is to take advantage of the expressiveness of natural language, and use linguistic devices to relate concepts. The combination of lexical resources (e.g., synonyms and meronyms in WordNet) and transformational rules provide a natural, extensible way to relate and structure different concepts. A compelling argument for natural language annotations is their expressiveness and compactness. Martin and Eklund (Martin and Eklund, 1999) argue against an XML-based system of metada</context>
</contexts>
<marker>Staab, Angele, Decker, Erdmann, Hotho, Maedche, Schnurr, Studer, Sure, 2000</marker>
<rawString>S. Staab, J. Angele, S. Decker, M. Erdmann, A. Hotho, A. Maedche, H.-P. Schnurr, R. Studer, and Y. Sure. 2000. Semantic community web portals. In Proceedings of the Ninth International World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Stork</author>
</authors>
<title>Character and document research in the open mind initiative.</title>
<date>1999</date>
<booktitle>In Proceedings of the Fifth International Conference on Document Analysis and Recognition.</booktitle>
<contexts>
<context position="18369" citStr="Stork, 1999" startWordPosition="2870" endWordPosition="2871">l contributors working on freely distributed source code. Under this development model, software reliability and quality is ensured through independent peer review by a large number of programmers. Successful Open Source projects include Linux, a popular Unix-like operating system; Apache, the most popular Web server in the World; SendMail, an utility on virtually every Unix machine; and dmoz, the Open Directory Project, whose goal is to produce the most comprehensive directory of the Web by relying on volunteer editors.? Another example of Web-based collaboration is the Open Mind Initiative (Stork, 1999; Stork, 2000), which is a recent effort to organize ordinary users on the World Wide Web (netizens) to assist in developing intelligent software. Based on the observation that many tasks such as speech recognition and character recognition require vast quantities of training data, the initiative attempts to provide a collaborate framework for collecting data from the World Wide Web. The three primary contributors within such a framework are domain experts, who provide fundamental algorithms, tool/infrastructure developers, who develop the framework for capturing data, and nonexpert netizens, </context>
</contexts>
<marker>Stork, 1999</marker>
<rawString>David G. Stork. 1999. Character and document research in the open mind initiative. In Proceedings of the Fifth International Conference on Document Analysis and Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Stork</author>
</authors>
<title>Open data collection for training intelligent software in the open mind initiative.</title>
<date>2000</date>
<booktitle>In Proceedings of the Engineering Intelligent Systems Symposium (EIS &apos;2000).</booktitle>
<contexts>
<context position="18383" citStr="Stork, 2000" startWordPosition="2872" endWordPosition="2873">s working on freely distributed source code. Under this development model, software reliability and quality is ensured through independent peer review by a large number of programmers. Successful Open Source projects include Linux, a popular Unix-like operating system; Apache, the most popular Web server in the World; SendMail, an utility on virtually every Unix machine; and dmoz, the Open Directory Project, whose goal is to produce the most comprehensive directory of the Web by relying on volunteer editors.? Another example of Web-based collaboration is the Open Mind Initiative (Stork, 1999; Stork, 2000), which is a recent effort to organize ordinary users on the World Wide Web (netizens) to assist in developing intelligent software. Based on the observation that many tasks such as speech recognition and character recognition require vast quantities of training data, the initiative attempts to provide a collaborate framework for collecting data from the World Wide Web. The three primary contributors within such a framework are domain experts, who provide fundamental algorithms, tool/infrastructure developers, who develop the framework for capturing data, and nonexpert netizens, who supply the</context>
</contexts>
<marker>Stork, 2000</marker>
<rawString>David G. Stork. 2000. Open data collection for training intelligent software in the open mind initiative. In Proceedings of the Engineering Intelligent Systems Symposium (EIS &apos;2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Grotschel W Dalitz</author>
<author>J Lugger</author>
</authors>
<title>Information services for mathematics and the internet.</title>
<date>1997</date>
<booktitle>Proceedings of the 15th IMACS World Congress on Scientific Computation: Modelling and Applied Mathematics. Wissenschaft und Technik Verlag.</booktitle>
<editor>In A. Sydow, editor,</editor>
<contexts>
<context position="29244" citStr="Dalitz and Lugger, 1997" startWordPosition="4545" endWordPosition="4548">l-language-based annotation system and whether the state of the art is indeed sufficiently advanced to make such a system practical and effective. 9 Related Work A variety of research has been conducted on better information access methods on the World Wide Web (e.g., the &amp;quot;Semantic Web&amp;quot; (BernersLee, 1999)). However, most of these approaches have concentrated on methods of annotating existing web pages with metadata such as XML/RDF (Resource Description Framework) (Staab et al., 2000), extensions to HTML (Luke et al., 1997; Heflin et al., 1999; Staab et al., 2000), specialized descriptions (W. Dalitz and Lugger, 1997), or even conceptual graphs (Martin and Eklund, 1999). The common thread among previous work is the embedding of metadata directly into Web documents, which are then gathered via crawling or spidering. This approach only works if the target community of the system is well-defined; adoption of various metadata techniques are presently limited, and thus it would be pointless to crawl the entire web to search for metadata. A model in which distributed metadata are gathered by a spider will not work with a constantly changing community that is ill-defined. In principle, there is no reason why our </context>
</contexts>
<marker>Dalitz, Lugger, 1997</marker>
<rawString>M. Grotschel W. Dalitz and J. Lugger. 1997. Information services for mathematics and the internet. In A. Sydow, editor, Proceedings of the 15th IMACS World Congress on Scientific Computation: Modelling and Applied Mathematics. Wissenschaft und Technik Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>