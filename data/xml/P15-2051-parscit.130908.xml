<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005056">
<title confidence="0.865785">
Recovering dropped pronouns from Chinese text messages
</title>
<author confidence="0.97032">
Yaqin Yang
</author>
<affiliation confidence="0.921504">
Paypal Inc.
</affiliation>
<email confidence="0.935366">
yaqin276@gmail.com
</email>
<author confidence="0.98283">
Yalin Liu
</author>
<affiliation confidence="0.96815">
Brandeis University
</affiliation>
<email confidence="0.980731">
yalin@brandeis.edu
</email>
<author confidence="0.970896">
Nianwen Xu
</author>
<affiliation confidence="0.958054">
Brandeis University
</affiliation>
<email confidence="0.990579">
xuen@brandeis.edu
</email>
<sectionHeader confidence="0.997303" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99968975">
Pronouns are frequently dropped in Chi-
nese sentences, especially in informal data
such as text messages. In this work we
propose a solution to recover dropped pro-
nouns in SMS data. We manually annotate
dropped pronouns in 684 SMS files and
apply machine learning algorithms to re-
cover them, leveraging lexical, contextual
and syntactic information as features. We
believe this is the first work on recover-
ing dropped pronouns in Chinese text mes-
sages.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999878783783784">
Text messages generated by users via SMS or Chat
have distinct linguistic characteristics that pose
unique challenges for existing natural language
processing techniques. Since such text messages
are often generated via mobile devices in infor-
mal settings and are limited in length, abbrevia-
tions and omissions are commonplace. In this pa-
per, we report work on detecting one particular
type of omission in Chinese text messages, namely
dropped pronouns.
It is well-known that Chinese is a pro-drop lan-
guage, meaning pronouns can be dropped from
a sentence without causing the sentence to be-
come ungrammatical or incomprehensible when
the identity of the pronoun can be inferred from
the context. Pronouns can be dropped even in
formal text genres like newswire, but the extent
to which this happens and the types of pronouns
that are dropped in text messages and formal gen-
res like newswire are very different. For exam-
ple, the most frequently dropped pronouns in Chi-
nese newswire is the third person singular 它(“it”)
(Baran et al. 2012 ), and one reason is that first
and second person pronouns are rarely used in
newswire in the first place. In contrast, in text
messages, the first person singular R and the
second person singular 你 are commonly found
in text messages due to their conversational style,
and they are often dropped as well when their ref-
erent is understood in the context. This is illus-
trated in (1), where there are instances of dropped
first person singular, second person singular and
third person singular pronouns. There is also an
instance where the dropped pronoun in Chinese
does not have any actual referent, translating to the
English pleonastic “it”. Dropped pronouns are in
parentheses:
</bodyText>
<equation confidence="0.977855318181818">
(1) A 你们
your
“It snowed in your area. How do you go
to work?”
坐车
take the bus
“(I) walk or take the bus.”
A (pleonastic) 看来 交通业 还是
(it) look like transportation
比较 发达 的.
relatively developed
“(It) looks like you have a relatively de-
veloped transportation system.”
B (pleonastic)
(it)
上班 T
go to work ASP
“When (it) snows, (I) cannot go to work.”
B (它)
还可以
(it) OK
“(It) is OK.”
</equation>
<bodyText confidence="0.987018">
Detecting dropped pronouns involves first of all
determining where in the sentence pronouns are
</bodyText>
<figure confidence="0.996791466666667">
去
go
上班
work
下雪
snow
怎么
how
T
ASP
那
area
, 你
,you
B (R)
(I)
或
or
步行
walk
不
not
下雪
snow
就
then
能
can
(R)
(I)
</figure>
<page confidence="0.926707">
309
</page>
<bodyText confidence="0.9580983125">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 309–313,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
dropped and then determining what the dropped
pronoun is, i.e., whether the dropped pronoun
should be 我, 你, 他, etc. The dropped pronoun
could either correspond to one of possible pro-
nouns in Chinese, or it can be an abstract pronoun
that does not correspond to any of the Chinese
pronouns. For example, Chinese does not have
a pronoun that is the equivalent of the pleonastic
“it” in English, but there are sentences in which a
dropped pronoun occurs in a context that is sim-
ilar to where “it” occurs. In this case we label
the dropped pronoun as a type of abstract pronoun.
Note that we do not attempt to resolve these pro-
nouns to an antecedent in this work. We think
there is value in just detecting these pronouns. For
example, if we translate Chinese sentences with
dropped pronouns into English, they may have to
be made explicit.
We approach this as a supervised learning prob-
lem, so first we need a corpus annotated with the
location and type of dropped pronouns to train
machine learning models. We annotated 292,455
words of Chinese SMS/Chat data with dropped
pronouns and we describe our annotation in more
detail in Section 2. We then present our machine
learning approach in Section 3. Experimental re-
sults are presented in Section 4, and related work
is described in Section 5. Finally we conclude in
Section 6.
</bodyText>
<sectionHeader confidence="0.890074" genericHeader="method">
2 Dropped pronoun annotation
</sectionHeader>
<bodyText confidence="0.999992461538462">
We annotated 684 Chinese SMS/Chat files follow-
ing the dropped pronoun annotation guidelines de-
scribed in (Baran et al. 2012 ). The original guide-
lines are mainly designed for annotating dropped
pronouns in newswire text, and we had to extend
the guidelines to accommodate SMS/Chat data.
For example, (Baran et al. 2012 ) identify 14 types
of pronouns, which include four abstract pronouns
which do not correspond to any actual pronouns
in Chinese. To accommodate SMS/Chat data, we
add one more type of abstract pronoun that refers
to the previous utterance. The full list of pronouns
that we use are listed below:
</bodyText>
<listItem confidence="0.997526090909091">
1. 我(I): first person singular
2. 我们(we): first person plural
3. 你(you): second person singular
4. 你们(you): second person plural
5. 他(he): third person masculine singular
6. 他们(they): third person masculine plural
7. 她(she): third person feminine singular
8. 她们(they): third person feminine plural
9. 它(it): third person inanimate singular
10. 它们(they): third person inanimate plural
11. Event: abstract pronoun that refers to an
event
12. Existential: abstract pronoun that refers to
existential subject
13. Pleonastic: abstract pronoun that refers to
pleonastic subject
14. generic: abstract pronoun that
refers to something generic or unspecific
15. Previous Utterance: abstract pronoun that
refers to previous utterance
16. Other: cases where it is unclear what the cor-
rect pronoun should be
</listItem>
<sectionHeader confidence="0.988628" genericHeader="method">
3 Learning
</sectionHeader>
<bodyText confidence="0.999965181818182">
We have formulated dropped pronoun recovery as
a sequential tagging problem, following (Yang and
Xue. 2010 ). We check each word token in a
sentence and decide if there is a pronoun dropped
before this word. If there is one, then we further
identify what type of pronoun it should be. Instead
of doing this in two separate steps, we trained a 17-
class Maximum Entropy classifier with the Mallet
(McCallum et al. 2002) machine learning pack-
age to tag each word token with one of the pro-
nouns or None in one run. None indicates that
there is no dropped pronoun before this word.
We leveraged a set of lexical features from pre-
vious work (Yang and Xue. 2010 ). To our knowl-
edge, the work we report here represents the first
effort on dropped pronoun recovery on Chinese
SMS/Chat data. As described in Section 2, SMS
data is different from newswire data which is com-
monly used in previous work (Converse. 2006;
Zhao and Ng. 2007; Peng and Araki. 2007; Kong
and Zhou. 2010; Chung and Gildea 2010; Cai et
al. 2011; Xiang et al. 2013) in many aspects.
The frequency of pronoun being dropped is much
higher in SMS/Chat data compared to newswire
data. The distribution of dropped pronoun types
in SMS data is also very different from that of
newswire data. In SMS/Chat data, the identities
of the participants who send the messages are crit-
ical in identifying the dropped pronoun type, while
there is no participant information in newswire
data. Thus, we also design a new set of context
based features to capture the stylistic properties of
text messages.
</bodyText>
<page confidence="0.99021">
310
</page>
<bodyText confidence="0.989755">
Lexical Features: Information embedded in
the target and surrounding words provide clues for
identifying dropped pronouns, e.g.,
</bodyText>
<equation confidence="0.958753333333333">
(2) (它)
(it)
“(It) is broken.”
</equation>
<bodyText confidence="0.999806333333333">
In (2), a pronoun is dropped at the beginning of
the sentence. The follwing words “坏T” means
“is broken”, and it indicates that the subject refers
to a thing, not a person. Part-of-speech tags are
also crucial in finding the location of a dropped
pronoun. Just like pronouns are usually located
before verbs, it is more likely to have a pronoun
dropped before an verb than a noun. We imple-
mented a set of lexical features along with part-of-
speech tags within a sliding window of five words
to capture such information. The contextual fea-
tures are listed below:
</bodyText>
<listItem confidence="0.842908318181818">
• unigrams within current window;
• previous and following (including current
word) bigrams;
• POS tags of unigrams within current window;
• POS tags of the previous and following (in-
cluding current word) bigrams;
• POS tags of the following (including current
word) trigram;
• combination previous word and POS tag of
current word;
• combination of POS tag of previous word and
current word;
• POS tag sequence from the previous word to
the beginning of a sentence or a punctuation
mark.
Context-based Features: It is hard to recover
dropped pronouns without understanding the con-
text. In SMS data, one sometimes needs to trace
back a few sentences to figure out what a dropped
pronoun refers to.
单反 .
SLR camera .
</listItem>
<bodyText confidence="0.985070454545454">
“I want to buy a SLR camera.”
“(I) will travel on Independent Day.”
In (3), the two sentences are attributed to the
same person, and a pronoun is dropped at the be-
ginning of the second sentence. While we could
easily understand the dropped pronoun refers to
“我(I)” from the previous sentence, it is difficult
to make this determination by just looking at the
second sentence independently. Thus, we propose
a list of novel context-based features tailored to-
wards SMS/Chat data to capture such information:
</bodyText>
<listItem confidence="0.927828388888889">
• previous pronoun used by the same partici-
pant;
• previous pronoun used by the other partici-
pant;
• all previous pronouns till the beginning of a
sentence or a punctuation mark used;
• next punctuation mark;
• if it is a question;
• if the POS tag of the last word is SP;
• for the first word in a sentence, use first two
nouns/pronouns from the previous sentence.
Syntactic Features: Syntactic features have
been shown to be useful in previous work (?). We
also implemented the following syntactic features:
• if it is the left frontier of the lowest IP an-
tecedent;
• if current word is “有”, then find it’s subject;
• path from current word to the root node.
</listItem>
<sectionHeader confidence="0.974585" genericHeader="method">
4 Experiments and discussion
</sectionHeader>
<subsectionHeader confidence="0.980748">
4.1 Data split
</subsectionHeader>
<bodyText confidence="0.9422435">
Table 1 presents the data split used in our experi-
ments.
</bodyText>
<table confidence="0.98833525">
data set # of words # of files
Train 235,184 487
Dev 24,769 98
Test 32,502 99
</table>
<tableCaption confidence="0.989084">
Table 1: Training, development and test data on
SMS data set.
</tableCaption>
<sectionHeader confidence="0.605598" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999584909090909">
As mentioned in Section 3, we extract lexical,
context and syntactic features from SMS data and
train a 17-class classifier to automatically recover
dropped pronouns. To obtain syntactic features,
we divided 684 SMS files into 10 portions, and
parsed each portion with a model trained on other
portions, using the Berkeley parser (Petrov and
Klein 2007). The parsing accuracy stands at
82.11% (F-score), with a precision of 82.57% and
a recall of 81.65%. The results of our experiments
are presented in Table 2.
</bodyText>
<figure confidence="0.999532642857143">
b. (我)
(I)
国庆节
Independent Day
出去
go out
玩 啊.
travel .
坏
broken
T .
ASP .
(3) a. 我 想 买 n
I want buy CL
</figure>
<page confidence="0.993711">
311
</page>
<table confidence="0.999668055555556">
tag pre.(%) rec.(%) f. count
NE 99.1 95.7 97.3 28963
我 48 53.1 50.4 1155
你 34.4 48.1 40.1 787
它 12.1 54.6 19.8 488
prev utterance 87.6 65.3 74.8 314
pleonastic 7 10.2 8.3 172
她 4.3 27.8 7.4 117
他 11 22.2 14.7 109
我们 24 41 30.3 104
generic 6.6 17.1 9.5 91
他们 2.7 11.1 4.4 73
event 4.3 25 7.3 47
它们 4.7 100 8.9 43
other 0 0 0 16
你们 0 0 0 13
existential 12.5 2 3.4 8
她们 0 0 0 2
</table>
<tableCaption confidence="0.98452">
Table 2: precision, recall and f-score for differ-
</tableCaption>
<bodyText confidence="0.948581666666667">
ent dropped pronoun categories on test set. The
combination of “我(I)”, “你(singular you)” and
“utterance” accounts for 63.7% of the overall
dropped pronoun population. The overall accu-
racy is 92.1%. “NE” stands for None, meaning
there is no dropped pronoun.
</bodyText>
<subsectionHeader confidence="0.995418">
4.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.9965525">
From Table 3, which is a confusion matrix gen-
erated from results on the test set, showing the
classification errors among different types, we can
see that the classifier did a better job of recover-
ing “我(I)”, “你(singular you)” and “previous ut-
terance”, the combination of which accounts for
63.7% of the total dropped pronoun instances.
However, it is hard for the classifier to recover
“它(it)”, e.g.,
“*pro* 这种?(*pro* that kind?)”
SMS sentences are usually short. To understand
what the dropped pronoun stands for, one needs to
look at its previous context. But it is hard for ma-
chine to capture such long distance information.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999824714285714">
One line of work that is closely related to ours is
zero pronoun resolution. In zero pronoun reso-
lution (Converse. 2006; Zhao and Ng. 2007;
Peng and Araki. 2007; Kong and Zhou. 2010),
pronouns are typically resolved in three steps:
zero pronoun detection, anaphoricity determina-
tion, and antecedent resolution. In the work we
</bodyText>
<table confidence="0.999207736842105">
NE 我 你 它 ut pl 她 他 我们 ge 他 ev 它们 ot 你们 ex 她们
们
NE 28695 130 77 9 8 7 2 10 9 8 1 . . . 1 6 .
我 433 554 101 11 5 13 2 5 10 4 1 1 . . 1 14 .
你 327 135 271 6 3 16 1 6 6 9 1 1 . . . 5 .
它 199 85 49 59 23 42 1 10 1 3 5 1 . . 1 9 .
utterance 23 7 1 4 275 4 . . . . . . . . . . .
pleonastic 36 17 5 5 88 12 1 1 1 . 1 . . . . 5 .
她 47 21 21 5 1 6 5 5 1 . 3 1 . . . 1 .
他 46 23 10 2 6 5 1 12 . 1 . . . . . 3 .
我们 47 17 5 2 . . 2 2 25 . 1 1 . . . 2 .
generic 52 20 5 . . . . 2 2 6 . . . . . 4 .
他们 38 15 7 2 . 3 2 . 1 2 2 1 . . . . .
event 16 4 3 2 11 6 1 1 . . 1 2 . . . . .
它们 14 11 4 . 1 3 . . 3 2 2 . 2 . . 1 .
other 15 . . . . 1 . . . . . . . . . . .
你们 6 2 4 1 . . . . . . . . . . . . .
existential 4 2 . . . . . . 1 . . . . . . 1 .
她们 1 . . . . . . . 1 . . . . . . . .
</table>
<tableCaption confidence="0.932780333333333">
Table 3: Confusion matrix for each annotation cat-
egory. Columns correspond to Maxent predicted
values and rows refer to annotated values.
</tableCaption>
<bodyText confidence="0.999620368421052">
report here, we are more interested in detecting
dropped pronouns and determining what types of
pronoun they are.
Dropped pronoun detection is also related to
Empty Category (EC) detection and resolution
(Chung and Gildea 2010; Cai et al. 2011; Xi-
ang et al. 2013), the aim of which is to recover
long-distance dependencies, discontinuous con-
stituents, and certain dropped elements in phrase
structure treebanks (Marcus et al. 1993; Xue et
al. 2005). In previous work on EC detection
(Chung and Gildea 2010; Cai et al. 2011; Xiang
et al. 2013), ECs are recovered from newswire
data by leveraging lexical and syntactic informa-
tion from each sentence. Context information be-
yond the current sentence is typically not used.
When recovering dropped pronouns in SMS/Chat
messages, it is crucially important to make use of
information beyond the current sentence.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998863416666667">
In this paper we report work on recovering
dropped pronouns in Chinese SMS/Chat mes-
sages. Based on the properties of SMS data, we
designed a set of lexical, contextual and syntac-
tic features, and trained a Maxent classifier to
recover dropped pronouns in Chinese SMS/Chat
messages. We believe this is the first work on re-
covering dropped pronouns in Chinese text mes-
sages. This proves to be a very challenging task,
and much remains to be done. In future work, we
plan to experiment with applying more expressive
machine learning techniques to this task.
</bodyText>
<page confidence="0.99719">
312
</page>
<sectionHeader confidence="0.999213" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9993985">
We want to thank the anonymous reviewers for
their suggestions. This work was partially sup-
ported by the National Science Foundation via
Grant No.0910532 entitled “Richer Representa-
tions for Machine Translation”. All views ex-
pressed in this paper are those of the authors and
do not necessarily represent the view of the Na-
tional Science Foundation.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999596409836066">
Zhao, Shanheng and Ng, Hwee Tou 2007 Identifi-
cation and Resolution of Chinese Zero Pronouns:
A Machine Learning Approach.. Proceedings of
the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL).
Kong, Fang and Zhou, Guodong 2010 A tree kernel-
based unified framework for Chinese zero anaphora
resolution.. Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing.
Fang Kong and Hwee Tou Ng 2013 Exploiting Zero
Pronouns to Improve Chinese Coreference Resolu-
tion.. Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing.
Shu Cai, David Chiang, and Yoav Goldberg. 2011
Language-independent parsing with empty ele-
ments.. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies, pages 212–216,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
Tagyoung Chung and Daniel Gildea. 2010. Effects
of empty categories on machine translation. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing.
Elizabeth Baran, Yaqin Yang and Nianwen Xue. 2012
Annotating dropped pronouns in Chinese newswire
text.. In Proceedings of the 8th International Con-
ference on Language Resources and Evaluation
(LREC), Istanbul, Turkey.
Andrew Kachites McCallum. 2002 Mallet:
A machine learning for language toolkit..
http://mallet.cs.umass.edu.
Nianwen Xue and Yaqin Yang. 2013 Dependency-
based empty category detection via phrase structure
trees.. In Proceedings of NAACL HLT. Atlanta,
Georgia.
Yaqin Yang and Nianwen Xue. 2010 Chasing the
ghost: recovering empty categories in the Chinese
Treebank.. In Proceedings of the 23rd International
Conference on Computational Linguistics (COL-
ING). Beijing, China.
Bing Xiang, Xiaoqiang Luo, Bowen Zhou. 2013. En-
listing the Ghost: Modeling Empty Categories for
Machine Translation. In Proceedings of the ACL.
Converse, Susan 2006 Pronominal anaphora resolu-
tion for Chinese.. Ph.D. thesis.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993 Building a large annotated
corpus of english: The penn treebank.. Computa-
tional Linguistics, 19(2):313–330.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005 The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural
Language Engineering, 11(2):207–238.
Slav Petrov and Dan Klein. 2007. Improved Infer-
encing for Unlexicalized Parsing. In Proceedings of
HLT-NAACL 2007.
Jing Peng and Kenji Araki. 2007 Zero-Anaphora Res-
olution in Chinese Using Maximum Entropy.. IEICE
Transactions.
</reference>
<page confidence="0.999504">
313
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.127204">
<title confidence="0.999231">Recovering dropped pronouns from Chinese text messages</title>
<author confidence="0.882307">Yaqin</author>
<affiliation confidence="0.99826">Paypal Inc.</affiliation>
<email confidence="0.990054">yaqin276@gmail.com</email>
<title confidence="0.37965">Yalin</title>
<author confidence="0.590931">Brandeis</author>
<email confidence="0.957961">yalin@brandeis.edu</email>
<note confidence="0.5212875">Nianwen Brandeis</note>
<email confidence="0.988973">xuen@brandeis.edu</email>
<abstract confidence="0.995301538461539">Pronouns are frequently dropped in Chinese sentences, especially in informal data such as text messages. In this work we propose a solution to recover dropped pronouns in SMS data. We manually annotate dropped pronouns in 684 SMS files and apply machine learning algorithms to recover them, leveraging lexical, contextual and syntactic information as features. We believe this is the first work on recovering dropped pronouns in Chinese text messages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shanheng Zhao</author>
<author>Ng</author>
</authors>
<title>Hwee Tou</title>
<date>2007</date>
<booktitle>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<marker>Zhao, Ng, 2007</marker>
<rawString>Zhao, Shanheng and Ng, Hwee Tou 2007 Identification and Resolution of Chinese Zero Pronouns: A Machine Learning Approach.. Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Kong</author>
<author>Guodong Zhou</author>
</authors>
<title>A tree kernelbased unified framework for Chinese zero anaphora resolution..</title>
<date>2010</date>
<booktitle>Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Kong, Zhou, 2010</marker>
<rawString>Kong, Fang and Zhou, Guodong 2010 A tree kernelbased unified framework for Chinese zero anaphora resolution.. Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Kong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Exploiting Zero Pronouns to Improve Chinese Coreference Resolution..</title>
<date>2013</date>
<booktitle>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Kong, Ng, 2013</marker>
<rawString>Fang Kong and Hwee Tou Ng 2013 Exploiting Zero Pronouns to Improve Chinese Coreference Resolution.. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shu Cai</author>
<author>David Chiang</author>
<author>Yoav Goldberg</author>
</authors>
<title>Language-independent parsing with empty elements..</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>212--216</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="7035" citStr="Cai et al. 2011" startWordPosition="1179" endWordPosition="1182">et (McCallum et al. 2002) machine learning package to tag each word token with one of the pronouns or None in one run. None indicates that there is no dropped pronoun before this word. We leveraged a set of lexical features from previous work (Yang and Xue. 2010 ). To our knowledge, the work we report here represents the first effort on dropped pronoun recovery on Chinese SMS/Chat data. As described in Section 2, SMS data is different from newswire data which is commonly used in previous work (Converse. 2006; Zhao and Ng. 2007; Peng and Araki. 2007; Kong and Zhou. 2010; Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013) in many aspects. The frequency of pronoun being dropped is much higher in SMS/Chat data compared to newswire data. The distribution of dropped pronoun types in SMS data is also very different from that of newswire data. In SMS/Chat data, the identities of the participants who send the messages are critical in identifying the dropped pronoun type, while there is no participant information in newswire data. Thus, we also design a new set of context based features to capture the stylistic properties of text messages. 310 Lexical Features: Information embedded in the target an</context>
<context position="13872" citStr="Cai et al. 2011" startWordPosition="2571" endWordPosition="2574"> 4 3 2 11 6 1 1 . . 1 2 . . . . . 它们 14 11 4 . 1 3 . . 3 2 2 . 2 . . 1 . other 15 . . . . 1 . . . . . . . . . . . 你们 6 2 4 1 . . . . . . . . . . . . . existential 4 2 . . . . . . 1 . . . . . . 1 . 她们 1 . . . . . . . 1 . . . . . . . . Table 3: Confusion matrix for each annotation category. Columns correspond to Maxent predicted values and rows refer to annotated values. report here, we are more interested in detecting dropped pronouns and determining what types of pronoun they are. Dropped pronoun detection is also related to Empty Category (EC) detection and resolution (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), the aim of which is to recover long-distance dependencies, discontinuous constituents, and certain dropped elements in phrase structure treebanks (Marcus et al. 1993; Xue et al. 2005). In previous work on EC detection (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), ECs are recovered from newswire data by leveraging lexical and syntactic information from each sentence. Context information beyond the current sentence is typically not used. When recovering dropped pronouns in SMS/Chat messages, it is crucially important to make use of information beyond the curr</context>
</contexts>
<marker>Cai, Chiang, Goldberg, 2011</marker>
<rawString>Shu Cai, David Chiang, and Yoav Goldberg. 2011 Language-independent parsing with empty elements.. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 212–216, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tagyoung Chung</author>
<author>Daniel Gildea</author>
</authors>
<title>Effects of empty categories on machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="7018" citStr="Chung and Gildea 2010" startWordPosition="1175" endWordPosition="1178">lassifier with the Mallet (McCallum et al. 2002) machine learning package to tag each word token with one of the pronouns or None in one run. None indicates that there is no dropped pronoun before this word. We leveraged a set of lexical features from previous work (Yang and Xue. 2010 ). To our knowledge, the work we report here represents the first effort on dropped pronoun recovery on Chinese SMS/Chat data. As described in Section 2, SMS data is different from newswire data which is commonly used in previous work (Converse. 2006; Zhao and Ng. 2007; Peng and Araki. 2007; Kong and Zhou. 2010; Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013) in many aspects. The frequency of pronoun being dropped is much higher in SMS/Chat data compared to newswire data. The distribution of dropped pronoun types in SMS data is also very different from that of newswire data. In SMS/Chat data, the identities of the participants who send the messages are critical in identifying the dropped pronoun type, while there is no participant information in newswire data. Thus, we also design a new set of context based features to capture the stylistic properties of text messages. 310 Lexical Features: Information embedded</context>
<context position="13855" citStr="Chung and Gildea 2010" startWordPosition="2567" endWordPosition="2570"> 2 1 . . . . . event 16 4 3 2 11 6 1 1 . . 1 2 . . . . . 它们 14 11 4 . 1 3 . . 3 2 2 . 2 . . 1 . other 15 . . . . 1 . . . . . . . . . . . 你们 6 2 4 1 . . . . . . . . . . . . . existential 4 2 . . . . . . 1 . . . . . . 1 . 她们 1 . . . . . . . 1 . . . . . . . . Table 3: Confusion matrix for each annotation category. Columns correspond to Maxent predicted values and rows refer to annotated values. report here, we are more interested in detecting dropped pronouns and determining what types of pronoun they are. Dropped pronoun detection is also related to Empty Category (EC) detection and resolution (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), the aim of which is to recover long-distance dependencies, discontinuous constituents, and certain dropped elements in phrase structure treebanks (Marcus et al. 1993; Xue et al. 2005). In previous work on EC detection (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), ECs are recovered from newswire data by leveraging lexical and syntactic information from each sentence. Context information beyond the current sentence is typically not used. When recovering dropped pronouns in SMS/Chat messages, it is crucially important to make use of informatio</context>
</contexts>
<marker>Chung, Gildea, 2010</marker>
<rawString>Tagyoung Chung and Daniel Gildea. 2010. Effects of empty categories on machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Baran</author>
<author>Yaqin Yang</author>
<author>Nianwen Xue</author>
</authors>
<title>Annotating dropped pronouns in Chinese newswire text..</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="1707" citStr="Baran et al. 2012" startWordPosition="264" endWordPosition="267">messages, namely dropped pronouns. It is well-known that Chinese is a pro-drop language, meaning pronouns can be dropped from a sentence without causing the sentence to become ungrammatical or incomprehensible when the identity of the pronoun can be inferred from the context. Pronouns can be dropped even in formal text genres like newswire, but the extent to which this happens and the types of pronouns that are dropped in text messages and formal genres like newswire are very different. For example, the most frequently dropped pronouns in Chinese newswire is the third person singular 它(“it”) (Baran et al. 2012 ), and one reason is that first and second person pronouns are rarely used in newswire in the first place. In contrast, in text messages, the first person singular R and the second person singular 你 are commonly found in text messages due to their conversational style, and they are often dropped as well when their referent is understood in the context. This is illustrated in (1), where there are instances of dropped first person singular, second person singular and third person singular pronouns. There is also an instance where the dropped pronoun in Chinese does not have any actual referent,</context>
<context position="4729" citStr="Baran et al. 2012" startWordPosition="793" endWordPosition="796">pervised learning problem, so first we need a corpus annotated with the location and type of dropped pronouns to train machine learning models. We annotated 292,455 words of Chinese SMS/Chat data with dropped pronouns and we describe our annotation in more detail in Section 2. We then present our machine learning approach in Section 3. Experimental results are presented in Section 4, and related work is described in Section 5. Finally we conclude in Section 6. 2 Dropped pronoun annotation We annotated 684 Chinese SMS/Chat files following the dropped pronoun annotation guidelines described in (Baran et al. 2012 ). The original guidelines are mainly designed for annotating dropped pronouns in newswire text, and we had to extend the guidelines to accommodate SMS/Chat data. For example, (Baran et al. 2012 ) identify 14 types of pronouns, which include four abstract pronouns which do not correspond to any actual pronouns in Chinese. To accommodate SMS/Chat data, we add one more type of abstract pronoun that refers to the previous utterance. The full list of pronouns that we use are listed below: 1. 我(I): first person singular 2. 我们(we): first person plural 3. 你(you): second person singular 4. 你们(you): s</context>
</contexts>
<marker>Baran, Yang, Xue, 2012</marker>
<rawString>Elizabeth Baran, Yaqin Yang and Nianwen Xue. 2012 Annotating dropped pronouns in Chinese newswire text.. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit..</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002 Mallet: A machine learning for language toolkit.. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Yaqin Yang</author>
</authors>
<title>Dependencybased empty category detection via phrase structure trees..</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL HLT.</booktitle>
<location>Atlanta,</location>
<marker>Xue, Yang, 2013</marker>
<rawString>Nianwen Xue and Yaqin Yang. 2013 Dependencybased empty category detection via phrase structure trees.. In Proceedings of NAACL HLT. Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaqin Yang</author>
<author>Nianwen Xue</author>
</authors>
<title>Chasing the ghost: recovering empty categories in the Chinese Treebank..</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING).</booktitle>
<location>Beijing, China.</location>
<marker>Yang, Xue, 2010</marker>
<rawString>Yaqin Yang and Nianwen Xue. 2010 Chasing the ghost: recovering empty categories in the Chinese Treebank.. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING). Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Xiang</author>
<author>Xiaoqiang Luo</author>
<author>Bowen Zhou</author>
</authors>
<title>Enlisting the Ghost: Modeling Empty Categories for Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="7055" citStr="Xiang et al. 2013" startWordPosition="1183" endWordPosition="1186">l. 2002) machine learning package to tag each word token with one of the pronouns or None in one run. None indicates that there is no dropped pronoun before this word. We leveraged a set of lexical features from previous work (Yang and Xue. 2010 ). To our knowledge, the work we report here represents the first effort on dropped pronoun recovery on Chinese SMS/Chat data. As described in Section 2, SMS data is different from newswire data which is commonly used in previous work (Converse. 2006; Zhao and Ng. 2007; Peng and Araki. 2007; Kong and Zhou. 2010; Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013) in many aspects. The frequency of pronoun being dropped is much higher in SMS/Chat data compared to newswire data. The distribution of dropped pronoun types in SMS data is also very different from that of newswire data. In SMS/Chat data, the identities of the participants who send the messages are critical in identifying the dropped pronoun type, while there is no participant information in newswire data. Thus, we also design a new set of context based features to capture the stylistic properties of text messages. 310 Lexical Features: Information embedded in the target and surrounding words </context>
<context position="13892" citStr="Xiang et al. 2013" startWordPosition="2575" endWordPosition="2579"> . 1 2 . . . . . 它们 14 11 4 . 1 3 . . 3 2 2 . 2 . . 1 . other 15 . . . . 1 . . . . . . . . . . . 你们 6 2 4 1 . . . . . . . . . . . . . existential 4 2 . . . . . . 1 . . . . . . 1 . 她们 1 . . . . . . . 1 . . . . . . . . Table 3: Confusion matrix for each annotation category. Columns correspond to Maxent predicted values and rows refer to annotated values. report here, we are more interested in detecting dropped pronouns and determining what types of pronoun they are. Dropped pronoun detection is also related to Empty Category (EC) detection and resolution (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), the aim of which is to recover long-distance dependencies, discontinuous constituents, and certain dropped elements in phrase structure treebanks (Marcus et al. 1993; Xue et al. 2005). In previous work on EC detection (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), ECs are recovered from newswire data by leveraging lexical and syntactic information from each sentence. Context information beyond the current sentence is typically not used. When recovering dropped pronouns in SMS/Chat messages, it is crucially important to make use of information beyond the current sentence. 6 Conc</context>
</contexts>
<marker>Xiang, Luo, Zhou, 2013</marker>
<rawString>Bing Xiang, Xiaoqiang Luo, Bowen Zhou. 2013. Enlisting the Ghost: Modeling Empty Categories for Machine Translation. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Converse</author>
</authors>
<title>Pronominal anaphora resolution for Chinese..</title>
<date>2006</date>
<tech>Ph.D. thesis.</tech>
<marker>Converse, 2006</marker>
<rawString>Converse, Susan 2006 Pronominal anaphora resolution for Chinese.. Ph.D. thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank..</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="14059" citStr="Marcus et al. 1993" startWordPosition="2600" endWordPosition="2603"> . . . . 1 . 她们 1 . . . . . . . 1 . . . . . . . . Table 3: Confusion matrix for each annotation category. Columns correspond to Maxent predicted values and rows refer to annotated values. report here, we are more interested in detecting dropped pronouns and determining what types of pronoun they are. Dropped pronoun detection is also related to Empty Category (EC) detection and resolution (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), the aim of which is to recover long-distance dependencies, discontinuous constituents, and certain dropped elements in phrase structure treebanks (Marcus et al. 1993; Xue et al. 2005). In previous work on EC detection (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), ECs are recovered from newswire data by leveraging lexical and syntactic information from each sentence. Context information beyond the current sentence is typically not used. When recovering dropped pronouns in SMS/Chat messages, it is crucially important to make use of information beyond the current sentence. 6 Conclusion and Future Work In this paper we report work on recovering dropped pronouns in Chinese SMS/Chat messages. Based on the properties of SMS data, we designed a set</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993 Building a large annotated corpus of english: The penn treebank.. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="14077" citStr="Xue et al. 2005" startWordPosition="2604" endWordPosition="2607">. . . . . . 1 . . . . . . . . Table 3: Confusion matrix for each annotation category. Columns correspond to Maxent predicted values and rows refer to annotated values. report here, we are more interested in detecting dropped pronouns and determining what types of pronoun they are. Dropped pronoun detection is also related to Empty Category (EC) detection and resolution (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), the aim of which is to recover long-distance dependencies, discontinuous constituents, and certain dropped elements in phrase structure treebanks (Marcus et al. 1993; Xue et al. 2005). In previous work on EC detection (Chung and Gildea 2010; Cai et al. 2011; Xiang et al. 2013), ECs are recovered from newswire data by leveraging lexical and syntactic information from each sentence. Context information beyond the current sentence is typically not used. When recovering dropped pronouns in SMS/Chat messages, it is crucially important to make use of information beyond the current sentence. 6 Conclusion and Future Work In this paper we report work on recovering dropped pronouns in Chinese SMS/Chat messages. Based on the properties of SMS data, we designed a set of lexical, conte</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha Palmer. 2005 The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inferencing for Unlexicalized Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<contexts>
<context position="10790" citStr="Petrov and Klein 2007" startWordPosition="1827" endWordPosition="1830"> the root node. 4 Experiments and discussion 4.1 Data split Table 1 presents the data split used in our experiments. data set # of words # of files Train 235,184 487 Dev 24,769 98 Test 32,502 99 Table 1: Training, development and test data on SMS data set. 4.2 Results As mentioned in Section 3, we extract lexical, context and syntactic features from SMS data and train a 17-class classifier to automatically recover dropped pronouns. To obtain syntactic features, we divided 684 SMS files into 10 portions, and parsed each portion with a model trained on other portions, using the Berkeley parser (Petrov and Klein 2007). The parsing accuracy stands at 82.11% (F-score), with a precision of 82.57% and a recall of 81.65%. The results of our experiments are presented in Table 2. b. (我) (I) 国庆节 Independent Day 出去 go out 玩 啊. travel . 坏 broken T . ASP . (3) a. 我 想 买 n I want buy CL 311 tag pre.(%) rec.(%) f. count NE 99.1 95.7 97.3 28963 我 48 53.1 50.4 1155 你 34.4 48.1 40.1 787 它 12.1 54.6 19.8 488 prev utterance 87.6 65.3 74.8 314 pleonastic 7 10.2 8.3 172 她 4.3 27.8 7.4 117 他 11 22.2 14.7 109 我们 24 41 30.3 104 generic 6.6 17.1 9.5 91 他们 2.7 11.1 4.4 73 event 4.3 25 7.3 47 它们 4.7 100 8.9 43 other 0 0 0 16 你们 0 0 </context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inferencing for Unlexicalized Parsing. In Proceedings of HLT-NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Peng</author>
<author>Kenji Araki</author>
</authors>
<title>Zero-Anaphora Resolution in Chinese Using Maximum Entropy..</title>
<date>2007</date>
<journal>IEICE Transactions.</journal>
<marker>Peng, Araki, 2007</marker>
<rawString>Jing Peng and Kenji Araki. 2007 Zero-Anaphora Resolution in Chinese Using Maximum Entropy.. IEICE Transactions.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>