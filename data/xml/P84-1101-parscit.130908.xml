<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009438">
<note confidence="0.535393">
ROBUST PROCESSING IN MACHINE TRANSLATION
Doug Arnold,
</note>
<author confidence="0.913916">
Rod Johnson,
</author>
<affiliation confidence="0.991826">
Centre for Cognitive Studies,
University of Essex,
</affiliation>
<address confidence="0.725433">
Colchester, 004 3SQ, U.K.
Centre for Computational Linguistics
UMIST, Manchester,
M60 8QD, U.K.
</address>
<email confidence="0.698348">
ABSTRACT
</email>
<bodyText confidence="0.9993627">
In this paper we provide an abstract
characterisation of different kinds of robust
processing in Machine Translation and Natural
Language Processing systems in terms of the kinds
of problem they are supposed to solve. We focus
on one problem which is typically exacerbated by
robust processing, and for which we know of no
existing solutions. We discuss two possible
approaches to this, emphasising the need to
correct or repair processing malfunctions.
</bodyText>
<sectionHeader confidence="0.920657" genericHeader="abstract">
ROBUST PROCESSING IN MACHINE TRANSLATION
</sectionHeader>
<bodyText confidence="0.976721203703704">
This paper is an attempt to provide part
of the basis for a general theory of robust
processing in Machine Translation (MT) with
relevance to other areas of Natural Language
Processing (NLP). That is, processing which is
resistant to malfunctioning however caused. The
background to the paper is work on a general
purpose fully automatic multi-lingual MT system
within a highly decentralised organisational
framework (specifically, the Eurotra system under
development by the EEC). This influences us in a
number of ways.
Decentralised development, and the fact
that the system is to be general purpose motivate
the formulation of a general theory, which
abstracts away from matters of purely local
relevance, and does not e.g. depend on exploiting
special properties of a particular subject field
(compare [7], e.g.).
The fact that we consider robustness at
all can be seen as a result of the difficulty of
MT, and the aim of full automation is reflected in
our concentration on a theory of robust process-
ing, rather than &apos;developmental robustness&apos;. We
will not be concerned here with problems that
arise in designing systems so that they are
capable of extension and repair (e.g. not being
prone to unforseen &apos;ripple effects&apos; under
modification). Developmental robustness is
clearly essential, and such problems are serious,
but no system which relies on this kind of robust-
ness can ever be fully automatic. For the same
reason, we will not consider the use of
&apos;interactive&apos; approaches to robustness such as
that of [10].
Finally, the fact that we are concerned
with translation militates against the kind of
disregard for input that is characteristic of some
robust systems (PARRY [4] is an extreme example),
and motivates a concern with the repair or
correction of errors. It is not enough that a
translation system produces superficially
acceptable output for a wide class of inputs, it
should aim to produce outputs which represent as
nearly as possible translations of the inputs. If
it cannot do this, then in some cases it will be
better if it indicates as much, so that other
action can be taken.
From the point of view we adopt, it is
possible to regard MT and NLP systems generally as
sets of processes implementing relations between
representations (texts can be considered
representations of themselves). It is important
to distinguish:
</bodyText>
<listItem confidence="0.822739227272727">
(i) R: the correct, or intended relation that
holds between representations (e.g. the relation
&apos;is a (correct) translation of&apos;, or &apos;is tile
surface constituent structure of&apos;): we have only
fairly vague, pre-theoretical ideas about Rs, in
virtue of being bi-lingual speakers, or having
some intuitive grasp of the semantics of
artificial representations;
(ii) T: a theoretical construct which is
supposed to embody R;
(iii) P: a process or program that is
supposed to implement T.
By a robust process P, we mean one which
operates error free for all inputs. Clearly, the
notion of error or correctness of P depends on the
independent standard provided by T and R. If, for
the sake of simplicity we ignore the possibility
of ambiguous inputs here, we can define
correctness thus:
(1) Given P(x)=y, and a set W such that for
all w in W, R(w)=y, then y is correct with respect
to R and w iff x is a member of W.
</listItem>
<bodyText confidence="0.999156857142857">
Intuitively, W is the set of items for which
y is the correct representation according to R.
One possible source of errors in P would be if P
correctly implemented T, but T did not embody R.
Clearly, in this case, the only sensible solution
is to modify T. Since we can imagine no automatic
way of finding such errors and doing this, we will
</bodyText>
<page confidence="0.997822">
472
</page>
<bodyText confidence="0.99699824">
ignore this possibility, and assume that T is a
well—defined, correct and complete embodiment of
R. We can thus replace R by T in (1), and treat T
as the standard of correctness below.
There appear to be two possible sources of
error in P:
Problem (i): where P is not a correct
implementation of T. One would expect this to be
common where (as often in MT and NLP) T is very
complex, and serious problems arise in devising
implementations for them.
Problem (ii): where P is a correct
implementation so far as it goes, but is incom—
plete, so that the domain of P is a proper—subset
of the domain of T. This will also be very common:
in reality processes are often faced with inputs
that violate the expectations implicit in an
implementation.
If we disregard hardware errors, low level
bugs and such malfunctions as non—termination of
P (for which there are well—known solutions),
there are three possible manifestations of
malfunction. We will discuss them in turn.
case (a): P(x)=0, where T(x)00
i.e. P halts producing 0 output for input x, where
this is not the intended output. This would be a
typical response to unforseen or illformed input,
and is the case of process fragility that is most
often dealt with.
There are two obvious solutions: (i) to
manipulate the input so that it conforms to the
expectations implicit in P (cf. the LIFER [8]
approach to ellipsis), or to change P itself,
modifying (generally relaxing) its expectations
(cf. e.g. the approaches of [71, Oh [10] and
DM. If successful, these guarantee that P
produces some output for input x. However, there
is of course no guarantee that it is correct with
respect to T. It may be that P plus the input
manipulation process, or P with relaxed expectat—
ions is simply a more correct or complete implem—
entation of T, but this will be fortuitous. It is
more likely that making P robust in these ways
will lead to errors of another kind:
case (b): P(x)=z where z is not a legal
output for P according to T (i.e. z is not in the
range of T.
Typically, such an error will show itself by
malfunctioning in a process that P feeds. Detec—
tion of such errors is straightforward: a well—
formedness check on the output of P is sufficient.
By itself, of course, this will lead to a
proliferation of case—(a) errors in P. These can
be avoided by a number of methods, in particular:
(i) introducing some process to manipulate the
output of P to make it well—formed according to T,
or (ii) attempting to set up processes that feed
on P so that they can use &apos;abnormal&apos; or &apos;non—
standard&apos; output from P (e.g. partial representat—
ions, or complete intermediate representations
produced within P. or alternative representations
constructed within P which can be more reliably
computed than the &apos;normal&apos; intended output of P
(the representational theories of GETA and Eurotra
are designed with this in mind: cf. [2], [3], [5],
[6], and references there, and see [1] for fuller
discussion of these issues). Again, it is
conceivable that the result of this may be to
produce a robust P that implements T more correct—
ly or completely, but again this will be fortuit—
ous. The most likely result will be robust P will
now produce errors of the third type:
case (c): P(x)=y, where y is a legal output
for P according to T, but is not the intended
output according to T. i.e. y is in the range of
T, but y4T(x).
Suppose both input x and output y of some
process are legal objects, it nevertheless does
not follow that they have been correctly paired by
the process: e.g.in the case of a parsing process,
x may be some sentence and y some representation.
Obviously, the fact that x and y are legal objects
for the parsing process and that y is the output
of the parser for input x does not guarantee that
y is a correct representation of x. Of course,
robust processing should be resistant to this kind
of malfunctioning also.
Case—(c) errors are by far the most serious
and resistant to solution because they are the
hardest to detect, and because in many cases no
output is preferable to superficially
(misleadingly) well—formed but incorrect output.
Notice also that while any process may be subject
to this kind of error, making a system robust in
response to case—(a) and case—(b) errors will make
this class of errors more widespread: we have
suggested that the likely result of changing P to
make it robust will be that it no longer pairs
respresentations in the manner required by T, but
since any process that takes the output of P
should be set up so as to expect inputs that
conform to T (since this is the &apos;correct&apos;
embodiment of R, we have assumed), we can expect
that in general making a process robust will lead
to cascades of errors. If we assume that a system
is resistant to case—(a) and case—(b) errors, then
it follows that inputs for which the system has to
resort to robust processing will be likely to lead
to case—(c) errors.
Moreover, we can expect that making P robust
will have made case—(c) errors more difficult to
deal with. The likely result of making P robust
is that it no longer implements T, but some T&apos;
which is distinct from T, and for which assump—
tions about correctness in relation to R no longer
hold. It is obvious that the possibility of
detecting case—(c) errors depends on the
possibility of distinguishing T from T%
Theoretically, this is unproblematic. However, in
a domain such as MT it will be rather unusual for
T and T&apos; to exist separately from the processes
that implement them. Thus, if we are to have any
chance of detecting case—(c) errors, we must be
able to clearly distinguish those aspects of a
process that relate to &apos;normal&apos; processing from
</bodyText>
<page confidence="0.997108">
473
</page>
<bodyText confidence="0.999586129032258">
those that relate to robust processing. This
distinction is not one that is made in most robust
systems.
We know of no existing solutions to case-(c)
malfunctions. Here we will outline two possible
approaches.
To begin with we might consider a partial
solution derived from a well-known technique in
systems theory: insuring against the effect of
faulty components in crucial parts of a system by
computing the result for a given input by a number
of different routes. For our purposes, the method
would consist essentially in implementing the same
theory T as a number of distinct processes
P1,ni etc. to be run in parallel, comparing
outputs and using statistical criteria to
determine the correctness of processing. We will
call this the &apos;statistical solution&apos;. (Notice that
certain kinds of system architecture make this
quite feasible, even given real time constraints).
Clearly, while this should significantly
improve the chances that output will be correct,
it can provide no guarantee. Moreover, the kind
of situation we are considering is more complex
than that arising given failure of relatively
simple pieces of hardware. In particular, to make
this worthwhile, we must be able to ensure that
the different Ps are genuinely distinct, and that
they are reasonably complete and correct
implementations of T, at the very least
sufficiently complete and correct that their
outputs can be sensibly compared.
Unfortunately, this will be very difficult to
ensure, particularly in a field such as MT, where
Ts are generally very complex, and (as we have
noted) are often not stated separately from the
processes that implement them.
The statistical approach is attractive
because it seems to provide a simultaneous solut-
ion to both the detection and repair of case-(c)
errors, and we consider such solutions are
certainly worth further consideration. However,
realistically, we expect the normal situation to
be that it is difficult to produce reasonably
correct and compelete distinct implementations, so
that we are forced to look for an alternative
approach to the detection of case-(c) errors.
It is obvious that reliable detection of (c)-
type errors requires the implementation of a
relation that pairs representations in exactly the
same way as T: the obvious candidate is a process
-1
P , implementing T1, the inverse of T.
The basic method here would be to compute an
enumeration of the set of all possible inputs W
that could have yielded the actual output, given
T, and some hypothetical ideal P which correctly
implements it. (Again, this is not unrealistic;
certain system architectures would allow forward
computation to procede while this inverse
processing is carried out).
To make this worthwhile would involve two
</bodyText>
<listItem confidence="0.734869666666667">
assumptions:
-1
(i) That P terminates in reasonable time.
</listItem>
<bodyText confidence="0.998251870967742">
This cannot be guaranteed, but the assumption can
be rendered more reasonable by observing
characteristics of the input, and thus restricting
W (e.g. restricting the members of W in relation
to the length of the input to P-I).
(ii) That construction of P-1 is somehow more
straightforward than construction of P, so that
-1
P is likely to be more reliable (correct and
complete) than P. In fact this is not implausible
for some applications (e.g. consider the case
where P is a parser: it is a widely held idea that
generators are easier to build than parsers).
Granted these assumptions, detection of case-
(c) errors is straightforward given this &apos;inverse
mapping&apos; approach: one simply examines the
enumeration for the actual input if it is present.
If it is present, then given that P-1 is likely to
be more reliable than P, then it is likely that
the output of P was T-correct, and hence did not
constitute a case-(c) error. At least, the
chances of the output of P being correct have been
increased. If the input is not present, then it
is likely that P has produced a case-(c) error.
The response to this will depend on the domain and
application -- e.g. on whether incorrect but
superficially well-formed output is preferable to
no output at all.
In the nature of things, we will ultimately
be lead to the original problems of robustness,
but now in connection with P. For this reason
we cannot forsee any complete solution to problems
of robustness generally. What we have seen is
that solutions to one sort of fragility are
normally only partly successful, leading to errors
of another kind elsewhere. Clearly, what we have
to hope is that each attempt to eliminate a source
of error nevertheless leads to a net decrease in
the overall number of errors.
On the one hand, this hope is reasonable,
since sometimes the faults that give rise to
processing errors are actually fixed. But there
can be no general guarantee of this, so that it
seems clear that merely making systems or
processes robust in the ways described provides
only a partial solution to the problem of
processing errors.
This should not be surprising. Because our
primary concern is with automatic error detection
and repair, we have assumed throughout that T
could be considered a correct and complete
embodiment of R. Of course, this is unrealistic,
and in fact it is probable that for many
processes, at least as many processing errors will
arise from the inadequacy of T with respect to R
as arise from the inadequacy of P with respect to
T. Our pre-theoretical and intuitive ability to
relate representations far exceeds our ability to
formulate clear theoretical statements about these
relations. Given this, it would seem that error
free processing depends at least as much on the
correctness of theoretical models as the capacity
</bodyText>
<page confidence="0.997026">
474
</page>
<bodyText confidence="0.999951589285714">
of a system to take advantage of the techniques
described above.
We should emphasise this because it
sometimes appears as though techniques for
ensuring process robustness might have a wider
importance. We assumed above that T was to be
regarded as a correct embodiment of R. Suppose
this assumption is relaxed, and in addition that
(as we have argued is likely to be the case) the
robust version of P implements a relation T&apos; which
is distinct from T. Now, it could, in principle,
turn out that T&apos; is a better embodiment of R than
T. It is worth saying that this possiblility is
remote, because it is a possibility that seems to
be taken seriously elsewhere: almost all the
strategies we have mentioned as enhancing process
robustness were originally proposed as theoretical
devices to increase the adequacy of Ts in relation
to Rs (e.g. by providing an account of
metaphorical or other &apos;problematic&apos; usage). There
can be no question that apart from improvements of
T, such theoretical developments can have the side
effect of increasing robustness. But notice that
their justification is then not to do with
robustness, but with theoretical adequacy. What
must be emphasised is that the chances that a
modification of a process to enhance robustness
(and improve reliability) will also have the
effect of improving the quality of its performance
are extremely slim. We cannot expect robust
processing to produce results which are as good as
those that would result from &apos;ideal&apos; (optimal/non-
robust) processing. In fact, we have suggested
that existing techniques for ensuring process
robustness typically have the effect of changing
the theory the process implements, changing the
relationship between representations that the
system defines in ways which do not preserve the
relationship relationship between representations
that the designers intended, so that processes
that have been made robust by existing methods can
be expected to produce output of lower than
intended quality.
These remarks are intended to emphasise
the importance of clear, complete, and correct
theoretical models of the pre-theoretical
relationships between the representations involved
in systems for which error free &apos;robust&apos; operation
important, and to emphasise the need for
approaches to robustness (such as the two we have
outlined above) that make it more likely that
robust processes will maintain the relationship
between representations that the designers of the
&apos;normal/optimal&apos; processes intended. That is,
to emphasise the need to detect and repair
malfunctions, so as to promote correct processing.
</bodyText>
<sectionHeader confidence="0.950343" genericHeader="acknowledgments">
AKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999919230769231">
Our debt to the Eurotra project is great:
collaboration on this paper developed out of work
on Eurotra and has only been possible because of
opportunities made available by the project. Some
of the ideas in this paper were first aired in
Eurotra report ETL-3 ([41), and in a paper
presented at the Cranfield conference on MT
earlier this year. We would like to thank all our
friends and colleagues in the project and our
institutions. The views (and, in particular, the
errors) in this paper are our own responsibility,
and should not be interpreted as &apos;official&apos;
Eurotra doctrine.
</bodyText>
<sectionHeader confidence="0.998164" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.9999440625">
1. ARNOLD, D.J. &amp; JOHNSON, R. (1984) &amp;quot;Approaches
to Robust Processing in Machine Translation&amp;quot;
Cognitive Studies Memo, University of Essex.
2. BDITET, CH. (1984) &amp;quot;Research and Development on
MT and Related Techniques at Grenoble University&amp;quot;
paper presented at Lugano MT tutorial April 1984.
3. BOITET, CH. &amp; NEDOBEJKINE, N. (1980) &amp;quot;Russian-
French at GETA: an outline of method and a
detailed example&amp;quot; RR 219, GETA, Grenoble.
4. COLBY, K.(1975) Artificial Paranoia Pergamon
Press, Oxford.
5. ETL-1-NL/B &amp;quot;Transfer (Taxonomy, Safety Nets,
Strategy), Report by the Belgo-Dutch Eurotra
Group, August 1983.
6. ETL-3 Final &apos;Trio&apos; Report by the Eurotra
Central Linguistics Team (Arnold, Jaspaert, Des
Tombe), February 1984.
7. HAYES, P.J. and MOURADIAN, G.V. (1981):
&amp;quot;Flexible parsing&amp;quot;, AJCL 7, 4:232-242.
8. HENDRIX, G.G. (1977) &amp;quot;Human Engineering for
Applied Natural Language Processing&amp;quot; Proc. 5th
IJCAI, 183-191, MIT Press.
9. KWASNY, S.C. and SONDHEIMER, N.K. (1981):
&amp;quot;Relaxation Techniques for Parsing Grammatically
Ill-formed Input in Natural Language Understanding
Systems&amp;quot;. AJCL 7, 2:99-108.
10. WEISCHEDEL, R.M, and BLACK, J. (1980)
&apos;Responding Intelligently to Unparsable Inputs&apos;
AJCL 6.2: 97-109.
11. WILKS, Y. (1975): &amp;quot;A Preferential Pattern
Matching Semantics for Natural Language&amp;quot;. A.I.
6:53-74.
</reference>
<page confidence="0.999093">
475
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.071651">
<title confidence="0.998944">ROBUST PROCESSING IN MACHINE TRANSLATION</title>
<author confidence="0.9954105">Doug Arnold</author>
<author confidence="0.9954105">Rod Johnson</author>
<affiliation confidence="0.9999495">Centre for Cognitive Studies, University of Essex,</affiliation>
<address confidence="0.98049">Colchester, 004 3SQ, U.K.</address>
<affiliation confidence="0.925736">Centre for Computational Linguistics UMIST, Manchester,</affiliation>
<address confidence="0.98256">M60 8QD, U.K.</address>
<abstract confidence="0.996385106132076">In this paper we provide an abstract characterisation of different kinds of robust processing in Machine Translation and Natural Language Processing systems in terms of the kinds of problem they are supposed to solve. We focus on one problem which is typically exacerbated by robust processing, and for which we know of no existing solutions. We discuss two possible approaches to this, emphasising the need to correct or repair processing malfunctions. ROBUST PROCESSING IN MACHINE TRANSLATION This paper is an attempt to provide part of the basis for a general theory of robust in Machine Translation (MT) relevance to other areas of Natural Language Processing (NLP). That is, processing which is resistant to malfunctioning however caused. The background to the paper is work on a general purpose fully automatic multi-lingual MT system within a highly decentralised organisational framework (specifically, the Eurotra system under development by the EEC). This influences us in a number of ways. Decentralised development, and the fact the system is to be general purpose formulation of a generaltheory, which abstracts away from matters of purely local relevance, and does not e.g. depend on exploiting special properties of a particular subject field (compare [7], e.g.). The fact that we consider robustness at can be seen as a result of the difficultyof MT, and the aim of full automation is reflected in concentration on a theory of robust processing,rather than &apos;developmental robustness&apos;. We not be concerned here with that arise in designing systems so that they are capable of extension and repair (e.g. not being prone to unforseen &apos;ripple effects&apos; under robustness is clearly essential, and such problems are serious, but no system which relies on this kind of robustness can ever be fully automatic. For the same reason, we will not consider the use of &apos;interactive&apos; approaches to robustness such as that of [10]. Finally, the fact that we are concerned translation militates against the kind disregard for input that is characteristic of some robust systems (PARRY [4] is an extreme example), motivates a concern with the repairor correctionof errors. It is not enough that a translation system produces superficially acceptable output for a wide class of inputs, it should aim to produce outputs which represent as nearly as possible translations of the inputs. If it cannot do this, then in some cases it will be better if it indicates as much, so that other action can be taken. From the point of view we adopt, it is possible to regard MT and NLP systems generally as sets of processes implementing relations between representations (texts can be considered representations of themselves). It is important to distinguish: (i) R: the correct, or intended relation that holds between representations (e.g. the relation &apos;is a (correct) translation of&apos;, or &apos;is tile surface constituent structure of&apos;): we have only fairly vague, pre-theoretical ideas about Rs, in virtue of being bi-lingual speakers, or having intuitive grasp of the artificial representations; (ii) T: a theoretical construct which is supposed to embody R; (iii) P: a process or program that is supposed to implement T. a robust process P, we one which operates error free for all inputs. Clearly, the of error correctness of P depends on the independent standard provided by T and R. If, for the sake of simplicity we ignore the possibility of ambiguous inputs here, we can define correctness thus: P(x)=y, and a set W such that for w in W, R(w)=y, then y is correctwith respect to R and w iff x is a member of W. Intuitively, W is the set of items for which is representation according to R. One possible source of errors in P would be if P implemented but T not embody Clearly, in this case, the only sensible solution to modify T. Since we can imagine no way of finding such errors and doing this, we will 472 ignore this possibility, and assume that T is a correctand completeembodiment of R. We can thus replace R by T in (1), and treat T as the standard of correctness below. There appear to be two possible sources of error in P: Problem (i): where P is not a correct implementation of T. One would expect this to be common where (as often in MT and NLP) T is very complex, and serious problems arise in devising implementations for them. Problem (ii): where P is a correct implementation so far as it goes, but is incom— plete, so that the domain of P is a proper—subset of the domain of T. This will also be very common: in reality processes are often faced with inputs that violate the expectations implicit in an implementation. If we disregard hardware errors, low level bugs and such malfunctions as non—termination of P (for which there are well—known solutions), there are three possible manifestations of malfunction. We will discuss them in turn. (a): P(x)=0, where P halts producing for input x, where this is not the intended output. This would be a typical response to unforseen or illformed input, and is the case of process fragility that is most often dealt with. There are two obvious solutions: (i) to manipulate the input so that it conforms to the expectations implicit in P (cf. the LIFER [8] approach to ellipsis), or to change P itself, modifying (generally relaxing) its expectations e.g. the approaches of [71, and successful, these guarantee that P produces some output for input x. However, there of course no guarantee that it is correctwith respect to T. It may be that P plus the input manipulation process, or P with relaxed expectat— ions is simply a more correct or complete implem— entation of T, but this will be fortuitous. It is more likely that making P robust in these ways will lead to errors of another kind: case (b): P(x)=z where z is not a legal output for P according to T (i.e. z is not in the range of T. such will show itself by malfunctioning in a process that P feeds. Detec— tion of such errors is straightforward: a well— formedness check on the output of P is sufficient. By itself, of course, this will lead to a proliferation of case—(a) errors in P. These can be avoided by a number of methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that they have been correctly paired by the process: e.g.in the case of a parsing process, x may be some sentence and y some representation. Obviously, the fact that x and y are legal objects for the parsing process and that y is the output of the parser for input x does not guarantee that y is a correct representation of x. Of course, robust processing should be resistant to this kind of malfunctioning also. Case—(c) errors are by far the most serious and resistant to solution because they are the hardest to detect, and because in many cases no output is preferable to superficially (misleadingly) well—formed but incorrect output. Notice also that while any process may be subject to this kind of error, making a system robust in response to case—(a) and case—(b) errors will make this class of errors more widespread: we have suggested that the likely result of changing P to make it robust will be that it no longer pairs respresentations in the manner required by T, but since any process that takes the output of P should be set up so as to expect inputs that conform to T (since this is the &apos;correct&apos; embodiment of R, we have assumed), we can expect that in general making a process robust will lead to cascades of errors. If we assume that a system is resistant to case—(a) and case—(b) errors, then it follows that inputs for which the system has to resort to robust processing will be likely to lead to case—(c) errors. Moreover, we can expect that making P robust will have made case—(c) errors more difficult to deal with. The likely result of making P robust is that it no longer implements T, but some T&apos; which is distinct from T, and for which assump— tions about correctness in relation to R no longer hold. It is obvious that the possibility of detecting case—(c) errors depends on the possibility of distinguishing T from T% Theoretically, this is unproblematic. However, in a domain such as MT it will be rather unusual for T and T&apos; to exist separately from the processes that implement them. Thus, if we are to have any chance of detecting case—(c) errors, we must be able to clearly distinguish those aspects of a process that relate to &apos;normal&apos; processing from 473 those that relate to robust processing. This distinction is not one that is made in most robust systems. We know of no existing solutions to case-(c) malfunctions. Here we will outline two possible approaches. To begin with we might consider a partial solution derived from a well-known technique in systems theory: insuring against the effect of faulty components in crucial parts of a system by computing the result for a given input by a number of different routes. For our purposes, the method would consist essentially in implementing the same theory T as a number of distinct processes to be run in parallel, comparing outputs and using statistical criteria to determine the correctness of processing. We will call this the &apos;statistical solution&apos;. (Notice that certain kinds of system architecture make this quite feasible, even given real time constraints). Clearly, while this should significantly improve the chances that output will be correct, it can provide no guarantee. Moreover, the kind of situation we are considering is more complex than that arising given failure of relatively simple pieces of hardware. In particular, to make this worthwhile, we must be able to ensure that the different Ps are genuinely distinct, and that they are reasonably complete and correct implementations of T, at the very least sufficiently complete and correct that their outputs can be sensibly compared. Unfortunately, this will be very difficult to ensure, particularly in a field such as MT, where Ts are generally very complex, and (as we have noted) are often not stated separately from the processes that implement them. The statistical approach is attractive because it seems to provide a simultaneous solution to both the detection and repair of case-(c) errors, and we consider such solutions are certainly worth further consideration. However, realistically, we expect the normal situation to be that it is difficult to produce reasonably correct and compelete distinct implementations, so that we are forced to look for an alternative approach to the detection of case-(c) errors. It is obvious that reliable detection of (c)type errors requires the implementation of a relation that pairs representations in exactly the same way as T: the obvious candidate is a process -1 , implementing the inverse of T. The basic method here would be to compute an enumeration of the set of all possible inputs W that could have yielded the actual output, given T, and some hypothetical ideal P which correctly implements it. (Again, this is not unrealistic; certain system architectures would allow forward computation to procede while this inverse processing is carried out). To make this worthwhile would involve two assumptions: -1 (i) That P terminates in reasonable time. This cannot be guaranteed, but the assumption can be rendered more reasonable by observing characteristics of the input, and thus restricting W (e.g. restricting the members of W in relation the length of the input to That construction of is somehow more straightforward than construction of P, so that -1 P is likely to be more reliable (correct and complete) than P. In fact this is not implausible for some applications (e.g. consider the case where P is a parser: it is a widely held idea that generators are easier to build than parsers). Granted these assumptions, detection of case- (c) errors is straightforward given this &apos;inverse mapping&apos; approach: one simply examines the enumeration for the actual input if it is present. it is present, then given that is likely to be more reliable than P, then it is likely that the output of P was T-correct, and hence did not constitute a case-(c) error. At least, the chances of the output of P being correct have been increased. If the input is not present, then it is likely that P has produced a case-(c) error. The response to this will depend on the domain and application -e.g. on whether incorrect but superficially well-formed output is preferable to no output at all. In the nature of things, we will ultimately be lead to the original problems of robustness, but now in connection with P. For this reason cannot forsee any completesolution to problems of robustness generally. What we have seen is that solutions to one sort of fragility are normally only partly successful, leading to errors of another kind elsewhere. Clearly, what we have to hope is that each attempt to eliminate a source of error nevertheless leads to a net decrease in the overall number of errors. On the one hand, this hope is reasonable, since sometimes the faults that give rise to processing errors are actually fixed. But there can be no general guarantee of this, so that it seems clear that merely making systems or processes robust in the ways described provides only a partial solution to the problem of processing errors. This should not be surprising. Because our primary concern is with automatic error detection and repair, we have assumed throughout that T could be considered a correct and complete of R. Of course, this in it is probable that for many processes, at least as many processing errors will from the inadequacy of T with respect to arise from the inadequacy P with respect to T. Our pre-theoretical and intuitive ability to relate representations far exceeds our ability to formulate clear theoretical statements about these relations. Given this, it would seem that error free processing depends at least as much on the correctness of theoretical models as the capacity 474 of a system to take advantage of the techniques described above. We should emphasise this because it sometimes appears as though techniques for ensuring process robustness might have a wider importance. We assumed above that T was to be regarded as a correct embodiment of R. Suppose this assumption is relaxed, and in addition that (as we have argued is likely to be the case) the robust version of P implements a relation T&apos; which is distinct from T. Now, it could, in principle, out that T&apos; is a betterembodiment of R than It worth saying that this possiblility is because it is a possibility that seems taken elsewhere: almost all the strategies we have mentioned as enhancing process robustness were originally proposed as theoretical devices to increase the adequacy of Ts in relation to Rs (e.g. by providing an account of metaphorical or other &apos;problematic&apos; usage). There can be no question that apart from improvements of T, such theoretical developments can have the side effect of increasing robustness. But notice that their justification is then not to do with robustness, but with theoretical adequacy. What must be emphasised is that the chances that a modification of a process to enhance robustness (and improve reliability) will also have the of improving the qualityof its performance are extremely slim. We cannot expect robust processing to produce results which are as good as those that would result from &apos;ideal&apos; (optimal/nonrobust) processing. In fact, we have suggested that existing techniques for ensuring process robustness typically have the effect of changing the theory the process implements, changing the relationship between representations that the system defines in ways which do not preserve the relationship relationship between representations that the designers intended, so that processes have been made robust by existing methods be expected to produce output of lower than intended quality. These remarks are intended to emphasise the importance of clear, complete, and correct theoretical models of the pre-theoretical relationships between the representations involved in systems for which error free &apos;robust&apos; operation important, and to emphasise the need for approaches to robustness (such as the two we have outlined above) that make it more likely that robust processes will maintain the relationship between representations that the designers of the &apos;normal/optimal&apos; processes intended. That is, to emphasise the need to detect and repair so as to promote correctprocessing. AKNOWLEDGEMENTS Our debt to the Eurotra project is great: collaboration on this paper developed out of work on Eurotra and has only been possible because of opportunities made available by the project. Some the ideas in this first aired in Eurotra report ETL-3 ([41), and in a paper presented at the Cranfield conference on MT earlier this year. We would like to thank all our friends and colleagues in the project and our institutions. The views (and, in particular, the errors) in this paper are our own responsibility, and should not be interpreted as &apos;official&apos; Eurotra doctrine. REFERENCES 1. ARNOLD, D.J. &amp; JOHNSON, R. (1984) &amp;quot;Approaches to Robust Processing in Machine Translation&amp;quot; Cognitive Studies Memo, University of Essex.</abstract>
<note confidence="0.97550715">2. BDITET, CH. (1984) &amp;quot;Research and Development on MT and Related Techniques at Grenoble University&amp;quot; paper presented at Lugano MT tutorial April 1984. 3. BOITET, CH. &amp; NEDOBEJKINE, N. (1980) &amp;quot;Russian- French at GETA: an outline of method and a detailed example&amp;quot; RR 219, GETA, Grenoble. COLBY, K.(1975) ParanoiaPergamon Press, Oxford. 5. ETL-1-NL/B &amp;quot;Transfer (Taxonomy, Safety Nets, Strategy), Report by the Belgo-Dutch Eurotra Group, August 1983. 6. ETL-3 Final &apos;Trio&apos; Report by the Eurotra Central Linguistics Team (Arnold, Jaspaert, Des Tombe), February 1984. 7. HAYES, P.J. and MOURADIAN, G.V. (1981): &amp;quot;Flexible parsing&amp;quot;, AJCL 7, 4:232-242. 8. HENDRIX, G.G. (1977) &amp;quot;Human Engineering for Natural Language Processing&amp;quot; Proc. IJCAI, 183-191, MIT Press. 9. KWASNY, S.C. and SONDHEIMER, N.K. (1981):</note>
<title confidence="0.8239425">amp;quot;Relaxation Techniques for Parsing Grammatically Ill-formed Input in Natural Language Understanding</title>
<note confidence="0.914931">Systems&amp;quot;. AJCL 7, 2:99-108. 10. WEISCHEDEL, R.M, and BLACK, J. (1980) &apos;Responding Intelligently to Unparsable Inputs&apos; AJCL 6.2: 97-109. 11. WILKS, Y. (1975): &amp;quot;A Preferential Pattern Matching Semantics for Natural Language&amp;quot;. A.I. 6:53-74. 475</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D J ARNOLD</author>
<author>R JOHNSON</author>
</authors>
<title>Approaches to Robust Processing in Machine Translation&amp;quot;</title>
<date>1984</date>
<institution>Cognitive Studies Memo, University of Essex.</institution>
<contexts>
<context position="7246" citStr="[1]" startWordPosition="1230" endWordPosition="1230">f methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that they have been correctly paired by the process: e.g</context>
</contexts>
<marker>1.</marker>
<rawString>ARNOLD, D.J. &amp; JOHNSON, R. (1984) &amp;quot;Approaches to Robust Processing in Machine Translation&amp;quot; Cognitive Studies Memo, University of Essex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CH BDITET</author>
</authors>
<title>Research and Development on MT and Related Techniques at Grenoble University&amp;quot; paper presented at Lugano MT tutorial</title>
<date>1984</date>
<contexts>
<context position="7196" citStr="[2]" startWordPosition="1221" endWordPosition="1221">a) errors in P. These can be avoided by a number of methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that t</context>
</contexts>
<marker>2.</marker>
<rawString>BDITET, CH. (1984) &amp;quot;Research and Development on MT and Related Techniques at Grenoble University&amp;quot; paper presented at Lugano MT tutorial April 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N NEDOBEJKINE</author>
</authors>
<title>RussianFrench at GETA: an outline of method and a detailed example&amp;quot; RR 219,</title>
<date>1980</date>
<location>GETA, Grenoble.</location>
<contexts>
<context position="7201" citStr="[3]" startWordPosition="1222" endWordPosition="1222">rors in P. These can be avoided by a number of methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that they h</context>
</contexts>
<marker>3.</marker>
<rawString>BOITET, CH. &amp; NEDOBEJKINE, N. (1980) &amp;quot;RussianFrench at GETA: an outline of method and a detailed example&amp;quot; RR 219, GETA, Grenoble.</rawString>
</citation>
<citation valid="false">
<authors>
<author>COLBY</author>
</authors>
<booktitle>K.(1975) Artificial Paranoia</booktitle>
<publisher>Pergamon Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="2405" citStr="[4]" startWordPosition="377" endWordPosition="377">h problems that arise in designing systems so that they are capable of extension and repair (e.g. not being prone to unforseen &apos;ripple effects&apos; under modification). Developmental robustness is clearly essential, and such problems are serious, but no system which relies on this kind of robustness can ever be fully automatic. For the same reason, we will not consider the use of &apos;interactive&apos; approaches to robustness such as that of [10]. Finally, the fact that we are concerned with translation militates against the kind of disregard for input that is characteristic of some robust systems (PARRY [4] is an extreme example), and motivates a concern with the repair or correction of errors. It is not enough that a translation system produces superficially acceptable output for a wide class of inputs, it should aim to produce outputs which represent as nearly as possible translations of the inputs. If it cannot do this, then in some cases it will be better if it indicates as much, so that other action can be taken. From the point of view we adopt, it is possible to regard MT and NLP systems generally as sets of processes implementing relations between representations (texts can be considered </context>
</contexts>
<marker>4.</marker>
<rawString>COLBY, K.(1975) Artificial Paranoia Pergamon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<title>ETL-1-NL/B &amp;quot;Transfer (Taxonomy, Safety Nets, Strategy), Report by the Belgo-Dutch Eurotra Group,</title>
<date>1983</date>
<contexts>
<context position="7206" citStr="[5]" startWordPosition="1223" endWordPosition="1223">in P. These can be avoided by a number of methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that they have b</context>
</contexts>
<marker>5.</marker>
<rawString>ETL-1-NL/B &amp;quot;Transfer (Taxonomy, Safety Nets, Strategy), Report by the Belgo-Dutch Eurotra Group, August 1983.</rawString>
</citation>
<citation valid="true">
<title>ETL-3 Final &apos;Trio&apos; Report by the Eurotra Central Linguistics Team</title>
<date>1984</date>
<location>(Arnold, Jaspaert, Des Tombe),</location>
<contexts>
<context position="7211" citStr="[6]" startWordPosition="1224" endWordPosition="1224"> These can be avoided by a number of methods, in particular: (i) introducing some process to manipulate the output of P to make it well—formed according to T, or (ii) attempting to set up processes that feed on P so that they can use &apos;abnormal&apos; or &apos;non— standard&apos; output from P (e.g. partial representat— ions, or complete intermediate representations produced within P. or alternative representations constructed within P which can be more reliably computed than the &apos;normal&apos; intended output of P (the representational theories of GETA and Eurotra are designed with this in mind: cf. [2], [3], [5], [6], and references there, and see [1] for fuller discussion of these issues). Again, it is conceivable that the result of this may be to produce a robust P that implements T more correct— ly or completely, but again this will be fortuit— ous. The most likely result will be robust P will now produce errors of the third type: case (c): P(x)=y, where y is a legal output for P according to T, but is not the intended output according to T. i.e. y is in the range of T, but y4T(x). Suppose both input x and output y of some process are legal objects, it nevertheless does not follow that they have been c</context>
</contexts>
<marker>6.</marker>
<rawString>ETL-3 Final &apos;Trio&apos; Report by the Eurotra Central Linguistics Team (Arnold, Jaspaert, Des Tombe), February 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J HAYES</author>
<author>G V MOURADIAN</author>
</authors>
<title>Flexible parsing&amp;quot;,</title>
<date>1981</date>
<journal>AJCL</journal>
<volume>7</volume>
<pages>4--232</pages>
<contexts>
<context position="1528" citStr="[7]" startWordPosition="231" endWordPosition="231">sing which is resistant to malfunctioning however caused. The background to the paper is work on a general purpose fully automatic multi-lingual MT system within a highly decentralised organisational framework (specifically, the Eurotra system under development by the EEC). This influences us in a number of ways. Decentralised development, and the fact that the system is to be general purpose motivate the formulation of a general theory, which abstracts away from matters of purely local relevance, and does not e.g. depend on exploiting special properties of a particular subject field (compare [7], e.g.). The fact that we consider robustness at all can be seen as a result of the difficulty of MT, and the aim of full automation is reflected in our concentration on a theory of robust processing, rather than &apos;developmental robustness&apos;. We will not be concerned here with problems that arise in designing systems so that they are capable of extension and repair (e.g. not being prone to unforseen &apos;ripple effects&apos; under modification). Developmental robustness is clearly essential, and such problems are serious, but no system which relies on this kind of robustness can ever be fully automatic. </context>
</contexts>
<marker>7.</marker>
<rawString>HAYES, P.J. and MOURADIAN, G.V. (1981): &amp;quot;Flexible parsing&amp;quot;, AJCL 7, 4:232-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G HENDRIX</author>
</authors>
<title>Human Engineering for Applied Natural Language Processing&amp;quot;</title>
<date>1977</date>
<booktitle>Proc. 5th IJCAI,</booktitle>
<pages>183--191</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5672" citStr="[8]" startWordPosition="953" endWordPosition="953">we disregard hardware errors, low level bugs and such malfunctions as non—termination of P (for which there are well—known solutions), there are three possible manifestations of malfunction. We will discuss them in turn. case (a): P(x)=0, where T(x)00 i.e. P halts producing 0 output for input x, where this is not the intended output. This would be a typical response to unforseen or illformed input, and is the case of process fragility that is most often dealt with. There are two obvious solutions: (i) to manipulate the input so that it conforms to the expectations implicit in P (cf. the LIFER [8] approach to ellipsis), or to change P itself, modifying (generally relaxing) its expectations (cf. e.g. the approaches of [71, Oh [10] and DM. If successful, these guarantee that P produces some output for input x. However, there is of course no guarantee that it is correct with respect to T. It may be that P plus the input manipulation process, or P with relaxed expectat— ions is simply a more correct or complete implem— entation of T, but this will be fortuitous. It is more likely that making P robust in these ways will lead to errors of another kind: case (b): P(x)=z where z is not a legal</context>
</contexts>
<marker>8.</marker>
<rawString>HENDRIX, G.G. (1977) &amp;quot;Human Engineering for Applied Natural Language Processing&amp;quot; Proc. 5th IJCAI, 183-191, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C KWASNY</author>
<author>N K SONDHEIMER</author>
</authors>
<title>Relaxation Techniques for Parsing Grammatically Ill-formed Input in Natural Language Understanding Systems&amp;quot;.</title>
<date>1981</date>
<journal>AJCL</journal>
<volume>7</volume>
<pages>2--99</pages>
<marker>9.</marker>
<rawString>KWASNY, S.C. and SONDHEIMER, N.K. (1981): &amp;quot;Relaxation Techniques for Parsing Grammatically Ill-formed Input in Natural Language Understanding Systems&amp;quot;. AJCL 7, 2:99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M WEISCHEDEL</author>
<author>J BLACK</author>
</authors>
<title>Responding Intelligently to Unparsable Inputs&apos;</title>
<date>1980</date>
<journal>AJCL</journal>
<volume>6</volume>
<pages>97--109</pages>
<contexts>
<context position="2240" citStr="[10]" startWordPosition="351" endWordPosition="351">e aim of full automation is reflected in our concentration on a theory of robust processing, rather than &apos;developmental robustness&apos;. We will not be concerned here with problems that arise in designing systems so that they are capable of extension and repair (e.g. not being prone to unforseen &apos;ripple effects&apos; under modification). Developmental robustness is clearly essential, and such problems are serious, but no system which relies on this kind of robustness can ever be fully automatic. For the same reason, we will not consider the use of &apos;interactive&apos; approaches to robustness such as that of [10]. Finally, the fact that we are concerned with translation militates against the kind of disregard for input that is characteristic of some robust systems (PARRY [4] is an extreme example), and motivates a concern with the repair or correction of errors. It is not enough that a translation system produces superficially acceptable output for a wide class of inputs, it should aim to produce outputs which represent as nearly as possible translations of the inputs. If it cannot do this, then in some cases it will be better if it indicates as much, so that other action can be taken. From the point </context>
<context position="5807" citStr="[10]" startWordPosition="974" endWordPosition="974"> there are three possible manifestations of malfunction. We will discuss them in turn. case (a): P(x)=0, where T(x)00 i.e. P halts producing 0 output for input x, where this is not the intended output. This would be a typical response to unforseen or illformed input, and is the case of process fragility that is most often dealt with. There are two obvious solutions: (i) to manipulate the input so that it conforms to the expectations implicit in P (cf. the LIFER [8] approach to ellipsis), or to change P itself, modifying (generally relaxing) its expectations (cf. e.g. the approaches of [71, Oh [10] and DM. If successful, these guarantee that P produces some output for input x. However, there is of course no guarantee that it is correct with respect to T. It may be that P plus the input manipulation process, or P with relaxed expectat— ions is simply a more correct or complete implem— entation of T, but this will be fortuitous. It is more likely that making P robust in these ways will lead to errors of another kind: case (b): P(x)=z where z is not a legal output for P according to T (i.e. z is not in the range of T. Typically, such an error will show itself by malfunctioning in a process</context>
</contexts>
<marker>10.</marker>
<rawString>WEISCHEDEL, R.M, and BLACK, J. (1980) &apos;Responding Intelligently to Unparsable Inputs&apos; AJCL 6.2: 97-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y WILKS</author>
</authors>
<title>A Preferential Pattern Matching Semantics for Natural Language&amp;quot;.</title>
<date>1975</date>
<journal>A.I.</journal>
<pages>6--53</pages>
<marker>11.</marker>
<rawString>WILKS, Y. (1975): &amp;quot;A Preferential Pattern Matching Semantics for Natural Language&amp;quot;. A.I. 6:53-74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>