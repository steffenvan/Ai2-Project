<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.032693">
<title confidence="0.9997515">
A Dependency-Driven Parser for German
Dependency and Constituency Representations
</title>
<author confidence="0.990969">
Johan Hall
</author>
<affiliation confidence="0.8029695">
V¨axj¨o University
Sweden
</affiliation>
<email confidence="0.993713">
johan.hall@vxu.se
</email>
<author confidence="0.98606">
Joakim Nivre
</author>
<affiliation confidence="0.871105">
V¨axj¨o University and
Uppsala University
Sweden
</affiliation>
<email confidence="0.995343">
joakim.nivre@vxu.se
</email>
<sectionHeader confidence="0.995577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999379928571429">
We present a dependency-driven parser that
parses both dependency structures and con-
stituent structures. Constituency representa-
tions are automatically transformed into de-
pendency representations with complex arc la-
bels, which makes it possible to recover the
constituent structure with both constituent la-
bels and grammatical functions. We report a
labeled attachment score close to 90% for de-
pendency versions of the TIGER and T¨uBa-
D/Z treebanks. Moreover, the parser is able to
recover both constituent labels and grammat-
ical functions with an F-Score over 75% for
T¨uBa-D/Z and over 65% for TIGER.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999808166666667">
Is it really that difficult to parse German? K¨ubler et
al. (2006) point out three grammatical features that
could make parsing of German more difficult: finite
verb placement, flexible phrase ordering and discon-
tinuous constituents. Earlier studies by Dubey and
Keller (2003) and Dubey (2005) using the Negra
treebank (Skut et al., 1997) reports that lexicaliza-
tion of PCFGs decrease the parsing accuracy when
parsing Negra’s flat constituent structures. However,
K¨ubler et al. (2006) present a comparative study
that suggests that it is not harder to parse German
than for example English. By contrast, Rehbein and
van Genabith (2007) study different parser evalua-
tion metrics by simulating parser errors on two Ger-
man treebanks (with different treebank annotation
schemes) and they claim that the question whether
German is harder to parse than English is still unde-
cided.
</bodyText>
<page confidence="0.989735">
47
</page>
<bodyText confidence="0.999909">
This paper does not try to answer the question
above, but presents a new way of parsing constituent
structures that can output the whole structure with
all grammatical functions. The shared task on pars-
ing German was to parse both the constituency ver-
sion and the dependency version of the two Ger-
man treebanks: TIGER (Brants et al., 2002) and
T¨uBa-D/Z (Telljohann et al., 2005). We present a
dependency-driven parser that parses both depen-
dency structures and constituent structures using an
extended version of MaltParser 1.0.1 The focus of
this paper is how MaltParser parses the constituent
structures with a dependency-based algorithm.
This paper is structured as follows. Section 2
briefly describes the MaltParser system, while sec-
tion 3 continues with presenting the dependency
parsing. Section 4 explains how a transition-based
dependency-driven parser can be turned into a con-
stituency parser. Section 5 presents the experimen-
tal evaluation and discusses the results. Finally sec-
tion 6 concludes.
</bodyText>
<sectionHeader confidence="0.996504" genericHeader="introduction">
2 MaltParser
</sectionHeader>
<bodyText confidence="0.999850875">
MaltParser is a transition-based parsing system
which was one of the top performing systems on
multilingual dependency parsing in the CoNLL
2006 shared task (Buchholz and Marsi, 2006; Nivre
et al., 2006) and the CoNLL shared task 2007 (Nivre
et al., 2007; Hall et al., 2007). The basic idea of
MaltParser is to derive dependency graphs using a
greedy parsing algorithm that approximates a glob-
</bodyText>
<footnote confidence="0.998638666666667">
1MaltParser is distributed with an open-source license
and can be downloaded free of charge from following page:
http://www.vxu.se/msi/users/jha/maltparser/
</footnote>
<note confidence="0.8019915">
Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 47–54,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.99893785">
ally optimal solution by making a sequence of lo-
cally optimal choices. The system is equipped with
several parsing algorithms, but we have chosen to
only optimize Nivre’s parsing algorithm for both
the dependency track and the constituency track.
Nivre’s algorithm is a deterministic algorithm for
building labeled projective dependency structures in
linear time (Nivre, 2006). There are two essential
parameters that can be varied for this algorithm. The
first is the arc order and we selected the arc-eager or-
der that attaches the right dependents to their head as
soon as possible. The second is the stack initializa-
tion and we chose to use an empty stack initializa-
tion that attaches root dependents with a default root
label after completing the left-to-right pass over the
input.
The algorithm uses two data structures: a stack
to store partially processed tokens and a queue of
remaining input tokens. The arc-eager transition-
system has four parser actions:
</bodyText>
<listItem confidence="0.9828931">
1. LEFT-ARC(r): Adds an arc labeled r from the
next input token to the top token of the stack,
the top token is popped from the stack because
it must be complete with respect to left and
right dependents at this point.
2. RIGHT-ARC(r): Adds an arc labeled r from
the top token of the stack to the next input token
and pushes the next input token onto the stack
(because it may have dependents further to the
right).
3. REDUCE: Pops the top token of the stack. This
transition can be performed only if the top to-
ken has been assigned a head and is needed for
popping a node that was pushed in a RIGHT-
ARC(r) transition and which has since found
all its right dependents.
4. SHIFT: Pushes the next input token onto the
stack. This is correct when the next input token
has its head to the right or should be attached
to the root.
</listItem>
<bodyText confidence="0.99928959375">
MaltParser uses history-based feature models for
predicting the next parser action at nondeterminis-
tic choice points. Previously, MaltParser combined
the prediction of the transition with the prediction of
the arc label r into one complex prediction with one
feature model. The experiments presented in this pa-
per use another prediction strategy, which divide the
prediction of the parser action into several predic-
tions. First the transition is predicted; if the transi-
tion is SHIFT or REDUCE the nondeterminism is re-
solved, but if the predicted transition is RIGHT-ARC
or LEFT-ARC the parser continues to predict the arc
label r. This prediction strategy enables the system
to have three different feature models: one for pre-
dicting the transition and two for predicting the arc
label r (RIGHT-ARC and LEFT-ARC). We will see
in section 4 that this change makes it more feasi-
ble to encode the inverse mapping into complex arc
labels for an arbitrary constituent structure without
losing any information.
All symbolic features were converted to nu-
merical features and we use the quadratic kernel
K(xZ7 xj) = (-yxT xj + r)2 of the LIBSVM pack-
age (Chang and Lin, 2001) for mapping histories to
parser actions and arc labels. All results are based
on the following settings of LIBSVM: -y = 0.2 and
r = 0 for the kernel parameters, C = 0.5 for the
penalty parameter, and E = 1.0 for the termination
criterion. We also split the training instances into
smaller sets according to the fine-grained part-of-
speech of the next input token to train separate one-
versus-one multi-class LIBSVM-classifiers.
</bodyText>
<sectionHeader confidence="0.993562" genericHeader="method">
3 Dependency Parsing
</sectionHeader>
<bodyText confidence="0.999883166666667">
Parsing sentences with dependency structures like
the one in Figure 1 is straightforward using Malt-
Parser. During training, the parser reconstructs the
correct transition sequence needed to derive the gold
standard dependency graph of a sentence. This in-
volves choosing a label r for each arc, which in
a pure dependency structure is an atomic symbol.
For example, in Figure 1, the arc from hat to Beck-
meyer is labeled SUBJ. This is handled by train-
ing a separate labeling model for RIGHT-ARC and
LEFT-ARC. During parsing, the sentence is pro-
cessed in the same way as during training except that
the parser requests the next transition from the tran-
sition classifier. If the predicted transition is an arc
transition (RIGHT-ARC or LEFT-ARC), it then asks
the corresponding classifier for the arc label r.
One complication when parsing the dependency
version of the two German treebanks is that they
</bodyText>
<page confidence="0.998819">
48
</page>
<figureCaption confidence="0.9993895">
Figure 1: The sentence ”For this statement has Beckmeyer until now not presented any evidence.” is taken from
dependency version of T¨uBa-D/Z treebank.
</figureCaption>
<bodyText confidence="0.999843333333333">
contain non-projective structures, such as the depen-
dency graph illustrated in Figure 1. Nivre’s pars-
ing algorithm only produces projective dependency
structures, and therefore we used pseudo-projective
parsing for recovering non-projective structures.
The training data are projectivized and information
about these transformations is encoded into the arc
labels to enable deprojectivizition of the parser out-
put (Nivre and Nilsson, 2005).
</bodyText>
<sectionHeader confidence="0.981624" genericHeader="method">
4 Constituency Parsing
</sectionHeader>
<bodyText confidence="0.999873130434783">
This section explains how a transition-based depen-
dency parser can be used for parsing constituent
structures. The basic idea is to use the common
practice of transforming a constituent structure into
a dependency graph and encode the inverse mapping
with complex arc labels. Note that the goal is not to
create the best dependency representation of a con-
stituent structure. Instead the main objective is to
find a general method to transform constituency to
dependency so that is easy to do the inverse trans-
formation without losing any information. More-
over, another goal is to transform the constituent
structures so that it is feasible for a transition-based
dependency parser to induce a parser model based
on the resulting dependency graphs and during pars-
ing use this parser model to derive constituent struc-
tures with the highest accuracy possible. Hence, the
transformation described below is not designed with
the purpose of deriving a linguistically sound depen-
dency graph from a constituent structure.
Our strategy for turning a dependency parser into
a constituency parser can be summarized with the
following steps:
</bodyText>
<listItem confidence="0.998166307692308">
1. Identify the lexical head of every constituent in
the constituent structure.
2. Identify the head of every token in the depen-
dency structure.
3. Build a labeled dependency graph that encodes
the inverse mapping in the arc labels.
4. Induce a parser model based on the labeled de-
pendency graphs.
5. Use the induced parser model to parse new sen-
tences into dependency graphs.
6. Derive the constituent structure by performing
the inverse mapping encoded in the dependency
graph produced in step 5.
</listItem>
<subsectionHeader confidence="0.990922">
4.1 Identify the Heads
</subsectionHeader>
<bodyText confidence="0.999979444444444">
The first steps are basically the steps that are used
to convert a constituent structure to a dependency
structure. One way of doing this is to traverse the
constituent structure from the root node and iden-
tify the head-child and the lexical head of all con-
stituent nodes in a recursive depth-first search. Usu-
ally this process is governed by pre-defined head-
finding rules that define the direction of the search
for each distinct constituent label. Moreover, it
is quite common that the head-finding rules define
some kind of priority lists over which part of speech
or grammatical function is the more preferable head-
child.
For our experiment on German we have kept this
search of the head-child and lexical head very sim-
ple. For the TIGER treebank we perform a left-
to-right search to find the leftmost lexical child. If
no lexical child can be found, the head-child of the
</bodyText>
<page confidence="0.996741">
49
</page>
<bodyText confidence="0.999990434782608">
constituent will be the leftmost constituent child and
the lexical head will be the lexical child of the head
child recursively. For the T¨uBa-D/Z treebank we got
higher accuracy if we varied the direction of search
according to the label of the target constituent.2 We
also tried more complex and linguistically motivated
head rules, but unfortunately no improvement in ac-
curacy could be found. We want to stress that the
use of more complex head rules was done late in the
parser optimization process and it would not be a
surprise if more careful experiments resulted in the
opposite conclusion.
Given that all constituents have been assigned a
lexical head it is a straightforward process to iden-
tify the head and the dependents of all input tokens.
The algorithm investigates, for each input token, the
containing constituent’s lexical head, and if the to-
ken is not the lexical head of the constituent it takes
the lexical head as its head in the dependency graph;
otherwise the head will be assigned the lexical head
of a higher constituent in the structure. The root of
the dependency graph will be the lexical head of the
root of the constituent structure.
</bodyText>
<subsectionHeader confidence="0.994242">
4.2 Build a Labeled Dependency Graph
</subsectionHeader>
<bodyText confidence="0.9999305">
The next step builds a labeled dependency represen-
tation that encodes the inverse mapping in the arc
labels of the dependency graph. Each arc label is a
quadruple consisting of four sublabels (dependency
relation, head relations, constituent labels, attach-
ment). The meaning of each sublabel is following:
</bodyText>
<listItem confidence="0.8899215">
• The dependency relation is the grammatical
function of the highest constituent of which the
dependent is the lexical head.
• The head relations encode the path of function
labels from the dependent to the highest con-
stituent of which is the lexical head (with path
elements separated by |).
• The constituent labels encode the path of con-
stituent labels from the dependent to the highest
constituent of which is the lexical head (with
path elements separated by |).
2It was beneficial to make a right-to-left search for the fol-
lowing labels: ADJX, ADVX, DM, DP, NX, PX
• The attachment is a non-negative integer i that
encodes the attachment level of the highest con-
stituent of which it is the lexical head.
</listItem>
<subsectionHeader confidence="0.998677">
4.3 Encoding Example
</subsectionHeader>
<bodyText confidence="0.999972675">
Figure 2 illustrates the procedure of encoding the
constituency representation as a dependency graph
with complex arc labels for a German sentence.
The constituent structure is shown above the sen-
tence and below we can see the resulting depen-
dency graph after the transformation. We want to
stress that the resulting dependency graph is not lin-
guistically sound, and the main purpose is to demon-
strate how a constituent structure can be encoded in
a dependency graph that have all information need
for the inverse transformation.
For example, the constituent MF has no lexical
child and therefore the head-child is the leftmost
constituent NX. The lexical head of MF is the token
Beckmeyer because it is the lexical head of NX. For
the same reason the lexical head of the constituent
SIMPX is the token F¨ur and this token will be the
head of the token Beckmeyer, because SIMPX dom-
inates MF. In the dependency graph this is illustrated
with an arc from the head F¨ur to its dependent Beck-
meyer.
The arc F¨ur to Beckmeyer is labeled with a com-
plex label (??, HD|ON, NX|MF, 2), which consists
of four sublabels. The first sublabel is the grammat-
ical function above MF and because this is missing
a dummy label ?? is used instead. The sublabel
HD|ON encodes a sequence of head relations from
the lexical head Beckmeyer to MF. The constituent
labels are encoded in the same way in the third sub-
label NX|MF. Finally, the fourth sublabel indicates
the attachment level of the constituent MF. In this
case, MF should be attached to the constituent two
levels up in the structure with respect to the head
F¨ur.3
The two arcs diese to Behauptung and keinen to
Nachweis both have the complex arc label (HD, *, *,
0), because the tokens Behauptung and Nachweis are
attached to a constituent without being a lexical head
of any dominating constituent. Consequently, there
are no sequences of head relations and constituent
</bodyText>
<footnote confidence="0.965788333333333">
3If the fourth sublabel had an attachment level of 1, then the
constituent MF would be attached to the constituent VF instead
of the constituent SIMPX.
</footnote>
<page confidence="0.996386">
50
</page>
<figureCaption confidence="0.995495">
Figure 2: The sentence ”For this statement has Beckmeyer until now not presented any evidence.” is taken from
T¨uBa-D/Z treebank and show the encoding of a constituent structure as a dependency graph.
</figureCaption>
<bodyText confidence="0.99937175">
labels to encode, and these are therefore marked *.
The encoding of the virtual root VROOT is treated
in a special way and the label VROOT is regarded as
a dependency relation instead of a constituent label.
If we compare the dependency graphs in Figure 1
and Figure 2, we can see large differences. The more
linguistically motivated dependency graph (LDG) in
Figure 1 has a completely difference structure and
different arc labels compared to the automatically
generated dependency graph (ADG) in Figure 2.
There are several reasons, some of which are listed
here:
</bodyText>
<listItem confidence="0.97973875862069">
• Different conversions strategies: LDG is based
on a conversion that sometimes leads to non-
projective structures for non-local dependen-
cies. For example, in Figure 2, the extracted
PP F¨ur diese Behauptung has the grammati-
cal function OAMOD, which indicates that it
is a modifier (MOD) of a direct object (OA)
elsewhere in the structure (in this case keinen
Nachweis). In LDG, this is converted to a non-
projective dependency from Nachweis to F¨ur
(with the label PP). No such transformtion is
attempted in ADC, which simply attaches F¨ur
to the lexical head of the containing constituent.
• Different head-finding rules: ADG are derived
without almost no rules at all. Most likely, the
conversion of LDG makes use of several lin-
guistically sound head-finding rules. A striking
difference is the root of the dependency graph,
where LDG has its root at the linguistically mo-
tivated token hat. Whereas ADG has its root at
the end of the sentence, because the leftmost
lexical child of the virtual root VROOT is the
punctuation.
• Different arc labels: ADG encodes the con-
stituent structure in the complex arc labels to
be able to recover the constituent structure,
whereas LDG have linguistically motivated de-
pendency relations that are not present in the
constituent structure.
</listItem>
<bodyText confidence="0.990601333333333">
We believe that our simplistic approach can be fur-
ther improved by using ideas from the conversion
process of LDG.
</bodyText>
<page confidence="0.996356">
51
</page>
<subsectionHeader confidence="0.953809">
4.4 Inverse Mapping
</subsectionHeader>
<bodyText confidence="0.999975857142857">
The last step of our presented strategy is to make the
inverse transformation from a dependency graph to
a constituent structure. This is done by a bottom-
up and top-down process of the dependency graph.
First we iterate over all tokens in the dependency
graph and restore the sequence of constituent nodes
with constituent labels and grammatical functions
for each individual token using the information of
the sublabels head relations and constituent labels.
After this bottom-up process we have the lineage of
constituents for each token where the token is the
lexical head. The top-down process then traverse
the dependency graph recursively from the root with
pre-order depth-first search. For each token, the
highest constituent of the lineage of the token is at-
tached to its head lineage at an attachment level ac-
cording to the sublabel attachment. Finally, the edge
between the dominating constituent and the highest
constituent of the lineage is labeled with a grammat-
ical function according to the sublabel dependency
relation.
</bodyText>
<subsectionHeader confidence="0.990024">
4.5 Parsing
</subsectionHeader>
<bodyText confidence="0.999961285714286">
For the constituency versions of both TIGER and
T¨uBa-D/Z we can recover the constituent structure
without any loss of information, if we transform
from constituency to dependency and back again to
constituency. During parsing we predict the sub-
labels separately with separate feature models for
RIGHT-ARC and LEFT-ARC. Moreover, the parsed
constituent structure can contain discontinuous con-
stituency because of wrong attachment levels of con-
stituents. To overcome this problem, the structure
is post-processed and the discontinuous constituents
are forced down in the structure so that the parser
output can be represented in a nested bracketing for-
mat.
</bodyText>
<sectionHeader confidence="0.999011" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999918428571428">
The shared task on parsing German consisted of
parsing either the dependency version or the con-
stituency version of two German treebanks, al-
though we chose to parse both versions. This section
first presents the data sets used. We continue with a
brief overview of how we optimized the four differ-
ent parser models. Finally, the results are discussed.
</bodyText>
<subsectionHeader confidence="0.997767">
5.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.999986735294118">
The prepared training and development data dis-
tributed by the organizers were based on the German
TIGER (Brants et al., 2002) and T¨uBa-D/Z (Telljo-
hann et al., 2005) treebanks, one dependency and
one constituency version for each treebank. Both
treebanks contain German newspaper text and the
prepared data sets were of the same size. The devel-
opment set contained 2611 sentences and the train-
ing set contained 20894 sentences. The dependency
and constituency versions contained the same set of
sentences.
The dependency data were formated according
to the CoNLL dependency data format.4 The
LEMMA, FEATS, PHEAD and PDEPREL columns
of the CoNLL format were not used at all.
The constituency data have been converted into a
bracketing format similar to the Penn Treebank for-
mat. All trees are dominated by a VROOT node
and all constituents are continuous. The test data
consisted of sentences with gold-standard part-of-
speech tags and also the gold-standard grammatical
functions attached to the part-of-speech tags. Unfor-
tunately, we were not aware of that the grammatical
functions attached to the part-of-speech tags should
be regarded as input to the parser and therefore our
presented results are based on not using the gram-
matical functions attached to the part-of-speech tags
as input to the parser.
We divided the development data into two sets,
one set used for parser optimization (80%) and the
other 20% we saved for final preparation before the
release of the test data. For the final test run we
trained parser models on all the data, both the train-
ing data and the development data.
</bodyText>
<subsectionHeader confidence="0.999407">
5.2 Parser optimization
</subsectionHeader>
<bodyText confidence="0.999916833333333">
We ran several experiments to optimize the four dif-
ferent parser models. The optimization of the de-
pendency versions was conducted in a way simi-
lar to the parser optimization of MaltParser in the
CoNLL shared tasks (Nivre et al., 2006; Hall et al.,
2007). A new parameter for the extended version
</bodyText>
<footnote confidence="0.9941528">
4More information about the CoNLL dependency data for-
mat can be found at: http://nextens.uvt.nl/ conll/#dataformat.
Yannick Versley has done work of converting both treebanks to
a dependency annotation that is similar to the Hamburg depen-
dency format.
</footnote>
<page confidence="0.998567">
52
</page>
<bodyText confidence="0.999942025641026">
of MaltParser 1.0 is the prediction strategy, where
we could choose between combining the prediction
of the transition with the prediction of the arc label
into one complex prediction or dividing the predic-
tion of the parser action into two predictions (one
model for predicting the transition and two models
for predicting the arc label depending on the out-
come of the transition-model). It was beneficial to
use the divided predication strategy for all four data
sets. In the next step we performed a feature opti-
mization with both forward and backward selection,
starting from a model extrapolated from many pre-
vious experiments on different languages. Because
we chose to use the divided predication strategy this
step was more complicated compared to using the
combined strategy, because we needed to optimize
three feature models (one transition-model and two
arc-label models, one for RIGHT-ARC and one for
LEFT-ARC).
The optimization of the constituency versions was
even more complex because each parser model con-
tained nine feature models (one transition-model,
two models for each sublabel). Another problem
for the parser optimization was the fact that we tried
out new ideas and for example changed the encod-
ing a couple of times. Due to the time constraints
of the shared task it was not possible to start parser
optimization all over again for every change. We
also performed some late experiments with different
head-finding rules to make the intermediate depen-
dency graphs more linguistically sound, but unfor-
tunately these experiments did not improve the pars-
ing accuracy. We want to emphasize that the time
for developing the extended version of MaltParser
to handle constituency was severely limited, espe-
cially the implementation of head-finding rules, so
it is very likely that head-finding rules can improve
parsing accuracy after more careful testing and ex-
periments.
</bodyText>
<subsectionHeader confidence="0.707112">
5.3 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999589571428571">
The results based on the prepared test data for the de-
pendency and constituency tracks are shown in table
1. The label attachment score (LAS) was used by the
organizer for evaluating the dependency versions,
that is, the proportion of tokens that are assigned the
correct head and the correct arc label (punctuation
included). We can see that the dependency results
</bodyText>
<table confidence="0.99666775">
Dependency Constituency
Treebank LAS LP LR LF
TIGER 90.80 67.06 63.40 65.18
T¨uBa-D/Z 88.64 76.44 74.79 75.60
</table>
<tableCaption confidence="0.977122666666667">
Table 1: The results for the extended version of Malt-
Parser 1.0 in the shared task on parsing German depen-
dency and constituency representations.
</tableCaption>
<bodyText confidence="0.999493717948718">
are close to 90% for both the treebanks, 90.80 for
TIGER and 88.64 for T¨uba-D/Z, which were the un-
challenged best scores in the shared task. The high-
est score on parsing German in the CoNLL-X shared
task was obtained by the system of McDonald et al.
(2006) with a LAS of 87.34 based on the TIGER
treebank, but we want to stress that these results
are not comparable due to different data sets (and
a different policy regarding the inclusion of punctu-
ation).
The constituency versions were evaluated accord-
ing to the labeled recall (LR), labeled precision
(LP) and labeled F-score (LF). Labeled in this con-
text means that both the constituent label and the
grammatical function should agree with the gold-
standard, but grammatical functions labeling the
edge between a constituent and a token were not in-
cluded in the evaluation. The labeled F-scores are
75.60 for T¨uba-D/Z and 65.18 for TIGER and these
results are the second best results in the shared task
out of three systems. We want to emphasize that the
results may not be strictly comparable because of
different use of the grammatical functions attached
to the parts of speech in the bracketing format. We
did not use these grammatical functions as input,
instead these were assigned by the parser. Our re-
sults are competitive if we compare with K¨ubler et
al. (2006), who report 51.41 labeled F-score on the
Negra treebank and 75.33 on the T¨uBa-D/Z treebank
using the unlexicalized, markovized PCFG version
of the Stanford parser.
We believe that our results for the constituency
representations can be improved upon by investi-
gating different methods for encoding the inverse
mapping in the complex arc labels and performing
a more careful evaluation of head-finding rules to
derive a more linguistically sound dependency rep-
resentation. Another interesting line of future work
is to try to parse discontinuous constituents by using
</bodyText>
<page confidence="0.995637">
53
</page>
<bodyText confidence="0.99755675">
a non-projective parsing algorithm like the Coving-
ton algorithm (Covington, 2001) or using pseudo-
projective parsing for discontinuous constituency
parsing (Nivre and Nilsson, 2005).
</bodyText>
<sectionHeader confidence="0.998612" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999970181818182">
We have shown that a transition-based dependency-
driven parser can be used for parsing German with
both dependency and constituent representations.
We can report state-of-the-art results for parsing the
dependency versions of two German treebanks, and
we have demonstrated, with promising results, how
a dependency parser can parse full constituent struc-
tures by encoding the inverse mapping in complex
arc labels of the dependency graph. We believe that
this method can be improved by using, for example,
head-finding rules.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999973">
We want to thank the treebank providers for making
the data available for the shared task and the orga-
nizers for their efforts in organizing it. Thanks also
to two reviewers for useful comments.
</bodyText>
<sectionHeader confidence="0.999113" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999879547945206">
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang
Lezius, and George Smith. 2002. The TIGER Tree-
bank. In Proceedings of the Workshop on Treebanks
and Linguistic Theories Sozopol, pages 1–18.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X Shared Task on Multilingual Dependency Parsing.
In Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning (CoNLL-X), pages
149–164.
Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM:
A Library for Support Vector Machines.
Michael A. Covington. 2001. A Fundamental Algorithm
for Dependency Parsing. In Proceedings of the 39th
Annual ACM Southeast Conference, pages 95–102.
Amit Dubey and Frank Keller. 2003. Probabilistic Pars-
ing for German using Sister-Head Dependencies. In
Proceedings of the 41st Annual Meeting of the Associ-
ation for Computational Linguistics (ACL), pages 96–
103.
Amit Dubey. 2005. What to do when Lexicaliza-
tion fails: Parsing German with Suffix Analysis and
Smoothing. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 314–321.
Johan Hall, Jens Nilsson, Joakim Nivre, G¨uls¸en Eryi˘git,
Be´ata Megyesi, Mattias Nilsson, and Markus Saers.
2007. Single Malt or Blended? A Study in Mul-
tilingual Parser Optimization. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007,
pages 933–939.
Sandra K¨ubler, Erhard W. Hinrichs, and Wolfgang Maier.
2006. Is it Really that Difficult to Parse German.
In Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2006), pages 111–119.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual Dependency Analysis with a
Two-Stage Discriminative Parser. In Proceedings of
the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 216–220.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-Projective
Dependency Parsing. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 99–106.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryi˘git,
and Svetoslav Marinov. 2006. Labeled Pseudo-
Projective Dependency Parsing with Support Vector
Machines. In Proceedings of the Tenth Conference on
Computational Natural Language Learning (CoNLL-
X), pages 221–225.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 Shared Task on Dependency
Parsing. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 915–932.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
Ines Rehbein and Josef van Genabith. 2007. Treebank
Annotation Schemes and Parser Evaluation for Ger-
man. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning (
EMNLP-CoNLL 2007), pages 630–639.
Wojciech Skut, Brigitte Krenn, Thorsten Brants, and
Hans Uszkoreit. 1997. An Annotation Scheme for
Free Word Order Languages. In Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing (ANLP), pages 314–321.
Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler,
and Heike Zinsmeister. 2005. Stylebook for
the T¨ubingen Treebank of Written German (T¨uBa-
D/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at
T¨ubingen, Germany.
</reference>
<page confidence="0.999023">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.126241">
<title confidence="0.999794">A Dependency-Driven Parser for Dependency and Constituency Representations</title>
<author confidence="0.851687">Johan V¨axj¨o</author>
<email confidence="0.905808">johan.hall@vxu.se</email>
<affiliation confidence="0.6848475">Joakim V¨axj¨o University</affiliation>
<address confidence="0.980747">Uppsala</address>
<email confidence="0.993583">joakim.nivre@vxu.se</email>
<abstract confidence="0.960140933333333">We present a dependency-driven parser that parses both dependency structures and constituent structures. Constituency representations are automatically transformed into dependency representations with complex arc labels, which makes it possible to recover the constituent structure with both constituent labels and grammatical functions. We report a labeled attachment score close to 90% for dependency versions of the TIGER and T¨uBa- D/Z treebanks. Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T¨uBa-D/Z and over 65% for TIGER.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER Treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories Sozopol,</booktitle>
<pages>1--18</pages>
<contexts>
<context position="2064" citStr="Brants et al., 2002" startWordPosition="312" endWordPosition="315">trast, Rehbein and van Genabith (2007) study different parser evaluation metrics by simulating parser errors on two German treebanks (with different treebank annotation schemes) and they claim that the question whether German is harder to parse than English is still undecided. 47 This paper does not try to answer the question above, but presents a new way of parsing constituent structures that can output the whole structure with all grammatical functions. The shared task on parsing German was to parse both the constituency version and the dependency version of the two German treebanks: TIGER (Brants et al., 2002) and T¨uBa-D/Z (Telljohann et al., 2005). We present a dependency-driven parser that parses both dependency structures and constituent structures using an extended version of MaltParser 1.0.1 The focus of this paper is how MaltParser parses the constituent structures with a dependency-based algorithm. This paper is structured as follows. Section 2 briefly describes the MaltParser system, while section 3 continues with presenting the dependency parsing. Section 4 explains how a transition-based dependency-driven parser can be turned into a constituency parser. Section 5 presents the experimenta</context>
<context position="19610" citStr="Brants et al., 2002" startWordPosition="3196" endWordPosition="3199">uents are forced down in the structure so that the parser output can be represented in a nested bracketing format. 5 Experiments The shared task on parsing German consisted of parsing either the dependency version or the constituency version of two German treebanks, although we chose to parse both versions. This section first presents the data sets used. We continue with a brief overview of how we optimized the four different parser models. Finally, the results are discussed. 5.1 Data Sets The prepared training and development data distributed by the organizers were based on the German TIGER (Brants et al., 2002) and T¨uBa-D/Z (Telljohann et al., 2005) treebanks, one dependency and one constituency version for each treebank. Both treebanks contain German newspaper text and the prepared data sets were of the same size. The development set contained 2611 sentences and the training set contained 20894 sentences. The dependency and constituency versions contained the same set of sentences. The dependency data were formated according to the CoNLL dependency data format.4 The LEMMA, FEATS, PHEAD and PDEPREL columns of the CoNLL format were not used at all. The constituency data have been converted into a br</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER Treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories Sozopol, pages 1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLLX Shared Task on Multilingual Dependency Parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="2928" citStr="Buchholz and Marsi, 2006" startWordPosition="440" endWordPosition="443"> the constituent structures with a dependency-based algorithm. This paper is structured as follows. Section 2 briefly describes the MaltParser system, while section 3 continues with presenting the dependency parsing. Section 4 explains how a transition-based dependency-driven parser can be turned into a constituency parser. Section 5 presents the experimental evaluation and discusses the results. Finally section 6 concludes. 2 MaltParser MaltParser is a transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the CoNLL 2006 shared task (Buchholz and Marsi, 2006; Nivre et al., 2006) and the CoNLL shared task 2007 (Nivre et al., 2007; Hall et al., 2007). The basic idea of MaltParser is to derive dependency graphs using a greedy parsing algorithm that approximates a glob1MaltParser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 47–54, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ally optimal solution by making a sequence of locally optimal choices</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLLX Shared Task on Multilingual Dependency Parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2001</date>
<contexts>
<context position="6416" citStr="Chang and Lin, 2001" startWordPosition="1022" endWordPosition="1025"> transition is RIGHT-ARC or LEFT-ARC the parser continues to predict the arc label r. This prediction strategy enables the system to have three different feature models: one for predicting the transition and two for predicting the arc label r (RIGHT-ARC and LEFT-ARC). We will see in section 4 that this change makes it more feasible to encode the inverse mapping into complex arc labels for an arbitrary constituent structure without losing any information. All symbolic features were converted to numerical features and we use the quadratic kernel K(xZ7 xj) = (-yxT xj + r)2 of the LIBSVM package (Chang and Lin, 2001) for mapping histories to parser actions and arc labels. All results are based on the following settings of LIBSVM: -y = 0.2 and r = 0 for the kernel parameters, C = 0.5 for the penalty parameter, and E = 1.0 for the termination criterion. We also split the training instances into smaller sets according to the fine-grained part-ofspeech of the next input token to train separate oneversus-one multi-class LIBSVM-classifiers. 3 Dependency Parsing Parsing sentences with dependency structures like the one in Figure 1 is straightforward using MaltParser. During training, the parser reconstructs the </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM: A Library for Support Vector Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>A Fundamental Algorithm for Dependency Parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual ACM Southeast Conference,</booktitle>
<pages>95--102</pages>
<contexts>
<context position="26177" citStr="Covington, 2001" startWordPosition="4264" endWordPosition="4265"> the Negra treebank and 75.33 on the T¨uBa-D/Z treebank using the unlexicalized, markovized PCFG version of the Stanford parser. We believe that our results for the constituency representations can be improved upon by investigating different methods for encoding the inverse mapping in the complex arc labels and performing a more careful evaluation of head-finding rules to derive a more linguistically sound dependency representation. Another interesting line of future work is to try to parse discontinuous constituents by using 53 a non-projective parsing algorithm like the Covington algorithm (Covington, 2001) or using pseudoprojective parsing for discontinuous constituency parsing (Nivre and Nilsson, 2005). 6 Conclusion We have shown that a transition-based dependencydriven parser can be used for parsing German with both dependency and constituent representations. We can report state-of-the-art results for parsing the dependency versions of two German treebanks, and we have demonstrated, with promising results, how a dependency parser can parse full constituent structures by encoding the inverse mapping in complex arc labels of the dependency graph. We believe that this method can be improved by u</context>
</contexts>
<marker>Covington, 2001</marker>
<rawString>Michael A. Covington. 2001. A Fundamental Algorithm for Dependency Parsing. In Proceedings of the 39th Annual ACM Southeast Conference, pages 95–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Dubey</author>
<author>Frank Keller</author>
</authors>
<title>Probabilistic Parsing for German using Sister-Head Dependencies.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>96--103</pages>
<contexts>
<context position="1121" citStr="Dubey and Keller (2003)" startWordPosition="157" endWordPosition="160">t structure with both constituent labels and grammatical functions. We report a labeled attachment score close to 90% for dependency versions of the TIGER and T¨uBaD/Z treebanks. Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T¨uBa-D/Z and over 65% for TIGER. 1 Introduction Is it really that difficult to parse German? K¨ubler et al. (2006) point out three grammatical features that could make parsing of German more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents. Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al., 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra’s flat constituent structures. However, K¨ubler et al. (2006) present a comparative study that suggests that it is not harder to parse German than for example English. By contrast, Rehbein and van Genabith (2007) study different parser evaluation metrics by simulating parser errors on two German treebanks (with different treebank annotation schemes) and they claim that the question whether German is harder to parse than English is still undecided.</context>
</contexts>
<marker>Dubey, Keller, 2003</marker>
<rawString>Amit Dubey and Frank Keller. 2003. Probabilistic Parsing for German using Sister-Head Dependencies. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 96– 103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Dubey</author>
</authors>
<title>What to do when Lexicalization fails: Parsing German with Suffix Analysis and Smoothing.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>314--321</pages>
<contexts>
<context position="1138" citStr="Dubey (2005)" startWordPosition="162" endWordPosition="163">tuent labels and grammatical functions. We report a labeled attachment score close to 90% for dependency versions of the TIGER and T¨uBaD/Z treebanks. Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T¨uBa-D/Z and over 65% for TIGER. 1 Introduction Is it really that difficult to parse German? K¨ubler et al. (2006) point out three grammatical features that could make parsing of German more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents. Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al., 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra’s flat constituent structures. However, K¨ubler et al. (2006) present a comparative study that suggests that it is not harder to parse German than for example English. By contrast, Rehbein and van Genabith (2007) study different parser evaluation metrics by simulating parser errors on two German treebanks (with different treebank annotation schemes) and they claim that the question whether German is harder to parse than English is still undecided. 47 This paper do</context>
</contexts>
<marker>Dubey, 2005</marker>
<rawString>Amit Dubey. 2005. What to do when Lexicalization fails: Parsing German with Suffix Analysis and Smoothing. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 314–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
<author>G¨uls¸en Eryi˘git</author>
<author>Be´ata Megyesi</author>
<author>Mattias Nilsson</author>
<author>Markus Saers</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>933--939</pages>
<marker>Hall, Nilsson, Nivre, Eryi˘git, Megyesi, Nilsson, Saers, 2007</marker>
<rawString>Johan Hall, Jens Nilsson, Joakim Nivre, G¨uls¸en Eryi˘git, Be´ata Megyesi, Mattias Nilsson, and Markus Saers. 2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 933–939.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Erhard W Hinrichs</author>
<author>Wolfgang Maier</author>
</authors>
<title>Is it Really that Difficult to Parse German.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>111--119</pages>
<marker>K¨ubler, Hinrichs, Maier, 2006</marker>
<rawString>Sandra K¨ubler, Erhard W. Hinrichs, and Wolfgang Maier. 2006. Is it Really that Difficult to Parse German. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 111–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual Dependency Analysis with a Two-Stage Discriminative Parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>216--220</pages>
<contexts>
<context position="24455" citStr="McDonald et al. (2006)" startWordPosition="3983" endWordPosition="3986">ed the correct head and the correct arc label (punctuation included). We can see that the dependency results Dependency Constituency Treebank LAS LP LR LF TIGER 90.80 67.06 63.40 65.18 T¨uBa-D/Z 88.64 76.44 74.79 75.60 Table 1: The results for the extended version of MaltParser 1.0 in the shared task on parsing German dependency and constituency representations. are close to 90% for both the treebanks, 90.80 for TIGER and 88.64 for T¨uba-D/Z, which were the unchallenged best scores in the shared task. The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al. (2006) with a LAS of 87.34 based on the TIGER treebank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF). Labeled in this context means that both the constituent label and the grammatical function should agree with the goldstandard, but grammatical functions labeling the edge between a constituent and a token were not included in the evaluation. The labeled F-scores are 75.</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual Dependency Analysis with a Two-Stage Discriminative Parser. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 216–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudo-Projective Dependency Parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>99--106</pages>
<contexts>
<context position="8357" citStr="Nivre and Nilsson, 2005" startWordPosition="1330" endWordPosition="1333">German treebanks is that they 48 Figure 1: The sentence ”For this statement has Beckmeyer until now not presented any evidence.” is taken from dependency version of T¨uBa-D/Z treebank. contain non-projective structures, such as the dependency graph illustrated in Figure 1. Nivre’s parsing algorithm only produces projective dependency structures, and therefore we used pseudo-projective parsing for recovering non-projective structures. The training data are projectivized and information about these transformations is encoded into the arc labels to enable deprojectivizition of the parser output (Nivre and Nilsson, 2005). 4 Constituency Parsing This section explains how a transition-based dependency parser can be used for parsing constituent structures. The basic idea is to use the common practice of transforming a constituent structure into a dependency graph and encode the inverse mapping with complex arc labels. Note that the goal is not to create the best dependency representation of a constituent structure. Instead the main objective is to find a general method to transform constituency to dependency so that is easy to do the inverse transformation without losing any information. Moreover, another goal i</context>
<context position="26276" citStr="Nivre and Nilsson, 2005" startWordPosition="4275" endWordPosition="4278"> PCFG version of the Stanford parser. We believe that our results for the constituency representations can be improved upon by investigating different methods for encoding the inverse mapping in the complex arc labels and performing a more careful evaluation of head-finding rules to derive a more linguistically sound dependency representation. Another interesting line of future work is to try to parse discontinuous constituents by using 53 a non-projective parsing algorithm like the Covington algorithm (Covington, 2001) or using pseudoprojective parsing for discontinuous constituency parsing (Nivre and Nilsson, 2005). 6 Conclusion We have shown that a transition-based dependencydriven parser can be used for parsing German with both dependency and constituent representations. We can report state-of-the-art results for parsing the dependency versions of two German treebanks, and we have demonstrated, with promising results, how a dependency parser can parse full constituent structures by encoding the inverse mapping in complex arc labels of the dependency graph. We believe that this method can be improved by using, for example, head-finding rules. Acknowledgments We want to thank the treebank providers for </context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudo-Projective Dependency Parsing. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨uls¸en Eryi˘git</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled PseudoProjective Dependency Parsing with Support Vector Machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLLX),</booktitle>
<pages>221--225</pages>
<marker>Nivre, Hall, Nilsson, Eryi˘git, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryi˘git, and Svetoslav Marinov. 2006. Labeled PseudoProjective Dependency Parsing with Support Vector Machines. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLLX), pages 221–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="3835" citStr="Nivre, 2006" startWordPosition="575" endWordPosition="576"> charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 47–54, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ally optimal solution by making a sequence of locally optimal choices. The system is equipped with several parsing algorithms, but we have chosen to only optimize Nivre’s parsing algorithm for both the dependency track and the constituency track. Nivre’s algorithm is a deterministic algorithm for building labeled projective dependency structures in linear time (Nivre, 2006). There are two essential parameters that can be varied for this algorithm. The first is the arc order and we selected the arc-eager order that attaches the right dependents to their head as soon as possible. The second is the stack initialization and we chose to use an empty stack initialization that attaches root dependents with a default root label after completing the left-to-right pass over the input. The algorithm uses two data structures: a stack to store partially processed tokens and a queue of remaining input tokens. The arc-eager transitionsystem has four parser actions: 1. LEFT-ARC</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
<author>Josef van Genabith</author>
</authors>
<title>Treebank Annotation Schemes and Parser Evaluation for German.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP-CoNLL</booktitle>
<pages>630--639</pages>
<marker>Rehbein, van Genabith, 2007</marker>
<rawString>Ines Rehbein and Josef van Genabith. 2007. Treebank Annotation Schemes and Parser Evaluation for German. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP-CoNLL 2007), pages 630–639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Skut</author>
<author>Brigitte Krenn</author>
<author>Thorsten Brants</author>
<author>Hans Uszkoreit</author>
</authors>
<title>An Annotation Scheme for Free Word Order Languages.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing (ANLP),</booktitle>
<pages>314--321</pages>
<contexts>
<context position="1183" citStr="Skut et al., 1997" startWordPosition="168" endWordPosition="171"> We report a labeled attachment score close to 90% for dependency versions of the TIGER and T¨uBaD/Z treebanks. Moreover, the parser is able to recover both constituent labels and grammatical functions with an F-Score over 75% for T¨uBa-D/Z and over 65% for TIGER. 1 Introduction Is it really that difficult to parse German? K¨ubler et al. (2006) point out three grammatical features that could make parsing of German more difficult: finite verb placement, flexible phrase ordering and discontinuous constituents. Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al., 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra’s flat constituent structures. However, K¨ubler et al. (2006) present a comparative study that suggests that it is not harder to parse German than for example English. By contrast, Rehbein and van Genabith (2007) study different parser evaluation metrics by simulating parser errors on two German treebanks (with different treebank annotation schemes) and they claim that the question whether German is harder to parse than English is still undecided. 47 This paper does not try to answer the question above, but </context>
</contexts>
<marker>Skut, Krenn, Brants, Uszkoreit, 1997</marker>
<rawString>Wojciech Skut, Brigitte Krenn, Thorsten Brants, and Hans Uszkoreit. 1997. An Annotation Scheme for Free Word Order Languages. In Proceedings of the Fifth Conference on Applied Natural Language Processing (ANLP), pages 314–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard W Hinrichs</author>
<author>Sandra K¨ubler</author>
<author>Heike Zinsmeister</author>
</authors>
<title>Stylebook for the T¨ubingen Treebank of Written German (T¨uBaD/Z). Seminar f¨ur Sprachwissenschaft,</title>
<date>2005</date>
<location>Universit¨at T¨ubingen, Germany.</location>
<marker>Telljohann, Hinrichs, K¨ubler, Zinsmeister, 2005</marker>
<rawString>Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler, and Heike Zinsmeister. 2005. Stylebook for the T¨ubingen Treebank of Written German (T¨uBaD/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>