<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000308">
<title confidence="0.649231">
The 2008 MedSLT System
</title>
<author confidence="0.9741005">
Manny Rayner&apos;, Pierrette Bouillon&apos;, Jane Brotanek2, Glenn Flores2
Sonia Halimi&apos;, Beth Ann Hockey3, Hitoshi Isahara4, Kyoko Kanzaki4
Elisabeth Kron5, Yukie Nakao6, Marianne Santaholma&apos;
Marianne Starlander&apos;, Nikos Tsourakis&apos;
</author>
<affiliation confidence="0.998085">
&apos; University of Geneva, TIM/ISSCO, 40 bvd du Pont-d’Arve, CH-1211 Geneva 4, Switzerland
</affiliation>
<email confidence="0.942844">
{Emmanuel.Rayner,Pierrette.Bouillon,Nikolaos.Tsourakis}@issco.unige.ch
{Sonia.Halimi,Marianne.Santaholma,Marianne.Starlander}@eti.unige.ch
</email>
<address confidence="0.525015">
2 UT Southwestern Medical Center, Children’s Medical Center of Dallas
</address>
<email confidence="0.979541">
{Glenn.Flores,Jane.Brotanek}@utsouthwestern.edu
</email>
<note confidence="0.510028">
3 Mail Stop 19-26, UCSC UARC, NASA Ames Research Center, Moffett Field, CA 94035–1000
</note>
<email confidence="0.914043">
bahockey@ucsc.edu
</email>
<address confidence="0.730998">
4 NICT, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
</address>
<email confidence="0.949637">
{isahara,kanzaki}@nict.go.jp
</email>
<note confidence="0.41778">
5 3 St Margarets Road, Cambridge CB3 0LT, England
</note>
<email confidence="0.887016">
elisabethkron@yahoo.co.uk
</email>
<affiliation confidence="0.908203">
6 University of Nantes, LINA, 2, rue de la Houssini`ere, BP 92208 44322 Nantes Cedex 03
</affiliation>
<email confidence="0.600555">
yukie.nakao@univ-nantes.fr
</email>
<sectionHeader confidence="0.985356" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999761">
MedSLT is a grammar-based medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several dif-
ferent subdomains and multiple language
pairs. Vocabulary ranges from about 350 to
1000 surface words, depending on the lan-
guage and subdomain. We will demo three
different versions of the system: an any-
to-any multilingual version involving the
languages Japanese, English, French and
Arabic, a bidirectional English H Span-
ish version, and a mobile version run-
ning on a hand-held PDA. We will also
demo the Regulus development environ-
ment, focussing on features which sup-
port rapid prototyping of grammar-based
speech translation systems.
</bodyText>
<footnote confidence="0.908192">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<sectionHeader confidence="0.993244" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999807666666667">
MedSLT is a medium-vocabulary grammar-based
medical speech translation system built on top of
the Regulus platform (Rayner et al., 2006). It is
intended for use in doctor-patient diagnosis dia-
logues, and provides coverage of several subdo-
mains and a large number of different language-
pairs. Coverage is based on standard examina-
tion questions obtained from physicians, and fo-
cusses primarily on yes/no questions, though there
is also support for WH-questions and elliptical ut-
terances.
Detailed descriptions of MedSLT can be found
in earlier papers (Bouillon et al., 2005; Bouil-
lon et al., 2008)1. In the rest of this note, we
will briefly sketch several versions of the system
that we intend to demo at the workshop, each of
which displays new features developed over the
last year. Section 2 describes an any-language-to-
any-language multilingual version of the system;
Section 3, a bidirectional English H Spanish ver-
sion; Section 4, a version running on a mobile PDA
</bodyText>
<footnote confidence="0.98018">
1All MedSLT publications are available on-line
at http://www.issco.unige.ch/projects/
medslt/publications.shtml.
</footnote>
<page confidence="0.987052">
32
</page>
<note confidence="0.580353">
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 32–35
</note>
<bodyText confidence="0.822042333333333">
Manchester, August 2008
platform; and Section 5, the Regulus development
environment.
</bodyText>
<sectionHeader confidence="0.658878" genericHeader="method">
2 A multilingual version
</sectionHeader>
<bodyText confidence="0.9999872">
During the last few months, we have reorganised
the MedSLT translation model in several ways2. In
particular, we give a much more central role to the
interlingua; we now treat this as a language in its
own right, defined by a normal Regulus grammar,
and using a syntax which essentially amounts to
a greatly simplified form of English. Making the
interlingua into another language has made it easy
to enforce tight constraints on well-formedness of
interlingual semantic expressions, since checking
well-formedness now just amounts to performing
generation using the interlingua grammar.
Another major advantage of the scheme is that
it is also possible to systematise multilingual de-
velopment, and only work with translation from
source language to interlingua, and from interlin-
gua to target language; here, the important point
is that the human-readable interlingua surface syn-
tax makes it feasible in practice to evaluate transla-
tion between normal languages and the interlingua.
Development of rules for translation to interlingua
is based on appropriate corpora for each source
language. Development of rules for translating
from interlingua uses a corpus which is formed by
merging together the results of translating each of
the individual source-language corpora into inter-
lingua.
We will demonstrate our new capabilities in
interlingua-based translation, using a version of
the system which translates doctor questions in the
headache domain from any language to any lan-
guage in the set {English, French, Japanese, Ara-
bic}. Table 1 gives examples of the coverage of the
English-input headache-domain version, and Ta-
ble 2 summarises recognition performance in this
domain for the three input languages where we
have so far performed serious evaluations. Differ-
ences in the sizes of the recognition vocabularies
are primarily due to differences in use of inflec-
tion.
</bodyText>
<sectionHeader confidence="0.990418" genericHeader="method">
3 A bidirectional version
</sectionHeader>
<bodyText confidence="0.999144">
The system from the preceding section is unidi-
rectional; all communication is in the doctor-to-
patient direction, the expectation being that the pa-
</bodyText>
<footnote confidence="0.9081525">
2The ideas in the section are described at greater length in
(Bouillon et al., 2008).
</footnote>
<table confidence="0.99971625">
Language Vocab WER SemER
English 447 6% 11%
French 1025 8% 10%
Japanese 422 3% 4%
</table>
<tableCaption confidence="0.997683">
Table 2: Recognition performance for English,
</tableCaption>
<bodyText confidence="0.98012825">
French and Japanese headache-domain recognis-
ers. “Vocab” = number of surface words in source
language recogniser vocabulary; “WER” = Word
Error Rate for source language recogniser, on in-
coverage material; “SemER” = semantic error rate
for source language recogniser, on in-coverage
material.
tient will respond non-verbally. Our second demo,
an early version of which is described in (Bouillon
et al., 2007), supports bidirectional translation for
the sore throat domain, in the English H Spanish
pair. Here, the English-speaking doctor typically
asks WH-questions, and the Spanish-speaking pa-
tient responds with elliptical utterances, which are
translated as full sentence responses. A short ex-
ample dialogue is shown in Table 3.
</bodyText>
<table confidence="0.967678">
Doctor: Where is the pain?
¿D´onde le duele?
Patient: En la garganta.
I experience the pain in my throat.
Doctor: How long have you had a pain
in your throat?
¿Desde cu´ando le duele la garganta?
Patient: M´as de tres dias.
I have experienced the pain in my
throat for more than three days.
</table>
<tableCaption confidence="0.864540666666667">
Table 3: Short dialogue with bidirectional English
H Spanish version. System translations are in ital-
ics.
</tableCaption>
<sectionHeader confidence="0.976148" genericHeader="method">
4 A mobile platform version
</sectionHeader>
<bodyText confidence="0.999896727272727">
When we have shown MedSLT to medical profes-
sionals, one of the most common complaints has
been that a laptop is not an ideal platform for use
in emergency medical situations. Our third demo
shows an experimental version of the system us-
ing a client/server architecture. The client, which
contains the user interface, runs on a Nokia Linux
N800 Internet Tablet; most of the heavy process-
ing, including in particular speech recognition, is
hosted on the remote server, with the nodes com-
municating over a wireless network. A picture of
</bodyText>
<page confidence="0.997969">
33
</page>
<table confidence="0.846589333333334">
Where? Is the pain above your eye?
When? Have you had the pain for more than a month?
How long? Does the pain typically last a few minutes?
How often? Do you get headaches several times a week?
How? Is it a stabbing pain?
Associated symptoms? Do you vomit when you get the headaches?
Why? Does bright light make the pain worse?
What helps? Does sleep make the pain better?
Background? Do you have a history of sinus disease?
</table>
<tableCaption confidence="0.999836">
Table 1: Examples of English MedSLT coverage
</tableCaption>
<bodyText confidence="0.999910923076923">
the tablet, showing the user interface, is presented
in Figure 1. The sentences appearing under the
back-translation at the top are produced by an on-
line help component, and are intended to guide the
user into the grammar’s coverage (Chatzichrisafis
et al., 2006).
The architecture is described further in
(Tsourakis et al., 2008), which also gives perfor-
mance results for another Regulus applications.
These strongly suggest that recognition perfor-
mance in the client/server environment is no
worse than on a laptop, as long as a comparable
microphone is used.
</bodyText>
<sectionHeader confidence="0.931477" genericHeader="method">
5 The development environment
</sectionHeader>
<bodyText confidence="0.999994928571429">
Our final demo highlights the new Regulus devel-
opment environment (Kron et al., 2007), which has
over the last few months acquired a large amount
of new functionality designed to facilitate rapid
prototyping of spoken language applications3. The
developer initially constructs and debugs her com-
ponents (grammar, translation rules etc) in a text
view. As soon as they are consistent, she is able
to compile the source-language grammar into a
recogniser, and combine this with other compo-
nents to run a complete speech translation system
within the development environment. Connections
between components are defined by a simple con-
fig file. Figure 2 shows an example.
</bodyText>
<sectionHeader confidence="0.999007" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987621142857142">
Bouillon, P., M. Rayner, N. Chatzichrisafis, B.A.
Hockey, M. Santaholma, M. Starlander, Y. Nakao,
K. Kanzaki, and H. Isahara. 2005. A generic multi-
lingual open source platform for limited-domain
medical speech translation. In Proceedings of the
10th Conference of the European Association for
3This work is presented in a paper currently under review.
Machine Translation (EAMT), pages 50–58, Bu-
dapest, Hungary.
Bouillon, P., G. Flores, M. Starlander,
N. Chatzichrisafis, M. Santaholma, N. Tsourakis,
M. Rayner, and B.A. Hockey. 2007. A bidirectional
grammar-based medical speech translator. In Pro-
ceedings of the ACL Workshop on Grammar-based
Approaches to Spoken Language Processing, pages
41–48, Prague, Czech Republic.
Bouillon, P., S. Halimi, Y. Nakao, K. Kanzaki, H. Isa-
hara, N. Tsourakis, M. Starlander, B.A. Hockey, and
M. Rayner. 2008. Developing non-european trans-
lation pairs in a medium-vocabulary medical speech
translation system. In Proceedings of LREC 2008,
Marrakesh, Morocco.
Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-
holma, M. Starlander, and B.A. Hockey. 2006. Eval-
uating task performance for a unidirectional con-
trolled language medical speech translation system.
In Proceedings of the HLT-NAACL International
Workshop on Medical Speech Translation, pages 9–
16, New York.
Kron, E., M. Rayner, P. Bouillon, and M. Santa-
holma. 2007. A development environment for build-
ing grammar-based speech-enabled applications. In
Proceedings of the ACL Workshop on Grammar-
based Approaches to Spoken Language Processing,
pages 49–52, Prague, Czech Republic.
Rayner, M., B.A. Hockey, and P. Bouillon. 2006.
Putting Linguistics into Speech Recognition: The
Regulus Grammar Compiler. CSLI Press, Chicago.
Tsourakis, N., M. Georghescul, P. Bouillon, and
M. Rayner. 2008. Building mobile spoken dialogue
applications using regulus. In Proceedings ofLREC
2008, Marrakesh, Morocco.
</reference>
<page confidence="0.999146">
34
</page>
<figureCaption confidence="0.9338515">
Figure 1: Mobile version of the MedSLT system, running on a Nokia tablet.
Figure 2: Speech to speech translation from the development environment, using a Japanese to Arabic
</figureCaption>
<bodyText confidence="0.9669458">
translator built from MedSLT components. The user presses the Recognise button (top right), speaks in
Japanese, and receives a spoken translation in Arabic together with screen display of various processing
results. The application is defined by a config file which combines a Japanese recogniser and analy-
sis grammar, Japanese to Interlingua and Interlingua to Arabic translation rules, an Arabic generation
grammar, and recorded Arabic wavfiles used to construct a spoken result.
</bodyText>
<page confidence="0.998944">
35
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.011532">
<title confidence="0.993176">The 2008 MedSLT System</title>
<author confidence="0.9850825">Pierrette Jane Glenn Beth Ann Hitoshi Kyoko</author>
<affiliation confidence="0.426371">Yukie Marianne</affiliation>
<note confidence="0.442415571428571">Nikos of Geneva, TIM/ISSCO, 40 bvd du Pont-d’Arve, CH-1211 Geneva 4, 2UT Southwestern Medical Center, Children’s Medical Center of 3Mail Stop 19-26, UCSC UARC, NASA Ames Research Center, Moffett Field, CA bahockey@ucsc.edu 4NICT, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 53 St Margarets Road, Cambridge CB3 0LT,</note>
<email confidence="0.94925">elisabethkron@yahoo.co.uk</email>
<affiliation confidence="0.374597">6University of Nantes, LINA, 2, rue de la Houssini`ere, BP 92208 44322 Nantes Cedex</affiliation>
<email confidence="0.834371">yukie.nakao@univ-nantes.fr</email>
<abstract confidence="0.999921684210526">MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from about 350 to 1000 surface words, depending on the language and subdomain. We will demo three different versions of the system: an anyto-any multilingual version involving the languages Japanese, English, French and a bidirectional English Spanish version, and a mobile version running on a hand-held PDA. We will also demo the Regulus development environment, focussing on features which support rapid prototyping of grammar-based speech translation systems.</abstract>
<note confidence="0.4171555">Licensed under the Commons Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>N Chatzichrisafis</author>
<author>B A Hockey</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>Y Nakao</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
</authors>
<title>A generic multilingual open source platform for limited-domain medical speech translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Conference of the European Association for 3This</booktitle>
<pages>50--58</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2449" citStr="Bouillon et al., 2005" startWordPosition="317" endWordPosition="320">nc-sa/3.0/). Some rights reserved. 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1. In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English H Spanish version; Section 4, a version running on a mobile PDA 1All MedSLT publications are available on-line at http://www.issco.unige.ch/projects/ medslt/publications.shtml. 32 Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Tra</context>
</contexts>
<marker>Bouillon, Rayner, Chatzichrisafis, Hockey, Santaholma, Starlander, Nakao, Kanzaki, Isahara, 2005</marker>
<rawString>Bouillon, P., M. Rayner, N. Chatzichrisafis, B.A. Hockey, M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki, and H. Isahara. 2005. A generic multilingual open source platform for limited-domain medical speech translation. In Proceedings of the 10th Conference of the European Association for 3This work is presented in a paper currently under review. Machine Translation (EAMT), pages 50–58, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>G Flores</author>
<author>M Starlander</author>
<author>N Chatzichrisafis</author>
<author>M Santaholma</author>
<author>N Tsourakis</author>
<author>M Rayner</author>
<author>B A Hockey</author>
</authors>
<title>A bidirectional grammar-based medical speech translator.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Grammar-based Approaches to Spoken Language Processing,</booktitle>
<pages>41--48</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5877" citStr="Bouillon et al., 2007" startWordPosition="842" endWordPosition="845">a2The ideas in the section are described at greater length in (Bouillon et al., 2008). Language Vocab WER SemER English 447 6% 11% French 1025 8% 10% Japanese 422 3% 4% Table 2: Recognition performance for English, French and Japanese headache-domain recognisers. “Vocab” = number of surface words in source language recogniser vocabulary; “WER” = Word Error Rate for source language recogniser, on incoverage material; “SemER” = semantic error rate for source language recogniser, on in-coverage material. tient will respond non-verbally. Our second demo, an early version of which is described in (Bouillon et al., 2007), supports bidirectional translation for the sore throat domain, in the English H Spanish pair. Here, the English-speaking doctor typically asks WH-questions, and the Spanish-speaking patient responds with elliptical utterances, which are translated as full sentence responses. A short example dialogue is shown in Table 3. Doctor: Where is the pain? ¿D´onde le duele? Patient: En la garganta. I experience the pain in my throat. Doctor: How long have you had a pain in your throat? ¿Desde cu´ando le duele la garganta? Patient: M´as de tres dias. I have experienced the pain in my throat for more th</context>
</contexts>
<marker>Bouillon, Flores, Starlander, Chatzichrisafis, Santaholma, Tsourakis, Rayner, Hockey, 2007</marker>
<rawString>Bouillon, P., G. Flores, M. Starlander, N. Chatzichrisafis, M. Santaholma, N. Tsourakis, M. Rayner, and B.A. Hockey. 2007. A bidirectional grammar-based medical speech translator. In Proceedings of the ACL Workshop on Grammar-based Approaches to Spoken Language Processing, pages 41–48, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>S Halimi</author>
<author>Y Nakao</author>
<author>K Kanzaki</author>
<author>H Isahara</author>
<author>N Tsourakis</author>
<author>M Starlander</author>
<author>B A Hockey</author>
<author>M Rayner</author>
</authors>
<title>Developing non-european translation pairs in a medium-vocabulary medical speech translation system.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="2473" citStr="Bouillon et al., 2008" startWordPosition="321" endWordPosition="325">s reserved. 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1. In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English H Spanish version; Section 4, a version running on a mobile PDA 1All MedSLT publications are available on-line at http://www.issco.unige.ch/projects/ medslt/publications.shtml. 32 Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive A</context>
<context position="5340" citStr="Bouillon et al., 2008" startWordPosition="759" endWordPosition="762">ench, Japanese, Arabic}. Table 1 gives examples of the coverage of the English-input headache-domain version, and Table 2 summarises recognition performance in this domain for the three input languages where we have so far performed serious evaluations. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. 3 A bidirectional version The system from the preceding section is unidirectional; all communication is in the doctor-topatient direction, the expectation being that the pa2The ideas in the section are described at greater length in (Bouillon et al., 2008). Language Vocab WER SemER English 447 6% 11% French 1025 8% 10% Japanese 422 3% 4% Table 2: Recognition performance for English, French and Japanese headache-domain recognisers. “Vocab” = number of surface words in source language recogniser vocabulary; “WER” = Word Error Rate for source language recogniser, on incoverage material; “SemER” = semantic error rate for source language recogniser, on in-coverage material. tient will respond non-verbally. Our second demo, an early version of which is described in (Bouillon et al., 2007), supports bidirectional translation for the sore throat domain</context>
</contexts>
<marker>Bouillon, Halimi, Nakao, Kanzaki, Isahara, Tsourakis, Starlander, Hockey, Rayner, 2008</marker>
<rawString>Bouillon, P., S. Halimi, Y. Nakao, K. Kanzaki, H. Isahara, N. Tsourakis, M. Starlander, B.A. Hockey, and M. Rayner. 2008. Developing non-european translation pairs in a medium-vocabulary medical speech translation system. In Proceedings of LREC 2008, Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chatzichrisafis</author>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>B A Hockey</author>
</authors>
<title>Evaluating task performance for a unidirectional controlled language medical speech translation system.</title>
<date>2006</date>
<booktitle>In Proceedings of the HLT-NAACL International Workshop on Medical Speech Translation,</booktitle>
<pages>9--16</pages>
<location>New York.</location>
<contexts>
<context position="7896" citStr="Chatzichrisafis et al., 2006" startWordPosition="1184" endWordPosition="1187"> pain typically last a few minutes? How often? Do you get headaches several times a week? How? Is it a stabbing pain? Associated symptoms? Do you vomit when you get the headaches? Why? Does bright light make the pain worse? What helps? Does sleep make the pain better? Background? Do you have a history of sinus disease? Table 1: Examples of English MedSLT coverage the tablet, showing the user interface, is presented in Figure 1. The sentences appearing under the back-translation at the top are produced by an online help component, and are intended to guide the user into the grammar’s coverage (Chatzichrisafis et al., 2006). The architecture is described further in (Tsourakis et al., 2008), which also gives performance results for another Regulus applications. These strongly suggest that recognition performance in the client/server environment is no worse than on a laptop, as long as a comparable microphone is used. 5 The development environment Our final demo highlights the new Regulus development environment (Kron et al., 2007), which has over the last few months acquired a large amount of new functionality designed to facilitate rapid prototyping of spoken language applications3. The developer initially const</context>
</contexts>
<marker>Chatzichrisafis, Bouillon, Rayner, Santaholma, Starlander, Hockey, 2006</marker>
<rawString>Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santaholma, M. Starlander, and B.A. Hockey. 2006. Evaluating task performance for a unidirectional controlled language medical speech translation system. In Proceedings of the HLT-NAACL International Workshop on Medical Speech Translation, pages 9– 16, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kron</author>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>M Santaholma</author>
</authors>
<title>A development environment for building grammar-based speech-enabled applications.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Grammarbased Approaches to Spoken Language Processing,</booktitle>
<pages>49--52</pages>
<location>Prague, Czech Republic.</location>
<marker>Kron, Rayner, Bouillon, Santaholma, 2007</marker>
<rawString>Kron, E., M. Rayner, P. Bouillon, and M. Santaholma. 2007. A development environment for building grammar-based speech-enabled applications. In Proceedings of the ACL Workshop on Grammarbased Approaches to Spoken Language Processing, pages 49–52, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>P Bouillon</author>
</authors>
<title>Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler.</title>
<date>2006</date>
<publisher>CSLI Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="2014" citStr="Rayner et al., 2006" startWordPosition="249" endWordPosition="252">guages Japanese, English, French and Arabic, a bidirectional English H Spanish version, and a mobile version running on a hand-held PDA. We will also demo the Regulus development environment, focussing on features which support rapid prototyping of grammar-based speech translation systems. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1. In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which disp</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2006</marker>
<rawString>Rayner, M., B.A. Hockey, and P. Bouillon. 2006. Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler. CSLI Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tsourakis</author>
<author>M Georghescul</author>
<author>P Bouillon</author>
<author>M Rayner</author>
</authors>
<title>Building mobile spoken dialogue applications using regulus.</title>
<date>2008</date>
<booktitle>In Proceedings ofLREC</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="7963" citStr="Tsourakis et al., 2008" startWordPosition="1194" endWordPosition="1197">al times a week? How? Is it a stabbing pain? Associated symptoms? Do you vomit when you get the headaches? Why? Does bright light make the pain worse? What helps? Does sleep make the pain better? Background? Do you have a history of sinus disease? Table 1: Examples of English MedSLT coverage the tablet, showing the user interface, is presented in Figure 1. The sentences appearing under the back-translation at the top are produced by an online help component, and are intended to guide the user into the grammar’s coverage (Chatzichrisafis et al., 2006). The architecture is described further in (Tsourakis et al., 2008), which also gives performance results for another Regulus applications. These strongly suggest that recognition performance in the client/server environment is no worse than on a laptop, as long as a comparable microphone is used. 5 The development environment Our final demo highlights the new Regulus development environment (Kron et al., 2007), which has over the last few months acquired a large amount of new functionality designed to facilitate rapid prototyping of spoken language applications3. The developer initially constructs and debugs her components (grammar, translation rules etc) in</context>
</contexts>
<marker>Tsourakis, Georghescul, Bouillon, Rayner, 2008</marker>
<rawString>Tsourakis, N., M. Georghescul, P. Bouillon, and M. Rayner. 2008. Building mobile spoken dialogue applications using regulus. In Proceedings ofLREC 2008, Marrakesh, Morocco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>