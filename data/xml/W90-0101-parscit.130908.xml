<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000264">
<title confidence="0.9964905">
Using Tree Adjoining Grammars in the
Systemic Framework*
</title>
<author confidence="0.99806">
Kathleen F. McCoy, K. Vijay-Shanker, Gijoo Yang
</author>
<affiliation confidence="0.998597">
University of Delaware
</affiliation>
<address confidence="0.596328">
Newark, DE 19716
</address>
<sectionHeader confidence="0.978573" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992703647058823">
In this paper we investigate the incorporation of
Tree Adjoining Grammars (TAG) into the systemic
framework. We show that while systemic grammars
have many desirable characteristics as a generation
paradigm, they appear to have problems in generating
certain kinds of sentences (e.g., those containing discon-
tinuity or long-distance dependencies). We argue that
these problems can be overcome with an appropriate
choice of structural units of realization.
We show that TAG provides appropriate units of
structural realization because they localize all depen-
dencies and allow the realization of two independent
subpieces to be interspersed with each other. We go on
to show how TAG can be incorporated without affect-
ing the basic tenants of systemic grammar. Finally, we
indicate how the incorporation of TAG yields several
benefits to the systemic framework.
</bodyText>
<sectionHeader confidence="0.978998" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999822166666667">
As pointed out by many researchers (e.g., [Davey 1978;
Mann 1983; Matthiessen &amp; Kasper 1985; Patten 1988;
Bateman Sz Paris 1989)), systemic linguistics offers
many advantages to a sentence generation component
of a text generation system. Perhaps the strongest as-
set of systemics is its view of the generation process
as a goal directed enterprise. Its emphasis is on func-
tion rather than form [Halliday 1985; Fawcett 1980;
Hudson 19711, where the functional distinctions that
are required in the grammar manifest themselves in the
eventual output form.
While systemic linguists have remained agnostic with
respect to certain processing decisions, a computer im-
plementation of a systemic grammar requires that ex-
plicit decisions be made concerning realization opera-
tors and the structures available for manipulation at
each point in the processing. The explicit decisions
that were made in previous implementations of systemic
</bodyText>
<footnote confidence="0.68248225">
*This work is supported in part by Grant #H133E80015
from the National Institute on Disability and Rehabilita-
tion Research. Support was also provided by the Nemours
Foundation.
</footnote>
<bodyText confidence="0.9964643">
grammar (e.g., [Mann 1983; Mann &amp; Matthiessen 1985;
Matthiessen &amp; Kasper 1985]) have proven to be prob-
lematic in some respects. In particular, the current
implementations have difficulty in generating certain
sentences which exhibit discontinuities or long distance
dependencies. To date, these can only be handled in a
limited fashion, and the solutions provided are not very
satisfying.
We argue that Tree Adjoining Grammar (TAG) pro-
vides a structural unit that is precisely appropriate for
the implementation of a systemic grammar for the gen-
eration task. Moreover, we believe our use of TAG for
this purpose is completely consistent with the systemic
paradigm and helps to overcome the above difficulties.
In this paper we first introduce the notion of a sys-
temic grammar and the processing paradigm it es-
pouses. We indicate problems with current implemen-
tations of this paradigm. Next, we introduce the notion
of lexicalized Tree Adjoining Grammars, emphasizing
their structural domains of locality, and justify that the
basic structures of TAG are appropriate structures to
be used in an implementation of a systemic grammar.
Following this we indicate how a tree adjoining gram-
mar can be used as the basis for an implementation
of systemic grammar indicating the differences between
the approach of current implementations of systemic
grammar and that which would result from the incor-
poration of TAG. Finally, we indicate potential gains
resulting from the incorporation of TAGs and the scope
of current work.
</bodyText>
<subsectionHeader confidence="0.5115845">
Generating in Systemic Paradigm:
Problems?
</subsectionHeader>
<bodyText confidence="0.999856">
Systemic linguistics deals with the meaning and func-
tion of an utterance. It is a semantics driven approach
rather than a syntax driven approach. In systemics,
form follows function. The grammar itself is factored
into three metafunctional domains (each of which affect
the final text): ideational (concerning the characteris-
tics of the conceptual situation to be presented), inter-
personal (concerning the interaction between speaker
and hearer) and textual (concerning the coherence of
</bodyText>
<page confidence="0.975401">
1
</page>
<bodyText confidence="0.996747780701755">
the text as a whole).
A systemic functional grammar consists of networks
of grammatical choice alternatives, where individual
networks are concerned with one of the metafunctional
domains. In generation, these networks are traversed
and fragments of grammatical structure are built up
and manipulated using a set of realization operators
which are associated with the various choice alterna-
tives. The correct choice is made by consulting the
information concerning the planned utterances. As the
choices are made, the associated realization statements
in the network are evaluated in order to realize the final
structure.
For instance, figure 1 contains a small fragment of a
systemic grammar for clauses. The network indicates
that a clause may either be simple or complex. If it is
simple and full, then the grammatical function process
is inserted (indicated by +process). The realization op-
eration &amp;quot;A subject process&amp;quot; indicates that the subject
should be ordered before the process in the final real-
ization.
Systemics deals with communicative function and its
eventual surface manifestation at many levels. The
basic processing starts with a semantically meaning-
ful piece of representation which is decomposed into its
component pieces via network traversal. The compo-
nent pieces may then be further specified by re-entering
the network. Given this rank-based decomposition (or
stepwise decomposition), it is not unreasonable to as-
sume that 1) decisions at a higher rank axe made prior
to decisions at a lower rank â€” that is, the decompo-
sition of a particular semantic unit may not be influ-
enced by the eventual decomposition of its component
pieces, and 2) the structural realizations of the com-
ponent pieces of a decomposed unit must be handled
independently. These criteria, which we call the inde-
pendence criterion, are implicitly followed by current
computer implementations of systemic grammar.
Implementing a systemic grammar on computer has
forced researchers to be very explicit about certain rep-
resentational issues. Such explicitness (coupled with an
implicit following of the independence criterion), has
enabled the uncovering of certain constructions which
appear to be problematic for the systemic framework.
For instance, Matthiessen points out that: &amp;quot;There are
various structural relationships (e.g., discontinuity...)
that do not pose a problem for the informal box diagram
representation [used by systemic linguists] but prove to
be a problem for explicit realization statements [nec-
essary for computer implementations].&amp;quot; [Matthiessen
Kasper 1985, p. 6]. We believe that the same applies
to (so called) long distance dependencies.
It can be argued that the problems uncovered by
Matthiessen are not due to explicit realization state-
ments, but rather result from using explicit realization
statements coupled with the implicit assumption that
grammatical functions are realized as atomic strings.
We further argue that if the independence criterion is
to be followed, the choice of realization operators, the
scope of the realization operators, and the choice of
appropriate units of realization must be considered to-
gether.
Consider, for example, the problems which arise in
generating a sentence containing a long distance de-
pendency when atomic strings are taken as the struc-
tural unit of realization. Consider the sentence: &amp;quot;It was
Mary that John thought Bill liked&amp;quot;. A natural decom-
position would result in the semantic subpieces which
correspond to &amp;quot;john thought&amp;quot; and the dependent clause
&amp;quot;bill liked mary&amp;quot;. The extraction of &amp;quot;mary&amp;quot; will be
done subsequent to this decomposition; this extraction
should influence the realization of the structural unit for
the dependent clause (and should not affect the func-
tional decomposition). But notice, if we assume the
structural units of realization are atomic strings, we can
get &amp;quot;John thought it was Mary that Bill liked&amp;quot; but not
our desired utterance &amp;quot;It was Mary that John thought
Bill liked&amp;quot; because to do so would necessitate inserting
one atomic string (&amp;quot;John thought&amp;quot;) within another (&amp;quot;It
was Mary that Bill liked&amp;quot;).
Two possible ways to get around this problem are:
(1) to say that the intended sentence is made up of sev-
eral independent but smaller functions (e.g., realized
as &amp;quot;john thought&amp;quot;, &amp;quot;bill&amp;quot;, &amp;quot;liked&amp;quot;, &amp;quot;mary&amp;quot;). But this
solution goes against the step-wise decomposition into
semantically meaningful units. Moreover, this method
is not sufficient because we can always consider a sen-
tence that requires one more level of embedding which
would necessitate a revision of units. (2) not to break up
the sentence into the two functional constituents men-
tioned, but use some other decomposition. But this is
not a correct solution because then one functional de-
cision at a lower level (extraction of &amp;quot;mary&amp;quot;) influences
another which logically precedes the first (decomposi-
tion in the clause complex network).
In order to follow the independence criterion (i.e.,
realization of different independent functions do not in-
fluence each other), the structural units being built as
the realization of a grammatical function must be ca-
pable of localizing all structural dependencies because
they must embody all constraints specified with that
function. In addition, the chosen structural units must
be composable in such a way as to allow the surface
string of one unit to be interspersed with the surface
string for another (as was required in our example). If
this is the case, then it makes sense that these struc-
tural units should be taken as the bounding domain
for the realization operators. The structures used by
TAGs have precisely these qualities and are thus an ap-
propriate choice for a structural unit of realization in
an implementation of systemic grammar. The struc-
tures used in a TAG have an enlarged domain of lo-
cality that factor all dependencies (e.g., agreement con-
straints, predicate-argument structure, filler-gap depen-
</bodyText>
<page confidence="0.992042">
2
</page>
<figure confidence="0.998234307692308">
- elliptical
declarative
â€” simple
A subject
process
â€” indicative
+ subject
clause
â€” full
interrogative
+ process
â€” imperative
â€” complex
</figure>
<figureCaption confidence="0.999978">
Figure 1: A Simple Systemic Network
</figureCaption>
<bodyText confidence="0.9999803">
dencies or movement). Also the composition operations
allow for the interspersing of words to obtain the order-
ing of utterances with or without discontinuity.
In this paper we argue that if the structures used
by TAG are taken as the structural units for systemic
grammar with the operations of composition of TAG
used to fit structures built at lower ranks into the evolv-
ing structures, then the generation of the above sen-
tence can be done in a straight forward and general
manner while at the same time maintaining the inde-
pendence criterion. This sentence could be generated
by adjoining a tree corresponding to &amp;quot;John thought&amp;quot;
into the third tree shown in figure 3 which, after lex-
ical insertion, corresponds to the string &amp;quot;It was Mary
that Bill liked&amp;quot;. As we will show later, this tree (rather
than the other two trees in figure 3) is considered be-
cause of the decision to extract &amp;quot;mary&amp;quot;. Notice that
the adjoining operation allows the strings for the two
independently derived clauses to be interspersed with
each other.
</bodyText>
<subsectionHeader confidence="0.908028">
Lexicalized TAGs: An Introduction
</subsectionHeader>
<bodyText confidence="0.998792444444444">
The grammatical formalism that we have chosen is a
Tree Adjoining Grammar (TAG) [Joshi 1985]. The en-
larged domain of locality in a TAG grammar enables
the kind of processing necessary to handle the identi-
fied problems in the systemic grammar. The lexicalized
and feature-based aspects of the formalism enables ease
of processing within the systemic framework.
TAG is a tree generating system where the basic
building blocks are tree structures. It is over these
tree structures that constraints may be placed. A TAG
grammar consists of two finite sets of elementary trees:
the initial trees and auxiliary trees. The initial trees
represent a minimal linguistic structure. The auxiliary
trees represent a minimal recursive structure that might
be brought into a derivation. The frontier of each auxil-
iary tree contains one node, termed the foot node, which
is a non-terminal identical to the root node of the tree.
Structures are derived in a TAG using the operations
</bodyText>
<sectionHeader confidence="0.487555" genericHeader="method">
ADJOINING
</sectionHeader>
<figure confidence="0.9890524">
Itoâ€“. root
Z
EL 7)L
foot
SUBSTITUTION
</figure>
<figureCaption confidence="0.99989">
Figure 2: Adjoining and Substitution Operations
</figureCaption>
<bodyText confidence="0.99983092">
adjunction and substitution which are described picto-
rially in figure 2. As shown in the figure the adjoining
operation first excises the subtree below the node of ad-
joining; inserts the auxiliary tree at this position; the
excised subtree is now inserted at the foot node of the
auxiliary tree used for adjunction. The substitution op-
eration replaces a node in the frontier of a tree with a
tree whose root is identical to that node.
We will use a feature structure based TAG[Vijay-
shanker &amp; Joshi 19881. That is, feature structures may
be associated with various nodes in the tree. When
adjoining or substitution is done, the feature structures
associated with the affected nodes must be unified. The
operation may only be done if the required unification is
successful. This will not be discussed any further here.
The TAG that we used is lexicalized in the sense de-
scribed in [Schabes et al. 1988]. This means that the
TAG is organized around the lexicon with lexical items
being associated with sets of elementary trees in which
that lexical item participates. The lexical item which
chooses a given elementary tree is termed the anchor of
that tree.
Trees are grouped into tree groups where each tree
in a tree group has the same underlying (logical form)
structure. Trees within a tree group are distinguished
</bodyText>
<page confidence="0.96434">
3
</page>
<figure confidence="0.959578636363636">
Transitive Tree Group
VP
V NP1
NPO S
NPO VP
V NP1
NPO
V N P 1
NPO
NP1
if means that at that node substitution must occur.
</figure>
<figureCaption confidence="0.999921">
Figure 3: A Tree Group Selected by Like
</figureCaption>
<bodyText confidence="0.986304652173913">
from one another by syntactic variations (which we shall
call transformations). For example, the verb like, which
takes a nominal subject and a nominal object, selects
the transitive tree group. Some of the members of this
tree group are shown in Figure 3. The figure contains
three initial trees, the first corresponds to a declarative
sentence, the second to a wh-question on the subject,
and the third to an it-cleft construction on the object.
S-TAGs
The processing within a Systemic Tree Adjoining
Grammar (S-TAG) is similar to that in systemic gram-
mar (e.g., the networks are traversed and the realization
operators associated with the choices taken are evalu-
ated). In S-TAG we have already stated that the indi-
vidual grammatical functions are realized structurally
by elementary trees and that elementary trees provide
the bounding scope for application of realization opera-
tors. Thus, the &amp;quot;functions&amp;quot; which are inserted into the
systemic structure will be associated with elementary
trees in the TAG formalism. While the types of realiza-
tion operators required by S-TAG will be the same as
for general systemic grammars, the individual operators
will be tailored to the TAG formalism.
</bodyText>
<subsectionHeader confidence="0.589393">
Regions in S-TAG
</subsectionHeader>
<bodyText confidence="0.896444926829268">
The basic processing within a systemic grammar must
take into account two dimensions of processing deci-
sions:
1. Metafunctional domains. Structures are built in the
three metafunctional domains (ideational, interper-
sonal, and textual) simultaneously. Certain realiza-
tion operators are used to &amp;quot;conflate&amp;quot; the indepen-
dently built structures.
2. Processing from one &amp;quot;rank&amp;quot; to another. It is through
changes in rank that semantic structures are eventu-
ally realized as surface form. The general method-
ology is to insert functional units into a structure.
Following this, these functional units are refined by
re-entering the network at a lower rank. This process
continues until a surface structure has been fleshed
out.
While the processing in the S-TAG grammar follows
the same principles, we differ in some implementation
issues to accommodate TAG. One of the major contri-
butions of this work is in the processing from one rank
to another. In particular, this work makes explicit the
bounding domains for the realization operators which
are responsible for realizing a given grammatical func-
tion. Thus it becomes clear what is available for manip-
ulation when a network is entered (and re-entered for
specifying a function inserted during the initial network
traversals). We employ the notion of a region for this
purpose.
In general a region is created to expand a grammat-
ical function. Since we have said that elementary trees
are appropriate structural units for realizing the func-
tions and for the bounding domains for the realization
operators, we state that an elementary tree will eventu-
ally be associated with every region. The appropriate
elementary tree will be chosen after a decision has been
made to insert a lexical item. Informally, this lexical
item will be the lexical anchor of the elementary tree
that will be chosen in the region. For this reason we
will call this lexical item the lexical anchor of the re-
gion also.1 The region serves as the bounding domain
on the realization operations. All realization operations
</bodyText>
<footnote confidence="0.746611">
&apos;This approach has interesting consequences, such as
adopting a head driven generation strategy within the sys-
</footnote>
<page confidence="0.992588">
4
</page>
<bodyText confidence="0.999484642857143">
used within a region are applicable on the features of the
lexical anchor of the region or the tree selected by this
anchor. In the section on &amp;quot;Lexicon and Tree Groups&amp;quot;
we will discuss how the features of the anchor, the tree
groups selected, and trees selected will be maintained
in a region.
Once a lexical anchor is picked, the tree groups asso-
ciated with that anchor will be considered. The choices
in the network will cause realization operators to be
evaluated which will narrow this set of trees to one.
This single tree is then said to be associated with the
region and will be the structuratrealization of the gram-
matical function being expanded (whose expansion was
the reason for the creation of the region). This filtering
will be done by using realization operations that select
between tree groups and those that select tree members
within tree groups. Such realization operations will be
discussed in the section on &amp;quot;Realization Operators&amp;quot;.
Based on the characteristics of the tree associated
with a region and directives from the networks be-
ing traversed, decisions to expand certain grammati-
cal functions (previously inserted in the region) will be
made. Sub-regions will be created to expand these func-
tions and the network will be re-entered to determine
the expansion. Notice that this will cause an elementary
tree to be associated with each sub-region. These sub-
regions must eventually be combined with the super-
regions which spawned them using realization opera-
tions for adjoining and substitution.
This view of the process is potentially complicated
since some of the realization operations to be evaluated
in the region may not be applied before the set of trees
being considered is narrowed down sufficiently. For ex-
ample, an operator which selects a particular tree need
not be applied until the tree groups have been narrowed
to one. If at the point an operator which selects a tree
is called for, if the number of tree groups has not been
reduced to one, it serves no purpose to apply the oper-
ation on each tree group. Hence, in such cases, within
a region we will maintain a record of realization opera-
tions that have to be completed later. These operations
will be applied at the appropriate time.
</bodyText>
<subsectionHeader confidence="0.854097">
Lexicon and Tree Groups
</subsectionHeader>
<bodyText confidence="0.9971757">
In the lexicon, a lexical item will be associated with
a set of tree groups, each of which contains a set of
elementary trees. We choose to represent a tree group
in the lexicon as a feature-structure/tree-group-name
pair. The feature-structure includes all of the common
features of the trees within the tree groups, the features
of the lexical item itself, and its lexical idiosyncrasies,
if any. The tree group name can be thought of as a
pointer to the actual tree group kept in a separate area
(allowing for sharing of tree groups by lexical items).
temics framework. It will also have implications on the de-
sign of the network.
For example, with the lexical item, walk, we will
associate the pairs ( f intrans),
&amp;noun, noun). trans, for instance, is the name of the
,...tran,, trans), ( f
tree group for transitive verbs. All trees in this group
share the information that the lexical anchor is a tran-
sitive verb. Thus, this information is stored in ftrans
along with any other features that are common to the
trees in the group. The other two pairs represent the
fact that walk can be used as a intransitive verb as well
as a noun.
The trees that constitute a tree group are kept to-
gether. Some realization operators which will be evalu-
ated in a region will refer to certain grammatical func-
tions that are represented as nodes in the tree associ-
ated with that region. Hence we will use a mapping
table that maps abstract positions (grammatical func-
tions) to actual nodes in an elementary tree.
</bodyText>
<subsectionHeader confidence="0.588956">
Realization Operators
</subsectionHeader>
<bodyText confidence="0.999979081081081">
Having set up the notion of a region (and its asso-
ciated elementary tree) as the bounding domain over
which the realization operators can function, we are
now in a position to discuss some of the realization
operators that will be used in S-TAG. These opera-
tors parallel those found in other systemic grammar
implementations, although they are particular to the
use of TAG. According to [Matthiessen &amp; Kasper 19851
the realization operators used in a systemic network
can be viewed along three dimensions: (1) Structuring
(which defines the structure and its organization within
one rank and within one functional domain), (2) Rank
(which &amp;quot;organizes the grammar into a scale of units:
clause - group/phrase - word - morpheme&amp;quot; [Matthiessen
&amp; Kasper 1985, p. 25]), and (3) Metafunctional lay-
ering (which integrates the structures developed within
the various metafunctional domains (e.g., interpersonal,
ideational, and textual)).
We concentrate on the rank and structuring opera-
tors because they appear to be most affected by the
addition of TAG. Aside from the nature of the actual
structural units, a major difference between S-TAG and
previous implementations of systemics is that previous
implementations have built up structures of minimal
import: upon proper evidence a functional unit is added
to the current structure, ordered with respect to the
other elements, accumulates features, and is then ex-
panded so as to satisfy those features. There appears
to be no automatic mechanism for carrying out syn-
tactic implications of decisions that have been made.
In S-TAG we take an opposite approach. In the TAG
we have precompiled minimally complete packages of
syntactic structure. Rather than building up structure
only when we have enough evidence to know that it
is correct (as has previously been done), our operation
can be characterized as deciding between the syntac-
tic possibilities that are consistent with what is known
</bodyText>
<page confidence="0.985996">
5
</page>
<bodyText confidence="0.981002571428572">
at the given point in the network.&apos; As a result many
of the structuring operators we introduce are designed
to narrow down the trees that could possibly realize a
particular function.
Introducing the Lexical Anchor: Insert(Lex-
item) When the lexical anchor is identified in the
network, this operation will be used. The purpose of
this operation is not only to introduce the lexical an-
chor into the region but also to bring the associated set
of feature-structure/tree-group-name pairs. Thus the
tree group itself is not brought in but is indirectly ac-
cessible. A tree is brought into the region only after
the narrowing process is completed. The anchor is then
inserted into the tree.
Filtering Tree Groups in a Region We will use
one realization operation to choose among the the tree
groups being considered in a region. This choice is made
on the basis of some features that become known during
the traversal of the network and is basically a decision
about the functional units the realization must repre-
sent. Thus, in some sense it is analogous to the &amp;quot;in-
sert&amp;quot; operator in Nigel. For example, the insertion of a
particular lexical item, say walk, will bring into consid-
eration all possible tree groups it can participate in. If
it becomes known (in the transitivity network) that the
recipient function will have to be realized, then among
the various tree groups of the lexical anchor of the re-
gion, only the appropriate tree groups (such as those
corresponding to transitive verb form) will have to be
considered.
For current purposes, the realization operation that
filters the tree groups will be called Select-Group
which takes a feature as an argument. In the
above example, the network may cause the opera-
tion: Select-Group(transitive) to be evaluated. Re-
call that the three tree-groups referenced for this lexi-
cal item are represented by the pairs: (â€žftra,,,,trans),
(fintra,â€ž , intrans), and ( f
â€ž noun , noun). Since the
feature-structures f
.â€¢ trans, fintr ans fnoun are kept in the
lexicon itself rather than with the tree group, these tu-
ples will be brought into the region on lexical insertion.
If the realization operation Select-Group(transitive)
(which is analogous to insert process and recipient in
the Nigel grammar) is evaluated in the region, the
feature transitive is unified with the three feature-
structures ftrans fintrans fnoun â€¢ Since this feature is
only consistent with the features in f
</bodyText>
<figureCaption confidence="0.568738">
trans 7 only the pair
</figureCaption>
<bodyText confidence="0.993718955555556">
(ftrans , trans) will remain in the region.
Selecting Trees from a Tree Group The realiza-
tion operation used to narrow down the choice of ele-
mentary trees within a tree group considered in a region
&apos;Note it is not necessary to bring all of the syntactic
structures into the region, rather much of this processing
can be done based on the features stored with the lexical
anchor.
is called Select-Tree. We had described a tree group
to correspond to a specific semantic entity with all of
its relevant semantic features inserted. The group it-
self represents all syntactic realizations of this entity.
Therefore the purpose of this operation is to choose
among different syntactic forms possible. Its effect is
somewhat analogous to that of the &amp;quot;order&amp;quot; operators
in Nigel. For example, if during the traversal of the
network it is realized that the object is to be topical-
ized then the Select-Tree operation will be evaluated.
Among the various syntactic variations possible, the
tree(s) which realize this thematization will thus be
identified.
Composing Trees Recall that sub-regions are cre-
ated to expand grammatical functions. The elementary
trees associated with the sub-regions are to be com-
posed with the tree associated with the super-region
either by substitution or by adjunction. Expansion of
a grammatical function is done, in the Nigel grammar,
when a function is preselected with a set of features.
The preselected features determine where to re-enter
the network in order to expand the given function. The
resulting realization will replace the original function
in the eventual realization of the input. In S-TAG this
is accomplished by using the realization operation Ex-
pand(function, features). This will cause the creation
of a sub-region (which is named by the function). The
realization of the function will occur in this sub-region
by re-entering the network at a point determined by the
preselected feature (as in Nigel).
The tree which eventually realizes the function must
be composed (by substitution or adjoining) with the
tree in the super-region at the node corresponding to
the function (as given by the mapping table). The
decision to adjoin or substitute is made based on the
types of the trees that are picked in the sub- and super-
regions.
</bodyText>
<sectionHeader confidence="0.976375" genericHeader="discussions">
Discussion
</sectionHeader>
<bodyText confidence="0.999954411764706">
The strongest asset of systemic grammar is its view of
generation as a goal-directed enterprise with emphasis
laid on function rather than form. While our work in-
volves the incorporation of a syntactic formalism into
systemic grammar, we have not departed from the gen-
eral approach of systemic&apos;s view of generation. Sys-
temic linguists, however, have not been interested in
the details of the mapping between functional choices
and the resulting form. In particular, they are not con-
cerned with the details of the structural units that are
realized. In a computer implementation, a programmer
needs to be concerned about the details of the structural
units, how they are realized, and how the constraints of
systemic grammars are translated as principles of im-
plementation. It is in this context that we propose the
use of TAG trees as appropriate structural units and
examine the processing paradigm (and its logical con-
</bodyText>
<page confidence="0.996172">
6
</page>
<bodyText confidence="0.995509212389381">
sequences) that follows from such a choice. Thus the
incorporation of TAG is more than just a simpleaddi-
tion of a syntactic formalism to the systemic framework.
We argue that the incorporation of TAGs enriches a sys-
temic grammar implementation for the following rea-
sons:
First, systemic linguists have stressed the notion of
stepwise semantic decomposition as a constraint on any
implementation of a systemic grammar. Hence it is not
unreasonable to expect the realization of the form to
conform to the decomposition of the semantic units. We
have called this the independence criterion, indicating
that independent decomposed functional units be real-
ized independently in any implementation of systemic
grammar. We argued that in order to be consistent with
this paradigm, we have to choose appropriate struc-
tural units as realizations of semantic/functional pieces.
These units must capture all necessary structural rela-
tionships, and should be the bounding domains for the
realization operators that build them. Under these con-
ditions, we argued that the structural units should have
a &amp;quot;large&amp;quot; enough notion of locality to be able to factor
out all structural dependencies. Since the elementary
structures of TAGs are &amp;quot;minimally complete&amp;quot; to allow
for the factoring of dependencies, we have argued that
they are appropriate structures that can be built and
manipulated in an implementation of systemic gram-
mar. They also form appropriate bounding domains
for the realization operators. Our preliminary work on
incorporating TAGs in the systemic framework gives us
encouragement to believe that this is indeed the case.
Second, in addition to justifying the use of TAG
structures for systemics, we can show that we can han-
dle the discontinuity (which we did not explicitly dis-
cuss for lack of space) and long distance dependency
problem which plague other implementations of sys-
temic grammars. The key point to make here is that
not only are these handled but that generation of utter-
ances with discontinuity or long distance dependencies
is conceptually no different than generation of utter-
ances without any form of discontinuity.
Third, systemic grammar places emphasis on func-
tion over form and makes clear that functional distinc-
tions in the input manifests themselves in the different
available forms. It is clear that our approach brings
this aspect of systemics to the fore front. Note that the
different trees in a tree group yield various syntactic re-
alizations of a single predicate-argument structure. As
we step through the network, various choices are made
on the basis of the functional content of the planned
utterance. These choices will result in choosing one
syntactic realization over another.
Finally, what we have suggested calls for putting to-
gether two formalisms so that a mainly semantics driven
processor (systemics) is able to reap some of the advan-
tages of a syntax driven (TAG) approach. Currently a
systemic network employs limited mechanism for carry-
ing through the syntactic consequences of the decisions
that it makes. Thus one of two things has to happen:
1. the network designer must anticipate all syntactic
consequences and explicitly state each of them at the
time a decision is made. This is not an ideal solution,
especially when the network becomes very large.
2. the system must depend on the environment being
consistent in order to carry out the desired conse-
quences. In this case the syntactic consequences are
strung throughout the network (perhaps prompted
by different questions that are asked). The envi-
ronment must be counted on to answer those ques-
tions in a consistent fashion. Even if the informa-
tion is straightforwardly captured in the environment
(which is unclear), due to lack of the ability to carry
out syntactic consequences, it becomes necessary to
ask questions of the environment (to make choices)
that are redundant. In addition, this arrangement
goes against the systemic enterprise in which the en-
vironment keeps track of semantic content.
The addition of TAG allows an independent mech-
anism (e.g., the TAG processing) to maintain consis-
tent syntactic consequences of decisions made. For ex-
ample, agreement constraints are precompiled into the
tree. Also, for example, given the choice of a particular
lexical item â€” once the trees for that item have been
narrowed to one, the tree itself will contain the infor-
mation about what functions must be expanded. Thus
this information need not be included in the network as
well.
We believe that network design will be simpler be-
cause the incorporation of TAG makes possible clear
demarcation of semantic choices from syntactic conse-
quences. Also it allow for the separation of lexical id-
iosyncrasies into the lexicon rather than the network.
Our work so far has been concerned with identifying
the TAG structures as appropriate structural units in a
computer implementation of a systemic grammar. The
implementation decisions that have been discussed are
given to indicate the logical consequences of incorpo-
rating the TAG formalism in the systemic paradigm.
These consequences would necessarily be handled in
any actual implementation (e.g., breaking processing
into regions, associating elementary trees with regions,
the nature of realization operators). Considerable work
remains to be done. We need to investigate the con-
sequences of using the TAG formalism on the design
of the systemic network especially in terms of uncov-
ering redundancy and separation of syntax, semantics,
and lexicon design. While currently used networks will
be helpful in this task, we anticipate considerable revi-
sions in the network design due to the incorporation of
TAG. Furthermore, we have only examined some func-
tional domains and a subset of realization operations
that will be required. These topics are the focus of our
current research.
</bodyText>
<page confidence="0.999235">
7
</page>
<sectionHeader confidence="0.998337" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999778980392157">
[Bateman St Paris 1989] Bateman, J. and Paris, C.
1989. Phrasing a text in terms the user can under-
stand. In: Proceedings of the 11th International Joint
Conference on Artificial Intelligence, IJCAI-89, De-
troit, Michigan: 1511-1517.
[Davey 1978] Davey, A. 1978. Discourse Production.
Edinburgh University Press, Edinburgh.
[Fawcett 1980] Fawcett, R.P. 1980. Cognitive linguis-
tics and social interaction. Julius Groos Verlag Hei-
delburg and Exter University.
[Halliday 1985] Halliday, M. A. K. 1985. An introduc-
tion to functional grammar. Edward Arnold, London
England.
[Hudson 1971] Hudson, R.A. 1971. English Complex
Sentences: An Introduction to Systemic Grammar.
North Holland.
[Joshi 1985] Joshi, Aravind K. 1985. How Much
Context-Sensitivity is Necessary for Chracterizing
Structural Descriptions : Tree Adjoining Grammar.
In: D. Dowty, L. Karttunen, and A. Zwicky, Eds.,
Natural Language Processing : Theoretical, Compu-
tational and Psychological Perspectives. Cambridge
University Press, New York.
[Mann 1983] Mann, William C. 1983. A Linguistic
Overview of the Nigel: Text Generation Grammar.
Technical Report ISI/RS-83-9, ISI/USC.
[Mann St Matthiessen 1985] Mann, W. and
Matthiessen, C. 1985. Nigel: A systemic grammar
for text generation. In: 0. Freedle, Ed., Systemic
Perspectives on Discourse. Norwood, NJ.
[Matthiessen St Kasper 1985] Matthiessen, Chris-
tian and Kasper, Robert. 1985. Representational Is-
sues in Systemic Functional Grammar -and- Systemic
Grammar and Functional Unification Grammar. In:
12th International Systemic Workshop, Ann Arbor,
Michigan, Also appears as: ISI/USC Technical Note
RS-87-179, May 1987.
[Patten 1988] Patten, T. 1988. Systemic Text Gen-
eration as Problem Solving. Cambridge University
Press, Cambridge.
[Schabes et al. 1988] Schabes, Y., Abille, A., and
Joshi, A. 1988. Parsing Strategies with &apos;Lexicalized&apos;
Grammars: Application to Tree Adjoining Gram-
mars. In: Proceedings of the 12th International
Conference on Computational Linguistics (COLING&apos;
88), Budapest, Hungary.
[Vijay-shanker &amp; Joshi 1988] Vijay-shanker, K. and
Joshi, Aravind K. 1988. Feature Structure Based
Tree Adjoining Grammar. In: Proceedings of the 12th
International Conference on Computational Linguis-
tics (COLING&apos; 88), Budapest, Hungary.
</reference>
<page confidence="0.998477">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966990">
<title confidence="0.9978325">Using Tree Adjoining Grammars in the Systemic Framework*</title>
<author confidence="0.999815">Kathleen F McCoy</author>
<author confidence="0.999815">K Vijay-Shanker</author>
<author confidence="0.999815">Gijoo Yang</author>
<affiliation confidence="0.999956">University of Delaware</affiliation>
<address confidence="0.987941">Newark, DE 19716</address>
<abstract confidence="0.999062611111111">In this paper we investigate the incorporation of Tree Adjoining Grammars (TAG) into the systemic framework. We show that while systemic grammars have many desirable characteristics as a generation paradigm, they appear to have problems in generating certain kinds of sentences (e.g., those containing discontinuity or long-distance dependencies). We argue that these problems can be overcome with an appropriate choice of structural units of realization. We show that TAG provides appropriate units of structural realization because they localize all dependencies and allow the realization of two independent subpieces to be interspersed with each other. We go on to show how TAG can be incorporated without affecting the basic tenants of systemic grammar. Finally, we indicate how the incorporation of TAG yields several benefits to the systemic framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bateman</author>
<author>C Paris</author>
</authors>
<title>Phrasing a text in terms the user can understand. In:</title>
<date>1989</date>
<booktitle>Proceedings of the 11th International Joint Conference on Artificial Intelligence, IJCAI-89,</booktitle>
<pages>1511--1517</pages>
<location>Detroit, Michigan:</location>
<marker>[Bateman St Paris 1989]</marker>
<rawString>Bateman, J. and Paris, C. 1989. Phrasing a text in terms the user can understand. In: Proceedings of the 11th International Joint Conference on Artificial Intelligence, IJCAI-89, Detroit, Michigan: 1511-1517.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Davey</author>
</authors>
<title>Discourse Production.</title>
<date>1978</date>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh.</location>
<marker>[Davey 1978]</marker>
<rawString>Davey, A. 1978. Discourse Production. Edinburgh University Press, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
</authors>
<title>Cognitive linguistics and social interaction.</title>
<date>1980</date>
<institution>Julius Groos Verlag Heidelburg and Exter University.</institution>
<marker>[Fawcett 1980]</marker>
<rawString>Fawcett, R.P. 1980. Cognitive linguistics and social interaction. Julius Groos Verlag Heidelburg and Exter University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>An introduction to functional grammar. Edward Arnold,</title>
<date>1985</date>
<location>London England.</location>
<marker>[Halliday 1985]</marker>
<rawString>Halliday, M. A. K. 1985. An introduction to functional grammar. Edward Arnold, London England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Hudson</author>
</authors>
<title>English Complex Sentences: An Introduction to Systemic Grammar.</title>
<date>1971</date>
<publisher>North Holland.</publisher>
<marker>[Hudson 1971]</marker>
<rawString>Hudson, R.A. 1971. English Complex Sentences: An Introduction to Systemic Grammar. North Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>How Much Context-Sensitivity is Necessary for Chracterizing Structural Descriptions : Tree Adjoining Grammar. In:</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<marker>[Joshi 1985]</marker>
<rawString>Joshi, Aravind K. 1985. How Much Context-Sensitivity is Necessary for Chracterizing Structural Descriptions : Tree Adjoining Grammar. In: D. Dowty, L. Karttunen, and A. Zwicky, Eds., Natural Language Processing : Theoretical, Computational and Psychological Perspectives. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
</authors>
<title>A Linguistic Overview of the Nigel: Text Generation Grammar.</title>
<date>1983</date>
<tech>Technical Report ISI/RS-83-9, ISI/USC.</tech>
<marker>[Mann 1983]</marker>
<rawString>Mann, William C. 1983. A Linguistic Overview of the Nigel: Text Generation Grammar. Technical Report ISI/RS-83-9, ISI/USC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>C Matthiessen</author>
</authors>
<title>Nigel: A systemic grammar for text generation. In: 0. Freedle, Ed., Systemic Perspectives on Discourse.</title>
<date>1985</date>
<location>Norwood, NJ.</location>
<marker>[Mann St Matthiessen 1985]</marker>
<rawString>Mann, W. and Matthiessen, C. 1985. Nigel: A systemic grammar for text generation. In: 0. Freedle, Ed., Systemic Perspectives on Discourse. Norwood, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Matthiessen</author>
<author>Robert Kasper</author>
</authors>
<title>Representational Issues in Systemic Functional Grammar -and- Systemic Grammar and Functional Unification Grammar. In:</title>
<date>1985</date>
<booktitle>12th International Systemic Workshop, Ann Arbor, Michigan, Also appears as: ISI/USC Technical Note</booktitle>
<pages>87--179</pages>
<marker>[Matthiessen St Kasper 1985]</marker>
<rawString>Matthiessen, Christian and Kasper, Robert. 1985. Representational Issues in Systemic Functional Grammar -and- Systemic Grammar and Functional Unification Grammar. In: 12th International Systemic Workshop, Ann Arbor, Michigan, Also appears as: ISI/USC Technical Note RS-87-179, May 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Patten</author>
</authors>
<title>Systemic Text Generation as Problem Solving.</title>
<date>1988</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>[Patten 1988]</marker>
<rawString>Patten, T. 1988. Systemic Text Generation as Problem Solving. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A Abille</author>
<author>A Joshi</author>
</authors>
<title>Parsing Strategies with &apos;Lexicalized&apos; Grammars: Application to Tree Adjoining Grammars. In:</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics (COLING&apos; 88),</booktitle>
<location>Budapest, Hungary.</location>
<marker>[Schabes et al. 1988]</marker>
<rawString>Schabes, Y., Abille, A., and Joshi, A. 1988. Parsing Strategies with &apos;Lexicalized&apos; Grammars: Application to Tree Adjoining Grammars. In: Proceedings of the 12th International Conference on Computational Linguistics (COLING&apos; 88), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-shanker</author>
<author>Aravind K Joshi</author>
</authors>
<title>Feature Structure Based Tree Adjoining Grammar. In:</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics (COLING&apos; 88),</booktitle>
<location>Budapest, Hungary.</location>
<marker>[Vijay-shanker &amp; Joshi 1988]</marker>
<rawString>Vijay-shanker, K. and Joshi, Aravind K. 1988. Feature Structure Based Tree Adjoining Grammar. In: Proceedings of the 12th International Conference on Computational Linguistics (COLING&apos; 88), Budapest, Hungary.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>