<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006681">
<title confidence="0.9921905">
PRHLT: Combination of Deep Autoencoders with Classification and
Regression Techniques for SemEval-2015 Task 11
</title>
<author confidence="0.944283">
Parth Gupta
</author>
<affiliation confidence="0.919234">
PRHLT Research Center
</affiliation>
<address confidence="0.771054666666667">
Universitat Polit`ecnica de Val`encia
Camino de Vera, s/n
46022 Valencia, SPAIN
</address>
<email confidence="0.99823">
pgupta@dsic.upv.es
</email>
<author confidence="0.811317">
Jon Ander G´omez
</author>
<affiliation confidence="0.798107">
PRHLT Research Center
</affiliation>
<address confidence="0.781468">
Universitat Polit`ecnica de Val`encia
Camino de Vera, s/n
46022 Valencia, SPAIN
</address>
<email confidence="0.999068">
jon@dsic.upv.es
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999816882352941">
This paper presents the system we developed
for Task 11 of SemEval 2015. Our system had
two stages: The first one was based on deep
autoencoders for extracting features to com-
pactly represent tweets. The next stage con-
sisted of a classifier or a regression function
for estimating the polarity value assigned to
a given tweet. We tested several techniques in
order to choose the ones with the highest accu-
racy. Finally, three regression techniques re-
vealed as the best ones for assigning the polar-
ity value to tweets. We presented six runs cor-
responding to three regression different tech-
niques in combination with two variants of the
autoencoder, one with input as bags of words
and another with input as bags of character 3-
grams.
</bodyText>
<sectionHeader confidence="0.999524" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9984693">
Sentiment Analysis from texts is a growing field of
research due to its social and economic relevance.
Task 11 of SemEval-2015 (Semantic Evaluation Ex-
ercises) was proposed to the research community in
order to foster the development of systems and tech-
niques for Sentiment Analysis (Ghosh et al., 2015).
We faced this challenging task with a system
based on deep autoencoders in combination with
classification and regression techniques. We used
deep autoencoders to extract features from tweets by
means of two ways of splitting text: i) words and
ii) character 3-grams. The training of autoencoders
was unsupervised. The extracted features (10) and a
few manually added features (5) were used for train-
ing classifiers or regression functions to estimate the
tweet’s polarity value.
The rest of the paper is organized as follows. Sec-
tion 2 describes the proposed system. Section 3
presents the obtained results on the test set. Finally,
conclusions are discussed in Section 4.
</bodyText>
<sectionHeader confidence="0.980521" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999938136363637">
Our system consists of two stages: (1) Dimension-
ality reduction by means of deep autoencoders. (2)
Polarity value assignment by using different classi-
fication and regression techniques.
The text of tweets was preprocessed before being
used as input to the autoencoders. The autoencoders
take as input a representation of each tweet. Two
different representations were used: bags of words
and bags of character 3-grams. In both cases the
output of an autoencoder was a vector of 10 real
values. Optionally we added other features in order
to improve the polarity assignment, these additional
features are binary features indicating whether some
symbols or hash tags appear in the tweet. The idea
behind adding these extra features is to set a con-
text for learning under their influence. The different
subsets of used features are described in subsection
2.3. The step of assigning a polarity value to a given
tweet was carried out by a classifier or a regression
function. Several techniques for classification and
regression were tested. Table 2 shows the relation of
the used techniques.
</bodyText>
<subsectionHeader confidence="0.987017">
2.1 Tweets Preprocessing
</subsectionHeader>
<bodyText confidence="0.9990075">
As mentioned above, the input for the autoencoders
was prepared from two different ways of splitting
</bodyText>
<page confidence="0.986069">
689
</page>
<note confidence="0.687941">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 689–693,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<table confidence="0.9994354">
Pattern or regular expression New text
&amp;quot;#&amp;quot; &amp;quot; #&amp;quot;
&amp;quot;@&amp;quot; &amp;quot; @&amp;quot;
&amp;quot;&amp;&amp;quot; &amp;quot; &amp; &amp;quot;
&amp;quot;&lt;&amp;quot; &amp;quot;&lt;&amp;quot;
&amp;quot;&gt;&amp;quot; &amp;quot;&gt;&amp;quot;
&amp;quot;&amp;.*;&amp;quot; &amp;quot; HTML &amp;quot;
&amp;quot;\\u0092&amp;quot; &amp;quot;’&amp;quot;
&amp;quot;[0-9]+:[0-9]+[Aa][Mm]&amp;quot; &amp;quot; H &amp;quot;
&amp;quot;[0-9]+:[0-9]+&amp;quot; &amp;quot; H &amp;quot;
&amp;quot;[0-9]+[Aa][Mm]&amp;quot; &amp;quot; H &amp;quot;
&amp;quot;http[s]*://[a-zA-Z0-9\\. /-_]+&amp;quot; &amp;quot;&amp;quot;
&amp;quot;http[s]*:/+&amp;quot; &amp;quot;&amp;quot;
&amp;quot;http&amp;quot; &amp;quot;&amp;quot;
&amp;quot;@[_a-zA-Z0-9]+&amp;quot; &amp;quot;&amp;quot;
&amp;quot; : &amp;quot; &amp;quot; &amp;quot;
&amp;quot; [0-9\\.-:]+ &amp;quot; &amp;quot; N &amp;quot;
&amp;quot;[\\u00ff-\\uffff]+&amp;quot; &amp;quot; A &amp;quot;
&amp;quot;!!!+&amp;quot; &amp;quot;!3+&amp;quot;
&amp;quot;\\?\\?\\?+&amp;quot; &amp;quot;?3+&amp;quot;
&amp;quot;\\.\\.\\.+&amp;quot; &amp;quot;?.+&amp;quot;
&amp;quot;\\p{Punct}{3,}&amp;quot; &amp;quot; P &amp;quot;
&amp;quot;&gt; &gt;&amp;quot; &amp;quot;&gt;&amp;quot;
&amp;quot;&lt; &lt;&amp;quot; &amp;quot;&lt;&amp;quot;
&amp;quot;&gt;+&amp;quot; &amp;quot;&gt;&amp;quot;
&amp;quot;&lt;+&amp;quot; &amp;quot;&gt;&amp;quot;
&amp;quot;-+&amp;quot; &amp;quot;-&amp;quot;
&amp;quot; +&amp;quot; &amp;quot; &amp;quot;
&amp;quot; &amp;quot; &amp;quot;_&amp;quot;
&amp;quot;_+&amp;quot; &amp;quot;_&amp;quot;
</table>
<tableCaption confidence="0.977104">
Table 1: Substitution rules used for normalizing the text
</tableCaption>
<figureCaption confidence="0.684028333333333">
of tweets. The double quotes are used here as delimiters,
like in Java for String literals, they are not part of the
pattern. Rules are presented in the same format they were
used as arguments for the method replaceAll() of
class String of Java. Rules were applied in the same
order they appear in this table.
</figureCaption>
<bodyText confidence="0.9999573">
the text of tweets. Before the splitting step, a clean-
ing process was carried out by applying a set of sub-
stitutions. The goal was to normalize the text before
generating the bags of words or character 3-grams.
Table 1 shows the rules used for carrying out such
substitutions. These rules were extracted by us af-
ter analyzing the text of tweets corresponding to the
training set. The order in that these rules were ap-
plied was relevant to the final result. The desired
effects were the following:
</bodyText>
<listItem confidence="0.96393">
• Removing URLs from the text of tweets. We
assumed URLs were not relevant for guessing
the polarity.
• User identifiers were also removed.
• Emoticons and possible animations were also
reduced to a capital A. We were interested in
knowing whether they appear or not.
• Sequences of repeated symbols or punctuation
signs were reduced to one instance or a se-
quence to indicate the repetition.
• Numbers or dates were reduced to a capital let-
ter indicating their appearance.
• Some symbols were forced to be preceded by
a white space in order to facilitate the posterior
splitting into words.
• Sequences of several white spaces were re-
duced to one white space and all white spaces
were converted to underscores.
</listItem>
<bodyText confidence="0.9998722">
After the normalizing step, the splitting step was
carried out in order to prepare the input for deep au-
toencoders. Two splitting ways were applied, one
for separating words using white spaces (or under-
scores) and another one using character sequences
of size 3 (character 3-grams).
In the case a tweet was represented as a bag of
words, all the words found in the training set were
used. A special entry for out-of-vocabulary words
was introduced into the word table for generating
the bags of words. We considered tokens as words
those including only letters from the Latin alphabet.
Numbers or other symbols were not included.
In the case of representing tweets as bags of char-
acter 3-grams, only those that appeared three or
more times in the training set were used. The re-
maining ones were considered as out-of-vocabulary.
A special entry for out-of-vocabulary 3-grams was
introduced into the 3-grams table for generating the
bags of 3-grams.
</bodyText>
<subsectionHeader confidence="0.993981">
2.2 Deep Autoencoders
</subsectionHeader>
<bodyText confidence="0.9996098">
Autoencoders provide an unsupervised way to learn
low-dimensional embeddings of the data. Such rep-
resentation can be used for discriminative tasks. We
used a deep autoencoder to extract such features.
The fundamental block of our autoencoder was the
restricted Boltzman machine (RBM). We used the
contrastive-divergence algorithm for pretraining the
autoencoder followed by the fine-tuning to minimize
the reconstruction error shown in Eq. 1 (Hinton and
Salakhutdinov, 2006).
</bodyText>
<equation confidence="0.987722">
J = IIX − X1112 (1)
</equation>
<bodyText confidence="0.495153">
where, X is the original vector and X&apos; is its recon-
struction.
</bodyText>
<page confidence="0.977744">
690
</page>
<bodyText confidence="0.999891666666667">
The architecture1 of the autoencoder was |X|-
200-100-100-10 and the sigmoid function was used
to add non-linearity to the hidden layers except for
the final layer which was linear. We used replicated
softmax to model count data in the visible layer of
the autoencoder (Hinton and Salakhutdinov, 2009).
</bodyText>
<subsectionHeader confidence="0.998325">
2.3 Classification and Regression Techniques
</subsectionHeader>
<bodyText confidence="0.999186333333333">
Different classification and regression techniques
were tested in order to figure out which ones were
the more appropriated for estimating the polarity
of tweets. This checking process was carried out
with the training set. We used the Scikit-Learn
toolkit (Pedregosa et al., 2011) for all the tested tech-
niques.
Given the output of each autoencoder we used
three different sets of features:
</bodyText>
<listItem confidence="0.94466525">
1. Just the vectors of 10 real values obtained from
autoencoders. 10 features.
2. Same 10 features as above plus five bi-
nary features indicating whether some hash
</listItem>
<bodyText confidence="0.994470619047619">
tags or symbols were present in the tweet.
The additional five binary features corre-
sponded to the presence of three hash tags
#irony, #sarcasm, #not, and whether
the tweet contains quotes or emoticons.
In total 15 features.
3. Same 15 features as for the second set
plus additional binary features for indicat-
ing whether any of the hash tags found in
the training set was present in the tweet.
In total 3580 (10+5+3565) features.
Table 2 shows the list of all classification and re-
gression techniques used in the second stage of our
system. All techniques are used from the Scikit-
Learn toolkit (Pedregosa et al., 2011). For train-
ing each classifier or regression function we used the
same input data, i.e. the feature vectors representing
each tweet from the training set and its polarity.
The output of classifiers is the integer value of the
polarity, but in the case of regression functions the
output value is truncated to the nearest integer.
</bodyText>
<footnote confidence="0.937933666666667">
1We did not notice any difference in performance empiri-
cally with other configurations with a general caution that much
larger number of parameters model might lead to over-fitting.
</footnote>
<bodyText confidence="0.9998362">
The different classification and regression tech-
niques used in the second stage were configured
with the default values for their hyperparame-
ters (Pedregosa et al., 2011). Some variations of hy-
perparameters were tested, but no further improve-
ments were observed. Our purpose was to check
which techniques were more suitable.
A more exhaustive search in order to find optimal
combinations of hyperparameters for each technique
would be an interesting extension of this work.
</bodyText>
<sectionHeader confidence="0.999872" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.999969166666667">
Tables 2 and 3 show the results obtained with the
test set. The whole training set was used for training
all the tested techniques. It could be observed that
the best results were obtained by the Ensemble of
Extremely Randomized Trees (or Extra-Trees) used
for regression (Geurts et al., 2006). Other ensemble
techniques presented similar results. Focusing our
attention on Table 3 and comparing with the results
shown in Table 2, it could be observed as two vari-
ants of SVMs get results similar to the best ones, but
no significant improvements were observed when
using the set of 3580 features.
</bodyText>
<sectionHeader confidence="0.997756" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999983095238095">
We developed a system for participating in Task 11
of SemEval-2015 which consisted of two stages. In
the first stage stage we used deep autoencoders for
obtaining a compact representation of tweets. We
tried three sets of features that were used as input for
different classification and regression techniques.
Results obtained in average from the 10-fold
cross-validation we carried out with the training
set revealed that the three most appropriated tech-
niques were three ensembles: Extremely Random-
ized Trees, Random Forest and Bagging of Decision
Trees. The regression setting of these techniques
performed better than that of classification.
The fact that the techniques which obtained the
best results are purely non-parametric and have no
weights for approximating the output value, tell us
that the obtained compact representation of tweets
by means of deep autoencoders needs more analy-
sis. An effort in exploring more configurations of
autoencoders will help us to obtain better compact
representations, which we plan to do in future. We
</bodyText>
<page confidence="0.99484">
691
</page>
<table confidence="0.999958321428571">
Classification or Regression Technique Cosine Similarity
3-grams 10 words 10 3-grams 15 words 15
Automatic Relevance Determination Regressor 0.469 0.451 0.462 0.525
Bayesian Ridge Linear Regressor 0.552 0.562 0.609 0.618
Elastic Net Regressor 0.544 0.557 0.541 0.557
Ensemble AdaBoost Regressor Exponential 0.311 0.332 0.377 0.351
Ensemble AdaBoost Regressor Linear 0.540 0.556 0.554 0.587
Ensemble AdaBoost Regressor Squared 0.199 0.213 0.314 0.212
Ensemble Bagging Regressor with Decision Trees 0.558 0.549 0.593 0.587
Ensemble of Extra Trees Classifier 0.549 0.542 0.549 0.537
Ensemble of Extra Trees Regressor 0.565 0.557 0.623 0.610
Ensemble of Random Forests Classifier 0.535 0.542 0.536 0.541
Ensemble of Random Forests Regressor 0.554 0.555 0.592 0.610
KNN Classifier with inverse distance weights 0.497 0.497 0.501 0.495
KNN Classifier with uniform weights 0.507 0.526 0.517 0.518
LARS Lasso Linear Regressor 0.546 0.546 0.546 0.546
Lasso Linear Regressor 0.545 0.557 0.545 0.557
Logistic Regression (Classifier) 0.556 0.542 0.545 0.541
Perceptron Classifier 0.469 0.451 0.462 0.525
Passive Aggresive Regressor 0.561 0.378 0.564 0.384
RANSAC Regressor 0.507 0.532 0.547 0.592
Ridge Linear Regressor 0.552 0.563 0.608 0.620
SVM Linear Classifier 0.555 0.539 0.552 0.545
SVM Linear Regressor 0.551 0.552 0.583 0.570
SVM Polynomial Classifier 0.545 0.539 0.540 0.550
SVM Polynomial Regressor 0.587 0.560 0.599 0.610
SVM RBF Classifier 0.541 0.542 0.541 0.538
SVM RBF Regressor 0.593 0.562 0.604 0.560
</table>
<tableCaption confidence="0.999673">
Table 2: Results of all the tested techniques for the two kind of inputs used for the deep autoencoder: 3-grams and
words, and for feature sets with 10 and 15 features.
</tableCaption>
<table confidence="0.999910666666667">
Classification or Regression Technique Cosine Similarity
3-grams 3580 features words 3580 features
Bayesian Ridge Linear Regressor 0.605 0.621
Ensemble Bagging Regressor with Decision Trees 0.595 0.605
Ensemble of Extra Trees Regressor 0.626 0.596
Ensemble of Random Forests Regressor 0.593 0.616
Ridge Linear Regressor 0.596 0.615
SVM Linear Regressor 0.598 0.593
SVM RBF Regressor 0.610 0.566
</table>
<tableCaption confidence="0.998589">
Table 3: Results of some of the tested techniques for the two kind of inputs used for the deep autoencoder: 3-grams
</tableCaption>
<bodyText confidence="0.89126525">
and words, and for the feature set with 3580 features.
also plan to use the tweet polarity information dur-
ing the fine-tuning stage of training as an additional
supervised component.
</bodyText>
<sectionHeader confidence="0.999338" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9625175">
The research work of the first author is supported by
the FPI grant from UPV.
</bodyText>
<page confidence="0.997683">
692
</page>
<sectionHeader confidence="0.998338" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999857653846154">
Pierre Geurts, Damien Ernst and Louis Wehenkel. 2006.
Extremely Randomized Trees. Machine Learning
(ISSN 0885-6125) vol. 63, no. 1, pp. 2–42. Kluwer
Academic Publishers, 2006
Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso,
Ekaterina Shutova, Antonio Reyes and John Barnden.
2015. SemEval-2015 Task 11: Sentiment Analysis of
Figurative Language in Twitter. In Proc. Int. Workshop
on Semantic Evaluation (SemEval-2015), Co-located
with NAACL and *SEM, Denver, Colorado, US, June
4-5, 2015
Geoffrey Hinton and Ruslan Salakhutdinov. 2006. Re-
ducing the Dimensionality of Data with Neural Net-
works. Science vol. 313, no. 5786, pp. 504–507, 2006
Fabian Pedregosa, Gael Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier Grisel,
Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vin-
cent Dubourg, Jake Vanderplas, Alexandre Passos,
David Cournapeau, Matthieu Brucher, Matthieu Perrot
and Edouard Duchesnay. 2011. Scikit-learn: Machine
Learning in Python, In Journal of Machine Learning
Research, JMLR vol. 12, pp. 2825–2830, 2011
Geoffrey Hinton and Ruslan Salakhutdinov. 2009.
Replicated Softmax: an Undirected Topic Model. In
Advances in Neural Information Processing Systems,
pp. 1607–1614, 2009
</reference>
<page confidence="0.999127">
693
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.420384">
<title confidence="0.848824333333333">PRHLT: Combination of Deep Autoencoders with Classification Regression Techniques for SemEval-2015 Task 11 Parth</title>
<affiliation confidence="0.975334666666667">PRHLT Research Universitat Polit`ecnica de Camino de Vera,</affiliation>
<address confidence="0.999505">46022 Valencia,</address>
<email confidence="0.952667">pgupta@dsic.upv.es</email>
<author confidence="0.999923">Jon Ander</author>
<affiliation confidence="0.993498">PRHLT Research Universitat Polit`ecnica de Camino de Vera,</affiliation>
<address confidence="0.999729">46022 Valencia,</address>
<email confidence="0.995193">jon@dsic.upv.es</email>
<abstract confidence="0.988723611111111">This paper presents the system we developed for Task 11 of SemEval 2015. Our system had two stages: The first one was based on deep autoencoders for extracting features to compactly represent tweets. The next stage consisted of a classifier or a regression function for estimating the polarity value assigned to a given tweet. We tested several techniques in order to choose the ones with the highest accuracy. Finally, three regression techniques revealed as the best ones for assigning the polarity value to tweets. We presented six runs corresponding to three regression different techniques in combination with two variants of the autoencoder, one with input as bags of words and another with input as bags of character 3grams.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pierre Geurts</author>
<author>Damien Ernst</author>
<author>Louis Wehenkel</author>
</authors>
<title>Extremely Randomized Trees.</title>
<date>2006</date>
<journal>Machine Learning (ISSN 0885-6125)</journal>
<volume>63</volume>
<pages>2--42</pages>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="10059" citStr="Geurts et al., 2006" startWordPosition="1626" endWordPosition="1629">et al., 2011). Some variations of hyperparameters were tested, but no further improvements were observed. Our purpose was to check which techniques were more suitable. A more exhaustive search in order to find optimal combinations of hyperparameters for each technique would be an interesting extension of this work. 3 Results Tables 2 and 3 show the results obtained with the test set. The whole training set was used for training all the tested techniques. It could be observed that the best results were obtained by the Ensemble of Extremely Randomized Trees (or Extra-Trees) used for regression (Geurts et al., 2006). Other ensemble techniques presented similar results. Focusing our attention on Table 3 and comparing with the results shown in Table 2, it could be observed as two variants of SVMs get results similar to the best ones, but no significant improvements were observed when using the set of 3580 features. 4 Conclusions We developed a system for participating in Task 11 of SemEval-2015 which consisted of two stages. In the first stage stage we used deep autoencoders for obtaining a compact representation of tweets. We tried three sets of features that were used as input for different classificatio</context>
</contexts>
<marker>Geurts, Ernst, Wehenkel, 2006</marker>
<rawString>Pierre Geurts, Damien Ernst and Louis Wehenkel. 2006. Extremely Randomized Trees. Machine Learning (ISSN 0885-6125) vol. 63, no. 1, pp. 2–42. Kluwer Academic Publishers, 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aniruddha Ghosh</author>
<author>Guofu Li</author>
<author>Tony Veale</author>
<author>Paolo Rosso</author>
<author>Ekaterina Shutova</author>
<author>Antonio Reyes</author>
<author>John Barnden</author>
</authors>
<title>SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter.</title>
<date>2015</date>
<booktitle>In Proc. Int. Workshop on Semantic Evaluation (SemEval-2015), Co-located with NAACL and *SEM,</booktitle>
<location>Denver, Colorado, US,</location>
<contexts>
<context position="1439" citStr="Ghosh et al., 2015" startWordPosition="223" endWordPosition="226">sion techniques revealed as the best ones for assigning the polarity value to tweets. We presented six runs corresponding to three regression different techniques in combination with two variants of the autoencoder, one with input as bags of words and another with input as bags of character 3- grams. 1 Introduction Sentiment Analysis from texts is a growing field of research due to its social and economic relevance. Task 11 of SemEval-2015 (Semantic Evaluation Exercises) was proposed to the research community in order to foster the development of systems and techniques for Sentiment Analysis (Ghosh et al., 2015). We faced this challenging task with a system based on deep autoencoders in combination with classification and regression techniques. We used deep autoencoders to extract features from tweets by means of two ways of splitting text: i) words and ii) character 3-grams. The training of autoencoders was unsupervised. The extracted features (10) and a few manually added features (5) were used for training classifiers or regression functions to estimate the tweet’s polarity value. The rest of the paper is organized as follows. Section 2 describes the proposed system. Section 3 presents the obtaine</context>
</contexts>
<marker>Ghosh, Li, Veale, Rosso, Shutova, Reyes, Barnden, 2015</marker>
<rawString>Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, Antonio Reyes and John Barnden. 2015. SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter. In Proc. Int. Workshop on Semantic Evaluation (SemEval-2015), Co-located with NAACL and *SEM, Denver, Colorado, US, June 4-5, 2015</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Hinton</author>
<author>Ruslan Salakhutdinov</author>
</authors>
<title>Reducing the Dimensionality of Data with</title>
<date>2006</date>
<journal>Neural Networks. Science</journal>
<volume>313</volume>
<pages>504--507</pages>
<contexts>
<context position="7160" citStr="Hinton and Salakhutdinov, 2006" startWordPosition="1149" endWordPosition="1152">of-vocabulary. A special entry for out-of-vocabulary 3-grams was introduced into the 3-grams table for generating the bags of 3-grams. 2.2 Deep Autoencoders Autoencoders provide an unsupervised way to learn low-dimensional embeddings of the data. Such representation can be used for discriminative tasks. We used a deep autoencoder to extract such features. The fundamental block of our autoencoder was the restricted Boltzman machine (RBM). We used the contrastive-divergence algorithm for pretraining the autoencoder followed by the fine-tuning to minimize the reconstruction error shown in Eq. 1 (Hinton and Salakhutdinov, 2006). J = IIX − X1112 (1) where, X is the original vector and X&apos; is its reconstruction. 690 The architecture1 of the autoencoder was |X|- 200-100-100-10 and the sigmoid function was used to add non-linearity to the hidden layers except for the final layer which was linear. We used replicated softmax to model count data in the visible layer of the autoencoder (Hinton and Salakhutdinov, 2009). 2.3 Classification and Regression Techniques Different classification and regression techniques were tested in order to figure out which ones were the more appropriated for estimating the polarity of tweets. T</context>
</contexts>
<marker>Hinton, Salakhutdinov, 2006</marker>
<rawString>Geoffrey Hinton and Ruslan Salakhutdinov. 2006. Reducing the Dimensionality of Data with Neural Networks. Science vol. 313, no. 5786, pp. 504–507, 2006</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fabian Pedregosa</author>
<author>Gael Varoquaux</author>
<author>Alexandre Gramfort</author>
<author>Vincent Michel</author>
<author>Bertrand Thirion</author>
<author>Olivier Grisel</author>
<author>Mathieu Blondel</author>
<author>Peter Prettenhofer</author>
</authors>
<title>Scikit-learn: Machine Learning in Python,</title>
<date>2011</date>
<journal>In Journal of Machine Learning Research, JMLR</journal>
<volume>12</volume>
<pages>2825--2830</pages>
<institution>Cournapeau, Matthieu Brucher, Matthieu Perrot</institution>
<location>Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David</location>
<contexts>
<context position="7877" citStr="Pedregosa et al., 2011" startWordPosition="1264" endWordPosition="1267">chitecture1 of the autoencoder was |X|- 200-100-100-10 and the sigmoid function was used to add non-linearity to the hidden layers except for the final layer which was linear. We used replicated softmax to model count data in the visible layer of the autoencoder (Hinton and Salakhutdinov, 2009). 2.3 Classification and Regression Techniques Different classification and regression techniques were tested in order to figure out which ones were the more appropriated for estimating the polarity of tweets. This checking process was carried out with the training set. We used the Scikit-Learn toolkit (Pedregosa et al., 2011) for all the tested techniques. Given the output of each autoencoder we used three different sets of features: 1. Just the vectors of 10 real values obtained from autoencoders. 10 features. 2. Same 10 features as above plus five binary features indicating whether some hash tags or symbols were present in the tweet. The additional five binary features corresponded to the presence of three hash tags #irony, #sarcasm, #not, and whether the tweet contains quotes or emoticons. In total 15 features. 3. Same 15 features as for the second set plus additional binary features for indicating whether any </context>
<context position="9452" citStr="Pedregosa et al., 2011" startWordPosition="1527" endWordPosition="1530">ed the same input data, i.e. the feature vectors representing each tweet from the training set and its polarity. The output of classifiers is the integer value of the polarity, but in the case of regression functions the output value is truncated to the nearest integer. 1We did not notice any difference in performance empirically with other configurations with a general caution that much larger number of parameters model might lead to over-fitting. The different classification and regression techniques used in the second stage were configured with the default values for their hyperparameters (Pedregosa et al., 2011). Some variations of hyperparameters were tested, but no further improvements were observed. Our purpose was to check which techniques were more suitable. A more exhaustive search in order to find optimal combinations of hyperparameters for each technique would be an interesting extension of this work. 3 Results Tables 2 and 3 show the results obtained with the test set. The whole training set was used for training all the tested techniques. It could be observed that the best results were obtained by the Ensemble of Extremely Randomized Trees (or Extra-Trees) used for regression (Geurts et al.</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, 2011</marker>
<rawString>Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot and Edouard Duchesnay. 2011. Scikit-learn: Machine Learning in Python, In Journal of Machine Learning Research, JMLR vol. 12, pp. 2825–2830, 2011</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Hinton</author>
<author>Ruslan Salakhutdinov</author>
</authors>
<title>Replicated Softmax: an Undirected Topic Model.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>1607--1614</pages>
<contexts>
<context position="7549" citStr="Hinton and Salakhutdinov, 2009" startWordPosition="1216" endWordPosition="1219">toencoder was the restricted Boltzman machine (RBM). We used the contrastive-divergence algorithm for pretraining the autoencoder followed by the fine-tuning to minimize the reconstruction error shown in Eq. 1 (Hinton and Salakhutdinov, 2006). J = IIX − X1112 (1) where, X is the original vector and X&apos; is its reconstruction. 690 The architecture1 of the autoencoder was |X|- 200-100-100-10 and the sigmoid function was used to add non-linearity to the hidden layers except for the final layer which was linear. We used replicated softmax to model count data in the visible layer of the autoencoder (Hinton and Salakhutdinov, 2009). 2.3 Classification and Regression Techniques Different classification and regression techniques were tested in order to figure out which ones were the more appropriated for estimating the polarity of tweets. This checking process was carried out with the training set. We used the Scikit-Learn toolkit (Pedregosa et al., 2011) for all the tested techniques. Given the output of each autoencoder we used three different sets of features: 1. Just the vectors of 10 real values obtained from autoencoders. 10 features. 2. Same 10 features as above plus five binary features indicating whether some has</context>
</contexts>
<marker>Hinton, Salakhutdinov, 2009</marker>
<rawString>Geoffrey Hinton and Ruslan Salakhutdinov. 2009. Replicated Softmax: an Undirected Topic Model. In Advances in Neural Information Processing Systems, pp. 1607–1614, 2009</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>