<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000742">
<title confidence="0.954724">
Parsing Coordinations
</title>
<author confidence="0.99768">
Sandra K¨ubler
</author>
<affiliation confidence="0.998593">
Indiana University
</affiliation>
<email confidence="0.991951">
skuebler@indiana.edu
</email>
<author confidence="0.952715">
Wolfgang Maier
</author>
<affiliation confidence="0.732141">
Unversit¨at T¨ubingen
</affiliation>
<email confidence="0.470685">
wo.maier@uni-tuebingen.de
</email>
<author confidence="0.838632">
Erhard Hinrichs
</author>
<affiliation confidence="0.693854">
Universit¨at T¨ubingen
</affiliation>
<email confidence="0.954222">
eh@sfs.uni-tuebingen.de
</email>
<author confidence="0.882047">
Eva Klett
</author>
<affiliation confidence="0.70494">
Universit¨at T¨ubingen
</affiliation>
<email confidence="0.992778">
eklett@sfs.uni-tuebingen.de
</email>
<sectionHeader confidence="0.993725" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999946444444444">
The present paper is concerned with sta-
tistical parsing of constituent structures
in German. The paper presents four ex-
periments that aim at improving parsing
performance of coordinate structure: 1)
reranking the n-best parses of a PCFG
parser, 2) enriching the input to a PCFG
parser by gold scopes for any conjunct, 3)
reranking the parser output for all possi-
ble scopes for conjuncts that are permissi-
ble with regard to clause structure. Exper-
iment 4 reranks a combination of parses
from experiments 1 and 3.
The experiments presented show that n-
best parsing combined with reranking im-
proves results by a large margin. Provid-
ing the parser with different scope possi-
bilities and reranking the resulting parses
results in an increase in F-score from
69.76 for the baseline to 74.69. While the
F-score is similar to the one of the first ex-
periment (n-best parsing and reranking),
the first experiment results in higher re-
call (75.48% vs. 73.69%) and the third one
in higher precision (75.43% vs. 73.26%).
Combining the two methods results in the
best result with an F-score of 76.69.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999946974358974">
The present paper is concerned with statistical
parsing of constituent structures in German. Ger-
man is a language with relatively flexible phrasal
ordering, especially of verbal complements and
adjuncts. This makes processing complex cases
of coordination particularly challenging and error-
prone. The paper presents four experiments that
aim at improving parsing performance of coor-
dinate structures: the first experiment involves
reranking of n-best parses produced by a PCFG
parser, the second experiment enriches the input
to a PCFG parser by offering gold pre-bracketings
for any coordinate structures that occur in the sen-
tence. In the third experiment, the reranker is
given all possible pre-bracketed candidate struc-
tures for coordinated constituents that are permis-
sible with regard to clause macro- and microstruc-
ture. The parsed candidates are then reranked.
The final experiment combines the parses from the
first and the third experiment and reranks them.
Improvements in this final experiment corroborate
our hypothesis that forcing the parser to work with
pre-bracketed conjuncts provides parsing alterna-
tives that are not present in the n-best parses.
Coordinate structures have been a central is-
sue in both computational and theoretical linguis-
tics for quite some time. Coordination is one of
those phenomena where the simple cases can be
accounted for by straightforward empirical gen-
eralizations and computational techniques. More
specifically, it is the observation that coordination
involves two or more constituents of the same cat-
egories. However, there are a significant number
of more complex cases of coordination that defy
this generalization and that make the parsing task
of detecting the right scope of individual conjuncts
and correctly delineating the correct scope of the
coordinate structure as a whole difficult. (1) shows
some classical examples of this kind from English.
</bodyText>
<listItem confidence="0.989963666666667">
(1) a. Sandy is a Republican and proud of it.
b. Bob voted, but Sandy did not.
c. Bob supports him and Sandy me.
</listItem>
<bodyText confidence="0.976222285714286">
In (1a), unlike categories (NP and adjective) are
conjoined. (1b) and (1c) are instances of ellipsis
(VP ellipsis and gapping). Yet another difficult set
of examples present cases of non-constituent con-
junction, as in (2), where the direct and indirect
object of a ditransitive verb are conjoined.
(2) Bob gave a book to Sam and a record to Jo.
</bodyText>
<note confidence="0.923829">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 406–414,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997556">
406
</page>
<sectionHeader confidence="0.86921" genericHeader="introduction">
2 Coordination in German
</sectionHeader>
<bodyText confidence="0.999159583333333">
The above phenomena have direct analogues in
German.1 Due to the flexible ordering of phrases,
their variability is even higher. For example, due
to constituent fronting to clause-initial position in
German verb-second main clauses, cases of non-
constituent conjunction can involve any two NPs
(including the subject) of a ditransitive verb to the
exclusion of the third NP complement that appears
in clause-initial position. In addition, German ex-
hibits cases of asymmetric coordination first dis-
cussed by H¨ohle (1983; 1990; 1991) and illus-
trated in (3).2
</bodyText>
<listItem confidence="0.680902">
(3) In
</listItem>
<sectionHeader confidence="0.369094" genericHeader="method">
Into
</sectionHeader>
<bodyText confidence="0.981139571428571">
Hasen.
hare.
Such cases of subject gap coordination are fre-
quently found in text corpora (cf. (4) below) and
involve conjunction of a full verb-second clause
with a VP whose subject is identical to the subject
in the first conjunct.
</bodyText>
<sectionHeader confidence="0.949934" genericHeader="method">
3 Experimental Setup and Baseline
</sectionHeader>
<subsectionHeader confidence="0.998514">
3.1 The Treebank
</subsectionHeader>
<bodyText confidence="0.999890222222222">
The data source used for the experiments is the
T¨ubingen Treebank of Written German (T¨uBa-
D/Z) (Telljohann et al., 2005). T¨uBa-D/Z uses
the newspaper ’die tageszeitung’ (taz) as its data
source, version 3 comprises approximately 27 000
sentences. The treebank annotation scheme dis-
tinguishes four levels of syntactic constituency:
the lexical level, the phrasal level, the level of
topological fields, and the clausal level. The pri-
mary ordering principle of a clause is the inventory
of topological fields (VF, LK, MF, VC, and NF),
which characterize the word order regularities
among different clause types of German. T¨uBa-
D/Z annotation relies on a context-free backbone
(i.e. proper trees without crossing branches) of
phrase structure combined with edge labels that
specify the grammatical function of the phrase in
question. Conjuncts are generally marked with the
</bodyText>
<footnote confidence="0.974553142857143">
1To avoid having to gloss German examples, they were
illustrated for English.
2Yet, another case of such asymmetric coordination dis-
cussed by H¨ohle involves cases of conjunction of different
clause types: [V −final Wenn du nach Hause kommst ] und
[V −2nd da warten Polizeibeamte vor der T¨ur. ’If you come
home and there are policemen waiting in front of the door ] .’
</footnote>
<bodyText confidence="0.998614545454545">
function label KONJ. Figure 1 shows the anno-
tation that sentence (4) received in the treebank.
Syntactic categories are displayed as nodes, gram-
matical functions as edge labels in gray (e.g. OA:
direct object, PRED: predicate). This is an exam-
ple of a subject-gap coordination, in which both
conjuncts (FKONJ) share the subject (ON) that is
realized in the first conjunct.
Bev¨olkerungs-
decline in
r¨uckgang zwar abgeschw¨acht, ist
population though lessened, is
so groß
so big
’For this reason, although the decline in
population has lessened, it is still twice as
big as in 1996.’
The syntactic annotation scheme of the T¨uBa-
D/Z is described in more detail in Telljohann et al.
(2004; 2005).
All experiments reported here are based on a
data split of 90% training data and 10% test data.
</bodyText>
<subsectionHeader confidence="0.999942">
3.2 The Parsers and the Reranker
</subsectionHeader>
<bodyText confidence="0.999975153846154">
Two parsers were used to investigate the influ-
ence of scope information on parser performance
on coordinate structures: BitPar (Schmid, 2004)
and LoPar (Schmid, 2000). BitPar is an effi-
cient implementation of an Earley style parser that
uses bit vectors. However, BitPar cannot han-
dle pre-bracketed input. For this reason, we used
LoPar for the experiments where such input was
required. LoPar, as it is used here, is a pure
PCFG parser, which allows the input to be par-
tially bracketed. We are aware that the results
that can be obtained by pure PCFG parsers are
not state of the art as reported in the shared task
of the ACL 2008 Workshop on Parsing German
(K¨ubler, 2008). While BitPar reaches an F-score
of 69.76 (see next section), the best performing
parser (Petrov and Klein, 2008) reaches an F-
score of 83.97 on T¨uBa-D/Z (but with a different
split of training and test data). However, our ex-
periments require certain features in the parsers,
namely the capability to provide n-best analyses
and to parse pre-bracketed input. To our knowl-
edge, the parsers that took part in the shared task
do not provide these features. Should they become
available, the methods presented here could be ap-
plied to such parsers. We see no reason why our
</bodyText>
<figure confidence="0.991313863636364">
den Wald ging ein J¨ager und
the woods went a hunter and
einen
a
schoss
shot
(4) Damit
So
hat
has
sich
itself
der
the
aber noch
however still
doppelt
double
wie
as
1996.
1996.
</figure>
<page confidence="0.885061">
407
</page>
<figureCaption confidence="0.999893">
Figure 1: A tree with coordination.
</figureCaption>
<bodyText confidence="0.999790785714286">
methods should not be able to improve the results
of these parsers further.
Since we are interested in parsing coordina-
tions, all experiments are conducted with gold
POS tags, so as to abstract away from POS tag-
ging errors. Although the treebank contains mor-
phological information, this type of information is
not used in the experiments presented here.
The reranking experiments were conducted us-
ing the reranker by Collins and Koo (2005). This
reranker uses a set of candidate parses for a sen-
tence and reranks them based on a set of features
that are extracted from the trees. The reranker uses
a boosting method based on the approach by Fre-
und et al. (1998). We used a similar feature set
to the one Collins and Koo used; the following
types of features were included: rules, bigrams,
grandparent rules, grandparent bigrams, lexical
bigrams, two-level rules, two-level bigrams, tri-
grams, head-modifiers, PPs, and distance for head-
modifier relations, as well as all feature types in-
volving rules extended by closed class lexicaliza-
tion. For a more detailed description of the rules,
the interested reader is referred to Collins and
Koo (2005). For coordination, these features give
a wider context than the original parser has and
should thus result in improvements for this phe-
nomenon.
</bodyText>
<subsectionHeader confidence="0.999675">
3.3 The Baseline
</subsectionHeader>
<bodyText confidence="0.99328209375">
When trained on 90% of the approximately 27,000
sentences of the T¨uBa-D/Z treebank, BitPar
reaches an F-Score of 69.73 (precision: 68.63%,
recall: 70.93%) on the full test set of 2611 sen-
tences. These results as well as all further re-
sults presented here are labeled results, including
grammatical functions. Since German has a rela-
tively free word order, it is impossible to deduce
the grammatical function of a noun phrase from
the configuration of the sentence. Consequently,
an evaluation based solely on syntactic constituent
labels would be meaningless (cf. (K¨ubler, 2008)
for a discussion of this point). The inclusion of
grammatical labels in the trees, makes the parsing
process significantly more complex.
Looking at sentences with coordination (i.e.
sentences that contain a conjunction which is not
in sentence-initial position), we find that 34.9%
of the 2611 test sentences contain coordinations.
An evaluation of only sentences with coordina-
tion shows that there is a noticeable difference: the
F-score reaches 67.28 (precision: 66.36%, recall:
68.23%) as compared to 69.73 for the full test set.
The example of a wrong parse shown below il-
lustrates why parsing of complex coordinations is
so hard. Complex coordinations can take up a con-
siderable part of the input string and accordingly
of the overall sentence structure. Such global phe-
nomena are particularly hard for pure PCFG pars-
ing, due to the independence assumption inherent
in the statistical models for PCFGs.
Sentence (4) has the following Viterbi parse:
</bodyText>
<equation confidence="0.9924894">
(VROOT
(SIMPX
(VF
(SIMPX-OS
(VF (PX-MOD (PROP-HD Damit)))
(LK
(VXFIN-HD (VAFIN-HD hat)))
(MF
408
(NX-OA (PRF-HD sich))
(NX-ON (ART der)
(NN-HD Bev¨olkerungsr¨uckgang))
(ADVX-MOD (ADV-HD zwar)))
(VC (VXINF-OV
(VVPP-HD abgeschw¨acht)))))
($, ,)
(LK
(VXFIN-HD (VAFIN-HD ist)))
(MF
(ADVX-MOD (ADV-HD aber))
(ADVX-MOD (ADV-HD noch))
(ADJX-PRED
(ADJX-HD (ADVX (ADV-HD mehr))
(ADJX (KOKOM als)
(ADJD-HD doppelt))
(ADVX (ADV-HD so))
(ADJD-HD groß))
(NX (KOKOM wie)
(CARD-HD 1996)))))
($. .))
</equation>
<bodyText confidence="0.999910833333333">
The parse shows that the parser did not
recognize the coordination. Instead, the first con-
junct including the fronted constituent, Damit
hat sich der Bev¨olkerungsr¨uckgang
zwar abgeschw¨acht, is treated as a fronted
subordinate clause.
</bodyText>
<sectionHeader confidence="0.971078" genericHeader="method">
4 Experiment 1: n-Best Parsing and
Reranking
</sectionHeader>
<bodyText confidence="0.999946626865672">
The first hypothesis for improving coordination
parsing is based on the assumption that the correct
parse may not be the most probable one in Viterbi
parsing but may be recovered by n-best parsing
and reranking, a technique that has become stan-
dard in the last few years. If this hypothesis holds,
we should find the correct parse among the n-best
parses. In order to test this hypothesis, we con-
ducted an experiment with BitPar (Schmid, 2004).
We parsed the test sentences in a 50-best setting.
A closer look at the 50-best parses shows that of
the 2611 sentences, 195 (7.5%) were assigned the
correct parse as the best parse. For 325 more sen-
tences (12.4%), the correct parse could be found
under the 50 best analyses. What is more, in
90.2% of these 520 sentences, for which the cor-
rect parse was among the 50 best parses, the best
parse was among the first 10 parses. Additionally,
only in 4 cases were the correct analyses among
the 40-best to 50-best parses, an indication that in-
creasing n may not result in improving the results
significantly. These findings resulted in the deci-
sion not to conduct experiments with higher n.
That the 50 best analyses contain valuable infor-
mation can be seen from an evaluation in which an
oracle chooses from the 50 parses. In this case, we
reach an F-score of 80.28. However, this F-score
is also the upper limit for improvement that can be
achieved by reranking the 50-best parses.
For reranking, the features of Collins and
Koo (2005) were extended in the following way:
Since the German treebank used for our exper-
iments includes grammatical function informa-
tion on almost all levels in the tree, all feature
types were also included with grammatical func-
tions attached: All nodes except the root node
of the subtree in question were annotated with
their grammatical information. Thus, for the noun
phrase (NX) rule with grandparent prepositional
phrase (PX) PXGP NX —*ART ADJX NN, we add
an additional rule PXGP NX-HD —* ART ADJX
NN-HD.
After pruning all features that occurred in the
training data with a frequency lower than 5, the ex-
tractions produced more than 5 mio. different fea-
tures. The reranker was optimized on the training
data, the 50-best parses were produced in a 5-fold
cross-validation setting. A non-exhaustive search
for the best value for the α parameter showed that
Collins and Koo’s value of 0.0025 produced the
best results. The row for exp. 1 in Table 1 shows
the results of this experiment. The evaluation of
the full data set shows an improvement of 4.77
points in the F-score, which reached 74.53. This is
a relative reduction in error rate of 18.73%, which
is slightly higher that the error rate reduction re-
ported by Collins and Koo for the Penn Treebank
(13%). However, the results for Collins and Koo’s
original parses were higher, and they did not eval-
uate on grammatical functions.
The evaluation of coordination sentences shows
that such sentences profit from reranking to the
same degree. These results prove that while coor-
dination structures profit from reranking, they do
not profit more than other phenomena. We thus
conclude that reranking is no cure-all for solving
the problem of accurate coordination parsing.
</bodyText>
<sectionHeader confidence="0.994543" genericHeader="method">
5 Experiment 2: Gold Scope
</sectionHeader>
<bodyText confidence="0.99979925">
The results of experiment 1 lead to the conclusion
that reranking the n-best parses can only result
in restricted improvements on coordinations. The
fact that the correct parse often cannot be found
in the 50-best analyses suggests that the different
possible scopes of a coordination are so different
in their probability distribution that not all of the
possible scopes are present in the 50-best analyses.
</bodyText>
<page confidence="0.991872">
409
</page>
<table confidence="0.997422571428571">
all sentences F-score coord. sentences
precision recall precision recall F-score
baseline: 68.63 70.93 69.76 66.36 68.23 67.28
exp. 1: 50-best reranking: 73.26 75.84 74.53 70.67 72.72 71.68
exp. 2: with gold scope: 76.12 72.87 74.46 75.78 72.22 73.96
exp. 3: automatic scope: 75.43 73.96 74.69 72.88 71.42 72.14
exp. 4: comb. 1 and 3: 76.15 77.23 76.69 73.79 74.73 74.26
</table>
<tableCaption confidence="0.99989">
Table 1: The results of parsing all sentences and coordinated sentences only
</tableCaption>
<bodyText confidence="0.999823227272727">
If this hypothesis holds, forcing the parser to con-
sider the different scope readings should increase
the accuracy of coordination parsing. In order to
force the parser to use the different scope readings,
we first extract these scope readings, and then for
each of these scope readings generate a new sen-
tence with partial bracketing that represents the
corresponding scope (see below for an example).
LoPar is equipped to parse partially-bracketed in-
put. Given input sentences with partial brackets,
the parser restricts analyses to such cases that do
not contradict the brackets in the input.
’Which is correct because they are enter-
taining, but also triggers wrong associa-
tions.’
In order to test the validity of this hypothe-
sis, we conducted an experiment with coordination
scopes extracted from the treebank trees. These
scopes were translated into partial brackets that
were included in the input sentences. For the sen-
tence in (5) from the treebank (sic), the input for
LoPar would be the following:
</bodyText>
<equation confidence="0.9646732">
Was/PWS stimmt/VVFIN ,/$, weil/
KOUS ( sie/PPER unterhalt-
sam/ADJD sind/VAFIN ) ,/$,
aber/KON ( auch/ADV falsche/ADJA
Assoziationen/NN weckt/VVFIN )
</equation>
<bodyText confidence="0.999984352941176">
The round parentheses delineate the conjuncts.
LoPar was then forced to parse sentences contain-
ing coordination with the correct scope for the co-
ordination. The results for this experiment are
shown in Table 1 as exp. 2.
The introduction of partial brackets that delimit
the scope of the coordination improve overall re-
sults on the full test set by 4.7 percent points, a
rather significant improvement when we consider
that only approximately one third of the test sen-
tences were modified. The evaluation of the set
of sentences that contain coordination shows that
here, the difference is even higher: 6.7 percent
points. It is also worth noticing that provided with
scope information, the parser parses such sen-
tences with the same accuracy as other sentences.
The difference in F-scores between all sentences
and only sentences with coordination in this ex-
periment is much lower (0.5 percent points) than
for all other experiments (2.5–3.0 percent points).
When comparing the results of experiment 1 (n-
best parsing) with the present one, it is evident that
the F-scores are very similar: 74.53 for the 50-best
reranking setting, and 74.46 for the one where we
provided the gold scope. However, a comparison
of precision and recall shows that there are differ-
ences: 50-best reranking results in higher recall,
providing gold scope for coordinations in higher
precision. The lower recall in the latter experiment
indicates that the provided brackets in some cases
are not covered by the grammar. This is corrob-
orated by the fact that in n-best parsing, only 1
sentence could not be parsed; but in parsing with
gold scope, 8 sentences could not be parsed.
</bodyText>
<sectionHeader confidence="0.994039" genericHeader="method">
6 Experiment 3: Extracting Scope
</sectionHeader>
<bodyText confidence="0.986804611111111">
The previous experiment has shown that providing
the scope of a coordination drastically improves
results for sentences with coordination as well as
for the complete test set (although to a lower de-
gree). The question that remains to be answered is
whether automatically generated possible scopes
can provide enough information for the reranker
to improve results.
The first question that needs to be answered is
how to find the possible scopes for a coordina-
tion. One possibility is to access the parse forest
of a chart parser such as LoPar and extract infor-
(5) Was stimmt, weil sie
Which is correct, because they
unterhaltsam sind, aber auch falsche
entertaining are, but also wrong
Assoziationen weckt.
associations wakes.
</bodyText>
<page confidence="0.958707">
410
</page>
<bodyText confidence="0.999903111111111">
mation about all the possible scope analyses that
the parser found. If the same parser is used for
this step and for the final parse, we can be cer-
tain that only scopes are extracted that are com-
patible with the grammar of the final parser. How-
ever, parse forests are generally stored in a highly
packed format so that an exhaustive search of the
structures is very inefficient and proved impossi-
ble with present day computing power.
</bodyText>
<listItem confidence="0.484088">
(6) ”Es
</listItem>
<bodyText confidence="0.970184307692308">
”There
Niederflurbusse,
low-floor buses,
nicht”,
not”,
’”There are indeed a few low-floor buses,
but that isn’t enough”, he says.
Another solution consists of generating all pos-
sible scopes around the coordination. Thus, for
the sentence in (6), the conjunction is aber. The
shortest possible left conjunct is Niederflurbusse,
the next one paar Niederflurbusse, etc. Clearly,
many of these possibilities, such as the last exam-
ple, are nonsensical, especially when the proposed
conjunct crosses into or out of base phrase bound-
aries. Another type of boundary that should not
be crossed is a clause boundary. Since the con-
junction is part of the subordinated clause in the
present example, the right conjunct cannot extend
beyond the end of the clause, i.e. beyond nicht.
For this reason, we used KaRoPars (M¨uller and
Ule, 2002), a partial parser for German, to parse
the sentences. From the partial parses, we ex-
tracted base phrases and clauses. For (6), the rel-
evant bracketing provided by KaRoPars is the fol-
lowing:
</bodyText>
<equation confidence="0.820412333333333">
( &amp;quot; Es gibt zwar { ein paar
Niederflurbusse } , ) aber ( das
reicht ja nicht ) &amp;quot; , sagt er .
</equation>
<bodyText confidence="0.99997150877193">
The round parentheses mark clause boundaries,
the curly braces the one base phrase that is longer
than one word. In the creation of possible con-
juncts, only such conjuncts are listed that do not
cross base phrase or clause boundaries. In order to
avoid unreasonably high numbers of pre-bracketed
versions, we also use higher level phrases, such as
coordinated noun phrases. KaRoPars groups such
higher level phrases only in contexts that allow
a reliable decision. While a small percentage of
such decisions is wrong, the heuristic used turns
out to be reliable and efficient.
For each scope, a partially bracketed version
of the input sentence is created, in which only
the brackets for the suggested conjuncts are in-
serted. Each pre-bracketed version of the sentence
is parsed with LoPar. Then all versions for one
sentence are reranked. The reranker was trained
on the data from experiment 1 (n-best parsing).
The results of the reranker show that our restric-
tions based on the partial parser may have been
too restrictive. Only 375 sentences had more than
one pre-bracketed version, and only 328 sentence
resulted in more than one parse. Only the latter set
could then profit from reranking.
The results of this experiment are shown in Ta-
ble 1 as exp. 3. They show that extracting pos-
sible scopes for conjuncts from a partial parse
is possible. The difference in F-score between
this experiment and the baseline reaches 5.93 per-
cent points. The F-score is also minimally higher
than the F-score for experiment 2 (gold scope),
and recall is increased by approximately 1 per-
cent point (even though only 12.5% of the sen-
tences were reranked). This can be attributed to
two factors: First, we provide different scope pos-
sibilities. This means that if the correct scope is
not covered by the grammar, the parser may still
be able to parse the next closest possibility in-
stead of failing completely. Second, reranking is
not specifically geared towards improving coordi-
nated structures. Thus, it is possible that a parse is
reranked higher because of some other feature. It
is, however, not the case that the improvement re-
sults completely from reranking. This can be de-
duced from two points: First, while the F-score
for experiment 1 (50-best analyses plus reranking)
and the present experiment are very close (74.53
vs. 74.69), there are again differences in precision
and recall: In experiment 1, recall is higher, and in
the present experiment precision. Second, a look
at the evaluation on only sentences with coordi-
nation shows that the F-score for the present ex-
periment is higher than the one for experiment 1
(72.14 vs. 71.68). Additionally, precision for the
present experiment is more than 2 percent points
higher.
</bodyText>
<sectionHeader confidence="0.87836" genericHeader="method">
7 Experiment 4: Combining n-Best
</sectionHeader>
<subsectionHeader confidence="0.780091">
Parses and Extracted Scope Parses
</subsectionHeader>
<bodyText confidence="0.9683">
As described above, the results for reranking the
50-best analyses and for reranking the versions
</bodyText>
<figure confidence="0.998512714285714">
ein
a
zwar
indeed
paar
few
gibt
are
aber das reicht ja
but that suffices part.
er.
he.
sagt
says
</figure>
<page confidence="0.997696">
411
</page>
<bodyText confidence="0.999987345454546">
with automatically extracted scope readings are
very close. This raises the question whether the
two methods produce similar improvements in the
parse trees. One indicator that this is not the case
can be found in the differences in precision and re-
call. Another possibility of verifying our assump-
tion that the improvements do not overlap lies in
the combination of the 50-best parses with the
parses resulting from the automatically extracted
scopes. This increases the number of parses be-
tween which the reranker can choose. In effect,
this means a combination of the methods of exper-
iments 1 (n-best) and 3 (automatic scope). Con-
sequently, if the results from this experiment are
very close to the results from experiment 1 (n-
best), we can conclude that adding the parses with
automatic scope readings does not add new infor-
mation. If, however, adding these parses improves
results, we can conclude that new information was
present in the parses with automatic scope that
was not covered in the 50-best parses. Note that
the combination of the two types of input for the
reranker should not be regarded as a parser ensem-
ble but rather as a resampling of the n-best search
space since both parsers use the same grammar,
parsing model, and probability model. The only
difference is that LoPar can accept partially brack-
eted input, and BitPar can list the n-best analyses.
The results of this experiment are shown in Ta-
ble 1 as exp. 4. For all sentences, both precision
and recall are higher than for experiment 1 and 3,
resulting in an F-score of 76.69. This is more than
2 percent points higher than for the 50-best parses.
This is a very clear indication that the parses con-
tributed by the automatically extracted scopes pro-
vide parses that were not present in the 50 best
parses from experiment 1 (n-best). The same trend
can be seen in the evaluation of the sentences con-
taining coordination: Here, the improvement in F-
score is higher than for the whole set, a clear in-
dication that this method is suitable for improving
coordination parsing. A comparison of the results
of the present experiment and experiment 3 (with
automatic scope only) shows that the gain in pre-
cision is rather small, but the combination clearly
improves recall, from 73.96% to 77.23%. We can
conclude that adding the 50 best parses remedies
the lacking coverage that was the problem of ex-
periment 3. More generally, experiment 4 suggests
that for the notoriously difficult problem of pars-
ing coordination structures, a hybrid approach that
combines parse selection of n best analyses with
pre-bracketed scope in the input results in a con-
siderable reduction in error rate compared to each
of these methods used in isolation.
</bodyText>
<sectionHeader confidence="0.999009" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999883666666667">
Parsing of coordinate structures for English has
received considerable attention in computational
linguistics. Collins (1999), among many other au-
thors, reports in the error analysis of his WSJ pars-
ing results that coordination is one of the most fre-
quent cases of incorrect parses, particularly if the
conjuncts involved are complex. He manages to
reduce errors for simple cases of NP coordination
by introducing a special phrasal category of base
NPs. In the experiments presented above, no ex-
plicit distinction is made between simple and com-
plex cases of coordination, and no transformations
are performed on the treebank annotations used for
training.
Our experiment 1, reranking 50-best parses, is
similar to the approaches of Charniak and John-
son (2005) and of Hogan (2007). However, it dif-
fers from their experiments in two crucial ways: 1)
Compared to Charniak and Johnson, who use 1.1
mio. features, our feature set is appr. five times
larger (more than 5 mio. features), with the same
threshold of at least five occurrences in the training
set. 2) Both Hogan and Charniak and Johnson use
special features for coordinate structures, such as a
Boolean feature for marking parallelism (Charniak
and Johnson) or for distinguishing between coor-
dination of base NPs and coordination of complex
conjuncts (Hogan), while our approach refrains
from such special-purpose features.
Our experiments using scope information are
similar to the approaches of Kurohashi and Na-
gao (1994) and Agarwal and Bogges (1992) in that
they try to identify coordinate structure bracket-
ings. However, the techniques used by Agarwal
and Bogges and in the present paper are quite dif-
ferent. Agarwal and Bogges and Kurohashi and
Nagao rely on shallow parsing techniques to de-
tect parallelism of conjuncts while we use a par-
tial parser only for suggesting possible scopes of
conjuncts. Both of these approaches are limited
to coordinate structures with two conjuncts only,
while our approach has no such limitation. More-
over, the goal of Agarwal and Bogges is quite dif-
ferent from ours. Their goal is robust detection of
coordinate structures only (with the intended ap-
</bodyText>
<page confidence="0.995572">
412
</page>
<bodyText confidence="0.972034260869565">
plication of term extraction), while our goal is to
improve the performance of a parser that assigns a
complete sentence structure to an input sentence.
Finally, our approach at present is restricted to
purely syntactic structural properties. This is in
contrast to approaches that incorporate semantic
information. Hogan (2007) uses bi-lexical head-
head co-occurrences in order to identify nominal
heads of conjuncts more reliably than by syntactic
information alone. Chantree et al. (2005) resolve
attachment ambiguities in coordinate structures, as
in (7a) and (7b), by using word frequency informa-
tion obtained from generic corpora as an effective
estimate of the semantic compatibility of a modi-
fier vis-`a-vis the candidate heads.
(7) a. Project managers and designers
b. Old shoes and boots
We view the work by Hogan and by Chantree
et al. as largely complementary to, but at the same
time as quite compatible with our approach. We
must leave the integration of structural syntac-
tic and lexical semantic information to future re-
search.
</bodyText>
<sectionHeader confidence="0.97865" genericHeader="conclusions">
9 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999681606060606">
We have presented a study on improving the treat-
ment of coordinated structures in PCFG parsing.
While we presented experiments for German, the
methods are applicable for any language. We have
chosen German because it is a language with rel-
atively flexible phrasal ordering (cf. Section 2)
which makes parsing coordinations particularly
challenging. The experiments presented show that
n-best parsing combined with reranking improves
results by a large margin. However, the number
of cases in which the correct parse is present in
the n-best parses is rather low. This led us to the
assumption that the n-best analyses often do not
cover the whole range of different scope possibil-
ities but rather present minor variations of parses
with few differences in coordination scope. The
experiments in which the parser was forced to as-
sume predefined scopes show that the scope infor-
mation is important for parsing quality. Provid-
ing the parser with different scope possibilities and
reranking the resulting parses results in an increase
in F-score from 69.76 for the baseline to 74.69.
One of the major challenges for this approach lies
in extracting a list of possible conjuncts. Forc-
ing the parser to parse all possible sequences re-
sults in a prohibitively large number of possibili-
ties, especially for sentences with 3 or more con-
junctions. For this reason, we used chunks above
base phases, such as coordinated noun chunks, to
restrict the space. However, an inspection of the
lists of bracketed versions of the sentences shows
that the definition of base phrases is one of the ar-
eas that must be refined. As mentioned above, the
partial parser groups sequences of ”NP KON NP”
into a single base phrase. This may be correct in
many cases, but there are exceptions such as (8).
(8) Die 31j¨ahrige Gewerkschaftsmitarbei-
The 31-year-old union staff member
For (8), the partial parser groups Die 31j¨ahrige
Gewerkschaftsmitarbeiterin und ausgebildete In-
dustriekauffrau as one noun chunk. Since our
proposed conjuncts cannot cross these boundaries,
the correct second conjunct, ausgebildete Indus-
triekauffrau aus Oldenburg, cannot be suggested.
However, if we remove these chunk boundaries,
the number of possible conjuncts increases dra-
matically, and parsing times become prohibitive.
As a consequence, we will need to find a good bal-
ance between these two needs. Our plan is to in-
crease flexibility very selectively, for example by
enabling the use of wider scopes in cases where
the conjunction is preceded and followed by base
noun phrases. For the future, we are planning to
repeat experiment 3 (automatic scope) with differ-
ent phrasal boundaries extracted from the partial
parser. It will be interesting to see if improvements
in this experiment will still improve results in ex-
periment 4 (combining 50-best parses with exp. 3).
Another area of improvement is the list of fea-
tures used for reranking. At present, we use a fea-
ture set that is similar to the one used by Collins
and Koo (2005). However, this feature set does
not contain any coordination specific features. We
are planning to extend the feature set by features
on structural parallelism as well as on lexical sim-
ilarity of the conjunct heads.
</bodyText>
<figure confidence="0.744871833333333">
terin und ausgebildete Industriekauffrau
and trained industrial clerk
aus Oldenburg bereitet nun ihre
from Oldenburg is preparing now her
erste eigene CD vor.
first own CD part..
</figure>
<page confidence="0.997438">
413
</page>
<sectionHeader confidence="0.995771" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999832588888889">
Rajeev Agarwal and Lois Boggess. 1992. A simple but
useful approach to conjunct identification. In Pro-
ceedings of the 30th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL-92), pages
15–21, Newark, DE.
Francis Chantree, Adam Kilgarriff, Anne de Roeck,
and Alistair Willis. 2005. Disambiguating coordi-
nations using word distribution information. In Pro-
ceedings of Recent Advances in NLP (RANLP 2005),
pages 144–151, Borovets, Bulgaria.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL’05), pages 173–180, Ann Arbor, MI.
Michael Collins and Terry Koo. 2005. Discriminative
reranking for natural language parsing. Computa-
tional Linguistics, 31(1):25–69.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Anette Frank. 2002. A (discourse) functional analysis
of asymmetric coordination. In Proceedings of the
LFG-02 Conference, Athens, Greece.
Yoav Freund, Ray Iyer, Robert Shapire, and Yoram
Singer. 1998. An efficient boosting algorithm
for combining preferences. In Proceedings of the
15th International Conference on Machine Learn-
ing, Madison, WI.
Deirdre Hogan. 2007. Coordinate noun phrase disam-
biguation in a generative parsing model. In Proceed-
ings of the 45th Annual Meeting of the Association of
Computational Linguistics, pages 680–687, Prague,
Czech Republic.
Tilman H¨ohle. 1983. Subjektl¨ucken in Koordinatio-
nen. Universit¨at T¨ubingen.
Tilman H¨ohle. 1990. Assumptions about asymmetric
coordination in German. In Joan Mascar´o and Ma-
rina Nespor, editors, Grammar in Progress. Glow
Essays for Henk van Riemsdijk, pages 221–235.
Foris, Dordrecht.
Tilman H¨ohle. 1991. On reconstruction and coor-
dination. In Hubert Haider and Klaus Netter, ed-
itors, Representation and Derivation in the The-
ory of Grammar, volume 22 of Studies in Natural
Language and Linguistic Theory, pages 139–197.
Kluwer, Dordrecht.
Andreas Kathol. 1990. Linearization vs. phrase struc-
ture in German coordination constructions. Cogni-
tive Linguistics, 10(4):303–342.
Sandra K¨ubler. 2008. The PaGe 2008 shared task on
parsing German. In Proceedings of the ACL Work-
shop on Parsing German, pages 55–63, Columbus,
Ohio.
Sadao Kurohashi and Makoto Nagao. 1994. A syn-
tactic analysis method of long Japanese sentences
based on the detection of conjunctive structures.
Computational Linguistics, 20(4):507–534.
Frank Henrik M¨uller and Tylman Ule. 2002. Annotat-
ing topological fields and chunks–and revising POS
tags at the same time. In Proceedings of the 19th In-
ternational Conference on Computational Linguis-
tics, COLING’02, pages 695–701, Taipei, Taiwan.
Slav Petrov and Dan Klein. 2008. Parsing German
with latent variable grammars. In Proceedings of
the ACL Workshop on Parsing German, pages 33–
39, Columbus, Ohio.
Helmut Schmid. 2000. LoPar: Design and implemen-
tation. Technical report, Universit¨at Stuttgart.
Helmut Schmid. 2004. Efficient parsing of highly
ambiguous context-free grammars with bit vectors.
In Proceedings of the 20th International Confer-
ence on Computational Linguistics (COLING 2004),
Geneva, Switzerland.
Heike Telljohann, Erhard Hinrichs, and Sandra K¨ubler.
2004. The T¨uBa-D/Z treebank: Annotating German
with a context-free backbone. In Proceedings of the
Fourth International Conference on Language Re-
sources and Evaluation (LREC 2004), pages 2229–
2235, Lisbon, Portugal.
Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler,
and Heike Zinsmeister, 2005. Stylebook for the
T¨ubingen Treebank of Written German (T¨uBa-
D/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at
T¨ubingen, T¨ubingen, Germany.
Dieter Wunderlich. 1988. Some problems of coor-
dination in German. In Uwe Reyle and Christian
Rohrer, editors, Natural Language Parsing and Lin-
guistic Theories, Studies in Linguistics and Philoso-
phy, pages 289–316. Reidel, Dordrecht.
</reference>
<page confidence="0.99812">
414
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.377574">
<title confidence="0.999978">Parsing Coordinations</title>
<author confidence="0.99996">Sandra K¨ubler</author>
<affiliation confidence="1">Indiana University</affiliation>
<email confidence="0.999057">skuebler@indiana.edu</email>
<author confidence="0.782968">Wolfgang Maier Unversit¨at T¨ubingen</author>
<email confidence="0.955015">wo.maier@uni-tuebingen.de</email>
<author confidence="0.998698">Erhard Hinrichs</author>
<affiliation confidence="0.859709">Universit¨at T¨ubingen</affiliation>
<email confidence="0.906636">eh@sfs.uni-tuebingen.de</email>
<author confidence="0.999086">Eva Klett</author>
<affiliation confidence="0.937315">Universit¨at T¨ubingen</affiliation>
<email confidence="0.986029">eklett@sfs.uni-tuebingen.de</email>
<abstract confidence="0.994013285714286">The present paper is concerned with statistical parsing of constituent structures in German. The paper presents four experiments that aim at improving parsing performance of coordinate structure: 1) the parses of a PCFG parser, 2) enriching the input to a PCFG parser by gold scopes for any conjunct, 3) reranking the parser output for all possible scopes for conjuncts that are permissible with regard to clause structure. Experiment 4 reranks a combination of parses from experiments 1 and 3. experiments presented show that best parsing combined with reranking improves results by a large margin. Providing the parser with different scope possibilities and reranking the resulting parses results in an increase in F-score from 69.76 for the baseline to 74.69. While the F-score is similar to the one of the first exparsing and reranking), the first experiment results in higher recall (75.48% vs. 73.69%) and the third one in higher precision (75.43% vs. 73.26%). Combining the two methods results in the best result with an F-score of 76.69.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rajeev Agarwal</author>
<author>Lois Boggess</author>
</authors>
<title>A simple but useful approach to conjunct identification.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92),</booktitle>
<pages>15--21</pages>
<location>Newark, DE.</location>
<marker>Agarwal, Boggess, 1992</marker>
<rawString>Rajeev Agarwal and Lois Boggess. 1992. A simple but useful approach to conjunct identification. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92), pages 15–21, Newark, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Chantree</author>
<author>Adam Kilgarriff</author>
<author>Anne de Roeck</author>
<author>Alistair Willis</author>
</authors>
<title>Disambiguating coordinations using word distribution information.</title>
<date>2005</date>
<booktitle>In Proceedings of Recent Advances in NLP (RANLP</booktitle>
<pages>144--151</pages>
<location>Borovets, Bulgaria.</location>
<marker>Chantree, Kilgarriff, de Roeck, Willis, 2005</marker>
<rawString>Francis Chantree, Adam Kilgarriff, Anne de Roeck, and Alistair Willis. 2005. Disambiguating coordinations using word distribution information. In Proceedings of Recent Advances in NLP (RANLP 2005), pages 144–151, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and MaxEnt discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>173--180</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="27619" citStr="Charniak and Johnson (2005)" startWordPosition="4510" endWordPosition="4514"> many other authors, reports in the error analysis of his WSJ parsing results that coordination is one of the most frequent cases of incorrect parses, particularly if the conjuncts involved are complex. He manages to reduce errors for simple cases of NP coordination by introducing a special phrasal category of base NPs. In the experiments presented above, no explicit distinction is made between simple and complex cases of coordination, and no transformations are performed on the treebank annotations used for training. Our experiment 1, reranking 50-best parses, is similar to the approaches of Charniak and Johnson (2005) and of Hogan (2007). However, it differs from their experiments in two crucial ways: 1) Compared to Charniak and Johnson, who use 1.1 mio. features, our feature set is appr. five times larger (more than 5 mio. features), with the same threshold of at least five occurrences in the training set. 2) Both Hogan and Charniak and Johnson use special features for coordinate structures, such as a Boolean feature for marking parallelism (Charniak and Johnson) or for distinguishing between coordination of base NPs and coordination of complex conjuncts (Hogan), while our approach refrains from such spec</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and MaxEnt discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 173–180, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="8762" citStr="Collins and Koo (2005)" startWordPosition="1405" endWordPosition="1408">woods went a hunter and einen a schoss shot (4) Damit So hat has sich itself der the aber noch however still doppelt double wie as 1996. 1996. 407 Figure 1: A tree with coordination. methods should not be able to improve the results of these parsers further. Since we are interested in parsing coordinations, all experiments are conducted with gold POS tags, so as to abstract away from POS tagging errors. Although the treebank contains morphological information, this type of information is not used in the experiments presented here. The reranking experiments were conducted using the reranker by Collins and Koo (2005). This reranker uses a set of candidate parses for a sentence and reranks them based on a set of features that are extracted from the trees. The reranker uses a boosting method based on the approach by Freund et al. (1998). We used a similar feature set to the one Collins and Koo used; the following types of features were included: rules, bigrams, grandparent rules, grandparent bigrams, lexical bigrams, two-level rules, two-level bigrams, trigrams, head-modifiers, PPs, and distance for headmodifier relations, as well as all feature types involving rules extended by closed class lexicalization.</context>
<context position="13411" citStr="Collins and Koo (2005)" startWordPosition="2155" endWordPosition="2158">st 10 parses. Additionally, only in 4 cases were the correct analyses among the 40-best to 50-best parses, an indication that increasing n may not result in improving the results significantly. These findings resulted in the decision not to conduct experiments with higher n. That the 50 best analyses contain valuable information can be seen from an evaluation in which an oracle chooses from the 50 parses. In this case, we reach an F-score of 80.28. However, this F-score is also the upper limit for improvement that can be achieved by reranking the 50-best parses. For reranking, the features of Collins and Koo (2005) were extended in the following way: Since the German treebank used for our experiments includes grammatical function information on almost all levels in the tree, all feature types were also included with grammatical functions attached: All nodes except the root node of the subtree in question were annotated with their grammatical information. Thus, for the noun phrase (NX) rule with grandparent prepositional phrase (PX) PXGP NX —*ART ADJX NN, we add an additional rule PXGP NX-HD —* ART ADJX NN-HD. After pruning all features that occurred in the training data with a frequency lower than 5, th</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 31(1):25–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="26985" citStr="Collins (1999)" startWordPosition="4409" endWordPosition="4410">es recall, from 73.96% to 77.23%. We can conclude that adding the 50 best parses remedies the lacking coverage that was the problem of experiment 3. More generally, experiment 4 suggests that for the notoriously difficult problem of parsing coordination structures, a hybrid approach that combines parse selection of n best analyses with pre-bracketed scope in the input results in a considerable reduction in error rate compared to each of these methods used in isolation. 8 Related Work Parsing of coordinate structures for English has received considerable attention in computational linguistics. Collins (1999), among many other authors, reports in the error analysis of his WSJ parsing results that coordination is one of the most frequent cases of incorrect parses, particularly if the conjuncts involved are complex. He manages to reduce errors for simple cases of NP coordination by introducing a special phrasal category of base NPs. In the experiments presented above, no explicit distinction is made between simple and complex cases of coordination, and no transformations are performed on the treebank annotations used for training. Our experiment 1, reranking 50-best parses, is similar to the approac</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Frank</author>
</authors>
<title>A (discourse) functional analysis of asymmetric coordination.</title>
<date>2002</date>
<booktitle>In Proceedings of the LFG-02 Conference,</booktitle>
<location>Athens, Greece.</location>
<marker>Frank, 2002</marker>
<rawString>Anette Frank. 2002. A (discourse) functional analysis of asymmetric coordination. In Proceedings of the LFG-02 Conference, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Ray Iyer</author>
<author>Robert Shapire</author>
<author>Yoram Singer</author>
</authors>
<title>An efficient boosting algorithm for combining preferences.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th International Conference on Machine Learning,</booktitle>
<location>Madison, WI.</location>
<contexts>
<context position="8984" citStr="Freund et al. (1998)" startWordPosition="1447" endWordPosition="1451"> results of these parsers further. Since we are interested in parsing coordinations, all experiments are conducted with gold POS tags, so as to abstract away from POS tagging errors. Although the treebank contains morphological information, this type of information is not used in the experiments presented here. The reranking experiments were conducted using the reranker by Collins and Koo (2005). This reranker uses a set of candidate parses for a sentence and reranks them based on a set of features that are extracted from the trees. The reranker uses a boosting method based on the approach by Freund et al. (1998). We used a similar feature set to the one Collins and Koo used; the following types of features were included: rules, bigrams, grandparent rules, grandparent bigrams, lexical bigrams, two-level rules, two-level bigrams, trigrams, head-modifiers, PPs, and distance for headmodifier relations, as well as all feature types involving rules extended by closed class lexicalization. For a more detailed description of the rules, the interested reader is referred to Collins and Koo (2005). For coordination, these features give a wider context than the original parser has and should thus result in impro</context>
</contexts>
<marker>Freund, Iyer, Shapire, Singer, 1998</marker>
<rawString>Yoav Freund, Ray Iyer, Robert Shapire, and Yoram Singer. 1998. An efficient boosting algorithm for combining preferences. In Proceedings of the 15th International Conference on Machine Learning, Madison, WI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deirdre Hogan</author>
</authors>
<title>Coordinate noun phrase disambiguation in a generative parsing model.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>680--687</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="27639" citStr="Hogan (2007)" startWordPosition="4517" endWordPosition="4518"> error analysis of his WSJ parsing results that coordination is one of the most frequent cases of incorrect parses, particularly if the conjuncts involved are complex. He manages to reduce errors for simple cases of NP coordination by introducing a special phrasal category of base NPs. In the experiments presented above, no explicit distinction is made between simple and complex cases of coordination, and no transformations are performed on the treebank annotations used for training. Our experiment 1, reranking 50-best parses, is similar to the approaches of Charniak and Johnson (2005) and of Hogan (2007). However, it differs from their experiments in two crucial ways: 1) Compared to Charniak and Johnson, who use 1.1 mio. features, our feature set is appr. five times larger (more than 5 mio. features), with the same threshold of at least five occurrences in the training set. 2) Both Hogan and Charniak and Johnson use special features for coordinate structures, such as a Boolean feature for marking parallelism (Charniak and Johnson) or for distinguishing between coordination of base NPs and coordination of complex conjuncts (Hogan), while our approach refrains from such special-purpose features</context>
<context position="29339" citStr="Hogan (2007)" startWordPosition="4789" endWordPosition="4790">h of these approaches are limited to coordinate structures with two conjuncts only, while our approach has no such limitation. Moreover, the goal of Agarwal and Bogges is quite different from ours. Their goal is robust detection of coordinate structures only (with the intended ap412 plication of term extraction), while our goal is to improve the performance of a parser that assigns a complete sentence structure to an input sentence. Finally, our approach at present is restricted to purely syntactic structural properties. This is in contrast to approaches that incorporate semantic information. Hogan (2007) uses bi-lexical headhead co-occurrences in order to identify nominal heads of conjuncts more reliably than by syntactic information alone. Chantree et al. (2005) resolve attachment ambiguities in coordinate structures, as in (7a) and (7b), by using word frequency information obtained from generic corpora as an effective estimate of the semantic compatibility of a modifier vis-`a-vis the candidate heads. (7) a. Project managers and designers b. Old shoes and boots We view the work by Hogan and by Chantree et al. as largely complementary to, but at the same time as quite compatible with our app</context>
</contexts>
<marker>Hogan, 2007</marker>
<rawString>Deirdre Hogan. 2007. Coordinate noun phrase disambiguation in a generative parsing model. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 680–687, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman H¨ohle</author>
</authors>
<date>1983</date>
<institution>Koordinationen. Universit¨at T¨ubingen.</institution>
<note>Subjektl¨ucken in</note>
<marker>H¨ohle, 1983</marker>
<rawString>Tilman H¨ohle. 1983. Subjektl¨ucken in Koordinationen. Universit¨at T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman H¨ohle</author>
</authors>
<title>Assumptions about asymmetric coordination in German.</title>
<date>1990</date>
<booktitle>In Joan Mascar´o and Marina Nespor, editors, Grammar in Progress. Glow Essays for Henk van Riemsdijk,</booktitle>
<pages>221--235</pages>
<location>Foris, Dordrecht.</location>
<marker>H¨ohle, 1990</marker>
<rawString>Tilman H¨ohle. 1990. Assumptions about asymmetric coordination in German. In Joan Mascar´o and Marina Nespor, editors, Grammar in Progress. Glow Essays for Henk van Riemsdijk, pages 221–235. Foris, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman H¨ohle</author>
</authors>
<title>On reconstruction and coordination.</title>
<date>1991</date>
<booktitle>Representation and Derivation in the Theory of Grammar,</booktitle>
<volume>22</volume>
<pages>139--197</pages>
<editor>In Hubert Haider and Klaus Netter, editors,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<marker>H¨ohle, 1991</marker>
<rawString>Tilman H¨ohle. 1991. On reconstruction and coordination. In Hubert Haider and Klaus Netter, editors, Representation and Derivation in the Theory of Grammar, volume 22 of Studies in Natural Language and Linguistic Theory, pages 139–197. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Kathol</author>
</authors>
<title>Linearization vs. phrase structure in German coordination constructions.</title>
<date>1990</date>
<journal>Cognitive Linguistics,</journal>
<volume>10</volume>
<issue>4</issue>
<marker>Kathol, 1990</marker>
<rawString>Andreas Kathol. 1990. Linearization vs. phrase structure in German coordination constructions. Cognitive Linguistics, 10(4):303–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
</authors>
<title>The PaGe</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Workshop on Parsing German,</booktitle>
<pages>55--63</pages>
<location>Columbus, Ohio.</location>
<marker>K¨ubler, 2008</marker>
<rawString>Sandra K¨ubler. 2008. The PaGe 2008 shared task on parsing German. In Proceedings of the ACL Workshop on Parsing German, pages 55–63, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="28340" citStr="Kurohashi and Nagao (1994)" startWordPosition="4625" endWordPosition="4629">ed to Charniak and Johnson, who use 1.1 mio. features, our feature set is appr. five times larger (more than 5 mio. features), with the same threshold of at least five occurrences in the training set. 2) Both Hogan and Charniak and Johnson use special features for coordinate structures, such as a Boolean feature for marking parallelism (Charniak and Johnson) or for distinguishing between coordination of base NPs and coordination of complex conjuncts (Hogan), while our approach refrains from such special-purpose features. Our experiments using scope information are similar to the approaches of Kurohashi and Nagao (1994) and Agarwal and Bogges (1992) in that they try to identify coordinate structure bracketings. However, the techniques used by Agarwal and Bogges and in the present paper are quite different. Agarwal and Bogges and Kurohashi and Nagao rely on shallow parsing techniques to detect parallelism of conjuncts while we use a partial parser only for suggesting possible scopes of conjuncts. Both of these approaches are limited to coordinate structures with two conjuncts only, while our approach has no such limitation. Moreover, the goal of Agarwal and Bogges is quite different from ours. Their goal is r</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures. Computational Linguistics, 20(4):507–534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Henrik M¨uller</author>
<author>Tylman Ule</author>
</authors>
<title>Annotating topological fields and chunks–and revising POS tags at the same time.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics, COLING’02,</booktitle>
<pages>695--701</pages>
<location>Taipei, Taiwan.</location>
<marker>M¨uller, Ule, 2002</marker>
<rawString>Frank Henrik M¨uller and Tylman Ule. 2002. Annotating topological fields and chunks–and revising POS tags at the same time. In Proceedings of the 19th International Conference on Computational Linguistics, COLING’02, pages 695–701, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Parsing German with latent variable grammars.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Workshop on Parsing German,</booktitle>
<pages>33--39</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="7650" citStr="Petrov and Klein, 2008" startWordPosition="1212" endWordPosition="1215">). BitPar is an efficient implementation of an Earley style parser that uses bit vectors. However, BitPar cannot handle pre-bracketed input. For this reason, we used LoPar for the experiments where such input was required. LoPar, as it is used here, is a pure PCFG parser, which allows the input to be partially bracketed. We are aware that the results that can be obtained by pure PCFG parsers are not state of the art as reported in the shared task of the ACL 2008 Workshop on Parsing German (K¨ubler, 2008). While BitPar reaches an F-score of 69.76 (see next section), the best performing parser (Petrov and Klein, 2008) reaches an Fscore of 83.97 on T¨uBa-D/Z (but with a different split of training and test data). However, our experiments require certain features in the parsers, namely the capability to provide n-best analyses and to parse pre-bracketed input. To our knowledge, the parsers that took part in the shared task do not provide these features. Should they become available, the methods presented here could be applied to such parsers. We see no reason why our den Wald ging ein J¨ager und the woods went a hunter and einen a schoss shot (4) Damit So hat has sich itself der the aber noch however still d</context>
</contexts>
<marker>Petrov, Klein, 2008</marker>
<rawString>Slav Petrov and Dan Klein. 2008. Parsing German with latent variable grammars. In Proceedings of the ACL Workshop on Parsing German, pages 33– 39, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>LoPar: Design and implementation.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>Universit¨at Stuttgart.</institution>
<contexts>
<context position="7028" citStr="Schmid, 2000" startWordPosition="1104" endWordPosition="1105">v¨olkerungsdecline in r¨uckgang zwar abgeschw¨acht, ist population though lessened, is so groß so big ’For this reason, although the decline in population has lessened, it is still twice as big as in 1996.’ The syntactic annotation scheme of the T¨uBaD/Z is described in more detail in Telljohann et al. (2004; 2005). All experiments reported here are based on a data split of 90% training data and 10% test data. 3.2 The Parsers and the Reranker Two parsers were used to investigate the influence of scope information on parser performance on coordinate structures: BitPar (Schmid, 2004) and LoPar (Schmid, 2000). BitPar is an efficient implementation of an Earley style parser that uses bit vectors. However, BitPar cannot handle pre-bracketed input. For this reason, we used LoPar for the experiments where such input was required. LoPar, as it is used here, is a pure PCFG parser, which allows the input to be partially bracketed. We are aware that the results that can be obtained by pure PCFG parsers are not state of the art as reported in the shared task of the ACL 2008 Workshop on Parsing German (K¨ubler, 2008). While BitPar reaches an F-score of 69.76 (see next section), the best performing parser (P</context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Helmut Schmid. 2000. LoPar: Design and implementation. Technical report, Universit¨at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="7003" citStr="Schmid, 2004" startWordPosition="1100" endWordPosition="1101">in the first conjunct. Bev¨olkerungsdecline in r¨uckgang zwar abgeschw¨acht, ist population though lessened, is so groß so big ’For this reason, although the decline in population has lessened, it is still twice as big as in 1996.’ The syntactic annotation scheme of the T¨uBaD/Z is described in more detail in Telljohann et al. (2004; 2005). All experiments reported here are based on a data split of 90% training data and 10% test data. 3.2 The Parsers and the Reranker Two parsers were used to investigate the influence of scope information on parser performance on coordinate structures: BitPar (Schmid, 2004) and LoPar (Schmid, 2000). BitPar is an efficient implementation of an Earley style parser that uses bit vectors. However, BitPar cannot handle pre-bracketed input. For this reason, we used LoPar for the experiments where such input was required. LoPar, as it is used here, is a pure PCFG parser, which allows the input to be partially bracketed. We are aware that the results that can be obtained by pure PCFG parsers are not state of the art as reported in the shared task of the ACL 2008 Workshop on Parsing German (K¨ubler, 2008). While BitPar reaches an F-score of 69.76 (see next section), the </context>
<context position="12374" citStr="Schmid, 2004" startWordPosition="1973" endWordPosition="1974">onted constituent, Damit hat sich der Bev¨olkerungsr¨uckgang zwar abgeschw¨acht, is treated as a fronted subordinate clause. 4 Experiment 1: n-Best Parsing and Reranking The first hypothesis for improving coordination parsing is based on the assumption that the correct parse may not be the most probable one in Viterbi parsing but may be recovered by n-best parsing and reranking, a technique that has become standard in the last few years. If this hypothesis holds, we should find the correct parse among the n-best parses. In order to test this hypothesis, we conducted an experiment with BitPar (Schmid, 2004). We parsed the test sentences in a 50-best setting. A closer look at the 50-best parses shows that of the 2611 sentences, 195 (7.5%) were assigned the correct parse as the best parse. For 325 more sentences (12.4%), the correct parse could be found under the 50 best analyses. What is more, in 90.2% of these 520 sentences, for which the correct parse was among the 50 best parses, the best parse was among the first 10 parses. Additionally, only in 4 cases were the correct analyses among the 40-best to 50-best parses, an indication that increasing n may not result in improving the results signif</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Helmut Schmid. 2004. Efficient parsing of highly ambiguous context-free grammars with bit vectors. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard Hinrichs</author>
<author>Sandra K¨ubler</author>
</authors>
<title>The T¨uBa-D/Z treebank: Annotating German with a context-free backbone.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<pages>2229--2235</pages>
<location>Lisbon, Portugal.</location>
<marker>Telljohann, Hinrichs, K¨ubler, 2004</marker>
<rawString>Heike Telljohann, Erhard Hinrichs, and Sandra K¨ubler. 2004. The T¨uBa-D/Z treebank: Annotating German with a context-free backbone. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), pages 2229– 2235, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard W Hinrichs</author>
<author>Sandra K¨ubler</author>
<author>Heike Zinsmeister</author>
</authors>
<title>Stylebook for the T¨ubingen Treebank of Written German (T¨uBaD/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen,</title>
<date>2005</date>
<location>T¨ubingen, Germany.</location>
<marker>Telljohann, Hinrichs, K¨ubler, Zinsmeister, 2005</marker>
<rawString>Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler, and Heike Zinsmeister, 2005. Stylebook for the T¨ubingen Treebank of Written German (T¨uBaD/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen, T¨ubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dieter Wunderlich</author>
</authors>
<title>Some problems of coordination in German.</title>
<date>1988</date>
<booktitle>In Uwe Reyle</booktitle>
<pages>289--316</pages>
<editor>and Christian Rohrer, editors,</editor>
<location>Reidel, Dordrecht.</location>
<marker>Wunderlich, 1988</marker>
<rawString>Dieter Wunderlich. 1988. Some problems of coordination in German. In Uwe Reyle and Christian Rohrer, editors, Natural Language Parsing and Linguistic Theories, Studies in Linguistics and Philosophy, pages 289–316. Reidel, Dordrecht.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>