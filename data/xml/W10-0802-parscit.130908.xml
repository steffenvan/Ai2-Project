<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000058">
<title confidence="0.990088">
Towards an Inventory of English Verb Argument Constructions
</title>
<author confidence="0.998123">
Matthew Brook O’Donnell Nick Ellis
</author>
<affiliation confidence="0.99987">
University of Michigan University of Michigan
</affiliation>
<address confidence="0.8874625">
500 E. Washington St. 500 E. Washington St.
Ann Arbor, MI 48104, USA Ann Arbor, MI 48104, USA
</address>
<email confidence="0.999294">
mbod@umich.edu ncellis@umich.edu
</email>
<sectionHeader confidence="0.993916" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999370777777778">
This paper outlines and pilots our approach to-
wards developing an inventory of verb-argument
constructions based upon English form, function,
and usage. We search a tagged and dependency-
parsed BNC (a 100-million word corpus of Eng-
lish) for Verb-Argument Constructions (VACs) in-
cluding those previously identified in the pattern
grammar resulting from the COBUILD project.
This generates (1) a list of verb types that occupy
each construction. We next tally the frequency pro-
files of these verbs to produce (2) a frequency
ranked type-token distribution for these verbs, and
we determine the degree to which this is Zipfian.
Since some verbs are faithful to one construction
while others are more promiscuous, we next pro-
duce (3) a contingency-weighted list reflecting
their statistical association. To test whether each of
these measures is a step towards increasing the
learnability of VACs as categories, following prin-
ciples of associative learning, we examine 20 verbs
from each distribution. Here we explore whether
there is an increase in the semantic cohesion of the
verbs occupying each construction using semantic
similarity measures. From inspection, this seems to
be so. We are developing measures of this using
network measures of clustering in the verb-space
defined by WordNet and Roget’s Thesaurus.
</bodyText>
<subsectionHeader confidence="0.495524">
1 Construction grammar and Usage
</subsectionHeader>
<bodyText confidence="0.999964849056604">
Constructions are form-meaning mappings,
conventionalized in the speech community, and
entrenched as language knowledge in the learner’s
mind. They are the symbolic units of language re-
lating the defining properties of their morphologi-
cal, lexical, and syntactic form with particular se-
mantic, pragmatic, and discourse functions
(Goldberg, 2006). Construction Grammar argues
that all grammatical phenomena can be understood
as learned pairings of form (from morphemes,
words, idioms, to partially lexically filled and fully
general phrasal patterns) and their associated se-
mantic or discourse functions: “the network of
constructions captures our grammatical knowledge
in toto, i.e. It’s constructions all the way down”
(Goldberg, 2006, p. 18). Such beliefs, increasingly
influential in the study of child language acquisi-
tion, have turned upside down generative assump-
tions of innate language acquisition devices, the
continuity hypothesis, and top-down, rule-
governed, processing, bringing back data-driven,
emergent accounts of linguistic systematicities.
Frequency, learning, and language come to-
gether in usage-based approaches which hold that
we learn linguistic constructions while engaging in
communication. The last 50 years of psycholin-
guistic research provides the evidence of usage-
based acquisition in its demonstrations that lan-
guage processing is exquisitely sensitive to usage
frequency at all levels of language representation
from phonology, through lexis and syntax, to sen-
tence processing (Ellis, 2002). Language knowl-
edge involves statistical knowledge, so humans
learn more easily and process more fluently high
frequency forms and ‘regular’ patterns which are
exemplified by many types and which have few
competitors. Psycholinguistic perspectives thus
hold that language learning is the associative learn-
ing of representations that reflect the probabilities
of occurrence of form-function mappings. Fre-
quency is a key determinant of acquisition because
‘rules’ of language, at all levels of analysis from
phonology, through syntax, to discourse, are struc-
tural regularities which emerge from learners’ life-
time unconscious analysis of the distributional
characteristics of the language input.
If constructions as form-function mappings are
the units of language, then language acquisition
involves inducing these associations from experi-
ence of language usage. Constructionist accounts
of language acquisition thus involve the distribu-
tional analysis of the language stream and the par-
allel analysis of contingent perceptuo-motor activ-
</bodyText>
<page confidence="0.97067">
9
</page>
<note confidence="0.966259">
Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 9–16,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999497625">
ity, with abstract constructions being learned as
categories from the conspiracy of concrete exem-
plars of usage following statistical learning mecha-
nisms (Bod, Hay, &amp; Jannedy, 2003; Bybee &amp;
Hopper, 2001; Ellis, 2002) relating input and
learner cognition. Psychological analyses of the
learning of constructions as form-meaning pairs is
informed by the literature on the associative learn-
ing of cue-outcome contingencies where the usual
determinants include: (1) input frequency (type-
token frequency, Zipfian distribution, recency), (2)
form (salience and perception), (3) function (proto-
typicality of meaning, importance of form for mes-
sage comprehension, redundancy), and (4) interac-
tions between these (contingency of form-function
mapping) (Ellis &amp; Cadierno, 2009).
</bodyText>
<sectionHeader confidence="0.785716" genericHeader="keywords">
2 Determinants of construction learning
</sectionHeader>
<bodyText confidence="0.999779121951219">
In natural language, Zipf’s law (Zipf, 1935) de-
scribes how a handful of the highest frequency
words account for the most linguistic tokens.
Zipf’s law states that the frequency of words de-
creases as a power function of their rank in the fre-
quency table. If pf is the proportion of words whose
frequency rank in a given language sample is f,
then pf ~ f -b, with b ≈ 1. Zipf showed this scaling
relation holds across a wide variety of language
samples. Subsequent research provides support for
this law as a linguistic universal: many language
events (e.g., frequencies of phoneme and letter
strings, of words, of grammatical constructs, of
formulaic phrases, etc.) across scales of analysis
follow this law (Sole, Murtra, Valverde, &amp; Steels,
2005).
Goldberg, Casenhiser &amp; Sethuraman (2004)
demonstrated that in samples of child language
acquisition, for a variety of verb-argument con-
structions (VACs), there is a strong tendency for
one single verb to occur with very high frequency
in comparison to other verbs used, a profile which
closely mirrors that of the mothers’ speech to these
children. Goldberg et al. (2004) show that Zipf’s
law applies within VACs too, and they argue that
this promotes acquisition: tokens of one particular
verb account for the lion’s share of instances of
each particular argument frame; this pathbreaking
verb also is the one with the prototypical meaning
from which the construction is derived (see also
Ninio, 1999).
Ellis and Ferreira-Junior (2009) investigate ef-
fects upon naturalistic second language acquisition
of type/token distributions in three English verb-
argument constructions. They show that VAC verb
type/token distribution in the input is Zipfian and
that learners first acquire the most frequent, proto-
typical and generic exemplar. (e.g. put in VOL
[verb-object-locative], give in VOO [verb-object-
object], etc.). Acquisition is affected by the fre-
quency distribution of exemplars within each is-
land of the construction, by their prototypicality,
and, using a variety of psychological (Shanks,
1995) and corpus linguistic association metrics
(Gries &amp; Stefanowitsch, 2004), by their contin-
gency of form-function mapping. This fundamental
claim that Zipfian distributional properties of lan-
guage usage helps to make language learnable has
thus begun to be explored for these three VACs, at
least. It remains an important research agenda to
explore its generality across a wide range of con-
structions (i.e. the constructicon).
The primary motivation of construction gram-
mar is that we must bring together linguistic form,
learner cognition, and usage. An important conse-
quence is that constructions cannot be defined
purely on the basis of linguistic form, or semantics,
or frequency of usage alone. All three factors are
necessary in their operationalization and measure-
ment. Our research aims to do this. We hope to
describe the verbal grammar of English, to analyze
the way VACs map form and meaning, and to pro-
vide an inventory of the verbs that exemplify con-
structions and their frequency. This last step is
necessary because the type-token frequency distri-
bution of their verbs determines VAC acquisition
as abstract schematic constructions, and because
usage frequency determines their entrenchment
and processing.
This paper describes and pilots our approach.
We focus on just two constructions for illustration
here (V across n, and V Obj Obj) although our
procedures are principled, generic and applicable
to all VACs. We search a tagged and dependency-
parsed British National Corpus (a 100-million
word corpus of English) for VACs including those
previously identified in the COBUILD pattern
grammar project. This generates (1) a list of verb
types that occupy each construction. We next tally
the frequency profiles of these verbs to produce (2)
a frequency ranked type-token distribution for
these verbs, and we determine the degree to which
</bodyText>
<page confidence="0.992619">
10
</page>
<bodyText confidence="0.9962745">
this is Zipfian. Since some verbs are faithful to one
construction while others are more promiscuous,
we next produce (3) a contingency-weighted list
which reflects their statistical association.
</bodyText>
<sectionHeader confidence="0.975047" genericHeader="introduction">
3 Method
</sectionHeader>
<bodyText confidence="0.999963846153846">
As a starting point, we considered several of the
major theories and datasets of construction gram-
mar such as FrameNet (Fillmore, Johnson, &amp;
Petruck, 2003). However, because our research
aims to empirically determine the semantic asso-
ciations of particular linguistic forms, it is impor-
tant that such forms are initially defined by bot-
tom-up means that are semantics-free. There is no
one in corpus linguistics who ‘trusts the text’ more
than Sinclair (2004). Therefore we chose the Pat-
tern Grammar (Francis et al. 1996) definition of
Verb constructions that arose out of his Cobuild
project.
</bodyText>
<subsectionHeader confidence="0.9942705">
3.1 Construction inventory: COBUILD Verb
Patterns
</subsectionHeader>
<bodyText confidence="0.998417404761905">
The form-based patterns described in the CO-
BUILD Verb Patterns volume (Francis et al. 1996)
take the form of word class and lexis combina-
tions, such as V across n, V into n and V n n. For
each of these patterns the resource provides infor-
mation as to the structural configurations and func-
tional/meaning groups found around these patterns
through detailed concordance analysis of the Bank
of English corpus during the construction of the
COBUILD dictionary. For instance, the following
is provided for the V across n pattern (Francis, et
al., 1996, p. 150):
The verb is followed by a prepositional phrase
which consists of across and a noun group.
This pattern has one structure:
* Verb with Adjunct.
I cut across the field.
Further example sentences are provided drawn
from the corpus and a list of verbs found in the
pattern and that are semantically typical are given.
For this pattern these are: brush, cut, fall, flicker,
flit plane, skim, sweep. No indication is given as to
how frequent each of these types are or how com-
prehensive the list is. Further structural (syntacti-
cal) characteristics of the pattern are sometimes
provided, such as the fact that for V across n the
prepositional phrase is an adjunct and that the verb
is never passive.
For some construction patterns with a gener-
ally fixed order it may be sufficient just to specify
combinations of word and part-of-speech se-
quences. For example, a main verb followed by
across within 1 to 3 words (to allow for adverbial
elements), followed by a noun or pronoun within a
few words. To such constraints a number excep-
tions of what should not occur within the specified
spans must be added. The variation and potential
complexity of English noun phrases presents chal-
lenges for this approach. On the other hand a
multi-level constituent parse tree provides more
than needed. A dependency parse with word-to-
word relations is well suited for the task.
</bodyText>
<subsectionHeader confidence="0.995507">
3.2 Corpus: BNC XML Parsed
</subsectionHeader>
<bodyText confidence="0.999417">
The analysis of verb type-token distribution in the
kinds of construction patterns described in the pre-
vious section should ideally be carried out using a
range of corpora in the magnitude of the tens or
hundreds of millions of words as the original work
is derived from the Bank of English (a growing
monitor corpus of over 400 million words). These
corpora should, at the least, be part-of-speech
tagged to search for the pattern as specified. Fur-
ther some kind of partial parsing and chunking is
necessary to apply the structural constraints (see
Mason &amp; Hunston, 2004 for exploratory
methodology). We chose to use the 100 million
word British National Corpus (BNC) on account of
its size, the breadth of genres it contains and con-
sistent lemmatization and part-of-speech tagging.
Andersen et al. (2008) parsed the XML version of
the BNC using the RASP parser (Briscoe, Carroll,
&amp; Watson, 2006). RASP is a statistical feature-
based parser that produces a probabilistically or-
dered set of parse trees for a given sentence and
additionally a set of grammatical relations (GRs)
that capture “those aspects of predicate-argument
structure that the system is able to recover and is
the most stable and grammar independent repre-
sentation available” (Briscoe, et al., 2006, p. 79).
The GRs are organized into a hierarchy of depend-
ency relations, including distinctions between
modifiers and arguments and within arguments
between subject (sub) and complements (comp).
Figure 1 shows the GRs assigned by RASP for the
</bodyText>
<page confidence="0.996265">
11
</page>
<bodyText confidence="0.8198065">
sentence: The kitchen light skids across the lawn
(BNC A0U). The main verb skids has two argu-
ments, a subject (ncsubj) and indirect object (iobj),
and the preposition one argument (dobj).
</bodyText>
<figureCaption confidence="0.999322">
Figure 1. Example of RASP GRs
</figureCaption>
<bodyText confidence="0.992607666666667">
The RASP GR hierarchy does not include catego-
ries such as prepositional complement or adjunct.
Figure 2 shows the GRs for another sentence con-
taining across which is not an example of the V
across n pattern. Alternate analyses might attach
across directly to the main verb threw, but at least
from examining BNC examples containing across,
it appears RASP tends to favor local attachments
(also for towards in this case).
</bodyText>
<figureCaption confidence="0.999419">
Figure 2. Example of RASP GRs
</figureCaption>
<bodyText confidence="0.999974">
The GRs from RASP have been incorporated into
the XML for each BNC sentence thereby preserv-
ing the token, part-of-speech and lemma informa-
tion in the corpus.
</bodyText>
<subsectionHeader confidence="0.974197">
3.3 Searching construction patterns
</subsectionHeader>
<bodyText confidence="0.756867">
Our search algorithm works as follows:
1. Process each sentence in turn testing
against an XPath expression to identify
components in construction patterns, e.g.
</bodyText>
<equation confidence="0.5984205">
.//w[@lem=&amp;quot;across&amp;quot;][@pos=&amp;quot;PREP&amp;quot;]/
preceding-sibling::w[position()&lt;3]
</equation>
<bodyText confidence="0.8943295">
[@pos=&amp;quot;VERB&amp;quot;][1] finds a verb followed by
across within 2 words.
2. Create a list of the grammatical relations
where this verb functions as the head.
</bodyText>
<listItem confidence="0.838294333333333">
i. This finds the ncsubj and iobj rela-
tions for the example sentence.
ii. Also find GRs involving other components
of pattern (e.g. across).
3. Check these GRs against a constraint list,
e.g. make sure that
</listItem>
<bodyText confidence="0.905486333333333">
i. only one relation where the dependent
word comes after the verb (excluding
verbs with both dobj and iobj or obj2)
</bodyText>
<listItem confidence="0.5725414">
ii. the dependent of the second component
matches a specific part-of-speech (e.g.
across as head and noun as dependent).
4. For matching sentences record verb
lemma.
</listItem>
<bodyText confidence="0.999445454545455">
Here we report on just two construction patterns: 1.
V across n and 2. V n n or V Obj Obj (where n
includes both nouns and pronouns). We have also
run a range of similar V Prep n patterns from CO-
BUILD, such as V into n, V after n, V as n. We
have still to carry out a systematic precision-recall
analysis, but ad hoc examination suggests that the
strict constraints using the dependency relations
provides a reasonable precision and the size of the
corpus results in a large enough number of tokens
to carry out distributional analysis (see Table 1).
</bodyText>
<tableCaption confidence="0.991996">
Table 1. Type-Token data for V across n and V Obj Obj
constructions
</tableCaption>
<subsectionHeader confidence="0.783677">
3.4 Identifying the meaning of verb types occu-
pying the constructions
</subsectionHeader>
<bodyText confidence="0.999984590909091">
We considered several ways of analyzing the
semantics the resulting verb distributions. It is im-
portant that the semantic measures we employ are
defined in a way that is free of linguistic distribu-
tional information, otherwise we would be building
in circularity. Therefore methods such as LSA are
not applicable here. Instead, our research utilizes
two distribution-free semantic databases: (1) Ro-
get’s thesaurus, a classic lexical resource of long-
standing proven utility, based on Roget’s guided
introspections, as implemented in the Open Ro-
get’s Project (Kennedy, 2009). This provides vari-
ous algorithms for measuring the semantic similar-
ity between terms and between sentences. (2)
WordNet, based upon psycholinguistic theory and
in development since 1985 (Miller, 2009). Word-
Net classes words into a hierarchical network. At
the top level, the hierarchy for verbs is organized
into 15 base types (such as move1 expressing trans-
lational movement and move2 movement without
displacement, communicate, etc.) which then split
into over 11,500 verb synonym sets or synsets.
</bodyText>
<figure confidence="0.980492571428571">
Construction Types Tokens
V across n
V Obj Obj 663 9183
799 4889
TTR
7.22
16.34
</figure>
<page confidence="0.989523">
12
</page>
<bodyText confidence="0.9997942">
Verbs are linked in the hierarchy according to rela-
tions such as hypernym (to move is an hypernym
of to walk), and troponym, the term used for hypo-
nymic relations in the verb component of WordNet
(to lisp is a troponym of to talk). There are various
algorithms to determine the semantic similarity
between synsets in WordNet which consider the
distance between the conceptual categories of
words, as well as considering the hierarchical
structure of the WordNet (Pedersen et al. 2004).
</bodyText>
<subsectionHeader confidence="0.9533645">
3.5 Determining the contingency between
construction form and function
</subsectionHeader>
<bodyText confidence="0.999973192307692">
Some verbs are closely tied to a particular con-
struction (for example, give is highly indicative of
the ditransitive construction, whereas leave, al-
though it can form a ditransitive, is more often as-
sociated with other constructions such as the sim-
ple transitive or intransitive). The more reliable the
contingency between a cue and an outcome, the
more readily an association between them can be
learned (Shanks, 1995), so constructions with
more faithful verb members are more transparent
and thus should be more readily acquired. Ellis and
Ferreira-Junior (2009) use ΔP and collostructional
analysis measures (Stefanowitsch &amp; Gries, 2003)
to show effects of form-function contingency upon
L2 VAC acquisition. Others use conditional prob-
abilities to investigate contingency effects in VAC
acquisition. This is still an active area of inquiry,
and more research is required before we know
which statistical measures of form-function con-
tingency are more predictive of acquisition and
processing. Meanwhile, the simplest usable meas-
ure is one of faithfulness – the proportion of tokens
of total verb usage as a whole that appear in this
particular construction. For illustration, the faith-
fulness of give to the ditransitive is approximately
0.40; that for leave is 0.01.
</bodyText>
<sectionHeader confidence="0.999989" genericHeader="method">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999166">
4.1 Evaluating the verb distribution
</subsectionHeader>
<bodyText confidence="0.996203">
For the V across n pattern the procedure outlined
in the previous section results in the following list:
</bodyText>
<footnote confidence="0.325296">
come 483
walk 203 .
cut 199 veer 4
run 175 whirl 4 ...
</footnote>
<figure confidence="0.49436025">
spread 146 slice 4 discharge 1
... clamber 4 navigate 1
. scythe 1
scroll 1
</figure>
<figureCaption confidence="0.995897">
Figure 3. Verb type distribution for V across n
</figureCaption>
<bodyText confidence="0.999171380952381">
At first glance this distribution does appear to be
Zipfian, exhibiting the characteristic long-tailed
distribution in a plot of rank against frequency.
Dorogovstev &amp; Mendes (2003, pp. 222-223) out-
line the commonly used methods for measuring
power-law distributions: 1. a simple log-log plot
(rank/frequency), 2. log-log plot of cumulative
probability against frequency and 3. the use of
logarithmic binning over the distribution for a log-
log plot as in 2. Linear regression can be applied to
the resulting plots and goodness of fit (R2) and the
slope (γ) recorded.
Figure 3 shows such a plot for verb type fre-
quency of the V across n construction pattern ex-
tracted from the parsed BNC XML corpus follow-
ing the third plotting method. Verb types are
grouped into 20 logarithmic bins according to their
frequency (x-axis) against the logarithm of the cu-
mulative probability of a verb occurring with or
above this frequency (y-axis). Each point repre-
sents one bin and a verb from each group is ran-
</bodyText>
<page confidence="0.997953">
13
</page>
<bodyText confidence="0.999691857142857">
domly selected to label the point with its token fre-
quency in parentheses. For example, the type look
occurs 102 times in the V across n pattern and is
placed into the 15th bin with the types go, lie and
lean. Points towards the lower right of the plot in-
dicate high-frequency low-type groupings and
those towards the top left low-frequency high-type
groupings, that is the fat- or long-tail of the distri-
bution. Looking at the verbs given as examples of
the pattern in COBUILD volume we find all but
plane represented in our corpus search V across n:
brush (12 tokens, group 9), cut (199 tokens, group
18), fall (57, g14), flicker (21, g10), flit (15, g9),
plane (0), skim (9, g8), sweep (34, g12).
</bodyText>
<figureCaption confidence="0.846627">
Figure 4. Verb type distribution for V Obj Obj
</figureCaption>
<bodyText confidence="0.991780533333333">
Figure 4 shows the plot for verb type frequency of
the ditransitive V Obj Obj construction pattern ex-
tracted and binned in the same way. Both distribu-
tions can be fitted with a straight regression line
(R2=0.993). Thus we conclude that the type-token
frequency distributions for these constructions are
Zipfian. (In future we will investigate the other
plot and fitting methods to ensure we have not
smoothed the data too much through binning.) In-
spection of the construction verb types, from most
frequent down, also suggests that, as in prior re-
search (Ellis &amp; Ferreira-Junior, 2009; Goldberg et
al., 2004; Ninio, 1999), the most frequent items are
prototypical of the construction and more generic
in their action semantics.
</bodyText>
<subsectionHeader confidence="0.6517885">
4.2 Evaluating the roles of frequency distribu-
tion and faithfulness in semantic cohesion
</subsectionHeader>
<bodyText confidence="0.999979727272727">
The second step in evaluating the verb distribu-
tions from the construction patterns is to compare a
small set of types selected on the basis of a flat
type distribution, the (Zipfian) token frequency
distribution and a distribution that represents the
degree to which a verb is attracted to the particular
construction. First we select the top 200 types from
the two VACs, ordered by token frequency. Then
we sample 20 verbs from this list at random. This
is the ‘types list’. Next we take the top 20 types as
the ‘tokens list’. Finally, we calculate the token-
ized faithfulness score for each type by dividing
the verb’s frequency in the construction by its
overall frequency in the whole BNC. For example,
spread occurs 146 times in the V across n pattern
and 5503 times in total. So its faithfulness is
146/5503*100 = 2.65%, i.e. 1 in 38, of the in-
stances of spread occur as spread across n. The
tokenized faithfulness score for spread is then
simply (146/5503) * 146 = 3.87, which tempers the
tendency for low frequency types such as scud,
skitter and emblazon to rise to the top of the list
and is our initial attempt to combine the effects of
token frequency and construction contingency. We
reorder the 200 types by this figure and take the
top twenty for the ‘faithfulness list’. Tables 2 and 3
contain these lists for the two constructions. An
intuitive reading of these lists suggests that the to-
kens list captures the most general and prototypical
senses (walk, move etc. for V across n and give,
make, tell, offer for V Obj Obj), while the list or-
dered by tokenized faith highlights some quite
construction specific (and low frequency) items,
such as scud, flit and flicker for V across n.
The final component is to quantify the seman-
tic coherence or ‘clumpiness’ of the verbs ex-
tracted in the previous steps. For this we use
WordNet and Roget’s. Pedersen et al. (2004) out-
line six measures in their Perl WordNet::Similarity
package, three (path, lch and wup) based on the
path length between concepts in WordNet Synsets
and three (res, jcn and lin) that incorporate a
measure called ‘information content’ related to
concept specificity. Tables 4 and 5 show the simi-
</bodyText>
<page confidence="0.997834">
14
</page>
<bodyText confidence="0.701645">
larity scores that result from taking the 20 types in
each of the lists in Tables 2 and 3 and generating a
20 by 20 distance matrix.
</bodyText>
<table confidence="0.999881285714286">
types (sample) tokens faithfulness
1 scuttle come spread
2 ride walk scud
3 paddle cut sprawl
4 communicate run cut
5 rise spread walk
6 stare move come
7 drift look stride
8 stride go lean
9 face lie flit
10 dart lean stretch
11 flee stretch run
12 skid fall scatter
13 print get skitter
14 shout pass flicker
15 use reach slant
16 stamp travel scuttle
17 look fly stumble
18 splash stride sling
19 conduct scatter skid
20 scud sweep flash
</table>
<tableCaption confidence="0.999041">
Table 2. Top 20 types for V across n ordered by types,
tokens and construction tokenized faithfulness
</tableCaption>
<table confidence="0.996951904761905">
types (sample) tokens faithfulness
1 eat give give
2 attend make call
3 feel call offer
4 receive tell make
5 miss do send
6 choose offer tell
7 affect send hand
8 come show show
9 mean find earn
10 provide get owe
11 cut bring cost
12 strike ask lend
13 prove take bring
14 teach pay do
15 refuse allow find
16 spare buy ask
17 leave see pay
18 wonder hand allow
19 permit cost buy
20 force set teach
</table>
<tableCaption confidence="0.9793825">
Table 3. Top 20 types for V Obj Obj ordered by types,
tokens and construction faithfulness
</tableCaption>
<bodyText confidence="0.9989425">
The figures are the mean of the values in each ma-
trix. Path and lin values range between 0 and 1,
Open Roget between 4 and 16 and the others are
on varying scales where larger values indicate
greater similarity. These tables show that the token
distribution sample of verb types increases the se-
mantic cohesion of the construction over a flat
verbs list.
</bodyText>
<table confidence="0.9966249">
Similarity Types Tokens Faithfulness
measure (sampled) (top 20) (top 20)
WordNet 0.163 0.387 0.245
path
lch 0.941 1.976 1.385
wup 0.312 0.653 0.453
res 2.473 4.673 3.748
jcn 1.033 0.383 0.190
lin 0.259 0.583 0.372
Open Roget 5.190 11.737 6.232
</table>
<tableCaption confidence="0.9794365">
Table 4. Semantic similarity measures for V across n
by types, tokens and construction faithfulness
</tableCaption>
<table confidence="0.9995023">
Similarity Types Tokens Faithfulness
measure (sampled) (top 20) (top 20)
WordNet 0.175 0.316 0.241
path
lch 1.008 1.654 1.299
wup 0.345 0.579 0.457
res 2.470 3.942 2.973
jcn 0.199 0.435 0.313
lin 0.308 0.558 0.406
Open Roget 7.863 13.011 10.768
</table>
<tableCaption confidence="0.9910865">
Table 5. Semantic similarity measures for V Obj Obj by
types, tokens and construction faithfulness
</tableCaption>
<bodyText confidence="0.980356947368421">
Sampling the items on the basis of their token fre-
quency weighted for faithfulness also improves
semantic homogeneity, although it does not here
offer any improvement over a tokenized distribu-
tion alone. We not entirely satisfied with these
measures. WordNet verb hierarchies are much flat-
ter and bushier than those for nouns, where these
measures are more successful. For verbs, distance
down a synset is less telling than distance across.
As a result, we are exploring other measures of the
semantic similarity of verbs informed by network
science. We are also exploring the use of word
sense disambiguation techniques to reduce prob-
lems introduced by the rich polysemy of verbs in
WordNet (e.g. give is assigned to 44 different syn-
sets) and also in Roget’s.
Future work
We plan to apply these methods to the full range of
English VACs as described in Francis et al (1996)
</bodyText>
<page confidence="0.992448">
15
</page>
<bodyText confidence="0.999925681818182">
and other construction grammars too. We are par-
ticularly interested in whether the inventory repre-
sents an optimal partitioning of verb semantics,
starting with basic categories of action semantics
and proceeding to greater specificity via Zipfian
mapping. We are also interested in extending these
approaches to learner language to investigate
whether first and second language learners’ acqui-
sition follows the construction distributional pro-
files and whether the factors outlined in Goldberg
et al. (2004) facilitate acquisition.
There have been suggestions that Zipfian type-
token frequency distributions are essentially unin-
teresting artifacts. For each motivated construction
identified along the lines described in 3.3, we have
begun to make matching random control distribu-
tions generated as a random selection of verb types
of comparable n types and tokens (yoked ersatz-
controls). For each of our outcome measures, we
will compare the various scores for VAC verb-
types gathered on the principled basis of construc-
tion-grammar against those for their controls.
</bodyText>
<sectionHeader confidence="0.758814" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999815166666667">
Meanwhile, these pilot studies show some promise
in these methods towards an English verb grammar
operationalized as an inventory of VACs, their
verb membership and their type-token frequency
distributions, their contingency of mapping, and
their semantic motivations.
</bodyText>
<sectionHeader confidence="0.999247" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684148648649">
Andersen, ¯. E., Nioche, J., Briscoe, T., &amp; Carroll, J.
(2008). The BNC Parsed with RASP4UIMA.
Proceedings of the Sixth International Language
Resources and Evaluation (LREC08), 28-30.
Bod, R., Hay, J., &amp; Jannedy, S. (eds.). (2003).
Probabilistic linguistics. Cambridge,MA: MIT Press.
Briscoe, E., Carroll, J., &amp; Watson, R. (2006). The
Second Release of the RASP System. Proceedings of
the COLING/ACL 2006 Interactive Presentation
Sessions, Sydney, Australia.
Bybee, J., &amp; Hopper, P. (Eds.). (2001). Frequency and
the emergence of linguistic structure. Amsterdam:
Benjamins.
Dorogovstev, S.N., &amp; Mendes, J.F.F. (2003). Evolution
of Networks: From Biological Nets to the Internet
and WWW. Oxford: Oxford University Press.
Ellis, N.C. (2002). Frequency effects in language
processing: A review with implications for theories
of implicit and explicit language acquisition. Studies
in Second Language Acquisition, 24 (2), 143-188.
Ellis, N.C., &amp; Cadierno, T. (2009). Constructing a
second language. Annual Review of Cognitive
Linguistics, 7 (Special section).
Ellis, N.C., &amp; Ferreira-Junior, F. (2009). Constructions
and their acquisition: Islands and the distinctiveness
of their occupancy. Annual Review of Cognitive
Linguistics, 111-139.
Fillmore, C. J., Johnson, C. R., &amp; Petruck, M. R. L.
(2003). Background to Framenet. International
Journal of Lexicography, 16, 235-250.
Francis, G., Hunston, S., &amp; Manning, E. (Eds.). (1996).
Grammar Patterns 1: Verbs. The COBUILD Series.
London: Harper Collins.
Goldberg, A.E. (2006). Constructions at work: The
nature of generalization in language. Oxford: Oxford
University Press.
Goldberg, A.E., Casenhiser, D.M., &amp; Sethuraman, N.
(2004). Learning argument structure generalizations.
Cognitive Linguistics, 15, 289–316.
Gries, S.T., &amp; Stefanowitsch, A. (2004). Extending
collostructional analysis: a corpus-based perspective
on ‘alternations’. International Journal of Corpus
Linguistics, 9, 97-129.
Kennedy, A. (2009). The Open Roget’s Project:
Electronic lexical knowledge base. Retr. 1st March,
2010: http://rogets.site.uottawa.ca/index.shtml
Mason, O., &amp; Hunston, S. (2004). The automatic
recognition of verb patterns: A feasibility study.
International Journal of Corpus Linguistics, 9, 253-
270.
Miller, G. A. (2009). WordNet - About us. Retrieved
March 1, 2010, from http://wordnet.princeton.edu
Ninio, A. (1999). Pathbreaking verbs in syntactic
development and the question of prototypical
transitivity. Journal of Child Language, 26, 619-653.
Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004).
WordNet::Similarity Ð Measuring the Relatedness of
Concepts. Proceedings of Fifth Annual Meeting of
the North American Chapter of the Association of
Computational Linguistics (NAACL 2004).
Shanks, D. R. (1995). The psychology of associative
learning. New York: Cambridge University Press.
Sinclair, J. (2004). Trust the text: Language, corpus and
discourse. London: Routledge.
Sol6, R. V., Murtra, B., Valverde, S., &amp; Steels, L.
(2005). Language Networks: their structure, function
and evolution. Trends in Cognitive Sciences, 12.
Stefanowitsch, A., &amp; Gries, S.T. (2003).
Collostructions: Investigating the interaction between
words and constructions. International Journal of
Corpus Linguistics, 8, 209-243.
Zipf, G. K. (1935). The psycho-biology of language: An
introduction to dynamic philology. Cambridge, MA:
The M.I.T. Press.
</reference>
<page confidence="0.998693">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002709">
<title confidence="0.999748">Towards an Inventory of English Verb Argument Constructions</title>
<author confidence="0.999939">Matthew Brook O’Donnell Nick Ellis</author>
<affiliation confidence="0.999977">University of Michigan University of Michigan</affiliation>
<address confidence="0.998277">500 E. Washington St. 500 E. Washington St. Ann Arbor, MI 48104, USA Ann Arbor, MI 48104, USA</address>
<email confidence="0.999613">mbod@umich.eduncellis@umich.edu</email>
<abstract confidence="0.998229399999999">This paper outlines and pilots our approach towards developing an inventory of verb-argument constructions based upon English form, function, and usage. We search a tagged and dependencyparsed BNC (a 100-million word corpus of English) for Verb-Argument Constructions (VACs) including those previously identified in the pattern grammar resulting from the COBUILD project. This generates (1) a list of verb types that occupy each construction. We next tally the frequency profiles of these verbs to produce (2) a frequency ranked type-token distribution for these verbs, and we determine the degree to which this is Zipfian. Since some verbs are faithful to one construction while others are more promiscuous, we next produce (3) a contingency-weighted list reflecting their statistical association. To test whether each of these measures is a step towards increasing the learnability of VACs as categories, following principles of associative learning, we examine 20 verbs from each distribution. Here we explore whether there is an increase in the semantic cohesion of the verbs occupying each construction using semantic similarity measures. From inspection, this seems to be so. We are developing measures of this using network measures of clustering in the verb-space defined by WordNet and Roget’s Thesaurus. 1 Construction grammar and Usage Constructions are form-meaning mappings, conventionalized in the speech community, and entrenched as language knowledge in the learner’s mind. They are the symbolic units of language relating the defining properties of their morphological, lexical, and syntactic form with particular semantic, pragmatic, and discourse functions (Goldberg, 2006). Construction Grammar argues that all grammatical phenomena can be understood as learned pairings of form (from morphemes, words, idioms, to partially lexically filled and fully general phrasal patterns) and their associated semantic or discourse functions: “the network of constructions captures our grammatical knowledge i.e. It’s constructions all the way down” (Goldberg, 2006, p. 18). Such beliefs, increasingly influential in the study of child language acquisition, have turned upside down generative assumptions of innate language acquisition devices, the continuity hypothesis, and top-down, rulegoverned, processing, bringing back data-driven, emergent accounts of linguistic systematicities. Frequency, learning, and language come together in usage-based approaches which hold that we learn linguistic constructions while engaging in communication. The last 50 years of psycholinguistic research provides the evidence of usagebased acquisition in its demonstrations that language processing is exquisitely sensitive to usage frequency at all levels of language representation from phonology, through lexis and syntax, to sentence processing (Ellis, 2002). Language knowledge involves statistical knowledge, so humans learn more easily and process more fluently high frequency forms and ‘regular’ patterns which are exemplified by many types and which have few competitors. Psycholinguistic perspectives thus hold that language learning is the associative learning of representations that reflect the probabilities of occurrence of form-function mappings. Frequency is a key determinant of acquisition because ‘rules’ of language, at all levels of analysis from phonology, through syntax, to discourse, are structural regularities which emerge from learners’ lifetime unconscious analysis of the distributional characteristics of the language input. If constructions as form-function mappings are the units of language, then language acquisition involves inducing these associations from experience of language usage. Constructionist accounts of language acquisition thus involve the distributional analysis of the language stream and the paranalysis of contingent perceptuo-motor activ- 9 of the NAACL HLT Workshop on Extracting and Using Constructions in Computational pages Angeles, California, June 2010. Association for Computational Linguistics ity, with abstract constructions being learned as categories from the conspiracy of concrete exemplars of usage following statistical learning mechanisms (Bod, Hay, &amp; Jannedy, 2003; Bybee &amp; Hopper, 2001; Ellis, 2002) relating input and learner cognition. Psychological analyses of the learning of constructions as form-meaning pairs is informed by the literature on the associative learning of cue-outcome contingencies where the usual determinants include: (1) input frequency (typetoken frequency, Zipfian distribution, recency), (2) form (salience and perception), (3) function (prototypicality of meaning, importance of form for message comprehension, redundancy), and (4) interactions between these (contingency of form-function (Ellis &amp; Cadierno, 2 Determinants of construction learning In natural language, Zipf’s law (Zipf, 1935) describes how a handful of the highest frequency words account for the most linguistic tokens. Zipf’s law states that the frequency of words decreases as a power function of their rank in the fretable. If the proportion of words whose rank in a given language sample is f with Zipf showed this scaling relation holds across a wide variety of language samples. Subsequent research provides support for this law as a linguistic universal: many language events (e.g., frequencies of phoneme and letter strings, of words, of grammatical constructs, of formulaic phrases, etc.) across scales of analysis follow this law (Sole, Murtra, Valverde, &amp; Steels, 2005). Goldberg, Casenhiser &amp; Sethuraman (2004) demonstrated that in samples of child language acquisition, for a variety of verb-argument constructions (VACs), there is a strong tendency for one single verb to occur with very high frequency in comparison to other verbs used, a profile which closely mirrors that of the mothers’ speech to these children. Goldberg et al. (2004) show that Zipf’s law applies within VACs too, and they argue that this promotes acquisition: tokens of one particular verb account for the lion’s share of instances of each particular argument frame; this pathbreaking verb also is the one with the prototypical meaning from which the construction is derived (see also Ninio, 1999). Ellis and Ferreira-Junior (2009) investigate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first acquire the most frequent, protoand generic exemplar. (e.g. VOL VOO [verb-objectobject], etc.). Acquisition is affected by the frequency distribution of exemplars within each island of the construction, by their prototypicality, and, using a variety of psychological (Shanks, 1995) and corpus linguistic association metrics (Gries &amp; Stefanowitsch, 2004), by their contingency of form-function mapping. This fundamental claim that Zipfian distributional properties of language usage helps to make language learnable has thus begun to be explored for these three VACs, at least. It remains an important research agenda to explore its generality across a wide range of constructions (i.e. the constructicon). The primary motivation of construction grammar is that we must bring together linguistic form, learner cognition, and usage. An important consequence is that constructions cannot be defined on the basis of linguistic form, of usage All three factors are necessary in their operationalization and measurement. Our research aims to do this. We hope to describe the verbal grammar of English, to analyze the way VACs map form and meaning, and to provide an inventory of the verbs that exemplify constructions and their frequency. This last step is necessary because the type-token frequency distribution of their verbs determines VAC acquisition as abstract schematic constructions, and because usage frequency determines their entrenchment and processing. This paper describes and pilots our approach. We focus on just two constructions for illustration across and V Obj Obj) although our procedures are principled, generic and applicable to all VACs. We search a tagged and dependencyparsed British National Corpus (a 100-million word corpus of English) for VACs including those previously identified in the COBUILD pattern grammar project. This generates (1) a list of verb types that occupy each construction. We next tally the frequency profiles of these verbs to produce (2) a frequency ranked type-token distribution for these verbs, and we determine the degree to which 10 this is Zipfian. Since some verbs are faithful to one construction while others are more promiscuous, we next produce (3) a contingency-weighted list which reflects their statistical association. 3 Method As a starting point, we considered several of the major theories and datasets of construction grammar such as FrameNet (Fillmore, Johnson, &amp; Petruck, 2003). However, because our research aims to empirically determine the semantic associations of particular linguistic forms, it is important that such forms are initially defined by bottom-up means that are semantics-free. There is no one in corpus linguistics who ‘trusts the text’ more than Sinclair (2004). Therefore we chose the Pattern Grammar (Francis et al. 1996) definition of Verb constructions that arose out of his Cobuild project. 3.1 Construction inventory: COBUILD Verb Patterns The form-based patterns described in the CO- BUILD Verb Patterns volume (Francis et al. 1996) take the form of word class and lexis combinasuch as V V and n For each of these patterns the resource provides information as to the structural configurations and functional/meaning groups found around these patterns through detailed concordance analysis of the Bank of English corpus during the construction of the COBUILD dictionary. For instance, the following provided for the V pattern (Francis, et al., 1996, p. 150): The verb is followed by a prepositional phrase which consists of across and a noun group. This pattern has one structure: * Verb with Adjunct. cutacross the Further example sentences are provided drawn from the corpus and a list of verbs found in the pattern and that are semantically typical are given. this pattern these are: cut, fall, flicker, plane, skim, No indication is given as to how frequent each of these types are or how comprehensive the list is. Further structural (syntactical) characteristics of the pattern are sometimes such as the fact that for V the prepositional phrase is an adjunct and that the verb is never passive. For some construction patterns with a generally fixed order it may be sufficient just to specify combinations of word and part-of-speech sequences. For example, a main verb followed by 1 to 3 words (to allow for adverbial elements), followed by a noun or pronoun within a few words. To such constraints a number exceptions of what should not occur within the specified spans must be added. The variation and potential complexity of English noun phrases presents challenges for this approach. On the other hand a multi-level constituent parse tree provides more than needed. A dependency parse with word-toword relations is well suited for the task. 3.2 Corpus: BNC XML Parsed The analysis of verb type-token distribution in the kinds of construction patterns described in the previous section should ideally be carried out using a range of corpora in the magnitude of the tens or hundreds of millions of words as the original work is derived from the Bank of English (a growing monitor corpus of over 400 million words). These corpora should, at the least, be part-of-speech tagged to search for the pattern as specified. Further some kind of partial parsing and chunking is necessary to apply the structural constraints (see Mason &amp; Hunston, 2004 for exploratory methodology). We chose to use the 100 million word British National Corpus (BNC) on account of its size, the breadth of genres it contains and consistent lemmatization and part-of-speech tagging. Andersen et al. (2008) parsed the XML version of the BNC using the RASP parser (Briscoe, Carroll, &amp; Watson, 2006). RASP is a statistical featurebased parser that produces a probabilistically ordered set of parse trees for a given sentence and additionally a set of grammatical relations (GRs) that capture “those aspects of predicate-argument structure that the system is able to recover and is the most stable and grammar independent representation available” (Briscoe, et al., 2006, p. 79). The GRs are organized into a hierarchy of dependency relations, including distinctions between modifiers and arguments and within arguments between subject (sub) and complements (comp). Figure 1 shows the GRs assigned by RASP for the 11 kitchen light skids across the lawn A0U). The main verb two arguments, a subject (ncsubj) and indirect object (iobj), and the preposition one argument (dobj). Figure 1. Example of RASP GRs The RASP GR hierarchy does not include categories such as prepositional complement or adjunct. Figure 2 shows the GRs for another sentence conis not an example of the V pattern. Alternate analyses might attach to the main verb but at least examining BNC examples containing it appears RASP tends to favor local attachments for this case). Figure 2. Example of RASP GRs The GRs from RASP have been incorporated into the XML for each BNC sentence thereby preserving the token, part-of-speech and lemma information in the corpus. 3.3 Searching construction patterns Our search algorithm works as follows: 1. Process each sentence in turn testing against an XPath expression to identify components in construction patterns, e.g. preceding-sibling::w[position()&lt;3] a verb followed by 2 words. 2. Create a list of the grammatical relations where this verb functions as the head. This finds the relations for the example sentence. ii. Also find GRs involving other components pattern (e.g. 3. Check these GRs against a constraint list, e.g. make sure that i. only one relation where the dependent word comes after the verb (excluding with both ii. the dependent of the second component matches a specific part-of-speech (e.g. head and noun as dependent). 4. For matching sentences record verb lemma. Here we report on just two construction patterns: 1. and 2. V n n or V Obj Obj (where n includes both nouns and pronouns). We have also run a range of similar V Prep n patterns from COsuch as V V V We have still to carry out a systematic precision-recall analysis, but ad hoc examination suggests that the strict constraints using the dependency relations provides a reasonable precision and the size of the corpus results in a large enough number of tokens to carry out distributional analysis (see Table 1). 1. Type-Token data for V and V Obj Obj constructions 3.4 Identifying the meaning of verb types occupying the constructions We considered several ways of analyzing the semantics the resulting verb distributions. It is important that the semantic measures we employ are defined in a way that is free of linguistic distributional information, otherwise we would be building in circularity. Therefore methods such as LSA are not applicable here. Instead, our research utilizes two distribution-free semantic databases: (1) Roget’s thesaurus, a classic lexical resource of longstanding proven utility, based on Roget’s guided introspections, as implemented in the Open Roget’s Project (Kennedy, 2009). This provides various algorithms for measuring the semantic similarity between terms and between sentences. (2) WordNet, based upon psycholinguistic theory and in development since 1985 (Miller, 2009). Word- Net classes words into a hierarchical network. At the top level, the hierarchy for verbs is organized 15 base types (such as transmovement and without etc.) which then split into over 11,500 verb synonym sets or synsets.</abstract>
<title confidence="0.765976">Construction Types Tokens</title>
<address confidence="0.479225">V Obj Obj 663 9183</address>
<phone confidence="0.825134">799 4889</phone>
<abstract confidence="0.990046992857143">TTR 7.22 16.34 12 Verbs are linked in the hierarchy according to relasuch as hypernym (to an hypernym to and troponym, the term used for hyponymic relations in the verb component of WordNet a troponym of to There are various algorithms to determine the semantic similarity between synsets in WordNet which consider the distance between the conceptual categories of words, as well as considering the hierarchical structure of the WordNet (Pedersen et al. 2004). the contingency between construction form and function Some verbs are closely tied to a particular con- (for example, highly indicative of ditransitive construction, whereas although it can form a ditransitive, is more often associated with other constructions such as the simple transitive or intransitive). The more reliable the contingency between a cue and an outcome, the more readily an association between them can be so constructions with more faithful verb members are more transparent and thus should be more readily acquired. Ellis and (2009) use collostructional analysis measures (Stefanowitsch &amp; Gries, 2003) to show effects of form-function contingency upon L2 VAC acquisition. Others use conditional probabilities to investigate contingency effects in VAC acquisition. This is still an active area of inquiry, and more research is required before we know which statistical measures of form-function contingency are more predictive of acquisition and processing. Meanwhile, the simplest usable measure is one of faithfulness – the proportion of tokens of total verb usage as a whole that appear in this particular construction. For illustration, the faithof the ditransitive is approximately that for 0.01. 4 Results 4.1 Evaluating the verb distribution the V pattern the procedure outlined in the previous section results in the following list: come 483 walk 203 . cut 199 veer 4 run 175 whirl 4 ... spread 146 slice 4 discharge 1 ... clamber 4 navigate 1 . scythe 1 scroll 1 3. Verb type distribution for V At first glance this distribution does appear to be Zipfian, exhibiting the characteristic long-tailed distribution in a plot of rank against frequency. Dorogovstev &amp; Mendes (2003, pp. 222-223) outline the commonly used methods for measuring power-law distributions: 1. a simple log-log plot (rank/frequency), 2. log-log plot of cumulative probability against frequency and 3. the use of logarithmic binning over the distribution for a loglog plot as in 2. Linear regression can be applied to resulting plots and goodness of fit and the recorded. Figure 3 shows such a plot for verb type freof the V construction pattern extracted from the parsed BNC XML corpus following the third plotting method. Verb types are grouped into 20 logarithmic bins according to their frequency (x-axis) against the logarithm of the cumulative probability of a verb occurring with or above this frequency (y-axis). Each point repreone bin and a verb from each group is ran- 13 domly selected to label the point with its token frein parentheses. For example, the type 102 times in the V pattern and is into the bin with the types Points towards the lower right of the plot indicate high-frequency low-type groupings and those towards the top left low-frequency high-type groupings, that is the fator long-tail of the distribution. Looking at the verbs given as examples of the pattern in COBUILD volume we find all but in our corpus search V tokens, group cut tokens, group fall flicker flit g9), skim sweep g12). Figure 4. Verb type distribution for V Obj Obj Figure 4 shows the plot for verb type frequency of the ditransitive V Obj Obj construction pattern extracted and binned in the same way. Both distributions can be fitted with a straight regression line Thus we conclude that the type-token frequency distributions for these constructions are Zipfian. (In future we will investigate the other plot and fitting methods to ensure we have not smoothed the data too much through binning.) Inspection of the construction verb types, from most frequent down, also suggests that, as in prior research (Ellis &amp; Ferreira-Junior, 2009; Goldberg et al., 2004; Ninio, 1999), the most frequent items are prototypical of the construction and more generic in their action semantics. 4.2 Evaluating the roles of frequency distribution and faithfulness in semantic cohesion The second step in evaluating the verb distributions from the construction patterns is to compare a small set of types selected on the basis of a flat type distribution, the (Zipfian) token frequency distribution and a distribution that represents the degree to which a verb is attracted to the particular construction. First we select the top 200 types from the two VACs, ordered by token frequency. Then we sample 20 verbs from this list at random. This is the ‘types list’. Next we take the top 20 types as the ‘tokens list’. Finally, we calculate the tokenized faithfulness score for each type by dividing the verb’s frequency in the construction by its overall frequency in the whole BNC. For example, 146 times in the V pattern and 5503 times in total. So its faithfulness is 146/5503*100 = 2.65%, i.e. 1 in 38, of the inof as across The faithfulness score for then simply (146/5503) * 146 = 3.87, which tempers the for low frequency types such as rise to the top of the list and is our initial attempt to combine the effects of token frequency and construction contingency. We reorder the 200 types by this figure and take the top twenty for the ‘faithfulness list’. Tables 2 and 3 contain these lists for the two constructions. An intuitive reading of these lists suggests that the tokens list captures the most general and prototypical move for V and tell, offer V Obj Obj), while the list ordered by tokenized faith highlights some quite construction specific (and low frequency) items, as V The final component is to quantify the semantic coherence or ‘clumpiness’ of the verbs extracted in the previous steps. For this we use WordNet and Roget’s. Pedersen et al. (2004) outline six measures in their Perl WordNet::Similarity three lch based on the path length between concepts in WordNet Synsets three that incorporate a measure called ‘information content’ related to specificity. Tables 4 and 5 show the simi- 14 larity scores that result from taking the 20 types in each of the lists in Tables 2 and 3 and generating a 20 by 20 distance matrix. faithfulness 1 scuttle come spread 2 ride walk scud 3 paddle cut sprawl 4 communicate run cut 5 rise spread walk 6 stare move come 7 drift look stride 8 stride go lean 9 face lie flit 10 dart lean stretch 11 flee stretch run 12 skid fall scatter 13 print get skitter 14 shout pass flicker 15 use reach slant 16 stamp travel scuttle 17 look fly stumble 18 splash stride sling 19 conduct scatter skid 20 scud sweep flash 2. Top 20 types for V ordered by types, tokens and construction tokenized faithfulness faithfulness 1 eat give give 2 attend make call 3 feel call offer 4 receive tell make 5 miss do send 6 choose offer tell 7 affect send hand 8 come show show 9 mean find earn 10 provide get owe 11 cut bring cost 12 strike ask lend 13 prove take bring 14 teach pay do 15 refuse allow find 16 spare buy ask 17 leave see pay 18 wonder hand allow 19 permit cost buy 20 force set teach Table 3. Top 20 types for V Obj Obj ordered by types, tokens and construction faithfulness The figures are the mean of the values in each marange between 0 and 1, Open Roget between 4 and 16 and the others are on varying scales where larger values indicate greater similarity. These tables show that the token distribution sample of verb types increases the semantic cohesion of the construction over a flat verbs list. measure (sampled) (top 20) Faithfulness (top 20) path 0.163 0.387 0.245 lch 0.941 1.976 1.385 wup 0.312 0.653 0.453 res 2.473 4.673 3.748 jcn 1.033 0.383 0.190 lin 0.259 0.583 0.372 Open Roget 5.190 11.737 6.232 4. Semantic similarity measures for V by types, tokens and construction faithfulness measure (sampled) (top 20) Faithfulness (top 20) path 0.175 0.316 0.241 lch 1.008 1.654 1.299 wup 0.345 0.579 0.457 res 2.470 3.942 2.973 jcn 0.199 0.435 0.313 lin 0.308 0.558 0.406 Open Roget 7.863 13.011 10.768 Table 5. Semantic similarity measures for V Obj Obj by types, tokens and construction faithfulness Sampling the items on the basis of their token frequency weighted for faithfulness also improves semantic homogeneity, although it does not here offer any improvement over a tokenized distribution alone. We not entirely satisfied with these measures. WordNet verb hierarchies are much flatter and bushier than those for nouns, where these measures are more successful. For verbs, distance down a synset is less telling than distance across. As a result, we are exploring other measures of the semantic similarity of verbs informed by network science. We are also exploring the use of word sense disambiguation techniques to reduce problems introduced by the rich polysemy of verbs in (e.g. assigned to 44 different synsets) and also in Roget’s. Future work We plan to apply these methods to the full range of VACs as described in Francis al 15 and other construction grammars too. We are particularly interested in whether the inventory represents an optimal partitioning of verb semantics, starting with basic categories of action semantics and proceeding to greater specificity via Zipfian mapping. We are also interested in extending these approaches to learner language to investigate whether first and second language learners’ acquisition follows the construction distributional profiles and whether the factors outlined in Goldberg et al. (2004) facilitate acquisition. There have been suggestions that Zipfian typetoken frequency distributions are essentially uninteresting artifacts. For each motivated construction identified along the lines described in 3.3, we have begun to make matching random control distributions generated as a random selection of verb types comparable and tokens (yoked ersatzcontrols). For each of our outcome measures, we will compare the various scores for VAC verbtypes gathered on the principled basis of construction-grammar against those for their controls. Conclusions Meanwhile, these pilot studies show some promise in these methods towards an English verb grammar operationalized as an inventory of VACs, their verb membership and their type-token frequency distributions, their contingency of mapping, and their semantic motivations.</abstract>
<note confidence="0.958951277777778">References Andersen, ¯. E., Nioche, J., Briscoe, T., &amp; Carroll, J. (2008). The BNC Parsed with RASP4UIMA. Proceedings of the Sixth International Language and Evaluation 28-30. Bod, R., Hay, J., &amp; Jannedy, S. (eds.). (2003). Cambridge,MA: MIT Press. E., Carroll, J., &amp; Watson, R. (2006). Release of the RASP System. of the COLING/ACL 2006 Interactive Presentation Sessions, Sydney, Australia. J., &amp; Hopper, P. (Eds.). (2001). and emergence of linguistic Amsterdam: Benjamins. S.N., &amp; Mendes, J.F.F. (2003). of Networks: From Biological Nets to the Internet Oxford: Oxford University Press. Ellis, N.C. (2002). Frequency effects in language</note>
<abstract confidence="0.830581">processing: A review with implications for theories implicit and explicit language acquisition.</abstract>
<note confidence="0.942663964285714">Second Language Acquisition, 24 143-188. Ellis, N.C., &amp; Cadierno, T. (2009). Constructing a language. Review of Cognitive 7 section). Ellis, N.C., &amp; Ferreira-Junior, F. (2009). Constructions and their acquisition: Islands and the distinctiveness their occupancy. Review of Cognitive 111-139. Fillmore, C. J., Johnson, C. R., &amp; Petruck, M. R. L. Background to Framenet. of Lexicography, 235-250. Francis, G., Hunston, S., &amp; Manning, E. (Eds.). (1996). Patterns 1: Verbs. The COBUILD London: Harper Collins. A.E. (2006). at work: The of generalization in Oxford: Oxford University Press. Goldberg, A.E., Casenhiser, D.M., &amp; Sethuraman, N. (2004). Learning argument structure generalizations. Linguistics, 289–316. Gries, S.T., &amp; Stefanowitsch, A. (2004). Extending collostructional analysis: a corpus-based perspective ‘alternations’. Journal of Corpus 97-129. Kennedy, A. (2009). The Open Roget’s Project: Electronic lexical knowledge base. Retr. 1st March, 2010: http://rogets.site.uottawa.ca/index.shtml Mason, O., &amp; Hunston, S. (2004). The automatic recognition of verb patterns: A feasibility study. Journal of Corpus Linguistics, 253- 270. Miller, G. A. (2009). WordNet - About us. Retrieved March 1, 2010, from http://wordnet.princeton.edu Ninio, A. (1999). Pathbreaking verbs in syntactic development and the question of prototypical of Child Language, 619-653. Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet::Similarity Ð Measuring the Relatedness of of Fifth Annual Meeting of the North American Chapter of the Association of Computational Linguistics (NAACL 2004). D. R. (1995). psychology of associative New York: Cambridge University Press. J. (2004). the text: Language, corpus and London: Routledge. Sol6, R. V., Murtra, B., Valverde, S., &amp; Steels, L. (2005). Language Networks: their structure, function evolution. in Cognitive Sciences, Stefanowitsch, A., &amp; Gries, S.T. (2003). Collostructions: Investigating the interaction between and constructions. Journal of Linguistics, 209-243. G. K. (1935). psycho-biology of language: An to dynamic Cambridge, MA: The M.I.T. Press. 16</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Nioche</author>
<author>J Briscoe</author>
<author>T</author>
<author>J Carroll</author>
</authors>
<date>2008</date>
<booktitle>The BNC Parsed with RASP4UIMA. Proceedings of the Sixth International Language Resources and Evaluation (LREC08),</booktitle>
<pages>28--30</pages>
<marker>Nioche, Briscoe, T, Carroll, 2008</marker>
<rawString>Andersen, ¯. E., Nioche, J., Briscoe, T., &amp; Carroll, J. (2008). The BNC Parsed with RASP4UIMA. Proceedings of the Sixth International Language Resources and Evaluation (LREC08), 28-30.</rawString>
</citation>
<citation valid="true">
<title>Probabilistic linguistics. Cambridge,MA:</title>
<date>2003</date>
<editor>Bod, R., Hay, J., &amp; Jannedy, S. (eds.).</editor>
<publisher>MIT Press.</publisher>
<marker>2003</marker>
<rawString>Bod, R., Hay, J., &amp; Jannedy, S. (eds.). (2003). Probabilistic linguistics. Cambridge,MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<date>2006</date>
<booktitle>The Second Release of the RASP System. Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="12785" citStr="Briscoe, Carroll, &amp; Watson, 2006" startWordPosition="1968" endWordPosition="1972">d from the Bank of English (a growing monitor corpus of over 400 million words). These corpora should, at the least, be part-of-speech tagged to search for the pattern as specified. Further some kind of partial parsing and chunking is necessary to apply the structural constraints (see Mason &amp; Hunston, 2004 for exploratory methodology). We chose to use the 100 million word British National Corpus (BNC) on account of its size, the breadth of genres it contains and consistent lemmatization and part-of-speech tagging. Andersen et al. (2008) parsed the XML version of the BNC using the RASP parser (Briscoe, Carroll, &amp; Watson, 2006). RASP is a statistical featurebased parser that produces a probabilistically ordered set of parse trees for a given sentence and additionally a set of grammatical relations (GRs) that capture “those aspects of predicate-argument structure that the system is able to recover and is the most stable and grammar independent representation available” (Briscoe, et al., 2006, p. 79). The GRs are organized into a hierarchy of dependency relations, including distinctions between modifiers and arguments and within arguments between subject (sub) and complements (comp). Figure 1 shows the GRs assigned b</context>
<context position="13156" citStr="Briscoe, et al., 2006" startWordPosition="2027" endWordPosition="2030"> National Corpus (BNC) on account of its size, the breadth of genres it contains and consistent lemmatization and part-of-speech tagging. Andersen et al. (2008) parsed the XML version of the BNC using the RASP parser (Briscoe, Carroll, &amp; Watson, 2006). RASP is a statistical featurebased parser that produces a probabilistically ordered set of parse trees for a given sentence and additionally a set of grammatical relations (GRs) that capture “those aspects of predicate-argument structure that the system is able to recover and is the most stable and grammar independent representation available” (Briscoe, et al., 2006, p. 79). The GRs are organized into a hierarchy of dependency relations, including distinctions between modifiers and arguments and within arguments between subject (sub) and complements (comp). Figure 1 shows the GRs assigned by RASP for the 11 sentence: The kitchen light skids across the lawn (BNC A0U). The main verb skids has two arguments, a subject (ncsubj) and indirect object (iobj), and the preposition one argument (dobj). Figure 1. Example of RASP GRs The RASP GR hierarchy does not include categories such as prepositional complement or adjunct. Figure 2 shows the GRs for another sente</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Briscoe, E., Carroll, J., &amp; Watson, R. (2006). The Second Release of the RASP System. Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bybee</author>
<author>P Hopper</author>
</authors>
<title>Frequency and the emergence of linguistic structure.</title>
<date>2001</date>
<location>Amsterdam: Benjamins.</location>
<contexts>
<context position="4588" citStr="Bybee &amp; Hopper, 2001" startWordPosition="659" endWordPosition="662">ons from experience of language usage. Constructionist accounts of language acquisition thus involve the distributional analysis of the language stream and the parallel analysis of contingent perceptuo-motor activ9 Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 9–16, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ity, with abstract constructions being learned as categories from the conspiracy of concrete exemplars of usage following statistical learning mechanisms (Bod, Hay, &amp; Jannedy, 2003; Bybee &amp; Hopper, 2001; Ellis, 2002) relating input and learner cognition. Psychological analyses of the learning of constructions as form-meaning pairs is informed by the literature on the associative learning of cue-outcome contingencies where the usual determinants include: (1) input frequency (typetoken frequency, Zipfian distribution, recency), (2) form (salience and perception), (3) function (prototypicality of meaning, importance of form for message comprehension, redundancy), and (4) interactions between these (contingency of form-function mapping) (Ellis &amp; Cadierno, 2009). 2 Determinants of construction le</context>
</contexts>
<marker>Bybee, Hopper, 2001</marker>
<rawString>Bybee, J., &amp; Hopper, P. (Eds.). (2001). Frequency and the emergence of linguistic structure. Amsterdam: Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Dorogovstev</author>
<author>J F F Mendes</author>
</authors>
<title>Evolution of Networks: From Biological Nets to the Internet and WWW.</title>
<date>2003</date>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<contexts>
<context position="19323" citStr="Dorogovstev &amp; Mendes (2003" startWordPosition="3029" endWordPosition="3032">tion. For illustration, the faithfulness of give to the ditransitive is approximately 0.40; that for leave is 0.01. 4 Results 4.1 Evaluating the verb distribution For the V across n pattern the procedure outlined in the previous section results in the following list: come 483 walk 203 . cut 199 veer 4 run 175 whirl 4 ... spread 146 slice 4 discharge 1 ... clamber 4 navigate 1 . scythe 1 scroll 1 Figure 3. Verb type distribution for V across n At first glance this distribution does appear to be Zipfian, exhibiting the characteristic long-tailed distribution in a plot of rank against frequency. Dorogovstev &amp; Mendes (2003, pp. 222-223) outline the commonly used methods for measuring power-law distributions: 1. a simple log-log plot (rank/frequency), 2. log-log plot of cumulative probability against frequency and 3. the use of logarithmic binning over the distribution for a loglog plot as in 2. Linear regression can be applied to the resulting plots and goodness of fit (R2) and the slope (γ) recorded. Figure 3 shows such a plot for verb type frequency of the V across n construction pattern extracted from the parsed BNC XML corpus following the third plotting method. Verb types are grouped into 20 logarithmic bi</context>
</contexts>
<marker>Dorogovstev, Mendes, 2003</marker>
<rawString>Dorogovstev, S.N., &amp; Mendes, J.F.F. (2003). Evolution of Networks: From Biological Nets to the Internet and WWW. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N C Ellis</author>
</authors>
<title>Frequency effects in language processing: A review with implications for theories of implicit and explicit language acquisition.</title>
<date>2002</date>
<journal>Studies in Second Language Acquisition,</journal>
<volume>24</volume>
<issue>2</issue>
<pages>143--188</pages>
<contexts>
<context position="3144" citStr="Ellis, 2002" startWordPosition="458" endWordPosition="459">vices, the continuity hypothesis, and top-down, rulegoverned, processing, bringing back data-driven, emergent accounts of linguistic systematicities. Frequency, learning, and language come together in usage-based approaches which hold that we learn linguistic constructions while engaging in communication. The last 50 years of psycholinguistic research provides the evidence of usagebased acquisition in its demonstrations that language processing is exquisitely sensitive to usage frequency at all levels of language representation from phonology, through lexis and syntax, to sentence processing (Ellis, 2002). Language knowledge involves statistical knowledge, so humans learn more easily and process more fluently high frequency forms and ‘regular’ patterns which are exemplified by many types and which have few competitors. Psycholinguistic perspectives thus hold that language learning is the associative learning of representations that reflect the probabilities of occurrence of form-function mappings. Frequency is a key determinant of acquisition because ‘rules’ of language, at all levels of analysis from phonology, through syntax, to discourse, are structural regularities which emerge from learne</context>
<context position="4602" citStr="Ellis, 2002" startWordPosition="663" endWordPosition="664"> language usage. Constructionist accounts of language acquisition thus involve the distributional analysis of the language stream and the parallel analysis of contingent perceptuo-motor activ9 Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 9–16, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ity, with abstract constructions being learned as categories from the conspiracy of concrete exemplars of usage following statistical learning mechanisms (Bod, Hay, &amp; Jannedy, 2003; Bybee &amp; Hopper, 2001; Ellis, 2002) relating input and learner cognition. Psychological analyses of the learning of constructions as form-meaning pairs is informed by the literature on the associative learning of cue-outcome contingencies where the usual determinants include: (1) input frequency (typetoken frequency, Zipfian distribution, recency), (2) form (salience and perception), (3) function (prototypicality of meaning, importance of form for message comprehension, redundancy), and (4) interactions between these (contingency of form-function mapping) (Ellis &amp; Cadierno, 2009). 2 Determinants of construction learning In natu</context>
</contexts>
<marker>Ellis, 2002</marker>
<rawString>Ellis, N.C. (2002). Frequency effects in language processing: A review with implications for theories of implicit and explicit language acquisition. Studies in Second Language Acquisition, 24 (2), 143-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N C Ellis</author>
<author>T Cadierno</author>
</authors>
<title>Constructing a second language.</title>
<date>2009</date>
<journal>Annual Review of Cognitive Linguistics,</journal>
<volume>7</volume>
<note>(Special section).</note>
<contexts>
<context position="5153" citStr="Ellis &amp; Cadierno, 2009" startWordPosition="736" endWordPosition="739">echanisms (Bod, Hay, &amp; Jannedy, 2003; Bybee &amp; Hopper, 2001; Ellis, 2002) relating input and learner cognition. Psychological analyses of the learning of constructions as form-meaning pairs is informed by the literature on the associative learning of cue-outcome contingencies where the usual determinants include: (1) input frequency (typetoken frequency, Zipfian distribution, recency), (2) form (salience and perception), (3) function (prototypicality of meaning, importance of form for message comprehension, redundancy), and (4) interactions between these (contingency of form-function mapping) (Ellis &amp; Cadierno, 2009). 2 Determinants of construction learning In natural language, Zipf’s law (Zipf, 1935) describes how a handful of the highest frequency words account for the most linguistic tokens. Zipf’s law states that the frequency of words decreases as a power function of their rank in the frequency table. If pf is the proportion of words whose frequency rank in a given language sample is f, then pf ~ f -b, with b ≈ 1. Zipf showed this scaling relation holds across a wide variety of language samples. Subsequent research provides support for this law as a linguistic universal: many language events (e.g., f</context>
</contexts>
<marker>Ellis, Cadierno, 2009</marker>
<rawString>Ellis, N.C., &amp; Cadierno, T. (2009). Constructing a second language. Annual Review of Cognitive Linguistics, 7 (Special section).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N C Ellis</author>
<author>F Ferreira-Junior</author>
</authors>
<title>Constructions and their acquisition: Islands and the distinctiveness of their occupancy.</title>
<date>2009</date>
<journal>Annual Review of Cognitive Linguistics,</journal>
<pages>111--139</pages>
<contexts>
<context position="6680" citStr="Ellis and Ferreira-Junior (2009)" startWordPosition="984" endWordPosition="987"> a variety of verb-argument constructions (VACs), there is a strong tendency for one single verb to occur with very high frequency in comparison to other verbs used, a profile which closely mirrors that of the mothers’ speech to these children. Goldberg et al. (2004) show that Zipf’s law applies within VACs too, and they argue that this promotes acquisition: tokens of one particular verb account for the lion’s share of instances of each particular argument frame; this pathbreaking verb also is the one with the prototypical meaning from which the construction is derived (see also Ninio, 1999). Ellis and Ferreira-Junior (2009) investigate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first acquire the most frequent, prototypical and generic exemplar. (e.g. put in VOL [verb-object-locative], give in VOO [verb-objectobject], etc.). Acquisition is affected by the frequency distribution of exemplars within each island of the construction, by their prototypicality, and, using a variety of psychological (Shanks, 1995) and corpus linguistic association m</context>
<context position="18106" citStr="Ellis and Ferreira-Junior (2009)" startWordPosition="2831" endWordPosition="2834">Determining the contingency between construction form and function Some verbs are closely tied to a particular construction (for example, give is highly indicative of the ditransitive construction, whereas leave, although it can form a ditransitive, is more often associated with other constructions such as the simple transitive or intransitive). The more reliable the contingency between a cue and an outcome, the more readily an association between them can be learned (Shanks, 1995), so constructions with more faithful verb members are more transparent and thus should be more readily acquired. Ellis and Ferreira-Junior (2009) use ΔP and collostructional analysis measures (Stefanowitsch &amp; Gries, 2003) to show effects of form-function contingency upon L2 VAC acquisition. Others use conditional probabilities to investigate contingency effects in VAC acquisition. This is still an active area of inquiry, and more research is required before we know which statistical measures of form-function contingency are more predictive of acquisition and processing. Meanwhile, the simplest usable measure is one of faithfulness – the proportion of tokens of total verb usage as a whole that appear in this particular construction. For</context>
<context position="21472" citStr="Ellis &amp; Ferreira-Junior, 2009" startWordPosition="3401" endWordPosition="3404">gure 4. Verb type distribution for V Obj Obj Figure 4 shows the plot for verb type frequency of the ditransitive V Obj Obj construction pattern extracted and binned in the same way. Both distributions can be fitted with a straight regression line (R2=0.993). Thus we conclude that the type-token frequency distributions for these constructions are Zipfian. (In future we will investigate the other plot and fitting methods to ensure we have not smoothed the data too much through binning.) Inspection of the construction verb types, from most frequent down, also suggests that, as in prior research (Ellis &amp; Ferreira-Junior, 2009; Goldberg et al., 2004; Ninio, 1999), the most frequent items are prototypical of the construction and more generic in their action semantics. 4.2 Evaluating the roles of frequency distribution and faithfulness in semantic cohesion The second step in evaluating the verb distributions from the construction patterns is to compare a small set of types selected on the basis of a flat type distribution, the (Zipfian) token frequency distribution and a distribution that represents the degree to which a verb is attracted to the particular construction. First we select the top 200 types from the two </context>
</contexts>
<marker>Ellis, Ferreira-Junior, 2009</marker>
<rawString>Ellis, N.C., &amp; Ferreira-Junior, F. (2009). Constructions and their acquisition: Islands and the distinctiveness of their occupancy. Annual Review of Cognitive Linguistics, 111-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>C R Johnson</author>
<author>M R L Petruck</author>
</authors>
<title>Background to Framenet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<volume>16</volume>
<pages>235--250</pages>
<contexts>
<context position="9458" citStr="Fillmore, Johnson, &amp; Petruck, 2003" startWordPosition="1409" endWordPosition="1413">the COBUILD pattern grammar project. This generates (1) a list of verb types that occupy each construction. We next tally the frequency profiles of these verbs to produce (2) a frequency ranked type-token distribution for these verbs, and we determine the degree to which 10 this is Zipfian. Since some verbs are faithful to one construction while others are more promiscuous, we next produce (3) a contingency-weighted list which reflects their statistical association. 3 Method As a starting point, we considered several of the major theories and datasets of construction grammar such as FrameNet (Fillmore, Johnson, &amp; Petruck, 2003). However, because our research aims to empirically determine the semantic associations of particular linguistic forms, it is important that such forms are initially defined by bottom-up means that are semantics-free. There is no one in corpus linguistics who ‘trusts the text’ more than Sinclair (2004). Therefore we chose the Pattern Grammar (Francis et al. 1996) definition of Verb constructions that arose out of his Cobuild project. 3.1 Construction inventory: COBUILD Verb Patterns The form-based patterns described in the COBUILD Verb Patterns volume (Francis et al. 1996) take the form of wo</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Fillmore, C. J., Johnson, C. R., &amp; Petruck, M. R. L. (2003). Background to Framenet. International Journal of Lexicography, 16, 235-250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Francis</author>
<author>S Hunston</author>
<author>E Manning</author>
</authors>
<date>1996</date>
<booktitle>Grammar Patterns 1: Verbs. The COBUILD Series.</booktitle>
<location>London: Harper Collins.</location>
<contexts>
<context position="9824" citStr="Francis et al. 1996" startWordPosition="1469" endWordPosition="1472">next produce (3) a contingency-weighted list which reflects their statistical association. 3 Method As a starting point, we considered several of the major theories and datasets of construction grammar such as FrameNet (Fillmore, Johnson, &amp; Petruck, 2003). However, because our research aims to empirically determine the semantic associations of particular linguistic forms, it is important that such forms are initially defined by bottom-up means that are semantics-free. There is no one in corpus linguistics who ‘trusts the text’ more than Sinclair (2004). Therefore we chose the Pattern Grammar (Francis et al. 1996) definition of Verb constructions that arose out of his Cobuild project. 3.1 Construction inventory: COBUILD Verb Patterns The form-based patterns described in the COBUILD Verb Patterns volume (Francis et al. 1996) take the form of word class and lexis combinations, such as V across n, V into n and V n n. For each of these patterns the resource provides information as to the structural configurations and functional/meaning groups found around these patterns through detailed concordance analysis of the Bank of English corpus during the construction of the COBUILD dictionary. For instance, the f</context>
<context position="26971" citStr="Francis et al (1996)" startWordPosition="4366" endWordPosition="4369">dNet verb hierarchies are much flatter and bushier than those for nouns, where these measures are more successful. For verbs, distance down a synset is less telling than distance across. As a result, we are exploring other measures of the semantic similarity of verbs informed by network science. We are also exploring the use of word sense disambiguation techniques to reduce problems introduced by the rich polysemy of verbs in WordNet (e.g. give is assigned to 44 different synsets) and also in Roget’s. Future work We plan to apply these methods to the full range of English VACs as described in Francis et al (1996) 15 and other construction grammars too. We are particularly interested in whether the inventory represents an optimal partitioning of verb semantics, starting with basic categories of action semantics and proceeding to greater specificity via Zipfian mapping. We are also interested in extending these approaches to learner language to investigate whether first and second language learners’ acquisition follows the construction distributional profiles and whether the factors outlined in Goldberg et al. (2004) facilitate acquisition. There have been suggestions that Zipfian typetoken frequency di</context>
</contexts>
<marker>Francis, Hunston, Manning, 1996</marker>
<rawString>Francis, G., Hunston, S., &amp; Manning, E. (Eds.). (1996). Grammar Patterns 1: Verbs. The COBUILD Series. London: Harper Collins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Goldberg</author>
</authors>
<title>Constructions at work: The nature of generalization in language. Oxford:</title>
<date>2006</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1969" citStr="Goldberg, 2006" startWordPosition="294" endWordPosition="295">bs occupying each construction using semantic similarity measures. From inspection, this seems to be so. We are developing measures of this using network measures of clustering in the verb-space defined by WordNet and Roget’s Thesaurus. 1 Construction grammar and Usage Constructions are form-meaning mappings, conventionalized in the speech community, and entrenched as language knowledge in the learner’s mind. They are the symbolic units of language relating the defining properties of their morphological, lexical, and syntactic form with particular semantic, pragmatic, and discourse functions (Goldberg, 2006). Construction Grammar argues that all grammatical phenomena can be understood as learned pairings of form (from morphemes, words, idioms, to partially lexically filled and fully general phrasal patterns) and their associated semantic or discourse functions: “the network of constructions captures our grammatical knowledge in toto, i.e. It’s constructions all the way down” (Goldberg, 2006, p. 18). Such beliefs, increasingly influential in the study of child language acquisition, have turned upside down generative assumptions of innate language acquisition devices, the continuity hypothesis, and</context>
</contexts>
<marker>Goldberg, 2006</marker>
<rawString>Goldberg, A.E. (2006). Constructions at work: The nature of generalization in language. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Goldberg</author>
<author>D M Casenhiser</author>
<author>N Sethuraman</author>
</authors>
<title>Learning argument structure generalizations.</title>
<date>2004</date>
<journal>Cognitive Linguistics,</journal>
<volume>15</volume>
<pages>289--316</pages>
<contexts>
<context position="6315" citStr="Goldberg et al. (2004)" startWordPosition="927" endWordPosition="930">law as a linguistic universal: many language events (e.g., frequencies of phoneme and letter strings, of words, of grammatical constructs, of formulaic phrases, etc.) across scales of analysis follow this law (Sole, Murtra, Valverde, &amp; Steels, 2005). Goldberg, Casenhiser &amp; Sethuraman (2004) demonstrated that in samples of child language acquisition, for a variety of verb-argument constructions (VACs), there is a strong tendency for one single verb to occur with very high frequency in comparison to other verbs used, a profile which closely mirrors that of the mothers’ speech to these children. Goldberg et al. (2004) show that Zipf’s law applies within VACs too, and they argue that this promotes acquisition: tokens of one particular verb account for the lion’s share of instances of each particular argument frame; this pathbreaking verb also is the one with the prototypical meaning from which the construction is derived (see also Ninio, 1999). Ellis and Ferreira-Junior (2009) investigate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first</context>
<context position="21495" citStr="Goldberg et al., 2004" startWordPosition="3405" endWordPosition="3408">for V Obj Obj Figure 4 shows the plot for verb type frequency of the ditransitive V Obj Obj construction pattern extracted and binned in the same way. Both distributions can be fitted with a straight regression line (R2=0.993). Thus we conclude that the type-token frequency distributions for these constructions are Zipfian. (In future we will investigate the other plot and fitting methods to ensure we have not smoothed the data too much through binning.) Inspection of the construction verb types, from most frequent down, also suggests that, as in prior research (Ellis &amp; Ferreira-Junior, 2009; Goldberg et al., 2004; Ninio, 1999), the most frequent items are prototypical of the construction and more generic in their action semantics. 4.2 Evaluating the roles of frequency distribution and faithfulness in semantic cohesion The second step in evaluating the verb distributions from the construction patterns is to compare a small set of types selected on the basis of a flat type distribution, the (Zipfian) token frequency distribution and a distribution that represents the degree to which a verb is attracted to the particular construction. First we select the top 200 types from the two VACs, ordered by token </context>
<context position="27483" citStr="Goldberg et al. (2004)" startWordPosition="4441" endWordPosition="4444">ure work We plan to apply these methods to the full range of English VACs as described in Francis et al (1996) 15 and other construction grammars too. We are particularly interested in whether the inventory represents an optimal partitioning of verb semantics, starting with basic categories of action semantics and proceeding to greater specificity via Zipfian mapping. We are also interested in extending these approaches to learner language to investigate whether first and second language learners’ acquisition follows the construction distributional profiles and whether the factors outlined in Goldberg et al. (2004) facilitate acquisition. There have been suggestions that Zipfian typetoken frequency distributions are essentially uninteresting artifacts. For each motivated construction identified along the lines described in 3.3, we have begun to make matching random control distributions generated as a random selection of verb types of comparable n types and tokens (yoked ersatzcontrols). For each of our outcome measures, we will compare the various scores for VAC verbtypes gathered on the principled basis of construction-grammar against those for their controls. Conclusions Meanwhile, these pilot studie</context>
</contexts>
<marker>Goldberg, Casenhiser, Sethuraman, 2004</marker>
<rawString>Goldberg, A.E., Casenhiser, D.M., &amp; Sethuraman, N. (2004). Learning argument structure generalizations. Cognitive Linguistics, 15, 289–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S T Gries</author>
<author>A Stefanowitsch</author>
</authors>
<title>Extending collostructional analysis: a corpus-based perspective on ‘alternations’.</title>
<date>2004</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>9</volume>
<pages>97--129</pages>
<contexts>
<context position="7316" citStr="Gries &amp; Stefanowitsch, 2004" startWordPosition="1074" endWordPosition="1077">gate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first acquire the most frequent, prototypical and generic exemplar. (e.g. put in VOL [verb-object-locative], give in VOO [verb-objectobject], etc.). Acquisition is affected by the frequency distribution of exemplars within each island of the construction, by their prototypicality, and, using a variety of psychological (Shanks, 1995) and corpus linguistic association metrics (Gries &amp; Stefanowitsch, 2004), by their contingency of form-function mapping. This fundamental claim that Zipfian distributional properties of language usage helps to make language learnable has thus begun to be explored for these three VACs, at least. It remains an important research agenda to explore its generality across a wide range of constructions (i.e. the constructicon). The primary motivation of construction grammar is that we must bring together linguistic form, learner cognition, and usage. An important consequence is that constructions cannot be defined purely on the basis of linguistic form, or semantics, or </context>
</contexts>
<marker>Gries, Stefanowitsch, 2004</marker>
<rawString>Gries, S.T., &amp; Stefanowitsch, A. (2004). Extending collostructional analysis: a corpus-based perspective on ‘alternations’. International Journal of Corpus Linguistics, 9, 97-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennedy</author>
</authors>
<title>The Open Roget’s Project: Electronic lexical knowledge base.</title>
<date>2009</date>
<journal>Retr.</journal>
<volume>1</volume>
<note>http://rogets.site.uottawa.ca/index.shtml</note>
<contexts>
<context position="16399" citStr="Kennedy, 2009" startWordPosition="2561" endWordPosition="2562">of verb types occupying the constructions We considered several ways of analyzing the semantics the resulting verb distributions. It is important that the semantic measures we employ are defined in a way that is free of linguistic distributional information, otherwise we would be building in circularity. Therefore methods such as LSA are not applicable here. Instead, our research utilizes two distribution-free semantic databases: (1) Roget’s thesaurus, a classic lexical resource of longstanding proven utility, based on Roget’s guided introspections, as implemented in the Open Roget’s Project (Kennedy, 2009). This provides various algorithms for measuring the semantic similarity between terms and between sentences. (2) WordNet, based upon psycholinguistic theory and in development since 1985 (Miller, 2009). WordNet classes words into a hierarchical network. At the top level, the hierarchy for verbs is organized into 15 base types (such as move1 expressing translational movement and move2 movement without displacement, communicate, etc.) which then split into over 11,500 verb synonym sets or synsets. Construction Types Tokens V across n V Obj Obj 663 9183 799 4889 TTR 7.22 16.34 12 Verbs are linke</context>
</contexts>
<marker>Kennedy, 2009</marker>
<rawString>Kennedy, A. (2009). The Open Roget’s Project: Electronic lexical knowledge base. Retr. 1st March, 2010: http://rogets.site.uottawa.ca/index.shtml</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Mason</author>
<author>S Hunston</author>
</authors>
<title>The automatic recognition of verb patterns: A feasibility study.</title>
<date>2004</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>9</volume>
<pages>253--270</pages>
<contexts>
<context position="12460" citStr="Mason &amp; Hunston, 2004" startWordPosition="1916" endWordPosition="1919">l suited for the task. 3.2 Corpus: BNC XML Parsed The analysis of verb type-token distribution in the kinds of construction patterns described in the previous section should ideally be carried out using a range of corpora in the magnitude of the tens or hundreds of millions of words as the original work is derived from the Bank of English (a growing monitor corpus of over 400 million words). These corpora should, at the least, be part-of-speech tagged to search for the pattern as specified. Further some kind of partial parsing and chunking is necessary to apply the structural constraints (see Mason &amp; Hunston, 2004 for exploratory methodology). We chose to use the 100 million word British National Corpus (BNC) on account of its size, the breadth of genres it contains and consistent lemmatization and part-of-speech tagging. Andersen et al. (2008) parsed the XML version of the BNC using the RASP parser (Briscoe, Carroll, &amp; Watson, 2006). RASP is a statistical featurebased parser that produces a probabilistically ordered set of parse trees for a given sentence and additionally a set of grammatical relations (GRs) that capture “those aspects of predicate-argument structure that the system is able to recover</context>
</contexts>
<marker>Mason, Hunston, 2004</marker>
<rawString>Mason, O., &amp; Hunston, S. (2004). The automatic recognition of verb patterns: A feasibility study. International Journal of Corpus Linguistics, 9, 253-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet - About us. Retrieved</title>
<date>2009</date>
<note>from http://wordnet.princeton.edu</note>
<contexts>
<context position="16601" citStr="Miller, 2009" startWordPosition="2590" endWordPosition="2591"> that is free of linguistic distributional information, otherwise we would be building in circularity. Therefore methods such as LSA are not applicable here. Instead, our research utilizes two distribution-free semantic databases: (1) Roget’s thesaurus, a classic lexical resource of longstanding proven utility, based on Roget’s guided introspections, as implemented in the Open Roget’s Project (Kennedy, 2009). This provides various algorithms for measuring the semantic similarity between terms and between sentences. (2) WordNet, based upon psycholinguistic theory and in development since 1985 (Miller, 2009). WordNet classes words into a hierarchical network. At the top level, the hierarchy for verbs is organized into 15 base types (such as move1 expressing translational movement and move2 movement without displacement, communicate, etc.) which then split into over 11,500 verb synonym sets or synsets. Construction Types Tokens V across n V Obj Obj 663 9183 799 4889 TTR 7.22 16.34 12 Verbs are linked in the hierarchy according to relations such as hypernym (to move is an hypernym of to walk), and troponym, the term used for hyponymic relations in the verb component of WordNet (to lisp is a tropony</context>
</contexts>
<marker>Miller, 2009</marker>
<rawString>Miller, G. A. (2009). WordNet - About us. Retrieved March 1, 2010, from http://wordnet.princeton.edu</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ninio</author>
</authors>
<title>Pathbreaking verbs in syntactic development and the question of prototypical transitivity.</title>
<date>1999</date>
<journal>Journal of Child Language,</journal>
<volume>26</volume>
<pages>619--653</pages>
<contexts>
<context position="6646" citStr="Ninio, 1999" startWordPosition="982" endWordPosition="983">quisition, for a variety of verb-argument constructions (VACs), there is a strong tendency for one single verb to occur with very high frequency in comparison to other verbs used, a profile which closely mirrors that of the mothers’ speech to these children. Goldberg et al. (2004) show that Zipf’s law applies within VACs too, and they argue that this promotes acquisition: tokens of one particular verb account for the lion’s share of instances of each particular argument frame; this pathbreaking verb also is the one with the prototypical meaning from which the construction is derived (see also Ninio, 1999). Ellis and Ferreira-Junior (2009) investigate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first acquire the most frequent, prototypical and generic exemplar. (e.g. put in VOL [verb-object-locative], give in VOO [verb-objectobject], etc.). Acquisition is affected by the frequency distribution of exemplars within each island of the construction, by their prototypicality, and, using a variety of psychological (Shanks, 1995) a</context>
<context position="21509" citStr="Ninio, 1999" startWordPosition="3409" endWordPosition="3410">shows the plot for verb type frequency of the ditransitive V Obj Obj construction pattern extracted and binned in the same way. Both distributions can be fitted with a straight regression line (R2=0.993). Thus we conclude that the type-token frequency distributions for these constructions are Zipfian. (In future we will investigate the other plot and fitting methods to ensure we have not smoothed the data too much through binning.) Inspection of the construction verb types, from most frequent down, also suggests that, as in prior research (Ellis &amp; Ferreira-Junior, 2009; Goldberg et al., 2004; Ninio, 1999), the most frequent items are prototypical of the construction and more generic in their action semantics. 4.2 Evaluating the roles of frequency distribution and faithfulness in semantic cohesion The second step in evaluating the verb distributions from the construction patterns is to compare a small set of types selected on the basis of a flat type distribution, the (Zipfian) token frequency distribution and a distribution that represents the degree to which a verb is attracted to the particular construction. First we select the top 200 types from the two VACs, ordered by token frequency. The</context>
</contexts>
<marker>Ninio, 1999</marker>
<rawString>Ninio, A. (1999). Pathbreaking verbs in syntactic development and the question of prototypical transitivity. Journal of Child Language, 26, 619-653.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet::Similarity Ð Measuring the Relatedness of Concepts.</title>
<date>2004</date>
<booktitle>Proceedings of Fifth Annual Meeting of the North American Chapter of the Association of Computational Linguistics (NAACL</booktitle>
<contexts>
<context position="17468" citStr="Pedersen et al. 2004" startWordPosition="2733" endWordPosition="2736"> split into over 11,500 verb synonym sets or synsets. Construction Types Tokens V across n V Obj Obj 663 9183 799 4889 TTR 7.22 16.34 12 Verbs are linked in the hierarchy according to relations such as hypernym (to move is an hypernym of to walk), and troponym, the term used for hyponymic relations in the verb component of WordNet (to lisp is a troponym of to talk). There are various algorithms to determine the semantic similarity between synsets in WordNet which consider the distance between the conceptual categories of words, as well as considering the hierarchical structure of the WordNet (Pedersen et al. 2004). 3.5 Determining the contingency between construction form and function Some verbs are closely tied to a particular construction (for example, give is highly indicative of the ditransitive construction, whereas leave, although it can form a ditransitive, is more often associated with other constructions such as the simple transitive or intransitive). The more reliable the contingency between a cue and an outcome, the more readily an association between them can be learned (Shanks, 1995), so constructions with more faithful verb members are more transparent and thus should be more readily acqu</context>
<context position="23585" citStr="Pedersen et al. (2004)" startWordPosition="3768" endWordPosition="3771">for the ‘faithfulness list’. Tables 2 and 3 contain these lists for the two constructions. An intuitive reading of these lists suggests that the tokens list captures the most general and prototypical senses (walk, move etc. for V across n and give, make, tell, offer for V Obj Obj), while the list ordered by tokenized faith highlights some quite construction specific (and low frequency) items, such as scud, flit and flicker for V across n. The final component is to quantify the semantic coherence or ‘clumpiness’ of the verbs extracted in the previous steps. For this we use WordNet and Roget’s. Pedersen et al. (2004) outline six measures in their Perl WordNet::Similarity package, three (path, lch and wup) based on the path length between concepts in WordNet Synsets and three (res, jcn and lin) that incorporate a measure called ‘information content’ related to concept specificity. Tables 4 and 5 show the simi14 larity scores that result from taking the 20 types in each of the lists in Tables 2 and 3 and generating a 20 by 20 distance matrix. types (sample) tokens faithfulness 1 scuttle come spread 2 ride walk scud 3 paddle cut sprawl 4 communicate run cut 5 rise spread walk 6 stare move come 7 drift look s</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet::Similarity Ð Measuring the Relatedness of Concepts. Proceedings of Fifth Annual Meeting of the North American Chapter of the Association of Computational Linguistics (NAACL 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Shanks</author>
</authors>
<title>The psychology of associative learning.</title>
<date>1995</date>
<publisher>Cambridge University Press.</publisher>
<location>New York:</location>
<contexts>
<context position="7244" citStr="Shanks, 1995" startWordPosition="1067" endWordPosition="1068">so Ninio, 1999). Ellis and Ferreira-Junior (2009) investigate effects upon naturalistic second language acquisition of type/token distributions in three English verbargument constructions. They show that VAC verb type/token distribution in the input is Zipfian and that learners first acquire the most frequent, prototypical and generic exemplar. (e.g. put in VOL [verb-object-locative], give in VOO [verb-objectobject], etc.). Acquisition is affected by the frequency distribution of exemplars within each island of the construction, by their prototypicality, and, using a variety of psychological (Shanks, 1995) and corpus linguistic association metrics (Gries &amp; Stefanowitsch, 2004), by their contingency of form-function mapping. This fundamental claim that Zipfian distributional properties of language usage helps to make language learnable has thus begun to be explored for these three VACs, at least. It remains an important research agenda to explore its generality across a wide range of constructions (i.e. the constructicon). The primary motivation of construction grammar is that we must bring together linguistic form, learner cognition, and usage. An important consequence is that constructions can</context>
<context position="17960" citStr="Shanks, 1995" startWordPosition="2812" endWordPosition="2813">e conceptual categories of words, as well as considering the hierarchical structure of the WordNet (Pedersen et al. 2004). 3.5 Determining the contingency between construction form and function Some verbs are closely tied to a particular construction (for example, give is highly indicative of the ditransitive construction, whereas leave, although it can form a ditransitive, is more often associated with other constructions such as the simple transitive or intransitive). The more reliable the contingency between a cue and an outcome, the more readily an association between them can be learned (Shanks, 1995), so constructions with more faithful verb members are more transparent and thus should be more readily acquired. Ellis and Ferreira-Junior (2009) use ΔP and collostructional analysis measures (Stefanowitsch &amp; Gries, 2003) to show effects of form-function contingency upon L2 VAC acquisition. Others use conditional probabilities to investigate contingency effects in VAC acquisition. This is still an active area of inquiry, and more research is required before we know which statistical measures of form-function contingency are more predictive of acquisition and processing. Meanwhile, the simples</context>
</contexts>
<marker>Shanks, 1995</marker>
<rawString>Shanks, D. R. (1995). The psychology of associative learning. New York: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sinclair</author>
</authors>
<title>Trust the text: Language, corpus and discourse.</title>
<date>2004</date>
<location>London: Routledge.</location>
<contexts>
<context position="9762" citStr="Sinclair (2004)" startWordPosition="1460" endWordPosition="1461">o one construction while others are more promiscuous, we next produce (3) a contingency-weighted list which reflects their statistical association. 3 Method As a starting point, we considered several of the major theories and datasets of construction grammar such as FrameNet (Fillmore, Johnson, &amp; Petruck, 2003). However, because our research aims to empirically determine the semantic associations of particular linguistic forms, it is important that such forms are initially defined by bottom-up means that are semantics-free. There is no one in corpus linguistics who ‘trusts the text’ more than Sinclair (2004). Therefore we chose the Pattern Grammar (Francis et al. 1996) definition of Verb constructions that arose out of his Cobuild project. 3.1 Construction inventory: COBUILD Verb Patterns The form-based patterns described in the COBUILD Verb Patterns volume (Francis et al. 1996) take the form of word class and lexis combinations, such as V across n, V into n and V n n. For each of these patterns the resource provides information as to the structural configurations and functional/meaning groups found around these patterns through detailed concordance analysis of the Bank of English corpus during t</context>
</contexts>
<marker>Sinclair, 2004</marker>
<rawString>Sinclair, J. (2004). Trust the text: Language, corpus and discourse. London: Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R V Sol6</author>
<author>B Murtra</author>
<author>S Valverde</author>
<author>L Steels</author>
</authors>
<title>Language Networks: their structure, function and evolution.</title>
<date>2005</date>
<journal>Trends in Cognitive Sciences,</journal>
<volume>12</volume>
<marker>Sol6, Murtra, Valverde, Steels, 2005</marker>
<rawString>Sol6, R. V., Murtra, B., Valverde, S., &amp; Steels, L. (2005). Language Networks: their structure, function and evolution. Trends in Cognitive Sciences, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stefanowitsch</author>
<author>S T Gries</author>
</authors>
<title>Collostructions: Investigating the interaction between words and constructions.</title>
<date>2003</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>8</volume>
<pages>209--243</pages>
<contexts>
<context position="18182" citStr="Stefanowitsch &amp; Gries, 2003" startWordPosition="2841" endWordPosition="2844">e closely tied to a particular construction (for example, give is highly indicative of the ditransitive construction, whereas leave, although it can form a ditransitive, is more often associated with other constructions such as the simple transitive or intransitive). The more reliable the contingency between a cue and an outcome, the more readily an association between them can be learned (Shanks, 1995), so constructions with more faithful verb members are more transparent and thus should be more readily acquired. Ellis and Ferreira-Junior (2009) use ΔP and collostructional analysis measures (Stefanowitsch &amp; Gries, 2003) to show effects of form-function contingency upon L2 VAC acquisition. Others use conditional probabilities to investigate contingency effects in VAC acquisition. This is still an active area of inquiry, and more research is required before we know which statistical measures of form-function contingency are more predictive of acquisition and processing. Meanwhile, the simplest usable measure is one of faithfulness – the proportion of tokens of total verb usage as a whole that appear in this particular construction. For illustration, the faithfulness of give to the ditransitive is approximately</context>
</contexts>
<marker>Stefanowitsch, Gries, 2003</marker>
<rawString>Stefanowitsch, A., &amp; Gries, S.T. (2003). Collostructions: Investigating the interaction between words and constructions. International Journal of Corpus Linguistics, 8, 209-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>The psycho-biology of language: An introduction to dynamic philology.</title>
<date>1935</date>
<publisher>The M.I.T. Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="5239" citStr="Zipf, 1935" startWordPosition="750" endWordPosition="751">r cognition. Psychological analyses of the learning of constructions as form-meaning pairs is informed by the literature on the associative learning of cue-outcome contingencies where the usual determinants include: (1) input frequency (typetoken frequency, Zipfian distribution, recency), (2) form (salience and perception), (3) function (prototypicality of meaning, importance of form for message comprehension, redundancy), and (4) interactions between these (contingency of form-function mapping) (Ellis &amp; Cadierno, 2009). 2 Determinants of construction learning In natural language, Zipf’s law (Zipf, 1935) describes how a handful of the highest frequency words account for the most linguistic tokens. Zipf’s law states that the frequency of words decreases as a power function of their rank in the frequency table. If pf is the proportion of words whose frequency rank in a given language sample is f, then pf ~ f -b, with b ≈ 1. Zipf showed this scaling relation holds across a wide variety of language samples. Subsequent research provides support for this law as a linguistic universal: many language events (e.g., frequencies of phoneme and letter strings, of words, of grammatical constructs, of form</context>
</contexts>
<marker>Zipf, 1935</marker>
<rawString>Zipf, G. K. (1935). The psycho-biology of language: An introduction to dynamic philology. Cambridge, MA: The M.I.T. Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>