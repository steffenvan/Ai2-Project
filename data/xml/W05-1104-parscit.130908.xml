<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9962495">
Designing an Extensible API for
Integrating Language Modeling and Realization
</title>
<author confidence="0.998186">
Michael White
</author>
<affiliation confidence="0.9978735">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.953367">
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.95644">
http://www.iccs.informatics.ed.ac.uk/~mwhite/
</email>
<sectionHeader confidence="0.99481" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999951782608696">
We present an extensible API for inte-
grating language modeling and realiza-
tion, describing its design and efficient
implementation in the OpenCCG sur-
face realizer. With OpenCCG, language
models may be used to select realiza-
tions with preferred word orders, pro-
mote alignment with a conversational
partner, avoid repetitive language use,
and increase the speed of the best-first
anytime search. The API enables a vari-
ety of n-gram models to be easily com-
bined and used in conjunction with ap-
propriate edge pruning strategies. The
n-gram models may be of any order,
operate in reverse (“right-to-left”), and
selectively replace certain words with
their semantic classes. Factored lan-
guage models with generalized backoff
may also be employed, over words rep-
resented as bundles of factors such as
form, pitch accent, stem, part of speech,
supertag, and semantic class.
</bodyText>
<sectionHeader confidence="0.995644" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.639807166666667">
The OpenCCG1 realizer (White and Baldridge,
2003; White, 2004a; White, 2004c) is an open
source surface realizer for Steedman’s (2000a;
2000b) Combinatory Categorial Grammar (CCG).
It is designed to be the first practical, reusable re-
alizer for CCG, and includes implementations of
</bodyText>
<footnote confidence="0.923583">
1http://openccg.sourceforge.net
</footnote>
<bodyText confidence="0.999427650793651">
CCG’s unique accounts of coordination and infor-
mation structure–based prosody.
Like other surface realizers, the OpenCCG re-
alizer takes as input a logical form specifying the
propositional meaning of a sentence, and returns
one or more surface strings that express this mean-
ing according to the lexicon and grammar. A dis-
tinguishing feature of OpenCCG is that it imple-
ments a hybrid symbolic-statistical chart realiza-
tion algorithm that combines (1) a theoretically
grounded approach to syntax and semantic com-
position, with (2) the use of integrated language
models for making choices among the options
left open by the grammar (thereby reducing the
need for hand-crafted rules). In contrast, previous
chart realizers (Kay, 1996; Shemtov, 1997; Car-
roll et al., 1999; Moore, 2002) have not included
a statistical component, while previous statisti-
cal realizers (Knight and Hatzivassiloglou, 1995;
Langkilde, 2000; Bangalore and Rambow, 2000;
Langkilde-Geary, 2002; Oh and Rudnicky, 2002;
Ratnaparkhi, 2002) have employed less general
approaches to semantic representation and com-
position, and have not typically made use of fine-
grained logical forms that include specifications
of such information structural notions as theme,
rheme and focus.
In this paper, we present OpenCCG’s extensi-
ble API (application programming interface) for
integrating language modeling and realization, de-
scribing its design and efficient implementation in
Java. With OpenCCG, language models may be
used to select realizations with preferred word or-
ders (White, 2004c), promote alignment with a
conversational partner (Brockmann et al., 2005),
and avoid repetitive language use. In addition,
by integrating language model scoring into the
search, it also becomes possible to use more accu-
rate models to improve realization times, when the
realizer is run in anytime mode (White, 2004b).
To allow language models to be combined
in flexible ways—as well as to enable research
on how to best combine language modeling and
realization—OpenCCG’s design includes inter-
faces that allow user-defined functions to be used
for scoring partial realizations and for pruning
low-scoring ones during the search. The design
also includes classes for supporting a range of
language models and typical ways of combining
them. As we shall see, experience to date indi-
cates that the benefits of employing a highly gen-
eralized approach to scoring and pruning can be
enjoyed with little or no loss of performance.
The rest of this paper is organized as follows.
Section 2 gives an overview of the realizer archi-
tecture, highlighting the role of the interfaces for
plugging in custom scoring and pruning functions,
and illustrating how n-gram scoring affects accu-
racy and speed. Sections 3 and 4 present Open-
CCG’s classes for defining scoring and pruning
functions, respectively, giving examples of their
usage. Finally, Section 5 summarizes the design
and concludes with a discussion of future work.
</bodyText>
<sectionHeader confidence="0.99302" genericHeader="method">
2 Realizer Overview
</sectionHeader>
<bodyText confidence="0.999564409090909">
The UML class diagram in Figure 1 shows the
high-level architecture of the OpenCCG realizer;
sample Java code for using the realizer appears in
Figure 2. A realizer instance is constructed with
a reference to a CCG grammar (which supports
both parsing and realization). The grammar’s lex-
icon has methods for looking up lexical items via
their surface forms (for parsing), or via the prin-
cipal predicates or relations in their semantics (for
realization). A grammar also has a set of hierar-
chically organized atomic types, which can serve
as the values of features in the syntactic categories,
or as ontological sorts for the discourse referents
in the logical forms (LFs).
Lexical lookup yields lexical signs. A sign pairs
a list of words with a category, which itself pairs
a syntactic category with a logical form. Lexical
signs are combined into derived signs using the
rules in the grammar’s rule group. Derived signs
maintain a derivation history, and their word lists
share structure with the word lists of their input
signs.
As mentioned in the introduction, for general-
ity, the realizer makes use of a configurable sign
scorer and pruning strategy. A sign scorer imple-
ments a function that returns a number between
0 and 1 for an input sign. For example, a stan-
dard trigram language model can be used to im-
plement a sign scorer, by returning the probability
of a sign’s words as its score. A pruning strat-
egy implements a method for determining which
edges to prune during the realizer’s search. The
input to the method is a ranked list of edges for
signs that have equivalent categories (but different
words); grouping edges in this way ensures that
pruning cannot “break” the realizer, i.e. prevent it
from finding some grammatical derivation when
one exists. By default, an N-best pruning strategy
is employed, which keeps the N highest scoring in-
put edges, pruning the rest (where N is determined
by the current preference settings).
The realization algorithm is implemented by the
realize method. As in the chart realizers cited
earlier, the algorithm makes use of a chart and
an agenda to perform a bottom-up dynamic pro-
gramming search for signs whose LFs completely
cover the elementary predications in the input log-
ical form. See Figure 9 (Section 3.1) for a real-
ization trace; the algorithm’s details and a worked
example appear in (White, 2004a; White, 2004c).
The realize method returns the edge for the best
realization of the input LF, as determined by the
sign scorer. After a realization request, the N-best
complete edges—or more generally, all the edges
for complete realizations that survived pruning—
are also available from the chart.
The search for complete realizations proceeds
in one of two modes, anytime and two-stage
(packing/unpacking). In the anytime mode, a best-
first search is performed with a configurable time
limit (which may be a limit on how long to look
for a better realization, after the first complete one
is found). With this mode, the scores assigned by
the sign scorer determine the order of the edges
on the agenda, and thus have an impact on realiza-
tion speed. In the two-stage mode, a packed forest
</bodyText>
<figure confidence="0.983535954545454">
*
After a realization request, the N−best edges
are also available from the chart.
Realizer
«interface»
SignScorer
+score(sign: Sign, complete: boolean): double
Lexicon
+getSignsFromWord(...): Set&lt;Sign&gt;
+getSignsFromPred(...): Set&lt;Sign&gt;
+getSignsFromRel(...): Set&lt;Sign&gt;
Types
Grammar
+timeLimitMS: int
+Realizer(grammar: Grammar)
+realize(lf: LF): Edge
+getChart( ): Chart
«interface»
PruningStrategy
Chart
+bestEdge: Edge
+bestEdges( ): List&lt;Edge&gt;
RuleGroup
+applyRules(...): List&lt;Sign&gt;
+getLF( ): LF
Edge
0..2
1..n
Word
Sign
DerivationHistory
The lexico−grammar and signs
are the same for parsing and
realization.
+score: double
+completeness: double
«interface»
Category
A realizer for a CCG grammar makes use of
a configurable sign scorer and pruning strategy.
The realize method takes a logical form (LF)
as input and returns the edge for the best
realization of that LF.
+pruneEdges(edges: List&lt;Edge&gt;): List&lt;Edge&gt;
</figure>
<figureCaption confidence="0.998086">
Figure 1: High-level architecture of the OpenCCG realizer
</figureCaption>
<figure confidence="0.998173647058824">
// load grammar, instantiate realizer
URL grammarURL = ...;
Grammar grammar = new Grammar(grammarURL);
Realizer realizer = new Realizer(grammar);
// configure realizer with trigram backoff model
// and 10-best pruning strategy
realizer.signScorer = new StandardNgramModel(3, &amp;quot;lm.3bo&amp;quot;);
realizer.pruningStrategy = new NBestPruningStrategy(10);
// ... then, for each request:
// get LF from input XML
Document inputDoc = ...;
LF lf = realizer.getLfFromDoc(inputDoc);
// realize LF and get output words in XML
Edge bestEdge = realizer.realize(lf);
Document outputDoc = bestEdge.sign.getWordsInXml();
// return output
... outputDoc ...;
</figure>
<figureCaption confidence="0.999758">
Figure 2: Example realizer usage
</figureCaption>
<bodyText confidence="0.993227307692308">
of all possible realizations is created in the first
stage; then in the second stage, the packed repre-
sentation is unpacked in bottom-up fashion, with
scores assigned to the edge for each sign as it is
unpacked, much as in (Langkilde, 2000). In both
modes, the pruning strategy is invoked to deter-
mine whether to keep or prune newly constructed
edges. For single-best output, the anytime mode
can provide signficant time savings by cutting off
the search early; see (White, 2004c) for discus-
sion. For N-best output—especially when a com-
plete search (up to the edges that survive the prun-
ing strategy) is desirable—the two-stage mode can
be more efficient.
To illustrate how n-gram scoring can guide the
best-first anytime search towards preferred real-
izations and reduce realization times, we repro-
duce in Table 1 and Figures 3 through 5 the cross-
validation tests reported in (White, 2004b). In
these tests, we measured the realizer’s accuracy
and speed, under a variety of configurations, on
the regression test suites for two small but linguis-
tically rich grammars: the English grammar for
the COMIC2 dialogue system—the core of which
is shared with the FLIGHTS system (Moore et al.,
2004)—and the Worldcup grammar discussed in
</bodyText>
<footnote confidence="0.839081">
2http://www.hcrc.ed.ac.uk/comic/
</footnote>
<bodyText confidence="0.99987725925926">
(Baldridge, 2002). Table 1 gives the sizes of the
test suites. Using these two test suites, we timed
how long it took on a 2.2 GHz Linux PC to realize
each logical form under each realizer configura-
tion. To measure accuracy, we counted the num-
ber of times the best scoring realization exactly
matched the target, and also computed a modified
version of the Bleu n-gram precision metric (Pap-
ineni et al., 2001) employed in machine translation
evaluation, using 1- to 4-grams, with the longer
n-grams given more weight (cf. Section 3.4). To
rank candidate realizations, we used standard n-
gram backoff models of orders 2 through 6, with
semantic class replacement, as described in Sec-
tion 3.1. For smoothing, we used Ristad’s nat-
ural discounting (Ristad, 1995), a parameter-free
method that seems to work well with relatively
small amounts of data.
To gauge how the amount of training data af-
fects performance, we ran cross-validation tests
with increasing numbers of folds, with 25 as the
maximum number of folds. We also compared the
realization results using the n-gram scorers with
two baselines and one topline (oracle method).
The first baseline assigns all strings a uniform
score of zero, and adds new edges to the end of the
agenda, corresponding to breadth-first search. The
</bodyText>
<equation confidence="0.804419222222222">
LF/target Unique up Length Input nodes
pairs to SC Mean Min MaxNMean Min Max
5 23 95 6 1
8COMIC 549 219 13.1 6 34 8.482 20
5.226 306.09
Worldcup 276
14.82 138
11 9.2 4 18 6.8 3 13
15 243 5.496 30 13
</equation>
<tableCaption confidence="0.973632">
Table 1: Test suite sizes.
</tableCaption>
<figure confidence="0.972971026315789">
212.674 47818 3 151819 115.2
COMIC: First Worldcup: First
1.04 1.1 1.2 1.33 1.5 2 3 5 10 25
N
Num Folds
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
Time (ms)
200
160
120
80
40
0
1.04 1.1 1.2 1.33 1.5 2 3 5 10 25
3 N
Num Folds
500
400
Time (ms)
300
200
100
0
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
</figure>
<figureCaption confidence="0.989654">
Figure 3: Mean time (in ms.) until first realization is found using n-grams of different orders and Ristad’s
</figureCaption>
<figure confidence="0.983826319148936">
241 41 548 542 542 542 542 549 .5 86 70 200 210 211 211 213 276
2 4 5 7 7 0
natural discounting (N), for cross-validation tests with increasing numbers of folds.
241 41 549 548 548 548 548 549 3 86 70 221 239 238
COMIC: Exact Worldcup: Exact
1.4 1.1 1.2 1.33 1.5 2 3 5 10 25
058 046 08 56 656
Num Folds
0767
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
56
Time (ms)
300
250
200
150
100
50
0 B
1.4 1.1 1.2 1.33 1.5 2 3 5 10 25
0.39 074 03 63 63
Num Folds
0953
600
500
Time (ms)
400
300
200
100
0B
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
63
</figure>
<figureCaption confidence="0.997984">
Figure 4: Number of realizations exactly matching target using n-grams of different orders.
</figureCaption>
<figure confidence="0.983215666666667">
0.379 1 0.999 0999 0999 0.999 1 3 06 0.538 0.901 0.923 0.92 0924 0.924
COMIC: Score Worldcup: Score
1
1
0.8
0.8
0.6
0.6
0.4
0.4
0.2
0.2
0
0
Time (ms)
Time (ms)
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
Baseline 1
Baseline 2
N2
N3
N4
N5
N6
Topline
1.04 1.1 1.2 1.33 1.5 2 3 5 10 25
Num Folds
1.04 1.1 1.2 1.33 1.5 2 3 5 10 25
Num Folds
</figure>
<figureCaption confidence="0.999987">
Figure 5: Modified BLEU scores using n-grams of different orders.
</figureCaption>
<bodyText confidence="0.99990375">
second baseline uses the same scorer, but adds new
edges at the front of the agenda, corresponding to
depth-first search. The topline uses the modified
Bleu score, computing n-gram precision against
just the target string. With this setup, Figures 3-
5 show how initial realization times decrease and
accuracy increases when longer n-grams are em-
ployed. Figure 3 shows that trigrams offer a sub-
stantial speedup over bigrams, while n-grams of
orders 4-6 offer a small further improvement. Fig-
ures 4 and 5 show that with the COMIC test suite,
all n-gram orders work well, while with the World-
cup test suite, n-grams of orders 3-6 offer some
improvement over bigrams.
To conclude this section, we note that together
with OpenCCG’s other efficiency methods, n-
gram scoring has helped to achieve realization
times adequate for interactive use in both the
COMIC and FLIGHTS dialogue systems, along
with very high quality. Estimates indicate that
n-gram scoring typically accounts for only 2-5%
of the time until the best realization is found,
while it can more than double realization speed by
accurately guiding the best-first anytime search.
This experience suggests that more complex scor-
ing models can more than pay for themselves,
efficiency-wise, if they yield significantly more ac-
curate preference orders on edges.
</bodyText>
<sectionHeader confidence="0.999382" genericHeader="method">
3 Classes for Scoring Signs
</sectionHeader>
<bodyText confidence="0.9999802">
The classes for implementing sign scorers appear
in Figure 6. In the diagram, classes for n-gram
scoring appear towards the bottom, while classes
for combining scorers appear on the left, and the
class for avoiding repetition appears on the right.
</bodyText>
<subsectionHeader confidence="0.999578">
3.1 Standard N-gram Models
</subsectionHeader>
<bodyText confidence="0.999979489361702">
The StandardNgramModel class can load stan-
dard n-gram backoff models for scoring, as shown
earlier in Figure 2. Such models can be con-
structed with the SRILM toolkit (Stolcke, 2002),
which we have found to be very useful; in princi-
ple, other toolkits could be used instead, as long as
their output could be converted into the same file
formats. Since the SRILM toolkit has more re-
strictive licensing conditions than those of Open-
CCG’s LGPL license, OpenCCG includes its own
classes for scoring with n-gram models, in order to
avoid any necessary runtime dependencies on the
SRILM toolkit.
The n-gram tables are efficiently stored in a trie
data structure (as in the SRILM toolkit), thereby
avoiding any arbitrary limit on the n-gram order.
To save memory and speed up equality tests, each
string is interned (replaced with a canonical in-
stance) at load time, which accomplishes the same
purpose as replacing the strings with integers, but
without the need to maintain a separate mapping
from integers back to strings. For better gener-
alization, certain words may be dynamically re-
placed with the names of their semantic classes
when looking up n-gram probabilities. Words are
assigned to semantic classes in the lexicon, and the
semantic classes to use in this way may be config-
ured at the grammar level. Note that (Oh and Rud-
nicky, 2002) and (Ratnaparkhi, 2002) make simi-
lar use of semantic classes in n-gram scoring, by
deferring the instantiation of classes (such as de-
parture city) until the end of the generation pro-
cess; our approach accomplishes the same goal in
a slightly more flexible way, in that it also allows
the specific word to be examined by other scoring
models, if desired.
As discussed in (White, 2004c), with dialogue
systems like COMIC n-gram models can do an
excellent job of placing underconstrained adjec-
tival and adverbial modifiers—as well as bound-
ary tones—without resorting to the more com-
plex methods investigated for adjective ordering in
(Shaw and Hatzivassiloglou, 1999; Malouf, 2000).
For instance, in examples like those in (1), they
correctly select the preferred positions for here and
also (as well as for the boundary tones), with re-
spect to the verbal head and sister dependents:
</bodyText>
<listItem confidence="0.95401825">
(1) a. HereL+H* LH% we have a design in
the classicH* style LL% .
b. ThisL+H* design LH% hereL+H* LH%
is alsoH* classic LL% .
</listItem>
<bodyText confidence="0.993218333333333">
We have also found that it can be useful to
use reverse (or “right-to-left”) models, as they can
help to place adverbs like though, as in (2):
</bodyText>
<listItem confidence="0.9200765">
(2) The tiles are alsoH* from the JazzH* series
though LL% .
</listItem>
<figure confidence="0.91127075862069">
2..n
N−gram models can be of any order,
can reverse the words, and
can replace certain words with
their semantic classes.
Utility classes for combining
scorers multiplicatively or
via linear interpolation.
SignScorerInterpolation
#weights: double[ ]
«interface»
SignScorer
+score(sign: Sign, complete: boolean): double
+nullScorer: SignScorer
Returns a score that is linear in
log space with the number of
repeated items times the penalty.
Returns zero for all signs, thereby
providing no distinguishing information.
#order: int
#reverse: boolean
2..n #useSemClasses: boolean
#wordsToScore: List&lt;Word&gt;
#prepareToScoreWords( )
#score( ): double
#logProbFromNgram(i: int, order: int): float
«interface»
NgramFilter
+filterOut(words: List&lt;Word&gt;): boolean
</figure>
<figureCaption confidence="0.924382">
Filters bigrams with the wrong
choice of a or an given
the initial letter of the following
word, with configurable exceptions.
</figureCaption>
<figure confidence="0.384744333333333">
NgramScorer
StandardNgramModel
+StandardNgramModel(order: int, filename:String)
#prepareToScoreWords( )
#logProbFromNgram(i: int, order: int): float
FactoredNgramModel
1..n
+FactoredNgramModel(child: String, parents: String[ ], filename: String)
#prepareToScoreWords( )
#logProbFromNgram(i: int, order: int): float
FactoredNgramModelFamily
+FactoredNgramModelFamily(filename: String)
#prepareToScoreWords( )
#logProbFromNgram(i: int, order: int): float
NgramPrecisionModel
+NgramPrecisionModel(targets: String[ ], order: int)
#prepareToScoreWords( )
#score( ): double
</figure>
<figureCaption confidence="0.65746">
Factored n−gram models return the probability of the
child factor of the current word given a sequence of
parent factors. Multiple models can be organized
into families.
</figureCaption>
<figure confidence="0.926731">
SignScorerProduct
RepetitionScorer
+penalty: double
+updateContext(sign: Sign)
+resetContext( )
+ageContext( )
*
LinearNgramScorerCombo
#weights: double[ ]
#logProbFromNgram(i: int, order: int): float
AAnFilter
+addException(w1: String, w2: String)
</figure>
<figureCaption confidence="0.7195152">
Returns a modified version of the
BLEU score used in MT evaluation.
Utility class for interpolating
n−gram models at the word level.
Figure 6: Classes for scoring signs
</figureCaption>
<bodyText confidence="0.99998846031746">
In principle, the forward and reverse probabilities
should be the same—as they are both derived via
the chain rule from the same joint probability of
the words in the sequence—but we have found that
with sparse data the estimates can differ substan-
tially. In particular, since though typically appears
at the end of a variety of clauses, its right context
is much more predictable than its left context, and
thus reverse models yield more accurate estimates
of its likelihood of appearing clause-finally. To il-
lustrate, Figures 7 and 8 show the forward and re-
verse trigram probabilities for two competing real-
izations of (2) in a 2-fold cross-validation test (i.e.
with models trained on the half of the test suite
not including this example). With the forward tri-
gram model, since though has not been observed
following series, and since series is a frequently
occurring word, the penalty for backing off to the
unigram probability for though is high, and thus
the probability is quite low. The medial placement
(following alsoH*) also yields a low probability,
but not as low as the clause-final one, and thus
the forward model ends up preferring the medial
placement, which is quite awkward. By contrast,
the reverse model yields a very clear preference
for the clause-final position of though, and for this
reason interpolating the forward and reverse mod-
els (see Section 3.3) also yields the desired prefer-
ence order.
Figure 9 shows a trace of realizing (2) with such
an interpolated model. In the trace, the interpo-
lated model is loaded by the class MyEvenScorer.
The input LF appears at the top. It is flattened
into a list of elementary predications, so that cov-
erage of these predications can be tracked using bit
vectors. The LF chunks ensure that the subtrees
under h1 and s1 are realized as independent sub-
problems; cf. (White, 2004a) for discussion. The
edges produced by lexical lookup and instantiation
appear next, under the heading Initial Edges,
with only the edges for alsoH* and though shown
in the figure. For each edge, the coverage percent-
age and score (here a probability) appear first, fol-
lowed by the word(s) and the coverage vector, then
the syntactic category (with features suppressed),
and finally any active LF chunks. The edges added
to the chart appear (unsorted) under the heading
All Edges. As this trace shows, in the best-first
search, high probability phrases such as the tiles
are alsoH* can be added to the chart before low-
frequency words such as though have even left
the agenda. The first complete realization, cor-
responding to (2), also turns out to be the best
one here. As noted in the figure, complete realiza-
tions are scored with sentence delimiters, which—
by changing the contexts of the initial and final
words—can result in a complete realization hav-
ing a higher probability than its input partial real-
izations (see next section for discussion). One way
to achieve more monotonic scores—and thus more
efficient search, in principle—could be to include
sentence delimiters in the grammar; we leave this
question for future work.
</bodyText>
<subsectionHeader confidence="0.983454">
3.2 N-gram Scorers
</subsectionHeader>
<bodyText confidence="0.99008328125">
The StandardNgramModel class is implemented
as a subclass of the base class NgramScorer.
All NgramScorer instances may have any num-
ber of NgramFilter instances, whose filter-
Out methods are invoked prior to n-gram scoring;
if any of these methods return true, a score of zero
is immediately returned. The AAnFilter provides
one concrete implementation of the NgramFilter
interface, and returns true if it finds a bigram con-
sisting of a followed by a vowel-inital word, or an
followed by a consonant-initial word, subject to a
configurable set of exceptions that can be culled
from bigram counts. We have found that such n-
gram filters can be more efficient, and more reli-
able, than relying on n-gram scores alone; in par-
ticular, with a/an, since the unigram probability
for a tends to be much higher than that of an, with
unseen words beginning with a vowel, there may
not be a clear preference for the bigram beginning
with an.
The base class NgramScorer implements the
bulk of the score method, using an abstract log-
ProbFromNgram method for subclass-specific cal-
culation of the log probabilities (with backoff) for
individual n-grams. The score method also in-
vokes the prepareToScoreWords method, in or-
der to allow for subclass-specific pre-processing
of the words in the given sign. With Standard-
NgramModel, this method is used to extract the
word forms or semantic classes into a list of strings
to score. It also appends any pitch accents to the
the tiles are also_H* from the SERIES_H* series though LL% .
</bodyText>
<equation confidence="0.998248620689655">
p( the  |&lt;s&gt; ) = [2gram] 0.0999418 [ -1.00025 ]
p( tiles  |the ...) = [3gram] 0.781102 [ -0.107292 ]
p( are  |tiles ...) = [3gram] 0.484184 [ -0.31499 ]
p( also_H*  |are ...) = [3gram] 0.255259 [ -0.593018 ]
p( from  |also_H* ...) = [3gram] 0.0649038 [ -1.18773 ]
p( the  |from ...) = [3gram] 0.5 [ -0.30103 ]
p( SERIES_H*  |the ...) = [3gram] 0.713421 [ -0.146654 ]
p( series  |SERIES_H* ...) = [3gram] 0.486827 [ -0.312626 ]
p( though  |series ...) = [1gram] 1.58885e-06 [ -5.79892 ]
p( LL%  |though ...) = [2gram] 0.416667 [ -0.380211 ]
p( .  |LL% ...) = [3gram] 0.75 [ -0.124939 ]
p( &lt;/s&gt;  |. ...) = [3gram] 0.999977 [ -1.00831e-05 ]
1 sentences, 11 words, 0 OOVs
0 zeroprobs, logprob= -10.2677 ppl= 7.17198 ppl1= 8.57876
the tiles are also_H* though from the SERIES_H* series LL% .
p( the  |&lt;s&gt; ) = [2gram] 0.0999418 [ -1.00025 ]
p( tiles  |the ...) = [3gram] 0.781102 [ -0.107292 ]
p( are  |tiles ...) = [3gram] 0.484184 [ -0.31499 ]
p( also_H*  |are ...) = [3gram] 0.255259 [ -0.593018 ]
p( though  |also_H* ...) = [1gram] 1.11549e-05 [ -4.95254 ]
p( from  |though ...) = [1gram] 0.00805451 [ -2.09396 ]
p( the  |from ...) = [2gram] 0.509864 [ -0.292545 ]
p( SERIES_H*  |the ...) = [3gram] 0.713421 [ -0.146654 ]
p( series  |SERIES_H* ...) = [3gram] 0.486827 [ -0.312626 ]
p( LL%  |series ...) = [3gram] 0.997543 [ -0.00106838 ]
p( .  |LL% ...) = [3gram] 0.733867 [ -0.134383 ]
p( &lt;/s&gt;  |. ...) = [3gram] 0.999977 [ -1.00831e-05 ]
1 sentences, 11 words, 0 OOVs
0 zeroprobs, logprob= -9.94934 ppl= 6.74701 ppl1= 8.02574
</equation>
<figureCaption confidence="0.846723">
Figure 7: Forward probabilities for two placements of though (COMIC test suite, 2-fold cross validation)
</figureCaption>
<bodyText confidence="0.585954">
the tiles are also_H* from the SERIES_H* series though LL% .
</bodyText>
<equation confidence="0.998812896551724">
p( .  |&lt;s&gt; ) = [2gram] 0.842366 [ -0.0744994 ]
p( LL%  |. ...) = [3gram] 0.99653 [ -0.00150975 ]
p( though  |LL% ...) = [3gram] 0.00677446 [ -2.16913 ]
p( series  |though ...) = [1gram] 0.00410806 [ -2.38636 ]
p( SERIES_H*  |series ...) = [2gram] 0.733867 [ -0.134383 ]
p( the  |SERIES_H* ...) = [3gram] 0.744485 [ -0.128144 ]
p( from  |the ...) = [3gram] 0.765013 [ -0.116331 ]
p( also_H*  |from ...) = [3gram] 0.0216188 [ -1.66517 ]
p( are  |also_H* ...) = [3gram] 0.5 [ -0.30103 ]
p( tiles  |are ...) = [3gram] 0.432079 [ -0.364437 ]
p( the  |tiles ...) = [3gram] 0.9462 [ -0.0240173 ]
p( &lt;/s&gt;  |the ...) = [3gram] 0.618626 [ -0.208572 ]
1 sentences, 11 words, 0 OOVs
0 zeroprobs, logprob= -7.57358 ppl= 4.27692 ppl1= 4.88098
the tiles are also_H* though from the SERIES_H* series LL% .
p( .  |&lt;s&gt; ) = [2gram] 0.842366 [ -0.0744994 ]
p( LL%  |. ...) = [3gram] 0.99653 [ -0.00150975 ]
p( series  |LL% ...) = [3gram] 0.0948425 [ -1.023 ]
p( SERIES_H*  |series ...) = [3gram] 0.733867 [ -0.134383 ]
p( the  |SERIES_H* ...) = [3gram] 0.744485 [ -0.128144 ]
p( from  |the ...) = [3gram] 0.765013 [ -0.116331 ]
p( though  |from ...) = [1gram] 3.50735e-08 [ -7.45502 ]
p( also_H*  |though ...) = [1gram] 0.00784775 [ -2.10525 ]
p( are  |also_H* ...) = [2gram] 0.2291 [ -0.639975 ]
p( tiles  |are ...) = [3gram] 0.432079 [ -0.364437 ]
p( the  |tiles ...) = [3gram] 0.9462 [ -0.0240173 ]
p( &lt;/s&gt;  |the ...) = [3gram] 0.618626 [ -0.208572 ]
1 sentences, 11 words, 0 OOVs
0 zeroprobs, logprob= -12.2751 ppl= 10.5421 ppl1= 13.0594
</equation>
<figureCaption confidence="0.854786">
Figure 8: Reverse probabilities for two placements of though (COMIC test suite, 2-fold cross validation)
</figureCaption>
<figure confidence="0.372265777777778">
Input LF:
@b1:state(be &apos; &lt;info&gt;rh &apos; &lt;mood&gt;dcl &apos; &lt;tense&gt;pres &apos; &lt;owner&gt;s &apos; &lt;kon&gt;-&apos;
&lt;Arg&gt;(t1:phys-obj &apos; tile &apos; &lt;det&gt;the &apos; &lt;num&gt;pl &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s &apos; &lt;kon&gt;-) &apos;
&lt;Prop&gt;(h1:proposition &apos; has-rel &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s &apos; &lt;kon&gt;-&apos;
&lt;Of&gt;t1:phys-obj &apos;
&lt;Source&gt;(s1:abstraction &apos; series &apos; &lt;det&gt;the &apos; &lt;num&gt;sg &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s &apos; &lt;kon&gt;-&apos;
&lt;HasProp&gt;(j1:series &apos; Jazz &apos; &lt;kon&gt;+ &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s))) &apos;
&lt;HasProp&gt;(a1:proposition &apos; also &apos; &lt;kon&gt;+ &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s) &apos;
&lt;HasProp&gt;(t2:proposition &apos; though &apos; &lt;info&gt;rh &apos; &lt;owner&gt;s &apos; &lt;kon&gt;-))
Instantiating scorer from class: MyEvenScorer
Preds:
ep[0]: @a1:proposition(also)
ep[1]: @a1:proposition(&lt;info&gt;rh)
ep[2]: @a1:proposition(&lt;kon&gt;+)
ep[3]: @a1:proposition(&lt;owner&gt;s)
ep[4]: @b1:state(be)
ep[5]: @b1:state(&lt;info&gt;rh)
...
LF chunks: 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}
chunk[0]: {14, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}
chunk[1]: {20,
Initial Edges:
{0.12} [0.011] also_H* {0, 1, 2, 3, 12} :- s\.s
{0.12} [0.011] also_H* {0, 1, 2, 3, 12} :- s\np/&apos;(s\np)
{0.12} [0.011] also_H* {0, 1, 2, 3, 12} :- s/&apos;s
...
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s\np/&apos;(s\np)
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s\.s
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s/&apos;s
...
Uninstantiated Semantically Null Edges:
{0.00} [0.073] LL% {} :- s$1\*(s$1)
{0.00} [0.011] L {} :- s$1\*(s$1)
All Edges:
{0.02} [0.059] . {7} :- sent\*s
{0.02} [0.059] . {7} :- sent\*(s\np)
</figure>
<bodyText confidence="0.993643272727273">
{0.02} [0.052] the {25} :- np/&apos;n &lt; 0 1 &gt;
{0.02} [0.052] the {32} :- np/&apos;n
{0.12} [0.032] tiles {31, 33, 34, 35, 36} :- n
{0.02} [0.018] from {19} :- n\n/&lt;np &lt; 0 &gt;
{0.15} [0.018] from {14, 15, 16, 17, 18, 19} :- s\!np/&lt;np &lt; 0 &gt;
{0.17} [0.017] is {4, 5, 6, 8, 9, 10, 11} :- s\np/(s\!np)
...
{0.15} [0.009] the tiles {31, 32, 33, 34, 35, 36} :- np
{0.15} [0.009] the tiles {31, 32, 33, 34, 35, 36} :- s/@i(s\@inp)
{0.15} [0.009] the tiles {31, 32, 33, 34, 35, 36} :- s$1\@i(s$1/@inp)
...
{0.44} [0.001] the tiles are also_H* {0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 31, 32, 33, 34, 35, 36} :- s/(s\!np)
...
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s\np/&apos;(s\np)
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s\.s
{0.12} [6E-4] though {13, 37, 38, 39, 40} :- s/&apos;s
...
{0.85} [1.32E-5] the tiles are also_H* from the Jazz_H* series {...} :- s
{0.85} [1.32E-5] the tiles are also_H* from the Jazz_H* series LL% {...} :- s
...
{0.24} [2.64E-6] also_H* though {0, 1, 2, 3, 12, 13, 37, 38, 39, 40} :- s\np/&apos;(s\np)
{0.24} [2.64E-6] also_H* though {0, 1, 2, 3, 12, 13, 37, 38, 39, 40} :- s\.s
...
{0.88} [5.44E-8] the tiles are from the Jazz_H* series though LL% . {...} :- sent
...
{0.85} [4.85E-8] the tiles are from the Jazz_H* series also_H* {...} :- s
...
{0.88} [3.14E-9] the tiles also_H* are from the Jazz_H* series LL% . {...} :- sent
...
{0.98} [2.96E-9] the tiles are also_H* from the Jazz_H* series though {...} :- s
...
{0.98} [1.51E-9] the tiles are also_H* from the Jazz_H* series though LL% {...} :- s
{1.00} [1.34E-8] the tiles are also_H* from the Jazz_H* series though LL% . {...} :- sent
</bodyText>
<figure confidence="0.74679725">
****** first complete realization; scored with &lt;s&gt; and &lt;/s&gt; tags ******
...
{0.24} [1.44E-9] also_H* though L {...} :- s\np/&apos;(s\np)
...
</figure>
<footnote confidence="0.657789166666667">
{0.56} [2E-10] though the tiles are also_H* LL% {...} :- s/(s\!np)
...
Complete Edges (sorted):
{1.00} [1.34E-8] the tiles are also_H* from the Jazz_H* series though LL% . {...} :- sent
{1.00} [1.33E-8] the tiles are also_H* from the Jazz_H* series LL% though LL% . {...} :- sent
...
</footnote>
<figureCaption confidence="0.998715">
Figure 9: Realizer trace for example (2) with interpolated model
</figureCaption>
<bodyText confidence="0.999601829268293">
word forms or semantic classes, effectively treat-
ing them as integral parts of the words.
Since the realizer builds up partial realizations
bottom-up rather than left-to-right, it only adds
start of sentence (and end of sentence) tags with
complete realizations. As a consequence, the
words with less than a full n −1 words of history
are scored with appropriate sub-models. For ex-
ample, the first word of a phrase is scored with
a unigram sub-model, without imposing backoff
penalties.
Another consequence of bottom-up realization
is that both the left- and right-contexts may change
when forming new signs from a given input sign.
Consequently, it is often not possible (even in prin-
ciple) to use the score of an input sign directly in
computing the score of a new result sign. If one
could make assumptions about how the score of an
input sign has been computed—e.g., by a bigram
model—one could determine the score of the re-
sult sign from the scores of the input signs together
with an adjustment for the word(s) whose context
has changed. However, our general approach to
sign scoring precludes making such assumptions.
Nevertheless, it is still possible to improve the effi-
ciency of n-gram scoring by caching the log prob-
ability of a sign’s words, and then looking up that
log probability when the sign is used as the first
input sign in creating a new combined sign—thus
retaining the same left context—and only recom-
puting the log probabilities for the words of any in-
put signs past the first one. (With reverse models,
the sign must be the last sign in the combination.)
In principle, the derivation history could be con-
sulted further to narrow down the words whose n-
gram probabilities must be recomputed to the min-
imum possible, though NgramScorer only imple-
ments a single-step lookup at present.3 Finally,
note that a Java WeakHashMap is used to imple-
ment the cache, in order to avoid an undesirable
buildup of entries across realization requests.
</bodyText>
<subsectionHeader confidence="0.982562">
3.3 Interpolation
</subsectionHeader>
<bodyText confidence="0.981571">
Scoring models may be linearly interpolated in
two ways. Sign scorers of any variety may be
</bodyText>
<footnote confidence="0.825828666666667">
3Informal experiments indicate that caching log probabil-
ities in this way can yield an overall reduction in best-first
realization times of 2-3% on average.
</footnote>
<bodyText confidence="0.999802823529412">
combined using the SignScorerInterpolation
class. For example, Figure 10 shows how forward
and reverse n-gram models may be interpolated.
With n-gram models of the same direction, it is
also possible to linearly interpolate models at the
word level, using the LinearNgramScorerCombo
class. Word-level interpolation makes it easier to
use cache models created with maximum likeli-
hood estimation, as word-level interpolation with
a base model avoids problems with zero probabil-
ities in the cache model. As discussed in (Brock-
mann et al., 2005), cache models can be used to
promote alignment with a conversational partner,
by constructing a cache model from the bigrams
in the partner’s previous turn, and interpolating it
with a base model.4 Figure 11 shows one way to
create such an interpolated model.
</bodyText>
<subsectionHeader confidence="0.983727">
3.4 N-gram Precision Models
</subsectionHeader>
<bodyText confidence="0.99986312">
The NgramPrecisionModel subclass of Ngram-
Scorer computes a modified version of the Bleu
score used in MT evaluation (Papineni et al.,
2001). Its constructor takes as input an array of
target strings—from which it extracts the n-gram
sequences to use in computing the n-gram preci-
sion score—and the desired order. Unlike with
the Bleu score, rank order centroid weights (rather
than the geometric mean) are used to combine
scores of different orders, which avoids problems
with scoring partial realizations which have no n-
gram matches of the target order. For simplicity,
the score also does not include the Bleu score’s
bells and whistles to make cheating on length dif-
ficult.
We have found n-gram precision models to be
very useful for regression testing the grammar, as
an n-gram precision model created just from the
target string nearly always leads the realizer to
choose that exact string as its preferred realiza-
tion. Such models can also be useful for evaluating
the success of different scoring models in a cross-
validation setup, though with high quality output,
manual inspection is usually necessary to deter-
mine the importance of any differences between
</bodyText>
<footnote confidence="0.97884175">
4At present, such cache models must be constructed with
a call to the SRILM toolkit; it would not be difficult to add
OpenCCG support for constructing them though, since these
models do not require smoothing.
</footnote>
<table confidence="0.7969345">
//configure realizer with 4-gram forward and reverse backoff models,
// interpolated with equal weight
NgramScorer forwardModel = new StandardNgramModel(4, &amp;quot;lm.4bo&amp;quot;);
NgramScorer reverseModel = new StandardNgramModel(4, &amp;quot;lm-r.4bo&amp;quot;);
reverseModel.setReverse(true);
realizer.signScorer = new SignScorerInterpolation(
new SignScorer[] { forwardModel, reverseModel }
);
</table>
<figureCaption confidence="0.897477">
Figure 10: Example interpolated n-gram model
</figureCaption>
<figure confidence="0.963861222222222">
// configure realizer with 4-gram backoff base model,
// interpolated at the word level with a bigram maximum-likelihood
// cache model, with more weight given to the base model
NgramScorer baseModel = new StandardNgramModel(4, &amp;quot;lm.4bo&amp;quot;);
NgramScorer cacheModel = new StandardNgramModel(2, &amp;quot;lm-cache.mle&amp;quot;);
realizer.signScorer = new LinearNgramScorerCombo(
new SignScorer[] { baseModel, cacheModel },
new double[] { 0.6 , 0.4 }
);
</figure>
<figureCaption confidence="0.998918">
Figure 11: Example word-level interpolation of a cache model
</figureCaption>
<bodyText confidence="0.896609">
the preferred realization and the target string.
</bodyText>
<subsectionHeader confidence="0.947066">
3.5 Factored Language Models
</subsectionHeader>
<bodyText confidence="0.999958408163265">
A factored language model (Bilmes and Kirch-
hoff, 2003) is a new kind of language model that
treats words as bundles of factors. To support
scoring with such models, OpenCCG represents
words as objects with a surface form, pitch accent,
stem, part of speech, supertag, and semantic class.
Words may also have any number of further at-
tributes, such as associated gesture classes, in or-
der to handle in a general way elements like pitch
accents that are “coarticulated” with words.
To represent words efficiently, and to speed up
equality tests, all attribute values are interned, and
the Word objects themselves are interned via a fac-
tory method. Note that in Java, it is straightfor-
ward to intern objects other than strings by em-
ploying a WeakHashMap to map from an object
key to a weak reference to itself as the canonical
instance. (Using a weak reference avoids accu-
mulating interned objects that would otherwise be
garbage collected.)
With the SRILM toolkit, factored language
models can be constructed that support general-
ized parallel backoff: that is, backoff order is
not restricted to just dropping the most temporally
distant word first, but rather may be specified as
a path through the set of contextual parent vari-
ables; additionally, parallel backoff paths may be
specified, with the possibility of combining these
paths dynamically in various ways. In OpenCCG,
the FactoredNgramModel class supports scoring
with factored language models that employ gen-
eralized backoff, though parallel backoff is not
yet supported, as it remains somewhat unclear
whether the added complexity of parallel backoff
is worth the implementation effort. Typically, sev-
eral related factored language models are specified
in a single file and loaded by a FactoredNgram-
ModelFamily, which can multiplicatively score
models for different child variables, and include
different sub-models for the same child variable.
To illustrate, let us consider a simplified version
of the factored language model family used in the
COMIC realizer. This model computes the proba-
bility of the current word given the preceding ones
according to the formula shown in (3), where a
word consists of the factors word (W), pitch accent
(A), gesture class (GC), and gesture instance (GI),
plus the other standard factors which the model ig-
nores:
</bodyText>
<equation confidence="0.999604">
P(hW,A,GC,GIi|hW,A,GC,GIi−1 ...) ≈
P(W |W−1W−2A−1A−2) ×
P(GC |W) ×
P(GI|GC)
</equation>
<bodyText confidence="0.999991666666667">
In (3), the probability of the current word is ap-
proximated by the probability of the current word
form given the preceding two word forms and pre-
ceding two pitch accents, multiplied by the proba-
bility of the current gesture class given the current
word form, and by the probability of the current
gesture instance given the current gesture class.
Note that in the COMIC grammar, the choice of
pitch accent is entirely rule governed, so the cur-
rent pitch accent is not scored separately in the
model. However, the preceding pitch accents are
taken into account in predicting the current word
form, as perplexity experiments have suggested
that they do provide additional information be-
yond that provided by the previous word forms.
The specification file for this model appears in
Figure 12. The format of the file is a restricted
form of the files used by the SRILM toolkit to
build factored language models. The file specifies
four models, where the first, third and fourth mod-
els correspond to those in (3). With the first model,
since the previous words are typically more infor-
mative than the previous pitch accents, the backoff
order specifies that the most distant accent, A(-2),
should be dropped first, followed by the previous
accent, A(-1), then the most distant word, W(-2),
and finally the previous word, W(-1). The sec-
ond model is considered a sub-model of the first—
since it likewise predicts the current word—to be
used when there is only one word of context avail-
able (i.e. with bigrams). Note that when scoring
a bigram, the second model will take the previous
pitch accent into account, whereas the first model
would not. For documentation of the file format as
it is used in the SRILM toolkit, see (Kirchhoff et
al., 2002).
Like StandardNgramModel, the Factored-
NgramModel class stores its n-gram tables in a trie
data structure, except that it stores an interned fac-
tor key (i.e. a factor name and value pair, or just a
string, in the case of the word form) at each node,
rather than a simple string. During scoring, the
logProbFromNgram method determines the log
probability (with backoff) of a given n-gram by
extracting the appropriate sequence of factor keys,
and using them to compute the log probability as
with standard n-gram models. The Factored-
NgramModelFamily class computes log probabil-
ities by delegating to its component factored n-
gram models (choosing appropriate sub-models,
when appropriate) and summing the results.
</bodyText>
<subsectionHeader confidence="0.997563">
3.6 Avoiding Repetition
</subsectionHeader>
<bodyText confidence="0.999990466666667">
While cache models appear to be a promising av-
enue to promote lexical and syntactic alignment
with a conversational partner, a different mech-
anism appears to be called for to avoid “self-
alignment”—that is, to avoid the repetitive use of
words and phrases. As a means to experiment
with avoiding repetition, OpenCCG includes the
RepetitionScorer class. This class makes use
of a configurable penalty plus a set of methods for
dynamically managing the context. It returns a
score of 10−c,×p, where c, is the count of repeated
items, and p is the penalty. Note that this formula
returns 1 if there are no repeated items, and returns
a score that is linear in log space with the number
of repeated items otherwise.
A repetition scorer can be combined multiplica-
tively with an n-gram model, in order to discount
realizations that repeat items from the recent con-
text. Figure 13 shows such a combination, to-
gether with the operations for updating the con-
text. By default, open class stems are the consid-
ered the relevant items over which to count rep-
etitions, though this behavior can be specialized
by subclassing RepetitionScorer and overrid-
ing the updateItems method. Note that in count-
ing repetitions, full counts are given to items in the
previous words or recent context, while fractional
counts are given to older items; the exact details
may likewise be changed in a subclass, by over-
riding the repeatedItems method.
</bodyText>
<sectionHeader confidence="0.984592" genericHeader="method">
4 Pruning Strategies
</sectionHeader>
<bodyText confidence="0.999724">
The classes for defining edge pruning strategies
appear in Figure 14. As mentioned in Section 2,
an N-best pruning strategy is employed by default,
where N is determined by the current preference
settings. It is also possible to define custom strate-
gies. To support the definition of a certain kind
</bodyText>
<table confidence="0.976537807692307">
(3)
## Simplified COMIC realizer FLM spec file
## Trigram Word model based on previous words and accents, dropping accents first,
## with bigram sub-model;
## Unigram Gesture Class model based on current word; and
## Unigram Gesture Instance model based on current gesture class
4
## 3gram with A
W : 4 W(-1) W(-2) A(-1) A(-2) w_w1w2a1a2.count w_w1w2a1a2.lm 5
W1,W2,A1,A2 A2 ndiscount gtmin 1
W1,W2,A1 A1 ndiscount gtmin 1
W1,W2 W2 ndiscount gtmin 1
W1 W1 ndiscount gtmin 1
0 0 ndiscount gtmin 1
## bigram with A
W : 2 W(-1) A(-1) w_w1a1.count w_w1a1.lm 3
W1,A1 A1 ndiscount gtmin 1
W1 W1 ndiscount gtmin 1
0 0 ndiscount gtmin 1
## Gesture class depends on current word
GC : 1 W(0) gc_w0.count gc_w0.lm 2
W0 W0 ndiscount gtmin 1
0 0 ndiscount gtmin 1
## Gesture instance depends only on class
GI : 1 GC(0) gi_gc0.count gi_gc0.lm 2
GC0 GC0 ndiscount gtmin 1
</table>
<figure confidence="0.604692">
0 0
</figure>
<figureCaption confidence="0.9776">
Figure 12: Example factored language model family specification
</figureCaption>
<figure confidence="0.919959866666667">
// set up n-gram scorer and repetition scorer
String lmfile = &amp;quot;ngrams/combined. flm&amp;quot;;
boolean semClasses = true;
NgramScorer ngramScorer = new FactoredNgramModelFamily(lmfile, semClasses);
ngramScorer.addFilter(new AAnFilter ());
RepetitionScorer repetitionScorer = new RepetitionScorer();
// combine n-gram scorer with repetition scorer
realizer.signScorer = new SignScorerProduct(
new SignScorer[] { ngramScorer, repetitionScorer }
);
// ... then, after each realization request,
Edge bestEdge = realizer.realize(lf);
// ... update repetition context for next realization:
repetitionScorer.ageContext();
repetitionScorer.updateContext(bestEdge.getSign());
</figure>
<figureCaption confidence="0.998431">
Figure 13: Example combination of an n-gram scorer and a repetition scorer
</figureCaption>
<bodyText confidence="0.999956113636364">
of custom strategy, the abstract class Diversity-
PruningStrategy provides an N-best pruning
strategy that promotes diversity in the edges that
are kept, according to the equivalence relation
established by the abstract notCompellingly-
Different method. In particular, in order to de-
termine which edges to keep, a diversity pruning
strategy clusters the edges into a ranked list of
equivalence classes, which are sequentially sam-
pled until the limit N is reached. If the single-
BestPerGroup flag is set, then a maximum of one
edge per equivalence class is retained.
As an example, the COMIC realizer’s diversity
pruning strategy appears in Figure 15. The idea
behind this strategy is to avoid having the N-best
lists become full of signs whose words differ only
in the exact gesture instance associated with one
or more of the words. With this strategy, if two
signs differ in just this way, the edge for the lower-
scoring sign will be considered “not compellingly
different” and pruned from the N-best list, mak-
ing way for other edges whose signs exhibit more
interesting differences.
OpenCCG also provides a concrete subclass
of DiversityPruningStrategy named Ngram-
DiversityPruningStrategy, which general-
izes the approach to pruning described in (Langk-
ilde, 2000). With this class, two signs are consid-
ered not compellingly different if they share the
same n−1 initial and final words, where n is the
n-gram order. When one is interested in single-
best output, an n-gram diversity pruning strategy
can increase efficiency while guaranteeing no loss
in quality—as long as the reduction in the search
space outweighs the extra time necessary to check
for the same initial and final words—since any
words in between an input sign’s n−1 initial and
final ones cannot affect the n-gram score of a
new sign formed from the input sign. However,
when N-best outputs are desired, or when repeti-
tion scoring is employed, it is less clear whether
it makes sense to use an n-gram diversity pruning
strategy; for this reason, a simple N-best strategy
remains the default option.
</bodyText>
<sectionHeader confidence="0.996976" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999985785714286">
In this paper, we have presented OpenCCG’s ex-
tensible API for efficiently integrating language
modeling and realization, in order to select realiza-
tions with preferred word orders, promote align-
ment with a conversational partner, avoid repeti-
tive language use, and increase the speed of the
best-first anytime search. As we have shown,
the design enables a variety of n-gram models
to be easily combined and used in conjunction
with appropriate edge pruning strategies. The n-
gram models may be of any order, operate in re-
verse (“right-to-left”), and selectively replace cer-
tain words with their semantic classes. Factored
language models with generalized backoff may
also be employed, over words represented as bun-
dles of factors such as form, pitch accent, stem,
part of speech, supertag, and semantic class.
In future work, we plan to further explore
how to best employ factored language models; in
particular, inspired by (Bangalore and Rambow,
2000), we plan to examine whether factored lan-
guage models using supertags can provide an ef-
fective way to combine syntactic and lexical prob-
abilities. We also plan to implement the capabil-
ity to use one-of alternations in the input logical
forms (Foster and White, 2004), in order to more
efficiently defer lexical choice decisions to the lan-
guage models.
</bodyText>
<sectionHeader confidence="0.99976" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.9725444">
Thanks to Jason Baldridge, Carsten Brockmann,
Mary Ellen Foster, Philipp Koehn, Geert-Jan Krui-
jff, Johanna Moore, Jon Oberlander, Miles Os-
borne, Mark Steedman, Sebastian Varges and the
anonymous reviewers for helpful discussion.
</reference>
<figure confidence="0.903725692307692">
«interface» Returns the edges pruned from
PruningStrategy the given ones, which always have
equivalent categories and are
sorted by score.
+pruneEdges(edges: List&lt;Edge&gt;): List&lt;Edge&gt;
#CAT_PRUNE_VAL: int
DiversityPruningStrategy
+singleBestPerGroup: boolean
+notCompellinglyDifferent(sign1: Sign, sign2: Sign): boolean
NBestPruningStrategy
Keeps only the n−best edges.
Prunes edges that are not
compellingly different.
</figure>
<figureCaption confidence="0.878634">
NgramDiversityPruningStrategy Defines edges to be not compellingly different
#order: int when the n−1 initial and final words are the same
(where n is the order).
+notCompellinglyDifferent(sign1: Sign, sign2: Sign): boolean
Figure 14: Classes for defining pruning strategies
</figureCaption>
<figure confidence="0.928113625">
// configure realixer with gesture diversity pruner
realizer.pruningStrategy = new DiversityPruningStrategy() {
/**
* Returns true iff the given signs are not compellingly different;
* in particular, returns true iff the words differ only in their
* gesture instances. */
public boolean notCompellinglyDifferent(Sign sign1 , Sign sign2) {
List words1 = sign1.getWords (); List words2 = sign2.getWords();
</figure>
<construct confidence="0.915542625">
if (words1.size() != words2.size()) return false;
for (int i = 0; i &lt; words1.size(); i++) {
Word w1 = (Word) words1.get(i); Word w2 = (Word) words2.get(i);
if (w1 == w2) continue;
if (w1.getForm() != w2.getForm()) return false;
if (w1.getPitchAccent() != w2.getPitchAccent()) return false;
if (w1.getVal(&amp;quot;GC&amp;quot;) != w2.getVal(&amp;quot;GC&amp;quot;)) return false;
// nb: assuming that they differ in the val of GI at this point
</construct>
<reference confidence="0.3799495">
1
return true;
</reference>
<page confidence="0.8121045">
1
1;
</page>
<figureCaption confidence="0.986002">
Figure 15: Example diversity pruning strategy
</figureCaption>
<sectionHeader confidence="0.98908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999983154761905">
Jason Baldridge. 2002. Lexically Specified Deriva-
tional Control in Combinatory Categorial Gram-
mar. Ph.D. thesis, School of Informatics, University
of Edinburgh.
Srinivas Bangalore and Owen Rambow. 2000. Ex-
ploiting a probabilistic hierarchical model for gen-
eration. In Proc. COLING-00.
Jeff Bilmes and Katrin Kirchhoff. 2003. Factored lan-
guage models and general parallelized backoff. In
Proc. HLT-03.
Carsten Brockmann, Amy Isard, Jon Oberlander, and
Michael White. 2005. Variable alignment in affec-
tive dialogue. In Proc. UM-05 Workshop on Affec-
tive Dialogue Systems. To appear.
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Pozna´nski. 1999. An efficient chart generator
for (semi-) lexicalist grammars. In Proc. EWNLG-
99.
Mary Ellen Foster and Michael White. 2004. Tech-
niques for Text Planning with XSLT. In Proc. 4th
NLPXML Workshop.
Martin Kay. 1996. Chart generation. In Proc. ACL-96.
Katrin Kirchhoff, Jeff Bilmes, Sourin Das, Nico-
lae Duta, Melissa Egan, Gang Ji, Feng He, John
Henderson, Daben Liu, Mohamed Noamany, Pat
Schone, Richard Schwartz, and Dimitra Vergyri.
2002. Novel Approaches to Arabic Speech Recogni-
tion: Report from the 2002 Johns-Hopkins Summer
Workshop.
Kevin Knight and Vasileios Hatzivassiloglou. 1995.
Two-level, many-paths generation. In Proc. ACL-
95.
Irene Langkilde-Geary. 2002. An empirical verifi-
cation of coverage and correctness for a general-
purpose sentence generator. In Proc. INLG-02.
Irene Langkilde. 2000. Forest-based statistical sen-
tence generation. In Proc. NAACL-00.
Robert Malouf. 2000. The order of prenominal adjec-
tives in natural language generation. In Proc. ACL-
00.
Johanna Moore, Mary Ellen Foster, Oliver Lemon, and
Michael White. 2004. Generating tailored, com-
parative descriptions in spoken dialogue. In Proc.
FLAIRS-04.
Robert C. Moore. 2002. A complete, efficient
sentence-realization algorithm for unification gram-
mar. In Proc. INLG-02.
Alice H. Oh and Alexander I. Rudnicky. 2002.
Stochastic natural language generation for spoken
dialog systems. Computer, Speech &amp; Language,
16(3/4):387–407.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176, IBM.
Adwait Ratnaparkhi. 2002. Trainable approaches to
surface natural language generation and their appli-
cation to conversational dialog systems. Computer,
Speech &amp; Language, 16(3/4):435–455.
Eric S. Ristad. 1995. A Natural Law of Succession.
Technical Report CS-TR-495-95, Princeton Univ.
James Shaw and Vasileios Hatzivassiloglou. 1999. Or-
dering among premodifiers. In Proc. ACL-99.
Hadar Shemtov. 1997. Ambiguity Management in Nat-
ural Language Generation. Ph.D. thesis, Stanford
University.
Mark Steedman. 2000a. Information structure and
the syntax-phonology interface. Linguistic Inquiry,
31(4):649–689.
Mark Steedman. 2000b. The Syntactic Process. MIT
Press.
Andreas Stolcke. 2002. SRILM — An extensible lan-
guage modeling toolkit. In Proc. ICSLP-02.
Michael White and Jason Baldridge. 2003. Adapting
Chart Realization to CCG. In Proc. EWNLG-03.
Michael White. 2004a. Efficient Realization of Coor-
dinate Structures in Combinatory Categorial Gram-
mar. Research on Language and Computation. To
appear.
Michael White. 2004b. Experiments with multimodal
output in human-machine interaction. IST Project
COMIC Public Deliverable 7.4.
Michael White. 2004c. Reining in CCG Chart Real-
ization. In Proc. INLG-04.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.296980">
<title confidence="0.9997065">Designing an Extensible API Integrating Language Modeling and Realization</title>
<author confidence="0.998164">Michael</author>
<affiliation confidence="0.996673">School of University of</affiliation>
<note confidence="0.326623">Edinburgh EH8 9LW,</note>
<web confidence="0.998304">http://www.iccs.informatics.ed.ac.uk/~mwhite/</web>
<abstract confidence="0.997076958333333">We present an extensible API for integrating language modeling and realization, describing its design and efficient implementation in the OpenCCG surface realizer. With OpenCCG, language models may be used to select realizations with preferred word orders, promote alignment with a conversational partner, avoid repetitive language use, and increase the speed of the best-first anytime search. The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies. The n-gram models may be of any order, operate in reverse (“right-to-left”), and selectively replace certain words with their semantic classes. Factored language models with generalized backoff may also be employed, over words represented as bundles of factors such as form, pitch accent, stem, part of speech, supertag, and semantic class.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Thanks to Jason Baldridge</author>
<author>Carsten Brockmann</author>
<author>Mary Ellen Foster</author>
<author>Philipp Koehn</author>
<author>Geert-Jan Kruijff</author>
<author>Johanna Moore</author>
<author>Jon Oberlander</author>
<author>Miles Osborne</author>
<author>Mark Steedman</author>
</authors>
<title>Sebastian Varges and the anonymous reviewers for helpful discussion.</title>
<marker>Baldridge, Brockmann, Foster, Koehn, Kruijff, Moore, Oberlander, Osborne, Steedman, </marker>
<rawString>Thanks to Jason Baldridge, Carsten Brockmann, Mary Ellen Foster, Philipp Koehn, Geert-Jan Kruijff, Johanna Moore, Jon Oberlander, Miles Osborne, Mark Steedman, Sebastian Varges and the anonymous reviewers for helpful discussion.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>Lexically Specified Derivational Control in Combinatory Categorial Grammar.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="10466" citStr="Baldridge, 2002" startWordPosition="1610" endWordPosition="1611">trate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 the crossvalidation tests reported in (White, 2004b). In these tests, we measured the realizer’s accuracy and speed, under a variety of configurations, on the regression test suites for two small but linguistically rich grammars: the English grammar for the COMIC2 dialogue system—the core of which is shared with the FLIGHTS system (Moore et al., 2004)—and the Worldcup grammar discussed in 2http://www.hcrc.ed.ac.uk/comic/ (Baldridge, 2002). Table 1 gives the sizes of the test suites. Using these two test suites, we timed how long it took on a 2.2 GHz Linux PC to realize each logical form under each realizer configuration. To measure accuracy, we counted the number of times the best scoring realization exactly matched the target, and also computed a modified version of the Bleu n-gram precision metric (Papineni et al., 2001) employed in machine translation evaluation, using 1- to 4-grams, with the longer n-grams given more weight (cf. Section 3.4). To rank candidate realizations, we used standard ngram backoff models of orders 2</context>
</contexts>
<marker>Baldridge, 2002</marker>
<rawString>Jason Baldridge. 2002. Lexically Specified Derivational Control in Combinatory Categorial Grammar. Ph.D. thesis, School of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Owen Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<booktitle>In Proc. COLING-00.</booktitle>
<contexts>
<context position="2350" citStr="Bangalore and Rambow, 2000" startWordPosition="345" endWordPosition="348">. A distinguishing feature of OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>Srinivas Bangalore and Owen Rambow. 2000. Exploiting a probabilistic hierarchical model for generation. In Proc. COLING-00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Bilmes</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Factored language models and general parallelized backoff.</title>
<date>2003</date>
<booktitle>In Proc. HLT-03.</booktitle>
<contexts>
<context position="36466" citStr="Bilmes and Kirchhoff, 2003" startWordPosition="5973" endWordPosition="5977">el // configure realizer with 4-gram backoff base model, // interpolated at the word level with a bigram maximum-likelihood // cache model, with more weight given to the base model NgramScorer baseModel = new StandardNgramModel(4, &amp;quot;lm.4bo&amp;quot;); NgramScorer cacheModel = new StandardNgramModel(2, &amp;quot;lm-cache.mle&amp;quot;); realizer.signScorer = new LinearNgramScorerCombo( new SignScorer[] { baseModel, cacheModel }, new double[] { 0.6 , 0.4 } ); Figure 11: Example word-level interpolation of a cache model the preferred realization and the target string. 3.5 Factored Language Models A factored language model (Bilmes and Kirchhoff, 2003) is a new kind of language model that treats words as bundles of factors. To support scoring with such models, OpenCCG represents words as objects with a surface form, pitch accent, stem, part of speech, supertag, and semantic class. Words may also have any number of further attributes, such as associated gesture classes, in order to handle in a general way elements like pitch accents that are “coarticulated” with words. To represent words efficiently, and to speed up equality tests, all attribute values are interned, and the Word objects themselves are interned via a factory method. Note that</context>
</contexts>
<marker>Bilmes, Kirchhoff, 2003</marker>
<rawString>Jeff Bilmes and Katrin Kirchhoff. 2003. Factored language models and general parallelized backoff. In Proc. HLT-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carsten Brockmann</author>
<author>Amy Isard</author>
<author>Jon Oberlander</author>
<author>Michael White</author>
</authors>
<title>Variable alignment in affective dialogue.</title>
<date>2005</date>
<booktitle>In Proc. UM-05 Workshop on Affective Dialogue Systems.</booktitle>
<note>To appear.</note>
<contexts>
<context position="3032" citStr="Brockmann et al., 2005" startWordPosition="442" endWordPosition="445">, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversational partner (Brockmann et al., 2005), and avoid repetitive language use. In addition, by integrating language model scoring into the search, it also becomes possible to use more accurate models to improve realization times, when the realizer is run in anytime mode (White, 2004b). To allow language models to be combined in flexible ways—as well as to enable research on how to best combine language modeling and realization—OpenCCG’s design includes interfaces that allow user-defined functions to be used for scoring partial realizations and for pruning low-scoring ones during the search. The design also includes classes for support</context>
<context position="33767" citStr="Brockmann et al., 2005" startWordPosition="5570" endWordPosition="5574">an yield an overall reduction in best-first realization times of 2-3% on average. combined using the SignScorerInterpolation class. For example, Figure 10 shows how forward and reverse n-gram models may be interpolated. With n-gram models of the same direction, it is also possible to linearly interpolate models at the word level, using the LinearNgramScorerCombo class. Word-level interpolation makes it easier to use cache models created with maximum likelihood estimation, as word-level interpolation with a base model avoids problems with zero probabilities in the cache model. As discussed in (Brockmann et al., 2005), cache models can be used to promote alignment with a conversational partner, by constructing a cache model from the bigrams in the partner’s previous turn, and interpolating it with a base model.4 Figure 11 shows one way to create such an interpolated model. 3.4 N-gram Precision Models The NgramPrecisionModel subclass of NgramScorer computes a modified version of the Bleu score used in MT evaluation (Papineni et al., 2001). Its constructor takes as input an array of target strings—from which it extracts the n-gram sequences to use in computing the n-gram precision score—and the desired order</context>
</contexts>
<marker>Brockmann, Isard, Oberlander, White, 2005</marker>
<rawString>Carsten Brockmann, Amy Isard, Jon Oberlander, and Michael White. 2005. Variable alignment in affective dialogue. In Proc. UM-05 Workshop on Affective Dialogue Systems. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Victor Pozna´nski</author>
</authors>
<title>An efficient chart generator for (semi-) lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proc. EWNLG99.</booktitle>
<marker>Carroll, Copestake, Flickinger, Pozna´nski, 1999</marker>
<rawString>John Carroll, Ann Copestake, Dan Flickinger, and Victor Pozna´nski. 1999. An efficient chart generator for (semi-) lexicalist grammars. In Proc. EWNLG99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Foster</author>
<author>Michael White</author>
</authors>
<title>Techniques for Text Planning with XSLT.</title>
<date>2004</date>
<booktitle>In Proc. 4th NLPXML Workshop. Martin Kay.</booktitle>
<marker>Foster, White, 2004</marker>
<rawString>Mary Ellen Foster and Michael White. 2004. Techniques for Text Planning with XSLT. In Proc. 4th NLPXML Workshop. Martin Kay. 1996. Chart generation. In Proc. ACL-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Kirchhoff</author>
<author>Jeff Bilmes</author>
<author>Sourin Das</author>
<author>Nicolae Duta</author>
<author>Melissa Egan</author>
<author>Gang Ji</author>
<author>Feng He</author>
<author>John Henderson</author>
<author>Daben Liu</author>
<author>Mohamed Noamany</author>
<author>Pat Schone</author>
<author>Richard Schwartz</author>
<author>Dimitra Vergyri</author>
</authors>
<title>Novel Approaches to Arabic Speech Recognition: Report from the 2002 Johns-Hopkins Summer Workshop.</title>
<date>2002</date>
<contexts>
<context position="40542" citStr="Kirchhoff et al., 2002" startWordPosition="6643" endWordPosition="6646">, the backoff order specifies that the most distant accent, A(-2), should be dropped first, followed by the previous accent, A(-1), then the most distant word, W(-2), and finally the previous word, W(-1). The second model is considered a sub-model of the first— since it likewise predicts the current word—to be used when there is only one word of context available (i.e. with bigrams). Note that when scoring a bigram, the second model will take the previous pitch accent into account, whereas the first model would not. For documentation of the file format as it is used in the SRILM toolkit, see (Kirchhoff et al., 2002). Like StandardNgramModel, the FactoredNgramModel class stores its n-gram tables in a trie data structure, except that it stores an interned factor key (i.e. a factor name and value pair, or just a string, in the case of the word form) at each node, rather than a simple string. During scoring, the logProbFromNgram method determines the log probability (with backoff) of a given n-gram by extracting the appropriate sequence of factor keys, and using them to compute the log probability as with standard n-gram models. The FactoredNgramModelFamily class computes log probabilities by delegating to i</context>
</contexts>
<marker>Kirchhoff, Bilmes, Das, Duta, Egan, Ji, He, Henderson, Liu, Noamany, Schone, Schwartz, Vergyri, 2002</marker>
<rawString>Katrin Kirchhoff, Jeff Bilmes, Sourin Das, Nicolae Duta, Melissa Egan, Gang Ji, Feng He, John Henderson, Daben Liu, Mohamed Noamany, Pat Schone, Richard Schwartz, and Dimitra Vergyri. 2002. Novel Approaches to Arabic Speech Recognition: Report from the 2002 Johns-Hopkins Summer Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Two-level, many-paths generation.</title>
<date>1995</date>
<booktitle>In Proc. ACL95.</booktitle>
<contexts>
<context position="2305" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="339" endWordPosition="342">ss this meaning according to the lexicon and grammar. A distinguishing feature of OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select r</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>Kevin Knight and Vasileios Hatzivassiloglou. 1995. Two-level, many-paths generation. In Proc. ACL95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a generalpurpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proc. INLG-02.</booktitle>
<contexts>
<context position="2373" citStr="Langkilde-Geary, 2002" startWordPosition="349" endWordPosition="350">f OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote align</context>
</contexts>
<marker>Langkilde-Geary, 2002</marker>
<rawString>Irene Langkilde-Geary. 2002. An empirical verification of coverage and correctness for a generalpurpose sentence generator. In Proc. INLG-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
</authors>
<title>Forest-based statistical sentence generation.</title>
<date>2000</date>
<booktitle>In Proc. NAACL-00.</booktitle>
<contexts>
<context position="2322" citStr="Langkilde, 2000" startWordPosition="343" endWordPosition="344">xicon and grammar. A distinguishing feature of OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with </context>
<context position="9426" citStr="Langkilde, 2000" startWordPosition="1447" endWordPosition="1448">izer.pruningStrategy = new NBestPruningStrategy(10); // ... then, for each request: // get LF from input XML Document inputDoc = ...; LF lf = realizer.getLfFromDoc(inputDoc); // realize LF and get output words in XML Edge bestEdge = realizer.realize(lf); Document outputDoc = bestEdge.sign.getWordsInXml(); // return output ... outputDoc ...; Figure 2: Example realizer usage of all possible realizations is created in the first stage; then in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). In both modes, the pruning strategy is invoked to determine whether to keep or prune newly constructed edges. For single-best output, the anytime mode can provide signficant time savings by cutting off the search early; see (White, 2004c) for discussion. For N-best output—especially when a complete search (up to the edges that survive the pruning strategy) is desirable—the two-stage mode can be more efficient. To illustrate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 th</context>
<context position="45935" citStr="Langkilde, 2000" startWordPosition="7497" endWordPosition="7499">5. The idea behind this strategy is to avoid having the N-best lists become full of signs whose words differ only in the exact gesture instance associated with one or more of the words. With this strategy, if two signs differ in just this way, the edge for the lowerscoring sign will be considered “not compellingly different” and pruned from the N-best list, making way for other edges whose signs exhibit more interesting differences. OpenCCG also provides a concrete subclass of DiversityPruningStrategy named NgramDiversityPruningStrategy, which generalizes the approach to pruning described in (Langkilde, 2000). With this class, two signs are considered not compellingly different if they share the same n−1 initial and final words, where n is the n-gram order. When one is interested in singlebest output, an n-gram diversity pruning strategy can increase efficiency while guaranteeing no loss in quality—as long as the reduction in the search space outweighs the extra time necessary to check for the same initial and final words—since any words in between an input sign’s n−1 initial and final ones cannot affect the n-gram score of a new sign formed from the input sign. However, when N-best outputs are de</context>
</contexts>
<marker>Langkilde, 2000</marker>
<rawString>Irene Langkilde. 2000. Forest-based statistical sentence generation. In Proc. NAACL-00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
</authors>
<title>The order of prenominal adjectives in natural language generation.</title>
<date>2000</date>
<booktitle>In Proc. ACL00.</booktitle>
<contexts>
<context position="17046" citStr="Malouf, 2000" startWordPosition="2788" endWordPosition="2789">-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective ordering in (Shaw and Hatzivassiloglou, 1999; Malouf, 2000). For instance, in examples like those in (1), they correctly select the preferred positions for here and also (as well as for the boundary tones), with respect to the verbal head and sister dependents: (1) a. HereL+H* LH% we have a design in the classicH* style LL% . b. ThisL+H* design LH% hereL+H* LH% is alsoH* classic LL% . We have also found that it can be useful to use reverse (or “right-to-left”) models, as they can help to place adverbs like though, as in (2): (2) The tiles are alsoH* from the JazzH* series though LL% . 2..n N−gram models can be of any order, can reverse the words, and </context>
</contexts>
<marker>Malouf, 2000</marker>
<rawString>Robert Malouf. 2000. The order of prenominal adjectives in natural language generation. In Proc. ACL00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanna Moore</author>
<author>Mary Ellen Foster</author>
<author>Oliver Lemon</author>
<author>Michael White</author>
</authors>
<title>Generating tailored, comparative descriptions in spoken dialogue.</title>
<date>2004</date>
<booktitle>In Proc. FLAIRS-04.</booktitle>
<contexts>
<context position="10377" citStr="Moore et al., 2004" startWordPosition="1600" endWordPosition="1603">urvive the pruning strategy) is desirable—the two-stage mode can be more efficient. To illustrate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 the crossvalidation tests reported in (White, 2004b). In these tests, we measured the realizer’s accuracy and speed, under a variety of configurations, on the regression test suites for two small but linguistically rich grammars: the English grammar for the COMIC2 dialogue system—the core of which is shared with the FLIGHTS system (Moore et al., 2004)—and the Worldcup grammar discussed in 2http://www.hcrc.ed.ac.uk/comic/ (Baldridge, 2002). Table 1 gives the sizes of the test suites. Using these two test suites, we timed how long it took on a 2.2 GHz Linux PC to realize each logical form under each realizer configuration. To measure accuracy, we counted the number of times the best scoring realization exactly matched the target, and also computed a modified version of the Bleu n-gram precision metric (Papineni et al., 2001) employed in machine translation evaluation, using 1- to 4-grams, with the longer n-grams given more weight (cf. Sectio</context>
</contexts>
<marker>Moore, Foster, Lemon, White, 2004</marker>
<rawString>Johanna Moore, Mary Ellen Foster, Oliver Lemon, and Michael White. 2004. Generating tailored, comparative descriptions in spoken dialogue. In Proc. FLAIRS-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A complete, efficient sentence-realization algorithm for unification grammar. In</title>
<date>2002</date>
<booktitle>Proc. INLG-02.</booktitle>
<contexts>
<context position="2190" citStr="Moore, 2002" startWordPosition="326" endWordPosition="327">ng the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing feature of OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization</context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>Robert C. Moore. 2002. A complete, efficient sentence-realization algorithm for unification grammar. In Proc. INLG-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice H Oh</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Stochastic natural language generation for spoken dialog systems.</title>
<date>2002</date>
<journal>Computer, Speech &amp; Language,</journal>
<pages>16--3</pages>
<contexts>
<context position="2396" citStr="Oh and Rudnicky, 2002" startWordPosition="351" endWordPosition="354">plements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversatio</context>
<context position="16367" citStr="Oh and Rudnicky, 2002" startWordPosition="2676" endWordPosition="2680">it on the n-gram order. To save memory and speed up equality tests, each string is interned (replaced with a canonical instance) at load time, which accomplishes the same purpose as replacing the strings with integers, but without the need to maintain a separate mapping from integers back to strings. For better generalization, certain words may be dynamically replaced with the names of their semantic classes when looking up n-gram probabilities. Words are assigned to semantic classes in the lexicon, and the semantic classes to use in this way may be configured at the grammar level. Note that (Oh and Rudnicky, 2002) and (Ratnaparkhi, 2002) make similar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investi</context>
</contexts>
<marker>Oh, Rudnicky, 2002</marker>
<rawString>Alice H. Oh and Alexander I. Rudnicky. 2002. Stochastic natural language generation for spoken dialog systems. Computer, Speech &amp; Language, 16(3/4):387–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2001</date>
<tech>Technical Report RC22176, IBM.</tech>
<contexts>
<context position="10858" citStr="Papineni et al., 2001" startWordPosition="1678" endWordPosition="1682">ly rich grammars: the English grammar for the COMIC2 dialogue system—the core of which is shared with the FLIGHTS system (Moore et al., 2004)—and the Worldcup grammar discussed in 2http://www.hcrc.ed.ac.uk/comic/ (Baldridge, 2002). Table 1 gives the sizes of the test suites. Using these two test suites, we timed how long it took on a 2.2 GHz Linux PC to realize each logical form under each realizer configuration. To measure accuracy, we counted the number of times the best scoring realization exactly matched the target, and also computed a modified version of the Bleu n-gram precision metric (Papineni et al., 2001) employed in machine translation evaluation, using 1- to 4-grams, with the longer n-grams given more weight (cf. Section 3.4). To rank candidate realizations, we used standard ngram backoff models of orders 2 through 6, with semantic class replacement, as described in Section 3.1. For smoothing, we used Ristad’s natural discounting (Ristad, 1995), a parameter-free method that seems to work well with relatively small amounts of data. To gauge how the amount of training data affects performance, we ran cross-validation tests with increasing numbers of folds, with 25 as the maximum number of fold</context>
<context position="34195" citStr="Papineni et al., 2001" startWordPosition="5640" endWordPosition="5643">els created with maximum likelihood estimation, as word-level interpolation with a base model avoids problems with zero probabilities in the cache model. As discussed in (Brockmann et al., 2005), cache models can be used to promote alignment with a conversational partner, by constructing a cache model from the bigrams in the partner’s previous turn, and interpolating it with a base model.4 Figure 11 shows one way to create such an interpolated model. 3.4 N-gram Precision Models The NgramPrecisionModel subclass of NgramScorer computes a modified version of the Bleu score used in MT evaluation (Papineni et al., 2001). Its constructor takes as input an array of target strings—from which it extracts the n-gram sequences to use in computing the n-gram precision score—and the desired order. Unlike with the Bleu score, rank order centroid weights (rather than the geometric mean) are used to combine scores of different orders, which avoids problems with scoring partial realizations which have no ngram matches of the target order. For simplicity, the score also does not include the Bleu score’s bells and whistles to make cheating on length difficult. We have found n-gram precision models to be very useful for re</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. Bleu: a Method for Automatic Evaluation of Machine Translation. Technical Report RC22176, IBM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Trainable approaches to surface natural language generation and their application to conversational dialog systems.</title>
<date>2002</date>
<journal>Computer, Speech &amp; Language,</journal>
<pages>16--3</pages>
<contexts>
<context position="2416" citStr="Ratnaparkhi, 2002" startWordPosition="355" endWordPosition="356">lic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversational partner (Brockma</context>
<context position="16391" citStr="Ratnaparkhi, 2002" startWordPosition="2682" endWordPosition="2683">ave memory and speed up equality tests, each string is interned (replaced with a canonical instance) at load time, which accomplishes the same purpose as replacing the strings with integers, but without the need to maintain a separate mapping from integers back to strings. For better generalization, certain words may be dynamically replaced with the names of their semantic classes when looking up n-gram probabilities. Words are assigned to semantic classes in the lexicon, and the semantic classes to use in this way may be configured at the grammar level. Note that (Oh and Rudnicky, 2002) and (Ratnaparkhi, 2002) make similar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective orde</context>
</contexts>
<marker>Ratnaparkhi, 2002</marker>
<rawString>Adwait Ratnaparkhi. 2002. Trainable approaches to surface natural language generation and their application to conversational dialog systems. Computer, Speech &amp; Language, 16(3/4):435–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric S Ristad</author>
</authors>
<title>A Natural Law of Succession.</title>
<date>1995</date>
<tech>Technical Report CS-TR-495-95,</tech>
<institution>Princeton Univ.</institution>
<contexts>
<context position="11206" citStr="Ristad, 1995" startWordPosition="1736" endWordPosition="1737">ealize each logical form under each realizer configuration. To measure accuracy, we counted the number of times the best scoring realization exactly matched the target, and also computed a modified version of the Bleu n-gram precision metric (Papineni et al., 2001) employed in machine translation evaluation, using 1- to 4-grams, with the longer n-grams given more weight (cf. Section 3.4). To rank candidate realizations, we used standard ngram backoff models of orders 2 through 6, with semantic class replacement, as described in Section 3.1. For smoothing, we used Ristad’s natural discounting (Ristad, 1995), a parameter-free method that seems to work well with relatively small amounts of data. To gauge how the amount of training data affects performance, we ran cross-validation tests with increasing numbers of folds, with 25 as the maximum number of folds. We also compared the realization results using the n-gram scorers with two baselines and one topline (oracle method). The first baseline assigns all strings a uniform score of zero, and adds new edges to the end of the agenda, corresponding to breadth-first search. The LF/target Unique up Length Input nodes pairs to SC Mean Min MaxNMean Min Ma</context>
</contexts>
<marker>Ristad, 1995</marker>
<rawString>Eric S. Ristad. 1995. A Natural Law of Succession. Technical Report CS-TR-495-95, Princeton Univ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Ordering among premodifiers.</title>
<date>1999</date>
<booktitle>In Proc. ACL-99.</booktitle>
<contexts>
<context position="17031" citStr="Shaw and Hatzivassiloglou, 1999" startWordPosition="2784" endWordPosition="2787">ilar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective ordering in (Shaw and Hatzivassiloglou, 1999; Malouf, 2000). For instance, in examples like those in (1), they correctly select the preferred positions for here and also (as well as for the boundary tones), with respect to the verbal head and sister dependents: (1) a. HereL+H* LH% we have a design in the classicH* style LL% . b. ThisL+H* design LH% hereL+H* LH% is alsoH* classic LL% . We have also found that it can be useful to use reverse (or “right-to-left”) models, as they can help to place adverbs like though, as in (2): (2) The tiles are alsoH* from the JazzH* series though LL% . 2..n N−gram models can be of any order, can reverse </context>
</contexts>
<marker>Shaw, Hatzivassiloglou, 1999</marker>
<rawString>James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proc. ACL-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hadar Shemtov</author>
</authors>
<date>1997</date>
<booktitle>Ambiguity Management in Natural Language Generation. Ph.D. thesis,</booktitle>
<institution>Stanford University.</institution>
<contexts>
<context position="2154" citStr="Shemtov, 1997" startWordPosition="319" endWordPosition="320">akes as input a logical form specifying the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing feature of OpenCCG is that it implements a hybrid symbolic-statistical chart realization algorithm that combines (1) a theoretically grounded approach to syntax and semantic composition, with (2) the use of integrated language models for making choices among the options left open by the grammar (thereby reducing the need for hand-crafted rules). In contrast, previous chart realizers (Kay, 1996; Shemtov, 1997; Carroll et al., 1999; Moore, 2002) have not included a statistical component, while previous statistical realizers (Knight and Hatzivassiloglou, 1995; Langkilde, 2000; Bangalore and Rambow, 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrati</context>
</contexts>
<marker>Shemtov, 1997</marker>
<rawString>Hadar Shemtov. 1997. Ambiguity Management in Natural Language Generation. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Information structure and the syntax-phonology interface.</title>
<date>2000</date>
<journal>Linguistic Inquiry,</journal>
<volume>31</volume>
<issue>4</issue>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000a. Information structure and the syntax-phonology interface. Linguistic Inquiry, 31(4):649–689.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000b. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM — An extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. ICSLP-02.</booktitle>
<contexts>
<context position="15210" citStr="Stolcke, 2002" startWordPosition="2483" endWordPosition="2484">g models can more than pay for themselves, efficiency-wise, if they yield significantly more accurate preference orders on edges. 3 Classes for Scoring Signs The classes for implementing sign scorers appear in Figure 6. In the diagram, classes for n-gram scoring appear towards the bottom, while classes for combining scorers appear on the left, and the class for avoiding repetition appears on the right. 3.1 Standard N-gram Models The StandardNgramModel class can load standard n-gram backoff models for scoring, as shown earlier in Figure 2. Such models can be constructed with the SRILM toolkit (Stolcke, 2002), which we have found to be very useful; in principle, other toolkits could be used instead, as long as their output could be converted into the same file formats. Since the SRILM toolkit has more restrictive licensing conditions than those of OpenCCG’s LGPL license, OpenCCG includes its own classes for scoring with n-gram models, in order to avoid any necessary runtime dependencies on the SRILM toolkit. The n-gram tables are efficiently stored in a trie data structure (as in the SRILM toolkit), thereby avoiding any arbitrary limit on the n-gram order. To save memory and speed up equality test</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM — An extensible language modeling toolkit. In Proc. ICSLP-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
<author>Jason Baldridge</author>
</authors>
<title>Adapting Chart Realization to CCG. In</title>
<date>2003</date>
<booktitle>Proc. EWNLG-03.</booktitle>
<contexts>
<context position="1144" citStr="White and Baldridge, 2003" startWordPosition="166" endWordPosition="169">, avoid repetitive language use, and increase the speed of the best-first anytime search. The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies. The n-gram models may be of any order, operate in reverse (“right-to-left”), and selectively replace certain words with their semantic classes. Factored language models with generalized backoff may also be employed, over words represented as bundles of factors such as form, pitch accent, stem, part of speech, supertag, and semantic class. 1 Introduction The OpenCCG1 realizer (White and Baldridge, 2003; White, 2004a; White, 2004c) is an open source surface realizer for Steedman’s (2000a; 2000b) Combinatory Categorial Grammar (CCG). It is designed to be the first practical, reusable realizer for CCG, and includes implementations of 1http://openccg.sourceforge.net CCG’s unique accounts of coordination and information structure–based prosody. Like other surface realizers, the OpenCCG realizer takes as input a logical form specifying the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing f</context>
</contexts>
<marker>White, Baldridge, 2003</marker>
<rawString>Michael White and Jason Baldridge. 2003. Adapting Chart Realization to CCG. In Proc. EWNLG-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Efficient Realization of Coordinate Structures in Combinatory Categorial Grammar. Research on Language and Computation.</title>
<date>2004</date>
<note>To appear.</note>
<contexts>
<context position="1157" citStr="White, 2004" startWordPosition="170" endWordPosition="171"> use, and increase the speed of the best-first anytime search. The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies. The n-gram models may be of any order, operate in reverse (“right-to-left”), and selectively replace certain words with their semantic classes. Factored language models with generalized backoff may also be employed, over words represented as bundles of factors such as form, pitch accent, stem, part of speech, supertag, and semantic class. 1 Introduction The OpenCCG1 realizer (White and Baldridge, 2003; White, 2004a; White, 2004c) is an open source surface realizer for Steedman’s (2000a; 2000b) Combinatory Categorial Grammar (CCG). It is designed to be the first practical, reusable realizer for CCG, and includes implementations of 1http://openccg.sourceforge.net CCG’s unique accounts of coordination and information structure–based prosody. Like other surface realizers, the OpenCCG realizer takes as input a logical form specifying the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing feature of Ope</context>
<context position="2956" citStr="White, 2004" startWordPosition="434" endWordPosition="435"> 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversational partner (Brockmann et al., 2005), and avoid repetitive language use. In addition, by integrating language model scoring into the search, it also becomes possible to use more accurate models to improve realization times, when the realizer is run in anytime mode (White, 2004b). To allow language models to be combined in flexible ways—as well as to enable research on how to best combine language modeling and realization—OpenCCG’s design includes interfaces that allow user-defined functions to be used for scoring partial realizations and for pruning low-</context>
<context position="6750" citStr="White, 2004" startWordPosition="1058" endWordPosition="1059">on when one exists. By default, an N-best pruning strategy is employed, which keeps the N highest scoring input edges, pruning the rest (where N is determined by the current preference settings). The realization algorithm is implemented by the realize method. As in the chart realizers cited earlier, the algorithm makes use of a chart and an agenda to perform a bottom-up dynamic programming search for signs whose LFs completely cover the elementary predications in the input logical form. See Figure 9 (Section 3.1) for a realization trace; the algorithm’s details and a worked example appear in (White, 2004a; White, 2004c). The realize method returns the edge for the best realization of the input LF, as determined by the sign scorer. After a realization request, the N-best complete edges—or more generally, all the edges for complete realizations that survived pruning— are also available from the chart. The search for complete realizations proceeds in one of two modes, anytime and two-stage (packing/unpacking). In the anytime mode, a bestfirst search is performed with a configurable time limit (which may be a limit on how long to look for a better realization, after the first complete one is foun</context>
<context position="9664" citStr="White, 2004" startWordPosition="1486" endWordPosition="1487">ealize(lf); Document outputDoc = bestEdge.sign.getWordsInXml(); // return output ... outputDoc ...; Figure 2: Example realizer usage of all possible realizations is created in the first stage; then in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). In both modes, the pruning strategy is invoked to determine whether to keep or prune newly constructed edges. For single-best output, the anytime mode can provide signficant time savings by cutting off the search early; see (White, 2004c) for discussion. For N-best output—especially when a complete search (up to the edges that survive the pruning strategy) is desirable—the two-stage mode can be more efficient. To illustrate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 the crossvalidation tests reported in (White, 2004b). In these tests, we measured the realizer’s accuracy and speed, under a variety of configurations, on the regression test suites for two small but linguistically rich grammars: the Englis</context>
<context position="16750" citStr="White, 2004" startWordPosition="2745" endWordPosition="2746"> semantic classes when looking up n-gram probabilities. Words are assigned to semantic classes in the lexicon, and the semantic classes to use in this way may be configured at the grammar level. Note that (Oh and Rudnicky, 2002) and (Ratnaparkhi, 2002) make similar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective ordering in (Shaw and Hatzivassiloglou, 1999; Malouf, 2000). For instance, in examples like those in (1), they correctly select the preferred positions for here and also (as well as for the boundary tones), with respect to the verbal head and sister dependents: (1) a. HereL+H* LH% we have a design in the classicH* style LL% . b. ThisL+H* design LH% hereL+H* LH%</context>
<context position="21458" citStr="White, 2004" startWordPosition="3444" endWordPosition="3445">a very clear preference for the clause-final position of though, and for this reason interpolating the forward and reverse models (see Section 3.3) also yields the desired preference order. Figure 9 shows a trace of realizing (2) with such an interpolated model. In the trace, the interpolated model is loaded by the class MyEvenScorer. The input LF appears at the top. It is flattened into a list of elementary predications, so that coverage of these predications can be tracked using bit vectors. The LF chunks ensure that the subtrees under h1 and s1 are realized as independent subproblems; cf. (White, 2004a) for discussion. The edges produced by lexical lookup and instantiation appear next, under the heading Initial Edges, with only the edges for alsoH* and though shown in the figure. For each edge, the coverage percentage and score (here a probability) appear first, followed by the word(s) and the coverage vector, then the syntactic category (with features suppressed), and finally any active LF chunks. The edges added to the chart appear (unsorted) under the heading All Edges. As this trace shows, in the best-first search, high probability phrases such as the tiles are alsoH* can be added to t</context>
</contexts>
<marker>White, 2004</marker>
<rawString>Michael White. 2004a. Efficient Realization of Coordinate Structures in Combinatory Categorial Grammar. Research on Language and Computation. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Experiments with multimodal output in human-machine interaction.</title>
<date>2004</date>
<journal>IST Project COMIC Public Deliverable</journal>
<volume>7</volume>
<contexts>
<context position="1157" citStr="White, 2004" startWordPosition="170" endWordPosition="171"> use, and increase the speed of the best-first anytime search. The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies. The n-gram models may be of any order, operate in reverse (“right-to-left”), and selectively replace certain words with their semantic classes. Factored language models with generalized backoff may also be employed, over words represented as bundles of factors such as form, pitch accent, stem, part of speech, supertag, and semantic class. 1 Introduction The OpenCCG1 realizer (White and Baldridge, 2003; White, 2004a; White, 2004c) is an open source surface realizer for Steedman’s (2000a; 2000b) Combinatory Categorial Grammar (CCG). It is designed to be the first practical, reusable realizer for CCG, and includes implementations of 1http://openccg.sourceforge.net CCG’s unique accounts of coordination and information structure–based prosody. Like other surface realizers, the OpenCCG realizer takes as input a logical form specifying the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing feature of Ope</context>
<context position="2956" citStr="White, 2004" startWordPosition="434" endWordPosition="435"> 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversational partner (Brockmann et al., 2005), and avoid repetitive language use. In addition, by integrating language model scoring into the search, it also becomes possible to use more accurate models to improve realization times, when the realizer is run in anytime mode (White, 2004b). To allow language models to be combined in flexible ways—as well as to enable research on how to best combine language modeling and realization—OpenCCG’s design includes interfaces that allow user-defined functions to be used for scoring partial realizations and for pruning low-</context>
<context position="6750" citStr="White, 2004" startWordPosition="1058" endWordPosition="1059">on when one exists. By default, an N-best pruning strategy is employed, which keeps the N highest scoring input edges, pruning the rest (where N is determined by the current preference settings). The realization algorithm is implemented by the realize method. As in the chart realizers cited earlier, the algorithm makes use of a chart and an agenda to perform a bottom-up dynamic programming search for signs whose LFs completely cover the elementary predications in the input logical form. See Figure 9 (Section 3.1) for a realization trace; the algorithm’s details and a worked example appear in (White, 2004a; White, 2004c). The realize method returns the edge for the best realization of the input LF, as determined by the sign scorer. After a realization request, the N-best complete edges—or more generally, all the edges for complete realizations that survived pruning— are also available from the chart. The search for complete realizations proceeds in one of two modes, anytime and two-stage (packing/unpacking). In the anytime mode, a bestfirst search is performed with a configurable time limit (which may be a limit on how long to look for a better realization, after the first complete one is foun</context>
<context position="9664" citStr="White, 2004" startWordPosition="1486" endWordPosition="1487">ealize(lf); Document outputDoc = bestEdge.sign.getWordsInXml(); // return output ... outputDoc ...; Figure 2: Example realizer usage of all possible realizations is created in the first stage; then in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). In both modes, the pruning strategy is invoked to determine whether to keep or prune newly constructed edges. For single-best output, the anytime mode can provide signficant time savings by cutting off the search early; see (White, 2004c) for discussion. For N-best output—especially when a complete search (up to the edges that survive the pruning strategy) is desirable—the two-stage mode can be more efficient. To illustrate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 the crossvalidation tests reported in (White, 2004b). In these tests, we measured the realizer’s accuracy and speed, under a variety of configurations, on the regression test suites for two small but linguistically rich grammars: the Englis</context>
<context position="16750" citStr="White, 2004" startWordPosition="2745" endWordPosition="2746"> semantic classes when looking up n-gram probabilities. Words are assigned to semantic classes in the lexicon, and the semantic classes to use in this way may be configured at the grammar level. Note that (Oh and Rudnicky, 2002) and (Ratnaparkhi, 2002) make similar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective ordering in (Shaw and Hatzivassiloglou, 1999; Malouf, 2000). For instance, in examples like those in (1), they correctly select the preferred positions for here and also (as well as for the boundary tones), with respect to the verbal head and sister dependents: (1) a. HereL+H* LH% we have a design in the classicH* style LL% . b. ThisL+H* design LH% hereL+H* LH%</context>
<context position="21458" citStr="White, 2004" startWordPosition="3444" endWordPosition="3445">a very clear preference for the clause-final position of though, and for this reason interpolating the forward and reverse models (see Section 3.3) also yields the desired preference order. Figure 9 shows a trace of realizing (2) with such an interpolated model. In the trace, the interpolated model is loaded by the class MyEvenScorer. The input LF appears at the top. It is flattened into a list of elementary predications, so that coverage of these predications can be tracked using bit vectors. The LF chunks ensure that the subtrees under h1 and s1 are realized as independent subproblems; cf. (White, 2004a) for discussion. The edges produced by lexical lookup and instantiation appear next, under the heading Initial Edges, with only the edges for alsoH* and though shown in the figure. For each edge, the coverage percentage and score (here a probability) appear first, followed by the word(s) and the coverage vector, then the syntactic category (with features suppressed), and finally any active LF chunks. The edges added to the chart appear (unsorted) under the heading All Edges. As this trace shows, in the best-first search, high probability phrases such as the tiles are alsoH* can be added to t</context>
</contexts>
<marker>White, 2004</marker>
<rawString>Michael White. 2004b. Experiments with multimodal output in human-machine interaction. IST Project COMIC Public Deliverable 7.4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Reining in CCG Chart Realization. In</title>
<date>2004</date>
<booktitle>Proc. INLG-04.</booktitle>
<contexts>
<context position="1157" citStr="White, 2004" startWordPosition="170" endWordPosition="171"> use, and increase the speed of the best-first anytime search. The API enables a variety of n-gram models to be easily combined and used in conjunction with appropriate edge pruning strategies. The n-gram models may be of any order, operate in reverse (“right-to-left”), and selectively replace certain words with their semantic classes. Factored language models with generalized backoff may also be employed, over words represented as bundles of factors such as form, pitch accent, stem, part of speech, supertag, and semantic class. 1 Introduction The OpenCCG1 realizer (White and Baldridge, 2003; White, 2004a; White, 2004c) is an open source surface realizer for Steedman’s (2000a; 2000b) Combinatory Categorial Grammar (CCG). It is designed to be the first practical, reusable realizer for CCG, and includes implementations of 1http://openccg.sourceforge.net CCG’s unique accounts of coordination and information structure–based prosody. Like other surface realizers, the OpenCCG realizer takes as input a logical form specifying the propositional meaning of a sentence, and returns one or more surface strings that express this meaning according to the lexicon and grammar. A distinguishing feature of Ope</context>
<context position="2956" citStr="White, 2004" startWordPosition="434" endWordPosition="435"> 2000; Langkilde-Geary, 2002; Oh and Rudnicky, 2002; Ratnaparkhi, 2002) have employed less general approaches to semantic representation and composition, and have not typically made use of finegrained logical forms that include specifications of such information structural notions as theme, rheme and focus. In this paper, we present OpenCCG’s extensible API (application programming interface) for integrating language modeling and realization, describing its design and efficient implementation in Java. With OpenCCG, language models may be used to select realizations with preferred word orders (White, 2004c), promote alignment with a conversational partner (Brockmann et al., 2005), and avoid repetitive language use. In addition, by integrating language model scoring into the search, it also becomes possible to use more accurate models to improve realization times, when the realizer is run in anytime mode (White, 2004b). To allow language models to be combined in flexible ways—as well as to enable research on how to best combine language modeling and realization—OpenCCG’s design includes interfaces that allow user-defined functions to be used for scoring partial realizations and for pruning low-</context>
<context position="6750" citStr="White, 2004" startWordPosition="1058" endWordPosition="1059">on when one exists. By default, an N-best pruning strategy is employed, which keeps the N highest scoring input edges, pruning the rest (where N is determined by the current preference settings). The realization algorithm is implemented by the realize method. As in the chart realizers cited earlier, the algorithm makes use of a chart and an agenda to perform a bottom-up dynamic programming search for signs whose LFs completely cover the elementary predications in the input logical form. See Figure 9 (Section 3.1) for a realization trace; the algorithm’s details and a worked example appear in (White, 2004a; White, 2004c). The realize method returns the edge for the best realization of the input LF, as determined by the sign scorer. After a realization request, the N-best complete edges—or more generally, all the edges for complete realizations that survived pruning— are also available from the chart. The search for complete realizations proceeds in one of two modes, anytime and two-stage (packing/unpacking). In the anytime mode, a bestfirst search is performed with a configurable time limit (which may be a limit on how long to look for a better realization, after the first complete one is foun</context>
<context position="9664" citStr="White, 2004" startWordPosition="1486" endWordPosition="1487">ealize(lf); Document outputDoc = bestEdge.sign.getWordsInXml(); // return output ... outputDoc ...; Figure 2: Example realizer usage of all possible realizations is created in the first stage; then in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). In both modes, the pruning strategy is invoked to determine whether to keep or prune newly constructed edges. For single-best output, the anytime mode can provide signficant time savings by cutting off the search early; see (White, 2004c) for discussion. For N-best output—especially when a complete search (up to the edges that survive the pruning strategy) is desirable—the two-stage mode can be more efficient. To illustrate how n-gram scoring can guide the best-first anytime search towards preferred realizations and reduce realization times, we reproduce in Table 1 and Figures 3 through 5 the crossvalidation tests reported in (White, 2004b). In these tests, we measured the realizer’s accuracy and speed, under a variety of configurations, on the regression test suites for two small but linguistically rich grammars: the Englis</context>
<context position="16750" citStr="White, 2004" startWordPosition="2745" endWordPosition="2746"> semantic classes when looking up n-gram probabilities. Words are assigned to semantic classes in the lexicon, and the semantic classes to use in this way may be configured at the grammar level. Note that (Oh and Rudnicky, 2002) and (Ratnaparkhi, 2002) make similar use of semantic classes in n-gram scoring, by deferring the instantiation of classes (such as departure city) until the end of the generation process; our approach accomplishes the same goal in a slightly more flexible way, in that it also allows the specific word to be examined by other scoring models, if desired. As discussed in (White, 2004c), with dialogue systems like COMIC n-gram models can do an excellent job of placing underconstrained adjectival and adverbial modifiers—as well as boundary tones—without resorting to the more complex methods investigated for adjective ordering in (Shaw and Hatzivassiloglou, 1999; Malouf, 2000). For instance, in examples like those in (1), they correctly select the preferred positions for here and also (as well as for the boundary tones), with respect to the verbal head and sister dependents: (1) a. HereL+H* LH% we have a design in the classicH* style LL% . b. ThisL+H* design LH% hereL+H* LH%</context>
<context position="21458" citStr="White, 2004" startWordPosition="3444" endWordPosition="3445">a very clear preference for the clause-final position of though, and for this reason interpolating the forward and reverse models (see Section 3.3) also yields the desired preference order. Figure 9 shows a trace of realizing (2) with such an interpolated model. In the trace, the interpolated model is loaded by the class MyEvenScorer. The input LF appears at the top. It is flattened into a list of elementary predications, so that coverage of these predications can be tracked using bit vectors. The LF chunks ensure that the subtrees under h1 and s1 are realized as independent subproblems; cf. (White, 2004a) for discussion. The edges produced by lexical lookup and instantiation appear next, under the heading Initial Edges, with only the edges for alsoH* and though shown in the figure. For each edge, the coverage percentage and score (here a probability) appear first, followed by the word(s) and the coverage vector, then the syntactic category (with features suppressed), and finally any active LF chunks. The edges added to the chart appear (unsorted) under the heading All Edges. As this trace shows, in the best-first search, high probability phrases such as the tiles are alsoH* can be added to t</context>
</contexts>
<marker>White, 2004</marker>
<rawString>Michael White. 2004c. Reining in CCG Chart Realization. In Proc. INLG-04.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>