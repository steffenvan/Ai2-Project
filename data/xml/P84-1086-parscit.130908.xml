<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.628057333333333">
DEALING WITH INCOMPLETENESS OF LINGUISTIC KNOWLEDGE
IN LANGUAGE TRANSLATION
-- TRANSFER AND GENERATION STAGE OF MU MACHINE TRANSLATION PROJECT --
</note>
<author confidence="0.814275">
Makoto Nagao, Toyoaki Nishida and Jun-ichi Tsujii
</author>
<affiliation confidence="0.782320333333333">
Department of Electrical Engineering
Kyoto University
Sakyo-ku, Kyoto 606, JAPAN
</affiliation>
<sectionHeader confidence="0.986121" genericHeader="abstract">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99950825">
Linguistic knowledge usable for machine trans-
lation is always imperfect. We cannot be free from
the uncertainty of knowledge we have for machine
translation. Especially at the transfer stage of
machine translation, the selection of target lan-
guage expression is rather subjective and optional.
Therefore the linguistic contents of machine
translation system always fluctuate, and make
gradual progress. The system should be designed to
allow such constant change and improvements. This
paper explains the details of the transfer and gen-
eration stages of Japanese-to-English system of the
machine translation project by the Japanese Govern-
ment, with the emphasis on the ideas to deal with
the incompleteness of linguistic knowledge for
machine translation.
</bodyText>
<sectionHeader confidence="0.751066" genericHeader="method">
2. DESIGN STRATEGIES
2.1 Annotated Dependency Structure
</sectionHeader>
<bodyText confidence="0.999901818181818">
The intermediate representation we adopted as
the result of analysis in our machine translation
is the annotated dependency structure. Each node
has arbitrary number of features as shown in Fig. 1.
This makes it possible to access the constituents
by more than one linguistic cues. This representa-
tion is therefore powerful and flexible for the
sophisticated grammatical and semantic checking,
especially when the completeness of semantic analy-
sis is not assured and trial-and-error improvements
are required at the transfer and generation stages.
</bodyText>
<subsectionHeader confidence="0.942453">
2.2 Multiple Laver Grammar
</subsectionHeader>
<bodyText confidence="0.9995154375">
We have three conceptual levels for grammar
rules.
lowest level: default grammar which guarantees the
output of the translation process. The quality
of the translation is not assured. Rules of
this level apply to those inputs for which no
higher layer grammar rules are applicable.
kernel level: main grammar which chooses and gener-
ates target language structure according to
semantic relations among constituents which are
determined in the analysis stage.
topmost level: heuristic grammar which attempts to
get elegant translation for the input. Each
rule bears heuristic nature in the sense that it
is word specific and it is applicable only to
some restricted classes of inputs.
</bodyText>
<subsectionHeader confidence="0.727112">
2.3 Multiple Relation Structure
</subsectionHeader>
<bodyText confidence="0.988344510638298">
In principle, we use deep case dependency
structure as a semantic representation. Theoreti-
cally we can assign a unique case dependency struc-
ture to each input sentence. In practice, however,
analysis phase may fail or may assign a wrong
structure. Therefore we use as an intermediate
representation a structure which makes it possible
to annotate multiple possibilities as well as mul-
tiple level representation. An example is shown in
Fig. 2. Properties at a node is represented as a
vector, so that this complex dependency structure
is flexible in the sense that different interpreta-
tion rules can be applied to the structure.
2.4 Lexicon Driven Feature
Besides the transfer and generation rules
which involve semantic checking functions, the
grammar allows the reference to a lexical item in
the dictionary. A lexical item contains its spe-
cial grammatical usages and idiomatic expressions.
During the transfer and generation stages, there
rules are activated with the highest priority.
This feature makes the system very flexible for .
dealing with exceptional cases. The improvement of
translation quality can be achieved progressively
by adding linguistic information and word usages in
the dictionary entries.
2.5 Format-Oriented Description of Dictionary
Entries
The quality of a machine translation system
heavily depends on the quality of the dictionary.
In order to build a machine translation dictionary,
we collaborate with expert translators. We develop-
ed a format-oriented language to allow computer-
naive human translators to encode their expertise
without any conscious effort on programming.
Although the format-oriented language we developed
lacks full expressive power for highly sophisticat-
ed linguistic phenomena, it can cover most of the
common lexical information translators may want to
describe. The formatted description is automati-
cally converted into statements in GRADE, a pro-
gramming language developed by the Mu-Project. We
prepared a manual according to which a man can fill
in the dictionary format with linguistic data of
items. The manual guarantees a certain level of
quality of the dictionary, which is important when
many people have to work in parallel.
</bodyText>
<page confidence="0.992566">
420
</page>
<note confidence="0.95355">
tr--Z-ttaWrIODI,T:113 P4t.lig Vitt b0
(Due to the advance of electronic instrumentation, automated ship increases in number.)
</note>
<figure confidence="0.953183851063829">
his work
J-CAT= Verb
J-LEX = 3D&apos;t ,6 (increase)
.1-DEEP-CASE = MAIN
J-GAP=XSOUrce GOAD&apos;
.1-SENTENCE-CONNECTOR =DECLARATIVE
.1-SENTENCE-RELATION =NIL
J-SENTENCE-END= NIL
.1-DEEP-TENSE = PRESENT
J-DEEP-ASPECT=BeyondTime
J-DEEP-MODE =NIL
J.VERB-ASPECT= TRANSITIVE
J-VERB-INT= NO
J-VERB-PAT = -C. t. s.
J-VERB-SD=.1 t -SUBject -CAUse
J-NEG =NIL
.1-CAT = Noun
J-LEX Oladvancel
J-DEEP-CASE CAUse
.1-SURFACE-CASE
.1-CAT= Noun
J-LEX=ZIKItala
(electronic instrumentation)
a-DEEP-CASE = SUBject
.1-SURFACE-CASE =
.1-CAT- Noun
.1-LEX = NIL
J-DEEP-CASE=SOUrce
.1-SURFACE-CASE
.1-CAT = Noun
.1-LEX Itlautornated ship)
J-DEEP-CASE = SUBje et
.1-SURFACE-CASE O&apos;
J-E4KK-LEX 5,
.1-NT-NIL
J-DEEP-BFKI--3 =NIL
a-SURFACE-8FM —3 =NIL
J-BFK-LEXI--3 = NIL
J-N=CommonNoun
J.SEM=0M(artificial object)
.1-NUMBER- NIL
.1-CAT =Noun
.J-LEX =NIL
J-DEEP-CASE= GOAI
J-SURFACE-CASE I ) D&apos;
..............
dummy nodes
</figure>
<figureCaption confidence="0.999778">
Fig. 1. Representation of analysis result by features.
</figureCaption>
<sectionHeader confidence="0.998674" genericHeader="method">
3. ORGANIZATION OF GRAMMAR RULES FOR TRANSFER
AND GENERATION STAGES
</sectionHeader>
<subsectionHeader confidence="0.986861">
3.1 Heuristic Rule First
</subsectionHeader>
<bodyText confidence="0.907282333333333">
[3-LEX = work, ... ]Grammar rules are organized along the princi-
ple that &amp;quot;if better rule exists then the system
work work i uses it; otherwise the system attempts to use a
</bodyText>
<equation confidence="0.78984425">
1 1 J-LEX = he
1 standard rule: if it fails, the system will use a
agent OR possess J-DEEP-CASE default rule.&amp;quot; The grammar rule involves a number
I 1L
</equation>
<bodyText confidence="0.92875325">
= agent OR posessj
of stages for applying heuristic rules. Fig. 3
he he shows a processing flow for the transfer and gener-
ation stages.
</bodyText>
<figureCaption confidence="0.807935">
Fig. 2. An example of complex dependency structure.
</figureCaption>
<bodyText confidence="0.843135">
Heuristic rules are word specific. GRADEmakes
it possible to define word specific rules. Such
rules can be invoked in many ways. For example, we
can associate a word selection rule for an ordinary
verb in a dictionary entry for a noun, as shown in
Fig. 4.
</bodyText>
<page confidence="0.997595">
421
</page>
<bodyText confidence="0.9747494">
post-transfer
loop
internal TRANSFER
representation
for Japanese
</bodyText>
<figureCaption confidence="0.540228">
Fig. 3. Processing flow for the transfer and generation stages.
</figureCaption>
<subsectionHeader confidence="0.97217">
3.2 Pre-transfer Rules
</subsectionHeader>
<bodyText confidence="0.999691625">
Some heuristic rules
are activated just after the
standard analysis of a
Japanese sentence is finish-
ed, to obtain a more neutral
(or target language oriented)
analyzed structure. We call
such invocation the pre-
transfer loop. Semantic and
pragmatic interpretation are
done in the pre-transfer
loop. The more heuristic
rules are applied in this
loop, the better result will
be obtained. Figs. 5 and 6
show some examples.
</bodyText>
<figure confidence="0.968142690476191">
\ GENERATION
phrase
structure
tree
structure
transformation
MORPHOLOGICAL
SYNTHESIS
ANALYSIS
pre-transfer
loop
internal
representation
for English
(a) Activating a Lexical Rule for a Noun &amp;quot;OA&amp;quot;(effect) from a Governing Verb &amp;quot;44 b &amp;quot;(give).
J-CAT.• Verb
J-LEX= i B (give)
• ..
TRANSFER
.1-CAT= Verb
.1 LEX =affect
/ - /
.J-CAT = Noun - SUBGRAMMAR:itb -V-TRANSFER
J-LEX= fib A(effect) dealing with cases like:
.1-DEEP-CASE OBJect
J-N-V-PROG= -V-TRANSFER ----------
J-N-KOUSETSU = -KOUSETSU-TRANSFE R
1.■
other subgramnmm
—11&amp;quot;- affected, affect, -
(have), (give)
IhiB)effect)
&lt;VERB &gt;: , ,
(b) Form-Oriented Description of a Transfer Rule for a Noun &amp;quot;ZA.&amp;quot;(effect)
D.
A-
C.
Lel.* •••-•
It t EFFECT 7- ; , I.
• IfFICIITIS S.t
e
a
</figure>
<listItem confidence="0.988311428571429">
•
• ••• lieu&amp; It • II e t.
•
•
•
AI, 4 6 TM 0 EFFECT 1TE
iyi ,• i T H 46 1/11.111.LIZE,.
. 1 • 0 I IMMO it • II C L
:
*.“, R f C Tw EFF[GT
: 11X111•L
:
• (i iI•• , ily it A el lAir• •Irm1
•
</listItem>
<bodyText confidence="0.501911285714286">
NJ , . , 4
.
if 8il suf3 oe7 RE c
:1
a •ae,.. &amp;quot;.). MGC olG I MG 1 MG 3
A rr6 C / !! SuOI a ey
i; Ai, I&apos; 00,
</bodyText>
<figure confidence="0.942906">
:1 Sul5 CSC.
1 1 3
I: A
• I
2) 1... .1.
II • • it NJ GIG • I kaGI GIG I M. 3
U
•
:1
I 3
:I a
:I
;1
NI MG X GIG I GIG I GIG I
El
i I
:i
</figure>
<subsectionHeader confidence="0.862483">
3.3 Word Selection in
</subsectionHeader>
<bodyText confidence="0.9903073">
Target Language by.
Using_ Semantic Markers
Word selection in the
target language is a big
problem in machine transla-
tion. There are varieties
of choices of translation
for a word in the source
language. Main principles
adopted in our system are,
</bodyText>
<listItem confidence="0.844550071428572">
(1) Area restriction by
using field code, such
as electrical Engineer-
ing, nuclear science,
medicine, and so on.
(2) Semantic code attached
to a word in the analy-
sis phase is used for
the selection of a proper
target language word or
a phrase.
(3) Sentential structure of
the vicinity of a word
to be translated is
</listItem>
<bodyText confidence="0.96362455">
sometimes effective for
the determination of a
proper word or a phrase
in the target language.
Table 1 shows examples
of a part of the verb trans-
fer dictionary. Selection
of English verb is done by
the semantic categories of
nouns related to the verb.
The number i attached to
verbs like form-1, produce-
2 is the i-th usage of the
verb. When the semantic
information of nouns is not
available, the column indi-
cated by (I) is applied to
Fig. 4. Lexicon-oriented
invocation of grammar
rules.
</bodyText>
<page confidence="0.979594">
422
</page>
<figure confidence="0.9556187">
J-CAT= Noun ,J-CAT= Noun
J.LEX = fi expression J-LEX = VA expression)
J-CAT = Verb J-CAT= ADJ ective
.1-LEX =r tdo not have) .1-LEX = (meaningless)
.1-DEEP-CASE = MOD .1-DEEP-CASE =MOD
J-CAT= Noun
J-LEX = (sense)
J-DEEP-CASE=SUBject
.1-CAT= Noun
J•LEX=NIL
(dummy node)
../
&amp;quot;expression which does not have sense&amp;quot; &amp;quot;meaningless expression&amp;quot;
Fig. 5. An example of a heuristic rule used in the
pre-transfer loop.
( )1_-__&amp;LL___ logarithmic
-
logarithmic have integral
characteristics equation
integral integral
equation equation
have with
sNP
integral logarithmic logarithmic
equation characteristics characteristics
(2) 1544- lz -Y-Z3 *t1L
conductivity give effect
effect effect
give
conductivity
</figure>
<bodyText confidence="0.992586055555555">
produce a default translation.
In most cases, we can use a fixed
format for describing a translation rule
for lexical items. We developed a num-
ber of dictionary formats specially
designed for the ease of dictionary in-
put by computer-naive expert translators.
The expressive power of format-
oriented description is, however, insuf-
ficient for a number of common verbs
such as &amp;quot;1 6 &amp;quot; (make, do, perform, ...)
and &amp;quot;Pi 6 &amp;quot; (become, consist of, provide,
...) etc. In such cases, we can encode
transfer rules directly by GRADE. An
example is shown in Fig. 7. Varieties
of usages are to be listed up with their
corresponding English sentential struc-
tures and semantic conditions.
</bodyText>
<subsectionHeader confidence="0.656366">
3.4 Post-Transfer Rules
</subsectionHeader>
<bodyText confidence="0.999975166666667">
The transfer stage bridges the gap
between Japanese and English expressions.
There are still many odd structures
after this stage, and we have to adjust
further more the English internal repre-
sentation into more natural ones. We
call this part as post-transfer loop.
An example is given in Fig. 8, where a
Japanese factitive verb is first trans-
ferred to English &amp;quot;make&amp;quot;, and then a
structural change is made to eliminate
it, and to have a more direct expression.
</bodyText>
<sectionHeader confidence="0.988489" genericHeader="method">
4. GENERATION PROCESS
</sectionHeader>
<subsectionHeader confidence="0.5206485">
4.1 Translation of Japanese
Postpositions
</subsectionHeader>
<bodyText confidence="0.937070888888889">
Postpositions in Japanese general-
ly express the case slots for verbs. A
postposition, however, has different
usages, and the determination of English
prepositions for each postposition is
quite difficult. It also depends on the
verb which governs the noun phrase hav-
ing that postposition.
effect conductivity (REC: recipient)
</bodyText>
<equation confidence="0.941339714285714">
(3) ADJ (95&amp;quot; ) )
DS1 ( ) .
to /
Icx
x1 X2 X1.; 1) :many
2
,j1iTxt):few
</equation>
<bodyText confidence="0.96242">
:be, exist,..
(to be determined
at transfer step)
</bodyText>
<footnote confidence="0.8857785">
X1
SN,5%
U(+tend to)
1,9 : do
V-9 :there exist
4151 :tendency
</footnote>
<bodyText confidence="0.9986153">
Table 2 illustrates a part of a
default table for determining deep and
surface case labels when no higher level
rule applies. This sort of tables are
defined for all case combination. In
this way, we confirm at least one trans-
lation to be assigned to an input. A
particular usage of preposition for a
particular English verb is written in
the lexical entry of the verb.
</bodyText>
<subsectionHeader confidence="0.491245">
4.2 Determination of Global Sentential
</subsectionHeader>
<table confidence="0.872642260869565">
Structures in Target Language
Fig. 6. Examples of pre-transfer rules.
ADJ
&apos;SUE
423
•*1&amp;quot; X t`.‘11-1 non-living substance form-1 form X(obj)
structure
social phenomena take place N--.E.Tke. place
occur-1 X occur
action,deed,movement
reaction
standard ,property arise-1 X arise
state,condition
relation
0 produce-2 produce X
X form Y
&apos; non-living substance form-1
structure
phenomena,action cause-1 X cause Y
0 produce-2 X_produce Y
...L11 XerE.birb property improve-1 X improve Y
measure increase-2 X increase Y
0 raise-1 X raise Y
</table>
<tableCaption confidence="0.9962865">
&apos;--Semantic marker for X/Y
Table 1. Word selection in target language by using semantic markers.
</tableCaption>
<bodyText confidence="0.997292727272727">
Grobal sentential structures of Japanese and
English are quite different, and correspondingly
the internal structure of a Japanese sentence is
not the same as that of English. Fundamental
difference from Japanese internal representation
to that of English is absorbed at the (pre-, post
-) transfer stages. But at the stage of English
generation, some structural transformations are
still required in such cases as (a) embedded
sentential structure, (b) complex sentential
structure.
</bodyText>
<figure confidence="0.989100896551724">
(NARU) NARU(J-VP=V1) consist of
(1) A 2,1&apos;8 bs3 / \ &gt;/\
(3:.:) A B
(2) Ael-B1-&apos;&amp;quot; (SUB) (COM) (OBJ) (COM)
(t) NARU(J-VP=V2]
/\
A
(SUB) (GOAL)
provide
(B.J-SEM=CE)
(AGT) (OBJ)
reach
[B.J-SEM=MU] &gt; \
MU: unit A B
(OBJ) (STO)
become
A
(OBJ) (GOAL)
turn
_====&gt; [default] &gt;/\
A
(OBJ) (GOAL)
(3) dictionary rules
11,JriL rth
help become &gt; give
-I:41Z al
double become ====p double
A &amp;•&apos; 6 El a_ta
do cause become A causes B
</figure>
<figureCaption confidence="0.9602305">
Fig. 7. An example of dictionary transfer rules
of popular verbs.
</figureCaption>
<bodyText confidence="0.988329606060606">
We classified four kinds of embedded senten-
tial structures.
(i) a case slot of an embedded sentence is vacant,
and the noun modified by the embedded sentence
comes to fill the slot.
(ii) The form like &amp;quot;Nlte V 4 N2&amp;quot; a &amp;quot; (N2 o N1*ell)
la N2&amp;quot;. In this case the noun NI must have
the semantic properties like parts, attributes,
and action.
(d) The third and the fourth classes are particular
embedded expressions in Japanese, which have
the connecting expressions like -44- &amp;quot; (in
the case of), &amp;quot; (in the way that,
(in that) , and so on.
An example of the structural transformation
is shown in Fig. 9. The relative clause &amp;quot;why...&amp;quot;
is generated after the structural transformation.
Connection of two sentences in the compound
and complex sentences is done according to Table
3. An example is given in Fig. 10.
4.3 The Process of Sentence Generation in English
After the transfer is done from the Japanese
deep dependency structure to the English one,
conversion is done to a phrase structure tree with
all the surface words attached to the tree. The
processes explained in 4.1 and 4.2 are involved at
this generation stage. The conversion is perform-
ed top-down from the root node of the dependency
tree to the leaf. Therefore when a governing verb
demands a noun phrase expression ora to-infinitive
expression to its dependent phrase, the structural
change of the phrase must be performed. Noun to
verb transformation, and noun to adjective
</bodyText>
<figure confidence="0.999635833333333">
CE:means, equipment A
{ B.J-CAT=ADJ
3-LEX= t&apos;Itl(easy)
mo)(diffi-
cult)
(B.J-SEM=IT,IC)
IT:theorymethod
IC: conceptual
object
LI B:complement marke
t),:t
/
A
(OBJ) (GOAL)
get
17 \\B
(OBJ) (GOAL)
become
</figure>
<page confidence="0.695018">
424
</page>
<figure confidence="0.999442615384615">
J&apos;&apos;V I NCb
NC1
A B C
ISUB
(transfer) (post-transfer)
make C&apos;
4
S‘IXOTIA
//
(C: intransitive (C :transitive verb derived
verb) (consultation to derived from C)
lexical item C)
A VP 13 l&apos;3$4 zr-o A make B rotate ----&gt;A rotate B
</figure>
<figureCaption confidence="0.997376">
Fig. 8. An example of post-transfer rule application.
</figureCaption>
<table confidence="0.997520125">
.1-SURFACE-CASE I-DEEP-CASE E-DEEP-CASE Default Preposition
t:(no RECipient REC. BENeficiary to(REC--to,BEN--for)
ORIgin OR! from
PARticipant PAR with
THAe Time-AT in
ROle RC)1. as
G041.1 GOA to
... . ...
</table>
<tableCaption confidence="0.961496">
Table 2. Default rule for assigning a case label of English to a
Japanese postposition &amp;quot; (7, &amp;quot; (ni).
</tableCaption>
<table confidence="0.99855180952381">
JAPANESE DEEP-CASE ENGLISH
SENTENTIAL SENTENTIAL
CONNECTIVE CONNECTIVE
RENY° TOOL BY -ING ..
(-SHI)TE TOOL BY -ING ..
RENY° CAUSE BECAUSE ..
(-SHI)TE
-TAME II II
-NODE ” *.
-KARA •■ n
-TO TIME WHEN ..
-TOKI
-TE H ”
-TAME PURPOSE SO-THAT-MAY
-NONI II Il
-YOU u ,.
-YOU MANNER AS-IP
-KOTONAKU n WITHOUT -ING ..
-NACARA ACCOMPANY WHILE -ING ..
-BA CIRCUMSTANCE WHEN ..
.... .... ....
</table>
<tableCaption confidence="0.999404">
Table 3. Correspondence of sentential connectives.
</tableCaption>
<figure confidence="0.500632785714286">
,1)\&apos;.•=4-=*ftA yipt
he school resign reason
N1 N2 N3
[ANALYSIS] reason(N3),
resign(V)
he
3 ,PROP. CAUSE
Git/Isse,
OBJ
NI N2 (N3)
[GENERATION] NP
3 RELCL
RELADV
why
</figure>
<figureCaption confidence="0.99518">
Fig. 9. Structural transformation of an embedded
sentence of type 3.
</figureCaption>
<figure confidence="0.9943385">
o 4:6,1
school(N2) reason
[TRANSFER]
14, N5
</figure>
<page confidence="0.68739">
425
</page>
<figure confidence="0.7692423125">
(a) (b) it V tIV be
vzMVp. Xtr earthquake building collapse
[ANALYSIS] V1 vi
(PURPOSE) -
TAMENI-)V7 (PURPOSE) I2
YOUNI.--sV
[TRANSFER] V
11 Ii
SO-THAT-MAY 2SO-THAT-MAY 12
(PURPOSE) (PURPOSE) &apos;
X
collapse
SUB CAUSE
building earthquake
= The buildings collapsed
due to the earthquake.
destroy
CPCZ
earthquake building
[CPO :causal potency]
= The earthquake
destroyed the
buildings.
[GENERATION] S
INF V SUB
1 1
CONJ S
t
SO-THAT ,/,1\
X AUX V
Is I
MAY
</figure>
<figureCaption confidence="0.975079">
Fig. 10. Structural transformation of
</figureCaption>
<bodyText confidence="0.926317466666667">
an embedded sentence.
transformation are often required due to the differ-
ence of expressions in Japanese and English. This
process goes down from the root node to all the
leaf nodes.
After this process of phrase structure genera-
tion, some sentential transformations are performed
such as follows.
( i ) When an agent is absent, passive transforma-
tion is applied.
(ii) When the agent and object are both missing,
the predicative verb is nominalized and
placed as the subject, and such verb phrases
as &amp;quot;is made&amp;quot;, and &amp;quot;is performed&amp;quot; are supple-
mented.
</bodyText>
<listItem confidence="0.976687">
(iii) When a subject phrase is a big tree, the
anticipatory subject &amp;quot;it&amp;quot; is introduced.
(iv) Pronominalization of the same subject nouns
is done in compound and complex sentences.
</listItem>
<bodyText confidence="0.94199215">
( v ) Duplication of a head noun in the conjunctive
noun phrase is eliminated, such as, &amp;quot;uniform
component and non-uniform component&amp;quot;
&amp;quot;uniform and non-uniform components&amp;quot;.
(vi) Others.
Another big structural transformation required
comes from the essential difference between DO-
language (English) and BE-language (Japanese). In
English the case slots such as tools, cause/reason,
and some others come to the subject position very
often, while in Japanese such expressions are never
used. The transformation of this kind is incorpo-
rated in the generation grammar such as shown in
Fig. 11, and produces more English-like expressions.
This stylistic transformation part is still very
primitive. We have to accumulate much more linguis-
tic knowledge and lexical data to have more satis-
fiable English expressions.
Fig. 11 An example of structural transformation
in the generation phase.
</bodyText>
<sectionHeader confidence="0.936286" genericHeader="conclusions">
5. SUMMARY
</sectionHeader>
<bodyText confidence="0.999985461538461">
This paper described a number of strategies
we employed in the transfer and generation stages
of our Mu system to make the system both powerful
and fault-tolerant. As is mentioned above, our
system has many advantages such as the flexibility
of the generation process, the utilization of
strong lexical information. The system is in the
course of development in collaboration with a num-
ber of computer scientists from computer industries
and expert translators. Some of the translation
results are attached in the last, which show the
present level of the translation system. Progres-
sive improvement is expected in the next two years.
</bodyText>
<sectionHeader confidence="0.953141" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999894125">
We acknowledge the members of the Mu-Project,
especially, Mr. S. Takai(JCS), Mr. Y. Fukumochi
(Sharp Co.), Mr. T. Ishioka(JCS), Miss M. Kume •
(JCS), Mr. H. Sakamoto(Oki Co.), Mr. A. Kosaka
(NEC Co.), Mr. H. Adachi(Toshiba Co.), Miss A.
Okumura(Intergroup), and Miss A. Okuda(Intergroup)
who contributed greatly for the implementation of
the system.
</bodyText>
<sectionHeader confidence="0.86226" genericHeader="references">
REFERENCES
</sectionHeader>
<listItem confidence="0.892290315789473">
[1] M. Nagao: Machine Translation Project of the
Japanese Government, a paper presented at the
workshop between EUROTRA and Japanese machine
translation experts, held in Brussels on
November 24-25, 1983.
[2] J. Nakamura, et al.: Grammar Writing System
(GRADE) of Mu-Machine Translation Project and
its Charactersitics, Proc. of COLING 84, 1984.
[3] J. Tsujii, et al.: Analysis Grammar of
Japanese in the Mu-Project -- A Procedural
Approach to Analysis Grammar --, ibid.
[4] Y. Sakamoto, et al.: Lexicon Features for
Japanese Syntactic Analysis in Mu-Project-
JE, ibid.
[5] J. Tsujii: The transfer Phase in an English-
Japanese Translation System, Proc. of COLING
82, 1982.
Sample outputs as of April, 1984 are attached in
the next page.
</listItem>
<figure confidence="0.920929">
TO V 2
IN-ORDER-TO
</figure>
<page confidence="0.690638">
426
</page>
<figure confidence="0.993067269784173">
.tr,{
!:4
Ka -0
•-,
• Z
0
VA
.&amp;quot;...t •••
. _
P ...
...• 0
.7,.... . ..., .-
6.1 VI
cl,
• 0 0
I 1 0 I.
744 -..
« a
,LR OW
&apos;-C
0
-.
d .0
.0
.Z... d
....
.1.• (II
ik$ e .-
.0
r; 0
,, ...• 0
.... CD .0
E
.117, .4 C
.,,,. 6 RI
•:Li 0 I.,
VI.
Q -•• _c
-o a. 0
a - « z
o •0, 2
...! ,
I *A
1,0 0
tit -C VI
1&amp;quot;1/4. ... ..-
• • 0 .0
cn
ITN
. -to -
-,, O&apos;,• 0 -
Z o.
&apos;0(\ 0I
0 .. 0&apos;-, ..- II
.I.J e.4 -7.7. 4.• 4-
C
O Iaa :,•:j
E 11
W
w-&apos;1 V
_, ca ..
0. w3 ,-,
,.-
e 0
ct
cr3 W., . -..
v, t to
310
51 .0
VI.-&apos;
.0
VI
measurement
selected
VI
.0
• -7,
* C
7.--- •
;
■,-
.11
O :
-I-• 4..
.,,, ....
.... •
I.;J• - C,
...
.
4-, 551
-.
- _
,
J. .
• ...
... ■ .0 • 4,
IA .....
0
4- a
▪ a
e. .._
.
0.4siS
.,:s. ._ &amp;quot;5
• f4&apos;I ... ..•
54 •-.- LI 0
0 1- \ 7 0
&apos;0 I.
a,...
,,,, .....-.
.....
&amp;quot;j 47 .0 CD
I/1 ...
0
r4,_, 4- ..-
o •:.:-J ...,
a.- 0
&apos;CL) 0 C
0 I
■11
cO .... ...
O &apos;V
c_31:_ e a,
z-_... x 13
W Z.,, I- V
Ins E
00
0
I. t..
.0 2
4.•
2. al
1- I.
.... w
E O.
E E
E 0
2.. *A
0
..- 0
X a. 0
IS 0
0 C
.... I) L.
0
Ft. 0
E..-
0 * &apos;
.0
.0 il-k
,, o
C
• 0.. .5.-- ..&amp;quot;
■&amp;quot;! a *4
C...`&amp;quot; &apos;11n ...a
ta.: .•
• t3.1 • • .75 l-
ye ■-.= 0 le •,-0
0ç
.... to
Q▪ :.:1 al C.&apos; 0:: ....
__I-_;- % -J 2
VI
c.J:1&apos;,- .0 ,-,, ..;
4-‘-,&apos; -0 1
tv-m
• _. N .. .4 -
...c••=• d
0.-
0 &apos;&apos;&apos; C
0 &apos;.. .... a..&apos; 0
.0 .3.1
o v 1.3 so r3 -
o 1 4.
eV 1 .1 •••• 04 I 1 00
W 4-f, cl) ▪ 15.17g 3
•,.._ C ,,,-, 0
C. ILI • - -0,1
0 --, &amp;quot;5 La -..-.
2 C••-•‘. E 2 ..:-• U
UJ ...e 4.1
a) I- . m
, , , L
u.i ...--. I- • W&apos; I-
C/1 I CM :
,it..•
.c
%
« o..
▪ •■••
Pg 0 To
C 4.1t,
*N- e
*o-
.44 C . 0 t
...
0
1•:&amp;quot;.:
.t-t• ...
.VI :-•--t ,
.
•-■., .0
-VI t4r ...,..-, ..-
.- ....
1) 0.
-n- « .... 0
W -
0
0
iKE -0 ,S1 .c •
...i.g « .ku• VI « z
«
e
VI VI F.) 03
&apos;.% ::« *c
r: .4.4
ig u c
3• 3 -
0 0
0
0
Ka 051
al 44 it &apos;0
VI VI
2..)•*. al U6 5 el&apos;
t... --• •••,;. 3
*1 t7, 0. !-.. 44 !, c
S.
« -
« E-4 o.. •••
O CI
1 1 0 4-2. c
Z 6&gt; -,6&apos; o --
,
O 6&apos;-Q. .1,
O .
.... 1.74 g g
... P 4.&apos;.
% .
.
&apos;,g C 4+
0■13
.0 7f33
.0 ••••
0* 0 d_ ...•C
&apos;0 •DI 0
CI K3 C v..
&lt; , al &amp;quot;0 0&apos;.
010 CI IN 0
...1 ....,, VI.&apos; d
•=7 -0 - 14 d I a
Inr.&lt; 2 E al
0
3 C
041 - ..-
VI (.3
.0 Eal
2
21 . V
••• 42
VI S4
O. 2 .-
0 -..s- ..- .-
c,,,,a1 . c, S, .....
co • 03 C VI VI
W frl, ■, 03 +&apos;C
6 --. 0 CI
W e so. VI VI
2 t••• 0 al &amp;quot;3
ILI j, l• .0 .0 t.
0 DI LI 0
2 ;rip .0 &gt;.
to-., I- ,0- &lt;15
CII s. 0 0 ••••
the correlation
The multiple scattering of
equation.
the ideal conductor covered by the ferrite
</figure>
<page confidence="0.970314">
427
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.967341">
<title confidence="0.989974333333333">DEALING WITH INCOMPLETENESS OF LINGUISTIC KNOWLEDGE IN LANGUAGE TRANSLATION -- TRANSFER AND GENERATION STAGE OF MU MACHINE TRANSLATION PROJECT --</title>
<author confidence="0.999202">Makoto Nagao</author>
<author confidence="0.999202">Toyoaki Nishida</author>
<author confidence="0.999202">Jun-ichi Tsujii</author>
<affiliation confidence="0.9995785">Department of Electrical Engineering Kyoto University</affiliation>
<address confidence="0.994578">Sakyo-ku, Kyoto 606, JAPAN</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>