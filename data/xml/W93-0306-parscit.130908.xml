<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.888746">
NPtool, a detector of English noun phrases *
</title>
<author confidence="0.715961">
Atro Voutilainen
</author>
<affiliation confidence="0.635342">
Research Unit for Computational Linguistics
P.O. Box 4 (Keskuskatu 8)
FIN-00014 University of Helsinki
</affiliation>
<address confidence="0.515579">
Finland
</address>
<email confidence="0.996475">
E-mail: avoutila@ling.Helsinki.FI
</email>
<note confidence="0.823782">
I
</note>
<sectionHeader confidence="0.986232" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999913444444445">
N Piool is a fast and accurate system for ex-
tracting noun phrases from English texts
for the purposes of e.g. information re-
trieval, translation unit discovery, and cor-
pus studies. After a general introduction,
the system architecture is presented in out-
line. Then follows an examination of a re-
cently written Constraint Syntax. Section 6
reports on the performance of the system.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999894625">
This paper outlines NPtool, a noun phrase detector.
At the heart of this modular system is reduction-
istic word-oriented morphosyntactic analysis
that expresses head—modifier dependencies. Previ-
ous work on this approach, largely based on Karla-
son&apos;s original proposal [Karlsson, 1990], is docu-
mented in [Karlsson el al., forthcoming]. Let us sum-
marise a few key features of this style of analysis.
</bodyText>
<listItem confidence="0.702808">
• As most parsing frameworks, also the present
style of analysis employs a lexicon and a grammar.
</listItem>
<bodyText confidence="0.909959736842105">
What may distinguish the present approach from
most other frameworks is the considerable degree of
attention we pay to the morphological and lexical
description: morphological analysis is based on an
extensive and detailed description that employs in-
flectional and central derivational categories as well
as other morphosyntactic features that can be use-
ful for stating syntactic generalisations. In this way
&apos;This paper is based on a longer manuscript with the
same title. The development of ENGCG was supported
by TEKES, the Finnish Technological Development Cen-
ter, and a part of the work on Finite-state syntax has
been supported by the Academy of Finland.
a carefully built and informative lexicon facilitates
the construction of accurate, wide-coverage parsing
grammars.
• We use tags to encode morphological distinc-
tions, part of speech, and also syntactic information;
for instance:
</bodyText>
<figure confidence="0.701601">
I PROF WIELD
see V PRES @VERB
a ART C&gt;11
</figure>
<sectionHeader confidence="0.731758" genericHeader="introduction">
bird N @HEAD
FULLSTOP
</sectionHeader>
<bodyText confidence="0.954104447058824">
In this type of analysis, each word is provided with
tags indicating e.g. part of speech, inflection, deriva-
tion, and syntactic function.
a Morphological and syntactic descriptions are
based on hand-coded linguistic rules rather than
on corpus-based statistical models. They employ
structural categories that can be found in descrip-
tive grammars, e.g. [Quirk, Greenbaum, Leech and
Svartvik, 1985].
Regarding the at times heated methodological de-
bate on whether statistical or rule-based information
is to be preferred in grammatical analysis of running
text (cf. e.g. [Sampson, 1987a; Taylor, Grover and
Briscoe, 1989; Church, 1992]), we do not object to
probabilistic methods in principle; nevertheless, it
seems to us that rule-based descriptions are prefer-
able because they can provide for more accurate and
reliable analyses than current probabilistic systems,
e.g. part-of-speech taggers [Voutilainen, Heikkila and
Anttila, 1992; Voutilainen, forthcoming a].&apos; Probe-
&apos;Consider for instance the question posed in [Church,
1992] whether lexical probabilities contribute more to
morphological or part-of-speech disambiguation than
context does. The ENGCG morphological disambigua-
tor, which is entirely based on context rules, uniquely
bilistic or heuristic techniques may still be a use-
ful add-on to linguistic information, if potentially re-
maining ambiguities must be resolved - though with
a higher risk of error.
• In the design of our grammar schemes, we have
paid considerable attention to the question on the re-
solvability of grammatical distinctions. In the
design of accurate parsers of running text, this ques-
tion is very important: if the description abounds
with distinctions that can be dependably resolved
only with extrasyntactic knowledge2, then either the
ambiguities due to these distinctions remain to bur-
den the structure-based parser (as well as the poten-
tial application based on the analysis), or a guess,
i.e. a misprediction, has to be hazarded.
This descriptive policy brings with it a certain de-
gree of shallowness; in terms of information con-
tent, a tag-based syntactic analysis is somewhere
between morphological (e.g. part-of-speech) analysis
and a conventional syntactic analysis, e.g. a phrase
structure tree or a feature-based analysis. What we
hope to achieve with this compromise in information
content is the higher reliability of the proposed anal-
yses. A superior accuracy could be considered as an
argument for postulating a new, &apos;intermediary&apos; level
of computational syntactic description. For more de-
tails, see e.g. [Voutilainen and Tapanainen, 1993).
• Our grammar schemes are also learnable: accord-
ing to double-blind experiments on manually assign-
ing morphological descriptions, a 100% interjudge
agreement is typical [Voutilainen, forthcoming 4.3
• The ability to parse running text is of a high
priority. Not only a structurally motivated descrip-
tion is important; in the construction of the pars-
ing grammars and lexica, attention should also be
paid to corpus evidence. Often a grammar rule,
as we express it in our parsing grammars, is formed
as a generalisation &apos;inspired&apos; by corpus observations;
in this sense the parsing grammar is corpus-based.
However, the description need not be restricted to
the corpus observation: the linguist is likely to gen-
eralise over past experience, and this is not necessar-
ily harmful - as long as the generalisations can also
and correctly identifies more than 97% of all appropriate
descriptions, and this is considerably more than the near-
90% success rate achieved with lexical probabilities alone
[Church, 1992]. Moreover, note that in all, the ENGCG
disambiguator identifies more than 99.5% of all appropri-
ate descriptions; only, some 2-3% of all analyses remain
ambiguous and thus do not become uniquely identified.
For more details, see [Voutilainen, forthcoming 1993].
&apos;Witness, for instance, ambiguities due to adverbial
attachment or modifier scope.
&apos;The 95% interjudge agreement rate reported in
[Church, 1992] probably indicates that in the ease of
debatable constructions, explicit descriptive conventions
have not been consistently established. Only a carefully
defined grammar scheme makes the evaluation of the ac-
curacy of the parsing system a meaningful enterprise (see
also [Sampson, 198 71A .
</bodyText>
<listItem confidence="0.985398045454546">
be validated against representative test corpora.
• At least in a practical application, a parsing
grammar should assign the best available anal-
ysis to its input rather than leave many of the input
utterances unrecognised e.g. as ill-formed. This does
not mean that the concept of well-formedness is irrel-
evant for the present approach. Our point is simply:
although we may consider some text utterance as de-
viant in one respect or another, we may still be inter-
ested in extracting as much information as possible
from it, rather than ignore it altogether. To achieve
this effect, the grammar rules should be used in such
a manner4 that no input becomes entirely rejected,
although the rules as such may express categorical
restrictions on what is possible or well-formed in the
language.
• In our approach, parsing consists of two main
kinds of operation:
1. Context-insensitive lookup of (alternative) de-
scriptions for input words
2. Elimination of unacceptable or contextually il-
legitimate alternatives.
</listItem>
<bodyText confidence="0.993861">
Morphological analysis typically corresponds to
the lookup module: it produces the desired mor-
phosyntactic analysis of the sentence, along with
a number of inappropriate ones, by providing each
word in the sentence with all conventional analyses as
a list or alternatives. The grammar itself exerts the
restrictions on permitted sequences of words and de-
scriptors. In other words, syntactic analysis proceeds
by way of ambiguity resolution or disambigua-
tion: the parser eliminates ill-formed readings, and
what &apos;survives&apos; the grammar is the (syntactic) anal-
ysis of the input utterance. Since the input contains
the desired analysis, no new structure will be built
during syntactic analysis itself.
</bodyText>
<listItem confidence="0.855471">
• Our grammars consist of constraints - par-
tial distributional definitions of morphosyntactic cat-
</listItem>
<bodyText confidence="0.992394176470588">
egories, such as parts of speech or syntactic func-
tions. Each constraint expresses a piecemeal linear-
precedence generalisation about the language, and
they are independent of each other. That is, the con-
straints can be applied in any order: a true grammar
will produce the same analysis, whatever the order.
The grammarian is relatively free to select the
level of abstraction at which (s)he is willing to ex-
press the distributional generalisation. In particular,
also reference to very low-level categories is possi-
ble, and this makes for the accuracy of the parser:
while the grammar will contain more or less ab-
stract, feature-oriented rules, often it is also expe-
dient to state further, more particular restrictions
on more particular distributional classes, even at
the word-form level. These &apos;smaller&apos; rules do not
contradict the more general rules; often it is aim-
</bodyText>
<footnote confidence="0.544378">
&apos;e.g. by ranking the grammar rules in terms of
compromisability
</footnote>
<page confidence="0.999346">
49
</page>
<bodyText confidence="0.9998058">
ply the case that further restrictions can be im-
posed on smaller lexical classes&apos; This flexibility in
the grammar formalism greatly contributes to the
accuracy of the parser [Voutilainen, forthcoming a;
Voutilainen, forthcoming 1993].
</bodyText>
<sectionHeader confidence="0.498257" genericHeader="method">
2 Uses of a noun phrase parser
</sectionHeader>
<bodyText confidence="0.999748">
The recognition and analysis of subclausal structural
units, e.g. noun phrases, is useful for several pur-
poses. Firstly, a noun phrase detector can be useful
for research purposes: automatic large-scale analy-
sis of running text provides the linguist with better
means to conduct e.g. quantitative studies over large
amounts of text.
An accurate though somewhat superficial analysis
can also serve as a &apos;preprocessor&apos; prior to more ambi-
tious, e.g. feature-based syntactic analysis. This kind
of division of labour is likely to be useful for technical
reasons. One major problem with e.g. unification-
based parsers is parsing time. Now if a substan-
tial part of the overall problem is resolved with
more simple and efficient techniques, the task of the
unification-based parser will become more manage-
able. In other words, the more expressive but compu-
tationally heavier machinery of e.g. the unification-
based parser can be reserved entirely for the analysis
of the descriptively hardest problems. The less com-
plex parts of the overall problem can be tackled with
more simple and efficient techniques.
Regarding production uses, even lower levels of
analysis can be directly useful. For instance, the de-
tection of noun phrases can provide e.g. information
management and retrieval systems with a suitable
input for index term generation.
Noun phrases can also serve as translation units;
for instance, [van der Eijk, 1993] suggests that noun
phrases are more appropriate translation units than
words or part-of-speech classes.
</bodyText>
<sectionHeader confidence="0.999415" genericHeader="method">
3 Previous work
</sectionHeader>
<bodyText confidence="0.9938388">
This section consists of two subsections. Firstly, a
performance-oriented survey of some related systems
is presented. Then follows a more detailed presents-
tion of ENGCG, a predecessor of the NPtool parser
in an information retrieval system.
</bodyText>
<subsectionHeader confidence="0.988035">
3.1 Related systems
</subsectionHeader>
<bodyText confidence="0.993236111111111">
So far, I have found relatively little documentation
on systems whose success in recognising or parsing
noun phrases has been reported. I am aware of three
systems with some relevant evaluations.
Church&apos;s Parts of speech [Church, 19881 performs
not only part-of-speech analysis, but it also identi-
fies the most simple kinds of noun phrases — mostly
sequences of determiners, premodifiers and nominal
heads — by inserting brackets around them, e.g.
</bodyText>
<sectionHeader confidence="0.630292" genericHeader="method">
5 Consider for instance the attachment of prepositional
</sectionHeader>
<subsectionHeader confidence="0.574178">
phrases in general and of of-phrases in particular.
</subsectionHeader>
<bodyText confidence="0.970770139534884">
EA/AT former/AP top/NI aide/NN) to/IN
EAttorney/NP/NP General/NP/NP Edwin/NP/NP
Meese/NP/NP) interceded/VBD
The appendix in [Church, 1988] lists the analysis of
a small text. The performance of the system on the
text is quite interesting: of 243 noun phrase brackets,
only five are omitted. — The performance of Parts of
speech was also very good in part-of-speech analysis
on the text: 99.5% of all words got the appropri-
ate tag. The mechanism for noun phrase identifica-
tion relies on the part-of-speech analysis; the part-of-
speech tagger was more successful on the text than
on an average; therefore the average performance of
the system in noun phrase identification may not be
quite as good as the figures in the appendix of the
paper suggest.
Bourigault&apos;s LECTER [Bourigault, 1992] is a
surface-syntactic analyser that extracts &apos;maximal-
length noun phrases&apos; — mainly sequences of determin-
ers, premodifiers, nominal heads, and certain kinds
of postmodifying prepositional phrases and adjec-
tives — from French texts for terminology applica-
tions. The system is reported to recognise 95% of all
maximal-length noun phrases (43,500 out of 46,000
noun phrases in the test corpus), but no figures are
given on how much &apos;garbage&apos; the system suggests as
noun phrases. It is indicated, however, that manual
validation is necessary.
Rausc.h, Norrback and Svensson 11992] have de-
signed a noun phrase extractor that takes as its in-
put part-of-speech analysed Swedish text, and inserts
brackets around noun phrases. In the recognition of
&apos;Nuclear Noun Phrases&apos; — sequences of determiners,
premodifiers and nominal heads — the system was
able to identify 85.9% of all nuclear noun phrases in a
text collection, some 6,000 words long in all, whereas
some 15.7% of all the suggested noun phrases were
false hits, i.e. the precisionb of the system was 84.3%.
The performance of a real application would proba-
bly be lower because potential misanalyses due to
previous stages of analysis (morphological analysis
and part-of-speech disambiguation, for instance) are
not accounted for by these figures.
</bodyText>
<subsectionHeader confidence="0.999173">
3.2 ENGCG and the SI1SAPR project
</subsectionHeader>
<bodyText confidence="0.9998215">
SIMPR, Structured Information Management: Pro-
cessing and Retrieval, was a 64 person year ESPRIT
II project (Nr. 2083, 1989-1992), whose objective
was to develop new methods for the management
and retrieval of large amounts of electronic texts. A
central function of such a system is to recognise those
words in the stored texts that represent it in a con-
cise fashion — in short, index terms.
Term indices created with traditional methods&apos;
are based on isolated, perhaps truncated words.
</bodyText>
<footnote confidence="0.9703725">
6For definitions of the terms recall and precision, see
Section 6.
</footnote>
<note confidence="0.764349">
&apos;See e.g. [Salton and McGill, 1983].
</note>
<page confidence="0.992039">
50
</page>
<bodyText confidence="0.99998002631579">
These largely string-based statistical methods are
somewhat unsatisfactory because many content iden-
tifiers consist of word sequences - compounds, head-
modifier constructions, even simple verb - noun
phrase sequences. One of the SIMPR objectives
was also to employ more complex constructions, the
recognition of which would require a shallow gram-
matical analysis. The Research Unit for Computa-
tional Linguistics at the University of Helsinki par-
ticipated in this project, and ENGTWOL, a Twol-
styled morphological analyser as well as ENGCG,
a Constraint Grammar of English, were written
1999-1992 by Voutilainen, Heikkila and Anttila
[forthcoming]. The resultant SIMPR system is an
improvement over previous systems [Smart (Ed.),
forthcoming] - it is not only reasonably accurate, but
also it operates on more complex constructions, e.g.
postmodifying constructions and simple verb-object
constructions.
There were also some persistent problems. The
original plan was to use the output of the whole
ENGCG parser for the indexing module. However,
the last module of the three sequential modules in
the ENGCG grammar, namely Constraint Syntax
proper, was not used in the more mature versions of
the indexing module - only lexical analysis and mor-
phological disambiguation were applied. The omis-
sion of the syntactic analysis was mainly due to the
somewhat high error rate (3-4% of all words lost the
proper syntactic tag) and the high rate of remaining
ambiguities (15-25% of all words remained syntacti-
cally ambiguous.
Here, we will not go into a detailed analysis of the
problems8, suffice it to say that the syntactic gram-
mar scheme was unnecessarily ambitious for the rela-
tively simple needs of the indexing application. One
of the improvements in NPtool is a more optimal syn-
tactic grammar scheme, as will be seen in Section 5.1.
</bodyText>
<sectionHeader confidence="0.817357" genericHeader="method">
4 NPtool in outline
</sectionHeader>
<bodyText confidence="0.999676">
In this section, the architecture of NPiool is pre-
sented in outline. Here is a flow chart of the system:
</bodyText>
<subsectionHeader confidence="0.939041">
Preprocessing
Morphological analysis
Constraint Grammar parsing
NP-hostile finite 1P-friendly finite
</subsectionHeader>
<bodyText confidence="0.983688">
state parsing state parsing
NP extraction NP extraction
Intersection of noun phrase sets
&apos;See e.g. [Voutilainen, Heikki11 and Anttila, 1992] for
details.
In the rest of this section, we will observe the analysis
of the following sample sentence, taken from a car
maintenance manual:
The inlet and exhaust manifolds are mounted
on opposite sides of the cylinder head, the
exhaust manifold channelling the gases to a
single exhaust pipe and silencer system.
</bodyText>
<subsectionHeader confidence="0.619625">
4.1 Preprocessing and morphological
analysis
</subsectionHeader>
<bodyText confidence="0.999913294117647">
The input ASCII text, preferably SGML-annotated,
is subjected to a preprocessor that e.g. determines
sentence boundaries, recognises fixed syntagmsg,
normalises certain typographical conventions, and
verticalises the text.
This preprocessed text is then submitted to mor-
phological analysis. ENGTWOL, a morphological
analyser of English, is a Koskenniemi-style morpho-
logical description that recognises all inflections and
central derivative forms of English. The present
lexicon contains some 56,000 word stems, and al-
together the analyser recognises several hundreds of
thousands of different word-forms. The analyser also
employs a detailed parsing-oriented morphosyntac-
tic description; the feature system is largely derived
from [Quirk, Greenbaum, Leech and Svartvik, 1985).
Here is a small sample:
</bodyText>
<figure confidence="0.814179692307692">
(&amp;quot;&lt;*the&gt;&amp;quot;
(&amp;quot;the&amp;quot; DET CENTRAL ART SG/PL (G&gt;N)))
(&amp;quot;&lt;inlet&gt;&amp;quot;
(&amp;quot;inlet&amp;quot; I NOM Sc))
(&amp;quot;&lt;and&gt;&amp;quot;
(&amp;quot;and&amp;quot; CC (CCC)))
(&amp;quot;&lt;exhaust&gt;&amp;quot;
(&amp;quot;exhaust&amp;quot; &lt;SVO&gt; V SUBJUNCTIVE VFIN (MV))
(&amp;quot;exhaust&amp;quot; &lt;SVO&gt; V IMP VFIN (CV))
(&amp;quot;exhaust&amp;quot; &lt;SVD&gt; V INF)
(&amp;quot;exhaust&amp;quot; &lt;SVO&gt; V PRES -SG3 VFIN (CV))
(&amp;quot;exhaust&amp;quot; N 10K SO))
(&amp;quot;&lt;manifolds&gt;&amp;quot;
</figure>
<figureCaption confidence="0.370808">
(&amp;quot;manifold&amp;quot; 1 NOM PL))
</figureCaption>
<bodyText confidence="0.994964444444444">
All running-text word-forms are given on the left-
hand margin, while all analyses are on indented lines
of their own. The multiplicity of these lines for a
word-form indicates morphological ambiguity.
For words not represented in the ENGTWOL lex-
icon, there is a 99.5% reliable utility that assigns
ENGTWOL-style descriptions. These predictions
are based on the form of the word, but also some
heuristics are involved.
</bodyText>
<subsectionHeader confidence="0.993541">
4.2 Constraint Grammar parsing
</subsectionHeader>
<bodyText confidence="0.9789902">
The next main stage in NPiool analysis is Con-
straint Grammar parsing. Parsing consists of two
main phases: morphological disambiguation and
Constraint syntax.
°e.g. multiword prepositions and compounds
</bodyText>
<page confidence="0.984463">
51
</page>
<listItem confidence="0.9830934">
• Morphological disambiguation. The task
of the morphological disambiguator is to discard all
contextually illegitimate morphological readings in
ambiguous cohorts. For instance, consider the fol-
lowing fragment:
</listItem>
<figure confidence="0.8942055">
(&amp;quot;&lt;a)&amp;quot;
(&amp;quot;a&amp;quot; &lt;Indef&gt; DET CENTRAL ART SG (O&gt;N)))
(&amp;quot;&lt;single&gt;&amp;quot;
(&amp;quot;single&amp;quot; &lt;SV)&gt; V IMP VFIN (OV))
(&amp;quot;single&amp;quot; &lt;SVD&gt; V INF)
(&amp;quot;single&amp;quot; A ABS))
</figure>
<bodyText confidence="0.999664565217392">
Here an unambiguous determiner is directly followed
by a three-ways ambiguous word, two of the analyses
being verb readings, and one, an adjective reading.
- A determiner is never followed by a verbt°; one
of the 1,100-odd constraints in the disambiguation
grammar [Voutilainen, forthcoming a] expresses this
fact about English grammar; so the verb readings of
szngle are discarded here.
The morphological disambiguator seldom discards
an appropriate morphological reading: after morpho-
logical disambiguation, 99.7-100% of all words re-
tain the appropriate analysis. On the other hand,
some 3-6% of all words remain ambiguous, e.g.
head in this sentence. There is also an additional
set of some 200 constraints - after the application
of both constraint sets, 97-98% of all words be-
come fully disambiguated, with an overall error rate
of up to 0.4% [Voutilainen, forthcoming 13). The
present disambiguator compares quite favourably
with other known, typically probabilistic, disam-
biguators, whose maximum error rate is as high as
5%, i.e. some 17 times as high as that of the ENGCG
disambiguator.
</bodyText>
<listItem confidence="0.7443915">
• Constraint syntax. After morphological dis-
ambiguation, the syntactic constraints are applied.
</listItem>
<bodyText confidence="0.987198375">
In the NPtool syntactic description, all syntactic am-
biguities are introduced directly in the lexicon, so
no extra lookup module is needed. Like disambigua-
tion constraints, syntactic constraints seek to discard
all contextually illegitimate syntactic function tags.
Here is the syntactic analysis of our sample sentence,
as produced by the current parser. To save space,
most of the morphological codes are omitted.
</bodyText>
<figure confidence="0.986913949152542">
(&amp;quot;the&amp;quot; DET (en)))
(&amp;quot;&lt;inlet&gt;&amp;quot;
(&amp;quot;inlet&amp;quot; N (en en)))
(&amp;quot;&lt;and&gt;&amp;quot;
(&amp;quot;and&amp;quot; CC (OCC)))
(&amp;quot;&lt;srhaust&gt;&amp;quot;
(&amp;quot;exhaust&amp;quot; N (en)))
(&amp;quot;&lt;manifolds&gt;&amp;quot;
(&amp;quot;manifold&amp;quot; I MEM
&amp;quot;save for no, which can be followed by an -ing-form;
cf. no in There is no going home
(&amp;quot;he&amp;quot; V (CV)))
(&amp;quot;&lt;mounted&gt;&amp;quot;
(&amp;quot;mount&amp;quot; PCP2 (CV)))
(&amp;quot;&lt;on&gt;&amp;quot;
(&amp;quot;on&amp;quot; PREP (CAB)))
(&amp;quot;&lt;opposite&gt;&amp;quot;
(&amp;quot;opposite&amp;quot; A (C&gt;N)))
(&amp;quot;&lt;sides&gt;&amp;quot;
(&amp;quot;side&amp;quot; N (ONR)))
(&amp;quot;&lt;of&gt;&amp;quot;
(&amp;quot;of&amp;quot; PREP (ON&lt;)))
(&amp;quot;&lt;the&gt;&amp;quot;
(&amp;quot;the&amp;quot; DET (OW))
(&amp;quot;&lt;cylinder&gt;&amp;quot;
(&amp;quot;cylinder&amp;quot; N (O&gt;N ONE)))
(&amp;quot;&lt;head&gt;&amp;quot;
(&amp;quot;head&amp;quot; V (OV))
(&amp;quot;head&amp;quot; N (CHE)))
(&amp;quot;&lt;N,&gt;&amp;quot;)
(&amp;quot;&lt;the&gt;&amp;quot;
(&amp;quot;the&amp;quot; DET (e&gt;N)))
(&amp;quot;&lt;exhaust&gt;&amp;quot;
(&amp;quot;exhaust&amp;quot; N (ID&gt;N)))
(&amp;quot;&lt;manifold)&amp;quot;
(&amp;quot;manifold&amp;quot; N (CNH)))
(&amp;quot;&lt;channelling&gt;&amp;quot;
(&amp;quot;channel&amp;quot; PCP1 (CV)))
(&amp;quot;&lt;the&gt;&amp;quot;
(&amp;quot;the&amp;quot; DET (O&gt;I)))
(&amp;quot;&lt;gases&gt;&amp;quot;
(&amp;quot;gas&amp;quot; N (CNH)))
(&amp;quot;&lt;to&gt;&amp;quot;
(&amp;quot;to&amp;quot; PREP (OAR)))
(&amp;quot;&lt;a&gt;&amp;quot;
(&amp;quot;a&amp;quot; DET (O&gt;N)))
(&amp;quot;&lt;single&gt;&amp;quot;
(&amp;quot;single&amp;quot; A (0&gt;N)))
(&amp;quot;&lt;exhaust&gt;&amp;quot;
(&amp;quot;exhaust&amp;quot; I (OW))
(&amp;quot;&lt;pipe&gt;&amp;quot;
(&amp;quot;pipe&amp;quot; N (CNR)))
(&amp;quot;&lt;and&gt;&amp;quot;
(&amp;quot;and&amp;quot; CC (CCC)))
(&amp;quot;&lt;silencer&gt;&amp;quot;
(&amp;quot;silencer&amp;quot; N (O&gt;N)))
(&amp;quot;&lt;system&gt;&amp;quot;
(&amp;quot;system&amp;quot; I (ONE)))
(“&lt;$.&gt;1111)
</figure>
<bodyText confidence="0.9605196">
All syntactic-function tags are flanked with For
instance, the tag &apos;0&gt;N&apos; indicates that the word is
a determiner or a premodifier of a nominal in the
right-hand context (e.g. the). The second word, in-
let, remains syntactically ambiguous due to a pre-
modifier reading and a nominal head @NH reading
- note that the ambiguity is structurally genuine, a
coordination ambiguity. The tag @V is reserved for
verbs and auxiliaries, cf. are as well as mounted. The
syntactic description will be outlined below.
</bodyText>
<page confidence="0.992546">
52
</page>
<bodyText confidence="0.9992616">
Pasi Tapanainen&amp;quot; has recently made a new imple-
mentation of the Constraint Grammar parser that
performs morphological disambiguation and syntac-
tic analysis at a speed of more than 1,000 words per
second on a Sun SparcStation 10, Model 30.
</bodyText>
<subsectionHeader confidence="0.99648">
4.3 Treatment of remaining ambiguities
</subsectionHeader>
<bodyText confidence="0.999789266666667">
The Constraint Grammar parser recognises only
word-level ambiguities, therefore some of the traver-
sals through an ambiguous sentence representation
may be blatantly ill-formed.
NPtoo/eliminates locally unacceptable analyses by
using a finite-state parser ITapanainen, 1991]2 as a
kind or &apos;post-processing module&apos; that distinguishes
between competing sentence readings. The parser
employs a small finite-state grammar that I have
written. The speed of the finite-state parser is com-
parable to that of the Constraint Grammar parser.
The finite-state parser produces all sentence read-
ings that are in agreement with the grammar. Con-
sider the following two adapted readings from the
beginning of our sample sentence:
</bodyText>
<equation confidence="0.964445625">
the/&gt;N inlet/11&gt;N and/OCC exhanst/O&gt;N
manifolds/ONE are/0V mounted/0V
on/CU oppos2te/0&gt;N sides/ONE
of/1J&lt; the/0&gt;N cylinder/NB head/OV
the/0&gt;N inlet/C&gt;N and/OCC exhaust/0&gt;N
manifolds/NB are/0V mounted/0V
on/AK opposite/0&gt;N sides/NH
of/0N‹ the/0&gt;1 cylinder/0&gt;N head/NR
</equation>
<bodyText confidence="0.999973727272727">
The only difference is in the analysis of cylinder head:
the first analysis reports cylinder as a noun phrase
head which is followed by the verb head, while the
second analysis considers cylinder head as a noun
phrase. Now the last remaining problem is, how
to deal with ambiguous analyses like these: should
cylinder be reported as a noun phrase, or is cylinder
head the unit to be extracted?
The present system provides all proposed noun
phrase candidates in the output, but each with an
indication of whether the candidate noun phrase is
unambiguously analysed as such, or not. In this so-
lution, I do not use all of the multiple analyses pro-
posed by the finite-state parser. For each sentence,
no more than two competing analyses are selected for
further processing: one with the highest number of
words as part of a maximally long noun phrase anal-
ysis, and the other with the lowest number of words
as part of a maximally short noun phrase analysis.
This &apos;weighing&apos; can be done during finite-state
parsing: the formalism employs a mechanism for im-
posing penalties on regular expressions, e.g. on tags.
</bodyText>
<footnote confidence="0.7828806">
&amp;quot;Research Unit for Computational Linguistics, Uni-
versity of Helsinki
&amp;quot;For other work in this approach, see also [Hosken-
niemi, 1990; Hoskenniemi, Tapanainen and Voutilainen,
1992; Vontilainen and Tapanainen, 1993].
</footnote>
<bodyText confidence="0.99990195">
A penalised reading is not discarded as ungrammat-
ical, only the parser returns all accepted analyses in
an order where the least penalised analyses are pro-
duced first and the &apos;worst&apos; ones last.
Thus there is an &apos;NP-hostile&apos; finite-state parser
that penalises noun phrase readings; this would
prefer the sentence reading with cylinder! NH
head/all. The &apos;NP-friendly&apos; parser, on the other
hand, penalises all readings which are not part of a
noun phrase reading, so it would prefer the analysis
with cylinder/@&gt;N head/WITH. Of all analyses, the
selected two parses are maximally dissimilar with re-
gard to NP-hood. The motivation for selecting max-
imally conflicting analyses in this respect is that a
candidate noun phrase that is agreed upon as a noun
phrase by the two finite-state parsers systems just as
it is - neither longer nor shorter - is likely to be an
unambiguously identified noun phrase. The compar-
ison of the outputs of the two competing finite-state
parsers is carried out during the extraction phase.
</bodyText>
<subsectionHeader confidence="0.999931">
4.4 Extraction of noun phrases
</subsectionHeader>
<bodyText confidence="0.713811529411765">
An unambiguous sentence reading is a linear se-
quence of symbols, and extracting noun phrases from
this kind of data is a simple pattern matching task.
in the present version of the system, I have used
the gawk program that allows the use of regular ex-
pressions. With gawk&apos;s gsub function, the bound-
aries of the longest non-overlapping expressions that
satisfy the search key can be marked. If we formu-
late our search query as something like the following
schematic regular expression:
WW1+ [CC M&gt;N+J*]* HEAD
EN&lt; [D/M&gt;N+ [CC D/N&gt;N4-],0]* READ]q
where
Et and IP are for grouping,
I+P stands for one or more
occurrences of its argument,
1 stands for zero or more
occurrences of its argument,
stands for premodifiers,
stands for determiners and
premodifiers,
&apos;HEAD) stands for nominal heads
except pronouns,
&apos;NO stands for prepositions
starting a postmodifying
prepositional phrase,
and do some additional formatting and &apos;cleaning&apos;,
the above two finite-state analyses will look like the
following13:
the
up: inlet and exhaust manifold
&amp;quot;Note that the noun phrase heads are here given in
the base form, hence the absence of the plural form of
e.g. &apos;manifold&apos;.
</bodyText>
<page confidence="0.996795">
53
</page>
<figure confidence="0.873642045454545">
are mounted on
np: opposite side of the cylinder
bead, the
np: exhaust manifold
channelling the
np: gas
to a
np: single exhaust pipe
and
np: silencer system
the
up: inlet and exhaust manifold
are mounted on
np: opposite side of the cylinder head
, the
np: exhaust manifold
channelling the
np: gas
to a
np: single exhaust pipe
and
np: silencer system
</figure>
<bodyText confidence="0.991646">
The proposed noun phrases are given on indented
lines, each marked with the symbol `np:&apos;. The can-
didate noun phrases are then subjected to further
routines: all candidate noun phrases with at least
one occurrence in the output of both the NP-hostile
and NP-friendly parsers are labelled with the sym-
bol &apos;ok:&apos;, and the remaining candidates are labelled
as uncertain, with the symbol &amp;quot;?:&apos;. From the outputs
given above, the following list can be produced:
ok: inlet and exhaust manifold
ok: exhaust manifold
ok: gas
ok: single exhaust pipe
ok: silencer system
?: opposite side of the cylinder
?: opposite side of the cylinder head
The linguistic analysis is relatively neutral as to
what is to be extracted from it. Here we have con-
centrated on noun phrase extraction, but from this
kind of input, also many other types of construction
could be extracted, e.g. simple verb-argument struc-
tures.
</bodyText>
<sectionHeader confidence="0.928819" genericHeader="method">
5 The syntactic description
</sectionHeader>
<bodyText confidence="0.999938066666667">
This section outlines the syntactic description that I
have written for NPtool purposes. The ENGTWOL
lexicon or the disambiguation constraints will not be
described further in this paper; they have been doc-
umented extensively elsewhere (see the relevant ar-
ticles in Karlsson &amp; al. iforthcomina.
According to the SIMPR experiences, the vast ma-
jority of index terms represent relatively few con-
structions. By far the most common construction
is a nominal head with optional, potentially coordi-
nated premodifiers and postmodifying prepositional
phrases, typically of phrases. The remainder, less
than 10%, consists almost entirely of relatively sim-
ple verb-NP patterns.
The syntactic description used in SIMPR em-
ployed some 30 dependency-oriented syntactic func-
tion tags, which differentiate (to some extent) be-
tween various kinds of verbal constructions, syntac-
tic functions of nominal beads, and so on. Some of
the ambiguity that survives ENGCG parsing is in
part due to these distinctions [Anttila, forthcoming].
The relatively simple needs of an index term ex-
traction utility on the one hand, and the relative
abundance of distinctions in the ENGCG syntactic
description on the other, suggest that a less distinc-
tive syntactic description might be more optimal for
the present purposes: a more shallow description
would entail less remaining ambiguity without un-
duly compromising its usefulness e.g. for an indexing
application.
</bodyText>
<subsectionHeader confidence="0.999634">
5.1 Syntactic tags
</subsectionHeader>
<bodyText confidence="0.938669">
I have designed a new syntactic grammar scheme
that employs seven function tags. These tags cap-
italise on the opposition between noun phrases and
other constructions on the one hand, and between
heads and modifiers, on the other. Here we will not
go into details; a gloss with a simple illustration will
suffice.
• @V represents auxiliary and main verbs as well
as the infinitive marker to in both finite and non-
finite constructions. For instance:
</bodyText>
<subsectionHeader confidence="0.634246">
She should/CV know/CV what to/CV do/CV.
</subsectionHeader>
<bodyText confidence="0.961818666666667">
• @NH represents nominal heads, especially
nouns, pronouns, numerals, abbreviations and -ing-
forms. Note that of adjectival categories, only those
with the morphological feature &lt;Nominal&gt;, e.g. En-
glish, are granted the corm status: all other adjec-
tives (and -ed-forms) are regarded as too unconven-
tional nominal heads to be granted this status in the
present description. An example:
The English/CHH may like the conventional.
</bodyText>
<listItem confidence="0.77143675">
• Itil&gt;N represents determiners and premodifiers
of nominals (the angle-bracket &apos;&apos;&gt;&apos; indicates the di-
rection in which the head is to be found). The head
is the following nominal with the tag @NR, or a pre-
modifier in between. An example:
the/C&gt;11 lat/41&gt;I1 butcher&apos;s/0&gt;Y wile
• ON&lt; represents prepositional phrases that un-
ambiguously postmodify a preceding nominal head.
Such unambiguously postmodifying constructions
are typically of two types: (i) in the absence of cer-
tain verbs like &apos;accuse&apos;, postnominal *phrases and
(ii) preverbal NP—PP sequences, e.g.
</listItem>
<bodyText confidence="0.81969">
The man in/Cl&lt; the moon had
a glass of/ON&lt; ale.
</bodyText>
<page confidence="0.995965">
54
</page>
<bodyText confidence="0.807316333333333">
Currently the description does not account for other
types of postmodifier, e.g. postmodifying adjectives,
numerals, other norninals, or clausal constructions.
</bodyText>
<listItem confidence="0.9785008">
• OCC and &apos;CS represent co-ordinating and sub-
ordinating conjunctions, respectively:
Either/CCC you or/CCC I will go
if/CCS necessary.
• ©AH represents the &apos;residual&apos;: adjectival heads,
</listItem>
<bodyText confidence="0.8127295">
adverbials of various kinds, adverbs (also intensi-
fiers), and also those of the prepositional phrases that
cannot be dependably analysed as a postmodifier.
An example is in order:
There/CAR have always/CAE been very/CAR
many people in/CAH this area.
</bodyText>
<subsectionHeader confidence="0.996214">
5.2 Syntactic constraints
</subsectionHeader>
<bodyText confidence="0.99951">
The syntactic grammar contains some 120 syntactic
constraints. Like the morphological disambiguation
constraints, these constraints are essentially negative
partial linear-precedence definitions of the syntactic
categories.
The present grammar is a partial expression of four
general grammar statements:
</bodyText>
<listItem confidence="0.999666">
1. Part of speech determines the order of determin-
ers and modifiers.
2. Only likes coordinate.
3. A determiner or a modifier has a head.
4. An auxiliary is followed by a main verb.
</listItem>
<bodyText confidence="0.974446173913044">
We will give only one illustration of how these
general statements can be expressed in Constraint
Grammar. Let us give a partial paraphrase of the
statement Par/ of speech determines the order of de-
ternziners and modifiers: &apos;A premodifying noun oc-
curs closest to its head&apos;. In other words, premodifiers
from other parts of speech do not immediately fol-
low a premodifying noun. Therefore, a noun in the
nominative immediately followed by an adjective is
not a premodifier. Thus a constraint in the grammar
would discard the ilbN tag of Harry in the following
sample sentence, where Harry is directly followed by
an unambiguous adjective:
(&amp;quot;&lt;sis&gt;&amp;quot;
(&amp;quot;be&amp;quot; &lt;SVC/N&gt; &lt;SVC/1&gt; V PRES SG3 (CV)))
(&amp;quot;&lt;*harry&gt;&amp;quot;
(&amp;quot;harry&amp;quot; &lt;Proper&gt; N NOM SG (CNH OW))
(&amp;quot;&lt;foolish&gt;&amp;quot;
(&amp;quot;foolish&amp;quot; A ABS MED)
We require that the noun in question is a nominative
because premodifying nouns in the genitive can occur
also before adjectival premodifiers; witness Harry&apos;s
in Harry&apos;s foolish self.
</bodyText>
<subsectionHeader confidence="0.887024">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.998938">
The present syntax has been applied to large
amounts of journalistic and technical text (news-
papers, abstracts on electrical engineering, manuals
on car maintenance, etc.), and the analysis of some
20,000-30,000 words has been proofread to get an
estimate of the accuracy of the parser.
After the application of the NPlool syntax, some
93-96% of all words become syntactically unambigu-
ous, with an error rate of less than 1%14.
To find out how much ambiguity remains at the
sentence level, I also applied a `NP-neutral&apos; version15
of the finite-state parser on a 25,500 word text from
The Grolier Electronic Encyclopaedia. The results
are given in Figure 1.
</bodyText>
<figureCaption confidence="0.99954725">
Figure 1: Ambiguity rates after finite-state parsing
in a text of 1,495 sentences (25,500 words). R in-
dicates the number of analyses per sentence, and F
indicates the frequency of these sentences.
</figureCaption>
<table confidence="0.9301565">
RF RF RF RF
1 960 6 19 12 6 32 2
2 304 7 3 14 3 48 2
3 54 8 28 16 5 69 1
4 93 9 3 24 1 72 1
5 4 10 3 28 1
</table>
<bodyText confidence="0.999018444444444">
Some 64% (960) of the 1,495 sentences became
syntactically unambiguous, while only some 2% of
all sentences analyses contain more than ten read-
ings, the worst ambiguity being due to 72 analyses.
This compares favourably with the ENGCG perfor-
mance: after ENGCG parsing, 23.5% of all sentences
remained ambiguous due to a number of sentence
readings greater than the worst case in NPtool syn-
tax.
</bodyText>
<sectionHeader confidence="0.970899" genericHeader="evaluation">
6 Performance of NPtoo/
</sectionHeader>
<bodyText confidence="0.998718666666667">
Various kinds of metrics can be proposed for the eval-
uation of a noun phrase extractor; our main metrics
are recall and precision, defined as follows&amp;quot;:
</bodyText>
<listItem confidence="0.97969025">
• Recall: the ratio &apos;retrieved intended NPs&apos;17 /
&apos;all intended NPs&apos;
• Precision: the ratio &apos;all retrieved NPs&apos; / &apos;re-
trieved intended NPs&apos;
</listItem>
<bodyText confidence="0.996026444444444">
&amp;quot;This figure also covers errors due to previous stages
of analysis.
i.e. a parser which does not contain the mechanism
for penalising or favouring noun phrase analyses; see Sec-
tion 4.3 above.
&amp;quot;This definition also agrees with that used in Rausch
&amp; al. [19923.
&amp;quot;An &apos;intended NP is the longest non-overlapping
match of the search query given in extraction phase.
</bodyText>
<page confidence="0.995094">
55
</page>
<bodyText confidence="0.99998555">
To paraphrase, a recall of less than 100% indicates
that the system missed some of the desired noun
phrases, while a precision of less than 100% indicates
that the system retrieved something that is not re-
garded as a correct result.
The performance of the whole system has been
evaluated against several texts from different do-
mains. In all, the analysis of some 20,000 words has
been manually checked.
If we wish to extract relatively complex noun
phrases with optional coordination, premodifiers and
postmodifiers (see the search query above in Sec-
tion 4.4), we reach a recall of 98.5-100%, with a
precision of some 95-98%.
As indicated in Section 4.4, the extraction utility
annotates each proposed noun phrase as a &apos;sure hit&apos;
(&apos;ok:&apos;) or as an &apos;uncertain hit&apos; (&apos;?:&apos;). This distinction
is quite useful for manual validation: approximately
95% of all superfluous noun phrase candidates are
marked with the question mark.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999973166666667">
In terms of accuracy, NPlool is probably one of the
best in the field. In terms of speed, much remains to
be optimised. Certainly the computationally most
demanding tasks - disambiguation and parsing - are
already carried out quite efficiently, but the more
trivial parts of the system could be improved.
</bodyText>
<sectionHeader confidence="0.997191" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999606">
I wish to thank Krister Linden, Pasi Tapanainen and
two anonymous referees for useful comments on an
earlier version of this paper. The usual disclaimers
hold.
</bodyText>
<sectionHeader confidence="0.969374" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.963263">
[Anttila, forthcoming] Anttila, A. (forthcoming).
How to recognise subjects in English. In Karlsson
&amp; al.
[Bourigault, 1992] Bourigault, D. 1992. Surface
grammatical analysis for the extraction of termi-
nological noun phrases. In Proceedings of the fif-
</bodyText>
<reference confidence="0.989018313432836">
teenth International Conference on Computational
Linguistics. COLING-92, Vol. III. Nantes, France.
977-981.
[Church, 1988] Church, K. 1988. A Stochastic Parts
Program and Noun Phrase Parser for Unrestricted
Text. Proceedings of the Second Conference on Ap-
plied Natural Language Processing, ACL. 136-143.
[Church, 1992] Church, K. 1992. Current Practice in
Part of Speech Tagging and Suggestions for the
Future, in Simmons (ed.), Sbornik praci: In Honor
of Henry KuCera. Michigan Slavic Studies.
[van der Eijk, 1993] van der Eijk, P. 1993. Automat-
ing the acquisition of bilingual terminology. Pro-
ceedings of EACL&apos;93. Utrecht, The Netherlands.
[Heikkili, forthcoming a] Heikkili, J. (forthcoming
a). A TWOL-Based Lexicon and Feature System
for English. In Karlsson &amp; al.
[Heikkili., forthcoming hi Heikkila, J. (forthcoming
ENGTWOL English lexicon: solutions and
problems. In Karlsson &amp; al.
[Karlsson, 1990] Karlsson, F. 1990.
Constraint Grammar as a Framework for Pars-
ing Running Text. In H. Karlgren (ed.), Papers
presented to the 13th International Conference on
Computational Linguistics, Vol. 3. Helsinki. 168-
173.
[Karlsson, forthcoming] Karisson, F. (forthcoming).
Designing a. parser for unrestricted text. In Karls-
son &amp; al.
[Karlsson et al., forthcoming] Karlsson, F., Vouti-
lainen, A., Heikkila, J. and Anttila, A. Con-
straint Grammar: a Language-Independent Sys.
ternfor Parsing Unrestricted Text. Mouton de
Gruyter.
[Koskenniemi, 1990] Koskenniemi,
K. (1990). Finite-state parsing and disambigua-
tion. In Karlgren, H. (ed.) COLING-90. Papers
presented to the 13th International Conference on
Computational Linguistics, Vol. 2. Helsinki, Fin-
land. 229-232.
[Koskenniemi, Tapanainen and Voutilainen, 1992]
Koskenniemi, K., Tapanainen, P. and Voutilainen,
A. (1992). Compiling and using finite-state syn-
tactic rules. In Proceedings of the fifteenth Inter-
national Conference on Computational Linguist-
ics. COLING-92, Vol. I. Nantes, Rance. 156-162.
[Quirk, Greenbaum, Leech and Svartvik, 1985]
Quirk, R., Greenbaum, S., Leech, G. and Svartvik,
J. 1985. A Comprehensive Grammar of the English
Language. London &amp; New York: Longman.
[Rausch, Norrback and Svensson, 1992] Hausa, B.,
Norrback, It., and Svensson, T. 1992. Excerper-
ing av nominalfraser ur 15pande text. Manuscript.
Stockhohns universitet, Institutionen fcir Lingvis-
tik.
[Salton and McGill, 1983] Salton, G. and McGill,
M. 1983. Introduction to Modern Information Re-
trieval. McGraw-Il ill, Auckland.
[Sampson, 1987a] Sampson, G. 1987. Probabilistic
Models of Analysis. In Garside, Leech and Samp-
son (eds.) 1987. 16-29.
[Sampson, 1987b] Sampson, G. 1987. The grammat-
ical database and parsing scheme. In Garside,
Leech and Sampson (eds.) 1987. 82-96.
[Smart (Ed.), forthcoming] Smart (Ed.) (forthcom-
ing). Structured Information Management: Pro-
cessing and Retrieval. (provisional title).
</reference>
<page confidence="0.969441">
56
</page>
<reference confidence="0.958599566666666">
[Tapanainen, 19911 Tapanainen, P. 1991. A- arellisina
automaatteina esitettyjen kielioppisiintiijen so-
veltaminen luonnollisen kielen jasentijiss (Nat-
ural language parsing with finite-state syntactic
rules). Master&apos;s thesis. Dept. of computer science,
University of Helsinki.
[Taylor, Grover and Briscoe, 1989] Taylor, L., Gro-
ver, C. and Briscoe, T. 1989. The Syntactic Regu-
larity of English Noun Phrases. In Proceedings of
the Fourth Conference of the European Chapter of
the ACL. 256-263.
[Voutilainen, forthcoming a] Voutilainen, A. (forth-
coming a). Context-sensitive disambiguation. In
Karlsson &amp; al.
[Voutilainen, forthcoming b] Voutilainen, A. (forth-
coming b). Experiments with heuristics. In Karts-
son &amp; al.
[Voutilainen, forthcoming 1993)
Voutilairien, A. (forthcoming 1993). Designing a
parsing grammar.
[Voutilainen, Heikkila and Anttila, 1992]
Voutilainen, A., Heikkili, .1. and Anttila., A.
(1992). Constraint Grammar of English: A
Performance-Oriented Introduction. Publication
No. 21, Department of General Linguistics, Uni-
versity of Helsinki.
[Voutilainen and Tapanainen, 1993] Voutilainen, A.
and Tapanainen, P. 1993. Ambiguity resolution in
a reductionistic parser. Proceedings of EA CL
Utrecht, Holland.
</reference>
<sectionHeader confidence="0.851378" genericHeader="references">
APPENDIX
</sectionHeader>
<bodyText confidence="0.997897885714286">
Here is given the NPtool analysis of a small sample
from the CACM text collection. - Here is the input
text:
The binary number system offers many
advantages over a decimal representation
for a high-performance, general-purpose
computer. The greater simplicity of a
binary arithmetic unit and the greater
compactness of binary numbers bath
contribute directly to arithmetic
speed. Less obvious and perhaps more
important is the way binary addressing
and instruction formats can increase the
overall performance. Binary addresses
are also essential to certain powerful
operations which are not practical with
decimal instruction formats. On the other
hand, decimal numbers are essential for
communicating between man and the
computer. In applications requiring the
processing of a large volume of
inherently decimal input and output
data, the time for decimal-binary
conversion needed by a purely binary
computer may be significant. A slower
decimal adder may take less time than
a fast binary adder doing an addition
and two conversions. A careful review
of the significance of decimal and
binary addressing and both binary
and decimal data arithmetic,
supplemented by efficient
conversion instructions.
Here is the list of noun phrases extracted by .ArPtool.
For the key, see Section 4.4.
</bodyText>
<reference confidence="0.829696868421053">
ok: addition
ok: advantage
ok: application
oh: arithmetic speed
ok: binary address
ok: binary addressing
ok: binary and decimal data arithmetic
ok: binary computer
ok: binary number system
ok: careful review of the significance
of decimal and binary addressing
ok: certain powerful operation
ok: computer
ok: decimal instruction format
ok: decimal number
ok: decimal representation
ok: decimal-binary conversion
ok: efficient conversion instruction
ok: fast binary adder
ok: high-performance, general-purpose
computer
ok: greater compactness of binary number
ok: greater simplicity of a binary
arithmetic unit
oh: instruction format
oh: man
oh: overall performance
ok: slower decimal adder
oh: time
ok: two conversion
ok: way
?: communicating
?: processing of a large volume of
inherently decimal input
?: processing of a large volume of
inherently decimal input and
output data
7: output data
</reference>
<page confidence="0.998509">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.066606">
<title confidence="0.839154333333333">detector of English noun phrases * Atro Research Unit for Computational</title>
<author confidence="0.454469">P O Box</author>
<address confidence="0.717376">FIN-00014 University of</address>
<email confidence="0.709436">E-mail:avoutila@ling.Helsinki.FII</email>
<abstract confidence="0.9117612">Piool is a fast accurate system for extracting noun phrases from English texts for the purposes of e.g. information retrieval, translation unit discovery, and cor-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date></date>
<booktitle>teenth International Conference on Computational Linguistics. COLING-92, Vol. III.</booktitle>
<pages>977--981</pages>
<location>Nantes,</location>
<marker></marker>
<rawString>teenth International Conference on Computational Linguistics. COLING-92, Vol. III. Nantes, France. 977-981.</rawString>
</citation>
<citation valid="true">
<title>A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text.</title>
<date>1988</date>
<booktitle>Proceedings of the Second Conference on Applied Natural Language Processing, ACL.</booktitle>
<pages>136--143</pages>
<marker>1988</marker>
<rawString>[Church, 1988] Church, K. 1988. A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. Proceedings of the Second Conference on Applied Natural Language Processing, ACL. 136-143.</rawString>
</citation>
<citation valid="true">
<title>Current Practice in Part of Speech Tagging and Suggestions for the Future,</title>
<date>1992</date>
<booktitle>Sbornik praci: In Honor of Henry KuCera. Michigan Slavic Studies.</booktitle>
<editor>in Simmons (ed.),</editor>
<marker>1992</marker>
<rawString>[Church, 1992] Church, K. 1992. Current Practice in Part of Speech Tagging and Suggestions for the Future, in Simmons (ed.), Sbornik praci: In Honor of Henry KuCera. Michigan Slavic Studies.</rawString>
</citation>
<citation valid="true">
<title>Automating the acquisition of bilingual terminology.</title>
<date>1993</date>
<booktitle>Proceedings of EACL&apos;93. Utrecht, The Netherlands. [Heikkili, forthcoming a] Heikkili, J. (forthcoming a). A TWOL-Based Lexicon and Feature System for English. In Karlsson &amp; al.</booktitle>
<marker>1993</marker>
<rawString>[van der Eijk, 1993] van der Eijk, P. 1993. Automating the acquisition of bilingual terminology. Proceedings of EACL&apos;93. Utrecht, The Netherlands. [Heikkili, forthcoming a] Heikkili, J. (forthcoming a). A TWOL-Based Lexicon and Feature System for English. In Karlsson &amp; al.</rawString>
</citation>
<citation valid="false">
<title>forthcoming ENGTWOL English lexicon: solutions and problems.</title>
<booktitle>In Karlsson &amp; al.</booktitle>
<marker></marker>
<rawString>[Heikkili., forthcoming hi Heikkila, J. (forthcoming ENGTWOL English lexicon: solutions and problems. In Karlsson &amp; al.</rawString>
</citation>
<citation valid="true">
<title>Constraint Grammar as a Framework for Parsing Running Text.</title>
<date>1990</date>
<booktitle>Papers presented to the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>168--173</pages>
<editor>In H. Karlgren (ed.),</editor>
<marker>1990</marker>
<rawString>[Karlsson, 1990] Karlsson, F. 1990. Constraint Grammar as a Framework for Parsing Running Text. In H. Karlgren (ed.), Papers presented to the 13th International Conference on Computational Linguistics, Vol. 3. Helsinki. 168-173.</rawString>
</citation>
<citation valid="false">
<authors>
<author>F Karisson</author>
</authors>
<title>Designing a. parser for unrestricted text.</title>
<booktitle>In Karlsson &amp; al.</booktitle>
<marker>Karisson, </marker>
<rawString>[Karlsson, forthcoming] Karisson, F. (forthcoming). Designing a. parser for unrestricted text. In Karlsson &amp; al.</rawString>
</citation>
<citation valid="false">
<title>Constraint Grammar: a Language-Independent Sys. ternfor Parsing Unrestricted Text. Mouton de Gruyter.</title>
<marker></marker>
<rawString>[Karlsson et al., forthcoming] Karlsson, F., Voutilainen, A., Heikkila, J. and Anttila, A. Constraint Grammar: a Language-Independent Sys. ternfor Parsing Unrestricted Text. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<title>Finite-state parsing and disambiguation.</title>
<date>1990</date>
<booktitle>COLING-90. Papers presented to the 13th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>229--232</pages>
<editor>In Karlgren, H. (ed.)</editor>
<location>Helsinki,</location>
<marker>1990</marker>
<rawString>[Koskenniemi, 1990] Koskenniemi, K. (1990). Finite-state parsing and disambiguation. In Karlgren, H. (ed.) COLING-90. Papers presented to the 13th International Conference on Computational Linguistics, Vol. 2. Helsinki, Finland. 229-232.</rawString>
</citation>
<citation valid="true">
<title>Compiling and using finite-state syntactic rules.</title>
<date>1992</date>
<booktitle>In Proceedings of the fifteenth International Conference on Computational Linguistics. COLING-92,</booktitle>
<volume>Vol.</volume>
<pages>156--162</pages>
<marker>1992</marker>
<rawString>[Koskenniemi, Tapanainen and Voutilainen, 1992] Koskenniemi, K., Tapanainen, P. and Voutilainen, A. (1992). Compiling and using finite-state syntactic rules. In Proceedings of the fifteenth International Conference on Computational Linguistics. COLING-92, Vol. I. Nantes, Rance. 156-162.</rawString>
</citation>
<citation valid="true">
<title>A Comprehensive Grammar of the English Language. London &amp;</title>
<date>1985</date>
<publisher>Longman.</publisher>
<location>New York:</location>
<marker>1985</marker>
<rawString>[Quirk, Greenbaum, Leech and Svartvik, 1985] Quirk, R., Greenbaum, S., Leech, G. and Svartvik, J. 1985. A Comprehensive Grammar of the English Language. London &amp; New York: Longman.</rawString>
</citation>
<citation valid="true">
<date>1992</date>
<booktitle>Excerpering av nominalfraser ur 15pande text. Manuscript. Stockhohns universitet, Institutionen fcir Lingvistik.</booktitle>
<marker>1992</marker>
<rawString>[Rausch, Norrback and Svensson, 1992] Hausa, B., Norrback, It., and Svensson, T. 1992. Excerpering av nominalfraser ur 15pande text. Manuscript. Stockhohns universitet, Institutionen fcir Lingvistik.</rawString>
</citation>
<citation valid="true">
<title>Introduction to Modern Information Retrieval. McGraw-Il ill,</title>
<date>1983</date>
<location>Auckland.</location>
<marker>1983</marker>
<rawString>[Salton and McGill, 1983] Salton, G. and McGill, M. 1983. Introduction to Modern Information Retrieval. McGraw-Il ill, Auckland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sampson</author>
</authors>
<title>Probabilistic Models of Analysis.</title>
<date>1987</date>
<pages>16--29</pages>
<editor>In Garside, Leech and Sampson (eds.)</editor>
<contexts>
<context position="2644" citStr="Sampson, 1987" startWordPosition="405" endWordPosition="406">ART C&gt;11 bird N @HEAD FULLSTOP In this type of analysis, each word is provided with tags indicating e.g. part of speech, inflection, derivation, and syntactic function. a Morphological and syntactic descriptions are based on hand-coded linguistic rules rather than on corpus-based statistical models. They employ structural categories that can be found in descriptive grammars, e.g. [Quirk, Greenbaum, Leech and Svartvik, 1985]. Regarding the at times heated methodological debate on whether statistical or rule-based information is to be preferred in grammatical analysis of running text (cf. e.g. [Sampson, 1987a; Taylor, Grover and Briscoe, 1989; Church, 1992]), we do not object to probabilistic methods in principle; nevertheless, it seems to us that rule-based descriptions are preferable because they can provide for more accurate and reliable analyses than current probabilistic systems, e.g. part-of-speech taggers [Voutilainen, Heikkila and Anttila, 1992; Voutilainen, forthcoming a].&apos; Probe&apos;Consider for instance the question posed in [Church, 1992] whether lexical probabilities contribute more to morphological or part-of-speech disambiguation than context does. The ENGCG morphological disambiguator</context>
</contexts>
<marker>Sampson, 1987</marker>
<rawString>[Sampson, 1987a] Sampson, G. 1987. Probabilistic Models of Analysis. In Garside, Leech and Sampson (eds.) 1987. 16-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sampson</author>
</authors>
<title>The grammatical database and parsing scheme.</title>
<date>1987</date>
<pages>82--96</pages>
<editor>In Garside, Leech and Sampson (eds.)</editor>
<contexts>
<context position="2644" citStr="Sampson, 1987" startWordPosition="405" endWordPosition="406">ART C&gt;11 bird N @HEAD FULLSTOP In this type of analysis, each word is provided with tags indicating e.g. part of speech, inflection, derivation, and syntactic function. a Morphological and syntactic descriptions are based on hand-coded linguistic rules rather than on corpus-based statistical models. They employ structural categories that can be found in descriptive grammars, e.g. [Quirk, Greenbaum, Leech and Svartvik, 1985]. Regarding the at times heated methodological debate on whether statistical or rule-based information is to be preferred in grammatical analysis of running text (cf. e.g. [Sampson, 1987a; Taylor, Grover and Briscoe, 1989; Church, 1992]), we do not object to probabilistic methods in principle; nevertheless, it seems to us that rule-based descriptions are preferable because they can provide for more accurate and reliable analyses than current probabilistic systems, e.g. part-of-speech taggers [Voutilainen, Heikkila and Anttila, 1992; Voutilainen, forthcoming a].&apos; Probe&apos;Consider for instance the question posed in [Church, 1992] whether lexical probabilities contribute more to morphological or part-of-speech disambiguation than context does. The ENGCG morphological disambiguator</context>
</contexts>
<marker>Sampson, 1987</marker>
<rawString>[Sampson, 1987b] Sampson, G. 1987. The grammatical database and parsing scheme. In Garside, Leech and Sampson (eds.) 1987. 82-96.</rawString>
</citation>
<citation valid="false">
<title>forthcoming] Smart (Ed.) (forthcoming). Structured Information Management: Processing and Retrieval.</title>
<note>(provisional title).</note>
<marker></marker>
<rawString>[Smart (Ed.), forthcoming] Smart (Ed.) (forthcoming). Structured Information Management: Processing and Retrieval. (provisional title).</rawString>
</citation>
<citation valid="true">
<title>A- arellisina automaatteina esitettyjen kielioppisiintiijen soveltaminen luonnollisen kielen jasentijiss (Natural language parsing with finite-state syntactic rules). Master&apos;s thesis. Dept. of computer science,</title>
<date>1991</date>
<institution>University of Helsinki.</institution>
<marker>1991</marker>
<rawString>[Tapanainen, 19911 Tapanainen, P. 1991. A- arellisina automaatteina esitettyjen kielioppisiintiijen soveltaminen luonnollisen kielen jasentijiss (Natural language parsing with finite-state syntactic rules). Master&apos;s thesis. Dept. of computer science, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<title>The Syntactic Regularity of English Noun Phrases.</title>
<date>1989</date>
<booktitle>In Proceedings of the Fourth Conference of the European Chapter of the ACL.</booktitle>
<pages>256--263</pages>
<marker>1989</marker>
<rawString>[Taylor, Grover and Briscoe, 1989] Taylor, L., Grover, C. and Briscoe, T. 1989. The Syntactic Regularity of English Noun Phrases. In Proceedings of the Fourth Conference of the European Chapter of the ACL. 256-263.</rawString>
</citation>
<citation valid="false">
<title>forthcoming a] Voutilainen, A. (forthcoming a). Context-sensitive disambiguation.</title>
<booktitle>In Karlsson &amp; al.</booktitle>
<marker></marker>
<rawString>[Voutilainen, forthcoming a] Voutilainen, A. (forthcoming a). Context-sensitive disambiguation. In Karlsson &amp; al.</rawString>
</citation>
<citation valid="false">
<title>forthcoming b] Voutilainen, A. (forthcoming b). Experiments with heuristics.</title>
<booktitle>In Kartsson &amp; al.</booktitle>
<marker></marker>
<rawString>[Voutilainen, forthcoming b] Voutilainen, A. (forthcoming b). Experiments with heuristics. In Kartsson &amp; al.</rawString>
</citation>
<citation valid="false">
<title>forthcoming 1993) Voutilairien, A. (forthcoming 1993). Designing a parsing grammar.</title>
<marker></marker>
<rawString>[Voutilainen, forthcoming 1993) Voutilairien, A. (forthcoming 1993). Designing a parsing grammar.</rawString>
</citation>
<citation valid="true">
<title>Constraint Grammar of English: A Performance-Oriented Introduction.</title>
<date>1992</date>
<tech>Publication No. 21,</tech>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<marker>1992</marker>
<rawString>[Voutilainen, Heikkila and Anttila, 1992] Voutilainen, A., Heikkili, .1. and Anttila., A. (1992). Constraint Grammar of English: A Performance-Oriented Introduction. Publication No. 21, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<title>Ambiguity resolution in a reductionistic parser.</title>
<date>1993</date>
<booktitle>Proceedings of EA CL Utrecht,</booktitle>
<location>Holland.</location>
<marker>1993</marker>
<rawString>[Voutilainen and Tapanainen, 1993] Voutilainen, A. and Tapanainen, P. 1993. Ambiguity resolution in a reductionistic parser. Proceedings of EA CL Utrecht, Holland.</rawString>
</citation>
<citation valid="false">
<title>ok: addition ok: advantage ok: application oh: arithmetic speed ok: binary address ok: binary addressing ok: binary and decimal data arithmetic ok: binary computer ok: binary number system ok: careful review of the significance of decimal and binary addressing ok: certain powerful operation ok: computer ok: decimal instruction format ok: decimal number ok: decimal representation ok: decimal-binary conversion ok: efficient conversion instruction ok: fast binary adder ok: high-performance, general-purpose computer ok: greater compactness of binary number ok: greater simplicity of a binary arithmetic unit oh: instruction format oh: man oh: overall performance ok: slower decimal adder oh: time ok: two conversion ok: way ?: communicating ?: processing of a large volume of inherently decimal input ?: processing of a large volume of inherently decimal input and output data 7: output data</title>
<marker></marker>
<rawString>ok: addition ok: advantage ok: application oh: arithmetic speed ok: binary address ok: binary addressing ok: binary and decimal data arithmetic ok: binary computer ok: binary number system ok: careful review of the significance of decimal and binary addressing ok: certain powerful operation ok: computer ok: decimal instruction format ok: decimal number ok: decimal representation ok: decimal-binary conversion ok: efficient conversion instruction ok: fast binary adder ok: high-performance, general-purpose computer ok: greater compactness of binary number ok: greater simplicity of a binary arithmetic unit oh: instruction format oh: man oh: overall performance ok: slower decimal adder oh: time ok: two conversion ok: way ?: communicating ?: processing of a large volume of inherently decimal input ?: processing of a large volume of inherently decimal input and output data 7: output data</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>