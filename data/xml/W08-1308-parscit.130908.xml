<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011424">
<title confidence="0.993929">
‘Deep’ Grammatical Relations for Semantic Interpretation
</title>
<author confidence="0.997716">
Mark McConville and Myroslava O. Dzikovska
</author>
<affiliation confidence="0.999243">
Institute for Communicating and Collaborative Systems
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.887181">
Informatics Forum, 10 Crichton Street, Edinburgh, EH8 9AB, Scotland
</address>
<email confidence="0.998968">
{Mark.McConville,M.Dzikovska}@ed.ac.uk
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999819357142857">
In this paper, we evaluate five distinct sys-
tems of labelled grammatical dependency
against the kind of input we require for se-
mantic interpretation, in particular for the
deep semantic interpreter underlying a tu-
torial dialogue system. We focus on the
following linguistic phenomena: passive,
control and raising, noun modifiers, and
meaningful vs. non-meaningful preposi-
tions. We conclude that no one system
provides all the features that we require,
although each such feature is contained
within at least one of the competing sys-
tems.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999861411764706">
The aim of the work reported in this paper is to
evaluate the extent to which proposed systems of
grammatical relations (GRs) reflect the kinds of
deep linguistic knowledge required for semantic
interpretation, in particular for deriving semantic
representations suitable for domain reasoning in
dialogue systems.
Grammatical relations either produced by or ex-
tracted from the output of wide-coverage syntactic
parsers are currently used as input to shallow se-
mantic parsers, which identify semantic relations
that exist between predicators (typically verbs) and
their dependents (Gildea and Jurafsky, 2002; Erk
and Pad´o, 2006). Predicate-argument structure
identified in this way can then be used in tasks like
information extraction (Surdeanu et al., 2003) and
question answering (Kaisser and Webber, 2007).
</bodyText>
<footnote confidence="0.9028645">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999934473684211">
However, wide-coverage stochastic parsers are
only rarely used in dialogue systems. Tradi-
tionally, interpretation modules of dialogue sys-
tems utilise specialised parsers and semantic in-
terpreters handcrafted to a small domain (Seneff,
1992; Chang et al., 2002), or wide coverage deep
parsers (Allen et al., 2007; Jordan et al., 2006;
Wolska and Kruijff-Korbayov´a, 2003; Callaway et
al., 2007; Kay et al., 1994). Unlike in information
retrieval and question answering tasks, the system
often needs to be connected to a knowledge base
which represents the state of the world, and must
be able to convert user utterances into knowledge
base queries. In addition to identifying predicate-
argument relationships, such systems need to sup-
port a variety of tasks, for example resolution of
pronouns and anaphors, and interpreting negation,
quantification, tense and modality.
While deep parsers produce precise seman-
tic representations appropriate for such reason-
ing, they suffer from robustness problems. Wide-
coverage dependency parsers could potentially
provide a more robust alternative, provided that
their output is easy to convert into semantic rep-
resentations for reasoning.
Section 2 introduces the kind of deep linguis-
tic processing application which motivates our ap-
proach to grammatical relations. Section 3 de-
fines some underlying principles behind the kind
of ‘deep’ GR system we have in mind. The remain-
der of the paper discusses a number of linguistic
phenomena in detail, and evaluates how well vari-
ous systems of GR representation from the depen-
dency parsing literature capture the kind of linguis-
tic insights required for interface with reasoning —
passive (section 4), raising and control (section 5),
noun modification (section 6) and syntactic versus
semantic prepositions (section 7).
</bodyText>
<page confidence="0.98586">
51
</page>
<note confidence="0.8313385">
Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 51–58
Manchester, August 2008
</note>
<sectionHeader confidence="0.992551" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.994981130434783">
As an example application that requires deep pars-
ing consider a tutorial dialogue system that inter-
prets students’ answers to factual questions (e.g.
Which bulbs will be lit in this circuit?) as well
as explanation questions (e.g. Explain your rea-
soning!). It has been argued previously (Wolska
and Kruijff-Korbayov´a, 2004; Ros´e et al., 2003)
that tutorial dialogue systems require deep under-
standing of student explanations, which can have
significantly more complex structure than database
queries in the information-seeking domain. In our
application, if a student is asked for an explana-
tion, his or her input has to be passed through the
domain knowledge base to verify its factual cor-
rectness, and a separate process verifies that all
relations mentioned in the explanation are correct
and relevant. For example, imagine that the stu-
dent says the following:
(1) The bulbs in circuits 1 and 3 will be lit
because they are in closed paths with the
batteries.
Here, the system has to verify two things: (a) that
the facts are correct (bulbs in circuits 1 and 3 will
be lit, and each of those bulbs is in a closed path
with a battery); and (b) that the reason is valid —
being in a closed path with a battery is a necessary
and sufficient condition for a bulb to be lit.
This task is particularly interesting because it
combines characteristics of deep and shallow inter-
pretation tasks. On the one hand, the fact-checking
mechanism requires a connection to the database.
Thus, both pronouns and definite noun phrases
need to be resolved to the objects they represent in
the knowledge base, and first-order logic formulas
representing utterance content need to be checked
against the system knowledge. This task is simi-
lar to natural language interfaces to databases, or
knowledge acquisition interfaces that convert lan-
guage into knowledge base statements (Yeh et al.,
2005). On the other hand, with respect to rea-
son checking, human tutors have indicated that
they would accept an answer simply if a student
produces the key concepts and relations between
them, even if the answer is not strictly logically
equivalent to the ideal answer (Dzikovska et al.,
2008). Human tutors tend to be especially lenient
if a student is asked a generic question, like What
is the definition of voltage?, which does not refer
to specific objects in the knowledge base. Thus, a
simpler matching mechanism is used to check the
reasons, making this task more similar to an infor-
mation retrieval task requiring shallower process-
ing, i.e. that the predicate-argument relations are
retrieved correctly (though negation still remains
important).
Thus, while a specific task is used to motivate
our evaluation, the conclusions would be applica-
ble to a variety of systems, including both deep and
shallow semantic interpreters.
For the purposes of this evaluation, we discuss
features of grammatical representation relevant to
two subtasks critical for the system: (a) identify-
ing predicate-argument structure; and (b) resolving
anaphora.
The extraction of predicate-argument relations
is a common requirement for both shallow and
deep semantic tasks. For example, for the stu-
dent input in example (1) we may expect some-
thing like:1
</bodyText>
<equation confidence="0.9748672">
(2) (LightBulb b1) (LightBulb b2)
(lit b1 true) (lit b2 true)
(Path P3) (closed P3 true)
(contains P3 b1) (Path P4)
(closed P4 true) (contains P4 b2)
</equation>
<bodyText confidence="0.997715315789474">
Resolving anaphora, on the other hand, is par-
ticularly important for the kind of deep seman-
tic processing used in dialogue systems. Implicit
in the above representation is the fact that the
definite noun phrase the bulbs in circuits 1 and
3 was resolved to domain constants b1 and b3,
and indefinite references to paths were replaced by
Skolem constants P3 and P4. The reference reso-
lution process requires detailed knowledge of noun
phrase structure, including information about re-
strictive modification, and this is the second focus
of our evaluation.
Ideally, we would like a dependency parser to
produce grammatical relations that can be con-
verted into such semantic representations with
minimal effort, thus minimising the number of spe-
cific rules used to convert individual relations. We
discuss the principles underlying such representa-
tions in more detail in the next section.
</bodyText>
<footnote confidence="0.996246428571429">
1We used a simplified representation of quantifiers that as-
sumes no scope ambiguity and uses skolem constants to rep-
resent existential quantification. This is sufficient for our par-
ticular application. In general, a more sophisticated quantifier
representation would be necessary, for example that proposed
in Copestake et al. (2005) or Bos and Oka (2002), but we
leave the relevant evaluation for future work.
</footnote>
<page confidence="0.999272">
52
</page>
<sectionHeader confidence="0.986863" genericHeader="method">
3 Deep grammatical relations
</sectionHeader>
<bodyText confidence="0.997116411764706">
We formulated four principles for deep grammati-
cal relations representation.
Firstly, grammatical relations should, whenever
possible, reflect relations between the predicators
(i.e. content words as opposed to function words)
in a sentence. In addition, the same relation should
correspond to the same role assignment. For exam-
ple, the deep GRs in passive constructions should
be the same as those in the active equivalents
(see section 4), and the analysis of a control verb
construction like John persuaded Mary to dance
should make it clear that there is a ‘subject’ GR
from dance to Mary similar to that in the implied
sentence Mary danced (see section 5).
Secondly, a GR should, whenever possible, ap-
pear only if there is a an explicit selectional restric-
tion link between the words. For example, in a
raising verb construction like John expects Mary to
dance, there should be no GR from the raising verb
expects to its object Mary (see section 5). Also,
where a preposition functions strictly as a syntac-
tic role marker, as in the construction John relies
on Mary, it should have no place in the GR anal-
ysis; rather there should be a direct link from the
verb to the embedded noun phrase (see section 7).
Thirdly, the GRs should preserve evidence of
syntactic modification to enable reference resolu-
tion. To understand why this is important, take the
following two examples:
(3) The lit bulb is in a closed path.
The bulb in a closed path is lit.
From a pure predicate-argument structure perspec-
tive, these two sentences share exactly the same
deep GRs:2
</bodyText>
<equation confidence="0.6213575">
(4) ext(lit,bulb)
ext(in-closed-path,bulb)
</equation>
<bodyText confidence="0.989753769230769">
However, from the perspective of reference resolu-
tion, the two sentences are very different. For the
first example, this process involves first finding the
lit bulb and then verifying that it is in a closed path,
whereas for the second we need to find the bulb in
a closed path and verify that it is lit. This differ-
ence can be captured by assigning the following
additional deep GRs to the first example:
2The representation is simplified for reasons of exposition.
The GRs should be interpreted as follows: ext denotes the
external argument of an adjective or preposition, ncmod a
non-clausal restrictive modifier, and det the determiner of a
noun.
</bodyText>
<listItem confidence="0.750958">
(5) det(bulb,the)
ncmod(bulb,lit)
</listItem>
<bodyText confidence="0.7882885">
And the following GRs are added to the analysis
of the second example:
</bodyText>
<equation confidence="0.324805">
(6) det(bulb,the)
ncmod(bulb,in-closed-path)
</equation>
<bodyText confidence="0.99996525">
Now the two analyses are formally distinct: (a) the
first is rooted at predicate in a closed path and the
second at lit; and (b) the definite external argument
the bulb takes scope over the modifier lit in the first
but over in a closed path in the second. Noun mod-
ification is discussed in section 6.
Finally, the set of grammatical relations should
make it easy to identify and separate out con-
structions which are largely dependent on seman-
tic/world knowledge, such as N-N modification, so
that separate models and evaluations can be con-
ducted as necessary.
</bodyText>
<sectionHeader confidence="0.999153" genericHeader="method">
4 Passive
</sectionHeader>
<bodyText confidence="0.999756033333333">
The shared task dataset contains numerous passive
participles, most of which can be classified into the
following four groups depending on how the par-
ticiple is used: (a) complement of passive auxiliary
e.g. Tax induction is activated by the RelA subunit;
(b) complement of raising verb e.g. The adminis-
tration doesn’t seem moved by the arguments; (c)
nominal postmodifier e.g. the genes involved in T-
cell growth; and (d) nominal premodifier e.g. the
proposed rules.
In all these cases, our system for deep gram-
matical relation annotation requires: (a) that
there is a relation from the passive partici-
ple to the deep object; and (b) that this rela-
tion be the same as in the corresponding ac-
tive declarative construction, so that predicate-
argument structure can be straightforwardly de-
rived. Thus, for example, the analysis of Tax in-
duction is activated by the RelA subunit will con-
tainthe GR dobj(activated,induction),
and that of the proposed rules will include
dobj(proposed,rules), where dobj is the
relation between a transitive verb and its (deep) di-
rect object.
We evaluated five GR-based output formats ac-
cording to these two features. The results are pre-
sented in Table 1, where for each representation
format (the rows) and each usage class of pas-
sive participles (the columns), we provide the GR
which goes from the participle to its deep object,
</bodyText>
<page confidence="0.994872">
53
</page>
<table confidence="0.998505">
complement of complement of nominal nominal active
passive auxiliary raising verb postmodifier premodifier
HPSG ARG2 (of verb arg12)
RASP ncsubj:obj dobj
CCGBank Spss\NP N/N S\NP/[NP]
Stanford nsubjpass - dobj
PARC subj - obj
</table>
<tableCaption confidence="0.999926">
Table 1: Representation of deep objects in passive and active
</tableCaption>
<bodyText confidence="0.996098542857143">
if such a GR exists.3 The five GR representations
compared are:
HPSG predicate-argument structures extracted
from the University of Tokyo HPSG Treebank
(Miyao, 2006)
RASP grammatical relations as output by the
RASP parser (Briscoe et al., 2006)
CCGBank predicate-argument dependencies ex-
tracted from CCGBank (Hockenmaier and
Steedman, 2007)
Stanford grammatical relations output by the
Stanford Parser (de Marneffe et al., 2006)
PARC dependency structures used in the annota-
tion of DepBank (King et al., 2003)
The first four columns in Table 1 represent, for
each of the four uses of passive participles listed
above, the grammatical relation, if any, which typ-
ically joins a passive participle to its deep object.
The rightmost column presents the label used for
this relation in equivalent active clauses. Adjacent
columns have been collapsed where the same GR
is used for both uses. The ideal system would have
the same GR listed in each of the five columns.
The grammatical relations used in the Stan-
ford, PARC and RASP systems are atomic labels
like subj, obj etc, although the latter system
does allow for a limited range of composite GRs
like ncsubj:obj (a non-clausal surface subject
which realises a deep object). In the HPSG sys-
tem, verbal subjects and objects are represented
as ARG1 and ARG2 respectively of strict transi-
tive verb type verb arg12. Finally, the GRs as-
sumed in CCGBank consist of a lexical category
(e.g. the strict transitive verb category S\NP/NP)
with one argument emphasised. I assume the
</bodyText>
<footnote confidence="0.863316">
3The relations presented for HPSG and CCG are those for
passive participle of strict transitive verbs.
</footnote>
<bodyText confidence="0.999199742857143">
following notational convenience for those cate-
gories which contain specify more than one argu-
ment — the emphasised argument is surrounded
by square brackets. Thus, subject and object of a
strict transitive verb are denoted S\[NP]/NP and
S\NP/[NP] respectively.
With respect to Table 1, note that: (a) in the
CCGbank dependency representation, although
prenominal passive participles are linked to their
deep object (i.e. the modified noun), this relation
is just one of generic noun premodification (i.e.
N/N) and is thus irrelevant to the kind of predicate-
argument relation we are interested in; (b) in the
PARC and Stanford dependency representations,
there is no GR from noun-modifying passive par-
ticiples to their deep objects, just generic modifica-
tion relations in the opposite direction; and (c) in
PARC, passive participles are themselves marked
as being passive, thus allowing a subsequent inter-
pretation module to normalise the deep grammati-
cal relations if desired.
If we are interested in a system of deep gram-
matical role annotation which allows for the rep-
resentation of normalised GRs for passive partici-
ples in all their uses, then the HPSG Treebank for-
mat is more appropriate than the other schemes,
since it uniformly uses deep GRs for both ac-
tive and passive verb constructions. The RASP
representation comes a close second, only requir-
ing a small amount of postprocessing to convert
ncsubj:obj relations into dobj ones. In addi-
tion, both the CCGBank and the Stanford notation
distinguish two kinds of surface subject — those
which realise deep subjects, and those which re-
alise passivised deep objects.
</bodyText>
<sectionHeader confidence="0.999088" genericHeader="method">
5 Control
</sectionHeader>
<bodyText confidence="0.999919">
The shared task dataset contains a number of in-
finitives or participles which are dependents of
non-auxiliary verbs or adjectives (rather than be-
ing noun modifiers for example). Most of these can
</bodyText>
<page confidence="0.993333">
54
</page>
<table confidence="0.999331166666667">
complements adjuncts raising
HPSG ✓ ✓ X
RASP ✓ ✓ X
CCGbank ✓ ✓ X
Stanford ✓ X ✓
PARC X X X
</table>
<tableCaption confidence="0.921258">
Table 2: Representation of controlled subjects and
raising
</tableCaption>
<bodyText confidence="0.999634489795918">
be partitioned into the following three classes: (a)
complements of subject control verbs e.g. The ac-
cumulation of nuclear c-Rel acts to inhibit its own
continued production; (b) complements of subject
raising verbs e.g. The administration seems moved
by arguments that ... ; and (c) subject controlled
adjuncts e.g. Alex de Castro has stopped by to slip
six cards to the Great Man Himself.
In all these cases, our deep grammatical role an-
notation requires that there be a subject relation
(or an object relation in the case of a passive par-
ticiple) from the infinitive/participle to the surface
subject (or surface object in the case of object con-
trol) of the controlling verb/adjective. For exam-
ple, the analysis of Tax acts indirectly by induc-
ing the action of various host transcription fac-
tors will contain both the GRs sbj(acts,Tax)
and sbj(inducing,Tax). In addition, we also
want to distinguish ‘raising’ verbs and adjectives
from control structures. Thus, in the analysis of
The administration seems moved by arguments
that ..., we want a (deep) object relation from
moved to administration, but we don’t want any
relation from seems to administration.
We again evaluated the various GR-based output
formats according to these features. The results are
presented in Table 2, where for each representation
format (the rows) we determine: (a) whether a verb
with an understood subject which is a complement
of the matrix verb is linked directly to its relevant
subject (column 1); (b) whether a verb with an un-
derstood subject which is a controlled adjunct of
the matrix verb is linked directly to its relevant
subject (column 2); and (c) whether raising verbs
are non-linked to their surface subjects (column
3). Note that the Stanford dependency represen-
tation is the only format which distinguishes be-
tween raising and control. This distinction is made
both structurally and in terms of the name assigned
to the relevant dependent — controlled subjects
are distinguished from all other subjects (includ-
ing raised ones) by having the label xsubj rather
than just nsubj.4
The ideal GR representation format would have
a tick in each of the three columns in Table 2. It is
clear that no single representation covers all of our
desiderata for a deep grammatical relation treat-
ment of control/raising, but each feature we require
is provided by at least one format.
</bodyText>
<sectionHeader confidence="0.997363" genericHeader="method">
6 Nominal modifiers
</sectionHeader>
<bodyText confidence="0.995655571428572">
The dataset contains numerous prenominal modi-
fiers5, subdivided into the following three groups:
(a) attributive adjectives e.g. a few notable excep-
tions; (b) verb participles e.g. the proposed rules;
and (c) nouns e.g. a car salesman.
In order to ensure an adequate representation of
basic predicate-argument structure, our system of
deep grammatical annotation first of all requires
that, from each prenominal adjective or verb, there
is an appropriate relation to the modified noun, of
the same type as in the corresponding predicative
usage. For example, assuming that He proposed
the rules has a direct object relation from proposed
to rules, the same relation should occur in the anal-
ysis of the proposed rules. Similarly, if The excep-
tions are notable is analysed as having an external
argument relation from notable to exceptions, then
the same should happen in the case of a few no-
table exceptions. However, this does not appear to
hold for prenominal nouns, since the relation be-
tween the two is not simply one of predication —
a car salesman is not a salesman who ‘is’ a car,
but rather a salesman who is ‘associated’ with cars
in some way. Thus we would not want the same
relation to be used here.6
Secondly, in order to ensure a straightforward
interface with reference resolution, we need a
modification relation going in the opposite direc-
4We have judged that CCGBank does not make the rele-
vant distinction between raising and control verbs based on
the dependency representations contained in the shared task
dataset. For example, for the example sentence The adminis-
tration seem moved by the fact that ..., a CCG subject relation
is specified from the raising verb seem to its surface subject
administration.
</bodyText>
<footnote confidence="0.977538666666667">
5We focus on prenominal modifiers in order to keep the
exposition simple. Similar remarks are valid for postnominal
restrictive modifiers as well.
6Presumably the same goes for attributive adjectives
which lack corresponding predicative uses, e.g. the former
president.
</footnote>
<page confidence="0.999207">
55
</page>
<bodyText confidence="0.9999615">
tion, from the modified noun to each (restrictive)
modifier, as argued in section 2. Thus, a complete
GR representation of a noun phrase like notable
exceptions would be cyclical, for example:
</bodyText>
<equation confidence="0.934521">
(7) ext(notable,exceptions)
ncmod(exceptions,notable)
</equation>
<bodyText confidence="0.999989097560975">
We evaluated the various GR-based output formats
according to these desiderata. The results are pre-
sented in Table 3. For each annotation scheme (the
rows), we first present the relation (if any) which
goes from the modified noun to each kind of pre-
modifier (adjective, verb participle and noun re-
spectively).7 The middle three columns contain the
relation (if any) which goes to the noun from each
kind of modifier. Finally, the last three columns
give the corresponding predicative relation used in
the annotation scheme, for example in construc-
tions like The exceptions are notable, He proposed
the rules, or Herbie is a car. Where it is un-
clear whether a particular format encodes the re-
lation between a predicative noun and its subject,
we mark this as ‘?’ in the last column.
Ideally, what we want is a representation where:
(a) there is a GR in all nine columns (with the pos-
sible exception of the ‘noun modifier to noun’ one
(column 6)); (b) the corresponding relations in the
middle and righthand sections are identical, except
for ‘noun modifier to noun’ (column 6) and ‘pred-
icative noun’ (the last column) which should be
distinct, since the relation between a noun modifier
and its head noun is not simply one of predication.
It is clear that no one representation is perfect,
though every feature we require is present in at
least one representation system. Note in particu-
lar that the HPSG, PARC and Stanford systems are
acyclic — the former only has ‘modifier to noun’
links, while the latter two only have ‘noun to mod-
ifier’ ones. The RASP format is cyclic, at least for
prenominal participles — in the proposed rules,
there is a modifier relation from rules to proposed,
as well as a deep object relation from proposed to
rules, the same relation that would be found in the
corresponding predicative the rules were proposed.
Note finally that the PARC and Stanford repre-
sentations distinguish between prenominal adjec-
tives and nouns, in terms of the name of the rele-
vant modifier GR. This corresponds well with our
</bodyText>
<footnote confidence="0.8564655">
7Note that the N/N links in the CCG representation actu-
ally go from the modifier to the noun. However, they have
been included in the set of ‘noun to modifier’ relations since
they are formally modifier categories (i.e. of the form X/X).
</footnote>
<bodyText confidence="0.998443">
preference for a GR system where we can evalu-
ate modules of N-N disambiguation (e.g. luxury
car salesman) in isolation from other aspects of
prenominal structure.
</bodyText>
<sectionHeader confidence="0.97999" genericHeader="method">
7 Prepositions
</sectionHeader>
<bodyText confidence="0.9999685">
All five grammatical relations formats treat prepo-
sition phrases in pretty much the same way: (a)
there is a GR link from the head of which the PP
is a complement or modifier to the preposition it-
self (the HPSG representation has this link going
in the opposite direction for PP modifiers, but the
principle is the same); and (b) there is a link from
the preposition to its complement NP. For example,
the noun phrase experts in Congress is annotated as
follows:
</bodyText>
<equation confidence="0.774578">
(8) ncmod(experts,in)
dobj(in,Congress)
</equation>
<bodyText confidence="0.9999665">
The only PPs which have been handled differently
are agentive by-PPs of passive participles, which
are either normalised or treated using a special,
construction-specific GR.
Note however that all prepositions are not equal
when it comes down to representing the predicate-
argument structure of a sentence. In a nutshell,
some prepositions are predicators (e.g. experts
in Congress) whereas others are simply syntactic
role markers (e.g. a workout of the Suns). Ide-
ally, we would want a GR system which marks
this distinction, for example by annotating pred-
icator prepositions as lexical heads and ignoring
role-marking prepositions altogether. The only
GR scheme which attempts to make this distinc-
tion is the PARC system, which has a ptype fea-
ture for every preposition with two possible val-
ues, semantic and non-semantic. However,
this does not appear to have been annotated consis-
tently in the PARC dataset — the only examples of
non-semantic prepositions are agentive by-PPs of
passive participles.
</bodyText>
<sectionHeader confidence="0.993798" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999981375">
We have proposed a set of principles for devel-
oping a grammatical relation annotation system
for use with both shallow and deep semantic in-
terpretation systems, in particular a tutorial dia-
logue system. We then evaluated five different GR
schemes from the dependency parsing literature
based on how well they handle a number of ‘deep’
syntactic phenomena implied by these principles,
</bodyText>
<page confidence="0.994087">
56
</page>
<table confidence="0.936395571428571">
noun to modifier modifier to noun predicative
A V N A V N A V N
RASP ncmod - ncsubj etc - - ncsubj etc -
HPSG - a arg1 v arg1 etc n arg1 a arg1 v arg1 etc n arg1
CCG N/N - N/N - S\NP etc - Sadj\NP S\NP etc ?
PARC adjunct mod - subj subj ?
Stanf amod nn - nsubj nsubj ?
</table>
<tableCaption confidence="0.999879">
Table 3: Representation of prenominal modifiers
</tableCaption>
<bodyText confidence="0.999959394736842">
i.e. passive, control and raising, noun modifica-
tion, and meaningful vs. non-meaningful prepo-
sitions. We conclude that none of the proposed
GR annotation schemes contains everything we re-
quire for deep semantic processing, although each
of the features/distinctions we included in our list
of desiderata is provided by at least one system.
Many of the deep syntactic phenomena dis-
cussed here are known issues for shallow seman-
tic tasks like semantic role labelling. For exam-
ple, passive constructions are a recognised source
of noise in semantic role labelling systems (Gildea
and Jurafsky, 2002), and resolving controlled sub-
jects provides more data for training models of se-
lectional restrictions, which are known to be useful
features for role labelling. More generally, Chen
and Rambow (2003) demonstrate that a focus on
‘deep’ syntactic features results in a more accurate
stochastic semantic role labeller than using surface
information alone.
Note also that the deep grammatical role rep-
resentation proposed here is meant to be ‘theory-
neutral’, in the sense that it was not influenced by
any one of the competing grammar formalisms to
the exclusion of the others. Indeed, it should be
a straightforward task to write a grammar using
either the HPSG, LFG, CCG or RASP-style un-
derlying formalism which can produce an output
representation consisting of deep relations, con-
structed in a purely compositional manner. Indeed,
the syntactic phenomena discussed in this paper
are those which form the basis of numerous in-
troductory textbooks on English generative syntax
(Haegeman, 1994; Sag and Wasow, 1999; Bres-
nan, 2000). In addition, the phenomena which
form the basis of the analysis in this paper were
among those which had been the focus of a sig-
nificant amount of attention in the development
of the semantic interpretation system underlying
our domain-independent tutorial dialogue system.
Other issues which were considered, but for which
we lack space to discuss in detail include: (a) ex-
pletive pronouns should be ignored, i.e. the subject
pronouns in ‘impersonal’ verb constructions like It
is raining or It’s great that John loves Mary should
not be seen as the target of deep grammatical re-
lations; (b) unbounded dependencies should be re-
solved, i.e. in the relative clause the woman Bill
thinks John loves there should be an object relation
between the embedded verb loves and its extracted
object woman; (c) restrictive and non-restrictive
modification (including apposition) should be dis-
tinguished, since the latter is not relevant for refer-
ence resolution; and (d) certain subsentential con-
junctions need to be compiled out (for examples
like electronic, computer and building products).
Finally, we recognise that, in many cases, it is
possible to transform parser representations into
our desired format. For example, if the parser out-
put tells us that a given verb form is a passive
participle, we can use this information to remap
the surface relations, thus retrieving the underlying
predicate-argument structure. However, we pre-
fer a system where this kind of post-processing
is not needed. Reasons for this include the in-
creased potential for error in a system relying on
post-processing rules, as well as the need to have
both detailed documentation for how each parser
output format handles particular constructions, as
well as a comprehensive mapping schema between
representations. Having a community standard for
GR-based parser output is an essential element of
future parsing technology, and to be practically
useful in a range of semantic interpretation tasks,
this standard should involve ‘deep’ syntactic dis-
tinctions of the kind discussed in this paper.
</bodyText>
<sectionHeader confidence="0.997292" genericHeader="acknowledgments">
9 Acknowledgements
</sectionHeader>
<bodyText confidence="0.995652">
The work reported here was supported by grants
N00014-08-1-0179 and N00014-08-1-0043 from
the Office of Naval Research.
</bodyText>
<page confidence="0.998065">
57
</page>
<sectionHeader confidence="0.996265" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999774927083334">
Allen, James, Myroslava Dzikovska, Mehdi Manshadi,
and Mary Swift. 2007. Deep linguistic processing
for spoken dialogue systems. In Proceedings of the
ACL’07 Workshop on Deep Linguistic Processing.
Bos, Johan and Tetsushi Oka. 2002. An inference-
based approach to dialogue system design. In Pro-
ceedings of COLING’02.
Bresnan, Joan. 2000. Lexical-Functional Syntax. Basil
Blackwell.
Briscoe, Ted, John Carroll, and Rebecca Watson. 2006.
The second release of the RASP system. In Pro-
ceedings of the COLING/ACL’06 Interactive Presen-
tation Sessions.
Callaway, Charles B., Myroslava Dzikovska, Elaine
Farrow, Manuel Marques-Pita, Colin Matheson, and
Johanna D. Moore. 2007. The Beetle and BeeDiff
tutoring systems. In Proceedings of SLaTE’07.
Chang, N., J. Feldman, R. Porzel, and K. Sanders.
2002. Scaling cognitive linguistics: Formalisms
for language understanding. In Proceedings of
ScaNaLU’02.
Chen, John and Owen Rambow. 2003. Use of deep
linguistic features for the recognition and labeling of
semantic arguments. In Proceedings of EMNLP’03.
Copestake, Ann, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Semantics:
An Introduction. Research on Language and Com-
putation, 3:281–332.
de Marneffe, Marie-Catherine, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of LREC’06.
Dzikovska, Myroslava O., Gwendolyn E. Campbell,
Charles B. Callaway, Natalie B. Steinhauser, Elaine
Farrow, Johanna D. Moore, Leslie A. Butler, and
Colin Matheson. 2008. Diagnosing natural lan-
guage answers to support adaptive tutoring. In Pro-
ceedings of FLAIRS’08 special track on Intelligent
Tutoring Systems.
Erk, Katrin and Sebastian Pad´o. 2006. SHAL-
MANESER - a toolchain for shallow semantic pars-
ing. In Proceedings of LREC’06.
Gildea, Daniel and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3).
Haegeman, Liliane. 1994. Introduction to Government
and Binding Theory. Basil Blackwell, 2nd edition
edition.
Hockenmaier, Julia and Mark Steedman. 2007. CCG-
bank: a corpus of CCG derivations and dependency
structures extracted from the Penn Treebank. Com-
putational Linguistics, 33(3).
Jordan, Pamela, Maxim Makatchev, Umarani Pap-
puswamy, Kurt VanLehn, and Patricia Albacete.
2006. A natural language tutorial dialogue system
for physics. In Proceedings of FLAIRS’06.
Kaisser, Michael and Bonnie Webber. 2007. Question
answering based on semantic roles. In Proceedings
of the ACL’07 Workshop on Deep Linguistic Pro-
cessing.
Kay, Martin, Jean Mark Gawron, and Peter Norvig.
1994. Verbmobil: A Translation System for Face-
To-Face Dialog. CSLI Press, Stanford, CA.
King, Tracy Holloway, Richard Crouch, Stefan Rie-
zler, Mary Dalrymple, and Ronald M. Kaplan. 2003.
The PARC 700 dependency bank. In Proceedings of
EACL’03.
Miyao, Yusuke. 2006. From Linguistic Theory to Syn-
tactic Analysis: Corpus-Oriented Grammar Devel-
opment and Feature Forest Model. Ph.D. thesis, Uni-
versity of Tokyo.
Ros´e, C. P., D. Bhembe, S. Siler, R. Srivastava, and
K. VanLehn. 2003. The role of why questions in ef-
fective human tutoring. In Proceedings of AIED’03.
Sag, Ivan A. and Thomas Wasow. 1999. Syntactic The-
ory: A Formal Introduction. CSLI.
Seneff, Stephanie. 1992. TINA: A natural language
system for spoken language applications. Computa-
tional Linguistics, 18(1).
Surdeanu, Mihai, Sanda M. Harabagiu, John Williams,
and Paul Aarseth. 2003. Using predicate-argument
structures for information extraction. In Proceedings
of ACL’03.
Wolska, Magdalena and Ivana Kruijff-Korbayov´a.
2003. Issues in the interpretation of input in mathe-
matical dialogs. In Duchier, Denys, editor, Prospects
and advances in the syntax/semantics interface.
Lorraine-Saarland Workshop Series proceedings.
Wolska, Magdalena and Ivana Kruijff-Korbayov´a.
2004. Analysis of mixed natural and symbolic lan-
guage input in mathematical dialogs. In Proceedings
of ACL’04.
Yeh, Peter Z., Bruce Porter, and Ken Barker. 2005.
Matching utterances to rich knowledge structures to
acquire a model of the speaker’s goal. In Proceed-
ings of K-CAP’05.
</reference>
<page confidence="0.999258">
58
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.325218">
<title confidence="0.993608">Deep’ Grammatical Relations for Semantic Interpretation</title>
<author confidence="0.959886">O McConville</author>
<affiliation confidence="0.753213">Institute for Communicating and Collaborative School of Informatics, University of Informatics Forum, 10 Crichton Street, Edinburgh, EH8 9AB,</affiliation>
<abstract confidence="0.990404533333333">In this paper, we evaluate five distinct systems of labelled grammatical dependency against the kind of input we require for semantic interpretation, in particular for the deep semantic interpreter underlying a tutorial dialogue system. We focus on the following linguistic phenomena: passive, control and raising, noun modifiers, and meaningful vs. non-meaningful prepositions. We conclude that no one system provides all the features that we require, although each such feature is contained within at least one of the competing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Myroslava Dzikovska</author>
<author>Mehdi Manshadi</author>
<author>Mary Swift</author>
</authors>
<title>Deep linguistic processing for spoken dialogue systems.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL’07 Workshop on Deep Linguistic Processing.</booktitle>
<contexts>
<context position="2171" citStr="Allen et al., 2007" startWordPosition="298" endWordPosition="301">can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality. While deep parsers produce precise semanti</context>
</contexts>
<marker>Allen, Dzikovska, Manshadi, Swift, 2007</marker>
<rawString>Allen, James, Myroslava Dzikovska, Mehdi Manshadi, and Mary Swift. 2007. Deep linguistic processing for spoken dialogue systems. In Proceedings of the ACL’07 Workshop on Deep Linguistic Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Tetsushi Oka</author>
</authors>
<title>An inferencebased approach to dialogue system design.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING’02.</booktitle>
<contexts>
<context position="8412" citStr="Bos and Oka (2002)" startWordPosition="1289" endWordPosition="1292">lations that can be converted into such semantic representations with minimal effort, thus minimising the number of specific rules used to convert individual relations. We discuss the principles underlying such representations in more detail in the next section. 1We used a simplified representation of quantifiers that assumes no scope ambiguity and uses skolem constants to represent existential quantification. This is sufficient for our particular application. In general, a more sophisticated quantifier representation would be necessary, for example that proposed in Copestake et al. (2005) or Bos and Oka (2002), but we leave the relevant evaluation for future work. 52 3 Deep grammatical relations We formulated four principles for deep grammatical relations representation. Firstly, grammatical relations should, whenever possible, reflect relations between the predicators (i.e. content words as opposed to function words) in a sentence. In addition, the same relation should correspond to the same role assignment. For example, the deep GRs in passive constructions should be the same as those in the active equivalents (see section 4), and the analysis of a control verb construction like John persuaded Ma</context>
</contexts>
<marker>Bos, Oka, 2002</marker>
<rawString>Bos, Johan and Tetsushi Oka. 2002. An inferencebased approach to dialogue system design. In Proceedings of COLING’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Lexical-Functional Syntax.</title>
<date>2000</date>
<publisher>Basil Blackwell.</publisher>
<contexts>
<context position="27663" citStr="Bresnan, 2000" startWordPosition="4463" endWordPosition="4465">posed here is meant to be ‘theoryneutral’, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others. Indeed, it should be a straightforward task to write a grammar using either the HPSG, LFG, CCG or RASP-style underlying formalism which can produce an output representation consisting of deep relations, constructed in a purely compositional manner. Indeed, the syntactic phenomena discussed in this paper are those which form the basis of numerous introductory textbooks on English generative syntax (Haegeman, 1994; Sag and Wasow, 1999; Bresnan, 2000). In addition, the phenomena which form the basis of the analysis in this paper were among those which had been the focus of a significant amount of attention in the development of the semantic interpretation system underlying our domain-independent tutorial dialogue system. Other issues which were considered, but for which we lack space to discuss in detail include: (a) expletive pronouns should be ignored, i.e. the subject pronouns in ‘impersonal’ verb constructions like It is raining or It’s great that John loves Mary should not be seen as the target of deep grammatical relations; (b) unbou</context>
</contexts>
<marker>Bresnan, 2000</marker>
<rawString>Bresnan, Joan. 2000. Lexical-Functional Syntax. Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL’06 Interactive Presentation Sessions.</booktitle>
<contexts>
<context position="13370" citStr="Briscoe et al., 2006" startWordPosition="2104" endWordPosition="2107">s (the columns), we provide the GR which goes from the participle to its deep object, 53 complement of complement of nominal nominal active passive auxiliary raising verb postmodifier premodifier HPSG ARG2 (of verb arg12) RASP ncsubj:obj dobj CCGBank Spss\NP N/N S\NP/[NP] Stanford nsubjpass - dobj PARC subj - obj Table 1: Representation of deep objects in passive and active if such a GR exists.3 The five GR representations compared are: HPSG predicate-argument structures extracted from the University of Tokyo HPSG Treebank (Miyao, 2006) RASP grammatical relations as output by the RASP parser (Briscoe et al., 2006) CCGBank predicate-argument dependencies extracted from CCGBank (Hockenmaier and Steedman, 2007) Stanford grammatical relations output by the Stanford Parser (de Marneffe et al., 2006) PARC dependency structures used in the annotation of DepBank (King et al., 2003) The first four columns in Table 1 represent, for each of the four uses of passive participles listed above, the grammatical relation, if any, which typically joins a passive participle to its deep object. The rightmost column presents the label used for this relation in equivalent active clauses. Adjacent columns have been collapsed</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Briscoe, Ted, John Carroll, and Rebecca Watson. 2006. The second release of the RASP system. In Proceedings of the COLING/ACL’06 Interactive Presentation Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>Myroslava Dzikovska</author>
<author>Elaine Farrow</author>
<author>Manuel Marques-Pita</author>
<author>Colin Matheson</author>
<author>Johanna D Moore</author>
</authors>
<title>The Beetle and BeeDiff tutoring systems.</title>
<date>2007</date>
<booktitle>In Proceedings of SLaTE’07.</booktitle>
<contexts>
<context position="2252" citStr="Callaway et al., 2007" startWordPosition="310" endWordPosition="313">and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality. While deep parsers produce precise semantic representations appropriate for such reasoning, they suffer from robustness pro</context>
</contexts>
<marker>Callaway, Dzikovska, Farrow, Marques-Pita, Matheson, Moore, 2007</marker>
<rawString>Callaway, Charles B., Myroslava Dzikovska, Elaine Farrow, Manuel Marques-Pita, Colin Matheson, and Johanna D. Moore. 2007. The Beetle and BeeDiff tutoring systems. In Proceedings of SLaTE’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chang</author>
<author>J Feldman</author>
<author>R Porzel</author>
<author>K Sanders</author>
</authors>
<title>Scaling cognitive linguistics: Formalisms for language understanding.</title>
<date>2002</date>
<booktitle>In Proceedings of ScaNaLU’02.</booktitle>
<contexts>
<context position="2120" citStr="Chang et al., 2002" startWordPosition="289" endWordPosition="292">Predicate-argument structure identified in this way can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and m</context>
</contexts>
<marker>Chang, Feldman, Porzel, Sanders, 2002</marker>
<rawString>Chang, N., J. Feldman, R. Porzel, and K. Sanders. 2002. Scaling cognitive linguistics: Formalisms for language understanding. In Proceedings of ScaNaLU’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
<author>Owen Rambow</author>
</authors>
<title>Use of deep linguistic features for the recognition and labeling of semantic arguments.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP’03.</booktitle>
<contexts>
<context position="26836" citStr="Chen and Rambow (2003)" startWordPosition="4330" endWordPosition="4333">rything we require for deep semantic processing, although each of the features/distinctions we included in our list of desiderata is provided by at least one system. Many of the deep syntactic phenomena discussed here are known issues for shallow semantic tasks like semantic role labelling. For example, passive constructions are a recognised source of noise in semantic role labelling systems (Gildea and Jurafsky, 2002), and resolving controlled subjects provides more data for training models of selectional restrictions, which are known to be useful features for role labelling. More generally, Chen and Rambow (2003) demonstrate that a focus on ‘deep’ syntactic features results in a more accurate stochastic semantic role labeller than using surface information alone. Note also that the deep grammatical role representation proposed here is meant to be ‘theoryneutral’, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others. Indeed, it should be a straightforward task to write a grammar using either the HPSG, LFG, CCG or RASP-style underlying formalism which can produce an output representation consisting of deep relations, constructed in a purel</context>
</contexts>
<marker>Chen, Rambow, 2003</marker>
<rawString>Chen, John and Owen Rambow. 2003. Use of deep linguistic features for the recognition and labeling of semantic arguments. In Proceedings of EMNLP’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal Recursion Semantics: An Introduction.</title>
<date>2005</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>3--281</pages>
<contexts>
<context position="8390" citStr="Copestake et al. (2005)" startWordPosition="1284" endWordPosition="1287">r to produce grammatical relations that can be converted into such semantic representations with minimal effort, thus minimising the number of specific rules used to convert individual relations. We discuss the principles underlying such representations in more detail in the next section. 1We used a simplified representation of quantifiers that assumes no scope ambiguity and uses skolem constants to represent existential quantification. This is sufficient for our particular application. In general, a more sophisticated quantifier representation would be necessary, for example that proposed in Copestake et al. (2005) or Bos and Oka (2002), but we leave the relevant evaluation for future work. 52 3 Deep grammatical relations We formulated four principles for deep grammatical relations representation. Firstly, grammatical relations should, whenever possible, reflect relations between the predicators (i.e. content words as opposed to function words) in a sentence. In addition, the same relation should correspond to the same role assignment. For example, the deep GRs in passive constructions should be the same as those in the active equivalents (see section 4), and the analysis of a control verb construction </context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Copestake, Ann, Dan Flickinger, Carl Pollard, and Ivan A. Sag. 2005. Minimal Recursion Semantics: An Introduction. Research on Language and Computation, 3:281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC’06.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>de Marneffe, Marie-Catherine, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myroslava O Dzikovska</author>
<author>Gwendolyn E Campbell</author>
<author>Charles B Callaway</author>
<author>Natalie B Steinhauser</author>
<author>Elaine Farrow</author>
<author>Johanna D Moore</author>
<author>Leslie A Butler</author>
<author>Colin Matheson</author>
</authors>
<title>Diagnosing natural language answers to support adaptive tutoring.</title>
<date>2008</date>
<booktitle>In Proceedings of FLAIRS’08 special track on Intelligent Tutoring Systems.</booktitle>
<contexts>
<context position="5975" citStr="Dzikovska et al., 2008" startWordPosition="905" endWordPosition="908">the objects they represent in the knowledge base, and first-order logic formulas representing utterance content need to be checked against the system knowledge. This task is similar to natural language interfaces to databases, or knowledge acquisition interfaces that convert language into knowledge base statements (Yeh et al., 2005). On the other hand, with respect to reason checking, human tutors have indicated that they would accept an answer simply if a student produces the key concepts and relations between them, even if the answer is not strictly logically equivalent to the ideal answer (Dzikovska et al., 2008). Human tutors tend to be especially lenient if a student is asked a generic question, like What is the definition of voltage?, which does not refer to specific objects in the knowledge base. Thus, a simpler matching mechanism is used to check the reasons, making this task more similar to an information retrieval task requiring shallower processing, i.e. that the predicate-argument relations are retrieved correctly (though negation still remains important). Thus, while a specific task is used to motivate our evaluation, the conclusions would be applicable to a variety of systems, including bot</context>
</contexts>
<marker>Dzikovska, Campbell, Callaway, Steinhauser, Farrow, Moore, Butler, Matheson, 2008</marker>
<rawString>Dzikovska, Myroslava O., Gwendolyn E. Campbell, Charles B. Callaway, Natalie B. Steinhauser, Elaine Farrow, Johanna D. Moore, Leslie A. Butler, and Colin Matheson. 2008. Diagnosing natural language answers to support adaptive tutoring. In Proceedings of FLAIRS’08 special track on Intelligent Tutoring Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>SHALMANESER - a toolchain for shallow semantic parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC’06.</booktitle>
<marker>Erk, Pad´o, 2006</marker>
<rawString>Erk, Katrin and Sebastian Pad´o. 2006. SHALMANESER - a toolchain for shallow semantic parsing. In Proceedings of LREC’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="1477" citStr="Gildea and Jurafsky, 2002" startWordPosition="205" endWordPosition="208">ms. 1 Introduction The aim of the work reported in this paper is to evaluate the extent to which proposed systems of grammatical relations (GRs) reflect the kinds of deep linguistic knowledge required for semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems. Grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (Gildea and Jurafsky, 2002; Erk and Pad´o, 2006). Predicate-argument structure identified in this way can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a smal</context>
<context position="26636" citStr="Gildea and Jurafsky, 2002" startWordPosition="4299" endWordPosition="4302">ation of prenominal modifiers i.e. passive, control and raising, noun modification, and meaningful vs. non-meaningful prepositions. We conclude that none of the proposed GR annotation schemes contains everything we require for deep semantic processing, although each of the features/distinctions we included in our list of desiderata is provided by at least one system. Many of the deep syntactic phenomena discussed here are known issues for shallow semantic tasks like semantic role labelling. For example, passive constructions are a recognised source of noise in semantic role labelling systems (Gildea and Jurafsky, 2002), and resolving controlled subjects provides more data for training models of selectional restrictions, which are known to be useful features for role labelling. More generally, Chen and Rambow (2003) demonstrate that a focus on ‘deep’ syntactic features results in a more accurate stochastic semantic role labeller than using surface information alone. Note also that the deep grammatical role representation proposed here is meant to be ‘theoryneutral’, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others. Indeed, it should be a st</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, Daniel and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liliane Haegeman</author>
</authors>
<title>Introduction to Government and Binding Theory. Basil Blackwell, 2nd edition edition.</title>
<date>1994</date>
<contexts>
<context position="27626" citStr="Haegeman, 1994" startWordPosition="4457" endWordPosition="4458">p grammatical role representation proposed here is meant to be ‘theoryneutral’, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others. Indeed, it should be a straightforward task to write a grammar using either the HPSG, LFG, CCG or RASP-style underlying formalism which can produce an output representation consisting of deep relations, constructed in a purely compositional manner. Indeed, the syntactic phenomena discussed in this paper are those which form the basis of numerous introductory textbooks on English generative syntax (Haegeman, 1994; Sag and Wasow, 1999; Bresnan, 2000). In addition, the phenomena which form the basis of the analysis in this paper were among those which had been the focus of a significant amount of attention in the development of the semantic interpretation system underlying our domain-independent tutorial dialogue system. Other issues which were considered, but for which we lack space to discuss in detail include: (a) expletive pronouns should be ignored, i.e. the subject pronouns in ‘impersonal’ verb constructions like It is raining or It’s great that John loves Mary should not be seen as the target of </context>
</contexts>
<marker>Haegeman, 1994</marker>
<rawString>Haegeman, Liliane. 1994. Introduction to Government and Binding Theory. Basil Blackwell, 2nd edition edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="13466" citStr="Hockenmaier and Steedman, 2007" startWordPosition="2115" endWordPosition="2118">53 complement of complement of nominal nominal active passive auxiliary raising verb postmodifier premodifier HPSG ARG2 (of verb arg12) RASP ncsubj:obj dobj CCGBank Spss\NP N/N S\NP/[NP] Stanford nsubjpass - dobj PARC subj - obj Table 1: Representation of deep objects in passive and active if such a GR exists.3 The five GR representations compared are: HPSG predicate-argument structures extracted from the University of Tokyo HPSG Treebank (Miyao, 2006) RASP grammatical relations as output by the RASP parser (Briscoe et al., 2006) CCGBank predicate-argument dependencies extracted from CCGBank (Hockenmaier and Steedman, 2007) Stanford grammatical relations output by the Stanford Parser (de Marneffe et al., 2006) PARC dependency structures used in the annotation of DepBank (King et al., 2003) The first four columns in Table 1 represent, for each of the four uses of passive participles listed above, the grammatical relation, if any, which typically joins a passive participle to its deep object. The rightmost column presents the label used for this relation in equivalent active clauses. Adjacent columns have been collapsed where the same GR is used for both uses. The ideal system would have the same GR listed in each</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Hockenmaier, Julia and Mark Steedman. 2007. CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics, 33(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Jordan</author>
<author>Maxim Makatchev</author>
<author>Umarani Pappuswamy</author>
<author>Kurt VanLehn</author>
<author>Patricia Albacete</author>
</authors>
<title>A natural language tutorial dialogue system for physics.</title>
<date>2006</date>
<booktitle>In Proceedings of FLAIRS’06.</booktitle>
<contexts>
<context position="2192" citStr="Jordan et al., 2006" startWordPosition="302" endWordPosition="305">tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality. While deep parsers produce precise semantic representations app</context>
</contexts>
<marker>Jordan, Makatchev, Pappuswamy, VanLehn, Albacete, 2006</marker>
<rawString>Jordan, Pamela, Maxim Makatchev, Umarani Pappuswamy, Kurt VanLehn, and Patricia Albacete. 2006. A natural language tutorial dialogue system for physics. In Proceedings of FLAIRS’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaisser</author>
<author>Bonnie Webber</author>
</authors>
<title>Question answering based on semantic roles.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL’07 Workshop on Deep Linguistic Processing.</booktitle>
<contexts>
<context position="1680" citStr="Kaisser and Webber, 2007" startWordPosition="235" endWordPosition="238">r semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems. Grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (Gildea and Jurafsky, 2002; Erk and Pad´o, 2006). Predicate-argument structure identified in this way can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike </context>
</contexts>
<marker>Kaisser, Webber, 2007</marker>
<rawString>Kaisser, Michael and Bonnie Webber. 2007. Question answering based on semantic roles. In Proceedings of the ACL’07 Workshop on Deep Linguistic Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
<author>Jean Mark Gawron</author>
<author>Peter Norvig</author>
</authors>
<title>Verbmobil: A Translation System for FaceTo-Face Dialog.</title>
<date>1994</date>
<publisher>CSLI Press,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="2271" citStr="Kay et al., 1994" startWordPosition="314" endWordPosition="317">(Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quantification, tense and modality. While deep parsers produce precise semantic representations appropriate for such reasoning, they suffer from robustness problems. Widecoverage</context>
</contexts>
<marker>Kay, Gawron, Norvig, 1994</marker>
<rawString>Kay, Martin, Jean Mark Gawron, and Peter Norvig. 1994. Verbmobil: A Translation System for FaceTo-Face Dialog. CSLI Press, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy Holloway King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The PARC 700 dependency bank.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL’03.</booktitle>
<contexts>
<context position="13635" citStr="King et al., 2003" startWordPosition="2142" endWordPosition="2145">[NP] Stanford nsubjpass - dobj PARC subj - obj Table 1: Representation of deep objects in passive and active if such a GR exists.3 The five GR representations compared are: HPSG predicate-argument structures extracted from the University of Tokyo HPSG Treebank (Miyao, 2006) RASP grammatical relations as output by the RASP parser (Briscoe et al., 2006) CCGBank predicate-argument dependencies extracted from CCGBank (Hockenmaier and Steedman, 2007) Stanford grammatical relations output by the Stanford Parser (de Marneffe et al., 2006) PARC dependency structures used in the annotation of DepBank (King et al., 2003) The first four columns in Table 1 represent, for each of the four uses of passive participles listed above, the grammatical relation, if any, which typically joins a passive participle to its deep object. The rightmost column presents the label used for this relation in equivalent active clauses. Adjacent columns have been collapsed where the same GR is used for both uses. The ideal system would have the same GR listed in each of the five columns. The grammatical relations used in the Stanford, PARC and RASP systems are atomic labels like subj, obj etc, although the latter system does allow f</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>King, Tracy Holloway, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald M. Kaplan. 2003. The PARC 700 dependency bank. In Proceedings of EACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
</authors>
<title>From Linguistic Theory to Syntactic Analysis: Corpus-Oriented Grammar Development and Feature Forest Model.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Tokyo.</institution>
<contexts>
<context position="13291" citStr="Miyao, 2006" startWordPosition="2093" endWordPosition="2094">sentation format (the rows) and each usage class of passive participles (the columns), we provide the GR which goes from the participle to its deep object, 53 complement of complement of nominal nominal active passive auxiliary raising verb postmodifier premodifier HPSG ARG2 (of verb arg12) RASP ncsubj:obj dobj CCGBank Spss\NP N/N S\NP/[NP] Stanford nsubjpass - dobj PARC subj - obj Table 1: Representation of deep objects in passive and active if such a GR exists.3 The five GR representations compared are: HPSG predicate-argument structures extracted from the University of Tokyo HPSG Treebank (Miyao, 2006) RASP grammatical relations as output by the RASP parser (Briscoe et al., 2006) CCGBank predicate-argument dependencies extracted from CCGBank (Hockenmaier and Steedman, 2007) Stanford grammatical relations output by the Stanford Parser (de Marneffe et al., 2006) PARC dependency structures used in the annotation of DepBank (King et al., 2003) The first four columns in Table 1 represent, for each of the four uses of passive participles listed above, the grammatical relation, if any, which typically joins a passive participle to its deep object. The rightmost column presents the label used for t</context>
</contexts>
<marker>Miyao, 2006</marker>
<rawString>Miyao, Yusuke. 2006. From Linguistic Theory to Syntactic Analysis: Corpus-Oriented Grammar Development and Feature Forest Model. Ph.D. thesis, University of Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C P Ros´e</author>
<author>D Bhembe</author>
<author>S Siler</author>
<author>R Srivastava</author>
<author>K VanLehn</author>
</authors>
<title>The role of why questions in effective human tutoring.</title>
<date>2003</date>
<booktitle>In Proceedings of AIED’03.</booktitle>
<marker>Ros´e, Bhembe, Siler, Srivastava, VanLehn, 2003</marker>
<rawString>Ros´e, C. P., D. Bhembe, S. Siler, R. Srivastava, and K. VanLehn. 2003. The role of why questions in effective human tutoring. In Proceedings of AIED’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Thomas Wasow</author>
</authors>
<title>Syntactic Theory: A Formal Introduction.</title>
<date>1999</date>
<publisher>CSLI.</publisher>
<contexts>
<context position="27647" citStr="Sag and Wasow, 1999" startWordPosition="4459" endWordPosition="4462">le representation proposed here is meant to be ‘theoryneutral’, in the sense that it was not influenced by any one of the competing grammar formalisms to the exclusion of the others. Indeed, it should be a straightforward task to write a grammar using either the HPSG, LFG, CCG or RASP-style underlying formalism which can produce an output representation consisting of deep relations, constructed in a purely compositional manner. Indeed, the syntactic phenomena discussed in this paper are those which form the basis of numerous introductory textbooks on English generative syntax (Haegeman, 1994; Sag and Wasow, 1999; Bresnan, 2000). In addition, the phenomena which form the basis of the analysis in this paper were among those which had been the focus of a significant amount of attention in the development of the semantic interpretation system underlying our domain-independent tutorial dialogue system. Other issues which were considered, but for which we lack space to discuss in detail include: (a) expletive pronouns should be ignored, i.e. the subject pronouns in ‘impersonal’ verb constructions like It is raining or It’s great that John loves Mary should not be seen as the target of deep grammatical rela</context>
</contexts>
<marker>Sag, Wasow, 1999</marker>
<rawString>Sag, Ivan A. and Thomas Wasow. 1999. Syntactic Theory: A Formal Introduction. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: A natural language system for spoken language applications.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="2099" citStr="Seneff, 1992" startWordPosition="287" endWordPosition="288">Pad´o, 2006). Predicate-argument structure identified in this way can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003; Callaway et al., 2007; Kay et al., 1994). Unlike in information retrieval and question answering tasks, the system often needs to be connected to a knowledge base which represents the state of the world, and must be able to convert user utterances into knowledge base queries. In addition to identifying predicateargument relationships, such systems need to support a variety of tasks, for example resolution of pronouns and anaphors, and interpreting negation, quanti</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Seneff, Stephanie. 1992. TINA: A natural language system for spoken language applications. Computational Linguistics, 18(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda M Harabagiu</author>
<author>John Williams</author>
<author>Paul Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL’03.</booktitle>
<contexts>
<context position="1630" citStr="Surdeanu et al., 2003" startWordPosition="228" endWordPosition="231"> kinds of deep linguistic knowledge required for semantic interpretation, in particular for deriving semantic representations suitable for domain reasoning in dialogue systems. Grammatical relations either produced by or extracted from the output of wide-coverage syntactic parsers are currently used as input to shallow semantic parsers, which identify semantic relations that exist between predicators (typically verbs) and their dependents (Gildea and Jurafsky, 2002; Erk and Pad´o, 2006). Predicate-argument structure identified in this way can then be used in tasks like information extraction (Surdeanu et al., 2003) and question answering (Kaisser and Webber, 2007). © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. However, wide-coverage stochastic parsers are only rarely used in dialogue systems. Traditionally, interpretation modules of dialogue systems utilise specialised parsers and semantic interpreters handcrafted to a small domain (Seneff, 1992; Chang et al., 2002), or wide coverage deep parsers (Allen et al., 2007; Jordan et al., 2006; Wolska and Kruijff-Korbayov´a, 2003;</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Surdeanu, Mihai, Sanda M. Harabagiu, John Williams, and Paul Aarseth. 2003. Using predicate-argument structures for information extraction. In Proceedings of ACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magdalena Wolska</author>
<author>Ivana Kruijff-Korbayov´a</author>
</authors>
<title>Issues in the interpretation of input in mathematical dialogs.</title>
<date>2003</date>
<booktitle>Prospects and advances in the syntax/semantics interface. Lorraine-Saarland Workshop Series proceedings.</booktitle>
<editor>In Duchier, Denys, editor,</editor>
<marker>Wolska, Kruijff-Korbayov´a, 2003</marker>
<rawString>Wolska, Magdalena and Ivana Kruijff-Korbayov´a. 2003. Issues in the interpretation of input in mathematical dialogs. In Duchier, Denys, editor, Prospects and advances in the syntax/semantics interface. Lorraine-Saarland Workshop Series proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magdalena Wolska</author>
<author>Ivana Kruijff-Korbayov´a</author>
</authors>
<title>Analysis of mixed natural and symbolic language input in mathematical dialogs.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL’04.</booktitle>
<marker>Wolska, Kruijff-Korbayov´a, 2004</marker>
<rawString>Wolska, Magdalena and Ivana Kruijff-Korbayov´a. 2004. Analysis of mixed natural and symbolic language input in mathematical dialogs. In Proceedings of ACL’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Z Yeh</author>
<author>Bruce Porter</author>
<author>Ken Barker</author>
</authors>
<title>Matching utterances to rich knowledge structures to acquire a model of the speaker’s goal.</title>
<date>2005</date>
<booktitle>In Proceedings of K-CAP’05.</booktitle>
<contexts>
<context position="5686" citStr="Yeh et al., 2005" startWordPosition="856" endWordPosition="859">lb to be lit. This task is particularly interesting because it combines characteristics of deep and shallow interpretation tasks. On the one hand, the fact-checking mechanism requires a connection to the database. Thus, both pronouns and definite noun phrases need to be resolved to the objects they represent in the knowledge base, and first-order logic formulas representing utterance content need to be checked against the system knowledge. This task is similar to natural language interfaces to databases, or knowledge acquisition interfaces that convert language into knowledge base statements (Yeh et al., 2005). On the other hand, with respect to reason checking, human tutors have indicated that they would accept an answer simply if a student produces the key concepts and relations between them, even if the answer is not strictly logically equivalent to the ideal answer (Dzikovska et al., 2008). Human tutors tend to be especially lenient if a student is asked a generic question, like What is the definition of voltage?, which does not refer to specific objects in the knowledge base. Thus, a simpler matching mechanism is used to check the reasons, making this task more similar to an information retrie</context>
</contexts>
<marker>Yeh, Porter, Barker, 2005</marker>
<rawString>Yeh, Peter Z., Bruce Porter, and Ken Barker. 2005. Matching utterances to rich knowledge structures to acquire a model of the speaker’s goal. In Proceedings of K-CAP’05.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>