<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000169">
<title confidence="0.998264">
ECNU: A Combination Method and Multiple Features for Aspect
Extraction and Sentiment Polarity Classification
</title>
<author confidence="0.998556">
Fangxi Zhang, Zhihua Zhang, Man Lan*
</author>
<affiliation confidence="0.950116">
Department of Computer Science and Technology
East China Normal University
</affiliation>
<email confidence="0.996153">
51111201041,51131201039@ecnu.cn; mlan@cs.ecnu.edu.cn*
</email>
<sectionHeader confidence="0.993801" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912882352941">
This paper reports our submissions to the
four subtasks of Aspect Based Sentimen-
t Analysis (ABSA) task (i.e., task 4) in
SemEval 2014 including aspect term ex-
traction and aspect sentiment polarity clas-
sification (Aspect-level tasks), aspect cat-
egory detection and aspect category sen-
timent polarity classification (Category-
level tasks). For aspect term extraction, we
present three methods, i.e., noun phrase
(NP) extraction, Named Entity Recogni-
tion (NER) and a combination of NP and
NER method. For aspect sentiment classi-
fication, we extracted several features, i.e.,
topic features, sentiment lexicon features,
and adopted a Maximum Entropy classifi-
er. Our submissions rank above average.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.962276406779661">
Recently, sentiment analysis has attracted a lot of
attention from researchers. Most previous work
attempted to detect overall sentiment polarity on a
text span, such as document, paragraph and sen-
tence. Since sentiments expressed in text always
adhere to objects, it is much meaningful to iden-
tify the sentiment target and its orientation, which
helps user gain precise sentiment insights on spe-
cific sentiment target.
The aspect based sentiment analysis (ABSA)
task (Task 4) (Pontiki et al., 2014) in SemEval
2014 is to extract aspect terms, determine its se-
mantic category, and then to detect the sentimen-
t orientation of the extracted aspect terms and its
category. Specifically, it consists of 4 subtasks.
The aspect term extraction (ATE) aims to extrac-
t the aspect terms from the sentences in two giv-
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
en domains (laptop and restaurant). The aspec-
t category detection (ACD) is to identify the se-
mantic category of aspects in a predefined set of
aspect categories (e.g., food, price). The aspect
term polarity (ATP) classification is to determine
whether the sentiment polarity of each aspect is
positive, negative, neutral or conflict (i.e., both
positive and negative). The aspect category po-
larity (ACP) classification is to determine the sen-
timent polarity of each aspect category. We partic-
ipated in these four subtasks.
Generally, there are three methods to extract as-
pect terms: unsupervised learning method based
on word frequency ((Ku et al., 2006), (Long et
al., 2010)), supervised machine learning method
(Kovelamudi et al., 2011) and semi-supervised
learning method (Mukherjee and Liu, 2012) where
only several user interested category seeds are
given and used to extract more categorize aspect
terms. Since sentiments always adhere to entities,
several researchers worked on polarity classifica-
tion of entity. For example, (Godbole et al., 2007)
proposed a system that assigned scores represent-
ing positive or negative opinion to each distinc-
t entity in the corpus. (Kim et al., 2013) presented
a hierarchical aspect sentiment model to classify
the polarity of aspect terms from unlabeled online
reviews. Moreover, some sentiment lexicons, such
as SentiWordNet (Baccianella et al., 2010) and M-
PQA Subjectivity Lexicon (Wilson et al., 2009),
have been used to generate sentiment score fea-
tures (Zhu et al., 2013).
The rest of this paper is organized as follows.
From Section 2 to Section 5, we describe our ap-
proaches to the Aspect Term Extraction task, the
Aspect Category detection task, the Aspect Term
Polarity task and the Aspect Category Polarity task
respectively. Section 6 provides the conclusion.
</bodyText>
<page confidence="0.966035">
252
</page>
<note confidence="0.822977">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 252–258,
Dublin, Ireland, August 23-24, 2014.
</note>
<sectionHeader confidence="0.892439" genericHeader="introduction">
2 Aspect Term Extraction System
</sectionHeader>
<bodyText confidence="0.999919916666667">
For aspect terms extraction task, we first adopted
two methods: a noun phrase (NP) based method
and a Named Entity Recognition (NER) based
method. In our preliminary experiments, we found
that the NP-based method generates many noisy
terms resulting in high recall and low precision,
and the NER-based method performs inverse re-
sults. In order to overcome their drawbacks and
make use of their advantages, we proposed a third
method which combines the two methods by using
the results of NP-based method as an additional
name list feature to the NER system.
</bodyText>
<subsectionHeader confidence="0.988023">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.9996425">
We used Stanford Parser Tools1 for POS tagging
and for parsing while the Natural Language Toolk-
it2 was used for removing stop words and lemma-
tization.
</bodyText>
<subsectionHeader confidence="0.977414">
2.2 NP-based Method
</subsectionHeader>
<bodyText confidence="0.9999343">
(Liu, 2012) showed that the majority of aspec-
t terms are noun phrases. Moreover, through the
observation of the training set, we found that more
than half of the aspects are pure noun phrases or
nested noun phrases. So we considered these two
types of noun phrases as aspect terms and adopt-
ed a rule-based noun phrases extraction system to
perform aspect term extraction. This extraction
is performed on parsed sentences. For example,
from parsed sentence:
</bodyText>
<equation confidence="0.95156775">
“(CC but)
(S
(NP (NN iwork))
(VP (VBZ is)
(ADJP (JJ cheap))
(PP (VBN compared)
(PP (TO to)
(NP (NN office))))))”
</equation>
<bodyText confidence="0.9999296">
iwork and office with NN tag are extracted as as-
pect terms. However, to make a more precise ex-
traction, we first removed white lines from parsed
sentences. Then we performed extraction only us-
ing three continuous lines. Since the NPs we ex-
tracted contain much noise which only appear in
NPs rather than in gold aspect terms list, we built
a stopwords list containing these noisy terms espe-
cially the numeric expressions. Table 1 shows the
set of manually built rules used for NP extraction.
</bodyText>
<footnote confidence="0.9998815">
1http://nlp.stanford.edu/software/lex-parser.shtml
2http://www.nltk.org/
</footnote>
<bodyText confidence="0.999607125">
Based on the experimental results on training
data, we found the NP-based method achieves
high recall and low precision as shown in Table
2. This indicates that we extracted plenty of NPs
which consist of a large proportion of aspect terms
and much noise such as irrelevant NPs and over-
lapping phrases. Thus the NP-based method alone
has not produced good results.
</bodyText>
<subsectionHeader confidence="0.990535">
2.3 NER-based Method
</subsectionHeader>
<bodyText confidence="0.99964493939394">
We also cast aspect term extraction task as a tradi-
tional NER task (Liu, 2012). We adopted the com-
monly used BIO tag format to represent the aspect
terms in the given annotated training data (Toh et
al., 2012), where B indicates the beginning of an
aspect term, I indicates the inside of an aspect ter-
m and O indicates the outside of an aspect term.
For example, given ”the battery life is excellent”,
where battery life is annotated as aspect term, we
tagged the three words the, is and excellent as O,
battery as B and life as I.
We adopted several widely used features for the
NER-based aspect term extraction system.
Word features: current word (word 0), previ-
ous word (word -1) and next word (word 1) are
used as word features.
POS feature: the POS tag of current word
(POS 0), the POS tags of two words around cur-
rent word (POS -2, POS -1, POS 1, POS 2), and
the combinations of contextual POS tags (POS -
1/POS 0, POS 0/POS 1, POS -1/POS 0/POS 1)
are included as POS features.
Word shape: a tag sequence of characters in
current word is recorded, i.e., the lowercase letter
tagged as a, and the uppercase letter tagged as A.
Chunk: We extracted this feature from the POS
tag sequence, which is defined as follows: the
shortest phrase based on POS taggers, i.e., “(VP
(VBD took) (NP (NN way)) (ADVP (RB too) (RB
long))”, took labeled as O, way labeled as B-NP,
too labeled as B-ADVP, long labeled as I-ADVP.
We implemented a CRF++ 3 based NER system
with the above feature types.
</bodyText>
<subsectionHeader confidence="0.999841">
2.4 Combination of NP and NER Method
</subsectionHeader>
<bodyText confidence="0.999953">
Based on our preliminary experiments, we con-
sidered to combine the above two methods. To
do so, we adopted the results of the NP system
as additional name lists feature for the NER sys-
tem. Through the observation on the results of the
</bodyText>
<footnote confidence="0.927955">
3http://crfpp.googlecode.com/svn/trunk/doc/index.html
</footnote>
<page confidence="0.99379">
253
</page>
<construct confidence="0.998607454545455">
if (NP in line 1) then select line 1 as candidate
if (NP in line 1 and PP in line 2 and NP in line 3) then select line 1 + line 2 + line 3 as candidate
else if (VB in line 1 and NN in line 2) then select line 1 + line 2 as candidate
else if (NP in line 1 and NP in line 2) then select line 1 + line 2 as candidate
else if (NP in line 1 and CC in line 2 and NN in line 3) then select line 3 as candidate
else if (JJ in line 1 and NN in line 2) then select line 2 as candidate
if (current term in candidate existing in stopwords) then remove current term
if (CD start candidate) then remove CD
if (DT or PRP start candidate) then remove DT or PRP
if (JJR in candidate) then remove JJR
if (Punctuation in candidate) then remove Punctuation
</construct>
<tableCaption confidence="0.999481">
Table 1: The rules in NP-based method.
</tableCaption>
<table confidence="0.9994264">
method Laptop Restaurant
Precision(%) Recall(%) F-score(%) Precision(%) Recall(%) F-score(%)
NP-based 44.35 74.43 55.59 45.99 70.50 56.17
NER-based 70.46 48.27 57.29 80.87 68.24 74.02
Combination 72.79 55.11 62.73 82.31 70.62 76.02
</table>
<tableCaption confidence="0.999469">
Table 2: The F-scores of three methods on training data.
</tableCaption>
<bodyText confidence="0.997627357142857">
NP-based method and the NER-based method, we
built two types of name lists for our combination
method as follows:
Gold Namelist: containing the gold aspec-
t terms and the intersection between the results of
the NP-based method and the NER-based method.
Stop Namelist: the words in original sentences
but not in gold aspect terms set or not in NPs set
we extracted before.
Table 3 shows the results of feature selection
for the combination method on training data. The
best performance was obtained by using all fea-
tures. Thus, our final submission system adopted
the combination method with all features.
</bodyText>
<table confidence="0.992653058823529">
Feature Dataset
Laptop Restaurant
word:
+word 0 40.35 58.58
+word 1 54.78 72.23
POS:
+POS 0 55.81 71.11
+POS 1 57.07 74.02
+POS 2 57.18 73.24
+POS 0/POS 1 51.85 70.58
chunk:
+chunk 0 56.74 73.45
word shape:
+word shape 0 57.29 74.02
name list:
+Gold Namelist 62.66 75.39
+Stop Namelist 62.73 76.02
</table>
<tableCaption confidence="0.997575">
Table 3: The F-scores of combination method
</tableCaption>
<bodyText confidence="0.84077475">
of subtask 1 on training data based on 2 cross-
validation
Table 2 shows the results of the above three
systems on training data. Comparing with oth-
er two methods, we easily find that the combina-
tion method outperforms the other two systems in
terms of precision, recall and F values on both do-
mains.
</bodyText>
<subsectionHeader confidence="0.925873">
2.5 Result and Discussion
</subsectionHeader>
<bodyText confidence="0.999975277777778">
In constrained run, we submitted the results us-
ing the method in combination of NP and NER.
Specifically, we adopted all features and the name
lists listed in Table 3 and the CRF++ tool for the
NER system. Table 4 lists the results of our fi-
nal system and the top two systems officially re-
leased by organizers. On both domains, our sys-
tem ranks above the average under constrained
model, which proves the effectiveness of the com-
bination method by using NP extraction and NER.
From Table 2 and Table 4 we find that the re-
sults on restaurant data are much better than those
on laptop data. Based on our further observation
on training data, the possible reason is that the
number of numeric descriptions in laptop dataset
is much larger than those in restaurant dataset and
the aspect terms containing numeric description
are quite difficult to be extracted.
</bodyText>
<table confidence="0.967806666666667">
Dataset DLIREC NRC-Canada Our result
laptop 70.41 68.57 65.88
restaurant 78.34 80.19 78.24
</table>
<tableCaption confidence="0.972564">
Table 4: The F-scores (%) of our system and the
top two systems of subtask 1 on test dataset.
</tableCaption>
<page confidence="0.997225">
254
</page>
<sectionHeader confidence="0.990376" genericHeader="method">
3 Aspect Category Classification System
</sectionHeader>
<bodyText confidence="0.999463833333333">
Aspect category classification task tries to assign
each aspect one or more semantic category labels.
Thus, we regarded this task as a multi-class clas-
sification problem. Following (Rennie, 2001), we
built a binary model for each category, where bag-
of-words is used as features.
</bodyText>
<subsectionHeader confidence="0.948245">
3.1 Features
</subsectionHeader>
<bodyText confidence="0.9999985">
We adopted the bag-of-words schema to represent
features as follows. Since not all training instances
have annotated aspect terms, we extracted only an-
notated aspect terms from sentence if the sentence
contains annotated aspect terms, or extracted all
words from sentence which does not contain any
annotated aspect terms as features, which results
in 5200 word features in total.
</bodyText>
<subsectionHeader confidence="0.997162">
3.2 Classification Algorithm
</subsectionHeader>
<bodyText confidence="0.9999745">
We adopted the maximum entropy algorithm im-
plemented in Mallet toolkit (McCallum, 2002) to
build a binary classifier for each category. All pa-
rameters are set as defaults. This subtask only pro-
vides restaurant data and there are five predefined
categories (i.e., food, price, service, ambience and
anecdotes/miscellaneous), thus we build five bina-
ry classifiers in total.
</bodyText>
<subsectionHeader confidence="0.873779">
3.3 Results and Discussions
</subsectionHeader>
<bodyText confidence="0.990371333333333">
Table 5 lists the precision, recall and F-score of
our final system along with the top two systems
released by the organizers.
</bodyText>
<table confidence="0.9988955">
Precision(%) Recall(%) F-score(%)
our system 65.26 69.46 67.30
rank 1 system 91.04 86.24 88.58
rank 2 system 83.23 81.37 82.29
</table>
<tableCaption confidence="0.8948795">
Table 5: The results of our system and the top two
systems of subtask 3 on the test data.
</tableCaption>
<bodyText confidence="0.999884615384615">
From Table 5, we find that there are quite a large
room to improve our system. One main reason
is that our system only uses simple features (i.e.,
bag-of-words) and these simple features may have
poor discriminating power. Another possible rea-
son may be that in training data there are at least
half sentences without annotated aspect terms. In
this case, when we used all words in the sentences
as features, it may bring much noise. In future
work, we consider to generate more effective fea-
tures from external resources to indicate the re-
lationships between aspects and categories to im-
prove our system.
</bodyText>
<sectionHeader confidence="0.875783" genericHeader="method">
4 Aspect Term Sentiment Polarity
Classification System
</sectionHeader>
<bodyText confidence="0.999488875">
Once we extract aspect terms, this task aims at
classifying the sentiment orientation of the anno-
tated aspect terms. To address this task, we firstly
extracted three types of features: sentiment lexi-
con based features, topic model based features and
other features. Then two machine learning algo-
rithms, i.e., SVM and MaxEnt, were used to con-
duct classification models.
</bodyText>
<sectionHeader confidence="0.504014" genericHeader="method">
4.1 Features
</sectionHeader>
<subsectionHeader confidence="0.701017">
4.1.1 Sentiment Lexicon (SL) Features
</subsectionHeader>
<bodyText confidence="0.999746">
We observed that the sentiment orientation of an
aspect term is usually revealed by the surrounding
terms. So in this feature we took four words before
and four words after the current aspect term and
then calculated their respective positive,negative
and neutral scores. During the calculation we re-
versed the sentiment orientation of the term if a
negation occurs before it. We manually built a
negative list: {no, nor, not, neither, none, no-
body, nothing, hardly, seldom}. Eight sentimen-
t lexicons are used: Bing Liu opinion lexicon4,
General Inquirer lexicons, IMDB6, MPQA7, Sen-
tiWordNet8, NRC emotion lexicon9, NRC Hash-
tag Sentiment Lexicon10 and NRC Sentiment140
Lexicon11. With regard to the synonym selection
of SentiWordNet, we selected the first term in the
synset as our lexicon. If the eight words surround-
ing the aspect term do not exist in the eight cor-
responding sentiment lexicons, we set their three
sentiment scores as 0. Then we got 24 sentimen-
t values for each word (3 polarities * 8 lexicons)
and summed up the values of eight words for each
sentiment polarity (i.e., positive, negative and neu-
ral). Finally we got 24 sentiment lexicon features
for each aspect.
</bodyText>
<footnote confidence="0.983232583333333">
4http://www.cs.uic.edu/˜liub/FBS/sentiment-
analysis.html#lexicon
5http://www.wjh.harvard.edu/˜inquirer/homecat.htm
6http://anthology.aclweb.org//S/S13/S13-
2.pdf#page=444
7http://mpqa.cs.pitt.edu/
8http://sentiwordnet.isti.cnr.it/
9http://mailman.uib.no/public/corpora/2012-
June/015643.html
10http://www.umiacs.umd.edu/˜saif/WebDocs/NRC-
Hashtag-Sentiment-Lexicon-v0.1.zip
11http://sentiwordnet.isti.cnr.it/
</footnote>
<page confidence="0.992536">
255
</page>
<table confidence="0.9998662">
feature F-pos(%) F-neg(%) F-neu(%) Acc(%)
MaxEnt SVM MaxEnt SVM MaxEnt SVM MaxEnt SVM
SL 72.50± 1.91 70.99± 5.91 65.10± 1.99 65.66± 3.48 25.54± 5.68 24.02± 9.28 62.28± 2.59 61.61± 4.68
+Other 72.92± 2.12 72.70± 1.44 65.93± 3.89 65.09± 3.67 31.14± 5.77 34.00± 7.31 62.88± 3.22 62.54± 3.17
+Topic 73.14± 1.02 72.21± 1.44 65.55± 5.43 65.58± 3.45 34.34± 10.55 12.16± 4.96 63.00± 4.34 61.74± 3.10
</table>
<tableCaption confidence="0.975453">
Table 6: The results of our system in subtask 2 on laptop training data based on 5-fold cross validation.
</tableCaption>
<table confidence="0.9998754">
features F-pos(%) F-neg(%) F-neu(%) Acc(%)
MaxEnt SVM MaxEnt SVM MaxEnt SVM MaxEnt SVM
SL 79.78± 1.37 79.85± 1.35 49.37± 3.54 47.96± 4.52 26.02± 3.62 31.67± 2.84 65.61± 2.59 65.45± 1.98
+Other 80.48± 2.18 79.09± 1.42 53.17± 2.70 50.51± 3.34 29.25± 3.60 33.13± 6.89 66.80± 2.33 65.21± 2.35
+Topic 80.71± 1.71 77.94± 1.34 52.61± 2.52 46.65± 3.17 34.51± 3.35 3.40± 2.79 67.18± 2.52 64.72± 1.48
</table>
<tableCaption confidence="0.9761655">
Table 7: The results of our system in subtask 2 on restaurant training data based on 5-fold cross valida-
tion.
</tableCaption>
<subsubsectionHeader confidence="0.815932">
4.1.2 Topic Features
</subsubsectionHeader>
<bodyText confidence="0.999923555555556">
In this section we considered to use the bag-of-
topics feature to replace the traditional bag-of-
words feature since the bag-of-words feature are
very sparse in the data set. To construct the cluster-
s of topics, we used the LDA12 based topic model
to estimate the K topics (in our experiment, we
set K to 50) from training data. Then we inferred
the topic distribution from training and test data
respectively as topic features.
</bodyText>
<subsectionHeader confidence="0.700496">
4.1.3 Other Features
</subsectionHeader>
<bodyText confidence="0.992758833333333">
Besides, we also proposed the following other fea-
tures in order to capture more useful information
from the short texts.
Aspect distance This feature records the num-
ber of words from the current aspect to the next
aspect in the same sentence. If the current aspect
term is the last term in the sentence, this value is
calculated as the negative number of words from
the current aspect to the former aspect. If only one
aspect term exists in a sentence, then the value is
set to zero.
Number of aspects This feature describes the
number of aspect terms in the current sentence.
Negation flag feature We set this feature as 1
if a negation word occurs in the current sentence,
otherwise -1.
Number of negations This feature is the num-
ber of negation words in the current sentence.
</bodyText>
<subsectionHeader confidence="0.994468">
4.2 Classification Algorithms
</subsectionHeader>
<bodyText confidence="0.944997">
The maximum entropy and SVM which are imple-
mented in Mallet toolkit (McCallum, 2002) and
LibSVM (Chang and Lin, 2011) respectively are
</bodyText>
<footnote confidence="0.898129">
12http://www.cs.princeton.edu/ blei/lda-c/
</footnote>
<bodyText confidence="0.949853333333333">
used to construct the classification model from
training data. Due to the limit of time, all parame-
ters are set as defaults.
</bodyText>
<subsectionHeader confidence="0.570952">
4.3 Results and Discussions
4.3.1 Results on Training Data
</subsectionHeader>
<bodyText confidence="0.999908833333333">
To compare the performance of different features
and different algorithms, we performed a 5-fold
cross validation on training data of two domain-
s. Table 6 and Table 7 show the results of two
domains in terms of F-scores and accuracy with
mean and standard deviation. The best results are
shown in bold.
From above two tables, we found that (1) Max-
Ent performed better than SVM on both dataset-
s and all feature types, and (2) using all features
achieved the best results. Moreover, the F-pos re-
sult was the highest in both datasets and the pos-
sible reason is that the majority of training in-
stances are positive sentiment. We also found that
in restaurant dataset, F-neg (52.61%) was much
smaller than F-pos (80.17%). However, in lap-
top dataset, they performed comparable results.
The possible reason is that the number of neg-
ative instances (805) is much smaller than the
number of positive instances (2164) in restauran-
t dataset, while the distribution is nearly even in
laptop dataset. So for restaurant data, we also con-
ducted another controlled experiment which dou-
bled the amount of negative instances of restaurant
dataset. Table 8 shows the preliminary experimen-
tal results on the doubled negative training data. It
illustrates that the F-neg increases a little but the
overall accuracy without any improvement even
slightly decreases after doubling the negative in-
stances. This result is beyond our expectation but
</bodyText>
<page confidence="0.995276">
256
</page>
<bodyText confidence="0.588416">
no further deep analysis has been done so far.
</bodyText>
<table confidence="0.998303333333333">
Strategy F-pos(%) F-neg(%) F-neu(%) Acc(%)
Double 80.28 55.11 19.22 65.48
No double 80.71 52.61 34.51 67.18
</table>
<tableCaption confidence="0.9661385">
Table 8: The results of controlled experiment on
restaurant dataset (MaxEnt).
</tableCaption>
<subsectionHeader confidence="0.578918">
4.3.2 Results on Test Data
</subsectionHeader>
<bodyText confidence="0.998373428571429">
Based on above results on training data, our final
system used all provided training data for both do-
mains. The MaxEnt algorithm is used for our final
system. Table 9 shows our results alone with the
top two systems results released by organizers.
Our final results ranked the 12th on the lap-
top dataset and the 14th on the restaurant dataset.
On one hand, the accuracy in restaurant dataset is
higher than laptop dataset for the possible reason
that the data size of restaurant dataset is much big-
ger than that of laptop dataset. On the other hand,
our results ranked middle in both datasets. Since
we utilized eight contextual words around aspect
to extract features and it may bring some noise.
</bodyText>
<table confidence="0.9020995">
Dataset laptop restaurant
our system 61.16 70.72
rank 1 system 70.49 80.95
rank 2 system 66.97 80.16
</table>
<tableCaption confidence="0.8959345">
Table 9: The Accuracy (%) of our system and the
top two systems on test dataset in subtask 2.
</tableCaption>
<sectionHeader confidence="0.9833675" genericHeader="method">
5 Aspect Category Sentiment Polarity
System
</sectionHeader>
<bodyText confidence="0.999938857142857">
The aspect category sentiment polarity classifi-
cation task is also only applicable to restauran-
t domain. For this task, we adopted the bag-
of-sentiment words representation, extracted sen-
timent features and used the supervised machine
learning algorithms to determine the sentimen-
t orientation of each category.
</bodyText>
<subsectionHeader confidence="0.526441">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.99994475">
To extract features, we firstly used eight sentiment
lexicons mentioned in Section 4.1.1 to build a big
sentiment words dictionary. Then we extracted al-
l aspect words and all sentiment words in train-
ing set as features. In the training and test data,
we used the sentiment polarity score of sentiment
word and the presence or absence of each aspect
term as their feature values.
</bodyText>
<subsectionHeader confidence="0.995472">
5.2 Classification Algorithms
</subsectionHeader>
<bodyText confidence="0.999174666666667">
The MaxEnt algorithm implemented in Mallet (M-
cCallum, 2002) with default parameters is used to
build a polarity classifier.
</bodyText>
<subsectionHeader confidence="0.988475">
5.3 Experiment and Results
</subsectionHeader>
<bodyText confidence="0.999907555555556">
We used all features and the maximum entropy al-
gorithm to conduct our final system. Table 10 list-
s the final results of our submitted system along
with top two systems.
As shown in Table 10, the accuracy of our sys-
tem is 0.63 while the best result is 0.83. The main
reason is that the features we used are quite sim-
ple. For the future work, more sufficient features
are examined to help classification.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.984528230769231">
In this work we proposed a combination of NP
and NER method and multiple features for aspec-
t extraction. And we also used multiple features
including eight sentiment lexicons for aspect and
category sentiment classification. Our final sys-
tems rank above average in the four subtasks. In
future work, we would expect to improve the re-
call of aspect terms extraction by extending name
lists using external data and seek other effective
features such as discourse relation, syntactic struc-
ture to improve the classification accuracy.
Table 10: The accuracy of our system and the top
two systems of subtask 4 on test dataset
</bodyText>
<sectionHeader confidence="0.994954" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999886857142857">
The authors would like to thank the organizers and
reviewers for this interesting task and their helpful
suggestions and comments. This research is sup-
ported by grants from National Natural Science
Foundation of China (No.60903093) and Shang-
hai Knowledge Service Platform Project (No.
ZF1213).
</bodyText>
<sectionHeader confidence="0.996441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.85787375">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining.
In LREC, volume 10, pages 2200–2204.
</reference>
<figure confidence="0.985018">
Systems
our system
rank 1 system
rank 2 system
Acc(%)
63.41
82.93
78.15
</figure>
<page confidence="0.953527">
257
</page>
<reference confidence="0.999737484375">
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technolo-
gy, 2:27:1–27:27. Software available at http://
www.csie.ntu.edu.tw/˜cjlin/libsvm.
Namrata Godbole, Manja Srinivasaiah, and Steven
Skiena. 2007. Large-scale sentiment analysis for
news and blogs. ICWSM, 7.
Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and
Shixia Liu. 2013. A hierarchical aspect-sentiment
model for online reviews. In Proceedings of AAAI.
Sudheer Kovelamudi, Sethu Ramalingam, Arpit Sood,
and Vasudeva Varma. 2011. Domain independen-
t model for product attribute extraction from user
reviews using wikipedia. In IJCNLP, pages 1408–
1412.
Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen.
2006. Opinion extraction, summarization and track-
ing in news and blog corpora. In AAAI Spring Sym-
posium: Computational Approaches to Analyzing
Weblogs, volume 100107.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Chong Long, Jie Zhang, and Xiaoyan Zhut. 2010. A
review selection approach for accurate feature rating
estimation. In Proceedings of the 23rd International
Conference on Computational Linguistics: Posters,
pages 766–774. Association for Computational Lin-
guistics.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
Arjun Mukherjee and Bing Liu. 2012. Aspect ex-
traction through semi-supervised modeling. In Pro-
ceedings of the 50th Annual Meeting of the Associ-
ation for Computational Linguistics: Long Papers-
Volume 1, pages 339–348. Association for Compu-
tational Linguistics.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Haris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect based sentiment analysis. in proceedings of
the 8th international workshop on semantic evalua-
tion (semeval 2014). Dublin, Ireland.
Jason DM Rennie. 2001. Improving multi-class text
classification with naive Bayes. Ph.D. thesis, Mas-
sachusetts Institute of Technology.
Zhiqiang Toh, Wenting Wang, Man Lan, and Xi-
aoli Li. 2012. An ner-based product identifica-
tion and lucene-based product linking approach to
cprod1 challenge: Description of submission sys-
tem to cprod1 challenge. In Data Mining Workshop-
s (ICDMW), 2012 IEEE 12th International Confer-
ence on, pages 869–871. IEEE.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing contextual polarity: An explo-
ration of features for phrase-level sentiment analy-
sis. Computational linguistics, 35(3):399–433.
Tian Tian Zhu, Fang Xi Zhang, and Man Lan. 2013.
Ecnucs: A surface information based system de-
scription of sentiment analysis in twitter in the
semeval-2013 (task 2). Atlanta, Georgia, USA, page
408.
</reference>
<page confidence="0.996123">
258
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.621064">
<title confidence="0.999614">ECNU: A Combination Method and Multiple Features for Extraction and Sentiment Polarity Classification</title>
<author confidence="0.999285">Zhihua Zhang Zhang</author>
<author confidence="0.999285">Man</author>
<affiliation confidence="0.8276115">Department of Computer Science and East China Normal</affiliation>
<abstract confidence="0.996589611111111">This paper reports our submissions to the four subtasks of Aspect Based Sentiment Analysis (ABSA) task (i.e., task 4) in SemEval 2014 including aspect term extraction and aspect sentiment polarity classification (Aspect-level tasks), aspect category detection and aspect category sentiment polarity classification (Categorylevel tasks). For aspect term extraction, we present three methods, i.e., noun phrase (NP) extraction, Named Entity Recognition (NER) and a combination of NP and NER method. For aspect sentiment classification, we extracted several features, i.e., topic features, sentiment lexicon features, and adopted a Maximum Entropy classifier. Our submissions rank above average.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="3407" citStr="Baccianella et al., 2010" startWordPosition="505" endWordPosition="508">od (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) and MPQA Subjectivity Lexicon (Wilson et al., 2009), have been used to generate sentiment score features (Zhu et al., 2013). The rest of this paper is organized as follows. From Section 2 to Section 5, we describe our approaches to the Aspect Term Extraction task, the Aspect Category detection task, the Aspect Term Polarity task and the Aspect Category Polarity task respectively. Section 6 provides the conclusion. 252 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 252–258, Dublin, Ireland, August 23-24, 2014. 2 Aspect Term Extraction System For aspe</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC, volume 10, pages 2200–2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<note>Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="18020" citStr="Chang and Lin, 2011" startWordPosition="2938" endWordPosition="2941">is value is calculated as the negative number of words from the current aspect to the former aspect. If only one aspect term exists in a sentence, then the value is set to zero. Number of aspects This feature describes the number of aspect terms in the current sentence. Negation flag feature We set this feature as 1 if a negation word occurs in the current sentence, otherwise -1. Number of negations This feature is the number of negation words in the current sentence. 4.2 Classification Algorithms The maximum entropy and SVM which are implemented in Mallet toolkit (McCallum, 2002) and LibSVM (Chang and Lin, 2011) respectively are 12http://www.cs.princeton.edu/ blei/lda-c/ used to construct the classification model from training data. Due to the limit of time, all parameters are set as defaults. 4.3 Results and Discussions 4.3.1 Results on Training Data To compare the performance of different features and different algorithms, we performed a 5-fold cross validation on training data of two domains. Table 6 and Table 7 show the results of two domains in terms of F-scores and accuracy with mean and standard deviation. The best results are shown in bold. From above two tables, we found that (1) MaxEnt perf</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Namrata Godbole</author>
<author>Manja Srinivasaiah</author>
<author>Steven Skiena</author>
</authors>
<title>Large-scale sentiment analysis for news and blogs.</title>
<date>2007</date>
<journal>ICWSM,</journal>
<volume>7</volume>
<contexts>
<context position="3065" citStr="Godbole et al., 2007" startWordPosition="453" endWordPosition="456"> the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) and MPQA Subjectivity Lexicon (Wilson et al., 2009), have been used to generate sentiment score features (Zhu et al., 2013). The rest of this paper is organized as follows. From Section 2 to Section 5, we describe our approaches to the Aspect Term Extractio</context>
</contexts>
<marker>Godbole, Srinivasaiah, Skiena, 2007</marker>
<rawString>Namrata Godbole, Manja Srinivasaiah, and Steven Skiena. 2007. Large-scale sentiment analysis for news and blogs. ICWSM, 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suin Kim</author>
<author>Jianwen Zhang</author>
<author>Zheng Chen</author>
<author>Alice Oh</author>
<author>Shixia Liu</author>
</authors>
<title>A hierarchical aspect-sentiment model for online reviews.</title>
<date>2013</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="3204" citStr="Kim et al., 2013" startWordPosition="477" endWordPosition="480">erms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) and MPQA Subjectivity Lexicon (Wilson et al., 2009), have been used to generate sentiment score features (Zhu et al., 2013). The rest of this paper is organized as follows. From Section 2 to Section 5, we describe our approaches to the Aspect Term Extraction task, the Aspect Category detection task, the Aspect Term Polarity task and the Aspect Category Polarity task respectively. Section 6 pro</context>
</contexts>
<marker>Kim, Zhang, Chen, Oh, Liu, 2013</marker>
<rawString>Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and Shixia Liu. 2013. A hierarchical aspect-sentiment model for online reviews. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sudheer Kovelamudi</author>
<author>Sethu Ramalingam</author>
<author>Arpit Sood</author>
<author>Vasudeva Varma</author>
</authors>
<title>Domain independent model for product attribute extraction from user reviews using wikipedia. In</title>
<date>2011</date>
<booktitle>IJCNLP,</booktitle>
<pages>1408--1412</pages>
<contexts>
<context position="2748" citStr="Kovelamudi et al., 2011" startWordPosition="407" endWordPosition="410">pects in a predefined set of aspect categories (e.g., food, price). The aspect term polarity (ATP) classification is to determine whether the sentiment polarity of each aspect is positive, negative, neutral or conflict (i.e., both positive and negative). The aspect category polarity (ACP) classification is to determine the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentimen</context>
</contexts>
<marker>Kovelamudi, Ramalingam, Sood, Varma, 2011</marker>
<rawString>Sudheer Kovelamudi, Sethu Ramalingam, Arpit Sood, and Vasudeva Varma. 2011. Domain independent model for product attribute extraction from user reviews using wikipedia. In IJCNLP, pages 1408– 1412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Yu-Ting Liang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Opinion extraction, summarization and tracking in news and blog corpora. In AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs,</title>
<date>2006</date>
<volume>volume</volume>
<pages>100107</pages>
<contexts>
<context position="2664" citStr="Ku et al., 2006" startWordPosition="395" endWordPosition="398">e aspect category detection (ACD) is to identify the semantic category of aspects in a predefined set of aspect categories (e.g., food, price). The aspect term polarity (ATP) classification is to determine whether the sentiment polarity of each aspect is positive, negative, neutral or conflict (i.e., both positive and negative). The aspect category polarity (ACP) classification is to determine the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify</context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006. Opinion extraction, summarization and tracking in news and blog corpora. In AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, volume 100107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="2810" citStr="Liu, 2012" startWordPosition="417" endWordPosition="418">ct term polarity (ATP) classification is to determine whether the sentiment polarity of each aspect is positive, negative, neutral or conflict (i.e., both positive and negative). The aspect category polarity (ACP) classification is to determine the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) an</context>
<context position="4757" citStr="Liu, 2012" startWordPosition="726" endWordPosition="727">n our preliminary experiments, we found that the NP-based method generates many noisy terms resulting in high recall and low precision, and the NER-based method performs inverse results. In order to overcome their drawbacks and make use of their advantages, we proposed a third method which combines the two methods by using the results of NP-based method as an additional name list feature to the NER system. 2.1 Preprocessing We used Stanford Parser Tools1 for POS tagging and for parsing while the Natural Language Toolkit2 was used for removing stop words and lemmatization. 2.2 NP-based Method (Liu, 2012) showed that the majority of aspect terms are noun phrases. Moreover, through the observation of the training set, we found that more than half of the aspects are pure noun phrases or nested noun phrases. So we considered these two types of noun phrases as aspect terms and adopted a rule-based noun phrases extraction system to perform aspect term extraction. This extraction is performed on parsed sentences. For example, from parsed sentence: “(CC but) (S (NP (NN iwork)) (VP (VBZ is) (ADJP (JJ cheap)) (PP (VBN compared) (PP (TO to) (NP (NN office))))))” iwork and office with NN tag are extracte</context>
<context position="6344" citStr="Liu, 2012" startWordPosition="989" endWordPosition="990">s. Table 1 shows the set of manually built rules used for NP extraction. 1http://nlp.stanford.edu/software/lex-parser.shtml 2http://www.nltk.org/ Based on the experimental results on training data, we found the NP-based method achieves high recall and low precision as shown in Table 2. This indicates that we extracted plenty of NPs which consist of a large proportion of aspect terms and much noise such as irrelevant NPs and overlapping phrases. Thus the NP-based method alone has not produced good results. 2.3 NER-based Method We also cast aspect term extraction task as a traditional NER task (Liu, 2012). We adopted the commonly used BIO tag format to represent the aspect terms in the given annotated training data (Toh et al., 2012), where B indicates the beginning of an aspect term, I indicates the inside of an aspect term and O indicates the outside of an aspect term. For example, given ”the battery life is excellent”, where battery life is annotated as aspect term, we tagged the three words the, is and excellent as O, battery as B and life as I. We adopted several widely used features for the NER-based aspect term extraction system. Word features: current word (word 0), previous word (word</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Long</author>
<author>Jie Zhang</author>
<author>Xiaoyan Zhut</author>
</authors>
<title>A review selection approach for accurate feature rating estimation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>766--774</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2685" citStr="Long et al., 2010" startWordPosition="399" endWordPosition="402">etection (ACD) is to identify the semantic category of aspects in a predefined set of aspect categories (e.g., food, price). The aspect term polarity (ATP) classification is to determine whether the sentiment polarity of each aspect is positive, negative, neutral or conflict (i.e., both positive and negative). The aspect category polarity (ACP) classification is to determine the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspe</context>
</contexts>
<marker>Long, Zhang, Zhut, 2010</marker>
<rawString>Chong Long, Jie Zhang, and Xiaoyan Zhut. 2010. A review selection approach for accurate feature rating estimation. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 766–774. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="12294" citStr="McCallum, 2002" startWordPosition="2037" endWordPosition="2038">lowing (Rennie, 2001), we built a binary model for each category, where bagof-words is used as features. 3.1 Features We adopted the bag-of-words schema to represent features as follows. Since not all training instances have annotated aspect terms, we extracted only annotated aspect terms from sentence if the sentence contains annotated aspect terms, or extracted all words from sentence which does not contain any annotated aspect terms as features, which results in 5200 word features in total. 3.2 Classification Algorithm We adopted the maximum entropy algorithm implemented in Mallet toolkit (McCallum, 2002) to build a binary classifier for each category. All parameters are set as defaults. This subtask only provides restaurant data and there are five predefined categories (i.e., food, price, service, ambience and anecdotes/miscellaneous), thus we build five binary classifiers in total. 3.3 Results and Discussions Table 5 lists the precision, recall and F-score of our final system along with the top two systems released by the organizers. Precision(%) Recall(%) F-score(%) our system 65.26 69.46 67.30 rank 1 system 91.04 86.24 88.58 rank 2 system 83.23 81.37 82.29 Table 5: The results of our syste</context>
<context position="17987" citStr="McCallum, 2002" startWordPosition="2934" endWordPosition="2935">ast term in the sentence, this value is calculated as the negative number of words from the current aspect to the former aspect. If only one aspect term exists in a sentence, then the value is set to zero. Number of aspects This feature describes the number of aspect terms in the current sentence. Negation flag feature We set this feature as 1 if a negation word occurs in the current sentence, otherwise -1. Number of negations This feature is the number of negation words in the current sentence. 4.2 Classification Algorithms The maximum entropy and SVM which are implemented in Mallet toolkit (McCallum, 2002) and LibSVM (Chang and Lin, 2011) respectively are 12http://www.cs.princeton.edu/ blei/lda-c/ used to construct the classification model from training data. Due to the limit of time, all parameters are set as defaults. 4.3 Results and Discussions 4.3.1 Results on Training Data To compare the performance of different features and different algorithms, we performed a 5-fold cross validation on training data of two domains. Table 6 and Table 7 show the results of two domains in terms of F-scores and accuracy with mean and standard deviation. The best results are shown in bold. From above two tabl</context>
<context position="21681" citStr="McCallum, 2002" startWordPosition="3541" endWordPosition="3543">acted sentiment features and used the supervised machine learning algorithms to determine the sentiment orientation of each category. 5.1 Features To extract features, we firstly used eight sentiment lexicons mentioned in Section 4.1.1 to build a big sentiment words dictionary. Then we extracted all aspect words and all sentiment words in training set as features. In the training and test data, we used the sentiment polarity score of sentiment word and the presence or absence of each aspect term as their feature values. 5.2 Classification Algorithms The MaxEnt algorithm implemented in Mallet (McCallum, 2002) with default parameters is used to build a polarity classifier. 5.3 Experiment and Results We used all features and the maximum entropy algorithm to conduct our final system. Table 10 lists the final results of our submitted system along with top two systems. As shown in Table 10, the accuracy of our system is 0.63 while the best result is 0.83. The main reason is that the features we used are quite simple. For the future work, more sufficient features are examined to help classification. 6 Conclusion In this work we proposed a combination of NP and NER method and multiple features for aspect</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect extraction through semi-supervised modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long PapersVolume 1,</booktitle>
<pages>339--348</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2810" citStr="Mukherjee and Liu, 2012" startWordPosition="415" endWordPosition="418">ice). The aspect term polarity (ATP) classification is to determine whether the sentiment polarity of each aspect is positive, negative, neutral or conflict (i.e., both positive and negative). The aspect category polarity (ACP) classification is to determine the sentiment polarity of each aspect category. We participated in these four subtasks. Generally, there are three methods to extract aspect terms: unsupervised learning method based on word frequency ((Ku et al., 2006), (Long et al., 2010)), supervised machine learning method (Kovelamudi et al., 2011) and semi-supervised learning method (Mukherjee and Liu, 2012) where only several user interested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) an</context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long PapersVolume 1, pages 339–348. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Haris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Semeval-2014 task 4: Aspect based sentiment analysis.</title>
<date>2014</date>
<booktitle>in proceedings of the 8th international workshop on semantic evaluation (semeval 2014).</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="1491" citStr="Pontiki et al., 2014" startWordPosition="212" endWordPosition="215"> sentiment lexicon features, and adopted a Maximum Entropy classifier. Our submissions rank above average. 1 Introduction Recently, sentiment analysis has attracted a lot of attention from researchers. Most previous work attempted to detect overall sentiment polarity on a text span, such as document, paragraph and sentence. Since sentiments expressed in text always adhere to objects, it is much meaningful to identify the sentiment target and its orientation, which helps user gain precise sentiment insights on specific sentiment target. The aspect based sentiment analysis (ABSA) task (Task 4) (Pontiki et al., 2014) in SemEval 2014 is to extract aspect terms, determine its semantic category, and then to detect the sentiment orientation of the extracted aspect terms and its category. Specifically, it consists of 4 subtasks. The aspect term extraction (ATE) aims to extract the aspect terms from the sentences in two givThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ en domains (laptop and restaurant). The aspect category detection (ACD) is to ide</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Haris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. Semeval-2014 task 4: Aspect based sentiment analysis. in proceedings of the 8th international workshop on semantic evaluation (semeval 2014). Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason DM Rennie</author>
</authors>
<title>Improving multi-class text classification with naive Bayes.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="11700" citStr="Rennie, 2001" startWordPosition="1945" endWordPosition="1946">he number of numeric descriptions in laptop dataset is much larger than those in restaurant dataset and the aspect terms containing numeric description are quite difficult to be extracted. Dataset DLIREC NRC-Canada Our result laptop 70.41 68.57 65.88 restaurant 78.34 80.19 78.24 Table 4: The F-scores (%) of our system and the top two systems of subtask 1 on test dataset. 254 3 Aspect Category Classification System Aspect category classification task tries to assign each aspect one or more semantic category labels. Thus, we regarded this task as a multi-class classification problem. Following (Rennie, 2001), we built a binary model for each category, where bagof-words is used as features. 3.1 Features We adopted the bag-of-words schema to represent features as follows. Since not all training instances have annotated aspect terms, we extracted only annotated aspect terms from sentence if the sentence contains annotated aspect terms, or extracted all words from sentence which does not contain any annotated aspect terms as features, which results in 5200 word features in total. 3.2 Classification Algorithm We adopted the maximum entropy algorithm implemented in Mallet toolkit (McCallum, 2002) to bu</context>
</contexts>
<marker>Rennie, 2001</marker>
<rawString>Jason DM Rennie. 2001. Improving multi-class text classification with naive Bayes. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiqiang Toh</author>
<author>Wenting Wang</author>
<author>Man Lan</author>
<author>Xiaoli Li</author>
</authors>
<title>An ner-based product identification and lucene-based product linking approach to cprod1 challenge: Description of submission system to cprod1 challenge.</title>
<date>2012</date>
<booktitle>In Data Mining Workshops (ICDMW), 2012 IEEE 12th International Conference on,</booktitle>
<pages>869--871</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6475" citStr="Toh et al., 2012" startWordPosition="1011" endWordPosition="1014">2http://www.nltk.org/ Based on the experimental results on training data, we found the NP-based method achieves high recall and low precision as shown in Table 2. This indicates that we extracted plenty of NPs which consist of a large proportion of aspect terms and much noise such as irrelevant NPs and overlapping phrases. Thus the NP-based method alone has not produced good results. 2.3 NER-based Method We also cast aspect term extraction task as a traditional NER task (Liu, 2012). We adopted the commonly used BIO tag format to represent the aspect terms in the given annotated training data (Toh et al., 2012), where B indicates the beginning of an aspect term, I indicates the inside of an aspect term and O indicates the outside of an aspect term. For example, given ”the battery life is excellent”, where battery life is annotated as aspect term, we tagged the three words the, is and excellent as O, battery as B and life as I. We adopted several widely used features for the NER-based aspect term extraction system. Word features: current word (word 0), previous word (word -1) and next word (word 1) are used as word features. POS feature: the POS tag of current word (POS 0), the POS tags of two words </context>
</contexts>
<marker>Toh, Wang, Lan, Li, 2012</marker>
<rawString>Zhiqiang Toh, Wenting Wang, Man Lan, and Xiaoli Li. 2012. An ner-based product identification and lucene-based product linking approach to cprod1 challenge: Description of submission system to cprod1 challenge. In Data Mining Workshops (ICDMW), 2012 IEEE 12th International Conference on, pages 869–871. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<booktitle>Computational linguistics,</booktitle>
<pages>35--3</pages>
<contexts>
<context position="3459" citStr="Wilson et al., 2009" startWordPosition="514" endWordPosition="517">rested category seeds are given and used to extract more categorize aspect terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) and MPQA Subjectivity Lexicon (Wilson et al., 2009), have been used to generate sentiment score features (Zhu et al., 2013). The rest of this paper is organized as follows. From Section 2 to Section 5, we describe our approaches to the Aspect Term Extraction task, the Aspect Category detection task, the Aspect Term Polarity task and the Aspect Category Polarity task respectively. Section 6 provides the conclusion. 252 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 252–258, Dublin, Ireland, August 23-24, 2014. 2 Aspect Term Extraction System For aspect terms extraction task, we first adopted two metho</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2009. Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis. Computational linguistics, 35(3):399–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tian Tian Zhu</author>
<author>Fang Xi Zhang</author>
<author>Man Lan</author>
</authors>
<title>Ecnucs: A surface information based system description of sentiment analysis</title>
<date>2013</date>
<booktitle>in twitter in the semeval-2013 (task 2).</booktitle>
<pages>408</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="3531" citStr="Zhu et al., 2013" startWordPosition="527" endWordPosition="530">terms. Since sentiments always adhere to entities, several researchers worked on polarity classification of entity. For example, (Godbole et al., 2007) proposed a system that assigned scores representing positive or negative opinion to each distinct entity in the corpus. (Kim et al., 2013) presented a hierarchical aspect sentiment model to classify the polarity of aspect terms from unlabeled online reviews. Moreover, some sentiment lexicons, such as SentiWordNet (Baccianella et al., 2010) and MPQA Subjectivity Lexicon (Wilson et al., 2009), have been used to generate sentiment score features (Zhu et al., 2013). The rest of this paper is organized as follows. From Section 2 to Section 5, we describe our approaches to the Aspect Term Extraction task, the Aspect Category detection task, the Aspect Term Polarity task and the Aspect Category Polarity task respectively. Section 6 provides the conclusion. 252 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 252–258, Dublin, Ireland, August 23-24, 2014. 2 Aspect Term Extraction System For aspect terms extraction task, we first adopted two methods: a noun phrase (NP) based method and a Named Entity Recognition (NER)</context>
</contexts>
<marker>Zhu, Zhang, Lan, 2013</marker>
<rawString>Tian Tian Zhu, Fang Xi Zhang, and Man Lan. 2013. Ecnucs: A surface information based system description of sentiment analysis in twitter in the semeval-2013 (task 2). Atlanta, Georgia, USA, page 408.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>