<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007060">
<title confidence="0.956911">
Detecting Word Misuse in Chinese
</title>
<author confidence="0.999609">
Wei Liu
</author>
<affiliation confidence="0.9990195">
Department of Computer Science
University of Sheffield
</affiliation>
<email confidence="0.982839">
W.Liu@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.993467" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994060684210526">
Social Network Service (SNS) and personal
blogs have become the most popular platform
for online communication and sharing infor-
mation. However because most modern com-
puter keyboards are Latin-based, Asian lan-
guage speakers (such as Chinese) has to rely
on a input system which accepts Romanisation
of the characters and convert them into charac-
ters or words in that language. In Chinese this
form of Romanisation (usually called Pinyin)
is highly ambiguous, word misuses often oc-
cur because the user choose a wrong candi-
date or deliverately substitute the word with
another character string that has the identical
Romanisation to convey certain semantics, or
to achieve a sarcasm effect. In this paper we
aim to develop a system that can automati-
cally identify such word misuse, and suggest
the correct word to be used.
</bodyText>
<sectionHeader confidence="0.998038" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999866818181818">
A certain kind of derogatory opinion is being con-
veyed in Chinese chat forums and SNS sites through
the use of Chinese Hanzi (hieroglyphic) characters.
There is potential for this to happen whenever two
expressions are pronounced in a similar way in Chi-
nese. For exmaple, irate readers have used “��”
(”Ji Zhe”) for “tib�” (”Ji Zhe”). While “��”
means reporter or journalist, “Ri�” can be inter-
preted as prostitute.
There are 5000 commonly used characters. While
the number of distinct Pinyin (toneless) is only 412.
Therefore Pinyin to character conversion is highly
ambigurous and is a active research topic (Zhou
et al., 2007), (Lin and Zhang, 2008), (Chen and
Lee, 2000). On the other hand, automatic Pinyin
generation is considered a solved task, (Liu and
Guthrie, 2009) shows that using the most frequent
Pinyin approach to assign Pinyin to each character
can achieve 98% accuracy. In fact, we test on the Gi-
gaword Chinese (Verson 2) corpus and find out that
only about 15% of the characters have ambigurous
Pinyin.
</bodyText>
<sectionHeader confidence="0.942212" genericHeader="method">
2 Automatically Detecting Word Misuse
</sectionHeader>
<bodyText confidence="0.989477">
We divided the detection process into three steps as
below:
</bodyText>
<listItem confidence="0.96793125">
• Segmentation: Given a piece of Chinese text,
we first feed it into an automatic word seg-
menter (Zhang et al., 2003) to break the text
into semantic units. Because we consider only
multiple-character anomaly cases, anomalies
can only be contained within sequences of sin-
gle characters.
• Character sequence extraction: After segmen-
</listItem>
<bodyText confidence="0.566955166666667">
tation, we are interested in sequences of sin-
gle characters, because anomalies will occur
only within those sequences. Once we obtain
these sequences, we generate all possible sub-
strings for each sequence because any anoma-
lous words can be part of a character sequence.
</bodyText>
<listItem confidence="0.998447">
• Detection: We assume the anomaly shares
</listItem>
<bodyText confidence="0.8423902">
many phonetic similarities with the ”true”
word. As a result we need a method for
comparing pronunciations of two character se-
quences. Here we use the Pinyin to represent
phonetics of a Chinese character, and we de-
fine two pronunciations to be similar when they
both have identical Pinyin (not including the
tone). We use character-to-pinyin conversion
tool1 to create a Pinyin-to-Word hash table us-
ing the machine-segmented Chinese Gigaword
</bodyText>
<footnote confidence="0.993145">
1http://pinyin4j.sourceforge.net/
</footnote>
<page confidence="0.915567">
5
</page>
<note confidence="0.880888">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 5–6,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.982170555555556">
ver. 2. Once we have the resources, we first
produce all possible Pinyin sequences of each
character sequence.Next we do a Pinyin-word
look up in the hash table we created; if there
exists any entries, we know that the Pinyin se-
quence maps to one or more ‘real’ words. Con-
sequently, we consider any character sequences
whose Pinyin maps to these words to be possi-
ble anomalies.
</bodyText>
<sectionHeader confidence="0.990016" genericHeader="method">
3 Data and Experiments
</sectionHeader>
<bodyText confidence="0.999965285714286">
We have conducted preliminary experiments to test
our algorithm. To start with, we manually gath-
ered a small number of documents which contain
anomalous phrases of the type described above. The
documents are gathered from internet chat-rooms
and contain 3,797 Chinese characters: the anoma-
lies herein are shown in table 1.
</bodyText>
<table confidence="0.996861857142857">
Intended Misused Pinyin Freq
word character seq.
Xrg 4rg Mei guo 43
(The U.S.)
C Nq% Jiao shou 23
(Professor)
AIR W-,Ror W-V, Ou xiang 12
</table>
<tableCaption confidence="0.998286">
Table 1: Testing document
</tableCaption>
<table confidence="0.946718142857143">
ces of our method.
No. of misused chararcter sequence 78
Total identified 130
Correctly identified 78
Precision 60%
Recall 100%
F-measure 75%
</table>
<tableCaption confidence="0.995411">
Table 2: Result for word misuse identification
</tableCaption>
<bodyText confidence="0.9008475">
d correct the three ex-
eves some
false positives, due to the highly ambiguous Pinyin
to word mappings.
Work
We also plan
to gather more real data that contain
misuse of our interests.
</bodyText>
<sectionHeader confidence="0.59103" genericHeader="method">
nces
</sectionHeader>
<subsectionHeader confidence="0.986679">
3.1 Results and Discussions
</subsectionHeader>
<bodyText confidence="0.999166714285714">
We evaluate our identification/correction perfor-
mance using standard measures of standard preci-
sion and recall. We tested our performance using
bigram thresholds of 0, 1 and 2.
Table 2 shows the performan
The initial experiments showed that our method
can successfully identify an
amples of non-word anomalies with reasonable pre-
cision and recall. The method obtains 100% recall
however it generates a lot of false positives; this can
be seen in a relatively low precision of 60%.
In summary, our method is successful at iden-
tifying genuine anomalous non-word character se-
quences; however the method also retri
</bodyText>
<sectionHeader confidence="0.996562" genericHeader="method">
4 Future
</sectionHeader>
<bodyText confidence="0.999966285714286">
Our experiments shows that our preliminary method
can detect word misuses due to the Pinyin sequence
being idential but with a relatively high false posi-
tives. In the future we plan to use other contextual
evidence, such as pointwise mutual information to
model whether the candidate sequence generated by
our method is a better fit than the original sequence.
</bodyText>
<sectionHeader confidence="0.973759" genericHeader="method">
Refere
</sectionHeader>
<reference confidence="0.978034933333333">
Chen, Z. and Lee, K.-F. (2000). Anew statistical ap-
proach to
pinyin input. In In Proceedings of
the 38th Annual Meeting on Association for Computa-
tional Linguistics, pages
Hong Kong.
Lin, B. and Zhang, J. (2008). A novel statistical
language model and its application in pinyin-to-
character conversion. In CIKM
Proceeding of the
17th ACM conference on Information and knowledge
management, pages
New York, NY, USA.
ACM.
Liu, W. and Guthrie, L. (2009). Chinese pinyin-text
conversion on segmented text. In TSD
Pro-
ceedings of the 12th International Conference on Text,
Speech and Dialogue, pages
Berlin, Heidel-
berg. Springer-Verlag.
Zhang, H.-P., Liu, Q., Cheng, X.-Q., Zhang, H., and Yu,
H.-K. (2003). Chinese lexical analysis using hierar-
chical hidden markov model. In Proceedings of the
second SIGHAN workshop on Chinese language pro-
cessing, pages
Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Zhou, X., Hu, X., Zhang, X., an
chinese
241–247,
chi-
nese
’08:
1433–1434,
’09:
116–123,
63–70,
d Shen, X. (2007). A
segment-based hidden markov model for real-setting
pinyin-to-chinese conversion. In CIKM ’07: Pro-
ceedings of the sixteenth ACM conference on Con-
ference on information and knowledge management,
pages 1027–1030, New York, NY, USA. ACM.
(Role model)
</reference>
<page confidence="0.987271">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.933159">
<title confidence="0.999681">Detecting Word Misuse in Chinese</title>
<author confidence="0.998778">Wei</author>
<affiliation confidence="0.9992815">Department of Computer University of</affiliation>
<email confidence="0.98749">W.Liu@dcs.shef.ac.uk</email>
<abstract confidence="0.9973366">Social Network Service (SNS) and personal blogs have become the most popular platform for online communication and sharing information. However because most modern computer keyboards are Latin-based, Asian language speakers (such as Chinese) has to rely on a input system which accepts Romanisation of the characters and convert them into characters or words in that language. In Chinese this form of Romanisation (usually called Pinyin) is highly ambiguous, word misuses often occur because the user choose a wrong candidate or deliverately substitute the word with another character string that has the identical Romanisation to convey certain semantics, or to achieve a sarcasm effect. In this paper we aim to develop a system that can automatically identify such word misuse, and suggest the correct word to be used.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Z Chen</author>
<author>K-F Lee</author>
</authors>
<title>Anew statistical approach to pinyin input. In</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>pages</pages>
<contexts>
<context position="1636" citStr="Chen and Lee, 2000" startWordPosition="260" endWordPosition="263">in Chinese chat forums and SNS sites through the use of Chinese Hanzi (hieroglyphic) characters. There is potential for this to happen whenever two expressions are pronounced in a similar way in Chinese. For exmaple, irate readers have used “��” (”Ji Zhe”) for “tib�” (”Ji Zhe”). While “��” means reporter or journalist, “Ri�” can be interpreted as prostitute. There are 5000 commonly used characters. While the number of distinct Pinyin (toneless) is only 412. Therefore Pinyin to character conversion is highly ambigurous and is a active research topic (Zhou et al., 2007), (Lin and Zhang, 2008), (Chen and Lee, 2000). On the other hand, automatic Pinyin generation is considered a solved task, (Liu and Guthrie, 2009) shows that using the most frequent Pinyin approach to assign Pinyin to each character can achieve 98% accuracy. In fact, we test on the Gigaword Chinese (Verson 2) corpus and find out that only about 15% of the characters have ambigurous Pinyin. 2 Automatically Detecting Word Misuse We divided the detection process into three steps as below: • Segmentation: Given a piece of Chinese text, we first feed it into an automatic word segmenter (Zhang et al., 2003) to break the text into semantic unit</context>
</contexts>
<marker>Chen, Lee, 2000</marker>
<rawString>Chen, Z. and Lee, K.-F. (2000). Anew statistical approach to pinyin input. In In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hong Kong</author>
</authors>
<marker>Kong, </marker>
<rawString>Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lin</author>
<author>J Zhang</author>
</authors>
<title>A novel statistical language model and its application in pinyin-tocharacter conversion.</title>
<date>2008</date>
<booktitle>In CIKM Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>pages</pages>
<contexts>
<context position="1614" citStr="Lin and Zhang, 2008" startWordPosition="256" endWordPosition="259">nion is being conveyed in Chinese chat forums and SNS sites through the use of Chinese Hanzi (hieroglyphic) characters. There is potential for this to happen whenever two expressions are pronounced in a similar way in Chinese. For exmaple, irate readers have used “��” (”Ji Zhe”) for “tib�” (”Ji Zhe”). While “��” means reporter or journalist, “Ri�” can be interpreted as prostitute. There are 5000 commonly used characters. While the number of distinct Pinyin (toneless) is only 412. Therefore Pinyin to character conversion is highly ambigurous and is a active research topic (Zhou et al., 2007), (Lin and Zhang, 2008), (Chen and Lee, 2000). On the other hand, automatic Pinyin generation is considered a solved task, (Liu and Guthrie, 2009) shows that using the most frequent Pinyin approach to assign Pinyin to each character can achieve 98% accuracy. In fact, we test on the Gigaword Chinese (Verson 2) corpus and find out that only about 15% of the characters have ambigurous Pinyin. 2 Automatically Detecting Word Misuse We divided the detection process into three steps as below: • Segmentation: Given a piece of Chinese text, we first feed it into an automatic word segmenter (Zhang et al., 2003) to break the t</context>
</contexts>
<marker>Lin, Zhang, 2008</marker>
<rawString>Lin, B. and Zhang, J. (2008). A novel statistical language model and its application in pinyin-tocharacter conversion. In CIKM Proceeding of the 17th ACM conference on Information and knowledge management, pages</rawString>
</citation>
<citation valid="false">
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker></marker>
<rawString>New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Liu</author>
<author>L Guthrie</author>
</authors>
<title>Chinese pinyin-text conversion on segmented text.</title>
<date>2009</date>
<booktitle>In TSD Proceedings of the 12th International Conference on Text, Speech and Dialogue,</booktitle>
<pages>pages</pages>
<contexts>
<context position="1737" citStr="Liu and Guthrie, 2009" startWordPosition="276" endWordPosition="279">here is potential for this to happen whenever two expressions are pronounced in a similar way in Chinese. For exmaple, irate readers have used “��” (”Ji Zhe”) for “tib�” (”Ji Zhe”). While “��” means reporter or journalist, “Ri�” can be interpreted as prostitute. There are 5000 commonly used characters. While the number of distinct Pinyin (toneless) is only 412. Therefore Pinyin to character conversion is highly ambigurous and is a active research topic (Zhou et al., 2007), (Lin and Zhang, 2008), (Chen and Lee, 2000). On the other hand, automatic Pinyin generation is considered a solved task, (Liu and Guthrie, 2009) shows that using the most frequent Pinyin approach to assign Pinyin to each character can achieve 98% accuracy. In fact, we test on the Gigaword Chinese (Verson 2) corpus and find out that only about 15% of the characters have ambigurous Pinyin. 2 Automatically Detecting Word Misuse We divided the detection process into three steps as below: • Segmentation: Given a piece of Chinese text, we first feed it into an automatic word segmenter (Zhang et al., 2003) to break the text into semantic units. Because we consider only multiple-character anomaly cases, anomalies can only be contained within </context>
</contexts>
<marker>Liu, Guthrie, 2009</marker>
<rawString>Liu, W. and Guthrie, L. (2009). Chinese pinyin-text conversion on segmented text. In TSD Proceedings of the 12th International Conference on Text, Speech and Dialogue, pages</rawString>
</citation>
<citation valid="false">
<authors>
<author>Heidelberg Berlin</author>
</authors>
<publisher>Springer-Verlag.</publisher>
<marker>Berlin, </marker>
<rawString>Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-P Zhang</author>
<author>Q Liu</author>
<author>X-Q Cheng</author>
<author>H Zhang</author>
<author>H-K Yu</author>
</authors>
<title>Chinese lexical analysis using hierarchical hidden markov model.</title>
<date>2003</date>
<booktitle>In Proceedings of the second SIGHAN workshop on Chinese language processing,</booktitle>
<pages>pages</pages>
<contexts>
<context position="2199" citStr="Zhang et al., 2003" startWordPosition="356" endWordPosition="359"> al., 2007), (Lin and Zhang, 2008), (Chen and Lee, 2000). On the other hand, automatic Pinyin generation is considered a solved task, (Liu and Guthrie, 2009) shows that using the most frequent Pinyin approach to assign Pinyin to each character can achieve 98% accuracy. In fact, we test on the Gigaword Chinese (Verson 2) corpus and find out that only about 15% of the characters have ambigurous Pinyin. 2 Automatically Detecting Word Misuse We divided the detection process into three steps as below: • Segmentation: Given a piece of Chinese text, we first feed it into an automatic word segmenter (Zhang et al., 2003) to break the text into semantic units. Because we consider only multiple-character anomaly cases, anomalies can only be contained within sequences of single characters. • Character sequence extraction: After segmentation, we are interested in sequences of single characters, because anomalies will occur only within those sequences. Once we obtain these sequences, we generate all possible substrings for each sequence because any anomalous words can be part of a character sequence. • Detection: We assume the anomaly shares many phonetic similarities with the ”true” word. As a result we need a me</context>
</contexts>
<marker>Zhang, Liu, Cheng, Zhang, Yu, 2003</marker>
<rawString>Zhang, H.-P., Liu, Q., Cheng, X.-Q., Zhang, H., and Yu, H.-K. (2003). Chinese lexical analysis using hierarchical hidden markov model. In Proceedings of the second SIGHAN workshop on Chinese language processing, pages</rawString>
</citation>
<citation valid="false">
<authors>
<author>NJ Morristown</author>
</authors>
<institution>USA. Association for Computational Linguistics.</institution>
<marker>Morristown, </marker>
<rawString>Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>X Zhou</author>
<author>X Hu</author>
<author>X Zhang</author>
</authors>
<note>an chinese 241–247,</note>
<marker>Zhou, Hu, Zhang, </marker>
<rawString>Zhou, X., Hu, X., Zhang, X., an chinese 241–247,</rawString>
</citation>
<citation valid="false">
<note>chi63–70,</note>
<marker></marker>
<rawString>chi63–70,</rawString>
</citation>
<citation valid="true">
<authors>
<author>d Shen</author>
<author>X</author>
</authors>
<title>A segment-based hidden markov model for real-setting pinyin-to-chinese conversion.</title>
<date>2007</date>
<booktitle>In CIKM ’07: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>1027--1030</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Shen, X, 2007</marker>
<rawString>d Shen, X. (2007). A segment-based hidden markov model for real-setting pinyin-to-chinese conversion. In CIKM ’07: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 1027–1030, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="false">
<note>(Role model)</note>
<marker></marker>
<rawString>(Role model)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>