<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.99552">
Matching Syntactic-Semantic Graphs for Semantic Relation Assignment
</title>
<author confidence="0.999524">
Vivi Nastase1 and Stan Szpakowicz1,2
</author>
<affiliation confidence="0.98028975">
1 School of Information Technology and Engineering,
University of Ottawa, Ottawa, Canada
2 Institute of Computer Science,
Polish Academy of Sciences, Warsaw, Poland
</affiliation>
<email confidence="0.998009">
{vnastase,szpak}@site.uottawa.ca
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895583333333">
We present a graph-matching algorithm
for semantic relation assignment. The al-
gorithm is part of an interactive text analy-
sis system. The system automatically ex-
tracts pairs of syntactic units from a text
and assigns a semantic relation to each
pair. This is an incremental learning algo-
rithm, in which previously processed pairs
and user feedback guide the process. Af-
ter each assignment, the system adds to its
database a syntactic-semantic graph cen-
tered on the main element of each pair of
units. A graph consists of the main unit
and all syntactic units with which it is syn-
tactically connected. An edge contains in-
formation both about syntax and about se-
mantic relations for use in further process-
ing. Syntactic-semantic graph matching is
used to produce a list of candidate assign-
ments for 63.75% of the pairs analysed,
and in 57% of situations the correct rela-
tions is one of the system’s suggestions;
in 19.6% of situations it suggests only the
correct relation.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997855">
When analysing texts, it is essential to see how el-
ements of meaning are interconnected. This is an
old idea. The first chronicled endeavour to con-
nect text elements and organise connections between
them goes back to the 51h century B.C. and the work
of Paninil. He was a grammarian who analysed San-
skrit (Misra, 1966). The idea resurfaced forcefully
at several points in the more recent history of lin-
guistic research (Tesni`ere, 1959; Gruber, 1965; Fill-
more, 1968). Now it has the attention of many re-
searchers in natural language processing, as shown
by recent research in semantic parsing and semantic
</bodyText>
<footnote confidence="0.9341625">
&apos;The sources date his work variously between the 5th and
7th century.
</footnote>
<note confidence="0.830476666666667">
role labelling (Baker et al., 1998; Kipper et al., 2000;
Carreras and Marquez, 2004; Carreras and Marquez,
2005; Atserias et al., 2001; Shi and Mihalcea, 2005).
</note>
<bodyText confidence="0.999870243902439">
Graph-like structures are a natural way of or-
ganising one’s impressions of a text seen from
the perspective of connections between its simpler
constituents of varying granularity, from sections
through paragraphs, sentences, clauses, phrases,
words to morphemes.
In this work we pursue a well-known and of-
ten tacitly assumed line of thinking: connections at
the syntactic level reflect connections at the seman-
tic level (in other words, syntax carries meaning).
Anecdotal support for this stance comes from the
fact that the grammatical notion of case is the basis
for semantic relations (Misra, 1966; Gruber, 1965;
Fillmore, 1968). Tesni`ere (1959), who proposes a
grouping of verb arguments into actants and circum-
stances, gives a set of rules to connect specific types
of actants – for example, agent or instrument – to
such grammatical elements as subject, direct object,
indirect object. This idea was expanded to include
nouns and their modifiers through verb nominaliza-
tions (Chomsky, 1970; Quirk et al., 1985).
We work with sentences, clauses, phrases and
words, using syntactic structures generated by a
parser. Our system incrementally processes a text,
and extracts pairs of text units: two clauses, a verb
and each of its arguments, a noun and each of its
modifiers. For each pair of units, the system builds a
syntactic graph surrounding the main element (main
clause, head verb, head noun). It then tries to find
among the previously processed instances another
main element with a matching syntactic graph. If
such a graph is found, then the system maps pre-
viously assigned semantic relations onto the current
syntactic graph. We have a list of 47 relations that
manifest themselves in compound clauses, inside a
simple clause or in noun phrases. The list, a syn-
thesis of a number of relation lists cited in the lit-
erature, has been designed to be general, domain-
independent (Barker et al., 1997a).
Section 2 overviews research in semantic relation
analysis. Section 3 describes the text we used in ex-
</bodyText>
<page confidence="0.986744">
81
</page>
<bodyText confidence="0.879909916666667">
Workshop on TextGraphs, at HLT-NAACL 2006, pages 81–88,
New York City, June 2006. c�2006 Association for Computational Linguistics
periments, and the semantic relation list. Section 4
looks in detail at the graph-matching heuristic. Sec-
tion 5 describes the experimental setting and shows
how often the heuristic was used when processing
the input text. We show in detail our findings about
syntactic levels (how often graph matching helped
assign a relation between two clauses, a verb and its
arguments, or a noun and its modifier) and about the
accuracy of the suggestion. Discussion and conclu-
sions appear in Section 6.
</bodyText>
<sectionHeader confidence="0.999759" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997106420289855">
Some methods of semantic relation analysis rely on
predefined templates filled with information from
processed texts (Baker et al., 1998). In other meth-
ods, lexical resources are specifically tailored to
meet the requirements of the domain (Rosario and
Hearst, 2001) or the system (Gomez, 1998). Such
systems extract information from some types of syn-
tactic units (clauses in (Fillmore and Atkins, 1998;
Gildea and Jurafsky, 2002; Hull and Gomez, 1996);
noun phrases in (Hull and Gomez, 1996; Rosario et
al., 2002)). Lists of semantic relations are designed
to capture salient domain information.
In the Rapid Knowledge Formation Project (RKF)
a support system was developed for domain experts.
It helps them build complex knowledge bases by
combining components: events, entities and modi-
fiers (Clark and Porter, 1997). The system’s inter-
face facilitates the expert’s task of creating and ma-
nipulating structures which represent domain con-
cepts, and assigning them relations from a relation
dictionary.
In current work on semantic relation analysis, the
focus is on semantic roles – relations between verbs
and their arguments. Most approaches rely on Verb-
Net (Kipper et al., 2000) and FrameNet (Baker et
al., 1998) to provide associations between verbs and
semantic roles, that are then mapped onto the cur-
rent instance, as shown by the systems competing in
semantic role labelling competitions (Carreras and
Marquez, 2004; Carreras and Marquez, 2005) and
also (Gildea and Jurafsky, 2002; Pradhan et al.,
2005; Shi and Mihalcea, 2005).
These systems share two ideas which make them
different from the approach presented here: they all
analyse verb-argument relations, and they all use
machine learning or probabilistic approaches (Prad-
han et al., 2005) to assign a label to a new instance.
Labelling every instance relies on the same previ-
ously encoded knowledge (see (Carreras and Mar-
quez, 2004; Carreras and Marquez, 2005) for an
overview of the systems in the semantic role la-
belling competitions from 2004 and 2005). Pradhan
et al. (2005) combine the outputs of multiple parsers
to extract reliable syntactic information, which is
translated into features for a machine learning ex-
periment in assigning semantic roles.
Our system analyses incrementally pairs of units
coming from three syntactic levels – clause (CL),
intra-clause (or verb-argument, IC), noun-phrase
(NP). There are no training and testing data sets. In-
stead of using previously built resources, the system
relies on previously processed examples to find the
most appropriate relation for a current pair. Because
the system does not rely on previously processed
or annotated data, it is flexible. It allows the user
to customize the process for a specific domain by
choosing the syntactic units of interest and her own
list of relations that best fit the domain.
It is also interesting to assess, using the current
system configuration, the effect of syntactic infor-
mation and incremental learning on semantic analy-
sis. This is described in section 5.
Because of these differences in the type of data
used, and in the learning approach, the results we
obtain cannot be compared to previous approaches.
In order to show that the system does learn, we show
that the number of examples for which it provides
the correct answer increases with the number of ex-
amples previously analysed.
</bodyText>
<sectionHeader confidence="0.864578" genericHeader="method">
3 Input data and semantic relations
</sectionHeader>
<subsectionHeader confidence="0.994574">
3.1 Input data
</subsectionHeader>
<bodyText confidence="0.999984333333333">
We work with a semi-technical text on meteorolog-
ical phenomena (Larrick, 1961), meant for primary
school students. The text gradually introduces con-
cepts related to precipitation, and explains them. Its
nature makes it appropriate for the semantic analy-
sis task in an incremental approach. The system will
mimic the way in which a human reader accumu-
lates knowledge and uses what was written before to
process ideas introduced later in the text.
The text contains 513 sentences, with an average
length of 9.13 words. There are 4686 word tokens
and 969 types. The difference between the num-
ber of types (2850) and tokens (573) in the extracted
pairs (which contain only open-class words) shows
that the same concepts recur, as expected in a didac-
tic text.
The syntactic structures of the input data are
produced by a parser with good coverage and de-
tailed syntactic information, DIPETT (Delisle and
Szpakowicz, 1995). The parser, written in Prolog,
implements a classic constituency English grammar
from Quirk et al. (1985). Pairs of syntactic units
connected by grammatical relations are extracted
from the parse trees. A dependency parser would
</bodyText>
<page confidence="0.992301">
82
</page>
<bodyText confidence="0.999741111111111">
produce a similar output, but DIPETT also provides
verb subcategorization information (such as, for ex-
ample, subject-verb-object or subject-verb-object-
indirect object), which we use to select the (best)
matching syntactic structures.
To find pairs, we use simple structural informa-
tion. If a unit is directly embedded in another unit,
we assume a subordinate relation between them; if
the two units are coordinate, we assume a coordinate
relation. These assumptions are safe if the parse is
correct. A modifier is subordinate to its head noun,
an argument to its head verb, and a clause perhaps to
the main clause in the sentence.
If we conclude that two units should interact, we
seek an appropriate semantic relation to describe this
interaction. The system uses three heuristics to find
one or more semantic relation candidates for the cur-
rent pair.
</bodyText>
<listItem confidence="0.955820545454545">
1. Word match – the system will propose the se-
mantic relation(s) that have previously been as-
signed to a pair containing the same lemmas.
2. Syntactic graph match – we elaborate this
heuristic in Section 4.
3. Marker – the system uses a manually built dic-
tionary of markers (prepositions, coordinators,
subordinators) associated with the semantic re-
lations they indicate. The dictionary contains
325 markers, and a total of 662 marker-relation
associations.
</listItem>
<bodyText confidence="0.999730545454545">
If neither of the three heuristics yield results, the
system will present an empty list, and expect the user
to input the appropriate relation. When at least one
relation is proposed, the user can accept a unique
relation, choose among several options, or supply
a new one. The system records which action took
place, as well as the heuristic that generated the op-
tions presented to the user. The pair is also analysed
to determine the syntactic level from which it came,
to allow for a more detailed analysis of the behaviour
of the system.
</bodyText>
<subsectionHeader confidence="0.999785">
3.2 Semantic relations
</subsectionHeader>
<bodyText confidence="0.9996419">
The list of semantic relations with which we work
is based on extensive literature study (Barker et al.,
1997a). Three lists of relations for three syntactic
levels – inter-clause, intra-clause (case) and noun-
modifier relations – were next combined based on
syntactic and semantic phenomena. The resulting
list is the one used in the experiments we present
in this paper. The relations are grouped by general
similarity into 6 relation classes (H denotes the head
of a base NP, M denotes the modifier).
</bodyText>
<listItem confidence="0.7992185">
1. CAUSAL groups relations enabling or oppos-
ing an occurrence. Examples:
</listItem>
<bodyText confidence="0.877301153846154">
cause - H causes M: flu virus;
effect - H is the effect (was caused by) M:
exam anxiety;
purpose - H is for M: concert hall;
2. CONJUNCTIVE includes relations that describe
the conjunction or disjunction of occurrences
(events/act/actions/states/activities), entities or
attributes:
conjunction - both H and M occur or exist
(and nothing more can be said about that
from the point of view of causality or
temporality): running and swimming (are
good for you);
</bodyText>
<listItem confidence="0.771193307692308">
disjunction - either one or both H and M occur
or exist: painting or drawing;
3. PARTICIPANT groups relations between an oc-
currence and its participants or circumstances.
Examples:
agent - M performs H: student protest;
object - M is acted upon by H: metal separa-
tor;
beneficiary - M benefits from H: student dis-
count;
4. SPATIAL groups relations that place an occur-
rence at an absolute or relative point in space.
Examples:
</listItem>
<bodyText confidence="0.77450375">
direction - H is directed towards M: outgoing
mail;
location - H is the location of M: home town;
location at - H is located at M: desert storm;
</bodyText>
<listItem confidence="0.800694214285714">
5. TEMPORAL groups relations that place an oc-
currence at an absolute or relative point in time.
Examples:
frequency - H occurs every time M occurs:
weekly game;
time at - H occurs when M occurs: morning
coffee;
time through - H existed while M existed: 2-
hour trip;
6. QUALITY groups the remaining relations be-
tween a verb or noun and its arguments. Exam-
ples:
manner - H occurs as indicated by M: stylish
writing;
</listItem>
<page confidence="0.995578">
83
</page>
<bodyText confidence="0.9979052">
material - H is made of M: brick house;
measure - M is a measure of H: heavy rock;
There is no consensus in the literature on a list of
semantic relations that would work in all situations.
This is, no doubt, because a general list of relations
such as the one we use would not be appropriate for
the semantic analysis of texts in a specific domain,
such as for example medical texts. All the relations
in the list we use were necessary, and sufficient, for
the analysis of the input text.
</bodyText>
<sectionHeader confidence="0.965533" genericHeader="method">
4 Syntactic-semantic graph-matching
</sectionHeader>
<bodyText confidence="0.999891259259259">
Our system begins operation with a minimum of
manually encoded knowledge, and accumulates in-
formation as it processes the text. This design idea
was adopted from TANKA (Barker et al., 1997b).
The only manually encoded knowledge is a dictio-
nary of markers (subordinators, coordinators, prepo-
sitions). This resource does not affect the syntactic-
semantic graph-matching heuristic.
Because the system gradually accumulates
knowledge as it goes through the input text, it uses a
form of memory-based learning to make predictions
about the semantic relation that fits the current pair.
The type of knowledge that it accumulates consists
of previously analysed pairs, together with the
semantic relation assigned, and a syntactic-semantic
graph centered on each word in a sentence which
appears as the main element in a processed pair.
To process a pair P not encountered previously,
the system builds a graph centered on the main ele-
ment (often the head) of P. This idea was inspired
by Delisle et al. (1993), who used a list of argu-
ments surrounding the main verb together with the
verb’s subcategorization information and previously
processed examples to analyse semantic roles (case
relations). In recent approaches, syntactic informa-
tion is translated into features which, together with
information from FrameNet, WordNet or VerbNet,
will be used with ML tools to make predictions for
each example in the test set (Carreras and Marquez,
2004; Carreras and Marquez, 2005).
Our system builds a (simple) graph surrounding
a head word (which may be a verb – representing
the predicate of a sentence, or representing a clause
– or noun), and matches it with previously analysed
examples.
A graph G(w) centered on word w consists of
the following: a node for w; a set of nodes for
each of the words wz in the sentence with which w
is connected by a grammatical relation (including
situations when w is a modifier/argument); edges
that connect w with each wz, tagged with gram-
matical relation GR (such as subject, object, com-
plement) and connective information Con (preposi-
tions, coordinators, subordinators, or nil). The nodes
also contain part-of-speech information for the cor-
responding word, and other information from the
parser (such as subcategorization structure for the
verb, if it is available).
Graph matching starts with the central node, and
continues with edge matching. If G(w) is the graph
centered on word w whose pairs are currently being
processed, the system selects from the collection of
previously stored graphs, a set of graphs {G(wz)},
which satisfy the following conditions:
</bodyText>
<listItem confidence="0.9568518">
• The central nodes match. The matching is
guided by a set of contraints. We choose the
graphs centered on the nodes that satisfy the
most constraints, presented here in the order of
their importance:
</listItem>
<bodyText confidence="0.917174818181818">
– w and wz must have the same part of
speech.
– w and wz have the same syntactic proper-
ties. If w and wz are verbs, they must have
the same subcategorization structure.
– w and wz are the same lemma. We empha-
size that a graph centered on a different
lemma, but with the same subcategoriza-
tion structure is preferred to a graph with
the same lemma, but a different subcate-
gorization structure.
</bodyText>
<listItem confidence="0.900114666666667">
• The edge representing the word pair to which
we want to assign a semantic relation has a
match in G(wz). From all graphs that com-
</listItem>
<bodyText confidence="0.9855836">
ply with this constraint, the ones that have the
lowest distance – corresponding to the high-
est matching score – are chosen. The graphs
are matched edge by edge. Two edges match
if the grammatical relation and the connectives
match. Figure 1 shows the formula that com-
putes the distance between two graphs. We
note that edge matching uses only edge infor-
mation – grammatical and connective informa-
tion. Using the node information as is (lemmas
and their part of speech) is too restrictive. We
are looking into using word similarity as a so-
lution of node matching.
If no matching graph has been found, the system
searches for a simpler match, in which the current
word pair is matched against previously processed
pairs, using the same formula as for edge distance,
and preferring the pairs that have the same modifier.
This algorithm will retrieve the set of graphs
{G(wz)}, which give the same score when matched
</bodyText>
<page confidence="0.994799">
84
</page>
<bodyText confidence="0.773269">
Definition of a graph centered on w:
</bodyText>
<equation confidence="0.965122363636364">
G(w) = {wi, edge(w, wi) or edge(wi, w)|wiappears in sent. S, and is connected to w}
edge(w, wi) = {GRi, Coni} ; GRi E {subject, object, complement, ...}
Coni E {at, in, on, with, for,...}
Distance metric between two graphs:
N
dist(G(w1), G(w2)) = E d(edge1k, edge2k); edgeik E G(wi), N is the number of edges in G(wi)
k=1
d(edge1k, edge2k)=d({GR1k, Con1k}, {GR2k, Con2k})
=d1(GR1k, GR2k) + d1(Con1k, Con2k)
� 0 x = y
d1(x,y) = 1 x =� y
</equation>
<figureCaption confidence="0.998466">
Figure 1: Distance between two graphs
</figureCaption>
<bodyText confidence="0.991272058823529">
with the current graph. The set of possible semantic
relations presented to the user consists of the seman-
tic relation on the edge of each G(wi) that matches
the edge (of the current graph) corresponding to the
word pair which we are analysing.
To the sentence:
When you breathe out on a cold day, you make a
cloud.
corresponds the following syntactic graph:
to its central node. For each graph found, we com-
pute a distance that gives a measure of the match
between the two graphs. The best match will have
the smallest distance.
For example, for the sentence:
Weathermen watch the clouds day and night.
the system builds the following network centered
on the predicate watch2:
</bodyText>
<figure confidence="0.463281769230769">
cold
breathe (subord,when) make
out (compl,nil) (v, sv) (v,svo)
day
you
you
cloud
day and night
weatherman
watch
(v, svo)
(compl,nil)
cloud
</figure>
<bodyText confidence="0.999805">
When we focus on the graph centered on a spe-
cific word, such as breathe, we look only at the node
corresponding to the word breathe, and the nodes
adjacent to it.
To process a pair P = (wH, wM), the system first
builds G(wH), and then searches through previously
stored graphs for those which have the same center
wH, or have the same part of speech as wH assigned
The system locates among previously stored net-
works those centered around verbs3. For the sen-
tence above, the system uses the following graph,
</bodyText>
<footnote confidence="0.832842833333333">
2The nil value on the edges means that no preposition or
other connective explicitly links the two words or the corre-
sponding syntactic structures.
3If more detailed information is available, the system will
choose only networks associated with verbs that have the same
subcategorisation pattern (svo, svoi and so on).
</footnote>
<page confidence="0.999749">
85
</page>
<bodyText confidence="0.997359333333333">
built from the immediately preceding sentence in the
text:
Air pilots know that clouds can bring rain, hail,
sleet and snow.
According to the metric, the networks match and
the pairs (watch, weatherman) and (know, air pi-
lots) match, so the semantic relation for the pair
(know, air pilots) is proposed as a possible relation
for pair (watch, weatherman) .
</bodyText>
<sectionHeader confidence="0.999602" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999961545454545">
The system processes the 513 sentences interac-
tively. It begins by running the DIPETT parser.
Next, it extracts syntactic units (clauses, phrases,
words) and pairs them up according to the informa-
tion in the parse tree. Each unit is represented by
its head word. Next, the system checks if the same
pair of word lemmas has already been processed, to
propose the same relation(s) to the user as options.
If not, the system builds a graph centered on the
head word, and proceeds with the matching on pre-
viously encountered instances, as described in sec-
tion 4. When a set of candidates has been found, the
system goes through a dialogue with the user.
The system generated 2020 pairs from the 513
sentences. The experiment was run in 5 interactive
sessions of approximately 3 hours each. The total
net processing time was 6 hours, 42 minutes and 52
seconds4. While it would have been instructive to
run the system several times with different users, it
was not feasible. The experiment was run once, with
two cooperating users. They were instructed on the
set of semantic relations, and told how the system
works. They discussed the semantic relation assign-
ment and, once agreed, compared the system’s sug-
gestion with their decision.
DIPETT did not produce a complete parse for all
sentences. When a complete parse (correct or incor-
rect) was not possible, DIPETT produced fragmen-
tary parses. The semantic analyser extracted units
even from tree fragments, although sometimes the
fragments were too small to accommodate any pairs.
Of the 513 input sentences, 441 had a parse tree that
allowed the system to extract pairs.
</bodyText>
<footnote confidence="0.961448">
4The time difference accounts for system processing times,
and user interaction for other steps of the analysis.
</footnote>
<table confidence="0.999463818181818">
# of analyzed examples 1475
level statistics CL IC NP
64 978 433
user actions accept choose supply
459 393 623
avg. # of suggestions 2.81
graph-matching usage 933
level/action statistics CL IC NP
accept 183 (19.61%) 9 141 33
choose 349 (37.41%) 23 314 12
supply 401 (42.98%) 27 316 58
</table>
<tableCaption confidence="0.99993">
Table 1: Summary of semantic analysis
</tableCaption>
<bodyText confidence="0.990399425">
Of 2020 pairs generated, the users discarded 545
in the dialogue step. An example of an erroneous
pair comes from the sentence:
Tiny clouds drift across like feathers on parade.
The semantic analyser produced the pair
(drift,parade), because of a parsing error: pa-
rade was parsed as a complement of drift, instead
of a post-modifier for feathers. The correct pairing
(feather,parade) is missing, because it cannot be
inferred from the parse tree.
Table 1 gives a summary of the processing statis-
tics. We observe that graph-matching was used to
process a clear majority of the total pairs extracted –
63.25% (933/1475) , leaving the remaining 36.75%
for the other two heuristics and for cases where no
suggestion could be made. In 57.02% of the situa-
tions when graph-matching was used, the system’s
suggestion contained the correct answer (user’s ac-
tion was either accept or choose), and in 19.61% of
the situations a single correct semantic relation was
proposed (user action was accept).
When the system presents multiple suggestions to
the user, including the correct one, the average num-
ber of suggestions is 3.75. The small number of
suggestions shows that the system does not simply
add to the list relations that it has previously encoun-
tered, but it learns from past experience and graph-
matching helps it make good selections. Figure 2
plots the difference between the number of exam-
ples for which the system gives the correct answer
(possibly among other suggestions) and the number
of examples when the user must supply the correct
relation, from the first example processed until the
end of the experiment. We observe a steady increase
in the number of correctly processed examples.
Our system does not differentiate between syntac-
tic levels, but based on the structures of the syntac-
tic units in each pair we can decide which syntactic
level it pertains to. For a more in-depth analysis, we
have separated the results for each syntactic level,
</bodyText>
<figure confidence="0.983717103448276">
air pilots bring
know
(v, svo)
86
600
Cummulative number of examples
500
400
300
200
100
0
Difference in number of examples
140
120
100
-20
80
40
20
60
0
0 100 200 300 400 500 600 700 800 900 1000
Examples processed
1. All syntactic levels
accept+choose
supply
0 100 200 300 400 500 600 700 800 900 1000
Examples processed
</figure>
<figureCaption confidence="0.882914">
Figure 2: Difference between the number of situa-
tions in which the user accepts or chooses from the
system’s suggestions, and when it must supply the
correct relation
</figureCaption>
<bodyText confidence="0.998486647058824">
and present them for comparison in Figure 3.
We observe that the intra-clause level – verbs
and their arguments – makes the best use of graph-
matching, with the curve showing the cumulative
number of situations in which the system makes cor-
rect predictions becoming steeper as more text is
processed. At the same time, the curve that plots the
cumulative number of cases in which the user has to
supply a correct answer begins to level off. As ex-
pected, at the noun-phrase level where the syntactic
structures are very simple, often consisting of only
the noun and its modifier (without even a connec-
tive), the graph-matching algorithm does not help as
much. At the inter-clause level the heuristic helps,
as shown by the marginally higher curve for cumula-
tive accept/choose user actions, compared to supply
actions.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999411176470588">
We have shown through the results gathered from an
interactive and incremental text processing system
that syntactic-semantic graph-matching can be used
with good results for semantic analysis of texts. The
graph-matching heuristic clearly dominates other
heuristics used, and it learns to make better predic-
tions as more examples accumulate.
Graph-matching is most useful for assigning se-
mantic relations between verbs and their arguments,
but it also gives good results for inter-clause rela-
tions. At the noun-phrase level, we could only tackle
noun-modifier pairs that exhibit a modicum of syn-
tactic structure – a connective. For base NPs there
is practically nothing that syntactic information can
bring to the semantic analysis process.
The graph-matching process could be improved
by bringing into play freely available lexical re-
</bodyText>
<figure confidence="0.9738635">
2. Clause level (CL)
0 10 20 30 40 50 60
Examples processed
3. Intra-clause level (IC)
0 100 200 300 400 500 600 700 800
Examples processed
4. Noun phrase level
(NP)
0 20 40 60 80 100 120
Examples processed
</figure>
<figureCaption confidence="0.9536425">
Figure 3: Graph-matching for different syntactic
levels
</figureCaption>
<figure confidence="0.9931792">
Cummulative number of examples
35
30
25
20
15
10
5
0
accept+choose
supply
Cummulative number of examples
500
450
400
350
300
250
200
150
100
50
0
accept+choose
supply
Cummulative number of examples
50
40
30
20
60
10
0
accept+choose
supply
</figure>
<bodyText confidence="0.999892142857143">
sources. For now, the actual words in the graph
nodes are not used at all. We could use WordNet
to compute word similarities, to select closer match-
ing graphs. VerbNet or FrameNet information could
help choose graphs centered on verbs with simi-
lar syntactic behaviour, as captured by Levin’s verb
groups (Levin, 1993) which are the basis of VerbNet.
</bodyText>
<sectionHeader confidence="0.999188" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999941952380952">
Jordi Atserias, L. Padr´o, and German Rigau. 2001. Integrating
multiple knowledge sources for robust semantic parsing. In
Proceedings of RANLP - 2001, Tsigov Czark, Bulgaria.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998.
The Berkeley FrameNet project. In COLING-ACL, pages
86–90, Montreal, Canada.
Ken Barker, Terry Copeck, Sylvain Delisle, and Stan Szpakow-
icz. 1997a. Systematic construction of a versatile case sys-
tem. Journal of Natural Language Engineering, 3(4):279–
315.
Ken Barker, Sylvain Delisle, and Stan Szpakowicz. 1997b.
Test-driving TANKA: Evaluating a semi-automatic system
of text analysis for knowledge acquisition. In Proceedings
of CAI 1997, pages 60–71, Vancouver, BC, Canada.
Xavier Carreras and Lluis Marquez, editors. 2004. Introduction
to the CoNLL-2004 Shared Task: Semantic Role Labelling.
Boston, MA, USA.
Xavier Carreras and Lluis Marquez, editors. 2005. Introduction
to the CoNLL-2005 Shared Task: Semantic Role Labelling.
Ann Arbour, MI, USA.
Noam Chomsky. 1970. Remarks on nominalizations. In Rod-
erick Jacobs and Peter Rosenbaum, editors, Readings in En-
glish Transformational Grammar, pages 184–221. Ginn and
Co., Waltham, MA, USA.
Peter Clark and Bruce Porter. 1997. Building concept reprezen-
tations from reusable components. In AAAI, pages 367–376,
Providence, Rhode Island.
Sylvain Delisle and Stan Szpakowicz. 1995. Realistic pars-
ing: Practical solutions of difficult problems. In PACLING,
Brisbane, Queensland, Australia.
Sylvain Delisle, Terry Copeck, Stan Szpakowicz, and Ken
Barker. 1993. Pattern matching for case analysis: A com-
putational definition of closeness. In ICCI, pages 310–315,
Sudbury, ON, Canada.
Charles Fillmore and Beryl T. Atkins. 1998. FrameNet and
lexicographic relevance. In Proceedings of the 1st Interna-
tional Conference on Language Resources and Evaluation,
Granada, Spain.
Charles Fillmore. 1968. The case for case. In Emmond Bach
and Robert T. Harms, editors, Universals in Linguistic The-
ory, pages 1–88. Holt, Rinehart and Winston.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling
of semantic roles. Computational Linguistics, 28(3):245–
288.
Fernando Gomez. 1998. A representation of complex events
and processes for the acquisition of knowledge from text.
Kowledge-Based Systems, 10(4):237–251.
Jeffrey Gruber. 1965. Studies in Lexical Relations. Ph.D.
thesis, MIT, Cambridge, MA. Reprinted in Jeffrey Gru-
ber. 1976. Lexical Structures in Syntax and Semantics. Part
I. North-Holland Publishing Company, Amsterdam.
Richard D. Hull and Fernando Gomez. 1996. Semantic inter-
pretation of nominalizations. In 13th National Conference
on Artificial Intelligence, pages 1062–1068, Portland, Ore-
gon, USA.
Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000.
Class-based construction of a verb lexicon. In AAAI/IAAI,
pages 691–696.
Nancy Larrick. 1961. Junior Science Book of Rain, Hail, Sleet
and Snow. Garrard Publishing Company, Champaign, Illi-
nois.
Beth Levin. 1993. English Verb Classes and Alternations. Uni-
versity of Chicago Press.
Vidya Niwas Misra. 1966. The Descriptive Technique of
Panini. Mouton, The Hague.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Mar-
tin, and Daniel Jurafsky. 2005. Semantic role labelling us-
ing different syntactic views. In Proceedings of ACL 2005,
pages 581–588, Ann Arbour, MI, USA.
Randolph Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan
Svartvik. 1985. A Comprehensive Grammar of the English
Language. Longman, London and New York.
Barbara Rosario and Marti Hearst. 2001. Classifying the se-
mantic relations in noun-compounds via a domain specific
hierarchy. In EMNLP, pages 82–90, Pittsburg, PA, USA.
Barbara Rosario, Marti Hearst, and Charles Fillmore. 2002.
The descent of hierarchy and selection in relational seman-
tics. In ACL, Philadelphia, PA, USA.
Lei Shi and Rada Mihalcea. 2005. Putting pieces together:
Combining framenet, verbnet and wordnet for robust seman-
tic parsing. In Proceedings of CICLing 2005, pages 100–
111, Mexico City, Mexico.
Lucien Tesni`ere. 1959. ´El´ements de syntaxe structurale. C.
Klincksieck, Paris.
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.805321">
<title confidence="0.999945">Matching Syntactic-Semantic Graphs for Semantic Relation Assignment</title>
<author confidence="0.99793">Stan</author>
<affiliation confidence="0.95151">of Information Technology and University of Ottawa, Ottawa, of Computer Polish Academy of Sciences, Warsaw,</affiliation>
<abstract confidence="0.99894512">We present a graph-matching algorithm for semantic relation assignment. The algorithm is part of an interactive text analysis system. The system automatically extracts pairs of syntactic units from a text and assigns a semantic relation to each pair. This is an incremental learning algorithm, in which previously processed pairs and user feedback guide the process. After each assignment, the system adds to its database a syntactic-semantic graph centered on the main element of each pair of units. A graph consists of the main unit and all syntactic units with which it is syntactically connected. An edge contains information both about syntax and about semantic relations for use in further processing. Syntactic-semantic graph matching is used to produce a list of candidate assignments for 63.75% of the pairs analysed, and in 57% of situations the correct relations is one of the system’s suggestions; in 19.6% of situations it suggests only the correct relation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>L Padr´o</author>
<author>German Rigau</author>
</authors>
<title>Integrating multiple knowledge sources for robust semantic parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of RANLP -</booktitle>
<institution>Tsigov Czark, Bulgaria.</institution>
<marker>Atserias, Padr´o, Rigau, 2001</marker>
<rawString>Jordi Atserias, L. Padr´o, and German Rigau. 2001. Integrating multiple knowledge sources for robust semantic parsing. In Proceedings of RANLP - 2001, Tsigov Czark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In COLING-ACL,</booktitle>
<pages>86--90</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2009" citStr="Baker et al., 1998" startWordPosition="319" endWordPosition="322">s is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal s</context>
<context position="4930" citStr="Baker et al., 1998" startWordPosition="789" endWordPosition="792">ic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge base</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In COLING-ACL, pages 86–90, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Barker</author>
<author>Terry Copeck</author>
<author>Sylvain Delisle</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Systematic construction of a versatile case system.</title>
<date>1997</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>315</pages>
<contexts>
<context position="4046" citStr="Barker et al., 1997" startWordPosition="649" endWordPosition="652">r of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the current syntactic graph. We have a list of 47 relations that manifest themselves in compound clauses, inside a simple clause or in noun phrases. The list, a synthesis of a number of relation lists cited in the literature, has been designed to be general, domainindependent (Barker et al., 1997a). Section 2 overviews research in semantic relation analysis. Section 3 describes the text we used in ex81 Workshop on TextGraphs, at HLT-NAACL 2006, pages 81–88, New York City, June 2006. c�2006 Association for Computational Linguistics periments, and the semantic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and i</context>
<context position="11334" citStr="Barker et al., 1997" startWordPosition="1824" endWordPosition="1827">ystem will present an empty list, and expect the user to input the appropriate relation. When at least one relation is proposed, the user can accept a unique relation, choose among several options, or supply a new one. The system records which action took place, as well as the heuristic that generated the options presented to the user. The pair is also analysed to determine the syntactic level from which it came, to allow for a more detailed analysis of the behaviour of the system. 3.2 Semantic relations The list of semantic relations with which we work is based on extensive literature study (Barker et al., 1997a). Three lists of relations for three syntactic levels – inter-clause, intra-clause (case) and nounmodifier relations – were next combined based on syntactic and semantic phenomena. The resulting list is the one used in the experiments we present in this paper. The relations are grouped by general similarity into 6 relation classes (H denotes the head of a base NP, M denotes the modifier). 1. CAUSAL groups relations enabling or opposing an occurrence. Examples: cause - H causes M: flu virus; effect - H is the effect (was caused by) M: exam anxiety; purpose - H is for M: concert hall; 2. CONJU</context>
<context position="13963" citStr="Barker et al., 1997" startWordPosition="2282" endWordPosition="2285">consensus in the literature on a list of semantic relations that would work in all situations. This is, no doubt, because a general list of relations such as the one we use would not be appropriate for the semantic analysis of texts in a specific domain, such as for example medical texts. All the relations in the list we use were necessary, and sufficient, for the analysis of the input text. 4 Syntactic-semantic graph-matching Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text. This design idea was adopted from TANKA (Barker et al., 1997b). The only manually encoded knowledge is a dictionary of markers (subordinators, coordinators, prepositions). This resource does not affect the syntacticsemantic graph-matching heuristic. Because the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears </context>
</contexts>
<marker>Barker, Copeck, Delisle, Szpakowicz, 1997</marker>
<rawString>Ken Barker, Terry Copeck, Sylvain Delisle, and Stan Szpakowicz. 1997a. Systematic construction of a versatile case system. Journal of Natural Language Engineering, 3(4):279– 315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Barker</author>
<author>Sylvain Delisle</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Test-driving TANKA: Evaluating a semi-automatic system of text analysis for knowledge acquisition.</title>
<date>1997</date>
<booktitle>In Proceedings of CAI</booktitle>
<pages>60--71</pages>
<location>Vancouver, BC,</location>
<contexts>
<context position="4046" citStr="Barker et al., 1997" startWordPosition="649" endWordPosition="652">r of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the current syntactic graph. We have a list of 47 relations that manifest themselves in compound clauses, inside a simple clause or in noun phrases. The list, a synthesis of a number of relation lists cited in the literature, has been designed to be general, domainindependent (Barker et al., 1997a). Section 2 overviews research in semantic relation analysis. Section 3 describes the text we used in ex81 Workshop on TextGraphs, at HLT-NAACL 2006, pages 81–88, New York City, June 2006. c�2006 Association for Computational Linguistics periments, and the semantic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and i</context>
<context position="11334" citStr="Barker et al., 1997" startWordPosition="1824" endWordPosition="1827">ystem will present an empty list, and expect the user to input the appropriate relation. When at least one relation is proposed, the user can accept a unique relation, choose among several options, or supply a new one. The system records which action took place, as well as the heuristic that generated the options presented to the user. The pair is also analysed to determine the syntactic level from which it came, to allow for a more detailed analysis of the behaviour of the system. 3.2 Semantic relations The list of semantic relations with which we work is based on extensive literature study (Barker et al., 1997a). Three lists of relations for three syntactic levels – inter-clause, intra-clause (case) and nounmodifier relations – were next combined based on syntactic and semantic phenomena. The resulting list is the one used in the experiments we present in this paper. The relations are grouped by general similarity into 6 relation classes (H denotes the head of a base NP, M denotes the modifier). 1. CAUSAL groups relations enabling or opposing an occurrence. Examples: cause - H causes M: flu virus; effect - H is the effect (was caused by) M: exam anxiety; purpose - H is for M: concert hall; 2. CONJU</context>
<context position="13963" citStr="Barker et al., 1997" startWordPosition="2282" endWordPosition="2285">consensus in the literature on a list of semantic relations that would work in all situations. This is, no doubt, because a general list of relations such as the one we use would not be appropriate for the semantic analysis of texts in a specific domain, such as for example medical texts. All the relations in the list we use were necessary, and sufficient, for the analysis of the input text. 4 Syntactic-semantic graph-matching Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text. This design idea was adopted from TANKA (Barker et al., 1997b). The only manually encoded knowledge is a dictionary of markers (subordinators, coordinators, prepositions). This resource does not affect the syntacticsemantic graph-matching heuristic. Because the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears </context>
</contexts>
<marker>Barker, Delisle, Szpakowicz, 1997</marker>
<rawString>Ken Barker, Sylvain Delisle, and Stan Szpakowicz. 1997b. Test-driving TANKA: Evaluating a semi-automatic system of text analysis for knowledge acquisition. In Proceedings of CAI 1997, pages 60–71, Vancouver, BC, Canada.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>Introduction to the CoNLL-2004 Shared Task: Semantic Role Labelling.</booktitle>
<editor>Xavier Carreras and Lluis Marquez, editors.</editor>
<location>Boston, MA, USA.</location>
<marker>2004</marker>
<rawString>Xavier Carreras and Lluis Marquez, editors. 2004. Introduction to the CoNLL-2004 Shared Task: Semantic Role Labelling. Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis Marquez</author>
<author>editors</author>
</authors>
<date>2005</date>
<booktitle>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labelling.</booktitle>
<location>Ann Arbour, MI, USA.</location>
<marker>Carreras, Marquez, editors, 2005</marker>
<rawString>Xavier Carreras and Lluis Marquez, editors. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labelling. Ann Arbour, MI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Remarks on nominalizations.</title>
<date>1970</date>
<booktitle>Readings in English Transformational Grammar,</booktitle>
<pages>184--221</pages>
<editor>In Roderick Jacobs and Peter Rosenbaum, editors,</editor>
<location>Waltham, MA, USA.</location>
<contexts>
<context position="3132" citStr="Chomsky, 1970" startWordPosition="496" endWordPosition="497">ct connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 1966; Gruber, 1965; Fillmore, 1968). Tesni`ere (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants – for example, agent or instrument – to such grammatical elements as subject, direct object, indirect object. This idea was expanded to include nouns and their modifiers through verb nominalizations (Chomsky, 1970; Quirk et al., 1985). We work with sentences, clauses, phrases and words, using syntactic structures generated by a parser. Our system incrementally processes a text, and extracts pairs of text units: two clauses, a verb and each of its arguments, a noun and each of its modifiers. For each pair of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semanti</context>
</contexts>
<marker>Chomsky, 1970</marker>
<rawString>Noam Chomsky. 1970. Remarks on nominalizations. In Roderick Jacobs and Peter Rosenbaum, editors, Readings in English Transformational Grammar, pages 184–221. Ginn and Co., Waltham, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Bruce Porter</author>
</authors>
<title>Building concept reprezentations from reusable components.</title>
<date>1997</date>
<booktitle>In AAAI,</booktitle>
<pages>367--376</pages>
<location>Providence, Rhode Island.</location>
<contexts>
<context position="5612" citStr="Clark and Porter, 1997" startWordPosition="895" endWordPosition="898">ored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles – relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al., 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez,</context>
</contexts>
<marker>Clark, Porter, 1997</marker>
<rawString>Peter Clark and Bruce Porter. 1997. Building concept reprezentations from reusable components. In AAAI, pages 367–376, Providence, Rhode Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Delisle</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Realistic parsing: Practical solutions of difficult problems.</title>
<date>1995</date>
<booktitle>In PACLING,</booktitle>
<location>Brisbane, Queensland, Australia.</location>
<contexts>
<context position="9115" citStr="Delisle and Szpakowicz, 1995" startWordPosition="1462" endWordPosition="1465">ch. The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-class words) shows that the same concepts recur, as expected in a didactic text. The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information, DIPETT (Delisle and Szpakowicz, 1995). The parser, written in Prolog, implements a classic constituency English grammar from Quirk et al. (1985). Pairs of syntactic units connected by grammatical relations are extracted from the parse trees. A dependency parser would 82 produce a similar output, but DIPETT also provides verb subcategorization information (such as, for example, subject-verb-object or subject-verb-objectindirect object), which we use to select the (best) matching syntactic structures. To find pairs, we use simple structural information. If a unit is directly embedded in another unit, we assume a subordinate relatio</context>
</contexts>
<marker>Delisle, Szpakowicz, 1995</marker>
<rawString>Sylvain Delisle and Stan Szpakowicz. 1995. Realistic parsing: Practical solutions of difficult problems. In PACLING, Brisbane, Queensland, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Delisle</author>
<author>Terry Copeck</author>
<author>Stan Szpakowicz</author>
<author>Ken Barker</author>
</authors>
<title>Pattern matching for case analysis: A computational definition of closeness.</title>
<date>1993</date>
<booktitle>In ICCI,</booktitle>
<pages>310--315</pages>
<location>Sudbury, ON,</location>
<contexts>
<context position="14777" citStr="Delisle et al. (1993)" startWordPosition="2411" endWordPosition="2414">ause the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears as the main element in a processed pair. To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P. This idea was inspired by Delisle et al. (1993), who used a list of arguments surrounding the main verb together with the verb’s subcategorization information and previously processed examples to analyse semantic roles (case relations). In recent approaches, syntactic information is translated into features which, together with information from FrameNet, WordNet or VerbNet, will be used with ML tools to make predictions for each example in the test set (Carreras and Marquez, 2004; Carreras and Marquez, 2005). Our system builds a (simple) graph surrounding a head word (which may be a verb – representing the predicate of a sentence, or repre</context>
</contexts>
<marker>Delisle, Copeck, Szpakowicz, Barker, 1993</marker>
<rawString>Sylvain Delisle, Terry Copeck, Stan Szpakowicz, and Ken Barker. 1993. Pattern matching for case analysis: A computational definition of closeness. In ICCI, pages 310–315, Sudbury, ON, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Fillmore</author>
<author>Beryl T Atkins</author>
</authors>
<title>FrameNet and lexicographic relevance.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st International Conference on Language Resources and Evaluation,</booktitle>
<location>Granada,</location>
<contexts>
<context position="5195" citStr="Fillmore and Atkins, 1998" startWordPosition="831" endWordPosition="834">en graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary</context>
</contexts>
<marker>Fillmore, Atkins, 1998</marker>
<rawString>Charles Fillmore and Beryl T. Atkins. 1998. FrameNet and lexicographic relevance. In Proceedings of the 1st International Conference on Language Resources and Evaluation, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Fillmore</author>
</authors>
<title>The case for case.</title>
<date>1968</date>
<booktitle>Universals in Linguistic Theory,</booktitle>
<pages>1--88</pages>
<editor>In Emmond Bach and Robert T. Harms, editors,</editor>
<publisher>Holt, Rinehart and Winston.</publisher>
<contexts>
<context position="1765" citStr="Fillmore, 1968" startWordPosition="279" endWordPosition="281">of situations the correct relations is one of the system’s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clau</context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Charles Fillmore. 1968. The case for case. In Emmond Bach and Robert T. Harms, editors, Universals in Linguistic Theory, pages 1–88. Holt, Rinehart and Winston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>288</pages>
<contexts>
<context position="5222" citStr="Gildea and Jurafsky, 2002" startWordPosition="835" endWordPosition="838">sign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semant</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245– 288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Gomez</author>
</authors>
<title>A representation of complex events and processes for the acquisition of knowledge from text.</title>
<date>1998</date>
<journal>Kowledge-Based Systems,</journal>
<volume>10</volume>
<issue>4</issue>
<contexts>
<context position="5087" citStr="Gomez, 1998" startWordPosition="816" endWordPosition="817"> when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and mani</context>
</contexts>
<marker>Gomez, 1998</marker>
<rawString>Fernando Gomez. 1998. A representation of complex events and processes for the acquisition of knowledge from text. Kowledge-Based Systems, 10(4):237–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Gruber</author>
</authors>
<title>Studies in Lexical Relations.</title>
<date>1965</date>
<booktitle>Lexical Structures in Syntax</booktitle>
<tech>Ph.D. thesis,</tech>
<publisher>North-Holland Publishing Company,</publisher>
<institution>MIT,</institution>
<location>Cambridge, MA.</location>
<note>Reprinted in</note>
<contexts>
<context position="1748" citStr="Gruber, 1965" startWordPosition="277" endWordPosition="278">d, and in 57% of situations the correct relations is one of the system’s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs</context>
</contexts>
<marker>Gruber, 1965</marker>
<rawString>Jeffrey Gruber. 1965. Studies in Lexical Relations. Ph.D. thesis, MIT, Cambridge, MA. Reprinted in Jeffrey Gruber. 1976. Lexical Structures in Syntax and Semantics. Part I. North-Holland Publishing Company, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard D Hull</author>
<author>Fernando Gomez</author>
</authors>
<title>Semantic interpretation of nominalizations.</title>
<date>1996</date>
<booktitle>In 13th National Conference on Artificial Intelligence,</booktitle>
<pages>1062--1068</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="5245" citStr="Hull and Gomez, 1996" startWordPosition="839" endWordPosition="842"> clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, t</context>
</contexts>
<marker>Hull, Gomez, 1996</marker>
<rawString>Richard D. Hull and Fernando Gomez. 1996. Semantic interpretation of nominalizations. In 13th National Conference on Artificial Intelligence, pages 1062–1068, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-based construction of a verb lexicon. In</title>
<date>2000</date>
<booktitle>AAAI/IAAI,</booktitle>
<pages>691--696</pages>
<contexts>
<context position="2030" citStr="Kipper et al., 2000" startWordPosition="323" endWordPosition="326">e first chronicled endeavour to connect text elements and organise connections between them goes back to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stanc</context>
<context position="5975" citStr="Kipper et al., 2000" startWordPosition="952" endWordPosition="955">apture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles – relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al., 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al., 2005) to assign a label to a new </context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-based construction of a verb lexicon. In AAAI/IAAI, pages 691–696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Larrick</author>
</authors>
<title>Junior Science Book of</title>
<date>1961</date>
<publisher>Garrard Publishing Company,</publisher>
<location>Rain, Hail, Sleet</location>
<contexts>
<context position="8278" citStr="Larrick, 1961" startWordPosition="1325" endWordPosition="1326">sing the current system configuration, the effect of syntactic information and incremental learning on semantic analysis. This is described in section 5. Because of these differences in the type of data used, and in the learning approach, the results we obtain cannot be compared to previous approaches. In order to show that the system does learn, we show that the number of examples for which it provides the correct answer increases with the number of examples previously analysed. 3 Input data and semantic relations 3.1 Input data We work with a semi-technical text on meteorological phenomena (Larrick, 1961), meant for primary school students. The text gradually introduces concepts related to precipitation, and explains them. Its nature makes it appropriate for the semantic analysis task in an incremental approach. The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-clas</context>
</contexts>
<marker>Larrick, 1961</marker>
<rawString>Nancy Larrick. 1961. Junior Science Book of Rain, Hail, Sleet and Snow. Garrard Publishing Company, Champaign, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>University of Chicago Press.</publisher>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vidya Niwas Misra</author>
</authors>
<title>The Descriptive Technique of Panini.</title>
<date>1966</date>
<publisher>Mouton, The Hague.</publisher>
<contexts>
<context position="1617" citStr="Misra, 1966" startWordPosition="257" endWordPosition="258">er processing. Syntactic-semantic graph matching is used to produce a list of candidate assignments for 63.75% of the pairs analysed, and in 57% of situations the correct relations is one of the system’s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text</context>
</contexts>
<marker>Misra, 1966</marker>
<rawString>Vidya Niwas Misra. 1966. The Descriptive Technique of Panini. Mouton, The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>Kadri Hacioglu</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Semantic role labelling using different syntactic views.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>581--588</pages>
<location>Ann Arbour, MI, USA.</location>
<contexts>
<context position="6304" citStr="Pradhan et al., 2005" startWordPosition="1004" endWordPosition="1007">anipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles – relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al., 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al., 2005) to assign a label to a new instance. Labelling every instance relies on the same previously encoded knowledge (see (Carreras and Marquez, 2004; Carreras and Marquez, 2005) for an overview of the systems in the semantic role labelling competitions from 2004 and 2005). Pradhan et al. (2005) combine the outputs of multiple parsers to extract reliable syntac</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Martin, and Daniel Jurafsky. 2005. Semantic role labelling using different syntactic views. In Proceedings of ACL 2005, pages 581–588, Ann Arbour, MI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffrey Leech</author>
<author>Jan Svartvik</author>
</authors>
<date>1985</date>
<journal>A Comprehensive Grammar of the English Language. Longman,</journal>
<location>London and New York.</location>
<contexts>
<context position="3153" citStr="Quirk et al., 1985" startWordPosition="498" endWordPosition="501">at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 1966; Gruber, 1965; Fillmore, 1968). Tesni`ere (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants – for example, agent or instrument – to such grammatical elements as subject, direct object, indirect object. This idea was expanded to include nouns and their modifiers through verb nominalizations (Chomsky, 1970; Quirk et al., 1985). We work with sentences, clauses, phrases and words, using syntactic structures generated by a parser. Our system incrementally processes a text, and extracts pairs of text units: two clauses, a verb and each of its arguments, a noun and each of its modifiers. For each pair of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the </context>
<context position="9222" citStr="Quirk et al. (1985)" startWordPosition="1478" endWordPosition="1481">rocess ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-class words) shows that the same concepts recur, as expected in a didactic text. The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information, DIPETT (Delisle and Szpakowicz, 1995). The parser, written in Prolog, implements a classic constituency English grammar from Quirk et al. (1985). Pairs of syntactic units connected by grammatical relations are extracted from the parse trees. A dependency parser would 82 produce a similar output, but DIPETT also provides verb subcategorization information (such as, for example, subject-verb-object or subject-verb-objectindirect object), which we use to select the (best) matching syntactic structures. To find pairs, we use simple structural information. If a unit is directly embedded in another unit, we assume a subordinate relation between them; if the two units are coordinate, we assume a coordinate relation. These assumptions are saf</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Randolph Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti Hearst</author>
</authors>
<title>Classifying the semantic relations in noun-compounds via a domain specific hierarchy.</title>
<date>2001</date>
<booktitle>In EMNLP,</booktitle>
<pages>82--90</pages>
<location>Pittsburg, PA, USA.</location>
<contexts>
<context position="5059" citStr="Rosario and Hearst, 2001" startWordPosition="809" endWordPosition="812">nd shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert</context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>Barbara Rosario and Marti Hearst. 2001. Classifying the semantic relations in noun-compounds via a domain specific hierarchy. In EMNLP, pages 82–90, Pittsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti Hearst</author>
<author>Charles Fillmore</author>
</authors>
<title>The descent of hierarchy and selection in relational semantics.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="5307" citStr="Rosario et al., 2002" startWordPosition="850" endWordPosition="853">) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system’s interface facilitates the expert’s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles – relations between verbs and th</context>
</contexts>
<marker>Rosario, Hearst, Fillmore, 2002</marker>
<rawString>Barbara Rosario, Marti Hearst, and Charles Fillmore. 2002. The descent of hierarchy and selection in relational semantics. In ACL, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of CICLing 2005,</booktitle>
<pages>100--111</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="2134" citStr="Shi and Mihalcea, 2005" startWordPosition="339" endWordPosition="342">k to the 51h century B.C. and the work of Paninil. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesni`ere, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic &apos;The sources date his work variously between the 5th and 7th century. role labelling (Baker et al., 1998; Kipper et al., 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al., 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one’s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 19</context>
<context position="6329" citStr="Shi and Mihalcea, 2005" startWordPosition="1008" endWordPosition="1011"> which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles – relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al., 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al., 2005) to assign a label to a new instance. Labelling every instance relies on the same previously encoded knowledge (see (Carreras and Marquez, 2004; Carreras and Marquez, 2005) for an overview of the systems in the semantic role labelling competitions from 2004 and 2005). Pradhan et al. (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is</context>
</contexts>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. 2005. Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing. In Proceedings of CICLing 2005, pages 100– 111, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucien Tesni`ere</author>
</authors>
<title>El´ements de syntaxe structurale.</title>
<date>1959</date>
<journal>C. Klincksieck,</journal>
<location>Paris.</location>
<marker>Tesni`ere, 1959</marker>
<rawString>Lucien Tesni`ere. 1959. ´El´ements de syntaxe structurale. C. Klincksieck, Paris.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>