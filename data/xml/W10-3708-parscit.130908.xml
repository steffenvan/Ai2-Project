<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009482">
<title confidence="0.9726725">
Application of the Tightness Continuum Measure
to Chinese Information Retrieval
</title>
<author confidence="0.999764">
Ying Xu†, Randy Goebel†, Christoph Ringlstetter‡ and Grzegorz Kondrak†
</author>
<affiliation confidence="0.984481666666667">
†Department of Computing Science ‡Center for Language and
University of Alberta Information Processing (CIS)
Ludwig Maximilians University
</affiliation>
<email confidence="0.985932">
{yx2,goebel,kondrak}@cs.ualberta.ca kristof@cis.uni-muenchen.de
</email>
<sectionHeader confidence="0.997223" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999794045454546">
Most word segmentation methods em-
ployed in Chinese Information Retrieval
systems are based on a static dictionary
or a model trained against a manually
segmented corpus. These general seg-
mentation approaches may not be opti-
mal because they disregard information
within semantic units. We propose a novel
method for improving word-based Chi-
nese IR, which performs segmentation ac-
cording to the tightness of phrases. In
order to evaluate the effectiveness of our
method, we employ a new test collection
of 203 queries, which include a broad dis-
tribution of phrases with different tight-
ness values. The results of our experi-
ments indicate that our method improves
IR performance as compared with a gen-
eral word segmentation approach. The ex-
periments also demonstrate the need for
the development of better evaluation cor-
pora.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999816976744186">
What distinguishes Chinese Information Retrieval
from information retrieval (IR) in other languages
is the challenge of segmenting the queries and the
documents, created by the lack of word delimiters.
In general, there are two categories of segmenters:
character-based methods and word-based meth-
ods. Despite the superior performance of bigram
segmenters (Nie et al., 2000; Huang et al., 2000;
Foo and Li, 2004), word-based approaches con-
tinue to be investigated because of their applica-
tion in sophisticated IR tasks such as cross lan-
guage IR, and within techniques such as query ex-
pansion (Nie et al., 2000; Peng et al., 2002a).
Most word-based segmenters in Chinese IR are
either rule-based models, which rely on a lexi-
con, or statistical-based models, which are trained
on manually segmented corpora (Zhang et al.,
2003). However, the relationship between the ac-
curacy of Chinese word segmentation and the per-
formance of Chinese IR is non-monotonic. Peng
et al. (2002b) reported that segmentation meth-
ods achieving segmentation accuracy higher than
90% according to a manual segmentation standard
yield no improvement in IR performance. They
further argued that IR often benefits from splitting
compound words that are annotated as single units
by manual segmentation.
The essence of the problem is that there is no
clear definition of word in Chinese. Experiments
have shown only about 75% agreement among na-
tive speakers regarding the correct word segmen-
tation (Sproat et al., 1996). While units such as
“��” (peanut) and “�T�9A” (match maker)
should clearly be considered as a single term in
Chinese IR, compounds such as “� * (ma-
chine learning) are more controversial.&apos;
Xu et al. (2009) proposed a “continuum hy-
pothesis” that rejects a clean binary classifica-
tion of Chinese semantic units as either compo-
sitional or non-compositional. Instead, they intro-
duced the notion of a tightness measure, which
quantifies the degree of compositionality. On
this tightness continuum, at one extreme are non-
</bodyText>
<footnote confidence="0.600894">
&apos;This issue is also present to a certain degree in languages
that do use explicit delimiters, including English (Halpern,
2000; McCarthy et al., 2003; Guenthner and Blanco, 2004).
</footnote>
<page confidence="0.979471">
55
</page>
<note confidence="0.8644975">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63,
Beijing, August 2010
</note>
<bodyText confidence="0.999859441860465">
compositional semantic units, such as “AT�9
A” (match maker), and at the other end are se-
quences of consecutive words with no depen-
dency relationship, such as “± 9P4” (Shang-
hai where). In the middle of the spectrum are
compositional compounds such as “K *%1”
(machine learning) and phrases such as “1EA�C
A” (legitimate income).
In this paper, we propose a method to ap-
ply the concept of semantic tightness to Chinese
IR, which refines the output of a general Chi-
nese word segmenter using tightness information.
In the first phase, we re-combine multiple units
that are considered semantically tight into single
terms. In the second phase, we break single units
that are not sufficiently tight. The experiments in-
volving two different IR systems demonstrate that
the new method improves IR performance as com-
pared to the general segmenter.
Most Chinese IR systems are evaluated on the
data from the TREC 5 and TREC 6 competi-
tions (Huang et al., 2000; Huang et al., 2003;
Nie et al., 2000; Peng et al., 2002a; Peng et al.,
2002b; Shi and Nie, 2009). That data contains
only 54 queries, which are linked to relevancy-
judged documents. During our experiments, we
found the TREC query data is ill-suited for ana-
lyzing the effects of compound segmentation on
Chinese IR. For this reason, we created an addi-
tional set of queries based on the TREC corpus,
which includes a wide variety of semantic com-
pounds.
This paper is organized as follows. After sum-
marizing related work on Chinese IR and word
segmentation studies, we introduce the measure
of semantic tightness. Section 4 describes the in-
tegration of the semantic tightness measure into
an IR system. Section 5 discusses the available
data for Chinese IR evaluation, as well as an ap-
proach to acquire new data. Section 6 presents the
results of our method on word segmentation and
IR. A short conclusion wraps up and gives direc-
tions for future work.
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999740333333334">
The impact of different Chinese word segmen-
tation methods on IR has received extensive at-
tention in the literature (Nie et al., 2000; Peng
et al., 2002a; Peng et al., 2002b; Huang et al.,
2000; Huang et al., 2003; Liu et al., 2008; Shi
and Nie, 2009). For example, Foo and Li (2004)
tested the effects of manual segmentation and var-
ious character-based segmentations. In contrast
with most related work that only reports the over-
all performance, they provide an in-depth analysis
of query results. They note that a small test col-
lection diminishes the significance of the results.
In a series of papers on Chinese IR, Peng
and Huang compared various segmentation meth-
ods in IR, and proposed a new segmentation
method (Peng et al., 2002a; Peng et al., 2002b;
Huang et al., 2000; Huang et al., 2003). Their
experiments suggest that the relationship between
segmentation accuracy and retrieval performance
is non-monotonic, ranging from 44%-95%. They
hypothesize that weak word segmenters are able
to improve the accuracy of Chinese IR by break-
ing compound words into smaller constituents.
Shi and Nie (2009) proposed a probability-
based IR score function that combines a unigram
score with a word score according to “phrase in-
separability.” Candidates for words in the query
are selected by a standard segmentation program.
Their results show a small improvement in com-
parison with a static combination of unigram and
word methods.
Liu et al. (2008) is the research most similar
to our proposed method. They point out that cur-
rent segmentation methods which treat segmenta-
tion as a classification problem are not suitable
for Chinese IR. They propose a ranking support
vector machine (SVM) model to predict the inter-
nal association strength (IAS) between characters,
which is similar to our concept of tightness. How-
ever, they do not analyze their segmentation ac-
curacy with respect to a standard corpus, such as
Chinese Treebank. Their method does not reliably
segment function words, mistakenly identifying
“�A” (’s people) as tight, for example. Unlike
their approach, our segmentation method tackles
the problem by combining the tightness measure
with a general segmentation method.
Chinese word segmentation is closely related
to multiword expression extraction. McCarthy et
al. (2003) investigate various statistical measures
of compositionality of candidate multiword verbs.
</bodyText>
<page confidence="0.994378">
56
</page>
<bodyText confidence="0.999753923076923">
Silva et al. (1999) propose a new compositional-
ity measure based on statistical information. The
main difference with Xu et al.’s measure is that
the latter is focused on word sense disambigua-
tion. In terms of multiword expressions in IR,
Vechtomova (2001) propose several approaches,
such as query expansion, to incorporating English
multiword expressions in IR. Braschler and Rip-
plinger (2004) analyze the effect of stemming and
decompounding on German text retrieval. How-
ever, Chinese compound segmentation in IR is a
thorny issue and needs more investigation for the
reasons mentioned earlier.
</bodyText>
<sectionHeader confidence="0.994099" genericHeader="method">
3 Semantic Tightness Continuum
</sectionHeader>
<bodyText confidence="0.999959647058824">
We adopt the method developed by (Xu et al.,
2009) for Chinese semantic unit tightness mea-
sure, which was shown to outperform the point-
wise mutual information method. For the sake
of completeness we briefly describe the basic ap-
proach here. The input of the measure is the prob-
ability distribution of a unit’s segmentation pat-
terns, i.e., potential segmentation candidates. The
output is a tightness value; the greater the value,
the tighter the unit. In this paper, we focus on 4-
gram sequences because 4-character compounds
are the most prominent in Chinese. There are
eight possible segmentations of any 4-character
sequence: “ABCD,” “A|BCD,” “A|B|CD,” etc.
For a sequence of n characters, there are 2n−1 po-
tential segmentations. Equation 1 below defines
the tightness measure.
</bodyText>
<equation confidence="0.994563">
♯Pt(s)
M—(♯Pt(s1|s2))+ 1N
if OPt(s) &gt; a
undef otherwise
(1)
</equation>
<bodyText confidence="0.9992867">
In Equation 1, ♯Pt(s) stands for frequencies of
segmentation patterns of a potential semantic unit
s; Pt(s1|s2) is a pattern which segments the unit
s into two parts: s1 and s2; Q is a threshold to
exclude rare patterns; and N is a smoothing factor
which is set as the number of documents. Note
that when the first part of the denominator is zero,
the ratio of the unit will be very high. Intuitively,
the lack of certain separating patterns in the data
is evidence for the tightness of the units.
</bodyText>
<sectionHeader confidence="0.936684" genericHeader="method">
4 Application to Chinese IR
</sectionHeader>
<bodyText confidence="0.999984090909091">
We propose a novel approach to segmentation
for Chinese IR which is based on the tight-
ness measure. Our segmenter revises the out-
put of a general segmenter according to the tight-
ness of units. The intuition behind our method
is that segmentation based on tightness of units
will lead to better IR performance. For exam-
ple, keeping “   ” (Pinatubo) as a unit
should lead to better results than segmenting it
into “(skin)|(include)|(picture) |(large)”.
On the other hand, segmenting the compositional
phrase “4Q” (Kuwait country) into “�
(Kuwait)|Q(country)” can improve recall. We
revise an initial segmentation in two steps: first,
we combine components that should not have
been separated, such as “ ” (Pinatubo);
second, we split units which are compositional,
such as “�Q” (Kuwait country).
In order to combine components, we first
extract 4-gram non-compositional compounds
whose tightness values are greater than a thresh-
old Q1 in a reference corpus, and then revise a
general segmenter by combining two separated
words if their combination is in the list. This ap-
proach is similar to the popular longest match first
method (LMF), but with segmentation chunks in-
stead of characters, and with the compound list
serving as the lexicon. For example, consider
a sequence “ABCDEFGHIGK,” which a general
segmenter annotates as “ABC|D|E|F|G|HI|GK.”
If our compound list constructed according to the
tightness measure contains {“DEFG”}, the re-
vised segmentation will be “ABC|DEFG|HI|GK.”
Units of length less than 4 are segmented by using
the LMF rule against a dictionary.
In order to split a compositional unit, we set the
additional thresholds Q2, Q3, and Q4, and employ
the segmentation rules in Equation 2. The intu-
ition comes from the pattern lattice of a unit (Fig-
ure 1). For the patterns on the same level, the most
frequent pattern suggests the most reasonable seg-
mentation. For the patterns on different levels, the
frequency of each level indicates the tightness of
the unit.
</bodyText>
<equation confidence="0.972917">
ratio = {
</equation>
<page confidence="0.992008">
57
</page>
<figureCaption confidence="0.99974">
Figure 1. The Lattice of the 8 Patterns.
</figureCaption>
<bodyText confidence="0.501632">
if
</bodyText>
<equation confidence="0.953501705882353">
♯P t(ABCD)
711 &gt; Q2
max(♯Pt(A|BCD),♯Pt(AB|CD),♯Pt(ABC|D))+N 1
then “ABCD” is one unit;
else if
max(♯P t(A|BCD),♯P t(AB|CD),♯P t(ABC|D))+ N
712 &gt;Q3
max(♯Pt(A|B|CD),♯Pt(A|BC|D),♯Pt(AB|C|D))+1 N
then “ABCD” is segmented into two parts;
else if
max(♯Pt(A|B|CD),♯Pt(A|BC|D),♯Pt(AB|C|D))+1N
713 &gt;Q4
♯Pt(A|B|C|D)+1 N
then “ABCD” is segmented into three parts;
else
“ABCD” is segmented into four parts;
(2)
</equation>
<bodyText confidence="0.999934083333333">
We apply the rules in Equation 2 to the se-
quence of 4-grams, with simple voting for select-
ing the segmentation pattern. For example, within
the sequence “ABCDEF,” three 4-gram patterns
are considered: “ABCD,” “BCDE,” and “CDEF.”
If only one of the 4-grams contains a segmentation
delimiter, the insertion of the delimiter depends
only upon that 4-gram. If two 4-grams contain the
same delimiter, the insertion of the delimiter de-
pends upon the two 4-grams. If the two 4-grams
disagree on the segmentation, a confidence value
is calculated as in Equation 3,
</bodyText>
<equation confidence="0.908985">
confidence = vi − Qi+1, (3)
</equation>
<bodyText confidence="0.999862576923077">
where i E [1, 2, 3]. If three 4-grams contain the
same delimiter, voting is employed to decide the
segmentation. Returning to our example, suppose
that the first 4-gram is segmented as “A B C D,”
the second as “BC DE,” and the third as “C DE F.”
Then the segmentation delimiter between “A” and
“B” is inserted, but the delimiter between “B” and
“C” depends on the confidence values of the first
two segmentation patterns. Finally, the delimiter
between “C” and “D” depends on the result of vot-
ing among the three 4-gram segmentations.
The two steps of combining and splitting can
either be applied in succession or separately. In
the former case, Q1 must be greater or equal to Q2.
In the remainder of this paper, we refer to the first
step as “Tight Combine,” and to the second step
applied after the first step as “Tight Split.” Note
that the second method can be used to segment
sentences directly instead of revising the output of
a general segmenter. This method, which we refer
to as “Online Tight,” has the same shortcoming
as the method of Liu et al. (2008), namely it fre-
quently fails to segment function words. For ex-
ample, it erroneously identifies “�A” (’s people)
as tight. Therefore, we do not attempt to embed it
into the IR systems discussed in Section 6.
</bodyText>
<sectionHeader confidence="0.969809" genericHeader="method">
5 Test Collection
</sectionHeader>
<bodyText confidence="0.99248">
We analyzed the currently available Chinese test
collection of TREC, and found it unsuitable for
evaluating different strategies of compound seg-
mentation. One problem with the TREC data is
that the Chinese queries (topic titles) have too
many keywords. According to the output of ICT-
CLAS, a general segmenter, the average length of
Chinese queries is 12.2 words; in contrast, the av-
erage length of English ad-hoc queries in TREC-
5 and 6 (English topics 251-350) is 4.7. Even if
we use English translation of the Chinese queries
instead, the average length is still more than 7
words. The problem with long queries is that
they introduce complicating effects that interact
in ways difficult to understand. An example is
the co-occurrence between different keywords in
the base corpus. Sometimes a completely correct
segmentation causes a decrease in IR performance
because the score function assigns a higher score
to less important terms in a topic. For example,
for query 47 (Trec-6 dataset), “40A:,1!N
JWALLI,kLLI&amp;,*lf&lt;, A” (Philippines,
Mount Pinatubo, volcanic ash, magma, eruption),
preserving the unit Pinatubo makes the average
precision drop from 0.76 to 0.62 as compared to
the segmentation “J� MJ N �”. The score of the
</bodyText>
<page confidence="0.991437">
58
</page>
<bodyText confidence="0.999933652173913">
unit is lower than that the sum of its components,
which results in a relatively low ranking for some
relevant documents. Another problem with the
TREC Chinese test collection is the small number
of queries (54). The number of of queries contain-
ing non-compositional words is smaller still. Sim-
ilarly, the other available corpus, NTCIR, com-
prises only 50 queries. In order to be confident of
our results, we would like to have a more substan-
tial number of queries containing units of varying
tightness.
Because of the shortcomings of available data
sets, we created our own test collection. There are
three components that define an IR test collection:
a query set, a corpus from which relevant docu-
ments are retrieved, and relevance judgements for
each query. Our criteria for gathering these com-
ponents are as follows.
First, the set of queries should contain both
tight queries and loose queries. For example,
there should be tight queries such as “ATSA”
(match maker), loose queries such as “±*
(Shanghai customs), and queries with tightness
values in between, such as “����” (machine
learning). Furthermore, the queries should be re-
alistic, rather than constructed by introspection.
In order to meet these requirements we randomly
chose 4-gram noun phrases (tagged by ICTCLAS)
from the TREC corpus. 51 queries are from a real
data set, the Sogou query logs2. The remaining
152 queries, which are selected manually based
on the initial 51 queries, represent queries that IR
system users are likely to enter. For example,
queries of locations and organizations are more
likely than queries such as “how are you.” Fi-
nally, the queries should not be too general (i.e.,
resulting in too many relevant documents found),
nor too specific (no relevant documents). There-
fore, we selected the 4-grams which had the cor-
responding document frequency in the TREC cor-
pus between 30 and 300.
The second set of criteria concerns the rele-
vance judgements of documents. As our retrieval
corpus, we adopted the TREC Mandarin corpus,
which contains 24,959 documents. Because of re-
source limitation, we used the Minimum Test Col-
</bodyText>
<footnote confidence="0.874205">
2Sogou query logs 2007 can be downloaded at
http://www.sogou.com/labs/dl/q.html.
</footnote>
<bodyText confidence="0.999878129032258">
lection (MTC) method (Carterette et al., 2006).
The method pools documents in such a way that
the documents which are best for discriminating
between different IR systems are judged first. We
applied this method on a document set that con-
tains all of the top 100 results of 8 IR systems
(two score functions, tf*idf and BM25, 4 index-
ing methods, unigram, bigram, ICTCLAS seg-
mentation, and our Tight Combine segmentation).
The systems were implemented with the Lucene
framework (http://lucene.apache.org/).
The last criterion determines which document
is relevant to a query. Annotators’ opinions vary
about whether a document is relevant to a topic.
Is having the query in a document enough to be
the criterion of relevance? For the query “Bei-
jing airport,” should the document that contains
the sentence “Chairman Mao arrived at the Bei-
jing airport yesterday,” be classified as relevant?
Since our goal is to analyze the relationship be-
tween Chinese word segmentation, and IR, we
use weak relevant judgements. It is more related
to score functions to distinguish weak relevance
from strong relevance, that is, whether the query
is the topic of the document. This means the above
document is judged as relevant for the query “Bei-
jing airport.”
In summary, our own test collection has about
200 queries, and at least 100 judged documents
per query with the TREC corpus as our base cor-
pus3.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999593">
We conducted a series of experiments in word-
based Chinese information retrieval, with the aim
of establishing which segmenter is best for CIR,
while pursuing the best segmentation performance
in terms of segmented corpus is not the main crux.
In this section, we first present the accuracy of dif-
ferent segmentation methods, and then discuss the
results of IR systems.
</bodyText>
<subsectionHeader confidence="0.996846">
6.1 Chinese Word Segmentation
</subsectionHeader>
<bodyText confidence="0.967444333333333">
ICTCLAS is a Chinese segmentation tool built by
the Institute of Computing Technology, Chinese
Academy of Sciences. Its segmentation model is a
</bodyText>
<footnote confidence="0.994685">
3The query set and relevance judgements are available at
http://www.cs.ualberta.ca/˜yx2/research.html
</footnote>
<equation confidence="0.311083">
�k”
</equation>
<page confidence="0.994353">
59
</page>
<bodyText confidence="0.999943416666667">
class-based hidden Markov model (HMM) model
(Zhang et al., 2003). The segmenter is trained
from manually segmented corpus, which makes
it ignore both the tightness of units and unknown
words such as “J-;ZM!M ” (Pinatubo), which are
difficult to identify.
In this experiment, we segmented the Chinese
Treebank using ICTCLAS and our three methods
that employ the tightness measure. The evalua-
tion is based on the manual segmentation of the
corpus. We evaluated the methods on the entire
Treebank corpus, employing 10-cross validation
for result significance verification.
In order to measure the tightness of Chinese
semantic units, pattern distributions of every 4-
gram were extracted from the Chinese Gigaword
corpus. Tight Combine is the ICTCLAS refined
segmentation that employs the non-compositional
compound list from the Chinese Gigaword cor-
pus. The threshold for non-compositional com-
pound Q1 is set to 11. Tight Split is the refined
segmentation of Tight Combine using Equation 2.
Online Tight is the segmentation using Equation
2 directly. For Tight Split and Online Tight, we
employed a lexicon which contains 41,245 words,
and set the thresholds Q2, Q3, and Q4 to 11, 0.01,
and 0.01, respectively. The parameters Q1 and Q2
are set according to the observation that the per-
centage of non-compositional units is high when
the tightness is greater than 11 for all the 4-grams
in the Chinese Gigaword corpus. The other two
parameters were established after experimenting
with several parameter pairs, such as (1,1), (0.1,
0.1), and (0.1, 0.01). We chose the one with the
best segmentation accuracy according to the stan-
dard corpus.
Table 1 shows the mean accuracy result over the
10 folders. The accuracy is the ratio of the number
of correctly segmented intervals to the number of
all intervals. The result shows that our method
improves over the ICTCLAS segmentation result,
but the improvement is not statistically significant
(measured by t-test). The only significant result is
that Online tight is worse than other methods.
Surprisingly, there is a large gap between
Tight Split and Online Tight, although they em-
ploy the same parameters. It turns out the ma-
jor difference lies in the segmentation of function
</bodyText>
<table confidence="0.99562425">
ICTCLAS 88.8%
Tight Combine 89.0%
Tight Split 89.1%
Online Tight 80.5%
</table>
<tableCaption confidence="0.8432725">
Table 1. Segmentation accuracy of different seg-
menters.
</tableCaption>
<bodyText confidence="0.999154888888889">
words. Since it is based on ICTCLAS, Tight Split
does a good job in segmenting function words
such as verbal particles which represent past tense
“f” and the nominalizer “M” Online Tight
tends to combine these words with the consecu-
tive one. For example, considering “f,R,W,f” (cu-
mulated), the Treebank and Tight Split segment it
into “�X|f” (cumulate + particle); while On-
line Tight leaves it unsegmented.
</bodyText>
<subsectionHeader confidence="0.99095">
6.2 IR Experiment Setup
</subsectionHeader>
<bodyText confidence="0.9999503">
We conducted our information retrieval experi-
ments using the Lucene package (Hatcher and
Gospodnetic, 2004). The documents and queries
were segmented by our three approaches before
indexing and searching process. In order to ana-
lyze the performance of our segmentation meth-
ods with different retrieval systems, we employed
two score functions: the BM25 function (Peng et
al., 2002b) 4; and BM25Beta (Function 4), which
prefers documents with more query terms.
</bodyText>
<equation confidence="0.989351">
Score(Q, D) =
{ =
(l+p).N �% o score(ti, D) if T &lt; N (4)
∑NO
No
score(ti, D) if T = N
i
</equation>
<bodyText confidence="0.999986272727273">
In the above equation, score(ti7 D) is the score
of the term ti in the document D. Although
we used BM25 as our base score function for
score(ti7 D), it can be replaced by other score
functions, such as tf*idf, or a probability language
model. β is a parameter to control a penalty com-
ponent for those documents that do not contain
all the query terms; T is the number of distinc-
tive query terms in the document; and N is the
number of query terms. The function penalizes
documents that do not contain all the query terms,
</bodyText>
<footnote confidence="0.9970605">
4An implementation of BM25 into Lucene can be down-
loaded at http://arxiv.org/abs/0911.5046
</footnote>
<page confidence="0.993057">
60
</page>
<table confidence="0.99837075">
BM25 BM25Beta
ICTCLAS 62.78% 70.79%
Tight Combine 65.92% 71.19%
Tight Split 63.40% 70.95%
</table>
<tableCaption confidence="0.959154">
Table 2. MAP of different IR systems with differ-
ent segmenters.
</tableCaption>
<bodyText confidence="0.9378275">
which is an indirect way of incorporating proxim-
ity distance 5.
</bodyText>
<subsectionHeader confidence="0.991061">
6.3 IR Experiment Results
</subsectionHeader>
<bodyText confidence="0.999882575757576">
Table 2 shows the comparison of our two seg-
menters to ICTCLAS on the IR task. The per-
formance of IR systems was measured by mean
average precision (MAP) of the query set. The re-
sults show that Tight Combine is better than the
ICTCLAS segmentation, especially when using
BM25. The relationship between Tight Split and
ICTCLAS is not clear.
In order to give a more in-depth analysis of
the word segmentation methods with respect to
the targeted phenomenon of semantic units, we
classified the 200 queries into three categories ac-
cording to their tightness as measured by func-
tion 1. The three classes are queries with tight-
ness in ranges [+oo, 10), [10, 1), and [1, 0),
which contain 54, 41, and 108 queries respec-
tively. Queries in the range [+oo, 10) are tight
queries, such as “” (Virginia). Queries
in the range [1, 0) are loose queries, such as “
a7” (advertising company). Other queries are
those compounds which have ambiguous segmen-
tations, such as “A��” (chain reaction). Be-
cause the classification was based on the tightness
measure, there are some errors. For example, “A
��” (Renmin University) was classified as a
loose query although it should at least be in the
middle range. The three classes cover the whole
tightness continuum, i.e. the whole possible query
set. Table 3 shows the MAP with respect to these
classes for the word segmentation methods. For
queries with tightness less than 10, the results of
ICTCLAS and Tight Combine are approximately
equal, which is not surprising since with few ex-
</bodyText>
<footnote confidence="0.984539">
5We also experimented with replacing β with the tight-
ness value, but the results were not substantially different.
</footnote>
<table confidence="0.999280222222222">
[+oo, 10) [10, 1) [1, 0)
BM25
ICTCLAS 74.48% 60.28% 57.87%
Tight Combine 86.44% 60.55% 57.70%
Tight Split 88.86% 56.78% 53.17%
BM25 Beta
ICTCLAS 84.60% 72.56% 63.28%
Tight Combine 86.44% 72.70% 63.07%
Tight Split 88.86% 74.80% 60.39%
</table>
<tableCaption confidence="0.999915">
Table 3. Results on three query categories.
</tableCaption>
<bodyText confidence="0.999651702702702">
ceptions they have the same segmentation for both
queries and documents.
For the interesting case of segmentation of
tight units, i.e. queries in the range [+oo, 10),
the results show clear superiority for IR systems
based on our segmentation methods. When us-
ing BM25, MAP is 86.44% for Tight Combine,
as compared to 74.48% for standard word seg-
mentation. The advantage of Tight Combine over
ICTCLAS is that it combines units such as “
&amp;W�” (plate glass) as the term is tight, while
ICTCLAS segments that unit into “&amp;” (plate)
and “W�” (glass). This is evidence that word
segmentation models based on the tight measure
are better than models trained on a human anno-
tated corpus which ignored tightness information.
Interestingly, Tight Split is superior in the range
[+oo, 10), although the segmentation for these
queries is the same as with Tight Combine. When
we analyzed the instances, we found it improved
IR results of proper nouns. One possible expla-
nation is that splitting of proper nouns such as
“�” (Virginia state) in documents im-
proved the recall even when the segmentation of
the queries remained the same. For example, for
query “” (Virginia), documents which
contain “�” (Virginia state) should be
retrieved. However, since ICTCLAS treats “
�” as a word, those documents are missed.
Instead, Tight Split segments the sequence into
“ �,” which results in the retrieval of
those documents.
In the range of [10, 1), the result is mixed.
For some instances, Tight Split is worse than
Tight Combine and ICTCLAS, as it segments
queries such as “A 1  �” (chain reaction).
However, in other instances, it is better than
</bodyText>
<page confidence="0.997543">
61
</page>
<bodyText confidence="0.999813096774193">
Tight Combine and ICTCLAS since it segments
queries such as “����” (international chess).
The result suggests that the setting of the thresh-
old for non-compositional terms should be below
10.
In the range of [1, 0), the result is also mixed.
One reason for the low performance of Tight Split
is that the tightness measure is not precise for
those queries, which affects the segmentation. For
example, splitting the queries “����” (labor
movement) and “rP�)�*” (Zhongshan Univer-
sity) decreases the IR performance dramatically.
In future work, we would like to investigate this
problem by segmenting queries manually accord-
ing to their tightness. If the manual segmentation
is superior, it would provided evidence for the hy-
pothesis that segmentation based on tightness is
superior.
The difference between BM25 and BM25 Beta
in the range [10, 1) suggests that for Chinese
IR, it is better to segment text in a more fine-
grained way, and combine terms through a score
function. For example, for queries such as “A
�IX�” (chain reaction), for which splitting the
unit is worse, BM25 Beta decreases the negative
effect of splitting dramatically. For the query
“Mqi�&amp;” (life insurance), when using BM25,
Tight Split is worse than ICTCLAS (average pre-
cision 0.59 vs. 0.66); but when using BM25 Beta,
it is better than ICTCLAS (average precision 0.72
vs. 0.66).
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999944956521739">
For Chinese IR, we have developed a new method
to segment documents based on the tightness of
Chinese semantic units. The segmentation per-
formance of our method is close to ICTCLAS,
but the mean average precision of IR systems
using our method is higher than for ICTCLAS
when using BM25. In addition, we proposed a
fine-grained segmenter plus a score function that
prefers short proximity distance for CIR.
In the future, we plan to employ ranking SVM
models with the tightness measure as one of the
features for segmentation (Liu et al., 2008). We
hope that it can predict the tightness more pre-
cisely, by combining with other features. In terms
of our test collection, the 203 query set clearly
helps the in-depth analysis for the performance of
different IR systems on different queries. We also
plan to gather more queries and more judged doc-
uments in order to further analyze the influence
of the proper treatment of semantic units in Chi-
nese information retrieval. A large query set could
also make it possible to employ machine learning
models for IR (Song et al., 2009).
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999127897435897">
Braschler, Martin, and B¨arbel Ripplinger. 2004. How
effective is stemming and compounding for German
text retrieval? Information Retrieval, 7(3/4), 291-
316.
Carterette, Ben, James Allan, and Ramesh Sitaraman.
2006. Minimal Test Collections for Retrieval Evalu-
ation. Proceedings of the 29th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, 268-275.
Chang, Pi-Chuan, Michel Galley, and Christopher D.
Manning. 2008. Optimizing Chinese Word Seg-
mentation for Machine Translation Performance.
Proceedings of the Third Workshop on Machine
Translation, 224-232.
Foo, Schubert and Hui Li. 2004. Chinese word seg-
mentation and its effect on information retrieval. In-
formation Processing and Management: an Inter-
national Journal, 40(1), 161-190.
Guenthner, Frantz and Xavier Blanco. 2004. Multi-
lexemic expressions: an overview. Linguisticae In-
vestigationes Supplementa, 239-252.
Halpern, Jack. 2000. Is English Segmentation Trivial?
Technical report, CJK Dictionary Institute.
Hatcher, Erik and Otis Gospodneti´c 2004. Lucene in
Action. Manning Publications Co.
Huang, Xiangji, Stephen Robertson, Nick Cercone,
and Aijun An. 2003. Probability-Based Chinese
Text Processing and Retrieval. Computational In-
telligence, 16(4), 552-569.
Huang, Xiangji, Fuchun Peng, Dale Schuurmans, Nick
Cercone, and Stephen E. Robertson. 2003. Apply-
ing Machine Learning for Text Segmentation in In-
formation Retrieval. Information Retrieval, 6 (3-4),
pp. 333-362, 2003.
Jiang, Wenbin, Liang Huang, Qun Liu, and Yajuan
Lv. 2008. A Cascaded Linear Model for Joint Chi-
nese Word Segmentation and Part-of-Speech Tag-
ging. Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics.
</reference>
<page confidence="0.981089">
62
</page>
<reference confidence="0.999769902777777">
Liu, Yixuan, Bin Wang, Fan Ding, and Sheng Xu.
2008. Information Retrieval Oriented Word Seg-
mentation based on Character Associative Strength
Ranking. Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, 1061-1069.
McCarthy, Diana, Bill Keller, and John Carroll. 2003.
Detecting a Continuum of Compositionality in
Phrasal Verbs. Proceedings Of the ACL-SIGLEDX
(a Special Interest Group on the Lexicon Workshop)
on Multiword Expressions, 73-80.
Nie, Jian-Yun, Jiangfeng Gao, Jian Zhang, and Ming
Zhou. 2000. On the use of words and N-grams
for Chinese information retrieval. Proceedings of
the Fifth International Workshop on Information Re-
trieval with Asian Languages, 141-148.
Packard, Jerome L. 2000. Morphology of Chinese:
A Linguistic and Cognitive Approach. Cambridge
University Press.
Peng, Fuchun, Xiangji Huang, Dale Schuurmans, Nick
Cercone, and Stephen E. Robertson. 2002. Using
Self-supervised Word Segmentation in Chinese In-
formation Retrieval. Proceedings of the 25th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
349-350.
Peng, Fuchun, Xiangji Huang, Dale Schuurmans, and
Nick Cercone. 2002. Investigating the Relationship
between Word Segmentation Performance and Re-
trieval Performance in Chinese IR. Retrieval Per-
formance in Chinese IR, Coling2002, 1-7.
Shi, Lixin and Jian-Yun Nie. 2009. Integrating phrase
inseparability in phrase-based model. Proceedings
of the 32th Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, 708-709.
Silva, Joaquim, Ga¨el Dias, Sylvie Guillor´e, and Jos´e
Gabriel Pereira Lopes. 1999. Using LocalMaxs Al-
gorithm for the Extraction of Contiguous and Non-
contiguous Multiword Lexical Units. In Proceed-
ings of 9th Portuguese Conference in Artificial In-
telligence (EPIA 1999), 849.
Sproat, Richard, Chilin Shih, William Gale and Nancy
Chang. 1996. A Stochastic Finite-State Word-
Segmentation Algorithm for Chinese. Computa-
tional Linguistics, 22(3), 377-404, 1996.
Song, Young-In, Jung-Tae Lee, and Hae-Chang Rim.
2009. Word or Phrase? Learning Which Unit to
Stress for Information Retrieval. Proceedings of the
47th Annual Meeting of the Association for Compu-
tational Linguistics and the 4th International Joint
Conference on Natural Language Processing of the
Asian Federation of Natural Language Processing,
1048-1056.
Tao, Tao and ChengXiang Zhai. 2007. An exploration
of proximity measures in information retrieval. Pro-
ceedings of the 30th annual international ACM SI-
GIR conference on Research and development in in-
formation retrieval, 295-302.
Vechtomova, Olga. 2001. Approaches to using word
collocation in information retrieval. Ph.D. Thesis
(City University, 2001).
Xu, Ying, Christoph Ringlstetter, and Randy Goebel.
2009. A Continuum-based Approach for Tightness
Analysis of Chinese Semantic Units. Proc. of the
23rd Pacific Asia Conference on Language, Infor-
mation and Computation, 569-578.
Zhang, Hua-Ping, Hong-Kui Yu, De-Yi Xiong, and
Qun Liu. 2003. HHMM-based Chinese lexical an-
alyzer ICTCLAS. Proceedings of the 2nd SIGHAN
Workshop on Chinese Language Processing, 184-
187.
</reference>
<page confidence="0.999436">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.776969">
<title confidence="0.977246">Application of the Tightness Continuum to Chinese Information Retrieval</title>
<author confidence="0.99993">Randy Christoph</author>
<affiliation confidence="0.988934">of Computing Science for Language and University of Alberta Information Processing (CIS) Ludwig Maximilians University</affiliation>
<email confidence="0.980732">kristof@cis.uni-muenchen.de</email>
<abstract confidence="0.993516608695652">Most word segmentation methods employed in Chinese Information Retrieval systems are based on a static dictionary or a model trained against a manually corpus. These segmentation approaches may not be optimal because they disregard information within semantic units. We propose a novel method for improving word-based Chinese IR, which performs segmentation according to the tightness of phrases. In order to evaluate the effectiveness of our method, we employ a new test collection of 203 queries, which include a broad distribution of phrases with different tightness values. The results of our experiments indicate that our method improves IR performance as compared with a general word segmentation approach. The experiments also demonstrate the need for the development of better evaluation corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Martin Braschler</author>
<author>B¨arbel Ripplinger</author>
</authors>
<title>How effective is stemming and compounding for German text retrieval?</title>
<date>2004</date>
<journal>Information Retrieval,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>291--316</pages>
<contexts>
<context position="8197" citStr="Braschler and Ripplinger (2004)" startWordPosition="1298" endWordPosition="1302">e with a general segmentation method. Chinese word segmentation is closely related to multiword expression extraction. McCarthy et al. (2003) investigate various statistical measures of compositionality of candidate multiword verbs. 56 Silva et al. (1999) propose a new compositionality measure based on statistical information. The main difference with Xu et al.’s measure is that the latter is focused on word sense disambiguation. In terms of multiword expressions in IR, Vechtomova (2001) propose several approaches, such as query expansion, to incorporating English multiword expressions in IR. Braschler and Ripplinger (2004) analyze the effect of stemming and decompounding on German text retrieval. However, Chinese compound segmentation in IR is a thorny issue and needs more investigation for the reasons mentioned earlier. 3 Semantic Tightness Continuum We adopt the method developed by (Xu et al., 2009) for Chinese semantic unit tightness measure, which was shown to outperform the pointwise mutual information method. For the sake of completeness we briefly describe the basic approach here. The input of the measure is the probability distribution of a unit’s segmentation patterns, i.e., potential segmentation cand</context>
</contexts>
<marker>Braschler, Ripplinger, 2004</marker>
<rawString>Braschler, Martin, and B¨arbel Ripplinger. 2004. How effective is stemming and compounding for German text retrieval? Information Retrieval, 7(3/4), 291-316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Carterette</author>
<author>James Allan</author>
<author>Ramesh Sitaraman</author>
</authors>
<title>Minimal Test Collections for Retrieval Evaluation.</title>
<date>2006</date>
<booktitle>Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="17600" citStr="Carterette et al., 2006" startWordPosition="2842" endWordPosition="2845"> Finally, the queries should not be too general (i.e., resulting in too many relevant documents found), nor too specific (no relevant documents). Therefore, we selected the 4-grams which had the corresponding document frequency in the TREC corpus between 30 and 300. The second set of criteria concerns the relevance judgements of documents. As our retrieval corpus, we adopted the TREC Mandarin corpus, which contains 24,959 documents. Because of resource limitation, we used the Minimum Test Col2Sogou query logs 2007 can be downloaded at http://www.sogou.com/labs/dl/q.html. lection (MTC) method (Carterette et al., 2006). The method pools documents in such a way that the documents which are best for discriminating between different IR systems are judged first. We applied this method on a document set that contains all of the top 100 results of 8 IR systems (two score functions, tf*idf and BM25, 4 indexing methods, unigram, bigram, ICTCLAS segmentation, and our Tight Combine segmentation). The systems were implemented with the Lucene framework (http://lucene.apache.org/). The last criterion determines which document is relevant to a query. Annotators’ opinions vary about whether a document is relevant to a top</context>
</contexts>
<marker>Carterette, Allan, Sitaraman, 2006</marker>
<rawString>Carterette, Ben, James Allan, and Ramesh Sitaraman. 2006. Minimal Test Collections for Retrieval Evaluation. Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 268-275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>Optimizing Chinese Word Segmentation for Machine Translation Performance.</title>
<date>2008</date>
<booktitle>Proceedings of the Third Workshop on Machine Translation,</booktitle>
<pages>224--232</pages>
<marker>Chang, Galley, Manning, 2008</marker>
<rawString>Chang, Pi-Chuan, Michel Galley, and Christopher D. Manning. 2008. Optimizing Chinese Word Segmentation for Machine Translation Performance. Proceedings of the Third Workshop on Machine Translation, 224-232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schubert Foo</author>
<author>Hui Li</author>
</authors>
<title>Chinese word segmentation and its effect on information retrieval.</title>
<date>2004</date>
<booktitle>Information Processing and Management: an International Journal,</booktitle>
<volume>40</volume>
<issue>1</issue>
<pages>161--190</pages>
<contexts>
<context position="1613" citStr="Foo and Li, 2004" startWordPosition="231" endWordPosition="234">te that our method improves IR performance as compared with a general word segmentation approach. The experiments also demonstrate the need for the development of better evaluation corpora. 1 Introduction What distinguishes Chinese Information Retrieval from information retrieval (IR) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters. In general, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their application in sophisticated IR tasks such as cross language IR, and within techniques such as query expansion (Nie et al., 2000; Peng et al., 2002a). Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al., 2003). However, the relationship between the accuracy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b) reported that segmentation methods ac</context>
<context position="5702" citStr="Foo and Li (2004)" startWordPosition="913" endWordPosition="916"> the integration of the semantic tightness measure into an IR system. Section 5 discusses the available data for Chinese IR evaluation, as well as an approach to acquire new data. Section 6 presents the results of our method on word segmentation and IR. A short conclusion wraps up and gives directions for future work. 2 Related Work The impact of different Chinese word segmentation methods on IR has received extensive attention in the literature (Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and r</context>
</contexts>
<marker>Foo, Li, 2004</marker>
<rawString>Foo, Schubert and Hui Li. 2004. Chinese word segmentation and its effect on information retrieval. Information Processing and Management: an International Journal, 40(1), 161-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frantz Guenthner</author>
<author>Xavier Blanco</author>
</authors>
<title>Multilexemic expressions: an overview.</title>
<date>2004</date>
<booktitle>Linguisticae Investigationes Supplementa,</booktitle>
<pages>239--252</pages>
<contexts>
<context position="3384" citStr="Guenthner and Blanco, 2004" startWordPosition="514" endWordPosition="517">d clearly be considered as a single term in Chinese IR, compounds such as “� * (machine learning) are more controversial.&apos; Xu et al. (2009) proposed a “continuum hypothesis” that rejects a clean binary classification of Chinese semantic units as either compositional or non-compositional. Instead, they introduced the notion of a tightness measure, which quantifies the degree of compositionality. On this tightness continuum, at one extreme are non&apos;This issue is also present to a certain degree in languages that do use explicit delimiters, including English (Halpern, 2000; McCarthy et al., 2003; Guenthner and Blanco, 2004). 55 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63, Beijing, August 2010 compositional semantic units, such as “AT�9 A” (match maker), and at the other end are sequences of consecutive words with no dependency relationship, such as “± 9P4” (Shanghai where). In the middle of the spectrum are compositional compounds such as “K *%1” (machine learning) and phrases such as “1EA�C A” (legitimate income). In this paper, we propose a method to apply the concept of semantic tightness to Chinese IR, which refines the output of a general Chinese word segmen</context>
</contexts>
<marker>Guenthner, Blanco, 2004</marker>
<rawString>Guenthner, Frantz and Xavier Blanco. 2004. Multilexemic expressions: an overview. Linguisticae Investigationes Supplementa, 239-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Halpern</author>
</authors>
<title>Is English Segmentation Trivial?</title>
<date>2000</date>
<tech>Technical report, CJK</tech>
<institution>Dictionary Institute.</institution>
<contexts>
<context position="3332" citStr="Halpern, 2000" startWordPosition="508" endWordPosition="509">eanut) and “�T�9A” (match maker) should clearly be considered as a single term in Chinese IR, compounds such as “� * (machine learning) are more controversial.&apos; Xu et al. (2009) proposed a “continuum hypothesis” that rejects a clean binary classification of Chinese semantic units as either compositional or non-compositional. Instead, they introduced the notion of a tightness measure, which quantifies the degree of compositionality. On this tightness continuum, at one extreme are non&apos;This issue is also present to a certain degree in languages that do use explicit delimiters, including English (Halpern, 2000; McCarthy et al., 2003; Guenthner and Blanco, 2004). 55 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63, Beijing, August 2010 compositional semantic units, such as “AT�9 A” (match maker), and at the other end are sequences of consecutive words with no dependency relationship, such as “± 9P4” (Shanghai where). In the middle of the spectrum are compositional compounds such as “K *%1” (machine learning) and phrases such as “1EA�C A” (legitimate income). In this paper, we propose a method to apply the concept of semantic tightness to Chinese IR, which</context>
</contexts>
<marker>Halpern, 2000</marker>
<rawString>Halpern, Jack. 2000. Is English Segmentation Trivial? Technical report, CJK Dictionary Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Hatcher</author>
<author>Otis Gospodneti´c</author>
</authors>
<title>Lucene in Action.</title>
<date>2004</date>
<publisher>Manning Publications Co.</publisher>
<marker>Hatcher, Gospodneti´c, 2004</marker>
<rawString>Hatcher, Erik and Otis Gospodneti´c 2004. Lucene in Action. Manning Publications Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangji Huang</author>
<author>Stephen Robertson</author>
<author>Nick Cercone</author>
<author>Aijun An</author>
</authors>
<date>2003</date>
<booktitle>Probability-Based Chinese Text Processing and Retrieval. Computational Intelligence,</booktitle>
<volume>16</volume>
<issue>4</issue>
<pages>552--569</pages>
<contexts>
<context position="4474" citStr="Huang et al., 2003" startWordPosition="696" endWordPosition="699">ose a method to apply the concept of semantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section </context>
<context position="6217" citStr="Huang et al., 2003" startWordPosition="999" endWordPosition="1002">g et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and retrieval performance is non-monotonic, ranging from 44%-95%. They hypothesize that weak word segmenters are able to improve the accuracy of Chinese IR by breaking compound words into smaller constituents. Shi and Nie (2009) proposed a probabilitybased IR score function that combines a unigram score with a word score according to “phrase inseparability.” Candidates for words in the query are selected by a standard segmentation program. Their results show a small improvement in comparison with a static combinati</context>
</contexts>
<marker>Huang, Robertson, Cercone, An, 2003</marker>
<rawString>Huang, Xiangji, Stephen Robertson, Nick Cercone, and Aijun An. 2003. Probability-Based Chinese Text Processing and Retrieval. Computational Intelligence, 16(4), 552-569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangji Huang</author>
<author>Fuchun Peng</author>
<author>Dale Schuurmans</author>
<author>Nick Cercone</author>
<author>Stephen E Robertson</author>
</authors>
<title>Applying Machine Learning for Text Segmentation in Information Retrieval.</title>
<date>2003</date>
<journal>Information Retrieval,</journal>
<volume>6</volume>
<pages>3--4</pages>
<contexts>
<context position="4474" citStr="Huang et al., 2003" startWordPosition="696" endWordPosition="699">ose a method to apply the concept of semantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section </context>
<context position="6217" citStr="Huang et al., 2003" startWordPosition="999" endWordPosition="1002">g et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and retrieval performance is non-monotonic, ranging from 44%-95%. They hypothesize that weak word segmenters are able to improve the accuracy of Chinese IR by breaking compound words into smaller constituents. Shi and Nie (2009) proposed a probabilitybased IR score function that combines a unigram score with a word score according to “phrase inseparability.” Candidates for words in the query are selected by a standard segmentation program. Their results show a small improvement in comparison with a static combinati</context>
</contexts>
<marker>Huang, Peng, Schuurmans, Cercone, Robertson, 2003</marker>
<rawString>Huang, Xiangji, Fuchun Peng, Dale Schuurmans, Nick Cercone, and Stephen E. Robertson. 2003. Applying Machine Learning for Text Segmentation in Information Retrieval. Information Retrieval, 6 (3-4), pp. 333-362, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
<author>Yajuan Lv</author>
</authors>
<title>A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging.</title>
<date>2008</date>
<booktitle>Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Jiang, Huang, Liu, Lv, 2008</marker>
<rawString>Jiang, Wenbin, Liang Huang, Qun Liu, and Yajuan Lv. 2008. A Cascaded Linear Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging. Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yixuan Liu</author>
<author>Bin Wang</author>
<author>Fan Ding</author>
<author>Sheng Xu</author>
</authors>
<title>Information Retrieval Oriented Word Segmentation based on Character Associative Strength Ranking.</title>
<date>2008</date>
<booktitle>Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1061--1069</pages>
<contexts>
<context position="5650" citStr="Liu et al., 2008" startWordPosition="903" endWordPosition="906"> measure of semantic tightness. Section 4 describes the integration of the semantic tightness measure into an IR system. Section 5 discusses the available data for Chinese IR evaluation, as well as an approach to acquire new data. Section 6 presents the results of our method on word segmentation and IR. A short conclusion wraps up and gives directions for future work. 2 Related Work The impact of different Chinese word segmentation methods on IR has received extensive attention in the literature (Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that </context>
<context position="13904" citStr="Liu et al. (2008)" startWordPosition="2242" endWordPosition="2245">ween “C” and “D” depends on the result of voting among the three 4-gram segmentations. The two steps of combining and splitting can either be applied in succession or separately. In the former case, Q1 must be greater or equal to Q2. In the remainder of this paper, we refer to the first step as “Tight Combine,” and to the second step applied after the first step as “Tight Split.” Note that the second method can be used to segment sentences directly instead of revising the output of a general segmenter. This method, which we refer to as “Online Tight,” has the same shortcoming as the method of Liu et al. (2008), namely it frequently fails to segment function words. For example, it erroneously identifies “�A” (’s people) as tight. Therefore, we do not attempt to embed it into the IR systems discussed in Section 6. 5 Test Collection We analyzed the currently available Chinese test collection of TREC, and found it unsuitable for evaluating different strategies of compound segmentation. One problem with the TREC data is that the Chinese queries (topic titles) have too many keywords. According to the output of ICTCLAS, a general segmenter, the average length of Chinese queries is 12.2 words; in contrast,</context>
</contexts>
<marker>Liu, Wang, Ding, Xu, 2008</marker>
<rawString>Liu, Yixuan, Bin Wang, Fan Ding, and Sheng Xu. 2008. Information Retrieval Oriented Word Segmentation based on Character Associative Strength Ranking. Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, 1061-1069.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a Continuum of Compositionality in Phrasal Verbs.</title>
<date>2003</date>
<booktitle>Proceedings Of the ACL-SIGLEDX (a Special Interest Group on the Lexicon Workshop) on Multiword Expressions,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="3355" citStr="McCarthy et al., 2003" startWordPosition="510" endWordPosition="513">9A” (match maker) should clearly be considered as a single term in Chinese IR, compounds such as “� * (machine learning) are more controversial.&apos; Xu et al. (2009) proposed a “continuum hypothesis” that rejects a clean binary classification of Chinese semantic units as either compositional or non-compositional. Instead, they introduced the notion of a tightness measure, which quantifies the degree of compositionality. On this tightness continuum, at one extreme are non&apos;This issue is also present to a certain degree in languages that do use explicit delimiters, including English (Halpern, 2000; McCarthy et al., 2003; Guenthner and Blanco, 2004). 55 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63, Beijing, August 2010 compositional semantic units, such as “AT�9 A” (match maker), and at the other end are sequences of consecutive words with no dependency relationship, such as “± 9P4” (Shanghai where). In the middle of the spectrum are compositional compounds such as “K *%1” (machine learning) and phrases such as “1EA�C A” (legitimate income). In this paper, we propose a method to apply the concept of semantic tightness to Chinese IR, which refines the output of </context>
<context position="7707" citStr="McCarthy et al. (2003)" startWordPosition="1227" endWordPosition="1230"> vector machine (SVM) model to predict the internal association strength (IAS) between characters, which is similar to our concept of tightness. However, they do not analyze their segmentation accuracy with respect to a standard corpus, such as Chinese Treebank. Their method does not reliably segment function words, mistakenly identifying “�A” (’s people) as tight, for example. Unlike their approach, our segmentation method tackles the problem by combining the tightness measure with a general segmentation method. Chinese word segmentation is closely related to multiword expression extraction. McCarthy et al. (2003) investigate various statistical measures of compositionality of candidate multiword verbs. 56 Silva et al. (1999) propose a new compositionality measure based on statistical information. The main difference with Xu et al.’s measure is that the latter is focused on word sense disambiguation. In terms of multiword expressions in IR, Vechtomova (2001) propose several approaches, such as query expansion, to incorporating English multiword expressions in IR. Braschler and Ripplinger (2004) analyze the effect of stemming and decompounding on German text retrieval. However, Chinese compound segmenta</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>McCarthy, Diana, Bill Keller, and John Carroll. 2003. Detecting a Continuum of Compositionality in Phrasal Verbs. Proceedings Of the ACL-SIGLEDX (a Special Interest Group on the Lexicon Workshop) on Multiword Expressions, 73-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Jiangfeng Gao</author>
<author>Jian Zhang</author>
<author>Ming Zhou</author>
</authors>
<title>On the use of words and N-grams for Chinese information retrieval.</title>
<date>2000</date>
<booktitle>Proceedings of the Fifth International Workshop on Information Retrieval with Asian Languages,</booktitle>
<pages>141--148</pages>
<contexts>
<context position="1574" citStr="Nie et al., 2000" startWordPosition="223" endWordPosition="226"> The results of our experiments indicate that our method improves IR performance as compared with a general word segmentation approach. The experiments also demonstrate the need for the development of better evaluation corpora. 1 Introduction What distinguishes Chinese Information Retrieval from information retrieval (IR) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters. In general, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their application in sophisticated IR tasks such as cross language IR, and within techniques such as query expansion (Nie et al., 2000; Peng et al., 2002a). Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al., 2003). However, the relationship between the accuracy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b</context>
<context position="4492" citStr="Nie et al., 2000" startWordPosition="700" endWordPosition="703">y the concept of semantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the in</context>
</contexts>
<marker>Nie, Gao, Zhang, Zhou, 2000</marker>
<rawString>Nie, Jian-Yun, Jiangfeng Gao, Jian Zhang, and Ming Zhou. 2000. On the use of words and N-grams for Chinese information retrieval. Proceedings of the Fifth International Workshop on Information Retrieval with Asian Languages, 141-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome L Packard</author>
</authors>
<title>Morphology of Chinese: A Linguistic and Cognitive Approach.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<marker>Packard, 2000</marker>
<rawString>Packard, Jerome L. 2000. Morphology of Chinese: A Linguistic and Cognitive Approach. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchun Peng</author>
<author>Xiangji Huang</author>
<author>Dale Schuurmans</author>
<author>Nick Cercone</author>
<author>Stephen E Robertson</author>
</authors>
<title>Using Self-supervised Word Segmentation in Chinese Information Retrieval.</title>
<date>2002</date>
<booktitle>Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>349--350</pages>
<contexts>
<context position="1829" citStr="Peng et al., 2002" startWordPosition="269" endWordPosition="272">guishes Chinese Information Retrieval from information retrieval (IR) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters. In general, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their application in sophisticated IR tasks such as cross language IR, and within techniques such as query expansion (Nie et al., 2000; Peng et al., 2002a). Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al., 2003). However, the relationship between the accuracy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b) reported that segmentation methods achieving segmentation accuracy higher than 90% according to a manual segmentation standard yield no improvement in IR performance. They further argued that IR often benefits from splitting compound words that are anno</context>
<context position="4511" citStr="Peng et al., 2002" startWordPosition="704" endWordPosition="707">emantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the integration of the se</context>
<context position="6155" citStr="Peng et al., 2002" startWordPosition="987" endWordPosition="990">e et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and retrieval performance is non-monotonic, ranging from 44%-95%. They hypothesize that weak word segmenters are able to improve the accuracy of Chinese IR by breaking compound words into smaller constituents. Shi and Nie (2009) proposed a probabilitybased IR score function that combines a unigram score with a word score according to “phrase inseparability.” Candidates for words in the query are selected by a standard segmentation program. Their results </context>
<context position="22770" citStr="Peng et al., 2002" startWordPosition="3669" endWordPosition="3672">o combine these words with the consecutive one. For example, considering “f,R,W,f” (cumulated), the Treebank and Tight Split segment it into “�X|f” (cumulate + particle); while Online Tight leaves it unsegmented. 6.2 IR Experiment Setup We conducted our information retrieval experiments using the Lucene package (Hatcher and Gospodnetic, 2004). The documents and queries were segmented by our three approaches before indexing and searching process. In order to analyze the performance of our segmentation methods with different retrieval systems, we employed two score functions: the BM25 function (Peng et al., 2002b) 4; and BM25Beta (Function 4), which prefers documents with more query terms. Score(Q, D) = { = (l+p).N �% o score(ti, D) if T &lt; N (4) ∑NO No score(ti, D) if T = N i In the above equation, score(ti7 D) is the score of the term ti in the document D. Although we used BM25 as our base score function for score(ti7 D), it can be replaced by other score functions, such as tf*idf, or a probability language model. β is a parameter to control a penalty component for those documents that do not contain all the query terms; T is the number of distinctive query terms in the document; and N is the number</context>
</contexts>
<marker>Peng, Huang, Schuurmans, Cercone, Robertson, 2002</marker>
<rawString>Peng, Fuchun, Xiangji Huang, Dale Schuurmans, Nick Cercone, and Stephen E. Robertson. 2002. Using Self-supervised Word Segmentation in Chinese Information Retrieval. Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 349-350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchun Peng</author>
<author>Xiangji Huang</author>
<author>Dale Schuurmans</author>
<author>Nick Cercone</author>
</authors>
<title>Investigating the Relationship between Word Segmentation Performance and Retrieval Performance</title>
<date>2002</date>
<booktitle>in Chinese IR. Retrieval Performance in Chinese IR, Coling2002,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="1829" citStr="Peng et al., 2002" startWordPosition="269" endWordPosition="272">guishes Chinese Information Retrieval from information retrieval (IR) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters. In general, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their application in sophisticated IR tasks such as cross language IR, and within techniques such as query expansion (Nie et al., 2000; Peng et al., 2002a). Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al., 2003). However, the relationship between the accuracy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b) reported that segmentation methods achieving segmentation accuracy higher than 90% according to a manual segmentation standard yield no improvement in IR performance. They further argued that IR often benefits from splitting compound words that are anno</context>
<context position="4511" citStr="Peng et al., 2002" startWordPosition="704" endWordPosition="707">emantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the integration of the se</context>
<context position="6155" citStr="Peng et al., 2002" startWordPosition="987" endWordPosition="990">e et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and retrieval performance is non-monotonic, ranging from 44%-95%. They hypothesize that weak word segmenters are able to improve the accuracy of Chinese IR by breaking compound words into smaller constituents. Shi and Nie (2009) proposed a probabilitybased IR score function that combines a unigram score with a word score according to “phrase inseparability.” Candidates for words in the query are selected by a standard segmentation program. Their results </context>
<context position="22770" citStr="Peng et al., 2002" startWordPosition="3669" endWordPosition="3672">o combine these words with the consecutive one. For example, considering “f,R,W,f” (cumulated), the Treebank and Tight Split segment it into “�X|f” (cumulate + particle); while Online Tight leaves it unsegmented. 6.2 IR Experiment Setup We conducted our information retrieval experiments using the Lucene package (Hatcher and Gospodnetic, 2004). The documents and queries were segmented by our three approaches before indexing and searching process. In order to analyze the performance of our segmentation methods with different retrieval systems, we employed two score functions: the BM25 function (Peng et al., 2002b) 4; and BM25Beta (Function 4), which prefers documents with more query terms. Score(Q, D) = { = (l+p).N �% o score(ti, D) if T &lt; N (4) ∑NO No score(ti, D) if T = N i In the above equation, score(ti7 D) is the score of the term ti in the document D. Although we used BM25 as our base score function for score(ti7 D), it can be replaced by other score functions, such as tf*idf, or a probability language model. β is a parameter to control a penalty component for those documents that do not contain all the query terms; T is the number of distinctive query terms in the document; and N is the number</context>
</contexts>
<marker>Peng, Huang, Schuurmans, Cercone, 2002</marker>
<rawString>Peng, Fuchun, Xiangji Huang, Dale Schuurmans, and Nick Cercone. 2002. Investigating the Relationship between Word Segmentation Performance and Retrieval Performance in Chinese IR. Retrieval Performance in Chinese IR, Coling2002, 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lixin Shi</author>
<author>Jian-Yun Nie</author>
</authors>
<title>Integrating phrase inseparability in phrase-based model.</title>
<date>2009</date>
<booktitle>Proceedings of the 32th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>708--709</pages>
<contexts>
<context position="4552" citStr="Shi and Nie, 2009" startWordPosition="712" endWordPosition="715">efines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the integration of the semantic tightness measure into an IR syste</context>
<context position="6525" citStr="Shi and Nie (2009)" startWordPosition="1043" endWordPosition="1046">y results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that the relationship between segmentation accuracy and retrieval performance is non-monotonic, ranging from 44%-95%. They hypothesize that weak word segmenters are able to improve the accuracy of Chinese IR by breaking compound words into smaller constituents. Shi and Nie (2009) proposed a probabilitybased IR score function that combines a unigram score with a word score according to “phrase inseparability.” Candidates for words in the query are selected by a standard segmentation program. Their results show a small improvement in comparison with a static combination of unigram and word methods. Liu et al. (2008) is the research most similar to our proposed method. They point out that current segmentation methods which treat segmentation as a classification problem are not suitable for Chinese IR. They propose a ranking support vector machine (SVM) model to predict t</context>
</contexts>
<marker>Shi, Nie, 2009</marker>
<rawString>Shi, Lixin and Jian-Yun Nie. 2009. Integrating phrase inseparability in phrase-based model. Proceedings of the 32th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 708-709.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joaquim Silva</author>
<author>Sylvie Guillor´e Ga¨el Dias</author>
<author>Jos´e Gabriel Pereira Lopes</author>
</authors>
<title>Using LocalMaxs Algorithm for the Extraction of Contiguous and Noncontiguous Multiword Lexical Units.</title>
<date>1999</date>
<booktitle>In Proceedings of 9th Portuguese Conference in Artificial Intelligence (EPIA</booktitle>
<pages>849</pages>
<marker>Silva, Ga¨el Dias, Lopes, 1999</marker>
<rawString>Silva, Joaquim, Ga¨el Dias, Sylvie Guillor´e, and Jos´e Gabriel Pereira Lopes. 1999. Using LocalMaxs Algorithm for the Extraction of Contiguous and Noncontiguous Multiword Lexical Units. In Proceedings of 9th Portuguese Conference in Artificial Intelligence (EPIA 1999), 849.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Chilin Shih</author>
<author>William Gale</author>
<author>Nancy Chang</author>
</authors>
<title>A Stochastic Finite-State WordSegmentation Algorithm for Chinese.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>3</issue>
<pages>377--404</pages>
<contexts>
<context position="2690" citStr="Sproat et al., 1996" startWordPosition="403" endWordPosition="406">racy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b) reported that segmentation methods achieving segmentation accuracy higher than 90% according to a manual segmentation standard yield no improvement in IR performance. They further argued that IR often benefits from splitting compound words that are annotated as single units by manual segmentation. The essence of the problem is that there is no clear definition of word in Chinese. Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996). While units such as “��” (peanut) and “�T�9A” (match maker) should clearly be considered as a single term in Chinese IR, compounds such as “� * (machine learning) are more controversial.&apos; Xu et al. (2009) proposed a “continuum hypothesis” that rejects a clean binary classification of Chinese semantic units as either compositional or non-compositional. Instead, they introduced the notion of a tightness measure, which quantifies the degree of compositionality. On this tightness continuum, at one extreme are non&apos;This issue is also present to a certain degree in languages that do use explicit de</context>
</contexts>
<marker>Sproat, Shih, Gale, Chang, 1996</marker>
<rawString>Sproat, Richard, Chilin Shih, William Gale and Nancy Chang. 1996. A Stochastic Finite-State WordSegmentation Algorithm for Chinese. Computational Linguistics, 22(3), 377-404, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-In Song</author>
<author>Jung-Tae Lee</author>
<author>Hae-Chang Rim</author>
</authors>
<title>Word or Phrase? Learning Which Unit to Stress for Information Retrieval.</title>
<date>2009</date>
<booktitle>Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing,</booktitle>
<pages>1048--1056</pages>
<marker>Song, Lee, Rim, 2009</marker>
<rawString>Song, Young-In, Jung-Tae Lee, and Hae-Chang Rim. 2009. Word or Phrase? Learning Which Unit to Stress for Information Retrieval. Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, 1048-1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>ChengXiang Zhai</author>
</authors>
<title>An exploration of proximity measures in information retrieval.</title>
<date>2007</date>
<booktitle>Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>295--302</pages>
<marker>Tao, Zhai, 2007</marker>
<rawString>Tao, Tao and ChengXiang Zhai. 2007. An exploration of proximity measures in information retrieval. Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, 295-302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Vechtomova</author>
</authors>
<title>Approaches to using word collocation in information retrieval.</title>
<date>2001</date>
<tech>Ph.D. Thesis</tech>
<institution>City University,</institution>
<contexts>
<context position="8058" citStr="Vechtomova (2001)" startWordPosition="1282" endWordPosition="1283">) as tight, for example. Unlike their approach, our segmentation method tackles the problem by combining the tightness measure with a general segmentation method. Chinese word segmentation is closely related to multiword expression extraction. McCarthy et al. (2003) investigate various statistical measures of compositionality of candidate multiword verbs. 56 Silva et al. (1999) propose a new compositionality measure based on statistical information. The main difference with Xu et al.’s measure is that the latter is focused on word sense disambiguation. In terms of multiword expressions in IR, Vechtomova (2001) propose several approaches, such as query expansion, to incorporating English multiword expressions in IR. Braschler and Ripplinger (2004) analyze the effect of stemming and decompounding on German text retrieval. However, Chinese compound segmentation in IR is a thorny issue and needs more investigation for the reasons mentioned earlier. 3 Semantic Tightness Continuum We adopt the method developed by (Xu et al., 2009) for Chinese semantic unit tightness measure, which was shown to outperform the pointwise mutual information method. For the sake of completeness we briefly describe the basic a</context>
</contexts>
<marker>Vechtomova, 2001</marker>
<rawString>Vechtomova, Olga. 2001. Approaches to using word collocation in information retrieval. Ph.D. Thesis (City University, 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Xu</author>
<author>Christoph Ringlstetter</author>
<author>Randy Goebel</author>
</authors>
<title>A Continuum-based Approach for Tightness Analysis of Chinese Semantic Units.</title>
<date>2009</date>
<booktitle>Proc. of the 23rd Pacific Asia Conference on Language, Information and Computation,</booktitle>
<pages>569--578</pages>
<contexts>
<context position="2896" citStr="Xu et al. (2009)" startWordPosition="439" endWordPosition="442"> segmentation standard yield no improvement in IR performance. They further argued that IR often benefits from splitting compound words that are annotated as single units by manual segmentation. The essence of the problem is that there is no clear definition of word in Chinese. Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996). While units such as “��” (peanut) and “�T�9A” (match maker) should clearly be considered as a single term in Chinese IR, compounds such as “� * (machine learning) are more controversial.&apos; Xu et al. (2009) proposed a “continuum hypothesis” that rejects a clean binary classification of Chinese semantic units as either compositional or non-compositional. Instead, they introduced the notion of a tightness measure, which quantifies the degree of compositionality. On this tightness continuum, at one extreme are non&apos;This issue is also present to a certain degree in languages that do use explicit delimiters, including English (Halpern, 2000; McCarthy et al., 2003; Guenthner and Blanco, 2004). 55 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63, Beijing, Aug</context>
<context position="8481" citStr="Xu et al., 2009" startWordPosition="1344" endWordPosition="1347">d on statistical information. The main difference with Xu et al.’s measure is that the latter is focused on word sense disambiguation. In terms of multiword expressions in IR, Vechtomova (2001) propose several approaches, such as query expansion, to incorporating English multiword expressions in IR. Braschler and Ripplinger (2004) analyze the effect of stemming and decompounding on German text retrieval. However, Chinese compound segmentation in IR is a thorny issue and needs more investigation for the reasons mentioned earlier. 3 Semantic Tightness Continuum We adopt the method developed by (Xu et al., 2009) for Chinese semantic unit tightness measure, which was shown to outperform the pointwise mutual information method. For the sake of completeness we briefly describe the basic approach here. The input of the measure is the probability distribution of a unit’s segmentation patterns, i.e., potential segmentation candidates. The output is a tightness value; the greater the value, the tighter the unit. In this paper, we focus on 4- gram sequences because 4-character compounds are the most prominent in Chinese. There are eight possible segmentations of any 4-character sequence: “ABCD,” “A|BCD,” “A|</context>
</contexts>
<marker>Xu, Ringlstetter, Goebel, 2009</marker>
<rawString>Xu, Ying, Christoph Ringlstetter, and Randy Goebel. 2009. A Continuum-based Approach for Tightness Analysis of Chinese Semantic Units. Proc. of the 23rd Pacific Asia Conference on Language, Information and Computation, 569-578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Ping Zhang</author>
<author>Hong-Kui Yu</author>
<author>De-Yi Xiong</author>
<author>Qun Liu</author>
</authors>
<title>HHMM-based Chinese lexical analyzer ICTCLAS.</title>
<date>2003</date>
<booktitle>Proceedings of the 2nd SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>184--187</pages>
<contexts>
<context position="2026" citStr="Zhang et al., 2003" startWordPosition="299" endWordPosition="302">eneral, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their application in sophisticated IR tasks such as cross language IR, and within techniques such as query expansion (Nie et al., 2000; Peng et al., 2002a). Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al., 2003). However, the relationship between the accuracy of Chinese word segmentation and the performance of Chinese IR is non-monotonic. Peng et al. (2002b) reported that segmentation methods achieving segmentation accuracy higher than 90% according to a manual segmentation standard yield no improvement in IR performance. They further argued that IR often benefits from splitting compound words that are annotated as single units by manual segmentation. The essence of the problem is that there is no clear definition of word in Chinese. Experiments have shown only about 75% agreement among native speake</context>
<context position="19673" citStr="Zhang et al., 2003" startWordPosition="3175" endWordPosition="3178">establishing which segmenter is best for CIR, while pursuing the best segmentation performance in terms of segmented corpus is not the main crux. In this section, we first present the accuracy of different segmentation methods, and then discuss the results of IR systems. 6.1 Chinese Word Segmentation ICTCLAS is a Chinese segmentation tool built by the Institute of Computing Technology, Chinese Academy of Sciences. Its segmentation model is a 3The query set and relevance judgements are available at http://www.cs.ualberta.ca/˜yx2/research.html �k” 59 class-based hidden Markov model (HMM) model (Zhang et al., 2003). The segmenter is trained from manually segmented corpus, which makes it ignore both the tightness of units and unknown words such as “J-;ZM!M ” (Pinatubo), which are difficult to identify. In this experiment, we segmented the Chinese Treebank using ICTCLAS and our three methods that employ the tightness measure. The evaluation is based on the manual segmentation of the corpus. We evaluated the methods on the entire Treebank corpus, employing 10-cross validation for result significance verification. In order to measure the tightness of Chinese semantic units, pattern distributions of every 4-</context>
</contexts>
<marker>Zhang, Yu, Xiong, Liu, 2003</marker>
<rawString>Zhang, Hua-Ping, Hong-Kui Yu, De-Yi Xiong, and Qun Liu. 2003. HHMM-based Chinese lexical analyzer ICTCLAS. Proceedings of the 2nd SIGHAN Workshop on Chinese Language Processing, 184-187.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>