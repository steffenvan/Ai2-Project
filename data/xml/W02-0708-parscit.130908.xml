<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000051">
<note confidence="0.808534333333333">
Proceedings of the Workshop on Speech-to-Speech Translation:
Algorithms and Systems, Philadelphia, July 2002, pp. 53-60.
Association for Computational Linguistics.
</note>
<title confidence="0.998237">
Balancing Expressiveness and Simplicity
in an Interlingua for Task Based Dialogue
</title>
<author confidence="0.942275">
Lori Levin, Donna Gates, Dorcas Wallace, Fabio Pianesi, Emanuele Pianta,
Kay Peterson, Alon Lavie Roldano Cattoni, Nadia Mana
</author>
<affiliation confidence="0.956976">
Language Technologies Institute IRST-itc, Italy
Carnegie Mellon University
</affiliation>
<address confidence="0.657077">
Pittsburgh, PA 15213
</address>
<email confidence="0.999372">
email: lsl@cs.cmu.edu
</email>
<sectionHeader confidence="0.995664" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999531684210526">
In this paper we compare two interlin-
gua representations for speech transla-
tion. The basis of this paper is a distri-
butional analysis of the C-STAR II and
NESPOLE databases tagged with inter-
lingua representations. The C-STAR II
database has been partially re-tagged
with the NESPOLE interlingua, which
enables us to make comparisons on the
same data with two types of interlin-
guas and on two types of data (C-
STAR II and NESPOLE) with the same
interlingua. The distributional infor-
mation presented in this paper show
that the NESPOLE interlingua main-
tains the language-independence and
simplicity of the C-STAR II speech-act-
based approach, while increasing se-
mantic expressiveness and scalability.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979333333334">
Several speech translation projects have chosen
interlingua-based approaches because of its con-
venience (especially in adding new languages)
in multi-lingual projects. However, interlingua
design is notoriously difficult and inexact. The
main challenge is deciding on the grain size of
meaning to represent and what facets of mean-
ing to include. This may depend on the do-
main and the contexts in which the translation
system is used. For projects that take place at
multiple research sites, another factor becomes
important in interlingua design: if the interlin-
gua is too complex, it cannot be used reliably by
researchers at remote sites. Furthermore, the in-
terlingua should not be biased toward one fam-
ily of languages. Finally, an interlingua should
clearly distinguish general and domain specific
components for easy scalability and portability
between domains.
Sections 2 and 3 describe how we balanced
the factors of grain-size, language independence,
and simplicity in two interlinguas for speech
translation projects — the C-STAR II Inter-
change Format (Levin et al., 1998) and the NE-
SPOLE Interchange Format. Both interlinguas
are based in the framework of domain actions
as described in (Levin et al., 1998). We will
show that the NESPOLE interlingua has a finer
grain-size of meaning, but is still simple enough
for collaboration across multiple research sites,
and still maintains language-independence.
Section 4 will address the issue of scalabil-
ity of interlinguas based on domain actions to
larger domains. The basis of Section 4 is a dis-
tributional analysis of the C-STAR II and NE-
SPOLE databases tagged with interlingua repre-
sentations. The C-STAR II database has been
partially re-tagged with the NESPOLE interlin-
gua, which enables us to make comparisons on
the same data with two types of interlinguas and
on two types of data (C-STAR II and NESPOLE)
with the same type of interlingua.
</bodyText>
<sectionHeader confidence="0.937531" genericHeader="introduction">
2 The C-STAR II Domain, Database,
and Interlingua
</sectionHeader>
<bodyText confidence="0.997366333333333">
The C-STAR II interlingua (Levin et al., 1998)
was developed between 1997 and 1999 for use
in the C-STAR II 1999 demo (www.c-star.org).
</bodyText>
<figure confidence="0.993438">
c: can I have some flight times
that would leave some time around June sixth
a: the there are several flights leaving D C
there’d be one at one twenty four
there’s a three fifty nine flight
that arrives at four fifty eight
...
what time would you like to go
c: I would take the last one that you mentioned
...
a: what credit card number would you like
to reserve this with
c: I have a visa card
and the number is double oh five three
three one one six
ninety nine eighty seven
a okay
c: the expiration date is eleven ninety seven
...
a okay they should be ready tomorrow
c: okay thank you very much
</figure>
<figureCaption confidence="0.999933">
Figure 1: Excerpt from a C-STAR II dialogue
</figureCaption>
<bodyText confidence="0.99973825">
with six participating research sites. The seman-
tic domain was travel, including reservations
and payments for hotels, tours, and transporta-
tion. Figure 1 shows a sample dialogue from
the C-STAR II database. (C is the client and a
is the travel agent.) The C-STAR II database
contains 2278 English sentences and 7148 non-
English (Japanese, Italian, Korean) sentences
tagged with interlingua representations. Most
of the database consists of transcripts of role-
playing conversations.
The driving concept behind the C-STAR II
interlingua is that there are a limited num-
ber of actions in the domain — requesting the
price of a room, telling the price of a room,
requesting the time of a flight, giving a credit
card number, etc. — and that each utter-
ance can be classified as an instance of one
of these domain actions. Figure 2 illustrates
the components of the C-STAR II interlingua:
</bodyText>
<listItem confidence="0.904563666666667">
(1) the speaker tag, in this case c for client,
(2) a speech act (request-action), (3) a list
of concepts (reservation, temporal, hotel),
(4) arguments (e.g., time), and (5) values of ar-
guments. The C-STAR II interlingua specifica-
tion document contains definitions for 44 speech
</listItem>
<bodyText confidence="0.981559916666667">
acts, 93 concepts, and 117 argument names.
The domain action is the part of the interlin-
gua consisting of the speech act and concepts, in
this case request-action+reservation+tem-
poral+hotel. The domain action does not in-
clude the list of argument-value pairs.
First it is important to point out that do-
main actions are created compositionally. A do-
main action consists of a speech act followed by
zero or more concepts. (Recall that argument-
value pairs are not part of the domain action.)
The NESPOLE interlingua includes 65 speech
acts and 110 concepts. An interlingua specifi-
cation document defines the legal combinations
of speech acts and arguments.
The linguistic justification for an interlingua
based on domain-actions is that many travel do-
main utterances contain fixed, formulaic phrases
(e.g., can you tell me; I was wondering; how
about; would you mind, etc.) that signal domain
actions, but either do not translate literally into
other languages or have a meaning that is suffi-
ciently indirect that the literal meaning is irrele-
vant for translation. To take two examples, how
about as a signal of a suggestion does not trans-
late into other languages with the words corre-
sponding to how and about. Also, would you
mind might translate literally into some Euro-
pean languages as a way of signaling a request,
but the literal meaning of minding is not rel-
evant to the translation, only the fact that it
signals politeness.
The measure of success for the domain-action
based interlingua (as described in (Levin et al.,
2000a)) is that (1) it covers the data in the C-
STAR II database with less than 8% no-tag rate,
</bodyText>
<listItem confidence="0.896787">
(2) inter-coder agreement across research sites
is reasonably high: 82% for speech acts, 88%
for concepts, and 65% for domain actions, and
(3) end-to-end translation results using an an-
alyzer and generator written at different sites
were about the same as end-to-end translation
results using an analyzer and generator written
at the same site.
</listItem>
<sectionHeader confidence="0.943337" genericHeader="method">
3 The NESPOLE Domain, Database,
and Interlingua
</sectionHeader>
<bodyText confidence="0.984113571428571">
The NESPOLE interlingua has been under devel-
opment for the last two years as part of the NE-
SPOLE project (http://nespole.itc.it). Fig-
I would like to make a hotel reservation for the fourth through
the seventh of july
c:request-action+reservation+temporal+hotel
(time=(start-time=md4, end-time=(md7, july)))
</bodyText>
<figureCaption confidence="0.99893">
Figure 2: Example of a C-STAR II interlingua representation
</figureCaption>
<bodyText confidence="0.9999725">
ure 3 shows a NESPOLE dialogue. The NE-
SPOLE domain does not include reservations and
payments, but includes more detailed inquiries
about hotels and facilities for ski vacations and
summer vacations in Val di Fiemme, Italy. (The
tourism board of the Trentino area is a partner
of the NESPOLE project.) Most of the database
consists of transcripts of dialogues between an
Italian-speaking travel agent and an English or
German speaker playing the role of a traveller.
There are fewer fixed, formulaic phrases in the
NESPOLE domain, prompting us to move toward
domain actions that are more general, and also
requiring more detailed interlingua representa-
tions. Changes from the C-STAR II interlingua
fall into several categories:
</bodyText>
<listItem confidence="0.865625333333334">
1. Extending semantic expressivity and
syntactic coverage: Increased coverage of
modality, tense, aspect, articles, fragments,
coordinate structures, number, and rhetor-
ical relations. In addition, we have added
more explicit representation of grammati-
cal relations and improved capabilities for
representing modification and embedding.
2. Additional Domain-Specific Con-
cepts: New concepts include giving
directions, describing sizes and dimensions
of objects, traveling routes, equipment and
gear, airports, tourist services, facilities,
vehicles, information objects (brochures,
web pages, rules and regulations), hours
of operation of businesses and attractions,
etc.
3. Utterances that accompany multi-
modal gestures: The NESPOLE system
includes capabilities to share web pages
and draw marks such as circles and arrows
</listItem>
<bodyText confidence="0.95550275">
on web pages. The interlingua was ex-
tended to cover colord, descriptions of two-
dimensional objects, and actions of show-
ing.
</bodyText>
<listItem confidence="0.881476285714286">
4. General concept names from Word-
Net: The NESPOLE interlingua includes
conventions for making new concept names
based on WordNet synsets.
5. More general domain actions replac-
ing specific ones: For example, replacing
hotel with accommodation.
</listItem>
<bodyText confidence="0.998112037037037">
Interlinguas based on domain actions con-
trast with interlinguas based on lexical seman-
tics (Dorr, 1993; Lee et al., 2001; Goodman and
Nirenburg, 1991). A lexical-semantic interlingua
includes a representation of predicates and their
arguments. For example, the sentence I want to
take a vacation has a predicate want with two
arguments I and to take a vacation, which in
turn has a predicate take and two arguments, I
and a vacation. Of course, predicates like take
may be represented as word senses that are less
language-dependent like participate-in. The
strength and weakness of the lexical-semantic
approach is that it is less domain dependent
than the domain-action approach.
In order to cover the less formulaic utterances
of the NESPOLE domain, we have taken a step
closer to the lexical-semantic approach. How-
ever, we have maintained the overall framework
of the domain-action approach because there are
still many formulaic utterances that are better
represented in a non-literal way. Also, in or-
der to abstract away from English syntax, con-
cepts such as disposition, eventuality, and obli-
gation are not represented in the interlingua as
argument-taking main verbs in order to accom-
modate languages in which these meanings are
</bodyText>
<table confidence="0.58925375">
c: and I have some questions about coming about a trip I’m gonna be taking to Trento
a: okay what are your questions
c: I currently have a hotel booking at the
Panorama-Hotel in Panchia but at the moment I have no idea how to get to my hotel from Trento
and I wanted to ask what would be the best way for me to get there
a: okay I’m gonna show you a map that and then describe the directions to you
okay so right so you will arrive in the train station in Trento
the that is shown in the middle of the map stazione FFSS
and just below that here is a bus stop labeled number forty
so okay on the map that I’m showing you here
the hotel is the orange building off on the right hand side
...
</table>
<tableCaption confidence="0.7480796">
c: I also wanted to ask about skiing in the area once I’m in Panchia
a: all right just a moment and I’ll show you another map
c: okay
a: okay so on the map you see now Panchia is right in the center of the map
c: I see it
</tableCaption>
<figureCaption confidence="0.991877">
Figure 3: Excerpt from a NESPOLE dialogue
</figureCaption>
<bodyText confidence="0.999983727272727">
represented as adverbs or suffixes on verbs. Fig-
ure 4 shows the NESPOLE interlingua represen-
tation corresponding to the C-STAR II interlin-
gua in Figure 2. The specification document for
the NESPOLE interlingua defines 65 speech acts,
110 concepts, 292 arguments, and 7827 values
grouped into 222 value classes. As in the C-
STAR II interlingua, domain actions are defined
compositionally from speech acts and arguments
in combinations that are allowed by the interlin-
gua specification.
</bodyText>
<subsectionHeader confidence="0.988903">
3.1 Comparison of NESPOLE and
</subsectionHeader>
<sectionHeader confidence="0.571099" genericHeader="method">
C-STAR II Interlinguas
</sectionHeader>
<bodyText confidence="0.9864289">
It is useful to compare the NESPOLE and C-
STAR II Interlinguas in expressivity, language in-
dependence, and simplicity.
Expressivity of the NESPOLE interlingua,
Argument 1: The metric we use for expres-
sivity is the no-tag rate in the databases. The
no-tag rate is the percentage of sentences that
cannot be assigned an interlingua representation
by a human expert. The C-STAR II database
tagged with C-STAR II interlingua had a no-
tag rate of 7.3% (Levin et al., 2000a). The
C-STAR II database tagged with NESPOLE in-
terlingua has a no-tag rate of 2.4%. More than
300 English sentences in the C-STAR II database
that were not covered by the C-STAR II interlin-
gua are now covered by the NESPOLE interlin-
gua. (See Table 2.) We conclude from this that
the NESPOLE interlingua is more expressive in
that it covers more data.
Language-independence of the NESPOLE
interlingua: We do not have a numerical
measure of language-independence, but we note
that interlinguas based on domain actions are
particularly suitable for avoiding translation
mismatches (Dorr, 1994), particularly head-
switching mismatches (e.g., I just arrived and
Je vient d’arriver where the meaning of recent
past is expressed by an adverb just or a syn-
tactic verb vient (venir).) Interlinguas based
on domain actions resolve head-switching mis-
matches by identifying the types of meanings
that are often involved in mismatches — modal-
ity, evidentiality, disposition, and so on — and
assigning them a representation that abstracts
away from predicate argument structure. In-
terlinguas based on domain actions also neu-
tralize the different ways of expressing indirect
speech acts within and across languages (for ex-
ample, Would you mind..., I was wondering if
you could...., and Please.... as ways of request-
ing an action). Although NESPOLE domain ac-
tions are more general than C-STAR II domain
actions, they maintain language independence
by abstracting away from predicate-argument
structure.
Simplicity and cross-site reliability of the
NESPOLE interlingua: Simplicity of an inter-
lingua is measured by cross-site reliability in
I would like to make a hotel reservation for the fourth through
the seventh of july
</bodyText>
<equation confidence="0.940424111111111">
C-star II Interlingua:
c:request-action+reservation+temporal+hotel
(time=(start-time=md4, end-time=(md7, july)))
Nespole Interlingua:
c:give-information+disposition+reservation+accommodation
(disposition=(who=i, desire),
reservation-spec=(reservation, identifiability=no),
accommodation-spec=hotel,
object-time=(start-time=(md=4), end-time=(md=7, month=7, incl-excl=inclusive)))}
</equation>
<figureCaption confidence="0.999582">
Figure 4: Example of NESPOLE interlingua representation
</figureCaption>
<bodyText confidence="0.999971409090909">
inter-coder agreement and end-to-end transla-
tion performance. At the time of writing this pa-
per we have not conducted cross-site inter-coder
agreement experiments using the NESPOLE in-
terlingua. We have, however, conducted cross-
site evaluations (Lavie et al., 2002), in which the
analyzer and generator were written at differ-
ent sites. Experiments at the end of C-STAR II
showed that cross-site evaluations were compa-
rable to intra-site evaluations (analyzer and gen-
erator written at the same site) (Levin et al.,
2000b). NESPOLE evaluations so far show a loss
of cross-site reliability: intra-site evaluations are
noticeably better than cross-site evaluations, as
reported in (Lavie et al., 2002). This seems to
indicate that developers at different sites have
a lower level of agreement on the NESPOLE in-
terlingua. However there are other possible ex-
planations for the discrepancy — for example
developers at different sites may have focused
their development on different sub-domains —
that are currently under investigation.
</bodyText>
<sectionHeader confidence="0.9856775" genericHeader="method">
4 Scalability of the NESPOLE
Interlingua
</sectionHeader>
<bodyText confidence="0.990806361111111">
The rest of this paper addresses the scalability
of the NESPOLE interlingua. A possible criti-
cism of domain actions is that they are domain
dependent and that the number of domain ac-
tions might increase too quickly with the size
of the domain. In this section, we will examine
the rate of increase in the number of domain ac-
tions as a function of the amount of data and
the diversity of the data.
Differences in the C-STAR and NESPOLE Do-
mains: We will first show that the C-STAR
and NESPOLE domains are significantly different
even though they both pertain to travel. The
combination of the two domains is therefore sig-
nificantly larger than either domain alone.
In order to demonstrate the differences be-
tween the C-STAR travel domain and the NE-
SPOLE travel domain, we measured the overlap
in vocabulary. The numbers in Table 4 are based
on the first 7900 word tokens in the C-STAR En-
glish database and the first 7900 word tokens
in the NESPOLE English database. The table
shows the number of unique word types in each
database, the number of word types that occur
in both databases, and the number of word types
that occur in one of the databases, but not in the
other. In each database, about half of the word
types overlap with the other database. The non-
overlapping vocabulary (402 C-STAR word types
and 344 NESPOLE word types) indicates that the
two databases cover quite different aspects of the
travel domain.
Scalability: Argument 1: We will now be-
gin to address the issue of scalability of the
domain action approach to interlingua design.
Our first argument concerns the number of
</bodyText>
<table confidence="0.9969215">
Number of unique word types
CSTAR English 745
Nespole English 687
Word types in both CSTAR and Nespole 343
Words types in CSTAR not in Nespole 402
Words types n Nespole not in CSTAR 344
</table>
<tableCaption confidence="0.931089">
Table 1: Number of overlapping word types in the C-STAR English and NESPOLE English
databases
</tableCaption>
<table confidence="0.999486714285714">
SA Con. Snts. Domain Ac-
tions
Old C-STAR English 44 93 2278 358
New C-STAR English 65 110 2564 452
NESPOLE English 65 110 1446 337
NESPOLE German 65 110 3298 427
NESPOLE Italian 65 110 1063 206
</table>
<tableCaption confidence="0.996792">
Table 2: Number of unique domain actions in interlingua databases
</tableCaption>
<bodyText confidence="0.999918263157895">
speech acts and concepts in the combined C-
STAR/NESPOLE domain. The C-STAR II in-
terlingua, designed for coverage of the C-STAR
travel domain, included 44 speech acts and 93
concepts. The NESPOLE interlingua, designed
for coverage of the combined C-STAR and NE-
SPOLE domains, has 65 speech acts and 110 con-
cepts. Thus a relatively small increase in the
number of speech acts and concepts is required
to cover a significantly larger domain.
The increased size of the C-STAR/NEPSOLE
domain is reflected in the number of arguments
and values. The C-STAR II interlingua contained
definitions for 117 arguments, whereas the NE-
SPOLE interlingua contains definitions for 292 ar-
guments. The number of values for arguments
also has increased significantly in the NESPOLE
domain. There are 7827 values grouped into 222
classes (airport names, days of the week, etc.).
</bodyText>
<subsectionHeader confidence="0.873117">
Distributional Data: number of domain
</subsectionHeader>
<bodyText confidence="0.989285888888889">
actions in each database: Next we will
present distributional data concerning the num-
ber of domain actions as a function of database
size. We will compare several databases: Old
C-STAR English (around 2278 sentences tagged
with C-STAR II interlingua), New C-STAR En-
glish (2564 sentences tagged with NESPOLE in-
terlingua, including the 2278 sentences from Old
C-STAR English), NESPOLE English, NESPOLE
German, and NESPOLE Italian. Table 2 shows
the number of sentences and the number of do-
main actions in each database. The number of
domain actions refers to the number of types,
not tokens, of domain actions.
Distributional data: Coverage of the top
50 domain actions: Table 3 shows the per-
centage of each database that is covered by the
5, 10, 20, and 50 most frequent domain actions
in that database. For each database, the do-
main actions were ordered by frequency. The
percentage of sentences covered by the top-n
domain actions was then calculated. For this
experiment, we separated sentences spoken by
the traveller (client) and sentences spoken by
the travel agent (agent). C-STAR data in Ta-
ble 3 refers to 2564 English sentences from the
C-STAR database that were tagged with NE-
SPOLE interlingua. NESPOLE data refers to the
English portion of the NESPOLE database (1446
sentences). Combined data refers to the combi-
nation of the two (4014 sentences).
Two points are worth noting about Table 3.
First, the NESPOLE agent data has a higher cov-
erage rate than the NESPOLE client data. That
is, more data is covered by the top-n domain
actions. This may be because there was was
</bodyText>
<table confidence="0.999680222222222">
Domain Actions Top 5 Top 10 Top 20 Top 50
Client
C-STAR data 33.6 42.7 53.1 66.7
NESPOLE data 31.7 43.5 53.9 66.5
Combined data 31.6 40.0 50.3 62.9
Agent
C-STAR data 33.8 42.8 54.1 67.3
NESPOLE data 39.0 47.8 56.1 71.4
Combined data 33.6 41.5 51.7 64.0
</table>
<tableCaption confidence="0.7147355">
Table 3: DA Coverage using NESPOLE interlingua on English data for both C-STAR and
NESPOLE
</tableCaption>
<bodyText confidence="0.983009757575758">
only a small amount of English agent data and
it was spoken by non-native speakers. Second,
the combined data has a slightly lower cover-
age rate than either the C-STAR or NESPOLE
databases alone. This is expected because, as
shown above, the combined domain is signifi-
cantly more diverse than either domain by itself.
Scalability: Argument 2: Table 3 provides
additional evidence for the scalability of the NE-
SPOLE interlingua to larger domains. In the
combined C-STAR and NESPOLE domain, the
top 50 domain actions cover only slightly less
data than the top 50 domain actions in either
domain separately. There is not, in fact, an ex-
plosion of domain actions when the two C-STAR
and NESPOLE domains are combined.
Distributional Data: domain actions as a
function of database size: Table 3 shows
that in each of our databases, the 50 most fre-
quent domain actions cover approximately 65%
of the sentences. The next issue we address is
the nature of the “tail” of less frequent domain
actions covering the remainder of the data.
Figure 5 shows the number of domain actions
as a function of data set size. Sampling was done
for intervals of 25 sentences starting at 100 sen-
tences. For each sample size s there was ten-fold
cross-validation. Ten random samples of size s
were chosen, and the number of different domain
actions in each sample was counted. The aver-
age of the number of domain actions in each of
the ten samples of size s are plotted in Figure 5.
The four databases represented in Figure 5 are
</bodyText>
<figureCaption confidence="0.9748775">
Figure 5: Number of domain actions as a function of
database size
</figureCaption>
<bodyText confidence="0.990682117647059">
the C-STAR English database tagged with C-
STAR II interlingua, the C-STAR II database
tagged with NESPOLE interlingua, the NESPOLE
English database, and the combined C-STAR
and NESPOLE English databases.
Expressivity, Argument 2: Figure 5 pro-
vides evidence for the increased expressivity of
the NESPOLE interlingua. In contrast to Ta-
ble 3, which deals with samples containing the
most frequent domain actions, the samples plot-
ted in Figure 5 contain random mixtures of fre-
quent and non-frequent domain actions. The
curve representing the C-STAR data with C-
STAR II interlingua is the slowest growing of the
four curves. This is because the grain-size of
meaning represented in the C-STAR II interlin-
gua was larger than in the NESPOLE interlin-
</bodyText>
<figure confidence="0.9784309375">
IF Coverage of Four Datasets
number of SDUs in sample
average number of unique DAs 700 Old CSTAR
over 10 random samples 600 New CSTAR
500 NESPOLE
400 Combined
300
200
100
0
100
700
1300
1900
2500
3100
</figure>
<bodyText confidence="0.99554384">
gua. Also many infrequent domain actions were
not covered by the C-STAR II interlingua. The
faster growth of the curve representing the C-
STAR data with NESPOLE interlingua indicates
improved expressivity of the NESPOLE interlin-
gua — it covers more of the infrequent domain
actions. The highest curve in Figure 5 repre-
sents the combined C-STAR and NESPOLE do-
mains. This curve is higher than the others be-
cause, as shown above, the two travel domains
are significantly different from each other.
Expressivity and Simplicity, the right bal-
ance: Comparing Table 3 and Figure 5, we ar-
gue that the NESPOLE interlingua strikes a good
balance between expressivity and simplicity. Ta-
ble 3 shows evidence for the simplicity of the NE-
SPOLE interlingua: Only 50 domain actions are
needed to cover 60-70% of the sentences in the
database. Figure 5 shows evidence for expressiv-
ity: because domain actions are compositionally
formed from speech acts and concepts, it is pos-
sible to form a large number of low-frequency
domain actions in order to cover the domain.
Over 600 domain actions are used in the com-
bined C-STAR and NESPOLE domains.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999991416666667">
We have presented a comparison of a purely
domain-action-based interlingua (the C-STAR II
interlingua) and a more expressive, but still
domain-action-based interlingua (the NESPOLE
interlingua). The data that we have presented
show that the more expressive interlingua has
better coverage of the domain (a decrease from
7.3% to 2.4% uncovered data in the C-STAR II
domain) and can also scale up to larger domains
without an explosion of domain actions. Thus
we have a reasonable compromise between sim-
plicity and expressiveness of the interlingua.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999860111111111">
We would like to acknowledge Hans-Ulrich Block
for first proposing the domain-action-based in-
terlingua to the C-STAR consortium. We would
also like to thank all of the C-STAR and NE-
SPOLE partners who have participated in the de-
sign of the interlingua. This work was supported
by NSF Grant 9982227 and EU Grant IST 1999-
11562 as part of the joint EU/NSF MLIAM re-
search initiative.
</bodyText>
<sectionHeader confidence="0.999171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999921361111111">
Bonnie J. Dorr. 1993. Machine Translation: A View
from the Lexicon. The MIT Press, Cambridge,
Massachusetts.
Bonnie J. Dorr. 1994. Machine Translation Diver-
gences: A Formal Description and Proposed Solu-
tion. Computational Linguistics, 20(4):597–633.
Kenneth Goodman and Sergei Nirenburg. 1991.
The KBMT Project: A Case Study in Knowledge-
Based Machine Translation. Morgan Kaufmann,
San Mateo, CA.
Alon Lavie, Florian Metze, Roldano Cattoni, and Er-
ica Constantini. 2002. A Multi-Perspective Eval-
uation of the NESPOLE! Speech-to-Speech Trans-
lation System. In Proceedings of Speech-to-Speech
Translation: Algorithms and Systems.
Young-Suk Lee, W. Yi, Clifford Weinstein, and
Stephanie Seneff. 2001. Interlingua-based broad-
coverage korean-to-english translation. In Pro-
ceedings of HLT, San Diego.
Lori Levin, Donna Gates, Alon Lavie, and Alex
Waibel. 1998. An Interlingua Based on Domain
Actions for Machine Translation of Task-Oriented
Dialogues. In Proceedings of the International
Conference on Spoken Language Processing (IC-
SLP’98), pages Vol. 4, 1155–1158, Sydney, Aus-
tralia.
Lori Levin, Donna Gates, Alon Lavie, Fabio Pianesi,
Dorcas Wallace, Taro Watanabe, and Monika
Woszczyna. 2000a. Evaluation of a Practical In-
terlingua for Task-Oriented Dialogue. In Work-
shop on Applied Interlinguas: Practical Applica-
tions of Interlingual Approaches to NLP, Seattle.
Lori Levin, Alon Lavie, Monika Woszczyna, Donna
Gates, Marsal Gavald`a, Detlef Koll, and Alex
Waibel. 2000b. The Janus-III Translation Sys-
tem. Machine Translation.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.458532">
<note confidence="0.950773">Proceedings of the Workshop on Speech-to-Speech Translation: Algorithms and Systems, Philadelphia, July 2002, pp. 53-60. Association for Computational Linguistics.</note>
<title confidence="0.946972">Balancing Expressiveness and in an Interlingua for Task Based Dialogue</title>
<author confidence="0.984488">Lori Levin</author>
<author confidence="0.984488">Donna Gates</author>
<author confidence="0.984488">Dorcas Fabio Pianesi</author>
<author confidence="0.984488">Emanuele Kay Peterson</author>
<author confidence="0.984488">Alon Roldano Cattoni</author>
<author confidence="0.984488">Nadia</author>
<affiliation confidence="0.82404">Language Technologies IRST-itc, Italy Carnegie Mellon</affiliation>
<address confidence="0.962551">Pittsburgh, PA</address>
<abstract confidence="0.99923945">In this paper we compare two interlingua representations for speech translation. The basis of this paper is a distrianalysis of the and tagged with interrepresentations. The database has been partially re-tagged the which enables us to make comparisons on the same data with two types of interlinand on two types of data and with the same interlingua. The distributional information presented in this paper show the maintains the language-independence and of the speech-actbased approach, while increasing semantic expressiveness and scalability.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Machine Translation: A View from the Lexicon.</title>
<date>1993</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="9508" citStr="Dorr, 1993" startWordPosition="1507" endWordPosition="1508">s that accompany multimodal gestures: The NESPOLE system includes capabilities to share web pages and draw marks such as circles and arrows on web pages. The interlingua was extended to cover colord, descriptions of twodimensional objects, and actions of showing. 4. General concept names from WordNet: The NESPOLE interlingua includes conventions for making new concept names based on WordNet synsets. 5. More general domain actions replacing specific ones: For example, replacing hotel with accommodation. Interlinguas based on domain actions contrast with interlinguas based on lexical semantics (Dorr, 1993; Lee et al., 2001; Goodman and Nirenburg, 1991). A lexical-semantic interlingua includes a representation of predicates and their arguments. For example, the sentence I want to take a vacation has a predicate want with two arguments I and to take a vacation, which in turn has a predicate take and two arguments, I and a vacation. Of course, predicates like take may be represented as word senses that are less language-dependent like participate-in. The strength and weakness of the lexical-semantic approach is that it is less domain dependent than the domain-action approach. In order to cover th</context>
</contexts>
<marker>Dorr, 1993</marker>
<rawString>Bonnie J. Dorr. 1993. Machine Translation: A View from the Lexicon. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Machine Translation Divergences: A Formal Description and Proposed Solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="13189" citStr="Dorr, 1994" startWordPosition="2147" endWordPosition="2148">(Levin et al., 2000a). The C-STAR II database tagged with NESPOLE interlingua has a no-tag rate of 2.4%. More than 300 English sentences in the C-STAR II database that were not covered by the C-STAR II interlingua are now covered by the NESPOLE interlingua. (See Table 2.) We conclude from this that the NESPOLE interlingua is more expressive in that it covers more data. Language-independence of the NESPOLE interlingua: We do not have a numerical measure of language-independence, but we note that interlinguas based on domain actions are particularly suitable for avoiding translation mismatches (Dorr, 1994), particularly headswitching mismatches (e.g., I just arrived and Je vient d’arriver where the meaning of recent past is expressed by an adverb just or a syntactic verb vient (venir).) Interlinguas based on domain actions resolve head-switching mismatches by identifying the types of meanings that are often involved in mismatches — modality, evidentiality, disposition, and so on — and assigning them a representation that abstracts away from predicate argument structure. Interlinguas based on domain actions also neutralize the different ways of expressing indirect speech acts within and across l</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Bonnie J. Dorr. 1994. Machine Translation Divergences: A Formal Description and Proposed Solution. Computational Linguistics, 20(4):597–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Goodman</author>
<author>Sergei Nirenburg</author>
</authors>
<title>The KBMT Project: A Case Study in KnowledgeBased Machine Translation.</title>
<date>1991</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="9556" citStr="Goodman and Nirenburg, 1991" startWordPosition="1513" endWordPosition="1516">stures: The NESPOLE system includes capabilities to share web pages and draw marks such as circles and arrows on web pages. The interlingua was extended to cover colord, descriptions of twodimensional objects, and actions of showing. 4. General concept names from WordNet: The NESPOLE interlingua includes conventions for making new concept names based on WordNet synsets. 5. More general domain actions replacing specific ones: For example, replacing hotel with accommodation. Interlinguas based on domain actions contrast with interlinguas based on lexical semantics (Dorr, 1993; Lee et al., 2001; Goodman and Nirenburg, 1991). A lexical-semantic interlingua includes a representation of predicates and their arguments. For example, the sentence I want to take a vacation has a predicate want with two arguments I and to take a vacation, which in turn has a predicate take and two arguments, I and a vacation. Of course, predicates like take may be represented as word senses that are less language-dependent like participate-in. The strength and weakness of the lexical-semantic approach is that it is less domain dependent than the domain-action approach. In order to cover the less formulaic utterances of the NESPOLE domai</context>
</contexts>
<marker>Goodman, Nirenburg, 1991</marker>
<rawString>Kenneth Goodman and Sergei Nirenburg. 1991. The KBMT Project: A Case Study in KnowledgeBased Machine Translation. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Florian Metze</author>
<author>Roldano Cattoni</author>
<author>Erica Constantini</author>
</authors>
<title>A Multi-Perspective Evaluation of the NESPOLE! Speech-to-Speech Translation System. In Proceedings of Speech-to-Speech Translation: Algorithms and Systems.</title>
<date>2002</date>
<contexts>
<context position="15005" citStr="Lavie et al., 2002" startWordPosition="2383" endWordPosition="2386">ime=md4, end-time=(md7, july))) Nespole Interlingua: c:give-information+disposition+reservation+accommodation (disposition=(who=i, desire), reservation-spec=(reservation, identifiability=no), accommodation-spec=hotel, object-time=(start-time=(md=4), end-time=(md=7, month=7, incl-excl=inclusive)))} Figure 4: Example of NESPOLE interlingua representation inter-coder agreement and end-to-end translation performance. At the time of writing this paper we have not conducted cross-site inter-coder agreement experiments using the NESPOLE interlingua. We have, however, conducted crosssite evaluations (Lavie et al., 2002), in which the analyzer and generator were written at different sites. Experiments at the end of C-STAR II showed that cross-site evaluations were comparable to intra-site evaluations (analyzer and generator written at the same site) (Levin et al., 2000b). NESPOLE evaluations so far show a loss of cross-site reliability: intra-site evaluations are noticeably better than cross-site evaluations, as reported in (Lavie et al., 2002). This seems to indicate that developers at different sites have a lower level of agreement on the NESPOLE interlingua. However there are other possible explanations fo</context>
</contexts>
<marker>Lavie, Metze, Cattoni, Constantini, 2002</marker>
<rawString>Alon Lavie, Florian Metze, Roldano Cattoni, and Erica Constantini. 2002. A Multi-Perspective Evaluation of the NESPOLE! Speech-to-Speech Translation System. In Proceedings of Speech-to-Speech Translation: Algorithms and Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>W Yi</author>
<author>Clifford Weinstein</author>
<author>Stephanie Seneff</author>
</authors>
<title>Interlingua-based broadcoverage korean-to-english translation.</title>
<date>2001</date>
<booktitle>In Proceedings of HLT,</booktitle>
<location>San Diego.</location>
<contexts>
<context position="9526" citStr="Lee et al., 2001" startWordPosition="1509" endWordPosition="1512">pany multimodal gestures: The NESPOLE system includes capabilities to share web pages and draw marks such as circles and arrows on web pages. The interlingua was extended to cover colord, descriptions of twodimensional objects, and actions of showing. 4. General concept names from WordNet: The NESPOLE interlingua includes conventions for making new concept names based on WordNet synsets. 5. More general domain actions replacing specific ones: For example, replacing hotel with accommodation. Interlinguas based on domain actions contrast with interlinguas based on lexical semantics (Dorr, 1993; Lee et al., 2001; Goodman and Nirenburg, 1991). A lexical-semantic interlingua includes a representation of predicates and their arguments. For example, the sentence I want to take a vacation has a predicate want with two arguments I and to take a vacation, which in turn has a predicate take and two arguments, I and a vacation. Of course, predicates like take may be represented as word senses that are less language-dependent like participate-in. The strength and weakness of the lexical-semantic approach is that it is less domain dependent than the domain-action approach. In order to cover the less formulaic u</context>
</contexts>
<marker>Lee, Yi, Weinstein, Seneff, 2001</marker>
<rawString>Young-Suk Lee, W. Yi, Clifford Weinstein, and Stephanie Seneff. 2001. Interlingua-based broadcoverage korean-to-english translation. In Proceedings of HLT, San Diego.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Donna Gates</author>
<author>Alon Lavie</author>
<author>Alex Waibel</author>
</authors>
<title>An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP’98),</booktitle>
<volume>4</volume>
<pages>pages</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2292" citStr="Levin et al., 1998" startWordPosition="337" endWordPosition="340"> at multiple research sites, another factor becomes important in interlingua design: if the interlingua is too complex, it cannot be used reliably by researchers at remote sites. Furthermore, the interlingua should not be biased toward one family of languages. Finally, an interlingua should clearly distinguish general and domain specific components for easy scalability and portability between domains. Sections 2 and 3 describe how we balanced the factors of grain-size, language independence, and simplicity in two interlinguas for speech translation projects — the C-STAR II Interchange Format (Levin et al., 1998) and the NESPOLE Interchange Format. Both interlinguas are based in the framework of domain actions as described in (Levin et al., 1998). We will show that the NESPOLE interlingua has a finer grain-size of meaning, but is still simple enough for collaboration across multiple research sites, and still maintains language-independence. Section 4 will address the issue of scalability of interlinguas based on domain actions to larger domains. The basis of Section 4 is a distributional analysis of the C-STAR II and NESPOLE databases tagged with interlingua representations. The C-STAR II database has</context>
</contexts>
<marker>Levin, Gates, Lavie, Waibel, 1998</marker>
<rawString>Lori Levin, Donna Gates, Alon Lavie, and Alex Waibel. 1998. An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues. In Proceedings of the International Conference on Spoken Language Processing (ICSLP’98), pages Vol. 4, 1155–1158, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Donna Gates</author>
<author>Alon Lavie</author>
<author>Fabio Pianesi</author>
<author>Dorcas Wallace</author>
<author>Taro Watanabe</author>
<author>Monika Woszczyna</author>
</authors>
<title>Evaluation of a Practical Interlingua for Task-Oriented Dialogue.</title>
<date>2000</date>
<booktitle>In Workshop on Applied Interlinguas: Practical Applications of Interlingual Approaches to NLP,</booktitle>
<location>Seattle.</location>
<contexts>
<context position="6637" citStr="Levin et al., 2000" startWordPosition="1078" endWordPosition="1081"> not translate literally into other languages or have a meaning that is sufficiently indirect that the literal meaning is irrelevant for translation. To take two examples, how about as a signal of a suggestion does not translate into other languages with the words corresponding to how and about. Also, would you mind might translate literally into some European languages as a way of signaling a request, but the literal meaning of minding is not relevant to the translation, only the fact that it signals politeness. The measure of success for the domain-action based interlingua (as described in (Levin et al., 2000a)) is that (1) it covers the data in the CSTAR II database with less than 8% no-tag rate, (2) inter-coder agreement across research sites is reasonably high: 82% for speech acts, 88% for concepts, and 65% for domain actions, and (3) end-to-end translation results using an analyzer and generator written at different sites were about the same as end-to-end translation results using an analyzer and generator written at the same site. 3 The NESPOLE Domain, Database, and Interlingua The NESPOLE interlingua has been under development for the last two years as part of the NESPOLE project (http://nes</context>
<context position="12597" citStr="Levin et al., 2000" startWordPosition="2050" endWordPosition="2053">ly from speech acts and arguments in combinations that are allowed by the interlingua specification. 3.1 Comparison of NESPOLE and C-STAR II Interlinguas It is useful to compare the NESPOLE and CSTAR II Interlinguas in expressivity, language independence, and simplicity. Expressivity of the NESPOLE interlingua, Argument 1: The metric we use for expressivity is the no-tag rate in the databases. The no-tag rate is the percentage of sentences that cannot be assigned an interlingua representation by a human expert. The C-STAR II database tagged with C-STAR II interlingua had a notag rate of 7.3% (Levin et al., 2000a). The C-STAR II database tagged with NESPOLE interlingua has a no-tag rate of 2.4%. More than 300 English sentences in the C-STAR II database that were not covered by the C-STAR II interlingua are now covered by the NESPOLE interlingua. (See Table 2.) We conclude from this that the NESPOLE interlingua is more expressive in that it covers more data. Language-independence of the NESPOLE interlingua: We do not have a numerical measure of language-independence, but we note that interlinguas based on domain actions are particularly suitable for avoiding translation mismatches (Dorr, 1994), partic</context>
<context position="15258" citStr="Levin et al., 2000" startWordPosition="2425" endWordPosition="2428">time=(md=7, month=7, incl-excl=inclusive)))} Figure 4: Example of NESPOLE interlingua representation inter-coder agreement and end-to-end translation performance. At the time of writing this paper we have not conducted cross-site inter-coder agreement experiments using the NESPOLE interlingua. We have, however, conducted crosssite evaluations (Lavie et al., 2002), in which the analyzer and generator were written at different sites. Experiments at the end of C-STAR II showed that cross-site evaluations were comparable to intra-site evaluations (analyzer and generator written at the same site) (Levin et al., 2000b). NESPOLE evaluations so far show a loss of cross-site reliability: intra-site evaluations are noticeably better than cross-site evaluations, as reported in (Lavie et al., 2002). This seems to indicate that developers at different sites have a lower level of agreement on the NESPOLE interlingua. However there are other possible explanations for the discrepancy — for example developers at different sites may have focused their development on different sub-domains — that are currently under investigation. 4 Scalability of the NESPOLE Interlingua The rest of this paper addresses the scalability</context>
</contexts>
<marker>Levin, Gates, Lavie, Pianesi, Wallace, Watanabe, Woszczyna, 2000</marker>
<rawString>Lori Levin, Donna Gates, Alon Lavie, Fabio Pianesi, Dorcas Wallace, Taro Watanabe, and Monika Woszczyna. 2000a. Evaluation of a Practical Interlingua for Task-Oriented Dialogue. In Workshop on Applied Interlinguas: Practical Applications of Interlingual Approaches to NLP, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Alon Lavie</author>
<author>Monika Woszczyna</author>
<author>Donna Gates</author>
<author>Marsal Gavald`a</author>
<author>Detlef Koll</author>
<author>Alex Waibel</author>
</authors>
<title>The Janus-III Translation System. Machine Translation.</title>
<date>2000</date>
<marker>Levin, Lavie, Woszczyna, Gates, Gavald`a, Koll, Waibel, 2000</marker>
<rawString>Lori Levin, Alon Lavie, Monika Woszczyna, Donna Gates, Marsal Gavald`a, Detlef Koll, and Alex Waibel. 2000b. The Janus-III Translation System. Machine Translation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>