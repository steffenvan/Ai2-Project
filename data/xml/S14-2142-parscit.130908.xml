<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019571">
<title confidence="0.982568">
UTH_CCB: A Report for SemEval 2014 Ð Task 7 Analysis of Clinical
Text
</title>
<author confidence="0.9958375">
Yaoyun Zhang1 Jingqi Wang1 Buzhou Tang2 Yonghui Wu1 Min Jiang1
Yukun Chen3 Hua Xu1*
</author>
<affiliation confidence="0.885682666666667">
1University of Texas 2Harbin Institute of Technology 3Vanderbilt University
School of Biomedical Shenzhen Graduate School Department of Biomedical
Informatics at Houston Shenzhen, 518055, China Informatics
</affiliation>
<address confidence="0.82575">
Houston, TX, 77030, USA Nashville, TN, 37240, USA
</address>
<email confidence="0.820544">
{Yaoyun.Zhang, Yonghui.Wu, Min.Jiang, Hua.Xu} @uth.tmc.edu
tangbuzhou@gmail.com yukun.chen@Vanderbilt.Edu
</email>
<sectionHeader confidence="0.9956" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979529411765">
This work describes the participation of the
University of Texas Health Science Center at
Houston (UTHealth) team on the SemEval 2014
– Task 7 analysis of clinical text challenge. The
task consisted of two subtasks: (1) disorder entity
recognition, recognizing mentions of disorder
concepts; (2) disorder entity encoding, mapping
each mention to a unique Concept Unique
Identifier (CUI) defined in Unified Medical
Language System (UMLS). We developed three
ensemble learning approaches for recognizing
disorder entities and a Vector Space Model based
method for encoding. Our approaches achieved
top rank in both subtasks, with the best F
measure of 0.813 for entity recognition and the
best accuracy of 74.1% for encoding, indicating
the proposed approaches are promising.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929833333333">
In recent years, clinical natural language
processing (NLP) has received great attention for
its critical role in unlocking information
embedded in clinical documents. Leveraging
such information can facilitate the secondary use
of electronic health record (EHR) data to
</bodyText>
<note confidence="0.5466615">
This work is licensed under a Creative Commons
Attribution 4.0 International Licence. Page numbers and
proceedings footer are added by the organisers. Licence
details:http://creativecommons.org/licenses/by/4.0/
</note>
<bodyText confidence="0.9929292">
promote clinical and translational research.
Clinical entity recognition, which recognizes
mentions of clinically relevant concepts (e.g.,
disorders, procedures, drugs etc.) in narratives,
and clinical entity encoding, which maps the
recognized entities to concepts in standard
vocabularies (e.g., UMLS CUI (Bodenreider,
2004)), are among the fundamental tasks in
clinical NLP research.
Many systems have been developed to extract
clinical concepts from various types of clinical
notes in last two decades, ranging from early
symbolic NLP systems heavily dependent on
domain knowledge to machine learning
algorithm based systems driven by increasingly
available annotated clinical corpora. The
representative systems include MedLEE
(Friedman et al., 1994), MetaMap (Aronson and
Lang, 2010), KnowledgeMap (Denny et al.,
2003), cTAKES (Savova et al., 2010), etc.
Clinical NLP challenges organized by the Center
for Informatics for Integrating Biology &amp; the
Beside (i2b2) have promoted research using
machine learning algorithms to recognize clinical
entities (Uzuner et al., 2010; Uzuner et al., 2011).
Unlike the previous i2b2 challenges, the
ShARe/CLEF challenge of clinical disorder
extraction and encoding held in 2013 took the
initiative to recognize disjoint entities, in
addition to entities made up of consecutive words
(Chapman et al., 2013). ShARe/CLEF challenge
also required encoding of the disorder entities to
Systematized Nomenclature Of Medicine
Clinical Terms (SNOMED-CT) (using UMLS
CUIs).
</bodyText>
<page confidence="0.972602">
802
</page>
<note confidence="0.730329">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 802–806,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.9998311">
In this paper, we describe our system for Task
7 of SemEval 2014, which followed the
requirements of 2013 ShARe/CLEF challenge.
Our system employed ensemble learning based
approaches for disorder entity recognition and a
Vector Space Model (VSM) based method for
mapping extracted entities to CUIs of SNOMED-
CT concepts. Our system was top-ranked among
all participating teams according to evaluation by
the organizer.
</bodyText>
<sectionHeader confidence="0.942825" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.999925111111111">
Our end-to-end system for Task 7 of SemEval
2014 consists of two components: disorder entity
recognition and encoding. The raw clinical notes
first went through the pre-processing modules for
rule-based sentence boundary detection and
tokenization. Extracted features were then used
to train two machine learning algorithm-based
entity recognition models, Conditional Random
Fields (CRFs) (Lafferty et al., 2001) and
Structural Support Vector Machines (SSVMs)
(Tsochantaridis et al., 2005), respectively. These
two models were ensembled with MetaMap, a
symbolic biomedical NLP system, by three
different approaches. Recognized entities were
mapped to SNOWMED-CT CUIs in the
encoding component. Detailed information of the
components are presented in the following
sections.
</bodyText>
<subsectionHeader confidence="0.916625">
2.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999946583333333">
The training and test sets of 2013
ShARe/CLEF challenge were used as the
training and development sets respectively for
system development in SemEval 2014 Task 7.
The training set consists of 199 notes and the
development set has 99 notes, both of which
were collected from four types of clinical notes
including discharge summaries (DIS), radiology
reports (RAD), and ECG/ECHO reports. Based
on a pre-defined guideline, disorder entities were
annotated for each note and then mapped to
UMLS CUIs of SNOMED-CT concepts.
Disorder entities not found in SNOMED-CT
were marked as “CUI-less”. The training set
contained 5811 disorder entities which were
mapped to 1007 unique CUIs or CUI-less. The
development set contained 5340 disorder entities
mapped to 795 CUIs or CUI-less. The test set
contained 133 notes, all of which were discharge
summaries. As the gold-standard annotation of
the test set is not released by the organizer, the
detailed annotation information of the test set is
not available. Table 1 shows the total counts of
notes, entities and CUIs in the three datasets.
</bodyText>
<table confidence="0.999398785714286">
Dataset Type Note Entity CUI CUI-
less
Train ALL 199 5816 4177 1639
ECHO 42 828 662 166
RAD 42 555 392 163
DIS 61 3589 2646 943
ECG 54 193 103 90
Dev ALL 99 5340 3619 1721
ECHO 12 338 241 97
RAD 12 162 126 36
DIS 75 4840 3252 1588
ECG 0 0 0
Test ALL 133 - -
DIS 133 - -
</table>
<tableCaption confidence="0.999883">
Table 1. Statistics of the dataset.
</tableCaption>
<subsectionHeader confidence="0.985788">
2.2 Disorder entity recognition
</subsectionHeader>
<bodyText confidence="0.997231735294118">
The disorder entity recognition component
consists of two modules: 1) the machine learning
(e.g., CRF and SSVM) based named entity
recognition (NER) module and 2) the ensemble
learning module. For the challenge of this year,
we mainly focused on the second ensemble
learning module.
Machine learning based NER Module. This
module was built based on our previous
challenge participation in the 2013 ShARe/CLEF
challenge (Tang et al., 2013). Annotated data
were typically converted into a BIO format in
machine learning-based NER systems. Each
word was assigned one of the three labels: B for
beginning of an entity, I for inside an entity, and
O for outside of an entity. A unique challenge of
this task is the high frequency (&gt;10%) of disjoint
disorders. For example, in the sentence “the left
atrium is not moderately dilated”, the
discontinuous phrase “left atriumÉdilated” is
defined as a disjoint disorder. Such entities could
not be directly represented using the traditional
BIO approach. Therefore, in addition to
traditional BIO tags used for labeling words in
the consecutive disorder entities, two sets of tags
were created for disjoint entities: (1) D{B, I} was
used to label disjoint entity words that are not
shared by multiple concepts; and (2) H{B, I} was
used to label head words that belonged to more
than two disjoint concepts. Ultimately, we
assigned one of the seven labels {B, I, O, DB,
DI, HB, HI} to each word. A few simple rules
were then defined to convert labeled words to
entities (Tang et al., 2013).
</bodyText>
<page confidence="0.994149">
803
</page>
<bodyText confidence="0.999958775510204">
We exploited two state-of-the-art machine
learning algorithms for disorder entity
recognition, namely CRF (Lafferty et al., 2001)
and SSVM (Tsochantaridis et al., 2005).
CRFsuite and SVMhmm were used to implement
CRF and SSVM respectively.
For features, we used bag-of-word, part-of-
speech from Stanford tagger, type of notes,
section information, word representation from
Brown clustering (Brown et al., 1992), random
indexing (Lund and Burgess, 1996) and semantic
categories of words based on UMLS lookup,
MetaMap, and cTAKES outputs. More detailed
information of this module can be found in our
paper for 2013 ShARe/CLEF challenge (Tang et
al., 2013).
One thing to note is that for word
representation features like Brown clustering and
random indexing, we only use the combination
of traning and development and test datasets for
feature extraction. The non-annotated corpus
provided by the SemEval organizers was not
employed currently. We do plan to pre-generate
word clusters and random indexing using the
provided corpus in the near future.
Ensemble Learning Module. Three
approaches were employed to consolidate the
CRF-model, SSVM-model and the MetaMap
outputs, namely machine learning classifier
based ensemble (ensembleML), majortiy voting
based ensemble (ensembleMV) and direct merging
of the entity recognition results from the three
models (ensembleDM).
In the ensembleML approach, a binary classifier
was trained to determine if the entities
recognized by the CRF-model, SSVM-model and
MetaMap were true positives. A new set of
features were then extracted for each candidate
entity, that included the specific models
recognizing the entity, the entity itself, n-gram
and word shape features of the first/last word of
the entity. A sliding window based feature was
extracted to check whether there was any
recognized entity within 20 characters before the
first and after the last word. Some features
extracted from the first module were also
employed. We used the open source toolkit
Liblinear (Fan et al., 2008), to build the binary
classifier for ensembleML.
</bodyText>
<subsectionHeader confidence="0.990045">
2.3 Disorder Entity Encoding
</subsectionHeader>
<bodyText confidence="0.9999728">
We developed a Vector Space Model (VSM)
based approach to find the most suitable CUI for
a given disorder entity. The disorder entity was
used as query and all the UMLS terms were
treated as documents. We used the cosine-
similarity score to rank the candidate terms. For
post-processing, if the top-ranked CUI was not a
disorder CUI, it was replaced with ‘CUI-less’.
‘CUI-less’ was also assigned to entities without
any retrieved candidate CUI.
</bodyText>
<subsectionHeader confidence="0.97375">
2.4 Experiments and Evaluation
</subsectionHeader>
<bodyText confidence="0.999985315789474">
Our system was developed and trained using
the enlarged training set by merging the 199
notes in the training set and the 99 notes in the
development set. All parameters of CRF, SSVM
and Liblinear were optimized by 10-fold cross-
validation on the enlarged training dataset. The
performance of disorder entity recognition was
evaluated by precision, recall and F-measure,
which were measured in both “strict” and “re-
laxed” modes. The “strict” mode was defined as
follows: a concept is correctly recognized if and
only if it can be matched exactly to a disorder
mention in the gold standard, and the “relaxed”
mode means that a disorder mention is correctly
recognized if it overlaps with any disorder men-
tion in the gold standard. For entity encoding, all
participating systems were evaluated using accu-
racy, in “strict” and “relaxed” modes, as defined
in (Suominen et al., 2013).
</bodyText>
<sectionHeader confidence="0.999857" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.999846083333333">
Table 2 and Table 3 show the best performance
of our systems in the SemEval 2014 Task 7 as
reported by the organizers, where “P”, “R”, “F”
denote precision, recall and F-measure
respectively. For disorder entity recognition, the
ensembleML based system outperformed the other
two ensemble approaches, achieving the best F-
measure of 0.813 under “strict” criterion and was
ranked first in the challenge. For encoding, our
system achieved an accuracy of 0.741 by
ensembleDM under “strict” criterion and was
again ranked first in the challenge.
</bodyText>
<table confidence="0.991261333333333">
Strict Relaxed
P R F P R F
ensembleML 84.3 78.6 81.3 93.6 86.6 90.0
</table>
<tableCaption confidence="0.995335">
Table 2. The disorder recognition performance
</tableCaption>
<table confidence="0.8723">
of our system for the SemEval 2014 task 7 (%).
Accuracy
Strict Relaxed
ensembleDM 0.741 0.873
</table>
<tableCaption confidence="0.832218">
Table 3. The SNOMED encoding performance
of our system for the SemEval 2014 task 7.
</tableCaption>
<page confidence="0.998317">
804
</page>
<sectionHeader confidence="0.998509" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999972333333334">
In this study, we developed an ensemble
learning-based approach to recognize disorder
entities and a vector space model-based method
to encode disorders to UMLS CUIs. Our system
was top-ranked among all participating teams.
However, there are still expectations for further
improvement.
For disorder entity recognition, directly
merging the entity recognition results of the three
models (ensembleDM) achieved the highest
encoding accuracy of 0.741. This shows the great
potential of performance enhancement by
combining different models. However, the
precision of ensembleDM was much lower than
the current machine learning-based ensemble
approach ensembleML. ensembleML improved the
precision to 84.3%, with the lowest recall of
78.6% among the three ensemble approaches.
Further investigations for balancing and
enhancing both precision and recall
simultaneously by combining different models
will be pursued in the follow-up studies.
For encoding, when a disorder entity can be
labelled with multiple CUIs in different contexts,
a more effective disambiguation model could be
exploited. Further, query expansion techniques
may be helpful and worth investigating. The
above methods should be potentially helpful to
address the problems caused by synonyms or
spelling variants.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999966545454545">
We developed a clinical disorder recognition and
encoding system that consists of a ensemble
learning-based approach to recognize disorder
entities and a vector space model-based method
to encode the identified disorders to UMLS CUIs
of SNOMED-CT concepts. The performance of
our system was top-ranked in the SemEval 2014
Task 7, indicating that our approaches are
promising. However, further improvements are
needed in order to enhance performance on
concept extraction and encoding in clinical text.
</bodyText>
<sectionHeader confidence="0.998302" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99221675">
This study is supported in part by grants from
NLM R01LM010681, NCI 1R01CA141307,
NIGMS 1R01GM102282 and CPRIT R1307
(H.X).
</bodyText>
<sectionHeader confidence="0.893837" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999573961538462">
Aronson, A. R., &amp; Lang, F.-M. (2010). An overview
of MetaMap: historical perspective and recent
advances. Journal of the American Medical
Informatics Association: JAMIA, 17(3), 229–236.
Bodenreider, O. (2004). The unified medical language
system (UMLS): integrating biomedical
terminology. Nucleic Acids Research, 32(suppl 1),
267–270.
Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V.
J. D., &amp; Lai, J. C. (1992). Class-Based n-gram
Models of Natural Language. Computational
Linguistics, 18, 467–479.
Denny, J. C., Irani, P. R., Wehbe, F. H., Smithers, J.
D., &amp; Spickard, A. (2003). The KnowledgeMap
Project: Development of a Concept-Based Medical
School Curriculum Database. AMIA Annual
Symposium Proceedings, 2003, 195–199.
Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R.,
&amp; Lin, C.-J. (2008). LIBLINEAR: A library for
large linear classification. The Journal of Machine
Learning Research, 9, 1871–1874.
Friedman, C., Alderson, P. O., Austin, J. H., Cimino,
J. J., &amp; Johnson, S. B. (1994). A general natural-
language text processor for clinical radiology.
Journal of the American Medical Informatics
Association, 1(2), 161–174.
Lafferty, J., McCallum, A., &amp; Pereira, F. C. N.
(2001). Conditional Random Fields: Probabilistic
Models for Segmenting and Labeling Sequence
Data. Departmental Papers (CIS).
Lund, K., &amp; Burgess, C. (1996). Producing high-
dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods,
Instruments, &amp; Computers, 28(2), 203–208.
Savova, G. K., Masanz, J. J., Ogren, P. V., Zheng, J.,
Sohn, S., Kipper-Schuler, K. C., &amp; Chute, C. G.
(2010). Mayo clinical Text Analysis and
Knowledge Extraction System (cTAKES):
architecture, component evaluation and
applications. Journal of the American Medical
Informatics Association: JAMIA, 17(5), 507–513.
Suominen, H., SalanterÌ, S., Velupillai, S., Chapman,
W. W., Savova, G., &amp; Elhadad, N. (2013).
Overview of the ShARe/CLEF eHealth Evaluation
Lab 2013. Information Access Evaluation.
Multilinguality, Multimodality, and Visualization,
2013, 212–231.
Tang, B., Cao, H., Wu, Y., Jiang, M., &amp; Xu, H.
(2013). Recognizing and Encoding Discorder
Concepts in Clinical Text using Machine Learning
and Vector Space Model. Workshop of
ShARe/CLEF eHealth Evaluation Lab 2013.
</reference>
<page confidence="0.985282">
805
</page>
<reference confidence="0.9996135">
Tsochantaridis, I., Joachims, T., Hofmann, T., &amp;
Altun, Y. (2005). Large margin methods for
structured and interdependent output variables.
Journal of Machine Learning Research, 6, 1453–
1484.
Uzuner, Ì., Solti, I., &amp; Cadag, E. (2010). Extracting
medication information from clinical text. Journal
of the American Medical Informatics Association,
17(5), 514–518.
Uzuner, Ì., South, B. R., Shen, S., &amp; DuVall, S. L.
(2011). 2010 i2b2/VA challenge on concepts,
assertions, and relations in clinical text. Journal of
the American Medical Informatics Association:
JAMIA, 18(5), 552–556.
</reference>
<page confidence="0.998814">
806
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.080216">
<title confidence="0.9631025">UTH_CCB: A Report for SemEval 2014 Ð Task 7 Analysis of Clinical Text</title>
<author confidence="0.9334235">Jingqi Buzhou Yonghui Min Hua</author>
<affiliation confidence="0.819216333333333">of Texas Institute of Technology University School of Biomedical Shenzhen Graduate School Department of Biomedical Informatics at Houston Shenzhen, 518055, China Informatics</affiliation>
<address confidence="0.6852465">Houston, TX, 77030, USA Nashville, TN, 37240, USA {Yaoyun.Zhang, Yonghui.Wu, Min.Jiang, Hua.Xu}</address>
<email confidence="0.982081">tangbuzhou@gmail.comyukun.chen@Vanderbilt.Edu</email>
<abstract confidence="0.885910944444445">This work describes the participation of the University of Texas Health Science Center at Houston (UTHealth) team on the SemEval 2014 – Task 7 analysis of clinical text challenge. The task consisted of two subtasks: (1) disorder entity recognition, recognizing mentions of disorder concepts; (2) disorder entity encoding, mapping each mention to a unique Concept Unique Identifier (CUI) defined in Unified Medical Language System (UMLS). We developed three ensemble learning approaches for recognizing disorder entities and a Vector Space Model based method for encoding. Our approaches achieved top rank in both subtasks, with the best F measure of 0.813 for entity recognition and the best accuracy of 74.1% for encoding, indicating the proposed approaches are promising.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A R Aronson</author>
<author>F-M Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association: JAMIA,</journal>
<volume>17</volume>
<issue>3</issue>
<pages>229--236</pages>
<contexts>
<context position="2585" citStr="Aronson and Lang, 2010" startWordPosition="351" endWordPosition="354">s etc.) in narratives, and clinical entity encoding, which maps the recognized entities to concepts in standard vocabularies (e.g., UMLS CUI (Bodenreider, 2004)), are among the fundamental tasks in clinical NLP research. Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe/CLEF challenge also required enco</context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>Aronson, A. R., &amp; Lang, F.-M. (2010). An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association: JAMIA, 17(3), 229–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bodenreider</author>
</authors>
<title>The unified medical language system (UMLS): integrating biomedical terminology.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<pages>267--270</pages>
<contexts>
<context position="2122" citStr="Bodenreider, 2004" startWordPosition="287" endWordPosition="288">ation can facilitate the secondary use of electronic health record (EHR) data to This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details:http://creativecommons.org/licenses/by/4.0/ promote clinical and translational research. Clinical entity recognition, which recognizes mentions of clinically relevant concepts (e.g., disorders, procedures, drugs etc.) in narratives, and clinical entity encoding, which maps the recognized entities to concepts in standard vocabularies (e.g., UMLS CUI (Bodenreider, 2004)), are among the fundamental tasks in clinical NLP research. Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics f</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Bodenreider, O. (2004). The unified medical language system (UMLS): integrating biomedical terminology. Nucleic Acids Research, 32(suppl 1), 267–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>P V deSouza</author>
<author>R L Mercer</author>
<author>V J D Pietra</author>
<author>J C Lai</author>
</authors>
<title>Class-Based n-gram Models of Natural Language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<pages>467--479</pages>
<contexts>
<context position="8015" citStr="Brown et al., 1992" startWordPosition="1209" endWordPosition="1212">two disjoint concepts. Ultimately, we assigned one of the seven labels {B, I, O, DB, DI, HB, HI} to each word. A few simple rules were then defined to convert labeled words to entities (Tang et al., 2013). 803 We exploited two state-of-the-art machine learning algorithms for disorder entity recognition, namely CRF (Lafferty et al., 2001) and SSVM (Tsochantaridis et al., 2005). CRFsuite and SVMhmm were used to implement CRF and SSVM respectively. For features, we used bag-of-word, part-ofspeech from Stanford tagger, type of notes, section information, word representation from Brown clustering (Brown et al., 1992), random indexing (Lund and Burgess, 1996) and semantic categories of words based on UMLS lookup, MetaMap, and cTAKES outputs. More detailed information of this module can be found in our paper for 2013 ShARe/CLEF challenge (Tang et al., 2013). One thing to note is that for word representation features like Brown clustering and random indexing, we only use the combination of traning and development and test datasets for feature extraction. The non-annotated corpus provided by the SemEval organizers was not employed currently. We do plan to pre-generate word clusters and random indexing using t</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V. J. D., &amp; Lai, J. C. (1992). Class-Based n-gram Models of Natural Language. Computational Linguistics, 18, 467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Denny</author>
<author>P R Irani</author>
<author>F H Wehbe</author>
<author>J D Smithers</author>
<author>A Spickard</author>
</authors>
<title>The KnowledgeMap Project: Development of a Concept-Based Medical School Curriculum Database. AMIA Annual Symposium Proceedings,</title>
<date>2003</date>
<pages>195--199</pages>
<contexts>
<context position="2620" citStr="Denny et al., 2003" startWordPosition="356" endWordPosition="359">ity encoding, which maps the recognized entities to concepts in standard vocabularies (e.g., UMLS CUI (Bodenreider, 2004)), are among the fundamental tasks in clinical NLP research. Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe/CLEF challenge also required encoding of the disorder entities to Sy</context>
</contexts>
<marker>Denny, Irani, Wehbe, Smithers, Spickard, 2003</marker>
<rawString>Denny, J. C., Irani, P. R., Wehbe, F. H., Smithers, J. D., &amp; Spickard, A. (2003). The KnowledgeMap Project: Development of a Concept-Based Medical School Curriculum Database. AMIA Annual Symposium Proceedings, 2003, 195–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-E Fan</author>
<author>K-W Chang</author>
<author>C-J Hsieh</author>
<author>X-R Wang</author>
<author>C-J Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>9</volume>
<pages>1871--1874</pages>
<contexts>
<context position="9634" citStr="Fan et al., 2008" startWordPosition="1456" endWordPosition="1459">fier was trained to determine if the entities recognized by the CRF-model, SSVM-model and MetaMap were true positives. A new set of features were then extracted for each candidate entity, that included the specific models recognizing the entity, the entity itself, n-gram and word shape features of the first/last word of the entity. A sliding window based feature was extracted to check whether there was any recognized entity within 20 characters before the first and after the last word. Some features extracted from the first module were also employed. We used the open source toolkit Liblinear (Fan et al., 2008), to build the binary classifier for ensembleML. 2.3 Disorder Entity Encoding We developed a Vector Space Model (VSM) based approach to find the most suitable CUI for a given disorder entity. The disorder entity was used as query and all the UMLS terms were treated as documents. We used the cosinesimilarity score to rank the candidate terms. For post-processing, if the top-ranked CUI was not a disorder CUI, it was replaced with ‘CUI-less’. ‘CUI-less’ was also assigned to entities without any retrieved candidate CUI. 2.4 Experiments and Evaluation Our system was developed and trained using the </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., &amp; Lin, C.-J. (2008). LIBLINEAR: A library for large linear classification. The Journal of Machine Learning Research, 9, 1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>P O Alderson</author>
<author>J H Austin</author>
<author>J J Cimino</author>
<author>S B Johnson</author>
</authors>
<title>A general naturallanguage text processor for clinical radiology.</title>
<date>1994</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>1</volume>
<issue>2</issue>
<pages>161--174</pages>
<contexts>
<context position="2551" citStr="Friedman et al., 1994" startWordPosition="346" endWordPosition="349">e.g., disorders, procedures, drugs etc.) in narratives, and clinical entity encoding, which maps the recognized entities to concepts in standard vocabularies (e.g., UMLS CUI (Bodenreider, 2004)), are among the fundamental tasks in clinical NLP research. Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe</context>
</contexts>
<marker>Friedman, Alderson, Austin, Cimino, Johnson, 1994</marker>
<rawString>Friedman, C., Alderson, P. O., Austin, J. H., Cimino, J. J., &amp; Johnson, S. B. (1994). A general naturallanguage text processor for clinical radiology. Journal of the American Medical Informatics Association, 1(2), 161–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F C N Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Departmental Papers (CIS).</title>
<date>2001</date>
<contexts>
<context position="4282" citStr="Lafferty et al., 2001" startWordPosition="596" endWordPosition="599">d a Vector Space Model (VSM) based method for mapping extracted entities to CUIs of SNOMEDCT concepts. Our system was top-ranked among all participating teams according to evaluation by the organizer. 2 Method Our end-to-end system for Task 7 of SemEval 2014 consists of two components: disorder entity recognition and encoding. The raw clinical notes first went through the pre-processing modules for rule-based sentence boundary detection and tokenization. Extracted features were then used to train two machine learning algorithm-based entity recognition models, Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Structural Support Vector Machines (SSVMs) (Tsochantaridis et al., 2005), respectively. These two models were ensembled with MetaMap, a symbolic biomedical NLP system, by three different approaches. Recognized entities were mapped to SNOWMED-CT CUIs in the encoding component. Detailed information of the components are presented in the following sections. 2.1 Dataset The training and test sets of 2013 ShARe/CLEF challenge were used as the training and development sets respectively for system development in SemEval 2014 Task 7. The training set consists of 199 notes and the development set </context>
<context position="7735" citStr="Lafferty et al., 2001" startWordPosition="1168" endWordPosition="1171">s used for labeling words in the consecutive disorder entities, two sets of tags were created for disjoint entities: (1) D{B, I} was used to label disjoint entity words that are not shared by multiple concepts; and (2) H{B, I} was used to label head words that belonged to more than two disjoint concepts. Ultimately, we assigned one of the seven labels {B, I, O, DB, DI, HB, HI} to each word. A few simple rules were then defined to convert labeled words to entities (Tang et al., 2013). 803 We exploited two state-of-the-art machine learning algorithms for disorder entity recognition, namely CRF (Lafferty et al., 2001) and SSVM (Tsochantaridis et al., 2005). CRFsuite and SVMhmm were used to implement CRF and SSVM respectively. For features, we used bag-of-word, part-ofspeech from Stanford tagger, type of notes, section information, word representation from Brown clustering (Brown et al., 1992), random indexing (Lund and Burgess, 1996) and semantic categories of words based on UMLS lookup, MetaMap, and cTAKES outputs. More detailed information of this module can be found in our paper for 2013 ShARe/CLEF challenge (Tang et al., 2013). One thing to note is that for word representation features like Brown clust</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., &amp; Pereira, F. C. N. (2001). Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Departmental Papers (CIS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lund</author>
<author>C Burgess</author>
</authors>
<title>Producing highdimensional semantic spaces from lexical cooccurrence.</title>
<date>1996</date>
<journal>Behavior Research Methods, Instruments, &amp; Computers,</journal>
<volume>28</volume>
<issue>2</issue>
<pages>203--208</pages>
<contexts>
<context position="8057" citStr="Lund and Burgess, 1996" startWordPosition="1215" endWordPosition="1218">assigned one of the seven labels {B, I, O, DB, DI, HB, HI} to each word. A few simple rules were then defined to convert labeled words to entities (Tang et al., 2013). 803 We exploited two state-of-the-art machine learning algorithms for disorder entity recognition, namely CRF (Lafferty et al., 2001) and SSVM (Tsochantaridis et al., 2005). CRFsuite and SVMhmm were used to implement CRF and SSVM respectively. For features, we used bag-of-word, part-ofspeech from Stanford tagger, type of notes, section information, word representation from Brown clustering (Brown et al., 1992), random indexing (Lund and Burgess, 1996) and semantic categories of words based on UMLS lookup, MetaMap, and cTAKES outputs. More detailed information of this module can be found in our paper for 2013 ShARe/CLEF challenge (Tang et al., 2013). One thing to note is that for word representation features like Brown clustering and random indexing, we only use the combination of traning and development and test datasets for feature extraction. The non-annotated corpus provided by the SemEval organizers was not employed currently. We do plan to pre-generate word clusters and random indexing using the provided corpus in the near future. Ens</context>
</contexts>
<marker>Lund, Burgess, 1996</marker>
<rawString>Lund, K., &amp; Burgess, C. (1996). Producing highdimensional semantic spaces from lexical cooccurrence. Behavior Research Methods, Instruments, &amp; Computers, 28(2), 203–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Savova</author>
<author>J J Masanz</author>
<author>P V Ogren</author>
<author>J Zheng</author>
<author>S Sohn</author>
<author>K C Kipper-Schuler</author>
<author>C G Chute</author>
</authors>
<title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association: JAMIA,</journal>
<volume>17</volume>
<issue>5</issue>
<pages>507--513</pages>
<contexts>
<context position="2650" citStr="Savova et al., 2010" startWordPosition="361" endWordPosition="364">recognized entities to concepts in standard vocabularies (e.g., UMLS CUI (Bodenreider, 2004)), are among the fundamental tasks in clinical NLP research. Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe/CLEF challenge also required encoding of the disorder entities to Systematized Nomenclature Of Med</context>
</contexts>
<marker>Savova, Masanz, Ogren, Zheng, Sohn, Kipper-Schuler, Chute, 2010</marker>
<rawString>Savova, G. K., Masanz, J. J., Ogren, P. V., Zheng, J., Sohn, S., Kipper-Schuler, K. C., &amp; Chute, C. G. (2010). Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications. Journal of the American Medical Informatics Association: JAMIA, 17(5), 507–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Suominen</author>
<author>S SalanterÌ</author>
<author>S Velupillai</author>
<author>W W Chapman</author>
<author>G Savova</author>
<author>N Elhadad</author>
</authors>
<title>Information Access Evaluation. Multilinguality, Multimodality, and Visualization,</title>
<date>2013</date>
<journal>Overview of the ShARe/CLEF eHealth Evaluation Lab</journal>
<pages>212--231</pages>
<contexts>
<context position="11064" citStr="Suominen et al., 2013" startWordPosition="1690" endWordPosition="1693">training dataset. The performance of disorder entity recognition was evaluated by precision, recall and F-measure, which were measured in both “strict” and “relaxed” modes. The “strict” mode was defined as follows: a concept is correctly recognized if and only if it can be matched exactly to a disorder mention in the gold standard, and the “relaxed” mode means that a disorder mention is correctly recognized if it overlaps with any disorder mention in the gold standard. For entity encoding, all participating systems were evaluated using accuracy, in “strict” and “relaxed” modes, as defined in (Suominen et al., 2013). 3 Results Table 2 and Table 3 show the best performance of our systems in the SemEval 2014 Task 7 as reported by the organizers, where “P”, “R”, “F” denote precision, recall and F-measure respectively. For disorder entity recognition, the ensembleML based system outperformed the other two ensemble approaches, achieving the best Fmeasure of 0.813 under “strict” criterion and was ranked first in the challenge. For encoding, our system achieved an accuracy of 0.741 by ensembleDM under “strict” criterion and was again ranked first in the challenge. Strict Relaxed P R F P R F ensembleML 84.3 78.6</context>
</contexts>
<marker>Suominen, SalanterÌ, Velupillai, Chapman, Savova, Elhadad, 2013</marker>
<rawString>Suominen, H., SalanterÌ, S., Velupillai, S., Chapman, W. W., Savova, G., &amp; Elhadad, N. (2013). Overview of the ShARe/CLEF eHealth Evaluation Lab 2013. Information Access Evaluation. Multilinguality, Multimodality, and Visualization, 2013, 212–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tang</author>
<author>H Cao</author>
<author>Y Wu</author>
<author>M Jiang</author>
<author>H Xu</author>
</authors>
<title>Recognizing and Encoding Discorder Concepts in Clinical Text using Machine Learning and Vector Space Model. Workshop of ShARe/CLEF eHealth Evaluation Lab</title>
<date>2013</date>
<contexts>
<context position="6511" citStr="Tang et al., 2013" startWordPosition="965" endWordPosition="968">340 3619 1721 ECHO 12 338 241 97 RAD 12 162 126 36 DIS 75 4840 3252 1588 ECG 0 0 0 Test ALL 133 - - DIS 133 - - Table 1. Statistics of the dataset. 2.2 Disorder entity recognition The disorder entity recognition component consists of two modules: 1) the machine learning (e.g., CRF and SSVM) based named entity recognition (NER) module and 2) the ensemble learning module. For the challenge of this year, we mainly focused on the second ensemble learning module. Machine learning based NER Module. This module was built based on our previous challenge participation in the 2013 ShARe/CLEF challenge (Tang et al., 2013). Annotated data were typically converted into a BIO format in machine learning-based NER systems. Each word was assigned one of the three labels: B for beginning of an entity, I for inside an entity, and O for outside of an entity. A unique challenge of this task is the high frequency (&gt;10%) of disjoint disorders. For example, in the sentence “the left atrium is not moderately dilated”, the discontinuous phrase “left atriumÉdilated” is defined as a disjoint disorder. Such entities could not be directly represented using the traditional BIO approach. Therefore, in addition to traditional BIO t</context>
<context position="8258" citStr="Tang et al., 2013" startWordPosition="1248" endWordPosition="1251">machine learning algorithms for disorder entity recognition, namely CRF (Lafferty et al., 2001) and SSVM (Tsochantaridis et al., 2005). CRFsuite and SVMhmm were used to implement CRF and SSVM respectively. For features, we used bag-of-word, part-ofspeech from Stanford tagger, type of notes, section information, word representation from Brown clustering (Brown et al., 1992), random indexing (Lund and Burgess, 1996) and semantic categories of words based on UMLS lookup, MetaMap, and cTAKES outputs. More detailed information of this module can be found in our paper for 2013 ShARe/CLEF challenge (Tang et al., 2013). One thing to note is that for word representation features like Brown clustering and random indexing, we only use the combination of traning and development and test datasets for feature extraction. The non-annotated corpus provided by the SemEval organizers was not employed currently. We do plan to pre-generate word clusters and random indexing using the provided corpus in the near future. Ensemble Learning Module. Three approaches were employed to consolidate the CRF-model, SSVM-model and the MetaMap outputs, namely machine learning classifier based ensemble (ensembleML), majortiy voting b</context>
</contexts>
<marker>Tang, Cao, Wu, Jiang, Xu, 2013</marker>
<rawString>Tang, B., Cao, H., Wu, Y., Jiang, M., &amp; Xu, H. (2013). Recognizing and Encoding Discorder Concepts in Clinical Text using Machine Learning and Vector Space Model. Workshop of ShARe/CLEF eHealth Evaluation Lab 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tsochantaridis</author>
<author>T Joachims</author>
<author>T Hofmann</author>
<author>Y Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>6</volume>
<pages>1453--1484</pages>
<contexts>
<context position="4359" citStr="Tsochantaridis et al., 2005" startWordPosition="606" endWordPosition="609">s to CUIs of SNOMEDCT concepts. Our system was top-ranked among all participating teams according to evaluation by the organizer. 2 Method Our end-to-end system for Task 7 of SemEval 2014 consists of two components: disorder entity recognition and encoding. The raw clinical notes first went through the pre-processing modules for rule-based sentence boundary detection and tokenization. Extracted features were then used to train two machine learning algorithm-based entity recognition models, Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Structural Support Vector Machines (SSVMs) (Tsochantaridis et al., 2005), respectively. These two models were ensembled with MetaMap, a symbolic biomedical NLP system, by three different approaches. Recognized entities were mapped to SNOWMED-CT CUIs in the encoding component. Detailed information of the components are presented in the following sections. 2.1 Dataset The training and test sets of 2013 ShARe/CLEF challenge were used as the training and development sets respectively for system development in SemEval 2014 Task 7. The training set consists of 199 notes and the development set has 99 notes, both of which were collected from four types of clinical notes </context>
<context position="7774" citStr="Tsochantaridis et al., 2005" startWordPosition="1174" endWordPosition="1177">consecutive disorder entities, two sets of tags were created for disjoint entities: (1) D{B, I} was used to label disjoint entity words that are not shared by multiple concepts; and (2) H{B, I} was used to label head words that belonged to more than two disjoint concepts. Ultimately, we assigned one of the seven labels {B, I, O, DB, DI, HB, HI} to each word. A few simple rules were then defined to convert labeled words to entities (Tang et al., 2013). 803 We exploited two state-of-the-art machine learning algorithms for disorder entity recognition, namely CRF (Lafferty et al., 2001) and SSVM (Tsochantaridis et al., 2005). CRFsuite and SVMhmm were used to implement CRF and SSVM respectively. For features, we used bag-of-word, part-ofspeech from Stanford tagger, type of notes, section information, word representation from Brown clustering (Brown et al., 1992), random indexing (Lund and Burgess, 1996) and semantic categories of words based on UMLS lookup, MetaMap, and cTAKES outputs. More detailed information of this module can be found in our paper for 2013 ShARe/CLEF challenge (Tang et al., 2013). One thing to note is that for word representation features like Brown clustering and random indexing, we only use </context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Tsochantaridis, I., Joachims, T., Hofmann, T., &amp; Altun, Y. (2005). Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6, 1453– 1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ì Uzuner</author>
<author>I Solti</author>
<author>E Cadag</author>
</authors>
<title>Extracting medication information from clinical text.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>17</volume>
<issue>5</issue>
<pages>514--518</pages>
<contexts>
<context position="2873" citStr="Uzuner et al., 2010" startWordPosition="393" endWordPosition="396">ous types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe/CLEF challenge also required encoding of the disorder entities to Systematized Nomenclature Of Medicine Clinical Terms (SNOMED-CT) (using UMLS CUIs). 802 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 802–806, Dublin, Ireland, August 23-24, 2014. In this paper, we describe our</context>
</contexts>
<marker>Uzuner, Solti, Cadag, 2010</marker>
<rawString>Uzuner, Ì., Solti, I., &amp; Cadag, E. (2010). Extracting medication information from clinical text. Journal of the American Medical Informatics Association, 17(5), 514–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ì Uzuner</author>
<author>B R South</author>
<author>S Shen</author>
<author>S L DuVall</author>
</authors>
<title>i2b2/VA challenge on concepts, assertions, and relations in clinical text.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association: JAMIA,</journal>
<volume>18</volume>
<issue>5</issue>
<pages>552--556</pages>
<contexts>
<context position="2895" citStr="Uzuner et al., 2011" startWordPosition="397" endWordPosition="400"> notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora. The representative systems include MedLEE (Friedman et al., 1994), MetaMap (Aronson and Lang, 2010), KnowledgeMap (Denny et al., 2003), cTAKES (Savova et al., 2010), etc. Clinical NLP challenges organized by the Center for Informatics for Integrating Biology &amp; the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (Uzuner et al., 2010; Uzuner et al., 2011). Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words (Chapman et al., 2013). ShARe/CLEF challenge also required encoding of the disorder entities to Systematized Nomenclature Of Medicine Clinical Terms (SNOMED-CT) (using UMLS CUIs). 802 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 802–806, Dublin, Ireland, August 23-24, 2014. In this paper, we describe our system for Task 7 of </context>
</contexts>
<marker>Uzuner, South, Shen, DuVall, 2011</marker>
<rawString>Uzuner, Ì., South, B. R., Shen, S., &amp; DuVall, S. L. (2011). 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text. Journal of the American Medical Informatics Association: JAMIA, 18(5), 552–556.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>