<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.992629">
Extraction of Author’s Definitions Using
Indexed Reference Identification
</title>
<author confidence="0.961646">
Marc Bertin, Iana Atanassova and Jean-Pierre Descles
</author>
<affiliation confidence="0.970945">
Paris-Sorbonne University
</affiliation>
<address confidence="0.874086333333333">
Maison de la Recherche
28 rue Serpente
75006 Paris
</address>
<email confidence="0.631419">
{Marc.bertin  |iana.atanassova  |jean-pierre.descles}@paris-sorbonne.fr
</email>
<sectionHeader confidence="0.927716" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.971725">
In this paper we present the implementation of
definition extraction from multilingual corpora of
scientific articles. We establish relations between
the definitions and authors by using indexed ref-
erences in the text. Our method is based on a
linguistic ontology designed for this purpose. We
propose two evaluations of the annotations.
</bodyText>
<sectionHeader confidence="0.985079" genericHeader="keywords">
Keywords
</sectionHeader>
<keyword confidence="0.967634">
Semantic annotation, definition extraction, indexed references
</keyword>
<sectionHeader confidence="0.998506" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978193548387">
The use of definitions plays an important role in a
number of scientific disciplines. The complexity of
some domains raises the necessity to develop tools for
the automatic annotation of information relevant to
definitions. The growth in scientific literature produc-
tion leads us to propose new tools for text navigation
and quick access to the textual information.
In this paper we explore a new way to extract def-
initions from scientific text corpora by establishing a
relation between the usage of a definition and a cited
author.
In section 2, we describe the elaboration of a lin-
guistic ontology, based on the analysis of multilingual
corpora. Then, the identification of indexed references
is used to establish the relations between authors.
In section 3, we explain our implementation. The
goal of our system is to provide to the user the possibil-
ity to clarify a notion and its usage in a given context
from a terminological or conceptual viewpoint. This
means that we need to maintain the link between the
extracted definitions and their contexts, in order to
provide access to the argumentation in the text. The
user can thus visualise the context in which the term in
question has been defined. Section 4 shows the results
produced by the application. In section 5 we discuss
the problem of the evaluation of the semantic annota-
tions and propose two types of evaluations: one by the
precision/recall measures and another by the Cohen’s
weighted Kappa coefficient.
Finally, we conclude by a discussion of the perspec-
tives for the utilisation of this tool.
</bodyText>
<sectionHeader confidence="0.990331" genericHeader="method">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999218285714286">
We propose a method for the identification of defini-
tions and also for the identification of relations be-
tween authors. This approach allows us to associate
a definition to an author and to establish a link with
other texts that could interest the user. The system
allows a fully automated text processing, which com-
prises several stages.
</bodyText>
<subsectionHeader confidence="0.865162">
2.1 Protocol
</subsectionHeader>
<bodyText confidence="0.99998">
Our protocol is as follows: first we carry out the identi-
fication of the sentences containing indexed references,
by using regular expressions. Then, we annotate the
definitions in the sentences identified in the previous
stage. Finally, we extract the definitions and create
indexes for the information retrieval. The results are
stored in a database. Different types of visualizations
and information retrieval are provided by our web-
based interface.
</bodyText>
<subsectionHeader confidence="0.997839">
2.2 Multilingual Corpora
</subsectionHeader>
<bodyText confidence="0.999390909090909">
We have constructed multilingual corpora, in order to
create our linguistic resources organized in a linguistic
ontology. The corpora comprise mainly scientific texts
and articles available online. The French corpus con-
sists of texts from several scientific reviews (Intellec-
tica, ALSIC, TALN, IRISA) and six PhD theses from
the domains of Linguistics and Computer science. The
articles in English corpus are from Nature, Journal of
Cell Science, Biophysical Journal, Proceedings of the
National Academy of Sciences, The Journal of Cell Bi-
ology, and others.
</bodyText>
<table confidence="0.41497375">
Corpus Texts Sentences
French 205 119410
English 116 38378
Total 321 158788
</table>
<tableCaption confidence="0.995382">
Table 1: Corpora
</tableCaption>
<bodyText confidence="0.99917925">
In table 1 we present the sizes of the corpora. In or-
der to ensure compatibility with the tools of segmenta-
tion and annotation, the corpora have been converted
into text files. The sentence counts are obtained after
</bodyText>
<page confidence="0.99322">
21
</page>
<subsubsectionHeader confidence="0.727996">
Workshop On Definition Extraction 2009 - Borovets, Bulgaria, pages 21–25,
</subsubsectionHeader>
<bodyText confidence="0.999681214285714">
the segmentation, which will be detailed later in the
section 3.2.2.
From a legal point of view, texts can be cited freely,
even if under copyright&apos;, provided that the following
three criteria are respected. Firstly, citations must be
short: our interface provides output in the form of
text segments corresponding to sentences. Secondly,
the purpose of extraction must be infromative, such
as in the case of information retrieval. Finally, the
source must be mentioned.
Moreover, we establish a relation between the defi-
nition and the cited document or author through the
bibliography. This stage is important for the creation
of an author network.
</bodyText>
<subsectionHeader confidence="0.998403">
2.3 Definition Ontology
</subsectionHeader>
<bodyText confidence="0.999987">
This section describes our linguistic approach and the
construction of an ontology for the annotation of def-
initions. The method we present is based on enun-
ciative discourse considerations and a corpus analysis,
through which we construct an ontology by abduction.
</bodyText>
<subsectionHeader confidence="0.541524">
2.3.1 Linguistic Analysis
</subsectionHeader>
<bodyText confidence="0.99828293877551">
We can examine a definition sentence by studying the
relation between the definiendum, what is to be de-
fined, and the definiens, what defines it. This lin-
guistic study of our corpus has led us to a better
understanding of the distinction between a definition
and a definatory characteristic, which has been taken
in consideration for the construction of our linguis-
tic resources. We define a definatory characteristic as
a sentence that gives only some essential properties
of the defined object. We have distinguished three
categories of definatory characteristics: identification,
determined categorization and pseudo-definition. We
have also considered two sub-categories of the defi-
nition: general definitions and axiomatic definitions.
The full ontology that we have created contains some
further sub-categorizations that are presented on fig-
ure 1.
The categorization in this linguistic ontology is
based on an analysis of the types of relations. Here
we will describe briefly the differences between some
of the categories that we have retained.
Firstly, it must be noted that in definition sentences,
apart from the relation between the definiendum and
the definiens, there exists a second relation, which is
between this first relation and the agent who estab-
lished the definition. The presence of this agent is not
always manifested in discourse and sometimes there is
no actual trace. In the case when the agent is present
in the text, we can speak of a contextualised definition,
because it is often marked in the context by a deictic,
which is limited to a domain or to a period in time,
or else introduced by a passive construction or ’on’ in
French.
Secondly, we have axiomatic definitions, which are
utterances expressing a primary truth.
Finally, there are cases where the author uses a re-
ported definition. In these cases the enunciator can
&apos; cf. CPI art L. 122-5
choose whether to attest the definition or not, in or-
der to use it in the elaboration of a demonstration,
or to introduce a new notion. This type of definitions
takes part in the text evolution by means of modalities
and we speak of committed definition.
The objective that we have fixed is to extract def-
inition sentences, in which the definition is explicitly
attributed to an author or another work, cited in the
text. We will also call them signed definitions, which
correspond to the category of Reported Definitions in
our ontology.
</bodyText>
<figureCaption confidence="0.962612">
Fig. 1: Linguistic ontology of the definition
</figureCaption>
<subsectionHeader confidence="0.970473">
2.4 Indexed Reference Identification
</subsectionHeader>
<bodyText confidence="0.999947333333333">
The method that we propose is based on the indexed
references in the text which point to the bibliography
as define in [1]. More precisely, the indexed references
allow us, in the case when we identify a definition in
the research scope determined by the segmentation,
to link this definition to the author cited in the text.
The theoretical framework as well as the experimental
procedures for the indexed reference identification are
described below.
</bodyText>
<subsubsectionHeader confidence="0.585062">
2.4.1 Bibliographic International Standards
</subsubsectionHeader>
<bodyText confidence="0.999067733333333">
We have considered several norms for bibliographic ref-
erences, namely the norms ISO-690 and ISO 690-2,
which are the international standards from the Inter-
national Organization for Standardization, as well as
the French norms AFNOR NF Z 44-005 and AFNOR
NF Z 44-005-2.
In practice the norms are not rigorously applied by
authors of scientific texts. For this reason, a method
based only on the norms described above is not suffi-
cient to carry out the text processing on a large scale.
That is why, although the identification of the indexed
references may seem trivial at first glance, a large num-
ber of morphological and syntactic variations must be
taken into account. To illustrate this complexity, here
is a list of forms that we have extracted from our cor-
</bodyText>
<note confidence="0.455677">
pus: (Hoc, 1990a), (Thom, 1970), (Dingwall et al.,
1995; Hartmann and Görlich, 1995), [24], Pickett-
Heaps et al. (1990), (like other authors e.g. Raven,
1983), (Cwuc and SPRAGUE 1989), (18, 53, 56).
</note>
<page confidence="0.994023">
22
</page>
<subsectionHeader confidence="0.442852">
2.4.2 Finite State Automata
</subsectionHeader>
<bodyText confidence="0.999970578947369">
Although the identification of indexed references has
been approached by Citeseer, we have developed our
own module. In fact, at the beginning of our work such
modules were not available2. The specificity of our
module is its capacity to identify also the author names
which can appear in the forms. The classification that
we use has been published in [2].
We identify automatically the indexed references by
the use of Finite State Automata (FSA). For this we
have to take into consideration the norms established
on the one hand by the practices proper to authors
and on the other hand by the different domains. That
is why in order to create robust FSA, different correc-
tions had to be made to take into consideration the
different customs in writing indexed references. The
annotation platform we have chosen takes as input
rules based on lists of regular expressions. Therefore,
for the implementation of this methodology, we have
converted the FSA into regular expressions.
</bodyText>
<subsubsectionHeader confidence="0.646734">
2.4.3 Identification of Known Named Entities
</subsubsectionHeader>
<bodyText confidence="0.999763166666667">
The identification of an indexed reference can become
difficult because of the presence of named entities in
the reference. The named entities are the more com-
plex part of the indexed references and introduce con-
siderable complications in the FSA due the various
name morphologies in different languages.
</bodyText>
<subsubsectionHeader confidence="0.9042825">
Fig. 2: Indexed reference identification with Named
Entity extraction
</subsubsectionHeader>
<bodyText confidence="0.992272375">
Figure 2 describes the implementation of a solution
which improves the system performance, through the
utilization of author names, that have been already
identified by the system, as part of the regular expres-
sions. In fact, by using some data already existing
2 The source code of the Citeseer module has been recently
published on http://sourceforge.net/projects/citeseerx/.
The identification module is based on a Perl module from
CPAN, which parses documents using regular expressions.
in the bibliographic databases, we can generate cer-
tain forms and limit the noise in the more complex
forms. Moreover, this approach permits some exten-
sions of the method: we can consider new sentences
for the signed definition extraction through matching
not only indexed references, but also author names in
the text that can be cited without bibliographic links.
</bodyText>
<sectionHeader confidence="0.985873" genericHeader="method">
3 Semantic Annotation
</sectionHeader>
<subsectionHeader confidence="0.998416">
3.1 Annotation Tools
</subsectionHeader>
<bodyText confidence="0.999958487179487">
Definition identification is traditionally based on pat-
tern matching, as for example in [11]. These ap-
proaches are used for the development of platforms
such as TerminoWeb3 of the National Research Coun-
cil Canada.
Different approaches are possible for the semantic
annotation. Among the tools that we have considered
we can cite the GATE4 platform [12] based on machine
learning algorithms, generally used with JAPE [4], and
the work of Xerox Concept-matching, based on XIP
[10], a morphosyntactic analyser
In our work we have used the Excom platform [6],
which implements the Contextual Exploration method
[5]. This is a decision-making procedure, presented in
the form of a set of rules and linguistic markers that
trigger the application of the rules. They are applied
to the segments containing indicators. The indicators
are linguistic units that carry the semantic meaning of
the categories for annotation. After the initial iden-
tification of the indicators in the text, the rules carry
out the localisation of complementary linguistic clues
which are co-present in the context of the indicators.
After the verification of the presence or absence of the
linguistic clues, the rules attribute a semantic annota-
tion to the segment.
In our approach we consider as a working hypothe-
sis the fact that in a scientific article the information
related to signed definition can be found in the textual
space close to an indexed reference, and more specif-
ically in the same sentence. Our aim is to limit as
much as possible the noise in the annotations, to be
able to obtain foolproof matching between authors and
definitions.
As we need to be able to disambiguate the linguistic
forms according to the context, in order to limit the
noise as much as possible and to deal with polysemy,
we have chosen the Contextual Exploration framework
as more adapted to our approach. For this reason, we
have used the Excom annotation systems.
</bodyText>
<subsectionHeader confidence="0.998757">
3.2 System Overview
</subsectionHeader>
<bodyText confidence="0.991068">
Here we describe in detail the main stages in the text
processing, that we have divided into a four-stage pro-
cess. The overall system pipeline is presented on figure
3.
</bodyText>
<footnote confidence="0.999294666666667">
3 http://termino.iit.nrc.ca/
4 http://gate.ac.uk
5 http://www.excom.fr
</footnote>
<page confidence="0.998587">
23
</page>
<figureCaption confidence="0.983604">
Fig. 3: Stages in the automatic processing
</figureCaption>
<subsectionHeader confidence="0.368368">
3.2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999986">
The initial corpora being in PDF format, in the pre-
processing stage the files are converted into text for-
mat. This is necessary because the next stages in our
processing, namely the segmentation and annotation,
need full text access to the corpora. The converted
files are in the UTF8 encoding which permits the pro-
cessing of different natural languages.
</bodyText>
<subsectionHeader confidence="0.54636">
3.2.2 Segmentation
</subsectionHeader>
<bodyText confidence="0.999985615384615">
In the second stage, we segment the corpora into para-
graphs and sentences, in order to prepare the input for
the annotation module. The quality of the segmenta-
tion is important for the overall system performance,
as the segmentation provides the text elements to be
annotated. The segmentation is carried out by the
SegaTex module [7] which we have chosen for the re-
liability of its results and its capacity to process texts
in both English and French. This module takes as in-
put text files and returns the segmented files in the
Docbook XML format, with paragraph and sentence
elements. This format is compatible with the annota-
tion module.
</bodyText>
<subsubsectionHeader confidence="0.781115">
3.2.3 Semantic Annotation
</subsubsectionHeader>
<bodyText confidence="0.999993857142857">
We will therefore analyze the discourse forms which
are to be found in the text space close to the indexed
reference. The semantic annotation is carried out by
the Excom module which takes as input the segmented
files as well as the linguistic resources that we have
constructed. According to our protocol, we use two
types of linguistic resources: regular expressions for
the identification of the indexed references and con-
textual exploration rules for the annotation of defini-
tions related to the ontology presented above. In the
output, the identified indexed references are present
as new elements and the annotations of the definitions
are added as attributes to the relevant XML sentence
elements in the corpora.
</bodyText>
<subsubsectionHeader confidence="0.616136">
3.2.4 Interface and Navigation
</subsubsectionHeader>
<bodyText confidence="0.999937470588235">
We have developed a web-based graphical user inter-
face, using the technology Apache/PHP/MySQL. The
annotated corpora are imported into a database de-
signed for this purpose, which contains the annota-
tions and the text segments, as well as meta-data re-
lated to the files. The Definition Extraction Interface
(DEI) permits the visualization of the information in
the database, and different other functionalities that
we will describe here.
The most important functionality of the DEI is the
information retrieval among the annotated sentences.
In the initial screen, shown on figure 3, the user can
formulate a query by using keywords and eventually
restricting the search to a specific set of corpora. The
results are presented in the form of a list of sentences,
together with the annotations and links to the initial
texts.
</bodyText>
<subsectionHeader confidence="0.560233">
3.3 Results
</subsectionHeader>
<figureCaption confidence="0.913329">
Fig. 4: Search results
</figureCaption>
<bodyText confidence="0.896798666666667">
Figure 4 presents the results from the French corpus
for the keyword &apos;sémantique&apos;. The following excerpts
were extracted from the English corpus:
</bodyText>
<listItem confidence="0.8670638">
1. Another homolog to RCCI has been identified in S.
cerevisiae, called either SRMl (Cwuc and SPRAGUE
1989) or PRP20 (AEBI et al. 1990; FLEISCHMANN
et al. 1991).
2. Silica polymerization occurs within an organelle called
</listItem>
<bodyText confidence="0.75055925">
the silica deposition vesicle, bounded by a membrane
called the silicalemma (18, 53, 56).
We can see that the first and the second examples
are general reported definitions.
</bodyText>
<footnote confidence="0.8515465">
6 Boolean expressions (AND, OR, NOT) with parentheses and
quotation marks in queries are also implemented.
</footnote>
<page confidence="0.999053">
24
</page>
<sectionHeader confidence="0.99126" genericHeader="evaluation">
4 Evaluation and Discussion
</sectionHeader>
<subsectionHeader confidence="0.966145">
4.1 Precision and Recall Measures
</subsectionHeader>
<bodyText confidence="0.9965581">
The first evaluation consists in measuring the accu-
racy of the retained indexed references, which have
been identified automatically by the regular expres-
sions. We have used the precision/recall measures [9]
which determine the capacity of the system to cor-
rectly identify textual segments containing indexed
references. Table 2 presents the number and the per-
centage of the sentences containing indexed references
in each corpus. We can see that around 5% of the
sentences have been extracted.
</bodyText>
<table confidence="0.9078956">
Corpus Sentences Annotated Sen- Percentage
tences
French 119410 5976 5,00 %
English 38378 1743 4,54 %
Total 157788 7719 4,89 %
</table>
<tableCaption confidence="0.994983">
Table 2: Annotated sentences
</tableCaption>
<bodyText confidence="0.941414">
We have carried out the evaluation on a set of 500
sentences extracted randomly from our corpora. In
table 3 we present the results obtained by this evalu-
ation.
</bodyText>
<table confidence="0.8662075">
Recall Precision F-measure
0,911% 0,989% 0,9483
</table>
<tableCaption confidence="0.997754">
Table 3: Evaluation of the Indexed References
</tableCaption>
<bodyText confidence="0.999984">
We consider that these results are satisfactory. It
must be noted that there is very little noise which
means that almost all of the identified indexed ref-
erences are valid. On the other hand, the value of the
recall is also very high. The several percents of indexed
references not identified by the system are due to the
various orthography rules for the names in different
languages, as well as the presence of commentaries in
the indexed reference itself.
</bodyText>
<subsectionHeader confidence="0.997465">
4.2 Cohen’s Weighted Kappa
</subsectionHeader>
<bodyText confidence="0.999909">
The problem we have to consider is how to evaluate the
semantic annotation which is by definition qualitative
in nature. The test Kappa (K) proposed by Cohen[3]
and developed by [8] provides a method to measure
numerically the agreement between two or more ob-
servers or methods in the case when the judgments are
qualitative in nature. We have adopted this method
for the second stage of our evaluation.
</bodyText>
<tableCaption confidence="0.981782">
Table 4: Evaluation Results
</tableCaption>
<bodyText confidence="0.999793444444445">
In order to carry out the test, we have constituted
a base of annotated text segments and these seg-
ments have been evaluated independently by two hu-
man judges. The judges had to classify the segments
into two categories: correct and incorrect. We have
used a set of 50 sentences for this evaluation. Table
4 presents the results. For the Cohen’s Kappa we ob-
tain: κ = 0, 6515, and therefore we have a subtantial
agreement, according to the interpretation in [8].
</bodyText>
<sectionHeader confidence="0.993856" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999996846153846">
We note that according to the evaluation the system
gives satisfactory results, which validates the linguistic
resources and the definition ontology in our approach.
Throughout the process of annotation and exploita-
tion of the results we maintain the links between the
extracted sentences and the original texts which makes
possible the visualization of the context of each defi-
nition. The evaluations confirm the relevance of this
application. However, we are not yet able to predict
the result on a larger scale and on corpora in other
domains. In the future we will extend this approach
to the processing of bigger corpora in English and in
French as well as other natural languages.
</bodyText>
<sectionHeader confidence="0.999123" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999956615384616">
[1] M. Bertin. Categorizations and annotations of citation in re-
search evaluation. In FLAIRS 2008, Coconut Grove, Florida,
Coconut Grove, Florida, May 2008.
[2] M. Bertin, I. Atanassova, and J.-P. Desclés. Automatic analy-
sis of author judgment in scientific articles based on semantic
annotation. In 22nd International Florida Artificial Intelli-
gence, Research Society Conference, Sanibel Island, Florida,
19-21 mai 2009.
[3] J. Cohen. A coefficient of agreement for nominal scales. Educ.
Psychol. Meas., 20:27–46, 1960.
[4] H. Cunningham, D. Maynard, and V. Tablan. Jape–a java an-
notation patterns engine. Advances in Text Processing, TIP-
STER Program Phase II, pages 185–189, 2000.
[5] J.-P. Desclés. Contextual exploration processing for discourse
automatic annotations of texts. FLAIRS 2006, Florida. In-
vited Speaker, 2006.
[6] B. Djioua, F. J. Garcia, A. Blais, J.-P. Desclés, G. Guibert,
A. Jackiewicz, F. L. Priol, L. Nait-Baha, and B. Sauzay. Ex-
com: an automatic annotation engine for semantic information.
FLAIRS 2006, Florida, pages 285–290, 2006.
[7] M. Ghassan. La segmentation de textes par exploration con-
textuelle automatique, présentation du module segatex. ISLsp,
Inscription Spatiale du Langage : structure et processus
IRIT, Université Paul Sabatier, Toulouse, 2002.
[8] J. Landis and G. Koch. The measurement of observer agree-
ment for categorical data. Biometrics, 33:159–174, 1977.
[9] G. Salton and M. J. McGill. Introduction to Modern Infor-
mation Retrieval. McGraw-Hill, 1979.
[10] A. Sandor, A. Kaplan, and G. Rondeau. Discourse and citation
analysis with concept-matching. International Symposium :
Discourse and document (ISDD), Caen, France, 2006.
[11] G. Sierra, R. Alarcon, C. Aguilar, and C. Bach. Definitional
verbal patterns for semantic relation extraction. Terminology,
14(1):74–98, 2008.
[12] V. Tablan, C. Ursu, K. Bontcheva, H. Cunningham, D. May-
nard, O. Hamza, T. McEnery, P. Baker, and M. Leisher. A
unicode-based environment for creation and use of language re-
sources. In Proceedings of 3rd Language Resources and Eval-
uation Conferenc, 2002.
</reference>
<page confidence="0.998735">
25
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.141432">
<title confidence="0.998753">Extraction of Author’s Definitions Indexed Reference Identification</title>
<author confidence="0.935269">Marc Bertin</author>
<author confidence="0.935269">Iana Atanassova</author>
<author confidence="0.935269">Jean-Pierre</author>
<abstract confidence="0.884572">Paris-Sorbonne Maison de la 28 rue 75006  |iana.atanassova | Abstract In this paper we present the implementation of definition extraction from multilingual corpora of scientific articles. We establish relations between the definitions and authors by using indexed references in the text. Our method is based on a linguistic ontology designed for this purpose. We propose two evaluations of the annotations.</abstract>
<keyword confidence="0.993805">Keywords</keyword>
<intro confidence="0.553128">Semantic annotation, definition extraction, indexed references</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bertin</author>
</authors>
<title>Categorizations and annotations of citation in research evaluation.</title>
<date>2008</date>
<booktitle>In FLAIRS 2008, Coconut</booktitle>
<location>Grove, Florida, Coconut Grove, Florida,</location>
<contexts>
<context position="7652" citStr="[1]" startWordPosition="1209" endWordPosition="1209">type of definitions takes part in the text evolution by means of modalities and we speak of committed definition. The objective that we have fixed is to extract definition sentences, in which the definition is explicitly attributed to an author or another work, cited in the text. We will also call them signed definitions, which correspond to the category of Reported Definitions in our ontology. Fig. 1: Linguistic ontology of the definition 2.4 Indexed Reference Identification The method that we propose is based on the indexed references in the text which point to the bibliography as define in [1]. More precisely, the indexed references allow us, in the case when we identify a definition in the research scope determined by the segmentation, to link this definition to the author cited in the text. The theoretical framework as well as the experimental procedures for the indexed reference identification are described below. 2.4.1 Bibliographic International Standards We have considered several norms for bibliographic references, namely the norms ISO-690 and ISO 690-2, which are the international standards from the International Organization for Standardization, as well as the French norms</context>
</contexts>
<marker>[1]</marker>
<rawString>M. Bertin. Categorizations and annotations of citation in research evaluation. In FLAIRS 2008, Coconut Grove, Florida, Coconut Grove, Florida, May 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bertin</author>
<author>I Atanassova</author>
<author>J-P Desclés</author>
</authors>
<title>Automatic analysis of author judgment in scientific articles based on semantic annotation.</title>
<date>2009</date>
<booktitle>In 22nd International Florida Artificial Intelligence, Research Society Conference,</booktitle>
<location>Sanibel Island, Florida,</location>
<contexts>
<context position="9373" citStr="[2]" startWordPosition="1490" endWordPosition="1490">acted from our corpus: (Hoc, 1990a), (Thom, 1970), (Dingwall et al., 1995; Hartmann and Görlich, 1995), [24], PickettHeaps et al. (1990), (like other authors e.g. Raven, 1983), (Cwuc and SPRAGUE 1989), (18, 53, 56). 22 2.4.2 Finite State Automata Although the identification of indexed references has been approached by Citeseer, we have developed our own module. In fact, at the beginning of our work such modules were not available2. The specificity of our module is its capacity to identify also the author names which can appear in the forms. The classification that we use has been published in [2]. We identify automatically the indexed references by the use of Finite State Automata (FSA). For this we have to take into consideration the norms established on the one hand by the practices proper to authors and on the other hand by the different domains. That is why in order to create robust FSA, different corrections had to be made to take into consideration the different customs in writing indexed references. The annotation platform we have chosen takes as input rules based on lists of regular expressions. Therefore, for the implementation of this methodology, we have converted the FSA i</context>
</contexts>
<marker>[2]</marker>
<rawString>M. Bertin, I. Atanassova, and J.-P. Desclés. Automatic analysis of author judgment in scientific articles based on semantic annotation. In 22nd International Florida Artificial Intelligence, Research Society Conference, Sanibel Island, Florida, 19-21 mai 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<journal>Educ. Psychol. Meas.,</journal>
<volume>20</volume>
<contexts>
<context position="18491" citStr="[3]" startWordPosition="2956" endWordPosition="2956">ory. It must be noted that there is very little noise which means that almost all of the identified indexed references are valid. On the other hand, the value of the recall is also very high. The several percents of indexed references not identified by the system are due to the various orthography rules for the names in different languages, as well as the presence of commentaries in the indexed reference itself. 4.2 Cohen’s Weighted Kappa The problem we have to consider is how to evaluate the semantic annotation which is by definition qualitative in nature. The test Kappa (K) proposed by Cohen[3] and developed by [8] provides a method to measure numerically the agreement between two or more observers or methods in the case when the judgments are qualitative in nature. We have adopted this method for the second stage of our evaluation. Table 4: Evaluation Results In order to carry out the test, we have constituted a base of annotated text segments and these segments have been evaluated independently by two human judges. The judges had to classify the segments into two categories: correct and incorrect. We have used a set of 50 sentences for this evaluation. Table 4 presents the results</context>
</contexts>
<marker>[3]</marker>
<rawString>J. Cohen. A coefficient of agreement for nominal scales. Educ. Psychol. Meas., 20:27–46, 1960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>V Tablan</author>
</authors>
<title>Jape–a java annotation patterns engine.</title>
<date>2000</date>
<booktitle>Advances in Text Processing, TIPSTER Program Phase II,</booktitle>
<pages>185--189</pages>
<contexts>
<context position="11737" citStr="[4]" startWordPosition="1859" endWordPosition="1859">on extraction through matching not only indexed references, but also author names in the text that can be cited without bibliographic links. 3 Semantic Annotation 3.1 Annotation Tools Definition identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and linguistic markers that trigger the application of the rules. They are applied to the segments containing indicators. The indicators are linguistic units that carry the semantic meaning of the categories for annotation. After the initial identification of the indicators in the text, the rules carry out the localisation of co</context>
</contexts>
<marker>[4]</marker>
<rawString>H. Cunningham, D. Maynard, and V. Tablan. Jape–a java annotation patterns engine. Advances in Text Processing, TIPSTER Program Phase II, pages 185–189, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-P Desclés</author>
</authors>
<title>Contextual exploration processing for discourse automatic annotations of texts. FLAIRS</title>
<date>2006</date>
<location>Florida. Invited Speaker,</location>
<contexts>
<context position="11928" citStr="[5]" startWordPosition="1889" endWordPosition="1889">ion identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and linguistic markers that trigger the application of the rules. They are applied to the segments containing indicators. The indicators are linguistic units that carry the semantic meaning of the categories for annotation. After the initial identification of the indicators in the text, the rules carry out the localisation of complementary linguistic clues which are co-present in the context of the indicators. After the verification of the presence or absence of the linguistic clues, the rules attribute a semantic a</context>
</contexts>
<marker>[5]</marker>
<rawString>J.-P. Desclés. Contextual exploration processing for discourse automatic annotations of texts. FLAIRS 2006, Florida. Invited Speaker, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Djioua</author>
<author>F J Garcia</author>
<author>A Blais</author>
<author>J-P Desclés</author>
<author>G Guibert</author>
<author>A Jackiewicz</author>
<author>F L Priol</author>
<author>L Nait-Baha</author>
<author>B Sauzay</author>
</authors>
<title>Excom: an automatic annotation engine for semantic information. FLAIRS</title>
<date>2006</date>
<pages>285--290</pages>
<location>Florida,</location>
<contexts>
<context position="11872" citStr="[6]" startWordPosition="1882" endWordPosition="1882">inks. 3 Semantic Annotation 3.1 Annotation Tools Definition identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and linguistic markers that trigger the application of the rules. They are applied to the segments containing indicators. The indicators are linguistic units that carry the semantic meaning of the categories for annotation. After the initial identification of the indicators in the text, the rules carry out the localisation of complementary linguistic clues which are co-present in the context of the indicators. After the verification of the presence or absence o</context>
</contexts>
<marker>[6]</marker>
<rawString>B. Djioua, F. J. Garcia, A. Blais, J.-P. Desclés, G. Guibert, A. Jackiewicz, F. L. Priol, L. Nait-Baha, and B. Sauzay. Excom: an automatic annotation engine for semantic information. FLAIRS 2006, Florida, pages 285–290, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ghassan</author>
</authors>
<title>La segmentation de textes par exploration contextuelle automatique, présentation du module segatex. ISLsp, Inscription Spatiale du Langage : structure et processus IRIT, Université Paul Sabatier,</title>
<date>2002</date>
<location>Toulouse,</location>
<contexts>
<context position="14280" citStr="[7]" startWordPosition="2275" endWordPosition="2275">mat. This is necessary because the next stages in our processing, namely the segmentation and annotation, need full text access to the corpora. The converted files are in the UTF8 encoding which permits the processing of different natural languages. 3.2.2 Segmentation In the second stage, we segment the corpora into paragraphs and sentences, in order to prepare the input for the annotation module. The quality of the segmentation is important for the overall system performance, as the segmentation provides the text elements to be annotated. The segmentation is carried out by the SegaTex module [7] which we have chosen for the reliability of its results and its capacity to process texts in both English and French. This module takes as input text files and returns the segmented files in the Docbook XML format, with paragraph and sentence elements. This format is compatible with the annotation module. 3.2.3 Semantic Annotation We will therefore analyze the discourse forms which are to be found in the text space close to the indexed reference. The semantic annotation is carried out by the Excom module which takes as input the segmented files as well as the linguistic resources that we have</context>
</contexts>
<marker>[7]</marker>
<rawString>M. Ghassan. La segmentation de textes par exploration contextuelle automatique, présentation du module segatex. ISLsp, Inscription Spatiale du Langage : structure et processus IRIT, Université Paul Sabatier, Toulouse, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Landis</author>
<author>G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<volume>33</volume>
<contexts>
<context position="18512" citStr="[8]" startWordPosition="2960" endWordPosition="2960"> that there is very little noise which means that almost all of the identified indexed references are valid. On the other hand, the value of the recall is also very high. The several percents of indexed references not identified by the system are due to the various orthography rules for the names in different languages, as well as the presence of commentaries in the indexed reference itself. 4.2 Cohen’s Weighted Kappa The problem we have to consider is how to evaluate the semantic annotation which is by definition qualitative in nature. The test Kappa (K) proposed by Cohen[3] and developed by [8] provides a method to measure numerically the agreement between two or more observers or methods in the case when the judgments are qualitative in nature. We have adopted this method for the second stage of our evaluation. Table 4: Evaluation Results In order to carry out the test, we have constituted a base of annotated text segments and these segments have been evaluated independently by two human judges. The judges had to classify the segments into two categories: correct and incorrect. We have used a set of 50 sentences for this evaluation. Table 4 presents the results. For the Cohen’s Kap</context>
</contexts>
<marker>[8]</marker>
<rawString>J. Landis and G. Koch. The measurement of observer agreement for categorical data. Biometrics, 33:159–174, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1979</date>
<publisher>McGraw-Hill,</publisher>
<contexts>
<context position="17145" citStr="[9]" startWordPosition="2733" endWordPosition="2733"> polymerization occurs within an organelle called the silica deposition vesicle, bounded by a membrane called the silicalemma (18, 53, 56). We can see that the first and the second examples are general reported definitions. 6 Boolean expressions (AND, OR, NOT) with parentheses and quotation marks in queries are also implemented. 24 4 Evaluation and Discussion 4.1 Precision and Recall Measures The first evaluation consists in measuring the accuracy of the retained indexed references, which have been identified automatically by the regular expressions. We have used the precision/recall measures [9] which determine the capacity of the system to correctly identify textual segments containing indexed references. Table 2 presents the number and the percentage of the sentences containing indexed references in each corpus. We can see that around 5% of the sentences have been extracted. Corpus Sentences Annotated Sen- Percentage tences French 119410 5976 5,00 % English 38378 1743 4,54 % Total 157788 7719 4,89 % Table 2: Annotated sentences We have carried out the evaluation on a set of 500 sentences extracted randomly from our corpora. In table 3 we present the results obtained by this evaluat</context>
</contexts>
<marker>[9]</marker>
<rawString>G. Salton and M. J. McGill. Introduction to Modern Information Retrieval. McGraw-Hill, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sandor</author>
<author>A Kaplan</author>
<author>G Rondeau</author>
</authors>
<title>Discourse and citation analysis with concept-matching.</title>
<date>2006</date>
<booktitle>International Symposium : Discourse and document (ISDD),</booktitle>
<location>Caen, France,</location>
<contexts>
<context position="11796" citStr="[10]" startWordPosition="1869" endWordPosition="1869">, but also author names in the text that can be cited without bibliographic links. 3 Semantic Annotation 3.1 Annotation Tools Definition identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and linguistic markers that trigger the application of the rules. They are applied to the segments containing indicators. The indicators are linguistic units that carry the semantic meaning of the categories for annotation. After the initial identification of the indicators in the text, the rules carry out the localisation of complementary linguistic clues which are co-present in the co</context>
</contexts>
<marker>[10]</marker>
<rawString>A. Sandor, A. Kaplan, and G. Rondeau. Discourse and citation analysis with concept-matching. International Symposium : Discourse and document (ISDD), Caen, France, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sierra</author>
<author>R Alarcon</author>
<author>C Aguilar</author>
<author>C Bach</author>
</authors>
<title>Definitional verbal patterns for semantic relation extraction.</title>
<date>2008</date>
<journal>Terminology,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="11410" citStr="[11]" startWordPosition="1807" endWordPosition="1807">fication module is based on a Perl module from CPAN, which parses documents using regular expressions. in the bibliographic databases, we can generate certain forms and limit the noise in the more complex forms. Moreover, this approach permits some extensions of the method: we can consider new sentences for the signed definition extraction through matching not only indexed references, but also author names in the text that can be cited without bibliographic links. 3 Semantic Annotation 3.1 Annotation Tools Definition identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and</context>
</contexts>
<marker>[11]</marker>
<rawString>G. Sierra, R. Alarcon, C. Aguilar, and C. Bach. Definitional verbal patterns for semantic relation extraction. Terminology, 14(1):74–98, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Tablan</author>
<author>C Ursu</author>
<author>K Bontcheva</author>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>O Hamza</author>
<author>T McEnery</author>
<author>P Baker</author>
<author>M Leisher</author>
</authors>
<title>A unicode-based environment for creation and use of language resources.</title>
<date>2002</date>
<booktitle>In Proceedings of 3rd Language Resources and Evaluation Conferenc,</booktitle>
<contexts>
<context position="11670" citStr="[12]" startWordPosition="1849" endWordPosition="1849">of the method: we can consider new sentences for the signed definition extraction through matching not only indexed references, but also author names in the text that can be cited without bibliographic links. 3 Semantic Annotation 3.1 Annotation Tools Definition identification is traditionally based on pattern matching, as for example in [11]. These approaches are used for the development of platforms such as TerminoWeb3 of the National Research Council Canada. Different approaches are possible for the semantic annotation. Among the tools that we have considered we can cite the GATE4 platform [12] based on machine learning algorithms, generally used with JAPE [4], and the work of Xerox Concept-matching, based on XIP [10], a morphosyntactic analyser In our work we have used the Excom platform [6], which implements the Contextual Exploration method [5]. This is a decision-making procedure, presented in the form of a set of rules and linguistic markers that trigger the application of the rules. They are applied to the segments containing indicators. The indicators are linguistic units that carry the semantic meaning of the categories for annotation. After the initial identification of the</context>
</contexts>
<marker>[12]</marker>
<rawString>V. Tablan, C. Ursu, K. Bontcheva, H. Cunningham, D. Maynard, O. Hamza, T. McEnery, P. Baker, and M. Leisher. A unicode-based environment for creation and use of language resources. In Proceedings of 3rd Language Resources and Evaluation Conferenc, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>