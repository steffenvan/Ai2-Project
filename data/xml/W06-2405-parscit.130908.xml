<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.98836">
Identifying idiomatic expressions using automatic word-alignment
</title>
<author confidence="0.90843">
Bego˜na Villada Moir´on and J¨org Tiedemann
</author>
<affiliation confidence="0.940201">
Alfa Informatica, University of Groningen
</affiliation>
<address confidence="0.7197525">
Oude Kijk in ’t Jatstraat 26
9712 EK Groningen, The Netherlands
</address>
<email confidence="0.999455">
{M.B.Villada.Moiron,J.Tiedemann}@rug.nl
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992533333333">
For NLP applications that require some
sort of semantic interpretation it would be
helpful to know what expressions exhibit
an idiomatic meaning and what expres-
sions exhibit a literal meaning. We invest-
igate whether automatic word-alignment
in existing parallel corpora facilitates
the classification of candidate expressions
along a continuum ranging from literal and
transparent expressions to idiomatic and
opaque expressions. Our method relies on
two criteria: (i) meaning predictability that
is measured as semantic entropy and (ii),
the overlap between the meaning of an ex-
pression and the meaning of its compon-
ent words. We approximate the mentioned
overlap as the proportion of default align-
ments. We obtain a significant improve-
ment over the baseline with both meas-
ures.
In the remainder of this section, we present our
characterization of idiomatic expressions, the mo-
tivation to use parallel corpora and related work.
Section 2 describes the materials required to ap-
ply our method. Section 3 portraits the routine to
extract a list of candidate expressions from auto-
matically annotated data. Experiments with differ-
ent word alignment types and metrics are shown
in section 4. Our results are discussed in section 5.
Finally, we draw some conclusions in section 6.
</bodyText>
<subsectionHeader confidence="0.995194">
1.1 What are idiomatic expressions?
</subsectionHeader>
<bodyText confidence="0.999327">
Idiomatic expressions constitute a subset of mul-
tiword expressions (Sag et al., 2001). We assume
that literal expressions can be distinguished from
idiomatic expressions provided we know how their
meaning is derived.1 The meaning of linguistic
expressions can be described within a scale that
ranges from fully transparent to opaque (in figur-
ative expressions).
</bodyText>
<note confidence="0.663292">
1 Introduction (1) Wat moeten lidstaten ondernemen om
what must member states do to
</note>
<bodyText confidence="0.987025961538462">
Knowing whether an expression receives a lit-
eral meaning or an idiomatic meaning is import-
ant for natural language processing applications
that require some sort of semantic interpretation.
Some applications that would benefit from know-
ing this distinction are machine translation (Im-
amura et al., 2003), finding paraphrases (Bannard
and Callison-Burch, 2005), (multilingual) inform-
ation retrieval (Melamed, 1997a), etc.
The purpose of this paper is to explore to what
extent word-alignment in parallel corpora can be
used to distinguish idiomatic multiword expres-
sions from more transparent multiword expres-
sions and fully productive expressions.
voldoen?
meet?
‘What must EU member states do to meet her
demands?’
politieke
political
barri`eres zeer duidelijk
barriers very clearly
‘This situation brings the existing political
limitations to light very clearly.’
1Here, we ignore morpho-syntactic and pragmatic factors
that could help model the distinction.
</bodyText>
<figure confidence="0.993624045454545">
eisen te
demands to
aan
at
haar
her
(2) Deze
this
situatie
situation
brengt
brings
bestaande
existing
de
the
het
the
aan
in
licht.
light
</figure>
<page confidence="0.704071">
33
</page>
<bodyText confidence="0.5522855625">
moeten
must
situatie
situation
maar
but
de
the
neerleggen,
agree,
publiekelijk aan
publicly op
pora can help us to find out the type of meaning an
expression has.
For our approach we make the following as-
sumptions:
</bodyText>
<listItem confidence="0.711929">
(3) Wij mogen ons hier niet bij
we may us here not by
</listItem>
<bodyText confidence="0.993443583333334">
stellen.
state
‘We cannot agree but must denounce the situ-
ation openly.’
Literal and transparent meaning is associated
with high meaning predictability. The meaning of
an expression is fully predictable if it results from
combining the meaning of its individual words
when they occur in isolation (see (1)). When
the expression undergoes a process of metaphor-
ical interpretation its meaning is less predictable.
Moon (1998) considers a continuum of transpar-
ent, semi-transparent and opaque metaphors. The
more transparent metaphors have a rather predict-
able meaning (2); the more opaque have an un-
predictable meaning (3). In general, an unpredict-
able meaning results from the fact that the mean-
ing of the expression has been fossilized and con-
ventionalized. In an uninformative context, idio-
matic expressions have an unpredictable meaning
(3). Put differently, the meaning of an idiomatic
expression cannot be derived from the cumulative
meaning of its constituent parts when they appear
in isolation.
</bodyText>
<subsectionHeader confidence="0.992089">
1.2 Why checking translations?
</subsectionHeader>
<bodyText confidence="0.99617925">
This paper addresses the task of distinguishing lit-
eral (transparent) expressions from idiomatic ex-
pressions. Deciding what sort of meaning an ex-
pression shows can be done in two ways:
</bodyText>
<listItem confidence="0.9645162">
• measuring how predictable the meaning of
the expression is and
• assessing the link between (a) the meaning of
the expression as a whole and (b) the cumu-
lative literal meanings of the components.
</listItem>
<bodyText confidence="0.868573">
Fernando and Flavell (1981) observe that no
connection between (a) and (b) suggests the ex-
istence of opaque idioms and, a clear link between
(a) and (b) is observed in clearly perceived meta-
phors and literal expressions.
We believe we can approximate the meaning
of an expression by looking up the expressions’
translation in a foreign language. Thus, we are
interested in exploring to what extent parallel cor-
</bodyText>
<listItem confidence="0.993779769230769">
• regular words are translated (more or less)
consistently, i.e. there will be one or only
a few highly frequent translations whereas
translation alternatives will be infrequent;
• an expression has a (almost) literal meaning
if its translation(s) into a foreign language is
the result of combining each word’s transla-
tion(s) when they occur in isolation into a for-
eign language;
• an expression has a non-compositional mean-
ing if its translation(s) into a foreign language
does not result from a combination of the reg-
ular translations of its component words.
</listItem>
<bodyText confidence="0.999799357142857">
We also assume that an automatic word aligner
will get into trouble when trying to align non-
decomposable idiomatic expressions word by
word. We expect the aligner to produce a large
variety of links for each component word in such
expressions and that these links are different from
the default alignments found in the corpus other-
wise.
Bearing these assumptions in mind, our ap-
proach attempts to locate the translation of a MWE
in a target language. On the basis of all recon-
structed translations of a (potential) MWE, it is de-
cided whether the original expression (in source
language) is idiomatic or a more transparent one.
</bodyText>
<sectionHeader confidence="0.825554" genericHeader="keywords">
1.3 Related work
</sectionHeader>
<bodyText confidence="0.999735533333333">
Melamed (1997b) measures the semantic entropy
of words using bitexts. Melamed computes the
translational distribution T of a word s in a source
language and uses it to measure the translational
entropy of the word H(T|s); this entropy approx-
imates the semantic entropy of the word that can
be interpreted either as (a) the semantic ambigu-
ity or (b) the inverse of reliability. Thus, a word
with high semantic entropy is potentially very am-
biguous and therefore, its translations are less re-
liable (or highly context-dependent). We also
use entropy to approximate meaning predictabil-
ity. Melamed (1997a) investigates various tech-
niques to identify non-compositional compounds
in parallel data. Non-compositional compounds
</bodyText>
<figure confidence="0.534112">
de
the
kaak
cheek
</figure>
<page confidence="0.99412">
34
</page>
<bodyText confidence="0.999943">
are those sequences of 2 or more words (adja-
cent or separate) that show a conventionalized
meaning. From English-French parallel corpora,
Melamed’s method induces and compares pairs of
translation models. Models that take into account
non-compositional compounds are highly accurate
in the identification task.
</bodyText>
<sectionHeader confidence="0.870877" genericHeader="introduction">
2 Data and resources
</sectionHeader>
<bodyText confidence="0.999947138888889">
We base our investigations on the Europarl corpus
consisting of several years of proceedings from the
European Parliament (Koehn, 2003). We focus on
Dutch expressions and their translations into Eng-
lish, Spanish and German.2 Thus, we used the en-
tire sections of Europarl in these three languages.
The corpus has been tokenized and aligned at the
sentence level (Tiedemann and Nygaard, 2004).
The Dutch part contains about 29 million tokens
in about 1.2 million sentences. The English, Span-
ish and German counterparts are of similar size
between 28 and 30 million words in roughly the
same number of sentences.
Automatic word alignment has been done us-
ing GIZA++ (Och, 2003). We used standard set-
tings of the system to produce Viterbi alignments
of IBM model 4. Alignments have been produced
for both translation directions (source to target and
target to source) on tokenized plain text.3 We also
used a well-known heuristics for combining the
two directional alignments, the so-called refined
alignment (Och et al., 1999). Word-to-word align-
ments have been merged such that words are con-
nected with each other if they are linked to the
same target. In this way we obtained three differ-
ent word alignment files: source to target (src2trg)
with possible multi-word units in the source lan-
guage, target to source (trg2src) with possible
multi-word units in the target language, and re-
fined with possible multi-word units in both lan-
guages. We also created bilingual word type links
from the different word-aligned corpora. These
lists include alignment frequencies that we will
use later on for extracting default alignments for
individual words. Henceforth, we will call them
link lexica.
</bodyText>
<footnote confidence="0.7430142">
2This is only a restriction for our investigation but not for
the approach itself.
3Manual corrections and evaluations of the tokenization,
sentence and word alignment have not been done. We rely
entirely on the results of automatic processes.
</footnote>
<sectionHeader confidence="0.90101" genericHeader="method">
3 Extracting candidates from corpora
</sectionHeader>
<bodyText confidence="0.999957956521739">
The Dutch section from the Europarl corpus was
automatically parsed with Alpino, a Dutch wide-
coverage parser.4 1.25% of the sentences could
not be parsed by Alpino, given the fact that many
sentences are rather lengthy. We selected those
sentences in the Dutch Europarl section that con-
tain at least one of a group of verbs that can
function as main or support verbs. Support verbs
are prone to lexicalization or idiomatization along
with their complementation (Butt, 2003). The se-
lected verbs are: doen, gaan, geven, hebben, ko-
men, maken, nemen, brengen, houden, krijgen,
stellen and zitten.5
A fully parsed sentence is represented by the list
of its dependency triples. From the dependency
triples, each main verb is tallied with every de-
pendent prepositional phrase (PP). In this way, we
collected all the VERB PP tuples found in the selec-
ted documents. To avoid data sparseness, the NP
inside the PP is reduced to the head noun’s lemma
and verbs are lemmatized, too. Other potential
arguments under a verb phrase node are ignored.
A sample of more than 191,000 candidates types
(413,000 tokens) was collected. To ensure statist-
ical significance, the types that occur less than 50
times were ignored.
For each candidate triple, the log-likelihood
(Dunning, 1993) and salience (Kilgarriff and Tug-
well, 2001) scores were calculated. These scores
have been shown to perform reasonably well in
identifying collocations and other lexicalized ex-
pressions (Villada Moir´on, 2005). In addition, the
head dependence between each PP in the candid-
ates dataset and its selecting verbs was measured.
Merlo and Leybold (2001) used the head depend-
ence as a diagnostic to determine the argument
(or adjunct) status of a PP. The head dependence
is measured as the amount of entropy observed
among the co-occurring verbs for a given PP as
suggested in (Merlo and Leybold, 2001; Bald-
win, 2005). Using the two association measures
and the head dependence heuristic, three different
rankings of the candidate triples were produced.
The three different ranks assigned to each triple
were uniformly combined to form the final rank-
ing. From this list, we selected the top 200 triples
</bodyText>
<footnote confidence="0.993292">
4Available at http://www.let.rug.nl/
</footnote>
<bodyText confidence="0.6936275">
˜vannoord/alp/Alpino.
5Butt (2003) maintains that the first 7 verbs are examples
of support verbs crosslinguistically. The other 5 have been
suggested for Dutch by (Hollebrandse, 1993).
</bodyText>
<page confidence="0.996419">
35
</page>
<bodyText confidence="0.999227">
which we considered a manageable size to test our
method.
</bodyText>
<sectionHeader confidence="0.998025" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.999976333333333">
We examine how expressions in the source lan-
guage (Dutch) are conceptualized in a target lan-
guage. The translations in the target language en-
code the meaning of the expression in the source
language. Using the translation links in paral-
lel corpora, we attempt to establish what type of
meaning the expression in the source language
has. To accomplish this we make use of the three
word-aligned parallel corpora from Europarl as
described in section 2.
Once the translation links of each expression in
the source language have been collected, the en-
tropy observed among the translation links is com-
puted per expression. We also take into account
how often the translation of an expression is made
out of the default alignment for each triple com-
ponent. The default ’translation’ is extracted from
the corresponding bilingual link lexicon.
</bodyText>
<subsectionHeader confidence="0.999637">
4.1 Collecting alignments
</subsectionHeader>
<bodyText confidence="0.997056074074074">
For each triple in the source language (Dutch)
we collect its corresponding (hypothetical) trans-
lations in a target language. Thus, we have a list
of 200 VERB PP triples representing 200 potential
MWEs in Dutch. We selected all occurrences of
each triple in the source language and all aligned
sentences containing their corresponding transla-
tions into English, German and Spanish. We re-
stricted ourselves to instances found in 1:1 sen-
tence alignments. Other units contain many er-
rors in word and sentence alignment and, there-
fore, we discarded them. Relying on automated
word-alignment, we collect all translation links for
each verb, preposition and noun occurrence within
the triple context in the three target languages.
To capture the meaning of a source expression
(triple) S, we collect all the translation links of its
component words s in each target language. Thus,
for each triple, we gather three lists of transla-
tion links Ts. Let us see the example AAN LICHT
BRENG representing the MWE iets aan het licht
brengen ’reveal’. Table 1 shows some of the links
found for the triple AAN LICHT BRENG. If a word
in the source language has no link in the target lan-
guage (which is usually due to alignments to the
empty word), NO LINK is assigned.
Note that Dutch word order is more flexible than
</bodyText>
<table confidence="0.992785166666667">
Triple Links in English
aan NO LINK, to, of, in, for, from, on, into, at
licht NO LINK, light, revealed, exposed, highlight,
shown, shed light, clarify
breng NO LINK, brought, bring, highlighted,
has, is, makes
</table>
<tableCaption confidence="0.9691075">
Table 1: Excerpt of the English links found for the
triple AAN LICHT BRENG ‘bring to light’.
</tableCaption>
<bodyText confidence="0.9993687">
English word order and that, the PP argument in a
candidate expression may be separate from its se-
lecting verb by any number of constituents. This
introduces much noise during retrieving transla-
tion links. In addition, it is known that concepts
may be lexicalized very differently in different
languages. Because of this, words in the source
language may translate to nothing in a target lan-
guage. This introduces many mappings of a word
to NO LINK.
</bodyText>
<subsectionHeader confidence="0.994814">
4.2 Measuring translational entropy
</subsectionHeader>
<bodyText confidence="0.999780058823529">
According to our intuition it is harder to align
words in idiomatic expressions than other words.
Thus, we expect a larger variety of links (includ-
ing erroneous alignments) for words in such ex-
pressions than for words taken from expressions
with a more literal meaning. For the latter, we
expect fewer alignment candidates, possibly with
only one dominant default translation. Entropy
is a good measure for the unpredictability of an
event. We like to use this measure for comparing
the alignment of our candidates and expect a high
average entropy for idiomatic expressions. In this
way we approximate a measure for meaning pre-
dictability.
For each word in a triple, we compute the en-
tropy of the aligned target words as shown in equa-
tion (1).
</bodyText>
<equation confidence="0.9924985">
H(Tsjs) = − � P(tjs)logP(tjs) (1)
t∈T3
</equation>
<bodyText confidence="0.998486">
This measure is equivalent to translational en-
tropy (Melamed, 1997b). P(tjs) is estimated as
the proportion of alignment t among all align-
ments of word s found in the corpus in the con-
text of the given triple.6 Finally, the translational
entropy of a triple is the average translational en-
tropy of its components. It is unclear how to
</bodyText>
<footnote confidence="0.9798555">
6Note that we also consider cases where s is part of an
aligned multi-word unit.
</footnote>
<page confidence="0.997406">
36
</page>
<bodyText confidence="0.9354955">
treat NO LINKS. Thus, we experiment with three
variants of entropy: (1) leaving out NO LINKS,
(2) counting NO LINKS as multiple types and (3)
counting all NO LINKS as one unique type.
</bodyText>
<subsectionHeader confidence="0.998078">
4.3 Proportion of default alignments (pda)
</subsectionHeader>
<bodyText confidence="0.99912">
If an expression has a literal meaning, we expect
the default alignments to be accurate literal trans-
lations. If an expression has idiomatic meaning,
the default alignments will be very different from
the links observed in the translations.
For each triple S, we count how often each of
its components s is linked to one of the default
alignments Ds. For the latter, we used the four
most frequent alignment types extracted from the
corresponding link lexicon as described in section
2. A large proportion of default alignments7 sug-
gests that the expression is very likely to have lit-
eral meaning; a low percentage is suggestive of
non-transparent meaning. Formally, pda is calcu-
lated in the following way:
</bodyText>
<equation confidence="0.4827055">
= Es∈S Ed∈D3 align f req(s, d) 2
pda(S) Es∈S Et∈T3 align f req(s, t) ( )
</equation>
<bodyText confidence="0.997463666666667">
where align freq(s, t) is the alignment fre-
quency of word s to word t in the context of the
triple S.
</bodyText>
<sectionHeader confidence="0.973434" genericHeader="method">
5 Discussion of experiments and results
</sectionHeader>
<bodyText confidence="0.999708684210526">
We experimented with the three word-alignment
types (src2trg, trg2src and refined) and the two
scoring methods (entropy and pda). The 200 can-
didate MWEs have been assessed and classified
into idiomatic or literal expressions by a human
expert. For assessing performance, standard pre-
cision and recall are not applicable in our case be-
cause we do not want to define an artificial cut-
off for our ranked list but evaluate the ranking it-
self. Instead, we measured the performance of
each alignment type and scoring method by ob-
taining another evaluation metric employed in in-
formation retrieval, uninterpolated average preci-
sion (uap), that aggregates precision points into
one evaluation figure. At each point c where a true
positive Sc in the retrieved list is found, the pre-
cision P(S1..Sc) is computed and, all precision
points are then averaged (Manning and Sch¨utze,
1999).
</bodyText>
<footnote confidence="0.693635">
7Note that we take NO LINKS into account when comput-
ing the proportions.
</footnote>
<equation confidence="0.911858">
(3)
|Sc|
</equation>
<bodyText confidence="0.999958">
We used the initial ranking of our candidates
as baseline. Our list of potential MWEs shows an
overall precision of 0.64 and an uap of 0.755.
</bodyText>
<subsectionHeader confidence="0.98469">
5.1 Comparing word alignment types
</subsectionHeader>
<bodyText confidence="0.98742">
Table 2 summarizes the results of using the en-
tropy measure (leaving out NO LINKS) with the
three alignment types for the NL-EN language
pair.8
</bodyText>
<table confidence="0.8128156">
Alignment uap
src2trg 0.864
trg2src 0.785
refined 0.765
baseline 0.755
</table>
<tableCaption confidence="0.996192">
Table 2: uap values of various alignments.
</tableCaption>
<bodyText confidence="0.9996315">
Using word alignments improves the ranking
of candidates in all three cases. Among them,
src2trg shows the best performance. This is
surprising because the quality of word-alignment
from English-to-Dutch (trg2src) in general is
higher due to differences in compounding in the
two languages. However, this is mainly an issue
for noun phrases which make up only one com-
ponent in the triples.
We assume that src2trg works better in our case
because in this alignment model we explicitly link
each word in the source language to exactly one
target word (or the empty word) whereas in the
trg2src model we often get multiple words (in the
target language) aligned to individual words in the
triple. Many errors are introduced in such align-
ment units. Table 3 illustrates this with an example
with links for the Dutch triple op prijs stel corres-
ponding to the expression iets op prijs stellen ’to
appreciate sth.’
</bodyText>
<table confidence="0.68648525">
src2trg trg2src
source target target source
NO LINK stellen
much appreciate indeed prijs
NO LINK op
gesteld be keenly appreciate stellen
prijs delighted
op NO LINK
</table>
<tableCaption confidence="0.951217">
Table 3: Example src2trg and trg2src alignments
for the triple OP PRIJS STEL.
</tableCaption>
<footnote confidence="0.9747925">
8The performance of the three alignment types remains
uniform across all chosen language pairs.
</footnote>
<figure confidence="0.984049">
uap =
E
Sc P(S1..Sc)
gesteld appreciate
prijs appreciate
op appreciate
fact prijs
NO LINK op
</figure>
<page confidence="0.997273">
37
</page>
<bodyText confidence="0.999968238095238">
src2trg alignment proposes appreciate as a link
to all three triple components. This type of align-
ment is not possible in trg2src. Instead, trg2src in-
cludes two NO LINKS in the first example in table
3. Furthermore, we get several multiword-units in
the target language linked to the triple compon-
ents also because of alignment errors. This way,
we end up with many NO LINKS and many align-
ment alternatives in trg2src that influence our en-
tropy scores. This can be observed for idiomatic
expressions as well as for literal expressions which
makes translational entropy less reliable in trg2src
alignments for contrasting these two types of ex-
pressions.
The refined alignment model starts with the in-
tersection of the two directional models and adds
iteratively links if they meet some adjacency con-
straints. This results in many NO LINKS and also
alignments with multiple words on both sides.
This seems to have the same negative effect as in
the trg2src model.
</bodyText>
<subsectionHeader confidence="0.999541">
5.2 Comparing scoring metrics
</subsectionHeader>
<bodyText confidence="0.9991648">
Table 4 offers a comparison of applying transla-
tional entropy and the pda across the three lan-
guage pairs. To produce these results, src2trg
alignment was used given that it reaches the best
performance (refer to Table 2).
</bodyText>
<table confidence="0.987677571428571">
Score NL-EN NL-ES NL-DE
entropy
- without NO LINKS 0.864 0.892 0.907
- NO LINKS=many 0.858 0.890 0.883
- NO LINKS=one 0.859 0.890 0.911
pda 0.891 0.894 0.894
baseline 0.755 0.755 0.755
</table>
<tableCaption confidence="0.907911">
Table 4: Translational entropy and the pda across
three language pairs. Alignment is src2trg.
</tableCaption>
<bodyText confidence="0.999072">
All scores produce better rankings than the
baseline. In general, pda achieves a slightly better
accuracy than entropy except for the NL-DE lan-
guage pair. Nevertheless, the difference between
the metrics is hardly significant.
</bodyText>
<subsectionHeader confidence="0.982214">
5.3 Further improvements
</subsectionHeader>
<bodyText confidence="0.999477473684211">
One problem in our data is that we deal with word-
form alignments and not with lemmatized ver-
sions. For Dutch, we know the lemma of each
word instance from our candidate set. However,
for the target languages, we only have access to
surface forms from the corpus. Naturally, inflec-
tional variations influence entropy scores (because
of the larger variety of alignment types) and also
the pda scores (where the exact wordforms have to
be matched with the default alignments instead of
lemmas). In order to test the effect of lemmatiz-
ation on different language pairs, we used CELEX
(Baayen et al., 1993) for English and German to
reduce wordforms in the alignments and in the link
lexicon to corresponding lemmas. We assigned the
most frequent lemma to ambiguous wordforms.
Table 5 shows the scores obtained from applying
lemmatization for the src2trg alignment using
entropy (without NO LINKS) and pda.
</bodyText>
<table confidence="0.9998068125">
Setting NL-EN NL-ES NL-DE
using entropy scores
with prepositions
wordforms 0.864 0.892 0.907
lemmas 0.873 – 0.906
without prepositions
wordforms 0.906 0.923 0.932
lemmas 0.910 – 0.931
using pda scores
with prepositions
wordforms 0.891 0.894 0.894
lemmas 0.888 – 0.903
without prepositions
wordforms 0.897 0.917 0.905
lemmas 0.900 – 0.910
baseline 0.755 0.755 0.755
</table>
<tableCaption confidence="0.727823333333333">
Table 5: Translational entropy and pda from
src2trg alignments across languages pairs with
different settings.
</tableCaption>
<bodyText confidence="0.999601727272727">
Surprisingly, lemmatization adds little or even
decreases the accuracy of the pda and entropy
scores. It is also surprising that lemmatization
does not affect the scores for morphologically
richer languages such as German (compared to
English). One possible reason for this is that
lemmatization discards morphological informa-
tion that is crucial to identify idiomatic expres-
sions. In fact, nouns in idiomatic expressions are
more fixed than nouns in literal expressions. By
contrast, verbs in idiomatic expressions often al-
low tense inflection. By clustering wordforms into
lemmas we lose this information. In future work,
we might lemmatize only the verb.
Another issue is the reliability of the word align-
ment that we base our investigation upon. We
want to make use of the fact that automatic word
alignment has problems with the alignment of in-
dividual words that belong to larger lexical units.
However, we believe that the alignment program
in general has problems with highly ambiguous
words such as prepositions. Therefore, preposi-
</bodyText>
<page confidence="0.997968">
38
</page>
<bodyText confidence="0.999550666666667">
tions might blur the contrast between idiomatic ex-
pressions and literal translations when measured
on the alignment of individual words. Table 5
includes scores for ranking our candidate expres-
sions with and without prepositions. We observe
that there is a large improvement when leaving out
the alignments of prepositions. This is consistent
for all language pairs and the scores we used for
ranking.
</bodyText>
<table confidence="0.89174088">
rank pda entropy MWE triple
breng tot stand ’create’
breng naar voren ’bring up’
kom in aanmerking ’qualify’
kom tot stand ’come about’
stel aan orde ’bring under discussion’
ga te werk ’act unfairly’
kom aan bod ’get a chance’
ga van start ’proceed’
stel aan kaak ’expose’
breng op gang ’get going’
kom ten goede ’benefit’
neem voor rekening ’pay costs’
kom tot uiting ’manifest’
houd in stand ’preserve’
breng in kaart ’chart’
breng onder aandacht ’bring to attention’
neem onder loep ’scrutinize’
breng aan licht ’reveal’
roep in leven ’set up’
neem in aanmerking ’consider’
leg aan band ’control’
houd voor gek ’pull s.o.’s leg’
kom te weten ’find out’
neem in ontvangst ’receive’
</table>
<bodyText confidence="0.635357264150943">
ga om waar ’go about where’
houd met daar ’keep with there’
ga om zaak ’go about issue’
kom tot overeenstemming ’come to terms’
breng in handel ’launch’
ga om bedrag ’go about amount’
blijk uit feit ’seems from fact’
ben van belang ’matter’
ga om kwestie ’go about issue’
voorzie in behoefte ’fill gap’
geef aan oproep ’make appeal’
houd met aspect ’keep with aspect’
houd aan regel ’adhere to rule’
stel vast met voldoening ’settle with satisfaction’
kom tot akkoord ’reach agreement’
breng in stemming ’get in mood’
sta op schroeven ’be unsettled’
voldoe aan criterium ’satisfy criterion’
beschik over informatie ’decide over information’
stem voor amendement ’vote for amending’
neem deel aan stemming ’participate in voting’
kan op aan ’be able to trust’
zeg tegen heer ’tell a gentleman’
verwijs terug naar commissie ’refer to comission’
stem tegen amendement ’vote againsta amending’
onthoud van stemming ’withhold one’s vote’
feliciteer met werk ’congratulate with work’
stem voor verslag ’vote for report’
schep van werkgelegenheid ’set up of employment’
stem voor resolutie ’vote for resolution ’
bedank voor feit ’thank for fact’
was wit van geld ’wash money’
stem tegen verslag ’vote against report’
schep van baan ’set up of job’
stem tegen resolutie ’vote against resolution’
dank voor antwoord ’thank for reply’
ontvang overeenkomstig artikel ’receive similar article’
recht van vrouw ’right of woman’
Table 6: Rank (using entropy), entropy score, and
pda score of 60 candidate MWEs.
Table 6 provides an excerpt from the ranked
list of candidate triples. The ranking has been
done using src2trg alignments from Dutch to Ger-
man with the best setting (see table 5). The score
assigned by the pda metric is also shown. The
column labeled MWE states whether the expres-
sion is idiomatic (’ok’) or literal (’*’). One issue
that emerges is whether we can find a threshold
value that splits candidate expressions into idio-
matic and transparent ones. One should choose
such a threshold empirically however, it will de-
pend on what level of precision is desirable and
also on the final application of the list.
</bodyText>
<sectionHeader confidence="0.996478" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999596333333333">
In this paper we have shown that assessing auto-
matic word alignment can help to identify idio-
matic multi-word expressions. We ranked candid-
ates according to their link variability using trans-
lational entropy and their link consistency with
regards to default alignments. For our experi-
ments we used a set of 200 Dutch MWE candid-
ates and word-aligned parallel corpora from Dutch
to English, Spanish and German. The MWE can-
didates have been extracted using standard associ-
ation measures and a head dependence heuristic.
The word alignment has been done using standard
models derived from statistical machine transla-
tion. Two measures were tested to re-rank the can-
didates. Translational entropy measures the pre-
dictability of the translation of an expression by
looking at the links of its components to a target
language. Ranking our 200 MWE candidates us-
ing entropy on Dutch to German word alignments
improved the baseline of 75.5% to 93.2% uninter-
polated average precision (uap). The proportion of
default alignments among the links found for MWE
components is another score we explored for rank-
ing our MWE candidates. Here, the accuracy is
rather similar giving us 91.7% while using the res-
ults of a directional alignment model from Dutch
to Spanish. In general, we obtain slightly better
results when using word alignment from Dutch to
German and Spanish, compared to alignment from
Dutch to English.
There emerge several extensions of this work
that we wish to address in the future. Alignment
types and scoring metrics need to be tested in lar-
ger lists of randomly selected MWE candidates to
see if the results remain unaltered. We also want to
apply some weighting scheme by using the num-
</bodyText>
<figure confidence="0.878307375">
1 9.80 8.3585 ok
2 9.24 8.0923 ok
3 16.40 7.8741 ok
4 15.33 7.8426 ok
5 8.70 7.4973 ok
6 5.65 7.4661 ok
7 17.46 7.4057 ok
8 9.38 7.1762 ok
9 14.15 7.1009 ok
10 18.75 7.0321 ok
11 13.00 6.9304 ok
12 1.78 6.8715 ok
13 20.99 6.7411 ok
14 1.41 6.7360 ok
15 0.81 6.6426 ok
16 16.71 6.5194 ok
17 10.25 6.4893 ok
18 7.83 6.4666 ok
19 5.99 6.4049 ok
20 15.89 6.3729 ok
...
100 1.72 4.6940 ok
101 14.91 4.6884 ok
102 23.56 4.6865 ok
103 15.38 4.6713 ok
104 31.57 4.6556 *
105 35.95 4.6380 *
106 34.86 4.6215 *
107 28.33 4.5846 ok
108 6.06 4.5715 ok
109 35.62 4.5370 *
110 22.58 4.5089 *
111 51.12 4.4063 ok
112 49.69 4.3921 *
113 23.61 4.3902 *
114 16.18 4.3568 ok
115 50.00 4.3254 *
116 40.91 4.3006 *
117 20.12 4.3002 *
118 36.90 4.2931 ok
119 36.49 4.2906 ok
120 14.06 4.2873 ok
...
180 70.53 2.7395 *
181 52.33 2.7351 *
182 74.71 2.6896 *
183 76.56 2.5883 *
184 30.26 2.4484 ok
185 68.89 2.3199 *
186 45.00 2.1113 *
187 80.39 2.0992 *
188 78.04 2.0924 *
189 77.63 1.9997 *
190 82.21 1.9020 *
191 77.78 1.9016 *
192 86.36 1.8775 *
193 73.33 1.8687 *
194 39.13 1.8497 *
195 82.20 1.7944 *
196 80.49 1.6443 *
197 86.17 1.4260 *
198 85.56 1.1779 *
199 90.55 1.0398 *
200 87.88 1.0258 *
</figure>
<page confidence="0.99699">
39
</page>
<bodyText confidence="0.9999262">
ber of NO LINKS per expression. Our assump-
tion is that an expression with many NO LINKS is
harder to translate compositionally, and probably
an idiomatic or ambiguous expression. Altern-
atively, an expression with no NO LINKS is very
predictable, thus a literal expression. Finally, an-
other possible improvement is combining several
language pairs. There might be cases where idio-
matic expressions are conceptualized in a similar
way in two languages. For example, a Dutch idio-
matic expression with a cognate expression in Ger-
man might be conceptualized in a different way in
Spanish. By combining the entropy or pda scores
for NL-EN, NL-DE and NL-ES the accuracy might
improve.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999514">
This research was carried out as part of the re-
search programs for IMIX, financed by NWO and
the IRME STEVIN project. We would also like
to thank the three anonymous reviewers for their
comments on an earlier version of this paper.
</bodyText>
<sectionHeader confidence="0.999445" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998800536585365">
R.H. Baayen, R. Piepenbrock, and H. van Rijn.
1993. The CELEX lexical database (CD-
ROM). Linguistic Data Consortium, University of
Pennsylvania,Philadelphia.
Timothy Baldwin. 2005. Looking for prepositional
verbs in corpus data. In Proc. of the 2nd ACL-
SIGSEM Workshop on the Linguistic Dimensions of
Prepositions and their use in computational linguist-
ics formalisms and applications, Colchester, UK.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Pro-
ceedings of the 43th Annual Meeting of the ACL,
pages 597–604, Ann Arbor. University of Michigan.
Miriam Butt. 2003. The light verb jungle.
http://ling.uni-konstanz.de/pages/
home/butt/harvard-work.pdf.
Ted Dunning. 1993. Accurate methods for the stat-
istics of surprise and coincidence. Computational
linguistics, 19(1):61—74.
Chitra Fernando and Roger Flavell. 1981. On idiom.
Critical views and perspectives, volume 5 of Exeter
Linguistic Studies. University of Exeter.
Bart Hollebrandse. 1993. Dutch light verb construc-
tions. Master’s thesis, Tilburg University, the Neth-
erlands.
K Imamura, E. Sumita, and Y. Matsumoto. 2003.
Automatic construction of machine translation
knowledge using translation literalness. In Proceed-
ings of the 10th EACL, pages 155–162, Budapest,
Hungary.
Adam Kilgarriff and David Tugwell. 2001. Word
sketch: Extraction &amp; display of significant colloc-
ations for lexicography. In Proceedings of the 39th
ACL &amp; 10th EACL -workshop ‘Collocation: Com-
putational Extraction, Analysis and Explotation’,
pages 32–38, Toulouse.
Philipp Koehn. 2003. Europarl: A multilin-
gual corpus for evaluation of machine trans-
lation. unpublished draft, available from
http://people.csail.mit.edu/koehn/publications/europarl/.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. The MIT Press, Cambridge, Massachu-
setts.
I. Dan Melamed. 1997a. Automatic discovery of non-
compositional compounds in parallel data. In 2nd
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’97), Providence, RI.
I. Dan Melamed. 1997b. Measuring semantic entropy.
In ACL-SIGLEX Workshop Tagging Text with Lex-
ical Semantics: Why, What and How, pages 41–46,
Washington.
Paola Merlo and Matthias Leybold. 2001. Automatic
distinction of arguments and modifiers: the case of
prepositional phrases. In Procs of the Fifth Com-
putational Natural Language Learning Workshop
(CoNLL–2001), pages 121–128, Toulouse. France.
Rosamund Moon. 1998. Fixed expressions and Idioms
in English. A corpus-based approach. Clarendom
Press, Oxford.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved alignment models for statist-
ical machine translation. In Proceedings of the Joint
SIGDAT Conference on Empirical Methods in Nat-
ural Language Processing and Very Large Corpora
(EMNLP/VLC), pages 20–28, University of Mary-
land, MD, USA.
Franz Josef Och. 2003. GIZA++: Training of
statistical translation models. Available from
http://www.isi.edu/˜och/GIZA++.html.
Ivan Sag, T. Baldwin, F. Bond, A. Copestake, and
D. Flickinger. 2001. Multiword expressions: a pain
in the neck for NLP. LinGO Working Paper No.
2001-03.
J¨org Tiedemann and Lars Nygaard. 2004. The OPUS
corpus - parallel &amp; free. In Proceedings of the
Fourth International Conference on Language Re-
sources and Evaluation (LREC’04), Lisbon, Por-
tugal.
Bego˜na Villada Moir´on. 2005. Data-driven Identi-
fication offixed expressions and their modifiability.
Ph.D. thesis, University of Groningen.
</reference>
<page confidence="0.998674">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.304478">
<title confidence="0.993017">Identifying idiomatic expressions using automatic word-alignment</title>
<author confidence="0.429953">Villada Moir´on</author>
<author confidence="0.429953">J¨org</author>
<affiliation confidence="0.4587065">Alfa Informatica, University of Oude Kijk in ’t Jatstraat</affiliation>
<address confidence="0.753387">9712 EK Groningen, The</address>
<abstract confidence="0.9981075">that require some sort of semantic interpretation it would be helpful to know what expressions exhibit an idiomatic meaning and what expressions exhibit a literal meaning. We investigate whether automatic word-alignment in existing parallel corpora facilitates the classification of candidate expressions along a continuum ranging from literal and transparent expressions to idiomatic and opaque expressions. Our method relies on two criteria: (i) meaning predictability that is measured as semantic entropy and (ii), the overlap between the meaning of an expression and the meaning of its component words. We approximate the mentioned overlap as the proportion of default alignments. We obtain a significant improvement over the baseline with both measures. In the remainder of this section, we present our characterization of idiomatic expressions, the motivation to use parallel corpora and related work. Section 2 describes the materials required to apply our method. Section 3 portraits the routine to extract a list of candidate expressions from automatically annotated data. Experiments with different word alignment types and metrics are shown in section 4. Our results are discussed in section 5. Finally, we draw some conclusions in section 6. 1.1 What are idiomatic expressions? Idiomatic expressions constitute a subset of multiword expressions (Sag et al., 2001). We assume that literal expressions can be distinguished from idiomatic expressions provided we know how their is The meaning of linguistic expressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>H van Rijn</author>
</authors>
<date>1993</date>
<booktitle>The CELEX lexical database (CDROM). Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania,Philadelphia.</institution>
<marker>Baayen, Piepenbrock, van Rijn, 1993</marker>
<rawString>R.H. Baayen, R. Piepenbrock, and H. van Rijn. 1993. The CELEX lexical database (CDROM). Linguistic Data Consortium, University of Pennsylvania,Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Looking for prepositional verbs in corpus data.</title>
<date>2005</date>
<booktitle>In Proc. of the 2nd ACLSIGSEM Workshop on the Linguistic Dimensions of Prepositions and their use in computational linguistics formalisms and applications,</booktitle>
<location>Colchester, UK.</location>
<contexts>
<context position="11342" citStr="Baldwin, 2005" startWordPosition="1790" endWordPosition="1792">3) and salience (Kilgarriff and Tugwell, 2001) scores were calculated. These scores have been shown to perform reasonably well in identifying collocations and other lexicalized expressions (Villada Moir´on, 2005). In addition, the head dependence between each PP in the candidates dataset and its selecting verbs was measured. Merlo and Leybold (2001) used the head dependence as a diagnostic to determine the argument (or adjunct) status of a PP. The head dependence is measured as the amount of entropy observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Baldwin, 2005). Using the two association measures and the head dependence heuristic, three different rankings of the candidate triples were produced. The three different ranks assigned to each triple were uniformly combined to form the final ranking. From this list, we selected the top 200 triples 4Available at http://www.let.rug.nl/ ˜vannoord/alp/Alpino. 5Butt (2003) maintains that the first 7 verbs are examples of support verbs crosslinguistically. The other 5 have been suggested for Dutch by (Hollebrandse, 1993). 35 which we considered a manageable size to test our method. 4 Methodology We examine how e</context>
</contexts>
<marker>Baldwin, 2005</marker>
<rawString>Timothy Baldwin. 2005. Looking for prepositional verbs in corpus data. In Proc. of the 2nd ACLSIGSEM Workshop on the Linguistic Dimensions of Prepositions and their use in computational linguistics formalisms and applications, Colchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43th Annual Meeting of the ACL,</booktitle>
<pages>597--604</pages>
<institution>Ann Arbor. University of Michigan.</institution>
<contexts>
<context position="2380" citStr="Bannard and Callison-Burch, 2005" startWordPosition="350" endWordPosition="353">ovided we know how their meaning is derived.1 The meaning of linguistic expressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions). 1 Introduction (1) Wat moeten lidstaten ondernemen om what must member states do to Knowing whether an expression receives a literal meaning or an idiomatic meaning is important for natural language processing applications that require some sort of semantic interpretation. Some applications that would benefit from knowing this distinction are machine translation (Imamura et al., 2003), finding paraphrases (Bannard and Callison-Burch, 2005), (multilingual) information retrieval (Melamed, 1997a), etc. The purpose of this paper is to explore to what extent word-alignment in parallel corpora can be used to distinguish idiomatic multiword expressions from more transparent multiword expressions and fully productive expressions. voldoen? meet? ‘What must EU member states do to meet her demands?’ politieke political barri`eres zeer duidelijk barriers very clearly ‘This situation brings the existing political limitations to light very clearly.’ 1Here, we ignore morpho-syntactic and pragmatic factors that could help model the distinction</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43th Annual Meeting of the ACL, pages 597–604, Ann Arbor. University of Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
</authors>
<title>The light verb jungle.</title>
<date>2003</date>
<note>http://ling.uni-konstanz.de/pages/ home/butt/harvard-work.pdf.</note>
<contexts>
<context position="9938" citStr="Butt, 2003" startWordPosition="1561" endWordPosition="1562">tence and word alignment have not been done. We rely entirely on the results of automatic processes. 3 Extracting candidates from corpora The Dutch section from the Europarl corpus was automatically parsed with Alpino, a Dutch widecoverage parser.4 1.25% of the sentences could not be parsed by Alpino, given the fact that many sentences are rather lengthy. We selected those sentences in the Dutch Europarl section that contain at least one of a group of verbs that can function as main or support verbs. Support verbs are prone to lexicalization or idiomatization along with their complementation (Butt, 2003). The selected verbs are: doen, gaan, geven, hebben, komen, maken, nemen, brengen, houden, krijgen, stellen and zitten.5 A fully parsed sentence is represented by the list of its dependency triples. From the dependency triples, each main verb is tallied with every dependent prepositional phrase (PP). In this way, we collected all the VERB PP tuples found in the selected documents. To avoid data sparseness, the NP inside the PP is reduced to the head noun’s lemma and verbs are lemmatized, too. Other potential arguments under a verb phrase node are ignored. A sample of more than 191,000 candidat</context>
<context position="11699" citStr="Butt (2003)" startWordPosition="1842" endWordPosition="1843"> head dependence as a diagnostic to determine the argument (or adjunct) status of a PP. The head dependence is measured as the amount of entropy observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Baldwin, 2005). Using the two association measures and the head dependence heuristic, three different rankings of the candidate triples were produced. The three different ranks assigned to each triple were uniformly combined to form the final ranking. From this list, we selected the top 200 triples 4Available at http://www.let.rug.nl/ ˜vannoord/alp/Alpino. 5Butt (2003) maintains that the first 7 verbs are examples of support verbs crosslinguistically. The other 5 have been suggested for Dutch by (Hollebrandse, 1993). 35 which we considered a manageable size to test our method. 4 Methodology We examine how expressions in the source language (Dutch) are conceptualized in a target language. The translations in the target language encode the meaning of the expression in the source language. Using the translation links in parallel corpora, we attempt to establish what type of meaning the expression in the source language has. To accomplish this we make use of th</context>
</contexts>
<marker>Butt, 2003</marker>
<rawString>Miriam Butt. 2003. The light verb jungle. http://ling.uni-konstanz.de/pages/ home/butt/harvard-work.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<booktitle>Computational linguistics,</booktitle>
<pages>19--1</pages>
<contexts>
<context position="10730" citStr="Dunning, 1993" startWordPosition="1691" endWordPosition="1692"> dependency triples. From the dependency triples, each main verb is tallied with every dependent prepositional phrase (PP). In this way, we collected all the VERB PP tuples found in the selected documents. To avoid data sparseness, the NP inside the PP is reduced to the head noun’s lemma and verbs are lemmatized, too. Other potential arguments under a verb phrase node are ignored. A sample of more than 191,000 candidates types (413,000 tokens) was collected. To ensure statistical significance, the types that occur less than 50 times were ignored. For each candidate triple, the log-likelihood (Dunning, 1993) and salience (Kilgarriff and Tugwell, 2001) scores were calculated. These scores have been shown to perform reasonably well in identifying collocations and other lexicalized expressions (Villada Moir´on, 2005). In addition, the head dependence between each PP in the candidates dataset and its selecting verbs was measured. Merlo and Leybold (2001) used the head dependence as a diagnostic to determine the argument (or adjunct) status of a PP. The head dependence is measured as the amount of entropy observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Ba</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational linguistics, 19(1):61—74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chitra Fernando</author>
<author>Roger Flavell</author>
</authors>
<title>On idiom. Critical views and perspectives,</title>
<date>1981</date>
<volume>5</volume>
<institution>of Exeter Linguistic Studies. University of Exeter.</institution>
<contexts>
<context position="4834" citStr="Fernando and Flavell (1981)" startWordPosition="738" endWordPosition="741"> unpredictable meaning (3). Put differently, the meaning of an idiomatic expression cannot be derived from the cumulative meaning of its constituent parts when they appear in isolation. 1.2 Why checking translations? This paper addresses the task of distinguishing literal (transparent) expressions from idiomatic expressions. Deciding what sort of meaning an expression shows can be done in two ways: • measuring how predictable the meaning of the expression is and • assessing the link between (a) the meaning of the expression as a whole and (b) the cumulative literal meanings of the components. Fernando and Flavell (1981) observe that no connection between (a) and (b) suggests the existence of opaque idioms and, a clear link between (a) and (b) is observed in clearly perceived metaphors and literal expressions. We believe we can approximate the meaning of an expression by looking up the expressions’ translation in a foreign language. Thus, we are interested in exploring to what extent parallel cor• regular words are translated (more or less) consistently, i.e. there will be one or only a few highly frequent translations whereas translation alternatives will be infrequent; • an expression has a (almost) literal</context>
</contexts>
<marker>Fernando, Flavell, 1981</marker>
<rawString>Chitra Fernando and Roger Flavell. 1981. On idiom. Critical views and perspectives, volume 5 of Exeter Linguistic Studies. University of Exeter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bart Hollebrandse</author>
</authors>
<title>Dutch light verb constructions. Master’s thesis,</title>
<date>1993</date>
<institution>Tilburg University, the Netherlands.</institution>
<contexts>
<context position="11849" citStr="Hollebrandse, 1993" startWordPosition="1865" endWordPosition="1866">py observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Baldwin, 2005). Using the two association measures and the head dependence heuristic, three different rankings of the candidate triples were produced. The three different ranks assigned to each triple were uniformly combined to form the final ranking. From this list, we selected the top 200 triples 4Available at http://www.let.rug.nl/ ˜vannoord/alp/Alpino. 5Butt (2003) maintains that the first 7 verbs are examples of support verbs crosslinguistically. The other 5 have been suggested for Dutch by (Hollebrandse, 1993). 35 which we considered a manageable size to test our method. 4 Methodology We examine how expressions in the source language (Dutch) are conceptualized in a target language. The translations in the target language encode the meaning of the expression in the source language. Using the translation links in parallel corpora, we attempt to establish what type of meaning the expression in the source language has. To accomplish this we make use of the three word-aligned parallel corpora from Europarl as described in section 2. Once the translation links of each expression in the source language ha</context>
</contexts>
<marker>Hollebrandse, 1993</marker>
<rawString>Bart Hollebrandse. 1993. Dutch light verb constructions. Master’s thesis, Tilburg University, the Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Imamura</author>
<author>E Sumita</author>
<author>Y Matsumoto</author>
</authors>
<title>Automatic construction of machine translation knowledge using translation literalness.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th EACL,</booktitle>
<pages>155--162</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2324" citStr="Imamura et al., 2003" startWordPosition="343" endWordPosition="347"> distinguished from idiomatic expressions provided we know how their meaning is derived.1 The meaning of linguistic expressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions). 1 Introduction (1) Wat moeten lidstaten ondernemen om what must member states do to Knowing whether an expression receives a literal meaning or an idiomatic meaning is important for natural language processing applications that require some sort of semantic interpretation. Some applications that would benefit from knowing this distinction are machine translation (Imamura et al., 2003), finding paraphrases (Bannard and Callison-Burch, 2005), (multilingual) information retrieval (Melamed, 1997a), etc. The purpose of this paper is to explore to what extent word-alignment in parallel corpora can be used to distinguish idiomatic multiword expressions from more transparent multiword expressions and fully productive expressions. voldoen? meet? ‘What must EU member states do to meet her demands?’ politieke political barri`eres zeer duidelijk barriers very clearly ‘This situation brings the existing political limitations to light very clearly.’ 1Here, we ignore morpho-syntactic and</context>
</contexts>
<marker>Imamura, Sumita, Matsumoto, 2003</marker>
<rawString>K Imamura, E. Sumita, and Y. Matsumoto. 2003. Automatic construction of machine translation knowledge using translation literalness. In Proceedings of the 10th EACL, pages 155–162, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>David Tugwell</author>
</authors>
<title>Word sketch: Extraction &amp; display of significant collocations for lexicography.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th ACL &amp; 10th EACL -workshop ‘Collocation: Computational Extraction, Analysis and Explotation’,</booktitle>
<pages>32--38</pages>
<location>Toulouse.</location>
<contexts>
<context position="10774" citStr="Kilgarriff and Tugwell, 2001" startWordPosition="1695" endWordPosition="1699"> dependency triples, each main verb is tallied with every dependent prepositional phrase (PP). In this way, we collected all the VERB PP tuples found in the selected documents. To avoid data sparseness, the NP inside the PP is reduced to the head noun’s lemma and verbs are lemmatized, too. Other potential arguments under a verb phrase node are ignored. A sample of more than 191,000 candidates types (413,000 tokens) was collected. To ensure statistical significance, the types that occur less than 50 times were ignored. For each candidate triple, the log-likelihood (Dunning, 1993) and salience (Kilgarriff and Tugwell, 2001) scores were calculated. These scores have been shown to perform reasonably well in identifying collocations and other lexicalized expressions (Villada Moir´on, 2005). In addition, the head dependence between each PP in the candidates dataset and its selecting verbs was measured. Merlo and Leybold (2001) used the head dependence as a diagnostic to determine the argument (or adjunct) status of a PP. The head dependence is measured as the amount of entropy observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Baldwin, 2005). Using the two association meas</context>
</contexts>
<marker>Kilgarriff, Tugwell, 2001</marker>
<rawString>Adam Kilgarriff and David Tugwell. 2001. Word sketch: Extraction &amp; display of significant collocations for lexicography. In Proceedings of the 39th ACL &amp; 10th EACL -workshop ‘Collocation: Computational Extraction, Analysis and Explotation’, pages 32–38, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A multilingual corpus for evaluation of machine translation.</title>
<date>2003</date>
<note>unpublished draft, available from http://people.csail.mit.edu/koehn/publications/europarl/.</note>
<contexts>
<context position="7631" citStr="Koehn, 2003" startWordPosition="1188" endWordPosition="1189">997a) investigates various techniques to identify non-compositional compounds in parallel data. Non-compositional compounds de the kaak cheek 34 are those sequences of 2 or more words (adjacent or separate) that show a conventionalized meaning. From English-French parallel corpora, Melamed’s method induces and compares pairs of translation models. Models that take into account non-compositional compounds are highly accurate in the identification task. 2 Data and resources We base our investigations on the Europarl corpus consisting of several years of proceedings from the European Parliament (Koehn, 2003). We focus on Dutch expressions and their translations into English, Spanish and German.2 Thus, we used the entire sections of Europarl in these three languages. The corpus has been tokenized and aligned at the sentence level (Tiedemann and Nygaard, 2004). The Dutch part contains about 29 million tokens in about 1.2 million sentences. The English, Spanish and German counterparts are of similar size between 28 and 30 million words in roughly the same number of sentences. Automatic word alignment has been done using GIZA++ (Och, 2003). We used standard settings of the system to produce Viterbi a</context>
</contexts>
<marker>Koehn, 2003</marker>
<rawString>Philipp Koehn. 2003. Europarl: A multilingual corpus for evaluation of machine translation. unpublished draft, available from http://people.csail.mit.edu/koehn/publications/europarl/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic discovery of noncompositional compounds in parallel data.</title>
<date>1997</date>
<booktitle>In 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP’97),</booktitle>
<location>Providence, RI.</location>
<contexts>
<context position="2433" citStr="Melamed, 1997" startWordPosition="358" endWordPosition="359">xpressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions). 1 Introduction (1) Wat moeten lidstaten ondernemen om what must member states do to Knowing whether an expression receives a literal meaning or an idiomatic meaning is important for natural language processing applications that require some sort of semantic interpretation. Some applications that would benefit from knowing this distinction are machine translation (Imamura et al., 2003), finding paraphrases (Bannard and Callison-Burch, 2005), (multilingual) information retrieval (Melamed, 1997a), etc. The purpose of this paper is to explore to what extent word-alignment in parallel corpora can be used to distinguish idiomatic multiword expressions from more transparent multiword expressions and fully productive expressions. voldoen? meet? ‘What must EU member states do to meet her demands?’ politieke political barri`eres zeer duidelijk barriers very clearly ‘This situation brings the existing political limitations to light very clearly.’ 1Here, we ignore morpho-syntactic and pragmatic factors that could help model the distinction. eisen te demands to aan at haar her (2) Deze this s</context>
<context position="6435" citStr="Melamed (1997" startWordPosition="1007" endWordPosition="1008">r will get into trouble when trying to align nondecomposable idiomatic expressions word by word. We expect the aligner to produce a large variety of links for each component word in such expressions and that these links are different from the default alignments found in the corpus otherwise. Bearing these assumptions in mind, our approach attempts to locate the translation of a MWE in a target language. On the basis of all reconstructed translations of a (potential) MWE, it is decided whether the original expression (in source language) is idiomatic or a more transparent one. 1.3 Related work Melamed (1997b) measures the semantic entropy of words using bitexts. Melamed computes the translational distribution T of a word s in a source language and uses it to measure the translational entropy of the word H(T|s); this entropy approximates the semantic entropy of the word that can be interpreted either as (a) the semantic ambiguity or (b) the inverse of reliability. Thus, a word with high semantic entropy is potentially very ambiguous and therefore, its translations are less reliable (or highly context-dependent). We also use entropy to approximate meaning predictability. Melamed (1997a) investigat</context>
<context position="15731" citStr="Melamed, 1997" startWordPosition="2515" endWordPosition="2516">ons with a more literal meaning. For the latter, we expect fewer alignment candidates, possibly with only one dominant default translation. Entropy is a good measure for the unpredictability of an event. We like to use this measure for comparing the alignment of our candidates and expect a high average entropy for idiomatic expressions. In this way we approximate a measure for meaning predictability. For each word in a triple, we compute the entropy of the aligned target words as shown in equation (1). H(Tsjs) = − � P(tjs)logP(tjs) (1) t∈T3 This measure is equivalent to translational entropy (Melamed, 1997b). P(tjs) is estimated as the proportion of alignment t among all alignments of word s found in the corpus in the context of the given triple.6 Finally, the translational entropy of a triple is the average translational entropy of its components. It is unclear how to 6Note that we also consider cases where s is part of an aligned multi-word unit. 36 treat NO LINKS. Thus, we experiment with three variants of entropy: (1) leaving out NO LINKS, (2) counting NO LINKS as multiple types and (3) counting all NO LINKS as one unique type. 4.3 Proportion of default alignments (pda) If an expression has</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997a. Automatic discovery of noncompositional compounds in parallel data. In 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP’97), Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Measuring semantic entropy.</title>
<date>1997</date>
<booktitle>In ACL-SIGLEX Workshop Tagging Text with Lexical Semantics: Why, What and How,</booktitle>
<pages>41--46</pages>
<location>Washington.</location>
<contexts>
<context position="2433" citStr="Melamed, 1997" startWordPosition="358" endWordPosition="359">xpressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions). 1 Introduction (1) Wat moeten lidstaten ondernemen om what must member states do to Knowing whether an expression receives a literal meaning or an idiomatic meaning is important for natural language processing applications that require some sort of semantic interpretation. Some applications that would benefit from knowing this distinction are machine translation (Imamura et al., 2003), finding paraphrases (Bannard and Callison-Burch, 2005), (multilingual) information retrieval (Melamed, 1997a), etc. The purpose of this paper is to explore to what extent word-alignment in parallel corpora can be used to distinguish idiomatic multiword expressions from more transparent multiword expressions and fully productive expressions. voldoen? meet? ‘What must EU member states do to meet her demands?’ politieke political barri`eres zeer duidelijk barriers very clearly ‘This situation brings the existing political limitations to light very clearly.’ 1Here, we ignore morpho-syntactic and pragmatic factors that could help model the distinction. eisen te demands to aan at haar her (2) Deze this s</context>
<context position="6435" citStr="Melamed (1997" startWordPosition="1007" endWordPosition="1008">r will get into trouble when trying to align nondecomposable idiomatic expressions word by word. We expect the aligner to produce a large variety of links for each component word in such expressions and that these links are different from the default alignments found in the corpus otherwise. Bearing these assumptions in mind, our approach attempts to locate the translation of a MWE in a target language. On the basis of all reconstructed translations of a (potential) MWE, it is decided whether the original expression (in source language) is idiomatic or a more transparent one. 1.3 Related work Melamed (1997b) measures the semantic entropy of words using bitexts. Melamed computes the translational distribution T of a word s in a source language and uses it to measure the translational entropy of the word H(T|s); this entropy approximates the semantic entropy of the word that can be interpreted either as (a) the semantic ambiguity or (b) the inverse of reliability. Thus, a word with high semantic entropy is potentially very ambiguous and therefore, its translations are less reliable (or highly context-dependent). We also use entropy to approximate meaning predictability. Melamed (1997a) investigat</context>
<context position="15731" citStr="Melamed, 1997" startWordPosition="2515" endWordPosition="2516">ons with a more literal meaning. For the latter, we expect fewer alignment candidates, possibly with only one dominant default translation. Entropy is a good measure for the unpredictability of an event. We like to use this measure for comparing the alignment of our candidates and expect a high average entropy for idiomatic expressions. In this way we approximate a measure for meaning predictability. For each word in a triple, we compute the entropy of the aligned target words as shown in equation (1). H(Tsjs) = − � P(tjs)logP(tjs) (1) t∈T3 This measure is equivalent to translational entropy (Melamed, 1997b). P(tjs) is estimated as the proportion of alignment t among all alignments of word s found in the corpus in the context of the given triple.6 Finally, the translational entropy of a triple is the average translational entropy of its components. It is unclear how to 6Note that we also consider cases where s is part of an aligned multi-word unit. 36 treat NO LINKS. Thus, we experiment with three variants of entropy: (1) leaving out NO LINKS, (2) counting NO LINKS as multiple types and (3) counting all NO LINKS as one unique type. 4.3 Proportion of default alignments (pda) If an expression has</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997b. Measuring semantic entropy. In ACL-SIGLEX Workshop Tagging Text with Lexical Semantics: Why, What and How, pages 41–46, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Matthias Leybold</author>
</authors>
<title>Automatic distinction of arguments and modifiers: the case of prepositional phrases.</title>
<date>2001</date>
<booktitle>In Procs of the Fifth Computational Natural Language Learning Workshop (CoNLL–2001),</booktitle>
<pages>121--128</pages>
<location>Toulouse. France.</location>
<contexts>
<context position="11079" citStr="Merlo and Leybold (2001)" startWordPosition="1742" endWordPosition="1745">uments under a verb phrase node are ignored. A sample of more than 191,000 candidates types (413,000 tokens) was collected. To ensure statistical significance, the types that occur less than 50 times were ignored. For each candidate triple, the log-likelihood (Dunning, 1993) and salience (Kilgarriff and Tugwell, 2001) scores were calculated. These scores have been shown to perform reasonably well in identifying collocations and other lexicalized expressions (Villada Moir´on, 2005). In addition, the head dependence between each PP in the candidates dataset and its selecting verbs was measured. Merlo and Leybold (2001) used the head dependence as a diagnostic to determine the argument (or adjunct) status of a PP. The head dependence is measured as the amount of entropy observed among the co-occurring verbs for a given PP as suggested in (Merlo and Leybold, 2001; Baldwin, 2005). Using the two association measures and the head dependence heuristic, three different rankings of the candidate triples were produced. The three different ranks assigned to each triple were uniformly combined to form the final ranking. From this list, we selected the top 200 triples 4Available at http://www.let.rug.nl/ ˜vannoord/alp/</context>
</contexts>
<marker>Merlo, Leybold, 2001</marker>
<rawString>Paola Merlo and Matthias Leybold. 2001. Automatic distinction of arguments and modifiers: the case of prepositional phrases. In Procs of the Fifth Computational Natural Language Learning Workshop (CoNLL–2001), pages 121–128, Toulouse. France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosamund Moon</author>
</authors>
<title>Fixed expressions and Idioms in English. A corpus-based approach.</title>
<date>1998</date>
<publisher>Clarendom Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="3814" citStr="Moon (1998)" startWordPosition="578" endWordPosition="579">n publicly op pora can help us to find out the type of meaning an expression has. For our approach we make the following assumptions: (3) Wij mogen ons hier niet bij we may us here not by stellen. state ‘We cannot agree but must denounce the situation openly.’ Literal and transparent meaning is associated with high meaning predictability. The meaning of an expression is fully predictable if it results from combining the meaning of its individual words when they occur in isolation (see (1)). When the expression undergoes a process of metaphorical interpretation its meaning is less predictable. Moon (1998) considers a continuum of transparent, semi-transparent and opaque metaphors. The more transparent metaphors have a rather predictable meaning (2); the more opaque have an unpredictable meaning (3). In general, an unpredictable meaning results from the fact that the meaning of the expression has been fossilized and conventionalized. In an uninformative context, idiomatic expressions have an unpredictable meaning (3). Put differently, the meaning of an idiomatic expression cannot be derived from the cumulative meaning of its constituent parts when they appear in isolation. 1.2 Why checking tran</context>
</contexts>
<marker>Moon, 1998</marker>
<rawString>Rosamund Moon. 1998. Fixed expressions and Idioms in English. A corpus-based approach. Clarendom Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC),</booktitle>
<pages>20--28</pages>
<location>University of Maryland, MD, USA.</location>
<contexts>
<context position="8518" citStr="Och et al., 1999" startWordPosition="1331" endWordPosition="1334">t contains about 29 million tokens in about 1.2 million sentences. The English, Spanish and German counterparts are of similar size between 28 and 30 million words in roughly the same number of sentences. Automatic word alignment has been done using GIZA++ (Och, 2003). We used standard settings of the system to produce Viterbi alignments of IBM model 4. Alignments have been produced for both translation directions (source to target and target to source) on tokenized plain text.3 We also used a well-known heuristics for combining the two directional alignments, the so-called refined alignment (Och et al., 1999). Word-to-word alignments have been merged such that words are connected with each other if they are linked to the same target. In this way we obtained three different word alignment files: source to target (src2trg) with possible multi-word units in the source language, target to source (trg2src) with possible multi-word units in the target language, and refined with possible multi-word units in both languages. We also created bilingual word type links from the different word-aligned corpora. These lists include alignment frequencies that we will use later on for extracting default alignments</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Franz Josef Och, Christoph Tillmann, and Hermann Ney. 1999. Improved alignment models for statistical machine translation. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC), pages 20–28, University of Maryland, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>GIZA++: Training of statistical translation models. Available from http://www.isi.edu/˜och/GIZA++.html.</title>
<date>2003</date>
<contexts>
<context position="8169" citStr="Och, 2003" startWordPosition="1278" endWordPosition="1279"> several years of proceedings from the European Parliament (Koehn, 2003). We focus on Dutch expressions and their translations into English, Spanish and German.2 Thus, we used the entire sections of Europarl in these three languages. The corpus has been tokenized and aligned at the sentence level (Tiedemann and Nygaard, 2004). The Dutch part contains about 29 million tokens in about 1.2 million sentences. The English, Spanish and German counterparts are of similar size between 28 and 30 million words in roughly the same number of sentences. Automatic word alignment has been done using GIZA++ (Och, 2003). We used standard settings of the system to produce Viterbi alignments of IBM model 4. Alignments have been produced for both translation directions (source to target and target to source) on tokenized plain text.3 We also used a well-known heuristics for combining the two directional alignments, the so-called refined alignment (Och et al., 1999). Word-to-word alignments have been merged such that words are connected with each other if they are linked to the same target. In this way we obtained three different word alignment files: source to target (src2trg) with possible multi-word units in </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. GIZA++: Training of statistical translation models. Available from http://www.isi.edu/˜och/GIZA++.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: a pain in the neck for NLP. LinGO Working Paper No.</title>
<date>2001</date>
<pages>2001--03</pages>
<contexts>
<context position="1660" citStr="Sag et al., 2001" startWordPosition="243" endWordPosition="246"> In the remainder of this section, we present our characterization of idiomatic expressions, the motivation to use parallel corpora and related work. Section 2 describes the materials required to apply our method. Section 3 portraits the routine to extract a list of candidate expressions from automatically annotated data. Experiments with different word alignment types and metrics are shown in section 4. Our results are discussed in section 5. Finally, we draw some conclusions in section 6. 1.1 What are idiomatic expressions? Idiomatic expressions constitute a subset of multiword expressions (Sag et al., 2001). We assume that literal expressions can be distinguished from idiomatic expressions provided we know how their meaning is derived.1 The meaning of linguistic expressions can be described within a scale that ranges from fully transparent to opaque (in figurative expressions). 1 Introduction (1) Wat moeten lidstaten ondernemen om what must member states do to Knowing whether an expression receives a literal meaning or an idiomatic meaning is important for natural language processing applications that require some sort of semantic interpretation. Some applications that would benefit from knowing</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2001</marker>
<rawString>Ivan Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger. 2001. Multiword expressions: a pain in the neck for NLP. LinGO Working Paper No. 2001-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
<author>Lars Nygaard</author>
</authors>
<title>The OPUS corpus - parallel &amp; free.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="7886" citStr="Tiedemann and Nygaard, 2004" startWordPosition="1228" endWordPosition="1231">ning. From English-French parallel corpora, Melamed’s method induces and compares pairs of translation models. Models that take into account non-compositional compounds are highly accurate in the identification task. 2 Data and resources We base our investigations on the Europarl corpus consisting of several years of proceedings from the European Parliament (Koehn, 2003). We focus on Dutch expressions and their translations into English, Spanish and German.2 Thus, we used the entire sections of Europarl in these three languages. The corpus has been tokenized and aligned at the sentence level (Tiedemann and Nygaard, 2004). The Dutch part contains about 29 million tokens in about 1.2 million sentences. The English, Spanish and German counterparts are of similar size between 28 and 30 million words in roughly the same number of sentences. Automatic word alignment has been done using GIZA++ (Och, 2003). We used standard settings of the system to produce Viterbi alignments of IBM model 4. Alignments have been produced for both translation directions (source to target and target to source) on tokenized plain text.3 We also used a well-known heuristics for combining the two directional alignments, the so-called refi</context>
</contexts>
<marker>Tiedemann, Nygaard, 2004</marker>
<rawString>J¨org Tiedemann and Lars Nygaard. 2004. The OPUS corpus - parallel &amp; free. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bego˜na Villada Moir´on</author>
</authors>
<title>Data-driven Identification offixed expressions and their modifiability.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Groningen.</institution>
<marker>Moir´on, 2005</marker>
<rawString>Bego˜na Villada Moir´on. 2005. Data-driven Identification offixed expressions and their modifiability. Ph.D. thesis, University of Groningen.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>